{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9adb0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models \n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006cffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python RNG\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# TF RNG\n",
    "from tensorflow.python.framework import random_seed\n",
    "random_seed.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e8c6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data = pd.read_csv(\"dataset/data.csv\", header=None)\n",
    "    labels = pd.read_csv(\"dataset/labels.csv\", header=None)\n",
    "    labels[\"label\"] = labels.apply(lambda x: x[0] > 0.5, axis=1)\n",
    "    labels.drop(labels.columns[:2], axis=1, inplace=True)\n",
    "\n",
    "    training_data, test_data, training_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(training_data.describe())\n",
    "    print(training_labels.describe())\n",
    "    print(test_data.describe())\n",
    "    print(test_labels.describe())\n",
    "\n",
    "    return training_data, training_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fccd365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = models.Sequential() # linear sequence of layers\n",
    "    model.add(layers.Dense(100, activation='relu', input_shape=(6,)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid')) # output probability \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(np.array(dataset[0]), np.array(dataset[1]), epochs=10, batch_size=128)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b9f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT TRY TO CHANGE THIS METHOD!\n",
    "def grade_model(model, dataset, silent=False):\n",
    "    lower = 0.75\n",
    "    upper = 0.92\n",
    "    scale = 20.0\n",
    "    bonus = 2.0\n",
    "    overfitting_margin = 0.5  # 0.5 percent are allowed!\n",
    "\n",
    "    train_data, train_label, test_data, test_labels = dataset\n",
    "    train_loss, train_acc = model.evaluate(train_data, train_label)\n",
    "    test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "    print(\"train_acc:\", train_acc)\n",
    "    print(\"test_acc:\", test_acc)\n",
    "    grade = (test_acc - lower) / (upper - lower)\n",
    "    overfitting = abs(test_acc - train_acc)\n",
    "    overfitting_penalty = max(overfitting*100.0 - overfitting_margin, 0.0) * 0.5  # overfitting and underfitting will be punished by 0.5 point/percent\n",
    "    grade = min(grade * scale, scale + bonus)      # you can get up to 2 points bonus for a high accuracy\n",
    "    grade = max(grade - overfitting_penalty, 0.0)  # but it will be cut down if overfitting/underfitting is present!\n",
    "    if not silent:\n",
    "        print(\"Accuracy  -  test: %s; training: %s; overfitting: %s\" % (test_acc, train_acc, overfitting))\n",
    "        print(\"Grade: %s (/%s + %s)  (overfitting penalty: %s)\" % (grade, scale, bonus, overfitting_penalty))\n",
    "    return grade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fbd2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_time = datetime.now()\n",
    "    # DO NOT MODIFY THIS CODE!\n",
    "    dataset = load_dataset()\n",
    "    print(\"dataset loaded %s\" % (datetime.now() - start_time))\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    model = train_model(dataset)\n",
    "    grade_model(model, dataset)\n",
    "    print(\"Done %s\" % (datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac23c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0            1            2            3            4  \\\n",
      "count  7996.000000  7996.000000  7996.000000  7996.000000  7996.000000   \n",
      "mean     19.299900    18.567659    17.618184    29.192346     0.662746   \n",
      "std      11.445249    10.847712     9.671252    16.222053     0.235469   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.095200   \n",
      "25%      10.000000    10.000000    10.000000    16.000000     0.467675   \n",
      "50%      18.000000    17.000000    17.000000    27.000000     0.706350   \n",
      "75%      27.000000    25.000000    24.000000    40.000000     0.869925   \n",
      "max      93.000000    71.000000    77.000000   108.000000     0.996300   \n",
      "\n",
      "                 5  \n",
      "count  7996.000000  \n",
      "mean      0.571307  \n",
      "std       0.078837  \n",
      "min       0.222460  \n",
      "25%       0.520457  \n",
      "50%       0.569641  \n",
      "75%       0.620721  \n",
      "max       0.882930  \n",
      "       label\n",
      "count   7996\n",
      "unique     2\n",
      "top     True\n",
      "freq    4686\n",
      "                 0            1            2            3            4  \\\n",
      "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
      "mean     19.312000    18.058500    17.364000    28.526000     0.656374   \n",
      "std      11.566008    10.225036     9.571798    15.880189     0.238366   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.106100   \n",
      "25%      10.000000    10.000000    10.000000    16.000000     0.458025   \n",
      "50%      18.000000    17.000000    16.000000    26.000000     0.692150   \n",
      "75%      27.000000    25.000000    24.000000    40.000000     0.871300   \n",
      "max      69.000000    60.000000    63.000000    91.000000     0.995000   \n",
      "\n",
      "                 5  \n",
      "count  2000.000000  \n",
      "mean      0.572125  \n",
      "std       0.079508  \n",
      "min       0.258931  \n",
      "25%       0.519806  \n",
      "50%       0.573426  \n",
      "75%       0.624904  \n",
      "max       0.832149  \n",
      "       label\n",
      "count   2000\n",
      "unique     2\n",
      "top     True\n",
      "freq    1214\n",
      "dataset loaded 0:00:00.116001\n",
      "Train on 7996 samples\n",
      "Epoch 1/10\n",
      "7996/7996 [==============================] - 1s 83us/sample - loss: 2.0873 - accuracy: 0.5038\n",
      "Epoch 2/10\n",
      "7996/7996 [==============================] - 0s 13us/sample - loss: 0.6595 - accuracy: 0.5734\n",
      "Epoch 3/10\n",
      "7996/7996 [==============================] - 0s 16us/sample - loss: 0.6052 - accuracy: 0.7029\n",
      "Epoch 4/10\n",
      "7996/7996 [==============================] - 0s 14us/sample - loss: 0.5608 - accuracy: 0.7518\n",
      "Epoch 5/10\n",
      "7996/7996 [==============================] - 0s 16us/sample - loss: 0.5158 - accuracy: 0.7825\n",
      "Epoch 6/10\n",
      "7996/7996 [==============================] - 0s 13us/sample - loss: 0.4801 - accuracy: 0.7969\n",
      "Epoch 7/10\n",
      "7996/7996 [==============================] - 0s 14us/sample - loss: 0.4501 - accuracy: 0.8122\n",
      "Epoch 8/10\n",
      "7996/7996 [==============================] - 0s 13us/sample - loss: 0.4308 - accuracy: 0.8170\n",
      "Epoch 9/10\n",
      "7996/7996 [==============================] - 0s 14us/sample - loss: 0.4132 - accuracy: 0.8227\n",
      "Epoch 10/10\n",
      "7996/7996 [==============================] - 0s 14us/sample - loss: 0.3981 - accuracy: 0.8292\n",
      "7996/7996 [==============================] - 0s 45us/sample - loss: 0.3889 - accuracy: 0.8365\n",
      "2000/2000 [==============================] - 0s 42us/sample - loss: 0.3930 - accuracy: 0.8360\n",
      "train_acc: 0.83654326\n",
      "test_acc: 0.836\n",
      "Accuracy  -  test: 0.836; training: 0.83654326; overfitting: 0.00054323673\n",
      "Grade: 10.117650032043455 (/20.0 + 2.0)  (overfitting penalty: 0.0)\n",
      "Done 0:00:03.243136\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff90e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
