<doc id="13588" url="https://en.wikipedia.org/wiki?curid=13588" title="History of Egypt">
History of Egypt

The history of Egypt has been long and rich, due to the flow of the Nile river, with its fertile banks and delta. Its rich history also comes from its native inhabitants and outside influence. Much of Egypt's ancient history was a mystery until the secrets of ancient Egyptian hieroglyphs were deciphered with the discovery and help of the Rosetta Stone. The Great Pyramid of Giza is the only one of the Seven Wonders of the Ancient World still standing. The Lighthouse of Alexandria, one of the other Seven Wonders, is gone. The Library of Alexandria was the only one of its kind for centuries.
Human settlement in Egypt dates back to at least 40,000 BC with Aterian tool manufacturing. Ancient Egyptian civilization coalesced around 3150 BC with the political unification of Upper and Lower Egypt under the first pharaoh of the First Dynasty, Narmer. Predominately native Egyptian rule lasted until the conquering of Egypt by the Achaemenid Persian Empire in the 6th century BC.
In 332 BC, Macedonian ruler Alexander the Great conquered Egypt as he toppled the Achaemenids and established the Hellenistic Ptolemaic Kingdom, whose first ruler was one of Alexander's former generals, Ptolemy I Soter. The Ptolemies had to fight native rebellions and were involved in foreign and civil wars that led to the decline of the kingdom and its final annexation by Rome. The death of Cleopatra ended the nominal independence of Egypt resulting in Egypt becoming one of the provinces of the Roman Empire.
Roman rule in Egypt (including Byzantine) lasted from 30 BC to 641 AD, with a brief Sassanid Persian interlude between 619-629, known as Sasanian Egypt. After the Islamic conquest of Egypt, parts of Egypt became provinces of successive Caliphates and other Muslim dynasties: Rashidun Caliphate (632-661), Umayyad Caliphate (661–750), Abbasid Caliphate (750-909), Fatimid Caliphate (909-1171), Ayyubid Sultanate (1171–1260), and the Mamluk Sultanate of Egypt (1250-1517). In 1517, Ottoman sultan Selim I captured Cairo, absorbing Egypt into the Ottoman Empire.
Egypt remained entirely Ottoman until 1867, except during French occupation from 1798 to 1801. Starting in 1867, Egypt became a nominally autonomous tributary state called the Khedivate of Egypt. However, Khedivate Egypt fell under British control in 1882 following the Anglo-Egyptian War. After the end of World War I and following the Egyptian Revolution of 1919, the Kingdom of Egypt was established. While a "de facto" independent state, the United Kingdom retained control over foreign affairs, defense, and other matters. British occupation lasted until 1954, with the Anglo-Egyptian agreement of 1954.
The modern Republic of Egypt was founded in 1953, and with the complete withdrawal of British forces from the Suez Canal in 1956, it marked the first time in 2,300 years that Egypt was both fully independent and ruled by native Egyptians. President Gamal Abdel Nasser (president from 1956 to 1970) introduced many reforms and created the short-lived United Arab Republic (with Syria). His terms also saw the Six Day War and the creation of the international Non-Aligned Movement. His successor, Anwar Sadat (president from 1970 to 1981) changed Egypt's trajectory, departing from many of the political, and economic tenets of Nasserism, re-instituting a multi-party system, and launching the Infitah economic policy. He led Egypt in the Yom Kippur War of 1973 to regain Egypt's Sinai Peninsula, which Israel had occupied since the Six-Day War of 1967. This later led to the Egypt–Israel Peace Treaty.
Recent Egyptian history has been dominated by events following nearly thirty years of rule by former president Hosni Mubarak. In 2011, Egypt underwent a revolution that deposed Mubarak and resulted in the first democratically elected president in Egyptian history, Mohamed Morsi. Unrest after the 2011 revolution and related disputes led to the 2013 Egyptian coup d'état.
Prehistory (pre–3100 BC).
There is evidence of rock carvings along the Nile terraces and in desert oases. In the 10th millennium BC, a culture of hunter-gatherers and fishermen was replaced by a grain-grinding culture. Climate changes and/or overgrazing around 6000 BC began to desiccate the pastoral lands of Egypt, forming the Sahara. Early tribal peoples migrated to the Nile River, where they developed a settled agricultural economy and more centralized society.
By about 6000 BC, a Neolithic culture rooted in the Nile Valley. During the Neolithic era, several predynastic cultures developed independently in Upper and Lower Egypt. The Badarian culture and the successor Naqada series are generally regarded as precursors to dynastic Egypt. The earliest known Lower Egyptian site, Merimda, predates the Badarian by about seven hundred years. Contemporaneous Lower Egyptian communities coexisted with their southern counterparts for more than two thousand years, remaining culturally distinct, but maintaining frequent contact through trade. The earliest known evidence of Egyptian hieroglyphic inscriptions appeared during the predynastic period on Naqada III pottery vessels, dated to about 3200 BC.
Ancient Egypt (3100–332 BC).
A unified kingdom was founded 3150 BC by King Menes, leading to a series of dynasties that ruled Egypt for the next three millennia. Egyptian culture flourished during this long period and remained distinctively Egyptian in its religion, arts, language and customs. The first two ruling dynasties of a unified Egypt set the stage for the Old Kingdom period, "c". 2700–2200 BC., which constructed many pyramids, most notably the Third Dynasty pyramid of Djoser and the Fourth Dynasty Giza Pyramids.
The First Intermediate Period ushered in a time of political upheaval for about 150 years. Stronger Nile floods and stabilization of government, however, brought back renewed prosperity for the country in the Middle Kingdom "c". 2040 BC, reaching a peak during the reign of Pharaoh Amenemhat III. A second period of disunity heralded the arrival of the first foreign ruling dynasty in Egypt, that of the Semitic Hyksos. The Hyksos invaders took over much of Lower Egypt around 1650 BC and founded a new capital at Avaris. They were driven out by an Upper Egyptian force led by Ahmose I, who founded the Eighteenth Dynasty and relocated the capital from Memphis to Thebes.
The New Kingdom, "c". 1550–1070 BC, began with the Eighteenth Dynasty, marking the rise of Egypt as an international power that expanded during its greatest extension to an empire as far south as Tombos in Nubia, and included parts of the Levant in the east. This period is noted for some of the most well known Pharaohs, including Hatshepsut, Thutmose III, Akhenaten and his wife Nefertiti, Tutankhamun and Ramesses II. The first historically attested expression of monotheism came during this period as Atenism. Frequent contacts with other nations brought new ideas to the New Kingdom. The country was later invaded and conquered by Libyans, Nubians and Assyrians, but native Egyptians eventually drove them out and regained control of their country.
First Persian rule.
In the 6th century BC, the Achaemenid Persians conquered Egypt. The entire Twenty-seventh Dynasty of Egypt, from 525 BC to 402 BC, save for Petubastis III, was an entirely Persian ruled period, with the Achaemenid kings being granted the title of pharaoh.
The Thirtieth Dynasty was the last native ruling dynasty during the Pharaonic epoch. It fell to the Persians again in 343 BC after the last native Pharaoh, King Nectanebo II, was defeated in battle.
Second Persian rule.
The Thirty-first Dynasty of Egypt also known as the Second Egyptian Satrapy was effectively a short-living province of the Achaemenid Persian Empire between 343 BC to 332 BC.
After an interval of independence, during which three indigenous dynasties reigned (the 28th, 29th, and 30th dynasty), Artaxerxes III (358–338 BC) reconquered the Nile valley for a brief second period (343–332 BC), which is called the Thirty-first Dynasty of Egypt, thus starting another period of pharaos of Persian origin.
Ptolemaic and Roman Egypt (332 BC–641 AD).
The Ptolemaic Kingdom was a powerful Hellenistic state, extending from southern Syria in the east, to Cyrene to the west, and south to the frontier with Nubia. Alexandria became the capital city and a center of Greek culture and trade. To gain recognition by the native Egyptian populace, they named themselves as the successors to the Pharaohs. The later Ptolemies took on Egyptian traditions, had themselves portrayed on public monuments in Egyptian style and dress, and participated in Egyptian religious life.
The last ruler from the Ptolemaic line was Cleopatra VII, who committed suicide following the burial of her lover Mark Antony, who had died in her arms (from a self-inflicted stab wound) after Octavian had captured Alexandria and her mercenary forces had fled.
The Ptolemies faced rebellions of native Egyptians, often caused by an unwanted regime, and were involved in foreign and civil wars that led to the decline of the kingdom and its annexation by Rome. Nevertheless, Hellenistic culture continued to thrive in Egypt well after the Muslim conquest.
Christianity was brought to Egypt by Saint Mark the Evangelist in the 1st century. Diocletian's reign marked the transition from the Roman to the Byzantine era in Egypt, when a great number of Egyptian Christians were persecuted. The New Testament had by then been translated into Egyptian. After the Council of Chalcedon in AD 451, a distinct Egyptian Coptic Church was firmly established.
Sassanid Egypt.
Sasanian Egypt (known in Middle Persian sources as Agiptus) refers to the brief rule of Egypt and parts of Libya by the Sasanian Empire, which lasted from 619 to 629, until the Sasanian rebel Shahrbaraz made an alliance with the Byzantine emperor Heraclius and had control over Egypt returned to him.
Arab and Ottoman Egypt (641–1882).
The Byzantines were able to regain control of the country after a brief Persian invasion early in the 7th century, until 639–42, when Egypt was invaded and conquered by the Islamic Empire by the Muslim Arabs. When they defeated the Byzantine Armies in Egypt, the Arabs brought Sunni Islam to the country. Early in this period, Egyptians began to blend their new faith with indigenous beliefs and practices, leading to various Sufi orders that have flourished to this day. These earlier rites had survived the period of Coptic Christianity.
Muslim rulers nominated by the Islamic Caliphate remained in control of Egypt for the next six centuries, with Cairo as the seat of the Caliphate under the Fatimids. With the end of the Kurdish Ayyubid dynasty, the Mamluks, a Turco-Circassian military caste, took control about AD 1250. By the late 13th century, Egypt linked the Red Sea, India, Malaya, and East Indies. They continued to govern the country until the conquest of Egypt by the Ottoman Turks in 1517, after which it became a province of the Ottoman Empire. The mid-14th-century Black Death killed about 40% of the country's population.
After the 15th century, the Ottoman invasion pushed the Egyptian system into decline. The defensive militarization damaged its civil society and economic institutions. The weakening of the economic system combined with the effects of plague left Egypt vulnerable to foreign invasion. Portuguese traders took over their trade. Egypt suffered six famines between 1687 and 1731. The 1784 famine cost it roughly one-sixth of its population.
The brief French invasion of Egypt led by Napoleon Bonaparte began in 1798. The expulsion of the French in 1801 by Ottoman, Mamluk, and British forces was followed by four years of anarchy in which Ottomans, Mamluks, and Albanians — who were nominally in the service of the Ottomans – wrestled for power. Out of this chaos, the commander of the Albanian regiment, Muhammad Ali (Kavalali Mehmed Ali Pasha) emerged as a dominant figure and in 1805 was acknowledged by the Sultan in Istanbul as his viceroy in Egypt; the title implied subordination to the Sultan but this was in fact a polite fiction: Ottoman power in Egypt was finished and Muhammad Ali, an ambitious and able leader, established a dynasty that was to rule Egypt until the revolution of 1952. In later years, the dynasty became a British puppet.
His primary focus was military: he annexed Northern Sudan (1820–1824), Syria (1833), and parts of Arabia and Anatolia; but in 1841 the European powers, fearful lest he topple the Ottoman Empire itself, forced him to return most of his conquests to the Ottomans, but he kept the Sudan and his title to Egypt was made hereditary. A more lasting result of his military ambition is that it required him to modernize the country. Eager to adopt the military (and therefore industrial) techniques of the great powers, he sent students to the West and invited training missions to Egypt. He built industries, a system of canals for irrigation and transport, and reformed the civil service.
The introduction in 1820 of long-staple cotton, the Egyptian variety of which became notable, transformed its agriculture into a cash-crop monoculture before the end of the century. The social effects of this were enormous: land ownership became concentrated and many foreigners arrived, shifting production towards international markets.
British Protectorate (1882–1953).
British indirect rule lasted from 1882, when the British succeeded in defeating the Egyptian Army at Tel el-Kebir in September and took control of the country, to the 1952 Egyptian revolution which made Egypt a republic and when British advisers were expelled.
Muhammad Ali was succeeded briefly by his son Ibrahim (in September 1848), then by a grandson Abbas I (in November 1848), then by Said (in 1854), and Isma'il (in 1863).
Abbas I was cautious. Said and Ismail were ambitious developers, but they spent beyond their means. The Suez Canal, built in partnership with the French, was completed in 1869. The cost of this and other projects had two effects: it led to enormous debt to European banks, and caused popular discontent because of the onerous taxation it required. In 1875 Ismail was forced to sell Egypt's share in the canal to the British Government. Within three years this led to the imposition of British and French controllers who sat in the Egyptian cabinet, and, "with the financial power of the bondholders behind them, were the real power in the Government."
Local dissatisfaction with Ismail and with European intrusion led to the formation of the first nationalist groupings in 1879, with Ahmad Urabi a prominent figure. In 1882 he became head of a nationalist-dominated ministry committed to democratic reforms including parliamentary control of the budget. Fearing a reduction of their control, Britain and France intervened militarily, bombarding Alexandria and crushing the Egyptian army at the battle of Tel el-Kebir. They reinstalled Ismail's son Tewfik as figurehead of a "de facto" British protectorate.
In 1914, the Protectorate was made official, and the title of the head of state, which in 1867 had changed from "pasha" to "khedive", was changed again to "sultan", to repudiate the vestigial suzerainty of the Ottoman sultan, who was backing the Central powers in the First World War. Abbas II was deposed as khedive and replaced by his uncle, Hussein Kamel, as sultan.
In 1906, the Dinshaway Incident prompted many neutral Egyptians to join the nationalist movement. After the First World War, Saad Zaghlul and the Wafd Party led the Egyptian nationalist movement to a majority at the local Legislative Assembly. When the British exiled Zaghlul and his associates to Malta on 8 March 1919, the country arose in its first modern revolution. The revolt led the UK government to issue a unilateral declaration of Egypt's independence on 22 February 1922.
The new government drafted and implemented a constitution in 1923 based on a parliamentary system. Saad Zaghlul was popularly elected as Prime Minister of Egypt in 1924. In 1936, the Anglo-Egyptian Treaty was concluded. Continued instability due to remaining British influence and increasing political involvement by the king led to the dissolution of the parliament in a military "coup d'état" known as the 1952 Revolution. The Free Officers Movement forced King Farouk to abdicate in support of his son Fuad.
British military presence in Egypt lasted until 1954.
Republican Egypt (since 1953).
On 18 June 1953, the Egyptian Republic was declared, with General Muhammad Naguib as the first President of the Republic. Naguib was forced to resign in 1954 by Gamal Abdel Nasserthe real architect of the 1952 movementand was later put under house arrest. Nasser assumed power as President in June 1956. British forces completed their withdrawal from the occupied Suez Canal Zone on 13 June 1956. He nationalized the Suez Canal on 26 July 1956, prompting the 1956 Suez Crisis.
In 1958, Egypt and Syria formed a sovereign union known as the United Arab Republic. The union was short-lived, ending in 1961 when Syria seceded, thus ending the union. During most of its existence, the United Arab Republic was also in a loose confederation with North Yemen (formerly the Mutawakkilite Kingdom of Yemen) known as the United Arab States.
In the 1967 Six Day War, Israel invaded and occupied Egypt's Sinai Peninsula and the Gaza Strip, which Egypt had occupied since the 1948 Arab–Israeli War. Three years later (1970), President Nasser died and was succeeded by Anwar Sadat. Sadat switched Egypt's Cold War allegiance from the Soviet Union to the United States, expelling Soviet advisors in 1972. He launched the Infitah economic reform policy, while clamping down on religious and secular opposition.
In 1973, Egypt, along with Syria, launched the October War, a surprise attack against the Israeli forces occupying the Sinai Peninsula and the Golan Heights. It was an attempt to regain part of the Sinai territory that Israel had captured six years earlier. Sadat hoped to seize some territory through military force, and then regain the rest of the peninsula by diplomacy. The conflict sparked an international crisis between the US and the USSR, both of whom intervened. The second UN-mandated ceasefire halted military action. While the war ended with a military stalemate, it presented Sadat with a political victory that later allowed him to regain the Sinai in return for peace with Israel.
Sadat made a historic visit to Israel in 1977, which led to the 1979 peace treaty in exchange for Israeli withdrawal from Sinai. Sadat's initiative sparked enormous controversy in the Arab world and led to Egypt's expulsion from the Arab League, but it was supported by most Egyptians. On 6 October 1981, Sadat and six diplomats were assassinated while observing a military parade commemorating the eighth anniversary of the October 1973 War. He was succeeded by Hosni Mubarak.
Terrorist insurgency.
In 1980s, 1990s, and 2000s, terrorist attacks in Egypt became numerous and severe, and began to target Christian Copts and foreign tourists as well as government officials. Some scholars and authors have credited Islamist writer Sayyid Qutb, who was executed in 1967, as the inspiration for the new wave of attacks.
The 1990s saw an Islamist group, Al-Gama'a al-Islamiyya, engage in an extended campaign of violence, from the murders and attempted murders of prominent writers and intellectuals, to the repeated targeting of tourists and foreigners. Serious damage was done to the largest sector of Egypt's economy—tourism—and in turn to the government, but it also devastated the livelihoods of many of the people on whom the group depended for support.
Victims of the campaign against the Egyptian state from 1992-1997 exceeded 1,200 and included the head of the counter-terrorism police (Major General Raouf Khayrat), a speaker of parliament (Rifaat al-Mahgoub), dozens of European tourists and Egyptian bystanders, and over 100 Egyptian police.
At times, travel by foreigners in parts of Upper Egypt was severely restricted and dangerous.
On 17 November 1997, 62 people, mostly tourists, were killed near Luxor. The assailants trapped the people in the Temple of Hatshepsut.
During this period, Al-Gama'a al-Islamiyya was given support by the governments of Iran and Sudan, as well as al-Qaeda. The Egyptian government received support during that time from the United States.
Civil unrest since 2011.
Revolution.
In 2003, the Egyptian Movement for Change, popularly known as "Kefaya", was launched to oppose the Mubarak regime and to establish democratic reforms and greater civil liberties.
On 25 January 2011, widespread protests began against Mubarak's government. The objective of the protest was the removal of Mubarak from power. These took the form of an intensive campaign of civil resistance supported by a very large number of people and mainly consisting of continuous mass demonstrations. By 29 January, it was becoming clear that Mubarak's government had lost control when a curfew order was ignored, and the army took a semi-neutral stance on enforcing the curfew decree. Some protesters, a very small minority in Cairo, expressed views against what they deemed was foreign interference, highlighted by the then-held view that the U.S. administration had failed to take sides, as well as linking the administration with Israel.
On 11 February 2011, Mubarak resigned and fled Cairo. Vice President Omar Suleiman announced that Mubarak had stepped down and that the Egyptian military would assume control of the nation's affairs in the short term. Jubilant celebrations broke out in Tahrir Square at the news. Mubarak may have left Cairo for Sharm el-Sheikh the previous night, before or shortly after the airing of a taped speech in which Mubarak vowed he would not step down or leave.
On 13 February 2011, the high level military command of Egypt announced that both the constitution and the parliament of Egypt had been dissolved. The parliamentary election was to be held in September.
A constitutional referendum was held on 19 March 2011. On 28 November 2011, Egypt held its first parliamentary election since the previous regime had been in power. Turnout was high and there were no reports of violence, although members of some parties broke the ban on campaigning at polling places by handing out pamphlets and banners. There were however complaints of irregularities.
Morsi's presidency.
The first round of a presidential election was held in Egypt on 23 and 24 May 2012. Mohamed Morsi won 25% of the vote and Ahmed Shafik, the last prime minister under deposed leader Hosni Mubarak, 24%. A second round was held on 16 and 17 June. On 24 June 2012, the election commission announced that Mohamed Morsi had won the election, making him the first democratically elected president of Egypt. According to official results, Morsi took 51.7 percent of the vote while Shafik received 48.3 percent. In August, 2013, former Israeli negotiator Yossi Beilin wrote that an Egyptian official had told him that the true results were the opposite, but the military gave the presidency to Morsi out of fear of unrest.
On 8 July 2012, Egypt's new president Mohamed Morsi announced he was overriding the military edict that dissolved the country's elected parliament and he called lawmakers back into session.
On 10 July 2012, the Supreme Constitutional Court of Egypt negated the decision by Morsi to call the nation's parliament back into session.
On 2 August 2012, Egypt's Prime Minister Hisham Qandil announced his 35-member cabinet comprising 28 newcomers including four from the influential Muslim Brotherhood, six others and the former military ruler Mohamed Hussein Tantawi as the Defence Minister from the previous Government.
On 22 November 2012,Morsi issued a declaration immunizing his decrees from challenge and seeking to protect the work of the constituent assembly drafting the new constitution. The declaration also requires a retrial of those accused in the Mubarak-era killings of protesters, who had been acquitted, and extends the mandate of the constituent assembly by two months. Additionally, the declaration authorizes Morsi to take any measures necessary to protect the revolution. Liberal and secular groups previously walked out of the constitutional constituent assembly because they believed that it would impose strict Islamic practices, while Muslim Brotherhood backers threw their support behind Morsi.
The move was criticized by Mohamed ElBaradei, the leader of Egypt's Constitution Party, who stated "Morsi today usurped all state powers & appointed himself Egypt's new pharaoh" on his Twitter feed. The move led to massive protests and violent action throughout Egypt. On 5 December 2012, Tens of thousands of supporters and opponents of Egypt's president clashed, hurling rocks and Molotov cocktails and brawling in Cairo's streets, in what was described as the largest violent battle between Islamists and their foes since the country's revolution. Six senior advisors and three other officials resigned from the government and the country's leading Islamic institution called on Morsi to stem his powers. Protesters also clamored from coastal cities to desert towns.
Morsi offered a "national dialogue" with opposition leaders but refused to cancel a 15 December vote on a draft constitution written by an Islamist-dominated assembly that has ignited two weeks of political unrest.
A constitutional referendum was held in two rounds on 15 and 22 December 2012, with 64% support, and 33% against. It was signed into law by a presidential decree issued by Morsi on 26 December 2012. On 3 July 2013, the constitution was suspended by order of the Egyptian army.
On 30 June 2013, on the first anniversary of the election of Morsi, millions of protesters across Egypt took to the streets and demanded the immediate resignation of the president. On 1 July, the Egyptian Armed Forces issued a 48-hour ultimatum that gave the country's political parties until 3 July to meet the demands of the Egyptian people. The presidency rejected the Egyptian Army's 48-hour ultimatum, vowing that the president would pursue his own plans for national reconciliation to resolve the political crisis. On 3 July, General Abdul Fatah al-Sisi, head of the Egyptian Armed Forces, announced that he had removed Morsi from power, suspended the constitution and would be calling new presidential and Shura Council elections and named Supreme Constitutional Court's leader, Adly Mansour as acting president. Mansour was sworn in on 4 July 2013.
After Morsi.
During the months after the coup d'état, a new constitution was prepared, which took effect on 18 January 2014. After that, presidential and parliamentary elections have to be held within 6 months.
On 24 March 2014, 529 Morsi's supporters were sentenced to death, while the trial of Morsi himself was still ongoing. Having delivered a final judgement, 492 sentences were commuted to life imprisonment with "only" 37 death sentences being upheld.
On 28 April, another mass trial took place with 683 Morsi supporters sentenced to death for killing 1 police officer.
In 2015, Egypt participated in the Saudi Arabian-led military intervention in Yemen.

</doc>
<doc id="13590" url="https://en.wikipedia.org/wiki?curid=13590" title="House">
House

A house is a building that functions as a home, ranging from simple dwellings such as rudimentary huts of nomadic tribes and the improvised shacks in shantytowns to complex, fixed structures of wood, brick, marble or other materials containing plumbing, ventilation and electrical systems. Most conventional modern houses in Western cultures will contain a bedroom, bathroom, kitchen or cooking area, and a living room. In traditional agriculture-oriented societies, domestic animals such as chickens or larger livestock (like cattle) may share part of the house with humans. The social unit that lives in a house is known as a household. Most commonly, a household is a family unit of some kind, although households may also be other social groups or individuals. The design and structure of the house is also subject to change as a consequence of globalization, urbanization and other social, economic, demographic, and technological reasons. Various other cultural factors also influence the building style and patterns of domestic space.
Etymology.
The English word "house" derives directly from the Old English "Hus" meaning "dwelling, shelter, home, house," which in turn derives from Proto-Germanic "Khusan" (reconstructed by etymological analysis) which is of unknown origin. The house itself gave rise to the letter 'B' through an early Proto-Semitic hieroglyphic symbol depicting a house. The symbol was called "bayt", "bet" or "beth" in various related languages, and became "beta", the Greek letter, before it was used by the Romans.
Elements.
Layout.
Ideally, architects of houses design rooms to meet the needs of the people who will live in the house. Such designing, known as "interior design", has become a popular subject in universities. Feng shui, originally a Chinese method of moving houses according to such factors as rain and micro-climates, has recently expanded its scope to address the design of interior spaces, with a view to promoting harmonious effects on the people living inside the house, although no actual effect has ever been demonstrated. Feng shui can also mean the "aura" in or around a dwelling, making it comparable to the real-estate sales concept of "indoor-outdoor flow".
The square footage of a house in the United States reports the area of "living space", excluding the garage and other non-living spaces. The "square metres" figure of a house in Europe reports the area of the walls enclosing the home, and thus includes any attached garage and non-living spaces. The number of floors or levels making up the house can affect the square footage of a home.
Parts.
Many houses have several large rooms with specialized functions and several very small rooms for other various reasons. These may include a living/eating area, a sleeping area, and (if suitable facilities and services exist) separate or combined washing and lavatory areas. Some larger properties may also feature rooms such as a spa room, indoor pool, indoor basketball court, and other 'non-essential' facilities. In traditional agriculture-oriented societies, domestic animals such as chickens or larger livestock (like cattle) often share part of the house with human beings. Most conventional modern houses will at least contain a bedroom, bathroom, kitchen or cooking area, and a living room. A typical "foursquare house" (as pictured) occurred commonly in the early history of the US where they were mainly built, with a staircase in the center of the house, surrounded by four rooms, and connected to other sections of the home (including in more recent eras a garage).
History of the interior.
Little is known about the earliest origin of the house and its interior, but it can be traced back to the simplest form of shelters. Roman architect Vitruvius' theories have claimed the first form of architecture as a frame of timber branches finished in mud, also known as the primitive hut.
Philip Tabor later states the contribution of 17th century Dutch houses as the foundation of houses today.
Communal rooms.
In the Middle Ages, the Manor Houses facilitated different activities and events. Furthermore, the houses accommodated numerous people, including family, relatives, employees, servants and their guests. Their lifestyles were largely communal, as areas such as the Great Hall enforced the custom of dining and meetings and the Solar intended for shared sleeping beds.
Interconnecting rooms.
During the 15th and 16th centuries, the Italian Renaissance Palazzo consisted of plentiful rooms of connectivity. Unlike the qualities and uses of the Manor Houses, most rooms of the palazzo contained no purpose, yet were given several doors. These doors adjoined rooms in which Robin Evans describes as a "matrix of discrete but thoroughly interconnected chambers." The layout allowed occupants to freely walk room to room from one door to another, thus breaking the boundaries of privacy. 
Although very public, the open plan encouraged sociality and connectivity for all inhabitants.
Corridor.
An early example of the segregation of rooms and consequent enhancement of privacy may be found in 1597 at the Beaufort House built in Chelsea. It was designed by English architect John Thorpe who wrote on his plans, "A Long Entry through all". The separation of the passageway from the room developed the function of the corridor. This new extension was revolutionary at the time, allowing the integration of one door per room, in which all universally connected to the same corridor. English architect Sir Roger Pratt states "the common way in the middle through the whole length of the house, the offices from one molesting the other by continual passing through them." Social hierarchies within the 17th century were highly regarded, as architecture was able to epitomize the servants and the upper class. More privacy is offered to the occupant as Pratt further claims, "the ordinary servants may never publicly appear in passing to and fro for their occasions there." This social divide between rich and poor favored the physical integration of the corridor into housing by the 19th century.
Sociologist Witold Rybczynski wrote, "the subdivision of the house into day and night uses, and into formal and informal areas, had begun." Rooms were changed from public to private as single entryways forced notions of entering a room with a specific purpose.
Employment-free house.
Compared to the large scaled houses in England and the Renaissance, the 17th Century Dutch house was smaller, and was only inhabited by up to four to five members. This was due to their embracing "self-reliance", in contrast to the dependence on servants, and a design for a lifestyle centered on the family. It was important for the Dutch to separate work from domesticity, as the home became an escape and a place of comfort. This way of living and the home has been noted as highly similar to the contemporary family and their dwellings. House layouts also incorporated the idea of the corridor as well as the importance of function and privacy.
By the end of the 17th Century, the house layout was soon transformed to become employment-free, enforcing these ideas for the future. This came in favour for the industrial revolution, gaining large-scale factory production and workers. The house layout of the Dutch and its functions are still relevant today.
The names of parts of a house often echo the names of parts of other buildings, but could typically include:
Technology and privacy.
The introduction of technology and electronic systems within the house has questioned the impressions of privacy as well as the segregation of work from home. Technological advances of surveillance and communications allow insight of personal habits and private lives. As a result, the "private becomes ever more public, the desire for a protective home life increases, fuelled by the very media that undermine it" writes Hill. Work also, has been altered due to the increase of communications. The "deluge of information", has expressed the efforts of work, conveniently gaining access inside the house. Although commuting is reduced, "the desire to separate working and living remains apparent." In Jonathan Hill's book "Immature Architecture", he identifies this new invasion of privacy as "Electromagnetic Weather". Natural or man-made weather remains concurrent inside or outside the house, yet the electromagnetic weather is able to generate within both positions. On the other hand, some architects have designed homes in which eating, working and living are brought together.
Construction.
In the United States, modern house-construction techniques include light-frame construction (in areas with access to supplies of wood) and adobe or sometimes rammed-earth construction (in arid regions with scarce wood-resources). Some areas use brick almost exclusively, and quarried stone has long provided walling. To some extent, aluminum and steel have displaced some traditional building materials. Increasingly popular alternative construction materials include insulating concrete forms (foam forms filled with concrete), structural insulated panels (foam panels faced with oriented strand board or fiber cement), and light-gauge steel framing and heavy-gauge steel framing.
More generally, people often build houses out of the nearest available material, and often tradition and/or culture govern construction-materials, so whole towns, areas, counties or even states/countries may be built out of one main type of material. For example, a large fraction of American houses use wood, while most British and many European houses utilize stone or brick or mud.
In the 1900s (decade), some house designers started using prefabrication. Sears, Roebuck & Co. first marketed their Sears Catalog Homes to the general public in 1908. Prefab techniques became popular after World War II. First small inside rooms framing, then later, whole walls were prefabricated and carried to the construction site. The original impetus was to use the labor force inside a shelter during inclement weather. More recently builders have begun to collaborate with structural engineers who use computers and finite element analysis to design prefabricated steel-framed homes with known resistance to high wind-loads and seismic forces. These newer products provide labor savings, more consistent quality, and possibly accelerated construction processes.
Lesser-used construction methods have gained (or regained) popularity in recent years. Though not in wide use, these methods frequently appeal to homeowners who may become actively involved in the construction process. They include:
Energy efficiency.
In the developed world, energy-conservation has grown in importance in house-design. Housing produces a major proportion of carbon emissions (30% of the total in the UK, for example).
Development of a number of low-energy building types and techniques continues. They include the zero-energy house, the passive solar house, the autonomous buildings, the superinsulated and houses built to the "Passivhaus" standard.
Earthquake protection.
One tool of earthquake engineering is base isolation which is increasingly used for earthquake protection. Base isolation is a collection of structural elements of a building that should substantially decouple it from the shaking ground thus protecting the building's integrity and enhancing its seismic performance. This technology, which is a kind of seismic vibration control, can be applied both to a newly designed building and to seismic upgrading of existing structures.
Normally, excavations are made around the building and the building is separated from the foundations. Steel or reinforced concrete beams replace the connections to the foundations, while under these, the isolating pads, or "base isolators", replace the material removed. While the "base isolation" tends to restrict transmission of the ground motion to the building, it also keeps the building positioned properly over the foundation. Careful attention to detail is required where the building interfaces with the ground, especially at entrances, stairways and ramps, to ensure sufficient relative motion of those structural elements.
Bamboo is an earthquake-resistant material, and is very versatile because it comes from fast-grow plants. Adding that bamboos are common in Asia, bamboo-made houses are popular in some Asian countries.
Found materials.
In many parts of the world, houses are constructed using scavenged materials. In Manila's Payatas neighborhood, slum houses are often made of material sourced from a nearby garbage dump.
In Dakar, it is not uncommon to see houses made of recycled materials standing atop a mixture of garbage and sand which serves as a foundation. The garbage-sand mixture is also used to protect the house from flooding.
Legal issues.
Buildings with historical importance have legal restrictions.
United Kingdom.
New houses in the UK are not covered by the Sale of Goods Act. When purchasing a new house the buyer has different legal protection than when buying other products. New houses in the UK are covered by a National House Building Council guarantee.
Identifying houses.
With the growth of dense settlement, humans designed ways of identifying houses and/or parcels of land. Individual houses sometimes acquire proper names; and those names may acquire in their turn considerable emotional connotations: see for example the house of "Howards End" or the castle of "Brideshead Revisited". A more systematic and general approach to identifying houses may use various methods of house numbering.
Animal houses.
Humans often build houses for domestic or wild animals, often resembling smaller versions of human domiciles. Familiar animal houses built by humans include birdhouses, henhouses and doghouses, while housed agricultural animals more often live in barns and stables.
Houses and symbolism.
Houses may express the circumstances or opinions of their builders or their inhabitants. Thus a vast and elaborate house may serve as a sign of conspicuous wealth, whereas a low-profile house built of recycled materials may indicate support of energy conservation.
Houses of particular historical significance (former residences of the famous, for example, or even just very old houses) may gain a protected status in town planning as examples of built heritage and/or of street scape. Commemorative plaques may mark such structures.
Home ownership provides a common measure of prosperity in economics. Contrast the importance of house-destruction, tent dwelling and house rebuilding in the wake of many natural disasters.
Peter Olshavsky's "House for the Dance of Death" provides a 'pataphysical variation on the house.

</doc>
<doc id="13593" url="https://en.wikipedia.org/wiki?curid=13593" title="Java applet">
Java applet

A Java applet is a small application which is written in Java and delivered to users in the form of bytecode. The user launches the Java applet from a web page, and the applet is then executed within a Java Virtual Machine (JVM) in a process separate from the web browser itself. A Java applet can appear in a frame of the web page, a new application window, Sun's AppletViewer, or a stand-alone tool for testing applets. Java applets were introduced in the first version of the Java language, which was released in 1995.
Java applets can be written in any programming language that compiles to Java bytecode. They are usually written in Java, but other languages such as Jython, JRuby, Pascal, Scala, or Eiffel (via SmartEiffel) may be used as well.
Java applets run at very fast speeds and, until 2011, they were many times faster than JavaScript. Unlike JavaScript, Java applets had access to 3D hardware acceleration, making them well-suited for non-trivial, computation-intensive visualizations. As browsers have gained support for hardware-accelerated graphics thanks to the canvas technology (or specifically WebGL in the case of 3D graphics), as well as just-in-time compiled JavaScript, the speed difference has become less noticeable.
Since Java's bytecode is cross-platform (or platform independent), Java applets can be executed by browsers (or other clients) for many platforms, including Microsoft Windows, FreeBSD, Unix, OS X and Linux.
Overview.
The Applets are used to provide interactive features to web applications that cannot be provided by HTML alone.They can capture mouse input and also have controls like buttons or check boxes. In response to user actions, an applet can change the provided graphic content. This makes applets well-suited for demonstration, visualization, and teaching. There are online applet collections for studying various subjects, from physics to heart physiology.
An applet can also be a text area only; providing, for instance, a cross-platform command-line interface to some remote system. If needed, an applet can leave the dedicated area and run as a separate window. However, applets have very little control over web page content outside the applet's dedicated area, so they are less useful for improving the site appearance in general, unlike other types of browser extensions (while applets like news tickers or WYSIWYG editors are also known). Applets can also play media in formats that are not natively supported by the browser.
Pages coded in HTML may embed parameters within them that are passed to the applet. Because of this, the same applet may have a different appearance depending on the parameters that were passed.
As applets were available before CSS and DHTML were standard, they were also widely used for trivial effects such as rollover navigation buttons. Heavily criticized, this usage is now declining.
Technical information.
Java applets are executed in a "sandbox" by most web browsers, preventing them from accessing local data like the clipboard or file system. The code of the applet is downloaded from a web server, after which the browser either embeds the applet into a web page or opens a new window showing the applet's user interface.
A Java applet extends the class , or in the case of a Swing applet, . The class which must override methods from the applet class to set up a user interface inside itself (codice_1) is a descendant of which is a descendant of . As applet inherits from container, it has largely the same user interface possibilities as an ordinary Java application, including regions with user specific visualization. 
The first implementations involved downloading an applet class by class. While classes are small files, there are often many of them, so applets got a reputation as slow-loading components. However, since .jars were introduced, an applet is usually delivered as a single file that has a size similar to an image file (hundreds of kilobytes to several megabytes).
The domain from where the applet executable has been downloaded is the only domain to which the usual (unsigned) applet is allowed to communicate. This domain can be different from the domain where the surrounding HTML document is hosted.
Java system libraries and runtimes are backwards-compatible, allowing one to write code that runs both on current and on future versions of the Java virtual machine.
Similar technologies.
Many Java developers, blogs and magazines are recommending that the Java Web Start technology be used in place of applets. Java Web Start allows the launching of unmodified applet code, which then runs in a separate window (not inside the invoking browser).
A Java Servlet is sometimes informally compared to be "like" a server-side applet, but it is different in its language, functions, and in each of the characteristics described here about applets.
Embedding into a web page.
The applet can be displayed on the web page by making use of the deprecated codice_2 HTML element, or the recommended codice_3 element. The codice_4 element can be used with Mozilla family browsers (codice_4 was deprecated in HTML 4 but is included in HTML 5). This specifies the applet's source and location. Both codice_3 and codice_4 tags can also download and install Java virtual machine (if required) or at least lead to the plugin page. codice_2 and codice_3 tags also support loading of the serialized applets that start in some particular (rather than initial) state. Tags also specify the message that shows up in place of the applet if the browser cannot run it due to any reason.
However, despite codice_3 being officially a recommended tag, as of 2010, the support of the codice_3 tag was not yet consistent among browsers and Sun kept recommending the older codice_2 tag for deploying in multibrowser environments, as it remained the only tag consistently supported by the most popular browsers. To support multiple browsers, the codice_3 tag currently requires JavaScript (that recognizes the browser and adjusts the tag), usage of additional browser-specific tags or delivering adapted output from the server side. Deprecating codice_2 tag has been criticized. Oracle now provides a maintained JavaScript code to launch applets with cross platform workarounds.
The Java browser plug-in relies on NPAPI, which many web browser vendors are deprecating due to its age and security issues. In January 2016, Oracle announced that Java runtime environments based on JDK 9 will discontinue the browser plug-in.
Example.
The following example illustrates the use of Java applets through the java.applet package. The example also uses classes from the Java Abstract Window Toolkit (AWT) to produce the message "Hello, world!" as output.
Simple applets are shared freely on the Internet for customizing applications that support plugins.
After compilation, the resulting .class file can be placed on a web server and invoked within an HTML page by using an <applet> or an <object> tag. For example:
When the page is accessed it will read as follows:
To minimize download time, applets can be delivered in the form of a jar file. In the case of this example, if all necessary classes are placed in the compressed archive "example.jar", the following embedding code could be used instead:
Applet inclusion is described in detail in Sun's official page about the APPLET tag.
Advantages.
A Java applet can have any or all of the following advantages:
Disadvantages.
A Java applet may have any of the following disadvantages compared to other client-side web technologies:
Compatibility-related lawsuits.
Sun has made considerable efforts to ensure compatibility is maintained between Java versions as they evolve, enforcing Java portability by law if required. Oracle seems to be continuing the same strategy.
1997 Sun vs Microsoft.
The 1997 lawsuit, was filed after Microsoft created a modified Java Virtual Machine of their own, which shipped with Internet Explorer. Microsoft added about 50 methods and 50 fields into the classes within the "java.awt, java.lang", and "java.io" packages. Other modifications included removal of RMI capability and replacement of Java native interface from JNI to RNI, a different standard. RMI was removed because it only easily supports Java to Java communications and competes with Microsoft DCOM technology. Applets that relied on these changes or just inadvertently used them worked only within Microsoft's Java system. Sun sued for breach of trademark, as the point of Java was that there should be no proprietary extensions and that code should work everywhere. Microsoft agreed to pay Sun $20 million, and Sun agreed to grant Microsoft limited license to use Java without modifications only and for a limited time.
2002 Sun vs Microsoft.
Microsoft continued to ship its own unmodified Java virtual machine. Over the years it became extremely outdated yet still default for Internet Explorer. A later study revealed that applets of this time often contain their own classes that mirror Swing and other newer features in a limited way. In 2002, Sun filed an antitrust lawsuit, claiming that Microsoft's attempts at illegal monopolization had harmed the Java platform. Sun demanded Microsoft distribute Sun's current, binary implementation of Java technology as part of Windows, distribute it as a recommended update for older Microsoft desktop operating systems and stop the distribution of Microsoft's Virtual Machine (as its licensing time, agreed in the prior lawsuit, had expired). Microsoft paid $700 million for pending antitrust issues, another $900 million for patent issues and a $350 million royalty fee to use Sun's software in the future.
2010 Oracle vs Google.
Google has developed their own Android platform that uses Java features and concepts, yet is incompatible with standard libraries. This may be a violation of conditions under which Sun granted OpenJDK patents to use open source Java for all. In 2010, Oracle sued Google for using Java "in a wrong way", claiming that "Google's Android competes with Oracle America's Java" and that "Google has been aware of Sun’s patent portfolio ... since Google hired certain former Sun Java engineers". In May 2012, the jury in this case found that Google did not infringe on Oracle's patents, and the trial judge ruled that the structure of the Java APIs used by Google was not copyrightable.
Security.
There are two applet types with very different security models: signed applets and unsigned applets. As of Java SE 7 Update 21 (April 2013) applets and Web-Start Apps are encouraged to be signed with a trusted certificate, and warning messages appear when running unsigned applets. Further starting with Java 7 Update 51 unsigned applets are blocked by default; they can be run by creating an exception in the Java Control Panel.
Unsigned.
Limits on unsigned applets are understood as "draconian": they have no access to the local filesystem and web access limited to the applet download site; there are also many other important restrictions. For instance, they cannot access all system properties, use their own class loader, call native code, execute external commands on a local system or redefine classes belonging to core packages included as part of a Java release. While they can run in a standalone frame, such frame contains a header, indicating that this is an untrusted applet. Successful initial call of the forbidden method does not automatically create a security hole as an access controller checks the entire stack of the calling code to be sure the call is not coming from an improper location.
As with any complex system, many security problems have been discovered and fixed since Java was first released. Some of these (like the Calendar serialization security bug) persisted for many years with nobody being aware. Others have been discovered in use by malware in the wild.
Some studies mention applets crashing the browser or overusing CPU resources but these are classified as nuisances and not as true security flaws. However, unsigned applets may be involved in combined attacks that exploit a combination of multiple severe configuration errors in other parts of the system. An unsigned applet can also be more dangerous to run directly on the server where it is hosted because while code base allows it to talk with the server, running inside it can bypass the firewall. An applet may also try DoS attacks on the server where it is hosted, but usually people who manage the web site also manage the applet, making this unreasonable. Communities may solve this problem via source code review or running applets on a dedicated domain.
The unsigned applet can also try to download malware hosted on originating server. However it could only store such file into a temporary folder (as it is transient data) and has no means to complete the attack by executing it. There were attempts to use applets for spreading Phoenix and Siberia exploits this way, but these exploits do not use Java internally and were also distributed in several other ways.
Signed.
A signed applet contains a signature that the browser should verify through a remotely running, independent certificate authority server. Producing this signature involves specialized tools and interaction with the authority server maintainers. Once the signature is verified, and the user of the current machine also approves, a signed applet can get more rights, becoming equivalent to an ordinary standalone program. The rationale is that the author of the applet is now known and will be responsible for any deliberate damage. This approach allows applets to be used for many tasks that are otherwise not possible by client-side scripting. However, this approach requires more responsibility from the user, deciding whom he or she trusts. The related concerns include a non-responsive authority server, wrong evaluation of the signer identity when issuing certificates, and known applet publishers still doing something that the user would not approve of. Hence signed applets that appeared from Java 1.1 may actually have more security concerns.
Self-signed.
Self-signed applets, which are applets signed by the developer themselves, may potentially pose a security risk; java plugins provide a warning when requesting authorization for a self-signed applet, as the function and safety of the applet is guaranteed only by the developer itself, and has not been independently confirmed. Such self-signed certificates are usually only used during development prior to release where third-party confirmation of security is unimportant, but most applet developers will seek third-party signing to ensure that users trust the applet's safety.
Java security problems are not fundamentally different from similar problems of any client-side scripting platform. In particular, all issues related to signed applets also apply to Microsoft ActiveX components.
As of approximately Jan 1 2014, self-signed and unsigned applets are no longer accepted by the commonly available java plugins or java web start. Consequently, developers who wish to deploy java applets have no alternative but to acquire trusted certificates from commercial sources.
Alternatives.
Alternative technologies exist (for example, JavaScript, Flash, signed SCSK Curl applets and Microsoft Silverlight) that satisfy some of the scope of what is possible with an applet. Of these, JavaScript is not always viewed as a competing replacement; JavaScript can coexist with applets in the same page, assist in launching applets (for instance, in a separate frame or providing platform workarounds) and later be called from the applet code. JavaFX is an extension of the Java platform and may also be viewed as an alternative.

</doc>
<doc id="13595" url="https://en.wikipedia.org/wiki?curid=13595" title="Heathrow Airport">
Heathrow Airport

Heathrow Airport is a major international airport in west London, England, United Kingdom. Heathrow is the busiest airport in the United Kingdom, busiest airport in Europe by passenger traffic, and sixth busiest airport in the world by total passenger traffic. In 2015, it handled a record 75 million passengers, a 2.2 percent increase from 2014.
Heathrow lies west of Central London, and has two parallel east–west runways along with four operational terminals on a site that covers . The airport is owned and operated by Heathrow Airport Holdings, which itself is owned by FGP TopCo Limited, an international consortium that includes Ferrovial Group (25.00%), Qatar Holding LLC (20.00%), Caisse de dépôt et placement du Québec (12.62%), Government of Singapore Investment Corporation (11.20%), Alinda Capital Partners (11.18%), China Investment Corporation (10.00%) and Universities Superannuation Scheme (USS) (10.00%). Heathrow is the primary hub for British Airways and the primary operating base for Virgin Atlantic.
In September 2012, the UK government established the Airports Commission, an independent commission chaired by Sir Howard Davies to examine various options for increasing capacity at UK airports. The commission shortlisted two options for expanding Heathrow in its interim report in 2013, along with a third option for expanding Gatwick Airport. The final report, published on 1 July 2015, backed a third runway at Heathrow.
Location.
Heathrow is west of central London, near the south end of the London Borough of Hillingdon on a parcel of land that is designated part of the Metropolitan Green Belt. The airport is surrounded by the built-up areas of Harlington, Harmondsworth, Longford and Cranford to the north and by Hounslow and Hatton to the east. To the south lie Bedfont and Stanwell while to the west Heathrow is separated from Slough in Berkshire by the M25 motorway. Heathrow falls entirely under the Hounslow post town of the TW postcode area.
As the airport is west of London and as its runways run east–west, an airliner's landing approach is usually directly over the conurbation of London when the wind is from the west.
Along with Gatwick, Stansted, Luton, Southend and London City, Heathrow is one of six airports with scheduled services serving the London area, although only Heathrow and London City are within Greater London.
History.
Heathrow Airport started in 1929 as a small airfield (Great West Aerodrome) on land south-east of the hamlet of Heathrow from which the airport takes its name. At that time there were farms, market gardens and orchards there: there was a "Heathrow Farm" about where Terminal 1 is now, a "Heathrow Hall" and a "Heathrow House". This hamlet was largely along a country lane (Heathrow Road) which ran roughly along the east and south edges of the present central terminals area.
Development of the whole Heathrow area as a very big airfield started in 1944: it was stated to be for long-distance military aircraft bound for the Far East. But by the time the airfield was nearing completion, World War II had ended. The government continued to develop the airfield as a civil airport; opened as London Airport in 1946 and renamed Heathrow Airport in 1966. The masterplan for the airport was designed by Sir Frederick Gibberd, who designed the original terminals and central area buildings, including the original control tower and multi-faith chapel of St George's.
Operations.
Facilities.
Heathrow Airport is used by over 90 airlines flying to 170 destinations worldwide. The airport is the primary hub of British Airways and is a base for Virgin Atlantic. It has four passenger terminals (numbered 2 to 5) and a cargo terminal. Of Heathrow's 73.4 million passengers in 2014, 93% were international travellers; the remaining 7% were bound for UK destinations. The busiest single destination in passenger numbers is New York, with over 3 million passengers flying between Heathrow and JFK Airport in 2013.
In the 1950s, Heathrow had six runways, arranged in three pairs at different angles in the shape of a hexagram (✡) with the permanent passenger terminal in the middle and the older terminal along the north edge of the field; two of its runways would always be within 30° of the wind direction. As the required length for runways has grown, Heathrow now has only two parallel runways running east–west. These are extended versions of the two east–west runways from the original hexagram. From the air, almost all of the original runways can still be seen, incorporated into the present system of taxiways. North of the northern runway and the former taxiway and aprons, now the site of extensive car parks, is the entrance to the access tunnel and the site of Heathrow's unofficial "gate guardian". For many years the home of a 40% scale model of a British Airways Concorde, G-CONC, the site has been occupied by a model of an Emirates Airbus A380 since 2008.
Heathrow Airport has Anglican, Catholic, free church, Hindu, Jewish, Muslim and Sikh chaplains. There is a multi-faith prayer room and counselling room in each terminal, in addition to St. George's Interdenominational Chapel in an underground vault adjacent to the old control tower, where Christian services take place. The chaplains organise and lead prayers at certain times in the prayer room.
The airport has its own resident press corps, consisting of six photographers and one TV crew, serving all the major newspapers and television stations around the world.
Most of Heathrow's internal roads are initial letter coded by area: N in the north (e.g. Newall Road), E in the east (e.g. Elmdon Road), S in the south (e.g. Stratford Road), W in the west (e.g. Walrus Road), C in the centre (e.g. Camborne Road).
Flight movements.
Aircraft destined for Heathrow usually enter its airspace via one of four main reporting points: Bovingdon "(BNN)" over Hertfordshire, Lambourne "(LAM)" over Essex, Biggin Hill "(BIG)" over Bromley and Ockham "(OCK)" over Surrey. Each is defined by a VOR radio-navigational beacon. When the airport is busy, aircraft orbit in the associated hold patterns. These holding areas lie to the northwest, northeast, southeast and southwest of the London conurbation. Aircraft hold between 7000 feet and 15000 feet at 1000 foot intervals. If these holds become full, aircraft are held at more distant points before being cleared onward to one of the four main holds.
Air traffic controllers at Heathrow Approach Control (based in Swanwick, Hampshire) then guide the aircraft to their final approach, merging aircraft from the four holds into a single stream of traffic, sometimes as close as apart. Considerable use is made of continuous descent approach techniques to minimise the environmental effects of incoming aircraft, particularly at night. Once an aircraft is established on its final approach, control is handed over to Heathrow Tower.
When runway alternation was introduced, aircraft generated significantly more noise on departure than when landing, so a preference for westerly operations during daylight was introduced, which continues to this day. In this mode, aircraft depart towards the west and approach from the east over London, thereby minimising the impact of noise on the most densely populated areas. Heathrow's two runways generally operate in segregated mode, whereby arriving aircraft are allocated to one runway and departing aircraft to the other. To further reduce noise nuisance to people beneath the approach and departure routes, the use of runways 27R and 27L is swapped at 15:00 each day if the wind is from the west. When landings are easterly there is no alternation; 09L remains the landing runway and 09R the departure runway due to the legacy of the now rescinded Cranford Agreement, pending taxiway works to allow the roles to be reversed. Occasionally, landings are allowed on the nominated departure runway, to help reduce airborne delays and to position landing aircraft closer to their terminal, reducing taxi times.
Night-time flights at Heathrow are subject to restrictions. Between 23:00 and 07:00, the noisiest aircraft (rated QC/8 and QC/16) cannot be scheduled for operation. In addition, during the night quota period (23:30–06:00) there are four limits:
A trial of "noise relief zones" ran from December 2012 to March 2013, which concentrated approach flight paths into defined areas compared with the existing paths which were spread out. The zones used alternated weekly, meaning residents in the "no-fly" areas received respite from aircraft noise for set periods. However, it was concluded that some residents in other areas experienced a significant disbenefit as a result of the trial and that it should therefore not be taken forward in its current form.
Regulation.
Until it was required to sell Gatwick and Stansted Airports, Heathrow Airport Holdings held a dominant position in the London aviation market, and has been heavily regulated by the Civil Aviation Authority (CAA) as to how much it can charge airlines to land. The annual increase in landing charge per passenger was capped at inflation minus 3% until 1 April 2003. From 2003 to 2007 charges increased by inflation plus 6.5% per year, taking the fee to £9.28 per passenger in 2007. In March 2008, the CAA announced that the charge would be allowed to increase by 23.5% to £12.80 from 1 April 2008 and by inflation plus 7.5% for each of the following four years. In April 2013, the CAA announced a proposal for Heathrow to charge fees calculated by inflation minus 1.3%, continuing until 2019. Whilst the cost of landing at Heathrow is determined by the CAA and Heathrow Airport Holdings, the allocation of landing slots to airlines is carried out by Airport Co-ordination Limited (ACL).
Until 2008, air traffic between Heathrow and the United States was strictly governed by the countries' bilateral Bermuda II treaty. The treaty originally allowed only British Airways, Pan Am and TWA to fly from Heathrow to the US. In 1991, PAA and TWA sold their rights to United Airlines and American Airlines respectively, while Virgin Atlantic was added to the list of airlines allowed to operate on these routes. The Bermuda bilateral agreement conflicted with the Right of Establishment of the United Kingdom in relation to its EU membership, and as a consequence the UK was ordered to drop the agreement in 2004. A new "open skies" agreement was signed by the United States and the European Union on 30 April 2007 and came into effect on 30 March 2008. Shortly afterwards, additional US airlines, including Northwest Airlines, Continental Airlines, US Airways and Delta Air Lines started services to Heathrow.
The airport has been criticised in recent years for overcrowding and delays; according to Heathrow Airport Holdings, Heathrow's facilities were originally designed to accommodate 55 million passengers annually. The number of passengers using the airport reached a record 70 million in 2012. In 2007 the airport was voted the world's least favourite, alongside Chicago O'Hare in a TripAdvisor survey. However, the opening of Terminal 5 in 2008 has relieved some pressure on terminal facilities, increasing the airport's terminal capacity to 90 million passengers per year. A tie-up is also in place with McLaren Applied Technologies to optimise the general procedure, reducing delays and pollution.
With only two runways, operating at over 98% of their capacity, Heathrow has little room for more flights, although the increasing use of larger aircraft such as the Airbus A380 will allow some increase in passenger numbers. It is difficult for existing airlines to obtain landing slots to enable them to increase their services from the airport, or for new airlines to start operations. To increase the number of flights, Heathrow Airport Holdings has proposed using the existing two runways in 'mixed mode' whereby aircraft would be allowed to take off and land on the same runway. This would increase the airport's capacity from its current 480,000 movements per year to as many as 550,000 according to British Airways CEO Willie Walsh. Heathrow Airport Holdings has also proposed building a third runway to the north of the airport, which would have significantly increased traffic capacity (see Future expansion below).
Security.
Policing of the airport is the responsibility of the aviation security unit of the Metropolitan Police, although the army, including armoured vehicles of the Household Cavalry, has occasionally been deployed at the airport during periods of heightened security.
Full body scanners are now used at the airport, and passengers who object to their use after being selected are required to submit to a hand search in a private room. The scanners display passengers' bodies as a cartoon-style figure, with indicators showing where concealed items may be. The new imagery was introduced initially as a trial in September 2011 following complaints over privacy.
Terminals.
Terminal 1.
The former Terminal 1, which closed in June 2015, originally opened in 1968 and was formally inaugurated by Queen Elizabeth II in May 1969. Before Terminal 5 opened, Terminal 1 was the base for British Airways' domestic (European) network from Heathrow and for a few of its long haul routes. The airline's owner International Airlines Group's acquisition of British Midland International in 2012 meant British Airways took over BMI's short-haul and medium-haul destinations from the terminal.
Terminal 1 is due to be demolished, and its site will be used for the extension of Terminal 2, which opened in June 2014. A number of newer boarding gates used by airlines at Terminal 1 were built as part of the Terminal 2 development will be retained for continued use by that terminal. British Airways was the last operator in Terminal 1. Two flights of this carrier, one departing to Hannover and one arriving from Baku, marked the terminal closure on 29 June 2015. British Airways operations have been relocated to Terminals 3 and 5.
Terminal 2.
The airport's newest terminal, officially known as the Queen's Terminal, was opened on 4 June 2014. Designed by Spanish architect Luis Vidal, it was built on the site previously occupied by the original Terminal 2 and the Queen's Building. The main complex was completed in November 2013 and underwent six months of testing before opening to passengers. It includes a satellite pier (T2B), a 1,340-space car park, an energy centre and a cooling station to generate chilled water. There are 52 shops and 17 bars and restaurants.
Terminal 2 is used by all Star Alliance members which fly from Heathrow (consolidating the airlines under Star Alliance's co-location policy "Move Under One Roof") with the exception of Air India which uses Terminal 4. Aer Lingus, Germanwings and Icelandair also operate from the terminal. The airlines moved from their original locations over a six-month period with only ten per cent of flights operating in the first six weeks (United Airlines' transatlantic flights) to avoid the opening problems seen at Terminal 5. Development will continue at the terminal to increase capacity in preparation for the closure of Terminal 3 in 2019.
The original Terminal 2 opened as the Europa Building in 1955 and was the airport's oldest terminal. It had an area of and was designed to handle around 1.2 million passengers annually. In its final years it accommodated up to 8 million. A total of 316 million passengers passed through the terminal in its lifetime. The building was demolished in 2010, along with the Queen's Building which contained the original control tower.
Terminal 3.
Terminal 3 opened as The Oceanic Terminal on 13 November 1961 to handle flight departures for long-haul routes for foreign carriers to the United States, Asia and other far eastern destinations. At this time the airport had a direct helicopter service to Central London from the gardens on the roof of the terminal building. Renamed Terminal 3 in 1968, it was expanded in 1970 with the addition of an arrivals building. Other facilities added included the UK's first moving walkways. In 2006, the new £105 million Pier 6 was completed to accommodate the Airbus A380 superjumbo; Emirates and Qantas operate regular flights from Terminal 3 using the Airbus A380.
Redevelopment of Terminal 3's forecourt through the addition of a new four lane drop-off area and a large pedestrianised plaza, complete with canopy to the front of the terminal building, was completed in 2007. These improvements were intended to improve passengers' experiences, reduce traffic congestion and improve security. As part of this project, Virgin Atlantic was assigned its own dedicated check-in area, known as 'Zone A', which features a large sculpture and atrium.
, Terminal 3 has an area of and in 2011 handled 19.8 million passengers on 104,100 flights. In May 2015, it has been announced that Terminal 3 will be demolished by 2019, when Terminal 2 has been completed.
Terminal 4.
Opened in 1986, Terminal 4 is situated to the south of the southern runway next to the cargo terminal and is connected to Terminals 1, 2 and 3 by the Heathrow Cargo Tunnel. The terminal has an area of and is now home to the SkyTeam alliance, as well as some unaffiliated carriers. It has recently undergone a £200m upgrade to enable it to accommodate 45 airlines with an upgraded forecourt to reduce traffic congestion and improve security. An extended check-in area with renovated piers and departure lounges, a new baggage system installed as well as the construction of two new stands to accommodate the Airbus A380 with Etihad Airways, Malaysia Airlines and Qatar Airways operating regular A380 flights.
Terminal 5.
Terminal 5 lies between the northern and southern runways at the western end of the Heathrow site and was opened by Queen Elizabeth II on 14 March 2008, some 19 years after its inception. It opened to the public on 27 March 2008, and British Airways and its partner company Iberia have exclusive use of this terminal. The first passenger to enter Terminal 5 was a UK ex-pat from Kenya who passed through security at 04:30 on the day to be presented with a boarding pass by the British Airways CEO Willie Walsh for the first departing flight, BA302 to Paris. During the two weeks after its opening, operations were disrupted by problems with the terminal's IT systems, coupled with insufficient testing and staff training, which caused over 500 flights to be cancelled. Until March 2012, Terminal 5 was exclusively used by British Airways as its global hub; however, because of the merger, on 25 March Iberia's operations at Heathrow were moved to the terminal, making it the home of International Airlines Group.
Built at a cost of £4.3 billion, the new terminal consists of a four-storey main terminal building (Concourse A) and two satellite buildings linked to the main terminal by an underground people mover transit system. The second satellite (Concourse C), includes dedicated aircraft stands for the Airbus A380. It became fully operational on 1 June 2011. Terminal 5 was voted Skytrax World's Best Airport Terminal 2014 in the Annual World Airport Awards.
The main terminal building (Concourse A) has an area of while Concourse B covers . It has 60 aircraft stands and capacity for 30 million passengers annually as well as more than 100 shops and restaurants.
A further building, designated Concourse D and of similar size to Concourse C, may yet be built to the east of the existing site, providing up to another 16 stands. Following British Airways' merger with Iberia, this may become a priority since the newly combined business will require accommodation at Heathrow under one roof to maximise the cost savings envisaged under the deal. A proposal for Concourse D featured in Heathrow's most recent capital investment plan.
The transport network around the airport has been extended to cope with the increase in passenger numbers. A dedicated motorway spur links the M25 between junctions 14 and 15 to the terminal, which includes a 3,800 space multi-storey car park. A more distant long-stay car park for business passengers is connected to the terminal by a personal rapid transit system, which became operational in the spring of 2011. New branches of both the Heathrow Express and the Underground's Piccadilly line serve a new shared Heathrow Terminal 5 station.
Terminal assignments and rearrangements.
Following the opening of Terminal 5 in March 2008, a hugely complex programme of terminal moves was implemented. This saw many airlines move so as to be grouped in terminals by airline alliance as far as possible.
Following the opening of Phase 1 of the new Terminal 2 in June 2014, all Star Alliance member airlines (with the exception of new member Air India) along with Aer Lingus, Germanwings and Virgin Atlantic Little Red domestic flights relocated to Terminal 2 in a phased process completed on 22 October 2014. Additionally, by 30 June 2015 all airlines left Terminal 1 in preparation for its demolition to make room for the construction of Phase 2 of Terminal 2.
Current terminal assignments.
As of 14 October 2015, the terminals are assigned as follows:
Scheduled terminal moves.
As of 28 March 2016, there have been currently no further terminal moves announced.
Airlines and destinations.
Passenger.
The following airlines operate regular scheduled flights at London Heathrow Airport:
Traffic and statistics.
Overview.
When ranked by passenger traffic, Heathrow is fifth busiest internationally, behind Hartsfield–Jackson Atlanta International Airport, Beijing Capital International Airport and Tokyo Haneda Airport, for the 12 months ending April 2015.
In 2015, Heathrow was the busiest airport in Europe in total passenger traffic, with 14% more passengers than Paris–Charles de Gaulle Airport and 22% more than Istanbul Atatürk Airport. Heathrow was the fourth busiest European airport by cargo traffic in 2013, after Frankfurt Airport, Paris Charles de Gaulle and Amsterdam Airport Schiphol.
Busiest routes.
The top seven domestic destinations are shown below:
Other facilities.
The head office of Heathrow Airport Holdings (formerly BAA Limited) is located in the Compass Centre by Heathrow's northern runway, a building that previously served as a British Airways flight crew centre. The World Business Centre Heathrow consists of buildings one and two. 1 World Business Centre houses offices of Heathrow Airport Holdings, Heathrow Airport itself, and Scandinavian Airlines. International Airlines Group has its head office in 2 World Business Centre.
At one time the British Airways head office was located within Heathrow Airport at Speedbird House before the completion of Waterside, the current BA head office in Harmondsworth, in June 1998.
To the north of the airfield lies the Northern Perimeter Road, along which most of Heathrow's car rental agencies are based and Bath Road, which runs parallel to it, but outside the airport campus–this is nicknamed by locals as "The Strip" owing to its continuous line of airport hotels.
Access.
Public transport.
Bus and coach.
Many buses and coaches operate from the large Heathrow airport central bus station serving Terminals 1, 2 and 3, and also from bus stations at Terminals 4 and 5. Services include the following:
Between 1981 and 2004, the airport was linked to central London by a group of routes known as Airbus. These routes carried A prefixes before their numbers; one route, A10, operates with such a number to Uxbridge.
Inter-terminal transport.
Terminals 1, 2 and 3 are within walking distance of each other. Transfers to Terminal 4 and 5 are by Heathrow Express trains or bus. Heathrow Express and Heathrow Connect services between Heathrow Central and Terminals 4 and 5 are free of charge. Normal fare rules apply to London Underground services between terminals. Local buses throughout the airport area are provided free of charge under the "Heathrow FreeFlow" scheme; passengers should tell the driver their destination to ensure they are not charged a fare.
Transit passengers remaining airside are provided free dedicated transfer buses between terminals.
ULTra Personal Rapid Transport opened in April 2011 to shuttle passengers between Terminal 5 and the business carpark at a speed of up to . There are 21 small transportation pods that can carry up to four adults, two children, and their luggage. The pods are battery-powered and are used on a four-kilometre track. The capsules run on demand. The provider claims a 95% availability rate and no accidents so far. Plans to use the same technology to connect terminals 2 and 3 to remote car parks were included in the draft 2014–2019 five-year master plan but have since been deferred due to other priorities.
Taxi.
Taxis are available at all terminals.
Car.
Heathrow is accessible via the nearby M4 motorway or A4 road (Terminals 1–3), the M25 motorway (Terminals 4 and 5) and the A30 road (Terminal 4). There are drop-off and pick-up areas at all terminals and short- and long-stay multi-storey car parks. All the Heathrow forecourts are drop-off only. There are further car parks, not run by Heathrow Airport Holdings, just outside the airport: the most recognisable is the National Car Parks facility, although there are many other options; these car parks are connected to the terminals by shuttle buses.
Four parallel tunnels under the northern runway connect the M4 Heathrow spur and the A4 road to Terminals 1–3. The two larger tunnels are each two lanes wide and are used for motorised traffic. The two smaller tunnels were originally reserved for pedestrians and bicycles; to increase traffic capacity the cycle lanes have been modified to each take a single lane of cars, although bicycles still have priority over cars. Pedestrian access to the smaller tunnels has been discontinued, with the free bus services being used instead.
Bicycle.
There are (mainly off-road) bicycle routes to some of the terminals. Free bicycle parking places are available in car parks 1 and 1A, at Terminal 4, and to the North and South of Terminal 5's Interchange Plaza.
Future expansion and plans.
Runway and terminal expansion.
In January 2009 the Transport Secretary Geoff Hoon announced that the UK government supported the expansion of Heathrow by building a third runway and a sixth terminal building. This decision followed the 2003 white paper on the future of air transport in the UK, and a public consultation in November 2007. This was a controversial decision which met with widespread opposition because of the expected greenhouse gas emissions, impact on local communities, as well as noise and air pollution concerns.
Before the 2010 General Election the Conservative and Liberal Democrats parties announced that they would prevent the construction of any third runway or further material expansion of the airport's operating capacity. The Mayor of London, Boris Johnson, has taken the position that London needs more airport capacity, but favours constructing an entirely new airport in the Thames Estuary rather than expanding Heathrow. After the Conservative – Liberal Democrat coalition took power, it was announced that the third runway expansion was cancelled. Two years later, leading Conservatives were reported to have changed their minds.
Another proposed plan for expanding Heathrow's capacity is the Heathrow Hub, which aims to extend both runways to a total length of about 7,000 metres and divide them into four so that they each provide two, full length runways, allowing simultaneous take-offs and landings while decreasing noise levels.
In July 2013, the airport submitted three new proposals for expansion to the Airports Commission, which was established to review airport capacity in the southeast of England. Each involved the construction of a third runway, either to the north, northwest or southwest of the airport. The commission released its interim report in December 2013, shortlisting the northwest third runway option at Heathrow, extending an existing runway at Heathrow and a second runway at Gatwick Airport. Following the publication of the interim report, the government confirmed that no options had been ruled out for airport expansion in the southeast and that a new runway would not be built at Heathrow before 2015. The full report was published on 1 July 2015, and backed a third northwest runway at Heathrow.
Reaction to the report was generally negative, particularly from London Mayor Boris Johnson. One senior Conservative told Channel 4: "Howard Davies has dumped an utter steaming pile of poo on the Prime Minister's desk."
Heathrow railway hub.
A plan to make Heathrow an international railway exchange has also been proposed with the potential construction of Heathrow Hub railway station, built on a link to the High Speed 2 railway line. This plan has since been scrapped.
Airtrack.
In July 2009, Heathrow Airport Limited submitted an application to the Secretary of State for Transport seeking to gain authorisation to develop a new rail link to Heathrow Terminal 5 to be known as Heathrow Airtrack. The rail link would address the current lack of public transport available to the South West of the Airport by connecting to Guildford, Reading and London Waterloo. BAA stated that the scheme should add significantly to its aim of increasing the proportion of people using public transport to travel to the airport. In April 2011 BAA announced that it was abandoning the project, citing the unavailability of government subsidy and other priorities for Heathrow, such as linking to Crossrail and HS2.
Heathrow/Gatwick rail link.
In late 2011 the Department for Transport began studying the feasibility of a high-speed rail link between Gatwick and Heathrow Airport. This rail link would form part of a plan to combine the UK's two biggest airports into a "collective" or "virtual hub" dubbed "Heathwick". The scheme envisages a high-speed rail route linking the two airports in 15 minutes, with trains travelling at a top speed of parallel to the M25 and passengers passing through immigration or check-in only once.
Heathrow City.
The Mayor of London's office and Transport for London commissioned plans in the event of Heathrow's closure—to replace it by a large built-up area. Some of the plans seem to show terminal 5, or part of it, kept as a shopping centre.
External links.
<br>

</doc>
<doc id="13600" url="https://en.wikipedia.org/wiki?curid=13600" title="Hipparchus">
Hipparchus

Hipparchus of Nicaea (; ;  ) was a Greek astronomer, geographer, and mathematician. He is considered the founder of trigonometry but is most famous for his incidental discovery of precession of the equinoxes.
Hipparchus was born in Nicaea, Bithynia (now Iznik, Turkey), and probably died on the island of Rhodes. He is known to have been a working astronomer at least from 162 to 127 . Hipparchus is considered the greatest ancient astronomical observer and, by some, the greatest overall astronomer of antiquity. He was the first whose quantitative and accurate models for the motion of the Sun and Moon survive. For this he certainly made use of the observations and perhaps the mathematical techniques accumulated over centuries by the Babylonians and other people from Mesopotamia. He developed trigonometry and constructed trigonometric tables, and he solved several problems of spherical trigonometry. With his solar and lunar theories and his trigonometry, he may have been the first to develop a reliable method to predict solar eclipses. His other reputed achievements include the discovery and measurement of Earth's precession, the compilation of the first comprehensive star catalog of the western world, and possibly the invention of the astrolabe, also of the armillary sphere, which he used during the creation of much of the star catalogue. It would be three centuries before Claudius Ptolemaeus' synthesis of astronomy would supersede the work of Hipparchus.
Life and work.
Relatively little of Hipparchus's direct work survives into modern times. Although he wrote at least fourteen books, only his commentary on the popular astronomical poem by Aratus was preserved by later copyists. Most of what is known about Hipparchus comes from Strabo's "Geography" and Pliny's "Natural History" in the 1st century; Ptolemy's 2nd-century "Almagest"; and additional references to him in the 4th century by Pappus of Alexandria and Theon of Alexandria in their commentaries on the "Almagest".
There is a strong tradition that Hipparchus was born in Nicaea (Greek "Νίκαια"), in the ancient district of Bithynia (modern-day Iznik in province Bursa), in what today is the country Turkey.
The exact dates of his life are not known, but Ptolemy attributes to him astronomical observations in the period from 147–127 , and some of these are stated as made in Rhodes; earlier observations since 162  might also have been made by him. His birth date ( ) was calculated by Delambre based on clues in his work. Hipparchus must have lived some time after 127  because he analyzed and published his observations from that year. Hipparchus obtained information from Alexandria as well as Babylon, but it is not known when or if he visited these places. He is believed to have died on the island of Rhodes, where he seems to have spent most of his later life.
It is not known what Hipparchus's economic means were nor how he supported his scientific activities. His appearance is likewise unknown: there are no contemporary portraits. In the 2nd and 3rd centuries coins were made in his honour in Bithynia that bear his name and show him with a globe; this supports the tradition that he was born there.
Hipparchus is thought to be the first to calculate a heliocentric system, but he abandoned his work because the calculations showed the orbits were not perfectly circular as believed to be mandatory by the science of the time. As an astronomer of antiquity his influence, supported by ideas from Aristotle, held sway for nearly 2000 years, until the heliocentric model of Copernicus.
Hipparchus's only preserved work is "Τῶν Ἀράτου καὶ Εὐδόξου φαινομένων ἐξήγησις" ("Commentary on the Phaenomena of Eudoxus and Aratus"). This is a highly critical commentary in the form of two books on a popular poem by Aratus based on the work by Eudoxus. Hipparchus also made a list of his major works, which apparently mentioned about fourteen books, but which is only known from references by later authors. His famous star catalog was incorporated into the one by Ptolemy, and may be almost perfectly reconstructed by subtraction of two and two thirds degrees from the longitudes of Ptolemy's stars. The first trigonometric table was apparently compiled by Hipparchus, who is now consequently known as "the father of trigonometry".
Modern speculation.
Hipparchus was in the international news in 2005, when it was again proposed (as in 1898) that the data on the celestial globe of Hipparchus or in his star catalog may have been preserved in the only surviving large ancient celestial globe which depicts the constellations with moderate accuracy, the globe carried by the Farnese Atlas. There are a variety of mis-steps in the more ambitious 2005 paper, thus no specialists in the area accept its widely publicized speculation.
Lucio Russo has said that Plutarch, in his work "On the Face in the Moon", was reporting some physical theories that we consider to be Newtonian and that these may have come originally from Hipparchus; he goes on to say that Newton may have been influenced by them. According to one book review, both of these claims have been rejected by other scholars.
A line in Plutarch's "Table Talk" states that Hipparchus counted 103049 compound propositions that can be formed from ten simple propositions; 103049 is the tenth Schröder–Hipparchus number and this line has led to speculation that Hipparchus knew about enumerative combinatorics, a field of mathematics that developed independently in modern mathematics.
Babylonian sources.
Earlier Greek astronomers and mathematicians were influenced by Babylonian astronomy to some extent, for instance the period relations of the Metonic cycle and Saros cycle may have come from Babylonian sources (see "Babylonian astronomical diaries"). Hipparchus seems to have been the first to exploit Babylonian astronomical knowledge and techniques systematically. Except for Timocharis and Aristillus, he was the first Greek known to divide the circle in 360 degrees of 60 arc minutes (Eratosthenes before him used a simpler sexagesimal system dividing a circle into 60 parts). He also used the Babylonian unit "pechus" ("cubit") of about 2° or 2.5°.
Hipparchus probably compiled a list of Babylonian astronomical observations; G. J. Toomer, a historian of astronomy, has suggested that Ptolemy's knowledge of eclipse records and other Babylonian observations in the "Almagest" came from a list made by Hipparchus. Hipparchus's use of Babylonian sources has always been known in a general way, because of Ptolemy's statements. However, Franz Xaver Kugler demonstrated that the synodic and anomalistic periods that Ptolemy attributes to Hipparchus had already been used in Babylonian ephemerides, specifically the collection of texts nowadays called "System B" (sometimes attributed to Kidinnu).
Hipparchus's long draconitic lunar period (5458 months = 5923 lunar nodal periods) also appears a few times in Babylonian records. But the only such tablet explicitly dated is post-Hipparchus so the direction of transmission is not settled by the tablets.
Hipparchus's draconitic lunar motion cannot be solved by the lunar-four arguments that are sometimes proposed to explain his anomalistic motion. A solution that has produced the exact 5458/5923 ratio is rejected by most historians though it uses the only anciently attested method of determining such ratios, and it automatically delivers the ratio's four-digit numerator and denominator. Hipparchus initially used ("Almagest" 6.9) his 141 B. C. E. eclipse with a Babylonian eclipse of 720 B. C. E. to find the less accurate ratio 7160 synodic months = 7770 draconitic months, simplified by him to 716 = 777 through division by 10. (He similarly found from the 345-year cycle the ratio 4267 synodic months = 4573 anomalistic months and divided by 17 to obtain the standard ratio 251 synodic months = 269 anomalistic months.) If he sought a longer time base for this draconitic investigation he could use his same 141 B. C. E. eclipse with a moonrise 1245 B. C. E. eclipse from Babylon, an interval of 13645 synodic months = 148807 1/2 draconitic months ≈ 14623 1/2 anomalistic months. Dividing by 5/2 produces 5458 synodic months = 5923 precisely. The obvious main objection is that the early eclipse is unattested though that is not surprising in itself and there is no consensus on whether Babylonian observations were recorded this remotely. Though Hipparchus's tables formally went back only to 747 B. C. E., 600 years before his era, the tables were actually good back to before the eclipse in question because as only recently noted their use in reverse is no more difficult than forwards.
Geometry, trigonometry, and other mathematical techniques.
Hipparchus was recognized as the first mathematician known to have possessed a trigonometric table, which he needed when computing the eccentricity of the orbits of the Moon and Sun. He tabulated values for the chord function, which gives the length of the chord for each angle. He did this for a circle with a circumference of 21600 and a radius (rounded) of 3438 units: this circle has a unit length of 1 arc minute along its perimeter. He tabulated the chords for angles with increments of 7.5°. In modern terms, the chord of an angle equals the radius times twice the sine of half of the angle, i.e.:
He described the chord table in a work, now lost, called "Tōn en kuklōi eutheiōn" ("Of Lines Inside a Circle") by Theon of Alexandria in his 4th-century commentary on the "Almagest" I.10; some claim his table may have survived in astronomical treatises in India, for instance the "Surya Siddhanta". Trigonometry was a significant innovation, because it allowed Greek astronomers to solve any triangle, and made it possible to make quantitative astronomical models and predictions using their preferred geometric techniques.
For his chord table Hipparchus must have used a better approximation for π than the one from Archimedes of between 3 + 1/7 and 3 + 10/71; perhaps he had the one later used by Ptolemy: 3;8:30 (sexagesimal) ("Almagest" VI.7); but it is not known if he computed an improved value himself.
But some scholars do not believe Arayabhatta's Sin table has anything to do with Hipparchus's chord table which does not exist today. Some scholars do not agree with this hypothesis that Hipparchus constructed a chord table. Bo. C Klintberg states "With mathematical reconstructions and philosophical arguments I show that Toomer's 1973 paper never contained any conclusive evidence for his claims that Hipparchus had a 3438'-based chord table, and that the Indians used that table to compute their sine tables. Recalculating Toomer's reconstructions with a 3600' radius – i.e. the radius of the chord table in Ptolemy's Almagest, expressed in 'minutes' instead of 'degrees' – generates Hipparchan-like ratios similar to those produced by a 3438' radius. It is therefore possible that the radius of Hipparchus's chord table was 3600', and that the Indians independently constructed their 3438'-based sine table."
Hipparchus could construct his chord table using the Pythagorean theorem and a theorem known to Archimedes. He also might have developed and used the theorem in plane geometry called Ptolemy's theorem, because it was proved by Ptolemy in his "Almagest" (I.10) (later elaborated on by Carnot).
Hipparchus was the first to show that the stereographic projection is conformal, and that it transforms circles on the sphere that do not pass through the center of projection to circles on the plane. This was the basis for the astrolabe.
Besides geometry, Hipparchus also used arithmetic techniques developed by the Chaldeans. He was one of the first Greek mathematicians to do this, and in this way expanded the techniques available to astronomers and geographers.
There are several indications that Hipparchus knew spherical trigonometry, but the first surviving text of it is that of Menelaus of Alexandria in the 1st century, who on that basis is now commonly credited with its discovery. (Previous to the finding of the proofs of Menelaus a century ago, Ptolemy was credited with the invention of spherical trigonometry.) Ptolemy later used spherical trigonometry to compute things like the rising and setting points of the ecliptic, or to take account of the lunar parallax. Hipparchus may have used a globe for these tasks, reading values off coordinate grids drawn on it, or he may have made approximations from planar geometry, or perhaps used arithmetical approximations developed by the Chaldeans. He might have used spherical trigonometry.
Aubrey Diller has shown that the clima calculations which Strabo preserved from Hipparchus were performed by spherical trigonometry with the sole accurate obliquity known to have been used by ancient astronomers, 23°40'. All thirteen clima figures agree with Diller's proposal. Further confirming his contention is the finding that the big errors in Hipparchus's longitude of Regulus and both longitudes of Spica agree to a few minutes in all three instances with a theory that he took the wrong sign for his correction for parallax when using eclipses for determining stars' positions.
Lunar and solar theory.
Motion of the Moon.
Hipparchus also studied the motion of the Moon and confirmed the accurate values for two periods of its motion that Chaldean astronomers are widely presumed to have possessed before him, whatever their ultimate origin. The traditional value (from Babylonian System B) for the mean synodic month is 29 days;31,50,8,20 (sexagesimal) = 29.5305941... days. Expressed as 29 days + 12 hours + 793/1080 hours this value has been used later in the Hebrew calendar (possibly from Babylonian sources). The Chaldeans also knew that 251 synodic months ≈ 269 anomalistic months. Hipparchus used a multiple of this period by a factor of 17, because that interval is also an eclipse period. The Moon also is close to an integer number of years (4267 moons : 4573 anomalistic periods : 4630.53 nodal periods : 4611.98 lunar orbits : 344.996 years : 344.982 solar orbits : 126,007.003 days : 126,351.985 rotations). What was so exceptional and useful about the cycle was that all 345-year-interval eclipse pairs occur slightly over 126,007 days apart within a tight range of only about ±1/2 hour, guaranteeing (after division by 4267) an estimate of the synodic month correct to one part in order of magnitude 10 million. The 345 year periodicity is why the ancients could conceive of a "mean" month and quantify it so accurately that it is even today correct to a fraction of a second of time.
Hipparchus could confirm his computations by comparing eclipses from his own time (presumably 27 January 141  and 26 November 139  according to 1980), with eclipses from Babylonian records 345 years earlier ("Almagest" IV.2; 2001). Already al-Biruni ("Qanun" VII.2.II) and Copernicus ("de revolutionibus" IV.4) noted that the period of 4,267 moons is actually about 5 minutes longer than the value for the eclipse period that Ptolemy attributes to Hipparchus. However, the timing methods of the Babylonians had an error of no less than 8 minutes. Modern scholars agree that Hipparchus rounded the eclipse period to the nearest hour, and used it to confirm the validity of the traditional values, rather than try to derive an improved value from his own observations. From modern ephemerides and taking account of the change in the length of the day (see ΔT) we estimate that the error in the assumed length of the synodic month was less than 0.2 seconds in the 4th century  and less than 0.1 seconds in Hipparchus's time.
Orbit of the Moon.
It had been known for a long time that the motion of the Moon is not uniform: its speed varies. This is called its "anomaly", and it repeats with its own period; the anomalistic month. The Chaldeans took account of this arithmetically, and used a table giving the daily motion of the Moon according to the date within a long period. The Greeks however preferred to think in geometrical models of the sky. Apollonius of Perga had at the end of the 3rd century  proposed two models for lunar and planetary motion:
Hipparchus devised a geometrical method to find the parameters from three positions of the Moon, at particular phases of its anomaly. In fact, he did this separately for the eccentric and the epicycle model. Ptolemy describes the details in the "Almagest" IV.11. Hipparchus used two sets of three lunar eclipse observations, which he carefully selected to satisfy the requirements. The eccentric model he fitted to these eclipses from his Babylonian eclipse list: 22/23 December 383 , 18/19 June 382 , and 12/13 December 382 . The epicycle model he fitted to lunar eclipse observations made in Alexandria at 22 September 201 , 19 March 200 , and 11 September 200 .
The somewhat weird numbers are due to the cumbersome unit he used in his chord table according to one group of historians, who explain their reconstruction's inability to agree with these four numbers as partly due to some sloppy rounding and calculation errors by Hipparchus, for which Ptolemy criticised him (he himself made rounding errors too). A simpler alternate reconstruction agrees with all four numbers. Anyway, Hipparchus found inconsistent results; he later used the ratio of the epicycle model (3122+1/2 : 247+1/2), which is too small (60 : 4;45 sexagesimal). Ptolemy established a ratio of 60 : 5+1/4. (The maximum angular deviation producible by this geometry is the arcsin of 5 1/4 divided by 60, or about 5° 1', a figure that is sometimes therefore quoted as the equivalent of the Moon's equation of the center in the Hipparchan model.)
Apparent motion of the Sun.
Before Hipparchus, Meton, Euctemon, and their pupils at Athens had made a solstice observation (i.e., timed the moment of the summer solstice) on 27 June 432  (proleptic Julian calendar). Aristarchus of Samos is said to have done so in 280 , and Hipparchus also had an observation by Archimedes. As shown in a 1991
paper, in 158 B. C. E. Hipparchus computed a very erroneous summer solstice from Callippus's calendar. He observed the summer solstice in 146 and 135  both accurate to a few hours, but observations of the moment of equinox were simpler, and he made twenty during his lifetime. Ptolemy gives an extensive discussion of Hipparchus's work on the length of the year in the "Almagest" III.1, and quotes many observations that Hipparchus made or used, spanning 162–128 . Analysis of Hipparchus's seventeen equinox observations made at Rhodes shows that the mean error in declination is positive seven arc minutes, nearly agreeing with the sum of refraction by air and Swerdlow's parallax. The random noise is two arc minutes or more nearly one arcminute if rounding is taken into account which approximately agrees with the sharpness of the eye. Ptolemy quotes an equinox timing by Hipparchus (at 24 March 146  at dawn) that differs by 5 hours from the observation made on Alexandria's large public equatorial ring that same day (at 1 hour before noon): Hipparchus may have visited Alexandria but he did not make his equinox observations there; presumably he was on Rhodes (at nearly the same geographical longitude). He could have used the equatorial ring of his armillary sphere or another equatorial ring for these observations, but Hipparchus (and Ptolemy) knew that observations with these instruments are sensitive to a precise alignment with the equator, so if he were restricted to an armillary, it would make more sense to use its meridian ring as a transit instrument. The problem with an equatorial ring (if an observer is naive enough to trust it very near dawn or dusk) is that atmospheric refraction lifts the Sun significantly above the horizon: so for a northern hemisphere observer its apparent declination is too high, which changes the observed time when the Sun crosses the equator. (Worse, the refraction decreases as the Sun rises and increases as it sets, so it may appear to move in the wrong direction with respect to the equator in the course of the 
day – as Ptolemy mentions. Ptolemy and Hipparchus apparently did not realize that refraction is the cause.) However, such details have doubtful relation to the data of either man, since there is no textual, scientific, or statistical ground for believing that their equinoxes were taken on an equatorial ring, which is useless for solstices in any case. Not one of two centuries of mathematical investigations of their solar errors has claimed to have traced them to the effect of refraction on use of an equatorial ring. Ptolemy claims his solar observations were on a transit instrument set in the meridian.
Recent expert translation and analysis by Anne Tihon of papyrus P. Fouad 267 A has confirmed the 1991 finding cited above that Hipparchus obtained a summer solstice in 158 B. C. E. But the papyrus makes the date June 26, over a day earlier than the 1991 paper's conclusion for June 28. The earlier study's §M found that Hipparchus did not adopt June 26 solstices until 146 B. C. E. when he founded the orbit of the sun which Ptolemy later adopted. 
Dovetailing these data suggests Hipparchus extrapolated the 158 B. C. E. June 26 solstice from his 145 solstice 12 years later a procedure that would cause only minuscule error. The papyrus also confirmed that Hipparchus had used Callippic solar motion in 158 B. C. E., a new finding in 1991 but not attested directly until P. Fouad 267 A. Another table on the papyrus is perhaps for sidereal motion and a third table is for Metonic tropical motion, using a previously unknown year of 365 1/4 – 1/309 days. This was presumably found by dividing the 274 years from 432 to 158 B. C. E., into the corresponding interval of 100077 days and 14 3/4 hours between Meton's sunrise and Hipparchus's sunset solstices.
At the end of his career, Hipparchus wrote a book called "Peri eniausíou megéthous" ("On the Length of the Year") about his results. The established value for the tropical year, introduced by Callippus in or before 330  was 365 + 1/4 days. Speculating a Babylonian origin for the Callippic year is hard to defend, since Babylon did not observe solstices thus the only extant System B year length was based on Greek solstices (see below). Hipparchus's equinox observations gave varying results, but he himself points out (quoted in "Almagest" III.1(H195)) that the observation errors by himself and his predecessors may have been as large as 1/4 day. He used old solstice observations, and determined a difference of about one day in about 300 years. So he set the length of the tropical year to 365 + 1/4 - 1/300 days (= 365.24666... days = 365 days 5 hours 55 min, which differs from the actual value (modern estimate, including earth spin acceleration) in his time of about 365.2425 days, an error of about 6 min per year, an hour per decade, 10 hours per century.
Between the solstice observation of Meton and his own, there were 297 years spanning 108,478 days. D. Rawlins noted that this implies a tropical year of 365.24579... days = 365 days;14,44,51 (sexagesimal; = 365 days + 14/60 + 44/602 + 51/603) and that this exact year length has been found on one of the few Babylonian clay tablets which explicitly specifies the System B month. This is an indication that Hipparchus's work was known to Chaldeans.
Another value for the year that is attributed to Hipparchus (by the astrologer Vettius Valens in the 1st century) is 365 + 1/4 + 1/288 days (= 365.25347... days = 365 days 6 hours 5 min), but this may be a corruption of another value attributed to a Babylonian source: 365 + 1/4 + 1/144 days (= 365.25694... days = 365 days 6 hours 10 min). It is not clear if this would be a value for the sidereal year (actual value at his time (modern estimate) about 365.2565 days), but the difference with Hipparchus's value for the tropical year is consistent with his rate of precession (see below).
Orbit of the Sun.
Before Hipparchus, astronomers knew that the lengths of the seasons are not equal. Hipparchus made observations of equinox and solstice, and according to Ptolemy ("Almagest" III.4) determined that spring (from spring equinox to summer solstice) lasted 94½ days, and summer (from summer solstice to autumn equinox) 92½ days. This is inconsistent with a premise of the Sun moving around the Earth in a circle at uniform speed. Hipparchus's solution was to place the Earth not at the center of the Sun's motion, but at some distance from the center. This model described the apparent motion of the Sun fairly well. It is known today that the planets, including the Earth, move in approximate ellipses around the Sun, but this was not discovered until Johannes Kepler published his first two laws of planetary motion in 1609. The value for the eccentricity attributed to Hipparchus by Ptolemy is that the offset is 1/24 of the radius of the orbit (which is a little too large), and the direction of the apogee would be at longitude 65.5° from the vernal equinox. Hipparchus may also have used other sets of observations, which would lead to different values. One of his two eclipse trios' solar longitudes are consistent with his having initially adopted inaccurate lengths for spring and summer of 95¾ and 91¼ days. His other triplet of solar positions is consistent with 94¼ and 92½ days, an improvement on the results (94½ and 92½ days) attributed to Hipparchus by Ptolemy, which a few scholars still question the authorship of. Ptolemy made no change three centuries later, and expressed lengths for the autumn and winter seasons which were already implicit (as shown, e.g., by A. Aaboe).
Distance, parallax, size of the Moon and the Sun.
Hipparchus also undertook to find the distances and sizes of the Sun and the Moon. He published his results in a work of two books called "Perí megethōn kaí apostēmátōn" ("On Sizes and Distances") by Pappus in his commentary on the "Almagest" V.11; Theon of Smyrna (2nd century) mentions the work with the addition "of the Sun and Moon".
Hipparchus measured the apparent diameters of the Sun and Moon with his "diopter". Like others before and after him, he found that the Moon's size varies as it moves on its (eccentric) orbit, but he found no perceptible variation in the apparent diameter of the Sun. He found that at the mean distance of the Moon, the Sun and Moon had the same apparent diameter; at that distance, the Moon's diameter fits 650 times into the circle, i.e., the mean apparent diameters are 360/650 = 0°33'14".
Like others before and after him, he also noticed that the Moon has a noticeable parallax, i.e., that it appears displaced from its calculated position (compared to the Sun or stars), and the difference is greater when closer to the horizon. He knew that this is because in the then-current models the Moon circles the center of the Earth, but the observer is at the surface—the Moon, Earth and observer form a triangle with a sharp angle that changes all the time. From the size of this parallax, the distance of the Moon as measured in Earth radii can be determined. For the Sun however, there was no observable parallax (we now know that it is about 8.8", several times smaller than the resolution of the unaided eye).
In the first book, Hipparchus assumes that the parallax of the Sun is 0, as if it is at infinite distance. He then analyzed a solar eclipse, which Toomer (against the opinion of over a century of astronomers) presumes to be the eclipse of 14 March 189 . It was total in the region of the Hellespont (and in his birthplace, Nicaea); at the time Toomer proposes the Romans were preparing for war with Antiochus III in the area, and the eclipse is mentioned by Livy in his "Ab Urbe Condita" VIII.2. It was also observed in Alexandria, where the Sun was reported to be obscured 4/5ths by the Moon. Alexandria and Nicaea are on the same meridian. Alexandria is at about 31° North, and the region of the Hellespont about 40° North. (It has been contended that authors like Strabo and Ptolemy had fairly decent values for these geographical positions, so Hipparchus must have known them too. However, Strabo's Hipparchus dependent latitudes for this region are at least 1° too high, and Ptolemy appears to copy them, placing Byzantium 2° high in latitude.) Hipparchus could draw a triangle formed by the two places and the Moon, and from simple geometry was able to establish a distance of the Moon, expressed in Earth radii. Because the eclipse occurred in the morning, the Moon was not in the meridian, and it has been proposed that as a consequence the distance found by Hipparchus was a lower limit. In any case, according to Pappus, Hipparchus found that the least distance is 71 (from this eclipse), and the greatest 81 Earth radii.
In the second book, Hipparchus starts from the opposite extreme assumption: he assigns a (minimum) distance to the Sun of 490 Earth radii. This would correspond to a parallax of 7', which is apparently the greatest parallax that Hipparchus thought would not be noticed (for comparison: the typical resolution of the human eye is about 2'; Tycho Brahe made naked eye observation with an accuracy down to 1'). In this case, the shadow of the Earth is a cone rather than a cylinder as under the first assumption. Hipparchus observed (at lunar eclipses) that at the mean distance of the Moon, the diameter of the shadow cone is 2+½ lunar diameters. That apparent diameter is, as he had observed, 360/650 degrees. With these values and simple geometry, Hipparchus could determine the mean distance; because it was computed for a minimum distance of the Sun, it is the maximum mean distance possible for the Moon. With his value for the eccentricity of the orbit, he could compute the least and greatest distances of the Moon too. According to Pappus, he found a least distance of 62, a mean of 67+1/3, and consequently a greatest distance of 72+2/3 Earth radii. With this method, as the parallax of the Sun decreases (i.e., its distance increases), the minimum limit for the mean distance is 59 Earth radii – exactly the mean distance that Ptolemy later derived.
Hipparchus thus had the problematic result that his minimum distance (from book 1) was greater than his maximum mean distance (from book 2). He was intellectually honest about this discrepancy, and probably realized that especially the first method is very sensitive to the accuracy of the observations and parameters. (In fact, modern calculations show that the size of the 189  solar eclipse at Alexandria must have been closer to 9/10ths and not the reported 4/5ths, a fraction more closely matched by the degree of totality at Alexandria of eclipses occurring in 310 and 129  which were also nearly total in the Hellespont and are thought by many to be more likely possibilities for the eclipse Hipparchus used for his computations.)
Ptolemy later measured the lunar parallax directly ("Almagest" V.13), and used the second method of Hipparchus with lunar eclipses to compute the distance of the Sun ("Almagest" V.15). He criticizes Hipparchus for making contradictory assumptions, and obtaining conflicting results ("Almagest" V.11): but apparently he failed to understand Hipparchus's strategy to establish limits consistent with the observations, rather than a single value for the distance. His results were the best so far: the actual mean distance of the Moon is 60.3 Earth radii, within his limits from Hipparchus's second book.
Theon of Smyrna wrote that according to Hipparchus, the Sun is 1,880 times the size of the Earth, and the Earth twenty-seven times the size of the Moon; apparently this refers to volumes, not diameters. From the geometry of book 2 it follows that the Sun is at 2,550 Earth radii, and the mean distance of the Moon is 60½ radii. Similarly, Cleomedes quotes Hipparchus for the sizes of the Sun and Earth as 1050:1; this leads to a mean lunar distance of 61 radii. Apparently Hipparchus later refined his computations, and derived accurate single values that he could use for predictions of solar eclipses.
See 1974 for a more detailed discussion.
Eclipses.
Pliny ("Naturalis Historia" II.X) tells us that Hipparchus demonstrated that lunar eclipses can occur five months apart, and solar eclipses seven months (instead of the usual six months); and the Sun can be hidden twice in thirty days, but as seen by different nations. Ptolemy discussed this a century later at length in "Almagest" VI.6. The geometry, and the limits of the positions of Sun and Moon when a solar or lunar eclipse is possible, are explained in "Almagest" VI.5. Hipparchus apparently made similar calculations. The result that two solar eclipses can occur one month apart is important, because this can not be based on observations: one is visible on the northern and the other on the southern hemisphere – as Pliny indicates – and the latter was inaccessible to the Greek.
Prediction of a solar eclipse, i.e., exactly when and where it will be visible, requires a solid lunar theory and proper treatment of the lunar parallax. Hipparchus must have been the first to be able to do this. A rigorous treatment requires spherical trigonometry, thus those who remain certain that Hipparchus lacked it must speculate that he may have made do with planar approximations. He may have discussed these things in "Perí tēs katá plátos mēniaías tēs selēnēs kinēseōs" ("On the monthly motion of the Moon in latitude"), a work mentioned in the "Suda".
Pliny also remarks that "he also discovered for what exact reason, although the shadow causing the eclipse must from sunrise onward be below the earth, it happened once in the past that the moon was eclipsed in the west while both luminaries were visible above the earth" (translation H. Rackham (1938), Loeb Classical Library 330 p. 207). Toomer (1980) argued that this must refer to the large total lunar eclipse of 26 November 139 , when over a clean sea horizon as seen from Rhodes, the Moon was eclipsed in the northwest just after the Sun rose in the southeast. This would be the second eclipse of the 345-year interval that Hipparchus used to verify the traditional Babylonian periods: this puts a late date to the development of Hipparchus's lunar theory. We do not know what "exact reason" Hipparchus found for seeing the Moon eclipsed while apparently it was not in exact opposition to the Sun. Parallax lowers the altitude of the luminaries; refraction raises them, and from a high point of view the horizon is lowered.
Astronomical instruments and astrometry.
Hipparchus and his predecessors used various instruments for astronomical calculations and observations, such as the gnomon, the astrolabe, and the armillary sphere.
Hipparchus is credited with the invention or improvement of several astronomical instruments, which were used for a long time for naked-eye observations. According to Synesius of Ptolemais (4th century) he made the first "astrolabion": this may have been an armillary sphere (which Ptolemy however says he constructed, in "Almagest" V.1); or the predecessor of the planar instrument called astrolabe (also mentioned by Theon of Alexandria). With an astrolabe Hipparchus was the first to be able to measure the geographical latitude and time by observing fixed stars. Previously this was done at daytime by measuring the shadow cast by a gnomon, by recording the length of the longest day of the year or with the portable instrument known as a "scaphe".
Ptolemy mentions ("Almagest" V.14) that he used a similar instrument as Hipparchus, called "dioptra", to measure the apparent diameter of the Sun and Moon. Pappus of Alexandria described it (in his commentary on the "Almagest" of that chapter), as did Proclus ("Hypotyposis" IV). It was a 4-foot rod with a scale, a sighting hole at one end, and a wedge that could be moved along the rod to exactly obscure the disk of Sun or Moon.
Hipparchus also observed solar equinoxes, which may be done with an equatorial ring: its shadow falls on itself when the Sun is on the equator (i.e., in one of the equinoctial points on the ecliptic), but the shadow falls above or below the opposite side of the ring when the Sun is south or north of the equator. Ptolemy quotes (in "Almagest" III.1 (H195)) a description by Hipparchus of an equatorial ring in Alexandria; a little further he describes two such instruments present in Alexandria in his own time.
Hipparchus applied his knowledge of spherical angles to the problem of denoting locations on the Earth's surface. Before him a grid system had been used by Dicaearchus of Messana, but Hipparchus was the first to apply mathematical rigor to the determination of the latitude and longitude of places on the Earth. Hipparchus wrote a critique in three books on the work of the geographer Eratosthenes of Cyrene (3rd century ), called "Pròs tèn 'Eratosthénous geografían" ("Against the Geography of Eratosthenes"). It is known to us from Strabo of Amaseia, who in his turn criticised Hipparchus in his own "Geografia". Hipparchus apparently made many detailed corrections to the locations and distances mentioned by Eratosthenes. It seems he did not introduce many improvements in methods, but he did propose a means to determine the geographical longitudes of different cities at lunar eclipses (Strabo "Geografia" 1 January 2012). A lunar eclipse is visible simultaneously on half of the Earth, and the difference in longitude between places can be computed from the difference in local time when the eclipse is observed. His approach would give accurate results if it were correctly carried out but the limitations of timekeeping accuracy in his era made this method impractical.
Star catalog.
Late in his career (possibly about 135 ) Hipparchus compiled his star catalog, the original of which does not survive. He also constructed a celestial globe depicting the constellations, based on his observations. His interest in the fixed stars may have been inspired by the observation of a supernova (according to Pliny), or by his discovery of precession, according to Ptolemy, who says that Hipparchus could not reconcile his data with earlier observations made by Timocharis and Aristillus. For more information see Discovery of precession.
Previously, Eudoxus of Cnidus in the 4th century  had described the stars and constellations in two books called "Phaenomena" and "Entropon". Aratus wrote a poem called "Phaenomena" or "Arateia" based on Eudoxus's work. Hipparchus wrote a commentary on the "Arateia" – his only preserved work – which contains many stellar positions and times for rising, culmination, and setting of the constellations, and these are likely to have been based on his own measurements.
Hipparchus made his measurements with an armillary sphere, and obtained the positions of at least 850 stars. It is disputed which coordinate system(s) he used. Ptolemy's catalog in the "Almagest", which is derived from Hipparchus's catalog, is given in ecliptic coordinates. However Delambre in his "Histoire de l'Astronomie Ancienne" (1817) concluded that Hipparchus knew and used the equatorial coordinate system, a conclusion challenged by Otto Neugebauer in his "A History of Ancient Mathematical Astronomy" (1975). Hipparchus seems to have used a mix of ecliptic coordinates and equatorial coordinates: in his commentary on Eudoxos he provides stars' polar distance (equivalent to the declination in the equatorial system), right ascension (equatorial), longitude (ecliptical), polar longitude (hybrid), but not celestial latitude.
As with most of his work, Hipparchus's star catalog was adopted and perhaps expanded by Ptolemy. Delambre, in 1817, cast doubt on Ptolemy's work. It was disputed whether the star catalog in the "Almagest" is due to Hipparchus, but 1976–2002 statistical and spatial analyses (by R. R. Newton, Dennis Rawlins, Gerd Grasshoff, Keith Pickering and Dennis Duke) have shown conclusively that the "Almagest" star catalog is almost entirely Hipparchan. Ptolemy has even (since Brahe, 1598) been accused by astronomers of fraud for stating ("Syntaxis", book 7, chapter 4) that he observed all 1025 stars: for almost every star he used Hipparchus's data and precessed it to his own epoch centuries later by adding 2°40' to the longitude, using an erroneously small precession constant of 1° per century.
In any case the work started by Hipparchus has had a lasting heritage, and was much later updated by Al Sufi (964) and Copernicus (1543). Ulugh Beg reobserved all the Hipparchus stars he could see from Samarkand in 1437 to about the same accuracy as Hipparchus's. The catalog was superseded only in the late 16th century by Brahe and Wilhelm IV of Kassel via superior ruled instruments and spherical trigonometry, which improved accuracy by an order of magnitude even before the invention of the telescope. Hipparchus is considered the greatest observational astronomer from classical antiquity until Brahe.
Stellar magnitude.
Hipparchos ranked stars in six magnitude classes according to their brightness: he assigned the value of one (today written 1,0 mag) to the twenty brightest stars, to fainter ones a value of two, and so forth to the stars with a class of six (6 mag), which can be barely seen with the naked eye. That system is effectively still in use today, though extended and made more precise through the introduction of a logarithmic scale by N. R. Pogson in 1856.
Precession of the equinoxes (146–127 ).
Hipparchus is generally recognized as discoverer of the precession of the equinoxes in 127 . His two books on precession, "On the Displacement of the Solsticial and Equinoctial Points" and "On the Length of the Year", are both mentioned in the "Almagest" of Claudius Ptolemy. According to Ptolemy, Hipparchus measured the longitude of Spica and Regulus and other bright stars. Comparing his measurements with data from his predecessors, Timocharis and Aristillus, he concluded that Spica had moved 2° relative to the autumnal equinox. He also compared the lengths of the tropical year (the time it takes the Sun to return to an equinox) and the sidereal year (the time it takes the Sun to return to a fixed star), and found a slight discrepancy. Hipparchus concluded that the equinoxes were moving ("precessing") through the zodiac, and that the rate of precession was not less than 1° in a century.
Geography.
Hipparchus's treatise "Against the Geography of Eratosthenes" in three books is not preserved. 
Most of our knowledge of it comes from Strabo, according to whom Hipparchus thoroughly and often unfairly criticized Eratosthenes mainly for internal contradictions and inaccuracy in determining positions of geographical localities. Hipparchus insists that a geographic map must be based only on astronomical measurements of latitudes and longitudes and triangulation for finding unknown distances. 
In geographic theory and methods Hipparchus introduced three main innovations.
He was the first to use the grade grid, to determine geographic latitude from star observations, and not only from the sun’s altitude, a method known long before him, and to suggest that geographic longitude could be determined by means of simultaneous observations of lunar eclipses in distant places. In the practical part of his work, the so-called "table of climata", Hipparchus listed latitudes for several tens of localities. In particular, he improved Eratosthenes' values for the latitudes of Athens, Sicily, and southern extremity of India. 
In calculating latitudes of climata (latitudes correlated with the length of the longest solstitial day), Hipparchus used an unexpectedly accurate value for the obliquity of the ecliptic, 23°40′ (the actual value in the second half of the 2nd century  was approximately 23°43′), whereas all other ancient authors knew only a roughly rounded value 24°, and even Ptolemy used a less accurate value, 23°51′. 
Hipparchus opposed the view generally accepted in the Hellenistic period that the Atlantic and Indian Oceans and the Caspian Sea are parts of a single ocean. At the same time he extends the limits of the oikoumene, i.e. the inhabited part of the land, up to the equator and the Arctic Circle. 
Hipparchus’ ideas found their reflection in the "Geography" of Ptolemy. In essence, Ptolemy's work is an extended attempt to realize Hipparchus’ vision of what geography ought to be.
Legacy.
The rather cumbersome formal name for the ESA's Hipparcos Space Astrometry Mission was High Precision Parallax Collecting Satellite; it was deliberately named in this way to give an acronym, HiPParCoS, that echoed and commemorated the name of Hipparchus. The lunar crater Hipparchus and the asteroid 4000 Hipparchus are more directly named after him.
Monument.
The Astronomer's Monument at the Griffith Observatory in Los Angeles, California, United States features a relief of Hipparchus as one of six of the greatest astronomers of all time and the only one from Antiquity.

</doc>
<doc id="13601" url="https://en.wikipedia.org/wiki?curid=13601" title="Hebrew (disambiguation)">
Hebrew (disambiguation)

Hebrew may refer to:

</doc>
<doc id="13602" url="https://en.wikipedia.org/wiki?curid=13602" title="Huldrych Zwingli">
Huldrych Zwingli

Huldrych Zwingli or Ulrich Zwingli (1 January 1484 – 11 October 1531) was a leader of the Reformation in Switzerland. Born during a time of emerging Swiss patriotism and increasing criticism of the Swiss mercenary system, he attended the University of Vienna and the University of Basel, a scholarly center of Renaissance humanism. He continued his studies while he served as a pastor in Glarus and later in Einsiedeln, where he was influenced by the writings of Erasmus.
In 1518, Zwingli became the pastor of the Grossmünster in Zurich where he began to preach ideas on reforming the Catholic Church. In his first public controversy in 1522, he attacked the custom of fasting during Lent. In his publications, he noted corruption in the ecclesiastical hierarchy, promoted clerical marriage, and attacked the use of images in places of worship. In 1525, Zwingli introduced a new communion liturgy to replace the Mass. Zwingli also clashed with the Anabaptists, which resulted in their persecution. Historians have debated whether or not he turned Zurich into a theocracy.
The Reformation spread to other parts of the Swiss Confederation, but several cantons resisted, preferring to remain Catholic. Zwingli formed an alliance of Reformed cantons which divided the Confederation along religious lines. In 1529, a war between the two sides was averted at the last moment. Meanwhile, Zwingli's ideas came to the attention of Martin Luther and other reformers. They met at the Marburg Colloquy and although they agreed on many points of doctrine, they could not reach an accord on the doctrine of the Real Presence of Christ in the Eucharist.
In 1531 Zwingli's alliance applied an unsuccessful food blockade on the Catholic cantons. The cantons responded with an attack at a moment when Zurich was ill prepared. Zwingli was killed in battle at the age of 47. His legacy lives on in the confessions, liturgy, and church orders of the Reformed churches of today.
Historical context.
The Swiss Confederation in Huldrych Zwingli's time consisted of thirteen states (cantons) as well as affiliated states and common lordships. Unlike the current modern state of Switzerland, which operates under a federal government, the thirteen states were nearly independent, conducting their own domestic and foreign affairs. Each state formed its own alliances within and without the Confederation. This relative independence served as the basis for conflict during the time of the Reformation when the various states divided between different confessional camps. Military ambitions were given an additional impetus with the competition to acquire new territory and resources, as seen for example in the Old Zurich War.
The political environment in Europe during the 15th and 16th centuries was also volatile. For centuries the foreign policies of the Confederation were determined by its relationship with its powerful neighbour, France. Nominally, the Confederation was under the control of the Holy Roman Empire. However, through a succession of wars culminating in the Swabian War, the Confederation had become "de facto" independent. As the two continental powers and minor states such as the Duchy of Milan, Duchy of Savoy, and the Papal States competed and fought against each other, there were far-reaching political, economic, and social consequences for the Confederation. It was during this time that the mercenary pension system became a subject of disagreement. The religious factions of Zwingli's time debated vociferously regarding the merits of sending young Swiss men to fight in foreign wars mainly for the enrichment of the cantonal authorities.
These internal and external factors contributed to the rise of a Confederation national consciousness, in which the term "fatherland" ("patria") began to take on meaning beyond an individual canton. At the same time, Renaissance humanism, with its universal values and emphasis on scholarship (as exemplified by Erasmus, the "prince of humanism"), had taken root in the country. It was within this environment, defined by the confluence of Swiss patriotism and humanism, that Zwingli was born.
Life.
Early years (1484–1518).
Huldrych Zwingli was born on 1 January 1484 in Wildhaus, in the Toggenburg valley of Switzerland, to a family of farmers, the third child of nine. His father, Ulrich, played a leading role in the administration of the community ("Amtmann" or chief local magistrate). Zwingli's primary schooling was provided by his uncle, Bartholomew, a cleric in Weesen, where he probably met Katharina von Zimmern. At ten years old, Zwingli was sent to Basel to obtain his secondary education where he learned Latin under Magistrate Gregory Bünzli. After three years in Basel, he stayed a short time in Bern with the humanist, Henry Wölfflin. The Dominicans in Bern tried to persuade Zwingli to join their order and it is possible that he was received as a novice. However, his father and uncle disapproved of such a course and he left Bern without completing his Latin studies. He enrolled in the University of Vienna in the winter semester of 1498 but was expelled, according to the university's records. However, it is not certain that Zwingli was indeed expelled, and he re-enrolled in the summer semester of 1500; his activities in 1499 are unknown. Zwingli continued his studies in Vienna until 1502, after which he transferred to the University of Basel where he received the Master of Arts degree ("Magister") in 1506.
Zwingli was ordained in Constance, the seat of the local diocese, and he celebrated his first Mass in his hometown, Wildhaus, on 29 September 1506. As a young priest he had studied little theology, but this was not considered unusual at the time. His first ecclesiastical post was the pastorate of the town of Glarus, where he stayed for ten years. It was in Glarus, whose soldiers were used as mercenaries in Europe, that Zwingli became involved in politics. The Swiss Confederation was embroiled in various campaigns with its neighbours: the French, the Habsburgs, and the Papal States. Zwingli placed himself solidly on the side of the Roman See. In return, Pope Julius II honoured Zwingli by providing him with an annual pension. He took the role of chaplain in several campaigns in Italy, including the Battle of Novara in 1513. However, the decisive defeat of the Swiss in the Battle of Marignano caused a shift in mood in Glarus in favour of the French rather than the pope. Zwingli, the papal partisan, found himself in a difficult position and he decided to retreat to Einsiedeln in the canton of Schwyz. By this time, he had become convinced that mercenary service was immoral and that Swiss unity was indispensable for any future achievements. Some of his earliest extant writings, such as "The Ox" (1510) and "The Labyrinth" (1516), attacked the mercenary system using allegory and satire. His countrymen were presented as virtuous people within a French, imperial, and papal triangle. Zwingli stayed in Einsiedeln for two years during which he withdrew completely from politics in favour of ecclesiastical activities and personal studies.
Zwingli's time as the pastor of Glarus and Einsiedeln was characterized by inner growth and development. He perfected his Greek and he took up the study of Hebrew. His library contained over three hundred volumes from which he was able to draw upon classical, patristic, and scholastic works. He exchanged scholarly letters with a circle of Swiss humanists and began to study the writings of Erasmus. Zwingli took the opportunity to meet him while Erasmus was in Basel between August 1514 and May 1516. Zwingli's turn to relative pacifism and his focus on preaching can be traced to the influence of Erasmus.
In late 1518, the post of the "Leutpriestertum" (people's priest) of the Grossmünster at Zurich became vacant. The canons of the foundation that administered the Grossmünster recognised Zwingli's reputation as a fine preacher and writer. His connection with humanists was a decisive factor as several canons were sympathetic to Erasmian reform. In addition, his opposition to the French and to mercenary service was welcomed by Zurich politicians. On 11 December 1518, the canons elected Zwingli to become the stipendiary priest and on 27 December he moved permanently to Zurich.
Zurich ministry begins (1519–1521).
On 1 January 1519, Zwingli gave his first sermon in Zurich. Deviating from the prevalent practice of basing a sermon on the Gospel lesson of a particular Sunday, Zwingli, using Erasmus' New Testament as a guide, began to read through the Gospel of Matthew, giving his interpretation during the sermon, known as the method of "lectio continua". He continued to read and interpret the book on subsequent Sundays until he reached the end and then proceeded in the same manner with the Acts of the Apostles, the New Testament epistles, and finally the Old Testament. His motives for doing this are not clear, but in his sermons he used exhortation to achieve moral and ecclesiastical improvement which were goals comparable with Erasmian reform. Sometime after 1520, Zwingli's theological model began to evolve into an idiosyncratic form that was neither Erasmian nor Lutheran. Scholars do not agree on the process of how he developed his own unique model. One view is that Zwingli was trained as an Erasmian humanist and Luther played a decisive role in changing his theology. Another view is that Zwingli did not pay much attention to Luther's theology and in fact he considered it as part of the humanist reform movement. A third view is that Zwingli was not a complete follower of Erasmus, but had diverged from him as early as 1516 and that he independently developed his theology.
Zwingli's theological stance was gradually revealed through his sermons. He attacked moral corruption and in the process he named individuals who were the targets of his denunciations. Monks were accused of indolence and high living. In 1519, Zwingli specifically rejected the veneration of saints and called for the need to distinguish between their true and fictional accounts. He cast doubts on hellfire, asserted that unbaptised children were not damned, and questioned the power of excommunication. His attack on the claim that tithing was a divine institution, however, had the greatest theological and social impact. This contradicted the immediate economic interests of the foundation. One of the elderly canons who had supported Zwingli's election, Konrad Hofmann, complained about his sermons in a letter. Some canons supported Hofmann, but the opposition never grew very large. Zwingli insisted that he was not an innovator and that the sole basis of his teachings was Scripture.
Within the diocese of Constance, Bernhardin Sanson was offering a special indulgence for contributors to the building of St Peter's in Rome. When Sanson arrived at the gates of Zurich at the end of January 1519, parishioners prompted Zwingli with questions. He responded with displeasure that the people were not being properly informed about the conditions of the indulgence and were being induced to part with their money on false pretences. This was over a year after Martin Luther published his Ninety-five theses (31 October 1517). The council of Zurich refused Sanson entry into the city. As the authorities in Rome were anxious to contain the fire started by Luther, the Bishop of Constance denied any support of Sanson and he was recalled.
In August 1519, Zurich was struck by an outbreak of the plague during which at least one in four persons died. All of those who could afford it left the city, but Zwingli remained and continued his pastoral duties. In September, he caught the disease and nearly died. He described his preparation for death in a poem, Zwingli's "Pestlied", consisting of three parts: the onset of the illness, the closeness to death, and the joy of recovery. The final verses of the first part read:
In the years following his recovery, Zwingli's opponents remained in the minority. When a vacancy occurred among the canons of the Grossmünster, Zwingli was elected to fulfill that vacancy on 29 April 1521. In becoming a canon, he became a full citizen of Zurich. He also retained his post as the people's priest of the Grossmünster.
First rifts (1522–1524).
The first public controversy regarding Zwingli's preaching broke out during the season of Lent in 1522. On the first fasting Sunday, 9 March, Zwingli and about a dozen other participants consciously transgressed the fasting rule by cutting and distributing two smoked sausages (the "Wurstessen" in Christoph Froschauer's workshop). Zwingli defended this act in a sermon which was published on 16 April, under the title "Von Erkiesen und Freiheit der Speisen" (Regarding the Choice and Freedom of Foods). He noted that no general valid rule on food can be derived from the Bible and that to transgress such a rule is not a sin. The event, which came to be referred to as the Affair of the Sausages, is considered to be the start of the Reformation in Switzerland. Even before the publication of this treatise, the diocese of Constance reacted by sending a delegation to Zurich. The city council condemned the fasting violation, but assumed responsibility over ecclesiastical matters and requested the religious authorities clarify the issue. The bishop responded on 24 May by admonishing the Grossmünster and city council and repeating the traditional position.
Following this event, Zwingli and other humanist friends petitioned the bishop on 2 July to abolish the requirement of celibacy on the clergy. Two weeks later the petition was reprinted for the public in German as "Eine freundliche Bitte und Ermahnung an die Eidgenossen" (A Friendly Petition and Admonition to the Confederates). The issue was not just an abstract problem for Zwingli, as he had secretly married a widow, Anna Reinhard, earlier in the year. Their cohabitation was well-known and their public wedding took place on 2 April 1524, three months before the birth of their first child. They would eventually have four children: Regula, William, Huldrych, and Anna. As the petition was addressed to the secular authorities, the bishop responded at the same level by notifying the Zurich government to maintain the ecclesiastical order. Other Swiss clergymen joined in Zwingli's cause which encouraged him to make his first major statement of faith, "Apologeticus Archeteles" (The First and Last Word). He defended himself against charges of inciting unrest and heresy. He denied the ecclesiastical hierarchy any right to judge on matters of church order because of its corrupted state.
Zurich disputations (1523).
The events of 1522 brought no clarification on the issues. Not only did the unrest between Zurich and the bishop continue, tensions were growing among Zurich's Confederation partners in the Swiss Diet. On 22 December, the Diet recommended that its members prohibit the new teachings, a strong indictment directed at Zurich. The city council felt obliged to take the initiative and find its own solution.
First Disputation.
On 3 January 1523, the Zurich city council invited the clergy of the city and outlying region to a meeting to allow the factions to present their opinions. The bishop was invited to attend or to send a representative. The council would render a decision on who would be allowed to continue to proclaim their views. This meeting, the first Zurich disputation, took place on 29 January 1523.
The meeting attracted a large crowd of approximately six hundred participants. The bishop sent a delegation led by his vicar general, Johannes Fabri. Zwingli summarised his position in the "Schlussreden" (Concluding Statements or the Sixty-seven Articles). Fabri, who had not envisaged an academic disputation in the manner Zwingli had prepared for, was forbidden to discuss high theology before laymen, and simply insisted on the necessity of the ecclesiastical authority. The decision of the council was that Zwingli would be allowed to continue his preaching and that all other preachers should teach only in accordance with Scripture.
Second Disputation.
In September 1523, Leo Jud, Zwingli's closest friend and colleague and pastor of St. Peterskirche, publicly called for the removal of statues of saints and other icons. This led to demonstrations and iconoclastic activities. The city council decided to work out the matter of images in a second disputation. The essence of the mass and its sacrificial character was also included as a subject of discussion. Supporters of the mass claimed that the eucharist was a true sacrifice, while Zwingli claimed that it was a commemorative meal. As in the first disputation, an invitation was sent out to the Zurich clergy and the bishop of Constance. This time, however, the lay people of Zurich, the dioceses of Chur and Basel, the University of Basel, and the twelve members of the Confederation were also invited. About nine hundred persons attended this meeting, but neither the bishop nor the Confederation sent representatives. The disputation started on 26 October 1523 and lasted two days.
Zwingli again took the lead in the disputation. His opponent was the aforementioned canon, Konrad Hofmann, who had initially supported Zwingli's election. Also taking part was a group of young men demanding a much faster pace of reformation, who among other things pleaded for replacing infant baptism with adult baptism. This group was led by Conrad Grebel, one of the initiators of the Anabaptist movement. During the first three days of dispute, although the controversy of images and the mass were discussed, the arguments led to the question of whether the city council or the ecclesiastical government had the authority to decide on these issues. At this point, Konrad Schmid, a priest from Aargau and follower of Zwingli, made a pragmatic suggestion. As images were not yet considered to be valueless by everyone, he suggested that pastors preach on this subject under threat of punishment. He believed the opinions of the people would gradually change and the voluntary removal of images would follow. Hence, Schmid rejected the radicals and their iconoclasm, but supported Zwingli's position. In November the council passed ordinances in support of Schmid's motion. Zwingli wrote a booklet on the evangelical duties of a minister, "Kurze, christliche Einleitung" (Short Christian Introduction), and the council sent it out to the clergy and the members of the Confederation.
Reformation progresses in Zurich (1524–1525).
In December 1523, the council set a deadline of Pentecost in 1524 for a solution to the elimination of the mass and images. Zwingli gave a formal opinion in "Vorschlag wegen der Bilder und der Messe" (Proposal Concerning Images and the Mass). He did not urge an immediate, general abolition. The council decided on the orderly removal of images within Zurich, but rural congregations were granted the right to remove them based on majority vote. The decision on the mass was postponed.
Evidence of the effect of the Reformation was seen in early 1524. Candlemas was not celebrated, processions of robed clergy ceased, worshippers did not go with palms or relics on Palm Sunday to the Lindenhof, and triptychs remained covered and closed after Lent. Opposition to the changes came from Konrad Hofmann and his followers, but the council decided in favour of keeping the government mandates. When Hofmann left the city, opposition from pastors hostile to the Reformation broke down. The bishop of Constance tried to intervene in defending the mass and the veneration of images. Zwingli wrote an official response for the council and the result was the severance of all ties between the city and the diocese.
Although the council had hesitated in abolishing the mass, the decrease in the exercise of traditional piety allowed pastors to be unofficially released from the requirement of celebrating mass. As individual pastors altered their practices as each saw fit, Zwingli was prompted to address this disorganised situation by designing a communion liturgy in the German language. This was published in "Aktion oder Brauch des Nachtmahls" (Act or Custom of the Supper). Shortly before Easter, Zwingli and his closest associates requested the council to cancel the mass and to introduce the new public order of worship. On Maundy Thursday, 13 April 1525, Zwingli celebrated communion under his new liturgy. Wooden cups and plates were used to avoid any outward displays of formality. The congregation sat at set tables to emphasise the meal aspect of the sacrament. The sermon was the focal point of the service and there was no organ music or singing. The importance of the sermon in the worship service was underlined by Zwingli's proposal to limit the celebration of communion to four times a year.
For some time Zwingli had accused mendicant orders of hypocrisy and demanded their abolition in order to support the truly poor. He suggested the monasteries be changed into hospitals and welfare institutions and incorporate their wealth into a welfare fund. This was done by reorganising the foundations of the Grossmünster and Fraumünster and pensioning off remaining nuns and monks. The council secularised the church properties and established new welfare programs for the poor. Zwingli requested permission to establish a Latin school, the "Prophezei" (Prophecy) or "Carolinum", at the Grossmünster. The council agreed and it was officially opened on 19 June 1525 with Zwingli and Jud as teachers. It served to retrain and re-educate the clergy. The Zurich Bible translation, traditionally attributed to Zwingli and printed by Christoph Froschauer, bears the mark of teamwork from the Prophecy school. Scholars have not yet attempted to clarify Zwingli's share of the work based on external and stylistic evidence.
Conflict with the Anabaptists (1525–1527).
Shortly after the second Zurich disputation, many in the radical wing of the Reformation became convinced that Zwingli was making too many concessions to the Zurich council. They rejected the role of civil government and demanded the immediate establishment of a congregation of the faithful. Conrad Grebel, the leader of the radicals and the emerging Anabaptist movement, spoke disparagingly of Zwingli in private. On 15 August 1524 the council insisted on the obligation to baptise all newborn infants. Zwingli secretly conferred with Grebel's group and late in 1524, the council called for official discussions. When talks were broken off, Zwingli published "Wer Ursache gebe zu Aufruhr" (Whoever Causes Unrest) clarifying the opposing points-of-view. On 17 January 1525 a public debate was held and the council decided in favour of Zwingli. Anyone refusing to have their children baptised was required to leave Zurich. The radicals ignored these measures and on 21 January, they met at the house of the mother of another radical leader, Felix Manz. Grebel and a third leader, George Blaurock, performed the first recorded Anabaptist adult baptisms.
On February 2, the council repeated the requirement on the baptism of all babies and some who failed to comply were arrested and fined, Manz and Blaurock among them. Zwingli and Jud interviewed them and more debates were held before the Zurich council. Meanwhile, the new teachings continued to spread to other parts of the Confederation as well as a number of Swabian towns. On 6–8 November, the last debate on the subject of baptism took place in the Grossmünster. Grebel, Manz, and Blaurock defended their cause before Zwingli, Jud, and other reformers. There was no serious exchange of views as each side would not move from their positions and the debates degenerated into an uproar, each side shouting abuse at the other.
The Zurich council decided that no compromise was possible. On 7 March 1526 it released the notorious mandate that no one shall rebaptise another under the penalty of death. Although Zwingli, technically, had nothing to do with the mandate, there is no indication that he disapproved. Felix Manz, who had sworn to leave Zurich and not to baptise any more, had deliberately returned and continued the practice. After he was arrested and tried, he was executed on 5 January 1527 by being drowned in the Limmat river. He was the first Anabaptist martyr; three more were to follow, after which all others either fled or were expelled from Zurich.
Reformation in the Confederation (1526–1528).
On 8 April 1524, five cantons, Lucerne, Uri, Schwyz, Unterwalden, and Zug, formed an alliance, "die fünf Orte" (the Five States) to defend themselves from Zwingli's Reformation. They contacted the opponents of Martin Luther including John Eck, who had debated Luther in the Leipzig Disputation of 1519. Eck offered to dispute Zwingli and he accepted. However, they could not agree on the selection of the judging authority, the location of the debate, and the use of the Swiss Diet as a court. Because of the disagreements, Zwingli decided to boycott the disputation. On 19 May 1526, all the cantons sent delegates to Baden. Although Zurich's representatives were present, they did not participate in the sessions. Eck led the Catholic party while the reformers were represented by Johannes Oecolampadius of Basel, a theologian from Württemberg who had carried on an extensive and friendly correspondence with Zwingli. While the debate proceeded, Zwingli was kept informed of the proceedings and printed pamphlets giving his opinions. It was of little use as the Diet decided against Zwingli. He was to be banned and his writings were no longer to be distributed. Of the thirteen Confederation members, Glarus, Solothurn, Fribourg, and Appenzell as well as the Five States voted against Zwingli. Bern, Basel, Schaffhausen, and Zurich supported him.
The Baden disputation exposed a deep rift in the Confederation on matters of religion. The Reformation was now emerging in other states. The city of St Gallen, an affiliated state to the Confederation, was led by a reformed mayor, Joachim Vadian, and the city abolished the mass in 1527, just two years after Zurich. In Basel, although Zwingli had a close relationship with Oecolampadius, the government did not officially sanction any reformatory changes until 1 April 1529 when the mass was prohibited. Schaffhausen, which had closely followed Zurich's example, formally adopted the Reformation in September 1529. In the case of Bern, Berchtold Haller, the priest at St Vincent Münster, and Niklaus Manuel, the poet, painter, and politician, had campaigned for the reformed cause. But it was only after another disputation that Bern counted itself as a canton of the Reformation. Four hundred and fifty persons participated, including pastors from Bern and other cantons as well as theologians from outside the Confederation such as Martin Bucer and Wolfgang Capito from Strasbourg, Ambrosius Blarer from Constance, and Andreas Althamer from Nuremberg. Eck and Fabri refused to attend and the Catholic cantons did not send representatives. The meeting started on 6 January 1528 and lasted nearly three weeks. Zwingli assumed the main burden of defending the Reformation and he preached twice in the Münster. On 7 February 1528 the council decreed that the Reformation be established in Bern.
First Kappel War (1529).
Even before the Bern disputation, Zwingli was canvassing for an alliance of reformed cities. Once Bern officially accepted the Reformation, a new alliance, "das Christliche Burgrecht" (the Christian Civic Union) was created. The first meetings were held in Bern between representatives of Bern, Constance, and Zurich on 5–6 January 1528. Other cities, including Basel, Biel, Mülhausen, Schaffhausen, and St Gallen, eventually joined the alliance. The Five (Catholic) States felt encircled and isolated, so they searched for outside allies. After two months of negotiations, the Five States formed "die Christliche Vereinigung" (the Christian Alliance) with Ferdinand of Austria on 22 April 1529.
Soon after the Austrian treaty was signed, a reformed preacher, Jacob Kaiser, was captured in Uznach and executed in Schwyz. This triggered a strong reaction from Zwingli; he drafted "Ratschlag über den Krieg" (Advice About the War) for the government. He outlined justifications for an attack on the Catholic states and other measures to be taken. Before Zurich could implement his plans, a delegation from Bern that included Niklaus Manuel arrived in Zurich. The delegation called on Zurich to settle the matter peacefully. Manuel added that an attack would expose Bern to further dangers as Catholic Valais and the Duchy of Savoy bordered its southern flank. He then noted, "You cannot really bring faith by means of spears and halberds." Zurich, however, decided that it would act alone, knowing that Bern would be obliged to acquiesce. War was declared on 8 June 1529. Zurich was able to raise an army of 30,000 men. The Five States were abandoned by Austria and could raise only 9,000 men. The two forces met near Kappel, but war was averted due to the intervention of Hans Aebli, a relative of Zwingli, who pleaded for an armistice.
Zwingli was obliged to state the terms of the armistice. He demanded the dissolution of the Christian Alliance; unhindered preaching by reformers in the Catholic states; prohibition of the pension system; payment of war reparations; and compensation to the children of Jacob Kaiser. Manuel was involved in the negotiations. Bern was not prepared to insist on the unhindered preaching or the prohibition of the pension system. Zurich and Bern could not agree and the Five (Catholic) States pledged only to dissolve their alliance with Austria. This was a bitter disappointment for Zwingli and it marked his decline in political influence. The first Land Peace of Kappel, "der erste Landfriede", ended the war on 24 June.
Marburg Colloquy (1529).
While Zwingli carried on the political work of the Swiss Reformation, he developed his theological views with his colleagues. The famous disagreement between Luther and Zwingli on the interpretation of the eucharist originated when Andreas Karlstadt, Luther's former colleague from Wittenberg, published three pamphlets on the Lord's Supper in which Karlstadt rejected the idea of a real presence in the elements. These pamphlets, published in Basel in 1524, received the approval of Oecolampadius and Zwingli. Luther rejected Karlstadt's arguments and considered Zwingli primarily to be a partisan of Karlstadt. Zwingli began to express his thoughts on the eucharist in several publications including "de Eucharistia" (On the Eucharist). He attacked the idea of the real presence and argued that the word "is" in the words of the institution—"This is my body, this is my blood"—means "signifies". Hence, the words are understood as a metaphor and Zwingli claimed that there was no real presence during the eucharist. In effect, the meal was symbolic of the Last Supper.
By spring 1527, Luther reacted strongly to Zwingli's views in the treatise "Dass Diese Worte Christi "Das ist mein Leib etc." noch fest stehen wider die Schwarmgeister" (That These Words of Christ "This is My Body etc." Still Stand Firm Against the Fanatics). The controversy continued until 1528 when efforts to build bridges between the Lutheran and the Zwinglian views began. Martin Bucer tried to mediate while Philip of Hesse, who wanted to form a political coalition of all Protestant forces, invited the two parties to Marburg to discuss their differences. This event became known as the Marburg Colloquy.
Zwingli accepted Philip's invitation fully believing that he would be able to convince Luther. By contrast, Luther did not expect anything to come out of the meeting and had to be urged by Philip to attend. Zwingli, accompanied by Oecolampadius, arrived on 28 September 1529 with Luther and Philipp Melanchthon arriving shortly thereafter. Other theologians also participated including Martin Bucer, Andreas Osiander, Johannes Brenz, and Justus Jonas. The debates were held from 1–3 October and the results were published in the fifteen "Marburg Articles". The participants were able to agree on fourteen of the articles, but the fifteenth article established the differences in their views on the presence of Christ in the eucharist. Afterwards, each side was convinced that they were the victors, but in fact the controversy was not resolved and the final result was the formation of two different Protestant confessions.
Politics, confessions, the Kappel Wars, and death (1529–1531).
With the failure of the Marburg Colloquy and the split of the Confederation, Zwingli set his goal on an alliance with Philip of Hesse. He kept up a lively correspondence with Philip. Bern refused to participate, but after a long process, Zurich, Basel, and Strasbourg signed a mutual defence treaty with Philip in November 1530. Zwingli also personally negotiated with France's diplomatic representative, but the two sides were too far apart. France wanted to maintain good relations with the Five States. Approaches to Venice and Milan also failed.
As Zwingli was working on establishing these political alliances, Charles V, the Holy Roman Emperor, invited Protestants to the Augsburg Diet to present their views so that he could make a verdict on the issue of faith. The Lutherans presented the Augsburg Confession. Under the leadership of Martin Bucer, the cities of Strasbourg, Constance, Memmingen, and Lindau produced the Tetrapolitan Confession. This document attempted to take a middle position between the Lutherans and Zwinglians. It was too late for the "Burgrecht" cities to produce a confession of their own. Zwingli then produced his own private confession, "Fidei ratio" (Account of Faith) in which he explained his faith in twelve articles conforming to the articles of the Apostles' Creed. The tone was strongly anti-Catholic as well as anti-Lutheran. The Lutherans did not react officially, but criticised it privately. Zwingli's and Luther's old opponent, John Eck, counter-attacked with a publication, "Refutation of the Articles Zwingli Submitted to the Emperor".
When Philip of Hesse formed the Schmalkaldic League at the end of 1530, the four cities of the Tetrapolitan Confession joined on the basis of a Lutheran interpretation of that confession. Given the flexibility of the league's entrance requirements, Zurich, Basel, and Bern also considered joining. However, Zwingli could not reconcile the Tetrapolitan Confession with his own beliefs and wrote a harsh refusal to Bucer and Capito. This offended Philip to the point where relations with the League were severed. The "Burgrecht" cities now had no external allies to help deal with internal Confederation religious conflicts.
The peace treaty of the First Kappel War did not define the right of unhindered preaching in the Catholic states. Zwingli interpreted this to mean that preaching should be permitted, but the Five States suppressed any attempts to reform. The "Burgrecht" cities considered different means of applying pressure to the Five States. Basel and Schaffhausen preferred quiet diplomacy while Zurich wanted armed conflict. Zwingli and Jud unequivocally advocated an attack on the Five States. Bern took a middle position which eventually prevailed. In May 1531, Zurich reluctantly agreed to impose a food blockade. It failed to have any effect and in October, Bern decided to withdraw the blockade. Zurich urged its continuation and the "Burgrecht" cities began to quarrel among themselves.
On 9 October 1531, in a surprise move, the Five States declared war on Zurich. Zurich's mobilisation was slow due to internal squabbling and on 11 October, 3500 poorly deployed men encountered a Five States force nearly double their size near Kappel on 11 October. Many pastors, including Zwingli, were among the soldiers. The battle lasted less than one hour and Zwingli was among the 500 casualties in the Zurich army.
Zwingli had considered himself first and foremost a soldier of Christ; second a defender of his country, the Confederation; and third a leader of his city, Zurich, where he had lived for the previous twelve years. Ironically, he died at the age of 47, not for Christ nor for the Confederation, but for Zurich. 
Luther wrote, "It is well that Zwingli, Carlstadt and Pellican lie dead on the battlefield, for otherwise we could not have kept the Landgrave, Strasbourg and others of our neighbors. Oh, what a triumph this is, that they have perished. How well God knows his business." A false report had added Carlstadt and Pellican to the fatalities. Erasmus wrote, "We are freed from great fear by the death of the two preachers, Zwingli and Oecolampadius, whose fate has wrought an incredible change in the mind of many. This is the wonderful hand of God on high." Oecolampadius had died on 24 November. Erasmus also wrote, "If Bellona had favoured them, it would have been all over with us."
Theology.
According to Zwingli, the cornerstone of theology is the Bible. Zwingli appealed to scripture constantly in his writings. He placed its authority above other sources such as the ecumenical councils or the Church Fathers, although he did not hesitate to use other sources to support his arguments. The principles that guide Zwingli's interpretations are derived from his rationalist humanist education and his Reformed understanding of the Bible. He rejected literalist interpretations of a passage, such as those of the Anabaptists, and used synecdoche and analogies, methods he describes in "A Friendly Exegesis" (1527). Two analogies that he used quite effectively were between baptism and circumcision and between the eucharist and Passover. He also paid attention to the immediate context and attempted to understand the purpose behind it, comparing passages of scripture with each other.
Zwingli rejected the word "sacrament" in the popular usage of his time. For ordinary people, the word meant some kind of holy action of which there is inherent power to free the conscience from sin. For Zwingli, a sacrament was an initiatory ceremony or a pledge, pointing out that the word was derived from "sacramentum" meaning an oath. (However, the word is also translated "mystery.") In his early writings on baptism, he noted that baptism was an example of such a pledge. He challenged Catholics by accusing them of superstition when they ascribed the water of baptism a certain power to wash away sin. Later, in his conflict with the Anabaptists, he defended the practice of infant baptism, noting that there is no law forbidding the practice. He argued that baptism was a sign of a covenant with God, thereby replacing circumcision in the Old Testament.
Zwingli approached the eucharist in a similar manner to baptism. During the first Zurich disputation in 1523, he denied that an actual sacrifice occurred during the mass, arguing that Christ made the sacrifice only once and for all eternity. Hence, the eucharist was "a memorial of the sacrifice". Following this argument, he further developed his view, coming to the conclusion of the "signifies" interpretation for the words of the institution. He used various passages of scripture to argue against transubstantiation as well as Luther's views, the key text being John 6:63, "It is the Spirit who gives life, the flesh is of no avail". Zwingli's approach and interpretation of scripture to understand the meaning of the eucharist was one reason he could not reach a consensus with Luther.
The impact of Luther on Zwingli's theological development has long been a source of interest and discussion among Zwinglian scholars. Zwingli himself asserted vigorously his independence of Luther. The most recent studies have lent credibility to this claim, although some scholars still claim his theology was dependent upon Luther's. Zwingli appears to have read Luther's books in search of confirmation from Luther for his own views. Zwingli did, however, admire Luther greatly for the stand he took against the pope. This, more than Luther's theology, was a key influence on Zwingli's convictions as a reformer. What Zwingli considered Luther's courageous stance at the Leipzig Disputation had a decisive impact on Zwingli during his earliest years as a priest, and during this time Zwingli praised and promoted Luther's writings to support his own similar ideas. Like Luther, Zwingli was also a student and admirer of Augustine. His later writings continued to show characteristic differences from Luther such as the inclusion of non-Christians in heaven as described in "An Exposition of the Faith".
Music.
Zwingli enjoyed music and could play several instruments, including the violin, harp, flute, dulcimer and hunting horn. He would sometimes amuse the children of his congregation on his lute and was so well known for his playing that his enemies mocked him as "the evangelical lute-player and fifer". Three of Zwingli's "Lieder" or hymns have been preserved: the "Pestlied" mentioned above, an adaptation of Psalm 65 (c. 1525), and the "Kappeler Lied", which is believed to have been composed during the campaign of the first war of Kappel (1529). These songs were not meant to be sung during worship services and are not identified as hymns of the Reformation, though they were published in some 16th-century hymnals.
Zwingli criticised the practice of priestly chanting and monastic choirs. The criticism dates from 1523 when he attacked certain worship practices. His arguments are detailed in the Conclusions of 1525, in which, Conclusions 44, 45 and 46 are concerned with musical practices under the rubric of "prayer". He associated music with images and vestments, all of which he felt diverted people's attention from true spiritual worship. It is not known what he thought of the musical practices in early Lutheran churches. Zwingli, however, eliminated instrumental music from worship in the church, stating that God had not commanded it in worship. The organist of the People's Church in Zurich is recorded as weeping upon seeing the great organ broken up. Although Zwingli did not express an opinion on congregational singing, he made no effort to encourage it. Nevertheless, scholars have found that Zwingli was supportive of a role for music in the church. Gottfried W. Locher writes, "The old assertion 'Zwingli was against church singing' holds good no longer ... Zwingli's polemic is concerned exclusively with the medieval Latin choral and priestly chanting and not with the hymns of evangelical congregations or choirs". Locher goes on to say that "Zwingli freely allowed vernacular psalm or choral singing. In addition, he even seems to have striven for lively, antiphonal, unison recitative". Locher then summarizes his comments on Zwingli's view of church music as follows: "The chief thought in his conception of worship was always 'conscious attendance and understanding'—'devotion', yet with the lively participation of all concerned".
The as of today Musikabteilung (literally: music departement), located in the choir of the "Predigern" church in Zürich was founded in 1971, being a scientific music collection of European importance. It publishes the materials entrusted to it at irregular intervals as CD's, the repertoire ranges of early 16th-century spiritual mucic of Huldrych Zwingli's to the late 20th century, published under the label "Musik aus der Zentralbibliothek Zürich".
Legacy.
Zwingli was a humanist and a scholar with many devoted friends and disciples. He communicated as easily with the ordinary people of his congregation as with rulers such as Philip of Hesse. His reputation as a stern, stolid reformer is counterbalanced by the fact that he had an excellent sense of humour and used satiric fables, spoofing, and puns in his writings. He was more conscious of social obligations than Luther and he genuinely believed that the masses would accept a government guided by God's word. He tirelessly promoted assistance to the poor, whom he believed should be cared for by a truly Christian community.
In December 1531, the Zurich council selected Heinrich Bullinger as his successor. He immediately removed any doubts about Zwingli's orthodoxy and defended him as a prophet and a martyr. During Bullinger's rule, the confessional divisions of the Confederation were stabilised. He rallied the reformed cities and cantons and helped them to recover from the defeat at Kappel. Zwingli had instituted fundamental reforms, while Bullinger consolidated and refined them.
Scholars have found it difficult to assess Zwingli's impact on history, for several reasons. There is no consensus on the definition of "Zwinglianism"; by any definition, Zwinglianism evolved under his successor, Heinrich Bullinger; and research into Zwingli's influence on Bullinger and John Calvin is still rudimentary. Bullinger adopted most of Zwingli's points of doctrine. Like Zwingli, he summarised his theology several times, the best-known being the Second Helvetic Confession of 1566. Meanwhile, Calvin had taken over the Reformation in Geneva. Calvin differed with Zwingli on the eucharist and criticised him for regarding it as simply a metaphorical event. In 1549, however, Bullinger and Calvin succeeded in overcoming the differences in doctrine and produced the "Consensus Tigurinus" (Zurich Consensus). They declared that the eucharist was not just symbolic of the meal, but they also rejected the Lutheran position that the body and blood of Christ is in union with the elements. With this rapprochement, Calvin established his role in the Swiss Reformed Churches and eventually in the wider world.
Outside of Switzerland, no church counts Zwingli as its founder. Scholars speculate as to why Zwinglianism has not diffused more widely, even though Zwingli's theology is considered the first expression of Reformed theology. Although his name is not widely recognised, Zwingli's legacy lives on in the basic confessions of the Reformed churches of today. He is often called, after Martin Luther and John Calvin, the "Third Man of the Reformation".
List of works.
Zwingli's collected works are expected to fill 21 volumes. A collection of selected works was published in 1995 by the "Zwingliverein" in collaboration with the "Theologischer Verlag Zürich" This four-volume collection contains the following works:
The complete 21-volume edition is being undertaken by the "Zwingliverein" in collaboration with the "Institut für schweizerische Reformationsgeschichte", and is projected to be organised as follows:
Vols. XIII and XIV have been published, vols. XV and XVI are under preparation. Vols. XVII to XXI are planned to cover the New Testament.
Older German / Latin editions available online include:
See also the following English translations of selected works by Zwingli:

</doc>
<doc id="13603" url="https://en.wikipedia.org/wiki?curid=13603" title="Homeschooling">
Homeschooling

Homeschooling, also known as home education, is the education of children inside the home, as opposed to in the formal settings of a public or private school. Home education is usually conducted by a parent or tutor. Many families that start out with a formal school structure at home often switch to less formal and, often, more effective ways of imparting education outside of school. "Homeschooling" is the term commonly used in North America, whereas "home education" is more commonly used in the United Kingdom, elsewhere in Europe, and in many Commonwealth countries.
Prior to the introduction of compulsory school attendance laws, most childhood education was imparted by the family or community. In several countries homeschooling in the modern sense is considered to be an alternative to attending public or private schools, and is a legal option for parents. In other countries homeschooling is considered illegal or restricted to specific conditions, as noted in the Homeschooling international status and statistics. According to the US National Household Education Surveys, about three percent of all children in the US were homeschooled in the 2011 and 2012 school year. The studies found that of these children, 83 percent were White, 5 percent were Black, 7 percent were Hispanic, and 2 percent were Asian or Pacific Islander.
Parents cite two main motivations for homeschooling their children: dissatisfaction with the local schools and the interest in increased involvement with their children's learning and development. Parents' dissatisfaction with available schools includes concerns about the school environment, the quality of academic instruction, the curriculum, and bullying as well as lack of faith in the school's ability to cater to their child's special needs. Some parents homeschool in order to have greater control over what and how their children are taught, to better cater for children's individual aptitudes and abilities adequately, to provide a specific religious or moral instruction, and to take advantage of the efficiency of one-to-one instruction, which allows the child to spend more time on childhood activities, socializing, and non-academic learning. Many parents are also influenced by alternative educational philosophies espoused by the likes of Susan Sutherland Isaacs, Charlotte Mason, John Holt, and Sir Kenneth Robinson, among others.
Homeschooling may also be a factor in the choice of parenting style. Homeschooling can be an option for families living in isolated rural locations, for those temporarily abroad, and for those who travel frequently. Many young athletes, actors, and musicians are taught at home to better accommodate their training and practice schedules. Homeschooling can be about mentorship and apprenticeship, in which a tutor or teacher is with the child for many years and gets to know the child very well. Recently, homeschooling has increased in popularity in the United States, and the percentage of children ages 5 through 17 who are homeschooled increased from 1.7% in 1999 to 3% in 2011/12.
Homeschooling can be used as a form of supplemental education and as a way of helping children learn under specific circumstances. The term may also refer to instruction in the home under the supervision of correspondence schools or umbrella schools. In some places, an approved curriculum is legally required if children are homeschooled. A curriculum-free philosophy of homeschooling is sometimes called "unschooling", a term coined in 1977 by American educator and author John Holt in his magazine, "Growing Without Schooling". The term emphasizes the more spontaneous, less structured learning environment where a child's interests drive their pursuit of knowledge. In some cases, a liberal arts education is provided using the trivium and quadrivium as the main models.
History.
For much of history and in many cultures, enlisting professional teachers (whether as tutors or in a formal academic setting) was an option available only to the elite social classes. Thus, until relatively recently, the vast majority of people, especially during early childhood, were educated by family members, family friends, or anyone with useful knowledge.
The earliest public schools in modern Western culture were established in the early 16th century in the German states of Gotha and Thuringia. However, even in the 18th century, the majority of people in Europe lacked formal schooling, meaning they were homeschooled, tutored, or received no education at all. Regional differences in schooling existed in colonial America; in the south, farms and plantations were so widely dispersed that community schools such as those in the more compact settlements were impossible. In the middle colonies, the educational situation varied when comparing New York with New England until the 1850s. Formal schooling in a classroom setting has been the most common means of schooling throughout the world, especially in developed countries, since the early- and mid-19th century. Native Americans, who traditionally used homeschooling and apprenticeship, vigorously resisted compulsory education in the United States.
In the 1960s, Rousas John Rushdoony began to advocate homeschooling, which he saw as a way to combat the intentionally secular nature of the public school system in the United States. He vigorously attacked progressive school reformers such as Horace Mann and John Dewey, and argued for the dismantling of the state's influence in education in three works: "Intellectual Schizophrenia", a general and concise study of education, "The Messianic Character of American Education", a history and castigation of public education in the U.S., and "The Philosophy of the Christian Curriculum", a parent-oriented pedagogical statement. Rushdoony was frequently called as an expert witness by the Home School Legal Defense Association (HSLDA) in court cases.
During this time, American educational professionals Raymond and Dorothy Moore began to research the academic validity of the rapidly growing Early Childhood Education movement. This research included independent studies by other researchers and a review of over 8,000 studies bearing on early childhood education and the physical and mental development of children.
They asserted that formal schooling before ages 8–12 not only lacked the anticipated effectiveness, but also harmed children. The Moores published their view that formal schooling was damaging young children academically, socially, mentally, and even physiologically. The Moores presented evidence that childhood problems such as juvenile delinquency, nearsightedness, increased enrollment of students in special education classes and behavioral problems were the result of increasingly earlier enrollment of students. The Moores cited studies demonstrating that orphans who were given surrogate mothers were measurably more intelligent, with superior long-term effects – even though the mothers were "mentally retarded teenagers" – and that illiterate tribal mothers in Africa produced children who were socially and emotionally more advanced than typical western children, "by western standards of measurement".
Their primary assertion was that the bonds and emotional development made at home with parents during these years produced critical long-term results that were cut short by enrollment in schools, and could neither be replaced nor corrected in an institutional setting afterward. Recognizing a necessity for early out-of-home care for some children, particularly special needs and impoverished children and children from exceptionally inferior homes, they maintained that the vast majority of children were far better situated at home, even with mediocre parents, than with the most gifted and motivated teachers in a school setting. They described the difference as follows: "This is like saying, if you can help a child by taking him off the cold street and housing him in a warm tent, then warm tents should be provided for "all" children – when obviously most children already have even more secure housing."
Like Holt, the Moores embraced homeschooling after the publication of their first work, "Better Late Than Early", in 1975, and went on to become important homeschool advocates and consultants with the publication of books such as "Home Grown Kids", 1981, "Homeschool Burnout" and others.
Simultaneously, other authors published books questioning the premises and efficacy of compulsory schooling, including "Deschooling Society" by Ivan Illich, 1970 and "No More Public School" by Harold Bennet, 1972.
In 1976, Holt published "Instead of Education; Ways to Help People Do Things Better". In its conclusion, he called for a "Children's Underground Railroad" to help children escape compulsory schooling. In response, Holt was contacted by families from around the U.S. to tell him that they were educating their children at home. In 1977, after corresponding with a number of these families, Holt began producing "Growing Without Schooling", a newsletter dedicated to home education.
In 1980, Holt said, "I want to make it clear that I don't see homeschooling as some kind of answer to badness of schools. I think that the home is the proper base for the exploration of the world which we call learning or education. Home would be the best base no matter how good the schools were." Holt later wrote a book about homeschooling, "Teach Your Own", in 1981.
One common theme in the homeschool philosophies of both Holt and that of the Moores is that home education should not attempt to bring the school construct into the home, or be seen as a view of education as an academic preliminary to life. They viewed home education as a natural, experiential aspect of life that occurs as the members of the family are involved with one another in daily living.
Methodology.
Homeschools use a wide variety of methods and materials. Families, for a variety of reasons (parent education, finances, educational philosophies, future educational plans, where they live, past educational experiences of the child, child’s interests and temperament) choose different educational methods, which represent a variety of educational philosophies and paradigms.
Some of the methods or learning environments used include Classical education (including Trivium, Quadrivium), Charlotte Mason education, Montessori method, Theory of multiple intelligences, Unschooling, Radical Unschooling, Waldorf education, School-at-home (curriculum choices from both secular and religious publishers), A Thomas Jefferson Education, unit studies, curriculum made up from private or small publishers, apprenticeship, hands-on-learning, distance learning (both on-line and correspondence), dual enrollment in local schools or colleges, and curriculum provided by local schools and many others. Some of these approaches are used in private and public schools. Educational research and studies support the use of some of these methods. Unschooling, natural learning, Charlotte Mason Education, Montessori, Waldorf, apprenticeship, hands-on-learning, unit studies are supported to varying degrees by research by constructivist learning theories and situated cognitive theories. Elements of these theories may be found in the other methods as well.
A student’s education may be customized to support his or her learning level, style, and interests. It is not uncommon for a student to experience more than one approach as the family discovers what works best as the students grow and their circumstances change. Many families use an eclectic approach, picking and choosing from various suppliers. For sources of curricula and books, "Homeschooling in the United States: 2003" found that 78 percent utilized "a public library"; 77 percent used "a homeschooling catalog, publisher, or individual specialist"; 68 percent used "retail bookstore or other store"; 60 percent used "an education publisher that was not affiliated with homeschooling." "Approximately half" used curriculum or books from "a homeschooling organization", 37 percent from a "church, synagogue or other religious institution" and 23 percent from "their local public school or district." 41 percent in 2003 utilized some sort of distance learning, approximately 20 percent by "television, video or radio"; 19 percent via "Internet, e-mail, or the World Wide Web"; and 15 percent taking a "correspondence course by mail designed specifically for homeschoolers."
Individual governmental units, e. g. states and local districts, vary in official curriculum and attendance requirements.
Unit studies.
In a unit study approach, multiple subjects such as math, science, history, art, and geography, are studied in relation to a single topic such as Native Americans, ancient Rome, or whales. For example, a unit study of Native Americans might combine age-appropriate lessons and projects teaching literature (Native American legends), writing (report on a famous Native American), vocabulary and spelling (Native American words that are now part of the English language), art and crafts (pottery, beadwork, sand painting, making moccasins), geography (original locations of tribes in the Americas), social studies (cultures of the different tribes), and science (plants and animals used by Native Americans). Unit studies may be purchased or be parent prepared. Unit studies are useful for teaching multiple grades simultaneously as the difficulty level can be adjusted for each student. An extended form of unit studies, Integrated Thematic Instruction utilizes one central theme integrated throughout the curriculum so that students finish a school year with a deep understanding of a certain broad subject or idea.
All-in-one curricula.
All-in-one homeschooling curricula (variously known as "school-at-home", "The Traditional Approach", "school-in-a-box" or "The Structured Approach"), are instructionist methods of teaching in which the curriculum and homework of the student are similar or identical to those used in a public or private school. Purchased as a grade level package or separately by subject, the package may contain all of the needed books, materials, internet access for remote testing, traditional tests, answer keys, and extensive teacher guides. These materials cover the same subject areas as do public schools, allowing for an easy transition back into the school system. These are among the more expensive options for homeschooling, but they require minimal preparation and are easy to use. Some localities provide the same materials used at local schools to homeschoolers. The purchase of a complete curriculum and their teaching/grading service from an accredited distance learning curriculum provider may allow students to obtain an accredited high school diploma.
Unschooling and natural learning.
"Natural learning" refers to a type of learning-on-demand where children pursue knowledge based on their interests and parents take an active part in facilitating activities and experiences conducive to learning but do not rely heavily on textbooks or spend much time "teaching", looking instead for "learning moments" throughout their daily activities. Parents see their role as that of affirming through positive feedback and modeling the necessary skills, and the child's role as being responsible for asking and learning.
The term "unschooling" as coined by John Holt describes an approach in which parents do not authoritatively direct the child's education, but interact with the child following the child's own interests, leaving them free to explore and learn as their interests lead. "Unschooling" does not indicate that the child is not being educated, but that the child is not being "schooled", or educated in a rigid school-type manner. Holt asserted that children learn through the experiences of life, and he encouraged parents to live their lives with their child. Also known as interest-led or child-led learning, unschooling attempts to follow opportunities as they arise in real life, through which a child will learn without coercion. Children at school learn from 1 teacher and 2 auxiliary teachers in a classroom of approximately 30. Kids have the opportunity of dedicated education at home with a ratio of 1 to 1. An unschooled child may utilize texts or classroom instruction, but these are not considered central to education. Holt asserted that there is no specific body of knowledge that is, or should be, required of a child.
Both unschooling and natural learning advocates believe that children learn best by doing; a child may learn reading to further an interest about history or other cultures, or math skills by operating a small business or sharing in family finances. They may learn animal husbandry keeping dairy goats or meat rabbits, botany tending a kitchen garden, chemistry to understand the operation of firearms or the internal combustion engine, or politics and local history by following a zoning or historical-status dispute. While any type of homeschoolers may also use these methods, the unschooled child initiates these learning activities. The natural learner participates with parents and others in learning together.
Another prominent proponent of unschooling is John Taylor Gatto, author of Dumbing Us Down, The Exhausted School, A Different Kind of Teacher, and Weapons of Mass Instruction. Gatto argues that public education is the primary tool of "state controlled consciousness" and serves as a prime illustration of the total institution — a social system which impels obedience to the state and quells free thinking or dissent.
Autonomous learning.
"Autonomous learning" is a school of education which sees learners as individuals who can and should be i.e. be responsible for their own learning climate.
Autonomous education helps students develop their self-consciousness, vision, practicality and freedom of discussion. These attributes serve to aid the student in his/her independent learning.
Some degree of autonomous learning is popular with those who home educate their children.In true autonomous learning the child usually gets to decide what projects they wish to tackle or what interests to pursue. In home education this can be instead of or in addition to regular subjects like doing math or English.
According to Home Education UK the autonomous education philosophy emerged from the epistemology of Karl Popper in "The Myth of the Framework: In Defence of Science and Rationality", which is developed in the debates, which seek to rebut the neo-Marxist social philosophy of convergence proposed by the Frankfurt School (e.g. Theodor W. Adorno, Jürgen Habermas, Max Horkheimer).
Homeschool cooperatives.
A Homeschool Cooperative is a cooperative of families who homeschool their children. It provides an opportunity for children to learn from other parents who are more specialized in certain areas or subjects. Co-ops also provide social interaction for homeschooled children. They may take lessons together or go on field trips. Some co-ops also offer events such as prom and graduation for homeschoolers.
Homeschoolers are beginning to utilize Web 2.0 as a way to simulate homeschool cooperatives online. With social networks homeschoolers can chat, discuss threads in forums, share information and tips, and even participate in online classes via blackboard systems similar to those used by colleges.
Research.
Supportive.
Test results.
According to the Home School Legal Defense Association (HSLDA) in 2004, "Many studies over the last few years have established the academic excellence of homeschooled children." Homeschooling Achievement—a compilation of studies published by the HSLDA—supported the academic integrity of homeschooling. This booklet summarized a 1997 study by Ray and the 1999 Rudner study. The Rudner study noted two limitations of its own research: it is not necessarily representative of all homeschoolers and it is not a comparison with other schooling methods. Among the homeschooled students who took the tests, the average homeschooled student outperformed his public school peers by 30 to 37 percentile points across all subjects. The study also indicates that public school performance gaps between minorities and genders were virtually non-existent among the homeschooled students who took the tests.
A study conducted in 2008 found that 11,739 homeschooled students, on average, scored 37 percentile points above public school students on standardized achievement tests. This is consistent with the Rudner study (1999). However, Rudner has said that these same students in public school may have scored just as well because of the dedicated parents they had. The Ray study also found that homeschooled students who had a certified teacher as a parent scored one percentile lower than homeschooled students who did not have a certified teacher as a parent.
In 2011, Martin-Chang found that unschooling children ages 5–10 scored significantly below traditionally educated children, while academically oriented homeschooled children scored from one half grade level above to 4.5 grade levels above traditionally schooled children on standardized tests (n=37 home schooled children matched with children from the same socioeconomic and educational background).
In the 1970s, Raymond S. and Dorothy N. Moore conducted four federally funded analyses of more than 8,000 early childhood studies, from which they published their original findings in "Better Late Than Early", 1975. This was followed by "School Can Wait", a repackaging of these same findings designed specifically for educational professionals. They concluded that, "where possible, children should be withheld from formal schooling until at least ages eight to ten." Their reason was that children "are not mature enough for formal school programs until their senses, coordination, neurological development and cognition are ready". They concluded that the outcome of forcing children into formal schooling is a sequence of "1) uncertainty as the child leaves the family nest early for a less secure environment, 2) puzzlement at the new pressures and restrictions of the classroom, 3) frustration because unready learning tools – senses, cognition, brain hemispheres, coordination – cannot handle the regimentation of formal lessons and the pressures they bring, 4) hyperactivity growing out of nerves and jitter, from frustration, 5) failure which quite naturally flows from the four experiences above, and 6) delinquency which is failure's twin and apparently for the same reason." According to the Moores, "early formal schooling is burning out our children. Teachers who attempt to cope with these youngsters also are burning out." Aside from academic performance, they think early formal schooling also destroys "positive sociability", encourages peer dependence, and discourages self-worth, optimism, respect for parents, and trust in peers. They believe this situation is particularly acute for boys because of their delay in maturity.
The Moores cited a Smithsonian Report on the development of genius, indicating a requirement for "1) much time spent with warm, responsive parents and other adults, 2) very little time spent with peers, and 3) a great deal of free exploration under parental guidance." Their analysis suggested that children need "more of home and less of formal school", "more free exploration with... parents, and fewer limits of classroom and books", and "more old fashioned chores – children working with parents – and less attention to rivalry sports and amusements."
Socialization.
Using the Piers-Harris Children's Self-Concept Scale, John Taylor later found that, "while half of the conventionally schooled children scored at or below the 50th percentile (in self-concept), only 10.3% of the home-schooling children did so." He further stated that "the self-concept of home-schooling children is significantly higher statistically than that of children attending conventional school. This has implications in the areas of academic achievement and socialization which have been found to parallel self-concept. Regarding socialization, Taylor's results would mean that very few home-schooling children are socially deprived. He states that critics who speak out against homeschooling on the basis of social deprivation are actually addressing an area which favors homeschoolers.
In 2003, the National Home Education Research Institute conducted a survey of 7,300 U.S. adults who had been homeschooled (5,000 for more than seven years). Their findings included:
Criticism.
People claim the studies that show that homeschooled students do better on standardized tests compare voluntary homeschool testing with mandatory public-school testing.
By contrast, SAT and ACT tests are self-selected by homeschooled and formally schooled students alike. Homeschoolers averaged higher scores on these college entrance tests in South Carolina. Other scores (1999 data) showed mixed results, for example showing higher levels for homeschoolers in English (homeschooled 23.4 vs national average 20.5) and reading (homeschooled 24.4 vs national average 21.4) on the ACT, but mixed scores in math (homeschooled 20.4 vs national average 20.7 on the ACT as opposed homeschooled 535 vs national average 511 on the 1999 SAT math).
Some advocates of homeschooling and educational choice counter with an input-output theory, pointing out that home educators expend only an average of $500–$600 a year on each student, in comparison to $9,000-$10,000 for each public school student in the United States, which suggests home-educated students would be especially dominant on tests if afforded access to an equal commitment of tax-funded educational resources.
General criticism.
Opposition to homeschooling comes from some organizations of teachers and school districts. The National Education Association, a United States teachers' union and professional association, opposes homeschooling.
Stanford University political scientist Professor Rob Reich (not to be confused with former U.S. Secretary of Labor Robert Reich) wrote in "The Civic Perils of Homeschooling" (2002) that homeschooling can probably result in biased students, as many homeschooling parents view the education of their children as a matter properly under their control and no one else's. He also claims that most parents choose to educate their children at home because they believe that their children's moral and spiritual needs will not be met in campus-based schools.
Many teachers and school districts oppose the idea of homeschooling. However, research has shown that homeschooled children often excel in many areas of academic endeavor. According to a study done on the homeschool movement, homeschoolers often achieve academic success and admission into elite universities. There is also evidence that most are remarkably well socialized. According to the National Home Education Research Institute president, Brian Ray, socialization is not a problem for homeschooling children, many of whom are involved in community sports, volunteer activities, book groups, or homeschool co-ops.
Gallup polls of American voters have shown a significant change in attitude in the last 20 years, from 73% opposed to home education in 1985 to 54% opposed in 2001. In 1988, when asked whether parents should have a right to choose homeschooling, 53 percent thought that they should, as revealed by another poll.
International status and statistics.
Homeschooling is legal in some countries. Countries with the most prevalent home education movements include Australia, Canada, New Zealand, the United Kingdom, Mexico, Chile and the United States. Some countries have highly regulated home education programs as an extension of the compulsory school system; others, such as Sweden, Germany and most European countries have outlawed it entirely. Brazil has a law project in process. In other countries, while not restricted by law, homeschooling is not socially acceptable or considered desirable and is virtually non-existent.

</doc>
<doc id="13605" url="https://en.wikipedia.org/wiki?curid=13605" title="Heteroatom">
Heteroatom

In organic chemistry, a heteroatom (from Ancient Greek "heteros", different, + "atomos") is any atom that is not carbon or hydrogen. Usually, the term is used to indicate that non-carbon atoms have replaced carbon in the backbone of the molecular structure. Typical heteroatoms are nitrogen, oxygen, sulphur, phosphorus, chlorine, bromine, and iodine.
In the description of protein structure, in particular in the Protein Data Bank file format, a heteroatom record (HETATM) describes an atom as belonging to a small molecule cofactor rather than being part of a biopolymer chain.
In the context of zeolites, the term heteroatom refers to partial isomorphous substitution of the typical framework atoms (silicon, aluminum, phosphorus) by other elements such as berrylium, vanadium, and chromium. The goal is usually to adjust properties of the material (e.g., Lewis acidity) to optimize the material for a certain application (e.g., catalysis).

</doc>
<doc id="13606" url="https://en.wikipedia.org/wiki?curid=13606" title="Half-life">
Half-life

Half-life (t1⁄2) is the time required for the amount of something to fall to half its initial value. The term is very commonly used in nuclear physics to describe how quickly unstable atoms undergo decay, or how long stable atoms survive, radioactive decay, and it is also used more generally of any type of exponential or non-exponential decay. The converse of half-life is doubling time.
The original term, "half-life period", dating to Ernest Rutherford's discovery of the principle in 1907, was shortened to "half-life" in the early 1950s. Rutherford applied the principle of a radioactive element's half-life to studies of age determination of rocks by measuring the decay period of radium to lead-206.
Half-life is constant over the lifetime of an exponentially decaying quantity, and it is a characteristic unit for the exponential decay equation. The table on the right shows the reduction of a quantity as a function of the number of half-lives elapsed.
Probabilistic nature of half-life.
A half-life usually describes the decay of discrete entities, such as radioactive atoms. In that case, it does not work to use the definition "half-life is the time required for exactly half of the entities to decay". For example, if there are 3 radioactive atoms with a half-life of one second, there will not be "1.5 atoms" left after one second.
Instead, the half-life is defined in terms of probability: "Half-life is the time required for exactly half of the entities to decay "on average"". In other words, the "probability" of a radioactive atom decaying within its half-life is 50%.
For example, the image on the right is a simulation of many identical atoms undergoing radioactive decay. Note that after one half-life there are not "exactly" one-half of the atoms remaining, only "approximately", because of the random variation in the process. Nevertheless, when there are many identical atoms decaying (right boxes), the law of large numbers suggests that it is a "very good approximation" to say that half of the atoms remain after one half-life.
There are various simple exercises that demonstrate probabilistic decay, for example involving flipping coins or running a statistical computer program.
Formulas for half-life in exponential decay.
An exponential decay can be described by any of the following three equivalent formulas:
where
The three parameters formula_4, formula_2, and formula_3 are all directly related in the following way:
where ln(2) is the natural logarithm of 2 (approximately 0.693).
By plugging in and manipulating these relationships, we get all of the following equivalent descriptions of exponential decay, in terms of the half-life:
Regardless of how it's written, we can plug into the formula to get
Decay by two or more processes.
Some quantities decay by two exponential-decay processes simultaneously. In this case, the actual half-life T1⁄2 can be related to the half-lives t1 and t2 that the quantity would have if each of the decay processes acted in isolation:
For three or more processes, the analogous formula is:
For a proof of these formulas, see Exponential decay § Decay by two or more processes.
Examples.
There is a half-life describing any exponential-decay process. For example:
The half life of a species is the time it takes for the concentration of the substance to fall to half of its initial value.
Half-life in non-exponential decay.
The decay of many physical quantities is not exponential—for example, the evaporation of water from a puddle, or (often) the chemical reaction of a molecule. In such cases, the half-life is defined the same way as before: as the time elapsed before half of the original quantity has decayed. However, unlike in an exponential decay, the half-life depends on the initial quantity, and the prospective half-life will change over time as the quantity decays.
As an example, the radioactive decay of carbon-14 is exponential with a half-life of 5730 years. A quantity of carbon-14 will decay to half of its original amount (on average) after 5730 years, regardless of how big or small the original quantity was. After another 5730 years, one-quarter of the original will remain. On the other hand, the time it will take a puddle to half-evaporate depends on how deep the puddle is. Perhaps a puddle of a certain size will evaporate down to half its original volume in one day. But on the second day, there is no reason to expect that one-quarter of the puddle will remain; in fact, it will probably be much less than that. This is an example where the half-life reduces as time goes on. (In other non-exponential decays, it can increase instead.)
The decay of a mixture of two or more materials which each decay exponentially, but with different half-lives, is not exponential. Mathematically, the sum of two exponential functions is not a single exponential function. A common example of such a situation is the waste of nuclear power stations, which is a mix of substances with vastly different half-lives. Consider a mixture of a rapidly decaying element A, with a half-life of 1 second, and a slowly decaying element B, with a half-life of 1 year. In a couple of minutes, almost all atoms of element A will have decayed after repeated halving of the initial number of atoms, but very few of the atoms of element B will have done so as only a tiny fraction of its half-life has elapsed. Thus, the mixture taken as a whole will not decay by halves.
Half-life in biology and pharmacology.
A biological half-life or elimination half-life is the time it takes for a substance (drug, radioactive nuclide, or other) to lose one-half of its pharmacologic, physiologic, or radiological activity. In a medical context, the half-life may also describe the time that it takes for the concentration of a substance in blood plasma to reach one-half of its steady-state value (the "plasma half-life").
The relationship between the biological and plasma half-lives of a substance can be complex, due to factors including accumulation in tissues, active metabolites, and receptor interactions.
While a radioactive isotope decays almost perfectly according to so-called "first order kinetics" where the rate constant is a fixed number, the elimination of a substance from a living organism usually follows more complex chemical kinetics.
For example, the biological half-life of water in a human being is about 9 to 10 days, though this can be altered by behavior and various other conditions. The biological half-life of cesium in human beings is between one and four months.

</doc>
<doc id="13607" url="https://en.wikipedia.org/wiki?curid=13607" title="Humus">
Humus

[[File:Horizons.gif|thumb|Humus has a characteristic black or dark brown color and is organic due to an accumulation of organic carbon. The three major horizons are: (A) surface horizon, (B) subsoil and (C) substratum. Some soils have an organic horizon (O) on the surface. Hard bedrock, which is not soil, uses the letter R.
In soil science, humus (coined 1790–1800; from the Latin "humus": earth, ground) refers to the fraction of soil organic matter that is amorphous and without the "cellular structure characteristic of plants, micro-organisms or animals." Humus significantly influences the bulk density of soil and contributes to moisture and nutrient retention.
Soil formation begins with the weathering of humus.
In agriculture, humus is sometimes also used to describe mature, or natural compost extracted from a forest or other spontaneous source for use to amend soil. It is also used to describe a topsoil horizon that contains organic matter (humus type, humus form, humus profile).
Humus is the dark organic matter that forms in the soil when plant and animal matter decays. Humus contains many useful nutrients for healthy soil, nitrogen being the most important of all.
Nature of humus.
A great part of the organic material that reaches the soil is broken down by the action of microorganisms, resulting in mineral components that can be taken by the roots of plants. In this way the nitrogen (nitrogen cycle) and the other nutrients (nutrient cycle) are recycled. This process is called mineralization (soil science). Depending on the conditions in which the break down is carried out, a fraction of the organic matter does not continue into mineralization, but instead goes in the contrary direction, forming new organic chains (polymers). These organic polymers are stable, that is resistant to the action of microorganisms, and constitute "humus". This stability implies that once formed humus integrates the permanent structure of soil, contributing to its improvement. 
It is difficult to define humus precisely; it is a highly complex substance, which is still not fully understood. Humus should be differentiated from decomposing organic matter. The latter is rough-looking material and remains of the original plant are still visible. Fully humified organic matter, on the other hand, has a uniform dark, spongy, jelly-like appearance, and is amorphous. It may remain like this for millennia or more. It has no determinate shape, structure or character. However, humified organic matter, when examined under the microscope may reveal tiny plant, animal or microbial remains that have been mechanically, but not chemically, degraded. This suggests a fuzzy boundary between humus and organic matter. In most literature, humus is considered an integral part of soil organic matter.
Humification.
Transformation of organic matter into humus.
The process of "humification" can occur naturally in soil, or in the production of compost. The importance of chemically stable humus is thought by some to be the fertility it provides to soils in both a physical and chemical sense, though some agricultural experts put a greater focus on other features of it, such as its ability to suppress disease. It helps the soil retain moisture by increasing microporosity, and encourages the formation of good soil structure. The incorporation of oxygen into large organic molecular assemblages generates many active, negatively charged sites that bind to positively charged ions (cations) of plant nutrients, making them more available to the plant by way of ion exchange. Humus allows soil organisms to feed and reproduce, and is often described as the "life-force" of the soil.
Plant remains (including those that passed through an animal gut and were excreted as feces) contain organic compounds: sugars, starches, proteins, carbohydrates, lignins, waxes, resins, and organic acids. The process of organic matter decay in the soil begins with the decomposition of sugars and starches from carbohydrates, which break down easily as detritivores initially invade the dead plant organs, while the remaining cellulose and lignin break down more slowly. Simple proteins, organic acids, starches and sugars break down rapidly, while crude proteins, fats, waxes and resins remain relatively unchanged for longer periods of time. Lignin, which is quickly transformed by white-rot fungi, together with by-products of microbial and animal activity. The end-product of this process, the humus, is thus a mixture of compounds and complex life chemicals of plant, animal, or microbial origin that has many functions and benefits in the soil. Earthworm humus (vermicompost) is considered by some to be the best organic manure there is.
Stability.
Much of the humus in most soils has persisted for more than a hundred years (rather than having been decomposed to CO2), and can be regarded as stable; this is organic matter that has been protected from decomposition by microbial or enzyme action because it is hidden (occluded) inside small aggregates of soil particles or tightly attached (sorbed or complexed) to clays. Most humus that is not protected in this way is decomposed within ten years and can be regarded as less stable or more labile. Thus stable humus contributes little to the pool of plant-available nutrients in the soil, but it does play a part in maintaining its physical structure. A very stable form of humus is that formed from the slow oxidation of black carbon, after the incorporation of finely powdered charcoal into the topsoil. This process is thought to have been important in the formation of the fertile Amazonian dark earths or Terra preta do Indio.
Horizons.
Humus has a characteristic black or dark brown color and is organic due to an accumulation of organic carbon. Soil scientists use the capital letters O, A, B, C, and E to identify the master horizons, and lowercase letters for distinctions of these horizons. Most soils have three major horizons—the surface horizon (A), the subsoil (B), and the substratum (C). Some soils have an organic horizon (O) on the surface, but this horizon can also be buried. The master horizon, E, is used for subsurface horizons that have a significant loss of minerals (eluviation). Hard bedrock, which is not soil, uses the letter R.
Criticism of humification theory.
The theory that a 'humification' process created 'humus' predates a sophisticated understanding of soils. Products of a humification process have not been observed in soil. Although 'humification' theory is unsupported by evidence, "the underlying theory persists in the contemporary literature, including current textbooks."

</doc>
<doc id="13609" url="https://en.wikipedia.org/wiki?curid=13609" title="Hydrogen bond">
Hydrogen bond

A hydrogen bond is the electrostatic attraction between polar groups that occurs when a hydrogen (H) atom bound to a highly electronegative atom such as nitrogen (N), oxygen (O) or fluorine (F) experiences attraction to some other nearby highly electronegative atom.
These hydrogen-bond attractions can occur between molecules ("intermolecular") or within different parts of a single molecule ("intramolecular"). Depending on geometry and environmental conditions, the hydrogen bond may be worth between 5 and 30 kJ/mole in thermodynamic terms. This makes it stronger than a van der Waals interaction, but weaker than covalent or ionic bonds. This type of bond can occur in inorganic molecules such as water and in organic molecules like DNA and proteins.
Intermolecular hydrogen bonding is responsible for the high boiling point of water (100 °C) compared to the other group 16 hydrides that have no hydrogen bonds. Intramolecular hydrogen bonding is partly responsible for the secondary and tertiary structures of proteins and nucleic acids. It also plays an important role in the structure of polymers, both synthetic and natural.
In 2011, an IUPAC Task Group recommended a modern evidence-based definition of hydrogen bonding, which was published in the IUPAC journal "Pure and Applied Chemistry". This definition specifies:
Bonding.
A hydrogen atom attached to a relatively electronegative atom will play the role of the hydrogen bond "donor". This electronegative atom is usually fluorine, oxygen, or nitrogen. A hydrogen attached to carbon can also participate in hydrogen bonding when the carbon atom is bound to electronegative atoms, as is the case in chloroform, CHCl3. An example of a hydrogen bond donor is the hydrogen from the hydroxyl group of ethanol, which is bonded to an oxygen.
An electronegative atom such as fluorine, oxygen, or nitrogen will be the hydrogen bond "acceptor", whether or not it is bonded to a hydrogen atom. An example of a hydrogen bond acceptor that does not have a hydrogen atom bonded to it is the oxygen atom in diethyl ether.
In the donor molecule, the electronegative atom attracts the electron cloud from around the hydrogen nucleus of the donor, and, by decentralizing the cloud, leaves the atom with a positive partial charge. Because of the small size of hydrogen relative to other atoms and molecules, the resulting charge, though only partial, represents a large charge density. A hydrogen bond results when this strong positive charge density attracts a lone pair of electrons on another heteroatom, which then becomes the hydrogen-bond acceptor.
The hydrogen bond is often described as an electrostatic dipole-dipole interaction. However, it also has some features of covalent bonding: it is directional and strong, produces interatomic distances shorter than the sum of the van der Waals radii, and usually involves a limited number of interaction partners, which can be interpreted as a type of valence. These covalent features are more substantial when acceptors bind hydrogens from more electronegative donors.
The partially covalent nature of a hydrogen bond raises the following questions: "To which molecule or atom does the hydrogen nucleus belong?" and "Which should be labeled 'donor' and which 'acceptor'?" Usually, this is simple to determine on the basis of interatomic distances in the X−H…Y system, where the dots represent the hydrogen bond: the X−H distance is typically ≈110 pm, whereas the H…Y distance is ≈160 to 200 pm. Liquids that display hydrogen bonding (such as water) are called associated liquids.
Hydrogen bonds can vary in strength from very weak (1–2 kJ mol−1) to extremely strong (161.5 kJ mol−1 in the ion ). Typical enthalpies in vapor include:
Quantum chemical calculations of the relevant interresidue potential constants (compliance constants) revealed large differences between individual H bonds of the same type. For example, the central interresidue N−H···N hydrogen bond between guanine and cytosine is much stronger in comparison to the N−H···N bond between the adenine-thymine pair.
The length of hydrogen bonds depends on bond strength, temperature, and pressure. The bond strength itself is dependent on temperature, pressure, bond angle, and environment (usually characterized by local dielectric constant). The typical length of a hydrogen bond in water is 197 pm. The ideal bond angle depends on the nature of the hydrogen bond donor. The following hydrogen bond angles between a hydrofluoric acid donor and various acceptors have been determined experimentally:
History.
In the book "The Nature of the Chemical Bond", Linus Pauling credits T. S. Moore and T. F. Winmill with the first mention of the hydrogen bond, in 1912. Moore and Winmill used the hydrogen bond to account for the fact that trimethylammonium hydroxide is a weaker base than tetramethylammonium hydroxide. The description of hydrogen bonding in its better-known setting, water, came some years later, in 1920, from Latimer and Rodebush. In that paper, Latimer and Rodebush cite work by a fellow scientist at their laboratory, Maurice Loyal Huggins, saying, "Mr. Huggins of this laboratory in some work as yet unpublished, has used the idea of a hydrogen kernel held between two atoms as a theory in regard to certain organic compounds."
Hydrogen bonds in water.
The most ubiquitous and perhaps simplest example of a hydrogen bond is
found between water molecules. In a discrete water molecule, there are two hydrogen atoms and one oxygen atom. Two molecules of water can form a hydrogen bond between them; the simplest case, when only two molecules are present, is called the water dimer and is often used as a model system. When more molecules are present, as is the case with liquid water, more bonds are possible because the oxygen of one water molecule has two lone pairs of electrons, each of which can form a hydrogen bond with a hydrogen on another water molecule. This can repeat such that every water molecule is H-bonded with up to four other molecules, as shown in the figure (two through its two lone pairs, and two through its two hydrogen atoms). Hydrogen bonding strongly affects the crystal structure of ice, helping to create an open hexagonal lattice. The density of ice is less than the density of water at the same temperature; thus, the solid phase of water floats on the liquid, unlike most other substances.
Liquid water's high boiling point is due to the high number of hydrogen bonds each molecule can form, relative to its low molecular mass. Owing to the difficulty of breaking these bonds, water has a very high boiling point, melting point, and viscosity compared to otherwise similar liquids not conjoined by hydrogen bonds. Water is unique because its oxygen atom has two lone pairs and two hydrogen atoms, meaning that the total number of bonds of a water molecule is up to four. For example, hydrogen fluoride—which has three lone pairs on the F atom but only one H atom—can form only two bonds; (ammonia has the opposite problem: three hydrogen atoms but only one lone pair).
The exact number of hydrogen bonds formed by a molecule of liquid water fluctuates with time and depends on the temperature. From TIP4P liquid water simulations at 25 °C, it was estimated that each water molecule participates in an average of 3.59 hydrogen bonds. At 100 °C, this number decreases to 3.24 due to the increased molecular motion and decreased density, while at 0 °C, the average number of hydrogen bonds increases to 3.69. A more recent study found a much smaller number of hydrogen bonds: 2.357 at 25 °C. The differences may be due to the use of a different method for defining and counting the hydrogen bonds.
Where the bond strengths are more equivalent, one might instead find the atoms of two interacting water molecules partitioned into two polyatomic ions of opposite charge, specifically hydroxide (OH−) and hydronium (H3O+). (Hydronium ions are also known as "hydroxonium" ions.)
Indeed, in pure water under conditions of standard temperature and pressure, this latter formulation is applicable only rarely; on average about one in every 5.5 × 108 molecules gives up a proton to another water molecule, in accordance with the value of the dissociation constant for water under such conditions. It is a crucial part of the uniqueness of water.
Because water may form hydrogen bonds with solute proton donors and acceptors, it may competitively inhibit the formation of solute intermolecular or intramolecular hydrogen bonds. Consequently, hydrogen bonds between or within solute molecules dissolved in water are almost always unfavorable relative to hydrogen bonds between water and the donors and acceptors for hydrogen bonds on those solutes. Hydrogen bonds between water molecules have an average lifetime of 10−11 seconds, or 10 picoseconds.
Bifurcated and over-coordinated hydrogen bonds in water.
A single hydrogen atom can participate in two hydrogen bonds, rather than one. This type of bonding is called "bifurcated" (split in two or "two-forked"). It can exist, for instance, in complex natural or synthetic organic molecules. It has been suggested that a bifurcated hydrogen atom is an essential step in water reorientation.
Acceptor-type hydrogen bonds (terminating on an oxygen's lone pairs) are more likely to form bifurcation (it is called overcoordinated oxygen, OCO) than are donor-type hydrogen bonds, beginning on the same oxygen's hydrogens.
Hydrogen bonds in DNA and proteins.
Hydrogen bonding also plays an important role in determining the three-dimensional structures adopted by proteins and nucleic bases. In these macromolecules, bonding between parts of the same macromolecule cause it to fold into a specific shape, which helps determine the molecule's physiological or biochemical role. For example, the double helical structure of DNA is due largely to hydrogen bonding between its base pairs (as well as pi stacking interactions), which link one complementary strand to the other and enable replication.
In the secondary structure of proteins, hydrogen bonds form between the backbone oxygens and amide hydrogens. When the spacing of the amino acid residues participating in a hydrogen bond occurs regularly between positions "i" and "i" + 4, an alpha helix is formed. When the spacing is less, between positions "i" and "i" + 3, then a 310 helix is formed. When two strands are joined by hydrogen bonds involving alternating residues on each participating strand, a beta sheet is formed. Hydrogen bonds also play a part in forming the tertiary structure of protein through interaction of R-groups. (See also protein folding).
The role of hydrogen bonds in protein folding has also been linked to osmolyte-induced protein stabilization. Protective osmolytes, such as trehalose and sorbitol, shift the protein folding equilibrium toward the folded state, in a concentration dependent manner. While the prevalent explanation for osmolyte action relies on excluded volume effects, that are entropic in nature, recent Circular dichroism (CD) experiments have shown osmolyte to act through an enthalpic effect. The molecular mechanism for their role in protein stabilization is still not well established, though several mechanism have been proposed. Recently, computer molecular dynamics simulations suggested that osmolytes stabilize proteins by modifying the hydrogen bonds in the protein hydration layer.
Several studies have shown that hydrogen bonds play an important role for the stability between subunits in multimeric proteins. For example, a study of sorbitol dehydrogenase displayed an important hydrogen bonding network which stabilizes the tetrameric quaternary structure within the mammalian sorbitol dehydrogenase protein family.
A protein backbone hydrogen bond incompletely shielded from water attack is a dehydron. Dehydrons promote the removal of water through proteins or ligand binding. The exogenous dehydration enhances the electrostatic interaction between the amide and carbonyl groups by de-shielding their partial charges. Furthermore, the dehydration stabilizes the hydrogen bond by destabilizing the nonbonded state consisting of dehydrated isolated charges.
Hydrogen bonds in polymers.
Many polymers are strengthened by hydrogen bonds in their main chains. Among the synthetic polymers, the best known example is nylon, where hydrogen bonds occur in the repeat unit and play a major role in crystallization of the material. The bonds occur between carbonyl and amine groups in the amide repeat unit. They effectively link adjacent chains to create crystals, which help reinforce the material. The effect is greatest in aramid fibre, where hydrogen bonds stabilize the linear chains laterally. The chain axes are aligned along the fibre axis, making the fibres extremely stiff and strong. Hydrogen bonds are also important in the structure of cellulose and derived polymers in its many different forms in nature, such as wood and natural fibres such as cotton and flax.
The hydrogen bond networks make both natural and synthetic polymers sensitive to humidity levels in the atmosphere because water molecules can diffuse into the surface and disrupt the network. Some polymers are more sensitive than others. Thus nylons are more sensitive than aramids, and nylon 6 more sensitive than nylon-11.
Symmetric hydrogen bond.
A symmetric hydrogen bond is a special type of hydrogen bond in which the proton is spaced exactly halfway between two identical atoms. The strength of the bond to each of those atoms is equal. It is an example of a three-center four-electron bond. This type of bond is much stronger than a "normal" hydrogen bond. The effective bond order is 0.5, so its strength is comparable to a covalent bond. It is seen in ice at high pressure, and also in the solid phase of many anhydrous acids such as hydrofluoric acid and formic acid at high pressure. It is also seen in the bifluoride ion [F−H−F]−.
Symmetric hydrogen bonds have been observed recently spectroscopically in formic acid at high pressure (>GPa). Each hydrogen atom forms a partial covalent bond with two atoms rather than one. Symmetric hydrogen bonds have been postulated in ice at high pressure (Ice X). Low-barrier hydrogen bonds form when the distance between two heteroatoms is very small.
Dihydrogen bond.
The hydrogen bond can be compared with the closely related dihydrogen bond, which is also an intermolecular bonding interaction involving hydrogen atoms. These structures have been known for some time, and well characterized by crystallography; however, an understanding of their relationship to the conventional hydrogen bond, ionic bond, and covalent bond remains unclear. Generally, the hydrogen bond is characterized by a proton acceptor that is a lone pair of electrons in nonmetallic atoms (most notably in the nitrogen, and chalcogen groups). In some cases, these proton acceptors may be pi-bonds or metal complexes. In the dihydrogen bond, however, a metal hydride serves as a proton acceptor, thus forming a hydrogen-hydrogen interaction. Neutron diffraction has shown that the molecular geometry of these complexes is similar to hydrogen bonds, in that the bond length is very adaptable to the metal complex/hydrogen donor system.
Advanced theory of the hydrogen bond.
In 1999, Isaacs "et al." showed from interpretations of the anisotropies in the Compton profile of ordinary ice that the hydrogen bond is partly covalent. Some NMR data on hydrogen bonds in proteins also indicate covalent bonding.
Most generally, the hydrogen bond can be viewed as a metric-dependent electrostatic scalar field between two or more intermolecular bonds. This is slightly different from the intramolecular bound states of, for example, covalent or ionic bonds; however, hydrogen bonding is generally still a bound state phenomenon, since the interaction energy has a net negative sum. The initial theory of hydrogen bonding proposed by Linus Pauling suggested that the hydrogen bonds had a partial covalent nature. This remained a controversial conclusion until the late 1990s when NMR techniques were employed by F. Cordier "et al." to transfer information between hydrogen-bonded nuclei, a feat that would only be possible if the hydrogen bond contained some covalent character. While much experimental data has been recovered for hydrogen bonds in water, for example, that provide good resolution on the scale of intermolecular distances and molecular thermodynamics, the kinetic and dynamical properties of the hydrogen bond in dynamic systems remain unchanged.
Dynamics probed by spectroscopic means.
The dynamics of hydrogen bond structures in water can be probed by the IR spectrum of OH stretching vibration. In terms of hydrogen bonding network in protic organic ionic plastic crystals (POIPCs), which are a type of phase change materials exhibiting solid-solid phase transitions prior to melting, variable-temperature infrared spectroscopy can reveal the temperature dependence of hydrogen bonds and the dynamics of both the anions and the cations. The sudden weakening of hydrogen bonds during the solid-solid phase transition seems to be coupled with the onset of orientational or rotational disorder of the ions.

</doc>
<doc id="13610" url="https://en.wikipedia.org/wiki?curid=13610" title="Heraldry">
Heraldry

Heraldry () is a broad term, encompassing the design, display, and study of armorial bearings (known as "armory"), as well as related disciplines, such as vexillology, together with the study of ceremony, rank, and pedigree. Armory, the most familiar branch of heraldry, concerns the design and transmission of the heraldic achievement, more commonly known as the coat of arms, usually consisting of a shield, helmet, and crest, together with any accompanying devices, such as supporters, badges, heraldic banners, and mottoes.
Although the use of various devices to signify individuals and groups goes back to antiquity, both the form and use of such devices varied widely, and the concept of regular, hereditary designs, constituting the distinguishing feature of heraldry, did not develop until the High Middle Ages. During this period, when large armies were gathered together for extended periods, the use of helmets with face guards made it difficult to recognize one's commanders in the field, necessitating the development of heraldry as a symbolic language.
The beauty and pageantry of heraldic designs allowed them to survive the gradual abandonment of armour on the battlefield during the seventeenth century. Heraldry has been described poetically as "the handmaid of history", "the shorthand of history", and "the floral border in the garden of history". In modern times, heraldry is used by individuals, public and private organizations, corporations, cities, towns, and regions to symbolize their heritage, achievements, and aspirations.
History.
Precursors.
Various symbols have been used to represent individuals or groups for thousands of years. The earliest representations of distinct persons and regions in Egyptian art show the use of standards topped with the images or symbols of various gods, and the names of kings appear upon emblems known as serekhs, representing the king's palace, and usually topped with a falcon representing the god Horus, of whom the king was regarded as the earthly incarnation. Similar emblems and devices are found in ancient Mesopotamian art of the same period, and the precursors of heraldic beasts such as the griffin can also be found. In the Bible, the Book of Numbers refers to the standards and ensigns of the children of Israel, who were commanded to gather beneath these emblems and declare their pedigrees. The Greek and Latin writers frequently describe the shields and symbols of various heroes, and units of the Roman army were sometimes identified by distinctive markings on their shields.
Until the nineteenth century, it was common for heraldic writers to cite examples such as these, and metaphorical symbols such as the "Lion of Judah" or "Eagle of the Caesars" as evidence of the antiquity of heraldry itself; and to infer therefrom that the great figures of ancient history bore arms representing their noble status and descent. The Book of Saint Albans, compiled in 1486, declares that Christ himself was a gentleman of coat armour. But these fabulous claims have long since been dismissed as the fantasy of medieval heralds, for there is no evidence of a distinctive symbolic language akin to that of heraldry during this early period; nor do many of the shields described in antiquity bear a close resemblance to those of medieval heraldry; nor is there any evidence that specific symbols or designs were passed down from one generation to the next, representing a particular person or line of descent.
The medieval heralds also devised arms for various knights and lords from history and literature. Notable examples include the toads attributed to Pharamond, the cross and martlets of Edward the Confessor, and the various arms attributed to the Nine Worthies and the Knights of the Round Table. These too are now regarded as a fanciful invention, rather than evidence of the antiquity of heraldry.
Origins of modern heraldry.
The development of the modern heraldic language cannot be attributed to a single individual, time, or place. Although certain designs that are now considered heraldic were evidently in use during the eleventh century, most accounts and depictions of shields up to the beginning of the twelfth century contain little or no evidence of their heraldic character. For example, the Bayeux Tapestry, illustrating the Norman invasion of England in 1066, and probably commissioned about 1077, when the cathedral of Bayeux was rebuilt, depicts a number of shields of various shapes and designs, many of which are plain, while others are decorated with dragons, crosses, or other typically heraldic figures. Yet no individual is depicted twice bearing the same arms, nor are any of the descendants of the various persons depicted known to have borne devices resembling those in the tapestry.
Similarly, an account of the French knights at the court of the Byzantine emperor Alexius I at the beginning of the twelfth century describes their shields of polished metal, utterly devoid of heraldic design. A Spanish manuscript from 1109 describes both plain and decorated shields, none of which appears to have been heraldic. The Abbey of St. Denis contained a window commemorating the knights who embarked on the Second Crusade in 1147, and was probably made soon after the event; but Montfaucon's illustration of the window before it was destroyed shows no heraldic design on any of the shields.
In England, from the time of the Norman conquest, official documents had to be sealed. Beginning in the twelfth century, seals assumed a distinctly heraldic character; a number of seals dating from between 1135 and 1155 appear to show the adoption of heraldic devices in England, France, Germany, Spain, and Italy. A notable example of an early armorial seal is attached to a charter granted by Philip I, Count of Flanders, in 1164. Seals from the latter part of the eleventh and early twelfth centuries show no evidence of heraldic symbolism, but by the end of the twelfth century, seals are uniformly heraldic in nature.
One of the earliest known examples of armory as it subsequently came to be practiced can be seen on the tomb of Geoffrey Plantagenet, Count of Anjou, who died in 1151. An enamel, probably commissioned by Geoffrey's widow between 1155 and 1160, depicts him carrying a blue shield decorated with six golden lions rampant. He wears a blue helmet adorned with another lion, and his cloak is lined in vair. A medieval chronicle states that Geoffrey was given a shield of this description when he was knighted by his father-in-law, Henry I, in 1128; but this account probably dates to about 1175.
The earlier heraldic writers attributed the lions of England to William the Conqueror, but the earliest evidence of the association of lions with the English crown is a seal bearing two lions passant, used by the future King John during the lifetime of his father, Henry II, who died in 1189. Since Henry was the son of Geoffrey Plantagenet, it seems reasonable to suppose that the adoption of lions as an heraldic emblem by Henry or his sons might have been inspired by Geoffrey's shield. John's elder brother, Richard the Lionheart, who succeeded his father on the throne, is believed to have been the first to have borne the arms of three lions passant-guardant, still the arms of England, having earlier used two lions rampant combatant, which arms may also have belonged to his father. Richard is also credited with having originated the English crest of a lion statant (now statant-guardant).
The origins of heraldry are sometimes associated with the Crusades, a series of military campaigns undertaken by Christian armies from 1096 to 1487, with the goal of reconquering Jerusalem and other former Byzantine territories captured by Muslim forces during the seventh century. While there is no evidence that heraldic art originated in the course of the Crusades, there is no reason to doubt that the gathering of large armies, drawn from across Europe for a united cause, would have encouraged the adoption of armorial bearings as a means of identifying one's commanders in the field, or that it helped disseminate the principles of armory across Europe. At least two distinctive features of heraldry are generally accepted as products of the crusaders: the surcoat, an outer garment worn over the armor to protect the wearer from the heat of the sun, was often decorated with the same devices that appeared on a knight's shield. It is from this garment that the phrase "coat of arms" is derived. Also the lambrequin, or mantling, that depends from the helmet and frames the shield in modern heraldry, began as a practical covering for the helmet and the back of the neck during the Crusades, serving much the same function as the surcoat. Its slashed or scalloped edge, today rendered as billowing flourishes, is thought to have originated from hard wearing in the field, or as a means of deadening a sword blow and perhaps entangling the attacker's weapon.
Heralds and heraldic authorities.
The spread of armorial bearings across Europe soon gave rise to a new occupation: the herald, originally a type of messenger employed by noblemen, assumed the responsibility of learning and knowing the rank, pedigree, and heraldic devices of various knights and lords, as well as the rules and protocols governing the design and description, or "blazoning" of arms, and the precedence of their bearers. As early as the late thirteenth century, certain heralds in the employ of monarchs were given the title "King of Heralds", which eventually became "King of Arms."
In the earliest period, arms were assumed by their bearers without any need for heraldic authority. However, by the middle of the fourteenth century, the principle that only a single individual was entitled to bear a particular coat of arms was generally accepted, and disputes over the ownership of arms seems to have led to gradual establishment of heraldic authorities to regulate their use. The earliest known work of heraldic jurisprudence, "De Insigniis et Armis", was written about 1350 by Bartolus de Saxoferrato, a professor of law at the University of Padua. The most celebrated armorial dispute in English heraldry is that of "Scrope v. Grosvenor" (1390), in which two different men claimed the right to bear "azure, a bend or". The continued proliferation of arms, and the number of disputes arising from different men assuming the same arms, led Henry V to issue a proclamation in 1419, forbidding all those who had not borne arms at the Battle of Agincourt from assuming arms, except by inheritance or a grant from the crown.
Beginning in the reign of Henry VIII, the Kings of Arms were commanded to make "visitations", in which they traveled about the country, recording arms borne under proper authority, and requiring those who bore arms without authority either to obtain authority for them, or cease their use. Arms borne improperly were to be taken down and defaced. The first such visitation began in 1530, and the last was carried out in 1700, although no new commissions to carry out visitations were made after the accession of William III in 1689.
In 1484, during the reign of Richard III, the various heralds employed by the crown were incorporated into the College of Arms, through which all new grants of arms would eventually be issued. The college currently consists of three Kings of Arms, assisted by six Heralds, and four Pursuivants, or junior officers of arms, all under the authority of the Earl Marshal; but all of the arms granted by the college are granted by the authority of the crown. Similar bodies regulate the granting of arms in other monarchies and several members of the Commonwealth of Nations, but in most other countries there is no heraldic authority, and no law preventing anyone from assuming whatever arms they please, provided that they do not infringe upon the arms of another.
Later uses and developments.
Although heraldry originated from military necessity, it soon found itself at home in the pageantry of the medieval tournament. The opportunity for knights and lords to display their heraldic bearings in a competitive medium led to further refinements, such as the development of elaborate tournament helms, and further popularized the art of heraldry throughout Europe. Prominent burghers and corporations, including many cities and towns, assumed or obtained grants of arms, with only nominal military associations. Heraldic devices were depicted in various contexts, such as religious and funerary art, and in using a wide variety of media, including stonework, carved wood, enamel, stained glass, and embroidery.
As the rise of firearms rendered the mounted knight increasingly irrelevant on the battlefield during the sixteenth and seventeenth centuries, and the tournament faded into history, the military character of heraldry gave way to its use as a decorative art. Freed from the limitations of actual shields and the need for arms to be easily distinguished in combat, heraldic artists designed increasingly elaborate achievements, culminating in the development of "landscape heraldry", incorporating realistic depictions of landscapes, during the latter part of the eighteenth and early part of the nineteenth century. These fell out of fashion during the mid-nineteenth century, when a renewed interest in the history of armory led to the re-evaluation of earlier designs, and a new appreciation for the medieval origins of the art. Since the late nineteenth century, heraldry has focused on the use of varied lines of partition and little-used ordinaries to produce new and unique designs.
The heraldic achievement.
Elements of an achievement.
An heraldic achievement consists of a shield of arms, together with all of its accompanying elements, such as a crest, supporters, and other heraldic embellishments. The term "coat of arms" technically refers to the shield of arms itself, but the phrase is commonly used to refer to the entire achievement. The one indispensable element of a coat of arms is the shield; many ancient coats of arms consist of nothing else, but no coat of arms exists without a shield.
From a very early date, illustrations of arms were frequently embellished with helmets placed above the shields. These in turn came to be decorated with fan-shaped or sculptural crests, often incorporating elements from the shield of arms; as well as a wreath or torse, or sometimes a coronet, from which depended the lambrequin or mantling. To these elements, modern heraldry often adds a motto displayed on a ribbon, typically below the shield. The helmet is borne of right, and forms no part of a grant of arms; it may be assumed without authority by anyone entitled to bear arms, together with mantling and whatever motto the armiger may desire. The crest, however, together with the torse or coronet from which it arises, must be granted or confirmed by the relevant heraldic authority.
If the bearer is entitled to the ribbon, collar, or badge of a knightly order, it may encircle or depend from the shield. Some arms, particularly those of the nobility, are further embellished with supporters, heraldic figures standing alongside or behind the shield; often these stand on a compartment, typically a mound of earth and grass, on which other badges, symbols, or heraldic banners may be displayed. The most elaborate achievements sometimes display the entire coat of arms beneath a pavilion, an embellished tent or canopy of the type associated with the medieval tournament.
The shield.
The primary element of an heraldic achievement is the shield, or escutcheon, upon which the coat of arms is depicted. All of the other elements of an achievement are designed to decorate and complement these arms, but only the shield of arms is required. The shape of the shield, like many other details, is normally left to the discretion of the heraldic artist, and many different shapes have prevailed during different periods of heraldic design, and in different parts of Europe.
One shape alone is normally reserved for a specific purpose: the lozenge, a diamond-shaped escutcheon, was traditionally used to display the arms of women, on the grounds that shields, as implements of war, were inappropriate for this purpose. This distinction was not always strictly adhered to, and a general exception was usually made for sovereigns, whose arms represented an entire nation. Sometimes an oval shield, or cartouche, was substituted for the lozenge; this shape was also widely used for the arms of clerics in French, Spanish, and Italian heraldry, although it was never reserved for their use. In recent years, the use of the cartouche for women's arms has become general in Scottish heraldry, while both Scottish and Irish authorities have permitted a traditional shield under certain circumstances, and in Canadian heraldry the shield is now regularly granted.
The whole surface of the escutcheon is termed the field, which may be plain, consisting of a single tincture, or divided into multiple sections of differing tinctures by various lines of partition; and any part of the field may be "semé", or powdered with small charges. The edges and adjacent parts of the escutcheon are used to identify the placement of various heraldic charges; the upper edge, and the corresponding upper third of the shield, are referred to as the chief; the lower part is the base. The sides of the shield are known as the dexter and sinister flanks, although it is important to note that these terms are based on the point of view of the bearer of the shield, who would be standing behind it; accordingly the side which is to the bearer's right is the dexter, and the side to the bearer's left is the sinister, although to the observer, and in all heraldic illustration, the dexter is on the left side, and the sinister on the right.
The placement of various charges may also refer to a number of specific points, nine in number according to some authorities, but eleven according to others. The three most important are "fess point", located in the visual center of the shield; the "honour point", located midway between fess point and the chief; and the "nombril point", located midway between fess point and the base. The other points include "dexter chief", "center chief", and "sinister chief", running along the upper part of the shield from left to right, above the honour point; "dexter flank" and "sinister flank", on the sides approximately level with fess point; and "dexter base", "middle base", and "sinister base" along the lower part of the shield, below the nombril point.
Tinctures.
One of the most distinctive qualities of heraldry is the use of a limited palette of colours and patterns, usually referred to as tinctures. These are divided into three categories, known as "metals", "colours", and "furs".
The metals are "or" and "argent", representing gold and silver, respectively, although in practice they are usually depicted as yellow and white. Five colours are universally recognized: "gules", or red; "sable", or black; "azure", or blue; "vert", or green; and "purpure", or purple; and most heraldic authorities also admit two additional colours, known as "sanguine" or "murrey", a dark red or mulberry colour between gules and purpure, and "tenné", an orange or dark yellow to brown colour. These last two are quite rare, and are often referred to as "stains", from the belief that they were used to represent some dishonourable act, although in fact there is no evidence that this use existed outside the imagination of the more fanciful heraldic writers. Perhaps owing to the realization that there is really no such thing as a "stain" in genuine heraldry, as well as the desire to create new and unique designs, the use of these colours for general purposes has become accepted in the twentieth and twenty-first centuries. Occasionally one meets with other colours, particularly in continental heraldry, although they are not generally regarded among the standard heraldic colours. Among these are "cendrée", or ash-colour; "brunâtre", or brown; "bleu-céleste" or "bleu de ciel", sky blue; "amaranth" or "columbine", a bright violet-red or pink colour; and "carnation", commonly used to represent flesh in French heraldry. A more recent addition is the use of "copper" as a metal in one or two Canadian coats of arms.
There are two basic types of heraldic fur, known as ermine and vair, but over the course of centuries each has developed a number of variations. Ermine represents the fur of the stoat, a type of weasel, in its white winter coat, when it is called an ermine. It consists of a white, or occasionally silver field, powdered with black figures known as "ermine spots", representing the black tip of the animal's tail. Ermine was traditionally used to line the cloaks and caps of the nobility. The shape of the heraldic ermine spot has varied considerably over time, and nowadays is typically drawn as an arrowhead surmounted by three small dots, but older forms may be employed at the artist's discretion. When the field is sable and the ermine spots argent, the same pattern is termed "ermines"; when the field is "or" rather than argent, the fur is termed "erminois"; and when the field is sable and the ermine spots "or", it is termed "pean".
Vair represents the winter coat of the red squirrel, which is blue-grey on top and white underneath. To form the linings of cloaks, the pelts were sewn together, forming an undulating, bell-shaped pattern, with interlocking light and dark rows. The heraldic fur is depicted with interlocking rows of argent and azure, although the shape of the pelts, usually referred to as "vair bells", is usually left to the artist's discretion. In the modern form, the bells are depicted with straight lines and sharp angles, and meet only at points; in the older, undulating pattern, now known as "vair ondé" or "vair ancien", the bells of each tincture are curved and joined at the base. There is no fixed rule as to whether the argent bells should be at the top or the bottom of each row. At one time vair commonly came in three sizes, and this distinction is sometimes encountered in continental heraldry; if the field contains fewer than four rows, the fur is termed "gros vair" or "beffroi"; if of six or more, it is "menu-vair", or miniver.
A common variation is "counter-vair", in which alternating rows are reversed, so that the bases of the vair bells of each tincture are joined to those of the same tincture in the row above or below. When the rows are arranged so that the bells of each tincture form vertical columns, it is termed "vair in pale"; in continental heraldry one may encounter "vair in bend", which is similar to vair in pale, but diagonal. When alternating rows are reversed as in counter-vair, and then displaced by half the width of one bell, it is termed "vair in point", or wave-vair. A form peculiar to German heraldry is "alternate vair", in which each vair bell is divided in half vertically, with half argent and half azure. All of these variations can also be depicted in the form known as "potent", in which the shape of the vair bell is replaced by a "T"-shaped figure, known as a potent from its resemblance to a crutch. Although it is really just a variation of vair, it is frequently treated as a separate fur.
When the same patterns are composed of tinctures other than argent and azure, they are termed "vairé" or "vairy" of those tinctures, rather than "vair"; "potenté" of other colours may also be found. Usually vairé will consist of one metal and one colour, but ermine or one of its variations may also be used, and vairé of four tinctures, usually two metals and two colours, is sometimes found.
Three additional furs are sometimes encountered in continental heraldry; in French and Italian heraldry one meets with "plumeté" or "plumetty", in which the field appears to be covered with feathers, and "papelonné", in which it is decorated with scales. In German heraldry one may encounter "kursch", or vair bellies, depicted as brown and furry; all of these probably originated as variations of vair.
Considerable latitude is given to the heraldic artist in depicting the heraldic tinctures; there is no fixed shade or hue to any of them.
Whenever an object is depicted as it appears in nature, rather than in one or more of the heraldic tinctures, it is termed "proper", or the colour of nature. This does not seem to have been done in the earliest heraldry, but examples are known from at least the seventeenth century. While there can be no objection to the occasional depiction of objects in this manner, the overuse of charges in their natural colours is often cited as indicative of bad heraldic practice. The much-maligned practice of landscape heraldry, which flourished in the latter part of the eighteenth and early part of the nineteenth century, made extensive use of such non-heraldic colours.
One of the most important conventions of heraldry is the so-called "rule of tincture". To provide for contrast and visibility, metals should never be placed on metals, and colours should never be placed on colours. This rule does not apply to charges which cross a division of the field, which is partly metal and partly colour; nor, strictly speaking, does it prevent a field from consisting of two metals or two colours, although this is unusual. Furs are considered amphibious, and neither metal nor colour; but in practice ermine and erminois are usually treated as metals, while ermines and pean are treated as colours. This rule is strictly adhered to in British armory, with only rare exceptions; although generally observed in continental heraldry, it is not adhered to quite as strictly. Arms which violate this rule are sometimes known as "puzzle arms", of which the most famous example is the arms of the Kingdom of Jerusalem, consisting of gold crosses on a silver field.
Variations of the field.
The field of a shield, or less often a charge or crest, is sometimes made up of a pattern of colours, or "variation". A pattern of horizontal (barwise) stripes, for example, is called "barry", while a pattern of vertical (palewise) stripes is called "paly". A pattern of diagonal stripes may be called "bendy" or "bendy sinister", depending on the direction of the stripes. Other variations include "chevrony", "gyronny" and "chequy". Wave shaped stripes are termed "undy". For further variations, these are sometimes combined to produce patterns of "barry-bendy", "paly-bendy", "lozengy" and "fusilly". Semés, or patterns of repeated charges, are also considered variations of the field. The Rule of tincture applies to all semés and variations of the field.
Divisions of the field.
The field of a shield in heraldry can be divided into more than one tincture, as can the various heraldic charges. Many coats of arms consist simply of a division of the field into two contrasting tinctures. These are considered divisions of a shield, so the rule of tincture can be ignored. For example, a shield divided azure and gules would be perfectly acceptable. A line of partition may be straight or it may be varied. The variations of partition lines can be wavy, indented, embattled, engrailed, nebuly, or made into myriad other forms; see Line (heraldry).
Ordinaries.
In the early days of heraldry, very simple bold rectilinear shapes were painted on shields. These could be easily recognized at a long distance and could be easily remembered. They therefore served the main purpose of heraldry: identification. As more complicated shields came into use, these bold shapes were set apart in a separate class as the "honorable ordinaries". They act as charges and are always written first in blazon. Unless otherwise specified they extend to the edges of the field. Though ordinaries are not easily defined, they are generally described as including the cross, the fess, the pale, the bend, the chevron, the saltire, and the pall.
There is a separate class of charges called sub-ordinaries which are of a geometrical shape subordinate to the ordinary. According to Friar, they are distinguished by their order in blazon. The sub-ordinaries include the inescutcheon, the orle, the tressure, the double tressure, the bordure, the chief, the canton, the label, and flaunches.
Ordinaries may appear in parallel series, in which case blazons in English give them different names such as pallets, bars, bendlets, and chevronels. French blazon makes no such distinction between these diminutives and the ordinaries when borne singly. Unless otherwise specified an ordinary is drawn with straight lines, but each may be indented, embattled, wavy, engrailed, or otherwise have their lines varied.
Charges.
A charge is any object or figure placed on a heraldic shield or on any other object of an armorial composition. Any object found in nature or technology may appear as a heraldic charge in armory. Charges can be animals, objects, or geometric shapes. Apart from the ordinaries, the most frequent charges are the cross – with its hundreds of variations – and the lion and eagle. Other common animals are stags, Wild Boars, martlets, and fish. Dragons, bats, unicorns, griffins, and more exotic monsters appear as charges and as supporters.
Animals are found in various stereotyped positions or "attitudes". Quadrupeds can often be found rampant (standing on the left hind foot). Another frequent position is passant, or walking, like the lions of the coat of arms of England. Eagles are almost always shown with their wings spread, or displayed. A pair of wings conjoined is called a vol.
In English heraldry the crescent, mullet, martlet, annulet, fleur-de-lis, and rose may be added to a shield to distinguish cadet branches of a family from the senior line. These cadency marks are usually shown smaller than normal charges, but it still does not follow that a shield containing such a charge belongs to a cadet branch. All of these charges occur frequently in basic undifferenced coats of arms.
Marshalling.
To "marshal" two or more coats of arms is to combine them in one shield, to express inheritance, claims to property, or the occupation of an office. This can be done in a number of ways, of which the simplest is impalement: dividing the field "per pale" and putting one whole coat in each half. Impalement replaced the earlier dimidiation – combining the dexter half of one coat with the sinister half of another – because dimidiation can create ambiguity between, for example, a bend and a chevron. "Dexter" (from Latin "dextra", right) means to the right from the viewpoint of the bearer of the arms and "sinister" (from Latin "sinistra", left) means to the left. The dexter side is considered the side of greatest honour (see also Dexter and sinister).
A more versatile method is quartering, division of the field by both vertical and horizontal lines. This practice originated in Spain (Castile and León) after the 13th century. As the name implies, the usual number of divisions is four, but the principle has been extended to very large numbers of "quarters".
Quarters are numbered from the dexter chief (the corner nearest to the right shoulder of a man standing behind the shield), proceeding across the top row, and then across the next row and so on. When three coats are quartered, the first is repeated as the fourth; when only two coats are quartered, the second is also repeated as the third. The quarters of a personal coat of arms correspond to the ancestors from whom the bearer has inherited arms, normally in the same sequence as if the pedigree were laid out with the father's father's ... father (to as many generations as necessary) on the extreme left and the mother's mother's...mother on the extreme right. A few lineages have accumulated hundreds of quarters, though such a number is usually displayed only in documentary contexts. The Scottish and Spanish traditions resist allowing more than four quarters, preferring to subdivide one or more "grand quarters" into sub-quarters as needed.
The third common mode of marshalling is with an inescutcheon, a small shield placed in front of the main shield. In Britain this is most often an "escutcheon of pretence" indicating, in the arms of a married couple, that the wife is an heraldic heiress (i.e., she inherits a coat of arms because she has no brothers). In continental Europe an inescutcheon (sometimes called a "heart shield") usually carries the ancestral arms of a monarch or noble whose domains are represented by the quarters of the main shield.
In German heraldry, animate charges in combined coats usually turn to face the centre of the composition.
Helm and crest.
In English the word "crest" is commonly (but erroneously) used to refer to an entire heraldic achievement of armorial bearings. The technical use of the heraldic term crest refers to just one component of a complete achievement. The crest rests on top of a helmet which itself rests on the most important part of the achievement: the shield.
The modern crest has grown out of the three-dimensional figure placed on the top of the mounted knights' helms as a further means of identification. In most heraldic traditions, a woman does not display a crest, though this tradition is being relaxed in some heraldic jurisdictions, and the stall plate of Lady Marion Fraser in the Thistle Chapel in St Giles, Edinburgh, shows her coat on a lozenge but with helmet, crest, and motto.
The crest is usually found on a wreath of twisted cloth and sometimes within a coronet. Crest-coronets are generally simpler than coronets of rank, but several specialized forms exist; for example, in Canada, descendants of the United Empire Loyalists are entitled to use a Loyalist military coronet (for descendants of members of Loyalist regiments) or Loyalist civil coronet (for others).
When the helm and crest are shown, they are usually accompanied by a mantling. This was originally a cloth worn over the back of the helmet as partial protection against heating by sunlight. Today it takes the form of a stylized cloak hanging from the helmet. Typically in British heraldry, the outer surface of the mantling is of the principal colour in the shield and the inner surface is of the principal metal, though peers in the United Kingdom use standard colourings (Gules doubled Argent - Red/White) regardless of rank or the colourings of their arms. The mantling is sometimes conventionally depicted with a ragged edge, as if damaged in combat, though the edges of most are simply decorated at the emblazoner's discretion.
Clergy often refrain from displaying a helm or crest in their heraldic achievements. Members of the clergy may display appropriate headwear. This often takes the form of a small crowned, wide brimmed hat called a galero with the colours and tassels denoting rank; or, in the case of Papal coats of arms until the inauguration of Pope Benedict XVI in 2005, an elaborate triple crown known as a tiara. Benedict broke with tradition to substitute a mitre in his arms. Orthodox and Presbyterian clergy do sometimes adopt other forms of head gear to ensign their shields. In the Anglican tradition, clergy members may pass crests on to their offspring, but rarely display them on their own shields.
Mottoes.
An armorial motto is a phrase or collection of words intended to describe the motivation or intention of the armigerous person or corporation. This can form a pun on the family name as in Thomas Nevile's motto "Ne vile velis". Mottoes are generally changed at will and do not make up an integral part of the armorial achievement. Mottoes can typically be found on a scroll under the shield. In Scottish heraldry where the motto is granted as part of the blazon, it is usually shown on a scroll above the crest, and may not be changed at will. A motto may be in any language.
Supporters and other insignia.
Supporters are human or animal figures or, very rarely, inanimate objects, usually placed on either side of a coat of arms as though supporting it. In many traditions, these have acquired strict guidelines for use by certain social classes. On the European continent, there are often fewer restrictions on the use of supporters. In the United Kingdom, only peers of the realm, a few baronets, senior members of orders of knighthood, and some corporate bodies are granted supporters. Often, these can have local significance or a historical link to the armiger.
If the armiger has the title of baron, hereditary knight, or higher, he may display a coronet of rank above the shield. In the United Kingdom, this is shown between the shield and helmet, though it is often above the crest in Continental heraldry.
Another addition that can be made to a coat of arms is the insignia of a baronet or of an order of knighthood. This is usually represented by a collar or similar band surrounding the shield. When the arms of a knight and his wife are shown in one achievement, the insignia of knighthood surround the husband's arms only, and the wife's arms are customarily surrounded by a meaningless ornamental garland of leaves for visual balance.
Differencing and cadency.
Since arms pass from parents to offspring, and there is frequently more than one child per couple, it is necessary to distinguish the arms of siblings and extended family members from the original arms as passed on from eldest son to eldest son. Over time several schemes have been used.
Blazon.
To "blazon" arms means to describe them using the formal language of heraldry. This language has its own vocabulary and syntax, or rules governing word order, which becomes essential for comprehension when blazoning a complex coat of arms. The verb comes from the Middle English "blasoun", itself a derivative of the French "blason" meaning "shield". The system of blazoning arms used in English-speaking countries today was developed by heraldic officers in the Middle Ages. The blazon includes a description of the arms contained within the escutcheon or shield, the crest, supporters where present, motto and other insignia. Complex rules, such as the rule of tincture, apply to the physical and artistic form of newly created arms, and a thorough understanding of these rules is essential to the art of heraldry. Though heraldic forms initially were broadly similar across Europe, several national styles had developed by the end of the Middle Ages, and artistic and blazoning styles today range from the very simple to extraordinarily complex.
National styles.
The emergence of heraldry occurred across western Europe almost simultaneously in the various countries. Originally, heraldic style was very similar from country to country. Over time, heraldic tradition diverged into four broad styles: German-Nordic, Gallo-British, Latin, and Eastern. In addition it can be argued that newer national heraldic traditions, such as South African and Canadian, have emerged in the 20th century.
German-Nordic heraldry.
Coats of arms in Germany, the Scandinavian countries, Estonia, Latvia, Czech lands and northern Switzerland generally change very little over time. Marks of difference are very rare in this tradition as are heraldic furs. One of the most striking characteristics of German-Nordic heraldry is the treatment of the crest. Often, the same design is repeated in the shield and the crest. The use of multiple crests is also common. The crest is rarely used separately as in British heraldry, but can sometimes serve as a mark of difference between different branches of a family. Torse is optional. Heraldic courtoisie is observed: that is, charges in a composite shield (or two shields displayed together) usually turn to face the centre.
Coats consisting only of a divided field are somewhat more frequent in Germany than elsewhere.
Greek heraldry.
Ancient Greeks were among the first civilizations to use symbols consistently in order to identify a warrior, clan or a state. The first record of a shield blazon is illustrated in Aeschylus' tragedy "Seven Against Thebes". The Greek Heraldry Society is a useful source of information on Hellenic Heraldry and Byzantine etiquette.
Dutch heraldry.
The Low Countries were great centres of heraldry in medieval times. One of the famous armorials is the Gelre Armorial or "Wapenboek", written between 1370 and 1414.
Coats of arms in the Netherlands were not controlled by an official heraldic system like the two in the United Kingdom, nor were they used solely by noble families. Any person could develop and use a coat of arms if they wished to do so, provided they did not usurp someone else's arms, and historically, this right was enshrined in Roman Dutch law. As a result, many merchant families had coats of arms even though they were not members of the nobility. These are sometimes referred to as "burgher arms," and it is thought that most arms of this type were adopted while the Netherlands was a republic (1581–1806). This heraldic tradition was also exported to the erstwhile Dutch colonies.
Dutch heraldry is characterised by its simple and rather sober style, and in this sense, is closer to its medieval origins than the elaborate styles which developed in other heraldic traditions.
Turkish heraldry.
Every sultan of the Ottoman Empire had his own monogram, called the tughra, which served as a royal symbol. A coat of arms in the European heraldic sense was created in the late 19th century. Hampton Court requested from Ottoman Empire the coat of arms to be included in their collection. As the coat of arms had not been previously used in Ottoman Empire, it was designed after this request and the final design was adopted by Sultan Abdul Hamid II on April 17, 1882. It included two flags: the flag of the Ottoman Dynasty, which had a crescent and a star on red base, and the flag of the Islamic Caliph, which had three crescents on a green base.
Gallo-British heraldry.
The use of cadency marks to difference arms within the same family and the use of semy fields are distinctive features of Gallo-British heraldry (in Scotland the most significant mark of cadency being the bordure, the small brisures playing a very minor role). It is common to see heraldic furs used. In the United Kingdom, the style is notably still controlled by royal officers of arms. French heraldry experienced a period of strict rules of construction under the Emperor Napoleon. English and Scots heraldries make greater use of supporters than other European countries.
Furs, chevrons and five-pointed stars are more frequent in France and Britain than elsewhere.
Latin heraldry.
The heraldry of southern France, Andorra, Spain, and Italy is characterized by a lack of crests, and uniquely shaped shields. Portuguese heraldry, however, does use crests. Portuguese and Spanish heraldry occasionally introduce words to the shield of arms, a practice disallowed in British heraldry. Latin heraldry is known for extensive use of quartering, because of armorial inheritance via the male and the female lines. Moreover, Italian heraldry is dominated by the Roman Catholic Church, featuring many shields and achievements, most bearing some reference to the Church.
Trees are frequent charges in Latin arms. Charged bordures, including bordures inscribed with words, are seen often in Spain.
Central and Eastern European heraldry.
Eastern European heraldry is in the traditions developed in Belarus, Bulgaria, Serbia, Croatia, Hungary, Romania, Lithuania, Poland, Slovakia, Ukraine, and Russia. Eastern coats of arms are characterized by a pronounced, territorial, clan system – often, entire villages or military groups were granted the same coat of arms irrespective of family relationships. In Poland, nearly six hundred unrelated families are known to bear the same Jastrzębiec coat of arms. Marks of cadency are almost unknown, and shields are generally very simple, with only one charge. Many heraldic shields derive from ancient house marks. At the least, fifteen per cent of all Hungarian personal arms bear a severed Turk's head, referring to their wars against the Ottoman Empire.
Modern heraldry.
Heraldry flourishes in the modern world; institutions, companies, and private persons continue using coats of arms as their pictorial identification. In the United Kingdom and Ireland, the English Kings of Arms, Scotland's Lord Lyon King of Arms, and the Chief Herald of Ireland continue making grants of arms. There are heraldic authorities in Canada, South Africa, Spain, and Sweden that grant or register coats of arms. In South Africa, the right to armorial bearings is also determined by Roman Dutch law, due to its origins as a 17th-century colony of the Netherlands.
Heraldic societies abound in Africa, Asia, Australasia, the Americas and Europe. Heraldry aficionados participate in the Society for Creative Anachronism, medieval revivals, micronationalism, et cetera. People see heraldry as a part of their national and personal heritages, and as a manifestation of civic and national pride. Today, heraldry is not a worldly expression of aristocracy, merely a form of identification.
Military heraldry continues developing, incorporating blazons unknown in the medieval world. Nations and their subdivisions – provinces, states, counties, cities, etc. – continue to build on the traditions of civic heraldry. The Roman Catholic Church, the Church of England, and other Churches maintain the tradition of ecclesiastical heraldry for their high-rank prelates, religious orders, universities, and schools.
Heraldry in many countries with heraldic authorities are governed by certain laws, granting rights and possession to bear arms as well as protection against misuse by others. Other countries without heraldic authorities to grant arms usually treat coat of arms in much the same way as logos and such could be protected under copyright laws if registered appropriately.

</doc>
<doc id="13611" url="https://en.wikipedia.org/wiki?curid=13611" title="Heretic (video game)">
Heretic (video game)

Heretic is a dark fantasy first-person shooter video game released in 1994. It was developed by Raven Software, published by id Software, and distributed by GT Interactive. The game was released on Steam on August 3, 2007.
Using a modified version of the "Doom" engine, "Heretic" was one of the first first-person games to feature inventory manipulation and the ability to look up and down. It also introduced multiple gib objects that spawned when a character suffered a death by extreme force or heat. Previously, the character would simply crumple into a heap. The game used randomized ambient sounds and noises, such as evil laughter, chains rattling, distantly ringing bells, and water dripping in addition to the background music to further enhance the atmosphere. All of the music in the game was composed by Kevin Schilder. An indirect sequel, "", was released the following year. "Heretic II" was released in 1998, which served as a direct sequel continuing the story.
Plot.
Three brothers, known as the Serpent Riders, have used their powerful magic to possess seven kings of Parthoris into mindless puppets and corrupt their armies. The Sidhe elves resist the Serpent Riders' magic. The Serpent Riders thus declared the Sidhe as heretics and waged war against them. The Sidhe are forced to take a drastic measure to sever the natural power of the kings destroying them and their armies, but at the cost of weakening the elves' power, giving the Serpent riders an advantage to slay the elders. While the Sidhe retreat, one elf (revealed to be named Corvus in "Heretic II"), sets off on a quest of vengeance against the weakest of the three Serpent Riders, D'Sparil. He travels through the "City of the Damned", the ruined capital of the Sidhe (its real name is revealed to be Silverspring in "Heretic II"), then past Hell's Maw and finally the Dome of D'Sparil.
The player must first fight through the undead hordes infesting the location where the elders performed their ritual. At its end is the gateway to Hell's Maw, guarded by the Iron Liches. After defeating them, the player must seal the portal and so prevent further infestation, but after he enters the portal guarded by the Maulotaurs, he finds himself inside D'Sparil's dome. After killing D'Sparil, Corvus ends up on a perilous journey with little hope of returning home.
Gameplay.
The gameplay of "Heretic" is heavily derived from "Doom", with a level-based structure and an emphasis on finding the proper keys to progress. Many weapons are similar to those from "Doom"; the early weapons in particular are near-exact copies in functionality to those seen in "Doom". Raven added a number of features to "Heretic" that differentiated it from "Doom", however, notably interactive environments, such as rushing water that pushes the player along, and inventory items. In "Heretic", the player can pick up many different items to use at their discretion. These items range from health potions to the "morph ovum", which transforms enemies into chickens. One of the most notable pickups that can be found is the "Tome of Power" which acts as a secondary firing mode for certain weapons, resulting in a much more powerful projectile from each weapon, some of which change the look of the projectile entirely. "Heretic" also features an improved version of the "Doom" engine, sporting the ability to look up and down within constraints, as well as fly. However, the rendering method for looking up and down merely uses a proportional pixel-shearing effect rather than any new rendering algorithm, which distorts the view considerably when looking at high-elevation angles.
As with "Doom", "Heretic" contains various cheat codes that give the player invulnerability, obtain every weapon, be able to instantly kill every monster in a particular level, and several other abilities. However, if the player uses the "all weapons" cheat from "Doom", a message appears warning the player against cheating and takes away all of his weapons, leaving him with only a quarterstaff. If the player uses the "god mode" cheat ("codice_1") from "Doom", the game will display a message saying "Trying to cheat, eh? Now you die!" and kills the player.
The original shareware release of the game was to come bundled with support for online multiplayer through the nascent DWANGO service.
"Shadow of the Serpent Riders".
The original version of "Heretic" was only available through shareware registration (i.e. mail order) and contained three episodes. The retail version, "Heretic: Shadow of the Serpent Riders", was distributed by GT Interactive in 1996 and featured the original three episodes plus two additional episodes: "The Ossuary", which takes the player to the shattered remains of a world conquered by the Serpent Riders several centuries ago, and "The Stagnant Demesne", where the player enters D'Sparil's birthplace. This version was the first official release of "Heretic" in Europe. A free patch was also downloadable from Raven's website to update the original "Heretic" with the content found in "Shadow of the Serpent Riders".
Source release.
On January 11, 1999, the source code of the game engine used in "Heretic" was published by Raven Software under a license that granted rights to non-commercial use, and was re-released under the GNU General Public License on September 4, 2008. This resulted in ports to Linux, Amiga, and other operating systems, and updates to the game engine to utilize 3D acceleration. The shareware version of a console port for the Dreamcast was also released.
The "Blasphemer" project aims to create a free content package for "Heretic", with a theme of metal-inspired dark fantasy, in a similar way as "Freedoom" does with "Doom".
Reception.
"Heretic" received mixed reviews, garnering an aggregated score of 62% on GameRankings and 78% on PC Zone.
While remarking that "Heretic" is a thinly-veiled clone of "Doom", and that its being released in Europe after and with "Quake" due out shortly makes it somewhat outdated, "Maximum" nonetheless regarded it as an extremely polished and worthwhile purchase. They particularly highlighted the two additional episodes of the retail version, saying they offer a satisfying challenge even to first person shooter veterans and are largely what make the game worth buying.

</doc>
<doc id="13613" url="https://en.wikipedia.org/wiki?curid=13613" title="Hexen II">
Hexen II

Hexen II is a dark fantasy first-person shooter video game developed by Raven Software from 1996 to 1997, published by id Software and distributed by Activision. It was the third game in the "Hexen"/"Heretic" series, and the last in the Serpent Riders trilogy. It was made available on Steam on August 3, 2007. Using a modified "Quake" engine, it featured single-player and multiplayer game modes, as well as four character classes to choose from, each with different abilities. These included the offensive Paladin, the defensive Crusader, the spell-casting Necromancer, and the stealthy Assassin.
Improvements from "Hexen" and "Quake" included destructible environments, mounted weapons, and unique level up abilities. Like its predecessor, "Hexen II" also used a hub system. These hubs were a number of interconnected levels; changes made in one level had effects in another. The Tome of Power artifact made a return from "Heretic".
Gameplay.
The gameplay of "Hexen II" is very similar to that of the original "Hexen". Instead of three classes, "Hexen II" features four: Paladin, Crusader, Assassin, and Necromancer, each with their own unique weapons and play style.
"Hexen II" also adds certain role-playing video game elements to the mix. Each character has a series of statistics which increase as they gain experience. This then causes the player character to grow in power as his or her HP and Mana increases.
Plot.
Thyrion is a world that was enslaved by the Serpent Riders. The two previous games in the series documented the liberation of two other worlds, along with the death of their Serpent Rider overlords. Now, the oldest and most powerful of the three Serpent Rider brothers, Eidolon, must be defeated to free Thyrion. Eidolon is supported by his four generals, themselves a reference to the Four Horsemen of the Apocalypse. To confront each general, the player has to travel to four different continents, each possessing a distinct theme (Medieval European for Blackmarsh, Mesoamerican for Mazaera, Ancient Egyptian for Thysis, and Greco-Roman for Septimus). Then, finally, the player returns to Blackmarsh in order to confront Eidolon himself inside of his own dominion Cathedral.
Development.
"Hexen II", by way of the "Quake" engine, uses OpenGL for 3D acceleration. However, due to the prevalence of 3dfx hardware at the time of release, the Windows version of the game installs an OpenGL ICD (opengl32.dll) designed specifically for 3dfx's hardware. This driver acts as a wrapper for the proprietary Glide API, and thus is only compatible with 3dfx hardware. Custom OpenGL drivers were also released by PowerVR and Rendition for running "Hexen II" with their respective (and also now defunct) products. Removal of the ICD allows the game to use the default OpenGL system library. Much of the music in this game is remixed versions of the soundtracks of and Heretic to match the hub themes.
"Siege".
A modification titled "Siege" was created and released by Raven Software in 1998 using updated QuakeWorld architecture, aptly dubbed "HexenWorld". The production concept was to eliminate a normal deathmatch environment in favor of a teamplay castle siege. The basic premise was to divide the players into two teams—attackers and defenders—with each side either assaulting or protecting the castle respectively. At the end of the time limit, whichever team controlled the crown was declared victorious. The mod featured appropriate objects used in the single-player portion of the game, namely catapults and ballistae. The classes, however, were drastically altered with new weapons and abilities, reflecting the departure from the normal deathmatch experience presented in "HexenWorld".
Source release.
Following the tradition from "Heretic" and "Hexen", Raven released the source code of the "Hexen II" engine on November 10, 2000. This time the source was released under the GNU General Public License, allowing source ports to be made to different platforms like Linux and the Dreamcast.
"Portal of Praevus".
An expansion pack called "Hexen II Mission Pack: Portal of Praevus" was released on March 31, 1998. It features new levels, new enemies and a new playable character class, The Demoness. It focuses on the attempted resurrection of the three Serpent Riders by the evil wizard Praevus, and takes place in a fifth continent, Tulku, featuring a Sino-Tibetan setting. Unlike the original game, the expansion was not published by id Software, and as such is not currently available via digital re-releases.
The expansion features new quest items, new enemies, and new weapons for the Demoness. She is the only player class to have a ranged starting weapon (similar to the Mage class in the original "Hexen"), whereas all other characters start with melee weapons. It also introduced minor enhancements to the game engine, mostly related to user interface, level scripts, particle effects (rain or snow), and 3D objects. "Portal of Praevus" also features a secret (easter egg) skill level, with respawning monsters. The only released patch for the expansion added respawning of certain items (such as health and ammo) in Nightmare mode, so that it would be slightly easier for playing.
Reception.
Because of the popularity of the original "Hexen", the game was heavily anticipated. Upon its release, "Hexen II" received mixed to positive reviews. IGN gave the game a score of 7.8 out of 10; however, GameSpot rated the game (7.3 out of 10) much lower than it rated the expansion (8.6 out of 10).

</doc>
<doc id="13614" url="https://en.wikipedia.org/wiki?curid=13614" title="Heretic II">
Heretic II

Heretic II is a dark fantasy action-adventure game developed by Raven Software and published by Activision in 1998 continuing the story of Corvus, the main character from its predecessor, "Heretic".
Using a modified Quake II engine, the game features a mix of a third-person camera with a first-person shooter's action, making for a new gaming experience at the time. While progressive, this was a controversial design decision among fans of the original title, a well-known first-person shooter built on the Doom engine. The music was composed by Kevin Schilder. Gerald Brom contributed conceptual work to characters and creatures for the game. This is the only Heretic/Hexen video game that is unrelated to id Software, apart from its role as engine licenser.
"Heretic II" was later ported to Linux by Loki Software and to the Amiga by Hyperion Entertainment and Macintosh by MacPlay.
Gameplay.
Players control Corvus from a camera fixed behind the player in third-person perspective. Players are able to use a combination of both melee and ranged attacks, similar to its predecessor. Defensive spells are also available, and they draw from a separate ammunition pool. The game consists of a wide variety of high fantasy medieval backdrops to Corvus's adventure. The third-person perspective and three-dimensional game environment allowed developers to introduce a wide variety of gymnastic moves, like pole vaulting, in a much more dynamic environment than the original game's engine could produce. Both games invite comparison with their respective game-engine namesake: the original "Heretic" was built on the "Doom" engine, and "Heretic II" was built using the "Quake II" engine, later known as id Tech 2. "Heretic II" was favorably received at release because it took a different approach to its design.
Plot.
After Corvus returns from his banishment, he finds that a mysterious plague has swept the land of Parthoris, taking the sanity of those it does not kill. Corvus, the protagonist of the first game, is forced to flee his hometown of Silverspring after the infected attack him, but not before he is infected himself. The effects of the disease are held at bay in Corvus’ case because he holds one of the Tomes of Power, but he still must find a cure before he succumbs.
His quest leads him through the city and swamps to a jungle palace, then through a desert canyon and insect hive, followed by a dark network of mines and finally to a castle on a high mountain where he finds an ancient Seraph named Morcalavin. Morcalavin is trying to reach immortality using the seven Tomes of Power, but he uses a false tome, as Corvus has one of them. This has caused Morcalavin to go insane and create the plague. During a battle between Corvus and Morcalavin, Corvus switches the false tome for his real one, curing Morcalavin’s insanity and ending the plague.

</doc>
<doc id="13615" url="https://en.wikipedia.org/wiki?curid=13615" title="Household hardware">
Household hardware

Household hardware, or simply, hardware, is a general term for equipment that can be touched/held by hand such as screws, nuts, washers, keys, locks, hinges, latches, handles, wire, chains, belts, plumbing supplies, electrical supplies, tools, utensils, cutlery and machine parts. Household hardware is typically sold in hardware stores.

</doc>
<doc id="13616" url="https://en.wikipedia.org/wiki?curid=13616" title="Howard Carter">
Howard Carter

Howard Carter (9 May 18742 March 1939) was an English archaeologist and Egyptologist who became world famous after discovering the intact tomb of the 18th Dynasty Pharaoh, Tutankhamun (colloquially known as "King Tut" and "the boy king") in November 1922.
Early life.
Howard Carter was born in Kensington, London, the son of Samuel Carter, an artist, and Martha Joyce Carter. His father trained and developed Howard's artistic talents.
Howard Carter spent much of his childhood with relatives in the Norfolk market town of Swaffham, the birthplace of both his parents. In 1891 the Egypt Exploration Fund (EEF) sent Carter to assist Percy Newberry in the excavation and recording of Middle Kingdom tombs at Beni Hasan. 
Although only 17, Carter was innovative in improving the methods of copying tomb decoration. In 1892, he worked under the tutelage of Flinders Petrie for one season at Amarna, the capital founded by the pharaoh Akhenaten. From 1894 to 1899, he worked with Édouard Naville at Deir el-Bahari, where he recorded the wall reliefs in the temple of Hatshepsut.
In 1899, Carter was appointed as the first chief inspector of the Egyptian Antiquities Service (EAS). He supervised a number of excavations at Thebes (now known as Luxor). In 1904, he was transferred to the Inspectorate of Lower Egypt. Carter was praised for his improvements in the protection of, and accessibility to, existing excavation sites, and his development of a grid-block system for searching for tombs. The Antiquities Service also provided funding for Carter to head his own excavation projects and during this period Carter discovered the Tombs of Thutmose I and Thutmose III, although both tombs had been robbed of treasures long before.
Carter resigned from the Antiquities Service in 1905 after a formal inquiry into what became known as the Saqqara Affair, a noisy confrontation between Egyptian site guards and a group of French tourists. Carter sided with the Egyptian personnel.
Tutankhamun's tomb.
In 1907, after three hard years for Carter, Lord Carnarvon employed him to supervise Carnarvon's Egyptian excavations in the Valley of the Kings. The intention of Gaston Maspero, who introduced the two, was to ensure that Howard Carter imposed modern archaeological methods and systems of recording.
Carnarvon financed Carter's work in the Valley of the Kings to 1914, but until 1917 excavations and study were interrupted by the First World War. Following the end of the First World War, Carter aggressively resumed his work.
After several years of finding little, Lord Carnarvon became dissatisfied with the lack of results, and in 1922 informed Carter that he had one more season of funding to search the Valley of the Kings and find the tomb.
On 4 November 1922, Howard Carter's excavation group found steps that Carter hoped led to Tutankhamun's tomb (subsequently designated KV62) (the tomb that would be considered the best preserved and most intact pharaonic tomb ever found in the Valley of the Kings).
He wired Lord Carnarvon to come, and on 26 November 1922, with Carnarvon, Carnarvon's daughter and others in attendance, Carter made the "tiny breach in the top left hand corner" of the doorway (with a chisel his grandmother had given him for his 17th birthday.) He was able to peer in by the light of a candle and see that many of the gold and ebony treasures were still in place. He did not yet know whether it was "a tomb or merely a cache", but he did see a promising sealed doorway between two sentinel statues. When Carnarvon asked "Can you see anything?", Carter replied with the famous words: "Yes, wonderful things!"
The next several months were spent cataloging the contents of the antechamber under the "often stressful" supervision of Pierre Lacau, director general of the Department of Antiquities of Egypt. On 16 February 1923, Carter opened the sealed doorway, and found that it did indeed lead to a burial chamber, and he got his first glimpse of the sarcophagus of Tutankhamun. All of these discoveries were eagerly covered by the world's press, but most of their representatives were kept in their hotels; only H. V. Morton was allowed on the scene, and his vivid descriptions helped to cement Carter's reputation with the British public.
Carter's own notes and photographic evidence indicate that he, Lord Carnarvon and Lady Evelyn Herbert entered the burial chamber shortly after the tomb's discovery and before the official opening.
Later work and death.
The clearance of the tomb with its thousands of objects continued until 1932. Following his sensational discovery, Carter retired from archaeology and became a part-time agent for collectors and museums, including the Cleveland Museum of Art and the Detroit Institute of Arts. He visited the United States in 1924 and gave a series of illustrated lectures in New York City and other cities in the United States that were attended by very large and enthusiastic audiences, sparking Egyptomania in America.
He died of Hodgkin's disease in Kensington, London, on 2 March 1939 at the age of 64. The archaeologist's natural death was so long after the opening of the tomb, despite his being the leader of the expedition, is the piece of evidence most commonly put forward by skeptics to refute the idea of a "curse of the pharaohs" plaguing whatever parties that might have "violated" Tutankhamun's tomb.
Carter is now buried in Putney Vale Cemetery in London. His epitaph reads: "May your spirit live, may you spend millions of years, you who love Thebes, sitting with your face to the north wind, your eyes beholding happiness", a quotation taken from the Wishing Cup of Tutankhamun, and "O night, spread thy wings over me as the imperishable stars".
In popular culture.
Film and television.
Carter has been portrayed in multiple film and television productions:

</doc>
<doc id="13617" url="https://en.wikipedia.org/wiki?curid=13617" title="History of Scotland">
History of Scotland

The is known to have begun by the end of the last glacial period (in the paleolithic), roughly 10,000 years ago. Prehistoric Scotland entered the Neolithic Era about 4000 , the Bronze Age about 2000 , and the Iron Age around 700 . Scotland's recorded history began with the arrival of the Roman Empire in the 1st century, when the province of Britannia reached as far north as the line between the firths of Clyde to the Forth. North of this was Caledonia, whose people were known in Latin as "Picti", "the painted ones". Constant risings forced Rome's legions back: Hadrian's Wall attempted to seal off the Roman south and the Antonine Wall attempted to move the Roman border north. The latter was swiftly abandoned and the former overrun, most spectacularly during the Great Conspiracy of the 360s. As Rome finally withdrew from Britain, Gaelic raiders called the "Scoti" began colonizing Western Scotland and Wales.
According to 9th- and 10th-century sources, the Gaelic kingdom of Dál Riata was founded on the west coast of Scotland in the 6th century. In the following century, the Irish missionary Columba founded a monastery on Iona and introduced the previously pagan Scoti and pagan Picts to Celtic Christianity. Following England's Gregorian mission, the Pictish king Nechtan chose to abolish most Celtic practices in favor of the Roman rite, restricting Gaelic influence on his kingdom and avoiding war with Saxon Northumbria. Towards the end of the 8th century, the Viking invasions began. Successive defeats by the Norse forced the Picts and Gaels to cease their historic hostility to each other and to unite in the 9th century, forming the Kingdom of Scotland.
The Kingdom of Scotland was united under the descendants of Kenneth MacAlpin, first king of a united Scotland. His descendants, known to modern historians as the House of Alpin, fought among each other during frequent disputed successions. The last Alpin king, Malcolm II, died without issue in the early 11th century and the kingdom passed through his daughter's son, Duncan I, who started a new line of kings known to modern historians as the House of Dunkeld or Canmore. The last Dunkeld king, Alexander III, died in 1286 leaving only a single infant granddaughter as heir; four years later, Margaret, Maid of Norway herself died in a tragic shipwreck "en route" to Scotland. England, under Edward I, would take advantage of the questioned succession in Scotland to launch a series of conquests into Scotland. The resulting Wars of Scottish Independence were fought in the late 13th and early 14th centuries as Scotland passed back and forth between the House of Balliol and the House of Bruce. Scotland's ultimate victory in the Wars of Independence under David II confirmed Scotland as a fully independent and sovereign kingdom. When David II died without issue, his nephew Robert II established the House of Stewart (the spelling would be changed to Stuart in the 16th century), which would rule Scotland uncontested for the next three centuries. James VI, Stuart king of Scotland, also inherited the throne of England in 1603, and the Stuart kings and queens ruled both independent kingdoms until the Act of Union in 1707 merged the two kingdoms into a new state, the Kingdom of Great Britain. Queen Anne was the last Stuart monarch, ruling until 1714. Since 1714, the succession of the British monarchs of the houses of Hanover and Saxe-Coburg and Gotha (Windsor) has been due to their descent from James VI and I of the House of Stuart.
During the Scottish Enlightenment and Industrial Revolution, Scotland became one of the commercial, intellectual and industrial powerhouses of Europe. Its industrial decline following the Second World War was particularly acute, but in recent decades the country has enjoyed something of a cultural and economic renaissance, fuelled in part by a resurgent financial services sector, the proceeds of North Sea oil and gas.
Prehistory.
People lived in Scotland for at least 8,500 years before Britain's recorded history. At times during the last interglacial period (130,000–70,000 ) Europe had a climate warmer than today's, and early humans may have made their way to Scotland, with the discovery of ten pre-ice age axes on Orkney and mainland Scotland. Glaciers then scoured their way across most of Britain, and only after the ice retreated did Scotland again become habitable, around 9600 . Mesolithic hunter-gatherer encampments formed the first known settlements, and archaeologists have dated an encampment near Biggar to around 8500 . Numerous other sites found around Scotland build up a picture of highly mobile boat-using people making tools from bone, stone and antlers. The oldest house for which there is evidence in Britain is the oval structure of wooden posts found at South Queensferry near the Firth of Forth, dating from the Mesolithic period, about 8240 . The earliest stone structures are probably the three hearths found at Jura, dated to about 6000 .
Neolithic farming brought permanent settlements. Evidence of these includes the well-preserved stone house at Knap of Howar on Papa Westray, dating from around 3500  and the village of similar houses at Skara Brae on West Mainland, Orkney from about 500 years later. The settlers introduced chambered cairn tombs from around 3500 , as at Maeshowe, and from about 3000  the many standing stones and circles such as those at Stenness on the mainland of Orkney, which date from about 3100 , of four stones, the tallest of which is in height. These were part of a pattern that developed in many regions across Europe at about the same time.
The creation of cairns and Megalithic monuments continued into the Bronze Age, which began in Scotland about 2000 . As elsewhere in Europe, hill forts were first introduced in this period, including the occupation of Eildon Hill near Melrose in the Scottish Borders, from around 1000 , which accommodated several hundred houses on a fortified hilltop. From the Early and Middle Bronze Age there is evidence of cellular round houses of stone, as at Jarlshof and Sumburgh on Shetland. There is also evidence of the occupation of crannogs, roundhouses partially or entirely built on artificial islands, usually in lakes, rivers and estuarine waters.
In the early Iron Age, from the seventh century , cellular houses began to be replaced on the northern isles by simple Atlantic roundhouses, substantial circular buildings with a dry stone construction. From about 400 , more complex Atlantic roundhouses began to be built, as at Howe, Orkney and Crosskirk, Caithness. The most massive constructions that date from this era are the circular broch towers, probably dating from about 200 . This period also saw the first wheelhouses, a roundhouse with a characteristic outer wall, within which was a circle of stone piers (bearing a resemblance to the spokes of a wheel), but these would flourish most in the era of Roman occupation. There is evidence for about 1,000 Iron Age hill forts in Scotland, most located below the Clyde-Forth line, which have suggested to some archaeologists the emergence of a society of petty rulers and warrior elites recognisable from Roman accounts.
Roman invasion.
The surviving pre-Roman accounts of Scotland originated with the Greek Pytheas of Massalia, who may have circumnavigated the British Isles of Albion (Britain) and Ierne (Ireland) sometime around 325 . The most northerly point of the island of Great Britain was called "Orcas" (Orkney). By the time of Pliny the Elder, who died in  79, Roman knowledge of the geography of Scotland had extended to the "Hebudes" (The Hebrides), "Dumna" (probably the Outer Hebrides), the Caledonian Forest and the people of the Caledonii, from whom the Romans named the region north of their control Caledonia. Ptolemy, possibly drawing on earlier sources of information as well as more contemporary accounts from the Agricolan invasion, identified 18 tribes in Scotland in his "Geography", but many of the names are obscure and the geography becomes less reliable in the north and west, suggesting early Roman knowledge of these area was confined to observations from the sea.
The Roman invasion of Britain began in earnest in  43, leading to the establishment of the Roman province of Britannia in the south. By the year 71, the Roman governor Quintus Petillius Cerialis had launched an invasion of what is now Scotland. In the year 78, Gnaeus Julius Agricola arrived in Britain to take up his appointment as the new governor and began a series of major incursions. He is said to have pushed his armies to the estuary of the "River Taus" (usually assumed to be the River Tay) and established forts there, including a legionary fortress at Inchtuthil. After his victory over the northern tribes at Mons Graupius in 84, a series of forts and towers were established along the Gask Ridge, which marked the boundary between the Lowland and Highland zones, probably forming the first Roman "limes" or frontier in Scotland. Agricola's successors were unable or unwilling to further subdue the far north. By the year 87, the occupation was limited to the Southern Uplands and by the end of the first century the northern limit of Roman expansion was a line drawn between the Tyne and Solway Firth. The Romans eventually withdrew to a line in what is now northern England, building the fortification known as Hadrian's Wall from coast to coast.
Around 141, the Romans undertook a reoccupation of southern Scotland, moving up to construct a new "limes" between the Firth of Forth and the Firth of Clyde, which became the Antonine Wall. The largest Roman construction inside Scotland, it is a sward-covered wall made of turf around high, with nineteen forts. It extended for . Having taken twelve years to build, the wall was overrun and abandoned soon after 160. The Romans retreated to the line of Hadrian's Wall. Roman troops penetrated far into the north of modern Scotland several more times, with at least four major campaigns. The most notable invasion was in 209 when the emperor Septimius Severus led a major force north. After the death of Severus in 210 they withdrew south to Hadrian's Wall, which would be Roman frontier until it collapsed in the 5th century. By the close of the Roman occupation of southern and central Britain in the 5th century, the Picts had emerged as the dominant force in northern Scotland, with the various Brythonic tribes the Romans had first encountered there occupying the southern half of the country. Roman influence on Scottish culture and history was not enduring.
Post-Roman Scotland.
In the centuries after the departure of the Romans from Britain, there were four groups within the borders of what is now Scotland. In the east were the Picts, with kingdoms between the river Forth and Shetland. In the late 6th century the dominant force was the Kingdom of Fortriu, whose lands were centred on Strathearn and Menteith and who raided along the eastern coast into modern England. In the west were the Gaelic (Goidelic)-speaking people of Dál Riata with their royal fortress at Dunadd in Argyll, with close links with the island of Ireland, from whom comes the name Scots. In the south was the British (Brythonic) Kingdom of Strathclyde, descendants of the peoples of the Roman influenced kingdoms of "The Old North", often named Alt Clut, the Brythonic name for their capital at Dumbarton Rock. Finally, there were the English or "Angles", Germanic invaders who had overrun much of southern Britain and held the Kingdom of Bernicia, in the south-east. The first English king in the historical record is Ida, who is said to have obtained the throne and the kingdom about 547. Ida’s grandson, Æthelfrith, united his kingdom with Deira to the south to form Northumbria around the year 604. There were changes of dynasty, and the kingdom was divided, but it was re-united under Æthelfrith's son Oswald (r. 634-42).
Scotland was largely converted to Christianity by Irish-Scots missions associated with figures such as St Columba, from the fifth to the seventh centuries. These missions tended to found monastic institutions and collegiate churches that served large areas. Partly as a result of these factors, some scholars have identified a distinctive form of Celtic Christianity, in which abbots were more significant than bishops, attitudes to clerical celibacy were more relaxed and there was some significant differences in practice with Roman Christianity, particularly the form of tonsure and the method of calculating Easter, although most of these issues had been resolved by the mid-7th century.
Rise of the Kingdom of Alba.
Conversion to Christianity may have speeded a long term process of gaelicisation of the Pictish kingdoms, which adopted Gaelic language and customs. There was also a merger of the Gaelic and Pictish crowns, although historians debate whether it was a Pictish takeover of Dál Riata, or the other way around. This culminated in the rise of Cínaed mac Ailpín (Kenneth MacAlpin) in the 840s, which brought to power the House of Alpin. In 867 AD the Vikings seized the southern half of Northumbria, forming the Kingdom of York; three years later they stormed the Britons’ fortress of Dumbarton and subsequently conquered much of England except for a reduced Kingdom of Wessex, leaving the new combined Pictish and Gaelic kingdom almost encircled. When he died as king of the combined kingdom in 900, Domnall II (Donald II) was the first man to be called "rí Alban" (i.e. "King of Alba"). The term Scotia was increasingly used to describe the kingdom between North of the Forth and Clyde and eventually the entire area controlled by its kings was referred to as Scotland.
The long reign (900–942/3) of Causantín (Constantine II) is often regarded as the key to formation of the Kingdom of Alba. He was later credited with bringing Scottish Christianity into conformity with the Catholic Church. After fighting many battles, his defeat at Brunanburh was followed by his retirement as a Culdee monk at St. Andrews. The period between the accession of his successor Máel Coluim I (Malcolm I) and Máel Coluim mac Cináeda (Malcolm II) was marked by good relations with the Wessex rulers of England, intense internal dynastic disunity and relatively successful expansionary policies. In 945, Máel Coluim I annexed Strathclyde as part of a deal with King Edmund of England, where the kings of Alba had probably exercised some authority since the later 9th century, an event offset somewhat by loss of control in Moray. The reign of King Donnchad I (Duncan I) from 1034 was marred by failed military adventures, and he was defeated and killed by MacBeth, the Mormaer of Moray, who became king in 1040. MacBeth ruled for seventeen years before he was overthrown by Máel Coluim, the son of Donnchad, who some months later defeated MacBeth's step-son and successor Lulach to become king Máel Coluim III (Malcolm III).
It was Máel Coluim III, who acquired the nickname "Canmore" ("Cenn Mór", "Great Chief"), which he passed to his successors and who did most to create the Dunkeld dynasty that ruled Scotland for the following two centuries. Particularly important was his second marriage to the Anglo-Hungarian princess Margaret. This marriage, and raids on northern England, prompted William the Conqueror to invade and Máel Coluim submitted to his authority, opening up Scotland to later claims of sovereignty by English kings. When Malcolm died in 1093, his brother Domnall III (Donald III) succeeded him. However, William II of England backed Máel Coluim's son by his first marriage, Donnchad, as a pretender to the throne and he seized power. His murder within a few months saw Domnall restored with one of Máel Coluim sons by his second marriage, Edmund, as his heir. The two ruled Scotland until two of Edmund's younger brothers returned from exile in England, again with English military backing. Victorious, Edgar, the oldest of the three, became king in 1097. Shortly afterwards Edgar and the King of Norway, Magnus Bare Legs concluded a treaty recognizing Norwegian authority over the Western Isles. In practice Norse control of the Isles was loose, with local chiefs enjoying a high degree of independence. He was succeeded by his brother Alexander, who reigned 1107–24.
When Alexander died in 1124, the crown passed to Margaret's fourth son David I, who had spent most of his life as an English baron. His reign saw what has been characterised as a "Davidian Revolution", by which native institutions and personnel were replaced by English and French ones, underpinning the development of later Medieval Scotland. Members of the Anglo-Norman nobility took up places in the Scottish aristocracy and he introduced a system of feudal land tenure, which produced knight service, castles and an available body of heavily armed cavalry. He created an Anglo-Norman style of court, introduced the office of justicar to oversee justice, and local offices of sheriffs to administer localities. He established the first royal burghs in Scotland, granting rights to particular settlements, which led to the development of the first true Scottish towns and helped facilitate economic development as did the introduction of the first recorded Scottish coinage. He continued a process begun by his mother and brothers helping to establish foundations that brought reform to Scottish monasticism based on those at Cluny and he played a part in organising diocese on lines closer to those in the rest of Western Europe.
These reforms were pursued under his successors and grandchildren Malcolm IV of Scotland and William I, with the crown now passing down the main line of descent through primogeniture, leading to the first of a series of minorities. The benefits of greater authority were reaped by William's son Alexander II and his son Alexander III, who pursued a policy of peace with England to expand their authority in the Highlands and Islands. By the reign of Alexander III, the Scots were in a position to annexe the remainder of the western seaboard, which they did following Haakon Haakonarson's ill-fated invasion and the stalemate of the Battle of Largs with the Treaty of Perth in 1266.
The Wars of Independence.
The death of king Alexander III in 1286, and the death of his granddaughter and heir Margaret, Maid of Norway in 1290, left 14 rivals for succession. To prevent civil war the Scottish magnates asked Edward I of England to arbitrate, for which he extracted legal recognition that the realm of Scotland was held as a feudal dependency to the throne of England before choosing John Balliol, the man with the strongest claim, who became king in 1292. Robert Bruce, 5th Lord of Annandale, the next strongest claimant, accepted this outcome with reluctance. Over the next few years Edward I used the concessions he had gained to systematically undermine both the authority of King John and the independence of Scotland. In 1295 John, on the urgings of his chief councillors, entered into an alliance with France, known as the Auld Alliance.
In 1296 Edward invaded Scotland, deposing King John. The following year William Wallace and Andrew de Moray raised forces to resist the occupation and under their joint leadership an English army was defeated at the Battle of Stirling Bridge. For a short time Wallace ruled Scotland in the name of John Balliol as Guardian of the realm. Edward came north in person and defeated Wallace at the Battle of Falkirk (1298). Wallace escaped but probably resigned as Guardian of Scotland. In 1305 he fell into the hands of the English, who executed him for treason despite the fact that he owed no allegiance to England.
Rivals John Comyn and Robert the Bruce, grandson of the claimant, were appointed as joint guardians in his place. On 10 February 1306, Bruce participated in the murder of Comyn, at Greyfriars Kirk in Dumfries. Less than seven weeks later, on 25 March, Bruce was crowned as King. However, Edward's forces overran the country after defeating Bruce's small army at the Battle of Methven. Despite the excommunication of Bruce and his followers by Pope Clement V, his support slowly strengthened; and by 1314 with the help of leading nobles such as Sir James Douglas and Thomas Randolph only the castles at Bothwell and Stirling remained under English control. Edward I had died in 1307. His heir Edward II moved an army north to break the siege of Stirling Castle and reassert control. Robert defeated that army at the Battle of Bannockburn in 1314, securing "de facto" independence. In 1320 the Declaration of Arbroath, a remonstrance to the Pope from the nobles of Scotland, helped convince Pope John XXII to overturn the earlier excommunication and nullify the various acts of submission by Scottish kings to English ones so that Scotland's sovereignty could be recognised by the major European dynasties. The Declaration has also been seen as one of the most important documents in the development of a Scottish national identity.
In 1326, what may have been the first full Parliament of Scotland met. The parliament had evolved from an earlier council of nobility and clergy, the "colloquium", constituted around 1235, but perhaps in 1326 representatives of the burghs — the burgh commissioners — joined them to form the Three Estates. In 1328, Edward III signed the Treaty of Northampton acknowledging Scottish independence under the rule of Robert the Bruce. However, four years after Robert's death in 1329, England once more invaded on the pretext of restoring Edward Balliol, son of John Balliol, to the Scottish throne, thus starting the Second War of Independence. Despite victories at Dupplin Moor and Halidon Hill, in the face of tough Scottish resistance led by Sir Andrew Murray, the son of Wallace's comrade in arms, successive attempts to secure Balliol on the throne failed. Edward III lost interest in the fate of his protégé after the outbreak of the Hundred Years' War with France. In 1341 David II, King Robert's son and heir, was able to return from temporary exile in France. Balliol finally resigned his claim to the throne to Edward in 1356, before retiring to Yorkshire, where he died in 1364.
The Stewarts.
After David II's death, Robert II, the first of the Stewart kings, came to the throne in 1371. He was followed in 1390 by his ailing son John, who took the regnal name Robert III. During Robert III's reign (1390–1406), actual power rested largely in the hands of his brother, Robert Stewart, Duke of Albany. After the suspicious death (possibly on the orders of the Duke of Albany) of his elder son, David, Duke of Rothesay in 1402, Robert, fearful for the safety of his younger son, the future James I, sent him to France in 1406. However, the English captured him en route and he spent the next 18 years as a prisoner held for ransom. As a result, after the death of Robert III, regents ruled Scotland: first, the Duke of Albany; and later his son Murdoch. When Scotland finally paid the ransom in 1424, James, aged 32, returned with his English bride determined to assert this authority. Several of the Albany family were executed; but he succeeded in centralising control in the hands of the crown, at the cost of increasing unpopularity, and was assassinated in 1437. His son James II (reigned 1437–1460), when he came of age in 1449, continued his father's policy of weakening the great noble families, most notably taking on the powerful Black Douglas family that had come to prominence at the time of the Bruce.
In 1468 the last significant acquisition of Scottish territory occurred when James III was engaged to Margaret of Denmark, receiving the Orkney Islands and the Shetland Islands in payment of her dowry. Berwick upon Tweed was captured by England in 1482. With the death of James III in 1488 at the Battle of Sauchieburn, his successor James IV successfully ended the quasi-independent rule of the Lord of the Isles, bringing the Western Isles under effective Royal control for the first time. In 1503, he married Margaret Tudor, daughter of Henry VII of England, thus laying the foundation for the 17th century Union of the Crowns.
Scotland advanced markedly in educational terms during the 15th century with the founding of the University of St Andrews in 1413, the University of Glasgow in 1450 and the University of Aberdeen in 1495, and with the passing of the Education Act 1496, which decreed that all sons of barons and freeholders of substance should attend grammar schools. James IV's reign is often considered to have seen a flowering of Scottish culture under the influence of the European Renaissance.
In 1512 the Auld Alliance was renewed and under its terms, when the French were attacked by the English under Henry VIII, James IV invaded England in support. The invasion was stopped decisively at the Battle of Flodden Field during which the King, many of his nobles, and a large number of ordinary troops were killed, commemorated by the song "Flowers of the Forest". Once again Scotland's government lay in the hands of regents in the name of the infant James V.
James V finally managed to escape from the custody of the regents in 1528. He continued his father's policy of subduing the rebellious Highlands, Western and Northern isles and the troublesome borders. He also continued the French alliance, marrying first the French noblewoman Madeleine of Valois and then after her death Marie of Guise. James V's domestic and foreign policy successes were overshadowed by another disastrous campaign against England that led to defeat at the Battle of Solway Moss (1542). James died a short time later, a demise blamed by contemporaries on "a broken heart". The day before his death, he was brought news of the birth of an heir: a daughter, who would become Mary, Queen of Scots.
Once again, Scotland was in the hands of a regent. Within two years, the Rough Wooing began, Henry VIII's military attempt to force a marriage between Mary and his son, Edward. This took the form of border skirmishing and several English campaigns into Scotland. In 1547, after the death of Henry VIII, forces under the English regent Edward Seymour, 1st Duke of Somerset were victorious at the Battle of Pinkie Cleugh, the climax of the Rough Wooing, and followed up by the occupation of Haddington. Mary was then sent to France at the age of five, as the intended bride of the heir to the French throne. Her mother, Marie de Guise, stayed in Scotland to look after the interests of Mary — and of France — although the Earl of Arran acted officially as regent. Guise responded by calling on French troops, who helped stiffen resistance to the English occupation. By 1550, after a change of regent in England, the English withdrew from Scotland completely.
From 1554, Marie de Guise, took over the regency, and continued to advance French interests in Scotland. French cultural influence resulted in a large influx of French vocabulary into Scots. But anti-French sentiment also grew, particularly among Protestants, who saw the English as their natural allies. In 1560 Marie de Guise died, and soon after the Auld Alliance also ended, with the signing of the Treaty of Edinburgh, which provided for the removal of French and English troops from Scotland. The Scottish Reformation took place only days later when the Scottish Parliament abolished the Roman Catholic religion and outlawed the Mass.
Meanwhile, Queen Mary had been raised as a Catholic in France, and married to the Dauphin, who became king as Francis II in 1559, making her queen consort of France. When Francis died in 1560, Mary, now 19, returned to Scotland to take up the government. Despite her private religion, she did not attempt to re-impose Catholicism on her largely Protestant subjects, thus angering the chief Catholic nobles. Her six-year personal reign was marred by a series of crises, largely caused by the intrigues and rivalries of the leading nobles. The murder of her secretary, David Riccio, was followed by that of her unpopular second husband Lord Darnley, and her abduction by and marriage to the Earl of Bothwell, who was implicated in Darnley's murder. Mary and Bothwell confronted the lords at Carberry Hill and after their forces melted away, he fled and she was captured by Bothwell's rivals. Mary was imprisoned in Loch Leven Castle, and in July 1567, was forced to abdicate in favour of her infant son James VI. Mary eventually escaped and attempted to regain the throne by force. After her defeat at the Battle of Langside in 1568, she took refuge in England, leaving her young son in the hands of regents. In Scotland the regents fought a civil war on behalf of James VI against his mother's supporters. In England, Mary became a focal point for Catholic conspirators and was eventually tried for treason and executed on the orders of her kinswoman Elizabeth I.
Protestant Reformation.
During the 16th century, Scotland underwent a Protestant Reformation that created a predominantly Calvinist national Kirk, which became Presbyterian in outlook and severely reduced the powers of bishops. In the earlier part of the century, the teachings of first Martin Luther and then John Calvin began to influence Scotland, particularly through Scottish scholars, often training for the priesthood, who had visited Continental universities. The Lutheran preacher Patrick Hamilton was executed for heresy in St. Andrews in 1528. The execution of others, especially the Zwingli-influenced George Wishart, who was burnt at the stake on the orders of Cardinal Beaton in 1546, angered Protestants. Wishart's supporters assassinated Beaton soon after and seized St. Andrews Castle, which they held for a year before they were defeated with the help of French forces. The survivors, including chaplain John Knox, were condemned to be galley slaves in France, stoking resentment of the French and creating martyrs for the Protestant cause.
Limited toleration and the influence of exiled Scots and Protestants in other countries, led to the expansion of Protestantism, with a group of lairds declaring themselves Lords of the Congregation in 1557 and representing their interests politically. The collapse of the French alliance and English intervention in 1560 meant that a relatively small, but highly influential, group of Protestants were in a position to impose reform on the Scottish church. A confession of faith, rejecting papal jurisdiction and the mass, was adopted by Parliament in 1560, while the young Mary, Queen of Scots, was still in France.
Knox, having escaped the galleys and spent time in Geneva as a follower of Calvin, emerged as the most significant figure of the period. The Calvinism of the reformers led by Knox resulted in a settlement that adopted a Presbyterian system and rejected most of the elaborate trappings of the medieval church. The reformed Kirk gave considerable power to local lairds, who often had control over the appointment of the clergy. There were widespread, but generally orderly outbreaks of iconoclasm. At this point the majority of the population was probably still Catholic in persuasion and the Kirk found it difficult to penetrate the Highlands and Islands, but began a gradual process of conversion and consolidation that, compared with reformations elsewhere, was conducted with relatively little persecution.
17th century.
In 1603, James VI King of Scots inherited the throne of the Kingdom of England, and became King James I of England, leaving Edinburgh for London, uniting England and Scotland under one monarch. The Union was a personal or dynastic union, with the Crowns remaining both distinct and separate—despite James's best efforts to create a new "imperial" throne of "Great Britain". The acquisition of the Irish crown along with the English, facilitated a process of settlement by Scots in what was historically the most troublesome area of the kingdom in Ulster, with perhaps 50,000 Scots settling in the province by the mid-17th century. Attempts to found a Scottish colony in North America in Nova Scotia were largely unsuccessful, with insufficient funds and willing colonists.
Wars of the Three Kingdoms and the Puritan Commonwealth.
Bishops' Wars.
Although James had tried to get the Scottish Church to accept some of the High Church Anglicanism of his southern kingdom, he met with limited success. His son and successor, Charles I, took matters further, introducing an English-style Prayer Book into the Scottish church in 1637. This resulted in anger and widespread rioting. (The story goes that it was initiated by a certain Jenny Geddes who threw a stool in St Giles Cathedral.) Representatives of various sections of Scottish society drew up the National Covenant in 1638, objecting to the King's liturgical innovations. In November of the same year matters were taken even further, when at a meeting of the General Assembly in Glasgow the Scottish bishops were formally expelled from the Church, which was then established on a full Presbyterian basis. Charles gathered a military force; but as neither side wished to push the matter to a full military conflict, a temporary settlement was concluded at Pacification of Berwick. Matters remained unresolved until 1640 when, in a renewal of hostilities, Charles's northern forces were defeated by the Scots at the Battle of Newburn to the west of Newcastle. During the course of these Bishops' Wars Charles tried to raise an army of Irish Catholics, but was forced to back down after a storm of protest in Scotland and England. The backlash from this venture provoked a rebellion in Ireland and Charles was forced to appeal to the English Parliament for funds. Parliament's demands for reform in England eventually resulted in the English Civil War. This series of civil wars that engulfed England, Ireland and Scotland in the 1640s and 1650s is known to modern historians as the Wars of the Three Kingdoms. The Covenanters meanwhile, were left governing Scotland, where they raised a large army of their own and tried to impose their religious settlement on Episcopalians and Roman Catholics in the north of the country. In England his religious policies caused similar resentment and he ruled without recourse to parliament from 1629.
Civil war.
As the civil wars developed, the English Parliamentarians appealed to the Scots Covenanters for military aid against the King. A Solemn League and Covenant was entered into, guaranteeing the Scottish Church settlement and promising further reform in England. Scottish troops played a major part in the defeat of Charles I, notably at the battle of Marston Moor. An army under the Earl of Leven occupied the North of England for some time.
However, not all Scots supported the Covenanter's taking arms against their King. In 1644, James Graham, 1st Marquess of Montrose attempted to raise the Highlands for the King. Few Scots would follow him, but, aided by 1,000 Irish, Highland and Islesmen troops sent by the Irish Confederates under Alasdair MacDonald (MacColla), and an instinctive genius for mobile warfare, he was stunningly successful. A Scottish Civil War began in September 1644 with his victory at battle of Tippermuir. After a series of victories over poorly trained Covenanter militias, the lowlands were at his mercy. However, at this high point, his army was reduced in size, as MacColla and the Highlanders preferred to continue the war in the north against the Campbells. Shortly after, what was left of his force was defeated at the Battle of Philiphaugh. Escaping to the north, Montrose attempted to continue the struggle with fresh troops; but in July 1646 his army was disbanded after the King surrendered to the Scots army at Newark, and the civil war came to an end.
The following year Charles, while he was being held captive in Carisbrooke Castle, entered into an agreement with moderate Scots Presbyterians. In this secret 'Engagement', the Scots promised military aid in return for the King's agreement to implement Presbyterianism in England on a three-year trial basis. The Duke of Hamilton led an invasion of England to free the King, but he was defeated by Oliver Cromwell in August 1648 at the Battle of Preston.
Cromwellian occupation and Restoration.
The execution of Charles I in 1649 was carried out in the face of objections by the Covenanter government and his son was immediately proclaimed as King Charles II in Edinburgh. Oliver Cromwell led an invasion of Scotland in 1650, and defeated the Scottish army at Dunbar and then defeated a Scottish invasion of England at Worcester on 3 September 1651 (the anniversary of his victory at Dunbar). Cromwell emerged as the leading figure in the English government and Scotland was occupied by an English force under George Monck. The country was incorporated into the Puritan-governed Commonwealth and lost its independent church government, parliament and legal system, but gained access to English markets. Various attempts were made to legitimise the union, calling representatives from the Scottish burghs and shires to negotiations and to various English parliaments, where they were always under-represented and had little opportunity for dissent. However, final ratification was delayed by Cromwell's problems with his various parliaments and the union did not become the subject of an act until 1657 (see Tender of Union).
After the death of Cromwell and the regime's collapse, Charles II was restored in 1660 and Scotland again became an independent kingdom. Scotland regained its system of law, parliament and kirk, but also the Lords of the Articles (by which the crown managed parliament), bishops and a king who did not visit the country. He ruled largely without reference to Parliament, through a series of commissioners. These began with John, Earl of Middleton and ended with the king's brother and heir, James, Duke of York (known in Scotland as the Duke of Albany). The English Navigation Acts prevented the Scots engaging in what would have been lucrative trading with England's colonies. The restoration of episcopacy was a source of trouble, particularly in the south-west of the country, an area with strong Presbyterian sympathies. Abandoning the official church, many of the inhabitants began to attend illegal field assemblies, known as conventicles. Official attempts to suppress these led to a rising in 1679, defeated by James, Duke of Monmouth, the King's illegitimate son, at the Battle of Bothwell Bridge. In the early 1680s a more intense phase of persecution began, later to be called "the Killing Time". When Charles died in 1685 and his brother, a Roman Catholic, succeeded him as James VII of Scotland (and II of England), matters came to a head.
The deposition of James VII.
James put Catholics in key positions in the government and attendance at conventicles was made punishable by death. He disregarded parliament, purged the Council and forced through religious toleration to Roman Catholics, alienating his Protestant subjects. It was believed that the king would be succeeded by his daughter Mary, a Protestant and the wife of William of Orange, Stadtholder of the Netherlands, but when in 1688, James produced a male heir, James Francis Edward Stuart, it was clear that his policies would outlive him. An invitation by seven leading Englishmen led William to land in England with 40,000 men, and James fled, leading to the almost bloodless "Glorious Revolution". The Estates issued a "Claim of Right" that suggested that James had forfeited the crown by his actions (in contrast to England, which relied on the legal fiction of an abdication) and offered it to William and Mary, which William accepted, along with limitations on royal power. The final settlement restored Presbyterianism and abolished the bishops who had generally supported James. However, William, who was more tolerant than the Kirk tended to be, passed acts restoring the Episcopalian clergy excluded after the Revolution.
Although William's supporters dominated the government, there remained a significant following for James, particularly in the Highlands. His cause, which became known as Jacobitism, from the Latin "(Jacobus)" for James, led to a series of risings. An initial Jacobite military attempt was led by John Graham, Viscount Dundee. His forces, almost all Highlanders, defeated William's forces at the Battle of Killiecrankie in 1689, but they took heavy losses and Dundee was slain in the fighting. Without his leadership the Jacobite army was soon defeated at the Battle of Dunkeld. In the aftermath of the Jacobite defeat on 13 February 1692, in an incident since known as the Massacre of Glencoe, 38 members of the Clan MacDonald of Glencoe were killed by members of the Earl of Argyll's Regiment of Foot, on the grounds that they had not been prompt in pledging allegiance to the new monarchs.
Economic crisis of the 1690s.
The closing decade of the 17th century saw the generally favourable economic conditions that had dominated since the Restoration come to an end. There was a slump in trade with the Baltic and France from 1689 to 1691, caused by French protectionism and changes in the Scottish cattle trade, followed by four years of failed harvests (1695, 1696 and 1698-9), an era known as the "seven ill years". The result was severe famine and depopulation, particularly in the north. The Parliament of Scotland of 1695 enacted proposals to help the desperate economic situation, including setting up the Bank of Scotland. The "Company of Scotland Trading to Africa and the Indies" received a charter to raise capital through public subscription.
Failure of Darien scheme.
With the dream of building a lucrative overseas colony for Scotland, the Company of Scotland invested in the Darien scheme, an ambitious plan devised by William Paterson to establish a colony on the Isthmus of Panama in the hope of establishing trade with the Far East. The Darién scheme won widespread support in Scotland as the landed gentry and the merchant class were in agreement in seeing overseas trade and colonialism as routes to upgrade Scotland's economy. Since the capital resources of the Edinburgh merchants and landholder elite were insufficient, the company appealed to middling social ranks, who responded with patriotic fervour to the call for money; the lower classes volunteered as colonists. But the English government opposed the idea: involved in the War of the Grand Alliance from 1689 to 1697 against France, it did not want to offend Spain, which claimed the territory as part of New Granada. The English investors withdrew. Returning to Edinburgh, the Company raised 400,000 pounds in a few weeks. Three small fleets with a total of 3,000 men eventually set out for Panama in 1698. The exercise proved a disaster. Poorly equipped; beset by incessant rain; under attack by the Spanish from nearby Cartagena; and refused aid by the English in the West Indies, the colonists abandoned their project in 1700. Only 1,000 survived and only one ship managed to return to Scotland.
18th century.
Scotland was a poor rural, agricultural society with a population of 1.3 million in 1755. Although Scotland lost home rule, the Union allowed it to break free of a stultifying system and opened the way for the Scottish enlightenment as well as a great expansion of trade and increase in opportunity and wealth. Edinburgh economist Adam Smith concluded in 1776 that "By the union with England, the middling and inferior ranks of people in Scotland gained a complete deliverance from the power of an aristocracy which had always before oppressed them." Historian Jonathan Israel holds that the Union "proved a decisive catalyst politically and economically," by allowing ambitious Scots entry on an equal basis to a rich expanding empire and its increasing trade.
Scotland's transformation into a rich leader of modern industry came suddenly and unexpectedly in the next 150 years, following its union with England in 1707 and its integration with the advanced English and imperial economies. The transformation was led by two cities that grew rapidly after 1770. Glasgow, on the river Clyde, was the base for the tobacco and sugar trade with an emerging textile industry. Edinburgh was the administrative and intellectual centre where the Scottish Enlightenment was chiefly based.
Union with England.
By the start of the 18th century, a political union between Scotland and England became politically and economically attractive, promising to open up the much larger markets of England, as well as those of the growing English Empire. With economic stagnation since the late 17th century, which was particularly acute in 1704; the country depended more and more heavily on sales of cattle and linen to England, who used this to create pressure for a union. The Scottish parliament voted on 6 January 1707, by 110 to 69, to adopt the Treaty of Union. It was also a full economic union; indeed, most of its 25 articles dealt with economic arrangements for the new state known as "Great Britain". It added 45 Scots to the 513 members of the House of Commons and 16 Scots to the 190 members of the House of Lords, and ended the Scottish parliament. It also replaced the Scottish systems of currency, taxation and laws regulating trade with laws made in London. Scottish law remained separate from English law, and the religious system was not changed. England had about five times the population of Scotland at the time, and about 36 times as much wealth.
Jacobitism.
Jacobitism was revived by the unpopularity of the union. In 1708 James Francis Edward Stuart, the son of James VII, who became known as "The Old Pretender", attempted an invasion with a French fleet carrying 6,000 men, but the Royal Navy prevented it from landing troops. A more serious attempt occurred in 1715, soon after the death of Anne and the accession of the first Hanoverian king, the eldest son of Sophie, as George I of Great Britain. This rising (known as "The 'Fifteen") envisaged simultaneous uprisings in Wales, Devon, and Scotland. However, government arrests forestalled the southern ventures. In Scotland, John Erskine, Earl of Mar, nicknamed "Bobbin' John", raised the Jacobite clans but proved to be an indecisive leader and an incompetent soldier. Mar captured Perth, but let a smaller government force under the Duke of Argyll hold the Stirling plain. Part of Mar's army joined up with risings in northern England and southern Scotland, and the Jacobites fought their way into England before being defeated at the Battle of Preston, surrendering on 14 November 1715. The day before, Mar had failed to defeat Argyll at the Battle of Sheriffmuir. At this point, James belatedly landed in Scotland, but was advised that the cause was hopeless. He fled back to France. An attempted Jacobite invasion with Spanish assistance in 1719 met with little support from the clans and ended in defeat at the Battle of Glen Shiel.
In 1745 the Jacobite rising known as "The 'Forty-Five" began. Charles Edward Stuart, son of the "Old Pretender", often referred to as "Bonnie Prince Charlie" or the "Young Pretender", landed on the island of Eriskay in the Outer Hebrides. Several clans unenthusiastically joined him. At the outset he was successful, taking Edinburgh and then defeating the only government army in Scotland at the Battle of Prestonpans. The Jacobite army marched into England, took Carlisle and advanced as far as south as Derby. However, it became increasingly evident that England would not support a Roman Catholic Stuart monarch. The Jacobite leadership had a crisis of confidence and they retreated to Scotland as two English armies closed in and Hanoverian troops began to return from the continent. Charles' position in Scotland began to deteriorate as the Whig supporters rallied and regained control of Edinburgh. After an unsuccessful attempt on Stirling, he retreated north towards Inverness. He was pursued by the Duke of Cumberland and gave battle with an exhausted army at Culloden on 16 April 1746, where the Jacobite cause was crushed. Charles hid in Scotland with the aid of Highlanders until September 1746, when he escaped back to France. There were bloody reprisals against his supporters and foreign powers abandoned the Jacobite cause, with the court in exile forced to leave France. The Old Pretender died in 1760 and the Young Pretender, without legitimate issue, in 1788. When his brother, Henry, Cardinal of York, died in 1807, the Jacobite cause was at an end.
Post-Jacobite politics.
With the advent of the Union and the demise of Jacobitism, access to London and the Empire opened up very attractive career opportunities for ambitious middle-class and upper-class Scots, who seized the chance to become entrepreneurs, intellectuals, and soldiers. Thousands of Scots, mainly Lowlanders, took up positions of power in politics, civil service, the army and navy, trade, economics, colonial enterprises and other areas across the nascent British Empire. Historian Neil Davidson notes that “after 1746 there was an entirely new level of participation by Scots in political life, particularly outside Scotland”. Davidson also states that “far from being ‘peripheral’ to the British economy, Scotland – or more precisely, the Lowlands – lay at its core”. British officials especially appreciated Scottish soldiers. As the Secretary of War told Parliament in 1751, "I am for having always in our army as many Scottish soldiers as possible...because they are generally more hardy and less mutinous". The national policy of aggressively recruiting Scots for senior civilian positions stirred up resentment among Englishmen, ranging from violent diatribes by John Wilkes, to vulgar jokes and obscene cartoons in the popular press, and the haughty ridicule by intellectuals such as Samuel Johnson that was much resented by Scots. In his great "Dictionary" Johnson defined oats as, "a grain, which in England is generally given to horses, but in Scotland supports the people." To which Lord Elibank retorted, "Very true, and where will you find such men and such horses?"
Scottish politics in the late 18th century was dominated by the Whigs, with the benign management of Archibald Campbell, 3rd Duke of Argyll (1682–1761), who was in effect the "viceroy of Scotland" from the 1720s until his death in 1761. Scotland generally supported the king with enthusiasm during the American Revolution. Henry Dundas (1742–1811) dominated political affairs in the latter part of the century. Dundas put a brake on intellectual and social change through his ruthless manipulation of patronage in alliance with Prime Minister William Pitt the Younger, until he lost power in 1806.
The main unit of local government was the parish, and since it was also part of the church, the elders imposed public humiliation for what the locals considered immoral behaviour, including fornication, drunkenness, wife beating, cursing and Sabbath breaking. The main focus was on the poor and the landlords ("lairds") and gentry, and their servants, were not subject to the parish's control. The policing system weakened after 1800 and disappeared in most places by the 1850s.
Collapse of the clan system.
After the battle of Culloden the leaders were declared to be traitors, with Jacobite officers executed and many of the rebel soldiers shipped to the colonies as indentured servants. Key laws included the Dress Act 1746, the Act of Proscription 1746, and especially the Heritable Jurisdictions Act of 1746. All aspects of Highland culture, especially the Scottish Gaelic language were forbidden. Parliament also banned the bearing of arms and the wearing of tartans, and limited the activities of the Episcopalian Church. After a generation the Highlands had been transformed and the laws were no longer needed; they were mostly repealed.
Historians debate whether the dramatic changes merely reflect long-term trends that were more-or-less inevitable, or whether government intervention played the decisive role in changing the goals and roles of the chiefs. As Conway (2006) concludes, the new policies "went far beyond earlier efforts to promote economic development in the Highlands and ... represented the first real endeavour to transform the region's social system ... the post-rebellion legislation certainly seems to have accelerated the change." However Devine (1999) and Ray (2001) argue that long-term economic and social changes were already undermining the clan system.
The major result of these changes were the Highland Clearances, by which much of the population of the Highlands suffered forced displacement as lands were enclosed, principally so that they could be used for sheep farming. The clearances followed patterns of agricultural change throughout Britain, but were particularly notorious as a result of the late timing, the lack of legal protection for year-by-year tenants under Scots law, the abruptness of the change from the traditional clan system, and the brutality of many evictions. One result was a continuous exodus from the land—to the cities, or further afield to England, Canada, America or Australia. Many of those who remained were now crofters: poor families living on "crofts"—very small rented farms with indefinite tenure used to raise various crops and animals, with kelping industry (where men burned kelp for the ashes), fishing, spinning of linen and military service as important sources of revenue.
The era of the Napoleonic wars, 1790–1815, brought prosperity, optimism, and economic growth to the Highlands. The economy grew thanks to higher wages, as well as large-scale infrastructure spending such as the Caledonian Canal project. On the East Coast, farmlands were improved, and high prices for cattle brought money to the community. Service in the Army was also attractive to young men from Highlands, who sent pay home and retired there with their army pensions, but the prosperity ended after 1815, and long-run negative factors began to undermine the economic position of the crofters.
Enlightenment.
Historian Jonathan Israel argues that by 1750 Scotland's major cities had created an intellectual infrastructure of mutually supporting institutions, such as universities, reading societies, libraries, periodicals, museums and masonic lodges. The Scottish network was "predominantly liberal Calvinist, Newtonian, and 'design' oriented in character which played a major role in the further development of the transatlantic Enlightenment ." In France Voltaire said "we look to Scotland for all our ideas of civilization," and the Scots in turn paid close attention to French ideas. Historian Bruce Lenman says their "central achievement was a new capacity to recognize and interpret social patterns." The first major philosopher of the Scottish Enlightenment was Francis Hutcheson, who held the Chair of Philosophy at the University of Glasgow from 1729 to 1746. A moral philosopher who produced alternatives to the ideas of Thomas Hobbes, one of his major contributions to world thought was the utilitarian and consequentialist principle that virtue is that which provides, in his words, "the greatest happiness for the greatest numbers". Much of what is incorporated in the scientific method (the nature of knowledge, evidence, experience, and causation) and some modern attitudes towards the relationship between science and religion were developed by his protégés David Hume and Adam Smith. Hume became a major figure in the skeptical philosophical and empiricist traditions of philosophy. He and other Scottish Enlightenment thinkers developed what he called a 'science of man', which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar and William Robertson, all of whom merged a scientific study of how humans behave in ancient and primitive cultures with a strong awareness of the determining forces of modernity. Modern sociology largely originated from this movement and Hume's philosophical concepts that directly influenced James Madison (and thus the U.S. Constitution) and when popularised by Dugald Stewart, would be the basis of classical liberalism. Adam Smith published "The Wealth of Nations", often considered the first work on modern economics. It had an immediate impact on British economic policy and in the 21st century still framed discussions on globalisation and tariffs. The focus of the Scottish Enlightenment ranged from intellectual and economic matters to the specifically scientific as in the work of the physician and chemist William Cullen, the agriculturalist and economist James Anderson, chemist and physician Joseph Black, natural historian John Walker and James Hutton, the first modern geologist.
Beginnings of industrialisation.
With tariffs with England now abolished, the potential for trade for Scottish merchants was considerable. However, Scotland in 1750 was still a poor rural, agricultural society with a population of 1.3 million. Some progress was visible: agriculture in the Lowlands was steadily upgraded after 1700 and standards remained high. there were the sales of linen and cattle to England, the cash flows from military service, and the tobacco trade that was dominated by Glasgow Tobacco Lords after 1740. Merchants who profited from the American trade began investing in leather, textiles, iron, coal, sugar, rope, sailcloth, glassworks, breweries, and soapworks, setting the foundations for the city's emergence as a leading industrial centre after 1815. The tobacco trade collapsed during the American Revolution (1776–83), when its sources were cut off by the British blockade of American ports. However, trade with the West Indies began to make up for the loss of the tobacco business, reflecting the British demand for sugar and the demand in the West Indies for herring and linen goods.
Linen was Scotland's premier industry in the 18th century and formed the basis for the later cotton, jute, and woollen industries. Scottish industrial policy was made by the Board of Trustees for Fisheries and Manufactures in Scotland, which sought to build an economy complementary, not competitive, with England. Since England had woollens, this meant linen. Encouraged and subsidised by the Board of Trustees so it could compete with German products, merchant entrepreneurs became dominant in all stages of linen manufacturing and built up the market share of Scottish linens, especially in the American colonial market. The British Linen Company, established in 1746, was the largest firm in the Scottish linen industry in the 18th century, exporting linen to England and America. As a joint-stock company, it had the right to raise funds through the issue of promissory notes or bonds. With its bonds functioning as bank notes, the company gradually moved into the business of lending and discounting to other linen manufacturers, and in the early 1770s banking became its main activity. It joined the established Scottish banks such as the Bank of Scotland (Edinburgh, 1695) and the Royal Bank of Scotland (Edinburgh, 1727). Glasgow would soon follow and Scotland had a flourishing financial system by the end of the century. There were over 400 branches, amounting to one office per 7,000 people, double the level in England, where banks were also more heavily regulated. Historians have emphasised that the flexibility and dynamism of the Scottish banking system contributed significantly to the rapid development of the economy in the 19th century.
German sociologist Max Weber mentioned Scottish Presbyterianism in The Protestant Ethic and the Spirit of Capitalism (1905), and many scholars in recent decades argued that "this worldly asceticism" of Calvinism was integral to Scotland's rapid economic modernization.
Religious fragmentation.
In the 1690s the Presbyterian establishment purged the land of Episcopalians and heretics, and made blasphemy a capital crime. Thomas Aitkenhead, the son of an Edinburgh surgeon, aged 18, was indicted for blasphemy by order of the Privy Council for calling the New Testament "The History of the Imposter Christ"; he was hanged in 1696. Their extremism led to a reaction known as the "Moderate" cause that ultimately prevailed and opened the way for liberal thinking in the cities.
The early 18th century saw the beginnings of a fragmentation of the Church of Scotland. These fractures were prompted by issues of government and patronage, but reflected a wider division between the hard-line Evangelicals and the theologically more tolerant Moderate Party. The battle was over fears of fanaticism by the former and the promotion of Enlightenment ideas by the latter. The Patronage Act of 1712 was a major blow to the evangelicals, for it meant that local landlords could choose the minister, not the members of the congregation. Schisms erupted as the evangelicals left the main body, starting in 1733 with the First Secession headed by figures including Ebenezer Erskine. The second schism in 1761 lead to the foundation of the independent Relief Church. These churches gained strength in the Evangelical Revival of the later 18th century. a key result was the main Presbyterian church was in the hands of the Moderate faction, which provided critical support for the Enlightenment in the cities.
Long after the triumph of the Church of Scotland in the Lowlands, Highlanders and Islanders clung to an old-fashioned Christianity infused with animistic folk beliefs and practices. The remoteness of the region and the lack of a Gaelic-speaking clergy undermined the missionary efforts of the established church. The later 18th century saw some success, owing to the efforts of the SSPCK missionaries and to the disruption of traditional society. Catholicism had been reduced to the fringes of the country, particularly the Gaelic-speaking areas of the Highlands and Islands. Conditions also grew worse for Catholics after the Jacobite rebellions and Catholicism was reduced to little more than a poorly run mission. Also important was Episcopalianism, which had retained supporters through the civil wars and changes of regime in the 17th century. Since most Episcopalians had given their support to the Jacobite rebellions in the early 18th century, they also suffered a decline in fortunes.
Literature.
Although Scotland increasingly adopted the English language and wider cultural norms, its literature developed a distinct national identity and began to enjoy an international reputation. Allan Ramsay (1686–1758) laid the foundations of a reawakening of interest in older Scottish literature, as well as leading the trend for pastoral poetry, helping to develop the Habbie stanza as a poetic form. James Macpherson was the first Scottish poet to gain an international reputation, claiming to have found poetry written by Ossian, he published translations that acquired international popularity, being proclaimed as a Celtic equivalent of the Classical epics. "Fingal" written in 1762 was speedily translated into many European languages, and its deep appreciation of natural beauty and the melancholy tenderness of its treatment of the ancient legend did more than any single work to bring about the Romantic movement in European, and especially in German, literature, influencing Herder and Goethe. Eventually it became clear that the poems were not direct translations from the Gaelic, but flowery adaptations made to suit the aesthetic expectations of his audience. Both the major literary figures of the following century, Robert Burns and Walter Scott, would be highly influenced by the Ossian cycle. Burns, an Ayrshire poet and lyricist, is widely regarded as the national poet of Scotland and a major figure in the Romantic movement. As well as making original compositions, Burns also collected folk songs from across Scotland, often revising or adapting them. His poem (and song) "Auld Lang Syne" is often sung at Hogmanay (the last day of the year), and "Scots Wha Hae" served for a long time as an unofficial national anthem of the country.
Education.
A legacy of the Reformation in Scotland was the aim of having a school in every parish, which was underlined by an act of the Scottish parliament in 1696 (reinforced in 1801). In rural communities this obliged local landowners (heritors) to provide a schoolhouse and pay a schoolmaster, while ministers and local presbyteries oversaw the quality of the education. The headmaster or "dominie" was often university educated and enjoyed high local prestige. The kirk schools were active in the rural lowlands but played a minor role in the Highlands, the islands, and in the fast-growing industrial towns and cities. The schools taught in English, not in Gaelic, because that language was seen as a leftover of Catholicism and was not an expression of Scottish nationalism. In cities such as Glasgow the Catholics operated their own schools, which directed their youth into clerical and middle class occupations, as well as religious vocations.
A "democratic myth" emerged in the 19th century to the effect that many a "lad of pairts" had been able to rise up through the system to take high office and that literacy was much more widespread in Scotland than in neighbouring states, particularly England. Historical research has largely undermined the myth. Kirk schools were not free, attendance was not compulsory and they generally imparted only basic literacy such as the ability to read the Bible. Poor children, starting at age 7, were done by age 8 or 9; the majority were finished by age 11 or 12. The result was widespread basic reading ability; since there was an extra fee for writing, half the people never learned to write. Scots were not significantly better educated than the English and other contemporary nations. A few talented poor boys did go to university, but usually they were helped by aristocratic or gentry sponsors. Most of them became poorly paid teachers or ministers, and none became important figures in the Scottish Enlightenment or the Industrial Revolution.
By the 18th century there were five universities in Scotland, at Edinburgh, Glasgow, St. Andrews and King's and Marischial Colleges in Aberdeen, compared with only two in England. Originally oriented to clerical and legal training, after the religious and political upheavals of the 17th century they recovered with a lecture-based curriculum that was able to embrace economics and science, offering a high quality liberal education to the sons of the nobility and gentry. It helped the universities to become major centres of medical education and to put Scotland at the forefront of Enlightenment thinking.
19th century.
Scotland's transformation into a rich leader of modern industry came suddenly and unexpectedly. The population grew steadily in the 19th century, from 1,608,000 in the census of 1801 to 2,889,000 in 1851 and 4,472,000 in 1901. The economy, long based on agriculture, began to industrialize after 1790. At first the leading industry, based in the west, was the spinning and weaving of cotton. In 1861 the American Civil War suddenly cut off the supplies of raw cotton and the industry never recovered. Thanks to its many entrepreneurs and engineers, and its large stock of easily mined coal, Scotland became a world centre for engineering, shipbuilding, and locomotive construction, with steel replacing iron after 1870.
Party politics.
The Scottish Reform Act 1832 increased the number of Scottish MPs and significantly widened the franchise to include more of the middle classes. From this point until the end of the century, the Whigs and (after 1859) their successors the Liberal Party, managed to gain a majority of the Westminster Parliamentary seats for Scotland, although these were often outnumbered by the much larger number of English and Welsh Conservatives. The English-educated Scottish peer Lord Aberdeen (1784–1860) led a coalition government from 1852-5, but in general very few Scots held office in the government. From the mid-century there were increasing calls for Home Rule for Scotland and when the Conservative Lord Salisbury became prime minister in 1885 he responded to pressure by reviving the post of Secretary of State for Scotland, which had been in abeyance since 1746. He appointed the Duke of Richmond, a wealthy landowner who was both Chancellor of Aberdeen University and Lord Lieutenant of Banff. Towards the end of the century Prime Ministers of Scottish descent included the Tory, Peelite and Liberal William E. Gladstone, who held the office four times between 1868 and 1894. The first Scottish Liberal to become prime minister was the Earl of Rosebery, from 1894 to 1895, like Aberdeen before him a product of the English education system. In the later 19th century the issue of Irish Home Rule led to a split among the Liberals, with a minority breaking away to form the Liberal Unionists in 1886. The growing importance of the working classes was marked by Keir Hardie's success in the Mid Lanarkshire by-election, 1888, leading to the foundation of the Scottish Labour Party, which was absorbed into the Independent Labour Party in 1895, with Hardie as its first leader.
Industrial expansion.
From about 1790 textiles became the most important industry in the west of Scotland, especially the spinning and weaving of cotton, which flourished until in 1861 the American Civil War cut off the supplies of raw cotton. The industry never recovered, but by that time Scotland had developed heavy industries based on its coal and iron resources. The invention of the hot blast for smelting iron (1828) revolutionised the Scottish iron industry. As a result, Scotland became a centre for engineering, shipbuilding and the production of locomotives. Toward the end of the 19th century, steel production largely replaced iron production. Coal mining continued to grow into the 20th century, producing the fuel to heat homes, factories and drive steam engines locomotives and steamships. By 1914 there were 1,000,000 coal miners in Scotland. The stereotype emerged early on of Scottish colliers as brutish, non-religious and socially isolated serfs; that was an exaggeration, for their life style resembled the miners everywhere, with a strong emphasis on masculinity, equalitarianism, group solidarity, and support for radical labour movements.
Britain was the world leader in the construction of railways, and their use to expand trade and coal supplies. The first successful locomotive-powered line in Scotland, between Monkland and Kirkintilloch, opened in 1831. Not only was good passenger service established by the late 1840s, but an excellent network of freight lines reduce the cost of shipping coal, and made products manufactured in Scotland competitive throughout Britain. For example, railways opened the London market to Scottish beef and milk. They enabled the Aberdeen Angus to become a cattle breed of worldwide reputation. By 1900 Scotland had 3500 miles of railway; their main economic contribution was moving supplies in and product out for heavy industry, especially coal-mining.
Scotland was already one of the most urbanised societies in Europe by 1800. The industrial belt ran across the country from southwest to northeast; by 1900 the four industrialised counties of Lanarkshire, Renfrewshire, Dunbartonshire, and Ayrshire contained 44 per cent of the population. Glasgow became one of the largest cities in the world, and known as "the Second City of the Empire" after London. Shipbuilding on Clydeside (the river Clyde through Glasgow and other points) began when the first small yards were opened in 1712 at the Scott family's shipyard at Greenock. After 1860 the Clydeside shipyards specialised in steamships made of iron (after 1870, made of steel), which rapidly replaced the wooden sailing vessels of both the merchant fleets and the battle fleets of the world. It became the world's pre-eminent shipbuilding centre. "Clydebuilt" became an industry benchmark of quality, and the river's shipyards were given contracts for warships.
Public health and welfare.
The industrial developments, while they brought work and wealth, were so rapid that housing, town-planning, and provision for public health did not keep pace with them, and for a time living conditions in some of the towns and cities were notoriously bad, with overcrowding, high infant mortality, and growing rates of tuberculosis. The companies attracted rural workers, as well as immigrants from Catholic Ireland, by inexpensive company housing that was a dramatic move upward from the inner-city slums. This paternalistic policy led many owners to endorse government sponsored housing programs as well as self-help projects among the respectable working class.
Intellectual life.
While the Scottish Enlightenment is traditionally considered to have concluded toward the end of the 18th century, disproportionately large Scottish contributions to British science and letters continued for another 50 years or more, thanks to such figures as the mathematicians and physicists James Clerk Maxwell, Lord Kelvin, and the engineers and inventors James Watt and William Murdoch, whose work was critical to the technological developments of the Industrial Revolution throughout Britain.
In literature the most successful figure of the mid-nineteenth century was Walter Scott, who began as a poet and also collected and published Scottish ballads. His first prose work, Waverley in 1814, is often called the first historical novel. It launched a highly successful career that probably more than any other helped define and popularise Scottish cultural identity. In the late 19th century, a number of Scottish-born authors achieved international reputations. Robert Louis Stevenson's work included the urban Gothic novella "Strange Case of Dr Jekyll and Mr Hyde" (1886), and played a major part in developing the historical adventure in books like "Kidnapped" and "Treasure Island". Arthur Conan Doyle's "Sherlock Holmes" stories helped found the tradition of detective fiction. The "kailyard tradition" at the end of the century, brought elements of fantasy and folklore back into fashion as can be seen in the work of figures like J. M. Barrie, most famous for his creation of Peter Pan, and George MacDonald, whose works, including "Phantasies", played a major part in the creation of the fantasy genre.
Scotland also played a major part in the development of art and architecture. The Glasgow School, which developed in the late 19th century, and flourished in the early 20th century, produced a distinctive blend of influences including the Celtic Revival the Arts and Crafts Movement, and Japonisme, which found favour throughout the modern art world of continental Europe and helped define the Art Nouveau style. Among the most prominent members were the loose collective of The Four: acclaimed architect Charles Rennie Mackintosh, his wife the painter and glass artist Margaret MacDonald, her sister the artist Frances, and her husband, the artist and teacher Herbert MacNair.
Decline and romanticism of the Highlands.
This period saw a process of rehabilitation for highland culture. Tartan had already been adopted for highland regiments in the British army, which poor highlanders joined in large numbers until the end of the Napoleonic Wars in 1815, but by the 19th century it had largely been abandoned by the ordinary people. In the 1820s, as part of the Romantic revival, tartan and the kilt were adopted by members of the social elite, not just in Scotland, but across Europe, prompted by the popularity of Macpherson's Ossian cycle and then Walter Scott's Waverley novels. The world paid attention to their literary redefinition of Scottishness, as they forged an image largely based on characteristics in polar opposition to those associated with England and modernity. This new identity made it possible for Scottish culture to become integrated into a wider European and North American context, not to mention tourist sites, but it also locked in a sense of "otherness" which Scotland began to shed only in the late 20th century. Scott's "staging" of the royal Visit of King George IV to Scotland in 1822 and the king's wearing of tartan, resulted in a massive upsurge in demand for kilts and tartans that could not be met by the Scottish linen industry. The designation of individual clan tartans was largely defined in this period and became a major symbol of Scottish identity. The fashion for all things Scottish was maintained by Queen Victoria, who helped secure the identity of Scotland as a tourist resort, with Balmoral Castle in Aberdeenshire becoming a major royal residence from 1852.
Despite these changes the highlands remained very poor and traditional, with few connections to the uplift of the Scottish Enlightenment and little role in the Industrial Revolution. A handful of powerful families, typified by the dukes of Argyll, Atholl, Buccleuch, and Sutherland, owned the best lands and controlled local political, legal and economic affairs. Particularly after the end of the boom created by the Revolutionary and Napoleonic Wars (1790–1815), these landlords needed cash to maintain their position in London society, and had less need of soldiers. They turned to money rents, displaced farmers to raise sheep, and downplayed the traditional patriarchal relationship that had historically sustained the clans. This was exacerbated after the repeal of the Corn Laws in mid-century, when Britain adopted a free trade policy, and grain imports from America undermined the profitability of crop production. The Irish potato famine of the 1840s was caused by a plant disease that reached the Highlands in 1846, where 150,000 people faced disaster because their food supply was largely potatoes (with a little herring, oatmeal and milk). They were rescued by an effective emergency relief system that stands in dramatic contrast to the failures of relief in Ireland.
Rural life.
The unequal concentration of land ownership remained an emotional subject and eventually became a cornerstone of liberal radicalism. The politically powerless poor crofters embraced the popularly oriented, fervently evangelical Presbyterian revival after 1800, and the breakaway "Free Church" after 1843. This evangelical movement was led by lay preachers who themselves came from the lower strata, and whose preaching was implicitly critical of the established order. This energised the crofters and separated them from the landlords, preparing them for their successful and violent challenge to the landlords in the 1880s through the Highland Land League. Violence began on the Isle of Skye when Highland landlords cleared their lands for sheep and deer parks. It was quieted when the government stepped in passing the Crofters' Holdings (Scotland) Act, 1886 to reduce rents, guarantee fixity of tenure, and break up large estates to provide crofts for the homeless. In 1885 three Independent Crofter candidates were elected to Parliament, leading to explicit security for the Scottish smallholders; the legal right to bequeath tenancies to descendants; and creating a Crofting Commission. The Crofters as a political movement faded away by 1892, and the Liberal Party gained most of their votes.
Migration.
The population of Scotland grew steadily in the 19th century, from 1,608,000 in the census of 1801 to 2,889,000 in 1851 and 4,472,000 in 1901. Even with the development of industry there were insufficient good jobs, as a result, during the period 1841-1931, about 2 million Scots migrated to North America and Australia, and another 750,000 Scots relocated to England. Scotland lost a much higher proportion of its population than England and Wales, reaching perhaps as much as 30.2 per cent of its natural increase from the 1850s onwards. This not only limited Scotland's population increase, but meant that almost every family lost members due to emigration and, because more of the migrants were young males, it skewed the sex and age ratios of the country.
Scots-born migrants that played a leading role in the foundation and development of the United States included cleric and revolutionary John Witherspoon, sailor John Paul Jones, industrialist and philanthropist Andrew Carnegie and scientist and inventor Alexander Graham Bell. In Canada they included soldier and governor of Quebec James Murray, Prime Minister John A. Macdonald and politician and social reformer Tommy Douglas. For Australia they included soldier and governor Lachlan Macquarie, governor and scientist Thomas Brisbane and Prime Minister Andrew Fisher. For New Zealand they included politician Peter Fraser and outlaw James Mckenzie. By the 21st century, there would be about as many people who were Scottish Canadians and Scottish Americans as the 5 million remaining in Scotland.
Religious schism and revival.
After prolonged years of struggle, in 1834 the Evangelicals gained control of the General Assembly and passed the Veto Act, which allowed congregations to reject unwanted "intrusive" presentations to livings by patrons. The following "Ten Years' Conflict" of legal and political wrangling ended in defeat for the non-intrusionists in the civil courts. The result was a schism from the church by some of the non-intrusionists led by Dr Thomas Chalmers known as the Great Disruption of 1843. Roughly a third of the clergy, mainly from the North and Highlands, formed the separate Free Church of Scotland. The evangelical Free Churches, which were more accepting of Gaelic language and culture, grew rapidly in the Highlands and Islands, appealing much more strongly than did the established church. Chalmers's ideas shaped the breakaway group. He stressed a social vision that revived and preserved Scotland's communal traditions at a time of strain on the social fabric of the country. Chalmers's idealized small equalitarian, kirk-based, self-contained communities that recognized the individuality of their members and the need for cooperation. That vision also affected the mainstream Presbyterian churches, and by the 1870s it had been assimilated by the established Church of Scotland. Chalmers's ideals demonstrated that the church was concerned with the problems of urban society, and they represented a real attempt to overcome the social fragmentation that took place in industrial towns and cities.
In the late 19th century the major debates were between fundamentalist Calvinists and theological liberals, who rejected a literal interpretation of the Bible. This resulted in a further split in the Free Church as the rigid Calvinists broke away to form the Free Presbyterian Church in 1893. There were, however, also moves towards reunion, beginning with the unification of some secessionist churches into the United Secession Church in 1820, which united with the Relief Church in 1847 to form the United Presbyterian Church, which in turn joined with the Free Church in 1900 to form the United Free Church of Scotland. The removal of legislation on lay patronage would allow the majority of the Free Church to rejoin Church of Scotland in 1929. The schisms left small denominations including the Free Presbyterians and a remnant that had not merged in 1900 as the Free Church.
Catholic Emancipation in 1829 and the influx of large numbers of Irish immigrants, particularly after the famine years of the late 1840s, principally to the growing lowland centres like Glasgow, led to a transformation in the fortunes of Catholicism. In 1878, despite opposition, a Roman Catholic ecclesiastical hierarchy was restored to the country, and Catholicism became a significant denomination within Scotland. Episcopalianism also revived in the 19th century as the issue of succession receded, becoming established as the Episcopal Church in Scotland in 1804, as an autonomous organisation in communion with the Church of England. Baptist, Congregationalist and Methodist churches had appeared in Scotland in the 18th century, but did not begin significant growth until the 19th century, partly because more radical and evangelical traditions already existed within the Church of Scotland and the free churches. From 1879 they were joined by the evangelical revivalism of the Salvation Army, which attempted to make major inroads in the growing urban centres.
Development of state education.
Industrialisation, urbanisation and the Disruption of 1843 all undermined the tradition of parish schools. From 1830 the state began to fund buildings with grants, then from 1846 it was funding schools by direct sponsorship, and in 1872 Scotland moved to a system like that in England of state-sponsored largely free schools, run by local school boards. Overall administration was in the hands of the Scotch (later Scottish) Education Department in London. Education was now compulsory from five to thirteen and many new board schools were built. Larger urban school boards established "higher grade" (secondary) schools as a cheaper alternative to the burgh schools. The Scottish Education Department introduced a Leaving Certificate Examination in 1888 to set national standards for secondary education and in 1890 school fees were abolished, creating a state-funded national system of free basic education and common examinations.
At the beginning of the 19th century, Scottish universities had no entrance exam, students typically entered at ages of 15 or 16, attended for as little as two years, chose which lectures to attend and could leave without qualifications. After two commissions of enquiry in 1826 and 1876 and reforming acts of parliament in 1858 and 1889, the curriculum and system of graduation were reformed to meet the needs of the emerging middle classes and the professions. Entrance examinations equivalent to the School Leaving Certificate were introduced and average ages of entry rose to 17 or 18. Standard patterns of graduation in the arts curriculum offered 3-year ordinary and 4-year honours degrees and separate science faculties were able to move away from the compulsory Latin, Greek and philosophy of the old MA curriculum. The historic University of Glasgow became a leader in British higher education by providing the educational needs of youth from the urban and commercial classes, as well as the upper class. It prepared students for non-commercial careers in government, the law, medicine, education, and the ministry and a smaller group for careers in science and engineering. St Andrews pioneered the admission of women to Scottish universities, creating the Lady Licentiate in Arts (LLA), which proved highly popular. From 1892 Scottish universities could admit and graduate women and the numbers of women at Scottish universities steadily increased until the early 20th century.
Early 20th century.
Fishing.
The years before the First World War were the golden age of the inshore fisheries. Landings reached new heights, and Scottish catches dominated Europe's herring trade, accounting for a third of the British catch. High productivity came about thanks to the transition to more productive steam-powered boats, while the rest of Europe's fishing fleets were slower because they were still powered by sails.
Political realignment.
In the Khaki Election of 1900, nationalist concern with the Boer War meant that the Conservatives and their Liberal Unionist allies gained a majority of Scottish seats for the first time, although the Liberals regained their ascendancy in the next election. The Unionists and Conservatives merged in 1912, usually known as the Conservatives in England and Wales, they adopted the name Unionist Party in Scotland. Scots played a major part in the leadership of UK political parties producing a Conservative Prime Minister in Arthur Balfour (1902–05) and a Liberal one in Henry Campbell-Bannerman (1905–08). Various organisations, including the Independent Labour Party, joined to make the British Labour Party in 1906, with Keir Hardie as its first chairman.
First World War 1914-18.
Scotland played a major role in the British effort in the First World War. It especially provided manpower, ships, machinery, food (particularly fish) and money, engaging with the conflict with some enthusiasm. Scotland's industries were directed at the war effort. For example, the Singer Clydebank sewing machine factory received over 5000 government contracts, and made 303 million artillery shells, shell components, fuses, and aeroplane parts, as well as grenades, rifle parts, and 361,000 horseshoes. Its labour force of 14,000 was about 70 percent female at war's end.
With a population of 4.8 million in 1911, Scotland sent 690,000 men to the war, of whom 74,000 died in combat or from disease, and 150,000 were seriously wounded. Scottish urban centres, with their poverty and unemployment were favourite recruiting grounds of the regular British army, and Dundee, where the female dominated jute industry limited male employment had one of the highest proportion of reservists and serving soldiers than almost any other British city. Concern for their families' standard of living made men hesitate to enlist; voluntary enlistment rates went up after the government guaranteed a weekly stipend for life to the survivors of men who were killed or disabled. After the introduction of conscription from January 1916 every part of the country was affected. Occasionally Scottish troops made up large proportions of the active combatants, and suffered corresponding loses, as at the Battle of Loos, where there were three full Scots divisions and other Scottish units. Thus, although Scots were only 10 per cent of the British population, they made up 15 per cent of the national armed forces and eventually accounted for 20 per cent of the dead. Some areas, like the thinly populated Island of Lewis and Harris suffered some of the highest proportional losses of any part of Britain. Clydeside shipyards and the nearby engineering shops were the major centres of war industry in Scotland. In Glasgow, radical agitation led to industrial and political unrest that continued after the war ended. After the end of the war in June 1919 the German fleet interned in Scapa Flow was scuttled by its German crews, to avoid its ships being taken over by the victorious allies.
Economic boom and stagnation.
A boom was created by the First World War, with the shipbuilding industry expanding by a third, but a serious depression hit the economy by 1922. The most skilled craftsmen were especially hard hit, because there were few alternative uses for their specialised skills. The main social indicators such as poor health, bad housing, and long-term mass unemployment, pointed to terminal social and economic stagnation at best, or even a downward spiral. The heavy dependence on obsolescent heavy industry and mining was a central problem, and no one offered workable solutions. The despair reflected what Finlay (1994) describes as a widespread sense of hopelessness that prepared local business and political leaders to accept a new orthodoxy of centralised government economic planning when it arrived during the Second World War.
A few industries did grow, such as chemicals and whisky, which developed a global market for premium "Scotch". However, in general the Scottish economy stagnated leading to growing unemployment and political agitation among industrial workers.
Interwar politics.
After World War I the Liberal Party began to disintegrate and Labour emerged as the party of progressive politics in Scotland, gaining a solid following among working classes of the urban lowlands. As a result, the Unionists were able to gain most of the votes of the middle classes, who now feared Bolshevik revolution, setting the social and geographical electoral pattern in Scotland that would last until the late 20th century. The fear of the left had been fuelled by the emergence of a radical movement led by militant trades unionists. John MacLean emerged as a key political figure in what became known as Red Clydeside, and in January 1919, the British Government, fearful of a revolutionary uprising, deployed tanks and soldiers in central Glasgow. Formerly a Liberal stronghold, the industrial districts switched to Labour by 1922, with a base in the Irish Catholic working class districts. Women were especially active in building neighbourhood solidarity on housing and rent issues. However, the "Reds" operated within the Labour Party and had little influence in Parliament; in the face of heavy unemployment the workers' mood changed to passive despair by the late 1920s. Scottish educated Andrew Bonar Law led a Conservative government from 1922 to 1923 and another Scot, Ramsay MacDonald, would be the Labour Party's first Prime Minister in 1924 and again from 1929 to 1935.
With all the main parties committed to the Union, new nationalist and independent political groupings began to emerge, including the National Party of Scotland in 1928 and Scottish Party in 1930. They joined to form the Scottish National Party (SNP) in 1934, with the goal of creating an independent Scotland, but it enjoyed little electoral success in the Westminster system.
Second World War 1939-45.
As in World War I, Scapa Flow in Orkney served as an important Royal Navy base. Attacks on Scapa Flow and Rosyth gave RAF fighters their first successes downing bombers in the Firth of Forth and East Lothian. The shipyards and heavy engineering factories in Glasgow and Clydeside played a key part in the war effort, and suffered attacks from the Luftwaffe, enduring great destruction and loss of life. As transatlantic voyages involved negotiating north-west Britain, Scotland played a key part in the battle of the North Atlantic. Shetland's relative proximity to occupied Norway resulted in the Shetland Bus by which fishing boats helped Norwegians flee the Nazis, and expeditions across the North Sea to assist resistance. Significant individual contributions to the war effort by Scots included the invention of radar by Robert Watson-Watt, which was invaluable in the Battle of Britain, as was the leadership at RAF Fighter Command of Air Chief Marshal Hugh Dowding.
In World War II, Prime Minister Winston Churchill appointed Labour politician Tom Johnston as Secretary of State for Scotland in February 1941; he controlled Scottish affairs until the war ended. He launched numerous initiatives to promote Scotland, attracting businesses and new jobs through his new Scottish Council of Industry. He set up 32 committees to deal with social and economic problems, ranging from juvenile delinquency to sheep farming. He regulated rents, and set up a prototype national health service, using new hospitals set up in the expectation of large numbers of casualties from German bombing. His most successful venture was setting up a system of hydro electricity using water power in the Highlands. A long-standing supporter of the Home Rule movement, Johnston persuaded Churchill of the need to counter the nationalist threat north of the border and created a Scottish Council of State and a Council of Industry as institutions to devolve some power away from Whitehall.
In World War II, despite extensive bombing by the Luftwaffe, Scottish industry came out of the depression slump by a dramatic expansion of its industrial activity, absorbing unemployed men and many women as well. The shipyards were the centre of more activity, but many smaller industries produced the machinery needed by the British bombers, tanks and warships. Agriculture prospered, as did all sectors except for coal mining, which was operating mines near exhaustion. Real wages, adjusted for inflation, rose 25 per cent, and unemployment temporarily vanished. Increased income, and the more equal distribution of food, obtained through a tight rationing system, dramatically improved the health and nutrition; the average height of 13-year-olds in Glasgow increased by .
End of mass migration.
While emigration began to tail off in England and Wales after the First World War, it continued apace in Scotland, with 400,000 Scots, ten per cent of the population, estimated to have left the country between 1921 and 1931. The economic stagnation was only one factor; other push factors included a zest for travel and adventure, and the pull factors of better job opportunities abroad, personal networks to link into, and the basic cultural similarity of the United States, Canada, and Australia. Government subsidies for travel and relocation facilitated the decision to emigrate. Personal networks of family and friends who had gone ahead and wrote back, or sent money, prompted emigrants to retrace their paths. When the Great Depression hit in the 1930s there were no easily available jobs in the US and Canada and emigration fell to less than 50,000 a year, bringing to an end the period of mass migrations that had opened in the mid-18th century.
Literary renaissance.
In the early 20th century there was a new surge of activity in Scottish literature, influenced by modernism and resurgent nationalism, known as the Scottish Renaissance. The leading figure in the movement was Hugh MacDiarmid (the pseudonym of Christopher Murray Grieve). MacDiarmid attempted to revive the Scots language as a medium for serious literature in poetic works including "A Drunk Man Looks at the Thistle" (1936), developing a form of Synthetic Scots that combined different regional dialects and archaic terms. Other writers that emerged in this period, and are often treated as part of the movement, include the poets Edwin Muir and William Soutar, the novelists Neil Gunn, George Blake, Nan Shepherd, A. J. Cronin, Naomi Mitchison, Eric Linklater and Lewis Grassic Gibbon, and the playwright James Bridie. All were born within a fifteen-year period (1887 and 1901) and, although they cannot be described as members of a single school, they all pursued an exploration of identity, rejecting nostalgia and parochialism and engaging with social and political issues.
Educational reorganisation and retrenchment.
In the 20th century the centre of the education system became more focused on Scotland, with the ministry of education partly moving north in 1918 and then finally having its headquarters relocated to Edinburgh in 1939. The school leaving age was raised to 14 in 1901, but despite attempts to raise it to 15 this was only made law in 1939 and then postponed because of the outbreak of war. In 1918 Roman Catholic schools were brought into the state system, but retained their distinct religious character, access to schools by priests and the requirement that school staff be acceptable to the Church.
The first half of the 20th century saw Scottish universities fall behind those in England and Europe in terms of participation and investment. The decline of traditional industries between the wars undermined recruitment. English universities increased the numbers of students registered between 1924 and 1927 by 19 per cent, but in Scotland the numbers fell, particularly among women. In the same period, while expenditure in English universities rose by 90 per cent, in Scotland the increase was less than a third of that figure.
Naval role.
Scotland's Scapa Flow was the main base for the Royal Navy in the 20th century. As the Cold War intensified in 1961, the United States deployed Polaris ballistic missiles, and submarines, in the Firth of Clyde's Holy Loch. Public protests from CND campaigners proved futile. The Royal Navy successfully convinced the government to allow the base because it wanted its own "Polaris"-class submarines, and it obtained them in 1963. The RN's nuclear submarine base opened four "Resolution" class Polaris submarines at the expanded Faslane Naval Base on the Gare Loch. The first patrol of a Trident-armed submarine occurred in 1994, although the US base was closed at the end of the Cold War.
Postwar.
After World War II, Scotland's economic situation became progressively worse due to overseas competition, inefficient industry, and industrial disputes. This only began to change in the 1970s, partly due to the discovery and development of North Sea oil and gas and partly as Scotland moved towards a more service-based economy. This period saw the emergence of the Scottish National Party and movements for both Scottish independence and more popularly devolution. However, a referendum on devolution in 1979 was unsuccessful as it did not achieve the support of 40 per cent of the electorate (despite a small majority of those who voted supporting the proposal.)
Politics and devolution.
In the second half of the 20th century the Labour Party usually won most Scottish seats in the Westminster parliament, losing this dominance briefly to the Unionists in the 1950s. Support in Scotland was critical to Labour's overall electoral fortunes as without Scottish MPs it would have gained only two UK electoral victories in the 20th century (1945 and 1966). The number of Scottish seats represented by Unionists (known as Conservatives from 1965 onwards) went into steady decline from 1959 onwards, until it fell to zero in 1997. Politicians with Scottish connections continued to play a prominent part in UK political life, with Prime Ministers including the Conservatives Harold Macmillan (whose father was Scottish) from 1955 to 1957 and Alec Douglas-Home from 1963 to 1964.
The Scottish National Party gained its first seat at Westminster in 1945 and became a party of national prominence during the 1970s, achieving 11 MPs in 1974. However, a referendum on devolution in 1979 was unsuccessful as it did not achieve the necessary support of 40 per cent of the electorate (despite a small majority of those who voted supporting the proposal) and the SNP went into electoral decline during the 1980s. The introduction in 1989 by the Thatcher-led Conservative government of the Community Charge (widely known as the Poll Tax), one year before the rest of the United Kingdom, contributed to a growing movement for a return to direct Scottish control over domestic affairs. The electoral success of New Labour in 1997 was led by two Prime Ministers with Scottish connections: Tony Blair (who was brought up in Scotland) from 1997 to 2007 and Gordon Brown from 2007 to 2010, opened the way for constitutional change. On 11 September 1997, the 700th anniversary of Battle of Stirling Bridge, the Blair led Labour government again held a referendum on the issue of devolution. A positive outcome led to the establishment of a devolved Scottish Parliament in 1999. A coalition government, which would last until 2007, was formed between Labour and the Liberal Democrats, with Donald Dewar as First Minister. The new Scottish Parliament Building, adjacent to Holyrood House in Edinburgh, opened in 2004. Although not initially reaching its 1970s peak in Westminster elections, the SNP had more success in the Scottish Parliamentary elections with their system of mixed member proportional representation. It became the official opposition in 1999, a minority government in 2007 and a majority government from 2011. In 2014 the independence referendum saw voters reject independence, choosing instead to remain in the United Kingdom. In the 2015 Westminster election, the SNP won 56 out of 59 Scottish seats, making them the third largest party in Westminster.
Economic reorientation.
After World War II, Scotland's economic situation became progressively worse due to overseas competition, inefficient industry, and industrial disputes. This only began to change in the 1970s, partly due to the discovery and development of North Sea oil and gas and partly as Scotland moved towards a more service-based economy. The discovery of the giant Forties oilfield in October 1970 signalled that Scotland was about to become a major oil producing nation, a view confirmed when Shell Expro discovered the giant Brent oilfield in the northern North Sea east of Shetland in 1971. Oil production started from the Argyll field (now Ardmore) in June 1975, followed by Forties in November of that year. Deindustrialisation took place rapidly in the 1970s and 1980s, as most of the traditional industries drastically shrank or were completely closed down. A new service-oriented economy emerged to replace traditional heavy industries. This included a resurgent financial services industry and the electronics manufacturing of Silicon Glen.
Religious diversity and decline.
In the 20th century existing Christian denominations were joined by other organisations, including the Brethren and Pentecostal churches. Although some denominations thrived, after World War II there was a steady overall decline in church attendance and resulting church closures for most denominations. Talks began in the 1950s aiming at a grand merger of the main Presbyterian, Episcopal and Methodist bodies in Scotland. The talks were ended in 2003, when the General Assembly of the Church of Scotland rejected the proposals. In the 2011 census, 53.8% of the Scottish population identified as Christian (declining from 65.1% in 2001). The Church of Scotland is the largest religious grouping in Scotland, with 32.4% of the population. The Roman Catholic Church accounted for 15.9% of the population and is especially important in West Central Scotland and the Highlands. In recent years other religions have established a presence in Scotland, mainly through immigration and higher birth rates among ethnic minorities, with a small number of converts. Those with the most adherents in the 2011 census are Islam (1.4%, mainly among immigrants from South Asia), Hinduism (0.3%), Buddhism (0.2%) and Sikhism (0.2%). Other minority faiths include the Bahá'í Faith and small Neopagan groups. There are also various organisations which actively promote humanism and secularism, included within the 43.6% who either indicated no religion or did not state a religion in the 2011 census.
Educational reforms.
Although plans to raise the school leaving age to 15 in the 1940s were never ratified, increasing numbers stayed on beyond elementary education and it was eventually raised to 16 in 1973. As a result, secondary education was the major area of growth in the second half of the 20th century. New qualifications were developed to cope with changing aspirations and economics, with the Leaving Certificate being replaced by the Scottish Certificate of Education Ordinary Grade ('O-Grade') and Higher Grade ('Higher') qualifications in 1962, which became the basic entry qualification for university study. The higher education sector expanded in the second half of the 20th century, with four institutions being given university status in the 1960s (Dundee, Heriot-Watt, Stirling and Strathclyde) and five in the 1990s (Abertay, Glasgow Caledonian, Napier, Paisley and Robert Gordon). After devolution, in 1999 the new Scottish Executive set up an Education Department and an Enterprise, Transport and Lifelong Learning Department. One of the major diversions from practice in England, possible because of devolution, was the abolition of student tuition fees in 1999, instead retaining a system of means-tested student grants.
New literature.
Some writers that emerged after the Second World War followed Hugh MacDiarmid by writing in Scots, including Robert Garioch and Sydney Goodsir Smith. Others demonstrated a greater interest in English language poetry, among them Norman MacCaig, George Bruce and Maurice Lindsay. George Mackay Brown from Orkney, and Iain Crichton Smith from Lewis, wrote both poetry and prose fiction shaped by their distinctive island backgrounds. The Glaswegian poet Edwin Morgan became known for translations of works from a wide range of European languages. He was also the first Scots Makar (the official national poet), appointed by the inaugural Scottish government in 2004. Many major Scottish post-war novelists, such as Muriel Spark, with "The Prime of Miss Jean Brodie" (1961) spent much or most of their lives outside Scotland, but often dealt with Scottish themes. Successful mass-market works included the action novels of Alistair MacLean, and the historical fiction of Dorothy Dunnett. A younger generation of novelists that emerged in the 1960s and 1970s included Shena Mackay, Alan Spence, Allan Massie and the work of William McIlvanney. From the 1980s Scottish literature enjoyed another major revival, particularly associated with a group of Glasgow writers focused around critic, poet and teacher Philip Hobsbaum and editor Peter Kravitz. In the 1990s major, prize winning, Scottish novels, often overtly political, that emerged from this movement included Irvine Welsh's "Trainspotting" (1993), Warner's "Morvern Callar" (1995), Gray’s "Poor Things" (1992) and Kelman’s "How Late It Was, How Late" (1994). Scottish crime fiction has been a major area of growth, particularly the success of Edinburgh's Ian Rankin and his Inspector Rebus novels. This period also saw the emergence of a new generation of Scottish poets that became leading figures on the UK stage, including Carol Ann Duffy, who was named as Poet Laureate in May 2009, the first woman, the first Scot and the first openly gay poet to take the post.

</doc>
<doc id="13621" url="https://en.wikipedia.org/wiki?curid=13621" title="Hadrian">
Hadrian

Hadrian (; ; 24 January, 76 AD – 10 July, 138 AD) was Roman emperor from 117 to 138. Hadrian is known for building Hadrian's Wall, which marked the northern limit of Britannia. He also rebuilt the Pantheon and constructed the Temple of Venus and Roma. Philhellene in most of his tastes, he is considered by some to have been a humanist, and he is regarded as one of the Five Good Emperors.
Hadrian was born Publius Aelius Hadrianus into a Hispano-Roman family. Although Italica near Santiponce (in modern-day Spain) is often considered his birthplace, his actual place of birth remains uncertain. However, it is generally accepted that he came from a family with centuries-old roots in Hispania. His predecessor, Trajan, was a maternal cousin of Hadrian's father. Trajan did not officially designate an heir, but according to his wife Pompeia Plotina, Trajan named Hadrian emperor immediately before his death. Trajan's wife and his friend Licinius Sura were well-disposed towards Hadrian, and he may well have owed his succession to them.
During his reign, Hadrian travelled to nearly every province of the Empire. An ardent admirer of Greece, he sought to make Athens the cultural capital of the Empire and ordered the construction of many opulent temples in the city. He used his relationship with his Greek lover Antinous to underline his philhellenism and led to the creation of one of the most popular cults of ancient times. He spent extensive amounts of time with the military; he usually wore military attire and even dined and slept amongst the soldiers. He ordered military training and drilling to be more rigorous and even made use of false reports of attack to keep the army alert.
Upon his accession to the throne, Hadrian withdrew from Trajan's conquests in Mesopotamia and Armenia, and even considered abandoning Dacia. Late in his reign he suppressed the Bar Kokhba revolt in Judaea, renaming the province Syria Palaestina. In 136 an ailing Hadrian adopted Lucius Aelius as his heir, but the latter died suddenly two years later. In 138 Hadrian resolved to adopt Antoninus Pius if he would in turn adopt Marcus Aurelius and Aelius's son Lucius Verus as his own eventual successors. Antoninus agreed, and soon afterward Hadrian died at Baiae.
Sources.
As is the case with his predecessor, Trajan, we lack a continuous account of the political history of Hadrian's reign. What we have in the way of such an account, as on Trajan's reign, is Book69 of the work "Roman History" by Cassius Dio. Dio's original text of this particular book is lost; what survives is a brief, much later, Byzantine era abridgment by the 11th century monk Xiphilinius, who made a selection from Dio's account of Hadrian's reign based on his mostly religious interests, covering the Bar Kokhba war relatively fully to the exclusion of much else. Hadrian is the first imperial biography of the "Historia Augusta", but the notorious unreliability of that work ("a mish mash of actual fact, cloak and dagger, sword and sandal, with a sprinkling of "Ubu Roi") does not allow its use as a source without care. Hadrian's biography is generally considered to be relatively free of fictional additions. Contemporary Greek authors such as Philostratus and Pausanias, who wrote shortly after Hadrian's reign, offer information on Hadrian's relations with the provincial Greek world, and Fronto, in his Latin correspondence, sheds some light on the general character of the reign's internal policies. As in the case of Trajan, using epigraphical, numismatic, archaeological and other non-literary sources is absolutely necessary in tracing a detailed historical account.
Early life.
Hadrian was born Publius Aelius Hadrianus in either Italica or Rome, from a well-established Roman family with centuries-old roots in Italica, Hispania Baetica (the republican Hispania Ulterior), near the present-day location of Seville, Spain. Although it was an accepted part of Hadrian's personal history that he was born in Spain, his "Historia Augusta" biography states that he was born in Rome on 24January 76, of an ethnically Hispanic with vague paternal links to Italy. However, this may be a complimentary fiction coined in order to make Hadrian appear as a natural-born Roman instead of a provincial, since his parents, grandparents, and great-grandparents were all born and raised in Hispania.
His father was Publius Aelius Hadrianus Afer, who as a senator of praetorian rank would spend much of his time in Rome, away from his homeland of Hispania. Hadrian's known paternal ancestry can be partially linked to a family from Hadria, modern Atri, an ancient town of Picenum in Italy. This family had settled in Italica in Hispania Baetica soon after its founding by Scipio Africanus several centuries before Hadrian's birth. His father Afer, was a paternal cousin of the future Emperor Trajan. Both Afer and Trajan were born and raised in Hispania. His mother was Domitia Paulina, who came from Gades (Cádiz). Paulina was a daughter of a distinguished Hispano-Roman senatorial family. His paternal great-grandmother is of unknown origin, which means that the exact amount of his paternal ancestry that can actually be linked to Italy (outside of nonspecific claims of forebears from Picenum from centuries earlier) is ultimately unknown.
Hadrian's elder sister and only sibling was Aelia Domitia Paulina, married with the triple consul Lucius Julius Ursus Servianus, his niece was Julia Serviana Paulina, and his great-nephew was Gnaeus Pedanius Fuscus Salinator, from Barcino (Barcelona). His parents died in 86 when Hadrian was ten, and the boy then became a ward of both Trajan and Publius Acilius Attianus (who was later Trajan's Praetorian Prefect). Hadrian was schooled in various subjects particular to young aristocrats of the day, and was so fond of learning Greek literature that he was nicknamed "Graeculus" ("Greekling").
Hadrian visited Italica when (or never left it until) he was 14 years old, when he was recalled by Trajan, who thereafter looked after his development. He never returned to Italica although it was later made a colonia in his honour.
Public service.
After his start at the vigintivirate (the minor posts whose holding qualified one for the senatorial "cursus"), Hadrian's first military service was as a tribune of the LegioII "Adiutrix". Exceptionally, he held a second tribunate when he was afterwards transferred to Legio V Macedonica and in such a capacity was chosen to inform Trajan of his adoption by Nerva. He was then retained in Germanypresumably on Trajan's ordersand was transferred to hold an even more exceptional third tribunate in Legio XXII Primigenia. The fact that he had three spells of military serviceinstead of just one or two, as was customary to the regular senatorpoints to a thorough military career and gave Hadrian an advantage, in terms of military expertise, over most scions from older senatorial families. When Nerva died in 98, Hadrian rushed to inform Trajan personally, coming in advance of the official envoy sent by the governor, Hadrian's brother-in-law and rival Lucius Julius Ursus Servianus – but this may be a fiction coined by Hadrian himself.
In 101 Hadrian began his senatorial career by being chosen quaestor, being charged with the task of reading Trajan's speeches to the Senateand possibly composing them himself. Next, he was "ab actis senatus", charged with the task of keeping the Senate's record of its proceedings. Next, he was created Tribune of the Plebs. From then on he began to be surrounded by stories about omens and portents that supposedly announced his future imperial condition. According to the "Historia Augusta", Hadrian had a great interest in astrology and divination and had been announced his future accession to the Empire by a grand-uncle who was himself a skilled astrologer. It is also noteworthy, however, that Trajan did not make Hadrian a Patrician, so as to allow him to become consul earlier, without having to hold the office of tribune.
During the First Dacian War, Hadrian was a member of Trajan's personal entourage, being excused from his military post in order to take office in Rome as tribune of the plebs. During the Second Dacian War, he was also relieved early from Trajan's personal attendance, becoming legate of a legionLegio I Minerviaand afterwards governor of Lower Pannonia. Therefore, if Hadrian had received the signal honour of assuming the tribunate of the plebs a year earlier than was customary, at the same time he departed early from both Dacian campaignsa sign that Trajan wanted to have him out of his way.
It was at this time that he married Trajan's grandniece, Vibia Sabina, in a move that seems to have been conceived by the empress Plotina, on whose favour he always counted. Also, he counted on the support of the bride's mother, Trajan's niece Salonina Matidia, daughter of Trajan's sister Ulpia Marciana. However, Trajan seemed to be far less enthusiastic. The subsequent relationship between Hadrian and Sabina was exceptionally and scandalously poor, even for a marriage of convenience. Also, Hadrian was at the time involved in some unexplained quarrel told in "Historia Augusta" around his relationships with Trajan's boy favourites, whom he had supposedly tried to groom. All these circumstances might explain the downturn experienced by Hadrian's fortunes late during Trajan's reign. Hadrian failed to achieve the honour of a regular consulate before his own reign, being only suffect consul for 108. As much as Trajan surely actively promoted Hadrian's advancement, at the same time he did it in a very measured, careful way.
Nevertheless, when Sabina's grandmother Ulpia Marciana died between 112 and 114, she was deified by the Senate and her daughter Salonina Matidia made a "princess of the blood", an Augusta. This made Hadrian, late during Trajan's reign, the first senator in history to have an "Augusta" as his mother-in-law, something that his contemporaries could not fail to notice.
It was at that time, in his mid-twenties, that Hadrian travelled to Greece, where he attended the lectures of the Stoic philosopher Epictetus, at the time living in the city of Nicopolis. He was also eponymous archon in Athens for a brief time, and was elected an Athenian citizen. The Athenians awarded Hadrian a statue with an inscription in the Theater of Dionysus offering a detailed account of his "cursus honorum", which confirms and expands the one in "Historia Augusta". Hadrian's career before Trajan's death was a regular one for a high ranking Roman senator, but without any particular distinction befitting an heir designate. After the 112 Athenian archontate, we hear no more of Hadrian before Trajan's Parthian War, and it is possible that he remained in Greece until being summoned into the imperial retinue.
His career before becoming emperor, as attested epigraphically in the Athens inscription, follows:
and afterwards
Hadrian was involved in the wars against the Dacians (as legate of the V"Macedonica" and reputedly won awards from Trajan for his successes. Hadrian's military skill is not well-attested due to a lack of military action during his reign; however, his keen interest in, and knowledge of, the army and his demonstrated skill of leadership show possible strategic talent.
Hadrian joined Trajan's expedition against Parthia as a legate on Trajan's staff. Neither during the first victorious phase, nor during the second phase of the war when rebellion swept Mesopotamia did Hadrian do anything of note. However, when the governor of Syria had to be sent to sort out renewed troubles in Dacia, Hadrian was appointed as a replacement, giving him an independent command.
Trajan, seriously ill by that time, decided to return to Rome while Hadrian remained in Syria to guard the Roman rear. In practical terms, that meant that Hadrian was "de facto" general commander of the Eastern Roman army, something that made his power position as a potential claimant to the throne unchallengeable. Trajan only got as far as Selinus before he became too ill to go further. While Hadrian may have been the obvious choice as successor, he had never been adopted as Trajan's heir. It is possible that Trajan never wanted to commit himself earlier with the appointment of a successor, as the great number of potential claimants made it possible that the definite choice of an heir would be seen as an abdication and therefore dash the chance for a transmission of power in an orderly way.
As Trajan lay dying, nursed by his wife, Plotina, and closely watched by Prefect Attianus, he could at last have adopted Hadrian as heir. Since the document was signed by Plotina, it has been suggested that Trajan may have already been dead. In a telltale sign, it has been discovered that Trajan's young manservant Phaedimus died in his late twenties a few days after Trajan's passing away, in Selinus, and that his body was interred in Rome only twelve years later. As Phaedimus was probably very close to Trajan, perhaps he was killed (or killed himself) for fear of his being posed awkward questions.
Emperor (117).
Securing power.
Even if Trajan's adoption of Hadrian was genuine, it came too late to keep other potential claimants from having wrong ideas. Therefore, Hadrian had to act on his own to secure his newly won position.
Hadrian quickly secured the support of the legions – one potential opponent, the Moorish prince and outstanding general Lusius Quietus, was promptly dismissed: by taking from Quietus his personal guard of Moorish auxiliaries, Hadrian could afterwards safely relieve him from his post as governor of Judea. The Senate's endorsement followed when possibly falsified papers of adoption from Trajan were presented. According to these papers, Hadrian had been adopted "in absentia" on 9 August 117 (Trajan having died on 8 August 8), which was technically irregular, as the two parties concerned were required to be present at the ceremony. The rumour of a falsified document of adoption carried little weight, as Hadrian's legitimacy arose from the endorsement of the Senate – and above all from the support of the Syrian armies. Nevertheless, various public ceremonies were organized – Egyptian papyri tell of one organized between 117 and 118 CE – extolling the fact that Hadrian had been divinely chosen by his deified father and by the gods themselves.
Hadrian did not at first go to Rome – he was busy sorting out the East and suppressing the Jewish revolt that had broken out under Trajan, then moving on to sort out the Danube frontier. Instead, Attianus, Hadrian's former guardian, was put in charge in Rome. There he "discovered" a conspiracy involving four leading Senators including Lusius Quietus and demanded of the Senate their deaths.
There was no question of a public trial – they were hunted down and killed out of hand. Because Hadrian was not in Rome at the time, he was able to claim that Attianus had acted on his own initiative. According to Elizabeth Speller, the real reason for their deaths was that they were Trajan's men. Or better, the reason for their elimination is simply that all four were prominent senators of consular rank and, as such, prospective candidates for the imperial office ("capaces imperii"). Also, the four consulars were the chiefs of a war hawk group of senators that was committed to Trajan's expansionist policies, which Hadrian intended to change. The consistent refusal of Hadrian to expand frontiers was to remain a bone of contention between him and the Senate throughout his reign.
Hadrian's instrument for getting rid of the four consulars, Prefect Attianus, was made a senator and promoted to consular rank, being afterwards discarded by Hadrian, who suspected his personal ambition. It is probable that Attianus was executed (or was already dead) by the end of Hadrian's reign. The four consulars episode, however, was to strain Hadrian's relations with the Senate for his entire reign. This tense relationship – and Hadrian's authoritarian stance towards the Senate – was acknowledged one generation later by Fronto, himself a senator, who wrote in one of his letters to Marcus Aurelius that "I praised the deified Hadrian, your grandfather, in the senate on a number of occasions with great enthusiasm, and I did this willingly, too [...] But, if it can be said – respectfully acknowledging your devotion towards your grandfather – I wanted to appease and assuage Hadrian as I would Mars Gradivus or Dis Pater, rather than to love him". The strain in the relationship between Hadrian and the Senate, however, never took the form of an overt confrontation, as had happened during the reigns of other previous "bad" emperors: Hadrian knew how to remain aloof in order to avoid an open clash. The Senate's political role, however, was effaced behind Hadrian's personal rule (in Ronald Syme's view, Hadrian "was a Führer, a Duce, a Caudillo"). The fact that Hadrian was to spend half of his reign away from Rome in constant travel undoubtedly helped the management of this strained relationship. Hadrian, however, underscored the autocratic character of his reign by counting the day of his acclamation by the armies as his "dies imperiii" and by enforcing new laws through imperial decree (as constitution) instead of having them approved by the Senate as a formality.
Hadrian and the military.
Despite his own great reputation as a military administrator, Hadrian's reign was marked by a general lack of documented major military conflicts, apart from the Second Roman–Jewish War. However, disturbances on the Danubian frontier early in the reign led to the killing of the governor of Dacia, Caius Julius Quadratus Bassus, to which Hadrian responded by placing the then equestrian governor of Mauretania Caesariensis, Q. Marcius Turbo, who had a long record of distinguished military service, as joint governor of Dacia and Pannonia Inferior with the powers of a Prefect. Shortly after, it was decided by Hadrian that all the part of Dacia that had been added to the province of Moesia Inferior – that is, present-day Southern Moldavia and the Wallachian Plain – was to be surrendered to the Roxolani Sarmatians, whose king Rasparaganus received Roman citizenship, client king status – and possibly an increased subsidy. The Roman partial withdrawal was probably supervised by the governor of Moesia Quintus Pompeius Falco. The presence of Hadrian on the Dacian front at this juncture, implied by the always unreliable "Historia Augusta", is merely conjectural. Hadrian did not visit Dacia in the course of his subsequent travels, but nevertheless included it into his subsequent monetary series of coins with allegories of the provinces. The notion that he contemplated the idea of withdrawing from Dacia altogether, as stated by Eutropius, appears, therefore, as unfounded.
Hadrian had already surrendered Trajan's conquests in Mesopotamia, considering them to be indefensible. In the East, Hadrian contented himself with retaining suzerainty over Osroene, which was ruled by the client king Parthamaspates, once client king of Parthia under Trajan. There was almost a new war with Parthia around 121, but the threat was averted when Hadrian succeeded in negotiating a peace. Late in the reign (135), an invasion of the Alani in Capadocia, covertly supported by the king of Caucasian Iberia Pharasmanes, was successful repulsed by Hadrian's governor, the historian Arrian – a Greek intellectual and fellow student of Epictetus who had been appointed to the Senate by Hadrian and ruled Capadocia as imperial legate between 131 and 137. After defeating the Alans, Arrian subsequently installed a Roman "adviser" in Iberia.
This abandonment of an aggressive policy was something for which the Senate and its historians never forgave Hadrian: the fourth century historian Aurelius Victor charged him with being jealous of Trajan's exploits and deliberately trying to downplay their worthiness: "Traiani gloriae invidens". It is more probable that Hadrian simply considered that the financial strain to be incurred in keeping on a policy of conquests was something the Roman Empire could not afford: proof to it is the disappearance during his reigns of two entire legions: Legio XXII Deiotariana and the famous "lost legion" IX Hispania, possibly destroyed during a late Trajanic uprising by the Brigantes in Britain. Also, the acknowledgement of the indefensible character of the Mesopotamian conquests had perhaps already been made by Trajan himself, who had disengaged from them at the time of his death.
The peace policy was strengthened by the erection of permanent fortifications along the empire's borders ("limites", sl. "limes"). The most famous of these is the massive Hadrian's Wall in Great Britain, built on stone and doubled on its rear by a ditch ("Vallum Hadriani"), which marked the boundary between a strictly military zone and the province. The Danube and Rhine borders were strengthened with a series of mostly wooden fortifications, forts, outposts and watchtowers, the latter specifically improving communications and local area security. These defensive activities, however, generated very few "literary" records: the information that it was Hadrian who built the Wall in Britain can only be found, in the entire corpus of ancient authors, in his "Historia Augusta" biography. But then, Hadrian's military activities were, in a certain measure, ideological, in that they emphasized a community of interests between all peoples living within the Roman Empire, instead a hegemony of conquest centered on the city of Rome and its Senate.
To maintain morale and prevent the troops from becoming restive, Hadrian established intensive drill routines, and personally inspected the armies. Although his coins showed military images almost as often as peaceful ones, Hadrian's policy was peace through strength, even threat, with an emphasis on "disciplina" (discipline), which was the subject of two monetary series. This emphasis on spit and polish was heartily praised by Cassius Dio, who saw it as a useful deterrent and therefore the cause of the general peaceful character of Hadrian's reign. Fronto, however, expressed other opinions on the subject: in his view, Hadrian liked to play war games and enjoyed "giving eloquent speeches to the armies" – like the series of addresses, inscribed on a column, that he made while on an inspection tour during 128 at the new headquarters of Legio III Augusta in Lambaesis – rather than actual warfare. In general, Fronto was very critical of Hadrian's pacifist policy, charging it with the decline in military standards of the Roman army of his own time. It was, however, Hadrian who at least systematized the employment of the "numeri" – ethnic non-citizen troops with special weapons, such as Eastern mounted archers – in low-intensity defensive tasks such as dealing with infiltrators and skirmishers. Using the "numeri" was an economic way to avoid frequent deployment of the legions, which suffered from a dearth of recruits from Italy as well as from the more Romanized provinces.
Cultural pursuits and patronage.
Hadrian has been described, firstly in an ancient anonymous source later echoed by Ronald Syme, among others, as the most versatile of all the Roman Emperors ("varius multiplex multiformis"). He also liked to demonstrate knowledge of all intellectual and artistic fields. Above all, Hadrian patronized the arts: Hadrian's Villa at Tibur (Tivoli) was the greatest Roman example of an Alexandrian garden, recreating a sacred landscape, albeit lost in large part to the despoliation of the ruins by the Cardinal d'Este, who had much of the marble removed to build Villa d'Este. In Rome, the Pantheon, originally built by Agrippa but destroyed by fire in 80, was rebuilt under Hadrian (working on a blueprint left by Trajan: see below) in the domed form it retains to this day. It is among the best-preserved of Rome's ancient buildings and was highly influential to many of the great architects of the Italian Renaissance and Baroque periods.
From well before his reign, Hadrian displayed a keen interest in architecture, but it seems that his eagerness was not always well received. For example, Apollodorus of Damascus, famed architect of the Forum of Trajan, dismissed his designs. When Trajan, predecessor to Hadrian, consulted Apollodorus about an architectural problem, Hadrian interrupted to give advice, to which Apollodorus replied, "Go away and draw your pumpkins. You know nothing about these problems." "Pumpkins" refers to Hadrian's drawings of domes like the Serapeum in his villa. The historian Cassius Dio wrote that, once Hadrian succeeded Trajan to become emperor, he had Apollodorus exiled and later put to death. The story, however, is problematical – archaeological evidence (brickstamps with consular dates) has demonstrated, e.g., that the Pantheon's dome was already under construction late in Trajan's reign (115) and probably under Apollodorus's sponsorship.
Hadrian wrote poetry in both Latin and Greek; one of the few surviving examples is a Latin poem he reportedly composed on his deathbed (see below). Some of his Greek productions found their way into the Palatine Anthology. He also wrote an autobiography, which "Historia Augusta" says was published under the name of Hadrian's freedman Phlegon of Tralles. It was not, apparently, a work of great length or revelation, but designed to scotch various rumours or explain Hadrian's most controversial actions. It is possible that this autobiography had the form of a series of open letters to Antoninus Pius.
Hadrian was a passionate hunter from the time of his youth, according to one source. In northwest Asia, he founded and dedicated a city to commemorate a she-bear he killed. It is documented that in Egypt he and his beloved Antinous killed a lion. In Rome, eight reliefs featuring Hadrian in different stages of hunting decorate a building that began as a monument celebrating a kill.
Another of Hadrian's contributions to "popular" culture (in fact the generalized mores of the imperial elites) was the beard, which symbolised his philhellenism: Dio of Prusa had equated the generalized using of the beard with Hellenic ethos. Since the time of Scipio Africanus it had been fashionable among the Romans to be clean-shaven. Also, all Roman emperors before Hadrian, except for Nero (also a great admirer of Greek culture), were clean shaven. Most of the emperors after Hadrian would be portrayed with beards. Their beards, however, were not worn out of an appreciation for Greek culture but because the beard had, thanks to Hadrian, become fashionable. This new fashion lasted until the reign of Constantine the Great and was revived again by Phocas at the start of the 7th century. Notwithstanding his philhellenism, however, in all other everyday life matters Hadrian behaved as a Roman civic traditionalist, who demanded the use of the toga by senators and knights in public and strict separation between the sexes in the public baths and theaters.
As a cultural Hellenophile Hadrian was familiar with the work of the philosophers Epictetus, Heliodorus and Favorinus. At home he attended to social needs. Hadrian mitigated slavery: masters were forbidden from killing their slaves unless allowed by a court to punish them for a grave offense. Masters were forbidden to sell slaves to a gladiator trainer (lanista) or to a procurer, except as justified punishment. Hadrian also had the legal code humanized and forbade torture of free defendants and witnesses, legislating against the common practice of condemning free persons in order to have them tortured as a means of gathering information on their supposed activities and accomplices. He also abolished ergastula, private prisons for slaves in which kidnapped free men could also be kept.
However, Hadrian's humanitarian views had a limit, namely, the existence of slavery itself: confronted with a crowd that demanded the freeing of a popular slave charioteer, he replied that he could not free a slave belonging to another person. Also, Hadrian at least once personally engaged in cruelty toward a slave: in a fit of rage, he stabbed the eye of one of his secretaries with a pen.
He built libraries, aqueducts, baths and theaters. Hadrian is considered by many historians to have been wise and just: Schiller called him "the Empire's first servant", and British historian Edward Gibbon admired his "vast and active genius", as well as his "equity and moderation". In 1776, he stated that Hadrian's era was part of the "happiest era of human history".
While visiting Greece in 131–132, Hadrian attempted to create a kind of provincial parliament to bind all the semi-autonomous former city states across all Greece and Ionia (in Asia Minor). This parliament, known as the Panhellenion, is generally conceived as a failed, albeit spirited, effort to foster cooperation among the Hellenes. However, as the German sociologist Georg Simmel remarked, the aim of the Panhellenion was probably to render Hellenism inert: to "divert" the feeling of a common Hellenic identity towards ideal purposes: "games, commemorations, preservation of an ideal, an entirely non-political Hellenism".
Hadrian died at his villa in Baiae. He was buried in a mausoleum on the western bank of the Tiber, in Rome, a building later transformed into a papal fortress, Castel Sant'Angelo. The dimensions of his mausoleum, in its original form, were deliberately designed to be slightly larger than the earlier Mausoleum of Augustus.
According to Cassius Dio, a gigantic equestrian statue was erected to Hadrian after his death. "It was so large that the bulkiest man could walk through the eye of each horse, yet because of the extreme height of the foundation persons passing along on the ground below believe that the horses themselves as well as Hadrian are very very small." This may refer to the huge statuary group placed atop the mausoleum, which disappeared at some later time, depicting Hadrian driving a four-horse quadriga chariot.
Hadrian's travels.
Purpose.
The most distinctive aspect of Hadrian's reign was the fact that the Emperor was to spend more than half of it outside of Italy and engaged in peaceful pursuits. Obviously, other emperors had often left Rome for long periods, but then mostly to go to war, returning soon after conflicts concluded. A previous emperor, Nero, once travelled through Greece and was condemned for his self-indulgence. According to modern historians such as Paul Veyne, what Hadrian intended by his incessant travelling was what Nero had failed to achieve: to break with the sedentary ("casanière") tradition of previous emperors, who saw the Empire as a purely Roman hegemony; instead, Hadrian sought to make his subjects feel part of a commonwealth of civilized peoples, sharing a common Hellenic culture. That is why Hadrian, in a speech to the Senate preserved by Aulus Gellius, supported the creation of new municipia, autonomous urban communities with their own customs and laws, over the creation of new colonies, urban communities with a standard Roman constitution.
All this did not go well with Roman traditionalism: as far as the "Historia Augusta" portrays traditional ideology, Hadrian was regarded by its author as "a little too much Greek", far more cosmopolitan than it was thought fit for a Roman emperor. The significance of Hadrian's travels as a means of stressing the cosmopolitan, ecumenical character of the Roman Empire was confirmed late during the reign when Hadrian struck a series of special issue coins representing allegories of the various provinces.
Hadrian traveled as an integral part of his governing, something he made clear to the Roman Senate and the people. In order to check the Roman populace, he made recourse to his chief equestrian adviser, Marcius Turbo, who was made Pretorian Prefect in 121 – while he was still joint-governor of Dacia and Pannonia Inferior – and who had as his task to adjudicate non-senators. Turbo had had a long career as a procurator, and was regarded as one of the leading men of the equestrian order. Nonetheless, he was not qualified to keep a check on the Senate, as Hadrian forbade equestrians to try cases against senators. The Senate had ultimate legal authority over its members, as it remained formally the highest court of appeal, from which appealing to the Emperor was forbidden. There are hints within certain sources that Hadrian also employed a secret police force, the frumentarii, on an ad hoc, occasional basis to snoop primarily on people of high social standing, such as his close friends.
His visits were marked by handouts that often contained instructions for the construction of new public buildings. His intention was to strengthen the Empire from within through improved infrastructure, as opposed to conquering or annexing perceived enemies. This was often the purpose of his journeys; commissioning new structures, projects and settlements. His almost evangelical belief in Greek culture strengthened his views: like many emperors before him, Hadrian's will was almost always obeyed. Later, the Greek rhetorician Aelius Aristides was to extol his activities by writing that he "extended over his subjects a protecting hand, raising them as one helps fallen men on their feet".
His travelling court was large, including administrators and probably also architects and builders. The burden on the areas he passed through was sometimes great. While his arrival usually brought some benefits, it is possible that those who had to bear the burden were of a different class from those who reaped the benefits. For example, huge amounts of provisions were requisitioned during his visit to Egypt; this suggests that the burden on the mainly subsistence farmers must have been intolerable, causing some measure of starvation and hardship.
At the same time, as in later times all the way through the European Renaissance, kings were welcomed into their cities or lands, and the financial burden was completely on them, and only indirectly on the poorer class. Hadrian's first tour came just four years after assuming the office of Caesar, when he sought a cure for a skin disease thought to be leprosy and travelled to Judea Roman province while en route to Egypt. This time also allowed him the freedom to concern himself with his general cultural aims. At some point, he travelled north, towards Germania and inspected the Rhine–Danube frontier, allocating funds to improve the defences. However, it was a voyage to the Empire's very frontiers that represented perhaps his most significant visit; upon hearing of a recent revolt, he journeyed to Britannia.
Britannia and the West (122).
Prior to Hadrian's arrival in Britain, there had been a major rebellion in Britannia from 119 to 121. Although operations in Britannia at the time got no mention worthy of note in the literary sources, inscriptions tell of an "expeditio Britannica" involving major troop movements, including sending a vexillatio (i.e., a detachment) of some 3,000 men taken from legions stationed on the Rhine and in Spain; Fronto writes about military losses in Britannia at the time. The "Historia Augusta" notes that the Britons could not be kept under Roman control; Pompeius Falco was sent to Britain to restore order, and coins of 119–120 refer to this. In 122 Hadrian initiated the construction of Hadrian's Wall. The wall was built "to separate Romans from barbarians", according to the "Historia Augusta". It deterred attacks on Roman territory (at a lower cost than a massed border army) and controlled cross-border trade and immigration.
Unlike the Germanic limes, built of wood palisades, Hadrian's Wall was primarily a stone construction. The western third of the wall, from modern-day Carlisle to the River Irthing, was originally built of turf for unknown reasons. Possibly to hasten its construction, the wall's width was narrowed in some sections from the original planned 12 feet to 7. The turf wall was, however, later rebuilt in stone, and a large ditch with adjoining mounds, known today as the Vallum, was dug to the south of the wall.
Under Hadrian, a shrine was erected in York to Britain as a goddess, and coins that introduced a female figure as the personification of Britain, labelled BRITANNIA, were struck. By the end of 122, Hadrian had concluded his visit to Britannia, and from there headed south to Mauretania, never to return. Thus he never saw the finished wall that bears his name.
Hadrian appears to have gone to Mauretania through southern Gaul, and it is probable that he visited Nemausus, where he may have overseen the building of a basilica dedicated to Plotina, who had meanwhile died in Rome. Plotina was in due course deified at Hadrian's prompting. Shortly before her death, Hadrian had already granted Plotina a signal favour, by stating that succession to the head of the Epicurean School in Athens could be granted to a non-Roman citizen – a petition that had been made by the incumbent head of the school seeking Plotina's intercession. Matidia Augusta, Hadrian's mother-in-law, had died earlier, in December 119, and had also been deified. Both deifications of these prominent female members of Trajan's family might be seen as an effort by Hadrian to buttress his legitimacy. At what appears to have been the same time, Hadrian dismissed his secretary in charge of his official correspondence ("ab epistulis"), the historian Suetonius, for "excessive familiarity" towards the empress. Also dismissed for the same alleged reason was Marcius Turbo's colleague as Praetorian Prefect, Gaius Septicius Clarus. Given Clarus' high office, the alleged reason for his dismissal could have been merely a pretext to remove him from office.
Hadrian spent the winter of 122/123 at Spain, in Tarraco, where he restored the Temple of Augustus before crossing the Mediterranean into Mauretania.
Africa, Parthia and Anatolia; Antinous (123–124).
In 123, he arrived in Mauretania where he personally led a campaign against local rebels. However, this visit was to be short, as reports came through that the Eastern nation of Parthia was again preparing for war; as a result, Hadrian quickly headed eastwards. On his journey east it is known that at some point he visited Cyrene, during which time he personally made available funds for the training of the young men of well-bred families for the Roman military. Cyrene had already benefited from his generosity: in 119 he had provided funds for the rebuilding of public buildings destroyed in the recent Jewish revolt. The rebuilding lasted until late in the reign, and in 138 a statue of Zeus was erected with a dedication to Hadrian as "saviour and founder" of Cyrene.
When Hadrian arrived on the Euphrates, he characteristically solved the problem through a negotiated settlement with the Parthian king Osroes I. He then proceeded to check the Roman defences before setting off west along the coast of the Black Sea. He probably spent the winter in Nicomedia, the main city of Bithynia. As Nicomedia had been hit by an earthquake only shortly prior to his stay, Hadrian was generous in providing funds for rebuilding, for which he was acclaimed as the chief restorer of the province as a whole.
It is possible that Hadrian visited Claudiopolis and there espied the beautiful Antinous, a young boy who was destined to become the emperor's beloved. Sources say nothing about when Hadrian met Antinous; however, there are depictions of Antinous that show him as a young man of 20 or so. As this was shortly before Antinous's death in 130 (the earliest date for which we can be sure of Antinous' being together with Hadrian) Antinous in 123 would most likely have been a youth of 13 or 14. It is possible that Antinous was sent to Rome to be trained as a page to serve the emperor and only gradually rose to the status of imperial favourite. The fact is, however, that the actual history of the Antinous/Hadrian relationship is mostly unknown.
With or without Antinous, Hadrian travelled through Anatolia. The route he took is uncertain. Various incidents are described, such as his founding of a city within Mysia, Hadrianutherae, after a successful boar hunt. (The building of the city was probably more than a mere whim – sparsely populated wooded areas such as the location of the new city were already ripe for development). Some historians dispute whether Hadrian did in fact commission the city's construction at all. At about this time, plans to complete the Temple of Zeus in Cyzicus, begun by the kings of Pergamon, were put into practice. The temple, whose completion had been contemplated by Trajan, received a colossal statue of Hadrian, and was built with dazzling white marble with gold thread. Cyzicus received the additional honor of being declared a regional center for the Imperial cult ("neocoros"), sharing it with Pergamon, Smyrna, Ephesus and Sardes – something that offered the benefits of Imperial sponsorship of sacred games, attracting tourism and stimulating private expenditure as well as channeling intercity rivalry into a common acceptance of Roman rule.
Greece (124–125).
The climax of this tour was the destination that Hadrian must have had in mind all along, Greece. He arrived in the autumn of 124 in time to participate in the Eleusinian Mysteries. By tradition, at one stage in the ceremony the initiates were supposed to carry arms; but, this was waived to avoid any risk to the emperor. At the Athenians' request, he conducted a revision of their constitution – among other things, a new phyle (tribe) was added bearing his name. Also, a system of coercive purchases of oil was imposed on Athenian producers in order to ensure an adequate supply of the commodity; management of the system was left in the hands of the local Assembly and Council, appeals to the Emperor notwithstanding. Athens also became the only provincial city to benefit from a regular supply of grain. Hadrian also created two foundations that were to provide for the funding of Athens' public games, whenever there was no citizen wealthy enough (or willing) to sponsor them as a Gymnasiarch or Agonothetes. Usually, however, Hadrian preferred that civic expenditure by Greek notables should concentrate on buildings rather than on spectacles and competitions: in a letter to Aphrodisias he praised a requirement that high priests of the imperial cult donate funds to works on an aqueduct rather than to gladiatorial games. Such aqueducts – associated with public fountains – "nymphaea" – were one of Hadrian's additions to the Greek urban landscape: besides Athens, where two such fountains were built, Argos also received a similar project.
It was possibly at this time that Hadrian received, according to Eusebius, an apology (i.e., a defense) of the Christian faith made by two Christians, Quadratus and Aristides. Apparently, Hadrian simply kept to Trajan's policy of passive tolerance, by which Christians should not be sought after but sentenced only after due trial. In a rescript addressed to the proconsul of Asia Minutius Fundanus and preserved by Justin Martyr, Hadrian laid down that accusers of Christians had to bear the burden of proof for their denunciations on pain of being punished for "calumnia" (defamation).
During the winter he toured the Peloponnese. His exact route is uncertain; however, Pausanias reports of tell-tale signs, such as temples built by Hadrian and the statue of the emperor – in heroic nudity – built by the grateful citizens of Epidaurus in thanks to their "restorer". He was especially generous to Mantinea, where he restored the Temple of Poseidon Hippios; this supports the theory that Antinous was in fact already Hadrian's lover because of the strong link between Mantinea and Antinous's home in Bithynia. However, as this kinship between Mantinea and Bythinia was itself a mythological fiction of the kind used at the time for encouraging political alliances between polities, a more serious reason might exist for Hadrian's particular generosity. Hadrian's buildings in Greece were no mere whims, as they followed a pattern of favoring old religious centers: besides the temple at Mantinea, Hadrian restored other ancient shrines in Abae, Argos – where he restored the Heraion – and Megara. This was a way of gathering legitimacy to Roman imperial rule by associating it to the glories of classical Greece – something well in line with contemporary antiquarian taste in cultural matters. Hadrian is credited by Pausanias with restoring to Mantinea its ancient, classical name: it had been named Antigoneia since Hellenistic times, in honor of the Macedonian king Antigonus III Doson.
This same idea of resurrecting the classical past under Roman overlordship was behind the possibility that, during his tour of the Peloponnese, Hadrian persuaded the Spartan grandee Eurycles Herculanus – the contemporary leader of the Euryclid family that had ruled Sparta since Augustus' day – to enter the Senate, alongside the Athenian grandee Herodes Atticus the Elder. The two aristocrats would be the first Greeks from Old Greece to enter the Roman Senate, as "representatives" of the two "great powers" of the Classical Age. This was an important step in overcoming Greek notables' haughty disdain and their reluctance to take part in Roman political life.
By March 125, Hadrian had reached Athens, presiding over the festival of Dionysia. The building program that Hadrian initiated was substantial. Various rulers had done work on building the Temple of Olympian Zeus over a timespan of more than five centuries – it was Hadrian and the vast resources he could command that ensured that the job would be finished. He also initiated the construction of several public buildings on his own whim and even organized the building of an aqueduct.
Return to Italy and trip to Africa (126–128).
On his return to Italy, Hadrian made a detour to Sicily. Coins celebrate him as the restorer of the island, though there is no record of what he did to earn this accolade.
Back in Rome, he was able to see for himself the completed work of rebuilding the Pantheon. Also completed by then was Hadrian's villa nearby at Tibur, a pleasant retreat by the Sabine Hills for whenever Rome became too much for him. At the beginning of March 127 Hadrian set off for a tour of Italy. Once again, historians are able to reconstruct his route by evidence of his hand-outs rather than the historical records.
For instance, in that year he restored the Picentine earth goddess Cupra in the town of Cupra Maritima. At some unspecified time he improved the drainage of the Fucine lake. Less welcome than such largesse was his decision in 127 to divide Italy into four regions under imperial legates with consular rank, who had jurisdiction over all of Italy excluding Rome itself, therefore shifting cases from the courts of Rome. Actually, the four consulars acted as governors of the regions assigned to them. Having Italy effectively reduced to the status of a group of mere provinces did not go down well with Italian hegemonic feelings (especially with the Roman Senate), and this innovation did not long outlive Hadrian.
Hadrian fell ill around this time, though the nature of his sickness is not known. Whatever the illness was, it did not stop him from setting off in the spring of 128 to visit Africa. His arrival began with the good omen of rain ending a drought. Along with his usual role as benefactor and restorer, he found time to inspect the troops; his speech to the troops survives to this day. Hadrian returned to Italy in the summer of 128 but his stay was brief, as he set off on another tour that would last three years.
Greece, Asia, and Egypt (128–130); Antinous' death.
In September 128, Hadrian again attended the Eleusinian mysteries. This time his visit to Greece seems to have concentrated on Athens and Sparta – the two ancient rivals for dominance of Greece. Hadrian had played with the idea of focusing his Greek revival around the Amphictyonic League based in Delphi, but by now he had decided on something far grander. His new Panhellenion was going to be a council that would bring Greek cities together. The meeting place was to be the new temple to Zeus in Athens. Having set in motion the preparations – deciding whose claim to be a Greek city was genuine would in itself take time – Hadrian set off for Ephesus. The notion of the "Greek city", however, was mostly political and mythological rather than historical: it involved fabricated claims to Greek origins and imperial favour. Most importantly, it linked appreciation of an idealized cultural Hellenism with loyalty to Rome and her Emperor. The Panhellenion was devised with a view to associating the Roman Emperor with protection of Greek culture and of the "liberties" of Greece – in the case, urban self-government. It allowed Hadrian to appear as the fictive heir to Pericles, who supposedly had convened a previous Panhellenic Congress – which is mentioned, by the way, only in his biography by Plutarch, whose sympathies to the Imperial order are well-known. Epigraphical evidence suggests, however, that the prospect of "applying" to the Panhellenion raised less interest in the wealthier cities from Asia Minor, which were jealous of Athenian and European Greek preeminence. Hadrian defined Hellenism in a narrow, archaizing manner: no Hellenistic foundations were admitted into the Panhellenion, as Hadrian defined "Greekness" in terms of classical roots alone.
From Greece, Hadrian proceeded by way of Asia to Egypt. It is known from an inscription that he was at the time probably conveyed across the Aegean with his entourage by one Ephesian, Lucius Erastus, on behalf of whom he later sent a letter to the Council of Ephesus, stating that Erastus wanted to become a town councillor, and that he, Hadrian, was willing to pay the honorary sum required for entrance in the council, if the Ephesians regarded Erastus (who, as a merchant, was probably snubbed upon as unfit for civic prominence) worthy to fill such a position.
In Egypt, Hadrian opened his stay by restoring Pompey the Great's tomb at Pelusium. Hadrian also offered sacrifice to Pompey as a hero and composed an epigram for the tomb. As Pompey was universally acknowledged as the conqueror of the Roman East, this restoration was probably linked to a need to reaffirm Roman Eastern hegemony after the recent disturbances there during Trajan's late reign. Also in Egypt, a poem about a lion hunt in the Libyan desert by the Greek Pankrates witnesses for the first time that Antinous travelled alongside Hadrian.
In October 130, while Hadrian and his entourage were sailing on the Nile, Antinous drowned for unknown reasons; accident, suicide, murder and religious sacrifice have all been postulated. "Historia Augusta" offers the following account:
It was at that time that Hadrian turned, by his personal initiative, the "persona" of Antinous – a low-status non-citizen Greek – into something far surpassing the usual imperial boy favourite and sexual interest. Deeply saddened, Hadrian founded the Egyptian city of Antinopolis in his memory, and had Antinous deified – an unprecedented honour for one not of the ruling family.
Although Hadrian was criticized for the intensity of his grief to Antinous's death, his attempt at turning the deceased youth into a cult-figure found little opposition. The cult of Antinous was to become very popular in the Greek-speaking world.Dyson, Stephen L., "Rome: A Living Portrait of an Ancient City", p. 195.</ref> It has been suggested that Hadrian created the cult as a political move to reconcile the Greek-speaking East to Roman rule. The existence of a copy, in Hadrian's villa, of the famous statue pair of the Tyrannicides, with a bearded Aristogeiton and a clean-shaven Harmodios, in a certain way linked the imperial favourite to the classical tradition of Greek love in opposition to usual Roman distrust of Greek pederasty. In Italy and the West, the cult also found supporters: in one inscription from Tivoli, Antinous was compared to the Celtic sun-god Belenos.
Medals were struck with Antinous' effigy, and statues erected to him in all parts of the empire, in all kinds of garb, including Egyptian dress. Temples were built for his worship in Bithynia and Mantineia in Arcadia. In Athens, festivals were celebrated in his honour and oracles delivered in his name. The site chosen for the city of Antinopolis (or Antinoe) was on the ruins of Besa, in the vicinity of Antinous's death-place. The city was a proper Greek polis, which, however, besides benefitting from an alimentary scheme similar to Trajan's alimenta, also allowed its citizens the privilege of marrying members of the native population without disenfranchising themselves – proof that Hadrian intended, again, to use a local religious cult (in this case, an Egyptianized one) as a means of integrating native populations into the celebration of Roman rule. Antinous's cult differed from the previous imperial cult in that, instead of centering on worshipping the Emperor as a ruler, it involved the Emperor "as well as his subjects" in a common religious activity, thereby emphasizing a sense of shared community. Eventually, it was very successful. As an "international" cult figure, Antinous had an enduring fame, far outlasting Hadrian's reign: local coins with his effigy were still being struck during Caracalla's reign, and he was invoked in a poem to celebrate the accession of Diocletian.
Greece and the East; return to Rome (130–133).
Hadrian’s movements subsequent to the founding of Antinopolis on 30 October 130 are obscure. Whether or not he returned to Rome, he traveled in the East during 130/131 (see below) and spent the winter of 131–32 in Athens, where he dedicated the Olympeion, and probably remained in Greece or went East because of the Jewish rebellion, which broke out in Judaea in 132 (see below). Inscriptions make it clear that he took the field in person against the rebels with his army in 133; he then returned to Rome, probably in that year and almost certainly – again, judging from inscriptions – via Illyricum. This third and final trip to the Greek East produced much religious enthusiasm in the region centered around Hadrian, who received a personal cult as a deity and numerous monuments and civic homages, according to the religious syncretism at the time.
Legal reforms and State apparatus.
It was around that time that Hadrian enacted, through the jurist Salvius Julianus, what was to become the first attempt to codify Roman law: the Perpetual Edict, according to which the various forms of legal action introduced yearly by pretors were to remain fixed. The practical meaning of this measure was that a law could no longer be changed by a magistrate's personal interpretation of it; the law had become a fixed statute, which only the Emperor could alter. At the same time, following a procedure initiated by Domitian, Hadrian professionalized the Emperor's legal advisory board, the Prince's Counsel or "consilia principis", which became a permanent body staffed by salaried legal aides. By so doing, Hadrian developed a professional bureaucracy, consisting mainly of equestrians and replacing the earlier freedmen of the Imperial household, that was to control the political field instead of the Senate's individual members, an innovation that marked the superseding of surviving Republican institutions by an openly autocratic political system. Hadrian's bureaucracy was supposed to carry out the administrative functions not earlier exercised by the old magistrates, and therefore objectively it did not detract from the Senate's position: the new civil servants were free men and as such supposed to act on behalf of the interests of the "Crown", not of the Emperor as an individual. However, the Senate never accepted the loss of its prestige caused by the emergence of a new aristocracy alongside it, placing additional strain on the already troubled relationship between the Senate and the Emperor that was to be a hallmark of the end of Hadrian's reign.
Hadrian and Judea; Second Roman–Jewish War and Jewish persecution (132–136).
In 130/131, Hadrian toured the East, bestowing honorific titles on many regional centers. Palmyra received a state visit and was given the civic name Hadriana Palmyra. Hadrian also bestowed honors on various Palmyrene magnates, among them one Soados, who lived in the Parthian city of Vologesias and, as a go-between, had done much to protect Palmyrene trade between the Roman Empire and Parthia.
It was then that Hadrian visited the ruins of Jerusalem, in Roman Judaea, left after the First Roman–Jewish War of 66–73. According to a midrashic tradition, he first showed himself sympathetic to the Jews, allegedly planning to have the city rebuilt and allowing the rebuilding of the Temple, but when told by Samaritans that it would be the catalyst for sedition, he changed his mind. The reliability of this tradition is, however, doubtful. The account stands in sharp contradiction to an alternate tradition that has Hadrian deciding to build a temple to the Roman god Jupiter on the ruins of the Temple Mount and other temples to various Roman gods throughout Jerusalem, including a large temple to the goddess Venus.
According to modern scholar Giovanni Bazzana, Hadrian's original intention may have been to rebuild Jerusalem as a Roman colony – such as Vespasian had done earlier to Caesarea Maritima – with various honorific and fiscal privileges, as well as a pagan population. It is accepted that the usual Roman policy in other colonies involved exempting the Jewish population from participating in Roman religious rituals. What was demanded from Jewish communities was political support to the Roman imperial order, as attested in Caesarea, where epigraphy attests that some of its Jewish citizens served in the Roman army during both the 66 and 132 rebellions.
It has been speculated that Hadrian intended to assimilate the Jewish Temple into the civic-religious basis of support to his reign, as he had been doing with Greek and other traditional places of worship. It has also been ventured that Hadrian attempted to unify all belief systems in his empire as a coherent whole that would serve as a basis of support for his autocratic legitimacy – a project that had already been devised earlier by Hellenized Jewish intellectuals such as Philo. The neighbouring Samaritans had already undergone such a process of Hellenization and religious syncretism, integrating their religious rites with Hellenistic ones. Hadrian probably sanctioned this Hellenized Samaritan worship when, after the suppression of the Jewish revolt, he built a temple to the Hellenistic (and probably syncretic) god Zeus Hypsistos ("Highest") on Mount Gerizim. This attempt at conciliation between Judaism and Hellenism, however, foundered when faced with strict Jewish monotheism. Therefore, the Romans appear to have been surprised by the outbreak of the uprising.
The evidence for this failure to integrate Judaism into a unified religious system lies in the fact that, after the war, Hadrian even renamed Jerusalem itself, as Aelia Capitolina after himself and Jupiter Capitolinus, the chief Roman deity. According to Epiphanius, Hadrian appointed Aquila from Sinope in Pontus as "overseer of the work of building the city", seeing that Aquila was related to him by marriage. Hadrian is said to have placed the city's main Forum at the junction of the main Cardo and Decumanus Maximus, now the location for the (smaller) Muristan.
A tradition based on the "Historia Augusta" suggests that tensions grew higher when Hadrian abolished circumcision ("brit milah"), which he, a Hellenist, viewed as mutilation. However, one scholar, Peter Schäfer, maintains that there is no evidence for this claim, given the notoriously problematical nature of the "Historia Augusta" as a source, the "tomfoolery" shown by the writer in this particular relevant passage, and the fact that contemporary Roman legislation on "genital mutilation" seems to address the general issue of castration of slaves by their masters. Actually, Hadrian had issued a rescript with a blanket ban on castration, performed on freeman or slave, voluntarily or not, on pain of death for both the performer and the patient. Castration was legally put by Hadrian on a par with conspiracy to murder and accordingly punished on the terms of the "Lex Cornelia de Sicaris et Veneficis".
The notion of an "antisemitic" legislation by Hadrian is, therefore, possibly an anachronistic ("midrashic", in the words of a modern scholar) reading of ancient sources.
It is possible that other issues intervened between Hadrian's intention to rebuild Jerusalem and the outbreak of the war: the tension between incoming Roman colonists and supporters who had appropriated land confiscated after the First Jewish War and the landless poor, as well as the existence of messianic groups triggered by an interpretation of Jeremiah's prophecy promising that the Temple would be rebuilt seventy years after its destruction, repeating the timing of the restoration of the First Temple after the Babylonian exile – something that would put the restoration of the Second Temple to around 140.
Hadrian's anti-Jewish policies (or, alternatively, assimilation policies by means of cultural and political hellenization) triggered in Judaea a massive anti-Hellenistic and anti-Roman Jewish uprising, led by Simon bar Kokhba. Based on the delineation of years in Eusebius' "Chronicon" (now Chronicle of Jerome), it was only in the 16th year of Hadrian's reign, or what was equivalent to the 4th year of the 227th Olympiad, that the Jewish revolt began, under the Roman governor Tineius (Tynius) Rufus who had asked for an army to crush the resistance. Bar Kokhba, the leader of the resistance, punished any Jew who refused to join his ranks. According to Justin Martyr and Eusebius, that had to do mostly with Christian converts, who opposed bar Kokhba's messianic claims.
It was then that Hadrian called his general Sextus Julius Severus from Britain, and troops were brought from as far as the Danube. The Fifth Macedonian Legion and the Eleventh Claudian Legion also took part in war operations in Judea at the time. Roman losses were very heavy – as they were compared by Fronto to the casualties of the earlier British uprising – and it is believed that an entire legion, the XXII Deiotariana, which according to epigraphy did not outlast Hadrian's reign, was destroyed in the rebellion. Indeed, Roman losses were so heavy that Hadrian's report to the Roman Senate omitted the customary salutation, "If you and your children are in health, it is well; I and the legions are in health."
Hadrian's army eventually put down the rebellion in 135. According to Cassius Dio, overall war operations in the land of Judea left some 580,000 Jews killed, and 50 fortified towns and 985 villages razed to the ground. The most famous battle took place in Beitar, a fortified city 10 km. southwest of Jerusalem. The city only fell after a lengthy siege of three and a half years, at which time Hadrian prohibited the Jews from burying their dead. They were eventually afforded burial when Antoninus Pius succeeded Hadrian as Roman Emperor. According to the Babylonian Talmud, after the war Hadrian continued the persecution of Jews.
The rabbinical sources, however, seem more concerned with morals and religion than with conveying history; therefore, occasionally such writings are known to contain embellished accounts of the war and its aftermath, according to whom Hadrian attempted to root out Judaism – which he saw as the cause of continuous rebellions – prohibited the Torah law, the Hebrew calendar and executed Judaic scholars (see Ten Martyrs). The sacred scroll was ceremonially burned on the Temple Mount. In an attempt to erase the memory of Judaea, he renamed the province Syria Palaestina (after the Philistines; the name was found in Herodotus' histories), and Jews were barred from entering its rededicated capital. When Jewish sources mention Hadrian it is always with the epitaph "may his bones be crushed" (שחיק עצמות or שחיק טמיא, the Aramaic equivalent), an expression never used even with respect to Vespasian or Titus, who destroyed the Second Temple.
Other modern scholars contend that Hadrian's strictures on circumcision and his no-entry policy for Jews were poorly enforced, falling into abeyance with his death. Namely, Hadrian's legislation on castration was amended by Antoninus Pius in order to allow Jews to circumcise their own sons (Jewish proselytism among "male" converts remaining forbidden). In spite of the enslavement of Jewish war prisoners and of their suffering high war casualties and wanton destruction, it has been proposed that Palestine remained predominantly Jewish in population, as well as its culture and religious life, a fact reflected by the completion of the Mishnah in the early Third Century (220 CE). However, the Jerusalem Talmud, compiled in the 2nd and 3rd century CE, speaks of areas in Palestine that were at that time wholly supplanted by non-Jewish peoples, owing to the sparseness of its Jewish citizens. Jerusalem remained a special case, due to the fact that it was rebuilt as a purely Roman city – a circumstance of which later Christian authors like Eusebius took advantage in order to stress its character as a Christian city and worship center. Therefore, the extent of the punitive measures taken by Hadrian against the Jewish population remains a matter of continuing debate in present-day historiography.
What Hadrian's bloody repression of the revolt undoubtedly did accomplish was to put an end to any measure of Jewish political independence alongside the Roman Imperial order.
In Rabbinic literature.
Rabbinic literature is critical of Hadrian's policy, particularly that of religious intolerance concerning the Jews. Indeed, his policies were viewed as an attack on the religious freedom of the practice of Torah law. Most of the stories related by the Sages of Israel reflect a two-faced approach to tolerance of the Jewish people. In one story he punishes a Jew who failed to greet him, and then punishes another Jew who wished him well. When asked what the logic was for his punishing both men, he replied: "You wish to give me advice on how to kill my enemies?"
In another story, Hadrian got down from his chariot and bowed to a Jewish girl afflicted with leprosy. When queried by his soldiers as to why he did this, Hadrian responded with a dual verse from the book of Isaiah in praise of the nation of Israel: "So says God the redeemer of Israel to the downtrodden soul to the (made) repulsive nation, kings will view and stand."
The Malbim commentary to the book of Daniel comments how Hadrian erected a statue of himself at the site of the Bet HaMikdash on a day marking the anniversary of the Temple's destruction by Titus.
According to Jewish historical records of that time, the famous rabbi and scholar and a contemporary of Hadrian, Rabbi Yehoshua, the son of Hananiah, opposed any Jewish military intervention against the occupying Roman army, in spite of Rome's harsh decrees against the Jewish people. Rabbi Yehoshua is reported as saying: "A lion once pounced upon its prey and got a bone stuck in his throat. He then said, 'Whosoever comes and takes it out, I will give to him a reward.' An Egyptian heron came along whose bill is long, and reaching down into the lion's throat, extracted the bone. The bird then said to the lion, 'Give to me my reward.' The lion replied, 'Just be happy that you can say, I went down into the lion's mouth and I came out alive and well.' It is the same with us. It is enough that we have gone into this nation and came out with our lives."
Final years.
Succession.
Hadrian spent the final years of his life at Rome. In 134, he took an Imperial salutation for the end of the Second Jewish War (which was not actually concluded until the following year). In 136, he dedicated a new Temple of Venus and Roma on the former site of Nero's Golden House.
About this time, suffering from poor health, he turned to the problem of the succession. In 136 he adopted one of the ordinary consuls of that year, Lucius Ceionius Commodus, who took the name Lucius Aelius Caesar. He was the son-in-law of Gaius Avidius Nigrinus, one of the "four consulars" executed in 118, but was himself in delicate health. Also, his reputation was more that "of a voluptuous, well educated great lord than that of a leader". Already at the time, it was ventured that Aelius had as his only commendation his beauty, a piece of gossip that found its way into the "Historia Augusta" biography. Various modern attempts have been made to justify this apparently unjustified choice, one of them – advanced by the French historian Jerome Carcopino – being that Aelius was actually Hadrian's natural son. It has also been speculated that Hadrian was fully aware that Aelius would never outlive him, and that the adoption of an aristocrat scion with no blood ties to the Emperor was a belated attempt to make amends for the episode of the four consulars, therefore aiming at a reconciliation with the powerful clan of old Italian families in the Senate. Of the four consulars, Aelius' father-in-law Avidius Nigrinus had been Hadrian's chief rival for the throne, as a senator of highest rank, breeding, and connections, and as a Stoic. According to the "Historia Augusta", early in his reign Hadrian had even considered making Nigrinus his heir apparent, before eventually deciding to get rid of this worthy opponent.
Granted tribunician power and the joint governorship of Pannonia Superior and Pannonia Inferior – a commission that he discharged honorably, according to the "Historia Augusta" – Aelius Caesar held a further consulship in 137, but died on 1 January 138.
Following the death of Aelius Caesar, Hadrian next adopted Titus Aurelius Fulvus Boionius Arrius Antoninus (the future emperor Antoninus Pius), who had served as one of the five imperial legates of Italy (a post created by Hadrian) and as proconsul of Asia. On 25 February 138 Antoninus received tribunician power and imperium. Moreover, to ensure the future of the dynasty, Hadrian required Antoninus to adopt both Lucius Ceionius Commodus (son of the deceased Aelius Caesar) and Marcus Annius Verus (who was the grandson of an influential senator of the same name who had been Hadrian's close friend; Annius was already betrothed to Aelius Caesar’s daughter Ceionia Fabia). Hadrian's precise intentions in this arrangement are debatable.
Though the consensus is that he wanted Annius Verus (who would later become the Emperor Marcus Aurelius) to succeed Antoninus, it has also been argued that he actually intended Ceionius Commodus, the son of his own adopted son, to succeed, but was constrained to show favour simultaneously to Annius Verus because of his strong connections to the Hispano-Narbonensian nexus of senatorial families of which Hadrian himself was a part. As Annius Verus was the step-grandson of the then Prefect of Rome Lucius Catilius Severus, one of the remnants of the all-powerful group of Spanish senators from Trajan's reign, it was unavoidable that Hadrian should show some favor to the grandson in order to count on the grandfather's support. It is possible, according to one prosopography, that Catilius Severus was the third and last husband of Hadrian's mother, Domitia Lucilla "Major". As Lucilla Major's second husband, Publius Calvisius Ruso, was the father of Domitia Lucilla "Minor", Annius Verus' mother, Lucilla Minor, would actually be Hadrian's half-sister, and Annius Verus, therefore, his (half)nephew. In this case, in advancing Annius Verus, Hadrian would promote his own bloodline's fortunes. Note, however, that this prosopography is not universally accepted by other scholars, who argue that Hadrian's mother was known, according to "Historia Augusta", as Domitia "Paulina".
Alternatively, it may well not have been Hadrian, but rather Antoninus Pius – who was Annius Verus's uncle – who advanced the latter to the principal position. The fact that Annius would divorce Ceionia Fabia and remarry to Antoninus' daughter Annia Faustina points in the same direction. When he eventually became Emperor, Marcus Aurelius would co-opt Ceionius Commodus as his co-Emperor (under the name of Lucius Verus) on his own initiative. Also, there is the fact that Marcus Aurelius, when already emperor, behaved coldly towards the memory of his adoptive grandfather, who is conspicuously absent from the list of people to which Marcus acknowledged a debt of gratitude in his "Meditations". As emperor, Marcus would be far more attracted to the conservative, "serious", Roman outlook of Antoninus' reign than to Hadrian's more open, "lewd", "Hellenic" outlook – including Hadrian's almost exclusive homosexuality. It is noteworthy that Marcus Aurelius's relationship towards Antinous's memory was one of total silence.
The ancient sources present Hadrian's last few years as marked by conflict and unhappiness. The adoption of Aelius Caesar proved unpopular, not least with Hadrian's brother-in-law Lucius Julius Ursus Servianus and Servianus's grandson Gnaeus Pedanius Fuscus Salinator. Servianus, though now far too old, had stood in the line of succession at the beginning of the reign; Fuscus is said to have had designs on the imperial power for himself, and in 137 he may have attempted a coup in which his grandfather was implicated. Whatever the truth, Hadrian ordered that both be put to death. Servianus is reported to have prayed before his execution that Hadrian would "long for death but be unable to die". The prayer was fulfilled; as Hadrian suffered from his final, protracted illness, he had to be prevented from suicide on several occasions.
Death.
Hadrian died in the year 138 on the 10th of July, in his villa at Baiae at the age of 62. The cause of death is believed to have been heart failure. Dio Cassius and the "Historia Augusta" record details of his failing health.
He was buried first at Puteoli, near Baiae, on an estate that had once belonged to Cicero. Soon after, his remains were transferred to Rome and buried in the Gardens of Domitia, close by the almost-complete mausoleum. Upon completion of the Tomb of Hadrian in Rome in 139 by his successor Antoninus Pius, his body was cremated, and his ashes were placed there together with those of his wife Vibia Sabina and his first adopted son, Lucius Aelius, who also died in 138. After threatening the Senate – which toyed with refusing Hadrian's divine honors – by refusing to assume power himself, Antoninus eventually succeeded in having his predecessor deified in 139 and given a temple on the Campus Martius, ornamented with reliefs representing the provinces. The Senate in consequence agreed to give Antoninus the title Pius for his filial piety in granting his adoptive father honors. At the same time, in order to mark the Senate's illwill, commemorative coinage honoring Hadrian's consecration was kept to a minimum.
Poem by Hadrian.
According to the "Historia Augusta", Hadrian composed shortly before his death the following poem:
References.
Primary sources.
Inscriptions:

</doc>
