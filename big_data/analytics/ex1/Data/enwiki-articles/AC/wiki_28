<doc id="14240" url="https://en.wikipedia.org/wiki?curid=14240" title="Hawaiian language">
Hawaiian language

The Hawaiian language (Hawaiian: "", ) is a Polynesian language that takes its name from Hawaii, the largest island in the tropical North Pacific archipelago where it developed. Hawaiian, along with English, is an official language of the state of Hawaii. King Kamehameha III established the first Hawaiian-language constitution in 1839 and 1840.
For various reasons, including territorial legislation establishing English as the official language in schools, the number of native speakers of Hawaiian gradually decreased during the period from the 1830s to the 1950s. Hawaiian was essentially displaced by English on six of seven inhabited islands. In 2001, native speakers of Hawaiian amounted to under 0.1% of the statewide population. Linguists are worried about the fate of this and other endangered languages.
Nevertheless, from around 1949 to the present day, there has been a gradual increase in attention to and promotion of the language. Public Hawaiian-language immersion preschools called Pūnana Leo were started in 1984; other immersion schools followed soon after that. The first students to start in immersion preschool have now graduated from college and many are fluent Hawaiian speakers. The federal government has acknowledged this development. For example, the Hawaiian National Park Language Correction Act of 2000 changed the names of several national parks in Hawaii, observing the Hawaiian spelling.
A pidgin or creole language spoken in Hawaii is Hawaiian Pidgin (or Hawaii Creole English, HCE). It should not be mistaken for the Hawaiian language nor for a dialect of English.
The Hawaiian alphabet has 13 letters: five vowels (long and short) and eight consonants, one of them being a glottal stop (called "" in Hawaiian).
The Hawaiian language takes its name from the largest island, Hawaii ("Hawaii" in the Hawaiian language), in the tropical North Pacific archipelago where it developed, originally from a Polynesian language of the South Pacific, most likely Marquesan or Tahitian. The island name was first written in English in 1778 by British explorer James Cook and his crew members. They wrote it as "Owhyhee" or "Owhyee". Explorers Mortimer (1791) and Otto von Kotzebue (1821) used that spelling.
The initial "O" in the name is a reflection of the fact that unique identity is predicated in Hawaiian by using a copula form, "o", immediately before a proper noun. Thus, in Hawaiian, the name of the island is expressed by saying "O Hawaii", which means " is Hawaii." The Cook expedition also wrote "Otaheite" rather than "Tahiti."
The spelling "why" in the name reflects the pronunciation of "wh" in 18th-century English (still in active use in parts of the English-speaking world). "Why" was pronounced . The spelling "hee" or "ee" in the name represents the sounds , or .
Putting the parts together, "O-why-(h)ee" reflects , a reasonable approximation of the native pronunciation, .
American missionaries bound for Hawaii used the phrases "Owhihe Language" and "Owhyhee language" in Boston prior to their departure in October 1819 and during their five-month voyage to Hawai'i. They still used such phrases as late as March 1822. However, by July 1823, they had begun using the phrase "Hawaiian Language."
In Hawaiian, "Ōlelo Hawaii" means "Hawaiian language", as adjectives follow nouns.
Family and origin.
Hawaiian is a Polynesian member of the Austronesian language family. It is closely related to other Polynesian languages, such as Marquesan, Tahitian, Māori, Rapa Nui (the language of Easter Island), and less closely to Samoan and Tongan.
According to Schütz (1994), the Marquesans colonized the archipelago in roughly 300 AD followed by later waves of immigration from the Society Islands and Samoa-Tonga. Their languages, over time, became the Hawaiian language within the Hawaiian Islands. Kimura and Wilson (1983) also state, "Linguists agree that Hawaiian is closely related to Eastern Polynesian, with a particularly strong link in the Southern Marquesas, and a secondary link in Tahiti, which may be explained by voyaging between the Hawaiian and Society Islands."
Methods of proving Hawaiian's family relationships.
The genetic history of the Hawaiian language is demonstrated primarily through the application of lexicostatistics, which involves quantitative comparison of lexical cognates, and the comparative method.
Lexicostatistics is a way of quantifying the degree to which any given languages are genetically related to one another. It is mainly based on determining the number of cognates (genetically shared words) that the languages have in a fixed set of vocabulary items which are nearly universal among all languages. The so-called "basic vocabulary" (or Swadesh list) amounts to about 200 words, having meanings such as "eye", "hair", "blood", "water", and "and." The measurement of a genetic relationship is expressed as a percentage. For example, Hawaiian and English have 0 cognates in the 200-word list, so they are 0% genetically related. By contrast, Hawaiian and Tahitian have about 152 cognates in the list, so they are estimated as being 76% genetically related.
The comparative method is a technique developed by linguists to determine if two or more languages are genetically related, and if they are, the historical nature of the relationships. For a given meaning, the words of the languages are compared.
Linguists observe:
In this method, the definition of "identical" is reasonably clear, but those of "similar" and "dissimilar" are based on phonological criteria which may require professional training to fully understand and which can vary in the contexts of different languages. Basically, a sound's manner and place of articulation, and its phonological features, are the main factors considered in investigating its status as "similar" or "dissimilar" to other sounds in a particular context. For example, /b/ and /m/ are both voiced labial sounds, but one is a stop and the other a nasal. When linguists find in compared languages that compared words of the same or similar meaning contain sounds which correspond to one another, and find that these same sound correspondences recur regularly in most, or in many, of the comparable words of the languages, then the usual conclusion is that the languages are genetically related.
The following table provides a limited data set for ten numbers. The asterisk (*) is used to show that these are hypothetical, reconstructed forms. In the table, the year date of the modern forms is rounded off to CE 2000 to emphasize the 6000-year time lapse since the PAN era.
Note: For the number "10", the Tongan form in the table is part of the word ('ten'). The Hawaiian cognate is part of the word ('ten days'); however, the more common word for "10" used in counting and quantifying is , a different root.
Application of the lexicostatistical method to the data in the table will show the four languages to be related to one another, with Tagalog having 100% cognacy with PAN, while Hawaiian and Tongan have 100% cognacy with each other, but 90% with Tagalog and PAN. This is because the forms for each number are cognates, except the Hawaiian and Tongan words for the number "1", which are cognate with each other, but not with Tagalog and PAN. When the full set of 200 meanings is used, the percentages will be much lower. For example, Elbert found Hawaiian and Tongan to have 49% (98 ÷ 200) shared cognacy. This points out the importance of data-set size for this method – less data, cruder result; more data, better result.
Application of the comparative method will show partly different genetic relationships. It will point out sound changes, such as:
This method will recognize sound change #1 as a shared innovation of Hawaiian and Tongan. It will also take the Hawaiian and Tongan cognates for "1" as another shared innovation. Due to these exclusively shared features, Hawaiian and Tongan are found to be more closely related to one another than either is to Tagalog or PAN.
The forms in the table show that the Austronesian vowels tend to be relatively stable, while the consonants are relatively volatile. It is also apparent that the Hawaiian words for "3", "5" and "8" have remained essentially unchanged for 6000 years.
History.
First European contact.
In 1778, British explorer James Cook made the first reported European contact with Hawaii, beginning a new phase in the development of Hawaiian. During the next forty years, the sounds of Spanish (1789), Russian (1804), French (1816), and German (1816) arrived in Hawaii via other explorers and businessmen. Hawaiian began to be written for the first time, largely restricted to isolated names and words, and word lists collected by explorers and travelers.
The early explorers and merchants who first brought European languages to the Hawaiian islands also took on a few native crew members who brought the Hawaiian language into new territory. Although there were not enough of these Hawaiian-speaking explorers to establish any viable speech communities abroad, they still had a noticeable presence. One of them, a boy in his teens known as Obookiah ("Ōpūkahaia"), had a major impact on the future of the language. He sailed to New England, where he eventually became a student at the Foreign Mission School in Cornwall, Connecticut. He inspired New Englanders to support a Christian mission to Hawaii, and provided information on the Hawaiian language to the American missionaries there prior to their departure for Hawaii in 1819.
Written Hawaiian.
In 1820, Protestant missionaries from New England arrived in Hawaii, inspired by the presence of several young Hawaiian men, especially Obookiah ("Ōpūkahaia"), at the Foreign Mission School in Cornwall, Connecticut. The missionaries began to learn the Hawaiian language so that they could form relationships with the locals and publish a Hawaiian Bible. To that end, they developed a successful alphabet for Hawaiian by 1826, taught Hawaiians to read and write the language, published various educational materials in Hawaiian, and eventually finished translating the Bible. Missionaries also influenced King Kamehameha III to establish the first Hawaiian-language constitutions in 1839 and 1840.
Adelbert von Chamisso might have consulted with a native speaker of Hawaiian in Berlin, Germany, before publishing his grammar of Hawaiian ("") in 1837. When Hawaiian King David Kalākaua took a trip around the world, he brought his native language with him. When his wife, Queen Kapiolani, and his sister, Princess (later Queen) Liliuokalani, took a trip across North America and on to the British Islands, in 1887, Liliuokalani's composition "Aloha Oe" was already a famous song in the U.S.
In 1834, the first Hawaiian-language newspapers were published by missionaries working with locals. The missionaries also played a significant role in publishing a vocabulary (1836) grammar (1854) and dictionary (1865) of Hawaiian. Literacy in Hawaiian was widespread among the local population, especially ethnic Hawaiians. Use of the language among the general population might have peaked around 1881. Even so, some people worried, as early as 1854, that the language was "soon destined to extinction."
The increase in travel to and from Hawaii during the 19th century introduced a number of fatal illnesses such as smallpox, influenza, and leprosy, which killed large numbers of native speakers of Hawaiian. Meanwhile, native speakers of other languages, especially English, Chinese, Japanese, Portuguese, and Ilokano, continued to immigrate to Hawaii. As a result, the actual number, as well as the percentage, of native speakers of Hawaiian in the local population decreased sharply, and continued to fall throughout the nineteenth century.
As the status of Hawaiian dropped, the status of English in Hawaii rose. In 1885, the Prospectus of the Kamehameha Schools announced that "instruction will be given only in English language" (see published opinion of the United States Court of Appeals for the Ninth Circuit, Doe v. Kamehameha Schools, case no. 04-15044, page 8928, filed August 2, 2005). Around 1900, students began to be punished for speaking Hawaiian in schools, and the number of native speakers of Hawaiian diminished from 37,000 at the turn of the twentieth century to 1,000 in 1997; half of these remaining are now in their seventies or eighties (see Ethnologue report below for citations). Due to immersion programs the number of speakers has risen to 24,000 according to the 2011 US census.
There has been some controversy over the reasons for this decline. One school of thought claims that the most important cause for the decline of the Hawaiian language was its voluntary abandonment by the majority of its native speakers. According to Mary Kawena Pukui, they wanted their own children to speak English, as a way to promote their success in a rapidly changing modern environment, so they refrained from using Hawaiian with their own children. The Hawaiian language schools disappeared as their enrollments dropped: parents preferred English language schools. Another school of thought emphasizes the importance of other factors that discouraged the use of the language, such as the fact that the English language was made the only medium of instruction in all schools in 1896 and the fact that schools punished the use of Hawaiian (see ""Banning" of Hawaiian" below.) General prejudice against ethnic Hawaiians ("kanaka") has also been blamed for the decline of the language.
A new dictionary was published in 1957, a new grammar in 1979, and new second-language textbooks in 1951, 1965, 1977, and 1989. Master's theses and doctoral dissertations on specific facets of Hawaiian appeared in 1951, 1975, 1976, and 1996.
"" or hidden meaning.
According to Mary Kawena Pukui and Samuel Elbert, ' (') is a "Hidden meaning, as in Hawaiian poetry; concealed reference, as to a person, thing, or place; words with double meanings that might bring good or bad fortune." Pukui lamented, “in spite of years of dedicated work, it is impossible to record any language completely. How true this seems for Hawaiian, with its rich and varied background, its many idioms heretofore undescribed, and its ingenious and sophisticated use of figurative language.” On page xiii of the 1986 dictionary she warned: "Hawaiian has more words with multiple meanings than almost any other language. One wishing to name a child, a house, a T-shirt, or a painting, should be careful that the chosen name does not have a naughty or vulgar meaning. The name of a justly respectable children's school, Hana Hauoli, means happy activity and suggests a missionary author, but among older Hawaiians it has another, less 'innocent' meaning that should not concern little children. A Honolulu street (and formerly the name of a hotel) is Hale Lea 'joyous house', but lea also means orgasm."
Understanding the kaona of the language requires a comprehensive knowledge of Hawaiian legends, history and cosmology.
"Banning" of Hawaiian.
The law cited as banning the Hawaiian language is identified as Act 57, sec. 30 of the 1896 Laws of the Republic of Hawaii:
The English Language shall be the medium and basis of instruction in all public and private schools, provided that where it is desired that another language shall be taught in addition to the English language, such instruction may be authorized by the Department, either by its rules, the curriculum of the school, or by direct order in any particular instance. Any schools that shall not conform to the provisions of this section shall not be recognized by the Department. June 8, 1896 Sanford B. Dole, President of the Republic of Hawaii 
This law established English as the medium of instruction for the government-recognized schools both "public and private". While it did not ban or make illegal the Hawaiian language in other contexts, its implementation in the schools had far reaching effects. Those who had been pushing for English-only schools took this law as licence to extinguish the native language at the early education level. While the law stopped short of making Hawaiian illegal (it was still the dominant language spoken at the time), many children who spoke Hawaiian at school, including on the playground, were disciplined. This included corporal punishment and going to the home of the offending child to strongly advise them to stop speaking it in their home. Moreover, the law specifically provided for teaching languages "in addition to the English language," reducing Hawaiian to the status of a foreign language, subject to approval by the Department. Hawaiian was not taught initially in any school, including the all-Hawaiian Kamehameha Schools. This is largely because when these schools were founded, like Kamehameha Schools founded in 1887 (nine years before this law), Hawaiian was being spoken in the home. Once this law was enacted, individuals at these institutions took it upon themselves to enforce a ban on Hawaiian. Beginning in 1900, Mary Kawena Pukui, who was later the co-author of the Hawaiian–English Dictionary, was punished for speaking Hawaiian by being rapped on the forehead, allowed to eat only bread and water for lunch, and denied home visits on holidays. Winona Beamer was expelled from Kamehameha Schools in 1937 for chanting Hawaiian.
Hawaiian-language newspapers were published for over a hundred years, through the period of the suppression. Very few pro-Hawaiian papers made it through the period of the overthrow of the kingdom and the subsequent Act 57. Most papers that survived that period had a distinctly pro-U.S.Annexation perspective. list fourteen Hawaiian newspapers. According to them, the newspapers entitled "Ka Lama Hawaii" and "Ke Kumu Hawaii" began publishing in 1834, and the one called "Ka Hoku o Hawaii" ceased publication in 1948. The longest run was that of "Ka Nupepa Kuokoa": about 66 years, from 1861 to 1927.
1949 to present.
In 1949, the legislature of the Territory of Hawaii commissioned Mary Pukui and Samuel Elbert to write a new dictionary of Hawaiian, either revising the Andrews-Parker work or starting from scratch. Pukui and Elbert took a middle course, using what they could from the Andrews dictionary, but making certain improvements and additions that were more significant than a minor revision. The dictionary they produced, in 1957, introduced an era of gradual increase in attention to the language and culture.
Efforts to promote the language have increased in recent decades. Hawaiian-language "immersion" schools are now open to children whose families want to reintroduce Hawaiian language for future generations. The Aha Pūnana Leo’s Hawaiian language preschools in Hilo, Hawaii, have received international recognition. The local National Public Radio station features a short segment titled "Hawaiian word of the day" and a Hawaiian language news broadcast. Honolulu television station KGMB ran a weekly Hawaiian language program, "Āhai Ōlelo Ola", as recently as 2010. Additionally, the Sunday editions of the "Honolulu Star-Advertiser", the largest newspaper in Hawaii, feature a brief article called "Kauakukalahale" written entirely in Hawaiian by teachers, students, and community members.
Today, on six of the seven permanently inhabited islands, Hawaiian has been largely displaced by English. The number of native speakers of Hawaiian, which was under 0.1% of the statewide population in 1997, has risen to 2,000, out of 24,000 total who are fluent in the language, according to the US 2011 census. Native speakers of Hawaiian who live on the island named "Niihau" have remained fairly isolated and have continued to use Hawaiian almost exclusively.
Niihau.
Niihau is the only area in the world where Hawaiian is the first language and English is a foreign language. Because of many sufficiently marked variations, Niihau people, when visiting or living in Honolulu, substitute the Oahu dialect for their own – apparently easy to do – saying that otherwise people in Honolulu have trouble understanding them. Niihau people speak very rapidly; many vowels and entire syllables are dropped or whispered.
The isolated island of Niihau, located off the southwest coast of Kauai, is the one island where Hawaiian is still spoken as the language of daily life. Children are taught Hawaiian as a first language, and learn English at about age eight. Reasons for the language's predominance on this island include:
Native speakers of Niihau Hawaiian have three distinct modes of speaking Hawaiian:
The last mode of speaking may be further restricted to a certain subset of Niihauans, and is rarely even overheard by non- Niihauans. In addition to being able to speak Hawaiian in different ways, most Niihauans can speak English as well.
Orthography.
Hawaiians had no written language prior to western contact, except for petroglyph symbols.
The modern Hawaiian alphabet, "ka pīāpā Hawaii", is based on the Latin script. Hawaiian words end "only" in vowels, and every consonant must be followed by a vowel. The Hawaiian alphabetical order has all of the vowels before the consonants, as in the following chart.
Origin.
This writing system was developed by American Protestant missionaries during 1820–1826. It was the first thing they ever printed in Hawaii, on January 7, 1822, and it originally included the consonants "B, D, R, T," and "V," in addition to the current ones ("H, K, L, M, N, P, W"), and it had "F, G, S, Y" and "Z" for "spelling foreign words". The initial printing also showed the five vowel letters ("A, E, I, O, U") and seven of the short diphthongs ("AE, AI, AO, AU, EI, EU, OU").
In 1826, the developers voted to eliminate some of the letters which represented functionally redundant allophones (called "interchangeable letters"), enabling the Hawaiian alphabet to approach the ideal state of one-symbol-one-phoneme, and thereby optimizing the ease with which people could teach and learn the reading and writing of Hawaiian. For example, instead of spelling one and the same word as "pule, bule, pure," and "bure" (because of interchangeable "p/b" and "l/r"), the word is spelled only as "pule".
However, hundreds of words were very rapidly borrowed into Hawaiian from English, Greek, Hebrew, Latin, and Syriac. Although these loan words were necessarily Hawaiianized, they often retained some of their "non-Hawaiian letters" in their published forms. For example, "Brazil" fully Hawaiianized is "Palakila", but retaining "foreign letters" it is "Barazila". Another example is "Gibraltar", written as "Kipalaleka" or "Gibaraleta". While and are not regarded as Hawaiian sounds, , , and were represented in the original alphabet, so the letters ("b", "r", and "t") for the latter are not truly "non-Hawaiian" or "foreign", even though their post-1826 use in published matter generally marked words of foreign origin.
Glottal stop.
"ʻOkina" ("oki" 'cut' + "-na" '-ing') is the modern Hawaiian name for the symbol (a letter) that represents the glottal stop. It was formerly known as "uina" ('snap').
For examples of the okina, consider the Hawaiian words "Hawaii" and "Oahu" (often simply "Hawaii" and "Oahu" in English orthography). In Hawaiian, these words can be pronounced and , and can be written with an okina where the glottal stop is pronounced.
History.
As early as 1823, the missionaries made some limited use of the apostrophe to represent the glottal stop, but they did not make it a letter of the alphabet. In publishing the Hawaiian Bible, they used it to distinguish "kou" ('my') from "kou" ('your'). In 1864, William DeWitt Alexander published a grammar of Hawaiian in which he made it clear that the glottal stop (calling it "guttural break") is definitely a true consonant of the Hawaiian language. He wrote it using an apostrophe. In 1922, the Andrews-Parker dictionary of Hawaiian made limited use of the opening single quote symbol, called "reversed apostrophe" or "inverse comma", to represent the glottal stop. Subsequent dictionaries have preferred to use that symbol. Today, many native speakers of Hawaiian do not bother, in general, to write any symbol for the glottal stop. Its use is advocated mainly among students and teachers of Hawaiian as a second language, and among linguists.
Electronic encoding.
The okina is written in various ways for electronic uses:
Because many people who want to write the ʻokina are not familiar with these specific characters and/or do not have access to the appropriate fonts and input and display systems, it is sometimes written with more familiar and readily available characters:
Macron.
A modern Hawaiian name for the macron symbol is "kahakō" ("kaha" 'mark' + "kō" 'long'). It was formerly known as "mekona" (Hawaiianization of "macron"). It can be written as a diacritical mark which looks like a hyphen or dash written above a vowel, i.e., "ā ē ī ō ū" and "Ā Ē Ī Ō Ū". It is used to show that the marked vowel is a "double", or "geminate", or "long" vowel, in phonemic terms. (See: Vowel length)
As early as 1821, at least one of the missionaries, Hiram Bingham, was using macrons (and breves) in making handwritten transcriptions of Hawaiian vowels. The missionaries specifically requested their sponsor in Boston to send them some type (fonts) with accented vowel characters, including vowels with macrons, but the sponsor made only one response and sent the wrong font size (pica instead of small pica). Thus, they could not print ā, ē, ī, ō, nor ū (at the right size), even though they wanted to.
Pronunciation.
Due to extensive allophony, Hawaiian has more than 13 phones. Although vowel length is phonemic, long vowels are not always pronounced as such, even though under the rules for assigning stress in Hawaiian, a long vowel will always receive stress.
Phonology.
Consonants.
Hawaiian is known for having very few consonant phonemes – eight: . It is notable that Hawaiian has allophonic variation of with , with , and (in some dialects) with . The – variation is quite unusual among the world's languages (although related to how hard and soft C developed in many European languages), and is likely a product both of the small number of consonants in Hawaiian, and the recent shift of historical *t to modern –, after historical *k had shifted to . In some dialects, remains as in some words. These variations are largely free, though there are conditioning factors. tends to especially in words with both and , such as in the island name "Lānai" (–), though this is not always the case: "eleele" or "eneene" "black". The allophone is almost universal at the beginnings of words, whereas is most common before the vowel . is also the norm after and , whereas is usual after and . After and initially, however, and are in free variation.
Vowels.
Hawaiian has five short and five long vowels, plus diphthongs.
Monophthongs.
Hawaiian has five pure vowels. The short vowels are , and the long vowels, if they are considered separate phonemes rather than simply sequences of like vowels, are . When stressed, short and tend to become and , while when unstressed they are and . also tends to become next to , , and another , as in "Pele" . Some grammatical particles vary between short and long vowels. These include "a" and "o" "of", "ma" "at", "na" and "no" "for". Between a back vowel or and a following non-back vowel (), there is an epenthetic , which is generally not written. Between a front vowel or and a following non-front vowel (), there is an epenthetic (a "y" sound), which is never written.
Diphthongs.
The short-vowel diphthongs are . In all except perhaps , these are falling diphthongs. However, they are not as tightly bound as the diphthongs of English, and may be considered vowel sequences. (The second vowel in such sequences may receive the stress, but in such cases it is not counted as a diphthong.) In fast speech, tends to and tends to , conflating these diphthongs with and .
There are only a limited number of vowels which may follow long vowels, and some authors treat these as diphthongs as well: .
Phonotactics.
Hawaiian syllable structure is (C)V. All CV syllables occur except for "wū"; "wu" occurs only in two words borrowed from English. As shown by Schütz, Hawaiian word-stress is predictable in words of one to four syllables, but not in words of five or more syllables. Hawaiian phonological processes include palatalization and deletion of consonants, as well as raising, diphthongization, deletion, and compensatory lengthening of vowels. Phonological reduction (or "decay") of consonant phonemes during the historical development of the language has resulted in the phonemic glottal stop. Ultimate loss (deletion) of intervocalic consonant phonemes has resulted in Hawaiian long vowels and diphthongs.
Grammar.
Hawaiian is an analytic language with verb–subject–object word order. While there is no use of inflection for verbs, in Hawaiian, like other Austronesian personal pronouns, declension is found in the differentiation between a- and o-class genitive case personal pronouns in order to indicate inalienable possession in a binary possessive class system. Also like many Austronesian languages, Hawaiian pronouns employ separate words for inclusive and exclusive we (clusivity), and distinguish singular, dual, and plural. The grammatical function of verbs is marked by adjacent particles (short words) and by their relative positions, that indicate tense–aspect–mood.
Some examples of verb phrase patterns:
Nouns can be marked with articles:
"ka" and "ke" are singular definite articles. "ke" is used before words beginning with a-, e-, o- and k-, and with some words beginning - and p-. "ka" is used in all other cases. "nā" is the plural definite article.
To show part of a group, the word "kekahi" is used. To show a bigger part, you would insert "mau" to pluralize the subject.
Examples:

</doc>
<doc id="14245" url="https://en.wikipedia.org/wiki?curid=14245" title="Second Polish Republic">
Second Polish Republic

The Second Polish Republic, also known as the Second Commonwealth of Poland or interwar Poland, refers to the country of Poland between the First and Second World Wars (1918–1939). Officially known as the Republic of Poland or the Commonwealth of Poland (), the Polish state was recreated in 1918, in the aftermath of World War I. When, after several regional conflicts, the borders of the state were fixed in 1922, Poland's neighbours were Czechoslovakia, Germany, the Free City of Danzig, Lithuania, Latvia, Romania and the Soviet Union. It had access to the Baltic Sea via a short strip of coastline either side of the city of Gdynia. Between March and August 1939, Poland also shared a border with the then-Hungarian province of Carpathian Ruthenia. Despite internal and external pressures, it continued to exist until 1939, when Poland was invaded by Nazi Germany, the Soviet Union and the Slovak Republic, marking the beginning of World War II in Europe. The Second Republic was significantly different in territory to the current Polish state. It included substantially more territory in the east and less in the west.
The Second Republic's land area was 388,634 km2, making it, in October 1938, the sixth largest country in Europe. After the annexation of Zaolzie, this grew to 389,720 km2. According to the 1921 census, the number of inhabitants was 27.2 million. By 1939, just before the outbreak of World War II, this had grown to an estimated 35.1 million. Almost a third of population came from minority groups: 13.9% Ukrainians; 10% Jews; 3.1% Belarusians; 2.3% Germans and 3.4% percent Czechs, Lithuanians and Russians. At the same time, a significant number of ethnic Poles lived outside the country borders, many in the Soviet Union. The Republic endured and expanded, despite a variety of difficulties in the aftermath of World War I, including conflicts with the Ukrainians, Czechoslovakia, Lithuania, Soviet Russia and Soviet Ukraine; the Weimar Republic over Greater Poland, and Upper Silesia; and in spite of increasing hostility from Nazi Germany.
Poland maintained a slow (see: trade embargo) but steady level of economic development. The cultural hubs of interwar PolandWarsaw, Kraków, Poznań, Wilno and Lwówbecame major European cities and the sites of internationally acclaimed universities and other institutions of higher education. By 1939, the Republic had become "one of Europe's major powers".
History.
After more than a century of foreign partitions by the forces of Austria-Hungary, the German, and the Russian Empires, Poland re-emerged at the end of the First World War in Europe. The rebirth of Poland was one of the great stories of the Paris Peace Conference, confirmed by the victorious powers through the Treaty of Versailles of June 1919. Poland's independence was achieved in a series of border wars fought by the newly formed Polish Army from 1918 to 1921. The eastern half of the interwar territory of Poland was settled in 1922 and internationally recognized by the League of Nations.
In the course of World War One, Germany gained dominance on the Eastern Front of World War I as the tsarist Russians fell back. German and Austro-Hungarian armies seized the Russian-ruled part of what became Poland. In a failed attempt to resolve the Polish question as quickly as possible, Berlin set up a German puppet state on 5 November 1916, with a governing Council of State and (from 15 October 1917) a Regency Council ("Rada Regencyjna Królestwa Polskiego"). The Council administered the country under German auspices (see also Mitteleuropa), pending the election of a king. A month before Germany surrendered on 7 October 1918 and ended the war, the Regency Council dissolved the Council of State, and announced its intention to restore Polish independence. With the notable exception of the Marxist-oriented Social Democratic Party of the Kingdom of Poland and Lithuania ("SDKPiL"), most political parties supported this move. On 23 October the Council appointed a new government under Józef Świeżyński and began conscription into the Polish Army.
Formation of the Republic.
During 1918-1919, over 100 workers' councils sprang up on Polish territories; on 5 November 1918, in Lublin, the first Soviet of Delegates was created. On 6 November, the Communists announced the creation of the Republic of Tarnobrzeg. The same day, a Provisional People's Government of the Republic of Poland was created in Lublin under the Socialist, Ignacy Daszyński. On Sunday, 10 November at 7 a.m., Józef Piłsudski, newly freed from 16-month imprisonment by the German authorities at Magdeburg, returned by train to Warsaw. Piłsudski, together with Colonel Kazimierz Sosnkowski, was greeted at Warsaw's rail station by Regent Zdzisław Lubomirski and Colonel Adam Koc. Next day, due to his popularity and support from most political parties, the Regency Council appointed Piłsudski Commander in Chief of the Polish Armed Forces. On 14 November, the Council dissolved itself and transferred all its authority to Piłsudski as Chief of State ("Naczelnik Państwa"). After consultation with Piłsudski, Daszyński's government dissolved itself and a new government was created under Jędrzej Moraczewski. In 1918, Italy was the first country in Europe to recognise Poland's sovereignty.
Centers of government that were at that time created in Galicia (formerly Austrian-ruled southern Poland) included National Council of the Principality of Cieszyn (created in November 1918), Republic of Zakopane and Polish Liquidation Committee (created on 28 October). Soon afterward, a conflict broke out in Lwów between forces of the Military Committee of Ukrainians, and the Polish irregular units made up of students known as the Lwów Eaglets, who were later supported by the Polish Army (see Battle of Lwów (1918), Battle of Przemyśl (1918)). Meanwhile, in western Poland, another war of national liberation began under the banner of the Greater Poland Uprising (1918–19). In January 1919, Czechoslovakian forces attacked Polish units in the area of Zaolzie (see Polish–Czechoslovak War). Soon afterwards, the Polish–Lithuanian War began, and in August 1919, Polish-speaking residents of Upper Silesia initiated a series of three Silesian Uprisings. The most important military conflict of that period, however, was the Polish–Soviet War, which ended in a decisive Polish victory. In 1919, the Republic of Tarnobrzeg and the workers' councils were suppressed by the government.
German-Soviet invasion of 1939.
The beginning of the Second World War put an end to the sovereign Second Polish Republic. The Invasion of Poland began 1 September 1939, one week after the signing of the secret Molotov–Ribbentrop Pact. On that day, Poland was attacked by Nazi Germany and Slovakia, and on 17 September, the Soviets attacked eastern Poland. Warsaw fell to the Nazis on 28 September after a twenty-day siege. Organized Polish resistance ended on 6 October 1939 after the Battle of Kock, with Germany and the Soviet Union occupying most of the country. The area of Wilno was annexed by Lithuania, and areas along southern border were seized by Slovakia including Górna Orawa and Tatranská Javorina which Poland had annexed from Czechoslovakia in October 1938. Poland did not surrender, but continued fighting as the Polish government-in-exile and the Polish Underground State. After signing the German–Soviet Treaty of Friendship, Cooperation and Demarcation, Polish areas occupied by Nazi Germany were either directly annexed to the Third Reich, or became part of the so-called General Government. The Soviet Union, following rigged Elections to the People's Assemblies of Western Ukraine and Western Belarus, annexed eastern Poland either to Byelorussian Soviet Socialist Republic, or Ukrainian Soviet Socialist Republic.
Between 1939 and 1990, the Polish government-in-exile operated in Paris and later London, maintaining that it was the only legal and legitimate representative of the Polish nation. In 1990, the last president in exile, Ryszard Kaczorowski handed the insignia to Lech Wałęsa, signifying continuity between the Second and Third republics.
Politics and government.
The Second Polish Republic was a parliamentary democracy from 1919 (see Small Constitution of 1919) to 1926, with the President having limited powers. The Parliament elected him, and he could appoint the Prime Minister as well as the government with the Sejm's (lower house's) approval, but he could only dissolve the Sejm with the Senate's consent. Moreover, his power to pass decrees was limited by the requirement that the Prime Minister and the appropriate other Minister had to verify his decrees with their signatures. Poland was one of the first countries in the world to recognize women's suffrage. Women in Poland were granted the right to vote on 28 November 1918 by a decree of Józef Piłsudski.
The major political parties at this time were the Polish Socialist Party, National Democrats, various Peasant Parties, Christian Democrats, and political groups of ethnic minorities (German: German Social Democratic Party of Poland, Jewish: General Jewish Labour Bund in Poland, United Jewish Socialist Workers Party, and Ukrainian: Ukrainian National Democratic Alliance). Frequently changing governments (see Polish legislative election, 1919, Polish legislative election, 1922) and other negative publicity the politicians received (such as accusations of corruption or 1919 Polish coup attempt), made them increasingly unpopular. Major politicians at this time, in addition to Piłsudski, included peasant activist Wincenty Witos (Prime Minister three times) and right-wing leader Roman Dmowski. Ethnic minorities were represented in the Sejm; e.g. in 1928 – 1930 there was the Ukrainian-Belarusian Club, with 26 Ukrainian and 4 Belarusian members.
After the Polish – Soviet war, Marshal Piłsudski led an intentionally modest life, writing historical books for a living. After he took power by a military coup in May 1926, he emphasized that he wanted to heal the Polish society and politics of excessive partisan politics. His regime, accordingly, was called Sanacja in Polish. The 1928 parliamentary elections were still considered free and fair, although the pro-Piłsudski Nonpartisan Bloc for Cooperation with the Government won them. The following three parliamentary elections (in 1930, 1935 and 1938) were manipulated, with opposition activists sent to Bereza Kartuska prison (see also Brest trials). As a result, pro-government party Camp of National Unity won huge majorities in them. Piłsudski died just after an authoritarian constitution was approved in the spring of 1935. During the last four years of the Second Polish Republic, the major politicians included President Ignacy Mościcki, Foreign Minister Józef Beck and the Commander-in-Chief of the Polish Army, Edward Rydz-Śmigły. The country was divided into 104 electoral districts, and those politicians who were forced to leave Poland, founded Front Morges in 1936. The government that ruled Second Polish Republic in its final years is frequently referred to as Piłsudski's colonels.
Military.
"Main articles: Polish armaments 1939–45 Polish army order of battle in 1939"
Prior to the 1939 invasion, Poland had a considerably large army of 283,000 soldiers on active duty: in 37 infantry divisions, 11 cavalry brigades, and two armored brigades, plus artillery units. Another 700,000 men served in the reserves. At the outbreak of the war, the Polish army was able to put in the field almost one million soldiers, 2,800 guns, 500 tanks and 400 aircraft.
The training of the Polish army was thorough. The N.C.O.s were a competent body of men with expert knowledge and high ideals. The officers, both senior and junior, constantly refreshed their training in the field and in the lecture-hall, where modern technical achievement and the lessons of contemporary wars were demonstrated and discussed. The equipment of the Polish army was less developed technically than that of the enemy and its rearmament was slowed down by a recrudescence of optimism in western Europe and the usual budget difficulties.
Sadly, war plans (Plan West and Plan East) failed as soon as Germany invaded in 1939, Polish losses in combat against Germans (killed and missing in action) amounted to ca. 70,000. 420,000 were taken prisoners. Losses against the Red Army (which invaded Poland on 17 September) added up to 6,000 to 7,000 of casualties and MIA, 250,000 were taken prisoners. Although the Polish army – considering the inactivity of the Allies – was in an unfavorable position – it managed to inflict serious losses to the enemies: 14,000 German soldiers were killed or MIA, 674 tanks and 319 armored vehicles destroyed or badly damaged, 230 aircraft shot down; the Red Army lost (killed and MIA) about 2,500 soldiers, 150 combat vehicles and 20 aircraft. The Soviet invasion of Poland, and lack of promised aid from the Western Allies, contributed to the Polish forces defeat by 6 October 1939.
Economy.
After regaining its independence, Poland was faced with major economic difficulties. In addition to the devastation wrought by World War I, the exploitation of the Polish economy by the German and Russian occupying powers, and the sabotage performed by retreating armies, the new republic was faced with the task of economically unifying desperate economic regions, which had previously been part of different countries. Within the borders of the Republic were the remnants of three different economic systems, with five different currencies (the German mark, the Russian ruble, the Austrian crown, the Polish marka and the Ostrubel) and with little or no direct infrastructural links. The situation was so bad that neighboring industrial centers as well as major cities lacked direct railroad links, because they had been parts of different nations. For example, there was no direct railroad connection between Warsaw and Kraków until 1934. This situation was described by Melchior Wańkowicz in his book Sztafeta.
On top of this was the massive destruction left after both World War I and the Polish–Soviet War. There was also a great economic disparity between the eastern (commonly called "Poland B") and western (called "Poland A") parts of the country, with the western half, especially areas that had belonged to the German Empire being much more developed and prosperous. Frequent border closures and a customs war with Germany also had negative economic impacts on Poland. In 1924 Prime Minister and Economic Minister Władysław Grabski introduced the złoty as a single common currency for Poland (it replaced the Polish marka), which remained a stable currency. The currency helped Poland to control the massive hyperinflation. It was the only country in Europe able to do this without foreign loans or aid. The average annual growth rate (GDP per capita) was 5.24% in 1920–29 and 0.34% in 1929–38.
Hostile relations with neighbours were a major problem for the economy of interbellum Poland. In the year 1937, foreign trade with all neighbours amounted to only 21% of Poland's total. Trade with Germany, Poland's most important neighbour, accounted for 14.3% of Polish exchange. Foreign trade with the Soviet Union (0.8%) was virtually nonexistent. Czechoslovakia accounted for 3.9%, Latvia for 0.3%, and Romania for 0.8%. By mid-1938, after the Anschluss of Austria, Greater Germany was responsible for as much as 23% of Polish foreign trade.
The basis of Poland's gradual recovery after the Great Depression was its mass economic development plans (see Four Year Plan), which oversaw the building of three key infrastructural elements. The first was the establishment of the Gdynia seaport, which allowed Poland to completely bypass Gdańsk (which was under heavy German pressure to boycott Polish coal exports). The second was construction of the 500-kilometer rail connection between Upper Silesia and Gdynia, called Polish Coal Trunk-Line, which served freight trains with coal. The third was the creation of a central industrial district, named "COP – Central Industrial Region" (Centralny Okręg Przemysłowy). Unfortunately, these developments were interrupted and largely destroyed by the German and Soviet invasion and the start of World War II. Other achievements of interbellum Poland included Stalowa Wola (a brand new city, built in a forest around a steel mill), Mościce (now a district of Tarnów, with a large nitrate factory), and the creation of a central bank. There were several trade fairs, with the most popular being Poznań International Fair, Lwów's Targi Wschodnie, and Wilno's Targi Północne. Polish Radio had ten stations (see Radio stations in interwar Poland), with the eleventh one planned to be opened in the autumn of 1939. Furthermore, in 1935 Polish engineers began working on the TV services. By early 1939, experts of the Polish Radio built four TV sets. The first movie broadcast by experimental Polish TV was Barbara Radziwiłłówna, and by 1940, regular TV service was scheduled to begin operation.
Interbellum Poland was also a country with numerous social problems. Unemployment was high, and poverty was widespread, which resulted in several cases of social unrest, such as the 1923 Kraków riot, and 1937 peasant strike in Poland. There were conflicts with national minorities, such as Pacification of Ukrainians in Eastern Galicia (1930), relations with Polish neighbors were sometimes complicated (see Soviet raid on Stołpce, Polish–Czechoslovak border conflicts, 1938 Polish ultimatum to Lithuania). On top of this, there were natural disasters, such as 1934 flood in Poland.
Major industrial centers.
Interbellum, Poland was unofficially divided into two parts – better developed "Poland A" in the west, and underdeveloped "Poland B" in the east. Polish industry was concentrated in the west, mostly in Polish Upper Silesia, and the adjacent Lesser Poland's province of Zagłębie Dąbrowskie, where the bulk of coal mines and steel plants was located. Furthermore, heavy industry plants were located in Częstochowa ("Huta Częstochowa", founded in 1896), Ostrowiec Świętokrzyski ("Huta Ostrowiec", founded in 1837–1839), Stalowa Wola (brand new industrial city, which was built from scratch in 1937 – 1938), Chrzanów ("Fablok", founded in 1919), Jaworzno, Trzebinia (oil refinery, opened in 1895), Łódź (the seat of Polish textile industry), Poznań (H. Cegielski – Poznań), Kraków and Warsaw (Ursus Factory). Further east, in Kresy, industrial centers were scarce, and limited to two major cities of the region – Lwów and Wilno (Elektrit). Besides coal mining, Poland also had deposits of oil in Borysław, Drohobycz, Jasło and Gorlice (see Polmin), potassium salt (TESP), and basalt (Janowa Dolina). Apart from already-existing industrial areas, in the mid-1930s, an ambitious, state-sponsored project of Central Industrial Region was started under Minister Eugeniusz Kwiatkowski. One of characteristic features of Polish economy in the interbellum was gradual nationalization of major plants. This was the case of Ursus Factory (see Państwowe Zakłady Inżynieryjne), and several steelworks, such as "Huta Pokój" in Ruda Śląska – Nowy Bytom, "Huta Królewska" in Chorzów – Królewska Huta, "Huta Laura" in Siemianowice Śląskie, as well as "Scheibler and Grohman Works" in Łódź.
Transport.
According to the 1939 Statistical Yearbook of Poland, total length of railways of Poland (as for 31 December 1937) was 20 118 kilometers. Rail density was 5.2 km. per 100 km2. Railways were very dense in western part of the country, while in the east, especially Polesie, rail was non-existent in some counties. During the interbellum period, the Polish government constructed several new lines, mainly in the central part of the country (see also Polish State Railroads Summer 1939). Construction of extensive Warszawa Główna railway station was never finished due to the war, and Polish railroads were famous for their punctuality (see Luxtorpeda, Strzała Bałtyku, Latający Wilnianin).
In the interbellum, road network of Poland was dense, but the quality of the roads was very poor – only 7% of all roads was paved and ready for automobile use, and none of the major cities were connected with each other by a good-quality highway. In the mid-1930s, Poland had 340,000 kilometers of roads, but only 58,000 had hard surface (gravel, cobblestone or sett), and 2,500 were modern, with asphalt or concrete surface. In different parts of the country, there were sections of paved roads, which suddenly ended, and were followed by dirt roads. The poor condition of the roads was the result of both long-lasting foreign dominance and inadequate funding. On 29 January 1931, the Polish Parliament created the State Road Fund, the purpose of which was to collect money for the construction and conservation of roads. The government drafted a 10-year plan, with road priorities: a highway from Wilno, through Warsaw and Cracow, to Zakopane (called Marshall Pilsudski Highway), asphalt highways from Warsaw to Poznań and Łódź, as well as a Warsaw ring road. However, the plan turned out to be too ambitious, with insufficient money in the national budget to pay for it. In January 1938, the Polish Road Congress estimated that Poland would need to spend three times as much money on roads to keep up with Western Europe.
In 1939, before the outbreak of the war, LOT Polish Airlines, which was established in 1929, had its hub at Warsaw Okęcie Airport. At that time, LOT maintained several services, both domestic and international. Warsaw had regular domestic connections with Gdynia-Rumia, Danzig-Langfuhr, Katowice-Muchowiec, Kraków-Rakowice-Czyżyny, Lwów-Skniłów, Poznań-Ławica, and Wilno-Porubanek. Furthermore, in cooperation with Air France, LARES, Lufthansa, and Malert, international connections were maintained with Athens, Beirut, Berlin, Bucharest, Budapest, Helsinki, Kaunas, London, Paris, Prague, Riga, Rome, Tallinn, and Zagreb.
Agriculture.
In the Second Polish Republic, the majority of inhabitants lived in the countryside (75% in 1921), and their existence depended on land. Farmers made up 65% of the population, while about 1% were landowners. In 1929, agricultural production made up 65% of Poland's GNP. After 123 years of partitions, regions of the country were very unevenly developed. Lands of former German Empire were most advanced; in Greater Poland and Pomerelia, crops were on Western European level. The situation was much worse in former Congress Poland, Kresy, and former Galicia, where agriculture was most backward and primitive, with a large number of small farms, unable to succeed in either the domestic and international market. Another problem was the overpopulation of the countryside, which resulted in chronic unemployment. Living conditions were so bad that in several regions, such as counties inhabited by the Hutsuls, there was permanent starvation. Farmers rebelled against the government (see: 1937 peasant strike in Poland), and the situation began to change in the late 1930s, due to construction of several factories for the Central Industrial Region, which gave employment to thousands of countryside residents.
German trade.
Beginning in June 1925 there was a customs' war with the revanchist Weimar Republic imposing trade embargo against Poland for nearly a decade; involving tariffs, and broad economic restrictions. After 1933 the trade war ended. The new agreements regulated and promoted trade. Germany became Poland's largest trading partner, followed by Britain. In October 1938 Germany granted a credit of Rm 60,000,000 to Poland (120,000,000 zloty, or £4,800,000) which was never realized, due to the outbreak of war. Germany would deliver factory equipment and machinery in return for Polish timber and agricultural produce. This new trade was to be "in addition" to the existing German-Polish trade agreements.
Education and culture.
In 1919, the Polish government introduced compulsory education for all children aged 7 to 14, in an effort to limit illiteracy, which was widespread especially in the former Russian Partition and the Austrian Partition of eastern Poland. In 1921, one-third of citizens of Poland remained illiterate (38% in the countryside). The process was slow, but by 1931, the illiteracy level had dropped to 23% overall (27% in the countryside) and further down to 18% in 1937. By 1939, over 90% of children attended school. In 1932, Minister of Religion and Education Janusz Jędrzejewicz carried out a major reform which introduced the following levels of education:
Before 1918, Poland had three universities: Jagiellonian University, University of Warsaw and Lwów University. Catholic University of Lublin was established in 1918; Adam Mickiewicz University, Poznań, in 1919; and finally, in 1922, after the annexation of Republic of Central Lithuania, Wilno University became the Republic's sixth university. There were also three technical colleges: the Warsaw University of Technology, Lwów Polytechnic and the AGH University of Science and Technology in Kraków, established in 1919. Warsaw University of Life Sciences was an agricultural institute. By 1939, there were around 50,000 students enrolled in further education. Women made up 28% of university students, the second highest proportion in Europe.
Polish science in the interbellum was renowned for its mathematicians – see Lwów School of Mathematics, Kraków School of Mathematics, and Warsaw School of Mathematics. There were well-known philosophers (see Lwów–Warsaw school of logic), Florian Znaniecki founded Polish sociological studies, Rudolf Weigl invented a vaccine against typhus, and Bronisław Malinowski was among the most important anthropologists of the 20th century. In Polish literature, the 1920s were marked by the domination of poetry. Polish poets were divided into two groups – the Skamanderites (Jan Lechoń, Julian Tuwim, Antoni Słonimski and Jarosław Iwaszkiewicz) and the Futurists (Anatol Stern, Bruno Jasieński, Aleksander Wat, Julian Przyboś). Apart from well-established novelists (Stefan Żeromski, Władysław Reymont), new names appeared in the interbellum – Zofia Nałkowska, Maria Dąbrowska, Jarosław Iwaszkiewicz, Jan Parandowski, Bruno Schultz, Stanisław Ignacy Witkiewicz, Witold Gombrowicz. Among other notable artists there were sculptor Xawery Dunikowski, painters Julian Fałat, Wojciech Kossak and Jacek Malczewski, composers Karol Szymanowski, Feliks Nowowiejski, and Artur Rubinstein, singer Jan Kiepura. Theatre was very popular in the interbellum, with three main centers in the cities of Warsaw, Wilno and Lwów. Altogether, there were 103 theaters in Poland and a number of other theatrical institutions (including 100 folk theaters). In 1936, different shows were seen by 5 million people, and main figures of Polish theatre of the time were Juliusz Osterwa, Stefan Jaracz, and Leon Schiller. Also, before the outbreak of the war, there were about a million radios (see Radio stations in interwar Poland).
Administrative division.
The administrative division of the Republic was based on a three-tier system. On the lowest rung were the "gminy", local town and village governments akin to districts or parishes. These were then grouped together into "powiaty" (akin to counties), which, in turn, were grouped as "województwa" (voivodeships, akin to provinces).
Demographics.
Historically, Poland was a nation of many nationalities. This was especially true after independence was regained in the wake of World War I and the subsequent Polish–Soviet War ending at Peace of Riga. The census of 1921 shows 30.8% of the population consisted of ethnic minorities. According to the 1931 Polish Census: 68.9% of the population was Polish, 13.9% were Ukrainians, around 10% Jewish, 3.1% Belarusians, 2.3% Germans and 2.8% – others, including Lithuanians, Czechs, Armenians, Russians, and Gypsies. The situation of minorities was a complex subject and changed during the period.
Poland was also a nation of many religions. In 1921, 16,057,229 Poles (approx. 62.5%) were Roman (Latin) Catholics, 3,031,057 citizens of Poland (approx. 11.8%) were Eastern Rite Catholics (mostly Ukrainian Greek Catholics and Armenian Rite Catholics), 2,815,817 (approx. 10.95%) were Greek Orthodox, 2,771,949 (approx. 10.8%) were Jewish, and 940,232 (approx. 3.7%) were Protestants (mostly Lutheran).
By 1931, Poland had the second largest Jewish population in the world, with one-fifth of all the world's Jews residing within its borders (approx. 3,136,000). The urban population of interbellum Poland was rising steadily; in 1921, only 24% of Poles lived in the cities, in the late 1930s, that proportion grew to 30%. In more than a decade, the population of Warsaw grew by 200,000, Łódź by 150,000, and Poznań – by 100,000. This was due not only to internal migration, but also to an extremely high birth rate.
Geography.
The Second Polish Republic was mainly flat, with average elevation of 223 m above sea level (after World War II and its border changes, the average elevation of Poland decreased to 173 m). Only 13% of territory, along the southern border, was higher than 300 m. The highest elevation was Mount Rysy, which rises 2,499 m in the Tatra Range of the Carpathians, 95 km south of Kraków. Between October 1938 and September 1939, the highest elevation was Lodowy Szczyt (known in the Slovak language as "Ľadový štít"), which rises 2,627 meters above sea level. The largest lake was Lake Narach.
The country's total area, after the annexation of Zaolzie, was . It extended 903 km from north to south and 894 km from east to west. On 1 January 1938, total length of boundaries was 5,529 km, including: 140 kilometers of coastline (out of which 71 kilometers were made by the Hel Peninsula), the 1412 kilometers with Soviet Union, 948 kilometers with Czechoslovakia (until 1938), 1912 kilometers with Germany (together with East Prussia), and 1081 kilometers with other countries (Lithuania, Romania, Latvia, Danzig).
The warmest yearly average temperature was in Kraków among major cities of the Second Polish Republic, at 9.1 °C in 1938; and the coldest in Wilno (7.6 °C in 1938).
Drainage.
Almost 75% of the territory of interbellum Poland was drained northward into the Baltic Sea by the Vistula (total area of drainage basin of the Vistula within boundaries of the Second Polish Republic was 180,300 km2), the Niemen (51,600 km2), the Odra (46,700 km2) and the Daugava (10,400 km2). The remaining part of the country was drained southward, into the Black Sea, by the rivers that drain into the Dnieper (Pripyat, Horyn and Styr, all together 61,500 km2) as well as Dniester (41,400 km2)

</doc>
<doc id="14246" url="https://en.wikipedia.org/wiki?curid=14246" title="Hedwig">
Hedwig

Hedwig is a feminine German given name, see Hedwig (name). Hedwig may also refer to:

</doc>
<doc id="14251" url="https://en.wikipedia.org/wiki?curid=14251" title="HMS Resolution">
HMS Resolution

Several ships of the Royal Navy have borne the name HMS "Resolution". However, the first English warship to bear the name "Resolution" was actually the first rate (built in 1610 and rebuilt in 1641), which was renamed "Resolution" in 1650 following the inauguration of the Commonwealth, and continued to bear that name until 1660, when the name "Prince Royal" was restored. The name "Resolution" was bestowed on the first of the vessels listed below:

</doc>
<doc id="14254" url="https://en.wikipedia.org/wiki?curid=14254" title="Helen Keller">
Helen Keller

Helen Adams Keller (June 27, 1880 – June 1, 1968) was an American author, political activist, and lecturer. She was the first deafblind person to earn a bachelor of arts degree. The story of how Keller's teacher, Anne Sullivan, broke through the isolation imposed by a near complete lack of language, allowing the girl to blossom as she learned to communicate, has become widely known through the dramatic depictions of the play and film "The Miracle Worker". Her birthplace in West Tuscumbia, Alabama, is now a museum and sponsors an annual "Helen Keller Day". Her birthday on June 27 is commemorated as Helen Keller Day in the U.S. state of Pennsylvania and was authorized at the federal level by presidential proclamation by President Jimmy Carter in 1980, the 100th anniversary of her birth.
A prolific author, Keller was well-traveled and outspoken in her convictions. A member of the Socialist Party of America and the Industrial Workers of the World, she campaigned for women's suffrage, labor rights, socialism, and other similar causes. She was inducted into the Alabama Women's Hall of Fame in 1971 and was one of twelve inaugural inductees to the Alabama Writers Hall of Fame on June 8, 2015.
Early childhood and illness.
Helen Adams Keller was born on June 27, 1880, in Tuscumbia, Alabama. Her family lived on a homestead, Ivy Green, that Helen's grandfather had built decades earlier. She had two younger siblings, Mildred Campbell and Phillip Brooks Keller, and two older half-brothers from her father's prior marriage, James and William Simpson Keller.
Her father, Arthur H. Keller, spent many years as an editor for the Tuscumbia "North Alabamian", and had served as a captain for the Confederate Army. Her paternal grandmother was the second cousin of Robert E. Lee. Her mother, Kate Adams, was the daughter of Charles W. Adams. Though originally from Massachusetts, Charles Adams also fought for the Confederate Army during the American Civil War, earning the rank of colonel (and acting brigadier-general). Her paternal lineage was traced to Casper Keller, a native of Switzerland. One of Helen's Swiss ancestors was the first teacher for the deaf in Zurich. Keller reflected on this coincidence in her first autobiography, stating "that there is no king who has not had a slave among his ancestors, and no slave who has not had a king among his."
Helen Keller was born with the ability to see and hear. At 19 months old, she contracted an illness described by doctors as "an acute congestion of the stomach and the brain", which might have been scarlet fever or meningitis. The illness left her both deaf and blind. At that time, she was able to communicate somewhat with Martha Washington, the six-year-old daughter of the family cook, who understood her signs; by the age of seven, Keller had more than 60 home signs to communicate with her family.
In 1886, Keller's mother, inspired by an account in Charles Dickens' "American Notes" of the successful education of another deaf and blind woman, Laura Bridgman, dispatched young Helen, accompanied by her father, to seek out physician J. Julian Chisolm, an eye, ear, nose, and throat specialist in Baltimore, for advice. Chisholm referred the Kellers to Alexander Graham Bell, who was working with deaf children at the time. Bell advised them to contact the Perkins Institute for the Blind, the school where Bridgman had been educated, which was then located in South Boston. Michael Anagnos, the school's director, asked 20-year-old former student Anne Sullivan, herself visually impaired, to become Keller's instructor. It was the beginning of a 49-year-long relationship during which Sullivan evolved into Keller's governess and eventually her companion.
Anne Sullivan arrived at Keller's house in March 1887, and immediately began to teach Helen to communicate by spelling words into her hand, beginning with "d-o-l-l" for the doll that she had brought Keller as a present. Keller was frustrated, at first, because she did not understand that every object had a word uniquely identifying it. In fact, when Sullivan was trying to teach Keller the word for "mug", Keller became so frustrated she broke the mug. Keller's big breakthrough in communication came the next month, when she realized that the motions her teacher was making on the palm of her hand, while running cool water over her other hand, symbolized the idea of "water"; she then nearly exhausted Sullivan demanding the names of all the other familiar objects in her world.
Formal education.
Starting in May 1888, Keller attended the Perkins Institute for the Blind. In 1894, Helen Keller and Anne Sullivan moved to New York to attend the Wright-Humason School for the Deaf, and to learn from Sarah Fuller at the Horace Mann School for the Deaf. In 1896, they returned to Massachusetts, and Keller entered The Cambridge School for Young Ladies before gaining admittance, in 1900, to Radcliffe College, where she lived in Briggs Hall, South House. Her admirer, Mark Twain, had introduced her to Standard Oil magnate Henry Huttleston Rogers, who, with his wife Abbie, paid for her education. In 1904, at the age of 24, Keller graduated from Radcliffe, becoming the first deaf blind person to earn a Bachelor of Arts degree. She maintained a correspondence with the Austrian philosopher and pedagogue Wilhelm Jerusalem, who was one of the first to discover her literary talent.
Determined to communicate with others as conventionally as possible, Keller learned to speak, and spent much of her life giving speeches and lectures. She learned to "hear" people's speech by reading their lips with her hands—her sense of touch had become extremely subtle. She became proficient at using braille and reading sign language with her hands as well. Shortly before World War I, with the assistance of the Zoellner Quartet she determined that by placing her fingertips on a resonant tabletop she could experience music played close by.
Example of her lectures.
On January 22, 1916, Helen Keller and her companion, Anne Sullivan Macy, traveled to the small western Wisconsin town of Menomonie, Wisconsin to deliver a lecture at the Mabel Tainter Memorial Building. Details of her talk were provided in the weekly Dunn County News on January 22, 1916:
“A message of optimism, of hope, of good cheer, and of loving service was brought to Menomonie Saturday — a message that will linger long with those fortunate enough to have received it. This message came with the visit of Helen Keller and her teacher, Mrs. John Macy, and both had a hand in imparting it Saturday evening to a splendid audience that filled The Memorial. The wonderful girl who has so brilliantly triumphed over the triple afflictions of blindness, dumbness and deafness, gave a talk with her own lips on “Happiness,” and it will be remembered always as a piece of inspired teaching by those who heard it.”
When part of the account was reprinted in the January 20, 2016, edition of the paper under the heading "From the Files," the column compiler added, "According to those who attended, Helen Keller spoke of the joy that life gave her. She was thankful for the faculties and abilities that she did possess and stated that the most productive pleasures she had were curiosity and imagination. Keller also spoke of the joy of service and the happiness that came from doing things for others . . . Keller imparted that 'helping your fellow men were one’s only excuse for being in this world and in the doing of things to help one’s fellows lay the secret of lasting happiness.' She also told of the joys of loving work and accomplishment and the happiness of achievement. Although the entire lecture lasted only a little over an hour, the lecture had a profound impact on the audience."
Companions.
Anne Sullivan stayed as a companion to Helen Keller long after she taught her. Anne married John Macy in 1905, and her health started failing around 1914. Polly Thomson was hired to keep house. She was a young woman from Scotland who had no experience with deaf or blind people. She progressed to working as a secretary as well, and eventually became a constant companion to Keller.
Keller moved to Forest Hills, Queens, together with Anne and John, and used the house as a base for her efforts on behalf of the American Foundation for the Blind. "While in her thirties Helen had a love affair, became secretly engaged, and defied her teacher and family by attempting an elopement with the man she loved." He was "Peter Fagan, a young Boston Herald reporter who was sent to Helen's home to act as her private secretary when lifelong companion, Anne, fell ill."
Anne Sullivan died in 1936 after a coma, with Keller holding her hand. Keller and Thomson moved to Connecticut. They traveled worldwide and raised funds for the blind. Thomson had a stroke in 1957 from which she never fully recovered, and died in 1960. Winnie Corbally, a nurse whom they originally hired to care for Thomson in 1957, stayed on after her death and was Keller's companion for the rest of her life.
Political activities.
Keller went on to become a world-famous speaker and author. She is remembered as an advocate for people with disabilities, amid numerous other causes. She was a suffragette, a pacifist, an opponent of Woodrow Wilson, a radical socialist and a birth control supporter. In 1915 she and George Kessler founded the Helen Keller International (HKI) organization. This organization is devoted to research in vision, health and nutrition. In 1920, she helped to found the American Civil Liberties Union (ACLU). Keller traveled to over 40 countries with Sullivan, making several trips to Japan and becoming a favorite of the Japanese people. Keller met every U.S. President from Grover Cleveland to Lyndon B. Johnson and was friends with many famous figures, including Alexander Graham Bell, Charlie Chaplin and Mark Twain. Keller and Twain were both considered radicals at the beginning of the 20th century, and as a consequence, their political views have been forgotten or glossed-over in the popular mind.
Keller was a member of the Socialist Party and actively campaigned and wrote in support of the working class from 1909 to 1921. She supported Socialist Party candidate Eugene V. Debs in each of his campaigns for the presidency. Before reading "Progress and Poverty", Helen Keller was already a socialist who believed that Georgism was a good step in the right direction. She later wrote of finding "in Henry George’s philosophy a rare beauty and power of inspiration, and a splendid faith in the essential nobility of human nature."
Newspaper columnists who had praised her courage and intelligence before she expressed her socialist views now called attention to her disabilities. The editor of the "Brooklyn Eagle" wrote that her "mistakes sprung out of the manifest limitations of her development." Keller responded to that editor, referring to having met him before he knew of her political views: 
Keller joined the Industrial Workers of the World (the IWW, known as the Wobblies) in 1912, saying that parliamentary socialism was "sinking in the political bog". She wrote for the IWW between 1916 and 1918. In "Why I Became an IWW", Keller explained that her motivation for activism came in part from her concern about blindness and other disabilities:
The last sentence refers to prostitution and syphilis, the former a frequent cause of the latter, and the latter a leading cause of blindness. In the same interview, Keller also cited the 1912 strike of textile workers in Lawrence, Massachusetts for instigating her support of socialism.
Writings.
Keller wrote a total of 12 published books and several articles.
One of her earliest pieces of writing, at age 11, was "The Frost King" (1891). There were allegations that this story had been plagiarized from "The Frost Fairies" by Margaret Canby. An investigation into the matter revealed that Keller may have experienced a case of cryptomnesia, which was that she had Canby's story read to her but forgot about it, while the memory remained in her subconscious.
At age 22, Keller published her autobiography, "The Story of My Life" (1903), with help from Sullivan and Sullivan's husband, John Macy. It recounts the story of her life up to age 21 and was written during her time in college.
Keller wrote "The World I Live In" in 1908, giving readers an insight into how she felt about the world. "Out of the Dark", a series of essays on socialism, was published in 1913.
When Keller was young, Anne Sullivan introduced her to Phillips Brooks, who introduced her to Christianity, Keller famously saying: "I always knew He was there, but I didn't know His name!"
Her spiritual autobiography, "My Religion", was published in 1927 and then in 1994 extensively revised and re-issued under the title "Light in My Darkness". It advocates the teachings of Emanuel Swedenborg, the Christian revelator and theologian who gives a spiritual interpretation of the teachings of the Bible and who claims that the second coming of Jesus Christ has already taken place. Adherents use several names to describe themselves, including Second Advent Christian, Swedenborgian, and New Church.
Keller described the progressive views of her belief in these words:
But in Swedenborg's teaching it Providence is shown to be the government of God's Love and Wisdom and the creation of uses. Since His Life cannot be less in one being than another, or His Love manifested less fully in one thing than another, His Providence must needs be universal . . . He has provided religion of some kind everywhere, and it does not matter to what race or creed anyone belongs if he is faithful to his ideals of right living.
Akita dog.
When Keller visited Akita Prefecture in Japan in July 1937, she inquired about Hachikō, the famed Akita dog that had died in 1935. She told a Japanese that she would like to have an Akita dog; one was given to her within a month, with the name of Kamikaze-go. When he died of canine distemper, his older brother, Kenzan-go, was presented to her as an official gift from the Japanese government in July 1938. Keller is credited with having introduced the Akita to the United States through these two dogs.
By 1939, a breed standard had been established, and dog shows had been held, but such activities stopped after World War II began. Keller wrote in the "Akita Journal":
Later life.
Keller suffered a series of strokes in 1961 and spent the last years of her life at her home.
On September 14, 1964, President Lyndon B. Johnson awarded her the Presidential Medal of Freedom, one of the United States' two highest civilian honors. In 1965 she was elected to the National Women's Hall of Fame at the New York World's Fair.
Keller devoted much of her later life to raising funds for the American Foundation for the Blind. She died in her sleep on June 1, 1968, at her home, Arcan Ridge, located in Easton, Connecticut, a few weeks short of her eighty-eighth birthday. A service was held in her honor at the National Cathedral in Washington, D.C., her body was cremated and her ashes were placed there next to her constant companions, Anne Sullivan and Polly Thomson. She was buried at the Washington National Cathedral.
Portrayals.
Keller's life has been interpreted many times. She appeared in a silent film, "Deliverance" (1919), which told her story in a melodramatic, allegorical style.
She was also the subject of the documentaries "Helen Keller in Her Story", narrated by Katharine Cornell, and "The Story of Helen Keller", part of the Famous Americans series produced by Hearst Entertainment.
"The Miracle Worker" is a cycle of dramatic works ultimately derived from her autobiography, "The Story of My Life". The various dramas each describe the relationship between Keller and Sullivan, depicting how the teacher led her from a state of almost feral wildness into education, activism, and intellectual celebrity. The common title of the cycle echoes Mark Twain's description of Sullivan as a "miracle worker." Its first realization was the 1957 "Playhouse 90" teleplay of that title by William Gibson. He adapted it for a Broadway production in 1959 and an Oscar-winning feature film in 1962, starring Anne Bancroft and Patty Duke. It was remade for television in 1979 and 2000.
In 1984, Keller's life story was made into a TV movie called "The Miracle Continues". This film that entailed the semi-sequel to "The Miracle Worker" recounts her college years and her early adult life. None of the early movies hint at the social activism that would become the hallmark of Keller's later life, although a Disney version produced in 2000 states in the credits that she became an activist for social equality.
The Bollywood movie "Black" (2005) was largely based on Keller's story, from her childhood to her graduation.
A documentary called "Shining Soul: Helen Keller's Spiritual Life and Legacy" was produced by the Swedenborg Foundation in the same year. The film focuses on the role played by Emanuel Swedenborg's spiritual theology in her life and how it inspired Keller's triumph over her triple disabilities of blindness, deafness and a severe speech impediment.
On March 6, 2008, the New England Historic Genealogical Society announced that a staff member had discovered a rare 1888 photograph showing Helen and Anne, which, although previously published, had escaped widespread attention. Depicting Helen holding one of her many dolls, it is believed to be the earliest surviving photograph of Anne Sullivan Macy.
Video footage showing Helen Keller learning to mimic speech sounds also exists.
Posthumous honors.
A preschool for the deaf and hard of hearing in Mysore, India, was originally named after Helen Keller by its founder, K. K. Srinivasan.
In 1999, Keller was listed in Gallup's Most Widely Admired People of the 20th century.
In 2003, Alabama honored its native daughter on its state quarter. The Alabama state quarter is the only circulating US coin to feature braille.
The Helen Keller Hospital in Sheffield, Alabama is dedicated to her.
Streets are named after Helen Keller in Zürich, Switzerland, in the USA, in Getafe, Spain, in Lod, Israel, in Lisbon, Portugal and in Caen, France.
A stamp was issued in 1980 by the United States Postal Service depicting Keller and Sullivan, to mark the centennial of Keller's birth.
On October 7, 2009, a bronze statue of Helen Keller was added to the National Statuary Hall Collection, as a replacement for the State of Alabama's former 1908 statue of the education reformer Jabez Lamar Monroe Curry. It is displayed in the United States Capitol Visitor Center and depicts Keller as a seven-year-old child standing at a water pump. The statue represents the seminal moment in Keller's life when she understood her first word: W-A-T-E-R, as signed into her hand by teacher Anne Sullivan. The pedestal base bears a quotation in raised Latin and braille letters: "The best and most beautiful things in the world cannot be seen or even touched, they must be felt with the heart." The statue is the first one of a person with a disability and of a child to be permanently displayed at the U.S. Capitol.
Archival material.
Archival material of Helen Keller stored in New York was lost when the Twin Towers were destroyed in the September 11 attacks.
The Helen Keller Archives are owned by the American Foundation for the Blind.

</doc>
<doc id="14257" url="https://en.wikipedia.org/wiki?curid=14257" title="Haddocks' Eyes">
Haddocks' Eyes

Haddocks' Eyes is a term for the name of a poem by Lewis Carroll from "Through the Looking-Glass". It is sung by The White Knight in to a tune that he claims as his own invention, but which Alice recognises as "I give thee all, I can no more".
By the time Alice heard it, she was already tired of poetry.
It is a parody of "Resolution and Independence" by William Wordsworth.
Naming.
The White Knight explains a confusing nomenclature for the song.
The complicated terminology distinguishing between 'the song, what the song is called, the name of the song, and what the name of the song is called' entails the use–mention distinction.
Upon the Lonely Moor.
Like "Jabberwocky," another poem published in "Through the Looking Glass," "Haddocks’ Eyes" appears to have been revised over the course of many years. In 1856, Carroll published the following poem anonymously under the name "Upon the Lonely Moor". It bears an obvious resemblance to "Haddocks' Eyes."

</doc>
<doc id="14260" url="https://en.wikipedia.org/wiki?curid=14260" title="Hoosier">
Hoosier

Hoosier is the official demonym for a resident of the U.S. state of Indiana. The origin of the term remains a matter of debate within the state, but "Hoosier" was in general use by the 1840s, having been popularized by Richmond resident John Finley's 1833 poem "The Hoosier's Nest". Anyone born in Indiana or a resident at the time is considered to be a Hoosier. Indiana adopted the nickname "The Hoosier State" more than 150 years ago.
"Hoosier" is used in the names of numerous Indiana-based businesses and organizations. "Hoosiers" is also the name of the Indiana University athletic teams and seven active and one disbanded athletic conferences in the Indiana High School Athletic Association have the word "Hoosier" in their name. As there is no accepted embodiment of a Hoosier, the IU schools are represented through their letters and colors alone.
Origin.
In addition to "The Hoosier's Nest", the term also appeared in the "Indianapolis Journal"'s "Carrier's Address" on January 1, 1833. There are many suggestions for the derivation of the word, but none is universally accepted.
Scholarship.
In 1900, Meredith Nicholson wrote "The Hoosiers", an early attempt to study the etymology of the word as applied to Indiana residents. Jacob Piatt Dunn, longtime secretary of the Indiana Historical Society, published "The Word Hoosier", a similar attempt, in 1907. Both chronicled some of the popular and satirical etymologies circulating at the time and focused much of their attention on the use of the word in the Upland South to refer to woodsmen, yokels, and rough people. Dunn traced the word back to the Cumbrian "hoozer", meaning anything unusually large, derived from the Old English "hoo" (as at Sutton Hoo), meaning "high" and "hill". The importance of immigrants from northern England and southern Scotland was reflected in numerous placenames including the Cumberland Mountains, the Cumberland River, and the Cumberland Gap. Nicholson defended the people of Indiana against such an association, while Dunn concluded that the early settlers had adopted the nickname self-mockingly and that it had lost its negative associations by the time of Finley's poem.
Johnathan Clark Smith subsequently showed that Nicholson and Dunn's earliest sources within Indiana were mistaken. A letter by James Curtis cited by Dunn and others as the earliest known use of the term was actually written in 1846, not 1826. Similarly, the use of the term in an 1859 newspaper item quoting an 1827 diary entry by Sandford Cox was more likely an editorial comment and not from the original diary. Smith's earliest sources led him to argue that the word originated as a term along the Ohio River for flatboatmen from Indiana and did not acquire its pejorative meanings until 1836, "after" Finley's poem.
William Piersen, a history professor at Fisk University, argued for a connection to the black Methodist minister Rev. Harry Hosier (–May 1806), who evangelized the American frontier at the beginning of the 19th century as part of the Second Great Awakening. "Black Harry" had been born a slave in North Carolina and sold north to Baltimore, Maryland, before gaining his freedom and beginning his ministry around the end of the American Revolution. He was a close associate and personal friend of Bishop Francis Asbury, the "Father of the American Methodist Church". Dr. Benjamin Rush said that, "making allowances for his illiteracy, he was the greatest orator in America" and his sermons called on Methodists to reject slavery and champion the common working man. Piersen proposed that Methodist communities inspired by his example took or were given a variant spelling of his name (possibly influenced by the "yokel" slang) during the decades after his ministry.
Folk etymologies.
Banter.
Humorous folk etymologies for the term "hoosier" have a long history, as recounted by Dunn in "The Word Hoosier".
One account traces the word to the necessary caution of approaching houses on the frontier. In order to avoid being shot, a traveler would call out from afar to let themselves be known. The inhabitants of the cabin would then reply "Who's here?" which in the Appalachian English of the early settlers slurred into "Who'sh 'ere?" and thence into "Hoosier?" A variant of this account had the Indiana pioneers calling out "Who'sh 'ere?" as a general greeting and warning when hearing someone in the bushes and tall grass, to avoid shooting a relative or friend in error.
The poet James Whitcomb Riley facetiously suggested that the fierce brawling that took place in Indiana involved enough biting that the expression "Whose ear?" became notable. This arose from or inspired the story of two 19th-century French immigrants brawling in a tavern in the foothills of southern Indiana. One was cut and a third Frenchman walked in to see an ear on the dirt floor of the tavern, prompting him to slur out "Whosh ear?"
Mr. Hoosier's men.
Two related stories trace the origin of the term to gangs of workers from Indiana under the direction of a Mr. Hoosier.
The account related by Dunn is that a Louisville contractor named Samuel Hoosier preferred to hire workers from communities on the Indiana side of the Ohio River like New Albany rather than Kentuckians. During the excavation of the first canal around the Falls of the Ohio from 1826 to 1833, his employees became known as "Hoosier's men" and then simply "Hoosiers". The usage spread from these hard-working laborers to all of the Indiana boatmen in the area and then spread north with the settlement of the state. The story was told to Dunn in 1901 by a man who had heard it from a Hoosier relative while traveling in southern Tennessee. Dunn could not find any family of the given name in any directory in the region or anyone else in southern Tennessee who had heard the story and accounted himself dubious. This version was subsequently retold by Gov. Evan Bayh and Sen. Vance Hartke, who introduced the story into the "Congressional Record" in 1975, and matches the timing and location of Smith's subsequent research. However, the U.S. Army Corps of Engineers has been unable to find any record of a Hoosier or Hosier in surviving canal company records.
Other uses.
The word "Hoosier" is still used in St. Louis, Missouri, to denote a "yokel" or "white trash". The word is also sometimes encountered in sea shanties such as "Shanties from the Seven Seas" in reference to its former use to denote cotton-stowers, who would move bales of cotton to and from the holds of ships and force them in tightly by means of jackscrews. "To hoosier" is sometimes still encountered as a verb meaning "to trick" or "to swindle".
A Hoosier cabinet, often shortened to "hoosier", is a type of free-standing kitchen cabinet popular in the early decades of the twentieth century. Almost all of these cabinets were produced by companies located in Indiana and the name derives from the largest of them, the Hoosier Manufacturing Co. of New Castle, Indiana. Other Indiana businesses include Hoosier Racing Tire and the Hoosier Bat Company, manufacturer of wooden baseball bats.
The RCA Dome, former home of the Indianapolis Colts, was known as the "Hoosier Dome" before RCA purchased the naming rights in 1994. The RCA Dome was replaced by Lucas Oil Stadium in 2008.

</doc>
<doc id="14263" url="https://en.wikipedia.org/wiki?curid=14263" title="Horner's method">
Horner's method

In mathematics, Horner's method (also known as Horner scheme in the UK or Horner's rule in the U.S.) is either of two things: (i) an algorithm for calculating polynomials, which consists of transforming the monomial form into a computationally efficient form; or (ii) a method for approximating the roots of a polynomial. The latter is also known as Ruffini–Horner's method.
These methods are named after the British mathematician William George Horner, although they were known before him by Paolo Ruffini and, six hundred years earlier, by the Chinese mathematician Qin Jiushao.
Description of the algorithm.
Given the polynomial
where formula_2 are real numbers, we wish to evaluate the polynomial at a specific value of formula_3, say formula_4.
To accomplish this, we define a new sequence of constants as follows:
Then formula_6 is the value of formula_7.
To see why this works, note that the polynomial can be written in the form
Thus, by iteratively substituting the formula_9 into the expression,
Examples.
Evaluate formula_11 for formula_12
We use synthetic division as follows:
The entries in the third row are the sum of those in the first two. Each entry in the second row is the product of the "x"-value (3 in this example) with the third-row entry immediately to the left. The entries in the first row are the coefficients of the polynomial to be evaluated. Then the remainder of formula_13 on division by formula_14 is 5.
But by the polynomial remainder theorem, we know that the remainder is formula_15. Thus formula_16
In this example, if formula_17 we can see that formula_18, the entries in the third row. So, synthetic division is based on Horner's method.
As a consequence of the polynomial remainder theorem, the entries in the third row are the coefficients of the second-degree polynomial, the quotient of formula_13 on division by formula_20. 
The remainder is 5. This makes Horner's method useful for polynomial long division.
Divide formula_21 by formula_22:
The quotient is formula_23.
Let formula_24 and formula_25. Divide formula_26 by formula_27 using Horner's method.
The third row is the sum of the first two rows, divided by 2. Each entry in the second row is the product of 1 with the third-row entry to the left. The answer is
Floating point multiplication and division.
Horner's method is a fast, code-efficient method for multiplication and division of binary numbers on a microcontroller with no hardware multiplier. One of the binary numbers to be multiplied is represented as a trivial polynomial, where, (using the above notation): ai = 1, and x = 2. Then, x (or x to some power) is repeatedly factored out. In this binary numeral system (base 2), x = 2, so powers of 2 are repeatedly factored out.
Example.
For example, to find the product of two numbers, (0.15625) and "m":
Method.
To find the product of two binary numbers, d and m:
Derivation.
In general, for a binary number with bit values: (formula_30) the product is:
At this stage in the algorithm, it is required that terms with zero-valued coefficients are dropped, so that only binary coefficients equal to one are counted, thus the problem of multiplication or division by zero is not an issue, despite this implication in the factored equation:
The denominators all equal one (or the term is absent), so this reduces to:
or equivalently (as consistent with the "method" described above):
In binary (base 2) math, multiplication by a power of 2 is merely a register shift operation. Thus, multiplying by 2 is calculated in base-2 by an arithmetic shift. The factor (2−1) is a right arithmetic shift, a (0) results in no operation (since 20 = 1, is the multiplicative identity element), and a (21) results in a left arithmetic shift.
The multiplication product can now be quickly calculated using only arithmetic shift operations, addition and subtraction.
The method is particularly fast on processors supporting a single-instruction shift-and-addition-accumulate. Compared to a C floating-point library, Horner's method sacrifices some accuracy, however it is nominally 13 times faster (16 times faster when the "canonical signed digit" (CSD) form is used), and uses only 20% of the code space.
Polynomial root finding.
Using Horner's method in combination with Newton's method, it is possible to approximate the real roots of a polynomial. The algorithm works as follows. Given a polynomial formula_35 of degree formula_36 with zeros formula_37 make some initial guess formula_38 such that formula_39. Now iterate the following two steps:
1. Using Newton's method, find the largest zero formula_40 of formula_35 using the guess formula_4.
2. Using Horner's method, divide out formula_43 to obtain formula_44. Return to step 1 but use the polynomial formula_44 and the initial guess formula_40.
These two steps are repeated until all real zeros are found for the polynomial. If the approximated zeros are not precise enough, the obtained values can be used as initial guesses for Newton's method but using the full polynomial rather than the reduced polynomials.
Example.
Consider the polynomial
which can be expanded to
From the above we know that the largest root of this polynomial is 7 so we are able to make an initial guess of 8. Using Newton's method the first zero of 7 is found as shown in black in the figure to the right. Next formula_49 is divided by formula_50 to obtain
which is drawn in red in the figure to the right. Newton's method is used to find the largest zero of this polynomial with an initial guess of 7. The largest zero of this polynomial which corresponds to the second largest zero of the original polynomial is found at 3 and is circled in red. The degree 5 polynomial is now divided by formula_52 to obtain
which is shown in yellow. The zero for this polynomial is found at 2 again using Newton's method and is circled in yellow. Horner's method is now used to obtain
which is shown in green and found to have a zero at −3. This polynomial is further reduced to
which is shown in blue and yields a zero of −5. The final root of the original polynomial may be found by either using the final zero as an initial guess for Newton's method, or by reducing formula_56 and solving the linear equation. As can be seen, the expected roots of −8, −5, −3, 2, 3, and 7 were found.
Octave implementation.
The following Octave code was used in the example above to implement Horner's method.
Python implementation.
The following Python code implements Horner's method.
Application.
Horner's method can be used to convert between different positional numeral systems – in which case "x" is the base of the number system, and the "a""i" coefficients are the digits of the base-"x" representation of a given number – and can also be used if "x" is a matrix, in which case the gain in computational efficiency is even greater. In fact, when "x" is a matrix, further acceleration is possible which exploits the structure of matrix multiplication, and only formula_57 instead of "n" multiplies are needed (at the expense of requiring more storage) using the 1973 method of Paterson and Stockmeyer.
Efficiency.
Evaluation using the monomial form of a degree-"n" polynomial requires at most "n" additions and ("n"2 + "n")/2 multiplications, if powers are calculated by repeated multiplication and each monomial is evaluated individually. (This can be reduced to "n" additions and 2"n" − 1 multiplications by evaluating the powers of "x" iteratively.) If numerical data are represented in terms of digits (or bits), then the naive algorithm also entails storing approximately 2"n" times the number of bits of "x" (the evaluated polynomial has approximate magnitude "x""n", and one must also store "x""n" itself). By contrast, Horner's method requires only "n" additions and "n" multiplications, and its storage requirements are only "n" times the number of bits of "x". Alternatively, Horner's method can be computed with "n" fused multiply–adds. Horner's method can also be extended to evaluate the first "k" derivatives of the polynomial with "kn" additions and multiplications.
Horner's method is optimal, in the sense that any algorithm to evaluate an arbitrary polynomial must use at least as many operations. Alexander Ostrowski proved in 1954 that the number of additions required is minimal. Victor Pan proved in 1966 that the number of multiplications is minimal. However, when "x" is a matrix, Horner's method is not optimal.
This assumes that the polynomial is evaluated in monomial form and no preconditioning of the representation is allowed, which makes sense if the polynomial is evaluated only once. However, if preconditioning is allowed and the polynomial is to be evaluated many times, then faster algorithms are possible. They involve a transformation of the representation of the polynomial. In general, a degree-"n" polynomial can be evaluated using only formula_58 multiplications and "n" additions (see Knuth: "The Art of Computer Programming", Vol.2).
History.
Horner's paper entitled "A new method of solving numerical equations of all orders, by continuous approximation", was read before the Royal Society of London, at its meeting on July 1, 1819, with Davies Gilbert, Vice-President and Treasurer, in the chair; this was the final meeting of the session before the Society adjorned for its Summer recess. When a sequel was read before the Society in 1823, it was again at the final meeting of the session. On both occasions, papers by James Ivory, FRS, were also read. In 1819, it was Horner's paper that got through to publication in the "Philosophical Transactions". later in the year, Ivory's paper falling by the way, despite Ivory being a Fellow; in 1823, when a total of ten papers were read, fortunes as regards publication, were reversed. But Gilbert, who had strong connections with the West of England and may have had social contact with Horner, resident as Horner was in Bristol and Bath, published his own survey of Horner-type methods earlier in 1823.
Horner's paper in Part II of "Philosophical Transactions of the Royal Society of London" for 1819 was warmly and expansively welcomed by a reviewer in the issue of "The Monthly Review: or, Literary Journal" for April, 1820; in comparison, a technical paper by Charles Babbage is dismissed curtly in this review. However, the reviewer noted that another, similar method had also recently been published by the architect and mathematical expositor, Peter Nicholson. This theme is developed in a further review of some of Nicholson's books in the issue of "The Monthly Review" for December, 1820, which in turn ends with notice of the appearance of a booklet by Theophilus Holdred, from whom Nicholson acknowledges he obtained the gist of his approach in the first place, although claiming to have improved upon it. The sequence of reviews is concluded in the issue of "The Monthly Review" for September, 1821, with the reviewer concluding that whereas Holdred was the first person to discover a direct and general practical solution of numerical equations, he had not reduced it to its simplest form by the time of Horner's publication, and saying that had Holdred published forty years earlier when he first discovered his method, his contribution could be more easily recognized. The reviewer is exceptionally well-informed, even having sighted Horner's preparatory correspondence with Peter Barlow in 1818, seeking work of Budan. The Bodlean Library, Oxford has the Editor's annotated copy of "The Monthly Review" from which it is clear that the most active reviewer in mathematics in 1814 and 1815 (the last years for which this information has been published) was none other than Peter Barlow,one of the foremost specialists on approximation theory of the period, suggesting that it was Barlow, who wrote this sequence of reviews. As it also happened, Henry Atkinson, of Newcastle, devised a similar approximation scheme in 1809; he had consulted his fellow Geordie, Charles Hutton, another specialist and a senior colleague of Barlow at the Royal Military Academy, Woolwich, only to be advised that, while his work was publishable, it was unlikely to have much impact. J. R. Young, writing in the mid-1830s, concluded that Holdred's first method replicated Atkinson's while his improved method was only added to Holdred's booklet some months after its first appearance in 1820, when Horner's paper was already in circulation.
The feature of Horner's writing that most distinguishes it from his English contemporaries is the way he draws on the Continental literature, notably the work of Arbogast. The advocacy, as well as the detraction, of Horner's Method has this as an unspoken subtext. Quite how he gained that familiarity has not been determined. Horner is known to have made a close reading of John Bonneycastle's book on algebra. Bonneycastle recognizes that Arbogast has the general, combinatorial expression for the reversion of series, a project going back at least to Newton. But Bonneycastle's main purpose in mentioning Arbogast is not to praise him, but to observe that Arbogast's notation is incompatible with the approach he adopts. The gap in Horner's reading was the work of Paolo Ruffini, except that, as far as awareness of Ruffini goes, citations of Ruffini's work by authors, including medical authors, in "Philosophical Transactions" speak volumes: there are none - Ruffini's name only appears in 1814, recording a work he donated to the Royal Society. Ruffini might have done better if his work had appeared in French, as had Malfatti's Problem in the reformulation of Joseph Diaz Gergonne, or had he written in French, as had Antonio Cagnoli, a source quoted by Bonneycastle on series reversion (today, Cagnoli is in the Italian Wikipedia, as shown, but has yet to make it into either French or English).
Fuller showed that the method in Horner's 1819 paper differs from what afterwards became known as 'Horner's method' and that in consequence the priority for this method should go to Holdred (1920). This view may be compared with the remarks concerning the works of Horner and Holdred in the previous paragraph. Fuller also takes aim at Augustus De Morgan. Precocious though Augustus de Morgan was, he was not the reviewer for "The Monthly Review", while several others - Thomas Stephens Davies, J. R. Young, Stephen Fenwick, T. T. Wilkinson - wrote Horner firmly into their records, not least Horner himself, as he published extensively up until the year of his death in 1837. His paper in 1819 was one that would have been difficult to miss. In contrast, the only other mathematical sighting of Holdred is a single named contribution to "The Gentleman's Mathematical Companion", an answer to a problem.
It is questionable to what extent it was De Morgan's advocacy of Horner's priority in discovery that led to "Horner's method" being so called in textbooks, but it is true that those suggesting this tend themselves to know of Horner largely through intermediaries, of whom De Morgan made himself a prime example. However, this method "qua" method was known long before Horner. In reverse chronological order, Horner's method was already known to:
However, this observation on its own masks significant differences in conception and also, as noted with Ruffini's work, issues of accessibility.
Qin Jiushao, in his "Shu Shu Jiu Zhang" ("Mathematical Treatise in Nine Sections"; 1247), presents a portfolio of methods of Horner-type for solving polynomial equations, which was based on earlier works of the 11th century Song dynasty mathematician Jia Xian; for example, one method is specifically suited to bi-qintics, of which Qin gives an instance, in keeping with the then Chinese custom of case studies. The first person writing in English to note the connection with Horner's method was Alexander Wylie, writing in "The North China Herald" in 1852; perhaps conflating and misconstruing different Chinese phrases, Wylie calls the method "Harmoniously Alternating Evolution" (which does not agree with his Chinese, "linglong kaifang", not that at that date he uses pinyin), working the case of one of Qin's quartics and giving, for comparison, the working with Horner's method. Yoshio Mikami in "Development of Mathematics in China and Japan" published in Leipzig in 1913, gave a detailed description of Qin's method, using the quartic illustrated to the above right in a worked example; he wrote: "who can deny the fact of Horner's illustrious process being used in China at least nearly six long centuries earlier than in Europe ... We of course don't intend in any way to ascribe Horner's invention to a Chinese origin, but the lapse of time sufficiently makes it not altogether impossible that the Europeans could have known of the Chinese method in a direct or indirect way.". However, as Mikami is also aware, it was "not altogether impossible" that a related work, "Si Yuan Yu Jian" ("Jade Mirror of the Four Unknowns; 1303)" by Zhu Shijie might make the shorter journey across to Japan, but seemingly it never did, although another work of Zhu, "Suan Xue Qi Meng", had a seminal influence on the development of traditional mathematics in the Edo period, starting in the mid-1600s. Ulrich Libbrecht (at the time teaching in school, but subsequently a professor of comparative philosophy) gave a detailed description in his doctoral thesis of Qin's method, he concluded: "It is obvious that this procedure is a Chinese invention...the method was not known in India". He said, Fibonacci probably learned of it from Arabs, who perhaps borrowed from the Chinese. Here, the problems is that there is no more evidence for this speculation than there is of the method being known in India. Of course, the extraction of square and cube roots along similar lines is already discussed by Liu Hui in connection with Problems IV.16 and 22 in "Jiu Zhang Suan Shu", while Wang Xiaotong in the 7th century supposes his readers can solve cubics by an approximation method he does not specify.

</doc>
<doc id="14268" url="https://en.wikipedia.org/wiki?curid=14268" title="Hapworth 16, 1924">
Hapworth 16, 1924

"Hapworth 16, 1924" is the "youngest" of J. D. Salinger's Glass family stories, in the sense that the narrated events happen chronologically before those in the rest of the "Glass series". It appeared in the June 19, 1965 edition of "The New Yorker"—infamously taking up almost the entire magazine—and was the last of Salinger's works to be published in his lifetime. Both contemporary and later literary critics harshly panned it; writing in "The New York Times", Michiko Kakutani called it "a sour, implausible and, sad to say, completely charmless story," "filled with digressions, narcissistic asides and ridiculous shaggy-dog circumlocutions. Even kind critics have regarded the work as "a long-winded sob story" which many have found to be "simply unreadable," and it has been speculated that this negative response was the reason Salinger decided to quit publishing. Conversely, Salinger is said to have considered the story a "high point of his writing" and made tentative steps to have it reprinted; nonetheless, these efforts came to nothing.
Plot.
The story is presented in the form of a letter from camp written by a seven-year-old Seymour Glass (the main character of "A Perfect Day for Bananafish"). In this respect, the plot is identical to Salinger's previous story "The Ocean Full of Bowling Balls," written some two decades earlier. In the course of requesting a veritable library of reading matter from home, Seymour predicts his brother's success as a writer as well as his own death and condemns the ironic "twist" endings in the stories of Anatole France, twist endings being an early Salinger device.
Publishing history.
After the story's appearance in "The New Yorker", Salinger—who had already withdrawn to his home in New Hampshire—stopped publishing altogether. Since he never put the story between hard covers, readers had to seek out a copy of that issue or find it on microfilm. Finally, with the release of "The Complete New Yorker" on DVD in 2005, the story was once again widely available.
In the meantime, however, in 1996, Orchises Press, a small publishing house in Virginia, started the process to publish "Hapworth" in book form. In an article in "The Washington Post", published after Salinger's death, and in a story for "New York", Orchises Press owner Roger Lathbury described his efforts to publish the story. According to Lathbury, Salinger was deeply concerned with the proposed book's appearance, even visiting Washington to examine the cloth for the binding. Salinger also sent Lathbury numerous "infectious and delightful and loving" letters.
Lathbury, following publishing norms, applied for Library of Congress Cataloging in Publication data, unaware of how publicly available the information would be. A writer in Seattle, researching an article on Jeff Bezos, the founder of the then-fledgling Amazon.com, came across the "Hapworth" publication date, told his sister, a journalist for the "Washington Business Journal", who wrote an article about the upcoming book. This led to substantial coverage in the press. Shortly before the books were to be shipped, Salinger changed his mind, and in accordance with his wishes, Orchises withdrew the work. Although new publication dates were repeatedly announced, the book never appeared. Lathbury said, "I never reached back out. I thought about writing some letters, but it wouldn't have done any good." Three months after Salinger's death, Lathbury published an account of the experience in "New York Magazine".

</doc>
<doc id="14269" url="https://en.wikipedia.org/wiki?curid=14269" title="Hypnotic">
Hypnotic

Hypnotic (from Greek "Hypnos", sleep) or soporific drugs, commonly known as sleeping pills, are a class of psychoactive drugs whose primary function is to induce sleep and to be used in the treatment of insomnia (sleeplessness), or surgical anesthesia.
This group is related to sedatives. Whereas the term "sedative" describes drugs that serve to calm or relieve anxiety, the term "hypnotic" generally describes drugs whose main purpose is to initiate, sustain, or lengthen sleep. Because these two functions frequently overlap, and because drugs in this class generally produce dose-dependent effects (ranging from anxiolysis to loss of consciousness) they are often referred to collectively as sedative-hypnotic drugs.
Hypnotic drugs are regularly prescribed for insomnia and other sleep disorders, with over 95% of insomnia patients being prescribed hypnotics in some countries. Many hypnotic drugs are habit-forming and, due to a large number of factors known to disturb the human sleep pattern, a physician may instead recommend changes in the environment before and during sleep, better sleep hygiene, and the avoidance of caffeine or other stimulating substances before prescribing medication for sleep. When prescribed, hypnotic medication should be used for the shortest period of time possible.
Most hypnotics prescribed today are either benzodiazepines or nonbenzodiazepines. Early classes of drugs, such as barbiturates, have fallen out of use in most practices but are still prescribed for some patients. In children, prescribing hypnotics is not yet acceptable unless used to treat night terrors or somnambulism. Elderly people are more sensitive to potential side effects of daytime fatigue and cognitive impairments, and a meta-analysis found that the risks generally outweigh any marginal benefits of hypnotics in the elderly. A review of the literature regarding benzodiazepine hypnotics and Z-drugs concluded that these drugs can have adverse effects, such as dependence and accidents, and that optimal treatment uses the lowest effective dose for the shortest therapeutic time period, with gradual discontinuation in order to improve health without worsening of sleep.
Falling outside of the above-mentioned categories, the neuro-hormone melatonin has a hypnotic function.
History.
Hypnotica was a class of somniferous drugs and substances tested in medicine of the 1890s and later, including: Urethan, Acetal, Methylal, Sulfonal, Paraldehyd, Amylenhydrate, Hypnon, Chloralurethan and Ohloralamid or Chloralimid.
Research about using medications to treat insomnia evolved throughout the last half of the 20th century. Treatment for insomnia in psychiatry dates back to 1869 when chloral hydrate was first used as a soporific. Barbiturates emerged as the first class of drugs that emerged in the early 1900s, after which chemical substitution allowed derivative compounds. Although the best drug family at the time (less toxic and with fewer side effects) they were dangerous in overdose.
During the 1970s, quinazolinones and benzodiazepines were introduced as safer alternatives to replace barbiturates; by the late 1970s benzodiazepines emerged as the safer drug.
Benzodiazepines are not without their drawbacks; substance dependence is possible, and deaths from overdoses sometimes occur, especially in combination with alcohol and/or other depressants. Questions have been raised as to whether they disturb sleep architecture.
Nonbenzodiazepines are the most recent development (1990s–present). Although it's clear that they are less toxic than their predecessors, barbiturates, comparative efficacy over benzodiazepines have not been established. Without longitudinal studies, it is hard to determine; however some psychiatrists recommend these drugs, citing research suggesting they are equally potent with less potential for abuse.
Other sleep remedies that may be considered "sedative-hypnotics" exist; psychiatrists will sometimes prescribe medicines off-label if they have sedating effects. Examples of these include mirtazapine (an antidepressant), clonidine (generally prescribed to regulate blood pressure), quetiapine (an antipsychotic), and the over-the-counter sleep aid diphenhydramine (Benadryl – an antihistamine). Off-label sleep remedies are particularly useful when first-line treatment is unsuccessful or deemed unsafe (for example, in patients with a history of substance abuse).
Types.
Barbiturates.
Barbiturates are drugs that act as central nervous system depressants, and can therefore produce a wide spectrum of effects, from mild sedation to total anesthesia. They are also effective as anxiolytics, hypnotics, and anticonvulsants. Barbiturates also have analgesic effects; however, these effects are somewhat weak, preventing barbiturates from being used in surgery in the absence of other analgesics. They have dependence liability, both physical and psychological. Barbiturates have now largely been replaced by benzodiazepines in routine medical practice – for example, in the treatment of anxiety and insomnia – mainly because benzodiazepines are significantly less dangerous in overdose. However, barbiturates are still used in general anesthesia, for epilepsy, and assisted suicide. Barbiturates are derivatives of barbituric acid.
The principal mechanism of action of barbiturates is believed to be positive allosteric modulation of GABAA receptors.
Examples include amobarbital, pentobarbital, phenobarbital, secobarbital, and sodium thiopental.
Quinazolinones.
Quinazolinones are also a class of drugs which function as hypnotic/sedatives that contain a 4-quinazolinone core. Their use has also been proposed in the treatment of cancer.
Examples of quinazolinones include cloroqualone, diproqualone, etaqualone (Aolan, Athinazone, Ethinazone), mebroqualone, mecloqualone (Nubarene, Casfen), and methaqualone (Quaalude).
Benzodiazepines.
Benzodiazepines can be useful for short-term treatment of insomnia. Their use beyond 2 to 4 weeks is not recommended due to the risk of dependence. It is preferred that benzodiazepines be taken intermittently and at the lowest effective dose. They improve sleep-related problems by shortening the time spent in bed before falling asleep, prolonging the sleep time, and, in general, reducing wakefulness. Like alcohol, benzodiazepines are commonly used to treat insomnia in the short-term (both prescribed and self-medicated), but worsen sleep in the long-term. While benzodiazepines can put people to sleep (i.e., inhibit NREM stage 1 and 2 sleep), while asleep, the drugs disrupt sleep architecture: decreasing sleep time, delaying time to REM sleep, and decreasing deep slow-wave sleep (the most restorative part of sleep for both energy and mood). This can directly and indirectly worsen other psychiatric symptoms such as depression, anxiety and irritability.
Other drawbacks of hypnotics, including benzodiazepines, are possible tolerance to their effects, rebound insomnia, and reduced slow-wave sleep and a withdrawal period typified by rebound insomnia and a prolonged period of anxiety and agitation. The list of benzodiazepines approved for the treatment of insomnia is fairly similar among most countries, but which benzodiazepines are officially designated as first-line hypnotics prescribed for the treatment of insomnia can vary distinctly between countries. Longer-acting benzodiazepines such as nitrazepam and diazepam have residual effects that may persist into the next day and are, in general, not recommended.
It is not clear as to whether the new nonbenzodiazepine hypnotics (Z-drugs) are better than the short-acting benzodiazepines. The efficacy of these two groups of medications is similar. According to the US Agency for Healthcare Research and Quality, indirect comparison indicates that side-effects from benzodiazepines may be about twice as frequent as from nonbenzodiazepines. Some experts suggest using nonbenzodiazepines preferentially as a first-line long-term treatment of insomnia. However, the UK National Institute for Health and Clinical Excellence (NICE) did not find any convincing evidence in favor of Z-drugs. A NICE review pointed out that short-acting Z-drugs were inappropriately compared in clinical trials with long-acting benzodiazepines. There have been no trials comparing short-acting Z-drugs with appropriate doses of short-acting benzodiazepines. Based on this, NICE recommended choosing the hypnotic based on cost and the patient's preference.
Older adults should not use benzodiazepines to treat insomnia unless other treatments have failed to be effective. When benzodiazepines are used, patients, their caretakers, and their physician should discuss the increased risk of harms, including evidence which shows twice the incidence of traffic collisions among driving patients as well as falls and hip fracture for all older patients.
Their mechanism of action is primarily at GABAA receptors.
Nonbenzodiazepines.
Nonbenzodiazepines are a class of psychoactive drugs that are very "benzodiazepine-like" in nature. Nonbenzodiazepines pharmacodynamics are almost entirely the same as benzodiazepine drugs and therefore employ similar benefits, side-effects, and risks. Nonbenzodiazepines, however, have dissimilar or entirely different chemical structures, and therefore are unrelated to benzodiazepines on a molecular level.
Examples include zopiclone (Imovane, Zimovane), eszopiclone (Lunesta), zaleplon (Sonata), and zolpidem (Ambien, Stilnox, Stilnoct).
Research on nonbenzodiazepines is new and conflicting. A review by a team of researchers suggests the use of these drugs for people that have trouble falling asleep but not staying asleep, as next-day impairments were minimal. The team noted that the safety of these drugs had been established, but called for more research into their long-term effectiveness in treating insomnia. Other evidence suggests that tolerance to nonbenzodiazepines may be slower to develop than with benzodiazepines. A different team was more skeptical, finding little benefit over benzodiazepines.
Others.
Melatonin and its agonists.
Melatonin, the hormone produced in the pineal gland in the brain and secreted in dim light and darkness, among its other functions, promotes sleep in diurnal mammals. Due to its hypnotic properties, it is available on prescription in many countries and is over-the-counter in others. A timed-release version, trade name Circadin®, was approved in 2007 in Europe (EU) for use as a treatment for primary insomnia.
At the beginning of the 21st century, several melatonin receptor agonists that bind to and activate melatonin receptors were developed. These analogues, prescribed for several sleep disorders, include ramelteon, agomelatine, TIK-301 and tasimelteon. Ramelteon (Rozerem®) was approved for treatment of insomnia in the US in 2005. In 2009 agomelatine (Valdoxan®, Melitor®, Thymanax®), primarily used for depression, was approved in Europe. Both TIK-301 (in 2004) and tasimelteon (Hetlioz®) ten years later were approved in the US for the circadian rhythm sleep disorder non-24-hour sleep–wake disorder in totally blind individuals.
Antihistamines.
In common use, the term "antihistamine" refers only to compounds that inhibit action at the H1 receptor (and not H2, etc.).
Clinically, H1 antagonists are used to treat allergic reactions. Sedation is a common side-effect, and some H1 antagonists, such as diphenhydramine (Benadryl) and doxylamine, are also used to treat insomnia.
Second-generation antihistamines cross the blood–brain barrier to a much lower degree than the first ones. This results in their primarily affecting peripheral histamine receptors, and therefore having a much lower sedative effect. High doses can still induce the central nervous system effect of drowsiness.
Antidepressants.
Some antidepressants have sedating effects. Some "may" increase actual quality of sleep (biologically) in contrast to Benzodiazepines that decrease quality.
Examples include:
Examples include:
Antipsychotics.
Examples of antipsychotics with sedation as a side effect:
Adverse effects.
Drowziness, dizziness, hangover, dependence

</doc>
<doc id="14273" url="https://en.wikipedia.org/wiki?curid=14273" title="HMS Dunraven">
HMS Dunraven

HMS "Dunraven" was a Q-Ship of the Royal Navy during World War I.
On 8 August 1917, 130 miles southwest of Ushant in the Bay of Biscay, disguised as the collier "Boverton" and commanded by Gordon Campbell, VC, "Dunraven" spotted , commanded by "Oberleutnant zur See" Reinhold Saltzwedel. Saltzwedel believed the disguised ship was a merchant vessel. The U-boat submerged and closed with "Dunraven" before surfacing astern at 11:43 am and opening fire at long range. "Dunraven" made smoke and sent off a panic party (a small number of men who "abandon ship" during an attack to continue the impersonation of a merchant).
Shells began hitting "Dunraven", detonating her depth charges and setting her stern afire. Her crew remained hidden letting the fires burn. Then a 4 inch (102 mm) gun and crew were blown away revealing "Dunraven"s identity as a warship, and "UC-71" submerged. A second "panic party" abandoned ship. "Dunraven" was hit by a torpedo. A third "panic party" went over the side, leaving only two guns manned. "UC-71" surfaced, shelled "Dunraven" and again submerged. Campbell replied with two torpedoes that missed, and around 3 pm, the undamaged U-boat left that area. Only one of "Dunraven"s crew was killed, but the Q-Ship was sinking.
The British destroyer picked up "Dunraven"s survivors and took her in tow for Plymouth, but "Dunraven" sank at 1:30 am early on 10 August 1917 to the north of Ushant.
In recognition, two Victoria Crosses were awarded, one to the ship's First Lieutenant, Lt. Charles George Bonner RNR, and the other, by ballot, to a gunlayer, Petty Officer Ernest Herbert Pitcher.
Captain Campbell later wrote:
Captain Campbell had been previously awarded the Victoria Cross, in February 1917, for the sinking of .

</doc>
<doc id="14275" url="https://en.wikipedia.org/wiki?curid=14275" title="Hacker ethic">
Hacker ethic

Hacker ethic is a term for the moral values and philosophy that are common in the hacker community. Whilst the philosophy originated at the Massachusetts Institute of Technology in the 1950s-1960s, the term "hacker ethic" is attributed to journalist Steven Levy as described in his 1984 book titled "." The key points within this ethic are access, freedom of information, and improvement to quality of life. While some tenets of hacker ethic were described in other texts like "Computer Lib/Dream Machines" (1974) by Ted Nelson, Levy appears to have been the first to document both the philosophy and the founders of the philosophy.
History.
Levy explains that MIT housed an early IBM 704 computer inside the Electronic Accounting Machinery (EAM) room in 1959. This room became the staging grounds for early hackers, as MIT students from the Tech Model Railroad Club sneaked inside the EAM room after hours to attempt programming the 30-ton, computer.
The MIT group defined a "hack" as a project undertaken or a product built to fulfill some constructive goal, but also with some wild pleasure taken in mere involvement. The term "hack" arose from MIT lingo, as the word had long been used to describe college pranks that MIT students would regularly devise. However, Levy's hacker ethic also has often been quoted out of context and misunderstood to refer to hacking as in breaking into computers, and so many sources incorrectly imply that it is describing the ideals of white-hat hackers. However, what Levy is talking about does not necessarily have anything particular to do with computer security, but addresses broader issues.
The hacker ethic was described as a "new way of life, with a philosophy, an ethic and a dream". However, the elements of the hacker ethic were not openly debated and discussed; rather they were implicitly accepted and silently agreed upon.
The free software movement was born in the early 1980s from followers of the hacker ethic. Its founder, Richard Stallman, is referred to by Steven Levy as "the last true hacker". Modern hackers who hold true to the hacker ethics—especially the Hands-On Imperative—are usually supporters of free and open source software. This is because free and open source software allows hackers to get access to the source code used to create the software, to allow it to be improved or reused in other projects.
Richard Stallman describes:
The hacker ethic refers to the feelings of right and wrong, to the ethical ideas this community of people had—that knowledge should be shared with other people who can benefit from it, and that important resources should be utilized rather than wasted.
and states more precisely that hacking (which Stallman defines as playful cleverness) and ethics are two separate issues:
Just because someone enjoys hacking does not mean he has an ethical commitment to treating other people properly. Some hackers care about ethics—I do, for instance—but that is not part of being a hacker, it is a separate trait. [...] Hacking is not primarily about an ethical issue. [...] hacking tends to lead a significant number of hackers to think about ethical questions in a certain way. I would not want to completely deny all connection between hacking and views on ethics.
The hacker ethics.
As Levy summarized in the preface of "Hackers", the general tenets or principles of hacker ethic include:
In addition to those principles, Levy also described more specific hacker ethics and beliefs in chapter 2, "The Hacker Ethic": The ethics he described in chapter 2 are:
Sharing.
From the early days of modern computing through to the 1970s, it was far more common for computer users to have the freedoms that are provided by an ethic of open sharing and collaboration. Software, including source code, was commonly shared by individuals who used computers. Most companies had a business model based on hardware sales, and provided or bundled the associated software free of charge. According to Levy's account, sharing was the norm and expected within the non-corporate hacker culture. The principle of sharing stemmed from the open atmosphere and informal access to resources at MIT. During the early days of computers and programming, the hackers at MIT would develop a program and share it with other computer users.
If the hack was deemed particularly good, then the program might be posted on a board somewhere near one of the computers. Other programs that could be built upon it and improved it were saved to tapes and added to a drawer of programs, readily accessible to all the other hackers. At any time, a fellow hacker might reach into the drawer, pick out the program, and begin adding to it or "bumming" it to make it better. Bumming referred to the process of making the code more concise so that more can be done in fewer instructions, saving precious memory for further enhancements.
In the second generation of hackers, sharing was about sharing with the general public in addition to sharing with other hackers. A particular organization of hackers that was concerned with sharing computers with the general public was a group called Community Memory. This group of hackers and idealists put computers in public places for anyone to use. The first community computer was placed outside of Leopold's Records in Berkeley, California.
Another sharing of resources occurred when Bob Albrecht provided considerable resources for a non-profit organization called the People's Computer Company (PCC). PCC opened a computer center where anyone could use the computers there for fifty cents per hour.
This second generation practice of sharing contributed to the battles of free and open software. In fact, when Bill Gates' version of BASIC for the Altair was shared among the hacker community, Gates claimed to have lost a considerable sum of money because few users paid for the software. As a result, Gates wrote an Open Letter to Hobbyists. This letter was published by several computer magazines and newsletters, most notably that of the Homebrew Computer Club where much of the sharing occurred.
Hands-On Imperative.
Many of the principles and tenets of hacker ethic contribute to a common goal: the Hands-On Imperative. As Levy described in Chapter 2, "Hackers believe that essential lessons can be learned about the systems—about the world—from taking things apart, seeing how they work, and using this knowledge to create new and more interesting things."
Employing the Hands-On Imperative requires free access, open information, and the sharing of knowledge. To a true hacker, if the Hands-On Imperative is restricted, then the ends justify the means to make it unrestricted "so that improvements can be made". When these principles are not present, hackers tend to work around them. For example, when the computers at MIT were protected either by physical locks or login programs, the hackers there systematically worked around them in order to have access to the machines. Hackers assumed a "willful blindness" in the pursuit of perfection.
This behavior was not malicious in nature: the MIT hackers did not seek to harm the systems or their users. This deeply contrasts with the modern, media-encouraged image of hackers who crack secure systems in order to steal information or complete an act of cyber-vandalism.
Community and collaboration.
Throughout writings about hackers and their work processes, a common value of community and collaboration is present. For example, in Levy's "Hackers", each generation of hackers had geographically based communities where collaboration and sharing occurred. For the hackers at MIT, it was the labs where the computers were running. For the hardware hackers (second generation) and the game hackers (third generation) the geographic area was centered in Silicon Valley where the Homebrew Computer Club and the People's Computer Company helped hackers network, collaborate, and share their work.
The concept of community and collaboration is still relevant today, although hackers are no longer limited to collaboration in geographic regions. Now collaboration takes place via the Internet. Eric S. Raymond identifies and explains this conceptual shift in "The Cathedral and the Bazaar":
Before cheap Internet, there were some geographically compact communities where the culture encouraged Weinberg's egoless programming, and a developer could easily attract a lot of skilled kibitzers and co-developers. Bell Labs, the MIT AI and LCS labs, UC Berkeley: these became the home of innovations that are legendary and still potent.
Raymond also notes that the success of Linux coincided with the wide availability of the World Wide Web. The value of community is still in high practice and use today.
Levy's "true hackers".
Levy identifies several "true hackers" who significantly influenced the hacker ethic. Some well-known "true hackers" include:
Levy also identified the "hardware hackers" (the "second generation", mostly centered in Silicon Valley) and the "game hackers" (or the "third generation"). All three generations of hackers, according to Levy, embodied the principles of the hacker ethic. Some of Levy's "second-generation" hackers include:
Levy's "third generation" practitioners of hacker ethic include:
Other descriptions.
In 2001, Finnish philosopher Pekka Himanen promoted the hacker ethic in opposition to the Protestant work ethic. In Himanen's opinion, the hacker ethic is more closely related to the virtue ethics found in the writings of Plato and of Aristotle. Himanen explained these ideas in a book, "The Hacker Ethic and the Spirit of the Information Age", with a prologue contributed by Linus Torvalds and an epilogue by Manuel Castells.
In this manifesto, the authors wrote about a hacker ethic centering on passion, hard work, creativity and joy in creating software. Both Himanen and Torvalds were inspired by the Sampo in Finnish mythology. The Sampo, described in the Kalevala saga, was a magical artifact constructed by Ilmarinen, the blacksmith god, that brought good fortune to its holder; nobody knows exactly what it was supposed to be. The Sampo has been interpreted in many ways: a world pillar or world tree, a compass or astrolabe, a chest containing a treasure, a Byzantine coin die, a decorated Vendel period shield, a Christian relic, etc. Kalevala saga compiler Lönnrot interpreted it to be a "quern" or mill of some sort that made flour, salt, and gold out of thin air.
The hacker ethic and its wider context can be associated with liberalism and anarchism.

</doc>
<doc id="14276" url="https://en.wikipedia.org/wiki?curid=14276" title="Hotel">
Hotel

A hotel is an establishment that provides lodging paid on a short-term basis. Facilities provided may range from a basic bed and storage for clothing, to luxury features like en-suite bathrooms. Larger hotels may provide additional guest facilities such as a swimming pool, business centre, childcare, conference facilities and social function services. Hotel rooms are usually numbered (or named in some smaller hotels and B&Bs) to allow guests to identify their room. Some hotels offer meals as part of a room and board arrangement. In the United Kingdom, a hotel is required by law to serve food and drinks to all guests within certain stated hours. In Japan, capsule hotels provide a minimized amount of room space and shared facilities.
The precursor to the modern hotel was the inn of medieval Europe. For a period of about 200 years from the mid-17th century, coaching inns served as a place for lodging for coach travelers. Inns began to cater for richer clients in the mid-18th century. One of the first hotels in a modern sense was opened in Exeter in 1768. Hotels proliferated throughout Western Europe and North America in the 19th century, and luxury hotels began to spring up in the later part of the century.
Hotel operations vary in size, function, and cost. Most hotels and major hospitality companies have set industry standards to classify hotel types. An upscale full-service hotel facility offers luxury amenities, full service accommodations, on-site full service restaurant(s), and the highest level of personalized service. Full service hotels often contain upscale full-service facilities with a large volume of full service accommodations, on-site full service restaurant(s), and a variety of on-site amenities. Boutique hotels are smaller independent non-branded hotels that often contain upscale facilities. Small to medium-sized hotel establishments offer a limited amount of on-site amenities. Economy hotels are small to medium-sized hotel establishments that offer basic accommodations with little to no services. Extended stay hotels are small to medium-sized hotels that offer longer term full service accommodations compared to a traditional hotel.
Timeshare and Destination clubs are a form of property ownership involving ownership of an individual unit of accommodation for seasonal usage. A motel is a small-sized low-rise lodging with direct access to individual rooms from the car park. Boutique hotels are typically hotels with a unique environment or intimate setting. A number of hotels have entered the public consciousness through popular culture, such as the Ritz Hotel in London. Some hotels are built specifically as a destination in itself, for example at casinos and holiday resorts.
Most hotel establishments consist of a General Manager who serves as the head executive (often referred to as the "Hotel Manager"), department heads who oversee various departments within a hotel, middle managers, administrative staff, and line-level supervisors. The organizational chart and volume of job positions and hierarchy varies by hotel size, function, and is often determined by hotel ownership and managing companies.
Etymology.
The word "hotel" is derived from the French "hôtel" (coming from the same origin as "hospital"), which referred to a French version of a building seeing frequent visitors, and providing care, rather than a place offering accommodation. In contemporary French usage, "hôtel" now has the same meaning as the English term, and "hôtel particulier" is used for the old meaning, as well as "hôtel" in some place names such as Hôtel-Dieu (in Paris), which has been a hospital since the Middle Ages. The French spelling, with the circumflex, was also used in English, but is now rare. The circumflex replaces the 's' found in the earlier "hostel" spelling, which over time took on a new, but closely related meaning. Grammatically, hotels usually take the definite article – hence "The Astoria Hotel" or simply "The Astoria."
History.
Facilities offering hospitality to travellers have been a feature of the earliest civilizations. In Greco-Roman culture hospitals for recuperation and rest were built at thermal baths. During the Middle Ages various religious orders at monasteries and abbeys would offer accommodation for travellers on the road.
The precursor to the modern hotel was the inn of medieval Europe, possibly dating back to the rule of Ancient Rome. These would provide for the needs of travelers, including food and lodging, stabling and fodder for the traveler's horse(s) and fresh horses for the mail coach. Famous London examples of inns include the George and the Tabard. A typical layout of an inn had an inner court with bedrooms on the two sides, with the kitchen and parlour at the front and the stables at the back.
For a period of about 200 years from the mid-17th century, coaching inns served as a place for lodging for coach travelers (in other words, a roadhouse). Coaching inns stabled teams of horses for stagecoaches and mail coaches and replaced tired teams with fresh teams. Traditionally they were seven miles apart but this depended very much on the terrain.
Some English towns had as many as ten such inns and rivalry between them was intense, not only for the income from the stagecoach operators but for the revenue for food and drink supplied to the wealthy passengers. By the end of the century, coaching inns were being run more professionally, with a regular timetable being followed and fixed menus for food.
Inns began to cater for richer clients in the mid-18th century, and consequently grew in grandeur and the level of service provided. One of the first hotels in a modern sense was opened in Exeter in 1768, although the idea only really caught on in the early 19th century. In 1812 Mivart's Hotel opened its doors in London, later changing its name to Claridge's.
Hotels proliferated throughout Western Europe and North America in the 19th century, and luxury hotels, including the Savoy Hotel in the United Kingdom and the Ritz chain of hotels in London and Paris and Tremont House and Astor House in the United States, began to spring up in the later part of the century, catering to an extremely wealthy clientele.
International scale.
Hotels cater to travelers from many countries and languages, since no one country dominates the travel industry.
Types.
Hotel operations vary in size, function, and cost. Most hotels and major hospitality companies that operate hotels have set widely accepted industry standards to classify hotel types. General categories include the following:
Upscale luxury.
An upscale full service hotel facility that offers luxury amenities, full service accommodations, on-site full service restaurant(s), and the highest level of personalized and professional service. Luxury hotels are normally classified with at least a Four Diamond or Five Diamond status or a Four or Five Star rating depending on the country and local classification standards. "Examples may include: InterContinental, Waldorf Astoria, Four Seasons, Conrad, Fairmont, and The Ritz-Carlton."
Full service.
Full service hotels often contain upscale full-service facilities with a large volume of full service accommodations, on-site full service restaurant(s), and a variety of on-site amenities such as swimming pools, a health club, children's activities, ballrooms, on-site conference facilities, and other amenities. Examples include: Starwood – Sheraton Westin, Hilton, Marriott, and Hyatt hotels.
Historic inns and boutique hotels.
Boutique hotels are smaller independent non-branded hotels that often contain upscale facilities of varying size in unique or intimate settings with full service accommodations. Boutique hotels are generally 100 rooms or less. Some historic inns and boutique hotels may be classified as luxury hotels. Examples include Hotel Indigo and Kimpton Hotels.
Focused or select service.
Small to medium-sized hotel establishments that offer a limited amount of on-site amenities that only cater and market to a specific demographic of travelers, such as the single business traveler. Most focused or select service hotels may still offer full service accommodations but may lack leisure amenities such as an on-site restaurant or a swimming pool. Examples include Crowne Plaza, Courtyard by Marriott and Hilton Garden Inn.
Economy and limited service.
Small to medium-sized hotel establishments that offer a very limited amount of on-site amenities and often only offer basic accommodations with little to no services, these facilities normally only cater and market to a specific demographic of travelers, such as the budget-minded traveler seeking a "no frills" accommodation. Limited service hotels often lack an on-site restaurant but in return may offer a limited complimentary food and beverage amenity such as on-site continental breakfast service. Examples include Hampton Inn, Aloft, Holiday Inn Express, Fairfield Inn, Four Points by Sheraton, and Days Inn.
Extended stay.
Extended stay hotels are small to medium-sized hotels that offer longer term full service accommodations compared to a traditional hotel. Extended stay hotels may offer non-traditional pricing methods such as a weekly rate that cater towards travelers in need of short-term accommodations for an extended period of time. Similar to limited and select service hotels, on-site amenities are normally limited and most extended stay hotels lack an on-site restaurant. Examples include Staybridge Suites, Homewood Suites by Hilton, Home2 Suites by Hilton, Residence Inn by Marriott, Element, and Extended Stay Hotels.
Timeshare and destination clubs.
Timeshare and Destination clubs are a form of property ownership also referred to as a vacation ownership involving the purchase and ownership of an individual unit of accommodation for seasonal usage during a specified period of time. Timeshare resorts often offer amenities similar that of a Full service hotel with on-site restaurant(s), swimming pools, recreation grounds, and other leisure-oriented amenities. Destination clubs on the other hand may offer more exclusive private accommodations such as private houses in a neighborhood-style setting. Examples of timeshare brands include Hilton Grand Vacations, Marriott Vacation Club International, Westgate Resorts, Starwood Vacation Ownership, and Disney Vacation Club.
Motel.
A motel is a small-sized low-rise lodging establishment similar to that of a limited service hotel, but with direct access to individual rooms from the car park. Common during the 1950s and 1960s, motels were often located adjacent to a major road, where they were built on inexpensive land at the edge of towns or along stretches of highways .
New motel construction is rare as hotel chains have been building economy limited service franchised properties at freeway exits which compete for largely the same clientele, largely saturating the market by the 1990s. They are still useful in less populated areas for driving travelers, but the more populated an area becomes the more hotels fill the need. Many of the motels which remain in operation have joined national franchise chains, rebranding themselves as hotels, inns or lodges.
Management.
Hotel management is a globally accepted professional career field and academic field of study. Degree programs such as hospitality management studies, a business degree, and/or certification programs formally prepare hotel managers for industry practice.
Most hotel establishments consist of a General Manager who serves as the head executive (often referred to as the "Hotel Manager"), department heads who oversee various departments within a hotel, middle managers, administrative staff, and line-level supervisors. The organizational chart and volume of job positions and hierarchy varies by hotel size, function, and is often determined by hotel ownership and managing companies.
Unique and specialty hotels.
Historic Inns and boutique hotels.
Boutique hotels are typically hotels with a unique environment or intimate setting.
Some hotels have gained their renown through tradition, by hosting significant events or persons, such as Schloss Cecilienhof in Potsdam, Germany, which derives its fame from the Potsdam Conference of the World War II allies Winston Churchill, Harry Truman and Joseph Stalin in 1945. The Taj Mahal Palace & Tower in Mumbai is one of India's most famous and historic hotels because of its association with the Indian independence movement. Some establishments have given name to a particular meal or beverage, as is the case with the Waldorf Astoria in New York City, United States where the Waldorf Salad was first created or the Hotel Sacher in Vienna, Austria, home of the Sachertorte. Others have achieved fame by association with dishes or cocktails created on their premises, such as the Hotel de Paris where the crêpe Suzette was invented or the Raffles Hotel in Singapore, where the Singapore Sling cocktail was devised.
A number of hotels have entered the public consciousness through popular culture, such as the Ritz Hotel in London, through its association with Irving Berlin's song, 'Puttin' on the Ritz'. The Algonquin Hotel in New York City is famed as the meeting place of the literary group, the Algonquin Round Table, and Hotel Chelsea, also in New York City, has been the subject of a number of songs and the scene of the stabbing of Nancy Spungen (allegedly by her boyfriend Sid Vicious).
Resort hotels.
Some hotels are built specifically as a destination in itself to create a captive trade, example at casinos and holiday resorts. Though of course hotels have always been built in popular destinations, the defining characteristic of a resort hotel is that it exists purely to serve another attraction, the two having the same owners.
On the Las Vegas Strip there is a tradition of one-upmanship with luxurious and extravagant hotels in a concentrated area. This trend now has extended to other resorts worldwide, but the concentration in Las Vegas is still the world's highest: nineteen of the world's twenty-five largest hotels by room count are on the Strip, with a total of over 67,000 rooms.
In Europe Center Parcs might be considered a chain of resort hotels, since the sites are largely man-made (though set in natural surroundings such as country parks) with captive trade, whereas holiday camps such as Butlins and Pontin's are probably not considered as resort hotels, since they are set at traditional holiday destinations which existed before the camps.
Bunker hotels.
The Null Stern Hotel in Teufen, Appenzellerland, Switzerland and the Concrete Mushrooms in Albania are former nuclear bunkers transformed into hotels.
Cave hotels.
The Cuevas Pedro Antonio de Alarcón (named after the author) in Guadix, Spain, as well as several hotels in Cappadocia, Turkey, are notable for being built into natural cave formations, some with rooms underground. The Desert Cave Hotel in Coober Pedy, South Australia is built into the remains of an opal mine.
Cliff hotels.
Located on the coast but high above sea level, these hotels offer unobstructed panoramic views and a great sense of privacy without the feeling of total isolation. Some examples from around the globe are the Riosol Hotel in Gran Canaria, Caruso Belvedere Hotel in Amalfi Coast (Italy), Aman Resorts Amankila in Bali, Birkenhead House in Hermanus (South Africa), The Caves in Jamaica and Caesar Augustus in Capri.
Capsule hotels.
Capsule hotels are a type of economical hotel first introduced in Japan, where people sleep in stacks of rectangular containers.
Ice, snow and igloo hotels.
Igloo Village in Kakslauttanen,the Ice Hotel in Jukkasjärvi, Sweden is the first ice hotel in the world, built in 1990, and the Hotel de Glace in Duschenay, Canada, melt every spring and are rebuilt each winter; the Mammut Snow Hotel in Finland is located within the walls of the Kemi snow castle; and the Lainio Snow Hotel is part of a snow village near Ylläs, Finland.
Garden hotels.
Garden hotels, famous for their gardens before they became hotels, include Gravetye Manor, the home of garden designer William Robinson, and Cliveden, designed by Charles Barry with a rose garden by Geoffrey Jellicoe.
Referral hotel.
A referral hotel is a hotel chain that offers branding to independently-operated hotels; the chain itself is founded by or owned by the member hotels as a group. Many former referral chains have been converted to franchises; the largest surviving member-owned chain is Best Western.
Railway hotels.
Frequently, expanding railway companies built grand hotels at their termini, such as the Midland Hotel, Manchester next to the former Manchester Central Station, and in London the ones above St Pancras railway station and Charing Cross railway station. London also has the Chiltern Court Hotel above Baker Street tube station, there are also Canada's grand railway hotels. They are or were mostly, but not exclusively, used by those traveling by rail.
Straw bale hotels.
The Maya Guesthouse in Nax Mont-Noble in the Swiss Alps, is the first hotel in Europe built entirely with straw bales. Due to the insulation values of the walls it needs no conventional heating or air conditioning system, although the Maya Guesthouse is built at an altitude of in the Alps.
Transit hotels.
Transit hotels are short stay hotels typically used at international airports where passengers can stay while waiting to change airplanes. The hotels are typically on the airside and do not require a visa for a stay.
Treehouse hotels.
Some hotels are built with living trees as structural elements, for example the Treehotel near Piteå, Sweden, the Costa Rica Tree House in the Gandoca-Manzanillo Wildlife Refuge, Costa Rica; the Treetops Hotel in Aberdare National Park, Kenya; the Ariau Towers near Manaus, Brazil, on the Rio Negro in the Amazon; and Bayram's Tree Houses in Olympos, Turkey.
Underwater hotels.
Some hotels have accommodation underwater, such as Utter Inn in Lake Mälaren, Sweden. Hydropolis, project in Dubai, would have had suites on the bottom of the Persian Gulf, and Jules' Undersea Lodge in Key Largo, Florida requires scuba diving to access its rooms.
Records.
Largest.
In 2006, "Guinness World Records" listed the First World Hotel in Genting Highlands, Malaysia, as the world's largest hotel with a total of 6,118 rooms. The Izmailovo Hotel in Moscow has the most rooms, with 7,500, followed by The Venetian and The Palazzo complex in Las Vegas (7,117 rooms) and MGM Grand Las Vegas complex (6,852 rooms).
Oldest.
According to the Guinness Book of World Records, the oldest hotel in operation is the Nisiyama Onsen Keiunkan in Yamanashi, Japan. The hotel, first opened in 707 A.D. has been operated by the same family for forty-six generations. The title was held until 2011 by the Hoshi Ryokan, in the Awazu Onsen area of Komatsu, Japan, which opened in the year 718, as the history of the Nisiyama Onsen Keiunkan was virtually unknown.
Highest.
The Ritz-Carlton Hong Kong claims to be the world's highest hotel. It is located on the top floors of the International Commerce Centre in Hong Kong, at above ground level.
Most expensive purchase.
In October 2014, the Anbang Insurance Group, based in China, purchased the Waldorf Astoria New York in Manhattan for US$1.95 billion, making it the world's most expensive hotel ever sold.
Living in hotels.
A number of public figures have notably chosen to take up semi-permanent or permanent residence in hotels.

</doc>
<doc id="14277" url="https://en.wikipedia.org/wiki?curid=14277" title="Hebrew mythology">
Hebrew mythology

Hebrew mythology may refer to:

</doc>
<doc id="14279" url="https://en.wikipedia.org/wiki?curid=14279" title="Hugh Hefner">
Hugh Hefner

Hugh Marston Hefner (born April 9, 1926) is an American adult magazine publisher, businessman, and a well-known playboy. Hefner is a native of Chicago, Illinois and a former journalist for "Esquire". Hefner is also a World War II veteran. He is best known for being the founder and chief creative officer of Playboy Enterprises. A self-made multi-millionaire, he is now worth over $43 million. Hefner is also a political activist and philanthropist active in several causes and public issues.
Early life.
Hugh Hefner was born in Chicago, Illinois on April 9, 1926. He is the first child of Grace Caroline (née Swanson; 1895–1997) and Glenn Lucius Hefner (1896–1976), who both worked as teachers. His parents were from Nebraska. He had a younger brother, Keith (1929–2016). Hefner's mother was of Swedish descent, and his father had German and English ancestry. Through his father's line, Hefner has stated that he is a direct descendant of Plymouth governor William Bradford. He has described his family as "conservative, Midwestern, Methodist".
He attended Sayre Elementary School and Steinmetz High School, then during World War II, served as a writer for a military newspaper in the U.S. Army from 1944 to 1946. Hugh graduated from the University of Illinois at Urbana Champaign with a bachelor of arts in psychology and a double minor in creative writing and art in 1949, earning his degree in two and a half years. After graduation, he took a semester of graduate courses in sociology at Northwestern University but dropped out soon after.
Career.
Working as a copywriter for "Esquire", he left in January 1952 after being denied a $5 raise. In 1953, he mortgaged his furniture, generating a bank loan of $600, and raised $8,000 from 45 investors, including $1,000 from his mother ("Not because she believed in the venture," he told "E!" in 2006, "but because she believed in her son."), to launch "Playboy", which was initially going to be called "Stag Party". The undated first issue, published in December 1953, featured Marilyn Monroe from her 1949 nude calendar shoot and sold over 50,000 copies. (Hefner, who never met Monroe, bought the crypt next to hers at the Westwood Village Memorial Park Cemetery.)
After it was rejected by "Esquire" magazine in 1955, Hefner agreed to publish in "Playboy" the Charles Beaumont science fiction short story "The Crooked Man", about straight men being persecuted in a world where homosexuality was the norm. After receiving angry letters to the magazine, Hefner wrote a response to criticism where he said, "If it was wrong to persecute heterosexuals in a homosexual society then the reverse was wrong, too." In 1961, Hefner watched Dick Gregory perform at the Herman Roberts Show Bar in Chicago. Based on that performance, Hefner hired Gregory to work at the Chicago Playboy Club; Gregory attributes the subsequent launch of his career to that night.
On June 4, 1963, Hefner was arrested for selling obscene literature after an issue of "Playboy" featuring nude shots of Jayne Mansfield was released. A jury was unable to reach a verdict.
In the 1993 "Simpsons" episode "Krusty Gets Cancelled", Hefner guest-voiced himself where he played a musical piece on the wine glasses.
In 1999, Hefner financed the Clara Bow documentary, "Discovering the It Girl." "Nobody has what Clara had. She defined an era and made her mark on the nation," he stated.
Hefner guest-starred as himself in a 2006 episode of Seth Green's "Robot Chicken" on the late-night programming block Adult Swim.
He has a star on the Hollywood Walk of Fame for television and has made several movie appearances as himself. In 2009, he received a "worst supporting actor" nomination for a Razzie award for his performance in "Miss March".
A documentary by Brigitte Berman, "", was released on July 30, 2010. He had previously granted full access to documentary filmmaker and television producer Kevin Burns for the A&E "Biography" special "Hugh Hefner: American Playboy" in 1996. Hefner and Burns later collaborated on numerous other television projects, most notably on "The Girls Next Door", a reality series that ran for six seasons (2005–2009) and 90 episodes.
Personal life.
In 1949, Hefner married Northwestern University student Mildred Williams (born 1926). They had two children: daughter Christie Hefner (born 1952) and son David (born 1955). Before the wedding, Mildred confessed that she had an affair while he was away in the army. He called the admission "the most devastating moment of my life." A 2006 "E! True Hollywood Story" profile of Hefner revealed that Mildred allowed him to have sex with other women, out of guilt for her infidelity and in the fond hope that it would preserve their marriage. The two were divorced in 1959.
Hefner remade himself as a bon viveur and man about town, a lifestyle he promoted in his magazine and two TV shows he hosted, "Playboy's Penthouse" (1959–1960) and "Playboy After Dark" (1969–1970). He admitted to being involved' with maybe eleven out of twelve months' worth of Playmates" during some of these years. Donna Michelle, Marilyn Cole, Lillian Müller, Shannon Tweed, Barbi Benton, Karen Christy, Sondra Theodore, and Carrie Leigh — who filed a $35 million palimony suit against him — were a few of his many lovers. In 1971, he acknowledged that he experimented in bisexuality. He moved from Chicago to Los Angeles.
Hefner had a minor stroke in 1985 at the age of 59. After re-evaluating his lifestyle, he made several changes. The wild, all-night parties were toned down significantly and in 1988, daughter Christie began to run the Playboy empire. The following year, he married Playmate of the Year Kimberley Conrad. The couple had two sons: Marston Glenn (born 1990) and Cooper Bradford (born 1991). The "E! True Hollywood Story" profile noted that the notorious Playboy Mansion had been transformed into a family-friendly homestead. After he and Conrad separated in 1998 she moved into a house next door to the mansion.
In January 2009, Hefner started dating Crystal Harris, joining the Shannon Twins after his previous "number one girlfriend", Holly Madison, had ended their 7-year relationship. On December 24, 2010, he became engaged to Harris, to become his third wife. Harris broke off their engagement on June 14, 2011, five days before their planned wedding. In anticipation of the wedding, the July issue of "Playboy", which reached store shelves and customer's homes within days of the wedding date, featured Harris on the cover and in a photo spread as well. The headline on the cover read "Introducing America's Princess, Mrs. Crystal Hefner". It was later covered on newsstand issues with a sticker that read "Runaway Bride". The two later reconciled, and on December 31, 2012, Harris and Hefner married at the Playboy Mansion in a small private ceremony; he was 86 and she was 26.
Keith, his younger brother, succumbed to cancer at the age of 87, merely one day before Hugh's 90th birthday.
Playboy Mansion.
Hefner became known for moving an ever-changing coterie of young women into the Playboy Mansion, including twins Sandy and Mandy Bentley. He dated as many as seven women concurrently. He also dated Brande Roderick, Izabella St. James, Tina Marie Jordan, Holly Madison, Bridget Marquardt, and Kendra Wilkinson. Madison, Wilkinson and Marquardt appeared on "The Girls Next Door" depicting their lives at the Playboy Mansion. In October 2008, all three girls decided to leave the mansion. Hefner soon began dating his new "Number One" girlfriend, Crystal Harris, along with identical twin models Kristina and Karissa Shannon. The relationship with the twins ended in January 2010. After an 11-year separation, Hefner filed for divorce from Conrad stating irreconcilable differences. Hefner has stated that he only remained nominally married to her for the sake of his children, and his youngest child had just turned 18. The divorce was finalized in March 2010. On December 24, 2010, Hefner presented an engagement ring to Crystal Harris, publicly announcing the proposal the following day. Hefner and Harris had planned to marry June 18, 2011. Harris called off the wedding just 5 days before they were due to be wed. Twenty-six-year-old Harris and eighty-six-year-old Hefner reconciled and were married on December 31, 2012.
In 2012, Hefner announced that his youngest son, Cooper, would likely succeed him as the public face of "Playboy".
In January 2016, the Playboy Mansion was put on the market for $200 million, on condition that Hugh Hefner would continue to work and live in the mansion.
Politics and philanthropy.
The Hugh Hefner First Amendment Award was created by Christie Hefner "to honor individuals who have made significant contributions in the vital effort to protect and enhance First Amendment rights for Americans."
He has donated and raised money for the Democratic Party. However, he has more recently referred to himself as an independent due to disillusionment with both the Democratic and Republican parties.
In 1978, Hefner helped organize fund-raising efforts that led to the restoration of the Hollywood Sign. He hosted a gala fundraiser at the Playboy Mansion and personally contributed $27,000 (or 1/9 of the total restoration costs) by purchasing the letter Y in a ceremonial auction.
Hefner donated $100,000 to the University of Southern California's School of Cinematic Arts to create a course called "Censorship in Cinema," and $2 million to endow a chair for the study of American film.
Both through his charitable foundation and individually, Hefner also contributes to charities outside the sphere of politics and publishing, throwing fundraiser events for Much Love Animal Rescue as well as Generation Rescue, a controversial anti-vaccinationist campaign organization supported by Jenny McCarthy.
On November 18, 2010, Children of the Night founder and president Dr. Lois Lee presented Hefner with the organization's first-ever Founder's Hero of the Heart Award in appreciation for his unwavering dedication, commitment and generosity.
On April 26, 2010, Hefner donated the last $900,000 sought by a conservation group for a land purchase needed to stop the development of the famed vista of the Hollywood Sign.
"Sylvilagus palustris hefneri", an endangered subspecies of Marsh rabbit, is named after him in honor of financial support that he provided.
Hefner supported legalizing same-sex marriage and he stated that a fight for gay marriage was "a fight for all our rights. Without it, we will turn back the sexual revolution and return to an earlier, puritanical time."

</doc>
<doc id="14280" url="https://en.wikipedia.org/wiki?curid=14280" title="Hafizullah Amin">
Hafizullah Amin

Hafizullah Amin ( born 1 August 1929 – 27 December 1979) was an Afghan politician and statesman during the Cold War. Amin was born in Paghman and educated at Kabul University, after which he started his career as a teacher. After a few years in that occupation, he went to the United States to study. He would visit the United States a second time before moving permanently to Afghanistan, and starting his career in radical politics. He ran as a candidate in the 1965 parliamentary election but failed to secure a seat. Amin was the only Khalqist elected to parliament in the 1969 parliamentary election, thus increasing his standing within the party. He was one of the leading organisers of the Saur Revolution which overthrew the government of Mohammad Daoud Khan.
Amin's short-lived presidency was marked by controversies from beginning to end. He came to power by ordering the death of his predecessor Nur Muhammad Taraki. The revolt against communist rule which had begun under Taraki worsened under Amin, and was a problem that his government was unable to solve. The Soviet Union, which alleged that Amin was an agent of the CIA, intervened in Afghanistan on behalf of the Twenty-Year Treaty of Friendship between Afghanistan and the Soviet Union. Amin was assassinated by the Soviets in December 1979 as part of Operation Storm-333, having ruled for slightly longer than three months.
Early life and career.
Hafizullah Amin was born to a Ghilzai Pashtun family in Paghman on 1 August 1929. His father, a civil servant, died when he was still very young. Thanks to his brother Abdullah, a primary school teacher, Amin was able to attend both primary and secondary school, which in turn allowed him to attend Kabul University (KU). After studying mathematics there, he also graduated from the Darul Mualimeen Teachers College in Kabul, and became a teacher. Amin later became vice-principal of the Darul Mualimeen College, and then principal of the prestigious Avesina High School, and in 1957 left Afghanistan for Columbia University in New York City, where he earned M. A. in education. It was at Columbia that Amin became attracted to Marxism, and in 1958 he became a member of the university's Socialist Progressive Club. When he returned to Afghanistan, Amin became a teacher at Kabul University, and later, for the second time, the principal of Avesina High School. During this period Amin became acquainted with Nur Muhammad Taraki, a communist. Around this time, Amin quit his position as principal of Avesina High School in order to become principal of the Darul Mualimeen College.
It is alleged that Amin became radicalised during his second stay in the United States in 1962, when he enrolled in a work-study group at the University of Wisconsin. Amin studied in the doctoral programme at the Columbia University Teachers College, but started to neglect his studies in favour of politics; in 1963 he became head of the Afghan students' association at the college. When he returned to Afghanistan in the mid-1960s, the route flew to Afghanistan by way of Moscow. There, Amin met the Afghan ambassador to the Soviet Union, his old friend Ali Ahmad Popel, a previous Afghan Minister of Education. During his short stay, Amin became even more radicalised. Some people, Nabi Misdaq for instance, do not believe he travelled through Moscow, but rather West Germany and Lebanon. By the time he had returned to Afghanistan, the Communist People's Democratic Party of Afghanistan (PDPA) had already held its founding congress, which was in 1965. Amin ran as a candidate for the PDPA in the 1965 parliamentary election, and lost by a margin of less than fifty votes.
In 1966, when the PDPA Central Committee was expanded, Amin was elected as a non-voting member, and in the spring of 1967 he gained full membership. Amin's standing in the Khalq faction of the PDPA increased when he was the only Khalqist elected to parliament in the 1969 parliamentary election. When the PDPA split along factional lines in 1967, between Khalqists led by Nur and Parchamites led by Babrak Karmal, Amin joined the Khalqists. As a member of parliament, Amin tried to win over support from the Pashtun people in the armed forces. According to a biography about Amin, he used his position as member of parliament to fight against imperialism, feudalism, and reactionary tendencies, and fought against the "rotten" regime, the monarchy. Amin himself said that he used his membership in parliament to pursue the class struggle against the bourgeoisie. Relations between Khalqists and Parchamites deteriorated during this period. Amin, the only Khalq member of parliament, and Babrak Karmal, the only Parcham member of parliament, did not cooperate with each other. Amin would later, during his short stint in power, mention these events with bitterness. Following the arrest of fellow PDPA members Dastagir Panjsheri and Saleh Mohammad Zeary in 1969, Amin became one of the party's leading members, and was still a pre-eminent party member by the time of their release in 1973.
The Daoud era.
From 1973 until the PDPA unification in 1977, Amin was second only to Taraki in the Khalqist PDPA. When the PDPA ruled Afghanistan, their relationship was referred to as a disciple (Amin) following his mentor (Taraki). This official portrayal of the situation was misleading; their relationship was more work-oriented. Taraki needed Amin's "tactical and strategic talents"; Amin's motivations are more uncertain, but it is commonly believed that he associated with Taraki to protect his own position. Amin had attracted many enemies during his career, the most notable being Karmal. According to the official version of events, Taraki protected Amin from party members or others who wanted to hurt the PDPA and the country.
When Mohammed Daoud Khan ousted the monarchy, and established the Republic of Afghanistan, the Khalqist PDPA offered its support for the new regime if it established a National Front which presumably included the Khalqist PDPA itself. The Parchamite PDPA had already established an alliance with Daoud at the beginning of his regime, and Karmal called for the dissolution of the Khalqist PDPA. Karmal's call for dissolution only worsened relations between the Khalqist and Parchamite PDPA. However, Taraki and Amin were lucky; Karmal's alliance actually hurt the Parchamites' standing in Afghan politics. Some communists in the armed forces became disillusioned with the government of Daoud, and turned to the Khalqist PDPA because of its apparent independence. Parchamite association with the Daoud government indirectly led to the Khalqist-led PDPA coup of 1978, popularly referred to as the Saur Revolution. From 1973 until the 1978 coup, Amin was responsible for organising party work in the Afghan armed forces. According to the official version, Amin "met patriotic liaison officers day or night, in the desert or the mountains, in the fields or the forests, enlightening them on the basis of the principles of the working class ideology." Amin's success in recruiting military officers lay in the fact that Daoud "betrayed the left" soon after taking power. When Amin began recruiting military officers for the PDPA, it was not difficult for him to find disgruntled military officers. In the meantime, relations between the Parchamite and Khalqist PDPA deteriorated; in 1973 it was rumoured that Major Zia Mohammadzai, a Parchamite and head of the Republican Guard, planned to assassinate the entire Khalqist leadership. The plan, if true, failed because the Khalqists found out about it.
The assassination attempt proved to be a further blow to relations between the Parchamites and Khalqists. The Parchamites deny that they ever planned to assassinate the Khalqist leadership, but historian Beverley Male argues that Karmal's subsequent activities give credence to the Khalqist view of events. Because of the Parchamite assassination attempt, Amin pressed the Khalqist PDPA to seize power in 1976 by ousting Daoud. The majority of the PDPA leadership voted against such a move. The following year, in 1977, the Parchamites and Khalqists officially reconciled, and the PDPA was unified. The Parchamite and Khalqist PDPAs, which had separate general secretaries, politburos, central committees and other organisational structures, were officially unified in the summer of 1977. One reason for unification was that the international communist movement, represented by the Communist Party of India, Iraqi Communist Party and the Communist Party of Australia, called for party unification.
Saur Revolution.
On 18 April 1978 Mir Akbar Khyber, the chief ideologue of the Parcham faction, was killed; he was commonly believed to have been assassinated by the Daoud government. Khyber's assassination initiated a chain of events which led to the PDPA taking power eleven days later, on 27 April. The assassin was never caught, but Anahita Ratebzad, a Parchamite, believed that Amin had ordered the assassination. Khyber's funeral evolved into a large anti-government demonstration. Daoud, who did not understand the significance of the events, began a mass arrest of PDPA members seven days after Khyber's funeral. Amin, who organised the subsequent revolution against Daoud, was one of the last Central Committee members to be arrested by the authorities. His late arrest can be considered as proof of the regime's lack of information; Amin was the leading revolutionary party organiser. The government's lack of awareness was proven by the arrest of Taraki – Taraki's arrest was the pre-arranged signal for the revolution to commence. When Amin found out that Taraki had been arrested, he ordered the revolution to begin at 9am on 27 April. Amin, in contrast to Taraki, was not imprisoned, but instead put under house arrest. His son, Abdur Rahman, was still allowed freedom of movement. The revolution was successful, thanks to overwhelming support from the Afghan military; for instance, it was supported by Defence Minister Ghulam Haidar Rasuli, Aslam Watanjar the commander of the ground forces, and the Chief of Staff of the Afghan Air Force, Abdul Qadir.
PDPA rule.
Khalq–Parcham break.
After the Saur revolution, Taraki was appointed Chairman of the Presidium of the Revolutionary Council and Chairman of the Council of Ministers, and retained his post as PDPA general secretary. Taraki initially formed a government which consisted of both Khalqists and Parchamites; Karmal became Deputy Chairman of the Revolutionary Council while Amin became Minister of Foreign Affairs and a Deputy Chairman of the Council of Ministers, and Mohammad Aslam Watanjar became a Deputy Chairman of the Council of Ministers. The two Parchamites Abdul Qadir and Mohammad Rafi became Minister of National Defence and Minister of Public Works respectively. According to Angel Rasanayagam, the appointment of Amin, Karmal and Watanjar as Deputy Chairmen of the Council of Ministers led to the establishment of three cabinets; the Khalqists were answerable to Amin, the Parchamites were answerable to Karmal, and the military officers (who were Parchamites) were answerable to Watanjar. The first conflict between the Khalqists and Parchamites arose when the Khalqists wanted to give PDPA Central Committee membership to the military officers who participated in the Saur Revolution. Amin, who had previously opposed the appointment of military officers to the PDPA leadership, switched sides; he now supported their elevation. The PDPA Politburo voted in favour of giving membership to the military officers; the victors (the Khalqists) portrayed the Parchamites as opportunists, implying that the Parchamites had ridden the revolutionary wave, but not actually participated in the revolution. To make matters worse for the Parchamites, the term Parcham was, according to Taraki, a word synonymous with factionalism.
On 27 June 1978, three months after the revolution, Amin managed to outmaneuver the Parchamites at a Central Committee meeting. The meeting decided that the Khalqists had exclusive rights to formulate and decide policy, a policy which left the Parchamites impotent. Karmal was exiled, but was able to establish a network with the remaining Parchamites in government. A coup to overthrow Amin was planned for September. Its leading members in Afghanistan were Qadir, the defence minister, and Army Chief of Staff General Shahpur Ahmedzai. The coup was planned for 4 September, on the Festival of Eid, because soldiers and officers would be off duty. The conspiracy failed when the Afghan ambassador to India told the Afghan leadership about the plan. A purge was initiated, and Parchamite ambassadors were recalled; few returned, for example Karmal and Mohammad Najibullah both stayed in their assigned countries.
Amin–Taraki break.
The Afghan people revolted against the PDPA government when the government introduced several socialist reforms, including land reforms. By early 1979, twenty-five out of Afghanistan's twenty-eight provinces were unsafe because of armed resistance against the government. On 29 March 1979, the Herat uprising began; the uprising turned the revolt into an open war between the Mujahideen and the Afghan government. It was during this period that Amin became Kabul's strongman. Shortly after the Herat uprising had been crushed, the Revolutionary Council convened to ratify the new Five-Year Plan, the Afghan–Soviet Friendship Treaty, and to vote on whether or not to reorganise the Council of Ministers and to enhance the power of the executive (the Chairman of the Revolutionary Council). While the official version of events said that all issues were voted on democratically at the meeting, the Revolutionary Council held another meeting the following day to ratify the new Five-Year Plan and to discuss the reorganisation of the Council of Ministers.
Alexander Puzanov, the Soviet ambassador to Afghanistan, was able to persuade Aslam Watanjar, Sayed Mohammad Gulabzoy and Sherjan Mazdoryar to become part of a conspiracy against Amin. These three men put pressure on Taraki, who by this time believed that "he really was the 'great leader'", to sack Amin from office. It is unknown if Amin knew anything about the conspiracy against him, but it was after the reorganisation of the Council of Ministers had taken place that he talked about his dissatisfaction. On 26 March the PDPA Politburo and the Council of Ministers approved the extension of the powers of the executive branch, and the establishment of the Homeland Higher Defence Council (HHDC) to handle security matters. Many analysts of the day regarded Amin's appointment to the Chairmanship of the Council of Ministers as an increase in his powers at the expense of Taraki. However, the reorganisation of the Council of Ministers and the strengthening of Taraki's position as Chairman of the Revolutionary Council, had reduced the authority of the Chairman of the Council of Ministers. The Council of Ministers chairman was, due to the strengthening of the executive, now appointed by the Chairman of the Revolutionary Council. While Amin could appoint and dismiss new ministers, he needed the consent of Taraki to actually do so. Another problem for Amin was that while the Council of Ministers was responsible to the Revolutionary Council and its chairman, individual ministers were only responsible to Taraki. When Amin became Chairman of the Council of Ministers, he was responsible for planning, finance and budgetary matters, the conduct of foreign policy, and for order and security. The order and security responsibilities had been taken over by the HHDC, which was chaired by Taraki. While Amin was HHDC Deputy Chairman, the majority of HHDC members were members of the anti-Amin faction. For instance, the HHDC membership included Watanjar the Minister of National Defence, Interior Minister Mazdoryar, the President of the Political Affairs of the Armed Forces Mohammad Iqbal, Mohammad Yaqub, the Chief of the General Staff, the Commander of the Afghan Air Force Nazar Mohammad and Assadullah Sarwari the head of ASGA, the Afghan secret police.
The order of precedence had been institutionalised, whereby Taraki was responsible for defence and Amin responsible for assisting Taraki in defence related matters. Amin's position was given a further blow by the democratisation of the decision-making process, which allowed its members to contribute; most of them were against Amin. Another problem for Amin was that the office of HHDC Deputy Chairman had no specific functions or powers, and the appointment of a new defence minister who opposed him drastically weakened his control over the Ministry of National Defence. The reorganisation of ministers was a further blow to Amin's position; he had lost control of the defence ministry, the interior ministry and the ASGA. Amin still had allies at the top, many of them in strategically important positions, for instance, Yaqub was his brother-in-law and the Security Chief in the Ministry of Interior was Sayed Daoud Taroon, who was also later appointed to the HHDC as an ordinary member in April. Amin succeeded in appointing two more of his allies to important positions; Mohammad Sediq Alemyar as Minister of Planning and Khayal Mohammad Katawazi as Minister of Information and Culture; and Faqir Mohammad Faqir was appointed Deputy Chairman of the Council of Ministers in April 1978. Amin's political position was not secure when Alexei Yepishev, the Head of the Main Political Directorate of the Soviet Army and Navy, visited Kabul. Yepishev met personally with Taraki on 7 April, but never met with Amin. The Soviets were becoming increasingly worried about Amin's control over the Afghan military. Even so, during Yepishev's visit Amin's position was actually strengthened; Taroon was appointed Taraki's aide-de-camp.
Soon after, at two meetings of the Council of Ministers, the strengthening of the executive powers of the Chairman of the Revolutionary Council was proven. Even though Amin was Chairman of the Council of Ministers, Taraki chaired the meetings instead of him. Amin's presence at these two meetings was not mentioned at all, and it was made clear that Taraki, through his office as Chairman of the Revolutionary Council, also chaired the Council of Ministers. Another problem facing Amin was Taraki's policy of autocracy; he tried to deprive the PDPA Politburo of its powers as a party and state decision-making organ. The situation deteriorated when Amin personally warned Taraki that "the prestige and popularity of leaders among the people has no common aspect with a personality cult."
Factionalism within the PDPA made it ill prepared to handle the intensified counter-revolutionary activities in the country. Amin tried to win support for the communist government by depicting himself as a devout Muslim. Taraki and Amin blamed different countries for helping the counter-revolutionaries; Amin attacked the United Kingdom and the British Broadcasting Corporation (BBC) and played down American and Chinese involvement, while Taraki blamed American imperialism and Iran and Pakistan for supporting the uprising. Amin's criticism of the United Kingdom and the BBC fed on the traditional anti-British sentiments held by rural Afghans. In contrast to Taraki, "Amin bent over backwards to avoid making hostile reference to", China, the United States or other foreign governments. Amin's cautious behavior was in deep contrast to the Soviet Union's official stance on the situation; it seemed, according to Beverley Male, that the Soviet leadership tried to force a confrontation between Afghanistan and its enemies. Amin also tried to appease the Shia communities by meeting with their leaders; despite this, a section of the Shia leadership called for the continuation of the resistance. Subsequently a revolt broke out in a Shia populated district in Kabul; this was the first sign of unrest in Kabul since the Saur Revolution. To add to the government's problems, Taraki's ability to lead the country was questioned – he was a heavy drinker and was not in good health. Amin on the other hand was characterised in this period by portrayals of strong self-discipline. In the summer of 1979 Amin began to disassociate himself from Taraki. On 27 June Amin became a member of the PDPA Politburo, the leading decision-making body in Afghanistan.
Rise to power.
In-mid July the Soviets made their view official when "Pravda" wrote an article about the situation in Afghanistan; the Soviets did not wish to see Amin become leader of Afghanistan. This triggered a political crisis in Afghanistan, as Amin initiated a policy of extreme repression, which became one of the main reasons for the Soviet intervention later that year. On 28 July, a vote in the PDPA Politburo approved Amin's proposal of creating a collective leadership with collective decision-making; this was a blow to Taraki, and many of his supporters were replaced by pro-Amin PDPA members. Ivan Pavlovsky, the Commander of the Soviet Ground Forces, visited Kabul in mid-August to study the situation in Afghanistan. Amin, in a speech just a few days after Pavlovsky's arrival, said that he wanted closer relations between Afghanistan and the People's Republic of China; in the same speech he hinted that he had reservations about Soviet meddling in Afghanistan. He likened Soviet assistance to Afghanistan with Vladimir Lenin's assistance to the Hungarian Soviet Republic in 1919. Taraki, a delegate to the conference held by the Non-Aligned Movement in Havana, met personally with Andrei Gromyko, the Soviet Minister of Foreign Affairs, to discuss the Afghanistan situation on 9 September. Shah Wali, the Minister of Foreign Affairs, who was a supporter of Amin, did not participate in the meeting. This, according to Beverley Male, "suggested that some plot against Amin was in preparation". Within hours of his return to Kabul on 11 September, Taraki convened the Council of Ministers "ostensibly to report on the Havana Summit". Instead of reporting on the summit, Taraki tried to dismiss Amin as Chairman of the Council of Ministers. This was a miscalculation, and all but the Gang of Four (consisting of Watanjar, Mazdoryar, Gulabzoi and Sarwari), supported retaining Amin as the Chairman of the Council of Ministers.
Taraki sought to neutralise Amin's power and influence by requesting that he serve overseas as an ambassador. Amin turned down the proposal, shouting "You are the one who should quit! Because of drink and old age you have taken leave of your senses." The following day Taraki invited Amin to the presidential palace for lunch with him and the Gang of Four. Amin turned down the offer, stating he would prefer their resignation rather than lunching with them. Soviet ambassador Puzanov persuaded Amin to make the visit to the Presidential Palace along with Taroon, the Chief of Police and Nawab Ali (an intelligence officer). Upon arriving at the palace, unknown individuals within the building opened fire on the visitors. Taroon was killed, while Ali sustained an injury and escaped, together with Amin, who was unharmed. Shortly afterward, Amin returned to the palace with a contingent of Army officers, and placed Taraki under arrest. The Gang of Four, however, had "disappeared" and their whereabouts would remain unknown for the duration of Amin's 104-day rule. After Taraki's arrest, Amin reportedly discussed the incident with Leonid Brezhnev, and indirectly asked for the permission to kill Taraki. Brezhnev replied that it was his choice. Amin, who now believed he had the full support of the Soviets, ordered the death of Taraki. Taraki was subsequently suffocated with pillows. The Afghan media would report that the ailing Taraki had died, omitting any mention of his murder.
Presidency.
Domestic policies.
Following Taraki's fall from power, Amin was elected Chairman of the Presidum of the Revolutionary Council and General Secretary of the PDPA Central Committee by the PDPA Politburo. The election of Amin as PDPA General Secretary and the removal of Taraki from all party posts was unanimous. The only members of the Council of Ministers replaced when Amin took power were the Gang of Four – Beverley Male saw this as "a clear indication that he had their of the Council of Ministers support". Amin's rise to power was followed by a policy of moderation, and attempts to persuade the Afghan people that the regime was not anti-Islamic. Amin's government began to invest in the reconstruction, or reparation, of mosques. He also promised the Afghan people freedom of religion. Religious groups were given copies of the Quran, and Amin began to refer to Allah in speeches. He even claimed that the Saur Revolution was "totally based on the principles of Islam". The campaign proved to be unsuccessful, and many Afghans held Amin responsible for the regime's totalitarian behavior. Amin's rise to power was officially endorsed by the Jamiatul Ulama on 20 September 1979. Their endorsement led to the official announcement that Amin was a pious Muslim – Amin thus scored a point against the counter-revolutionary propaganda which claimed the communist regime was atheist. Amin also tried to increase his popularity with tribal groups, a feat Taraki had been unable or unwilling to achieve. In a speech to tribal elders Amin was defensive about the Western way he dressed; an official biography was published which depicted Amin in traditional Pashtun clothes. During his short stay in power, Amin became committed to establishing a collective leadership; when Taraki was ousted, Amin promised "from now on there will be no one-man government..."
Attempting to pacify the population, Amin released a list of 18,000 people who had been executed, and blamed the executions on Taraki. The total number of arrested during Taraki's and Amin's combined reign number between 17,000 and 45,000. Amin was not liked by the Afghan people. During his rule, opposition to the communist regime increased, and the government lost control of the countryside. The state of the Afghan military deteriorated; due to desertions the number of military personnel in the Afghan army decreased from 100,000 in the immediate aftermath of the Saur Revolution, to somewhere between 50,000 and 70,000. Another problem Amin faced was the KGB's penetration of the PDPA, the military and the government bureaucracy. While Amin's position in Afghanistan was becoming more perilous by the day, his enemies who were exiled in the Soviet Union and the Eastern Bloc were agitating for his removal. Babrak Karmal, the Parchamite leader, met several leading Eastern Bloc figures during this period, and Mohammad Aslam Watanjar, Sayed Mohammad Gulabzoy and Assadullah Sarwari wanted to exact revenge upon Amin.
Foreign policy.
When Amin became leader, he tried to reduce Afghanistan's dependence on the Soviet Union. To accomplish this, he aimed to balance Afghanistan's relations with the Soviet Union by strengthening relations with Pakistan and Iran. The Soviets were concerned when they received reports that Amin had met personally with Gulbuddin Hekmatyar, one of the leading anti-communists in Afghanistan. His general untrustworthiness and his unpopularity amongst Afghans made it more difficult for Amin to find new "foreign patrons". Amin's involvement in the death of Adolph Dubs, the American Ambassador to Afghanistan, strained his relations with the United States. He tried to improve relations by reestablishing contact, met with three different American chargé d'affaires, and was interviewed by an American correspondent. But this did not improve Afghanistan's standing in the eyes of the United States Government. After the third meeting with Amin, J. Bruce Amstutz, the American Ambassador to Afghanistan from 1979 to 1980, believed the wisest thing to do was to maintain "a low profile, trying to avoid issues, and waiting to see what happens". In early December 1979, the Ministry of Foreign Affairs proposed a joint summit meeting between Amin and Muhammad Zia-ul-Haq, the President of Pakistan. The Pakistanti Government, accepting a modified version of the offer, agreed to send Agha Shahi, the Pakistani foreign minister, to Kabul for talks. In the meanwhile, the Inter-Services Intelligence (ISI), Pakistani's secret police, continued to train Mujahideen fighters who opposed the communist regime.
Afghan–Soviet relations.
Contrary to popular belief, the Soviet leadership headed by Leonid Brezhnev, Alexei Kosygin and the Politburo, were not eager to send troops to Afghanistan. The Soviet Politburo decisions were guided by a Special Commission on Afghanistan, which consisted of Yuri Andropov the KGB Chairman, Andrei Gromyko the Minister of Foreign Affairs, Defence Minister Dmitriy Ustinov, and Boris Ponomarev, the head of the International Department of the Central Committee. The Politburo was opposed to the removal of Taraki and his subsequent murder. According to Brezhnev, the General Secretary of the Central Committee of the Communist Party of the Soviet Union, "Events developed so swiftly in Afghanistan that essentially there was little opportunity to somehow interfere in them. Right now our mission is to determine our further actions, so as to preserve our position in Afghanistan and to secure our influence there." Although Afghan–Soviet relations deteriorated during Amin's short stint in power, he was invited on an official visit to Moscow by Alexander Puzanov, the Soviet ambassador to Afghanistan, because of the Soviet leadership's satisfaction with his party and state-building policy. Not everything went as planned, and Andropov talked about "the undesirable turn of events" taking place in Afghanistan under Amin's rule. Andropov also brought up the ongoing political shift in Afghanistan under Amin; the Soviets were afraid that Amin would move Afghanistan's foreign policy from a pro-Soviet position to a pro-United States position. By early-to-mid December 1979, the Soviet leadership had established an alliance with Babrak Karmal and Assadullah Sarwari.
As it turned out, the relationship between Puzanov and Amin broke down. Amin started a smear campaign to discredit Puzanov. This in turn led to an assassination attempt against Amin, in which Puzanov participated. The situation was worsened by the KGB accusing Amin of misrepresenting the Soviet position on Afghanistan in the PDPA Central Committee and the Revolutionary Council. The KGB also noted an increase in anti-Soviet agitation by the government during Amin's rule, and harassment against Soviet citizens increased under Amin. A group of senior politicians reported to the Soviet Central Committee that it was necessary to do "everything possible" to prevent a change in political orientation in Afghanistan. However, the Soviet leadership did not advocate intervention at this time, and instead called for increasing its influence in the Amin leadership to expose his "true intentions". A Soviet Politburo assessment referred to Amin as "a power-hungry leader who is distinguished by brutality and treachery". Amongst the many sins they alleged were his "insincerity and duplicity" when dealing with the Soviet Union, creating fictitious accusations against PDPA-members who opposed him, indulging in a policy of nepotism, and his tendency to conduct a more "balanced policy" towards First World countries.
By the end of October the Special Commission on Afghanistan, which consisted of Andropov, Gromyko, Ustinov and Ponomarev, wanted to end the impression that the Soviet government supported Amin's leadership and policy. The KGB's First Chief Directorate was put under orders that something had to be done about Afghanistan, and several of its personnel were assembled to deal with the task. Andropov fought hard for Soviet intervention, saying to Brezhnev that Amin's policies had destroyed the military and the government's capabilities to handle the crisis by use of mass repression. The plan, according to Andropov, was to assemble a small force to intervene and remove Amin from power and replace him with Karmal. The Soviet Union declared its plan to intervene in Afghanistan on 12 December 1979, and the Soviet leadership initiated Operation Storm-333 (the first phase of the intervention) on 27 December 1979.
Death.
Amin trusted the Soviet Union until the very end, despite the deterioration of official relations. When the Afghan intelligence service handed Amin a report that the Soviet Union would invade the country and topple him, Amin claimed the report was a product of imperialism. His view can be explained by the fact that the Soviet Union, after several months, finally gave in to Amin's demands and sent troops into Afghanistan to secure the PDPA government. Contrary to common Western belief, Amin was informed of the Soviet decision to send troops into Afghanistan. General Tukharinov, Commander of the 40th Army, met with Afghan Major General Babadzhan to talk about Soviet troop movements before the Soviet army's intervention. On 25 December Dmitriy Ustinov issued a formal order, stating "The state frontier of the Democratic Republic of Afghanistan is to be crossed on the ground and in the air by forces of the 40th Army and the Air Force at 1500 hrs on 25 December". This was the formal beginning of the Soviet intervention in Afghanistan.
Concerned for his safety, Amin moved from the Presidential Palace, in the centre of Kabul, to the Tajbeg Palace, which had previously been the headquarters of the Central Army Corps of the Afghan military. The palace was formidable, with walls strong enough to withstand artillery fire. According to Rodric Braithwaite, "its defences had been carefully and intelligently organised". All roads to the palace had been mined, with the exception of one, which had heavy machine guns and artillery positioned to defend it. To make matters worse for the Soviets, the Afghans had established a second line of defence which consisted of seven posts, "each manned by four sentries armed with a machine gun, a mortar, and automatic rifles". The external defences of the palace were handled by the Presidential Guard, which consisted of 2,500 troops and three T-54 tanks. Several Soviet commanders involved in the assassination of Amin thought the plan to attack the palace was "crazy". Several soldiers hesitated, claiming, in contradiction of what their commanders Yuri Drozdov and Vasily Kolesnik had told them (they in turn had been informed by the Soviet leadership), it seemed strange that Amin, the leader of the PDPA government, was an American sympathiser (accused of being a "CIA agent" by the Soviets) and betrayed the Saur Revolution. Despite several objections, the plan to assassinate Amin went ahead.
Before resorting to killing Amin by brute force, the Soviets had tried to poison him (but nearly killed his nephew instead) and to kill him with a sniper shot on his way to work (this proved impossible as the Afghans had improved their security measures). They even tried to poison Amin just hours before the assault on the Presidential Palace. Amin had organised a lunch for party members to show guests his palace and to celebrate Ghulam Dastagir Panjsheri's return from Moscow. Panjsheri's return improved the mood even further; he boasted that the Soviet divisions had already crossed the border, and that he and Gromyko always kept in contact with each other. During the meal, Amin and several of his guests lost consciousness as they had been poisoned. Luckily for Amin, but unfortunately for the Soviets, he survived his encounter with death. Mikhail Talybov, a KGB agent, was given responsibility for the poisonings.
The assault on the palace began shortly afterward. During the attack Amin still believed the Soviet Union was on his side, and told his adjutant, "The Soviets will help us". The adjutant replied that it was the Soviets who were attacking them; Amin initially replied that this was a lie. Only after he tried but failed to contact the Chief of the General Staff, he muttered, "I guessed it. It's all true". There are various accounts of how Amin died, but the exact details have never been confirmed. Amin was either killed by a deliberate attack or died by a "random burst of fire". Amin's son was fatally wounded and died shortly after. His daughter was wounded, but survived. It was Gulabzoy who had been given orders to kill Amin and Watanjar who later confirmed his death.

</doc>
<doc id="14282" url="https://en.wikipedia.org/wiki?curid=14282" title="Hubris">
Hubris

Hubris (, also hybris, from ancient Greek ) refers to a purely negative emotion that may be defined verbally in a modern context as extreme or foolish pride or confidence. In its ancient Greek context, it typically describes violent behavior rather than an attitude. The adjectival form of the noun "hubris" is "hubristic".
Hubris is usually perceived as a characteristic of an individual rather than a group, although the group the offender belongs to may unintentionally suffer consequences from the wrongful act. Hubris often indicates a loss of contact with reality and an overestimation of one's own competence, accomplishments or capabilities.
As one might expect, hubris is not necessarily associated with high self-esteem but with highly fluctuating or variable self-esteem, and a gap between inflated self perception and a more modest reality.
Excessive feelings of hubris have a tendency to create conflict, sometimes terminating close relationships; which has led it to be understood as one of the few emotions with no clear positive or adaptive function (Rhodwalt, et al.).
Hubris is generally considered a sin in world religions. C.S. Lewis writes, in "Mere Christianity", that pride is the "anti-God" state, the position in which the ego and the self are directly opposed to God: "Unchastity, anger, greed, drunkenness, and all that, are mere fleabites in comparison: it was through Pride that the devil became the devil: Pride leads to every other vice: it is the complete anti-God state of mind."
Ancient Greek origin.
In ancient Greek, "hubris" referred to actions that shamed and humiliated the victim for the pleasure or gratification of the abuser. The term had a strong sexual connotation, and the shame reflected on the perpetrator as well.
Violations of the law against hubris included what might today be termed assault and battery; sexual crimes; or the theft of public or sacred property. Two well-known cases are found in the speeches of Demosthenes, a prominent statesman and orator in ancient Greece. These two examples occurred when first Midias punched Demosthenes in the face in the theatre ("Against Midias"), and second when (in "Against Conon") a defendant allegedly assaulted a man and crowed over the victim. Yet another example of hubris appears in Aeschines' "Against Timarchus", where the defendant, Timarchus, is accused of breaking the law of hubris by submitting himself to prostitution and anal intercourse. Aeschines brought this suit against Timarchus to bar him from the rights of political office and his case succeeded.
In Ancient Athens, hubris was defined as the use of violence to shame the victim (this sense of hubris could also characterize rape). Aristotle defined hubris as shaming the victim, not because of anything that happened to the committer or might happen to the committer, but merely for that committer's own gratification:
Crucial to this definition are the ancient Greek concepts of honour (τιμή, "timē") and shame (αἰδώς, "aidōs"). The concept of honour included not only the exaltation of the one receiving honour, but also the shaming of the one overcome by the act of hubris. This concept of honour is akin to a zero-sum game. Rush Rehm simplifies this definition of hubris to the contemporary concept of "insolence, contempt, and excessive violence".
In Greek mythology, when a figure's hubris offends the pagan gods of ancient Greece, it is usually punished; examples of such hubristic, sinful humans include Icarus, Phaethon, Arachne, Salmoneus, Niobe, Cassiopeia, and Tereus.
Modern usage.
In its modern usage, hubris denotes overconfident pride and arrogance. Hubris is often associated with a lack of humility. Sometimes a person's hubris is also associated with a lack of knowledge.The accusation of hubris often implies that suffering or punishment will follow, similar to the occasional pairing of hubris and nemesis in Greek mythology. The proverb "pride goeth (goes) before destruction, a haughty spirit before a fall" (from the biblical Book of Proverbs, 16:18) is thought to sum up the modern use of hubris. Hubris is also referred to as "pride that blinds", as it often causes a committer of hubris to act in foolish ways that belie common sense. In other words, the modern definition may be thought of as, "that pride that goes just before the fall".
Examples of hubris are often found in literature, most famously in "Paradise Lost": John Milton's depiction of Lucifer (who attempts to force the other angels to worship him, is cast down to hell by God and the innocent angels, and proclaims: ""Better to reign in hell than serve in heaven."") Victor in Mary Shelley's "Frankenstein" manifests hubris in his attempt to become a great scientist by creating life through technological means, but eventually regrets this previous desire. Marlowe's play "Doctor Faustus" portrays the eponymous character as a scholar whose arrogance and pride compel him to sign a deal with the Devil, and retain his haughtiness until his death and damnation, despite the fact that he could easily have repented had he chosen to do so. Chinua Achebe's novel "Things Fall Apart" has been called a modern Greek tragedy, and the main character Okonkwo is a classic tragic hero whose hubris leads to his downfall. Another example is the character Walter White from the TV show "Breaking Bad", whose entry into the criminal world gradually caused him to eradicate all moral boundaries (except for the will to protect his family) and perform heinous crimes in order to empower his ever growing meth empire. The characters Pride and Father in the popular manga Fullmetal Alchemist were inspired by the sin of hubris.
One notable example is the Battle of Little Big Horn, as General George Armstrong Custer was apocryphally reputed to have said there: "Where did all those damned Indians come from?"
More recently, in his two-volume biography of Adolf Hitler, historian Ian Kershaw uses both 'hubris' and 'nemesis' as titles. The first volume, "Hubris", describes Hitler's early life and rise to political power. The second, "Nemesis", gives details of Hitler's role in the Second World War, and concludes with his fall and suicide in 1945.

</doc>
<doc id="14283" url="https://en.wikipedia.org/wiki?curid=14283" title="Heavy water">
Heavy water

Heavy water (deuterium oxide ( )) is a form of water that contains a larger than normal amount of the hydrogen isotope deuterium ( or D, also known as "heavy hydrogen"), rather than the common hydrogen-1 isotope ( or H, also called protium) that makes up most of the hydrogen in normal water.
Explanation.
Deuterium is an isotope of hydrogen whose nucleus comprises both a neutron and a proton; the nucleus of a protium (normal hydrogen) atom consists of just a proton. The additional neutron makes a deuterium atom roughly twice as heavy as a protium atom.
A molecule of heavy water has two deuterium atoms in place of the two protium atoms of ordinary "light" water. The weight of a heavy water molecule, however, is not substantially different from that of a normal water molecule, because about 89% of the molecular weight of water comes from the single oxygen atom rather than the two hydrogen atoms. The colloquial term "heavy water" refers to a highly enriched water mixture that contains mostly deuterium oxide , but also some hydrogen-deuterium oxide (HDO) and a smaller number of ordinary hydrogen oxide molecules. For instance, the heavy water used in CANDU reactors is 99.75% enriched by hydrogen atom-fraction—meaning that 99.75% of the hydrogen atoms are of the heavy type. For comparison, ordinary water (the "ordinary water" used for a deuterium standard) contains only about 156 deuterium atoms per million hydrogen atoms.
Heavy water is not radioactive. In its pure form, it has a density about 11% greater than water, but is otherwise physically and chemically similar. Nevertheless, the various differences in deuterium-containing water (especially affecting the biological properties) are larger than in any other commonly occurring isotope-substituted compound because deuterium is unique among heavy stable isotopes in being twice as heavy as the lightest isotope. This difference increases the strength of water's hydrogen-oxygen bonds, and this in turn is enough to cause differences that are important to some biochemical reactions. The human body naturally contains deuterium equivalent to about five grams of heavy water, which is harmless. When a large fraction of water (> 50%) in higher organisms is replaced by heavy water, the result is cell dysfunction and death.
Heavy water was first produced in 1932, a few months after the discovery of deuterium. With the discovery of nuclear fission in late 1938, and the need for a neutron moderator that captured few neutrons, heavy water became a component of early nuclear energy research. Since then, heavy water has been an essential component in some types of reactors, both those that generate power and those designed to produce isotopes for nuclear weapons. These heavy water reactors have the advantage of being able to run on natural uranium without using graphite moderators that pose radiological and dust explosion hazards in the decommissioning phase. Most modern reactors use enriched uranium with ordinary water as the moderator.
Other heavy forms of water.
Semiheavy water.
Semiheavy water, HDO, exists whenever there is water with light hydrogen (protium, ) and deuterium (D or ) in the mix. This is because hydrogen atoms (hydrogen-1 and deuterium) are rapidly exchanged between water molecules. Water containing 50% H and 50% D in its hydrogen actually contains about 50% HDO and 25% each of and , in dynamic equilibrium.
In normal water, about 1 molecule in 3,200 is HDO (one hydrogen in 6,400 is in the form of D), and heavy water molecules () only occur in a proportion of about 1 molecule in 41 million (i.e. one in 6,4002). Thus semiheavy water molecules are far more common than "pure" (homoisotopic) heavy water molecules.
Heavy-oxygen water.
Water enriched in the heavier oxygen isotopes and is also commercially available, e.g., for use as a non-radioactive isotopic tracer. It is "heavy water" as it is denser than normal water ( is approximately as dense as , is about halfway between and )—but is rarely called heavy water, since it does not contain the deuterium that gives D2O its unusual nuclear and biological properties. It is more expensive than D2O due to the more difficult separation of 17O and 18O.
Tritiated water.
Tritiated water contains tritium (3H) in place of protium (1H) or deuterium (2H).
Physical properties (with comparison to light water).
Physical properties to distinguish water from heavy water: Heavy water is 10.6% denser than ordinary water. One of the few ways to demonstrate heavy water's physically different properties without equipment is to freeze a sample and drop it into normal water (it sinks). If the water is ice-cold the higher melting temperature of heavy ice can also be observed: it melts at 3.7 °C, and thus endures very well in ice-cold normal water.
An early experiment reported not the "slightest difference" in taste between ordinary and heavy water. On the other hand, rats given a choice between distilled normal water and heavy water were able to avoid the heavy water based on smell, and it may be possible that it has a different taste.
No physical properties are listed for "pure" semi-heavy water, because it is unstable as a bulk liquid. In the liquid state, a few water molecules are always in an ionised state, which means the hydrogen atoms can exchange among different oxygen atoms. Semi-heavy water could, in theory, be created via a chemical method, but it would rapidly transform into a dynamic mixture of 25% light water, 25% heavy water, and 50% semi-heavy water. However, if it were made in the gas phase and directly deposited into a solid, semi heavy water (in the form of ice) could be stable.
History.
Harold Urey discovered the isotope deuterium in 1931 and was later able to concentrate it in water. Urey's mentor Gilbert Newton Lewis isolated the first sample of pure heavy water by electrolysis in 1933. George de Hevesy and Hoffer used heavy water in 1934 in one of the first biological tracer experiments, to estimate the rate of turnover of water in the human body. The history of large-quantity production and use of heavy water in early nuclear experiments is given below.
Emilian Bratu and Otto Redlich studied the autodissociation of heavy water in 1934.
Effect on biological systems.
Different isotopes of chemical elements have slightly different chemical behaviors, but for most elements the differences are far too small to use, or even detect. For hydrogen, however, this is not true. The larger chemical isotope-effects seen between protium (light hydrogen) versus deuterium and tritium manifest because bond energies in chemistry are determined in quantum mechanics by equations in which the quantity of reduced mass of the nucleus and electrons appears. This quantity is altered in heavy-hydrogen compounds (of which deuterium oxide is the most common) more than for heavy-isotope substitution in other chemical elements. This isotope effect of heavy hydrogen is magnified further in biological systems, which are very sensitive to small changes in the solvent properties of water.
Heavy water is the only known chemical substance that affects the period of circadian oscillations, consistently increasing the length of each cycle. The effect is seen in unicellular organisms, green plants, isopods, insects, birds, mice, and hamsters. The mechanism is unknown.
To perform their tasks, enzymes rely on their finely tuned networks of hydrogen bonds, both in the active center with their substrates, and outside the active center, to stabilize their tertiary structures. As a hydrogen bond with deuterium is slightly stronger than one involving ordinary hydrogen, in a highly deuterated environment, some normal reactions in cells are disrupted.
Particularly hard-hit by heavy water are the delicate assemblies of mitotic spindle formation necessary for cell division in eukaryotes. Plants stop growing and seeds do not germinate when given only heavy water, because heavy water stops eukaryotic cell division. The deuterium cell is larger and it is a modification of the direction of division. The cell membrane also changes, and it reacts first to the impact of heavy water. In 1972 it was demonstrated that an increase in the percentage content of deuterium in water reduces plant growth. Research conducted on the growth of prokaryote microorganisms in artificial conditions of a heavy hydrogen environment showed that in this environment, all the hydrogen atoms of water could be replaced with deuterium. Experiments showed that bacteria can live in 98% heavy water. However, all concentrations over 50% of deuterium in the water molecules were found to kill plants.
Effect on animals.
Experiments in mice, rats, and dogs have shown that a degree of 25% deuteration causes (sometimes irreversible) sterility, because neither gametes nor zygotes can develop. High concentrations of heavy water (90%) rapidly kill fish, tadpoles, flatworms, and "Drosophila". Mammals, such as rats, given heavy water to drink die after a week, at a time when their body water approaches about 50% deuteration. The mode of death appears to be the same as that in cytotoxic poisoning (such as chemotherapy) or in acute radiation syndrome (though deuterium is not radioactive), and is due to deuterium's action in generally inhibiting cell division. It is more toxic to malignant cells than normal cells but the concentrations needed are too high for regular use. As in chemotherapy, deuterium-poisoned mammals die of a failure of bone marrow (bleeding and infection) and intestinal-barrier functions (diarrhea and fluid loss).
Despite the problems of plants and animals in living with too much deuterium, prokaryotic organisms such as bacteria, which do not have the mitotic problems induced by deuterium, may be grown and propagated in fully deuterated conditions, resulting in replacement of all hydrogen atoms in the bacterial proteins and DNA with the deuterium isotope.
Full replacement with heavy atom isotopes can be accomplished in higher organisms with other non-radioactive heavy isotopes (such as carbon-13, nitrogen-15, and oxygen-18), but this cannot be done for the stable heavy isotope of hydrogen.
Deuterium oxide is used to enhance boron neutron capture therapy, but this effect does not rely on the biological effects of deuterium per se, but instead on deuterium's ability to moderate (slow) neutrons without capturing them.
Toxicity in humans.
Because it would take a very large amount of heavy water to replace 25% to 50% of a human being's body water (water being in turn 50–75% of body weight) with heavy water, accidental or intentional poisoning with heavy water is unlikely to the point of practical disregard. Poisoning would require that the victim ingest large amounts of heavy water without significant normal water intake for many days to produce any noticeable toxic effects.
Oral doses of heavy water in the range of several grams, as well as heavy oxygen 18O, are routinely used in human metabolic experiments. See doubly labeled water testing. Since one in about every 6,400 hydrogen atoms is deuterium, a 50 kg human containing 32 kg of body water would normally contain enough deuterium (about 1.1 g) to make 5.5 g of pure heavy water, so roughly this dose is required to double the amount of deuterium in the body.2O --->
The American patent is for the use of heavy water to treat hypertension (high blood pressure). A loss of blood pressure may partially explain the reported incidence of dizziness upon ingestion of heavy water. However, it is more likely that this symptom can be attributed to altered vestibular function.
Heavy water radiation contamination confusion.
Although many people associate heavy water primarily with its use in nuclear reactors, pure heavy water is not radioactive. Commercial-grade heavy water is slightly radioactive due to the presence of minute traces of natural tritium, but the same is true of ordinary water. Heavy water that has been used as a coolant in nuclear power plants contains substantially more tritium as a result of neutron bombardment of the deuterium in the heavy water (tritium is a health risk when ingested in large quantities).
In 1990, a disgruntled employee at the Point Lepreau Nuclear Generating Station in Canada obtained a sample (estimated as about a "half cup") of heavy water from the primary heat transport loop of the nuclear reactor, and loaded it into a cafeteria drink dispenser. Eight employees drank some of the contaminated water. The incident was discovered when employees began leaving bioassay urine samples with elevated tritium levels. The quantity of heavy water involved was far below levels that could induce heavy water toxicity, but several employees received elevated radiation doses from tritium and neutron-activated chemicals in the water. This was not an incident of heavy water poisoning, but rather radiation poisoning from other isotopes in the heavy water. Some news services were not careful to distinguish these points, and some of the public were left with the impression that heavy water is normally radioactive and more severely toxic than it is. Even if pure heavy water had been used in the water cooler indefinitely, it is not likely the incident would have been detected or caused harm, since no employee would be expected to get much more than 25% of their daily drinking water from such a source.
Production.
On Earth, deuterated water, HDO, occurs naturally in normal water at a proportion of about 1 molecule in 3,200. This means that 1 in 6,400 hydrogen atoms is deuterium, which is 1 part in 3,200 by weight (hydrogen weight). The HDO may be separated from normal water by distillation or electrolysis and also by various chemical exchange processes, all of which exploit a kinetic isotope effect. (For more information about the isotopic distribution of deuterium in water, see Vienna Standard Mean Ocean Water.) In theory, deuterium for heavy water could be created in a nuclear reactor, but separation from ordinary water is the cheapest bulk production process.
The difference in mass between the two hydrogen isotopes translates into a difference in the zero-point energy and thus into a slight difference in the speed of the reaction. Once HDO becomes a significant fraction of the water, heavy water becomes more prevalent as water molecules trade hydrogen atoms very frequently. Production of pure heavy water by distillation or electrolysis requires a large cascade of stills or electrolysis chambers and consumes large amounts of power, so the chemical methods are generally preferred.
The most cost-effective process for producing heavy water is the dual temperature exchange sulphide process (known as the Girdler sulfide process) developed in parallel by Karl-Hermann Geib and Jerome S. Spevack in 1943.
An alternative process, patented by Graham M. Keyser, uses lasers to selectively dissociate deuterated hydrofluorocarbons to form deuterium fluoride, which can then be separated by physical means. Although the energy consumption for this process is much less than for the Girdler sulfide process, this method is currently uneconomical due to the expense of procuring the necessary hydrofluorocarbons.
As noted, modern commercial heavy water is almost universally referred to, and sold as, deuterium oxide. It is most often sold in various grades of purity, from 98% enrichment to 99.75–99.98% deuterium enrichment (nuclear reactor grade) and occasionally even higher isotopic purity.
Argentina.
Argentina is the main producer of heavy water, using an ammonia/hydrogen exchange based plant supplied by Switzerland's Sulzer company. It is also a major exporter to countries such as Canada, US, and Germany as well as others. The heavy water production facility located at Arroyito (Neuquén Province) is the world's largest heavy water production facility. Argentina produces 200 tons of heavy water per year.
Soviet Union.
In October 1939, Soviet physicists Yakov Borisovich Zel'dovich and Yulii Borisovich Khariton concluded that heavy water and carbon were the only feasible moderators for a natural uranium reactor, and in August, 1940, along with Georgy Flyorov, submitted a plan to the Russian Academy of Sciences calculating that 15 tons of heavy water were needed for a reactor. With the Soviet Union having no uranium mines at the time, young Academy workers were sent to Leningrad photographic shops to buy uranium nitrate, but the entire heavy water project was halted in 1941 when German forces invaded during Operation Barbarossa.
By 1943, Soviet scientists had discovered that all scientific literature relating to heavy water had disappeared from the West, which Flyorov in a letter warned Soviet leader Joseph Stalin about, and at which time there was only 2–3 kg of heavy water in the entire country. In late 1943, the Soviet purchasing commission in the U.S. obtained 1 kg of heavy water and a further 100 kg in February 1945, and upon World War II ending, the NKVD took over the project.
In October 1946, as part of the Russian Alsos, the NKVD deported to the Soviet Union from Germany the German scientists who had worked on heavy water production during the war, including the inventor of the Girdler sulfide process Karl-Hermann Geib. These German scientists worked under the supervison of German physical chemist Max Volmer at the Institute of Physical Chemistry in Moscow with the plant they constructed producing large quantities of heavy water by 1948.
United States.
During the Manhattan Project the United States constructed three heavy water production plants as part of the P-9 Project at Morgantown Ordnance Works, near Morgantown, West Virginia; at the Wabash River Ordnance Works, near Dana and Newport, Indiana; and at the Alabama Ordnance Works, near Childersburg and Sylacauga, Alabama. Heavy water was also acquired from the Cominco plant in Trail, British Columbia (Canada). The Chicago Pile-3 experimental reactor used heavy water as a moderator and went critical in 1944. The three domestic production plants were shut down in 1945 after producing around 20 metric tons of product (around 20,000 litres). The Wabash plant was reopened and began resumption of heavy water production in 1952.
In 1953, the United States began using heavy water in plutonium production reactors at the Savannah River Site. The first of the five heavy water reactors came online in 1953, and the last was placed in cold shutdown in 1996. The SRS reactors were heavy water reactors so that they could produce both plutonium and tritium for the US nuclear weapons program.
The U.S. developed the Girdler sulfide chemical exchange production process—which was first demonstrated on a large scale at the Dana, Indiana plant in 1945 and at the Savannah River Plant, South Carolina in 1952. DuPont operated the SRP for the USDOE until 1 April 1989, when Westinghouse took it over.
India.
India is one of the world's largest producers of heavy water through its Heavy Water Board and also exports to countries like Republic of Korea and the US. Development of heavy water process in India happened in three phases: The first phase (late 1950s to mid-1980s) was a period of technology development, the second phase was of deployment of technology and process stabilisation (mid-1980s to early 1990s) and third phase saw consolidation and a shift towards improvement in production and energy conservation.
Empire of Japan.
In the 1930s, it was suspected by the United States and Soviet Union that Austrian chemist Fritz Johann Hansgirg built a pilot plant for the Empire of Japan in Japanese ruled northern Korea to produce heavy water by using a new process he had invented.
Norway.
In 1934, Norsk Hydro built the first commercial heavy water plant at Vemork, Tinn, with a capacity of 12 tonnes per year. From 1940 and throughout World War II, the plant was under German control and the Allies decided to destroy the plant and its heavy water to inhibit German development of nuclear weapons. In late 1942, a planned raid by British airborne troops failed, both gliders crashing. The raiders were killed in the crash or subsequently executed by the Germans. On the night of 27 February 1943 Operation Gunnerside succeeded. Norwegian commandos and local resistance managed to demolish small, but key parts of the electrolytic cells, dumping the accumulated heavy water down the factory drains.
On 16 November 1943, the Allied air forces dropped more than 400 bombs on the site. The Allied air raid prompted the Nazi government to move all available heavy water to Germany for safekeeping. On 20 February 1944, a Norwegian partisan sank the ferry M/F "Hydro" carrying heavy water across Lake Tinn, at the cost of 14 Norwegian civilian lives, and most of the heavy water was presumably lost. A few of the barrels were only half full, and therefore could float, and may have been salvaged and transported to Germany.
Recent investigation of production records at Norsk Hydro and analysis of an intact barrel that was salvaged in 2004 revealed that although the barrels in this shipment contained water of pH 14—indicative of the alkaline electrolytic refinement process—they did not contain high concentrations of D2O. Despite the apparent size of the shipment, the total quantity of pure heavy water was quite small, most barrels only containing 0.5–1% pure heavy water. The Germans would have needed a total of about 5 tons of heavy water to get a nuclear reactor running. The manifest clearly indicated that there was only half a ton of heavy water being transported to Germany. "Hydro" was carrying far too little heavy water for one reactor, let alone the 10 or more tons needed to make enough plutonium for a nuclear weapon.
Israel admitted running the Dimona reactor with Norwegian heavy water sold to it in 1959. Through re-export using Romania and Germany, India probably also used Norwegian heavy water.
Canada.
As part of its contribution to the Manhattan Project, Canada built and operated a 6-tonnes-per-year electrolytic heavy water plant at Trail, British Columbia, which started operation in 1943.
The Atomic Energy of Canada Limited (AECL) design of power reactor requires large quantities of heavy water to act as a neutron moderator and coolant. AECL ordered two heavy water plants, which were built and operated in Atlantic Canada at Glace Bay, Nova Scotia (by Deuterium of Canada Limited) and Port Hawkesbury, Nova Scotia (by General Electric Canada). These plants proved to have significant design, construction and production problems and so AECL built the Bruce Heavy Water Plant (), which it later sold to Ontario Hydro, to ensure a reliable supply of heavy water for future power plants. The two Nova Scotia plants were shut down in 1985 when their production proved unnecessary.
The Bruce Heavy Water Plant in Ontario was the world's largest heavy water production plant with a capacity of 700 tonnes per year. It used the Girdler sulfide process to produce heavy water, and required 340,000 tonnes of feed water to produce one tonne of heavy water. It was part of a complex that included eight CANDU reactors, which provided heat and power for the heavy water plant. The site was located at Douglas Point near Tiverton, Ontario on Lake Huron where it had access to the waters of the Great Lakes.
The Bruce plant was commissioned in 1979 to provide heavy water for a large increase in Ontario's nuclear power generation. The plants were significantly more efficient than planned and only three of the planned four units were eventually commissioned. In addition, the nuclear power programme was slowed down and effectively stopped due to a perceived oversupply of electricity, later shown to be temporary, in 1993. Improved efficiency in the use and recycling of heavy water plus the over-production at Bruce left Canada with enough heavy water for its anticipated future needs. Also, the Girdler process involves large amounts of hydrogen sulfide, raising environmental concerns if there should be a release. The Bruce heavy water plant was shut down in 1997, after which the plant was gradually dismantled and the site cleared.
Atomic Energy of Canada Limited (AECL) is currently researching other more efficient and environmentally benign processes for creating heavy water. This is essential for the future of the CANDU reactors since heavy water represents about 20% of the capital cost of each reactor.
Iran.
Since 1996 a plant for production of heavy water was being constructed at Khondab near Arak. On 26 August 2006, Iranian President Ahmadinejad inaugurated the expansion of the country's heavy-water plant. Iran has indicated that the heavy-water production facility will operate in tandem with a 40 MW research reactor that had a scheduled completion date in 2009.
Iran produced deuterated solvents in early 2011 for the first time.
The core of the IR-40 is supposed to be re-designed based on the nuclear agreement in July 2015.
Pakistan.
The 50 MWt heavy water and natural uranium research reactor at Khushab, in Punjab province, is a central element of Pakistan's program for production of plutonium, deuterium and tritium for advanced compact warheads (i.e. thermonuclear weapons). Pakistan succeeded in acquiring a tritium purification and storage plant and deuterium and tritium precursor materials from two German firms.
Other countries.
Romania produces heavy water at the Drobeta Girdler sulfide plant for domestic and export purposes.
France operated a small plant during the 1950s and 1960s.
Heavy water exists in elevated concentration in Lake Tanganyika.
Applications.
Nuclear magnetic resonance.
Deuterium oxide is used in nuclear magnetic resonance spectroscopy when the solvent of interest is water and the nuclide of interest is hydrogen. This is because the signal from the water solvent would interfere with the signal from the molecule of interest. Deuterium has a different magnetic moment from hydrogen and therefore does not contribute to the 1H NMR signal at the hydrogen-1 resonance frequency.
For some experiments, it may be desirable to identify the labile hydrogens on a compound, that is hydrogens that can easily exchange away as H+ ions on some positions in a molecule. 1H NMR shows natural abundance hydrogens in a molecule. With addition of D2O, sometimes referred to as a "D2O shake", labile hydrogens exchange away and are substituted by deuterium (2H) atoms from D2O and not show up at those positions in the molecule in an 1H NMR spectrum.
Organic chemistry.
Deuterium oxide is often used as the source of deuterium for preparing specifically labelled isotopologues of organic compounds. For example, C-H bonds adjacent to ketonic carbonyl groups can be replaced by C-D bonds, using acid or base catalysis. Trimethylsulfoxonium iodide, made from dimethyl sulfoxide and methyl iodide can be recrystallized from deuterium oxide, and then dissociated to regenerate methyl iodide and dimethyl sulfoxide, both deuterium labelled. In cases where specific double labelling by deuterium and tritium is contemplated, the researcher must be aware that deuterium oxide, depending upon age and origin, can contain some tritium.
Fourier transform spectroscopy.
Deuterium oxide is often used instead of water when collecting FTIR spectra of proteins in solution. H2O creates a strong band that overlaps with the amide I region of proteins. The band from D2O is shifted away from the amide I region.
Neutron moderator.
Heavy water is used in certain types of nuclear reactors, where it acts as a neutron moderator to slow down neutrons so that they are more likely to react with the fissile uranium-235 than with uranium-238, which captures neutrons without fissioning.
The CANDU reactor uses this design. Light water also acts as a moderator, but because light water absorbs more neutrons than heavy water, reactors using light water for a reactor moderator must use enriched uranium rather than natural uranium, otherwise criticality is impossible. A significant fraction of outdated power reactors, such as the RBMK reactors in the USSR, were constructed using normal water for cooling but graphite as a moderator. However, the danger of graphite in power reactors (graphite fires in part led to the Chernobyl disaster) has led to the discontinuation of graphite in standard reactor designs.
Because they do not require uranium enrichment, heavy water reactors are more of a concern in regards to nuclear proliferation. The breeding and extraction of plutonium can be a relatively rapid and cheap route to building a nuclear weapon, as chemical separation of plutonium from fuel is easier than isotopic separation of U-235 from natural uranium.
Among current and past nuclear weapons states, Israel, India, and North Korea first used plutonium from heavy water moderated reactors burning natural uranium, while China, South Africa and Pakistan first built weapons using highly enriched uranium.
In the U.S., however, the first experimental atomic reactor (1942), as well as the Manhattan Project Hanford production reactors that produced the plutonium for the Trinity test and Fat Man bombs, all used pure carbon (graphite) neutron moderators combined with normal water cooling pipes. They functioned with neither enriched uranium nor heavy water. Russian and British plutonium production also used graphite-moderated reactors.
There is no evidence that civilian heavy water power reactors—such as the CANDU or Atucha designs—have been used to produce military fissile materials. In nations that do not already possess nuclear weapons, nuclear material at these facilities is under IAEA safeguards to discourage any diversion.
Due to its potential for use in nuclear weapons programs, the possession or import/export of large industrial quantities of heavy water are subject to government control in several countries. Suppliers of heavy water and heavy water production technology typically apply IAEA (International Atomic Energy Agency) administered safeguards and material accounting to heavy water. (In Australia, the "Nuclear Non-Proliferation (Safeguards) Act 1987".) In the U.S. and Canada, non-industrial quantities of heavy water (i.e., in the gram to kg range) are routinely available without special license through chemical supply dealers and commercial companies such as the world's former major producer Ontario Hydro.
Neutrino detector.
The Sudbury Neutrino Observatory (SNO) in Sudbury, Ontario used 1,000 tonnes of heavy water on loan from Atomic Energy of Canada Limited. The neutrino detector is underground in a mine, to shield it from muons produced by cosmic rays. SNO was built to answer the question of whether or not electron-type neutrinos produced by fusion in the Sun (the only type the Sun should be producing directly, according to theory) might be able to turn into other types of neutrinos on the way to Earth. SNO detects the Cherenkov radiation in the water from high-energy electrons produced from electron-type neutrinos as they undergo charged current (CC) interactions with neutrons in deuterium, turning them into protons and electrons (however, only the electrons are fast enough to produce Cherenkov radiation for detection). SNO also detects neutrino↔electron scattering (ES) events, where the neutrino transfers energy to the electron, which then proceeds to generate Cherenkov radiation distinguishable from that produced by CC events. The first of these two reactions is produced only by electron-type neutrinos, while the second can be caused by all of the neutrino flavors. The use of deuterium is critical to the SNO function, because all three "flavours" (types) of neutrinos may be detected in a third type of reaction as well, neutrino-disintegration, in which a neutrino of any type (electron, muon, or tau) scatters from a deuterium nucleus (deuteron), transferring enough energy to break up the loosely bound deuteron into a free neutron and proton via a neutral current (NC) interaction. This event is detected when the free neutron is absorbed by 35Cl− present from NaCl deliberately dissolved in the heavy water, causing emission of characteristic capture gamma rays. Thus, in this experiment, heavy water not only provides the transparent medium necessary to produce and visualize Cherenkov radiation, but it also provides deuterium to detect exotic mu type (μ) and tau (τ) neutrinos, as well as a non-absorbent moderator medium to preserve free neutrons from this reaction, until they can be absorbed by an easily detected neutron-activated isotope.
Metabolic rate testing in physiology/biology.
Heavy water is employed as part of a mixture with H218O for a common and safe test of mean metabolic rate in humans and animals undergoing their normal activities. This metabolic test is usually called the doubly labeled water test.
Tritium production.
Tritium is the active substance in self-powered lighting and controlled nuclear fusion, its other uses including autoradiography and radioactive labeling. It is also used in nuclear weapon design for boosted fission weapons and initiators. Some tritium is created in heavy water moderated reactors when deuterium captures a neutron. This reaction has a small cross-section (probability of a single neutron-capture event) and produces only small amounts of tritium, although enough to justify cleaning tritium from the moderator every few years to reduce the environmental risk of tritium escape.
Producing a lot of tritium in this way would require reactors with very high neutron fluxes, or with a very high proportion of heavy water to nuclear fuel and very low neutron absorption by other reactor material. The tritium would then have to be recovered by isotope separation from a much larger quantity of deuterium, unlike production from lithium-6 (the present method), where only chemical separation is needed.
Deuterium's absorption cross section for thermal neutrons is 0.52 millibarns (barn=10−28 m2, milli=1/1000), while oxygen-16's is 0.19 millibarns and oxygen-17's is 0.24 barns. 17O makes up 0.038% of natural oxygen, making the overall cross section 0.28 millibarns. Therefore, in D2O with natural oxygen, 21% of neutron captures are on oxygen, rising higher as 17O builds up from neutron capture on 16O. Also, 17O may emit an alpha particle on neutron capture, producing radioactive carbon-14.
References.
Notes

</doc>
<doc id="14285" url="https://en.wikipedia.org/wiki?curid=14285" title="History of science and technology">
History of science and technology

The history of Science and Technology (HST) is a field of history which examines how humanity's understanding of the natural world (science) and ability to manipulate it (technology) have changed over the centuries. This academic discipline also studies the cultural, economic, and political impacts of scientific innovation.
Histories of science were originally written by practicing and retired scientists, starting primarily with William Whewell, as a way to communicate the virtues of science to the public. In the early 1930s, after a famous paper given by the Soviet historian Boris Hessen, was focused into looking at the ways in which scientific practices were allied with the needs and motivations of their context. After World War II, extensive resources were put into teaching and researching the discipline, with the hopes that it would help the public better understand both Science and Technology as they came to play an exceedingly prominent role in the world. In the 1960s, especially in the wake of the work done by Thomas Kuhn, the discipline began to serve a very different function, and began to be used as a way to critically examine the scientific enterprise. At the present time it is often closely aligned with the field of science studies.
Modern engineering as it is understood today took form during the scientific revolution, though much of the mathematics and science was built on the work of the Greeks, Egyptians, Mesopotamians, Chinese, Indians. See the main articles History of science and History of technology for these respective topics.
Universities with HST programs.
India.
HST is a well developed field in India. At least three generations of scholars can be identified.
The first generation includes D.D.Kosambi, Dharmpal, Debiprasad Chattopadhyay and Rahman. The second generation mainly consists of Ashis Nandy, Deepak Kumar, Dhruv Raina, S. Irfan Habib, Shiv Visvanathan, Gyan Prakash, Stan Lourdswamy, V.V. Krishna, Itty Abraham, Richard Grove, Kavita Philip, Mira Nanda and Rob Anderson. There is an emergent third generation that includes scholars like Abha Sur and Jahnavi Phalkey.
Departments and Programmes
The National Institute of Science, Technolology and Development Studies had a research group active in 1990s which consolidated social history of science as a field of research in India. 
Currently there are several institutes and university departments offering HST programmes.
United States.
Academic study of the History of Science as an independent discipline was launched by George Sarton at Harvard with his book "Introduction to the History of Science" (1927) and the "Isis" journal (founded in 1912). Sarton exemplified the early 20th century view of the history of science as the history of great men and great ideas. He shared with many of his contemporaries a Whiggish belief in history as a record of the advances and delays in the march of progress. The History of Science was not a recognized subfield of American history in this period, and most of the work was carried out by interested Scientists and Physicians rather than professional Historians. With the work of I. Bernard Cohen at Harvard, the history of Science became an established subdiscipline of history after 1945.
Bibliography.
Historiography of science
History of science as a discipline

</doc>
<doc id="14286" url="https://en.wikipedia.org/wiki?curid=14286" title="Holographic principle">
Holographic principle

The holographic principle is a property of string theories and a supposed property of quantum gravity that states that the description of a volume of space can be thought of as encoded on a boundary to the region—preferably a light-like boundary like a gravitational horizon. First proposed by Gerard 't Hooft, it was given a precise string-theory interpretation by Leonard Susskind who combined his ideas with previous ones of 't Hooft and Charles Thorn. As pointed out by Raphael Bousso, Thorn observed in 1978 that string theory admits a lower-dimensional description in which gravity emerges from it in what would now be called a holographic way.
In a larger sense, the theory suggests that the entire universe can be seen as two-dimensional information on the cosmological horizon, the event horizon from which information may still be gathered and not lost due to the natural limitations of spacetime supporting a black hole, an observer and a given setting of these specific elements, such that the three dimensions we observe are an effective description only at macroscopic scales and at low energies. Cosmological holography has not been made mathematically precise, partly because the particle horizon has a non-zero area and grows with time.
The holographic principle was inspired by black hole thermodynamics, which conjectures that the maximal entropy in any region scales with the radius "squared", and not cubed as might be expected. In the case of a black hole, the insight was that the informational content of all the objects that have fallen into the hole might be entirely contained in surface fluctuations of the event horizon. The holographic principle resolves the black hole information paradox within the framework of string theory.
However, there exist classical solutions to the Einstein equations that allow values of the entropy larger than those allowed by an area law, hence in principle larger than those of a black hole. These are the so-called "Wheeler's bags of gold". The existence of such solutions conflicts with the holographic interpretation, and their effects in a quantum theory of gravity including the holographic principle are not yet fully understood.
Black hole entropy.
An object with relatively high entropy is microscopically random, like a hot gas. A known configuration of classical fields has zero entropy: there is nothing random about electric and magnetic fields, or gravitational waves. Since black holes are exact solutions of Einstein's equations, they were thought not to have any entropy either.
But Jacob Bekenstein noted that this leads to a violation of the second law of thermodynamics. If one throws a hot gas with entropy into a black hole, once it crosses the event horizon, the entropy would disappear. The random properties of the gas would no longer be seen once the black hole had absorbed the gas and settled down. One way of salvaging the second law is if black holes are in fact random objects, with an enormous entropy whose increase is greater than the entropy carried by the gas.
Bekenstein assumed that black holes are maximum entropy objects—that they have more entropy than anything else in the same volume. In a sphere of radius "R", the entropy in a relativistic gas increases as the energy increases. The only known limit is gravitational; when there is too much energy the gas collapses into a black hole. Bekenstein used this to put an upper bound on the entropy in a region of space, and the bound was proportional to the area of the region. He concluded that the black hole entropy is directly proportional to the area of the event horizon.
Stephen Hawking had shown earlier that the total horizon area of a collection of black holes always increases with time. The horizon is a boundary defined by light-like geodesics; it is those light rays that are just barely unable to escape. If neighboring geodesics start moving toward each other they eventually collide, at which point their extension is inside the black hole. So the geodesics are always moving apart, and the number of geodesics which generate the boundary, the area of the horizon, always increases. Hawking's result was called the second law of black hole thermodynamics, by analogy with the law of entropy increase, but at first, he did not take the analogy too seriously.
Hawking knew that if the horizon area were an actual entropy, black holes would have to radiate. When heat is added to a thermal system, the change in entropy is the increase in mass-energy divided by temperature:

</doc>
<doc id="14288" url="https://en.wikipedia.org/wiki?curid=14288" title="Hamilton, Ontario">
Hamilton, Ontario

Hamilton (; 2011 population 519,949; UA population 670,580; CMA population 721,053) is a port city in the Canadian province of Ontario. Conceived by George Hamilton when he purchased the Durand farm shortly after the War of 1812, Hamilton has become the centre of a densely populated and industrialized region at the west end of Lake Ontario known as the Golden Horseshoe. On January 1, 2001, the new City of Hamilton was formed through the amalgamation of the former city and the other constituent lower-tier municipalities of the Regional Municipality of Hamilton-Wentworth with the upper-tier regional government. Residents of the old city are known as Hamiltonians. Since 1981, the metropolitan area has been listed as the ninth largest in Canada and the third largest in Ontario.
Hamilton is home to the Royal Botanical Gardens, the Canadian Warplane Heritage Museum, the Bruce Trail, McMaster University and Mohawk College. McMaster University is ranked 4th in Canada and 94th in the world by Times Higher Education Rankings 2015-16 and has a well-known medical school. The Canadian Football Hall of Fame can be found downtown right beside Hamilton City Hall and across town to the east, the Canadian Football League's Hamilton Tiger-Cats began playing at the new Tim Hortons Field in 2014, which was built as part of the 2015 Pan American Games.
Possibly because of its diverse environment, numerous TV and film productions have been filmed in Hamilton, regulated by the Hamilton Film and Television Office. A growing arts and culture community garnered media attention in 2006 when the "Globe and Mail" published an article called "Go West, Young Artist" about Hamilton's growing art scene. The article highlighted local art galleries, recording studios and independent film production.
History.
In pre-colonial times, the Neutral Indians used much of the land but were gradually driven out by the Five (later Six) Nations (Iroquois) who were allied with the British against the Huron and their French allies. A member of the Iroquois Confederacy provided the route and name for Mohawk Road, which originally included King Street in the lower city. In 1784, about 10,000 United Empire Loyalists settled in Upper Canada (what is now southern Ontario), chiefly in Niagara, around the Bay of Quinte, and along the St. Lawrence River between Lake Ontario and Montreal. They were soon followed by many more Americans, some of them not so much ardent loyalists but attracted nonetheless by the availability of inexpensive, arable land. At the same time, large numbers of Iroquois loyal to Britain arrived from the United States and were settled on reserves west of Lake Ontario.
The town of Hamilton was conceived by George Hamilton (a son of a Queenston entrepreneur and founder, Robert Hamilton), when he purchased farm holdings of James Durand, the local Member of the British Legislative Assembly, shortly after the War of 1812. Nathaniel Hughson, a property owner to the north, cooperated with George Hamilton to prepare a proposal for a courthouse and jail on Hamilton's property. Hamilton offered the land to the crown for the future site. Durand was empowered by Hughson and Hamilton to sell property holdings which later became the site of the town. As he had been instructed, Durand circulated the offers at York during a session of the Legislative Assembly and a new Gore District was established of which the Hamilton townsite was a member.
Initially, this town was not the most important centre of the Gore District. A permanent jail was not constructed until 1832 when a cut-stone design was completed on one of the two squares created in 1816, Prince's Square. Subsequently, the first police board and the town limits were defined by statute on February 13, 1833. Official City status was achieved on June 9, 1846, by an act of Parliament, 9 Victoria Chapter 73. 
As the city grew, several prominent buildings were constructed in the late 19th century, including the Grand Lodge of Canada in 1855, West Flamboro Methodist Church in 1879 (later purchased by Dufferin Masonic Lodge in 1893), a public library in 1890, and the Right House department store in 1893. The first commercial telephone service in Canada, the first telephone exchange in the British Empire, and the second telephone exchange in all of North America all were established in the city between 1877–78. The city had several interurban electric street railways and two inclines, all powered by the Cataract Power Co.
Though suffering through the Hamilton Street Railway strike of 1906, with industrial businesses expanding, Hamilton's population doubled between 1900 and 1914. Two steel manufacturing companies, Stelco and Dofasco, were formed in 1910 and 1912, respectively, and Procter & Gamble and the Beech-Nut Packing Company opened manufacturing plants in 1914 and 1922, respectively, their first outside the US. Population and economic growth continued until the 1960s, with the 1929 construction of the city's first high-rise building, the Pigott Building, the move of McMaster University from Toronto to Hamilton, the opening of the second Canadian Tire store in Canada in 1934, an airport in 1940, a Studebaker assembly line in 1948, the Burlington Bay James N. Allan Skyway in 1958, and the first Tim Hortons store in 1964. Since then, many of the large industries have moved or shut down operations and the economy has shifted more toward the service sector, such as transportation, education, and health services.
On January 1, 2001, the new city of Hamilton was formed from the amalgamation of Hamilton and its five neighbouring municipalities: Ancaster, Dundas, Flamborough, Glanbrook, and Stoney Creek. --> Before amalgamation, the "old" City of Hamilton had 331,121 Hamiltonians divided into 100 neighbourhoods. The former region of Hamilton-Wentworth had a population of 490,268. The amalgamation created a single-tier municipal government ending subsidization of its suburbs. The new amalgamated city has 519,949 people in over 100 old neighbourhoods, and surrounding communities.
The city experienced a devastating fire at the Plastimet plastics plant in 1997. Approximately 300 firefighters battled the blaze, and many sustained severe chemical burns and inhaled volatile organic compounds when at least 400 tonnes of PVC plastic were consumed in the fire.
Geography.
Hamilton is located in Southern Ontario on the western end of the Niagara Peninsula and wraps around the westernmost part of Lake Ontario; most of the city, including the downtown section, is on the south shore. Hamilton is situated in the geographic centre of the Golden Horseshoe and is roughly the midway point between Toronto and Buffalo, New York, although slightly closer to the former. Its major physical features are Hamilton Harbour, marking the northern limit of the city, and the Niagara Escarpment running through the middle of the city across its entire breadth, bisecting the city into "upper" and "lower" parts. The maximum high point is 250m (820') above the level of Lake Ontario.
According to all records from local historians, this district was called "Attiwandaronia" by the native Neutral people. The first aboriginals to settle in the Hamilton area called the bay "Macassa", meaning "beautiful waters". Hamilton is one of 11 cities showcased in the book, "Green City: People, Nature & Urban Places" by Quebec author Mary Soderstrom, which examines the city as an example of an industrial powerhouse co-existing with nature. Soderstrom credits Thomas McQuesten and family in the 1930s who "became champions of parks, greenspace and roads" in Hamilton.
Hamilton Harbour is a natural harbour with a large sandbar called the Beachstrip. This sandbar was deposited during a period of higher lake levels during the last ice age, and extends southeast through the central lower city to the escarpment. Hamilton's deep sea port is accessed by ship canal through the beach strip into the harbour and is traversed by two bridges, the QEW's Burlington Bay James N. Allan Skyway and the lower Canal Lift Bridge.
Between 1788 and 1793, the townships at the Head-of-the-Lake were surveyed and named. The area was first known as The Head-of-the-Lake for its location at the western end of Lake Ontario. John Ryckman, born in Barton township (where present day downtown Hamilton is), described the area in 1803 as he remembered it: "The city in 1803 was all forest. The shores of the bay were difficult to reach or see because they were hidden by a thick, almost impenetrable mass of trees and undergrowth ... Bears ate pigs, so settlers warred on bears. Wolves gobbled sheep and geese, so they hunted and trapped wolves. They also held organized raids on rattlesnakes on the mountainside. There was plenty of game. Many a time have I seen (sic) a deer jump the fence into my back yard, and there were millions of pigeons which we clubbed as they flew low."
George Hamilton, a settler and local politician, established a town site in the northern portion of Barton Township in 1815. He kept several east–west roads which were originally Indian trails, but the north–south streets were on a regular grid pattern. Streets were designated "East" or "West" if they crossed James Street or Highway 6. Streets were designated "North" or "South" if they crossed King Street or Highway 8. The overall design of the townsite, likely conceived in 1816, was commonplace. George Hamilton employed a grid street pattern used in most towns in Upper Canada and throughout the American frontier. The eighty original lots had frontages of fifty feet; each lot faced a broad street and backed onto a twelve-foot lane. It took at least a decade for all of the original lots to be sold, but the construction of the Burlington Canal in 1823, and a new court-house in 1827, encouraged Hamilton to add more blocks around 1828–9. At this time, he included a market square in an effort to draw commercial activity onto his lands, but the natural growth of the town was to the north of Hamilton's plot.
The Hamilton Conservation Authority owns, leases or manages about of land with the City operating of parkland at 310 locations. Many of the parks are located along the Niagara Escarpment, which runs from Tobermory at the tip of the Bruce Peninsula in the north, to Queenston at the Niagara River in the south, and provides views of the cities and towns at the western end of Lake Ontario. The hiking path Bruce Trail runs the length of the escarpment. Hamilton is home to more than 100 waterfalls and cascades, most of which are on or near the Bruce Trail as it winds through the Niagara Escarpment.
Climate.
Hamilton's climate is humid-continental, characterized by changeable weather patterns. However, its climate is moderate compared with most of Canada. Hamilton's location on an embayment at the southwestern corner of Lake Ontario with an escarpment dividing upper and lower parts of the city results in noticeable disparities in weather over short distances, this is also the case with pollution levels, which depending on localized winds patterns or low clouds can be high in certain areas mostly originating from the city's steel industry mixed with regional vehicle pollution. With a July average of exactly , the lower city is located in a pocket of the found at the southwestern end of Lake Ontario (between Hamilton and Toronto and eastward into the Niagara Peninsula), while the upper reaches of the city fall into the .
The airport's open, rural location and higher altitude (240m vs. 85m ASL downtown) results in lower temperatures, generally windier conditions and higher snowfall amounts than lower, built-up areas of the city. One exception is on early spring afternoons; when colder than air lake temperatures keep shoreline areas significantly cooler, under the presence of an east or north-east onshore flow.
The highest temperature ever recorded in Hamilton was 41.1°C (106°F) on 14 July 1868. The coldest temperature ever recorded was -30.6°C (-23°F) on 25 January 1884.
Demographics.
According to the 2006 Canadian Census, more than 20 percent of the local population was not born in Canada. This is the third highest such proportion in Canada after Toronto at 49%, and Vancouver at 39%. Between 2001 and 2006, the foreign-born population increased by 7.7% while the total population of the Hamilton census metropolitan area (CMA) grew by 4.3%. The share of Canada's recent immigrants who settle in Hamilton has remained unchanged since 2001 at 1.9%. Hamilton was home to 20,800 immigrants who arrived in Canada between 2001 and 2006, half of whom were born in Asia and the Middle East, while nearly one-quarter (23%) were from Europe. Hamilton also had a high proportion of people with Italian, English, Scottish, German and Irish ancestry. Nearly three in ten residents reported English as their sole ethnic origin or as one of their ancestral origins. As well, nearly one in five reported Scottish ancestry either alone or in combination with another ethnic origin.
The Canada 2011 Census short form did not include questions on ethnic background or national origin. However, the 2011 National Household Survey (NHS) (a voluntary survey that accompanied the census) produced the following data:
In February 2014, the city's council voted to declare Hamilton a sanctuary city, offering municipal services to undocumented immigrants at risk of deportation.
Hamilton also has a large French community for which provincial services are offered in French. In Ontario, urban centres where there are at least 5000 Francophones or where at least 10% of the population is francophone are designated areas where bilingual provincial services have to be offered. According to the latest statistics, the Francophone community grew by 50% between 2006 and 2011 in Hamilton, and in the City, 45,000 citizens claim to have knowledge of both official languages, amongst which 13,000 have French as a mother tongue. The Franco-Ontarian community of Hamilton boasts two schoolboards (Conseil scolaire Viamonde and Conseil scolaire de district catholique Centre-Sud) five schools (2 secondary and 3 elementary), a community health centre that is part of the LHIN (Centre de santé communautaire Hamilton/Niagara), a cultural centre (Centre français Hamilton), three daycare centres, a provincially funded employment centre (Options Emploi), a community college site (Collège Boréal) and a community organization that supports the development of the francophone community in Hamilton (ACFO Régionale Hamilton).
The top countries of birth for the newcomers living in Hamilton in the 1990s were: former Yugoslavia, Poland, India, China, the Philippines, and Iraq.
Children aged 14 years and under accounted for 17.8% of the population while those 65 years of age and older constituted 14.9%, resulting in an average age of 39.6 years.
The most described religion in Hamilton is Christianity although other religions brought by immigrants are also growing. The 2011 census indicates that 67.6% of the population adheres to a Christian denomination, with Catholics being the largest at 34.3% of the city's population. The Christ the King Cathedral is the seat of the Diocese of Hamilton. Other denominations include the United Church (6.5%), Anglican (6.4%), Presbyterian (3.1%), Christian Orthodox (2.9%), and other denominations (9.8%). Other religions with significant populations include Islam (3.7%), Buddhist (0.9%), Sikh (0.8%), Hindu (0.8%), and Jewish (0.7%). Those with no religious affiliation accounted for 24.9% of the population.
Environics Analytics, a geodemographic marketing firm that created 66 different "clusters" of people complete with profiles of how they live, what they think and what they consume, sees a future Hamilton with younger upscale Hamiltonians—who are tech savvy and university educated—choosing to live in the downtown and surrounding areas rather than just visiting intermittently. More two and three-storey townhouses and apartments will be built on downtown lots; small condos will be built on vacant spaces in areas such as Dundas, Ainslie Wood and Westdale to accommodate newly retired seniors; and more retail and commercial zones will be created. The city is also expected to grow by more than 28,000 people and 18,000 households by the year 2012.
The following data are recorded by the 2011 NHS survey:
Economy.
The most important economic activity in Ontario is manufacturing, and the Toronto–Hamilton region is the most highly industrialized section of the country. The area from Oshawa, Ontario around the west end of Lake Ontario to Niagara Falls, with Hamilton at its centre, is known as the Golden Horseshoe and had a population of approximately 8.1 million people in 2006. The phrase was first used by Westinghouse President Herbert H. Rogge in a speech to the Hamilton Chamber of Commerce, on January 12, 1954. "Hamilton in 50 years will be the forward cleat in a golden horseshoe of industrial development from Oshawa to the Niagara River ... 150 miles long and wide...It will run from Niagara Falls on the south to about Oshawa on the north and take in numerous cities and towns already there, including Hamilton and Toronto."
With sixty percent of Canada's steel being produced in Hamilton by Stelco and Dofasco, the city has become known as the Steel Capital of Canada. After nearly declaring bankruptcy, Stelco returned to profitability in 2004. On August 26, 2007 United States Steel Corporation acquired Stelco for C$38.50 in cash per share, owning more than 76 percent of Stelco's outstanding shares. On September 17, 2014 US Steel Canada announced that it was applying for bankruptcy protection and that it would be closing down its Hamilton operations.
Dofasco, in 1999, was the most profitable steel producer in North America and in 2000, the most profitable in Canada. It currently has approximately 7,300 employees at its Hamilton plant and produces over four million tons of steel annually, representing about 30% of Canada's flat rolled sheet steel shipments. Dofasco is one of North America's most profitable steel companies, and Dofasco was named to the Dow Jones Sustainability World Index in 2006 for the seventh year in a row. Dofasco produces steel products for the automotive, construction, energy, manufacturing, pipe and tube, appliance, packaging and steel distribution industries. Dofasco is currently a stand alone subsidiary of Arcelor Mittal, the world's largest steel producer. Previously ordered by the U.S. Department of Justice to divest itself of the Canadian company, Arcelor Mittal has now been allowed to retain Dofasco provided it sells several of its American assets instead.
Originally, in the 1940s, the John C. Munro Hamilton International Airport was used as a wartime air force training station. Today TradePort International Corporation manages and operates the John C. Munro Hamilton International Airport. Under TradePort management, passenger traffic at the Hamilton terminal has increased from 90,000 in 1996 to approximately 900,000 in 2002. The airport's mid-term target for growth in its passenger service is five million air travelers annually. The air cargo sector of the airport has 24–7 operational capability and strategic geographic location, allowing its capacity to increase by 50% since 1996; 91,000 metric tonnes (100,000 tons) of cargo passed through the airport in 2002. Courier companies with operations at the airport include United Parcel Service and Cargojet Canada. In 2003, the city began developing a 30-year growth management strategy which called, in part, for a massive aerotropolis industrial park centred on Hamilton Airport. The aerotropolis proposal, now known as the "Airport Employment Growth District", is touted as a solution to the city's shortage of employment lands. Hamilton turned over operation of the airport to TradePort International Corp. in 1996. In 2007, YVR Airport Services (YVRAS), which runs the Vancouver International Airport, took over 100 percent ownership of TradePort in a $13-million deal. The airport is also home to the Canadian Warplane Heritage Museum.
A report by Hemson Consulting identified an opportunity to develop of greenfields (the size of the Royal Botanical Gardens) that could generate an estimated 90,000 jobs by 2031. A proposed aerotropolis industrial park at Highway 6 and 403, has been debated at City Hall for years. Opponents feel the city needs to do more investigation about the cost to taxpayers before embarking on the project.
Crime.
When ranked on a "total crime severity index", Hamilton was 21st in Canada in 2011 for a metropolitan area. This was an eight percent decrease from 2010. Of note was Hamilton's second place rank for police-reported hate crimes in 2011.
Government.
Citizens of Hamilton are represented at all three levels of Canadian government. Following the 2015 Federal Election, representation in the Parliament of Canada will consist of five Members of Parliament representing the federal ridings of Hamilton West—Ancaster—Dundas, Hamilton Centre, Hamilton East—Stoney Creek, Hamilton Mountain, and Flamborough—Glanbrook. This election will mark the first occasion in which Hamilton will have five Members of Parliament representing areas wholly within Hamilton's city boundaries, with previous boundaries situating rural ridings across municipal lines.
Provincially, there are five elected Members of Provincial Parliament who serve in the Legislature of Ontario. Minister of Housing and Municipal Affairs, Ted McMeekin (Liberal), represents Ancaster—Dundas—Flamborough—Westdale. Leader of the Ontario New Democratic Party, Andrea Horwath, represents Hamilton Centre, Paul Miller (NDP) represents Hamilton East—Stoney Creek, and Monique Taylor (NDP) represents Hamilton Mountain. Former leader of the Progressive Conservative Party of Ontario, Tim Hudak, serves as MPP for Niagara West—Glanbrook.
Hamilton's municipal government consists of one mayor, elected city wide, and 15 city councillors, elected individually by each of the city's wards, to serve on the Hamilton City Council. Presently, Hamilton's mayor is Fred Eisenberger, elected on October 27, 2014 to a second, non-consecutive term. Additionally, both Public and Catholic school board trustees are elected for defined areas ranging from two trustees for multiple wards to a single trustee for an individual ward. Municipal elections in Hamilton occur every four years, the last one occurring on October 27, 2014. The next scheduled municipal election will occur in October 2018.
The Hamilton City Council is granted authority to govern by the province through the Municipal Act of Ontario. As with all municipalities, the Province of Ontario has supervisory privilege over the municipality and the power to redefine, restrict or expand the powers of all municipalities in Ontario.
The Criminal Code of Canada is the chief piece of legislation defining criminal conduct and penalty. The Hamilton Police Service is chiefly responsible for the enforcement of federal and provincial law. Although the Hamilton Police Service has authority to enforce, bylaws passed by the Hamilton City Council are mainly enforced by Provincial Offences Officers employed by the City of Hamilton.
The Canadian Military maintains a presence in Hamilton, with the John Weir Foote Armoury located in the downtown core on James Street North, housing the Royal Hamilton Light Infantry as well as the 11th Field Hamilton-Wentworth Battery and the Argyll and Sutherland Highlanders of Canada. The Hamilton Reserve Barracks, located on Pier Nine, houses the naval reserve division , 23 Service Battalion and the 23 Field Ambulance.
Education.
Hamilton is home to several post-secondary institutions that have created numerous direct and indirect jobs in education and research. McMaster University moved to the city in 1930 and today has around 30,000 enrolled students, of whom almost two-thirds come from outside the immediate Hamilton region. Brock University of St. Catharines, Ontario has a satellite campus used primarily for teacher education located in Hamilton. Colleges in Hamilton include:
Public education for students from kindergarten through high school is administered by three school boards. The Hamilton-Wentworth District School Board manages 114 public schools, while the Hamilton-Wentworth Catholic District School Board operates 55 schools in the greater Hamilton area. The Conseil scolaire de district du Centre-Sud-Ouest operates one elementary and one secondary school (École secondaire Georges-P.-Vanier), and the Conseil scolaire de district catholique Centre-Sud operates two elementary schools and one secondary school. Calvin Christian School, Providence Christian School and Timothy Christian School are independent Christian elementary schools. Hamilton District Christian High School, Rehoboth Christian High School and Guido de Bres Christian High School are independent Christian high schools in the area. Both HDCH and Guido de Brès participate in the city's interscholastic athletics. Hillfield Strathallan College is located on the West Hamilton mountain and is a CAIS member, non-profit school for children from early Montessori ages through grade twelve.
The Dundas Valley School of Art is an independent art school which has serviced the Hamilton region since 1964. Students range in age from 4 years old to senior citizens and enrollment as of February 2007 was close to 4,000. In 1998, a new full time diploma programme was launched as a joint venture with McMaster University. The faculty and staff are highly regarded regional artists.
The Hamilton Conservatory for the Arts is home to many of the area's talented young actors, dancers, musicians, singers and visual artists. The school is equipped with a keyboard studio, spacious dance studios, art and sculpting studios, gallery space and a 300 seat recital hall. HCA offers over 90 programs for ages 3–93, creating a "united nations" of arts under one roof.
The Hamilton Literacy Council is a non-profit organization that provides basic (grades 1–5 equivalent) training in reading, writing, and math to English-speaking adults. The council's service is free, private, and one-to-one. It started to assist adults with their literacy skills in 1973.
Hamilton is home to two think tanks, the Centre for Cultural Renewal and Cardus, which deals with social architecture, culture, urbanology, economics and education and also publishes the "LexView Policy Journal" and "Comment Magazine".
Culture.
Hamilton has built on its historical and social background with attractions including the Canadian Warplane Heritage Museum, the National Historic Site (Canada's most famous warship and the last remaining Tribal Class in the world), Dundurn Castle (the residence of a Prime Minister of Upper Canada), the Royal Botanical Gardens, the Canadian Football Hall of Fame, the African Lion Safari Park, the Cathedral of Christ the King, and the Workers' Arts and Heritage Centre.
Founded in 1914, the Art Gallery of Hamilton is Ontario's third largest public art gallery. The gallery has over 9,000 works in its permanent collection that focus on three areas: 19th century European, Historical Canadian and Contemporary Canadian.
The McMaster Museum of Art (MMA), founded at McMaster University in 1967, houses and exhibits the University's art collection of more than 7,000 objects, including historical, modern and contemporary art, the Levy Collection of Impressionist and Post Impressionist paintings, and a collection of over 300 German Expressionist prints.
Hamilton has quite an active theatre scene, with the professional company Theatre Aquarius, plus long-time amateur companies, the Players' Guild of Hamilton and Hamilton Theatre Inc.. Many smaller theatre companies have also opened in the past decade, bringing a variety of theatre to the area.
Growth in the arts and culture sector has garnered high level media attention for Hamilton. A "Globe and Mail" article in 2006, entitled "Go West, Young Artist," focused on the growing art scene in Hamilton. The Factory: Hamilton Media Arts Centre, opened up a new home on James Street North in 2006. Art galleries are springing up on many streets across the City: James Street, King William Street, Locke Street and King Street, to name a few. This, coupled with growth in the downtown condo market which is drawing people back to the core, is having an impact on the cultural fabric of the city. The opening of the Downtown Arts Centre on Rebecca Street has spurred further creative activities in the core. The Community Centre for Media Arts (CCMA) continues to operate in downtown Hamilton. The CCMA works with marginalized populations and combines new media services such as website development, graphic design, video, and information technology, with arts education and skills development programming.
The 2009 film "Defendor", starring Woody Harrelson as a vigilante superhero, is implied to take place in Hamilton, referred to by its nickname of "Hammer Town" several times throughout the film. It was filmed in Hamilton and Toronto.
In March 2015, Hamilton was host to the JUNO Awards, which featured performances by Hedley, Alanis Morissette and Magic!. The award ceremony was held at the FirstOntario Centre in downtown Hamilton. During JUNOfest, hundreds of local acts performed across the city, bringing thousands of tourists.
Sports.
Hamilton was the host of Canada's first major international athletic event, the first Commonwealth Games (then called the British Empire Games) in 1930. Hamilton bid unsuccessfully for the Commonwealth Games in 2010, losing out to New Delhi in India. On November 7, 2009, in Guadalajara, Mexico it was announced that Toronto would host the 2015 Pan Am Games after beating out two rival South American cities, Lima, Peru and Bogota, Colombia. The city of Hamilton co-hosted the Games with Toronto. Hamilton Mayor Fred Eisenberger said, "the Pan Am Games will provide a 'unique opportunity for Hamilton to renew major sport facilities giving Hamiltonians a multi-purpose stadium, a 50-metre swimming pool, and an international-calibre velodrome to enjoy for generations to come.'"
The Around the Bay Road Race circumnavigates Hamilton Harbour. Although it is not a marathon distance, it is the longest continuously held long distance foot race in North America. The local newspaper also hosts the amateur Spectator Indoor Games.
Hamilton has representation in two professional sports leagues, the Canadian Football League and Major League Lacrosse. Its major sports complexes include Ivor Wynne Stadium and Copps Coliseum; Hamilton is also home to the Canadian Football Hall of Fame museum. The museum hosts an annual induction event in a week-long celebration that includes school visits, a golf tournament, a formal induction dinner and concludes with the Hall of Fame game involving the local CFL Hamilton Tiger-Cats at Ivor Wynne Stadium.
In addition to team sports, Hamilton is also home to an auto race track, Flamboro Speedway and Canada's fastest half-mile harness horse racing track, Flamboro Downs. Another auto race track, Cayuga International Speedway, is located near Hamilton in the Haldimand County community of Nelles Corners, situated between Hagersville and Cayuga.
Hamilton hosted an NHL team in the 1920s called the Hamilton Tigers. The team folded after a players' strike in 1925. Research in Motion CEO Jim Balsillie has shown interest in bringing another NHL team to southern Ontario. The NHL's Phoenix Coyotes filed for bankruptcy in 2009 and have included within their Chapter 11 reorganization a plan to sell the team to Balsillie and move the team and its operations to Hamilton, Ontario. In late September, however, the bankruptcy judge did not rule in favor of Balsillie. The City plans to continue their fight for an NHL team.
Sister cities.
Hamilton is a sister city with Flint, Michigan, and its young amateur athletes compete in the CANUSA Games, held alternatively in the two cities since 1958. Flint and Hamilton hold the distinction of having the oldest continuous sister-city relationship between a U.S. and Canadian city, since 1957.
Other sister cities with Hamilton include:
Other city relationships:

</doc>
<doc id="14291" url="https://en.wikipedia.org/wiki?curid=14291" title="Hussites">
Hussites

The Hussites ( or "Kališníci"; "Chalice People") were a Christian movement in the Kingdom of Bohemia following the teachings of Czech reformer Jan Hus (c. 1369–1415), who became the best-known representative of the Bohemian Reformation and one of the forerunners of the Protestant Reformation. This predominantly religious movement was propelled by social issues and strengthened Czech national awareness.
After the Council of Constance lured Jan Hus in with a letter of indemnity, then tried him for heresy and put him to death at the stake on 6 July 1415, the Hussites fought the Hussite Wars (1420–1434) for their religious and political cause.
Among present-day Christians, Hussite traditions are represented in the Moravian Church, Unity of the Brethren, and the refounded Czechoslovak Hussite churches.
Impact of Hus's death on Bohemia.
The arrest of Hus in 1414 caused considerable resentment in Czech lands. The authorities of both countries appealed urgently and repeatedly to King Sigismund to release Jan Hus.
When news of his death at the Council of Constance in 1415 arrived, disturbances broke out, directed primarily against the clergy and especially against the monks. Even the Archbishop narrowly escaped from the effects of this popular anger. The treatment of Hus was felt to be a disgrace inflicted upon the whole country and his death was seen as a criminal act. King Wenceslaus, prompted by his grudge against Sigismund, at first gave free vent to his indignation at the course of events in Constance. His wife openly favoured the friends of Hus. Avowed Hussites stood at the head of the government.
A league was formed by certain lords, who pledged themselves to protect the free preaching of the Gospel upon all their possessions and estates and to obey the power of the Bishops only where their orders accorded with the injunctions of the Bible. The university would arbitrate any disputed points. The entire Hussite nobility joined the league. Other than verbal protest of the council's treatment of Hus, there was little evidence of any actions taken by the nobility until 1417. At that point several of the lesser nobility and some barons, signatories of the 1415 protest letter, removed Romanist priests from their parishes, replacing them with priests willing to give communion in both wine and bread. The chalice of wine became the central identifying symbol of the Hussite movement. If the king had joined, its resolutions would have received the sanction of the law; but he refused, and approached the newly formed Roman Catholic League of lords, whose members pledged themselves to support the king, the Catholic Church, and the Council. The prospect of a civil war began to emerge.
Pope Martin V as Cardinal Otto of Colonna had attacked Hus with relentless severity. He energetically resumed the battle against Hus's teaching after the enactments of the Council of Constance. He wished to eradicate completely the doctrine of Hus, for which purpose the co-operation of King Wenceslaus had to be obtained. In 1418, Sigismund succeeded in winning his brother over to the standpoint of the council by pointing out the inevitability of a religious war if the heretics in Bohemia found further protection. Hussite statesmen and army leaders had to leave the country and Roman Catholic priests were reinstated. These measures caused a general commotion which hastened the death of King Wenceslaus by a paralytic stroke in 1419. His heir was Sigismund.
The parties of the Bohemian Hussites.
Hussism organised itself during the years 1415–1419. From the beginning, there formed two parties, with a smaller number of people withdrawing from both parties around the pacifist Petr Chelčický, whose teachings would form the foundation of the Unitas Fratrum.
The moderate party, who followed Hus more closely, sought to conduct reform while leaving the whole hierarchical and liturgical order of the Church untouched.
The more radical party identified itself more boldly with the doctrines of John Wycliffe, sharing his passionate hatred of the monastic clergy, and his desire to return the Church to its supposed condition during the time of the apostles. This required the removal of the existing hierarchy and the secularisation of ecclesiastical possessions. The radicals preached the ""sufficientia legis Christi""—the divine law (i.e. the Bible) is the sole rule and canon for human society, not only in the church, but also in political and civil matters. They rejected therefore, as early as 1416, everything that they believed had no basis in the Bible, such as the veneration of saints and images, fasts, superfluous holidays, the oath, intercession for the dead, auricular Confession, indulgences, the sacraments of Confirmation and the Anointing of the Sick; they admitted laymen and women to the preacher's office, and chose their own priests. But above all they clung to Wycliffe's doctrine of the Lord's Supper, denying transubstantiation, and this is the principal point by which they are distinguished from the moderate party.
Four Articles of Prague.
The programme of the more conservative Hussites (the moderate party) is contained in the Four Articles of Prague, which where written by Jakoubek z Vřesovic and agreed upon in July 1420, promulgated in the Latin, Czech, and German languages. The full text is about two pages long, but they are often summarized as:
Calixtines (or Utraquists) and Taborites.
The views of the moderate Hussites were widely represented at the University and among the citizens of Prague; they were therefore called the Prague Party, but also Calixtines (Latin "calix" chalice) or Utraquists (Latin "utraque" both), because they emphasized the second article of Prague, and the chalice became their emblem.
The radicals (the radical party) had their gathering-places all around the country. Their first armed assault fell on the small town of Ústí, on the river Lužnice, south of Prague (today's Sezimovo Ústí). However, as the place did not prove to be defensible, they settled in the remains of an older town upon a hill not far away and founded a new town, which they named Tábor (after the traditional name of the mountain on which Jesus was expected to return; see Mark 13); hence they were called Táborité (Taborites). They comprised the essential force of the radical Hussites. Their aim was to destroy the enemies of the law of God, and to defend his kingdom (which had been expected to come in a short time) by the sword. Their end-of-world visions did not come true. In order to preserve their settlement and spread their ideology, they waged bloody wars; in the beginning they observed a strict regime, inflicting the severest punishment equally for murder, as for less severe faults as adultery, perjury and usury, and also tried to apply rigid Biblical standards to the social order of the time. The Taborites usually had the support of the Orebites (later called Orphans), an eastern Bohemian sect of Hussitism based in Hradec Králové.
Hussite Wars.
The news of the death of King Wenceslaus in 1419 produced a great commotion among the people of Prague. A revolution swept over the country: churches and monasteries were destroyed, and church property was seized by the Hussite nobility. Sigismund could get possession of his kingdom only by force of arms. Pope Martin V called upon Catholics of the West to take up arms against the Hussites, declaring a crusade, and there followed twelve years of warfare.
The Hussites initially campaigned defensively, but after 1427, they assumed the offensive. Apart from their religious aims, they fought for the national interests of the Czechs. The moderate and radical parties were united and they not only repelled the attacks of the army of crusaders, but crossed the borders into neighboring countries. On March 23, 1430, Joan of Arc dictated a letter that threatened to lead a crusading army against the Hussites unless they returned to the Catholic faith, but her capture by English and Burgundian troops two months later would keep her from carrying out this threat.
The Council of Basel and Compacta of Prague.
Eventually, the opponents of the Hussites found themselves forced to consider an amicable settlement. They invited a Bohemian embassy to appear at the Council of Basel. The discussions began on 10 January 1432, centering chiefly on the four articles of Prague. No agreement emerged. After repeated negotiations between the Basel Council and Bohemia, a Bohemian–Moravian state assembly in Prague accepted the ""Compacta"" of Prague on 30 November 1433. The agreement granted communion in both kinds to all who desired it, but with the understanding that Christ was entirely present in each kind. Free preaching was granted conditionally: the Church hierarchy had to approve and place priests, and the power of the bishop must be considered. The article which prohibited the secular power of the clergy was almost reversed.
The Taborites refused to conform. The Calixtines united with the Roman Catholics and destroyed the Taborites at the Battle of Lipany on (30 May 1434). From that time, the Taborites lost their importance, though the Hussite movement would continue in Poland for another five years, until the Royalist forces of Poland defeated the Polish Hussites at the Battle of Grotniki. The state assembly of Jihlava in 1436 confirmed the ""Compacta"" and gave them the sanction of law. This accomplished the reconciliation of Bohemia with Rome and the Western Church, and at last Sigismund obtained possession of the Bohemian crown. His reactionary measures caused a ferment in the whole country, but he died in 1437. The state assembly in Prague rejected Wyclif's doctrine of the Lord's Supper, which was obnoxious to the Utraquists, as heresy in 1444. Most of the Taborites now went over to the party of the Utraquists; the rest joined the "Brothers of the Law of Christ" () (see Unity of the Brethren; also Bohemian Brethren and Moravian Church).
Reorganisation of the Hussites.
In 1462, Pope Pius II declared the ""Compacta"" null and void, prohibited communion in both kinds, and acknowledged King George of Podebrady as king on condition that he would promise an unconditional harmony with the Roman Church. This he refused, but his successor, King Vladislaus II, favored the Roman Catholics and proceeded against some zealous clergymen of the Calixtines. The troubles of the Utraquists increased from year to year. In 1485, at the Diet of Kutná Hora, an agreement was made between the Roman Catholics and Utraquists which lasted for thirty-one years. It was only later, at the Diet of 1512, that the equal rights of both religions were permanently established. Luther's appearance was hailed by the Utraquist clergy, and Martin Luther himself was astonished to find so many points of agreement between the doctrines of Hus and his own. But not all Utraquists approved of the German Reformation; a schism arose among them, and many returned to the Roman doctrine, while other elements had organised the ""Unitas Fratrum"" already in 1457.
Under Emperor Maximilian II, the Bohemian state assembly established the ""Confessio Bohemica,"" upon which Lutherans, Reformed, and Bohemian Brethren agreed. From that time forward Hussitism began to die out. After the Battle of White Mountain on 8 November 1620 the Roman Catholic Faith was re-established with vigour which fundamentally changed the religious conditions of the Czech lands.
Leaders and members of Unitas Fratrum were forced to choose to either leave the many and varied southeastern principalities of what was the Holy Roman Empire (mainly Austria, Hungary, Bohemia, Moravia and parts of Germany and its many states), or to practice their beliefs secretly. As a result, members were forced underground and dispersed across northwestern Europe. The largest remaining communities of the Brethren were located in Lissa (Leszno) in Poland, which had historically strong ties with the Czechs, and in small, isolated groups in Moravia. Some, among them Jan Amos Comenius, fled to western Europe, mainly the Low Countries. A settlement of Hussites in Herrnhut, Saxony, now Germany, in 1722 caused the emergence of the Moravian Church.
Today, the Czechoslovak Hussite Church claims to be the modern successor of the Hussite tradition.

</doc>
<doc id="14292" url="https://en.wikipedia.org/wiki?curid=14292" title="HMS Ark Royal">
HMS Ark Royal

Five ships of the Royal Navy have borne the name HMS "Ark Royal":
The Prince of Wales is understood to have privately agreed to allow that the second "Queen Elizabeth"-class aircraft carrier, which is set to be named , be renamed "Ark Royal".

</doc>
<doc id="14293" url="https://en.wikipedia.org/wiki?curid=14293" title="Herman of Alaska">
Herman of Alaska

Saint Herman of Alaska (Russian: Преподобный Герман Аляскинский, c. 1750s – November 15, 1836) was a Russian Orthodox monk and missionary to Alaska, which was then part of Russian America. His gentle approach and ascetic life earned him the love and respect of both the native Alaskans and the Russian colonists. He is considered by many Orthodox Christians as the patron saint of North America.
Early life.
Biographers disagree about Herman’s early life. His official biography, which Valaam Monastery published in 1867, stated that his pre-monastic name was unknown, but Herman was born into a merchant’s family in Serpukhov, a city in Moscow Governorate, and later became a novice at the Trinity-St. Sergius Hermitage near St. Petersburg before going to Valaam to become a full monk. However, modern biographer Sergei Korsun found this based on erroneous information provided by Simeon Yanovsky, a former administrator of the Russian-American Company (RAC) in Alaska, who confused Herman’s biographical information with another monk, Joseph (Telepnev).
Another former RAC administrator, Ferdinand von Wrangel, stated Herman was originally from a prosperous peasant family in the Voronezh Governorate and served in the military, but then became a monk at Sarov Monastery. This concurred with testimony of Archimandrite Theophan (Sokolov), and a letter written by Herman himself, which all agree that Herman actually began his monastic life at Sarov as a novice, and later received the full tonsure at Valaam. A young military clerk named Egor Ivanovich Popov from the Voronezh Governorate, was in fact tonsured with the name Herman at Valaam in 1782.
All biographers agree that at Valaam, Herman studied under Abbot Nazarius, previously of Sarov Monastery, who was influenced by the hesychastic tradition of Paisius Velichkovsky. Herman undertook various obediences and was well-liked by the brethren, but wanted a more solitary life and so became a hermit with Abbot Nazarius' blessing. His hermitage, which later became known as “Herman’s field” or Germanovo, was two kilometers from the monastery. Metropolitan Gabriel of St. Petersburg offered to ordain Herman to the priesthood and twice offered to send him to lead the Russian Orthodox Mission in China, but he refused, preferring the solitary life and remain a simple monk. Years after he left for America, Herman continued to keep in touch with his spiritual home, and in a letter to Abbot Nazarius wrote, “in my mind I imagine my beloved Valaam, and constantly behold it across the great ocean.”
Mission in Alaska.
The Russian colonization of the Americas began when Vitus Bering and Aleksei Chirikov discovered Alaska in 1741. The expedition harvested 1,500 sea otter pelts, which Chinese merchants bought for 1,000 rubles each at their trading post near Lake Baikal. This spurred a “fur rush” from 1741–1798 in which frontiersmen known as "promyshlenniki" explored Alaska and the Aleutian Islands and alternately fought and intermarried with the native peoples. Grigory Shelikhov, a fur-trader, subjugated the native population of Kodiak Island and with Ivan Golikov founded a fur-trading company which eventually received a monopoly from the Imperial government and became the Russian-American Company. Shelikhov founded a school for the natives, of whom many were converted to Russian Orthodox Christianity.
The Shelikhov-Golikov Company appealed to the Most Holy Synod of the Russian Orthodox Church to provide a priest for the natives. Catherine the Great decided instead to send an entire mission to America. She entrusted the task of recruiting missionaries to Metropolitan Gabriel of St. Petersburg, who sent ten monks from Valaam, including Herman. The missionaries arrived on Kodiak on September 24, 1794.
Herman and the other missionaries encountered a harsh reality at Kodiak that did not correspond to Shelikhov’s rosy descriptions. The native Kodiak population, called “Americans” by the Russian settlers, were subject to harsh treatment by the Russian-American Company, which was being overseen by Shelikhov’s manager Alexander Baranov who later became the first governor of the colony. The men were forced to hunt for sea otter even during harsh weather, and women and children were abused. The monks were also shocked at the widespread alcoholism in the Russian population, and the fact that most of the settlers had taken native mistresses. The monks themselves were not given the supplies that Shelikhov promised them, and had to till the ground with wooden implements. Despite these difficulties, the monks managed to baptize over 7,000 natives in the Kodiak region, and set about building a church and monastery. Herman was assigned in the bakery and acted as the mission’s steward ("ekonom").
The monks became the defenders of the native Kodiak population. Herman was especially noted for his zeal in protecting them from the excessive demands of the RAC, and Baranov disparaged him in a letter as a “hack writer and chatterer.” A contemporary historian compares him to Bartolomé de las Casas, the Roman Catholic friar who defended the rights of native South Americans against the Spanish.
After over a decade spent in Alaska, Herman became the head of the mission in 1807, although he was not ordained to the priesthood. The local population loved and respected him, and he even had good relations with Baranov. Herman ran the mission school, where he taught church subjects such as singing and catechism alongside reading and writing. He also taught agriculture on Spruce Island. However, because he longed for the life of a hermit he soon retired from active duty in the mission and moved to Spruce Island.
Life on Spruce Island.
Herman moved to Spruce Island around 1811 to 1817. The island is separated from Kodiak by a mile-wide strait, making it ideal for eremetic life. Herman named his hermitage “New Valaam.” He wore simple clothes and slept on a bench covered with a deerskin. When asked how he could bear to be alone in the forest, he replied, “I am not alone. God is here, as God is everywhere.”
Despite his solitary life, he soon gained a following. He received many visitors—especially native Aleuts—on Sundays and church feasts. Soon his hermitage had next to it a chapel and guesthouse, and then a school for orphans. Herman had a few disciples, including the Creole orphan Gerasim Ivanovich Zyrianov, a young Aleut woman named Sofia Vlasova, and others. Entire families moved in order to be closer to the Elder, who helped to sort out their disputes. Herman had a deep love for the native Aleuts: he stood up for them against the excesses of the Russian-American Company, and once during an epidemic he was the only Russian to visit them, working tirelessly to care for the sick and console the dying. Herman spent the rest of his life on Spruce Island, where he died on November 15, 1836.
Sainthood.
On March 11, 1969, the bishops of the Orthodox Church in America (OCA) formally declared their intention to canonize Herman, “as a sublime example of the Holy Life, for our spiritual benefit, inspiration, comfort, and the confirmation of our Faith.” On August 9, 1970, Metropolitan Ireney (Bekish) of the OCA along with Archbishop Paul (Olmari) of Finland and other hierarchs and clergy presided over the canonization service, which was held at Holy Resurrection Cathedral on Kodiak Island. His relics were transferred from his grave underneath the Sts. Sergius and Herman of Valaam Chapel (i.e., the Saints Sergius and Herman of Valaam Chapel), on Spruce Island, to the Holy Resurrection Cathedral.
On the same date, the bishops of the Russian Orthodox Church Outside of Russia also canonized Herman at the Holy Virgin Cathedral (“Joy of All Who Sorrow”) in San Francisco. At the all-night vigil, the canon to St. Herman was read for the first time by Brother Gleb Podmoshensky (later Fr. Herman), one of the founding brothers of the St. Herman of Alaska Serbian Orthodox Brotherhood in 1963. He, Eugene (Seraphim) Rose, and Lawrence Campbell (now Monk John of Holy Trinity Monastery (Jordanville)) gathered material for the Synod of Bishops in order to support the glorification of St. Herman, and also helped compose the liturgical service in his honor.
There are several feast days throughout the year on which Saint Herman of Alaska is commemorated. Since there are two different calendars currently in use among various Orthodox churches, two dates are listed: the first date is the date on the traditional Julian Calendar, the second date, after the slash, is the same day on the modern Gregorian Calendar:
The major portion of his relics are preserved at Holy Resurrection Cathedral in Kodiak, Alaska, while his burial site at the Sts. Sergius and Herman Chapel, Spruce Island, Alaska is an important pilgrimage site, where the devout will often take soil from his grave and water from the spring named in his honour. A portion of his relics are enshrined at the St. Ignatius Chapel at the Antiochan Village in Pennsylvania, a conference and retreat center of the Antiochian Orthodox Christian Archdiocese of North America, where he is regarded as one of their patron saints.
In 1963, with the blessing of St. John Maximovitch, Archbishop of Shanghai and San Francisco, a community of Orthodox booksellers and publishers called the St. Herman of Alaska Brotherhood was formed to publish Orthodox missionary information in English. One of the founders was Father Seraphim Rose. The Brotherhood did much to advance the cause of St. Herman's glorification as a saint. Saint Herman's Orthodox Theological Seminary in Kodiak, Alaska is named in his honor, as are numerous parish churches throughout the world.
On Tuesday, August 4, 1970, the 91st Congress of the United States acknowledged the Glorification of St Herman of Alaska with a speech in the Senate, and his biography was formally entered into the Congressional Record.
In 1993, Patriarch Alexis II visited Kodiak to venerate the relics of Saint Herman. He left as a gift an ornate "lampada" (oil lamp) which burns constantly over the reliquary. Pilgrims from all over the world are anointed with holy oil from this lampada.
Herman is also honored with a feast day on the liturgical calendar of the Episcopal Church (USA) on August 9.
The Finnish Orthodox Church chapel in Tapiola, Finland is dedicated to St. Herman of Alaska.

</doc>
<doc id="14294" url="https://en.wikipedia.org/wiki?curid=14294" title="Hausdorff dimension">
Hausdorff dimension

Hausdorff dimension is a concept in mathematics introduced in 1918 by mathematician Felix Hausdorff, and it serves as a measure of the local size of a set of numbers (i.e., a "space"), taking into account the distance between each of its members (i.e., the "points" in the "space"). Applying its mathematical formalisms provides that the Hausdorff dimension of a single point is zero, of a line is 1, and of a square is 2, of a cube is 3. That is, for sets of points that define a smooth shape or a shape that has a small number of corners—the shapes of traditional geometry and science—the Hausdorff dimension is a "counting number" (integer) agreeing with a dimension corresponding to its topology. However, formalisms have also been developed that allow calculation of the dimension of other less simple objects, where, based solely on its properties of scaling and self-similarity, one is led to the conclusion that particular objects—including fractals—have non-integer Hausdorff dimensions. Because of the significant technical advances made by Abram Samoilovitch Besicovitch allowing computation of dimensions for highly irregular sets, this dimension is also commonly referred to as the "Hausdorff–Besicovitch dimension."
The Hausdorff dimension is, more specifically, a further dimensional number associated with a given set of numbers, where the distances between all members of that set are defined, and where the dimension is drawn from the real numbers, ℝ, to which two elements have been added, +∞ and −∞ (read as positive and negative infinity, respectively). The set that provides the Hausdorff dimension is called the extended real numbers, , and a set of numbers where distances between all members are defined is termed a metric space, so that foregoing can be succinctly stated, saying the Hausdorff dimension is a non-negative extended real number ( ≥ 0) associated with any metric space.
In mathematical terms, the Hausdorff dimension generalizes the notion of the dimension of a real vector space. That is, the Hausdorff dimension of an "n"-dimensional inner product space equals "n". This underlies the earlier statement that the Hausdorff dimension of a point is zero, of a line is one, etc., and that irregular sets can have noninteger Hausdorff dimensions. For instance, the Koch curve summarized earlier is constructed from an equilateral triangle; in each iteration, its component line segments are divided into 3 segments of unit length, the newly created middle segment is used as the base of a new equilateral triangle that points outward, and this base segment is then deleted to leave a final object from the iteration of unit length of 4. That is, after the first iteration, each original line segment has been replaced with N=4, where each self-similar copy is 1/S = 1/3 as long as the original. Stated another way, we have taken an object with Euclidean dimension, D, and reduced its linear scale by 1/3 in each direction, so that its length increases to N=SD. This equation is easily solved for D, yielding the ratio of logarithms (or natural logarithms) appearing in the figures, and giving—in the Koch and other fractal cases—non-integer dimensions for these objects.
The Hausdorff dimension is a successor to the simpler, but usually equivalent, box-counting or Minkowski–Bouligand dimension.
Intuition.
The intuitive concept of dimension of a geometric object "X" is the number of independent parameters one needs to pick out a unique point inside. However, any point specified by two parameters can be instead specified by one, because the cardinality of the real plane is equal to the cardinality of the real line (this can be seen by an argument involving interweaving the digits of two numbers to yield a single number encoding the same information.) The example of a space-filling curve shows that one can even take one real number into two both surjectively (so all pairs of numbers are covered) and "continuously", so that a one-dimensional object completely fills up a higher-dimensional object.
Every space filling curve hits some points multiple times, and does not have a continuous inverse. It is impossible to map two dimensions onto one in a way that is continuous and continuously invertible. The topological dimension, also called Lebesgue covering dimension, explains why. This dimension is "n" if, in every covering of "X" by small open balls, there is at least one point where "n" + 1 balls overlap. For example, when one covers a line with short open intervals, some points must be covered twice, giving dimension "n" = 1.
But topological dimension is a very crude measure of the local size of a space (size near a point). A curve that is almost space-filling can still have topological dimension one, even if it fills up most of the area of a region. A fractal has an integer topological dimension, but in terms of the amount of space it takes up, it behaves like a higher-dimensional space.
The Hausdorff dimension measures the local size of a space taking into account the distance between points, the metric. Consider the number "N"("r") of balls of radius at most "r" required to cover "X" completely. When "r" is very small, "N"("r") grows polynomially with 1/"r". For a sufficiently well-behaved "X", the Hausdorff dimension is the unique number "d" such that N("r") grows as 1/"rd" as "r" approaches zero. More precisely, this defines the box-counting dimension, which equals the Hausdorff dimension when the value "d" is a critical boundary between growth rates that are insufficient to cover the space, and growth rates that are overabundant.
For shapes that are smooth, or shapes with a small number of corners, the shapes of traditional geometry and science, the Hausdorff dimension is an integer agreeing with the topological dimension. But Benoît Mandelbrot observed that fractals, sets with noninteger Hausdorff dimensions, are found everywhere in nature. He observed that the proper idealization of most rough shapes you see around you is not in terms of smooth idealized shapes, but in terms of fractal idealized shapes:
Clouds are not spheres, mountains are not cones, coastlines are not circles, and bark is not smooth, nor does lightning travel in a straight line.
For fractals that occur in nature, the Hausdorff and box-counting dimension coincide. The packing dimension is yet another similar notion which gives the same value for many shapes, but there are well documented exceptions where all these dimensions differ.
Formal definitions.
Hausdorff content.
Let "X" be a metric space. If "S" ⊂ "X" and "d" ∈ [0, ∞), the "d"-dimensional Hausdorff content of "S" is defined by
In other words, formula_2 is the infimum of the set of numbers δ ≥ 0 such that there is some (indexed) collection of balls formula_3 covering "S" with "ri" > 0 for each "i" ∈ "I" that satisfies formula_4. (Here, we use the standard convention that inf Ø = ∞.)
Hausdorff dimension.
The Hausdorff dimension of "X" is defined by
Equivalently, dimH("X") may be defined as the infimum of the set of "d" ∈ [0, ∞) such that the "d"-dimensional Hausdorff measure of "X" is zero. This is the same as the supremum of the set of "d" ∈ [0, ∞) such that the "d"-dimensional Hausdorff measure of "X" is infinite (except that when this latter set of numbers "d" is empty the Hausdorff dimension is zero).
Properties of Hausdorff dimension.
Hausdorff dimension and inductive dimension.
Let "X" be an arbitrary separable metric space. There is a topological notion of inductive dimension for "X" which is defined recursively. It is always an integer (or +∞) and is denoted dimind("X").
Theorem. Suppose "X" is non-empty. Then 
Moreover,
where "Y" ranges over metric spaces homeomorphic to "X". In other words, "X" and "Y" have the same underlying set of points and the metric "d""Y" of "Y" is topologically equivalent to "d""X".
These results were originally established by Edward Szpilrajn (1907–1976), e.g., see Hurewicz and Wallman, Chapter VII.
Hausdorff dimension and Minkowski dimension.
The Minkowski dimension is similar to, and at least as large as, the Hausdorff dimension, and they are equal in many situations. However, the set of rational points in 1 has Hausdorff dimension zero and Minkowski dimension one. There are also compact sets for which the Minkowski dimension is strictly larger than the Hausdorff dimension.
Hausdorff dimensions and Frostman measures.
If there is a measure μ defined on Borel subsets of a metric space "X" such that "μ"("X") > 0 and "μ"("B"("x", "r")) ≤ "rs" holds for some constant "s" > 0 and for every ball "B"("x", "r") in "X", then dimHaus("X") ≥ "s". A partial converse is provided by Frostman's lemma.
Behaviour under unions and products.
If formula_8 is a finite or countable union, then
This can be verified directly from the definition.
If "X" and "Y" are non-empty metric spaces, then the Hausdorff dimension of their product satisfies
This inequality can be strict. It is possible to find two sets of dimension 0 whose product has dimension 1. In the opposite direction, it is known that when "X" and "Y" are Borel subsets of R"n", the Hausdorff dimension of "X" × "Y" is bounded from above by the Hausdorff dimension of "X" plus the upper packing dimension of "Y". These facts are discussed in Mattila (1995).
Self-similar sets.
Many sets defined by a self-similarity condition have dimensions which can be determined explicitly. Roughly, a set "E" is self-similar if it is the fixed point of a set-valued transformation ψ, that is ψ("E") = "E", although the exact definition is given below.
Theorem. Suppose
are contractive mappings on R"n" with contraction constant "rj" < 1. Then there is a unique "non-empty" compact set "A" such that
The theorem follows from Stefan Banach's contractive mapping fixed point theorem applied to the complete metric space of non-empty compact subsets of R"n" with the Hausdorff distance.
The open set condition.
To determine the dimension of the self-similar set "A" (in certain cases), we need a technical condition called the "open set condition" (OSC) on the sequence of contractions ψ"i".
There is a relatively compact open set "V" such that
where the sets in union on the left are pairwise disjoint.
The open set condition is a separation condition that ensures the images ψ"i"("V") do not overlap "too much".
Theorem. Suppose the open set condition holds and each ψ"i" is a similitude, that is a composition of an isometry and a dilation around some point. Then the unique fixed point of ψ is a set whose Hausdorff dimension is "s" where "s" is the unique solution of
The contraction coefficient of a similitude is the magnitude of the dilation.
We can use this theorem to compute the Hausdorff dimension of the Sierpinski triangle (or sometimes called Sierpinski gasket). Consider three non-collinear points "a"1, "a"2, "a"3 in the plane R2 and let ψ"i" be the dilation of ratio 1/2 around "ai". The unique non-empty fixed point of the corresponding mapping ψ is a Sierpinski gasket and the dimension "s" is the unique solution of
Taking natural logarithms of both sides of the above equation, we can solve for "s", that is: "s" = ln(3)/ln(2). The Sierpinski gasket is self-similar and satisfies the OSC. In general a set "E" which is a fixed point of a mapping
is self-similar if and only if the intersections
where "s" is the Hausdorff dimension of "E" and "Hs" denotes Hausdorff measure. This is clear in the case of the Sierpinski gasket (the intersections are just points), but is also true more generally:
Theorem. Under the same conditions as the previous theorem, the unique fixed point of ψ is self-similar.

</doc>
<doc id="14296" url="https://en.wikipedia.org/wiki?curid=14296" title="Heckler &amp; Koch">
Heckler &amp; Koch

Heckler & Koch GmbH (HK) () is a German defense manufacturing company that manufactures handguns, military rifles, submachine guns, and grenade launchers. The company is located in Oberndorf in the state of Baden-Württemberg, and also has subsidiaries in the United Kingdom, France and the United States.
The Heckler & Koch Group comprises Heckler & Koch GmbH, Heckler & Koch Defense, NSAF Ltd., and Heckler & Koch France SAS. The company motto is ""Keine Kompromisse!"" (No Compromise!). HK provides firearms for many military and paramilitary units, like the SAS, KMar, the US Navy Seals, Delta Force, HRT, the German KSK and GSG 9 and many other counter-terrorist and hostage rescue teams.
Their products include the MP5 SMG, the G3 battle rifle, the HK33, G36, HK416 assault rifles, the Heckler & Koch HK21 general-purpose machine gun, the MP7 PDW, the UMP SMG, the USP series of handguns, and the high-precision PSG1 sniper rifle. All firearms made by HK are named by a prefix and the official designation, with suffixes used for variants.
HK has a history of innovation in firearms, such as the use of polymers in weapon designs and the use of an integral rail for flashlights on handguns. HK also developed modern polygonal rifling, noted for its high accuracy, increased muzzle velocity and barrel life. Not all of its technologically ambitious designs have translated into commercially successful products (for instance, the advanced but now abandoned G11 military rifle, which fired caseless high-velocity ammunition). In its extensive product range, HK has used the following operating systems for small arms: blowback operation, short-recoil, roller-delayed blowback, gas-delayed blowback, and gas operation (via Short-stroke piston).
History.
With the fall of Germany at the end of World War II, Oberndorf came under French control, and the entire Waffenfabrik Mauser AG factory was dismantled by French occupying forces. All records in the factory were destroyed on orders of the local US Army commander. In 1948, three former Mauser engineers, Edmund Heckler, Theodor Koch, and Alex Seidel saved what they could from the factory and what they salvaged was used to start a machine tool plant in the vacant factory that became known as the Engineering Office Heckler & Co.
On December 28, 1949, the Engineering Office Heckler & Co. changed its name and was registered officially as Heckler & Koch GmbH. Initially the new company manufactured machine tools, bicycle and sewing machine parts, gauges and other precision parts.
In 1956, Heckler & Koch responded to the West German Government's tender for a new infantry rifle for the Bundeswehr (German Federal Army) with the proposal of the G3 battle rifle, which was based on the Spanish CETME rifle. The German Government awarded Heckler & Koch this tender and by 1959, declared the G3 as the standard rifle of the Bundeswehr. In 1961, Heckler & Koch developed the 7.62×51mm HK21 general-purpose machine gun, based on the G3 battle rifle.
In 1966, Heckler & Koch introduced the HK54 machine pistol, which eventually launched in 1969 as the MP5 machine pistol. Two years later, the company introduced the 5.56×45mm HK33 assault rifle, which is a smaller version of the G3 battle rifle chambered in 5.56mm NATO.
Diversification.
In 1974, Heckler & Koch diversified into the following two business areas: HK Defense and Law Enforcement Technology and HK Hunting and Sports Firearms. Since then HK has designed and manufactured more than one hundred different types of firearms and devices for the world's military and law enforcement organizations as well as sportsmen and hunters.
In 1990, Heckler & Koch finalised over two decades of development with their revolutionary case-less weapon system and produces prototypes of the HK G11. In addition, the company produced prototypes of the HK G41 military rifle intended for the Bundeswehr. Due to the international political climate at that time (East and West Germany uniting and defense budget cuts) the company was unable to secure funded contracts from the German Government to support production of either weapon system and this resulted in the company becoming financially vulnerable. In the following year, the Heckler & Koch company was sold to the British Aerospace's Royal Ordnance division.
During 1994 and 1995, the German Government awarded Heckler & Koch with contracts for producing an updated standard assault rifle and updated standard sidearm for the Bundeswehr. As a result, Heckler & Koch developed and produced the Project HK50, a lightweight carbon fiber–reinforced polymer assault rifle, which became the HK G36 assault rifle. In addition, Heckler & Koch produced the HK P8 derived as a variant based upon its Universale Selbstladepistole (USP) series of handguns (which had been in production since 1989). The P8 was adopted as the standard issue handgun for the Bundeswehr in 1994 and the G36 was adopted in 1995.
As the result of a 1999 merger between British Aerospace and Marconi Electronic Systems, Heckler & Koch was then owned by BAE Systems and was contracted to refurbish the SA80 rifle for the British Army. This contract entailed a modification programme to the SA80 series of rifles to address a number of reliability issues with the SA80. Three years later in 2002, BAE Systems restructured and sold Heckler & Koch to a group of private investors, who created the German group holding company (HK Beteiligungs-GmbH).
In 2003, the HK Beteiligungs GmbH group's business organization restructured as Heckler & Koch Jagd und Sportwaffen GmbH (HKJS) and its business was separated into the following two business areas (similar to the 1974 business mission areas): Defense and Law Enforcement and Sporting Firearms.
In 2004, Heckler & Koch was awarded a major handgun contract for the DHS, worth a potential $26.2 million for up to 65,000 handguns. This contract ranks as the single largest handgun procurement contract in US law enforcement history.
HK was contracted by the U.S. Army to produce the kinetic energy subsystem (see: kinetic projectiles or kinetic energy penetrator) of the Objective Individual Combat Weapon, a planned replacement for the M16/M203 grenade launcher combination. The OICW was designed to fire 5.56 mm bullets and 25 mm grenades. The kinetic energy component was also developed separately as the XM8, though both the OICW and XM8 are now indefinitely suspended.
Heckler & Koch developed a Colt M4 variant, marketed as the HK416. HK replaced the direct impingement system used by the Stoner design on the original M16 platform with a short-stroke piston operating system.
At this date, there is no indication that the rifle will be adopted by the United States Armed Forces; other than use in the Marine Corps as the IAR or M27. However, the elite Delta Force and other special operations units have fielded the HK416 in combat, and Oklahoma Senator Tom Coburn has called for a "free and open competition" to determine whether the army should buy the HK416 or continue to purchase more M4 carbines. Incoming Secretary of the Army Pete Geren agreed in July 2007 to hold a "dust chamber" test, pitting the M4 against HK's HK416 and XM8, as well as the rival Fabrique Nationale's SOF Combat Assault Rifle (SCAR) design. Coburn had threatened to stop Geren’s Senate confirmation if he did not agree to the test. The HK XM8 and FN SCAR had the fewest failures in the test, closely followed by the HK416, while the M4 had by far the most. In 2007, the Norwegian Army became the first to field the HK416 as a standard issue rifle.
HK sells its pistols in the United States to both law enforcement and civilian markets. The company has locations in Virginia, New Hampshire, and Georgia.
Trafficking allegations.
HK has been accused of shipping small arms to conflict regions such as Bosnia and Nepal, and has licensed its weapons for production by governments with poor human rights records such as Sudan, Thailand and Burma. It has been argued that the company effectively evaded EU export restrictions when these licensees sold HK weapons to conflict zones including Indonesia, Sri Lanka and Sierra Leone.
According to the Stuttgarter Nachrichten papers (31.8.11), as well as the state broadcaster ARD, a large stockpile of G36 assault rifles fell into rebel hands during the attack on Colonel Qaddafi's compound in Tripoli in August 2011, reporting that pictures proved the rifles carried the company's trademark. It was unclear exactly how many or who exported them to Libya.
HK abbreviations.
Format: Abbreviation = "German Text" ("English Text")

</doc>
<doc id="14297" url="https://en.wikipedia.org/wiki?curid=14297" title="Heckler &amp; Koch MP5">
Heckler &amp; Koch MP5

The Heckler & Koch MP5 (from , meaning "machine pistol 5") is a 9mm submachine gun of German design, developed in the 1960s by a team of engineers from the German small arms manufacturer Heckler & Koch GmbH (H&K) of Oberndorf am Neckar. There are over 100 variants of the MP5, including a semi-automatic version.
The MP5 is one of the most widely used submachine guns in the world, having been adopted by 40 nations and numerous military, law enforcement, intelligence, and security organizations. It is widely used by SWAT teams in North America.
In 1999, Heckler & Koch developed the Heckler & Koch UMP, the MP5's successor; both are available .
History.
Heckler & Koch, encouraged by the success of the G3 automatic rifle, developed a family of small arms consisting of four types of firearms all based on a common G3 design layout and operating principle. The first type was chambered for 7.62×51mm NATO, the second for the 7.62×39mm M43 round, the third for the intermediate 5.56×45mm NATO caliber, and the fourth type for the 9×19mm Parabellum pistol cartridge. The MP5 was created within the fourth group of firearms and was initially known as the HK54.
Work on the MP5 began in 1964 and two years later it was adopted by the German Federal Police, border guard and army special forces.
In 1980, the MP5 achieved iconic status as a result of its use on live television by SAS commandos in Operation Nimrod, where they stormed the Iranian Embassy in London, rescuing hostages and killing five terrorists. The MP5 became a mainstay of SWAT units of law enforcement agencies in the United States since then. However, in the late 1990s, as a result of the North Hollywood shootout, police special response teams have supplanted some MP5s with AR-15-based assault rifles.
The MP5 is manufactured under license in several nations including Greece (formerly at EBO – Hellenic Arms Industry, currently at EAS – Hellenic Defense Systems), Iran (Defense Industries Organization), Mexico (SEDENA), Pakistan (Pakistan Ordnance Factories), Saudi Arabia, Sudan (Military Industry Corporation), Turkey (MKEK), and the United Kingdom (initially at Royal Ordnance, later diverted to Heckler & Koch Great Britain).
Design details.
The primary version of the MP5 family is the MP5A2, which is a lightweight, air-cooled, selective fire delayed blowback operated 9×19mm Parabellum weapon with a roller-delayed bolt. It fires from a closed bolt (bolt forward) position.
The fixed, free floating, cold hammer-forged barrel has 6 right-hand grooves with a 1 in 250 mm (1:10 in) rifling twist rate and is pressed and pinned into the receiver.
Features.
The first MP5 models used a double-column straight box magazine, but since 1977, slightly curved, steel magazines are used with a 15-round capacity (weighing 0.12 kg) or a 30-round capacity (0.17 kg empty).
The adjustable iron sights (closed type) consist of a rotating rear diopter drum and a front post installed in a hooded ring. The rear sight is adjustable for both windage and elevation with the use of a special tool, being adjusted at the factory for firing at 25m with standard 124 grains FMJ 9×19mm NATO ammunition; the drum provides four different apertures of varying width used to adjust the light entrance in the diopter system, according to the user's eye relief and tactical situation.
The MP5 has a hammer firing mechanism. The trigger group is housed inside an interchangeable polymer trigger module (with an integrated pistol grip) and equipped with a three-position fire mode selector that serves as the manual safety toggle. The "S" or "Sicher" position in white denotes weapon safe, "E" or "Einzelfeuer" in red represents single fire, and "F" or "Feuerstoß" (also marked in red) designates continuous fire. The SEF symbols appear on both sides of the plastic trigger group. The selector lever is actuated with the thumb of the shooting hand and is located only on the left side of the original SEF trigger group or on both sides of the ambidextrous trigger groups. The safety/selector is rotated into the various firing settings or safety position by depressing the tail end of the lever. Tactile clicks (stops) are present at each position to provide a positive stop and prevent inadvertent rotation. The "safe" setting disables the trigger by blocking the hammer release with a solid section of the safety axle located inside the trigger housing.
The non-reciprocating cocking handle is located above the handguard and protrudes from the cocking handle tube at approximately a 45° angle. This rigid control is attached to a tubular piece within the cocking lever housing called the cocking lever support, which in turn, makes contact with the forward extension of the bolt group. It is not however connected to the bolt carrier and therefore cannot be used as a forward assist to fully seat the bolt group. The cocking handle is held in a forward position by a spring detent located in the front end of the cocking lever support which engages in the cocking lever housing. The lever is locked back by pulling it fully to the rear and rotating it slightly clockwise where it can be hooked into an indent in the cocking lever tube.
Operating mechanism.
The bolt rigidly engages the barrel extension—a cylindrical component welded to the receiver into which the barrel is pinned. The delay mechanism is of the same design as that used in the G3 rifle. The two-part bolt consists of a bolt head with rollers and a bolt carrier. The heavier bolt carrier lies up against the bolt head when the weapon is ready to fire and inclined planes on the front locking piece lie between the rollers and force them out into recesses in the barrel extension.
When fired, expanding propellant gases produced from the burning powder in the cartridge exert rearward pressure on the bolt head transferred through the base of the cartridge case as it is propelled out of the chamber. A portion of this force is transmitted through the rollers projecting from the bolt head, which are cammed inward against the inclined flanks of the locking recesses in the barrel extension and to the angled shoulders of the locking piece. The selected angles of the recesses and the incline on the locking piece produce a velocity ratio of about 4:1 between the bolt carrier and the bolt head. This results in a calculated delay, allowing the projectile to exit the barrel and gas pressure to drop to a safe level before the case is extracted from the chamber.
The delay results from the amount of time it takes for enough recoil energy to be transferred through to the bolt carrier in a sufficient quantity for it to be driven to the rear against the force of inertia of the bolt carrier and the forward pressure exerted against the bolt by the recoil spring. As the rollers are forced inward they displace the locking piece and propel the bolt carrier to the rear. The bolt carrier's rearward velocity is four times that of the bolt head since the cartridge remains in the chamber for a short period of time during the initial recoil impulse. After the bolt carrier has traveled rearward 4 mm, the locking piece is withdrawn fully from the bolt head and the rollers are compressed into the bolt head. Only once the locking rollers are fully cammed into the bolt head can the entire bolt group continue its rearward movement in the receiver, breaking the seal in the chamber and continuing the feeding cycle.
Since the 9×19mm Parabellum cartridge is relatively low powered, the bolt does not have an anti-bounce device like the G3, but instead the bolt carrier contains tungsten granules that prevent the bolt group from bouncing back after impacting the barrel extension. The weapon has a fluted chamber that enhances extraction reliability by bleeding gases backwards into the shallow flutes running along the length of the chamber to prevent the cartridge case from expanding and sticking to the chamber walls (since the bolt is opened under relatively high barrel pressure). A spring extractor is installed inside the bolt head and holds the case securely until it strikes the ejector arm and is thrown out of the ejection port to the right of the receiver. The lever-type ejector is located inside the trigger housing (activated by the movement of the recoiling bolt).
Accessories.
In the early 1970s HK introduced a conversion kit for the MP5 that enables it to use rimfire ammunition (.22 LR). This unit consists of a barrel insert, a bolt group and two 20-round magazines. This modification reduces the cyclic rate to 650 rounds/min. It was sold mostly to law enforcement agencies as a way to train recruits on handling the MP5. It used ammunition that was cheaper and had a lower recoil than 9×19mm Parabellum. This reduced training costs and built up skill and confidence in the operators before transitioning them to the full-bore model.
Barrel accessories.
Threading is provided at the muzzle to work with certain muzzle devices made by Heckler & Koch, including: a slotted flash suppressor, blank firing attachment (marked with a red-painted band denoting use with blank ammunition only), an adapter for launching rifle grenades (for use with rifle-style grenades with an inside diameter of 22 mm using a special grenade launching cartridge) and a cup-type attachment used to launch tear gas grenades. An optional three-lugged barrel is also available for mounting a Quick Detachable suppressor.
Receiver.
The receiver housing has a proprietary claw-rail mounting system that permits the attachment of a standard Heckler & Koch quick-detachable scope mount (also used with the G3, HK33 and G3SG/1). It can be used to mount daytime optical sights (telescopic 4×24), night sights, reflex sights and laser pointers. The mount features two spring-actuated bolts, positioned along the base of the mount, which exert pressure on the receiver to hold the mount in the same position at all times assuring zero retention. All versions of the quick-detachable scope mount provide a sighting tunnel through the mount so that the shooter can continue to use the fixed iron sights with the scope mount attached to the top of the receiver.
A Picatinny rail adapter can be placed on top that locks into the claw rails. This allows the mounting of STANAG scopes and has a lower profile than the claw-rail system.
Handguard.
Aftermarket replacement handguards with Picatinny rails are available. Single-rail models have a Picatinny rail along the bottom and triple-rail models have rails along the bottom and sides. They allow the mounting of accessories like flashlights, laser pointers, target designators, vertical foregrips, and bipods.
Variants.
The MP5A2 has a fixed buttstock (made of a synthetic polymer), whereas the compact "MP5A3" has a retractable metal stock. The stockless "MP5A1" has a buttcap with a sling mount for concealed carry; the MP5K series was a further development of this idea.
The "MP5A4" (fixed stock) and "MP5A5" (sliding stock) models, which were introduced in 1974, are available with four-position trigger groups. The pistol grips are straight, lacking the contoured grip and thumb groove of the "MP5A1", "MP5A2", and "MP5A3". The selector lever stops are marked with bullet pictograms rather than letters or numbers (each symbol represents the number of bullets that will be fired when the trigger is pulled and held rearward with a full magazine inserted in the weapon) and are fully ambidextrous (the selector lever is present on each side of the trigger housing). The additional setting of the fire selector, one place before the fully automatic setting, enables a two or three-shot burst firing mode.
A variant with the last trigger group designated the MP5-N (N—Navy) was developed in 1986 for the United States Navy. This model has a collapsible stock, a tritium-illuminated front sight post and a threaded barrel for use with a stainless steel sound suppressor made by Knight's Armament Company together with quieter subsonic ammunition. It had ambidextrous controls, a straight pistol grip, pictogram markings, and originally had a four-position selector (Safe, Semi-Auto, 3-Round Burst, Full Auto). This was replaced with a similar three-position ambidextrous selector after an improperly-reassembled trigger group spontaneously fired during an exercise. The "Navy"-style ambidextrous trigger group later became standard, replacing the classic "SEF".
Plastic training variants.
H&K offers dedicated training variants of these weapons, designated "MP5A4PT" and "MP5A5PT" (PT—Plastic Training), modified to fire a plastic 9×19mm PT training cartridge produced by Dynamit Nobel of Germany. These weapons operate like the standard MP5 but have a floating chamber and both rollers have been omitted from the bolt to function properly when firing the lighter plastic projectiles. To help identify these weapons blue dots were painted on their cocking handles and additional lettering provided. The PT variant can be configured with various buttstocks and trigger groups and was developed for the West German Police and Border Guard.
Semi-auto only variants.
The "MP5SFA2" (SF – single-fire) was developed in 1986 in response to the American FBI solicitation for a "9 mm Single-fire Carbine". It is the same as the MP5A2 but is fitted with an ambidextrous semi-automatic only trigger group. The "MP5SFA3" is similar except it has a retractable metal stock like the MP5A3. Versions delivered after December 1991 are assembled with select-fire bolt carriers allowing fully automatic operation when used with the appropriate trigger module.
The two-position trigger unit was used in the single-fire "HK94" carbine that was produced specifically for the civilian market with a barrel.
Suppressed variants.
In 1974 H&K initiated design work on a sound-suppressed variant of the MP5, designated the MP5SD (SD—"Schalldämpfer" German for "sound suppressor"), which features an integral but detachable aluminium sound suppressor and a lightweight bolt. The weapon's barrel has 30 ports drilled forward of the chamber through which escaping gases are diverted to the surrounding sealed tubular casing that is screwed onto threading on the barrel’s external surface just prior to the ported segment. The suppressor itself is divided into two stages; the initial segment surrounding the ported barrel serves as an expansion chamber for the propellant gases, reducing gas pressure to slow down the acceleration of the projectile. The second, decompression stage occupies the remaining length of the suppressor tube and contains a stamped metal helix separator with several compartments which increase the gas volume and decrease its temperature, deflecting the gases as they exit the muzzle, so muffling the exit report. The bullet leaves the muzzle at subsonic velocity, so it does not generate a sonic shock wave in flight. As a result of reducing the barrel’s length and venting propellant gases into the suppressor, the bullet’s muzzle velocity was lowered anywhere from 16% to 26% (depending on the ammunition used) while maintaining the weapon’s automation and reliability. The weapon was designed to be used with standard supersonic ammunition with the suppressor on at all times.
The MP5SD is produced exclusively by H&K in several versions: the "MP5SD1" and "MP5SD4" (both have a receiver end cap instead of a buttstock), "MP5SD2" and "MP5SD5" (equipped with a fixed synthetic buttstock) and the "MP5SD3" and "MP5SD6" (fitted with a collapsible metal stock). The MP5SD1, MP5SD2 and MP5SD3 use a standard 'SEF' trigger group (from the MP5A2 and MP5A3), while the MP5SD4, MP5SD5, and MP5SD6 use the 'Navy' trigger group—a trigger module with a mechanically limited 3-round burst mode and ambidextrous selector controls (from the MP5A4 and MP5A5). A suppressed version was produced for the U.S. Navy – designated the "MP5SD-N", which is a version of the MP5SD3 with a retractable metal stock, front sight post with tritium-illuminated dot and a stainless steel suppressor. This model has a modified cocking handle support to account for the slightly larger outside diameter of the suppressor. The design of the suppressor allows the weapon to be fired with water inside, should water enter the device during operation in or near water.
MP5K.
In 1976 a shortened version of the MP5A2 was introduced; the "MP5K" (K from the German word "Kurz" = "short") was designed for close quarters battle use by clandestine operations and special services. The MP5K does not have a shoulder stock (the receiver end was covered with a flat end cap, featuring a buffer on the inside and a sling loop on the outside), and the bolt and receiver were shortened at the rear. The resultant lighter bolt led to a higher rate of fire than the standard MP5. The barrel, cocking handle and its cover were shortened and a vertical foregrip was used to replace the standard handguard. The barrel ends at the base of the front sight, which prevents the use of any sort of muzzle device.
The MP5K is produced (by Heckler & Koch and under license in Iran and Turkey) in four different versions: the MP5K, "MP5KA4", "MP5KA1", "MP5KA5", where the first two variants have adjustable, open-type iron sights (with a notched rotary drum), and the two remaining variants – fixed open sights; however, the front sight post was changed and a notch was cut into the receiver top cover. The MP5K retained the capability to use optical sights through the use of an adapter.
A civilian semiautomatic derivative of the MP5K known as the SP89 was produced that had a foregrip with a muzzle guard in place of the vertical grip.
In 1991 a further variant of the MP5K was developed, designated the "MP5K-PDW" (PDW—Personal Defense Weapon) that retained the compact dimensions of the MP5K but restored the fire handling characteristics of the full-size MP5A2. The MP5K-PDW uses a side-folding synthetic shoulder stock (made by the U.S. company Choate Machine and Tool), a "Navy" trigger group, a front sight post with a built-in tritium insert and a slightly lengthened threaded, three-lug barrel (analogous to the MP5-N). The stock can be removed and replaced with a receiver endplate; a rotary drum with apertures from the MP5A2 can also be used.
Larger caliber versions.
In 1991, Heckler & Koch introduced the "MP5/10" (chambered in 10mm Auto) and "MP5/40" (chambered for the .40 S&W cartridge), which are based on the MP5A4 and MP5A5. These weapons were assembled in fixed and retractable stock configurations (without a separate designation) and are fed from translucent 30-round polymer box magazines. These weapons include a bolt hold-open device, which captures the bolt group in its rear position after expending the last cartridge from the magazine. The bolt is then released by pressing a lever positioned on the left side of the receiver. Both weapons use a barrel with 6 right-hand grooves and a 380 mm (1:15 in) twist rate, and like the MP5-N, both have a 3-lugged muzzle device and a tritium-illuminated front sight aiming dot.
Problems with the MP5/10 and MP5/40 led to their discontinuation, although Heckler & Koch continues to provide support and spare parts.
Variants list.
Foreign variant copies.
Contrary to popular belief, the S-U-O marked lowers (in lieu of S-E-F) commonly found on many MP5 clones and conversion were not manufactured in Malaysia, but were in fact German made as part of a large contract of HK33s, MP5s and several other H&K weapons.

</doc>
<doc id="14298" url="https://en.wikipedia.org/wiki?curid=14298" title="Henry Middleton">
Henry Middleton

Henry Middleton (1717 – June 13, 1784) was a planter and public official from South Carolina. A member of the colonial legislature, during the American Revolution he attended the Continental Congress and served as that body's presiding officer for a few days in 1774. He left Congress before it declared independence. Back in South Carolina, he served as president of the provincial congress and senator in the newly created state government. After his capture by the British in 1780, he accepted defeat and returned to the status of a British subject until the end of the war.
Early life and family.
Henry Middleton was born in 1717 near Charleston, Province of South Carolina, to Arthur Middleton (1681–1737) and Susan Amory (1690-1722), on the family plantation, "The Oaks". Henry's father Arthur Middleton was a wealthy planter who had served as an acting governor of South Carolina. Henry was educated in England before returning to South Carolina to inherit his father's plantation. He became one of the largest landowners in the colony, owning and about 800 slaves.
Middleton married Mary Williams in 1741, with whom he would have five sons and seven daughters. After Mary’s death in 1761, Middleton would go on to marry twice more, second to Maria Henrietta Bull (in 1762) and third to Lady Mary McKenzie (in 1776).
Public offices.
Middleton served in a variety of public offices in South Carolina. He was a justice of the peace and a member of the Commons House of Assembly, where he was elected speaker in 1747, 1754, and 1755. He was a member of provincial council, but resigned in 1770 in opposition to British policy.
In 1774, at the outset of the American Revolution, Middleton was selected as a delegate to the Continental Congress. He served as that body's president during the last few days of the First Continental Congress, following the departure of Peyton Randolph. Middleton opposed declaring independence from Great Britain, and resigned from the Second Continental Congress in February 1776 when more radical delegates began pushing for independence. He was succeeded in Congress by his son, Arthur Middleton (1742–1787), who was more radical than his father and became a signer of the Declaration of Independence.
After Middleton's return to South Carolina, he was elected president of the provincial congress and, beginning on November 16, 1775, served on the council of safety. In 1776, he and his son Arthur helped frame a temporary state constitution. In 1779, he became a state senator in the new government.
When Charleston was captured by the British in 1780, Middleton accepted defeat and status as a British subject. This reversal apparently did not damage his reputation in the long run, due to his previous support of the Revolution, and he did not suffer the fate of having his estates confiscated, as many Loyalists did after the war.
Death and legacy.
Middleton died on June 13, 1784 in Charleston.
His grandson, also named Henry (1770–1846), had a long career in politics. He was Governor of South Carolina (1810–1812), U.S. Representative (1815–1819), and the minister to Russia (1820–1830). Some of Middleton's children married into prominent families. Daughter Henrietta married Governor Edward Rutledge, Sarah was the first wife of Charles Cotesworth Pinckney, and his daughter Susannah married John Parker.
His descendants include the politician Baldur von Schirach, through the latter's mother Emma Middleton Lynah Tillou.

</doc>
<doc id="14299" url="https://en.wikipedia.org/wiki?curid=14299" title="Ham">
Ham

Ham is pork that has been preserved through salting, smoking, or wet curing. It was traditionally made only from the hind leg of swine, and referred to that specific cut of pork. Ham is made around the world, including a number of highly coveted regional specialties, such as Westphalian ham and Jamón serrano. Technically a processed meat, "ham" may refer to a product which has been through mechanical re-forming.
The precise nature of meat termed "ham" is controlled in a number of areas, often by statute, including the United States and European Union. In addition, numerous ham products have specific geographical naming protection, such as Prosciutto di Parma and Prosciutto Toscano PDO in Europe, and Smithfield ham in the US.
Definition.
The preserving of pork leg as ham has a long history, with Cato the Elder writing about the "salting of hams" in his "De Agri Cultura" tome around 160 BC.
There are claims that the Chinese were the first people to mention the production of cured ham, whilst Larousse Gastronomique claims an origin from Gaul, but it was certainly well established by the Roman period, including an import trade from Gaul mentioned by Marcus Terentius Varro in his writings.
The modern word "ham" is derived from the Old English "ham" or "hom" meaning the hollow or bend of the knee, from a Germanic base where it meant "crooked". It began to refer to the cut of pork derived from the hind leg of a swine around the 15th century. Preservation methods include curing, smoking, and salting.
Because of the preservation process, ham is a compound foodstuff or ingredient, being made up of the original meat, as well as the remnants of the preserving agent(s), such as salt, but it is still recognised as a food in its own right.
Labeling.
In many countries the term is now protected by statute, with a specific definition. For instance, in the United States, the Code of Federal Regulations (CFR) says that "the word 'ham', without any prefix indicating the species of animal from which derived, shall be used in labeling only in connection with the hind legs of swine".
In addition to the main categories, some processing choices can affect legal labeling. For instance, in the United States, a "smoked" ham must have been smoked by hanging over burning wood chips in a smokehouse or an atomized spray of liquid smoke such that the product appearance is equivalent; a "hickory-smoked" ham must have been smoked using only hickory. However, injecting "smoke flavor" is not legal grounds for claiming the ham was "smoked"; these are labeled "smoke flavor added". Hams can only be labelled "honey-cured" if honey was at least 50% of the sweetener used, is at least 3% of the formula, and has a discernible effect on flavor. So-called "lean" and "extra lean" hams must adhere to maximum levels of fat and cholesterol per 100 grams of product.
Ham re-formed from smaller pieces in to a larger block also has to be labelled in many jurisdictions.
Methods.
Ham is produced by preserving and flavoring raw pork by salting, smoking, or wet curing. Besides salt, several ingredients may be used to obtain flavoring and preservation, from black pepper (e.g. Prosciutto Toscano PDO) to the precious saffron (e.g. the "Zafferano di San Gimignano PDO" in the esteemed Golden Ham).
Salting.
The duration of the curing process varies by the type of ham, with Serrano ham curing in 9–12 months, Parma hams taking more than 12 months, and Iberian ham taking up to 2 years to reach the desired flavour characteristics. Some dry cured hams, such as the Jinhua ham, take approximately 8 to 10 months to complete.
Most modern dry cure hams also use nitrites (either sodium or potassium), which are added along with the salt, although following a similar methodology. The nitrites deliver a distinctive pink or red tinge to the meat, as well as imparting flavour. The amount and mixture of salt and nitrites used has an effect on the shrinkage of the meat.
Sodium nitrite is used because it prevents bacterial growth and, in a reaction with the meat's myoglobin, gives the product a desirable dark red color. Because of the toxicity of nitrite (the lethal dose of nitrite for humans is about 22 mg per kg body weight), some areas specify a maximum allowable content of nitrite in the final product. Under certain conditions, especially during cooking, nitrites in meat can react with degradation products of amino acids, forming nitrosamines, which are known carcinogens.
The dry curing of ham involves a number of enzymatic reactions. The enzymes involved are proteinases (cathepsins – B, D, H & L, and calpains) and exopeptidases (peptidase and aminopeptidase). These enzymes cause proteolysis of muscle tissue, which creates large numbers of small peptides and free amino acids, while the adipose tissue undergoes lipolysis to create free fatty acids. Salt and phosphates act as strong inhibitors of proteolytic activity.
Animal factors influencing enzymatic activity include age, weight, and breed. During the process itself, conditions such as temperature, duration, water content, redox potential, and salt content all have an effect.
The salt content in dry-cured ham varies throughout a piece of meat, with gradients determinable through sampling and testing or non-invasively through CT scanning.
Smoking.
Ham can also be preserved through the smoking method, in which the meat is placed in a smokehouse (or equivalent) to be cured by the action of smoke.
The main flavor compounds of smoked ham are guaiacol, and its 4-, 5-, and 6-methyl derivatives as well as 2,6-dimethylphenol. These compounds are produced by thermal breakdown (i.e., combustion) of lignin, a major constituent of wood used in the smokehouse.
Wet curing.
Wet curing (also known as brining) involves the immersion of the meat in a brine, sometimes with other ingredients such as sugar also added for flavour. Meat is submerged in the brine for around 3–14 days, during which time the meat needs to be kept submerged, and the brine mixture agitated periodically to prevent separation of the ingredients.
Wet curing also has the effect of increasing volume and weight of the finished product, by about 4%.
The wet curing process can also be replicated by using mechanical pumping using needles and curing solution. This can be quicker, increase the weight of the finished product by more than immersion wet curing, and ensure a more even distribution of salt through the meat. This process is quicker than traditional wet cure, normally being completed between a few days and a few weeks.
Protected designations.
A number of hams worldwide have some level of protection of their unique characteristics, usually relating to their method of preservation and/or location of production or processing. Dependent on jurisdiction, rules may prevent any other product being sold with the particular appellation, such as through the European protected geographical indication.
Uses.
Ham is typically used in its sliced form, often as a filling for sandwiches and similar foods, such as in the ham sandwich and ham and cheese sandwich. Other variations include toasted sandwiches such as the croque-monsieur.
Preserved ham can be cooked (although there is no requirement), and usually requires washing in water to remove salt. Whole fresh pork leg is also served cooked as gammon, known as ham in the United States.
Health effects.
As a processed meat, there has been concern over the health effects of ham consumption. A meta-analysis study has shown a statistically relevant correlation between processed meat consumption and the risk of pancreatic cancer, with an increase in consumption of per day leading to a 19% increase in risk.
This supported earlier studies, including the 2007 study "", by the World Cancer Research Fund and the American Institute for Cancer Research, which reviewed more than 7,000 studies published worldwide. Among the recommendations was that, except for very rare occasions, people should avoid eating ham or other processed meats – cured, smoked, salted or chemically preserved meat products such as bacon, hot dogs, sausage, salami, and pastrami. The report states that once an individual reaches the weekly limit for red meat, every of processed meat consumed a day increases cancer risk by 21%.
A European cohort study also positively correlated processed meat consumption with higher all-cause mortality, with an estimation that 3.3% of the deaths amongst participants could have been prevented by consuming less than of 

</doc>
<doc id="14300" url="https://en.wikipedia.org/wiki?curid=14300" title="Henry Laurens">
Henry Laurens

Henry Laurens (December 8, 1792) was an American merchant and rice planter from South Carolina who became a political leader during the Revolutionary War. A delegate to the Second Continental Congress, Laurens succeeded John Hancock as President of the Congress. He was a signatory to the Articles of Confederation and President of the Continental Congress when the Articles were passed on November 15, 1777.
Laurens had earned great wealth as a partner in the largest slave-trading house in North America (Austin and Laurens). In the 1750s alone, this Charleston firm oversaw the sale of more than 8,000 enslaved Africans. He was for a time Vice-President of South Carolina and a diplomat to the Netherlands during the Revolutionary War. He was captured at sea and imprisoned for some time by the British in the Tower of London.
His son John Laurens, a colonel in the Continental Army and officer on Washington's staff, believed that Americans could not fight for their own freedom while holding slaves. In 1779, he persuaded the Continental Congress to authorize the recruitment of a brigade (3000 men) of slaves, who would be given their freedom after the war. However, when he presented it to them, the South Carolina Provincial Congress overwhelmingly rejected the proposal, and instead voted to use confiscated slaves as payment to recruit more white soldiers. John Laurens was killed in a skirmish in South Carolina in 1782.
Early life and education.
Henry Laurens’s forebears were Huguenots who fled France after the Edict of Nantes was revoked in 1685. Henry’s grandfather Andre Laurens left earlier, in 1682, and eventually made his way to America, settling first in New York City and then Charleston, South Carolina. Andre’s son John married Hester (or Esther) Grasset, also a Huguenot refugee. Henry was their third child and eldest son. John Laurens became a saddler, and his business eventually grew to be the largest of its kind in the colonies. In 1744 he sent Henry to London to augment the young man’s business training. John Laurens died in 1747, bequeathing twenty-three-year-old Henry a considerable estate 
Marriage and family.
He married Eleanor Ball, also of a South Carolina rice planter family, on June 25, 1750. They had thirteen children, many of whom died in infancy or childhood. Eleanor died in 1770, one month after giving birth to their last child. Laurens took their three sons to England for their education, encouraging their oldest, John Laurens, to study law. The young Laurens returned to the United States in 1776, at the time of the American Revolutionary War.
Political career.
Laurens served in the militia, as did most able-bodied men in his time. He rose to the rank of Lt. Colonel in the campaigns against the Cherokee Indians in 1757–1761, during the French and Indian War (also known as the Seven Years' War).
1757 also marked the first year he was elected to the colonial assembly. Laurens was elected again every year but one until the Revolution replaced the assembly with a state Convention as an interim government. The year he missed was 1773, when he visited England to arrange for his sons' educations. He was named to the colony's Council in 1764 and 1768, but declined both times. In 1772 he joined the American Philosophical Society of Philadelphia, and carried on extensive correspondence with other members.
As the American Revolution neared, Laurens was at first inclined to support reconciliation with the British Crown. But as conditions deteriorated, he came to fully support the American position. When Carolina began to create a revolutionary government, Laurens was elected to the Provincial Congress, which first met on January 9, 1775. He was president of the Committee of Safety, and presiding officer of that congress from June until March 1776. When South Carolina installed a fully independent government, he served as the Vice President of South Carolina from March 1776 to June 27, 1777.
Henry Laurens was first named a delegate to the Continental Congress on January 10, 1777. He served in the Congress from until 1780. He was the President of the Continental Congress from November 1, 1777 to December 9, 1778.
In the fall of 1779, the Congress named Laurens their minister to the Netherlands. In early 1780 he took up that post and successfully negotiated Dutch support for the war. But on his return voyage to Amsterdam that fall, the British frigate intercepted his ship, the continental packet "Mercury", off the banks of Newfoundland. Although his dispatches were tossed in the water, they were retrieved by the British, who discovered the draft of a possible U.S.-Dutch treaty prepared in Aix-la-Chapelle in 1778 by William Lee and the Amsterdam banker Jean de Neufville. This prompted Britain to declare war on the Dutch Republic, it becoming known as the Fourth Anglo-Dutch War.
The British charged Laurens with treason, transported him to England, and imprisoned him in the Tower of London (he is the only American to have been held prisoner in the Tower). His imprisonment was protested by the Americans. In the field, most captives were regarded as prisoners of war, and while conditions were frequently appalling, prisoner exchanges and mail privileges were accepted practice. During his imprisonment, Laurens was assisted by Richard Oswald, his former business partner and the principal owner of Bunce Island. Oswald argued on Laurens' behalf to the British government. Finally, on December 31, 1781 he was released in exchange for General Lord Cornwallis and completed his voyage to Amsterdam. He helped raise funds for the American effort.
In a late skirmish during the war, Laurens' oldest son John was killed in 1782. He had supported enlisting and freeing slaves for the war effort and suggested to his father that he begin with the 40 he stood to inherit. He urged his father to free their slaves. Yet, although conflicted, Henry Laurens never manumitted his 260 slaves.
In 1783 Laurens was sent to Paris as one of the Peace Commissioners for the negotiations leading to the Treaty of Paris. While he was not a signatory of the primary treaty, he was instrumental in reaching the secondary accords that resolved issues related to the Netherlands and Spain. Richard Oswald, a big former partner of Laurens in the slave trade, was the principal negotiator for the British during the Paris peace talks.
Laurens generally retired from public life in 1784. He was sought for a return to the Continental Congress, the Constitutional Convention in 1787 and the state assembly, but he declined all of these positions. He did serve in the state convention of 1788, where he voted to ratify the United States Constitution.
Later events.
The British occupying forces from Charleston had burned the main home at Mepkin during the war. When Laurens and his family returned in 1784, they lived in an outbuilding while the great house was rebuilt. He lived on the estate the rest of his life, working to recover the estimated £40,000 that the revolution had cost him (equivalent to about $3,500,000 in 2000 values).
Death and cremation.
Laurens died on December 8, 1792, at his estate, Mepkin. In his will he stated he wished to be cremated, and his ashes be interred at his estate. It is reported that his was the first formal cremation in United States. Afterward, the estate passed through several hands. Large portions of the estate still exist and are used today as a Trappist abbey.

</doc>
<doc id="14301" url="https://en.wikipedia.org/wiki?curid=14301" title="HOTOL">
HOTOL

HOTOL, for Horizontal Take-Off and Landing, was a British design for an Airbreathing jet engine spaceplane by Rolls-Royce and British Aerospace.
Designed as a single-stage-to-orbit (SSTO) reusable winged launch vehicle, it was to be fitted with a unique air-breathing engine, the RB545 or Swallow, to be developed by the Rolls-Royce company. The engine was technically a liquid hydrogen/liquid oxygen design, but dramatically reduced the amount of oxidizer needed to be carried on board by utilising atmospheric oxygen as the spacecraft climbed through the lower atmosphere.
Since propellant typically represents the majority of the takeoff weight of a rocket, HOTOL was to be considerably smaller than normal pure-rocket designs, roughly the size of a medium-haul airliner such as the McDonnell Douglas DC-9/MD-80. Ultimately, comparison with a rocket vehicle using similar construction techniques failed to show much advantage, and funding for the vehicle ceased.
Description.
HOTOL would have been 63 metres long, 12.8 metres high, 7 metres in diameter and with a wingspan of 28.3 metres. The unmanned craft was intended to put a payload of around 7 to 8 tonnes in orbit, at 300 km altitude. It was intended to take off from a runway, mounted on the back of a large rocket-boosted trolley that would help get the craft up to "working speed". The engine was intended to switch from jet propulsion to pure rocket propulsion at 26–32 km high, by which time the craft would be travelling at Mach 5 to 7. After reaching orbit, HOTOL was intended to re-enter the atmosphere and glide down to land on a conventional runway (approx 1,500 metres minimum). HOTOL was designed for automatic, unmanned flights, although later stages would reintroduce a pilot. The internal landing gear would have been too small to carry the weight of the fully fuelled rocket, so emergency landings would have required the fuel to be dumped.
Engine.
The RB545 was an air-breathing rocket engine. The exact details of this engine were covered by the UK's Official Secrets Act, and there is consequently little public information about its operation, although it has apparently been declassified.
Within the atmosphere, hydrogen fuel would be used in a heat exchanger to precool air entering a high overall pressure ratio turbojet-like engine cycle, before being burnt with the air in a rocket motor, to produce a very high velocity propulsive jet. 
Once out of the atmosphere, the RB545 would be capable of burning the hydrogen with on-board liquid oxygen as a high-efficiency hydrogen/oxygen rocket. The engine was given the Rolls Royce name "Swallow".
Development.
The ideas behind HOTOL originated from work done by Alan Bond for precooled jet engines which he had done specifically with the intention of powering a launch system.
Formal development began with government funding in 1982. The design team was a joint effort between Rolls-Royce and British Aerospace led by John Scott-Scott and Dr Bob Parkinson. About the same time, the Rockwell X-30 scramjet programme was announced in America.
Problems.
During development, it was found that the comparatively heavy rear-mounted engine moved the centre of mass of the vehicle rearwards. This meant that the vehicle had to be designed to push the centre of drag as far rearward as possible to ensure stability during the entire flight regime. Redesign of the vehicle to do this required a large mass of hydraulic systems, which cost a significant proportion of the payload, and made the economics unclear. In particular, some of the analysis seemed to indicate that similar technology applied to a pure rocket approach would give approximately the same performance at less cost.
Shutdown.
In 1988 the government withdrew further funding. The project was almost at the end of its design phase but the plans were still speculative and dogged with aerodynamic problems and operational disadvantages.
Successors.
A cheaper redesign, Interim HOTOL or HOTOL 2, to be launched from the back of a modified Antonov An-225 "Mriya" transport aircraft, was offered by BAe in 1991 but that too was rejected. Interim HOTOL was to have dispensed with an air-breathing engine cycle and was designed to use more conventional LOX and liquid hydrogen.
In 1989, HOTOL co-creator Alan Bond formed Reaction Engines Limited (REL) which has since been working on the Skylon vehicle intended to solve the problems of HOTOL. In November 2012, REL conducted tests on an engine observed by the European Space Agency and declared the tests a success and that a major technical obstacle had been removed. In July 2013 the UK government announced a £60m investment in REL.

</doc>
<doc id="14306" url="https://en.wikipedia.org/wiki?curid=14306" title="Hammerhead shark">
Hammerhead shark

The hammerhead sharks are a group of sharks in the family Sphyrnidae, so named for the unusual and distinctive structure of their heads, which are flattened and laterally extended into a "hammer" shape called a cephalofoil. Most hammerhead species are placed in the genus Sphyrna while the winghead shark is placed in its own genus, Eusphyra. Many not necessarily mutually exclusive functions have been proposed for the cephalofoil, including sensory reception, maneuvering, and prey manipulation. Hammerheads are found worldwide in warmer waters along coastlines and continental shelves. Unlike most sharks, hammerheads usually swim in schools during the day, becoming solitary hunters at night. Some of these schools can be found near Malpelo Island in Colombia, Cocos Island off Costa Rica, and near Molokai in Hawaii. Large schools are also seen in the waters off southern and eastern Africa.
Description.
The known species range from in length and weigh from . They are usually light gray and have a greenish tint. Their bellies are white which allows them to blend into the ocean when viewed from the bottom and sneak up on their prey. Their heads have lateral projections which give them a hammer-like shape.
Hammerheads have disproportionately small mouths and seem to do a lot of bottom-hunting. They are also known to form schools during the day, sometimes in groups of over 100. In the evening, like other sharks, they become solitary hunters.
Taxonomy and evolution.
Since sharks do not have mineralized bones and rarely fossilize, it is their teeth alone that are commonly found as fossils. The hammerheads seem closely related to the carcharhinid sharks that evolved during the mid-Tertiary Period. According to DNA studies, the ancestor of the hammerheads probably lived in the Miocene epoch about 20 million years ago.
Using mitochondrial DNA, a phylogenetic tree of the hammerhead sharks showed the winghead shark as its most basal member. As the winghead shark has proportionately the largest "hammer" of the hammerhead sharks, this suggests that the first ancestral hammerhead sharks also had large hammers.
Cephalofoil.
The theory has been advanced that the hammer-like shape of the head may have evolved (at least in part) to enhance the animal's vision. The positioning of the eyes, mounted on the sides of the shark's distinctive hammer head give the shark good 360-degree vision in the vertical plane, meaning they can see above and below them at all times. The shape of the head was previously thought to help the shark find food, aiding in close-quarters maneuverability and allowing sharp turning movement without losing stability. However, it has been found that the unusual structure of its vertebrae was instrumental in making the turns correctly, more often than the shape of its head, though it would also shift and provide lift. From what is known about the winghead shark, it would appear that the shape of the hammer-head has to do with an evolved sensory function. Like all sharks, hammerheads have electroreceptory sensory pores called ampullae of Lorenzini. By distributing the receptors over a wider area, like a larger radio antenna, hammerheads can sweep for prey more effectively.
Reproduction.
Reproduction occurs only once a year for hammerhead sharks, and usually occurs with the male shark biting the female shark violently until she agrees to mate with him. The hammerhead sharks exhibit a viviparous mode of reproduction with females giving birth to live young. Like other sharks, fertilization is internal with the male transferring sperm to the female through one of two intromittent organs called claspers. The developing embryos are at first sustained by a yolk sac. When the supply of yolk is exhausted, the depleted yolk sac transforms into a structure analogous to a mammalian placenta (called a "yolk sac placenta" or "pseudoplacenta"), through which the mother delivers sustenance until birth. Once the baby sharks are born, they are not taken care of by the parents in any way. There is usually a litter of 12 to 15 pups; except for the Great Hammerhead which births litters of 20 to 40 pups. These baby sharks huddle together and swim toward warmer water until they are old enough and large enough to survive on their own.
In 2007, the bonnethead shark was found to be capable of asexual reproduction via automictic parthenogenesis, in which a female's ovum fuses with a polar body to form a zygote without the need for a male. This was the first shark known to do this.
Diet.
Hammerhead sharks are known to eat a large range of prey including fish, squid, octopus, crustaceans, and other sharks. Stingrays are a particular favorite. These sharks are often found swimming along the bottom of the ocean, stalking their prey. Their unique head is used as a weapon when hunting down prey. The hammerhead shark uses its head to pin down stingrays and eats the ray when the ray is weak and in shock. The Great Hammerhead, tending to be larger and more aggressive than most hammerheads, occasionally engage in cannibalism, as they are known to eat other hammerhead sharks, including their own young.
Relationship with humans.
Of the 10 known species of hammerhead, only three of them are known to be particularly dangerous to humans: the scalloped, great, and smooth hammerheads. As of 2013 there have been 33 attacks, but no fatalities.
The great and the scalloped hammerhead are listed on the World Conservation Union's (IUCN) 2008 Red List as endangered, whereas the smalleye hammerhead is listed as vulnerable. The status given to these sharks is as a result of over-fishing and demand for their fins, an expensive delicacy. Among others, scientists expressed their concern about the plight of the scalloped hammerhead at the American Association for the Advancement of Science annual meeting in Boston. The young swim mostly in shallow waters along shores all over the world to avoid predators.
Shark fins are prized as a delicacy in certain countries in Asia (i.e. China), and overfishing is putting many hammerhead sharks at risk of extinction. Fishermen who harvest the animals typically cut off the fins and toss the remainder of the fish, which is often still alive, back into the sea. This practice is known as finning, which will lead to the shark's death.
In Native Hawaiian culture, sharks are considered to be gods of the sea, protectors of humans, and cleaners of excessive ocean life. Some of these sharks are believed to be family members who died and have been reincarnated into shark form. However, there are sharks that are considered man-eaters, also known as "niuhi". These sharks include great white sharks, tiger sharks, and bull sharks. The hammerhead shark, also known as "mano kihikihi", is not considered a man-eater or "niuhi"; it is considered to be one of the most respected sharks of the ocean, an "aumakua". Many Hawaiian families believe that they have an "aumakua" watching over them and protecting them from the "niuhi". The hammerhead shark is thought to be the birth animal of some children. Hawaiian children who are born with the hammerhead shark as an animal sign are believed to be warriors and are meant to sail the oceans. It is extremely rare for hammerhead sharks to pass through the waters of Maui, but many Maui natives believe that when the hammerhead sharks pass by, it is a sign that the gods are watching over the families, and the oceans are clean and balanced.
Hammerheads in captivity.
Great hammerheads have been kept in captivity at several facilities, including Atlantis Paradise Island Resort (Bahamas), Adventure Aquarium (New Jersey), Georgia Aquarium (Atlanta), Mote Marine Laboratory (Florida) and at the Shark Reef exhibit at Mandalay Bay (Las Vegas). Aquarist Dean Trinh has successfully raised scalloped hammerhead pups, which he has claimed were collected by hand from an environment in which they might otherwise face the prospect of starvation. Other aquarists have noted the importance of providing adequate room for hammerheads to swim constantly and for the provision of mechanical filtration systems to maintain suitable water quality for shark survival. In 2015, the proprietors of the nightclub Atlantis in Adelaide, South Australia announced plans to keep two hammerhead sharks in a 3-metre diameter cylindrical tank on their premises. The proposal prompted animal rights activists to start a petition calling for the abandonment of the idea. The petition attracted 35,000 signatures in two weeks. 
Protection.
In March 2013, three endangered commercially valuable sharks, the hammerheads, the oceanic whitetip and porbeagle were added to Appendix 2 of CITES, bringing shark fishing and commerce of these species under licensing and regulation.

</doc>
<doc id="14307" url="https://en.wikipedia.org/wiki?curid=14307" title="Hall effect">
Hall effect

The Hall effect is the production of a voltage difference (the Hall voltage) across an electrical conductor, transverse to an electric current in the conductor and a magnetic field perpendicular to the current. It was discovered by Edwin Hall in 1879.
The Hall coefficient is defined as the ratio of the induced electric field to the product of the current density and the applied magnetic field. It is a characteristic of the material from which the conductor is made, since its value depends on the type, number, and properties of the charge carriers that constitute the current.
Discovery.
The Hall effect was discovered in 1879 by Edwin Herbert Hall while he was working on his doctoral degree at Johns Hopkins University in Baltimore, Maryland. His measurements of the tiny effect produced in the apparatus he used were an experimental tour de force, accomplished 18 years before the electron was discovered and published under the name "On a New Action of the Magnet on Electric Currents".
Theory.
The Hall effect is due to the nature of the current in a conductor. Current consists of the movement of many small charge carriers, typically electrons, holes, ions (see Electromigration) or all three. When a magnetic field is present, these charges experience a force, called the Lorentz force. When such a magnetic field is absent, the charges follow approximately straight, 'line of sight' paths between collisions with impurities, phonons, etc. However, when a magnetic field with a perpendicular component is applied, their paths between collisions are curved so that moving charges accumulate on one face of the material. This leaves equal and opposite charges exposed on the other face, where there is a scarcity of mobile charges. The result is an asymmetric distribution of charge density across the Hall element, arising from a force that is perpendicular to both the 'line of sight' path and the applied magnetic field. The separation of charge establishes an electric field that opposes the migration of further charge, so a steady electrical potential is established for as long as the charge is flowing.
In classical electromagnetism electrons move in the opposite direction of the current formula_1 (by convention "current" describes a theoretical "hole flow"). In some semiconductors it "appears" "holes" are actually flowing because the direction of the voltage is opposite to the derivation below.
For a simple metal where there is only one type of charge carrier (electrons) the Hall voltage "VH" can be derived by using the Lorentz force and seeing that in the steady-state condition charges are not moving in the y-axis direction because the magnetic force on each electron in the y-axis direction is cancelled by an y-axis electrical force due to the buildup of charges. The formula_2 term is the drift velocity of the current which is assumed at this point to be holes by convention. The formula_3 term is negative in the y-axis direction by the right hand rule.
In wires, electrons instead of holes are flowing, so formula_7 and formula_8. Also formula_9. Substituting these changes gives
The conventional "hole" current is in the negative direction of the electron current and the negative of the electrical charge which gives formula_11 where formula_12 is charge carrier density, formula_13 is the cross-sectional area, and formula_14 is the charge of each electron. Solving for formula_15 and plugging into the above gives the Hall voltage:
If the charge build up had been positive (as it appears in some semiconductors), then the formula_17 assigned in the image would have been negative (positive charge would have built up on the left side).
The Hall coefficient is defined as
where "j" is the current density of the carrier electrons, and formula_6 is the induced electric field. In SI units, this becomes
(The units of "R"H are usually expressed as m3/C, or Ω·cm/G, or other variants.) As a result, the Hall effect is very useful as a means to measure either the carrier density or the magnetic field.
One very important feature of the Hall effect is that it differentiates between positive charges moving in one direction and negative charges moving in the opposite. The Hall effect offered the first real proof that electric currents in metals are carried by moving electrons, not by protons. The Hall effect also showed that in some substances (especially p-type semiconductors), it is more appropriate to think of the current as positive "holes" moving rather than negative electrons. A common source of confusion with the Hall Effect is that holes moving to the left are really electrons moving to the right, so one expects the same sign of the Hall coefficient for both electrons and holes. This confusion, however, can only be resolved by modern quantum mechanical theory of transport in solids.
The sample inhomogeneity might result in spurious sign of the Hall effect, even in ideal van der Pauw configuration of electrodes. For example, positive Hall effect was observed in evidently n-type semiconductors. Another source of artifact, in uniform materials, occurs when the sample's aspect ratio is not long enough: the full Hall voltage only develops far away from the current-introducing contacts, since at the contacts the transverse voltage is shorted out to zero.
Hall effect in semiconductors.
When a current-carrying semiconductor is kept in a magnetic field, the charge carriers of the semiconductor experience a force in a direction perpendicular to both the magnetic field and the current. At equilibrium, a voltage appears at the semiconductor edges.
The simple formula for the Hall coefficient given above becomes more complex in semiconductors where the carriers are generally both electrons and holes which may be present in different concentrations and have different mobilities. For moderate magnetic fields the Hall coefficient is
or equivalently
with
Here formula_24 is the electron concentration, formula_25 the hole concentration, formula_26 the electron mobility, formula_27 the hole mobility and formula_28 the elementary charge. 
For large applied fields the simpler expression analogous to that for a single carrier type holds.
Relationship with star formation.
Although it is well known that magnetic fields play an important role in star formation, research models indicate that Hall diffusion critically influences the dynamics of gravitational collapse that forms protostars.
Quantum Hall effect.
For a two-dimensional electron system which can be produced in a MOSFET, in the presence of large magnetic field strength and low temperature, one can observe the quantum Hall effect, which is the quantization of the Hall voltage.
Spin Hall effect.
The spin Hall effect consists in the spin accumulation on the lateral boundaries of a current-carrying sample. No magnetic field is needed. It was predicted by M. I. Dyakonov and V. I. Perel in 1971 and observed experimentally more than 30 years later, both in semiconductors and in metals, at cryogenic as well as at room temperatures.
Quantum spin Hall effect.
For mercury telluride two dimensional quantum wells with strong spin-orbit coupling, in zero magnetic field, at low temperature, the Quantum spin Hall effect has been recently observed.
Anomalous Hall effect.
In ferromagnetic materials (and paramagnetic materials in a magnetic field), the Hall resistivity includes an additional contribution, known as the anomalous Hall effect (or the extraordinary Hall effect), which depends directly on the magnetization of the material, and is often much larger than the ordinary Hall effect. (Note that this effect is "not" due to the contribution of the magnetization to the total magnetic field.) For example, in nickel, the anomalous Hall coefficient is about 100 times larger than the ordinary Hall coefficient near the Curie temperature, but the two are similar at very low temperatures. Although a well-recognized phenomenon, there is still debate about its origins in the various materials. The anomalous Hall effect can be either an "extrinsic" (disorder-related) effect due to spin-dependent scattering of the charge carriers, or an "intrinsic" effect which can be described in terms of the Berry phase effect in the crystal momentum space ("k"-space).
Hall effect in ionized gases.
The Hall effect in an ionized gas (plasma) is significantly different from the Hall effect in solids (where the Hall parameter is always very inferior to unity). In a plasma, the Hall parameter can take any value. The Hall parameter, "β", in a plasma is the ratio between the electron gyrofrequency, Ω"e", and the electron-heavy particle collision frequency, "ν":
where
The Hall parameter value increases with the magnetic field strength.
Physically, the trajectories of electrons are curved by the Lorentz force. Nevertheless, when the Hall parameter is low, their motion between two encounters with heavy particles (neutral or ion) is almost linear. But if the Hall parameter is high, the electron movements are highly curved. The current density vector, "J", is no longer colinear with the electric field vector, "E". The two vectors "J" and "E" make the Hall angle, "θ", which also gives the Hall parameter:
Applications.
Hall probes are often used as magnetometers, i.e. to measure magnetic fields, or inspect materials (such as tubing or pipelines) using the principles of magnetic flux leakage.
Hall effect devices produce a very low signal level and thus require amplification. While suitable for laboratory instruments, the vacuum tube amplifiers available in the first half of the 20th century were too expensive, power consuming, and unreliable for everyday applications. It was only with the development of the low cost integrated circuit that the Hall effect sensor became suitable for mass application. Many devices now sold as Hall effect sensors in fact contain both the sensor as described above plus a high gain integrated circuit (IC) amplifier in a single package. Recent advances have further added into one package an analog-to-digital converter and I²C (Inter-integrated circuit communication protocol) IC for direct connection to a microcontroller's I/O port.
Advantages over other methods.
Hall effect devices (when appropriately packaged) are immune to dust, dirt, mud, and water. These characteristics make Hall effect devices better for position sensing than alternative means such as optical and electromechanical sensing.
When electrons flow through a conductor, a magnetic field is produced. Thus, it is possible to create a non-contacting current sensor. The device has three terminals.
A sensor voltage is applied across two terminals and the third provides a voltage proportional to the current being sensed. This has several advantages; no additional resistance (a "shunt", required for the most common current sensing method) need be inserted in the primary circuit. Also, the voltage present on the line to be sensed is not transmitted to the sensor, which enhances the safety of measuring equipment.
Disadvantages compared with other methods.
Magnetic flux from the surroundings (such as other wires) may diminish or enhance the field the Hall probe intends to detect, rendering the results inaccurate. Also, as Hall voltage is often on the order of millivolts, the output from this type of sensor cannot be used to directly drive actuators but instead must be amplified by a transistor-based circuit.
Ways to measure component positions within an electromagnetic system, such as a brushless direct current motor, include I) the Hall Effect, II) light detection with a light-dark position encoder such as a Gray code disk and III) induced voltage by moving the amount of metal core inserted into a transformer. When Hall is compared to photo-sensitive methods, it is harder to get absolute position with Hall. Hall detection is also sensitive to stray magnetic fields.
Contemporary applications.
Hall effect sensors are readily available from a number of different manufacturers, and may be used in various sensors such as rotating speed sensors (bicycle wheels, gear-teeth, automotive speedometers, electronic ignition systems), fluid flow sensors, current sensors, and pressure sensors. Common applications are often found where a robust and contactless switch or potentiometer is required. These include: electric airsoft guns, triggers of electropneumatic paintball guns, go-cart speed controls, smart phones, and some global positioning systems.
Ferrite toroid Hall effect current transducer.
Hall sensors can detect stray magnetic fields easily, including that of Earth, so they work well as electronic compasses: but this also means that such stray fields can hinder accurate measurements of small magnetic fields. To solve this problem, Hall sensors are often integrated with magnetic shielding of some kind. For example, a Hall sensor integrated into a ferrite ring (as shown) can reduce the detection of stray fields by a factor of 100 or better (as the external magnetic fields cancel across the ring, giving no residual magnetic flux). This configuration also provides an improvement in signal-to-noise ratio and drift effects of over 20 times that of a bare Hall device.
The range of a given feedthrough sensor may be extended upward and downward by appropriate wiring. To extend the range to lower currents, multiple turns of the current-carrying wire may be made through the opening, each turn adding to the sensor output the same quantity; when the sensor is installed onto a printed circuit board, the turns can be carried out by a staple on the board. To extend the range to higher currents, a current divider may be used. The divider splits the current across two wires of differing widths and the thinner wire, carrying a smaller proportion of the total current, passes through the sensor.
Split ring clamp-on sensor.
A variation on the ring sensor uses a split sensor which is clamped onto the line enabling the device to be used in temporary test equipment. If used in a permanent installation, a split sensor allows the electric current to be tested without dismantling the existing circuit.
Analog multiplication.
The output is proportional to both the applied magnetic field and the applied sensor voltage. If the magnetic field is applied by a solenoid, the sensor output is proportional to the product of the current through the solenoid and the sensor voltage. As most applications requiring computation are now performed by small digital computers, the remaining useful application is in power sensing, which combines current sensing with voltage sensing in a single Hall effect device.
Power measurement.
By sensing the current provided to a load and using the device's applied voltage as a sensor voltage it is possible to determine the power dissipated by a device.
Position and motion sensing.
Hall effect devices used in motion sensing and motion limit switches can offer enhanced reliability in extreme environments. As there are no moving parts involved within the sensor or magnet, typical life expectancy is improved compared to traditional electromechanical switches. Additionally, the sensor and magnet may be encapsulated in an appropriate protective material. This application is used in brushless DC motors.
Automotive ignition and fuel injection.
Commonly used in distributors for ignition timing (and in some types of crank and camshaft position sensors for injection pulse timing, speed sensing, etc.) the Hall effect sensor is used as a direct replacement for the mechanical breaker points used in earlier automotive applications. Its use as an ignition timing device in various distributor types is as follows. A stationary permanent magnet and semiconductor Hall effect chip are mounted next to each other separated by an air gap, forming the Hall effect sensor. A metal rotor consisting of windows and tabs is mounted to a shaft and arranged so that during shaft rotation, the windows and tabs pass through the air gap between the permanent magnet and semiconductor Hall chip. This effectively shields and exposes the Hall chip to the permanent magnet's field respective to whether a tab or window is passing though the Hall sensor. For ignition timing purposes, the metal rotor will have a number of equal-sized tabs and windows matching the number of engine cylinders. This produces a uniform square wave output since the on/off (shielding and exposure) time is equal. This signal is used by the engine computer or ECU to control ignition timing. Many automotive Hall effect sensors have a built-in internal NPN transistor with an open collector and grounded emitter, meaning that rather than a voltage being produced at the Hall sensor signal output wire, the transistor is turned on providing a circuit to ground through the signal output wire.
Wheel rotation sensing.
The sensing of wheel rotation is especially useful in anti-lock braking systems. The principles of such systems have been extended and refined to offer more than anti-skid functions, now providing extended vehicle handling enhancements.
Electric motor control.
Some types of brushless DC electric motors use Hall effect sensors to detect the position of the rotor and feed that information to the motor controller. This allows for more precise motor control
Industrial applications.
Applications for Hall Effect sensing have also expanded to industrial applications, which now use Hall Effect joysticks to control hydraulic valves, replacing the traditional mechanical levers with contactless sensing. Such applications include mining trucks, backhoe loaders, cranes, diggers, scissor lifts, etc.
Spacecraft propulsion.
A Hall effect thruster (HET) is a relatively low power device that is used to propel some spacecraft, after it gets into orbit or farther out into space. In the HET, atoms are ionized and accelerated by an electric field. A radial magnetic field established by magnets on the thruster is used to trap electrons which then orbit and create an electric field due to the Hall effect. A large potential is established between the end of the thruster where neutral propellant is fed, and the part where electrons are produced; so, electrons trapped in the magnetic field cannot drop to the lower potential. They are thus extremely energetic, which means that they can ionize neutral atoms. Neutral propellant is pumped into the chamber and is ionized by the trapped electrons. Positive ions and electrons are then ejected from the thruster as a quasineutral plasma, creating thrust.
The Corbino effect.
The Corbino effect is a phenomenon involving the Hall effect, but a disc-shaped metal sample is used in place of a rectangular one. Because of its shape the Corbino disc allows the observation of Hall effect–based magnetoresistance without the associated Hall voltage.
A radial current through a circular disc, subjected to a magnetic field perpendicular to the plane of the disc, produces a "circular" current through the disc.
The absence of the free transverse boundaries renders the interpretation of the Corbino effect simpler than that of the Hall effect.
References.
Introduction to Plasma Physics and Controlled Fusion, Volume 1, Plasma Physics, Second Edition, 1984, Francis F. Chen

</doc>
<doc id="14308" url="https://en.wikipedia.org/wiki?curid=14308" title="Hoover Dam">
Hoover Dam

Hoover Dam, once known as Boulder Dam, is a concrete arch-gravity dam in the Black Canyon of the Colorado River, on the border between the U.S. states of Nevada and Arizona. It was constructed between 1931 and 1936 during the Great Depression and was dedicated on September 30, 1935, by President Franklin D. Roosevelt. Its construction was the result of a massive effort involving thousands of workers, and cost over one hundred lives. The dam was controversially named after President Herbert Hoover.
Since about 1900, the Black Canyon and nearby Boulder Canyon had been investigated for their potential to support a dam that would control floods, provide irrigation water and produce hydroelectric power. In 1928, Congress authorized the project. The winning bid to build the dam was submitted by a consortium called Six Companies, Inc., which began construction on the dam in early 1931. Such a large concrete structure had never been built before, and some of the techniques were unproven. The torrid summer weather and lack of facilities near the site also presented difficulties. Nevertheless, Six Companies turned over the dam to the federal government on March 1, 1936, more than two years ahead of schedule.
Hoover Dam impounds Lake Mead, the largest reservoir in the United States by volume. The dam is located near Boulder City, Nevada, a municipality originally constructed for workers on the construction project, about southeast of Las Vegas, Nevada. The dam's generators provide power for public and private utilities in Nevada, Arizona, and California. Hoover Dam is a major tourist attraction; nearly a million people tour the dam each year. The heavily travelled U.S. 93 ran along the dam's crest until October 2010, when the Hoover Dam Bypass opened.
Background.
Search for resources.
As the United States developed the Southwest, the Colorado River was seen as a potential source of irrigation water. An initial attempt at diverting the river for irrigation purposes occurred in the late 1890s, when land speculator William Beatty built the Alamo Canal just north of the Mexican border; the canal dipped into Mexico before running to a desolate area, Beatty which was named the Imperial Valley. Though water from the Imperial Canal allowed for the widespread settlement of the valley, the canal proved expensive to maintain. After a catastrophic breach that caused the Colorado River to fill the Salton Sea, the Southern Pacific Railroad spent $3 million in 1906–07 to stabilize the waterway, an amount it hoped vainly would be reimbursed by the Federal Government. Even after the waterway was stabilized, it proved unsatisfactory because of constant disputes with landowners on the Mexican side of the border.
As the technology of electric power transmission improved, the Lower Colorado was considered for its hydroelectric-power potential. In 1902, the Edison Electric Company of Los Angeles surveyed the river in the hope of building a rock dam which could generate . However, at the time, the limit of transmission of electric power was , and there were few customers (mostly mines) within that limit. Edison allowed land options it held on the river to lapse—including an option for what became the site of Hoover Dam.
In the following years, the Bureau of Reclamation (BOR), known as the Reclamation Service at the time, also considered the Lower Colorado as the site for a dam. Service chief Arthur Powell Davis proposed using dynamite to collapse the walls of Boulder Canyon, north of the eventual dam site, into the river. The river would carry off the smaller pieces of debris, and a dam would be built incorporating the remaining rubble. In 1922, after considering it for several years, the Reclamation Service finally rejected the proposal, citing doubts about the unproven technique and questions as to whether it would in fact save money.
Planning and agreements.
In 1922, the Reclamation Service presented a report calling for the development of a dam on the Colorado River for flood control and electric power generation. The report was principally authored by Davis, and was called the Fall-Davis report after Interior Secretary Albert Fall. The Fall-Davis report cited use of the Colorado River as a federal concern, because the river's basin covered several states, and the river eventually entered Mexico. Though the Fall-Davis report called for a dam "at or near Boulder Canyon", the Reclamation Service (which was renamed the Bureau of Reclamation the following year) found that canyon unsuitable. One potential site at Boulder Canyon was bisected by a geologic fault; two others were so narrow there was no space for a construction camp at the bottom of the canyon or for a spillway. The Service investigated Black Canyon and found it ideal; a railway could be laid from the railhead in Las Vegas to the top of the dam site. Despite the site change, the dam project was referred to as the "Boulder Canyon Project".
With little guidance on water allocation from the Supreme Court, proponents of the dam feared endless litigation. A Colorado attorney proposed that the seven states which fell within the river's basin (California, Nevada, Arizona, Utah, New Mexico, Colorado and Wyoming) form an interstate compact, with the approval of Congress. Such compacts were authorized by Article I of the United States Constitution but had never been concluded among more than two states. In 1922, representatives of seven states met with then-Secretary of Commerce Herbert Hoover. Initial talks produced no result, but when the Supreme Court handed down the "Wyoming v. Colorado" decision undermining the claims of the upstream states, they became anxious to reach an agreement. The resulting Colorado River Compact was signed on November 24, 1922.
Legislation to authorize the dam was introduced repeatedly by Representative Phil Swing (R-Calif.) and Senator Hiram Johnson (R-Calif.), but representatives from other parts of the country considered the project as hugely expensive and one that would mostly benefit California. The 1927 Mississippi flood made Midwestern and Southern congressmen and senators more sympathetic toward the dam project. On March 12, 1928, the failure of the St. Francis Dam, constructed by the city of Los Angeles, caused a disastrous flood that killed up to 600 people. As that dam was a curved-gravity type, similar in design to the arch-gravity as was proposed for the Black Canyon dam, opponents claimed that the Black Canyon dam's safety could not be guaranteed. Congress authorized a board of engineers to review plans for the proposed dam. The Colorado River Board found the project feasible, but warned that should the dam fail, every downstream Colorado River community would be destroyed, and that the river might change course and empty into the Salton Sea. The Board cautioned: "To avoid such possibilities, the proposed dam should be constructed on conservative if not ultra-conservative lines."
On December 21, 1928 President Coolidge signed the bill authorizing the dam. The Boulder Canyon Project Act appropriated $165 million for the Hoover Dam along with the downstream Imperial Dam and All-American Canal, a replacement for Beatty's canal entirely on the U.S. side of the border. It also permitted the compact to go into effect when at least six of the seven states approved it. This occurred on March 6, 1929 with Utah's ratification; Arizona did not approve it until 1944.
Design, preparation and contracting.
Even before Congress approved the Boulder Canyon Project, the Bureau of Reclamation was considering what kind of dam should be used. Officials eventually decided on a massive concrete arch-gravity dam, the design of which was overseen by the Bureau's chief design engineer John L. Savage. The monolithic dam would be thick at the bottom and thin near the top, and would present a convex face towards the water above the dam. The curving arch of the dam would transmit the water's force into the abutments, in this case the rock walls of the canyon. The wedge-shaped dam would be thick at the bottom, narrowing to at the top, leaving room for a highway connecting Nevada and Arizona.
On January 10, 1931, the Bureau made the bid documents available to interested parties, at five dollars a copy. The government was to provide the materials; but the contractor was to prepare the site and build the dam. The dam was described in minute detail, covering 100 pages of text and 76 drawings. A $2 million bid bond was to accompany each bid; the winner would have to post a $5 million performance bond. The contractor had seven years to build the dam, or penalties would ensue.
The Wattis Brothers, heads of the Utah Construction Company, were interested in bidding on the project, but lacked the money for the performance bond. They lacked sufficient resources even in combination with their longtime partners, Morrison-Knudsen, which employed the nation's leading dam builder, Frank Crowe. They formed a joint venture to bid for the project with Pacific Bridge Company of Portland, Oregon; Henry J. Kaiser & W. A. Bechtel Company of San Francisco; MacDonald & Kahn Ltd. of Los Angeles; and the J.F. Shea Company of Portland, Oregon. The joint venture was called Six Companies, Inc. as Bechtel and Kaiser were considered one company for purposes of 6 in the name. The name was descriptive and was an inside joke among the San Franciscans in the bid, where "Six Companies" was also a Chinese benevolent association in the city. There were three valid bids, and Six Companies' bid of $48,890,955 was the lowest, within $24,000 of the confidential government estimate of what the dam would cost to build, and five million dollars less than the next-lowest bid.
The city of Las Vegas had lobbied hard to be the headquarters for the dam construction, closing its many speakeasies when the decision maker, Secretary of the Interior Ray Wilbur came to town. Instead, Wilbur announced in early 1930 that a model city was to be built in the desert near the dam site. This town became known as Boulder City, Nevada. Construction of a rail line joining Las Vegas and the dam site began in September 1930.
Construction.
Labor force.
Soon after the dam was authorized, increasing numbers of unemployed people converged on southern Nevada. Las Vegas, then a small city of some 5,000, saw between 10,000 and 20,000 unemployed descend on it. A government camp was established for surveyors and other personnel near the dam site; this soon became surrounded by a squatters' camp. Known as McKeeversville, the camp was home to men hoping for work on the project, together with their families. Another camp, on the flats along the Colorado River, was officially called Williamsville, but was known to its inhabitants as "Ragtown". When construction began, Six Companies hired large numbers of workers, with more than 3,000 on the payroll by 1932 and with employment peaking at 5,251 in July 1934. "Mongolian" (Chinese) labor was prevented by the construction contract, while the number of blacks employed by Six Companies never exceeded thirty, mostly lowest-pay-scale laborers in a segregated crew, who were issued separate water buckets.
As part of the contract, Six Companies, Inc. was to build Boulder City to house the workers. The original timetable called for Boulder City to be built before the dam project began, but President Hoover ordered work on the dam to begin in March 1931 rather than in October. The company built bunkhouses, attached to the canyon wall, to house 480 single men at what became known as River Camp. Workers with families were left to provide their own accommodations until Boulder City could be completed, and many lived in Ragtown. The site of Hoover Dam endures extremely hot weather, and the summer of 1931 was especially torrid, with the daytime high averaging . Sixteen workers and other riverbank residents died of heat prostration between June 25 and July 26, 1931.
The Industrial Workers of the World (IWW or "Wobblies"), though much-reduced from their heyday as militant labor organizers in the early years of the century, hoped to unionize the Six Companies workers by capitalizing on their discontent. They sent eleven organizers, several of whom were arrested by Las Vegas police. On August 7, 1931, the company cut wages for all tunnel workers. Although the workers sent away the organizers, not wanting to be associated with the "Wobblies", they formed a committee to represent them with the company. The committee drew up a list of demands that evening and presented them to Crowe the following morning. He was noncommittal. The workers hoped that Crowe, the general superintendent of the job, would be sympathetic; instead he gave a scathing interview to a newspaper, describing the workers as "malcontents".
On the morning of the 9th, Crowe met with the committee and told them that management refused their demands, was stopping all work, and was laying off the entire work force, except for a few office workers and carpenters. The workers were given until 5 p.m. to vacate the premises. Concerned that a violent confrontation was imminent, most workers took their paychecks and left for Las Vegas to await developments. Two days later, the remainder were talked into leaving by law enforcement. On August 13, the company began hiring workers again, and two days later, the strike was called off. While the workers received none of their demands, the company guaranteed there would be no further reductions in wages. Living conditions began to improve as the first residents moved into Boulder City in late 1931.
A second labor action took place in July 1935, as construction on the dam wound down. When a Six Companies manager altered working times to force workers to take lunch on their own time, workers responded with a strike. Emboldened by Crowe's reversal of the lunch decree, workers raised their demands to include a $1-per-day raise. The company agreed to ask the Federal government to supplement the pay, but no money was forthcoming from Washington. The strike ended.
River diversion.
Before the dam could be built, the Colorado River needed to be diverted away from the construction site. To accomplish this, four diversion tunnels were driven through the canyon walls, two on the Nevada side and two on the Arizona side. These tunnels were in diameter. Their combined length was nearly 16,000 ft, or more than . The contract required these tunnels to be completed by October 1, 1933, with a $3,000-per-day fine to be assessed for any delay. To meet the deadline, Six Companies had to complete work by early 1933, since only in late fall and winter was the water level in the river low enough to safely divert.
Tunneling began at the lower portals of the Nevada tunnels in May 1931. Shortly afterward, work began on two similar tunnels in the Arizona canyon wall. In March 1932, work began on lining the tunnels with concrete. First the base, or invert, was poured. Gantry cranes, running on rails through the entire length of each tunnel were used to place the concrete. The sidewalls were poured next. Movable sections of steel forms were used for the sidewalls. Finally, using pneumatic guns, the overheads were filled in. The concrete lining is thick, reducing the finished tunnel diameter to . The river was diverted into the two Arizona tunnels on November 13, 1932; the Nevada tunnels were kept in reserve for high water. This was done by exploding a temporary cofferdam protecting the Arizona tunnels while at the same time dumping rubble into the river until its natural course was blocked.
Following the completion of the dam, the entrances to the two outer diversion tunnels were sealed at the opening and halfway through the tunnels with large concrete plugs. The downstream halves of the tunnels following the inner plugs are now the main bodies of the spillway tunnels. The inner diversion tunnels were plugged at approximately one-third of their length, beyond which they now carry steel pipes connecting the intake towers to the power plant and outlet works. The inner tunnels' outlets are equipped with gates that can be closed to drain the tunnels for maintenance.
Groundworks, rock clearance and grout curtain.
To protect the construction site from the Colorado River and to facilitate the river's diversion, two cofferdams were constructed. Work on the upper cofferdam began in September 1932, even though the river had not yet been diverted. The cofferdams were designed to protect against the possibility of the river flooding a site at which two thousand men might be at work, and their specifications were covered in the bid documents in nearly as much detail as the dam itself. The upper cofferdam was high, and thick at its base, as thicker than the dam itself. It contained of material.
When the cofferdams were in place and the construction site was drained of water, excavation for the dam foundation began. For the dam to rest on solid rock, it was necessary to remove accumulated erosion soils and other loose materials in the riverbed until sound bedrock was reached. Work on the foundation excavations was completed in June 1933. During this excavation, approximately of material was removed. Since the dam was an arch-gravity type, the side-walls of the canyon would bear the force of the impounded lake. Therefore, the side-walls were excavated too, to reach virgin rock as weathered rock might provide pathways for water seepage.
The men who removed this rock were called "high scalers". While suspended from the top of the canyon with ropes, the high-scalers climbed down the canyon walls and removed the loose rock with jackhammers and dynamite. Falling objects were the most common cause of death on the dam site; the high scalers' work thus helped ensure worker safety. One high scaler was able to save life in a more direct manner: when a government inspector lost his grip on a safety line and began tumbling down a slope towards almost certain death, a high scaler was able to intercept him and pull him into the air. The construction site had, even then, become a magnet for tourists; the high scalers were prime attractions and showed off for the watchers. The high scalers received considerable media attention, with one worker dubbed the "Human Pendulum" for swinging co-workers (and, at other times, cases of dynamite) across the canyon. To protect themselves against falling objects, some high scalers took cloth hats and dipped them in tar, allowing them to harden. When workers wearing such headgear were struck hard enough to inflict broken jaws, they sustained no skull damage, Six Companies ordered thousands of what initially were called "hard boiled hats" (later "hard hats") and strongly encouraged their use.
The cleared, underlying rock foundation of the dam site was reinforced with grout, called a grout curtain. Holes were driven into the walls and base of the canyon, as deep as into the rock, and any cavities encountered were to be filled with grout. This was done to stabilize the rock, to prevent water from seeping past the dam through the canyon rock, and to limit "uplift"—upward pressure from water seeping under the dam. The workers were under severe time constraints due to the beginning of the concrete pour, and when they encountered hot springs or cavities too large to readily fill, they moved on without resolving the problem. A total of 58 of the 393 holes were incompletely filled. After the dam was completed and the lake began to fill, large numbers of significant leaks into the dam caused the Bureau of Reclamation to look into the situation. It found that the work had been incompletely done, and was based on less than a full understanding of the canyon's geology. New holes were drilled from inspection galleries inside the dam into the surrounding bedrock. It took nine years (1938–47) under relative secrecy to complete the supplemental grout curtain.
Concrete.
The first concrete was poured into the dam on June 6, 1933, 18 months ahead of schedule. Since concrete heats and contracts as it cures, the potential for uneven cooling and contraction of the concrete posed a serious problem. Bureau of Reclamation engineers calculated that if the dam was built in a single continuous pour, the concrete would take 125 years to cool and the resulting stresses would cause the dam to crack and crumble. Instead, the ground where the dam was to rise was marked with rectangles, and concrete blocks in columns were poured, some as large as and high. Each five-foot form contained a series of steel pipes through which first cool river water, then later ice-cold water from a refrigeration plant was run. When an individual block had cured and had stopped contracting, the pipes were filled with grout. Grout was also used to fill the hairline spaces between columns, which were grooved to increase the strength of the joins.
The concrete was delivered in huge steel buckets and almost 7 feet in diameter; Crowe was awarded two patents for their design. These buckets, which weighed when full, were filled at two massive concrete plants on the Nevada side, and were delivered to the site in special railcars. The buckets were then suspended from aerial cableways, which were used to deliver the bucket to a specific column. As the required grade of aggregate in the concrete differed depending on placement in the dam (from pea-sized gravel to 9-inch or 23 cm stones), it was vital that the bucket be maneuvered to the proper column. When the bottom of the bucket opened up, disgorging of concrete, a team of men worked it throughout the form. Although there are myths that men were caught in the pour and are entombed in the dam to this day, each bucket only deepened the concrete in a form by an inch, and Six Companies engineers would not have permitted a flaw caused by the presence of a human body.
A total of of concrete was used in the dam before concrete pouring ceased on May 29, 1935. In addition, were used in the power plant and other works. More than of cooling pipes were placed within the concrete. Overall, there is enough concrete in the dam to pave a two-lane highway from San Francisco to New York. Concrete cores were removed from the dam for testing in 1995; they showed that "Hoover Dam's concrete has continued to slowly gain strength" and the dam is composed of a "durable concrete having a compressive strength exceeding the range typically found in normal mass concrete". Hoover Dam concrete is not subject to alkali–silica reaction (ASR) as the Hoover Dam builders happened to use nonreactive aggregate, unlike that at downstream Parker Dam, where ASR has caused measurable deterioration.
Dedication and completion.
With most work finished on the dam itself (the powerhouse remained uncompleted), a formal dedication ceremony was arranged for September 30, 1935, to coincide with a western tour being made by President Franklin D. Roosevelt. The morning of the dedication, it was moved forward three hours from 2 p.m. Pacific time to 11 a.m.; this was done because Secretary of the Interior Harold L. Ickes had reserved a radio slot for the President for 2 p.m. but officials did not realize until the day of the ceremony that the slot was for 2 p.m. Eastern Time. Despite the change in the ceremony time, and temperatures of , 10,000 people were present for the President's speech in which he avoided mentioning the name of former President Hoover, who was not invited to the ceremony. To mark the occasion, a three-cent stamp was issued by the United States Post Office Department—bearing the name "Boulder Dam", the official name of the dam between 1933 and 1947. After the ceremony, Roosevelt made the first visit by any American president to Las Vegas.
Most work had been completed by the dedication, and Six Companies negotiated with the government through late 1935 and early 1936 to settle all claims and arrange for the formal transfer of the dam to the Federal Government. The parties came to an agreement and on March 1, 1936, Secretary Ickes formally accepted the dam on behalf of the government. Six Companies was not required to complete work on one item, a concrete plug for one of the bypass tunnels, as the tunnel had to be used to take in irrigation water until the powerhouse went into operation.
Construction deaths.
There were 112 deaths associated with the construction of the dam. The first was J. G. Tierney, a surveyor who drowned on December 20, 1922, while looking for an ideal spot for the dam. Ninety-six of the deaths occurred during construction at the site. Of the 112 fatalities, 91 were Six Companies employees, three were BOR employees, and one was a visitor to the site, with the remainder employees of various contractors not part of Six Companies.
Not included in the official fatalities number were deaths that were recorded as pneumonia. Workers alleged that this diagnosis was a cover for death from carbon monoxide poisoning, brought on by the use of gasoline-fueled vehicles in the diversion tunnels, and a classification used by Six Companies to avoid paying compensation claims. The site's diversion tunnels frequently reached , enveloped in thick plumes of vehicle exhaust gases. A total of 42 workers were recorded as having died from pneumonia; none were listed as having died from carbon monoxide poisoning. No deaths of non-workers from pneumonia were recorded in Boulder City during the construction period.
Architectural style.
The initial plans for the facade of the dam, the power plant, the outlet tunnels and ornaments clashed with the modern look of an arch dam. The Bureau of Reclamation, more concerned with the dam's functionality, adorned it with a Gothic-inspired balustrade and eagle statues. This initial design was criticized by many as being too plain and unremarkable for a project of such immense scale, so Los Angeles-based architect Gordon B. Kaufmann, then the supervising architect to the Bureau of Reclamation, was brought in to redesign the exteriors. Kaufmann greatly streamlined the design, and applied an elegant Art Deco style to the entire project. He designed sculptured turrets rising seamlessly from the dam face and clock faces on the intake towers set for the time in Nevada and Arizona — the two states are in different time zones, but as Arizona does not observe Daylight Saving Time, the clocks display the same time for more than half the year.
At Kaufmann's request, Denver artist Allen Tupper True was hired to handle the design and decoration of the walls and floors of the new dam. True's design scheme incorporated motifs of the Navajo and Pueblo tribes of the region. Although some initially were opposed to these designs, True was given the go-ahead and was officially appointed consulting artist. With the assistance of the National Laboratory of Anthropology, True researched authentic decorative motifs from Indian sand paintings, textiles, baskets and ceramics. The images and colors are based on Native American visions of rain, lightning, water, clouds, and local animals — lizards, serpents, birds — and on the Southwestern landscape of stepped mesas. In these works, which are integrated into the walkways and interior halls of the dam, True also reflected on the machinery of the operation, making the symbolic patterns appear both ancient and modern.
With the agreement of Kaufmann and the engineers, True also devised an innovative color-coding for the pipes and machinery, which was implemented throughout all BOR projects. True's consulting artist job lasted through 1942; it was extended so he could complete design work for the Parker, Shasta and Grand Coulee dams and power plants. True's work on the Hoover Dam was humorously referred to in a poem published in "The New Yorker", part of which read, "lose the spark, and justify the dream; but also worthy of remark will be the color scheme".
Complementing Kaufmann and True's work, the Norwegian-born, naturalized American sculptor Oskar J.W. Hansen designed many of the sculptures on and around the dam. His works include the monument of dedication plaza, a plaque to memorialize the workers killed and the bas-reliefs on the elevator towers. In his words, Hansen wanted his work to express "the immutable calm of intellectual resolution, and the enormous power of trained physical strength, equally enthroned in placid triumph of scientific accomplishment", because "he building of Hoover Dam belongs to the sagas of the daring." Hansen's dedication plaza, on the Nevada abutment, contains a sculpture of two winged figures flanking a flagpole.
Surrounding the base of the monument is a terrazzo floor embedded with a "star map". The map depicts the Northern Hemisphere sky at the moment of President Roosevelt's dedication of the dam. This is intended to help future astronomers, if necessary, calculate the exact date of dedication. The bronze figures, dubbed "Winged Figures of the Republic", were each formed in a continuous pour. To put such large bronzes into place without marring the highly polished bronze surface, they were placed on ice and guided into position as the ice melted. Hansen's bas-relief on the Nevada elevator tower depicts the benefits of the dam: flood control, navigation, irrigation, water storage, and power. The bas-relief on the Arizona elevator depicts, in his words, "the visages of those Indian tribes who have inhabited mountains and plains from ages distant."
Operation.
Power plant and water demands.
Excavation for the powerhouse was carried out simultaneously with the excavation for the dam foundation and abutments. A U-shaped structure located at the downstream toe of the dam, its excavation was completed in late 1933 with the first concrete placed in November 1933. Filling of Lake Mead began February 1, 1935, even before the last of the concrete was poured that May. The powerhouse was one of the projects uncompleted at the time of the formal dedication on September 30, 1935—a crew of 500 men remained to finish it and other structures. To make the powerhouse roof bombproof, it was constructed of layers of concrete, rock, and steel with a total thickness of about , topped with layers of sand and tar.
In the latter half of 1936, water levels in Lake Mead were high enough to permit power generation, and the first three Allis Chalmers built Francis turbine-generators, all on the Nevada side, began operating. In March 1937, one more Nevada generator went online and the first Arizona generator by August. By September 1939, four more generators were operating, and the dam's power plant became the largest hydroelectricity facility in the world. The final generator was not placed in service until 1961, bringing the maximum generating capacity to 1,345 megawatts at the time. Original plans called for 16 large generators, eight on each side of the river, but two smaller generators were installed instead of one large one on the Arizona side for a total of 17. The smaller generators were used to serve smaller communities at a time when the output of each generator was dedicated to a single municipality, before the dam's total power output was placed on the grid and made arbitrarily distributable. The present contracts for the sale of electricity expire in 2017.
Before water from Lake Mead reaches the turbines, it enters the intake towers and then four gradually narrowing penstocks which funnel the water down towards the powerhouse. The intakes provide a maximum hydraulic head (water pressure) of as the water reaches a speed of about . The entire flow of the Colorado River passes through the turbines. The spillways and outlet works (jet-flow gates) are rarely used. The jet-flow gates, located in concrete structures above the river, and also at the outlets of the inner diversion tunnels at river level, may be used to divert water around the dam in emergency or flood conditions, but have never done so, and in practice are only used to drain water from the penstocks for maintenance. Following an uprating project from 1986 to 1993, the total gross power rating for the plant, including two 2.4 megawatt Pelton turbine-generators that power Hoover Dam's own operations is a maximum capacity of 2080 megawatts. The annual generation of Hoover Dam varies. The maximum net generation was 10.348 TWh in 1984, and the minimum since 1940 was 2.648 TWh in 1956. The average has been about 4.2 TWh/year. To lower the minimum power pool elevation from , five wide-head turbines, designed to work efficiently with less flow, will be online by 2017.
Control of water was the primary concern in the building of the dam. Power generation has allowed the dam project to be self-sustaining: proceeds from the sale of power repaid the 50-year construction loan, and those revenues also finance the multimillion-dollar yearly maintenance budget. Power is generated in step with and only with the release of water in response to downstream water demands.
Lake Mead and downstream releases from the dam also provide water for both municipal and irrigation uses. Water released from the Hoover Dam eventually reaches several canals. The Colorado River Aqueduct and Central Arizona Project branch off Lake Havasu while the All-American Canal is supplied by the Imperial Dam. In total, water from the Lake Mead serves 18 million people in Arizona, Nevada and California and supplies the irrigation of over of land.
Power distribution.
Electricity from the dam's powerhouse was originally sold pursuant to a fifty-year contract, authorized by Congress in 1934, which ran from 1937 to 1987. In 1984, Congress passed a new statute which set power allocations from the dam from 1987 to 2017. The powerhouse was run under the original authorization by the Los Angeles Department of Water and Power and Southern California Edison; in 1987, the Bureau of Reclamation assumed control. In 2011, Congress enacted legislation extending the current contracts until 2067, after setting aside 5% of Hoover Dam's power for sale to Native American tribes, electric cooperatives, and other entities. The new arrangement will begin in 2017. The Bureau of Reclamation reports that the energy generated is allocated as follows:
Spillways.
The dam is protected against over-topping by two spillways. The spillway entrances are located behind each dam abutment, running roughly parallel to the canyon walls. The spillway entrance arrangement forms a classic side-flow weir with each spillway containing four and steel-drum gates. Each gate weighs and can be operated manually or automatically. Gates are raised and lowered depending on water levels in the reservoir and flood conditions. The gates are unable to entirely prevent water from entering the spillways but are able to maintain an extra of lake level.
Water flowing over the spillways flows smoothly into , spillway tunnels before connecting to the outer diversion tunnels, and reentering the main river channel below the dam. This complex spillway entrance arrangement combined with the approximate elevation drop from the top of the reservoir to the river below was a difficult engineering problem and posed numerous design challenges. Each spillway's capacity of was empirically verified in post-construction tests in 1941.
The large spillway tunnels have been used only twice, for testing in 1941 and because of flooding in 1983. During both times, when inspecting the tunnels after the spillways were used, engineers found major damage to the concrete linings and underlying rock. The 1941 damage was attributed to a slight misalignment of the tunnel invert (or base), which caused cavitation, a phenomenon in fast-flowing liquids in which vapor bubbles collapse with explosive force. In response to this finding, the tunnels were patched with special heavy-duty concrete and the surface of the concrete was polished mirror-smooth. The spillways were modified in 1947 by adding flip buckets, which both slow the water and decrease the spillway's effective capacity, in an attempt to eliminate conditions thought to have contributed to the 1941 damage. The 1983 damage, also due to cavitation, led to the installation of aerators in the spillways. Tests at Grand Coulee Dam showed that the technique worked, in principle.
Roadway and tourism.
There are two lanes for automobile traffic across the top of the dam, which formerly served as the Colorado River crossing for U.S. Route 93. In the wake of the September 11, 2001 terrorist attacks, authorities expressed security concerns and the Hoover Dam Bypass project was expedited. Pending the completion of the bypass, restricted traffic was permitted over Hoover Dam. Some types of vehicles were inspected prior to crossing the dam while semi-trailer trucks, buses carrying luggage, and enclosed-box trucks over long were not allowed on the dam at all, and were diverted to U.S. Route 95 or Nevada State Routes 163/68. The four-lane Hoover Dam Bypass opened on October 19, 2010. It includes a composite steel and concrete arch bridge, the Mike O'Callaghan–Pat Tillman Memorial Bridge, downstream from the dam.
With the opening of the bypass, through traffic is no longer allowed across Hoover Dam, dam visitors are allowed to use the existing roadway to approach from the Nevada side and cross to parking lots and other facilities on the Arizona side.
Hoover Dam opened for tours in 1937 after its completion, but following Japan's attack on Pearl Harbor on December 7, 1941, it was closed to the public when the United States entered World War II, during which only authorized traffic, in convoys, was permitted. After the war, it reopened September 2, 1945, and by 1953, annual attendance had risen to 448,081. The dam closed on November 25, 1963 and March 31, 1969, days of mourning in remembrance of Presidents Kennedy and Eisenhower. In 1995, a new visitors' center was built, and the following year, visits exceeded one million for the first time. The dam closed again to the public on September 11, 2001; modified tours were resumed in December and a new "Discovery Tour" was added the following year. Today, nearly a million people per year take the tours of the dam offered by the Bureau of Reclamation. Increased security concerns by the government have led to most of the interior structure being inaccessible to tourists. As a result, few of True's decorations can now be seen by visitors.
Environmental impact.
The changes in water flow and use caused by Hoover Dam's construction and operation have had a large impact on the Colorado River Delta. The construction of the dam has been credited as causing the decline of this estuarine ecosystem. For six years after the construction of the dam, while Lake Mead filled, virtually no water reached the mouth of the river. The delta's estuary, which once had a freshwater-saltwater mixing zone stretching south of the river's mouth, was turned into an inverse estuary where the level of salinity was higher close to the river's mouth.
The Colorado River had experienced natural flooding before the construction of the Hoover Dam. The dam eliminated the natural flooding, which threatened many species adapted to the flooding, including both plants and animals. The construction of the dam devastated the populations of native fish in the river downstream from the dam. Four species of fish native to the Colorado River, the Bonytail chub, Colorado pikeminnow, Humpback chub, and Razorback sucker, are listed as endangered.
Naming controversy.
During the years of lobbying leading up to the passage of legislation authorizing the dam in 1928, the press generally referred to the dam as "Boulder Dam" or as "Boulder Canyon Dam", even though the proposed site had shifted to Black Canyon. The Boulder Canyon Project Act of 1928 (BCPA) never mentioned a proposed name or title for the dam. The BCPA merely allows the government to "construct, operate, and maintain a dam and incidental works in the main stream of the Colorado River at Black Canyon or Boulder Canyon".
When Secretary Wilbur spoke at the ceremony starting the building of the railway between Las Vegas and the dam site on September 17, 1930, he named the dam "Hoover Dam", citing a tradition of naming dams after Presidents, though none had been so honored during their terms of office. Wilbur justified his choice on the ground that Hoover was "the great engineer whose vision and persistence ... has done so much to make dam possible". One writer complained in response that "the Great Engineer had quickly drained, ditched, and dammed the country".
After Hoover's election defeat in 1932 and the accession of the Roosevelt administration, Secretary Ickes ordered on May 13, 1933 that the dam be referred to as "Boulder Dam". Ickes stated that Wilbur had been imprudent in naming the dam after a sitting president, that Congress had never ratified his choice, and that it had long been referred to as Boulder Dam. When Ickes spoke at the dedication ceremony on September 30, 1935, he was determined, as he recorded in his diary, "to try to nail down for good and all the name Boulder Dam". At one point in the speech, he spoke the words "Boulder Dam" five times within thirty seconds. Further, he suggested that if the dam were to be named after any one person, it should be for California Senator Hiram Johnson, a lead sponsor of the authorizing legislation. Roosevelt also referred to the dam as Boulder Dam, and the Republican-leaning "Los Angeles Times", which at the time of Ickes' name change had run an editorial cartoon showing Ickes ineffectively chipping away at an enormous sign "HOOVER DAM", reran it showing Roosevelt reinforcing Ickes, but having no greater success.
In the following years, the name "Boulder Dam" failed to fully take hold, with many Americans using both names interchangeably and mapmakers divided as to which name should be printed. Memories of the Great Depression faded, and Hoover to some extent rehabilitated himself through good works during and after World War II. In 1947, a bill passed both Houses of Congress unanimously restoring the name "Hoover Dam". Ickes, who was by then a private citizen, opposed the change, stating, "I didn't know Hoover was that small a man to take credit for something he had nothing to do with."
Bibliography.
Other sources

</doc>
<doc id="14309" url="https://en.wikipedia.org/wiki?curid=14309" title="Holger Pedersen">
Holger Pedersen

Holger Pedersen may refer to:

</doc>
<doc id="14311" url="https://en.wikipedia.org/wiki?curid=14311" title="Adventures of Huckleberry Finn">
Adventures of Huckleberry Finn

Adventures of Huckleberry Finn (or, in more recent editions, The Adventures of Huckleberry Finn) is a novel by Mark Twain, first published in the United Kingdom in December 1884 and in the United States in February 1885. Commonly named among the Great American Novels, the work is among the first in major American literature to be written throughout in vernacular English, characterized by local color regionalism. It is told in the first person by Huckleberry "Huck" Finn, a friend of Tom Sawyer and narrator of two other Twain novels ("Tom Sawyer Abroad" and "Tom Sawyer, Detective"). It is a direct sequel to "The Adventures of Tom Sawyer".
The book is noted for its colorful description of people and places along the Mississippi River. Set in a Southern antebellum society that had ceased to exist about 20 years before the work was published, "Adventures of Huckleberry Finn" is an often scathing satire on entrenched attitudes, particularly racism.
Perennially popular with readers, "Adventures of Huckleberry Finn" has also been the continued object of study by literary critics since its publication. It was criticized upon release because of its coarse language and became even more controversial in the 20th century because of its perceived use of racial stereotypes and because of its frequent use of the racial slur "nigger", despite strong arguments that the protagonist and the tenor of the book are anti-racist.
Characters.
In order of appearance:
Plot summary.
In Missouri.
The story begins in fictional St. Petersburg, Missouri (based on the actual town of Hannibal, Missouri), on the shore of the Mississippi River "forty to fifty years ago" (the novel having been published in 1884). Huckleberry "Huck" Finn (the protagonist and first-person narrator) and his friend, Thomas "Tom" Sawyer, have each come into a considerable sum of money as a result of their earlier adventures (detailed in "The Adventures of Tom Sawyer"). Huck explains how he is placed under the guardianship of the Widow Douglas, who, together with her stringent sister, Miss Watson, are attempting to "sivilize" him and teach him religion. Finding civilized life confining, his spirits are raised somewhat when Tom Sawyer helps him to escape one night past Miss Watson's slave Jim, to meet up with Tom's gang of self-proclaimed "robbers." Just as the gang's activities begin to bore Huck, he is suddenly interrupted by the reappearance of his shiftless father, "Pap", an abusive alcoholic. Knowing that Pap would only spend the money on alcohol, Huck is successful in preventing Pap from acquiring his fortune; however, Pap kidnaps Huck and leaves town with him.
In Illinois and on Jackson's Island.
Pap forcibly moves Huck to his isolated cabin in the woods along the Illinois shoreline. Due to Pap's drunken violence and imprisonment of Huck inside the cabin, Huck, during one of his father's absences, elaborately fakes his own death, escapes the cabin, and sets off down river. He settles comfortably, on Jackson's Island. Here, Huck reunites with Jim, Miss Watson's slave. Jim has also run away after he overheard Miss Watson planning to sell him "down the river" to presumably more brutal owners. Jim plans to make his way to the town of Cairo in Illinois, a free state, so that he can later buy the rest of his enslaved family's freedom. At first, Huck is conflicted about the sin and crime of supporting a runaway slave, but as the two talk in depth and bond over their mutually held superstitions, Huck emotionally connects with Jim, who increasingly becomes Huck's close friend and guardian. After heavy flooding on the river, the two find a raft (which they keep) as well as an entire house floating on the river. Entering the house to seek loot, Jim finds the naked body of a dead man lying on the floor, shot in the back. He prevents Huck from viewing the corpse.
To find out the latest news in town, Huck dresses as a girl and enters the house of Judith Loftus, a woman new to the area. Huck learns from her about the news of his own supposed murder; Pap was initially blamed, but since Jim ran away he is also a suspect and a reward for Jim's capture has initiated a manhunt. Mrs. Loftus becomes increasingly suspicious that Huck is a boy, finally proving it by a series of tests. Once he is exposed, she nevertheless allows him to leave her home without commotion, not realizing that he is the allegedly murdered boy they have just been discussing. Huck returns to Jim to tell him the news and that a search party is coming to Jackson's Island that very night. The two hastily load up the raft and depart.
After a while, Huck and Jim come across a grounded steamship. Searching it, they stumble upon two thieves discussing murdering a third, but they flee before being noticed. They are later separated in a fog, making Jim intensely anxious, and when they reunite, Huck tricks Jim into thinking he dreamed the entire incident. Jim is not deceived for long, and is deeply hurt that his friend should have teased him so mercilessly. Huck becomes remorseful and apologizes to Jim, though his conscience troubles him about humbling himself to a black man.
In Kentucky: the Grangerfords and Shepherdsons.
Travelling onward, Huck and Jim's raft is struck by a passing steamship, again separating the two. Huck is given shelter on the Kentucky side of the river by the Grangerfords, an aristocratic family. He befriends Buck Grangerford, a boy about his age, and learns that the Grangerfords are engaged in a 30-year blood feud against another family, the Shepherdsons. The Grangerfords and Shepherdsons go to the same church, which ironically preaches brotherly love. The vendetta finally comes to a head when Buck's older sister elopes with a member of the Shepherdson clan. In the resulting conflict, all the Grangerford males from this branch of the family are shot and killed, including Buck, whose horrific murder Huck witnesses. He is immensely relieved to be reunited with Jim, who has since recovered and repaired the raft.
In Arkansas: the duke and the king.
Near the Arkansas-Missouri-Tennessee border, Jim and Huck take two on-the-run grifters aboard the raft. The younger man, who is about thirty, introduces himself as the long-lost son of an English duke (the Duke of Bridgewater). The older one, about seventy, then trumps this outrageous claim by alleging that he himself is the Lost Dauphin, the son of Louis XVI and rightful King of France. The "duke" and "king" soon become permanent passengers on Jim and Huck's raft, committing a series of confidence schemes upon unsuspecting locals all along their journey. To divert suspicions from the public away from Jim, they pose him as recaptured slave runaway, but later paint him up entirely blue and call him the "Sick Arab" so that he can move about the raft without bindings.
On one occasion, the swindlers advertise a three-night engagement of a play called "The Royal Nonesuch". The play turns out to be only a couple of minutes' worth of an absurd, bawdy sham. On the afternoon of the first performance, a drunk called Boggs is shot dead by a gentleman named Colonel Sherburn; a lynch mob forms to retaliate against Sherburn; and Sherburn, surrounded at his home, disperses the mob by making a defiant speech describing how true lynching should be done. By the third night of "The Royal Nonesuch", the townspeople prepare for their revenge on the duke and king for their money-making scam, but the two cleverly skip town together with Huck and Jim just before the performance begins.
In the next town, the two swindlers then impersonate brothers of Peter Wilks, a recently deceased man of property. To match accounts of Wilks's brothers, the king attempts an English accent and the duke pretends to be a deaf-mute, while starting to collect Wilks's inheritance. Huck decides that Wilks's three orphaned nieces, who treat Huck with kindness, do not deserve to be cheated thus and so he tries to retrieve for them the stolen inheritance. In a desperate moment, Huck is forced to hide the money in Wilks's coffin, which is abruptly buried the next morning. The arrival of two new men who seem to be the real brothers throws everything into confusion, so that the townspeople decide to dig up the coffin in order to determine which are the true brothers, but, with everyone else distracted, Huck leaves for the raft, hoping to never see the duke and king again. Suddenly, though, the two villains return, to Huck's despair. When Huck is finally able to get away a second time, he finds to his horror that the swindlers have sold Jim away to a family that intends to return him to his proper owner for the reward. Defying his conscience and accepting the negative religious consequences he expects for his actions—"All right, then, I'll go to hell!"—Huck resolves to free Jim once and for all.
On the Phelps' farm.
Huck learns that Jim is being held at the plantation of Silas and Sally Phelps. The family's nephew, Tom, is expected for a visit at the same time as Huck's arrival, so Huck is mistaken for Tom and welcomed into their home. He plays along, hoping to find Jim's location and free him; in a surprising plot twist, it is revealed that the expected nephew is in fact Tom Sawyer. When Huck intercepts the real Tom Sawyer on the road and tells him everything, Tom decides to join Huck's scheme, pretending to be his own younger half-brother, Sid, while Huck continues pretending to be Tom. In the meantime, Jim has told the family about the two grifters and the new plan for "The Royal Nonesuch", and so the townspeople capture the duke and king, who are then tarred and feathered and ridden out of town on a rail.
Rather than simply sneaking Jim out of the shed where he is being held, Tom develops an elaborate plan to free him, involving secret messages, a hidden tunnel, a rope ladder sent in Jim's food, and other elements from adventure books he has read, including an anonymous note to the Phelps warning them of the whole scheme. During the actual escape and resulting pursuit, Tom is shot in the leg, while Jim remains by his side, risking recapture rather than completing his escape alone. Although a local doctor admires Jim's decency, he has Jim arrested in his sleep and returned to the Phelps. After this, events quickly resolve themselves. Tom's Aunt Polly arrives and reveals Huck and Tom's true identities to the Phelps family. Jim is revealed to be a free man: Miss Watson died two months earlier and freed Jim in her will, but Tom (who already knew this) chose not to reveal this information to Huck so that he could come up with an artful rescue plan for Jim. Jim tells Huck that Huck's father (Pap Finn) has been dead for some time (he was the dead man they found earlier in the floating house), and so Huck may now return safely to St. Petersburg. Huck declares that he is quite glad to be done writing his story, and despite Sally's plans to adopt and civilize him, he intends to flee west to Indian Territory.
Major themes.
"Adventures of Huckleberry Finn" explores notions of race and identity. An obvious complexity exists concerning Jim's character. While some scholars point out that Jim is good-hearted, moral, and not unintelligent (in pointed contrast to several of the white characters), others have criticized the novel as racist, citing the use of the word "nigger" and emphasizing the stereotypically "comic" treatment of Jim's superstition and ignorance.
Huck struggles not only with the challenges of his strenuous journey, but also with the 19th century social climate and the role it forces on him regarding Jim. Throughout the story, Huck is in moral conflict with the received values of the society in which he lives, and while he is unable to consciously refute those values even in his thoughts, he makes a moral choice based on his own valuation of Jim's friendship and human worth, a decision in direct opposition to the things he has been taught. Mark Twain, in his lecture notes, proposes that "a sound heart is a surer guide than an ill-trained conscience" and goes on to describe the novel as "...a book of mine where a sound heart and a deformed conscience come into collision and conscience suffers defeat".
To highlight the hypocrisy required to condone slavery within an ostensibly moral system, Twain has Huck's father enslave his son, isolate him, and beat him. When Huck escapes – which anyone would agree was the right thing to do – he then immediately encounters Jim "illegally" doing the same thing.
Some scholars discuss Huck's own character, and the novel itself, in the context of its relation to African-American culture as a whole. John Alberti quotes Shelley Fisher Fishkin, who writes in her 1990s book "Was Huck Black?: Mark Twain and African-American Voices", "by limiting their field of inquiry to the periphery," white scholars "have missed the ways in which African-American voices shaped Twain's creative imagination at its core." It is suggested that the character of Huckleberry Finn illustrates the correlation, and even interrelatedness, between white and black culture in the United States.
Illustrations.
The original illustrations were done by E.W. Kemble, at the time a young artist working for "Life" magazine. Kemble was hand-picked by Twain, who admired his work. Hearn suggests that Twain and Kemble had a similar skill, writing that:
Whatever he may have lacked in technical grace ... Kemble shared with the greatest illustrators the ability to give even the minor individual in a text his own distinct visual personality; just as Twain so deftly defined a full-rounded character in a few phrases, so too did Kemble depict with a few strokes of his pen that same entire personage.
As Kemble could afford only one model, most of his illustrations produced for the book were done by guesswork. When the novel was published, the illustrations were praised even as the novel was harshly criticized. E.W. Kemble produced another set of illustrations for Harper's and the American Publishing Company in 1898 and 1899 after Twain lost the copyright.
Publication's effect on literary climate.
Twain initially conceived of the work as a sequel to "The Adventures of Tom Sawyer" that would follow Huckleberry Finn through adulthood. Beginning with a few pages he had removed from the earlier novel, Twain began work on a manuscript he originally titled "Huckleberry Finn's Autobiography." Twain worked on the manuscript off and on for the next several years, ultimately abandoning his original plan of following Huck's development into adulthood. He appeared to have lost interest in the manuscript while it was in progress, and set it aside for several years. After making a trip down the Hudson River, Twain returned to his work on the novel. Upon completion, the novel's title closely paralleled its predecessor's: "Adventures of Huckleberry Finn (Tom Sawyer's Comrade)".
As it relates to the actual body of text during the time of publication, Mark Twain composed the story in pen on notepaper between 1876 and 1883. Paul Needham, who supervised the authentication of the manuscript for Sotheby's books and manuscripts department in New York in 1991, stated, "What you see is attempt to move away from pure literary writing to dialect writing". For example, Twain revised the opening line of "Huck Finn" three times. He initially wrote, "You will not know about me", which he changed to, "You do not know about me", before settling on the final version, "You don't know about me, without you have read a book by the name of 'The Adventures of Tom Sawyer'; but that ain't no matter." The revisions also show how Twain reworked his material to strengthen the characters of Huck and Jim, as well as his sensitivity to the then-current debate over literacy and voting.
A later version was the first typewritten manuscript delivered to a printer.
Demand for the book spread outside of the United States. "Adventures of Huckleberry Finn" was eventually published on December 10, 1884, in Canada and the United Kingdom, and on February 18, 1885, in the United States. The illustration on page 283 became a point of issue after an engraver, whose identity was never discovered, made a last-minute addition to the printing plate of Kemble's picture of old Silas Phelps, which drew attention to Phelps' groin. Thirty thousand copies of the book had been printed before the obscenity was discovered. A new plate was made to correct the illustration and repair the existing copies.
In 1885, the Buffalo Public Library's curator, James Fraser Gluck, approached Twain to donate the manuscript to the library. Twain did so. Later it was believed that half of the pages had been misplaced by the printer. In 1991, the missing half turned up in a steamer trunk owned by descendants of Gluck's. The library successfully proved possession and, in 1994, opened the Mark Twain Room to showcase the treasure.
In relation to the literary climate at the time of the book's publication in 1885, Henry Nash Smith describes the importance of Mark Twain's already established reputation as a "professional humorist", having already published over a dozen other works. Smith suggests that while the "dismantling of the decadent Romanticism of the later nineteenth century was a necessary operation," "Adventures of Huckleberry Finn" illustrated "previously inaccessible resources of imaginative power, but also made vernacular language, with its new sources of pleasure and new energy, available for American prose and poetry in the twentieth century."
Reception.
While it was clear that the publication of "Adventures of Huckleberry Finn" was controversial from the outset, Norman Mailer, writing in "The New York Times" in 1984, concluded that Twain's novel was not initially "too unpleasantly regarded." In fact, Mailer writes: "the critical climate could hardly anticipate T. S. Eliot and Ernest Hemingway's encomiums 50 years later," reviews that would remain longstanding in the American consciousness.
Alberti suggests that the academic establishment responded to the book's challenges both dismissively and with confusion. During Twain's time, and today, defenders of "Adventures of Huckleberry Finn" "lump all nonacademic critics of the book together as extremists and ‘censors' thus equating the complaints about the book's ‘coarseness' from the genteel bourgeois trustees of the Concord Public Library in the 1880s with more recent objections based on race and civil rights."
Upon issue of the American edition in 1885 several libraries banned it from their shelves. The early criticism focused on what was perceived as the book's crudeness. One incident was recounted in the newspaper, the "Boston Transcript":
The Concord (Mass.) Public Library committee has decided to exclude Mark Twain's latest book from the library. One member of the committee says that, while he does not wish to call it immoral, he thinks it contains but little humor, and that of a very coarse type. He regards it as the veriest trash. The library and the other members of the committee entertain similar views, characterizing it as rough, coarse, and inelegant, dealing with a series of experiences not elevating, the whole book being more suited to the slums than to intelligent, respectable people.
Twain later remarked to his editor, "Apparently, the Concord library has condemned Huck as 'trash and only suitable for the slums.' This will sell us another twenty-five thousand copies for sure!"
In 1905, New York's Brooklyn Public Library also banned the book due to "bad word choice" and Huck's having "not only itched but scratched" within the novel, which was considered obscene. When asked by a Brooklyn librarian about the situation, Twain sardonically replied: I am greatly troubled by what you say. I wrote 'Tom Sawyer' & 'Huck Finn' for adults exclusively, & it always distressed me when I find that boys and girls have been allowed access to them. The mind that becomes soiled in youth can never again be washed clean. I know this by my own experience, & to this day I cherish an unappeased bitterness against the unfaithful guardians of my young life, who not only permitted but compelled me to read an unexpurgated Bible through before I was 15 years old. None can do that and ever draw a clean sweet breath again on this side of the grave.
Many subsequent critics, Ernest Hemingway among them, have deprecated the final chapters, claiming the book "devolves into little more than minstrel-show satire and broad comedy" after Jim is detained. Although Hemingway declared, "All modern American literature comes from" "Huck Finn", and hailed it as "the best book we've had", he cautioned, "If you must read it you must stop where the Nigger Jim is stolen from the boys "sic". That is the real end. The rest is just cheating." Pulitzer Prize winner Ron Powers states in his Twain biography ("Mark Twain: A Life") that "Huckleberry Finn endures as a consensus masterpiece despite these final chapters", in which Tom Sawyer leads Huck through elaborate machinations to rescue Jim.
The words "nigger" and "Jim" appear side-by-side once in the novel, in Chapter XXXI, in a letter Huck writes to Mrs. Watson, but they are not used as a name. The phrase "our old nigger Jim" also appears twice in Tom Sawyer, Detective. After "nigger Jim" appears in Albert Bigelow Paine's 1912 Clemens biography, it continued to be used by twentieth century critics, including Leslie Fiedler, Norman Mailer, and Russell Baker.
Writer Louisa May Alcott criticized the book's publication as well, saying that if Twain "not think of something better to tell our pure-minded lads and lasses he had best stop writing for them".
Controversy.
In his introduction to "The Annotated Huckleberry Finn", Michael Patrick Hearn writes that Twain "could be uninhibitedly vulgar," and quotes William Dean Howells, a Twain contemporary, who wrote that the author's "humor was not for most women." However, Hearn continues by explaining that "the reticent Howells found nothing in the proofs of Huckleberry Finn so offensive that it needed to be struck out."
Much of modern scholarship of "Huckleberry Finn" has focused on its treatment of race. Many Twain scholars have argued that the book, by humanizing Jim and exposing the fallacies of the racist assumptions of slavery, is an attack on racism. Others have argued that the book falls short on this score, especially in its depiction of Jim. According to Professor Stephen Railton of the University of Virginia, Twain was unable to fully rise above the stereotypes of black people that white readers of his era expected and enjoyed, and therefore resorted to minstrel show-style comedy to provide humor at Jim's expense, and ended up confirming rather than challenging late-19th century racist stereotypes.
In one instance, the controversy caused a drastically altered interpretation of the text: in 1955, CBS tried to avoid controversial material in a televised version of the book, by deleting all mention of slavery and omitting the character of Jim entirely.
Because of this controversy over whether "Huckleberry Finn" is racist or anti-racist, and because the word "nigger" is frequently used in the novel, many have questioned the appropriateness of teaching the book in the U.S. public school system—this questioning of the word "nigger" is illustrated by a school administrator of Virginia in 1982 calling the novel the "most grotesque example of racism I've ever seen in my life". According to the American Library Association, "Huckleberry Finn" was the fifth most frequently challenged book in the United States during the 1990s.
There have been several more recent cases involving protests for the banning of the novel. In 2003 high school student Calista Phair and her grandmother, Beatrice Clark, in Renton, Washington, proposed banning the book from classroom learning in the Renton School District, though not from any public libraries, because of the word "nigger". Clark filed a request with the school district in response to the required reading of the book, asking for the novel to be removed from the English curriculum. The two curriculum committees that considered her request eventually decided to keep the novel on the 11th grade curriculum, though they suspended it until a panel had time to review the novel and set a specific teaching procedure for the novel and its controversial topics.
In 2009 a Washington state high school teacher called for the removal of the novel from a school curriculum. The teacher, John Foley, called for replacing "Adventures of Huckleberry Finn" with a more modern novel. In an opinion column that Foley wrote in the Seattle Post Intelligencer, he states that all "novels that use the ‘N-word' repeatedly need to go." He states that teaching the novel is not only unnecessary, but difficult due to the offensive language within the novel with many students becoming uncomfortable at "just hearthe N-word." He views this change as "common sense," with Obama's election into office as a sign that Americans "are ready for a change," and that by removing these books from the reading lists, they would be following this change.
Publishers of the book have made their own attempts at easing the controversy by way of less-coarse publications. A 2011 edition of the book, published by NewSouth Books, replaced the word "nigger" with "slave" (although being incorrectly addressed to a freed man) and did not use the term "Injun." Mark Twain scholar Alan Gribben said he hoped the edition would be more friendly for use in classrooms, rather than have the work banned outright from classroom reading lists due to its language.
According to publisher Suzanne La Rosa "At NewSouth, we saw the value in an edition that would help the works find new readers. If the publication sparks good debate about how language impacts learning or about the nature of censorship or the way in which racial slurs exercise their baneful influence, then our mission in publishing this new edition of Twain's works will be more emphatically fulfilled." Another scholar, Thomas Wortham, criticized the changes, saying the new edition "doesn't challenge children to ask, 'Why would a child like Huck use such reprehensible language?'"
Responses to this include the publishing of "The Hipster Huckleberry Finn" which is an edition with the word "nigger" replaced with the word "hipster". The book's description includes this statement "Thanks to editor Richard Grayson, the adventures of Huckleberry Finn are now neither offensive nor uncool."

</doc>
<doc id="14312" url="https://en.wikipedia.org/wiki?curid=14312" title="Harpsichord">
Harpsichord

A harpsichord is a musical instrument played by means of a keyboard. It produces sound by plucking a string when a key is pressed.
"Harpsichord" designates the whole family of similar plucked keyboard instruments, including the smaller virginals, muselar, and spinet.
The harpsichord was widely used in Renaissance and Baroque music. During the late 18th century, it gradually disappeared from the musical scene with the rise of the piano. But in the 20th century, it made a resurgence, being used in historically informed performance of older music, in new (contemporary) compositions, and in popular culture.
Mechanism.
Harpsichords vary in size and shape, but all have the same basic functional arrangement. The player depresses a key that rocks over a pivot in the middle of its length. The other end of the key lifts a jack (a long strip of wood) that holds a small plectrum (a wedge-shaped piece of quill, nowadays often plastic), which plucks the string. When the player releases the key, the far end returns to its rest position, and the jack falls back. The plectrum, mounted on a tongue that can swivel backwards away from the string, passes the string without plucking it again. As the key reaches its rest position, a felt damper atop the jack stops the string's vibrations. These basic principles are explained in detail below.
Strings, tuning, and soundboard.
Each string is wound around a "tuning pin", normally at the end of the string closer to the player. When rotated with a wrench or tuning hammer, the tuning pin adjusts the tension so that the string sounds the correct pitch. Tuning pins are held tightly in holes drilled in the "pinblock" or "wrestplank", an oblong hardwood plank.
Proceeding from the tuning pin, a string next passes over the "nut", a sharp edge that is made of hardwood and is normally attached to the wrestplank. The section of the string beyond the nut forms its "vibrating length", which is plucked and creates sound.
At the other end of its vibrating length, the string passes over the bridge, another sharp edge made of hardwood. As with the nut, the horizontal position of the string along the bridge is determined by a vertical metal pin inserted into the bridge, against which the string rests.
The bridge itself rests on a "soundboard", a thin panel of wood usually made of spruce, fir or—in some Italian harpsichords—cypress. The soundboard efficiently transduces the vibrations of the strings into vibrations in the air; without a soundboard, the strings would produce only a very feeble sound.
A string is attached at its far end by a loop to a "hitchpin" that secures it to the case.
Multiple choirs of strings.
While many harpsichords have exactly one string per note, more elaborate harpsichords can have more. This provides two advantages: ability to vary volume and ability to vary tonal quality. Volume is increased when the mechanism of the instrument is set up by the player (see below) so that the press of a single key plucks more than one string. Tonal quality can be varied in two ways. First, different choirs of strings can be designed to have distinct tonal qualities, usually by having one set of strings plucked closer to the nut, which emphasizes the higher harmonics, and produces a "nasal" sound quality; the mechanism of the instrument permits the player to select one choir or the other. Second, having one key pluck two strings at once changes not just volume but also tonal quality; for instance, when two strings tuned to the same pitch are plucked simultaneously, the note is not just louder but also richer and more complex. A particularly vivid effect is obtained when the strings plucked simultaneously are an octave apart. This is normally heard by the ear not as two pitches but as one: the sound of the higher string is blended with that of the lower one, and the ear hears the lower pitch, enriched in tonal quality by the additional strength in the upper harmonics of the note sounded by the higher string.
When describing a harpsichord it is customary to specify its choirs of strings, often called its disposition. Strings at eight foot pitch sound at the normal expected pitch, strings at four foot pitch sound an octave higher. Harpsichords occasionally include a sixteen-foot choir (one octave lower than eight-foot) or a two-foot choir (two octaves higher; quite rare).
When there are multiple choirs of strings, the player is often able to control which choirs sound. This is usually done by having a set of jacks for each choir, and a mechanism for "turning off" each set, often by moving the upper register (through which the jacks slide) sideways a short distance, so that their plectra miss the strings. In simpler instruments this is done by manually moving the registers, but as the harpsichord evolved, builders invented levers, knee levers and pedal mechanisms to make it easier to change registration.
Harpsichords with more than one keyboard provide flexibility in selecting which strings play, since each manual can control the plucking of a different set of strings. In addition, such harpsichords often have a mechanism that couples manuals together, so that a single manual plays both sets of strings. The most flexible system is the French shove coupler, in which the lower manual slides forward and backward. In the backward position, "dogs" attached to the upper surface of the lower manual engage the lower surface of the upper manual's keys. Depending on choice of keyboard and coupler position, the player can select any of the sets of jacks labeled in figure 4 as A, or B and C, or all three.
The English dogleg jack system (also used in Baroque Flanders) does not require a coupler. The jacks labeled A in Figure 5 have a "dogleg" shape that permits either keyboard to play A. If the player wishes to play the upper 8' from the upper manual only and not from the lower manual, a stop handle disengages the jacks labeled A and engages instead an alternative row of jacks called "lute stop" (not shown in the Figure).
The use of multiple manuals in a harpsichord was not originally provided for the flexibility in choosing which strings would sound, but rather for transposition. For discussion, see "History of the harpsichord".
Case.
The case holds in position all of the important structural members: pinblock, soundboard, hitchpins, keyboard, and the jack action. It usually includes a solid bottom, and also internal bracing to maintain its form without warping under the tension of the strings. Cases vary greatly in weight and sturdiness: Italian harpsichords are often of light construction; heavier construction is found in the later Flemish instruments and those derived from them (see "History of the harpsichord").
The case also gives the harpsichord its external appearance and protects the instrument. A large harpsichord is, in a sense, a piece of furniture, as it stands alone on legs and may be styled in the manner of other furniture of its place and period. Early Italian instruments, on the other hand, were so light in construction that they were treated rather like a violin: kept for storage in a protective outer case, and played after taking it out of its case and placing it on a table. Such tables were often quite high – until the late 18th century people usually played standing up. Eventually, harpsichords came to be built with just a single case, though an intermediate stage also existed: the "false inner–outer", which for purely aesthetic reasons was built to look as if the outer case contained an inner one, in the old style. Even after harpsichords became self-encased objects, they often were supported by separate stands, and some modern harpsichords have separate legs for improved portability.
Many harpsichords have a lid that can be raised, a cover for the keyboard, and a stand for music.
Harpsichords have been decorated in a great many different ways: with plain buff paint (e.g. some Flemish instruments), with paper printed with patterns, with leather or velvet coverings, with chinoiserie, or occasionally with highly elaborate painted artwork.
Variants.
Harpsichord.
In modern usage, "harpsichord" can mean any member of the family of instruments. More often, though, it specifically denotes a grand-piano-shaped instrument with a roughly triangular case accommodating long bass strings at the left and short treble strings at the right. The characteristic profile of such a harpsichord is more elongated than a modern piano, with a sharper curve to the bentside.
Virginals.
The virginal is a smaller and simpler rectangular form of the harpsichord having only one string per note; the strings run parallel to the keyboard, which is on the long side of the case.
Spinet.
A spinet is a harpsichord with the strings set at an angle (usually about 30 degrees) to the keyboard. The strings are too close together for the jacks to fit between them. Instead, the strings are arranged in pairs, and the jacks are in the larger gaps between the pairs. The two jacks in each gap face in opposite directions, and each plucks a string adjacent to a gap.
The English diarist Samuel Pepys mentions his "tryangle" several times. This was not the percussion instrument that we call triangle today; rather, it was a name for octave-pitched spinets, which were triangular in shape.
Clavicytherium.
A clavicytherium is a harpsichord with the soundboard and strings mounted vertically facing the player, the same space-saving principle as an upright piano. In a clavicytherium, the jacks move horizontally without the assistance of gravity, so that clavicytherium actions are more complex than those of other harpsichords.
Clavicymbalum.
An early relative of the harpsichord, first attested in 1323, with an unusual jack system, and lacking any method to dampen a string once sounded.
Ottavino.
Ottavini are small spinets or virginals at four foot pitch. Harpsichords at octave pitch were more common in the early Renaissance, but lessened in popularity later on. However, the ottavino remained very popular as a domestic instrument in Italy until the 19th century. In the Low Countries, an ottavino was commonly paired with an 8' virginals, encased in a small cubby under the soundboard of the larger instrument. The ottavino could be removed and placed on top of the virginal, making in effect a double manual instrument. These are sometimes called 'mother-and-child' or 'double' virginals.
Other.
The archicembalo, built in the 16th century, had an unusual keyboard layout, designed to accommodate variant tuning systems demanded by compositional practice and theoretical experimentation. More common were instruments with split sharps, also designed to accommodate the tuning systems of the time.
The folding harpsichord was an instrument that could be folded up for travel.
Pedal Harpsichord: Occasionally, harpsichords were built which included another set or sets of strings underneath and operated by pedals which pluck the lowest keys of the harpsichord. Although there are no known extant pedal harpsichords from the 18th century or before, from Adlung (1758): the lower set of usually 8' strings "...is built like an ordinary harpsichord, but with an extent of two octaves only. The jacks are similar, but they will benefit from being arranged back to back, since the two octaves take as much space as four in an ordinary harpsichord Prior to 1980 when Keith Hill introduced his design for a pedal harpsichord, most pedal harpsichords were built based on the designs of extant pedal pianos from the 19th century, in which the instrument is as wide as the pedalboard. While these were mostly intended as practice instruments for organists, a few pieces are believed to have been written specifically for the pedal harpsichord. However, the set of pedals can augment the sound from any piece performed on the instrument, as demonstrated on several albums by E. Power Biggs.
Compass and pitch range.
On the whole, earlier harpsichords have smaller ranges than later ones, although there are many exceptions. The largest harpsichords have a range of just over five octaves, and the smallest have under four. Usually, the shortest keyboards were given extended range in the bass with a "short octave". The traditional pitch range for a 5-octave instrument is F1 - F6 (FF - f3).
Tuning pitch is often taken to be a=415 Hz, roughly a semitone lower than the modern standard concert pitch of a=440 Hz. An accepted exception is for French baroque repertoire, which is often performed with a=392 Hz, approximately a semitone lower again. See Jean-Philippe Rameau's "Treatise on Harmony" (1722) Publications, Book One, chapter five, for insight into French baroque tuning; "Since most of these semitones are absolutely necessary in the tuning of organs and other similar instruments, the following chromatic system has been drawn up." Tuning an instrument nowadays usually starts with setting an A; historically it would commence from a C or an F.
Some modern instruments are built with keyboards that can shift sideways, allowing the player to align the mechanism with strings at either a=415 Hz or a=440 Hz. If a tuning other than equal temperament is used, the instrument requires retuning once the keyboard is shifted.
History.
The harpsichord was most probably invented in the late Middle Ages. By the 16th century, harpsichord makers in Italy were making lightweight instruments with low string tension. A different approach was taken in the Southern Netherlands starting in the late 16th century, notably by the Ruckers family. Their harpsichords used a heavier construction and produced a more powerful and distinctive tone. They included the first harpsichords with two keyboards, used for transposition.
The Flemish instruments served as the model for 18th century harpsichord construction in other nations. In France, the double keyboards were adapted to control different choirs of strings, making a more musically flexible instrument. Instruments from the peak of the French tradition, by makers such as the Blanchet family and Pascal Taskin, are among the most widely admired of all harpsichords, and are frequently used as models for the construction of modern instruments. In England, the Kirkman and Shudi firms produced sophisticated harpsichords of great power and sonority. German builders extended the sound repertoire of the instrument by adding sixteen foot and two foot choirs; these instruments have recently served as models for modern builders.
In the late 18th century the harpsichord was supplanted by the piano and almost disappeared from view for most of the 19th century: an exception was its continued use in opera for accompanying recitative, but the piano sometimes displaced it even there. Twentieth century efforts to revive the harpsichord began with instruments that used piano technology, with heavy strings and metal frames. Starting in the middle of the 20th century, ideas about harpsichord making underwent a major change, when builders such as Frank Hubbard, William Dowd, and Martin Skowroneck sought to re-establish the building traditions of the Baroque period. Harpsichords of this type of historically informed building practice dominate the current scene.
Music for the harpsichord.
Historical period.
The great bulk of the standard repertoire for the harpsichord was written during its first historical flowering, the Renaissance and Baroque eras.
The first music written specifically for solo harpsichord was published around the early 16th century. Composers who wrote solo harpsichord music were numerous during the whole Baroque era in European countries including Italy, Germany, England and France. Solo harpsichord compositions included dance suites, fantasias, and fugues. Among the most famous composers who wrote for the harpsichord were the members of English virginal school of the late Renaissance, notably William Byrd (ca. 1540 – 1623). In France, a great number of highly characteristic solo works were created and compiled into four books of "ordres" by François Couperin (1668–1733). Domenico Scarlatti (1685–1757) began his career in Italy but wrote most of his solo harpsichord works in Spain; his most famous work is his series of 555 harpsichord sonatas. Perhaps the most celebrated composer who wrote for the harpsichord was J. S. Bach (1685–1750), whose solo works (for instance, the Well-Tempered Clavier and the Goldberg Variations), continue to be performed very widely, often on the piano. Bach was also a pioneer of the harpsichord concerto, both in works designated as such, and in the harpsichord part of his Fifth Brandenburg Concerto.
Two of the most prominent composers of the Classical era, Joseph Haydn (1732–1809) and Wolfgang Amadeus Mozart (1756–1791), wrote harpsichord music. For both, the instrument featured in the earlier period of their careers and was abandoned once they had shifted their efforts to the piano.
Besides solo works, the historical harpsichord was widely used for accompaniment in the basso continuo style (a function it maintained in operatic recitative even into the 19th century).
Music written for the revived harpsichord.
Through the 19th century, the harpsichord was almost completely supplanted by the piano. In the 20th century, composers returned to the instrument, as they sought out variation in the sounds available to them. Under the influence of Arnold Dolmetsch, the harpsichordists Violet Gordon-Woodhouse (1872–1951) and in France, Wanda Landowska (1879–1959), were at the forefront of the instrument's renaissance. Concertos for the instrument were written by Francis Poulenc (the "Concert champêtre", 1927–28), and Manuel de Falla. Elliott Carter's "Double Concerto" is scored for harpsichord, piano and two chamber orchestras. For a detailed account of music composed for the revived harpsichord, see "Contempory harpsichord".

</doc>
