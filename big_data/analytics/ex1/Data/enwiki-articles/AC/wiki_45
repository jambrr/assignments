<doc id="15214" url="https://en.wikipedia.org/wiki?curid=15214" title="Irish Civil War">
Irish Civil War

The Irish Civil War (; 28 June 1922 – 24 May 1923) followed the Irish War of Independence and accompanied the establishment of the Irish Free State, an entity independent from the United Kingdom but within the British Empire.
The conflict was waged between two opposing groups, Irish republicans and Irish nationalists over the Anglo-Irish Treaty. The forces of the Provisional Government (which became the Free State in December 1922) supported the Treaty, while the Republican opposition saw it as a betrayal of the Irish Republic (which had been proclaimed during the Easter Rising). Many of those who fought in the conflict had been members of the Irish Republican Army (IRA) during the War of Independence.
The Civil War was won by the Free State forces, which were heavily armed with weapons provided by the British Government. The conflict may have claimed more lives than the War of Independence that preceded it, and left Irish society divided and embittered for generations. Today, two of the main political parties in the Republic of Ireland, Fianna Fáil and Fine Gael, are direct descendants of the opposing sides of the war.
Background.
The treaty and its consequences.
The Anglo-Irish Treaty was agreed to end the 1919-1921 Irish War of Independence between the Irish Republic and the United Kingdom of Great Britain and Ireland. The treaty provided for a self-governing Irish state, having its own army and police. The Treaty also allowed Northern Ireland (the six north-eastern countiesFermanagh, Antrim, Tyrone, Londonderry, Armagh and Down where the majority population was of the Protestant religion) to opt out of the new state and return to the United Kingdomwhich it did immediately. However, rather than creating the independent republic favoured by most nationalists, the Irish Free State would be an autonomous dominion of the British Empire with the British monarch as head of state, in the same manner as Canada and Australia. The British suggested this dominion in secret correspondence even before treaty negotiations began, but Sinn Féin leader Eamon de Valera rejected the dominion. The treaty also stipulated that members of the new Irish Oireachtas (parliament) would have to take the following "Oath of Allegiance"
This oath was highly objectionable to many Irish Republicans. Furthermore, the partition of Ireland, which had already been decided by the Westminster parliament in the Government of Ireland Act 1920, was effectively confirmed in the Anglo-Irish treaty. The most contentious areas of the Treaty for the IRA were the disestablishment of the Irish Republic declared in 1919, the abandonment of the First Dáil, the status of the Irish Free State as a dominion in the British Commonwealth and the British retention of the so-called strategic Treaty Ports on Ireland's south coast which were to remain occupied by the Royal Navy. All these issues were the cause of a split in the IRA and ultimately civil war.
Michael Collins, the republican leader who had led the Irish negotiating team, argued that the treaty gave "not the ultimate freedom that all nations aspire and develop, but the freedom to achieve freedom". However, anti-treaty militants in 1922 believed that the treaty would never deliver full Irish independence.
Split in the Nationalist movement.
The split over the treaty was deeply personal. Many of the leaders on both sides had been close friends and comrades during the War of Independence. This made their disagreement over the treaty all the more bitter. Michael Collins later said that Éamon de Valera had sent him as plenipotentiary to negotiate the treaty because he knew that the British would not concede an independent Irish republic and wanted Collins to take the blame for the compromise settlement. He said that he felt deeply betrayed when de Valera refused to stand by the agreement that the plenipotentiaries had negotiated with David Lloyd George and Winston Churchill. De Valera, for his part, was furious that Collins and Arthur Griffith had signed the treaty without consulting him or the Irish cabinet as instructed.
Dáil Éireann (the parliament of the Irish Republic) narrowly passed the Anglo-Irish Treaty by 64 votes to 57 on 7 January 1922. Following the Treaty's ratification, in accordance with article 17 of the Treaty, the British-recognised Provisional Government of the Irish Free State was established. Its authority under the Treaty was to provide a "provisional arrangement for the administration of Southern Ireland during the interval" before the establishment of the Irish Free State. In accordance with the Treaty, the British Government transferred "the powers and machinery requisite for the discharge of its duties". Before the British Government transferred such powers, the members of the Provisional Government each "signified in writing acceptance of [the Treaty".
Upon the Treaty's ratification, de Valera resigned as President of the Republic and failed to be re-elected by an even closer vote of 60–58. He challenged the right of the Dáil to approve the treaty, saying that its members were breaking their oath to the Irish Republic. De Valera continued to promote a compromise whereby the new Irish Free State would be in "external association" with the British Commonwealth rather than be a member of it (the inclusion of republics within the Commonwealth of Nations was not formally implemented until 1949).
In early March, he formed the "Cumann na Poblachta" (Republican Association) party while remaining a member of Sinn Féin and commenced a speaking tour of the more republican province of Munster on 17 March 1922. During the tour, de Valera made controversial speeches at Carrick on Suir, Lismore, Dungarvan and Waterford, saying at one point, "If the Treaty were accepted, the fight for freedom would still go on, and the Irish people, instead of fighting foreign soldiers, will have to fight the Irish soldiers of an Irish government set up by Irishmen." At Thurles, several days later, he repeated this imagery and added that the IRA "would have to wade through the blood of the soldiers of the Irish Government, and perhaps through that of some members of the Irish Government to get their freedom." de Valera stated in a speech n Killarney in March 1922, that if the Treaty was accepted by the electorate,"IRA men will have to march over the dead bodies of their own brothers. They will have to wade through Irish blood."</ref>
In a letter to the Irish Independent on 23 March, de Valera accepted the accuracy of their report of his comment about "wading" through blood, but deplored that the newspaper had published it.
More seriously, many Irish Republican Army (IRA) officers were also against the treaty, and in March 1922 an ad hoc Army Convention repudiated the authority of the Dáil to accept the treaty. In contrast, the Minister of Defence, Richard Mulcahy, stated in the Dáil on 28 April that conditions in Dublin had prevented a Convention from being held, but that delegates had been selected and voted by ballot to accept the Oath.MR. MULCAHY:...(h) It was proposed to submit the proposed Constitution to a specially summoned Convention of the Irish Volunteers. That Convention was not held because no single member of the Volunteer Executive of the time would recommend the holding of that Convention in the circumstances that then existed in Dublin. Delegates for this Convention were actually selected but the Convention was not held. Ballot papers were circulated to the delegates and a vote was taken as far as the question of the Oath was concerned. As far as this question was concerned, the amendment to the constitution was accepted.</ref> The anti-Treaty IRA formed their own "Army Executive", which they declared to be the real government of the country, despite the result of the 1921 general election. On 26 April, the Minister of Defence, Richard Mulcahy, summarised alleged illegal activities by many IRA men over the previous three months, whom he described as 'seceding volunteers', including hundreds of robberies. Yet this fragmenting army was the only police force on the ground following the disintegration of the Irish Republican Police and the disbanding of the Royal Irish Constabulary (RIC).
By putting ten questions to General Mulcahy on 28 April, Seán McEntee argued that the Army Executive had acted continuously on its own to create a republic since 1917, had an unaltered constitution, had never fallen under the control of the Dáil, and that: ""the only body competent to dissolve the Volunteer Executive was a duly convened convention of the Irish Republican Army"" – not the Dáil. By accepting the treaty in January and abandoning the republic, the Dáil majority had effectively deserted the Army Executive. In his reply, Mulcahy rejected this interpretation. Then, in a debate on defence, McEntee suggested that supporting the Army Executive ""... even if it meant the scrapping of the Treaty and terrible and immediate war with England, would be better than the civil war which we are beginning at present apparently."" McEntee's supporters added that the many robberies complained of by Mulcahy on 26 April were caused by the lack of payment and provision by the Dáil to the volunteers.
Delay until the June election.
Collins established an "army re-unification committee" to re-unite the IRA and organised an election pact with de Valera's anti-treaty political followers to campaign jointly in the Free State's first election in 1922 and form a coalition government afterwards. He also tried to reach a compromise with anti-treaty IRA leaders by agreeing to a republican-type constitution (with no mention of the British monarchy) for the new state. IRA leaders such as Liam Lynch were prepared to accept this compromise. However, the proposal for a republican constitution was vetoed by the British as being contrary to the terms of the treaty and they threatened military intervention in the Free State unless the treaty were fully implemented.Michael Hopkinson, "Green Against Green", p. 107, "Winston Churchill told a concerned House of Commons... that a Republic could not be tolerated. He warned that, 'in the event of such a Republic, it will be the intention of the Government to hold Dublin as one of the preliminary essential steps to military operations'.</ref> Collins reluctantly agreed. This completely undermined the electoral pact between the pro- and anti-treaty factions, who went into the Irish general election on 18 June 1922 as hostile parties, both calling themselves Sinn Féin.
The Pro-Treaty Sinn Féin party won the election with 239,193 votes to 133,864 for Anti-Treaty Sinn Féin. A further 247,226 people voted for other parties, most of whom supported the Treaty. Labour's 132,570 votes were ambiguous with regard to the Treaty. According to Hopkinson, "Irish labour and union leaders, while generally pro-Treaty, made little attempt to lead opinion during the Treaty conflict, casting themselves rather as attempted peacemakers." The election showed that a majority of the Irish electorate accepted the treaty and the foundation of the Irish Free State, but de Valera, his political followers and most of the IRA continued to oppose the treaty. De Valera is quoted as saying, "the majority have no right to do wrong".
Meanwhile, under the leadership of Michael Collins and Arthur Griffith, the pro-treaty Provisional Government set about establishing the Irish Free State, and organised the National Army – to replace the IRA – and a new police force. However, since it was envisaged that the new army would be built around the IRA, Anti-Treaty IRA units were allowed to take over British barracks and take their arms. In practice, this meant that by the summer of 1922, the Provisional Government of Southern Ireland controlled only Dublin and some other areas like County Longford where the IRA units supported the treaty. Fighting ultimately broke out when the Provisional Government tried to assert its authority over well-armed and intransigent Anti-Treaty IRA units around the country – particularly a hardline group in Dublin.
Course of the war.
Dublin fighting.
On 14 April 1922, 200 Anti-Treaty IRA militants, led by Rory O'Connor, occupied the Four Courts and several other buildings in central Dublin, resulting in a tense stand-off. These anti-treaty Republicans wanted to spark a new armed confrontation with the British, which they hoped would unite the two factions of the IRA against their common enemy. However, for those who were determined to make the Free State into a viable, self-governing Irish state, this was an act of rebellion that would have to be put down "by them" rather than the British.
Arthur Griffith was in favour of using force against these men immediately, but Michael Collins, who wanted at all costs to avoid civil war, left the Four Courts garrison alone until late June 1922. By this point, the Pro-Treaty Sinn Féin party had secured a large majority in the general election, along with other parties that supported the Treaty. Collins was also coming under continuing pressure from London to assert his government's authority in his capital.
The British lost patience as a result of an action which may have been secretly ordered by Collins. He had Henry Hughes Wilson, a retired British Army field marshal and a prominent security advisor to the Prime Minister of Northern Ireland James Craig, assassinated in London on 22 June because of his role in Northern Ireland.
ME Collins, "Ireland 1868–1966", p. 229, "Evidence has since come to light proving it was Collins, enraged by Wilson's role in the north, who ordered the killing".
Niall C. Hartigan, "The Kerry Landings", p. 29, "It is probable that the execution of the ... field marshal was ordered by Collins".</ref>
Winston Churchill assumed that the Anti-Treaty IRA were responsible for the killing and warned Collins that he would use British troops to attack the Four Courts unless the Provisional Government took action. In fact, the British cabinet actually resolved to attack the Four Courts themselves on 25 June, in an operation that would have involved tanks, howitzers and aeroplanes. However, on the advice of General Nevil Macready, who commanded the British garrison in Dublin, the plan was cancelled at the last minute. Macready's argument was that British involvement would have united Irish Nationalist opinion against the treaty, and instead Collins was given a last chance to clear the Four Courts himself.
The final straw for the Free State government came on 26 June, when the Four Courts republican garrison kidnapped JJ "Ginger" O'Connell, a general in the new National Army. Collins, after giving the Four Courts garrison a final ultimatum to leave the building on 27 June, decided to end the stand-off by bombarding the Four Courts garrison into surrender. The government then appointed Collins as Commander-in-Chief of the National Army. This attack was not the opening shot of the war, as skirmishes had taken place between pro- and anti-treaty IRA factions throughout the country when the British were handing over the barracks. However, this represented the 'point of no return', when all-out war was "ipso facto" declared and the Civil War officially began.
Collins ordered Mulcahy to accept a British offer of two 18-pdr field artillery for use by the new army of the Free State, though General Macready gave just 200 shells of the 10,000 he had in store at Richmond barracks in Inchicore. The anti-treaty forces in the Four Courts, who possessed only small arms, surrendered after two days of bombardment and the storming of the building by Provisional Government troops (28–30 June 1922). Shortly before the surrender, a massive explosion destroyed the western wing of the complex, including the Irish Public Record Office (PRO), injuring many advancing Free State soldiers and destroying the records. Government supporters alleged that the building had been deliberately mined. Historians dispute whether the PRO was intentionally destroyed by mines laid by the Republicans on their evacuation or if the explosions occurred when their ammunition store was accidentally ignited by the bombardment.
Pitched battles continued in Dublin until 5 July, as Anti-Treaty IRA units from the Dublin Brigade, led by Oscar Traynor, occupied O'Connell Street – provoking a week's more street fighting: costing both sides 65 killed and 280 wounded. Among the dead was Republican leader Cathal Brugha, who made his last stand after exiting the Granville Hotel. In addition, the Free State took over 500 Republican prisoners. The civilian casualties are estimated to have numbered well over 250. When the fighting in Dublin died down, the Free State government was left firmly in control of the Irish capital and the anti-treaty forces dispersed around the country, mainly to the south and west.
The opposing forces.
The outbreak of the Civil War forced pro- and anti-treaty supporters to choose sides. Supporters of the treaty came to be known as "pro-treaty" or Free State Army, legally the National Army, and were often called "Staters" by their opponents. The latter called themselves Republicans and were also known as "anti-treaty" forces, or Irregulars, a term preferred by the Free State side.
The Anti-Treaty IRA claimed that it was defending the Irish Republic declared in 1916 during the Easter Rising, confirmed by the First Dáil and invalidly set aside by those who accepted the compromise of the Free State. Éamon de Valera stated that he would serve as an ordinary IRA volunteer and left the leadership of the Anti-Treaty Republicans to military leaders such as Liam Lynch, the IRA Chief of Staff. De Valera despite being the nominal leader had little control over military operations. Military operations were directed by Liam Lynch until he was killed on 10 April 1923 and then by Frank Aiken. The republican Irregulars that fought against the Free State were virtually all the same men who fought in the IRA during the War of Independence and thus used the same organisational structure, ranks and tactics as during the preceding conflict. At the beginning of the war in June 1922, the IRA had 6,780 rifles and 12,900 men. A major difficulty for the IRA was a shortage of arms. To secure weapons, the IRA either had to capture from the National Army or buy arms overseas. To pay for the arms, the IRA resorted to bank robberies and in the spring of 1922 in the run-up to the conflict the IRA committed 650 bank robberies. During the first phrase of the war, the IRA's strategy was to seize control of key urban centers. In the second phrase in the summer of 1922 the IRA attempted to defeat the National Army in the field and finally in the third phrase returned to guerilla warfare.
The Civil War split the IRA. When the Civil War broke out, the Anti-Treaty IRA (concentrated in the south and west) outnumbered the pro-Free State forces by roughly 15,000 men to 7,000 or over 2-1. The paper strength of the IRA in early 1922 was over 72,000 men, but most of them were recruited during the truce with the British and fought in neither the War of Independence nor the Civil War.
However, the Anti-Treaty IRA lacked an effective command structure, a clear strategy and sufficient arms. They started the war with only 6,780 rifles and a handful of machine guns. Many of their fighters were armed only with shotguns. They also took a handful of armoured cars from British troops as they were evacuating the country. Finally, they had no artillery of any kind. As a result, they were forced to adopt a defensive stance throughout the war.
By contrast, the Free State government managed to expand its forces dramatically after the start of the war. Michael Collins and his commanders were able to build up an army that was able to overwhelm their opponents in the field. British supplies of artillery, aircraft, armoured cars, machine guns, small arms, and ammunition were of much help to pro-treaty forces. The National Army amounted to 14,000 men by August 1922, was 38,000 strong by the end of 1922, and by the end of the war had grown to 55,000 men and 3,500 officers, far in excess of what the Irish state would need to maintain in peacetime. Like the Irregulars, the Free State's National Army was rooted in the IRA that fought against the British. The British government supplied weapons to the National Army on a generous scale, which could thus bring significantly far more firepower to bear. In July 1922, the Dáil voted to raise an army of some 35,000 men, but as the war continued the Free State had raised 53,000 men by May 1923. A major problem for the National Army was a shortage of experienced officers. At least 20% of the National Army's officers had previously served as officers in the British Army while 50% of the rank and file of the National Army had served in the British Army in World War I. The shortage of experienced officers which led to problems with logistics, administration and training together with the fact that at least 50% of the other ranks had no military experience in turn led to ill-discipline becoming a major problem. The most effective unit in the National Army was the elite Dublin Guards, which comprised men who had previously served in Collins's assassination unit known as "the Squad" or in the Royal Dublin Fusiliers regiment of the British Army.
Collins' most ruthless officers and men were recruited from the Dublin Active Service Unit (the elite unit of the IRA's Dublin Brigade), which Collins had commanded in the Irish War of Independence and in particular from his assassination unit, The Squad. In the new National Army, they were known as the Dublin Guard. Towards the end of the war, they were implicated in some notorious atrocities against anti-treaty guerrillas. Most of the National Army's officers were pro-Treaty IRA men, as were a substantial number of their soldiers. However, many of the new army's other recruits were unemployed veterans of World War I, where they had served in Irish Divisions of the British Army. Former British Army officers were also recruited for their technical expertise. A number of the senior Free State commanders, such as Emmet Dalton, John T. Prout, and W.R.E. Murphy, had seen service as officers in World War One, Dalton and Murphy in the British Army and Prout in the US Army. The ex-veterans brought considerable combat experience with them and, by May 1923, comprised 50 per cent of its 53,000 soldiers and 20 per cent of its officers. The Republicans made much use of this fact in their propaganda — claiming that the Free State was only a proxy force for Britain itself. However, in fact, the remaining Free State soldiers were raw recruits without military experience in either World War I or the Irish War of Independence. Former members of the British Armed Forces on the Republican side included Tom Barry and Erskine Childers.
The Free State takes major towns.
With Dublin in pro-treaty hands, conflict spread throughout the country. The war started with the anti-treaty forces holding Cork, Limerick and Waterford as part of a self-styled Munster Republic. However, since the anti-treaty side were not equipped to wage conventional war, Liam Lynch was unable to take advantage of the Republicans' initial advantage in numbers and territory held. He hoped simply to hold the Munster Republic long enough to force Britain to re-negotiate the treaty.
The large towns in Ireland were all relatively easily taken by the Free State in August 1922. Michael Collins, Richard Mulcahy and Eoin O'Duffy planned a nationwide Free State offensive, dispatching columns overland to take Limerick in the west and Waterford in the south-east and seaborne forces to take counties Cork and Kerry in the south and Mayo in the west. In the south, landings occurred at Union Hall in Co. Cork and Fenit, the port of Tralee, in Co. Kerry. Limerick fell on 20 July, Waterford on the same day and Cork city on 10 August after a Free State force landed by sea at Passage West. Another seaborne expedition to Mayo in the west secured government control over that part of the country. While in some places the Republicans had put up determined resistance, nowhere were they able to defeat regular forces armed with artillery and armour. The only real conventional battle during the Free State offensive, the Battle of Killmallock, was fought when Free State troops advanced south from Limerick.
Guerrilla war.
Government victories in the major towns inaugurated a period of guerrilla warfare. After the fall of Cork, Liam Lynch ordered Anti-Treaty IRA units to disperse and form flying columns as they had when fighting the British. They held out in areas such as the western part of counties Cork and Kerry in the south, county Wexford in the east and counties Sligo and Mayo in the west. Sporadic fighting also took place around Dundalk, where Frank Aiken and the Fourth Northern Division of the Irish Republican Army were based, and Dublin, where small-scale but regular attacks were mounted on Free State troops.
August and September 1922 saw widespread attacks on Free State forces in the territories that they had occupied in the July–August offensive, inflicting heavy casualties on them. Commander-in-Chief Michael Collins was killed in an ambush by anti-treaty Republicans at Béal na mBláth, near his home in County Cork, in August 1922. Collins' death increased the bitterness of the Free State leadership towards the Republicans and probably contributed to the subsequent descent of the conflict into a cycle of atrocities and reprisals. Arthur Griffith, the Free State president, had also died of a brain haemorrhage ten days before, leaving the Free State government in the hands of W. T. Cosgrave and the Free State army under the command of General Richard Mulcahy. For a brief period, with rising casualties among its troops and its two principal leaders dead, it looked as if the Free State might collapse.
However, as winter set in, the republicans found it increasingly difficult to sustain their campaign, and casualty rates among National Army troops dropped rapidly. For instance, in County Sligo, 54 people died in the conflict, of whom all but eight had been killed by the end of September.
In the autumn and winter of 1922, Free State forces broke up many of the larger Republican guerrilla units – in Sligo, Meath, and Connemara in the west, for example, and in much of Dublin city. Elsewhere, Anti-Treaty units were forced by lack of supplies and safe-houses to disperse into smaller groups, typically of nine to ten men. Despite these successes for the National Army, it took eight more months of intermittent warfare before the war was brought to an end.
By late 1922 and early 1923, the Anti Treaty guerrillas' campaign had been reduced largely to acts of sabotage and destruction of public infrastructure such as roads and railways. It was also in this period that the Anti-Treaty IRA began burning the homes of Free State Senators and of many of the Anglo-Irish landed class.
In October 1922, Éamon de Valera and the anti-treaty TDs (Members of Parliament) set up their own "Republican government" in opposition to the Free State. However, by then the anti-treaty side held no significant territory and de Valera's "government" had no authority over the population. In any case, the IRA leaders paid no attention to it, seeing the Republican authority as vested in their own military leaders.
Atrocities and executions.
On 27 September 1922, three months after the outbreak of war, the Free State's Provisional Government put before the Dáil an Army Emergency Powers Resolution proposing legislation for setting up military tribunals, transferring most of the Free State's judicial powers over Irish citizens accused of anti-government activities to the Army Council. By instituting martial law, the first democratically elected Free State had in effect suspended most, if not all civil rights of the Irish population for the duration of the conflict. The legislation, commonly referred to as the Public Safety Bill, empowered military tribunals with the ability to impose life imprisonment, as well as the death penalty, for a variety of offences. By allowing appointed courts martial to execute any Irish citizen found in possession of firearms or ammunition, the Free State prevented Republican sympathizers from storing any arms or ammunition that could be used by Republican forces; possession of even a single sporting or civilian firearm or round of ammunition could result in execution by firing squad. Offenses included attacks on state policy or military forces, donning army or police uniforms, publication of "seditious publications", and membership in the Republican Army.
The final phase of the Civil War degenerated into a series of atrocities that left a lasting legacy of bitterness in Irish politics. The Free State began executing Republican prisoners on 17 November 1922, when five IRA men were shot by firing squad. They were followed on 24 November by the execution of acclaimed author and treaty negotiator Robert Erskine Childers. In all, the Free State sanctioned 77 official executions of anti-treaty prisoners during the Civil War. The Anti-Treaty IRA in reprisal assassinated TD Seán Hales.
On 7 December 1922, the day after Hales' killing, four prominent Republicans (one from each province), who had been held since the first week of the war—Rory O'Connor, Liam Mellows, Richard Barrett and Joe McKelvey — were executed in revenge for the killing of Hales. In addition, Free State troops, particularly in County Kerry, where the guerrilla campaign was most bitter, began the summary execution of captured anti-treaty fighters. The most notorious example of this occurred at Ballyseedy, where nine Republican prisoners were tied to a landmine, which was detonated, killing eight and only leaving one, Stephen Fuller, who was blown clear by the blast, to escape.
The number of "unauthorised" executions of Republican prisoners during the war has been put as high as 153. Among the Republican reprisals were the assassination of Kevin O'Higgins' father and WT Cosgrave's uncle in February 1923.
The Anti-Treaty IRA were unable to maintain an effective guerrilla campaign, given the gradual loss of support. The Catholic Church also supported the Free State, deeming it the lawful government of the country, denouncing the Anti-Treaty IRA and refusing to administer the Sacraments to anti-treaty fighters. On 10 October 1922, the Catholic Bishops of Ireland issued a formal statement, describing the anti-treaty campaign as:
Churchmen were appalled by the ruthlessness and cruelty. The Church's support for the Free State aroused bitter hostility among some republicans. Although the Catholic Church in independent Ireland has often been seen as a triumphalist Church, a recent study has found that it felt deeply insecure after these events.
End of the war.
By early 1923, the offensive capability of the Anti-Treaty IRA had been seriously eroded and when, in February 1923, the Republican leader Liam Deasy was captured by Free State forces, he called on the republicans to end their campaign and reach an accommodation with the Free State. The State's executions of Anti-Treaty prisoners, 34 of whom were shot in January 1923, also took its toll on the Republicans' morale.
In addition, the National Army's operations in the field were slowly but steadily breaking up the remaining Republican concentrations.
March and April 1923 saw this progressive dismemberment of the Republican forces continue with the capture and sometimes killing of guerrilla columns. A National Army report of 11 April stated, "Events of the last few days point to the beginning of the end as a far as the irregular campaign is concerned".
As the conflict petered out into a "de facto" victory for the pro-treaty side, de Valera asked the IRA leadership to call a ceasefire, but they refused. The Anti-Treaty IRA executive met on 26 March in County Tipperary to discuss the war's future. Tom Barry proposed a motion to end the war, but it was defeated by 6 votes to 5. Éamon de Valera was allowed to attend, after some debate, but was given no voting rights.
Liam Lynch, the Republican leader, was killed in a skirmish in the Knockmealdown Mountains in County Tipperary on 10 April. The National Army had extracted information from Republican prisoners in Dublin that the IRA Executive was in the area and as well as killing Lynch, they also captured senior Anti-Treaty IRA officers Dan Breen, Todd Andrews, Seán Gaynor and Frank Barrett in the operation.
It is often suggested that the death of Lynch allowed the more pragmatic Frank Aiken, who took over as IRA Chief of Staff, to call a halt to what seemed a futile struggle. Aiken's accession to IRA leadership was followed on 30 April by the declaration of a ceasefire on behalf of the anti-treaty forces. On 24 May 1923, Aiken followed this with an order to IRA volunteers to dump arms rather than surrender them or continue a fight that they were incapable of winning.
Aftermath of the ceasefire.
Éamon de Valera supported the order, issuing a statement to Anti-Treaty fighters on 24 May:
The Free State government had started peace negotiations in early May, which broke down. The High Court of Justice in Ireland ruled on 31 July 1923 that a state of war no longer existed, and consequently the internment of republicans, permitted under common law only in wartime, was now illegal. Without a formal peace, holding 13,000 prisoners and worried that fighting could break out again at any time, the government enacted two Public Safety (Emergency Powers) Acts on 1 and 3 August 1923, to permit continued internment and other measures. Thousands of Anti-Treaty IRA members (including Éamon de Valera on 15 August) were arrested by the Free State forces in the weeks and months after the end of the war, when they had dumped their arms and returned home.
On 27 August 1923, a general election was held, which Cumann na nGaedheal, the pro-Free State party, won with about 40% of the first-preference vote. The Republicans, represented by Sinn Féin, won about 27% of the vote. Many of their candidates and supporters were still imprisoned before, during and after the election.
In October 1923, around 8,000 of the 12,000 Republican prisoners in Free State gaols went on a hunger strike. The strike lasted for 41 days and met little success (among those who died were Denny Barry and Andy O'Sullivan). However, most of the women prisoners were released shortly thereafter and the hunger strike helped concentrate the Republican movement on the prisoners and their associated organisations. In July, de Valera had recognised the Republican political interests lay with the prisoners and went so far as to say:
Attacks on former Loyalists.
Although the cause of the Civil War was the Treaty, as the war developed the Republicans sought to identify their actions with the traditional Republican cause of the "men of no property" and the result was that large Anglo-Irish landowners and some less well-off former Protestant Loyalists were attacked. A total of 192 "stately homes" of the old landed class were destroyed by Republicans during the war.
The stated reason for such attacks was that some landowners had become Free State senators. In October 1922, a deputation of Southern Unionists met W.T. Cosgrave to offer their support to the Free State and some of them had received positions in the State's Upper house or Senate. Among the prominent senators whose homes were attacked were: Palmerstown House near Naas, which belonged to the Earl of Mayo, Moore Hall in Mayo, Horace Plunkett (who had helped to establish the rural co-operative schemes), and Senator Henry Guinness (which was unsuccessful). Also burned was Marlfield House in Clonmel, the home of Senator John Philip Bagwell with its extensive library of historical documents. Bagwell was kidnapped and held in the Dublin Mountains, but later released when reprisals were threatened.
However, in addition to their allegiance to the Free State, there were also other factors behind Republican animosity towards the old landed class. Many, but not all of these people, had supported the Crown forces during the War of Independence. This support was often largely moral, but sometimes it took the form of actively assisting the British in the conflict. Such attacks should have ended with the Truce of 11 July 1921, but they continued after the truce and escalated during the Civil War. In July 1922, Con Moloney, the anti-treaty IRA's Deputy Chief of Staff, ordered that unionist property should be seized to accommodate their men. The "worst spell" of attacks on former unionist property came in the early months of 1923, 37 "big houses" being burnt in January and February alone.
Though the Wyndham Act of 1903 allowed tenants to buy land from their landlords, some small farmers, particularly in Mayo and Galway, simply occupied land belonging to political opponents during this period when the RIC had ceased to function. In 1919, senior Sinn Féin officials were sufficiently concerned at this unilateral action that they instituted Arbitration Courts to adjudicate disputes. Sometimes these attacks had sectarian overtones, although most Anti-Treaty IRA men made no distinction between Catholic and Protestant supporters of the Irish government.
Controversy continues to this day about the extent of intimidation of Protestants at this time. Many left Ireland during and after the Civil War. Dr Andy Bielenberg of UCC considers that about 41,000 who were not linked to the former British administration left Southern Ireland (which became the Irish Free State) between 1919 and 1923. He has found that a "high-water mark" of this 41,000 left between 1921 and 1923. In all, from 1911 to 1926, the Protestant population of the 26 counties fell from some 10.4% of the total population to 7.4%.
Consequences.
Casualties.
The Civil War, though short, was bloody. It cost the lives of many public figures, including Michael Collins, Cathal Brugha, Arthur Griffith and Liam Lynch. Both sides carried out brutal acts: the anti-treaty forces murdered TDs and burned many historic homes, while the government executed anti-treaty prisoners, officially and unofficially.
Precise figures for the dead and wounded have yet to be calculated. The pro-treaty forces may have suffered between 540–800 fatalities, and the anti-treaty forces appear to have received considerably heavier losses. For total combatant and civilian deaths, a minimum of 1,000 and a maximum of 4,000 have been suggested.
The new police force was not involved in the war, which meant that it was well-placed to develop into an unarmed and politically neutral police service after the war. It had been disarmed by the Government in order to win public confidence in June–September 1922 and in December 1922, the IRA issued a General Order not to fire on the Civil Guard. The Criminal Investigation Department, or CID, a 350-strong, armed, plain-clothed Police Corps that had been established during the conflict for the purposes of counter-insurgency, was disbanded in October 1923, shortly after the conflict's end.
Economic costs.
The economic costs of the war were also high. As their forces abandoned their fixed positions in July–August 1922, the Republicans burned many of the administrative buildings and businesses that they had been occupying. In addition, their subsequent guerrilla campaign caused much destruction and the economy of the Free State suffered a hard blow in the earliest days of its existence as a result. The material damage caused by the war to property came to over £30 million. Particularly damaging to the Free State's economy was the systematic destruction of railway infrastructure and roads by the Republicans. In addition, the cost to the Free State of waging the war came to another £17 million. By September 1923, Deputy Hogan estimated the cost at £50 million. The new State ended 1923 with a budget deficit of over £4 million. This weakened financial situation meant that the new state could not pay its share of Imperial debt under the treaty. This adversely affected the boundary negotiations in 1924–25, in which the Free State government acquiesced that border with Northern Ireland would remain unchanged in exchange for forgiveness of the Imperial debt. Further, the state undertook to pay for damage caused to property between the truce of July 1921 and the end of the Civil War; W.T. Cosgrave told the Dáil:
Political results.
The fact that the Irish Civil War was fought between Irish Nationalist factions meant that the sporadic conflict in Northern Ireland ended. Collins and Sir James Craig signed an agreement to end it on 30 March 1922, but, despite this, Collins covertly supplied arms to the Northern IRA until a week before his death in August 1922. Because of the Irish Civil War, Northern Ireland was able to consolidate its existence and the partition of Ireland was confirmed for the foreseeable future. The continuing war also confirmed the northern Unionists' existing prejudices against the ethos of all shades of nationalism. This might have led to open hostilities between North and South had the Irish Civil War not broken out. Indeed, the Ulster Special Constabulary (the "B-Specials") that had been established in 1920 (on the foundation of Northern Ireland) was expanded in 1922 rather than being demobilised.
In the event, it was only well after their defeat in the Civil War that anti-treaty Irish Republicans seriously considered whether to take armed action against British rule in Northern Ireland (the first serious suggestion to do this came in the late 1930s). The northern units of the IRA largely supported the Free State side in the Civil War because of Collins's policies, and over 500 of them joined the new Free State's National Army.
The cost of the war and the budget deficit it caused was a difficulty for the new Free State and affected the Boundary Commission negotiations of 1925, which were to determine the border with Northern Ireland. The Free State agreed to waive its claim to predominantly Nationalist areas in Northern Ireland and in return its agreed share of the Imperial debt under the 1921 Treaty was not paid.
In 1926, having failed to persuade the majority of the Anti-Treaty IRA or the anti-treaty party of Sinn Féin to accept the new status quo as a basis for an evolving Republic, a large faction led by de Valera and Aiken left to resume constitutional politics and to found the Fianna Fáil party. Whereas Fianna Fáil was to become the dominant party in Irish politics, Sinn Féin became a small, isolated political party. The IRA, then much more numerous and influential than Sinn Féin, remained associated with Fianna Fáil (though not directly) until banned by de Valera in 1935.
In 1927, Fianna Fáil members took the Oath of Allegiance and entered the Dáil, effectively recognising the legitimacy of the Free State. The Free State was already moving towards independence by this point. Under the Statute of Westminster 1931, the British Parliament gave up its right to legislate for members of the British Commonwealth. When elected to power in 1932, Fianna Fáil under de Valera set about dismantling what they considered to be objectionable features of the treaty, abolishing the Oath of Allegiance, removing the power of the Office of Governor General (British representative in Ireland) and abolishing the Senate, which was dominated by former Unionists and pro-treaty Nationalists. In 1937, they passed a new constitution, which made a President the head of state, did not mention any allegiance to the British monarch, and which included a territorial claim to Northern Ireland. The following year, Britain returned without conditions the seaports that it had kept under the terms of the treaty. When the Second World War broke out in 1939, the Free State was able to demonstrate its independence by remaining neutral throughout the war, although Dublin did to some extent tacitly support the Allies. Finally, in 1948, a coalition government, containing elements of both sides in the Civil War (pro-treaty Fine Gael and anti-treaty Clann na Poblachta) left the British Commonwealth and renamed the Free State the Republic of Ireland. By the 1950s, the issues over which the Civil War had been fought were largely settled.
Legacy.
As with most civil wars, the internecine conflict left a bitter legacy, which continues to influence Irish politics to this day. The two largest political parties in the republic through most of its history (until the 2011 Irish General Election) were Fianna Fáil and Fine Gael, the descendants respectively of the anti-treaty and pro-treaty forces of 1922. Until the 1970s, almost all of Ireland's prominent politicians were veterans of the Civil War, a fact which poisoned the relationship between Ireland's two biggest parties. Examples of Civil War veterans include: Republicans Éamon de Valera, Frank Aiken, Todd Andrews, and Seán Lemass; and Free State supporters W. T. Cosgrave, Richard Mulcahy and Kevin O'Higgins. Moreover, many of these men's sons and daughters also became politicians, meaning that the personal wounds of the civil war were felt over three generations. In the 1930s, after Fianna Fáil took power for the first time, it looked possible for a while that the Civil War might break out again between the IRA and the pro-Free State Blueshirts. Fortunately, this crisis was averted, and by the 1950s violence was no longer prominent in politics in the Republic of Ireland.
However, the breakaway IRA continued (and continues in various forms) to exist. It was not until 1948 that the IRA renounced military attacks on the forces of the southern Irish state when it became the Republic of Ireland. After this point, the organisation dedicated itself primarily to the end of British rule in Northern Ireland. The IRA Army Council still makes claim to be the legitimate Provisional Government of the Irish Republic declared in 1918 and annulled by the Anglo-Irish Treaty of 1921.

</doc>
<doc id="15215" url="https://en.wikipedia.org/wiki?curid=15215" title="Internet Explorer">
Internet Explorer

Internet Explorer (formerly Microsoft Internet Explorer and Windows Internet Explorer, commonly abbreviated IE or MSIE) is a series of graphical web browsers developed by Microsoft and included as part of the Microsoft Windows line of operating systems, starting in 1995. It was first released as part of the add-on package Plus! for Windows 95 that year. Later versions were available as free downloads, or in service packs, and included in the Original Equipment Manufacturer (OEM) service releases of Windows 95 and later versions of Windows.
Internet Explorer was one of the most widely used web browsers, attaining a peak of about 95% usage share during 2002 and 2003. This came after it managed to win the first browser war against Netscape, which was the dominant browser in the 1990s. Its usage share has since declined with the launch of Firefox (2004) and Google Chrome (2008), and with the growing popularity of operating systems such as OS X, Linux, iOS and Android that do not run Internet Explorer. Estimates for Internet Explorer's overall market share range from 17.11% to 51.59% or by StatCounter's numbers ranked 3rd, just after Firefox (or even as low as 10.3% when counting all platforms, then after Safari), (browser market share is notoriously difficult to calculate). Microsoft spent over per year on Internet Explorer in the late 1990s, with over 1,000 people working on it by 1999.
Versions of Internet Explorer for other operating systems have also been produced, including an Xbox 360 version called Internet Explorer for Xbox and an embedded OEM version called Pocket Internet Explorer, later rebranded Internet Explorer Mobile made for Windows Phone, Windows CE, and previously, based on Internet Explorer 7 for Windows Mobile. It remains in development alongside the desktop versions. Internet Explorer for Mac and Internet Explorer for UNIX (Solaris and HP-UX) have been discontinued.
On March 17, 2015, Microsoft announced that Microsoft Edge will replace Internet Explorer as the default browser on its Windows 10 devices. This effectively makes Internet Explorer 11 the last release. Internet Explorer will, however, remain on some versions of Windows 10 primarily for enterprise purposes. Starting January 12, 2016, only the most recent version of Internet Explorer on each operating system is supported. Support varies based on the operating system's technical capabilities and its support lifecycle.
The browser has been scrutinized throughout its development for use of third-party technology (such as the source code of Spyglass Mosaic, used without royalty in early versions) and security and privacy vulnerabilities, and the United States and the European Union have alleged that integration of Internet Explorer with Windows has been to the detriment of fair browser competition.
History.
The Internet Explorer project was started in the summer of 1994 by Thomas Reardon, who, according to the Massachusetts Institute of Technology Review of 2003, used source code from Spyglass, Inc. Mosaic, which was an early commercial web browser with formal ties to the pioneering National Center for Supercomputing Applications (NCSA) Mosaic browser. In late 1994, Microsoft licensed Spyglass Mosaic for a quarterly fee plus a percentage of Microsoft's non-Windows revenues for the software. Although bearing a name similar to NCSA Mosaic, Spyglass Mosaic had used the NCSA Mosaic source code sparingly. Microsoft was sued by Synet Inc. in 1996, over the trademark infringement.
IE1 – IE8.
The first version of Internet Explorer, Microsoft Internet Explorer (later referred to as Internet Explorer 1) made its debut on August 16, 1995. It was a reworked version of Spyglass Mosaic, which Microsoft licensed from Spyglass Inc., like many other companies initiating browser development. It was installed as part of the "Internet Jumpstart Kit" in Microsoft Plus! for Windows 95 and Plus!. The Internet Explorer team began with about six people in early development. Internet Explorer 1.5 was released several months later for Windows NT and added support for basic table rendering. By including it free of charge on their operating system, they did not have to pay royalties to Spyglass Inc, resulting in a lawsuit and a US$8 million settlement on January 22, 1997.
Internet Explorer 8 is the last version of IE to be supported on Windows XP as Windows Vista is listed as a minimum requirements for Internet Explorer 9. This is because Windows XP does not support the minimum version of DirectX (version 10) that Internet Explorer 9 uses for hardware acceleration.
IE9.
Windows Internet Explorer 9 was released on March 14, 2011. Development for Internet Explorer 9 began shortly after the release of Internet Explorer 8. Microsoft first announced Internet Explorer 9 at PDC 2009, and spoke mainly about how it takes advantage of hardware acceleration in DirectX to improve the performance of web applications and quality of web typography. At MIX 10, Microsoft showed and publicly released the first Platform Preview for Internet Explorer 9, a frame for IE9's engine not containing any UI of the browser. Leading up to the release of the final browser, Microsoft released updated platform previews, each featuring improved JavaScript compiling (32-bit version), improved scores on the Acid3 test, as well as additional HTML5 standards support, approximately every 6 weeks. Ultimately, eight platform previews were released. The first public beta was released at a special event in San Francisco, which was themed around "the beauty of the web". The release candidate was released on February 10, 2011, and featured improved performance, refinements to the UI, and further standards support. The final version was released during the South by Southwest (SXSW) Interactive conference in Austin, Texas, on March 14, 2011.
Internet Explorer 9 is only supported on Windows Vista SP2, Windows 7, Windows Server 2008, and Windows Server 2008 R2. It supports several CSS 3 properties (including border-radius, box-shadow, etc.), and embedded ICC v2 or v4 colour profiles support via Windows Color System. The 32-bit version has faster JavaScript performance, this being due to a new JavaScript engine called "Chakra". It also features hardware accelerated graphics rendering using Direct2D, hardware-accelerated text rendering using DirectWrite, hardware-accelerated video rendering using Media Foundation, imaging support provided by Windows Imaging Component, and high fidelity printing powered by the XPS print pipeline. IE9 also supports the HTML5 video and audio tags and the Web Open Font Format. Internet Explorer 9 initially scored 95/100 on the Acid3 test, but has scored 100/100 since the test was updated in September 2011.
Internet Explorer was to be omitted from Windows 7 and Windows Server 2008 R2 in Europe, but Microsoft ultimately included it, with a browser option screen allowing users to select any of several web browsers (including Internet Explorer).
Internet Explorer is now available on Xbox 360 with Kinect support, as of October 2012.
IE10.
Internet Explorer 10 became generally available on October 26, 2012, alongside Windows 8 and Windows Server 2012. It became available for Windows 7 on February 26, 2013. Microsoft announced Internet Explorer 10 in April 2011, at MIX 11 in Las Vegas, releasing the first Platform Preview at the same time. At the show, it was said that Internet Explorer 10 was about 3 weeks in development. This release further improves upon standards support, including HTML5 Drag & Drop and CSS3 gradients. Internet Explorer 10 drops support for Windows Vista and will only run on Windows 7 Service Pack 1 and later.
Internet Explorer 10 Release Preview was also released on the Windows 8 Release Preview platform.
IE11.
Internet Explorer 11 is featured in a Windows 8.1 update which was released on October 17, 2013. It includes an incomplete mechanism for syncing tabs. It is a major update to its developer tools, enhanced scaling for high DPI screens, HTML5 prerender and prefetch, hardware-accelerated JPEG decoding, closed captioning, HTML5 full screen, and is the first Internet Explorer to support WebGL and Google's protocol SPDY (starting at v3).
Windows 8.1 only: cryptography (WebCrypto), adaptive bitrate streaming (Media Source Extensions), Encrypted Media Extensions.
Internet Explorer 11 was made available for Windows 7 users to download on November 7, 2013, with Automatic Updates in the following weeks.
Internet Explorer 11's user agent string now identifies the agent as "Trident" (the underlying layout engine) instead of "MSIE". It also announces compatibility with Gecko (the layout engine of Firefox).
Microsoft claims that Internet Explorer 11, running the WebKit SunSpider JavaScript Benchmark, is the fastest browser as of October 15, 2013.
Features.
Internet Explorer has been designed to view a broad range of web pages and provide certain features within the operating system, including Microsoft Update. During the heyday of the browser wars, Internet Explorer superseded Netscape only when it caught up technologically to support the progressive features of the time.
Standards support.
Internet Explorer, using the Trident layout engine:
Internet Explorer uses DOCTYPE sniffing to choose between standards mode and a "quirks mode" in which it deliberately mimicks nonstandard behaviours of old versions of MSIE for HTML and CSS rendering on screen (Internet Explorer always uses standards mode for printing). It also provides its own dialect of ECMAScript called JScript.
Internet Explorer was criticised by Tim Berners-Lee for its limited support for SVG which is promoted by W3C.
Non-standard extensions.
Internet Explorer has introduced an array of proprietary extensions to many of the standards, including HTML, CSS, and the DOM. This has resulted in a number of web pages that appear broken in standards-compliant web browsers and has introduced the need for a "quirks mode" to allow for rendering improper elements meant for Internet Explorer in these other browsers.
Internet Explorer has introduced a number of extensions to the DOM that have been adopted by other browsers. These include the innerHTML property, which provides access to the HTML string within an element ; the XMLHttpRequest object, which allows the sending of HTTP request and receiving of HTTP response, and may be used to perform AJAX; and the designMode attribute of the contentDocument object, which enables rich text editing of HTML documents . Some of these functionalities were not possible until the introduction of the W3C DOM methods. Its Ruby character extension to HTML is also accepted as a module in W3C XHTML 1.1, though it is not found in all versions of W3C HTML.
Microsoft submitted several other features of IE for consideration by the W3C for standardization. These include the 'behaviour' CSS property, which connects the HTML elements with JScript behaviours (known as HTML Components, HTC); HTML+TIME profile, which adds timing and media synchronization support to HTML documents (similar to the W3C XHTML+SMIL), and the VML vector graphics file format. However, all were rejected, at least in their original forms; VML was subsequently combined with PGML (proposed by Adobe and Sun), resulting in the W3C-approved SVG format, one of the few vector image formats being used on the web, which IE did not support until version 9.
Other non-standard behaviours include: support for vertical text, but in a syntax different from W3C CSS3 candidate recommendation, support for a variety of image effects and page transitions, which are not found in W3C CSS, support for obfuscated script code, in particular JScript.Encode. Support for embedding EOT fonts in web pages.
Favicon.
Support for favicons was first added in Internet Explorer 5. Internet Explorer supports favicons in PNG, static GIF and native Windows icon formats. In Windows Vista and later, Internet Explorer can display native Windows icons that have embedded PNG files.
Usability and accessibility.
Internet Explorer makes use of the accessibility framework provided in Windows. Internet Explorer is also a user interface for FTP, with operations similar to that of Windows Explorer. Pop-up blocking and tabbed browsing were added respectively in Internet Explorer 6 and Internet Explorer 7. Tabbed browsing can also be added to older versions by installing MSN Search Toolbar or Yahoo Toolbar.
Cache.
Internet Explorer caches visited content in the Temporary Internet Files folder to allow quicker access (or offline access) to previously visited pages. The content is indexed in a database file, known as Index.dat. Multiple Index.dat files exist which index different content—visited content, web feeds, visited URLs, cookies, etc.
Prior to IE7, clearing the cache used to clear the index but the files themselves were not reliably removed, posing a potential security and privacy risk. In IE7 and later, when the cache is cleared, the cache files are more reliably removed, and the index.dat file is overwritten with null bytes.
Caching has been improved in IE9.
Group Policy.
Internet Explorer is fully configurable using Group Policy. Administrators of Windows Server domains (for domain-joined computers) or the local computer can apply and enforce a variety of settings on computers that affect the user interface (such as disabling menu items and individual configuration options), as well as underlying security features such as downloading of files, zone configuration, per-site settings, ActiveX control behaviour and others. Policy settings can be configured for each user and for each machine. Internet Explorer also supports Integrated Windows Authentication.
Architecture.
Internet Explorer uses a componentized architecture built on the Component Object Model (COM) technology. It consists of several major components, each of which is contained in a separate Dynamic-link library (DLL) and exposes a set of COM programming interfaces hosted by the Internet Explorer main executable, iexplore.exe:
Internet Explorer does not include any native scripting functionality. Rather, MSHTML.dll exposes an API that permit a programmer to develop a scripting environment to be plugged-in and to access the DOM tree. Internet Explorer 8 includes the bindings for the Active Scripting engine, which is a part of Microsoft Windows and allows any language implemented as an Active Scripting module to be used for client-side scripting. By default, only the JScript and VBScript modules are provided; third party implementations like ScreamingMonkey (for ECMAScript 4 support) can also be used. Microsoft also makes available the Microsoft Silverlight runtime (not supported in Windows RT) that allows CLI languages, including DLR-based dynamic languages like IronPython and IronRuby, to be used for client-side scripting.
Internet Explorer 8 introduces some major architectural changes, called "Loosely Coupled IE" (LCIE). LCIE separates the main window process (frame process) from the processes hosting the different web applications in different tabs (tab processes). A frame process can create multiple tab processes, each of which can be of a different integrity level; each tab process can host multiple web sites. The processes use asynchronous Inter-Process Communication to synchronize themselves. Generally, there will be a single frame process for all web sites. In Windows Vista with Protected Mode turned on, however, opening privileged content (such as local HTML pages) will create a new tab process as it will not be constrained by Protected Mode.
Extensibility.
Internet Explorer exposes a set of Component Object Model (COM) interfaces that allows add-ons to extend the functionality of the browser. Extensibility is divided into two types: Browser extensibility and content extensibility. Browser extensibility involves adding context menu entries, toolbars, menu items or Browser Helper Objects (BHO). BHOs are used to extend the feature set of the browser, whereas the other extensibility options are used to expose that feature in the user interface. Content extensibility adds support for non-native content formats. It allows Internet Explorer to handle new file formats and new protocols, e.g. WebM or SPDY. In addition, web pages can integrate widgets known as ActiveX controls which run on Windows only but have vast potentials to extend the content capabilities; Adobe Flash Player and Microsoft Silverlight are examples. Add-ons can be installed either locally, or directly by a web site.
Since malicious add-ons can compromise the security of a system, Internet Explorer implements several safeguards. Internet Explorer 6 with Service Pack 2 and later feature an Add-on Manager for enabling or disabling individual add-ons, complemented by a "No Add-Ons" mode. Starting with Windows Vista, Internet Explorer and its BHOs run with restricted privileges and are isolated from the rest of the system. Internet Explorer 9 introduced a new component – Add-on Performance Advisor. Add-on Performance Advisor shows a notification when one or more of installed add-ons exceed a pre-set performance threshold. The notification appears in the Notification Bar when the user launches the browser. Windows 8 and Windows RT introduce a Metro-style version of Internet Explorer that is entirely sandboxed and does not run add-ons at all. In addition, Windows RT cannot download or install ActiveX controls at all; although existing ones bundled with Windows RT still run in the traditional version of Internet Explorer.
Internet Explorer itself can be hosted by other applications via a set of COM interfaces. This can be used to embed the browser functionality inside a computer program or create Internet Explorer shells.
Security.
Internet Explorer uses a zone-based security framework that groups sites based on certain conditions, including whether it is an Internet- or intranet-based site as well as a user-editable whitelist. Security restrictions are applied per zone; all the sites in a zone are subject to the restrictions.
Internet Explorer 6 SP2 onwards uses the "Attachment Execution Service" of Microsoft Windows to mark executable files downloaded from the Internet as being potentially unsafe. Accessing files marked as such will prompt the user to make an explicit trust decision to execute the file, as executables originating from the Internet can be potentially unsafe. This helps in preventing accidental installation of malware.
Internet Explorer 7 introduced the phishing filter, that restricts access to phishing sites unless the user overrides the decision. With version 8, it also blocks access to sites known to host malware. Downloads are also checked to see if they are known to be malware-infected.
In Windows Vista, Internet Explorer by default runs in what is called "Protected Mode", where the privileges of the browser itself are severely restricted—it cannot make any system-wide changes. One can optionally turn this mode off but this is not recommended. This also effectively restricts the privileges of any add-ons. As a result, even if the browser or any add-on is compromised, the damage the security breach can cause is limited.
Patches and updates to the browser are released periodically and made available through the Windows Update service, as well as through Automatic Updates. Although security patches continue to be released for a range of platforms, most feature additions and security infrastructure improvements are only made available on operating systems which are in Microsoft's mainstream support phase.
On December 16, 2008, Trend Micro recommended users switch to rival browsers until an emergency IE patch was released to fix a potential security risk which "could allow outside users to take control of a person's computer and steal their passwords". Microsoft representatives countered this recommendation, claiming that "0.02% of internet sites" were affected by the flaw.
On December 17, 2008, a fix to the security problem above became available, with the release of the Security Update for Internet Explorer KB960714, which is available from Microsoft Windows Update's webpage. Microsoft has said that this update fixes the security risk found by Trend Micro the previous day.
In 2011, a report by Accuvant, funded by Google, rated the security (based on sandboxing) of Internet Explorer worse than Google Chrome but better than Mozilla Firefox.
Security vulnerabilities.
Internet Explorer has been subjected to many security vulnerabilities and concerns: Much of the spyware, adware, and computer viruses across the Internet are made possible by exploitable bugs and flaws in the security architecture of Internet Explorer, sometimes requiring nothing more than viewing of a malicious web page in order to install themselves. This is known as a "drive-by install". There are also attempts to trick the user into installing malicious software by misrepresenting the software's true purpose in the description section of an ActiveX security alert.
A number of security flaws affecting IE originated not in the browser itself, but ActiveX-based add-ons used by it. Because the add-ons have the same privilege as IE, the flaws can be as critical as browser flaws. This has led to the ActiveX-based architecture being criticized for being fault-prone. By 2005, some experts maintained that the dangers of ActiveX have been overstated and there were safeguards in place. In 2006, new techniques using automated testing found more than a hundred vulnerabilities in standard Microsoft ActiveX components. Security features introduced in Internet Explorer 7 mitigated some of these vulnerabilities.
Internet Explorer in 2008, had a number of published security vulnerabilities. According to research done by security research firm Secunia, Microsoft did not respond as quickly as its competitors in fixing security holes and making patches available. The firm also reported 366 vulnerabilities in ActiveX controls, an increase from the prior year.
According to an October 2010 report in "The Register", researcher Chris Evans had detected a known security vulnerability which, then dating back to 2008, had not been fixed for at least 600 days. Microsoft says that it had known about this vulnerability but it was of very low severity as the victim web site must be configured in a special way for this attack to be feasible at all.
In December 2010, researchers were able to bypass the "Protected Mode" feature in Internet Explorer.
Vulnerability exploited in attacks on U.S. firms.
In an advisory on January 14, 2010, Microsoft said that attackers targeting Google and other U.S. companies used software that exploits a security hole, which had already been patched, in Internet Explorer. The vulnerability affected Internet Explorer 6 on Windows XP and Server 2003, IE6 SP1 on Windows 2000 SP4, IE7 on Windows Vista, XP, Server 2008 and Server 2003, and IE8 on Windows 7, Vista, XP, Server 2003, and Server 2008 (R2).
The German government warned users against using Internet Explorer and recommended switching to an alternative web browser, due to the major security hole described above that was exploited in Internet Explorer. The Australian and French Government issued a similar warning a few days later.
Major vulnerability across versions.
On April 26, 2014, Microsoft issued a security advisory relating to CVE-2014-1776, a vulnerability that could allow "remote code execution" in Internet Explorer versions 6 to 11. On April 28, 2014, the United States Department of Homeland Security's United States Computer Emergency Readiness Team (US-CERT) released an advisory stating that the vulnerability could result in "the complete compromise" of an affected system. US-CERT recommended reviewing Microsoft's suggestions to mitigate an attack or using an alternate browser until the bug is fixed. The UK National Computer Emergency Response Team (CERT-UK) published an advisory announcing similar concerns and for users to take the additional step of ensuring their antivirus software is up-to-date. Symantec, a cyber security firm, confirmed that "the vulnerability crashes Internet Explorer on Windows XP". The vulnerability was resolved on May 1, 2014, with a security update.
Market adoption and usage share.
The adoption rate of Internet Explorer seems to be closely related to that of Microsoft Windows, as it is the default web browser that comes with Windows. Since the integration of Internet Explorer 2.0 with Windows 95 OSR 1 in 1996, and especially after version 4.0's release in 1997, the adoption was greatly accelerated: from below 20% in 1996, to about 40% in 1998, and over 80% in 2000. This made Microsoft the winner in the infamous 'first browser war' against Netscape. Netscape Navigator was the dominant browser during 1995 and until 1997, but rapidly lost share to IE starting in 1998, and eventually slipped behind in 1999. The integration of IE with Windows led to a lawsuit by AOL, Netscape's owner, accusing Microsoft of unfair competition. The infamous case was eventually won by AOL but by then it was too late, as Internet Explorer had already become the dominant browser.
Internet Explorer peaked during 2002 and 2003, with about 95% share. Its first notable competitor after beating Netscape was Firefox from Mozilla, which itself was an offshoot from Netscape.
Firefox 1.0 had surpassed Internet Explorer 5 in early 2005, with Firefox 1.0 at roughly 8 percent market share.
Approximate usage over time based on various usage share counters averaged for the year overall, or for the fourth quarter, or for the last month in the year depending on availability of reference.
According to StatCounter Internet Explorer's marketshare fell below 50% in September 2010. In May 2012, it was announced that Google Chrome overtook Internet Explorer as the most used browser worldwide. 
Industry adoption.
Browser Helper Objects are also used by many search engine companies and third parties for creating add-ons that access their services, such as search engine toolbars. Because of the use of COM, it is possible to embed web-browsing functionality in third-party applications. Hence, there are a number of Internet Explorer shells, and a number of content-centric applications like RealPlayer also use Internet Explorer's web browsing module for viewing web pages within the applications.
Removal.
While a major upgrade of Internet Explorer can be uninstalled in a traditional way if the user has saved the original application files for installation, the matter of uninstalling the version of the browser that has shipped with an operating system remains a controversial one.
The idea of removing a stock install of Internet Explorer from a Windows system was proposed during the "United States v. Microsoft" case. One of Microsoft's arguments during the trial was that removing Internet Explorer from Windows may result in system instability. Indeed, programs that depend on libraries installed by IE, including Windows help and support system, fail to function without IE. Before Windows Vista, it was not possible to run Windows Update without IE because the service used ActiveX technology, which no other web browser supports.
Microsoft Edge, officially unveiled on January 21, 2015, has replaced Internet Explorer as the default browser on Windows 10. Internet Explorer is still installed in Windows 10 in order to maintain compatibility with older websites and intranet sites that require ActiveX and other Microsoft legacy web technologies.
Impersonation by malware.
The popularity of Internet Explorer has led to the appearance of malware abusing its name. On January 28, 2011, a fake Internet Explorer browser calling itself "Internet Explorer – Emergency Mode" appeared. It closely resembles the real Internet Explorer, but has fewer buttons and no search bar. If a user launches any other browser such as Google Chrome, Mozilla Firefox, Opera, Safari or the real Internet Explorer, this browser will pop-up instead. It also displays a fake error message, claiming that the computer is infected with malware and Internet Explorer has entered Emergency Mode. It blocks access to legitimate sites such as Google if infected users try to access them.

</doc>
<doc id="15220" url="https://en.wikipedia.org/wiki?curid=15220" title="Imprecise language">
Imprecise language

Often, informal, spoken language, "everyday language" is less precise than any more formal or academic languages.
Language might be said to be imprecise because it exhibits one or more of the following features:
While imprecise language is not desirable in various scientific fields, it may be helpful, illustrative or discussion-stimulative in other contexts. Imprecision in a discourse may or may not be the intention of the author(s) or speaker(s). The role of imprecision may depend on audience, end goal, extended context and subject matter. Relevant players and real stakes will also bear on truth-grounds of statements.

</doc>
<doc id="15221" url="https://en.wikipedia.org/wiki?curid=15221" title="Intel 80188">
Intel 80188

The Intel 80188 microprocessor was a variant of the Intel 80186. The 80188 had an 8-bit external data bus instead of the 16-bit bus of the 80186; this made it less expensive to connect to peripherals. The 16-bit registers and the one megabyte address range were unchanged, however. It had a throughput of 1 million instructions per second.
Description.
Features and performance.
The 80188 series was generally intended for embedded systems, as microcontrollers with external memory. Therefore, to reduce the number of chips required, it included features such as clock generator, interrupt controller, timers, wait state generator, DMA channels, and external chip select lines.
While the N80188 was compatible with the 8087 numerics co-processor, the 80C188 was not. It didn't have the ESC control codes integrated.
The initial clock rate of the 80188 was 6 MHz, but due to more hardware available for the microcode to use, especially for address calculation, many individual instructions ran faster than on an 8086 at the same clock frequency. For instance, the common "register+immediate" addressing mode was significantly faster than on the 8086, especially when a memory location was both (one of the) operand(s) and the destination. Multiply and divide also showed great improvement, being several times as fast as on the original 8086 and multi-bit shifts were done almost four times as quickly as in the 8086.

</doc>
<doc id="15222" url="https://en.wikipedia.org/wiki?curid=15222" title="IEEE 802.2">
IEEE 802.2

IEEE 802.2 is the original name of the ISO/IEC 8802-2 standard which defines Logical Link Control (LLC) as the upper portion of the data link layer of the OSI Model. The original standard developed by the Institute of Electrical and Electronics Engineers (IEEE) in collaboration with the American National Standards Institute (ANSI) was adopted by the International Organization for Standardization (ISO) in 1998, but it still remains an integral part of the family of IEEE 802 standards for local and metropolitan networks.
LLC is a software component that provides a uniform interface to the user of the data link service, usually the network layer. LLC may offer three types of services:
Conversely, the LLC uses the services of the Media Access Control (MAC), which is dependent on the specific transmission medium (Ethernet, Token Ring, FDDI, 802.11, etc.). Using LLC is compulsory for all IEEE 802 networks with the exception of Ethernet. It is also used in Fiber Distributed Data Interface (FDDI) which is not part of the IEEE 802 family.
The IEEE 802.2 sublayer adds some control information to the message created by the upper layer and passed to the LLC for transmission to another node on the same data link. The resulting packet is generally referred to as "LLC Protocol Data Unit (PDU)" and the additional information added by the LLC sublayer is the "LLC HEADER". The LLC Header consist of "DSAP" ("Destination Service Access Point"), "SSAP" ("Source Service Access Point") and the "Control" field.
The two 8-bit fields DSAP and SSAP allow to multiplex various upper layer protocols above LLC. However, many protocols use the Subnetwork Access Protocol (SNAP) extension which allows using of EtherType values to specify the protocol being transported atop IEEE 802.2. It also allows vendors to define their own protocol value spaces.
The 8 or 16 bit HDLC-style Control field serves to distinguish communication mode, to specify a specific operation and to facilitate connection control and flow control (in connection mode) or acknowledgements (in acknowledged connectionless mode).
Operational modes.
IEEE 802.2 provides two connectionless and one connection-oriented operational modes:
The use of multicasts and broadcasts reduce network traffic when the same information needs to be propagated to all stations of the network. However the Type 1 service provides no guarantees regarding the order of the received frames compared to the order in which they have been sent; the sender does not even get an acknowledgment that the frames have been received.
Each device conforming the IEEE 802.2 standard must support service type 1. Each network node is assigned an LLC Class according to which service types it supports:
LLC header.
Any 802.2 LLC PDU has the following format:
When Subnetwork Access Protocol (SNAP) extension is used, it is located at the start of the Information field:
The 802.2 header includes two eight-bit address fields, called service access points (SAP) or collectively LSAP in the OSI terminology:
LSAP Values.
The DSAP and SSAP can have the following values:
Despite the SAP fields being 8-bit long, some bits have specific significance, so that there is room for only 64 distinguished SAP numbers, which are globally assigned by the IEEE to uniquely identify well established international standards.
The low-order bit of the DSAP indicates whether it contains an individual or a group address. 
The low-order bit of the SSAP indicates whether the packet is a command or response packet; 
The remaining 7 bits of the SSAP specify the LSAP from which the packet was transmitted.
The protocols or families of protocols which have assigned one or more SAPs may operate directly on top of 802.2 LLC. Other protocols may use the Subnetwork Access Protocol (SNAP) with IEEE 802.2 which is indicated by the hexadecimal value 0xAA (or 0xAB, if the low-order bit of the field is set) in SSAP and DSAP. The SNAP extension allows using EtherType values or private protocol ID spaces in all IEEE 802 networks. It can be used both in datagram and in connection-oriented network services.
Ethernet (IEEE 802.3) networks are an exception; the IEEE 802.3x-1997 standard explicitly allowed using of the Ethernet II framing, where the 16-bit field after the MAC addresses does not carry the length of the frame followed by the IEEE 802.2 LLC header, but the EtherType value followed by the upper layer data. With this framing only datagram services are supported on the data link layer.
Internet Protocol and 802.2 LLC.
Although IPv4 has assigned SAP value of 6 and there is even a SAP value of 98 hex for ARP, IP traffic is almost never encapsulated in IEEE 802.2 LLC frames without SNAP. Instead, the Internet standard RFC 1042 is usually used for encapsulating IP version 4 traffic in IEEE 802.2 frames with LLC/SNAP headers in FDDI and IEEE 802 networks. In Ethernet/IEEE 802.3 networks using Ethernet II framing with EtherType 800 hex for IP and 806 hex for ARP is more common.
It is possible to use diverse framings in a single network. It is possible to do it even for the same upper layer protocol, but in such a case the nodes using unlike framings cannot directly communicate. IPX protocol used in the Novell NetWare networks allows an additional Ethernet frame format supporting 4 frame types in Ethernet and 2 frame types in IEEE 802 networks and FDDI.
Control Field.
Following the destination and source SAP fields is a control field. IEEE 802.2 was conceptually derived from HDLC, and has the same three types of PDUs:
To carry data in the most-often used unacknowledged connectionless mode the U-format is used. It is identified by the value '11' in lower two bits of the single-byte control field.

</doc>
<doc id="15223" url="https://en.wikipedia.org/wiki?curid=15223" title="Invertebrate">
Invertebrate

Invertebrates are animals that neither possess nor develop a vertebral column, derived from the notochord. This includes all animals apart from the subphylum Vertebrata. Familiar examples of invertebrates include insects; crabs, lobsters and their kin; snails, clams, octopuses and their kin; starfish, sea-urchins and their kin; and worms.
The majority of animal species are invertebrates; one estimate puts the figure at 97%. Many invertebrate taxa have a greater number and variety of species than the entire subphylum of Vertebrata.
Some of the so-called invertebrates, such as the Chaetognatha, Hemichordata, Tunicata and Cephalochordata are more closely related to the vertebrates than to other invertebrates. This makes the term "invertebrate" paraphyletic and hence almost meaningless for taxonomic purposes.
Etymology.
The word "invertebrate" comes from the form of the Latin word "vertebra", which means a joint in general, and sometimes specifically a joint from the spinal column of a vertebrate. In turn the jointed aspect of "vertebra" derived from the concept of turning, expressed in the root "verto" or "vorto", to turn. Coupled with the prefix "in-", meaning "not" or "without".
Taxonomic significance.
The term invertebrates is not always precise among non-biologists since it does not accurately describe a taxon in the same way that Arthropoda, Vertebrata or Manidae do. Each of these terms describes a valid taxon, phylum, subphylum or family. "Invertebrata" is a term of convenience, not a taxon; it has very little circumscriptional significance except within the Chordata. The Vertebrata as a subphylum comprises such a small proportion of the Metazoa that to speak of the kingdom Animalia in terms of "Vertebrata" and "Invertebrata" has limited practicality. In the more formal taxonomy of Animalia other attributes that logically should precede the presence or absence of the vertebral column in constructing a cladogram, for example, the presence of a notochord. That would at least circumscribe the Chordata. However, even the notochord would be a less fundamental criterion than aspects of embryological development and symmetry or perhaps bauplan.
Invertebrates don't have a skeleton of bone, either internal or external. They include hugely varied body plans. Many have fluid-filled, hydrostatic skeletons, like jellyfish or worms. Others have hard exoskeletons, outer shells like those of insects and crustaceans. The most familiar invertebrates include the Protozoa, Porifera, Coelenterata, Platyhelminthes, Nematoda, Annelida, Echinodermata, Mollusca and Arthropoda. Arthropoda include insects, crustaceans and arachnids.
Number of extant species.
By far the largest number of described invertebrate species are insects. The following table lists the number of described extant species for each major invertebrate group as estimated in the IUCN Red List of Threatened Species", 2014.3.
The IUCN estimates that 66,178 extant vertebrate species have been described, which means that over 95% of the described animal species in the world are invertebrates.
Characteristics.
The trait that is common to all invertebrates is the absence of a vertebral column: this creates a distinction between invertebrates and vertebrates. The distinction is one of convenience only; it is not based on any clear biologically homologous trait, any more than the common trait of having wings functionally unites insects, bats, and birds, or than not having wings unites tortoises, snails and sponges. Being animals, invertebrates are heterotrophs, and require sustenance in the form of the consumption of other organisms. With a few exceptions, such as the Porifera, invertebrates generally have bodies composed of differentiated tissues. There is also typically a digestive chamber with one or two openings to the exterior.
Morphology and symmetry.
The body plans of most multicellular organisms exhibit some form of symmetry, whether radial, bilateral, or spherical. A minority, however, exhibit no symmetry. One example of asymmetric invertebrates include all gastropod species. This is easily seen in snails and sea snails, which have helical shells. Slugs appear externally symmetrical, but their pneumostome (breathing hole) is located on the right side. Other gastropods develop external asymmetry, such as Glaucus atlanticus that develops asymmetrical cerata as they mature. The origin of gastropod asymmetry is a subject of scientific debate.
Other examples of asymmetry are found in fiddler crabs and hermit crabs. They often have one claw much larger than the other. If a male fiddler loses its large claw, it will grow another on the opposite side after moulting. Sessile animals such as sponges are asymmetrical alongside coral colonies (with the exception of the individual polyps that exhibit radial symmetry); alpheidae claws that lack pincers; and some copepods, polyopisthocotyleans, and monogeneans which parasitize by attachment or residency within the gill chamber of their fish hosts).
Nervous system.
Neurons differ in invertebrates from mammalian cells. Invertebrates cells fire in response to similar stimuli as mammals, such as tissue trauma, high temperature, or changes in pH. The first invertebrate in which a neuron cell was identified was the medicinal leech, "Hirudo medicinalis."
Learning and memory using nociceptors in the sea hare, "Aplysia" has been described. Mollusk neurons are able to detect increasing pressures and tissue trauma.
Neurons have been identified in a wide range of invertebrate species, including annelids, molluscs, nematodes and arthropods.
Respiratory system.
One type of invertebrate respiriatory system is the open respiratory system composed of spiracles, tracheae, and tracheoles that terrestrial arthropods have to transport metabolic gases to and from tissues. The distribution of spiracles can vary greatly among the many orders of insects, but in general each segment of the body can have only one pair of spiracles, each of which connects to an atrium and has a relatively large tracheal tube behind it. The tracheae are invaginations of the cuticular exoskeleton that branch (anastomose) throughout the body with diameters from only a few micrometres up to 0.8 mm. The smallest tubes, tracheoles, penetrate cells and serve as sites of diffusion for water, oxygen, and carbon dioxide. Gas may be conducted through the respiratory system by means of active ventilation or passive diffusion. Unlike vertebrates, insects do not generally carry oxygen in their haemolymph.
A tracheal tube may contain ridge-like circumferential rings of taenidia in various geometries such as loops or helices. In the head, thorax, or abdomen, tracheae may also be connected to air sacs. Many insects, such as grasshoppers and bees, which actively pump the air sacs in their abdomen, are able to control the flow of air through their body. In some aquatic insects, the tracheae exchange gas through the body wall directly, in the form of a gill, or function essentially as normal, via a plastron. Note that despite being internal, the tracheae of arthropods are shed during moulting (ecdysis).
Reproduction.
Like vertebrates, most invertebrates reproduce at least partly through sexual reproduction. They produce specialized reproductive cells that undergo meiosis to produce smaller, motile spermatozoa or larger, non-motile ova. These fuse to form zygotes, which develop into new individuals. Others are capable of asexual reproduction, or sometimes, both methods of reproduction.
Social interaction.
Social behavior is widespread in invertebrates, including cockroaches, termites, aphids, thrips, ants, bees, Passalidae, Acari, spiders, and more. Social interaction is particularly salient in eusocial species but applies to other invertebrates as well.
Insects recognize information transmitted by other insects.
Phyla.
The term invertebrates covers several phyla. One of these are the sponges (Porifera). They were long thought to have diverged from other animals early. They lack the complex organization found in most other phyla. Their cells are differentiated, but in most cases not organized into distinct tissues. Sponges typically feed by drawing in water through pores. Some speculate that sponges are not so primitive, but may instead be secondarily simplified. The Ctenophora and the Cnidaria, which includes sea anemones, corals, and jellyfish, are radially symmetric and have digestive chambers with a single opening, which serves as both the mouth and the anus. Both have distinct tissues, but they are not organized into organs. There are only two main germ layers, the ectoderm and endoderm, with only scattered cells between them. As such, they are sometimes called diploblastic.
The Echinodermata are radially symmetric and exclusively marine, including starfish (Asteroidea), sea urchins, (Echinoidea), brittle stars (Ophiuroidea), sea cucumbers (Holothuroidea) and feather stars (Crinoidea).
The largest animal phylum is also included within invertebrates: the Arthropoda, including insects, spiders, crabs, and their kin. All these organisms have a body divided into repeating segments, typically with paired appendages. In addition, they possess a hardened exoskeleton that is periodically shed during growth. Two smaller phyla, the Onychophora and Tardigrada, are close relatives of the arthropods and share these traits. The Nematoda or roundworms, are perhaps the second largest animal phylum, and are also invertebrates. Roundworms are typically microscopic, and occur in nearly every environment where there is water. A number are important parasites. Smaller phyla related to them are the Kinorhyncha, Priapulida, and Loricifera. These groups have a reduced coelom, called a pseudocoelom. Other invertebrates include the Nemertea or ribbon worms, and the Sipuncula.
Another phylum is Platyhelminthes, the flatworms. These were originally considered primitive, but it now appears they developed from more complex ancestors. Flatworms are acoelomates, lacking a body cavity, as are their closest relatives, the microscopic Gastrotricha. The Rotifera or rotifers, are common in aqueous environments. Invertebrates also include the Acanthocephala or spiny-headed worms, the Gnathostomulida, Micrognathozoa, and the Cycliophora.
Also included are two of the most successful animal phyla, the Mollusca and Annelida. The former, which is the second-largest animal phylum by number of described species, includes animals such as snails, clams, and squids, and the latter comprises the segmented worms, such as earthworms and leeches. These two groups have long been considered close relatives because of the common presence of trochophore larvae, but the annelids were considered closer to the arthropods because they are both segmented. Now, this is generally considered convergent evolution, owing to many morphological and genetic differences between the two phyla.
Among lesser phyla of invertebrates are the Hemichordata, or acorn worms, and the Chaetognatha, or arrow worms. Other phyla include Acoelomorpha, Brachiopoda, Bryozoa, Entoprocta, Phoronida, and Xenoturbellida.
Classification of invertebrates.
Invertebrates can be classified into several main categories, some of which are taxonomically obsolescent or debatable, but still used as terms of convenience. Each however appears in its own article at the following links.
History.
The earliest animal fossils appear to be those of invertebrates. 665-million-year-old fossils in the Trezona Formation at Trezona Bore, West Central Flinders, South Australia have been interpreted as being early sponges. Some paleontologists suggest that animals appeared much earlier, possibly as early as 1 billion years ago. Trace fossils such as tracks and burrows found in the Tonian era indicate the presence of triploblastic worms, like metazoans, roughly as large (about 5 mm wide) and complex as earthworms.
Around 453 MYA, animals began diversifying, and many of the important groups of invertebrates diverged from one another. Fossils of invertebrates are found in various types of sediment from the Phanerozoic. Fossils of invertebrates are commonly used in stratigraphy.
Classification.
Carl Linnaeus divided these animals into only two groups, the Insecta and the now-obsolete Vermes (worms). Jean-Baptiste Lamarck, who was appointed to the position of "Curator of Insecta and Vermes" at the Muséum National d'Histoire Naturelle in 1793, both coined the term "invertebrate" to describe such animals, and divided the original two groups into ten, by splitting Arachnida and Crustacea from the Linnean Insecta, and Mollusca, Annelida, Cirripedia, Radiata, Coelenterata and Infusoria from the Linnean Vermes. They are now classified into over 30 phyla, from simple organisms such as sea sponges and flatworms to complex animals such as arthropods and molluscs.
Significance of the group.
Invertebrates are animals "without" a vertebral column. This has led to the conclusion that "in"vertebrates are a group that deviates from the normal, vertebrates. This has been said to be because researchers in the past, such as Lamarck, viewed vertebrates as a "standard": in Lamarck's theory of evolution, he believed that characteristics acquired through the evolutionary process involved not only survival, but also progression toward a "higher form", to which humans and vertebrates were closer than invertebrates were. Although goal-directed evolution has been abandoned, the distinction of invertebrates and vertebrates persists to this day, even though the grouping has been noted to be "hardly natural or even very sharp." Another reason cited for this continued distinction is that Lamarck created a precedent through his classifications which is now difficult to escape from. It's also possible that some humans believe that, they themselves being vertebrates, the group deserves more attention than invertebrates. In any event, in the 1968 edition of "Invertebrate Zoology", it is noted that "division of the Animal Kingdom into vertebrates and invertebrates is artificial and reflects human bias in favor of man's own relatives." The book also points out that the group lumps a vast number of species together, so that no one characteristic describes all invertebrates. In addition, some species included are only remotely related to one another, with some more related to vertebrates than other invertebrates (see Paraphyly).
In research.
For many centuries, invertebrates have been neglected by biologists, in favor of big vertebrates and "useful" or charismatic species. Invertebrate biology was not a major field of study until the work of Linnaeus and Lamarck in the 18th century. During the 20th century, invertebrate zoology became one of the major fields of natural sciences, with prominent discoveries in the fields of medicine, genetics, palaeontology, and ecology. The study of invertebrates has also benefited law enforcement, as arthropods, and especially insects, were discovered to be a source of information for forensic investigators.
Two of the most commonly studied model organisms nowadays are invertebrates: the fruit fly "Drosophila melanogaster" and the nematode "Caenorhabditis elegans". They have long been the most intensively studied model organisms, and were among the first life-forms to be genetically sequenced. This was facilitated by the severely reduced state of their genomes, but many genes, introns, and linkages have been lost. Analysis of the starlet sea anemone genome has emphasised the importance of sponges, placozoans, and choanoflagellates, also being sequenced, in explaining the arrival of 1500 ancestral genes unique to animals. Invertebrates are also used by scientists in the field of aquatic biomonitoring to evaluate the effects of water pollution and climate change.

</doc>
<doc id="15225" url="https://en.wikipedia.org/wiki?curid=15225" title="Ivar Aasen">
Ivar Aasen

Ivar Andreas Aasen (; 5 August 1813 – 23 September 1896) was a Norwegian philologist, lexicographer, playwright, and poet. He is best known for having assembled from dialects one of the two official written versions of the Norwegian language, Nynorsk.
Background.
Aasen was born at Åsen in Ørsta (then Ørsten), in the district of Sunnmøre, on the west coast of Norway. His father, a peasant with a small farm, Ivar Jonsson, died in 1826. The younger Ivar was brought up to farmwork, but he assiduously cultivated all his leisure in reading. An early interest of his was botany. When he was eighteen, he opened an elementary school in his native parish. In 1833 he entered the household of H. C. Thoresen, the husband of the eminent writer Magdalene Thoresen, in Herøy (then Herø), and there he picked up the elements of Latin. Gradually, and by dint of infinite patience and concentration, the young peasant mastered many languages, and began the scientific study of their structure. Ivar single-handedly created a new language for Norway to become the "literary" language.
Career.
About 1841 he had freed himself from all the burden of manual labour, and could occupy his thoughts with the dialect of his native district, Sunnmøre; his first publication was a small collection of folk songs in the Sunnmøre dialect (1843). His remarkable abilities now attracted general attention, and he was helped to continue his studies undisturbed. His "Grammar of the Norwegian Dialects" (, 1848) was the result of much labour, and of journeys taken to every part of the country. Aasen's famous "Dictionary of the Norwegian Dialects" () appeared in its original form in 1850, and from this publication dates all the wide cultivation of the popular language in Norwegian, since Aasen really did no less than construct, out of the different materials at his disposal, a popular language or definite "folke-maal" (people's language) for Norway. By 1853, he had created the norm for utilizing his new language, which he called Landsmaal, meaning country language. With certain modifications, the most important of which were introduced later by Aasen himself, but also through a latter policy aiming to merge this Norwegian language with Dano-Norwegian, this language has become "Nynorsk" ("New Norwegian"), the second of Norway's two official languages (the other being "Bokmål", the Dano-Norwegian descendant of the Danish language used in Norway in Aasen's time). An unofficial variety of Norwegian more close to Aasen's language is still found in Høgnorsk ("High Norwegian"). Today, some consider Nynorsk on equal footing with bokmål, as bokmål tends to be used more in radio and television and most newspapers, whereas New Norse (Nynorsk) is used equally in government work as well as approximately 17% of schools. Although it is not as common as its brother language, it needs to be looked upon as a viable language, as a large minority of Norwegians use it as their primary language including many scholars and authors. New Norse is both a written and spoken language.
Aasen composed poems and plays in the composite dialect to show how it should be used; one of these dramas, "The Heir" (1855), was frequently acted, and may be considered as the pioneer of all the abundant dialect-literature of the last half-century of the 1800s, from Vinje to Garborg. In 1856, he published "Norske Ordsprog", a treatise on Norwegian proverbs. Aasen continuously enlarged and improved his grammars and his dictionary. He lived very quietly in lodgings in Oslo (then Christiania), surrounded by his books and shrinking from publicity, but his name grew into wide political favour as his ideas about the language of the peasants became more and more the watch-word of the popular party. In 1864, he published his definitive grammar of Nynorsk and in 1873 he published the definitive dictionary.
Quite early in his career, in 1842, he had begun to receive a grant to enable him to give his entire attention to his philological investigations; and the Storting (Norwegian parliament), conscious of the national importance of his work, treated him in this respect with more and more generosity as he advanced in years. He continued his investigations to the last, but it may be said that, after the 1873 edition of his "Dictionary" (with a new title: ), he added but little to his stores. Aasen holds perhaps an isolated place in literary history as the one man who has invented, or at least selected and constructed, a language which has pleased so many thousands of his countrymen that they have accepted it for their schools, their sermons and their songs. He died in Christiania on 23 September 1896, and was buried with public honours.
The Ivar Aasen Centre.
Ivar Aasen-tunet, an institution devoted to the Nynorsk language, opened in June 2000. Their web page includes most of Aasens' texts, numerous other examples of Nynorsk literature (in Nettbiblioteket, the Internet Library), and some articles, including some in English, about language history in Norway.
2013 Language year.
"Språkåret 2013" (The Language Year 2013) celebrated Ivar Aasen's 200 year anniversary, as well as the 100 year anniversary of Det Norske Teateret. The year's main focus was to celebrate linguistic diversity in Norway. In a poll released in connection with the celebration, 56% of Norwegians said they held positive views of Aasen, while 7% held negative views. On Aasen's 200 anniversary, 5 August 2013, "Bergens Tidende", which is normally published mainly in bokmål, published an edition fully in nynorsk in memory of Aasen.
Bibliography.
Aasen published a wide range of material, some of it released posthumously.

</doc>
<doc id="15226" url="https://en.wikipedia.org/wiki?curid=15226" title="Irredentism">
Irredentism

Irredentism (from Italian "irredento" for "unredeemed") is any political or popular movement intended to reclaim and reoccupy a lost homeland. As such, irredentism tries to justify its territorial claims on the basis of (real or imagined) historic or ethnic affiliations. It is often advocated by nationalist and pan-nationalist movements and has been a feature of identity politics, cultural, and political geography.
An area that may be subjected to a potential claim is sometimes called an irredenta. Not all irredentas are necessarily involved in irredentism.
Etymology.
The word was coined in Italy from the phrase "Italia irredenta" ("unredeemed Italy"). This originally referred to rule by Austria-Hungary over territories mostly or partly inhabited by ethnic Italians, such as Trentino, Trieste, Gorizia, Istria, Rijeka and Dalmatia during the 19th and early 20th centuries.
A common way to express a claim to adjacent territories on the grounds of historical or ethnic association is by using the epithet "Greater" before the country name. This conveys the image of national territory at its maximum conceivable extent with the country "proper" at its core. The use of "Greater" does not always convey an irredentistic meaning.
Formal irredentism.
Some states formalize their irredentist claims by including them in their constitutional documents, or through other means of legal enshrinement.
Afghanistan.
The Afghan border with Pakistan, known as the Durand Line, was agreed to by Afghanistan and British India in 1893. The Pashtun tribes inhabiting the border areas were divided between what have become two nations; Afghanistan never accepted the still-porous border and clashes broke out in the 1950s and 1960s between Afghanistan and Pakistan over the issue. All Afghan governments of the past century have declared, with varying intensity, a long-term goal of re-uniting all Pashtun-dominated areas under Afghan rule.
Argentina.
The Argentine government has maintained a claim over the Falkland Islands since 1833, and renewed it as recently as January 2013. It considers the archipelago part of the Tierra del Fuego Province, along with South Georgia and the South Sandwich Islands.
The Argentine claim is included in the transitional provisions of the Constitution of Argentina as amended in 1994:
Bolivia.
The 2009 constitution of Bolivia states that the country has an unrenounceable right over the territory that gives it access to the Pacific Ocean and its maritime space. This is understood as territory that Bolivia and Peru ceded to Chile after the War of the Pacific, which left Bolivia as a landlocked country.
China.
The preamble to the Constitution of the People's Republic of China states, "Taiwan is part of the sacred territory of the People's Republic of China (PRC). It is the lofty duty of the entire Chinese people, including our compatriots in Taiwan, to accomplish the great task of reunifying the motherland." The PRC claim to sovereignty over Taiwan is generally based on the theory of the succession of states, with the PRC claiming that it is the successor state to the Republic of China (1912–49).
The Government of the Republic of China formerly administered both mainland China and Taiwan; the government has been administering only Taiwan since its defeat in the Chinese Civil War by the armed forces of the Communist Party of China. While the official name of the state remains 'Republic of China', the country is commonly called 'Taiwan', since Taiwan makes up 99% of the controlled territory of the ROC.
Article 4 of the Constitution of the Republic of China originally stated that "he territory of the Republic of China within its existing national boundaries shall not be altered except by a resolution of the National Assembly". Throughout the 1950s and 1960s, the Government of the Republic of China on Taiwan maintained itself to be the legitimate ruler of Mainland China as well. As part of its current policy continuing of the 'status quo', the ROC has not renounced claims over the territories currently controlled by the People's Republic of China, Mongolia, Russia, Burma and some Central Asian states. However, Taiwan does not actively pursue these claims in practice; the remaining claims that Taiwan is actively seeking are the Senkaku Islands, whose sovereignty is also asserted by Japan and the PRC; Paracel Islands and the Spratly Islands in South China Sea, with multiple claimants.
Comoros.
Article 1 of the Constitution of the Union of the Comoros begins: "The Union of the Comoros is a republic, composed of the autonomous islands of Mohéli, Mayotte, Anjouan, and Grande Comore." Mayotte, geographically a part of the Comoro Islands, was the only island of the four to vote against independence from France (independence losing 37%–63%) in the referendum held December 22, 1974. The total vote was 94%–5% in favor of independence. Mayotte is currently a department of the French Republic.
India.
All of the European colonies on the Indian subcontinent which were not part of the British Raj have been annexed by India since it gained its independence from the British Empire. An example of such territories was the 1961 Indian annexation of Goa. An example of annexation of a territory from the British Raj was the Indian integration of Junagadh.
Akhand Bharat, literally Undivided India, is an irredentist call to reunite Pakistan and Bangladesh with India to form an "Undivided India" as it existed before partition in 1947 (and before that, during other periods of political unity in South Asia, such as during the Maurya Empire, the Gupta Empire, the Mughal Empire or the Maratha Empire). The call for "Akhand Bharat" has often been raised by mainstream Indian nationalistic cultural and political organizations such as the Rashtriya Swayamsevak Sangh (RSS) and the Bharatiya Janata Party (BJP). Other major Indian political parties such as the Indian National Congress, while maintaining positions against the partition of India on religious grounds, do not necessarily subscribe to a call to reunite South Asia in the form of Akhand Bharat.
The region of Kashmir in northwestern India has been the issue of a territorial dispute between India and Pakistan since 1947, the Kashmir conflict. Multiple wars have been fought over the issue, the first one immediately upon independence and partition in 1947 itself. To stave off a Pakistani and tribal invasion, Maharaja Hari Singh of the princely state of Jammu and Kashmir signed the Instrument of Accession with India. Kashmir has remained divided in three parts, administered by India, Pakistan and China, since then. However, on the basis of the instrument of accession, India continues to claim the entire Kashmir region as its integral part. All modern Indian political parties support the return of the entirety of Kashmir to India, and all official maps of India show the entire Jammu and Kashmir state (including parts under Pakistani or Chinese administration after 1947) as an integral part of India.
Indonesia.
Indonesia claimed all territories of the former Dutch East Indies, and previously viewed British plans to group the British Malaya and Borneo into a new independent federation of Malaysia as a threat to its objective to create a united state called Greater Indonesia. The Indonesian opposition of Malaysian formation has led to the Indonesia–Malaysia confrontation in the early 1960s. It also held Portuguese Timor (modern East Timor) from 1975 to 2002 based on irredentist claims.
The idea of uniting former British and Dutch colonial possessions in Southeast Asia actually has its roots in the early 20th century, as the concept of Greater Malay ("Melayu Raya") was coined in British Malaya espoused by students and graduates of Sultan Idris Training College for Malay Teachers in the late 1920s. Some of political figures in Indonesia including Mohammad Yamin and Sukarno revived the idea in the 1950s and named the political union concept as Greater Indonesia.
Israel.
The nation state of Israel was established in 1948. The United Nations General Assembly passed U.N. Resolution 181 otherwise known as the United Nations Partition Plan for Palestine by an overwhelming 78% of the UNGA passing the resolution. Eventually, Israeli independence was achieved following the liquidation of the former British-administered Mandate of Palestine, the departure of the British and the "Independence War" between the Jews in ex-Mandatory Palestine and five Arab states' armies. The Jewish claim for Palestine as the "Jewish homeland" can be seen as an example of irredentism, based on ancestral conquest and the Bible. Proponents of the formation, expansion, or defense of Israel, who subscribe to these historical or religious justifications, are sometimes called (and refer to themselves as) "Zionists". It should also be noted that Mandatory Palestine had sizable Jewish and Arab populations before the Second World War.
Judea and Samaria, as they are called in the Bible, were part of the ancient Kingdom of Israel (designated the West Bank by Jordan in 1947) and the Gaza Strip, previously annexed by Jordan and occupied by Egypt respectively, were conquered and occupied by Israel in the Six-Day War in 1967. Israel withdrew from Gaza in August 2005; Judea and Samaria (West Bank) remain under Israeli control. Israel has never explicitly claimed sovereignty over any part of the West Bank apart from East Jerusalem, which it unilaterally annexed in 1980. However, the Israeli military supports and defends hundreds of thousands of Israeli citizens who have migrated to the West Bank, incurring criticism by some who otherwise support Israel. The United Nations Security Council, the United Nations General Assembly, and some countries and international organizations continue to regard Israel as occupying Gaza. "(See Israeli-Occupied Territories.)"
The Israeli annexing instrument, the Jerusalem Law—one of the Basic Laws of Israel (Israel does not have a constitution)—declares Jerusalem, "complete and united", to be the capital of Israel. Article 3 of the Basic Law of the Palestinian Authority, which was ratified in 2002 by the Palestinian National Authority and serves as an interim constitution, claims that "Jerusalem is the capital of Palestine." "De facto", the Palestinian government administers the parts of the West Bank that Israel has granted it authority over from Ramallah, while the Gaza Strip is administered by the Hamas movement from Gaza.
The United States does not recognize Israeli sovereignty over East Jerusalem and maintains its embassy in Tel Aviv. In Jerusalem, the United States maintains two Consulates General as a diplomatic representation to the city of Jerusalem alone, separate from representation to the state of Israel. One of the Consulates General was established before the 1967 war, and the other in a recently constructed building on the Israeli side of Jerusalem. However, Congress passed the Jerusalem Embassy Act in 1995 that says the US shall move its embassy from Tel Aviv to Jerusalem, but allows the president to delay the move every year if it is deemed contrary to national security interests. Since 1995, every president has delayed the move.
A minority of Israelis and Jews regard the East Bank of the Jordan river (which is today the Kingdom of Jordan) as the eastern parts of the Land of Israel (following the revisionist idea) because, according to the Bible, the Israelite tribes of Menasseh, Gad, and Reuben settled on the east bank of the Jordan, and because that area was designated a Jewish national home by the League of Nations in the Mandate for Palestine.
Korea.
Since their founding, both Korean states have disputed the legitimacy of the other. South Korea's constitution claims jurisdiction over the entire Korean peninsula. It acknowledges the division of Korea only indirectly by requiring the president to work for reunification. The Committee for the Five Northern Korean Provinces, established in 1949, is the South Korean authority charged with the administration of Korean territory north of the Military Demarcation Line (i.e., North Korea), and consists of the governors of the five provinces, who are appointed by the President. However the body is purely symbolic and largely tasked with dealing with Northern defectors; if reunification were to actually occur the Committee would be dissolved and new administrators appointed by the Ministry of Unification.
North Korea's constitution also stresses the importance of reunification, but, while it makes no similar formal provision for administering the South, it effectively claims its territory as it does not diplomatically recognise the Republic of Korea, deeming it an "entity occupying the Korean territory".
Other territories sometimes disputed to belong to Korea are Manchuria and Gando.
Venezuela.
The Guayana Esequiba is a territory administered by Guyana but claimed by Venezuela. It was first included in the Viceroyalty of New Granada and the Captaincy General of Venezuela by Spain, but was later included in Essequibo by the Dutch and in British Guiana by the United Kingdom. Originally, parts of what is now eastern Venezuela were included in the disputed area. This territory of 159,500 km² is the subject of a long-running boundary dispute inherited from the colonial powers and complicated by the independence of Guyana in 1966. The status of the territory is subject to the Treaty of Geneva, which was signed by the United Kingdom, Venezuela and British Guiana governments on February 17, 1966. This treaty stipulates that the parties will agree to find a practical, peaceful and satisfactory solution to the dispute.
Other irredentism.
Europe.
Former Yugoslavia.
Some of the most violent irredentist conflicts of recent times in Europe flared up as a consequence of the break-up of the former Yugoslavian federal state in the early 1990s. The conflict erupted further south with the ethnic Albanian majority in Kosovo seeking to switch allegiance to the adjoining state of Albania.
Albania.
Greater Albania or "Ethnic Albania" as called by the Albanian nationalists themselves, is an irredentist concept of lands outside the borders of Albania which are considered part of a greater national homeland by most Albanians, based on claims on the present-day or historical presence of Albanian populations in those areas. The term incorporates claims to Kosovo, as well as territories in the neighbouring countries Montenegro, Greece and the Republic of Macedonia. Albanians themselves mostly use the term "ethnic Albania" instead. According to the "Gallup Balkan Monitor" 2010 report, the idea of a Greater Albania is supported by the majority of Albanians in Albania (63%), Kosovo (81%) and the Republic of Macedonia (53%). In 2012, as part of the celebrations for the 100th Anniversary of the Independence of Albania, Prime Minister Sali Berisha spoke of "Albanian lands" stretching from Preveza in Greece to Preševo in Serbia, and from the Macedonian capital of Skopje to the Montenegrin capital of Podgorica, angering Albania's neighbors. The comments were also inscribed on a parchment that will be displayed at a museum in the city of Vlore, where the country's independence from the Ottoman Empire was declared in 1912.
Bulgaria.
Based on the territorial definition of a historic Bulgarian state, a "Greater Bulgaria" nationalist movement has been active for more than a century that would annex most of Macedonia, Thrace, and Moesia.
France.
The idea of the natural borders of France is a political theory conceptualized primarily in the late 18th and early 19th centuries that focused on widening the borders primarily based on either practical reasons or the territory that was thought to be the maximum extent that the ancient Gauls inhabited. This theory lays claim to portions of Belgium and Germany.
Germany.
During the unification of Germany (1871), the term "Großdeutschland" "Greater Germany" referred to a possible German nation consisting of the states that later comprised the German Empire and Austria. The term "Kleindeutschland" "Lesser Germany" referred to a possible German state without Austria. The term was also used by Germans referring to Greater Germany, a state consisting of pre-World War I Germany, Austria and the Sudetenland. This issue was known as the German Question.
A main point of Nazi ideology was to reunify all Germans either born or living outside of Germany to create an "all-German Reich." These beliefs ultimately resulted in the Munich Agreement, which ceded to Germany areas of Czechoslovakia that were mainly inhabited by those of German descent and the Anschluss, which ceded the entire country of Austria to Germany; both events occurred in 1938.
Greece.
Following the Greek War of Independence in 1821–1832, Greece began to contest areas inhabited by Greeks, primarily against the Ottoman Empire. The Megali Idea (Great Idea) envisioned Greek incorporation of Greek-inhabited lands, but also historical lands in Asia Minor corresponding with the predominantly Greek and Orthodox Byzantine Empire and the dominions of the ancient Greeks.
The Greek quest began with the acquisition of Thessaly through the Convention of Constantinople in 1881, a failed war against Turkey in 1897 and the Balkan Wars (Macedonia, Epirus, some Aegean Islands). After World War I, Greece acquired Western Thrace from Bulgaria as per the Treaty of Neuilly-sur-Seine, but also Ionia/Smyrna and Eastern Thrace (excluding Constantinople) from the Ottoman Empire as ordained in the Treaty of Sèvres. Subsequently, Greece launched an unsuccessful campaign to further their gains in Asia Minor, but were halted by the Turkish revolution. The events culminated into the Great Fire of Smyrna, Population exchange between Greece and Turkey and Treaty of Lausanne which returned Eastern Thrace and Ionia to the newfound Turkish Republic. The events are known as the "Asia Minor Catastrophe" to Greeks. The Ionian Islands were ceded by Britain in 1864, and the Dodecanese by Italy in 1947.
Another Greek irredentist claim includes Northern Epirus (currently part of Albania), where a sizable Greek minority lives. Greece officially annexed Northern Epirus in March 1916, but was forced to revoke by the Great Powers. In 1917 Greece lost control of the rest of Northern Epirus to Italy. The Paris Peace Conference of 1919 awarded the area to Greece after World War I, however, political developments such as the Greek defeat in the Greco-Turkish War (1919–22) and, crucially, Italian, Austrian and German lobbying in favor of Albania resulted in the area being ceded to Albania in November 1921.
Another concern of the Greeks is the incorporation of Cyprus which was ceded by the Ottomans to the British. As a result of the Cyprus Emergency the island gained independence as the Republic of Cyprus in 1960. The failed incorporation by Greece through coup d'état and the Turkish invasion of Cyprus in 1974 led to the formation of the mostly unrecognized Northern Cyprus and has culminated into the present-day Cyprus issue.
The Aegean islands of Imbros and Tenedos which were not ceded to Greece over the course of the 20th century and where the dominant Greek community has faced persecution are also of concern.
Hungary.
The restoration of the borders of Hungary to their state prior to World War I, in order to unite all ethnic Hungarians within the same country once again.
Ireland.
From 1937 until 1999, Articles 2 and 3 of the Constitution of Ireland provided that "national territory consists of the whole island of Ireland". However, "[pending the re-integration of the national territory", the powers of the state were restricted to legislate only for the area that had ceded from the United Kingdom. Arising from the Northern Ireland peace process, the matter was mutually resolved in 1998. The Republic of Ireland's constitution was altered by referendum and its territorial claim to Northern Ireland was suspended. The amended constitution asserts that while it is the entitlement of "every person born in the island of Ireland ... to be part of the Irish Nation" and to hold Irish citizenship, "a united Ireland shall be brought about only by peaceful means with the consent of a majority of the people, democratically expressed, in both jurisdictions in the island." Certain joint policy and executive bodies were created between Northern Ireland, the part of the island that remained in the United Kingdom, and the Republic of Ireland, and these were given executive authority. The advisory and consultative role of the government of Ireland in the government of Northern Ireland granted by the United Kingdom, that had begun with the 1985 Anglo-Irish Agreement, was maintained, although that Agreement itself was ended. The two states also settled the long-running dispute concerning their respective names: "Ireland" and the "United Kingdom of Great Britain and Northern Ireland", with both governments agreeing to use those names.
Italy.
Italy's territorial claims were on the basis of re-establishing a Romanesque Empire, a fourth shore according to the concept of Mare Nostrum (Latin for 'Our Sea') and traditional ethnic borders. Evident in Italy's rapid takeover of surrounding territories under Fascist leader Benito Mussolini and claims following the collapsed 1915 Treaty of London and 1918 Treaty of Versailles which established feelings of betrayal. Similar to the Nazis' stab-in-the-back myth, Mussolini and Hitler's similarities including a joint hatred towards the French and wanting to expand their territories brought the two leaders together, solidified in the Pact of Steel and later WW2. By 1942 Italy had conquered Abyssinia (modern day Ethiopia), Libya, Much of Egypt, Tunisia, Kenya and Somalia. And – on the European continent – Istria, Dalmatia, Albania, Slovenia, Croatia, Macedonia, the Spanish island of Majorca and France's Corsica; Malta was also bombed. Underlying tensions remained with France, over its territories of Corsica, Nice and Savoy.
Macedonia.
The Republic of Macedonia promotes the irredentist concept of a United Macedonia () among ethnic Macedonian nationalists which involves territorial claims on the northern province of Macedonia in Greece, but also in Blagoevgrad Province ("Pirin Macedonia") in Bulgaria, Albania, and Serbia. The United Macedonia concept aims to unify the transnational region of Macedonia in the Balkans (which they claim as their homeland and which they assert was wrongfully divided under the Treaty of Bucharest in 1913), into a single state under Macedonian domination, with the Greek city of Thessaloniki ("Solun" in the Slavic languages) as its capital.
Norway.
The Kingdom of Norway maintains some claim to territories lost at the dissolution of the Denmark-Norway union. The Norwegian Empire, which was the Norwegian territories at its maximum extent, included Iceland, the settleable areas of Greenland, the Faroe Islands and Shetland among others. Under Danish sovereignty since they established a hegemonic position in the Kalmar Union, the territories were considered as Norwegian colonies. When in the Treaty of Kiel in 1814, Norway's territories were transferred from Denmark to Sweden, the territories of Iceland, Greenland, and the Faroe Islands were maintained by Denmark. In 1919, Norway declared sovereignty over an area in Eastern Greenland in the Ihlen Declaration, which led to a dispute with Denmark that was not settled until 1933, by the Permanent Court of International Justice. Norway formerly included the provinces Jämtland, Härjedalen, Idre, Särna (lost since the Second Treaty of Brömsebro), and Bohuslän (lost since the Treaty of Roskilde), which were ceded to Sweden after Danish defeats in wars such as the Thirty Years' War and Second Northern War.
Poland.
Kresy ("Borderlands"), is a term that refers to the eastern lands that formerly belonged to Poland. In 1921, Polish troops crossed the Curzon Line, the border between ethnic Polish and ethnic Ukrainian and Belorussian territories and seized large Ukrainian and Belorussian territories, and also seized 7 percent of Lithuania's territory in 1920. These territories were re-annexed by the Soviet Union in 1939 under the Molotov-Ribbentrop pact, and include major cities, like Lviv (Ukraine), Vilnius (the capital of Lithuania), and Hrodna (Belarus). Even though "Kresy", or the "Eastern Borderlands", are no longer Polish territories, the area is still inhabited by a significant Polish minority, and the memory of a Polish "Kresy" is still cultivated. The attachment to the "myth of Kresy", the vision of the region as a peaceful, idyllic, rural land, has been criticized in Polish discourse.
In January, February and March 2012, the Centre for Public Opinion Research conducted a survey, asking Poles about their ties to the Kresy. It turned out that almost 15% of the population of Poland (4.3–4.6 million people) declared that they had either been born in the Kresy, or had a parent or a grandparent who came from that region. Numerous treasures of Polish culture remain and there are numerous Kresy-oriented organizations. There are Polish sports clubs (Pogoń Lwów, FK Polonia Vilnius), newspapers (Gazeta Lwowska, Kurier Wileński), radio stations (in Lviv and Vilnius), numerous theatres, schools, choirs and folk ensembles. Poles living in "Kresy" are helped by Fundacja Pomoc Polakom na Wschodzie, a Polish government-sponsored organization, as well as other organizations, such as The "Association of Help of Poles in the East Kresy" (see also Karta Polaka). Money is frequently collected to help those Poles who live in "Kresy", and there are several annual events, such as a "Christmas Package for a Polish Veteran in Kresy", and "Summer with Poland", sponsored by the Association "Polish Community", in which Polish children from "Kresy" are invited to visit Poland. Polish language handbooks and films, as well as medicines and clothes are collected and sent to "Kresy". Books are most often sent to Polish schools which exist there — for example, in December 2010, The University of Wrocław organized an event called "Become a Polish Santa Claus and Give a Book to a Polish Child in Kresy". Polish churches and cemeteries (such as Cemetery of the Defenders of Lwów) are renovated with money from Poland.
Portugal.
Portugal does not recognize Spanish sovereignty over the territory of Olivenza, ceded under coercion to Spain during the Napoleonic Wars. Since the Rexurdimento of the mid-nineteenth century, there has been an intellectual movement pleading for the reintegration between Portugal and the region of Galicia, under Spanish sovereignty. Although this movement has become increasingly popular on both sides of the border, there is no consensus in regard to the nature of such "reintegration": whether political, socio-cultural or merely linguistic.
Romania.
Romania lays claims to Greater Romania, which include Bessarabia and Bucovina as Moldova, since they were parts of Romania' and are inhabited in majority by Romanians (same people as Moldavians).
Russia.
The annexation of Crimea by the Russian Federation in 2014 was based on a claim of protecting ethnic Russians residing there. Crimea was part of the Russian Empire from 1783 to 1917, after which it enjoyed a few years of autonomy until it was made part of the Russian Soviet Federative Socialist Republic (which was a part of Soviet Union) from 1921 to 1954 and then transferred to Soviet Ukraine (which also was a part of Soviet Union) in 1954, which remained part of Ukraine until February 2014. Russia declared Crimea to be part of the Russian Federation in March 2014, and effective administration commenced. The Russian regional status is not currently recognised by the UN General Assembly and by many countries.
Russian irredentism also includes southeastern and coastal Ukraine, known as "Novorossiya", a term from the Russian Empire.
Serbia.
Pan-Serbism or Greater Serbia sees the creation of a Serb land which would incorporate all regions of traditional significance to the Serbian nation, and regions outside of Serbia that are populated mostly by Serbs. This movement's main ideology is to unite all Serbs (or all historically ruled or Serb populated lands) into one state, claiming, depending on the version, different areas of many surrounding countries.
Spain.
Spain maintains a claim on Gibraltar, a British Overseas Territory near the southernmost tip of the Iberian Peninsula, which has been British since the 18th Century.
Gibraltar was captured in 1704, during the War of the Spanish Succession (1701–1714). The Kingdom of Castile formally ceded the territory in perpetuity to the British Crown in 1713, under Article X of the Treaty of Utrecht. Spain's territorial claim was formally reasserted by the Spanish dictator Francisco Franco in the 1960s and has been continued by successive Spanish governments. In 2002 an agreement in principle on joint sovereignty over Gibraltar between the governments of the United Kingdom and Spain was decisively rejected in a referendum. The British Government now refuses to discuss sovereignty without the consent of the Gibraltarians.
Western Asia.
Caucasus.
Irredentism is acute in the Caucasus region, too. The Nagorno-Karabakh movement's original slogan of "miatsum" ('union') was explicitly oriented towards unification with Armenia, feeding an Azerbaijani understanding of the conflict as a bilateral one between itself and an irredentist Armenia. According to Prof. Thomas Ambrosio, "Armenia's successful irredentist project in the Nagorno-Karabakh region of Azerbaijan" and "From 1992 to the cease-fire in 1994, Armenia encountered a highly permissive or tolerant international environment that allowed its annexation of some 15 percent of Azerbaijani territory".
In the view of Nadia Milanova, Nagorno-Karabakh represents a combination of separatism and irredentism.
Azerbaijan.
Whole Azerbaijan is a concept based on the political and historical union of territories currently and historically inhabited by Azerbaijanis or historically controlled by them. Western Azerbaijan is an irredentist political concept that is used in Azerbaijan mostly to refer to Armenia. Azerbaijani statements claim that the territory of the modern Armenian republic were lands that once belonged to Azerbaijanis.
Iraq.
Saddam Hussein's Iraq wanted to annex Khuzestan Province of Iran during the Iran–Iraq War due to the Arab population living there.
Kurdistan.
Kurds have often used the ancient entity of Corduene as evidence that they should have a state separate from the countries where they are now a minority.
Lebanon.
The Lebanese nationalism goes even further and incorporates irredentist views going beyond the Lebanese borders, seeking to unify all the lands of ancient Phoenicia around present day Lebanon. This comes from the fact that present day Lebanon, the Mediterranean coast of Syria, and northern Israel is the area that roughly corresponds to ancient Phoenicia and as a result the majority of the Lebanese people identify with the ancient Phoenician population of that region. The proposed Greater Lebanese country includes Lebanon, Mediterranean coast of Syria, and northern Israel.
Syria.
The French Mandate of Syria handed over the Sanjak of Alexandretta to Turkey which turned it into Hatay Province. Syria disputes this and still regards the region as belonging to Syria.
The Syrian Social Nationalist Party, which operates in Lebanon and Syria, works for the unification of most modern states of the Levant and beyond in a single state referred to as Greater Syria. The proposed Syrian country includes Israel, Jordan, Iraq, Kuwait; and southern Turkey, northern Egypt, and southwestern Iran.
Turkey.
Misak-ı Millî is the set of six important decisions made by the last term of the Ottoman Parliament. Parliament met on 28 January 1920 and published their decisions on 12 February 1920. These decisions worried the occupying Allies, resulting in the Occupation of Constantinople by the British, French and Italian troops on 16 March 1920 and the establishment of a new Turkish nationalist parliament, the Grand National Assembly, in Ankara.
The Ottoman Minister of Internal Affairs, Damat Ferid Pasha, made the opening speech of parliament due to Mehmed VI's illness. A group of parliamentarians called "Felâh-ı Vatan" was established by Mustafa Kemal's friends to acknowledge the decisions taken at the Erzurum Congress and the Sivas Congress. Mustafa Kemal said "It is the nation's iron fist that writes the Nation's Oath which is the main principle of our independence to the annals of history." Decisions taken by this parliament were used as the basis for the new Turkish Republic's claims in the Treaty of Lausanne.
United Arab Emirates.
The Greater and Lesser Tunbs are disputed by the United Arab Emirates against Iran.
Yemen.
Greater Yemen is a theory giving Yemen claim to former territories that were held by various predecessor states that existed between the 13th and 18th centuries. The areas claimed include parts of Saudi Arabia and Oman.
East Asia.
China.
When Hong Kong and Macau were British and Portuguese territories, respectively, China considered these two territories to be Chinese territories under British and Portuguese administration, respectively. Therefore, Hong Kong people and Macanese people descended from Chinese immigrants were entitled to Hong Kongs or Macao Special Administrative Region passports after the two territories became the special administrative regions.
Japan.
Japan claims the two southernmost islands of the Russian-administered Kuril Islands, the island chain north of Hokkaido, annexed by the Soviet Union following World War II. Japan also claims the South Korean-administered Liancourt Rocks, which are known as Takeshima in Japan and have been claimed since the end of the Second World War.
Korea.
The 1909 Gando Convention addressed a territory dispute between China and Joseon Korea in China's favor. Both Korean states now accept the convention border as an administrative boundary. However, because the convention was made by the occupying Empire of Japan, South Korea has disputed its legality and some Koreans claim that Korea extends into "de facto" PRC territory, viz. Dandong and Liaoning. The most ambitious claims include all parts of Manchuria that the Goguryeo kingdom controlled.
Mongolia.
The irredentist idea that advocates cultural and political solidarity of Mongols. The proposed territory usually includes the independent state of Mongolia, the Chinese regions of Inner Mongolia (Southern Mongolia) and Dzungaria (in Xinjiang), and the Russian subjects of Buryatia. Sometimes Tuva and the Altai Republic are included as well.
South Asia.
South Asia too is another region in which armed irredentist movements have been active for almost a century, in North-East India, Burma and Bangladesh. Most prominent amongst them are the Naga fight for Greater Nagaland, the Chin struggle for a unified Chinland, the Sri Lankan Tamil struggle for a return of their state under Tamil Eelam and other self-determinist movements by the ethnic indigenous peoples of the erstwhile Assam both under the British and post-British Assam under India.
Bangladesh.
Greater Bangladesh is an assumption of several Indian intellectuals that the neighboring country of Bangladesh has an aspiration to unite all Bengali dominated regions under their flag. These include the states of West Bengal, Tripura and Assam as well as the Andaman Islands which are currently part of India and the Burmese Arakan Province. The theory is principally based on a widespread belief amongst Indian masses that a large number of illegal Bangladeshi immigrants reside in Indian territory. It is alleged that illegal immigration is actively encouraged by some political groups in Bangladesh as well as the state of Bangladesh to convert large parts of India's northeastern states and West Bengal into Muslim-majority areas that would subsequently seek to separate from India and join Muslim-majority Bangladesh. Scholars have reflected that under the guise of anti-Bangladeshi immigrant movement it is actually an anti-Muslim agenda pointed towards Bangladeshi Muslims by false propaganda and widely exaggerated claims on immigrant population. In 1998, Lieutenant General S.K. Sinha, then the Governor of Assam, claimed that massive illegal immigration from Bangladesh was directly linked with "the long-cherished design of Greater Bangladesh.
India.
Akhand Bharat
The call for creation of the "Akhand Bharat" or "Akhand Hindustan" has on occasions been raised by some Indian right wing Hindutvadi cultural and political organisations such as the Hindu Mahasabha, Rashtriya Swayamsevak Sangh (RSS), Vishwa Hindu Parishad, Bharatiya Janata Party (BJP). The name of one organisation sharing this goal, the Akhand Hindustan Morcha, bears the term in its name. Other major Indian non-sectarian political parties such as the Indian National Congress, maintain a position against the partition of India on religious grounds, do not subscribe to a call for Akhand Bharat.
Sri Lanka.
Tamil Eelam is a proposed independent state that Tamils in Sri Lanka and the Sri Lankan Tamil diaspora wish to reclaim in the north and east of Sri Lanka. The name is derived from the ancient Tamil name for Sri Lanka, Eelam. Tamils have often used the former state of the Vanni country, home of the Jaffna kingdom as evidence that they should have a state separate from the countries where they are now a minority. Their former state's dissolution began earlier in Sri Lanka's European colonial history, but was sealed in the Colebrooke–Cameron Commission of British Ceylon in 1833.
Africa.
Irredentism is commonplace in Africa due to the political boundaries of former European colonial nation-states passing through ethnic boundaries, and recent declarations of independence after civil war. For example, some Ethiopian nationalist circles still claim the former Ethiopian province of Eritrea (internationally recognized as the independent State of Eritrea in 1993 after a 30-year civil war).
Somalia.
Greater Somalia refers to the region in the Horn of Africa in which ethnic Somalis are and have historically represented the predominant population. The territory encompasses The Republic of Somalia, the Ogaden region in Ethiopia, the North Eastern Province in Kenya and southern and eastern Djibouti. Ogaden in eastern Ethiopia has seen military and civic movements seeking to make it part of Somalia. This culminated in the 1977–78 Ogaden War between the two neighbours where the Somali military offensive between July 1977 and March 1978 over the disputed Ethiopian region Ogaden ended when the Somali Armed Forces retreated back across the border and a truce was declared. The Kenyan Northern Frontier District also saw conflict during the Shifta War (1963–1967) when a secessionist conflict in which ethnic Somalis in, what is now known as the North Eastern Province of Kenya, attempted to join with their fellow Somalis in a "Greater Somalia". There has been no similar conflicts in Djibouti, which was previously known as the "French Somaliland" during colonisation. Here the apparent struggles for unification manifested itself in political strife that ended when in a referendum to join France as opposed to the Somali Republic succeeded among rumours of widespread vote rigging. and the subsequent death of Somali nationalist Mahmoud Harbi, Vice President of the Government Council, who was killed in a plane crash two years later under suspicious circumstances.
Some sources say that Somalia has also laid a claim to the Socotra archipelago, which is currently governed by Yemen.
North America.
Mexico.
Irredentism is also expressed by some Mexican-American activists in the Reconquista movement. They call for the return of formerly Mexican-dominated lands in the Southwestern United States to Mexico. These lands were annexed by the US in the Treaty of Guadalupe Hidalgo and became the present-day states of California, Texas, Nevada and Utah; and parts of Colorado, Arizona, Wyoming, Oklahoma, Kansas, and New Mexico.

</doc>
<doc id="15227" url="https://en.wikipedia.org/wiki?curid=15227" title="Inuit languages">
Inuit languages

The Inuit languages are a closely related group of Native American languages traditionally spoken across the North American Arctic and to some extent in the subarctic in Labrador. The related Yupik languages are spoken in western and southern Alaska and in the far east of Russia, but are severely endangered in Russia today and spoken only in a few villages on the Chukchi Peninsula. The Inuit live primarily in three countries: Greenland, Canada (specifically in the Nunatsiavut region of Labrador, the Nunavik region of Quebec, Nunavut, and the Northwest Territories), and the United States (specifically the coast of Alaska).
The total population of Inuit speaking their traditional languages is difficult to assess with precision, since most counts rely on self-reported census data that may not accurately reflect usage or competence. Greenland census estimates place the number of speakers of varieties of Inuit there at roughly 50,000, while Canadian estimates are at roughly 35,000. These two countries count the bulk of speakers of Inuit language variants, although about 7,500 Alaskans speak varieties of Inuit out of a population of over 13,000 Inuit.
The Inuit languages have a few hundred speakers in Russia. In addition, an estimated 7,000 Greenlandic Inuit live in European Denmark, the largest group outside of Greenland, Canada and Alaska. Thus, the global population of speakers of varieties of Inuit is on the order of nearly 100,000 people.
Nomenclature.
The traditional language of the Inuit is a system of closely interrelated dialects that are not readily comprehensible from one end of the Inuit world to the other, and some people do not think of it as a single language but rather as a group of languages. However, there are no clear criteria for breaking the Inuit language into specific member languages, since it forms a continuum of close dialects. Each band of Inuit understands its neighbours, and most likely its neighbours' neighbours; but at some remove, comprehensibility drops to a very low level.
As a result, Inuit in different places use different words for its own variants and for the entire group of languages, and this ambiguity has been carried into other languages, creating a great deal of confusion over what labels should be applied to it.
In Greenland the official form of Inuit language, and the official language of the state, is called "Kalaallisut". In other languages, it is often called "Greenlandic" or some cognate term. The Eskimo languages of Alaska are called "Inupiatun", but the variants of the Seward Peninsula are distinguished from the other Alaskan variants by calling them "Qawiaraq", or for some dialects, "Bering Straits Inupiatun".
In Canada, the word "Inuktitut" is routinely used to refer to all Canadian variants of the Inuit traditional language, and it is under that name that it is recognised as one of the official languages of Nunavut and the Northwest Territories. However, one of the variants of western Nunavut is called "Inuinnaqtun" to distinguish itself from the dialects of eastern Canada, while the variants of the Northwest Territories are sometimes called "Inuvialuktun" and have in the past sometimes been called "Inuktun". In those dialects, the name is sometimes rendered as "Inuktitun" to reflect dialectal differences in pronunciation. The Inuit language of Quebec is called "Inuttitut" by its speakers, and often by other people, but this is a minor variation in pronunciation. In Labrador, the language is called "Inuttut" or, often in official documents, by the more descriptive name "Labradorimiutut". Furthermore, Canadians – both Inuit and non-Inuit – sometimes use the word "Inuktitut" to refer to "all" of the Inuit language variants, including those of Alaska and Greenland.
The phrase ""Inuit language"" is largely limited to professional discourse, since in each area, there is one or more conventional terms that cover all the local variants; or it is used as a descriptive term in publications where readers can't necessarily be expected to know the locally used words.
Although many people refer to the Inuit language as "Eskimo language", this is a broad term that also includes Yupik, and is in addition strongly discouraged in Canada and diminishing in usage elsewhere. See the article on "Eskimo" for more information on this word.
Classification and history.
The language of the Inuit is an Eskimo–Aleut language. It is fairly closely related to the Yupik languages, and more remotely to the Aleut language. These cousin languages are all spoken in Western Alaska and Eastern Chukotka, Russia. It is not discernibly related to other North American or northeast Asian indigenous languages, although some have proposed that it is related to Uralic languages such as Finnish and Saami in the proposed Uralo-Siberian grouping, or even Indo-European languages as part of the hypothetical Nostratic superphylum. Some consider it a Paleo-Siberian language, although that is more a geographic than a linguistic grouping.
Early forms of the Inuit language were spoken by the Thule people, who overran the Dorset people, who had previously occupied Arctic America, at the beginning of the second millennium. By 1300, the Inuit and their language had reached western Greenland, and finally east Greenland roughly at the same time the Viking colony in southern Greenland disappeared. It is generally believed that it was during this centuries-long eastward migration that the Inuit language became distinct from the Yupik languages spoken in Western Alaska and Chukotka.
Until 1902, a possible enclave of Dorset people or "Sadlermiut" (in modern Inuktitut spelling "Sallirmiut") existed on Southampton Island. Almost nothing is known about their language, but the few eyewitness accounts tell of them speaking a "strange dialect". This suggests that they also spoke an Eskimo–Aleut language, but one quite distinct from the forms spoken in Canada today.
The Yupik and Inuit languages are very similar syntactically and morphologically. Their common origin can be seen in a number of cognates:
The western Alaskan variants retain a large number of features present in proto-Inuit language and in Yup'ik, enough so that they might be classed as Yup'ik languages if they were viewed in isolation from the larger Inuit world.
Geographic distribution and variants.
The Inuit language is a fairly closely linked set of dialects which can be broken up using a number of different criteria. Traditionally, Inuit describe dialect differences by means of place names to describe local idiosyncrasies in language: The dialect of Iglulik versus the dialect of Iqaluit, for example. However, political and sociological divisions are increasingly the principal criteria for describing different variants of the Inuit language because of their links to different writing systems, literary traditions, schools, media sources and borrowed vocabulary. This makes any partition of the Inuit language somewhat problematic. This article will use labels that try to synthesise linguistic, sociolinguistic and political considerations in splitting up the Inuit dialect spectrum. This scheme is not the only one used or necessarily one used by Inuit themselves, but its labels do try to reflect the usages most seen in popular and technical literature.
In addition to the territories listed below, some 7,000 Greenlandic speakers are reported to live in mainland Denmark, and according to the 2001 census roughly 200 self-reported Inuktitut native speakers regularly live in parts of Canada which are outside of traditional Inuit lands.
Alaska.
Of the roughly 13,000 Alaskan Inupiat, as few as 3,000 may still be able to speak Inuit language variants, with most of them over the age of 40. Alaskan Inuit speak four distinct dialects:
Canada.
The Inuit language is an official language in the Northwest Territories, and the official and dominant language of Nunavut; it enjoys a high level of official support in Nunavik, a semi-autonomous portion of Quebec; and is still spoken in some parts of Labrador. Generally, Canadians refer to all dialects spoken in Canada as "Inuktitut", but the terms "Inuvialuktun", "Inuinnaqtun", "Nunatsiavummiutut", (sometimes called "Inuttut" or "Labradorimiutut") have some currency in referring to the variants of specific areas.
Greenland.
Greenland counts approximately 50,000 speakers of Inuit language variants, of whom over 90% speak west Greenlandic dialects at home.
Phonology and phonetics.
Eastern Canadian Inuit language variants have fifteen consonants and three vowels (which can be long or short).
Consonants are arranged with five places of articulation: bilabial, alveolar, palatal, velar and uvular; and three manners of articulation: voiceless plosives, voiced continuants, and nasals, as well as two additional sounds—voiceless fricatives. The Alaskan dialects have an additional manner of articulation, the "retroflex", which was present in proto-Inuit language. Retroflexes have disappeared in all the Canadian and Greenlandic dialects. In Natsilingmiutut, the voiced palatal plosive derives from a former retroflex.
Almost all Inuit language variants have only three basic vowels and make a phonological distinction between short and long forms of all vowels. The only exceptions are at the extreme edges of the Inuit world: parts of Greenland, and in western Alaska.
Morphology and syntax.
The Inuit language, like other Eskimo–Aleut languages, has a very rich morphological system, in which a succession of different morphemes are added to root words (like verb endings in European languages) to indicate things that, in languages like English, would require several words to express. (See also: Agglutinative language and Polysynthetic language) All Inuit language words begin with a root morpheme to which other morphemes are suffixed. The language has hundreds of distinct suffixes, in some dialects as many as 700. Fortunately for learners, the language has a highly regular morphology. Although the rules are sometimes very complicated, they do not have exceptions in the sense that English and other Indo-European languages do.
This system makes words very long, and potentially unique. For example, in central Nunavut Inuktitut:
This long word is composed of a root word "tusaa-" 'to hear' followed by five suffixes:
This sort of word construction is pervasive in Inuit language and makes it very unlike English. In one large Canadian corpus – the "Nunavut Hansard" – 92% of all words appear only once, in contrast to a small percentage in most English corpora of similar size. This makes the application of Zipf's law quite difficult in the Inuit language. Furthermore, the notion of a part of speech can be somewhat complicated in the Inuit language. Fully inflected verbs can be interpreted as nouns. The word ilisaijuq can be interpreted as a fully inflected verb: "he studies", but can also be interpreted as a noun: "student". That said, the meaning is probably obvious to a fluent speaker, when put in context.
The morphology and syntax of the Inuit language vary to some degree between dialects, and the article "Inuit language morphology and syntax" describes primarily central Nunavut dialects, but the basic principles will generally apply to all of them and to some degree to Yupik as well.
Vocabulary.
Toponymy and names.
Both the names of places and people tend to be highly prosaic when translated. "Iqaluit", for example, is simply the plural of the noun "iqaluk" "fish" ("Arctic char", "salmon" or "trout" depending on dialect). "Iglulik" means "place with houses", a word that could be interpreted as simply "town"; "Inuvik" is "place of people"; "Baffin Island", "Qikiqtaaluk" in Inuit, translates approximately to "big island".
Although practically all Inuit have legal names based on southern naming traditions, at home and among themselves they still use native naming traditions. There too, names tend to consist of highly prosaic words. The Inuit traditionally believed that by adopting the name of a dead person or a class of things, they could take some of their characteristics or powers, and enjoy a part of their identity. (This is why they were always very willing to accept European names: they believed that this made them equal to the Europeans.)
Common native names in Canada include "Ujarak" (rock), "Nuvuk" (headland), "Nasak" (hat, or hood), "Tupiq" or "Tupeq" in Kalaallisut (tent), and "Qajaq" (kayak). Inuit also use animal names, traditionally believing that by using those names, they took on some of the characteristics of that animal: "Nanuq" or "Nanoq" in Kalaallisut (polar-bear), "Uqalik" or "Ukaleq" in Kalaallisut (Arctic hare), and "Tiriaq" or "Teriaq" in Kalaallisut (ermine) are favourites. In other cases, Inuit are named after dead people or people in traditional tales, by naming them after anatomical traits those people are believed to have had. Examples include "Itigaituk" (has no feet), "Anana" or "Anaana" (mother), "Piujuq" (beautiful) and "Tulimak" (rib). Inuit may have any number of names, given by parents and other community members.
Disc numbers and Project Surname.
In the 1920s, changes in lifestyle and serious epidemics like tuberculosis made the government of Canada interested in tracking the Inuit of Canada's Arctic. Traditionally Inuit names reflect what is important in Inuit culture: environment, landscape, seascape, family, animals, birds, spirits. However these traditional names were difficult for non-Inuit to parse. Also, the agglutinative nature of Inuit language meant that names seemed long and were difficult for southern bureaucrats and missionaries to pronounce.
Thus, in the 1940s, the Inuit were given disc numbers, recorded on a special leather ID tag, like a dog tag. They were required to keep the tag with them always. (Some tags are now so old and worn that the number is polished out.) The numbers were assigned with a letter prefix that indicated location (E = east), community, and then the order in which the census-taker saw the individual. In some ways this state renaming was abetted by the churches and missionaries, who viewed the traditional names and their calls to power as related to shamanism and paganism.
They encouraged people to take Christian names. So a young woman who was known to her relatives as "Lutaaq, Pilitaq, Palluq, or Inusiq" and had been baptised as "Annie" was under this system to become Annie E7-121. People adopted the number-names, their family members' numbers, etc., and learned all the region codes (like knowing a telephone area code).
Until Inuit began studying in the south, many did not know that numbers were not normal parts of Christian and English naming systems. Then in 1969, the government started Project Surname, headed by Abe Okpik, to replace number-names with patrilineal "family surnames". But contemporary Inuit carvers and graphic artists still use their disk number as their signature on their works of art.
Words for snow.
A popular belief exists that the Inuit have an unusually large number of words for snow. This is not accurate, and results from a misunderstanding of the nature of polysynthetic languages. In fact, the Inuit have only a few base roots for snow: 'qanniq-' ('qanik-' in some dialects), which is used most often like the verb "to snow", and 'aput', which means "snow" as a substance. Parts of speech work very differently in the Inuit language than in English, so these definitions are somewhat misleading.
The Inuit language can form very long words by adding more and more descriptive affixes to words. Those affixes may modify the syntactic and semantic properties of the base word, or may add qualifiers to it in much the same way that English uses adjectives or prepositional phrases to qualify nouns (e.g. "falling snow", "blowing snow", "snow on the ground", "snow drift", etc.)
The "fact" that there are many Inuit words for snow has been put forward so often that it has become a journalistic cliché.
Numbers.
The Inuit use a base-20 counting system.
Writing.
Because the Inuit language is spread over such a large area, divided between different nations and political units and originally reached by Europeans of different origins at different times, there is no uniform way of writing the Inuit language.
Currently there are six "standard" ways to write the language:
Though all except the syllabics use the Latin alphabet, all of them are a bit different from each other.
Most Inuktitut in Nunavut and Nunavik is written using a script called Inuktitut syllabics, based on Canadian Aboriginal syllabics. The western part of Nunavut and the Northwest Territories use Latin alphabet usually identified as Inuinnaqtun. In Alaska, two other Latin alphabets are used. Nunatsiavut uses an alphabet devised by German-speaking Moravian missionaries, which included the letter "kra". Greenland's Latin alphabet was originally much like the one used in Nunatsiavut, but underwent a spelling reform in 1973 to bring the orthography in line with changes in pronunciation and better reflect the phonemic inventory of the language.
Canadian syllabics.
Inuktitut syllabics, used in Canada, is based on Cree syllabics, which was devised by the missionary James Evans. The present form of Canadian Inuktitut syllabics was adopted by the Inuit Cultural Institute in Canada in the 1970s. The Inuit in Alaska, the Inuvialuit, Inuinnaqtun speakers, and Inuit in Greenland and Labrador use Latin alphabets.
Though presented in syllabic form, syllabics is not a true syllabary, but an alpha-syllabary (abugida), since syllables starting with the same consonant are written with graphically similar letters.
All of the characters needed for Inuktitut syllabics are available in the Unicode character repertoire, in the blocks Unified Canadian Aboriginal Syllabics.

</doc>
<doc id="15229" url="https://en.wikipedia.org/wiki?curid=15229" title="Ibn Battuta">
Ibn Battuta

Early life and first "hajj".
All that is known about Ibn Battuta's life comes from the autobiographical information included in the account of his travels, which records that he was of Berber descent, born into a family of Islamic legal scholars in Tangier, Morocco, on February 25, 1304, during the reign of the Marinid dynasty. He claimed descent from a Berber tribe known as the Lawata. As a young man he would have studied at a Sunni Maliki madh'hab (Islamic jurisprudence school), the dominant form of education in North Africa at that time. In June 1325, at the age of twenty-one, Ibn Battuta set off from his hometown on a "hajj", or pilgrimage, to Mecca, a journey that would take sixteen months. He would not see Morocco again for twenty-four years.
I set out alone, having neither fellow-traveller in whose companionship I might find cheer, nor caravan whose part I might join, but swayed by an overmastering impulse within me and a desire long-cherished in my bosom to visit these illustrious sanctuaries. So I braced my resolution to quit my dear ones, female and male, and forsook my home as birds forsake their nests. My parents being yet in the bonds of life, it weighed sorely upon me to part from them, and both they and I were afflicted with sorrow at this separation.
He travelled to Mecca overland, following the North African coast across the sultanates of Abd al-Wadid and Hafsid. The route took him through Tlemcen, Béjaïa, and then Tunis, where he stayed for two months. For safety, Ibn Battuta usually joined a caravan to reduce the risk of being robbed. He took a bride in the town of Sfax, the first in a series of marriages that would feature in his travels.
In the early spring of 1326, after a journey of over , Ibn Battuta arrived at the port of Alexandria, at the time part of the Bahri Mamluk empire. He met two ascetic pious men in Alexandria. One was Sheikh Burhanuddin who is supposed to have foretold the destiny of Ibn Battuta as a world traveller saying "It seems to me that you are fond of foreign travel. You will visit my brother Fariduddin in India, Rukonuddin in Sind and Burhanuddin in China. Convey my greetings to them". Another pious man Sheikh Murshidi interpreted the meaning of a dream of Ibn Battuta that he was meant to be a world traveller. He spent several weeks visiting sites in the area, and then headed inland to Cairo, the capital of the Mamluk Sultanate and an important large city. After spending about a month in Cairo, he embarked on the first of many detours within the relative safety of Mamluk territory. Of the three usual routes to Mecca, Ibn Battuta chose the least-travelled, which involved a journey up the Nile valley, then east to the Red Sea port of Aydhab. Upon approaching the town, however, a local rebellion forced him to turn back.
Ibn Battuta returned to Cairo and took a second side trip, this time to Mamluk-controlled Damascus. During his first trip he had encountered a holy man who prophesied that he would only reach Mecca by travelling through Syria. The diversion held an added advantage; because of the holy places that lay along the way, including Hebron, Jerusalem, and Bethlehem, the Mamluk authorities spared no efforts in keeping the route safe for pilgrims. Without this help many travellers would be robbed and murdered.
After spending the Muslim month of Ramadan in Damascus, he joined a caravan travelling the south to Medina, site of the tomb of the Islamic prophet Muhammad. After four days in the town, he journeyed on to Mecca, where completing his pilgrimage he took the honorific status of "El-Hajji". Rather than returning home, Ibn Battuta instead decided to continue on, choosing as his next destination the Ilkhanate, a Mongol Khanate, to the northeast.
Iraq and Persia.
On 17 November 1326, following a month spent in Mecca, Ibn Battuta joined a large caravan of pilgrims returning to Iraq across the Arabian Peninsula. The group headed north to Medina and then, travelling at night, turned northeast across the Najd plateau to Najaf, on a journey that lasted about two weeks. In Najaf, he visited the mausoleum of Ali, the Fourth Caliph.
Then, instead of continuing on to Baghdad with the caravan, Ibn Battuta started a six-month detour that took him into Persia. From Najaf, he journeyed to Wasit, then followed the river Tigris south to Basra. His next destination was the town of Isfahan across the Zagros Mountains in Persia. He then headed south to Shiraz, a large, flourishing city spared the destruction wrought by Mongol invaders on many more northerly towns. Finally, he returned across the mountains to Baghdad, arriving there in June 1327. Parts of the city were still ruined from the damage inflicted by Hulago Khan's invading army in 1258.
In Baghdad, he found Abu Sa'id, the last Mongol ruler of the unified Ilkhanate, leaving the city and heading north with a large retinue. Ibn Battuta joined the royal caravan for a while, then turned north on the Silk Road to Tabriz, the first major city in the region to open its gates to the Mongols and by then an important trading centre as most of its nearby rivals had been razed by the Mongol invaders.
Ibn Battuta left again for Baghdad, probably in July, but first took an excursion northwards along the river Tigris. He visited Mosul, where he was the guest of the Ilkhanate governor, and then the towns of Cizre (Jazirat ibn 'Umar) and Mardin in modern-day Turkey. At a hermitage on a mountain near Sinjar, he met a Kurdish mystic who gave him some silver coins. Once back in Mosul, he joined a "feeder" caravan of pilgrims heading south to Baghdad, where they would meet up with the main caravan that crossed the Arabian Desert to Mecca. Ill with diarrhoea, he arrived in the city weak and exhausted for his second "hajj".
Arabian Peninsula.
Ibn Battuta remained in Mecca for some time (the "Rihla" suggests about three years, from September 1327 until autumn 1330). Problems with chronology, however, lead commentators to suggest that he may have left after the 1328 "hajj".
After the "hajj" in either 1328 or 1330, he made his way to the port of Jeddah on the Red Sea coast. From there he followed the coast in a series of boats making slow progress against the prevailing south-easterly winds. Once in Yemen he visited Zabīd and later the highland town of Ta'izz, where he met the Rasulid dynasty king "(Malik)" Mujahid Nur al-Din Ali. Ibn Battuta also mentions visiting Sana'a, but whether he actually did so is doubtful. In all likelihood, he went directly from Ta'izz to the important trading port of Aden, arriving around the beginning of 1329 or 1331.
Somalia.
From Aden, Ibn Battuta embarked on a ship heading for Zeila on the coast of Somalia. He then moved on to Cape Guordafui further down the Somalia seaboard, spending about a week in each location. Later he would visit Mogadishu, the then pre-eminent city of the "Land of the Berbers" (بلد البربر "Balad al-Barbar", the medieval Arabic term for the Horn of Africa).
When Ibn Battuta arrived in 1331, Mogadishu stood at the zenith of its prosperity. He described it as "an exceedingly large city" with many rich merchants, noted for its high-quality fabric that was exported to other countries, including Egypt. Ibn Battuta added that the city was ruled by a Somali Sultan, Abu Bakr ibn Sayx 'Umar, who was originally from Berbera in northern Somalia and spoke both Somali (referred to by Battuta as "Mogadishan", the Benadir dialect of Somali) and Arabic with equal fluency. The Sultan also had a retinue of wazirs (ministers), legal experts, commanders, royal eunuchs, and assorted hangers-on at his beck and call.
Swahili Coast.
Ibn Battuta continued by ship south to the Swahili Coast, a region then known in Arabic as the "Bilad al-Zanj" ("Land of the Zanj"), with an overnight stop at the island town of Mombasa. Although relatively small at the time, Mombasa would become important in the following century. After a journey along the coast, Ibn Battuta next arrived in the island town of Kilwa in present-day Tanzania, which had become an important transit centre of the gold trade. He described the city as "one of the finest and most beautifully built towns; all the buildings are of wood, and the houses are roofed with "dīs" reeds."
Ibn Battuta recorded his visit to the Kilwa Sultanate in 1330, and commented favorably on the humility and religion of its ruler, Sultan al-Hasan ibn Sulaiman, a descendant of the legendary Ali ibn al-Hassan Shirazi. He further wrote that the authority of the Sultan extended from Malindi in the north to Inhambane in the south and was particularly impressed by the planning of the city, believing it to be the reason for Kilwa's success along the coast. From this period date the construction of the Palace of Husuni Kubwa and a significant extension to the Great Mosque of Kilwa, which was made of Coral stones and the largest Mosque of its kind. With a change in the monsoon winds, Ibn Battuta sailed back to Arabia, first to Oman and the Strait of Hormuz then on to Mecca for the "hajj" of 1330 (or 1332).
Anatolia.
After his third pilgrimage to Mecca, Ibn Battuta decided to seek employment with the Muslim Sultan of Delhi, Muhammad bin Tughluq. In the autumn of 1330 (or 1332) he set off for the Seljuq controlled territory of Anatolia with the intention of taking an overland route to India. He crossed the Red Sea and the Eastern Desert to reach the Nile valley and then headed north to Cairo. From there he crossed the Sinai Peninsula to Palestine and then travelled north again through some of the towns that he had visited in 1326. From the Syrian port of Latakia, a Genoese ship took him (and his companions) to Alanya on the southern coast of modern-day Turkey. He then journeyed westwards along the coast to the port of Antalya. In the town he met members of one of the semi-religious "fityan" associations. These were a feature of most Anatonian towns in the 13th and 14th centuries. The members were young artisans and had at their head a leader with the title of "Akhis". The associations specialised in welcoming travellers. Ibn Battuta was very impressed with the hospitality that he received and would later stay in their hospices in more than 25 towns in Anatolia. From Antalya Ibn Battuta headed inland to Eğirdir which was the capital of the Hamid dynasty. He spent Ramadan (June 1331 or May 1333) in the city.
From this point the itinerary across Anatolia in the "Rihla" is confused. Ibn Battuta describes travelling westwards from Eğirdir to Milas and then skipping eastward past Eğirdir to Konya. He then continues travelling in an easterly direction, reaching Erzurum from where he skips back to Birgi which lies north of Milas. Historians believe that Ibn Battuta visited a number of towns in central Anatolia, but not in the order that he describes.
Central Asia and Southern Asia.
From Sinope he took a sea route to the Crimean Peninsula, arriving in the Golden Horde realm. He went to the port town of Azov, where he met with the emir of the Khan, then to the large and rich city of Majar. He left Majar to meet with Uzbeg Khan's travelling court ("Orda"), which was at the time near Beshtau mountain. From there he made a journey to Bolghar, which became the northernmost point he reached, and noted its unusually (for a subtropics dweller) short nights in summer. Then he returned to the Khan's court and with it moved to Astrakhan.
Ibn Battuta recorded that while in Bulghar he wanted to travel further north into the land of darkness. The land is snow-covered throughout (northern Siberia) and the only means of transport is dog-drawn sled. There lived a mysterious people who were reluctant to show themselves. They traded with southern people in a peculiar way. Southern merchants brought various goods and placed them in an open area on the snow in the night, then returned to their tents. Next morning they came to the place again and found their merchandise taken by the mysterious people, but in exchange they found fur-skins which could be used for making valuable coats, jackets, and other winter garments. The trade is done between merchants and the mysterious people without seeing each other. As Ibn Battuta was not a merchant and saw no benefit of going there he abandoned the travel to this land of darkness.
When they reached Astrakhan, Öz Beg Khan had just given permission for one of his pregnant wives, Princess Bayalun, a daughter of Byzantine emperor Andronikos III Palaiologos, to return to her home city of Constantinople to give birth. Ibn Battuta talked his way into this expedition, which would be his first beyond the boundaries of the Islamic world.
Arriving in Constantinople towards the end of 1332 (or 1334), he met the Byzantine emperor Andronikos III Palaiologos. He visited the great church of Hagia Sophia and spoke with an Eastern Orthodox priest about his travels in the city of Jerusalem. After a month in the city, Ibn Battuta returned to Astrakhan, then arrived in the capital city Sarai al-Jadid and reported the accounts of his travels to Sultan Öz Beg Khan (r. 1313–1341). Then he continued past the Caspian and Aral Seas to Bukhara and Samarkand, where he visited the court of another Mongolian king, Tarmashirin (r. 1331–1334) of the Chagatai Khanate. From there, he journeyed south to Afghanistan, ruled by the Mongols, then crossed into India via the mountain passes of the Hindu Kush. In the "Rihla", he mentions these mountains and the history of the range in slave trading. He wrote,
Ibn Battuta and his party reached the Indus River on 12 September 1333. From there, he made his way to Delhi and became acquainted with the sultan, Muhammad bin Tughluq.
India.
Muhammad bin Tughluq was renowned as the wealthiest man in the Muslim world at that time. He patronized various scholars, Sufis, qadis, viziers and other functionaries in order to consolidate his rule. As with Mamluk Egypt, the Tughlaq Dynasty was a rare vestigial example of Muslim rule in Asia after the Mongol invasion. On the strength of his years of study in Mecca, Ibn Battuta was appointed a "qadi", or judge, by the sultan. However, he found it difficult to enforce Islamic law beyond the sultan's court in Delhi, due to lack of Islamic appeal in India.
From the Rajput Kingdom of Sarsatti, Battuta visited Hansi in India, describing it as "among the most beautiful cities, the best constructed and the most populated; it is surrounded with a strong wall, and its founder is said to be one of the great infidel kings, called Tara". Upon his arrival in Sindh, Ibn Battuta mentions the Indian rhinoceros that lived on the banks of the Indus.
The Sultan was erratic even by the standards of the time and for six years Ibn Battuta veered between living the high life of a trusted subordinate and falling under suspicion of treason for a variety of offences. His plan to leave on the pretext of taking another "hajj" was stymied by the Sultan. The opportunity for Battuta to leave Delhi finally arose around 1347 when an embassy arrived from Yuan dynasty China asking for permission to rebuild a Himalayan Buddhist temple popular with Chinese pilgrims.
Ibn Battuta was given charge of the embassy but en route to the coast at the start of the journey to China, he and his large retinue were attacked by a group of bandits. Separated from his companions, he was robbed and nearly lost his life. Despite this setback, within ten days he had caught up with his group and continued on to Khambhat in the Indian state of Gujarat. From there, they sailed to Calicut (now known as Kozhikode), where Portuguese explorer Vasco da Gama would land two centuries later. While in Calicut, Battuta was the guest of the ruling Zamorin. He then sailed on to Quilon (now known as Kollam), one of the busiest port cities on the Southern Coast. His journey from Calicut to Quilon lasted 10 days. While Ibn Battuta visited a mosque on shore, a storm arose and one of the ships of his expedition sank. The other ship then sailed without him only to be seized by a local Sumatran king a few months later.
Afraid to return to Delhi and be seen as a failure, he stayed for a time in southern India under the protection of Jamal-ud-Din, ruler of the small but powerful Nawayath sultanate on the banks of the Sharavathi river next to the Arabian Sea. This area is today known as Hosapattana and lies in the Honavar administrative district of Uttara Kannada. Following the overthrow of the sultanate, Ibn Battuta had no choice but to leave India. Although determined to continue his journey to China, he first took a detour to visit the Maldive Islands.
He spent nine months on the islands, much longer than he had intended. As a "Chief Qadi", his skills were highly desirable in the formerly Buddhist nation that had recently converted to Islam. Half-kidnapped into staying, he became chief judge and married into the royal family of Omar I. He became embroiled in local politics and left when his strict judgments in the laissez-faire island kingdom began to chafe with its rulers. In the "Rihla" he mentions his dismay at the local women going about with no clothing above the waist, and the locals taking no notice when he complained. From the Maldives, he carried on to Sri Lanka and visited Sri Pada and Tenavaram temple.
Ibn Battuta's ship almost sank on embarking from Sri Lanka, only for the vessel that came to his rescue to suffer an attack by pirates. Stranded onshore, he worked his way back to the Madurai kingdom in India. Here he spent some time in the court of the short-lived Madurai Sultanate under Ghiyas-ud-Din Muhammad Damghani, from where he returned to the Maldives and boarded a Chinese junk, still intending to reach China and take up his ambassadorial post.
He reached the port of Chittagong in modern-day Bangladesh intending to travel to Sylhet to meet Shah Jalal, who became so renowned that Ibn Battuta, then in Chittagong, made a one-month journey through the mountains of Kamaru near Sylhet to meet him. On his way to Sylhet, Ibn Battuta was greeted by several of Shah Jalal's disciples who had come to assist him on his journey many days before he had arrived. At the meeting in 1345 CE, Ibn Battuta noted that Shah Jalal was tall and lean, fair in complexion and lived by the mosque in a cave, where his only item of value was a goat he kept for milk, butter, and yogurt. He observed that the companions of the Shah Jalal were foreign and known for their strength and bravery. He also mentions that many people would visit the Shah to seek guidance. Ibn Battuta went further north into Assam, then turned around and continued with his original plan.
Southeast Asia.
In 1345, Ibn Battuta travelled on to Samudra Pasai Sultanate in present-day Aceh, Northern Sumatra, where he notes in his travel log that the ruler of Samudra Pasai was a pious Muslim named Sultan Al-Malik Al-Zahir Jamal-ad-Din, who performed his religious duties with utmost zeal and often waged campaigns against animists in the region. The island of Sumatra, according to Ibn Battuta, was rich in camphor, areca nut, cloves, and tin. The "madh'hab" he observed was Imam Al-Shafi‘i, whose similar customs he had previously seen in coastal India, especially among the Mappila Muslims, who were also followers of Imam Al-Shafi‘i. At that time Samudra Pasai marked the end of Dar al-Islam, because no territory east of this was ruled by a Muslim. Here he stayed for about two weeks in the wooden walled town as a guest of the sultan, and then the sultan provided him with supplies and sent him on his way on one of his own junks to China.
Ibn Battuta first sailed to Malacca on the Malay Peninsula which he described as "Mul Jawi". He met the ruler of Malacca and stayed as a guest for three days. He then sailed to Po Klong Garai (named "Kailukari") in Vietnam where he is said to have briefly met the local princess Urduja, who wrote the word Bismillah in Islamic calligraphy. Ibn Battuta described her people as opponents of the Yuan dynasty. From Po Klong Garai he finally reached Quanzhou in Fujian province, China.
China.
In the year 1345 Ibn Battuta arrived at Quanzhou in China's Fujian province, then under the rule of the Mongols. One of the first things he noted was that Muslims referred to the city as "Zaitun" (meaning olive), but Ibn Battuta could not find any olives anywhere. He mentioned local artists and their mastery in making portraits of newly arrived foreigners; these were for security purposes. Ibn Battuta praised the craftsmen and their silk and porcelain; as well as fruits such as plums and watermelons and the advantages of paper money. He described the manufacturing process of large ships in the city of Quanzhou. He also mentioned Chinese cuisine and its usage of animals such as frogs, pigs and even dogs which were sold in the markets, and noted that the chickens in China were larger in comparison.
In Quanzhou, Ibn Battuta was welcomed by the local Muslim Qadi "Fanzhang" (Judge), Sheikh al-Islam (Imam) and the leader of the local Muslim merchants. who all came to meet him with flags, drums, trumpets and musicians. Ibn Battuta noted that the Muslim populace lived within a separate portion in the city where they had their own mosques, bazaars and hospitals. In Quanzhou, he met two prominent Persians, Burhan al-Din of Kazerun and Sharif al-Din from Tabriz (both of whom were influential figures noted in the "Yuan History" as "A-mi-li-ding" and "Sai-fu-ding", respectively). While in Quanzhou he ascended the "Mount of the Hermit" and briefly visited a well-known Taoist monk in a cave.
He then traveled south along the Chinese coast to Guangzhou, where he lodged for two weeks with one of the city's wealthy merchants.
From Guangzhou he went north to Quanzhou and then proceeded to the city of Fuzhou, where he took up residence with Zahir al-Din and was proud to meet Kawam al-Din and a fellow countryman named Al-Bushri of Ceuta, who had become a wealthy merchant in China. Al-Bushri accompanied Ibn Battuta northwards to Hangzhou and paid for the gifts that Ibn Battuta would present to the Mongolian Emperor Togon-temür of the Yuan Dynasty.
Ibn Battuta said that Hangzhou was one of the largest cities he had ever seen, and he noted its charm, describing that the city sat on a beautiful lake surrounded by gentle green hills. He mentions the city's Muslim quarter and resided as a guest with a family of Egyptian origin. During his stay at Hangzhou he was particularly impressed by the large number of well-crafted and well-painted Chinese wooden ships, with colored sails and silk awnings, assembling in the canals. Later he attended a banquet of the Yuan Mongol administrator of the city named Qurtai, who according to Ibn Battuta, was very fond of the skills of local Chinese conjurers. Ibn Battuta also mentions locals who worship the Solar deity.
He described floating through the Grand Canal on a boat watching crop fields, orchids, merchants in black-silk, and women in flowered-silk and priests also in silk. In Beijing, Ibn Battuta referred to himself as the long-lost ambassador from the Delhi Sultanate and was invited to the Yuan imperial court of Togon-temür (who according to Ibn Battuta was worshipped by some people in China). Ibn Batutta noted that the palace of Khanbaliq was made of wood and that the ruler's "head wife" (Empress Gi) held processions in her honor.
Ibn Battuta also reported "the rampart of Yajuj and Majuj" was "sixty days' travel" from the city of Zeitun (Quanzhou); Hamilton Alexander Rosskeen Gibb notes that Ibn Battuta believed that the Great Wall of China was built by Dhul-Qarnayn to contain Gog and Magog as mentioned in the Quran.
Ibn Battuta travelled from Beijing to Hangzhou, and then proceeded to Fuzhou. Upon his return to Quanzhou, he soon boarded a Chinese junk owned by the Sultan of Samudera Pasai Sultanate heading for Southeast Asia, whereupon Ibn Battuta was unfairly charged a hefty sum by the crew and lost much of what he had collected during his stay in China.
Return home and the Black Death.
After returning to Quanzhou in 1346, Ibn Battuta began his journey back to Morocco. In Kozhikode, he once again considered throwing himself at the mercy of Muhammad bin Tughluq in Delhi, but thought better of it and decided to carry on to Mecca. On his way to Basra he passed through the Strait of Hormuz, where he learned that Abu Sa'id, last ruler of the Ilkhanate Dynasty had died in Persia. Abu Sa'id's territories had subsequently collapsed due to a fierce civil war between the Persians and Mongols.
In 1348, Ibn Battuta arrived in Damascus with the intention of retracing the route of his first "hajj". He then learned that his father had died 15 years earlier and death became the dominant theme for the next year or so. The Black Death had struck and he was on hand as it spread through Syria, Palestine, and Arabia. After reaching Mecca he decided to return to Morocco, nearly a quarter of a century after leaving home. On the way he made one last detour to Sardinia, then in 1349 returned to Tangier by way of Fez, only to discover that his mother had also died a few months before.
Al-Andalus and North Africa.
After a few days in Tangier, Ibn Battuta set out for a trip to the Moor controlled territory of al-Andalus on the Iberian Peninsula. King Alfonso XI of Castile and León had threatened to attack Gibraltar, so in 1350 Ibn Battuta joined a group of Muslims leaving Tangier with the intention of defending the port. By the time he arrived, the Black Death had killed Alfonso and the threat of invasion had receded, so he turned the trip into a sight-seeing tour, traveling through Valencia and ending up in Granada.
After his departure from al-Andalus he decided to travel through Morocco. On his return home, he stopped for a while in Marrakech, which was almost a ghost town following the recent plague and the transfer of the capital to Fez.
Once more Ibn Battuta returned to Tangier, but only stayed for a short while. In 1324, two years before his first visit to Cairo, the West African Malian "Mansa", or king of kings, Musa had passed through the same city on his own "hajj" and caused a sensation with a display of extravagant riches brought from his gold-rich homeland. Although Ibn Battuta never mentioned this visit specifically, when he heard the story it may have planted a seed in his mind as he then decided to cross the Sahara and visit the Muslim kingdoms on its far side.
Mali and Timbuktu.
In the autumn of 1351, Ibn Battuta left Fez and made his way to the town of Sijilmasa on the northern edge of the Sahara in present-day Morocco. There he bought a number of camels and stayed for four months. He set out again with a caravan in February 1352 and after 25 days arrived at the dry salt lake bed of Taghaza with its salt mines. All of the local buildings were made from slabs of salt by the slaves of the Masufa tribe, who cut the salt in thick slabs for transport by camel. Taghaza was a commercial centre and awash with Malian gold, though Ibn Battuta did not form a favourable impression of the place, recording that it was plagued by flies and the water was brackish.
After a ten-day stay in Taghaza, the caravan set out for the oasis of Tasarahla (probably Bir al-Ksaib) where it stopped for three days in preparation for the last and most difficult leg of the journey across the vast desert. From Tasarahla, a Masufa scout was sent ahead to the oasis town of Oualata, where he arranged for water to be transported a distance of four days travel where it would meet the thirsty caravan. Oualata was the southern terminus of the trans-Saharan trade route and had recently become part of the Mali Empire. Altogether, the caravan took two months to cross the of desert from Sijilmasa.
From there, Ibn Battuta travelled southwest along a river he believed to be the Nile (it was actually the river Niger), until he reached the capital of the Mali Empire. There he met "Mansa" Suleyman, king since 1341. Ibn Battuta disapproved of the fact that female slaves, servants and even the daughters of the sultan went about exposing parts of their bodies not befitting a Muslim. He left the capital in February accompanied by a local Malian merchant and journeyed overland by camel to Timbuktu. Though in the next two centuries it would become the most important city in the region, at that time it was a small city and relatively unimportant. It was during this journey that Ibn Battuta first encountered a hippopotamus. The animals were feared by the local boatmen and hunted with lances to which strong cords were attached. After a short stay in Timbuktu, Ibn Battuta journeyed down the Niger to Gao in a canoe carved from a single tree. At the time Gao was an important commercial center.
After spending a month in Gao, Ibn Battuta set off with a large caravan for the oasis of Takedda. On his journey across the desert, he received a message from the Sultan of Morocco commanding him to return home. He set off for Sijilmasa in September 1353, accompanying a large caravan transporting 600 female slaves, and arrived back in Morocco early in 1354.
Ibn Battuta's itinerary gives scholars a glimpse as to when Islam first began to spread into the heart of west Africa.
"Rihla".
After returning home from his travels in 1354, and at the instigation of the Marinid ruler of Morocco, Abu Inan Faris, Ibn Battuta dictated an account of his journeys to Ibn Juzayy, a scholar whom he had previously met in Granada. The account is the only source for Ibn Battuta's adventures. The full title of the manuscript تحفة النظار في غرائب الأمصار وعجائب الأسفار may be translated as "A Gift to Those Who Contemplate the Wonders of Cities and the Marvels of Travelling". However, it is often simply referred to as the "Rihla" الرحلة, or "The Journey".
There is no indication that Ibn Battuta made any notes during his twenty-nine years of travelling. When he came to dictate an account of his experiences he had to rely on memory and manuscripts produced by earlier travellers. Ibn Juzayy did not acknowledge his sources and presented some of the earlier descriptions as Ibn Battuta's own observations. When describing Damascus, Mecca, Medina and some other places in the Middle East, he clearly copied passages from the account by the Andalusian Ibn Jubayr which had been written more than 150 years earlier. Similarly, most of Ibn Juzayy's descriptions of places in Palestine were copied from an account by the 13th-century traveller Muhammad al-Abdari.
Scholars do not believe that Ibn Battuta visited all the places he described and argue that in order to provide a comprehensive description of places in the Muslim world, he relied on hearsay evidence and made use of accounts by earlier travellers. For example, it is considered very unlikely that Ibn Battuta made a trip up the Volga River from New Sarai to visit Bolghar and there are serious doubts about a number of other journeys such as his trip to Sana'a in Yemen, his journey from Balkh to Bistam in Khorasan and his trip around Anatolia. Some scholars have also questioned whether he really visited China. However, even if the "Rihla" is not fully based on what its author personally witnessed, it provides an important account of much of the 14th-century world.
Ibn Battuta often experienced culture shock in regions he visited where the local customs of recently converted peoples did not fit in with his orthodox Muslim background. Among the Turks and Mongols, he was astonished at the freedom and respect enjoyed by women and remarked that on seeing a Turkish couple in a bazaar one might assume that the man was the woman's servant when he was in fact her husband. He also felt that dress customs in the Maldives, and some sub-Saharan regions in Africa were too revealing.
Little is known about Ibn Battuta's life after completion of his "Rihla" in 1355. He was appointed a judge in Morocco and died in 1368 or 1369.
Manuscripts and publication.
Ibn Battuta's work was unknown outside the Muslim world until the beginning of the 19th century when the German traveller-explorer Ulrich Jasper Seetzen (1767–1811) acquired a collection of manuscripts in the Middle East, among which was a 94-page volume containing an abridged version of Ibn Juzayy's text. Three extracts were published in 1818 by the German orientalist Johann Kosegarten. A fourth extract was published the following year. French scholars were alerted to the initial publication by a lengthy review published in the "Journal de Savants" by the orientalist Silvestre de Sacy.
Three copies of another abridged manuscript were acquired by the Swiss traveller Johann Burckhardt and bequeathed to the University of Cambridge. He gave a brief overview of their content in a book published posthumously in 1819. The Arabic text was translated into English by the orientalist Samuel Lee and published in London in 1829.
In the 1830s, during the French occupation of Algeria, the Bibliothèque Nationale (BNF) in Paris acquired five manuscripts of Ibn Battuta's travels, in which two were complete. One manuscript containing just the second part of the work is dated 1356 and is believed to be Ibn Juzayy's autograph. The BNF manuscripts were used in 1843 by the Irish-French orientalist Baron de Slane to produce a translation into French of Ibn Battuta's visit to the Sudan. They were also studied by the French scholars Charles Defrémery and Beniamino Sanguinetti. Beginning in 1853 they published a series of four volumes containing a critical edition of the Arabic text together with a translation into French. In their introduction Defrémery and Sanguinetti praised Lee's annotations but were critical of his translation which they claimed lacked precision, even in straightforward passages.
In 1929, exactly a century after the publication of Lee's translation, the historian and orientalist Hamilton Gibb published an English translation of selected portions of Defrémery and Sanguinetti's Arabic text. Gibb had proposed to the Hakluyt Society in 1922 that he should prepare an annotated translation of the entire "Rihla" into English. His intention was to divide the translated text into four volumes, each volume corresponding to one of the volumes published by Defrémery and Sanguinetti. The first volume was not published until 1958. Gibb died in 1971, having completed the first three volumes. The fourth volume was prepared by Charles Beckingham and published in 1994. Defrémery and Sanguinetti's printed text has now been translated into number of other languages.
Legacy.
Ibn Battuta himself stated according to Ibn Juzayy that:

</doc>
<doc id="15231" url="https://en.wikipedia.org/wiki?curid=15231" title="Integrated Services Digital Network">
Integrated Services Digital Network

Integrated Services for Digital Network (ISDN) is a set of communication standards for simultaneous digital transmission of voice, video, data, and other network services over the traditional circuits of the public switched telephone network. It was first defined in 1988 in the CCITT red book. Prior to ISDN, the telephone system was viewed as a way to transport voice, with some special services available for data. The key feature of ISDN is that it integrates speech and data on the same lines, adding features that were not available in the classic telephone system. The ISDN standards define several kinds of access interfaces, such as Basic Rate Interface (BRI), Primary Rate Interface (PRI), Narrowband ISDN (N-ISDN), and Broadband ISDN (B-ISDN).
ISDN is a circuit-switched telephone network system, which also provides access to packet switched networks, designed to allow digital transmission of voice and data over ordinary telephone copper wires, resulting in potentially better voice quality than an analog phone can provide. It offers circuit-switched connections (for either voice or data), and packet-switched connections (for data), in increments of 64 kilobit/s. In some countries, ISDN found major market application for Internet access, in which ISDN typically provides a maximum of 128 kbit/s bandwidth in both upstream and downstream directions. Channel bonding can achieve a greater data rate; typically the ISDN B-channels of three or four BRIs (six to eight 64 kbit/s channels) are bonded.
ISDN is employed as the network, data-link and physical layers in the context of the OSI model, or could be considered a suite of digital services existing on layers 1, 2, and 3 of the OSI model. In common use, ISDN is often limited to usage to Q.931 and related protocols, which are a set of signaling protocols establishing and breaking circuit-switched connections, and for advanced calling features for the user. They were introduced in 1986.
In a videoconference, ISDN provides simultaneous voice, video, and text transmission between individual desktop videoconferencing systems and group (room) videoconferencing systems.
ISDN elements.
"Integrated services" refers to ISDN's ability to deliver at minimum two simultaneous connections, in any combination of data, voice, video, and fax, over a single line. Multiple devices can be attached to the line, and used as needed. That means an ISDN line can take care of most people's complete communications needs (apart from broadband Internet access and entertainment television) at a much higher transmission rate, without forcing the purchase of multiple analog phone lines. It also refers to integrated switching and transmission in that telephone switching and carrier wave transmission are integrated rather than separate as in earlier technology.
Basic Rate Interface.
The entry level interface to ISDN is the Basic Rate Interface (BRI), a 128 kbit/s service delivered over a pair of standard telephone copper wires. The 144 kbit/s payload rate is broken down into two 64 kbit/s bearer channels ('B' channels) and one 16 kbit/s signaling channel ('D' channel or data channel). This is sometimes referred to as 2B+D.
The interface specifies the following network interfaces:
BRI-ISDN is very popular in Europe but is much less common in North America. It is also common in Japan — where it is known as INS64.
Primary Rate Interface.
The other ISDN access available is the Primary Rate Interface (PRI), which is carried over an E1 (2048 kbit/s) in most parts of the world. An E1 is 30 'B' channels of 64 kbit/s, one 'D' channel of 64 kbit/s and a timing and alarm channel of 64 kbit/s. This is often referred to as 30B+D.
In North America PRI service is delivered on one or more T1 carriers (often referred to as 23B+D) of 1544 kbit/s (24 channels). A PRI has 23 'B' channels and 1 'D' channel for signalling (Japan uses a circuit called a J1, which is similar to a T1). Inter-changeably but incorrectly, a PRI is referred to as T1 because it uses the T1 carrier format. A true T1 (commonly called "Analog T1" to avoid confusion) uses 24 channels of 64 kbit/s of in-band signaling. Each channel uses 56 kb for data and voice and 8 kb for signaling and messaging. PRI uses out of band signaling which provides the 23 B channels with clear 64 kb for voice and data and one 64 kb 'D' channel for signaling and messaging. In North America, Non-Facility Associated Signalling allows two or more PRIs to be controlled by a single D channel, and is sometimes called "23B+D + n*24B". D-channel backup allows for a second D channel in case the primary fails. NFAS is commonly used on a T3.
PRI-ISDN is popular throughout the world, especially for connecting private branch exchanges to the public network.
Even though many network professionals use the term "ISDN" to refer to the lower-bandwidth BRI circuit, in North America BRI is relatively uncommon whilst PRI circuits serving PBXs are commonplace.
Bearer channels.
The bearer channel (B) is a standard 64 kbit/s voice channel of 8 bits sampled at 8 kHz with G.711 encoding. B-Channels can also be used to carry data, since they are nothing more than digital channels.
Each one of these channels is known as a DS0.
Most B channels can carry a 64 kbit/s signal, but some were limited to 56K because they traveled over RBS lines. This was commonplace in the 20th century, but has since become less so.
Signaling channel.
The signaling channel (D) uses Q.931 for signaling with the other side of the link.
X.25.
X.25 can be carried over the B or D channels of a BRI line, and over the B channels of a PRI line. X.25 over the D channel is used at many point-of-sale (credit card) terminals because it eliminates the modem setup, and because it connects to the central system over a B channel, thereby eliminating the need for modems and making much better use of the central system's telephone lines.
X.25 was also part of an ISDN protocol called "Always On/Dynamic ISDN", or AO/DI. This allowed a user to have a constant multi-link PPP connection to the internet over X.25 on the D channel, and brought up one or two B channels as needed.
Frame Relay.
In theory, Frame Relay can operate over the D channel of BRIs and PRIs, but it is seldom, if ever, used.
Consumer and industry perspectives.
There is a second viewpoint: that of the telephone industry, where ISDN is a core technology. A telephone network can be thought of as a collection of wires strung between switching systems. The common electrical specification for the signals on these wires is T1 or E1. Between telephone company switches, the signaling is performed via SS7. Normally, a PBX is connected via a T1 with robbed bit signaling to indicate on-hook or off-hook conditions and MF and DTMF tones to encode the destination number. ISDN is much better because messages can be sent much more quickly than by trying to encode numbers as long (100 ms per digit) tone sequences. This results in faster call setup times. Also, a greater number of features are available and fraud is reduced.
ISDN is also used as a smart-network technology intended to add new services to the public switched telephone network (PSTN) by giving users direct access to end-to-end circuit-switched digital services and as a backup or failsafe circuit solution for critical use data circuits.
ISDN and broadcast industry.
ISDN is used heavily by the broadcast industry as a reliable way of switching low-latency, high-quality, long-distance audio circuits. In conjunction with an appropriate codec using MPEG or various manufacturers proprietary algorithms, an ISDN BRI can be used to send stereo bi-directional audio coded at 128 kbit/s with 20 Hz – 20 kHz audio bandwidth, although commonly the G.722 algorithm is used with a single 64 kbit/s B channel to send much lower latency mono audio at the expense of audio quality. Where very high quality audio is required multiple ISDN BRIs can be used in parallel to provide a higher bandwidth circuit switched connection. BBC Radio 3 commonly makes use of three ISDN BRIs to carry 320 kbit/s audio stream for live outside broadcasts. ISDN BRI services are used to link remote studios, sports grounds and outside broadcasts into the main broadcast studio. ISDN via satellite is used by field reporters around the world. It is also common to use ISDN for the return audio links to remote satellite broadcast vehicles.
In many countries, such as the UK and Australia, ISDN has displaced the older technology of equalised analogue landlines, with these circuits being phased out by telecommunications providers. IP-based streaming codecs are starting to gain a foothold in the broadcast sector, using broadband internet to connect remote studios. However, reliability and latency is crucially important for broadcasters and the quality of service offered by ISDN has not yet been matched by packet switched alternatives.
Countries.
United States and Canada.
ISDN-BRI never gained popularity as a general use telephone access technology in Canada and the US, and remains a niche product. The service was seen as "a solution in search of a problem", and the extensive array of options and features were difficult for customers to understand and use. ISDN has long been known by derogatory backronyms highlighting these issues, such as "It Still Does Nothing, Innovations Subscribers Don't Need," and "I Still Don't kNow."
Once the concept of "broadband Internet access" came to be associated with data rates incoming to the customer at 256 kbit/s or more, and alternatives like ADSL grew in popularity, the consumer market for BRI did not develop. Its only remaining advantage is that while ADSL has a functional distance limitation and can use ADSL loop extenders, BRI has a greater limit and can use repeaters. As such, BRI may be acceptable for customers who are too remote for ADSL. Widespread use of BRI is further stymied by some small North American CLECs such as CenturyTel having given up on it and not providing Internet access using it. However, AT&T in most states (especially the former SBC/SWB territory) will still install an ISDN BRI line anywhere a normal analog line can be placed and the monthly charge is roughly $55.
ISDN-BRI is currently primarily used in industries with specialized and very specific needs. High-end videoconferencing hardware made by companies such as Sony, Polycom, Tandberg, and LifeSize via the LifeSize Networker can bond up to 8 B-channels together (using a BRI circuit for every 2 channels) to provide digital, circuit-switched video connections to almost anywhere in the world. This is very expensive, and is being replaced by IP-based conferencing, but where cost concern is less of an issue than predictable quality and where a QoS-enabled IP does not exist, BRI is the preferred choice.
Most modern non-VoIP PBXs use ISDN-PRI circuits. These are connected via T1 lines with the central office switch, replacing older analog two-way and direct inward dialing (DID) trunks. PRI is capable of delivering Calling Line Identification (CLID) in both directions so that the telephone number of an extension, rather than a company's main number, can be sent. It is still commonly used in recording studios, when a voice-over actor is in one studio, but the director and producer are in a studio at another location. The ISDN protocol delivers channelized, not-over-the-Internet service, powerful call setup and routing features, faster setup and tear down, superior audio fidelity as compared to POTS (plain old telephone service), lower delay and, at higher densities, lower cost.
In 2013, Verizon announced it would no longer take orders for ISDN service in the Northeastern United States.
India.
Bharat Sanchar Nigam Limited, Reliance Communications and Bharti Airtel are the largest communication service providers, and offer both ISDN BRI and PRI services across the country. Reliance Communications and Bharti Airtel uses the DLC technology for providing these services. With the introduction of broadband technology, the load on bandwidth is being absorbed by ADSL. ISDN continues to be an important backup network for point-to-point leased line customers such as banks, Eseva Centers, Life Insurance Corporation of India, and SBI ATMs.
Japan.
On April 19, 1988, Japanese telecommunications company NTT began offering nationwide ISDN services trademarked INS Net 64, and INS Net 1500, a fruition of NTT's independent research and trial from the 1970s of what it referred to the INS (Information Network System).
Previously, on April 1985, Japanese digital telephone exchange hardware made by Fujitsu was used to experimentally deploy the world's first I interface ISDN. The I interface, unlike the older and incompatible Y interface, is what modern ISDN services use today.
Since 2000, NTT's ISDN offering have been known as FLET's ISDN, incorporating the "FLET's" brand that NTT uses for all of its ISP offerings.
In Japan, the number of ISDN subscribers dwindled as alternative technologies such as ADSL, cable Internet access, and fiber to the home gained greater popularity. On November 2, 2010, NTT announced plans to migrate their backend from PSTN to the IP network from around 2020 to around 2025. For this migration, ISDN services will be retired, and fiber optic services are recommended as an alternative.
United Kingdom.
In the United Kingdom, British Telecom (BT) provides ISDN2e (BRI) as well as ISDN30 (PRI). Until April 2006, they also offered services named Home Highway and Business Highway, which were BRI ISDN-based services that offered integrated analogue connectivity as well as ISDN. Later versions of the Highway products also included built-in universal serial bus (USB) sockets for direct computer access. Home Highway was bought by many home users, usually for Internet connection, although not as fast as ADSL, because it was available before ADSL and in places where ADSL does not reach.
In early 2015, BT announced their intention to retire the UK's ISDN infrastructure by 2025.
France.
France Telecom offers ISDN services under their product name Numeris (2 B+D), of which a professional Duo and home Itoo version is available. ISDN is generally known as RNIS in France and has widespread availability. The introduction of ADSL is reducing ISDN use for data transfer and Internet access, although it is still common in more rural and outlying areas, and for applications such as business voice and point-of-sale terminals.
Germany.
In Germany, ISDN is very popular with an installed base of 25 million channels (29% of all subscriber lines in Germany as of 2003 and 20% of all ISDN channels worldwide). Due to the success of ISDN, the number of installed analog lines is decreasing. Deutsche Telekom (DTAG) offers both BRI and PRI. Competing phone companies often offer ISDN only and no analog lines. However, these operators generally offer free hardware that also allows the use of POTS equipment, such as NTBAs with integrated terminal adapters. Because of the widespread availability of ADSL services, ISDN is today primarily used for voice and fax traffic, but is still very popular thanks to the pricing policy of German telecommunication providers.
Today ISDN (BRI) and ADSL/VDSL are often bundled on the same line, mainly because the combination of ADSL with an analog line has no cost advantage over a combined ISDN-ADSL line. Some German operators started to implement Next Generation Networking, generally realized via DSL and unbundled local loop. However, a few operators offer the same services via the cable television infrastructure or, in selected areas, via FTTH. Because of the popularity of ISDN, virtually all these telecommunication providers bundle their products with residential gateways that include both integrated analog telephony adapters and ISDN-NGN adapters.
Greece.
OTE, the incumbent telecommunications operator, offers ISDN BRI (BRA) services in Greece. Following the launch of ADSL in 2003, the importance of ISDN for data transfer began to decrease and is today limited to niche business applications with point-to-point requirements.
International deployment.
A study of the German Department of Science shows the following spread of ISDN-channels per 1,000 inhabitants in the year 2005:
Configurations.
In ISDN, there are two types of channels, "B" (for "bearer") and "D" (for "data"). "B channels" are used for data (which may include voice), and "D channels" are intended for signaling and control (but can also be used for data).
There are two ISDN implementations. Basic Rate Interface (BRI), also called basic rate access (BRA) — consists of two B channels, each with bandwidth of 64 kbit/s, and one D channel with a bandwidth of 16 kbit/s. Together these three channels can be designated as 2B+D. Primary Rate Interface (PRI), also called primary rate access (PRA) in Europe — contains a greater number of B channels and a D channel with a bandwidth of 64 kbit/s. The number of B channels for PRI varies according to the nation: in North America and Japan it is 23B+1D, with an aggregate bit rate of 1.544 Mbit/s (T1); in Europe, India and Australia it is 30B+1D, with an aggregate bit rate of 2.048 Mbit/s (E1). Broadband Integrated Services Digital Network (BISDN) is another ISDN implementation and it is able to manage different types of services at the same time. It is primarily used within network backbones and employs ATM.
Another alternative ISDN configuration can be used in which the B channels of an ISDN BRI line are bonded to provide a total duplex bandwidth of 128 kbit/s. This precludes use of the line for voice calls while the internet connection is in use. The B channels of several BRIs can be bonded, a typical use is a 384K videoconferencing channel.
Using bipolar with eight-zero substitution encoding technique, call data is transmitted over the data (B) channels, with the signaling (D) channels used for call setup and management. Once a call is set up, there is a simple 64 kbit/s synchronous bidirectional data channel (actually implemented as two simplex channels, one in each direction) between the end parties, lasting until the call is terminated. There can be as many calls as there are bearer channels, to the same or different end-points. Bearer channels may also be multiplexed into what may be considered single, higher-bandwidth channels via a process called B channel BONDING, or via use of Multi-Link PPP "bundling" or by using an H0, H11, or H12 channel on a PRI.
The D channel can also be used for sending and receiving X.25 data packets, and connection to X.25 packet network, this is specified in X.31. In practice, X.31 was only commercially implemented in UK, France and Japan.
Reference points.
A set of "reference points" are defined in the ISDN standard to refer to certain points between the telco and the end user ISDN equipment.
Most NT-1 devices can perform the functions of the NT2 as well, and so the S and T reference points are generally collapsed into the S/T reference point.
In North America, the NT1 device is considered customer premises equipment (CPE) and must be maintained by the customer, thus, the U interface is provided to the customer. In other locations, the NT1 device is maintained by the telco, and the S/T interface is provided to the customer. In India, service providers provide U interface and an NT1 may be supplied by Service provider as part of service offering.
Types of communications.
Among the kinds of data that can be moved over the 64 kbit/s channels are pulse-code modulated voice calls, providing access to the traditional voice PSTN. This information can be passed between the network and the user end-point at call set-up time. In North America, ISDN is now used mostly as an alternative to analog connections, most commonly for Internet access. Some of the services envisioned as being delivered over ISDN are now delivered over the Internet instead. In Europe, and in Germany in particular, ISDN has been successfully marketed as a phone with features, as opposed to a POTS phone with few or no features. Meanwhile, features that were first available with ISDN (such as Three-Way Calling, Call Forwarding, Caller ID, etc.) are now commonly available for ordinary analog phones as well, eliminating this advantage of ISDN. Another advantage of ISDN was the possibility of multiple simultaneous calls (one call per B channel), e.g. for big families, but with the increased popularity and reduced prices of mobile telephony this has become less interesting as well, making ISDN unappealing to the private customer. However, ISDN is typically more reliable than POTS, and has a significantly faster call setup time compared with POTS, and IP connections over ISDN typically have some 30–35ms round trip time, as opposed to 120–180ms (both measured with otherwise unused lines) over 56k or V.34/V.92 modems, making ISDN more reliable and more efficient for telecommuters.
Where an analog connection requires a modem, an ISDN connection requires a terminal adapter (TA). The function of an ISDN terminal adapter is often delivered in the form of a PC card with an S/T interface, and single-chip solutions seem to exist, considering the plethora of combined ISDN- and ADSL-routers.
ISDN is commonly used in radio broadcasting. Since ISDN provides a high quality connection this assists in delivering good quality audio for transmission in radio. Most radio studios are equipped with ISDN lines as their main form of communication with other studios or standard phone lines. Equipment made by companies such as Telos/Omnia (the popular Zephyr codec), Comrex, Tieline and others are used regularly by radio broadcasters. Almost all live sports broadcasts on radio are backhauled to their main studios via ISDN connections.
Sample call.
The following is an example of a Primary Rate (PRI) ISDN call showing the Q.921/LAPD and the Q.931/Network message intermixed (i.e. exactly what was exchanged on the D-channel). The call is originating from the switch where the trace was taken and goes out to some other switch, possibly an end-office LEC, who terminates the call.
The first line format is <time> <D-channel> <Transmitted/Received> <LAPD/ISDN message ID>. If the message is an ISDN level message, then a decoding of the message is attempted showing the various Information Elements that make up the message. All ISDN messages are tagged with an ID number relative to the switch that started the call (local/remote). Following this optional decoding is a dump of the bytes of the message in <offset> <hex> ... <hex> <ascii> ... <ascii> format.
The RR messages at the beginning prior to the call are the keep alive messages. SETUP message indicate the start of the call. Each message is acknowledged by the other side with a RR.
See also.
Protocols.
Specifications defining the physical layer and part of the data link layers of ISDN:
From the point of view of the OSI architecture, an ISDN line has a stack of three protocols
External links.
<html></html>

</doc>
<doc id="15235" url="https://en.wikipedia.org/wiki?curid=15235" title="Genomic imprinting">
Genomic imprinting

Genomic imprinting is the epigenetic phenomenon by which certain genes are expressed in a parent-of-origin-specific manner. If the allele inherited from the father is imprinted, it is thereby silenced, and only the allele from the mother is expressed. If the allele from the mother is imprinted, then only the allele from the father is expressed. Forms of genomic imprinting have been demonstrated in fungi, plants and animals. As of 2014, there are about 150 imprinted genes known in the mouse and about half that in humans.
Genomic imprinting is an inheritance process independent of the classical Mendelian inheritance. It is an epigenetic process that involves DNA methylation and histone methylation without altering the genetic sequence. These epigenetic marks are established ("imprinted") in the germline (sperm or egg cells) of the parents and are maintained through mitotic cell divisions in the somatic cells of an organism.
Appropriate imprinting of certain genes is important for normal development. Human diseases involving genomic imprinting include Angelman syndrome and Prader–Willi syndrome.
Overview.
In diploid organisms (like humans), the somatic cells possess two copies of the genome, one inherited from the father and one from the mother. Each autosomal gene is therefore represented by two copies, or alleles, with one copy inherited from each parent at fertilization. For the vast majority of autosomal genes, expression occurs from both alleles simultaneously. In mammals, however, a small proportion (<1%) of genes are imprinted, meaning that gene expression occurs from only one allele. (some recent studies have questioned this assertion, claiming that the number of regions of parent-of-origin methylation in, for example, the human genome, is much larger than previously thought). The expressed allele is dependent upon its parental origin. For example, the gene encoding insulin-like growth factor 2 (IGF2/Igf2) is only expressed from the allele inherited from the father; this is called paternal imprinting.
The term "imprinting" was first used to describe events in the insect "Pseudococcus nipae". In Pseudococcids (mealybugs) (Hemiptera, Coccoidea) both the male and female develop from a fertilised egg. In females, all chromosomes remain euchromatic and functional. In embryos destined to become males, one haploid set of chromosomes becomes heterochromatinised after the sixth cleavage division and remains so in most tissues; males are thus functionally haploid.
In mammals, genomic imprinting describes the processes involved in introducing functional inequality between two parental alleles of a gene.
Imprinted genes in mammals.
That imprinting might be a feature of mammalian development was suggested in breeding experiments in mice carrying reciprocal chromosomal translocations. Nucleus transplantation experiments in mouse zygotes in the early 1980s confirmed that normal development requires the contribution of both the maternal and paternal genomes. The vast majority of mouse embryos derived from parthenogenesis (called parthenogenones, with two maternal or egg genomes) and androgenesis (called androgenones, with two paternal or sperm genomes) die at or before the blastocyst/implantation stage. In the rare instances that they develop to postimplantation stages, gynogenetic embryos show better embryonic development relative to placental development, while for androgenones, the reverse is true. Nevertheless, for the latter, only a few have been described (in a 1984 paper).
No naturally occurring cases of parthenogenesis exist in mammals because of imprinted genes. However, in 2004, experimental manipulation by Japanese researchers of a paternal methylation imprint controlling the "Igf2" gene led to the birth of a mouse (named Kaguya) with two maternal sets of chromosomes, though it is not a true parthenogenone since cells from two different female mice were used. The researchers were able to succeed by using one egg from an immature parent, thus reducing maternal imprinting, and modifying it to express the gene Igf2, which is normally only expressed by the paternal copy of the gene.
Parthenogenetic/gynogenetic embryos have twice the normal expression level of maternally derived genes, and lack expression of paternally expressed genes, while the reverse is true for androgenetic embryos. It is now known that there are at least 80 imprinted genes in humans and mice, many of which are involved in embryonic and placental growth and development. Hybrid offspring of two species may exhibit unusual growth due to the novel combination of imprinted genes.
Various methods have been used to identify imprinted genes. In swine, Bischoff "et al." 2009 compared transcriptional profiles using short-oligonucleotide microarrays to survey differentially expressed genes between parthenotes (2 maternal genomes) and control fetuses (1 maternal, 1 paternal genome). An intriguing study surveying the transcriptome of murine brain tissues revealed over 1300 imprinted gene loci (approximately 10-fold more than previously reported) by RNA-sequencing from F1 hybrids resulting from reciprocal crosses. The result however has been challenged by others who claimed that this is an overestimation by an order of magnitude due to flawed statistical analysis.
In domesticated livestock, single-nucleotide polymorphisms in imprinted genes influencing foetal growth and development have been shown to be associated with economically important production traits in cattle, sheep and pigs.
Genetic mapping of imprinted genes.
At the same time as the generation of the gynogenetic and androgenetic embryos discussed above, mouse embryos were also being generated that contained only small regions that were derived from either a paternal or maternal source. The generation of a series of such uniparental disomies, which together span the entire genome, allowed the creation of an imprinting map. Those regions which when inherited from a single parent result in a discernible phenotype contain imprinted gene(s). Further research showed that within these regions there were often numerous imprinted genes. Around 80% of imprinted genes are found in clusters such as these, called imprinted domains, suggesting a level of co-ordinated control. More recently, genome-wide screens to identify imprinted genes have used differential expression of mRNAs from control fetuses and parthenogenetic or androgenetic fetuses hybridized to expression arrays, allele-specific gene expression using SNP genotyping arrays, transcriptome sequencing, and in silico prediction pipelines.
Imprinting mechanisms.
Imprinting is a dynamic process. It must be possible to erase and re-establish imprints through each generation so that genes that are imprinted in an adult may still be expressed in that adult's offspring. (For example the maternal genes that control insulin production will be imprinted in a male but will be expressed in any of the male's offspring that inherit these genes.) The nature of imprinting must therefore be epigenetic rather than DNA sequence dependent. In germline cells the imprint is erased and then re-established according to the sex of the individual, i.e. in the developing sperm (during spermatogenesis), a paternal imprint is established, whereas in developing oocytes (oogenesis), a maternal imprint is established. This process of erasure and reprogramming is necessary such that the germ cell imprinting status is relevant to the sex of the individual. In both plants and mammals there are two major mechanisms that are involved in establishing the imprint; these are DNA methylation and histone modifications.
Recently, a new study has suggested a novel inheritable imprinting mechanism in humans that would be specific of placental tissue and that is independent of DNA methylation (the main and classical mechanism for genomic imprinting). Among the hypothetical explanations for this exclusively human phenomenon, two possible mechanisms have been proposed: either a histone modification that confers imprinting at novel placental-specific imprinted "loci" or, alternatively, a recruitment of DNMTs to these loci by a specific and unknown transcription factor that would be expressed during early trophoblast differentiation.
Regulation.
The grouping of imprinted genes within clusters allows them to share common regulatory elements, such as non-coding RNAs and differentially methylated regions (DMRs). When these regulatory elements control the imprinting of one or more genes, they are known as imprinting control regions (ICR). The expression of non-coding RNAs, such as "Air" on mouse chromosome 17 and KCNQ1OT1 on human chromosome 11p15.5, have been shown to be essential for the imprinting of genes in their corresponding regions.
Differentially methylated regions are generally segments of DNA rich in cytosine and guanine nucleotides, with the cytosine nucleotides methylated on one copy but not on the other. Contrary to expectation, methylation does not necessarily mean silencing; instead, the effect of methylation depends upon the default state of the region.
Functions of imprinted genes.
The control of expression of specific genes by genomic imprinting is unique to therian mammals (placental mammals and marsupials) and flowering plants. Imprinting of whole chromosomes has been reported in mealybugs (Genus: "Pseudococcus"). and a fungus gnat ("Sciara"). It has also been established that X-chromosome inactivation occurs in an imprinted manner in the extra-embryonic tissues of mice and all tissues in marsupials, where it is always the paternal X-chromosome which is silenced.
The majority of imprinted genes in mammals have been found to have roles in the control of embryonic growth and development, including development of the placenta. Other imprinted genes are involved in post-natal development, with roles affecting suckling and metabolism.
Theories on the origins of imprinting.
A widely accepted hypothesis for the evolution of genomic imprinting is the "parental conflict hypothesis." Also known as the kinship theory of genomic imprinting, this hypothesis states that the inequality between parental genomes due to imprinting is a result of the differing interests of each parent in terms of the evolutionary fitness of their genes. The father's genes that encode for imprinting gain greater fitness through the success of the offspring, at the expense of the mother. The mother's evolutionary imperative is often to conserve resources for her own survival while providing sufficient nourishment to current and subsequent litters. Accordingly, paternally expressed genes tend to be growth promoting whereas maternally expressed genes tend to be growth limiting. In support of this hypothesis, genomic imprinting has been found in all placental mammals, where post-fertilisation offspring resource consumption at the expense of the mother is high; although it has also been found in oviparous birds where there is relatively little post-fertilisation resource transfer and therefore less parental conflict.
However, our understanding of the molecular mechanisms behind genomic imprinting show that it is the maternal genome that controls much of the imprinting of both its own and the paternally-derived genes in the zygote, making it difficult to explain why the maternal genes would willingly relinquish their dominance to that of the paternally-derived genes in light of the conflict hypothesis.
Another hypothesis proposed is that some imprinted genes act coadaptively to improve both fetal development and maternal provisioning for nutrition and care. In it a subset of paternally expressed genes are co-expressed in both the placenta and the mother's hypothalamus. This would come about through selective pressure from parent-infant coadaptation to improve infant survival. Paternally expressed 3 (Peg3) is a gene for which this hypothesis may apply.
Others have approached their study of the origins of genomic imprinting from a different side, arguing that natural selection is operating on the role of epigenetic marks as machinery for homologous chromosome recognition during meiosis, rather than on their role in differential expression. This argument centers on the existence of epigenetic effects on chromosomes that do not directly affect gene expression, but do depend on which parent the chromosome originated from. This group of epigenetic changes that depend on the chromosome's parent of origin (including both those that affect gene expression and those that do not) are called parental origin effects, and include phenomena such as paternal X inactivation in the marsupials, nonrandom parental chromatid distribution in the ferns, and even mating type switching in yeast. This diversity in organisms that show parental origin effects has prompted theorists to place the evolutionary origin of genomic imprinting before the last common ancestor of plants and animals, over a billion years ago.
Natural selection for genomic imprinting requires genetic variation in a population. A hypothesis for the origin of this genetic variation states that the host-defense system responsible for silencing foreign DNA elements, such as genes of viral origin, mistakenly silenced genes whose silencing turned out to be beneficial for the organism. There appears to be an over-representation of retrotransposed genes, that is to say genes that are inserted into the genome by viruses, among imprinted genes. It has also been postulated that if the retrotransposed gene is inserted close to another imprinted gene, it may just acquire this imprint.
Disorders associated with imprinting.
Imprinting may cause problems in cloning, with clones having DNA that is not methylated in the correct positions. It is possible that this is due to a lack of time for reprogramming to be completely achieved. When a nucleus is added to an egg during somatic cell nuclear transfer, the egg starts dividing in minutes, as compared to the days or months it takes for reprogramming during embryonic development. If time is the responsible factor, it may be possible to delay cell division in clones, giving time for proper reprogramming to occur.
An allele of the "callipyge" (from the Greek for "beautiful buttocks"), or CLPG, gene in sheep produces large buttocks consisting of muscle with very little fat. The large-buttocked phenotype only occurs when the allele is present on the copy of chromosome 18 inherited from a sheep's father and is "not" on the copy of chromosome 18 inherited from that sheep's mother.
In vitro fertilisation, including ICSI, is associated with an increased risk of imprinting disorders, with an odds ratio of 3.7 (95% confidence interval 1.4 to 9.7).
Prader-Willi/Angelman.
The first imprinted genetic disorders to be described in humans were the reciprocally inherited Prader-Willi syndrome and Angelman syndrome. Both syndromes are associated with loss of the chromosomal region 15q11-13 (band 11 of the long arm of chromosome 15). This region contains the paternally expressed genes SNRPN and NDN and the maternally expressed gene UBE3A.
DIRAS3 (NOEY2 or ARH1).
DIRAS3 is a paternally expressed and maternally imprinted gene located on chromosome 1 in humans. Reduced DIRAS3 expression is linked to an increased risk of ovarian and breast cancers; in 41% of breast and ovarian cancers the protein encoded by DIRAS3 is not expressed, suggesting that it functions as a tumor suppressor gene Therefore, if uniparental disomy occurs and a person inherits both chromosomes from the mother, the gene will not be expressed and the individual is put at a greater risk for breast and ovarian cancer.
Other.
Other conditions involving imprinting include Beckwith-Wiedemann syndrome, Silver-Russell syndrome, and pseudohypoparathyroidism.
Transient neonatal diabetes mellitus can also involve imprinting.
The "imprinted brain theory" argues that unbalanced imprinting may be a cause of autism and psychosis.
Imprinted genes in other animals.
In insects, imprinting affects entire chromosomes. In some insects the entire paternal genome is silenced in male offspring, and thus is involved in sex determination. The imprinting produces effects similar to the mechanisms in other insects that eliminate paternally inherited chromosomes in male offspring, including arrhenotoky.
In placental species, parent-offspring conflict can result in the evolution of strategies, such as genomic imprinting, for embryos to subvert maternal nutrient provisioning. Despite several attempts to find it, genomic imprinting has not been found in the platypus, reptiles, birds or fish. The absence of genomic imprinting in a placental reptile, the southern grass skink, is interesting as genomic imprinting was thought to be associated with the evolution of viviparity and placental nutrient transport.
Imprinted genes in plants.
A similar imprinting phenomenon has also been described in flowering plants (angiosperms). During fertilisation of the egg cell, a second, separate fertilization event gives rise to the endosperm, an extraembryonic structure that nourishes the embryo in a manner analogous to the mammalian placenta. Unlike the embryo, the endosperm is often formed from the fusion of two maternal cells with a male gamete. This results in a triploid genome. The 2:1 ratio of maternal to paternal genomes appears to be critical for seed development. Some genes are found to be expressed from both maternal genomes while others are expressed exclusively from the lone paternal copy. It has been suggested that these imprinted genes are responsible for the triploid block effect in flowering plants that prevents hybridization between diploids and autotetraploids.

</doc>
<doc id="15236" url="https://en.wikipedia.org/wiki?curid=15236" title="ICANN">
ICANN

The Internet Corporation for Assigned Names and Numbers (ICANN ) is a nonprofit organization that is responsible for coordinating the maintenance and procedures of several databases related to the namespaces of the Internet - thereby ensuring the network's stable and secure operation. ICANN performs the actual technical maintenance work of the central Internet address pools and DNS Root registries pursuant to the Internet Assigned Numbers Authority (IANA) function contract.
Much of its work has concerned the Internet's global Domain Name System, including policy development for internationalization of the DNS system, introduction of new generic top-level domains (TLDs), and the operation of root name servers. The numbering facilities ICANN manages include the Internet Protocol address spaces for IPv4 and IPv6, and assignment of address blocks to regional Internet registries. ICANN also maintains registries of Internet protocol identifiers.
ICANN's primary principles of operation have been described as helping preserve the operational stability of the Internet; to promote competition; to achieve broad representation of the global Internet community; and to develop policies appropriate to its mission through bottom-up, consensus-based processes.
ICANN was created on September 18, 1998, and incorporated on September 30, 1998 in the state of California. It is headquartered in the Playa Vista neighborhood of the city of Los Angeles. 
History.
Before the establishment of ICANN, the IANA function of administering registries of Internet protocol identifiers (including the distributing top-level domains and IP addresses) was performed by Jon Postel, a Computer Science researcher who had been involved in the creation of ARPANET, first at UCLA and then at the University of Southern California's Information Sciences Institute (ISI). In 1997 Postel testified before Congress that this had come about as a "side task" to this research work. The Information Sciences Institute was funded by the U.S. Department of Defense, as was SRI International's Network Information Center, which also performed some assigned name functions.
As the Internet grew and expanded globally, the U.S. Department of Commerce initiated a process to establish a new organization to perform the IANA functions. On January 30, 1998, the National Telecommunications and Information Administration (NTIA), an agency of the U.S. Department of Commerce, issued for comment, "A Proposal to Improve the Technical Management of Internet Names and Addresses." The proposed rule making, or "Green Paper", was published in the Federal Register on February 20, 1998, providing opportunity for public comment. NTIA received more than 650 comments as of March 23, 1998, when the comment period closed.
The Green Paper proposed certain actions designed to privatize the management of Internet names and addresses in a manner that allows for the development of competition and facilitates global participation in Internet management. The Green Paper proposed for discussion a variety of issues relating to DNS management including private sector creation of a new not-for-profit corporation (the "new corporation") managed by a globally and functionally representative Board of Directors. ICANN was formed in response to this policy. ICANN manages the Internet Assigned Numbers Authority (IANA) under contract to the United States Department of Commerce (DOC) and pursuant to an agreement with the IETF.
ICANN was incorporated in California on September 30, 1998, with entrepreneur and philanthropist Esther Dyson as founding chairwoman. It is qualified to do business in the District of Columbia. ICANN was established in California due to the presence of Jon Postel, who was a founder of ICANN and was set to be its first Chief Technology Officer prior to his unexpected death. ICANN formerly operated from the same Marina del Rey building where Postel formerly worked, which is home to an office of the Information Sciences Institute at the University of Southern California. However, ICANN's headquarters is now located in the nearby Playa Vista section of Los Angeles.
Per its original Bylaws, primary responsibility for policy formation in ICANN was to be delegated to three supporting organizations (Address Supporting Organization, Domain Name Supporting Organization, and Protocol Supporting Organization), each of which was to develop and recommend substantive policies and procedures for the management of the identifiers within their respective scope. They were also required to be financially independent from ICANN. As expected, the Regional Internet Registries and the IETF agreed to serve as the Address Supporting Organization and Protocol Supporting Organization respectively, and ICANN issued a call for interested parties to propose the structure and composition of the Domain Name Supporting Organization. On 4 March 1999, the ICANN Board, based in part on the DNSO proposals received, decided instead on an alternate construction for the DNSO which delineated specific constituencies bodies within ICANN itself, thus adding primary responsibility for DNS policy development to ICANN's existing duties of oversight and coordination.
On July 26, 2006, the United States government renewed the contract with ICANN for performance of the IANA function for an additional one to five years. The context of ICANN's relationship with the U.S. government was clarified on September 29, 2006 when ICANN signed a new Memorandum of understanding with the United States Department of Commerce (DOC). This document gave the DOC oversight over some of the ICANN operations.
During July 2008, the U.S. Department of Commerce reiterated an earlier statement that it has "no plans to transition management of the authoritative root zone file to ICANN". The letter also stresses the separate roles of the IANA and VeriSign.
On September 30, 2009, ICANN signed an agreement with the United States Department of Commerce (DOC), known as the "Affirmation of Commitments", that confirmed ICANN's commitment to a multi-stakeholder governance model, but did not remove it from DOC oversight and control. 
On March 10, 2016, ICANN and the DOC signed a historic, culminating agreement to finally remove ICANN and IANA from the control and oversight of the DOC. This agreement is scheduled to go for approval by the U.S. National Telecommunications and Information Administration in April, 2016. This approval must occur before ICANN's current contract with the DOC expires in September, 2016. 
Notable events.
On March 18, 2002, publicly elected At-Large Representative for North America board member Karl Auerbach sued ICANN in Superior Court in California to gain access to ICANN's accounting records without restriction. Auerbach won.
During September and October 2003, ICANN played a crucial role in the conflict over VeriSign's "wild card" DNS service Site Finder. After an open letter from ICANN issuing an ultimatum to VeriSign, later endorsed by the Internet Architecture Board, the company voluntarily ended the service on October 4, 2003. After this action, VeriSign filed a lawsuit against ICANN on February 27, 2004, claiming that ICANN had exceeded its authority. By this lawsuit, VeriSign sought to reduce ambiguity about ICANN's authority. The antitrust component of VeriSign's claim was dismissed during August 2004. VeriSign's challenge that ICANN overstepped its contractual rights is currently outstanding. A proposed settlement already approved by ICANN's board would resolve VeriSign's challenge to ICANN in exchange for the right to increase pricing on .com domains. At the meeting of ICANN in Rome, which took place from March 2 to March 6, 2004, ICANN agreed to ask approval of the US Department of Commerce for the Waiting List Service of VeriSign.
On May 17, 2004, ICANN published a proposed budget for the year 2004-05. It included proposals to increase the openness and professionalism of its operations, and greatly increased its proposed spending from US $8.27 million to $15.83 million. The increase was to be funded by the introduction of new top-level domains, charges to domain registries, and a fee for some domain name registrations, renewals and transfers (initially USD 0.20 for all domains within a country-code top-level domain, and USD 0.25 for all others). The Council of European National Top Level Domain Registries (CENTR), which represents the Internet registries of 39 countries, rejected the increase, accusing ICANN of a lack of financial prudence and criticizing what it describes as ICANN's ""unrealistic political and operational targets"". Despite the criticism, the registry agreement for the top-level domains jobs and travel includes a US $2 fee on every domain the licensed companies sell or renew.
After a second round of negotiations during 2004, the TLDs eu, .asia, travel, jobs, mobi, and cat were introduced during 2005.
On February 28, 2006, ICANN's board approved a settlement with VeriSign in the lawsuit resulting from SiteFinder that involved allowing VeriSign (the registry) to raise its registration fees by up to 7% a year. This was criticised by some people in the US House of Representatives' Small Business committee.
During February 2007, ICANN began procedures to end accreditation of one of their registrars, RegisterFly amid charges and lawsuits involving fraud, and criticism of ICANN's management of the situation. ICANN has been the subject of criticism as a result of its handling of RegisterFly, and the harm caused to thousands of clients as a result of what has been termed ICANN's ""laissez faire attitude toward customer allegations of fraud"". Backend cybercrime detection within the ICANN sphere of influence is also lacking.
On May 23, 2008, ICANN issued Enforcement Notices against 10 Accredited Registrars and announced this through a press release entitled: "Worst Spam Offenders" Notified by ICANN, Compliance system working to correct Whois and other issues. This was largely in response to a report issued by KnujOn called The 10 Worst Registrars in terms of spam advertised junk product sites and compliance failure. The mention of the word spam in the title of the ICANN memo is somewhat misleading since ICANN does not address issues of spam or email abuse. Website content and usage are not within ICANN's mandate. However the KnujOn Report details how various registrars have not complied with their contractual obligations under the Registrar Accreditation Agreement (RAA). The main point of the KnujOn research was to demonstrate the relationships between compliance failure, illicit product traffic, and spam. The report demonstrated that out of 900 ICANN accredited Registrars fewer than 20 held 90% of the web domains advertised in spam. These same Registrars were also most frequently cited by KnujOn as failing to resolve complaints made through the Whois Data Problem Reporting System (WDPRS).
On June 26, 2008, the ICANN Board started a new process of TLD naming policy to take a ""significant step forward on the introduction of new generic top-level domains."" This program envisions the availability of many new or already proposed domains, as well a new application and implementation process.
On October 1, 2008, ICANN issued Breach Notices against Joker and Beijing Innovative Linkage Technology Ltd. after further researching reports and complaints issued by KnujOn. These notices gave the Registrars 15 days to fix their Whois investigation efforts.
During 2010, ICANN approved a major review of its policies with respect to accountability, transparency, and public participation by the Berkman Center for Internet and Society at Harvard University. This external review was an assistance of the work of ICANN's Accountability and Transparency Review team.
On February 3, 2011, ICANN announced that it had distributed the last batch of its remaining IPv4 addresses to the world’s five Regional Internet Registries, the organizations that manage IP addresses in different regions. These Registries began assigning the final IPv4 addresses within their regions until they ran out completely.
On June 20, 2011, the ICANN board voted to end most restrictions on the names of generic top-level domains (gTLD). Companies and organizations became able to choose essentially arbitrary top-level Internet domain names. The use of non-Latin characters (such as Cyrillic, Arabic, Chinese, etc.) is also allowed in gTLDs. ICANN began accepting applications for new gTLDS on January 12, 2012. The initial price to apply for a new gTLD was set at $185,000 and the annual renewal fee is $25,000.
The 2013 NSA spying scandal has led to ICANN endorsing the Montevideo Statement.
Structure.
At present ICANN is organized formally as a non-profit corporation "for charitable and public purposes" under the California Nonprofit Public Benefit Corporation Law. It is managed by a 16-member Board of Directors composed of eight members selected by a nominating committee on which all the constituencies of ICANN are represented; six representatives of its Supporting Organizations, sub-groups that deal with specific sections of the policies under ICANN's purview; an At-Large seat filled by an At-Large Organization; and the President / CEO, appointed by the Board.
There are currently three Supporting Organizations. The Generic Names Supporting Organization (GNSO) deals with policy making on generic top-level domains (gTLDs). The Country Code Names Supporting Organization (ccNSO) deals with policy making on country-code top-level domains (ccTLDs). The Address Supporting Organization (ASO) deals with policy making on IP addresses.
ICANN also relies on some advisory committees and other advisory mechanisms to receive advice on the interests and needs of stakeholders that do not directly participate in the Supporting Organizations. These include the Governmental Advisory Committee (GAC), which is composed of representatives of a large number of national governments from all over the world; the At-Large Advisory Committee (ALAC), which is composed of individual Internet users from around the world selected by each of the Regional At-Large Organizations (RALO) and Nominating Committee; the Root Server System Advisory Committee, which provides advice on the operation of the DNS root server system; the Security and Stability Advisory Committee (SSAC), which is composed of Internet experts who study security issues pertaining to ICANN's mandate; and the Technical Liaison Group (TLG), which is composed of representatives of other international technical organizations that focus, at least in part, on the Internet.
Governmental Advisory Committee.
The Governmental Advisory Committee has representatives from 111 states (108 UN members, the Holy See, Cook Islands, Niue and Taiwan), Hong Kong, Bermuda, Montserrat, the European Commission and the African Union Commission.
In addition the following organizations are GAC Observers:
Democratic input.
In the Memorandum of Understanding that set up the relationship between ICANN and the U.S. government, ICANN was given a mandate requiring that it operate "in a bottom up, consensus driven, democratic manner." However, the attempts that ICANN have made to establish an organizational structure that would allow wide input from the global Internet community did not produce results amenable to the current Board. As a result, the At-Large constituency and direct election of board members by the global Internet community were soon abandoned.
ICANN holds periodic public meetings rotated between continents for the purpose of encouraging global participation in its processes. Resolutions of the ICANN Board, preliminary reports, and minutes of the meetings, are published on the ICANN website, sometimes in real time. However, there are criticisms from ICANN constituencies including the Noncommercial Users Constituency (NCUC) and the At-Large Advisory Committee (ALAC) that there is not enough public disclosure and that too many discussions and decisions take place out of sight of the public.
During the early 2000s, there had been speculation that the United Nations might assume control of ICANN, followed by a negative reaction from the US government and worries about a division of the Internet. The World Summit on the Information Society in Tunisia during November 2005 agreed not to get involved in the day-to-day and technical operations of ICANN. However it also agreed to establish an international Internet Governance Forum, with a consultative role on the future governance of the Internet. ICANN's Government Advisory Committee is currently established to provide advice to ICANN regarding public policy issues and has participation by many of the world's governments.
Some have attempted to argue that ICANN was never given the authority to decide policy, e.g., choose new TLDs or exclude other interested parties who refuse to pay ICANN's US$185,000 fee, but was to be a technical caretaker. Critics suggest that ICANN should not be allowed to impose business rules on market participants, and that all TLDs should be added on a first-come, first-served basis and the market should be the arbiter of who succeeds and who does not.
Activities.
Uniform Domain-Name Dispute Resolution Policy (UDRP).
One task that ICANN was asked to do was to address the issue of domain name ownership resolution for generic top-level domains (gTLDs). ICANN's attempt at such a policy was drafted in close cooperation with the World Intellectual Property Organization (WIPO), and the result has now become known as the Uniform Dispute Resolution Policy (UDRP). This policy essentially attempts to provide a mechanism for rapid, cheap and reasonable resolution of domain name conflicts, avoiding the traditional court system for disputes by allowing cases to be brought to one of a set of bodies that arbitrate domain name disputes. According to ICANN policy, a domain registrant must agree to be bound by the UDRP—they cannot get a domain name without agreeing to this.
Examination of the UDRP decision patterns has caused some to conclude that compulsory domain name arbitration is less likely to give a fair hearing to domain name owners asserting defenses under the First Amendment and other laws, compared to the federal courts of appeal in particular.
Proposed elimination of public DNS whois.
The initial report of ICANN's Expert Working Group has recommended that the present form of Whois, a utility that allows anyone to know who has registered a domain name on the Internet, be scrapped. It recommends it be replaced with a system that keeps most registration information secret (or "gated") from most Internet users, and only discloses information for "permissible purposes". ICANN's list of permissible purposes includes Domain name research, Domain name sale and purchase, Regulatory enforcement, Personal data protection, Legal actions, and Abuse mitigation. Whois has been a key tool of investigative journalists interested in determining who was disseminating information on the Internet. The use of whois by the free press is not included in the list of permissible purposes in the initial report.
Criticism.
Since its creation, ICANN has been the subject of criticism and controversy. In 2000, professor Michael Froomkin of the University of Miami School of Law argued that ICANN's relationship with the U.S. Department of Commerce is illegal, in violation of either the Constitution or federal statutes. In 2009, the new "Affirmation of Commitments" agreement between ICANN and the U.S. Department of Commerce, that aimed to create international oversight, ran into criticism.
During December 2011, the Federal Trade Commission stated ICANN had long failed to provide safeguards that protect consumers from online swindlers.
Also during 2011, seventy-nine companies, including The Coca-Cola Company, Hewlett-Packard, Samsung and others, signed a petition against ICANN's new TLD program (sometimes referred to as a "commercial landgrab"), in a group organized by the Association of National Advertisers. As of September 2014, this group, the Coalition for Responsible Internet Domain Oversight, that opposes the rollout of ICANN's TLD expansion program, has been joined by 102 associations and 79 major companies. Partly as a response to this criticism, ICANN initiated an effort to protect trademarks in domain name registrations, which eventually culminated in the establishment of the Trademark Clearinghouse.
IBSA proposal (2011).
One controversial proposal, resulting from a September 2011 summit between India, Brazil, and South Africa (IBSA), would seek to move Internet governance into a "UN Committee on Internet-Related Policy" (UN-CIRP). The action was a reaction to a perception that the principles of the 2005 Tunis Agenda for the Information Society have not been met. The statement proposed the creation of a new political organization operating as a component of the United Nations to provide policy recommendations for the consideration of technical organizations such as ICANN and international bodies such as the ITU. Subsequent to public criticisms, the Indian government backed away from the proposal.
Montevideo Statement on the Future of Internet Cooperation (2013).
On 7 October 2013 the Montevideo Statement on the Future of Internet Cooperation was released by the managers of a number of organizations involved in coordinating the Internet's global technical infrastructure, loosely known as the "I*" (or "I-star") group. Among other things, the statement "expressed strong concern over the undermining of the trust and confidence of Internet users globally due to recent revelations of pervasive monitoring and surveillance" and "called for accelerating the globalization of ICANN and IANA functions, towards an environment in which all stakeholders, including all governments, participate on an equal footing". This desire to reduce United States association with the internet is considered a reaction to the ongoing NSA surveillance scandal. The statement was signed by the managers of the Internet Corporation for Assigned Names and Numbers (ICANN), the Internet Engineering Task Force, the Internet Architecture Board, the World Wide Web Consortium, the Internet Society, and the five regional Internet address registries (African Network Information Center, American Registry for Internet Numbers, Asia-Pacific Network Information Centre, Latin America and Caribbean Internet Addresses Registry, and Réseaux IP Européens Network Coordination Centre).
Global Multistakeholder Meeting on the Future of Internet Governance (2013).
During October 2013, Fadi Chehadé, current President and CEO of ICANN, met with Brazilian President Dilma Rousseff in Brasilia. Upon Chehadé's invitation, the two announced that Brazil would host an international summit on Internet governance during April 2014. The announcement came after the 2013 disclosures of mass surveillance by the U.S. government, and President Rousseff's speech at the opening session of the 2013 United Nations General Assembly, where she strongly criticized the American surveillance program as a "breach of international law". The "Global Multistakeholder Meeting on the Future of Internet Governance (NET mundial)" will include representatives of government, industry, civil society, and academia. At the IGF VIII meeting in Bali in October 2013 a commenter noted that Brazil intends the meeting to be a "summit" in the sense that it will be high level with decision-making authority. The organizers of the "NET mundial" meeting have decided that an online forum called "/1net", set up by the I* group, will be a major conduit of non-governmental input into the three committees preparing for the meeting in April.
The Obama administration that had joined critics of ICANN during 2011 announced in March 2014 that they intended to transition away from oversight of the IANA functions contract. The current contract that the United States Department of Commerce has with ICANN will expire during 2015, in its place the NTIA will transition oversight of the IANA functions to the 'global multistakeholder community'.
NetMundial Initiative (2014).
The NetMundial Initiative is a plan for international governance of the Internet that was first proposed at the Global Multistakeholder Meeting on the Future of Internet Governance (GMMFIG) conference (23–24 April 2014)
and later developed into the NetMundial Initiative by ICANN CEO Fadi Chehade along with representatives of the World Economic Forum (WEF)
and the Brazilian Internet Steering Committee (Comitê Gestor da Internet no Brasil), commonly referred to as "CGI.br".
The meeting produced a nonbinding statement in favor of consensus-based decision-making. It represented a compromise and did not harshly condemn mass surveillance or include the words "net neutrality", despite initial endorsement for that from Brazil. The final resolution says ICANN should be controlled internationally by September 2015.
A minority of governments, including Russia, China, Iran and India, were unhappy with the final resolution and wanted multi-lateral management for the Internet, rather than broader multi-stakeholder management.
A month later, the Panel On Global Internet Cooperation and Governance Mechanisms (convened by the Internet Corporation for Assigned Names and Numbers (ICANN) and the World Economic Forum (WEF) with assistance from The Annenberg Foundation), endorsed and included the NetMundial statement in its own report.
During June 2014, France strongly attacked ICANN, saying ICANN is not a fit venue for Internet governance and that alternatives should be sought.
.sucks domain.
ICANN has received more than $60 million from gTLD auctions, and has accepted the very controversial domain names ".xxx" and ".sucks". When the .sucks registry announced their pricing model, "most brand owners were upset and felt like they were being penalized by having to pay more to protect their brands." The .sucks domain registrar has been described as "predatory, exploitive and coercive" by the Intellectual Property Constituency that advises the ICANN board.
Because of the low utility of the ".sucks" domain, it is expected that most of the fees will come from "Brand Protection" customers registering their trademarks to prevent domains being registered. Virginia member of Congress Bob Goodlatte says that trademark holders are "being shaken down" by the registry's fees. Jay Rockefeller says that .sucks is a "a predatory shakedown scheme" and "Approving '.sucks', a gTLD with little or no public interest value, will have the effect of undermining the credibility ICANN has slowly been building with skeptical stakeholders."
Steve DelBianco says that businesses are "very concerned about what they consider extortionist pricing."
Canadian brands had complained that they were being charged "exorbitant" prices to register their trademarks as premium names. FTC chair Edith Ramirez has written to ICANN to say the agency will take action against the .sucks owner if “we have reason to believe an entity has engaged in deceptive or unfair practices in violation of Section 5 of the FTC Act”. The Register reported that intellectual property lawyers are infuriated that "the dot-sucks registry was charging trademark holders $2,500 for .sucks domains and everyone else $10."

</doc>
<doc id="15237" url="https://en.wikipedia.org/wiki?curid=15237" title="Iterative method">
Iterative method

In computational mathematics, an iterative method is a mathematical procedure that generates a sequence of improving approximate solutions for a class of problems. A specific implementation of an iterative method, including the termination criteria, is an algorithm of the iterative method. An iterative method is called convergent if the corresponding sequence converges for given initial approximations. A mathematically rigorous convergence analysis of an iterative method is usually performed; however, heuristic-based iterative methods are also common. In the problems of finding the root of an equation (or a solution of a system of equations), an iterative method uses an initial guess to generate successive approximations to a solution. 
In contrast, direct methods attempt to solve the problem by a finite sequence of operations. In the absence of rounding errors, direct methods would deliver an exact solution (like solving a linear system of equations formula_1 by Gaussian elimination). Iterative methods are often the only choice for nonlinear equations. However, iterative methods are often useful even for linear problems involving a large number of variables (sometimes of the order of millions), where direct methods would be prohibitively expensive (and in some cases impossible) even with the best available computing power.
Attractive fixed points.
If an equation can be put into the form "f"("x") = "x", and a solution x is an attractive fixed point of the function "f", then one may begin with a point "x"1 in the basin of attraction of x, and let "x""n"+1 = "f"("x""n") for "n" ≥ 1, and the sequence {"x""n"}"n" ≥ 1 will converge to the solution x. Here "x""n" is the "n"th approximation or iteration of "x" and "x""n"+1 is the next or "n" + 1 iteration of "x". Alternately, superscripts in parentheses are often used in numerical methods, so as not to interfere with subscripts with other meanings. (For example, "x"("n"+1) = "f"("x"("n")).) If the function "f" is continuously differentiable, a sufficient condition for convergence is that the spectral radius of the derivative is strictly bounded by one in a neighborhood of the fixed point. If this condition holds at the fixed point, then a sufficiently small neighborhood (basin of attraction) must exist.
Linear systems.
In the case of a system of linear equations, the two main classes of iterative methods are the stationary iterative methods, and the more general Krylov subspace methods.
Stationary iterative methods.
Stationary iterative methods solve a linear system with an operator approximating the original one; and based on a measurement of the error in the result (the residual), form a "correction equation" for which this process is repeated. While these methods are simple to derive, implement, and analyze, convergence is only guaranteed for a limited class of matrices. Examples of stationary iterative methods are the Jacobi method, Gauss–Seidel method and the Successive over-relaxation method. Linear stationary iterative methods are also called relaxation methods.
Krylov subspace methods.
Krylov subspace methods work by forming a basis of the sequence of successive matrix powers times the initial residual (the Krylov sequence). The approximations to the solution are then formed by minimizing the residual over the subspace formed. The prototypical method in this class is the conjugate gradient method (CG). Other methods are the generalized minimal residual method (GMRES) and the biconjugate gradient method (BiCG).
Convergence of Krylov subspace methods.
Since these methods form a basis, it is evident that the method converges in "N" iterations, where "N" is the system size. However, in the presence of rounding errors this statement does not hold; moreover, in practice "N" can be very large, and the iterative process reaches sufficient accuracy already far earlier. The analysis of these methods is hard, depending on a complicated function of the spectrum of the operator.
Preconditioners.
The approximating operator that appears in stationary iterative methods can also be incorporated in Krylov subspace methods such as GMRES (alternatively, preconditioned Krylov methods can be considered as accelerations of stationary iterative methods), where they become transformations of the original operator to a presumably better conditioned one. The construction of preconditioners is a large research area.
History.
Probably the first iterative method for solving a linear system appeared in a letter of Gauss to a student of his. He proposed solving a 4-by-4 system of equations by repeatedly solving the component in which the residual was the largest. 
The theory of stationary iterative methods was solidly established with the work of D.M. Young starting in the 1950s. The Conjugate Gradient method was also invented in the 1950s, with independent developments by Cornelius Lanczos, Magnus Hestenes and Eduard Stiefel, but its nature and applicability were misunderstood at the time. Only in the 1970s was it realized that conjugacy based methods work very well for partial differential equations, especially the elliptic type.

</doc>
<doc id="15238" url="https://en.wikipedia.org/wiki?curid=15238" title="International judicial institution">
International judicial institution

International judicial institutions can be divided into courts, arbitral tribunals and quasi-judicial institutions. Courts are permanent bodies, with near the same composition for each case. Arbitral tribunals, by contrast, are constituted anew for each case. Both courts and arbitral tribunals can make binding decisions. Quasi-judicial institutions, by contrast, make rulings on cases, but these rulings are not in themselves legally binding; the main example is the individual complaints mechanisms available under the various UN human rights treaties.
Institutions can also be divided into global and regional institutions.
The listing below incorporates both currently existing institutions, defunct institutions that no longer exist, institutions which never came into existence due to non-ratification of their constitutive instruments, and institutions which do not yet exist, but for which constitutive instruments have been signed. It does not include mere proposed institutions for which no instrument was ever signed.

</doc>
<doc id="15239" url="https://en.wikipedia.org/wiki?curid=15239" title="International Prize Court">
International Prize Court

The International Prize Court was an international court proposed at the beginning of the 20th century, to hear prize cases. An international agreement to create it, the "Convention Relative to the Creation of an International Prize Court", was made at the Hague conference of 1907.
The capturing of prizes (enemy equipment, vehicles, and especially ships) during wartime is a tradition that goes back as far as organized warfare itself. The International Prize Court was to hear appeals from national courts concerning prize cases. It was later modified by the "Additional Protocol to the Convention Relative to the Creation of an International Prize Court" [http://www1.umn.edu/humanrts/instree/1907k.htm], done at the Hague on October 18, 1910. However, neither the convention nor the subsequent protocol ever entered into force, since only Nicaragua ratified the agreements. As a result, the court never came into existence.
The Convention was opposed, particularly by elements within the United States and the United Kingdom, as a violation of national sovereignty.
Even as a draft, the convention was innovative for the time, in being both the first ever treaty for a truly international court (as opposed to a mere arbitral tribunal), and in providing individuals with access to the court, going against the prevailing doctrines of international law at the time, according to which only states had rights and duties under international law. The protocol was an attempt to resolve some concerns expressed by the United States at the court, which felt it to be in violation of its constitutional provision that provides for the U.S. Supreme Court being the final judicial authority.
A number of ideas from the International Prize Court proposal can be seen in present day international courts, such as its provision for judges "ad hoc", later adopted in the Permanent Court of International Justice and the subsequent International Court of Justice.

</doc>
<doc id="15240" url="https://en.wikipedia.org/wiki?curid=15240" title="Imam">
Imam

An imam (; ', plural: '; ) is an Islamic leadership position. It is most commonly in the context of a worship leader of a mosque and Muslim community by Sunni Muslims. In this context, imams may lead Islamic worship services, serve as community leaders, and provide religious guidance. For Shi'a Muslims, the imam has a more central meaning and role in Islam through the concept of Imamah; the term is only applicable to those members of the house of the prophet ahl al-Bayt, designated as infallibles.
Sunni imams.
The Sunni branch of Islam does not have imams in the same sense as the Shi'a, an important distinction often overlooked by those outside of the Islamic faith. In everyday terms, the imam for Sunni Muslims is the one who leads Islamic formal (Fard) prayers, even in locations besides the mosque, whenever prayers are done in a group of two or more with one person leading (imam) and the others following by copying his ritual actions of worship. Friday sermon is most often given by an appointed imam. All mosques have an imam to lead the (congregational) prayers, even though it may sometimes just be a member from the gathered congregation rather than an officially appointed salaried person. Women imams may only lead amongst female-only congregations. The person that should be chosen according to Hadith is one who has most knowledge of the Qu'ran, and Sunnah (prophetic tradition) and is of good character; the age being irrelevant.
The term is also used for a recognized religious scholar or authority in Islam, often for the founding scholars of the four Sunni madhhabs, or schools of jurisprudence "(fiqh)". It may also refer to the Muslim scholars who created the analytical sciences related to Hadith or it may refer to the heads of the Prophet Muhammad's family in their generational times.
The following table shows the considered imams in the context of scholarly authority by Sunni Muslims:
Shi'a imams.
In the Shi'a context, Imam is not only presented as the man of God par excellence but as participating fully in the names, attributes, and acts that theology usually reserves for God alone. Imams have a meaning more central to belief, referring to leaders of the community. Twelver and Ismaili Shi'a believe that these imams are chosen by God to be perfect examples for the faithful and to lead all humanity in all aspects of life. They also believe that all the imams chosen are free from committing any sin, impeccability which is called "ismah". These leaders must be followed since they are appointed by God.
Twelver.
Here follows a list of the Twelvers imams:
Fatimah, also Fatimah al-Zahraa, daughter of Muhammed (615–632), is also considered infallible but not an Imam. Shi'a believe that the last Imam will one day return.
Ismaili.
See Imamah (Ismaili doctrine) and List of Ismaili imams for Ismaili imams.
Imams as secular rulers.
At times, imams have held both secular and religious authority. This was the case in Oman among the Kharijite or Ibadi sects. At times, the imams were elected. At other times the position was inherited, as with the Yaruba dynasty from 1624 and 1742. The Imamate of Futa Jallon (1727-1896) was a Fulani state in West Africa where secular power alternated between two lines of hereditary Imams, or "almami".
In the Zaidi Shiite sect, imams were secular as well as spiritual leaders who held power in Yemen for more than a thousand years. In 897, a Zaidi ruler, al-Hadi ila'l-Haqq Yahya, founded a line of such imams, a theocratic form of government which survived until the second half of the 20th century. (See details under Zaidiyyah, History of Yemen, Imams of Yemen.)
Ruhollah Khomeini and his successor Ali Khamenei are officially referred to as Imams in the Islamic Republic of Iran. Several Iranian places and institutions are named "Imam Khomeini", including a city, an international airport, a hospital, and a university.

</doc>
<doc id="15242" url="https://en.wikipedia.org/wiki?curid=15242" title="Instrument flight rules">
Instrument flight rules

Instrument flight rules (IFR) is one of two sets of regulations governing all aspects of civil aviation aircraft operations; the other is visual flight rules (VFR).
FAA's "Instrument Flying Handbook" defines IFR as: "Rules and regulations established by the FAA to govern flight under conditions in which flight by outside visual reference is not safe. IFR flight depends upon flying by reference to instruments in the flight deck, and navigation is accomplished by reference to electronic signals." It is also a term used by pilots and controllers to indicate the type of flight plan an aircraft is flying, such as an IFR or VFR flight plan.
Basic Information.
Comparison to Visual flight rules.
To put instrument flight rules into context, a brief overview of visual flight rules, or VFR, is necessary. It is possible and fairly straightforward, in relatively clear weather conditions, to fly a plane solely by reference to outside visual cues, such as the horizon to maintain orientation, nearby buildings and terrain features for navigation, and other aircraft to maintain "separation". This is known as operating the aircraft under VFR, and is the most common mode of operation for small craft. However, it is only safe to fly VFR when these outside references can be clearly seen from a sufficient distance; when flying through or above clouds, or in fog, rain, dust or similar low-level weather conditions, these references can be obscured. Thus, cloud ceiling and flight visibility are the most important variables for safe operations during all phases of flight. The minimum weather conditions for ceiling and visibility for VFR flights are defined in FAR Part 91.155, and vary depending on the type of airspace in which the aircraft is operating, and on whether the flight is conducted during daytime or nighttime. However, typical daytime VFR minimums for most airspace is 3 statute miles of flight visibility and a distance from clouds of 500' below, 1,000' above, and 2,000' feet horizontally. Flight conditions reported as equal to or greater than these VFR minimums are referred to as visual meteorological conditions (VMC).
Any aircraft operating under VFR must have the required equipment on board, as described in FAR Part 91.205 (which includes some instruments necessary for IFR flight). VFR pilots "may" use cockpit instruments as secondary aids to navigation and orientation, but are not required to; the view outside of the aircraft is the primary source for keeping the aircraft straight and level (orientation), flying to the intended destination (navigation), and not hitting anything (separation).
Visual flight rules are generally simpler than instrument flight rules, and require significantly less training and practice. VFR provides a great degree of freedom, allowing pilots to go where they want, when they want, and allows them a much wider latitude in determining how they get there. Pilots are not required to file a flight plan, do not have to communicate with ATC (unless flying within certain types of relatively busy airspace such as near airports or military bases), and are not limited to following predefined published routes or flight procedures. For these reasons, and because "visual meteorological conditions" in which VFR flight is allowed are typically calm, clear conditions in which a recreational pilot would want to fly a small propeller aircraft in the first place, many such pilots never pursue the training to obtain an "instrument rating" which allows IFR operation.
Instrument flight rules.
When operation of an aircraft under VFR is not safe, because the visual cues outside the aircraft are obscured by weather or darkness, instrument flight rules must be used instead. IFR permits an aircraft to operate in instrument meteorological conditions (IMC), which is essentially any weather condition less than VMC but in which aircraft can still operate safely. Use of instrument flight rules are also required when flying in "Class A" airspace regardless of weather conditions. Class A airspace extends from 18,000 feet above mean sea level to flight level 600 (60,000 feet Pressure altitude) above the contiguous 48 United States and overlying the waters within 12 miles thereof. Flight in Class A airspace requires pilots and aircraft to be instrument equipped and rated and to be operating under Instrument Flight Rules (IFR). In many countries commercial airliners and their pilots must operate under IFR as the majority of flights enter Class A airspace; however, aircraft operating as commercial airliners must operate under IFR even if the flight plan does not take the craft into Class A airspace, such as with smaller regional flights. Procedures and training are significantly more complex compared to VFR instruction, as a pilot must demonstrate competency in conducting an entire cross-country flight in IMC conditions, while controlling the aircraft solely by reference to instruments.
Instrument pilots must meticulously evaluate weather, create a very detailed flight plan based around specific instrument departure, en route, and arrival procedures, and dispatch the flight.
Separation and clearance.
The distance by which an aircraft avoids obstacles or other aircraft is termed "separation". The most important concept of IFR flying is that separation is maintained regardless of weather conditions. In controlled airspace, air traffic control (ATC) separates IFR aircraft from obstacles and other aircraft using a flight "clearance" based on route, time, distance, speed, and altitude. ATC monitors IFR flights on radar, or through aircraft position reports in areas where radar coverage is not available. Aircraft position reports are sent as voice radio transmissions. In the United States, a flight operating under IFR is required to provide position reports unless ATC advises a pilot that the plane is in radar contact. The pilot must resume position reports after ATC advises that radar contact has been lost, or that radar services are terminated.
IFR flights in controlled airspace require an ATC "clearance" for each part of the flight. A clearance always specifies a "clearance limit", which is the farthest the aircraft can fly without a new clearance. In addition, a clearance typically provides a heading or route to follow, altitude, and communication parameters, such as frequencies and transponder codes.
In uncontrolled airspace, ATC clearances are unavailable. In some states a form of separation is provided to certain aircraft in uncontrolled airspace as far as is practical (often known under ICAO as an advisory service in class G airspace), but separation is not mandated nor widely provided.
Despite the protection offered by flight in controlled airspace under IFR, the ultimate responsibility for the safety of the aircraft rests with the pilot in command, who can refuse clearances.
Weather.
It is essential to differentiate between flight plan type (VFR or IFR) and weather conditions (VMC or IMC). While current and forecast weather may be a factor in deciding which type of flight plan to file, weather conditions themselves do not affect one's filed flight plan. For example, an IFR flight that encounters visual meteorological conditions (VMC) en route does not automatically change to a VFR flight, and the flight must still follow all IFR procedures regardless of weather conditions. In the US, weather conditions are forecast broadly as VFR, MVFR (Marginal Visual Flight Rules), IFR, or LIFR (Low Instrument Flight Rules).
The main purpose of IFR is the safe operation of aircraft in instrument meteorological conditions (IMC). The weather is considered to be MVFR or IMC when it does not meet the minimum requirements for visual meteorological conditions (VMC). To operate safely in IMC ("actual instrument conditions"), a pilot controls the aircraft relying on flight instruments and ATC provides separation.
It is important not to confuse IFR with IMC. A significant amount of IFR flying is conducted in Visual Meteorological Conditions (VMC). Anytime a flight is operating in VMC and in a volume of airspace in which VFR traffic can operate, the crew is responsible for seeing and avoiding VFR traffic; however, because the flight is conducted under Instrument Flight Rules, ATC still provides separation services from other IFR traffic, and can in many cases also advise the crew of the location of VFR traffic near the flight path.
Although dangerous and usually illegal, a certain amount of VFR flying is conducted in instrument meteorological conditions (IMC). A scenario is a VFR pilot taking off in VMC conditions, but encountering deteriorating visibility while en route. "Continued VFR flight into IMC" can lead to spatial disorientation of the pilot which is the cause of a significant number of general aviation crashes. VFR flight into IMC is distinct from VFR-on-top, an IFR procedure in which the aircraft operates in VMC using a hybrid of VFR and IFR rules, and VFR over the top, a VFR procedure in which the aircraft takes off and lands in VMC but flies above an intervening area of IMC. Also possible in many countries is "Special VFR" flight, where an aircraft is explicitly granted permission to operate VFR within the controlled airspace of an airport in conditions technically less than VMC; the pilot asserts they have the necessary visibility to fly despite the weather, must stay in contact with ATC, and cannot leave controlled airspace while still below VMC minimums.
During flight under IFR, there are no visibility requirements, so flying through clouds (or other conditions where there is zero visibility outside the aircraft) is legal and safe. However, there are still minimum weather conditions that must be present in order for the aircraft to take off or to land; these vary according to the kind of operation, the type of navigation aids available, the location and height of terrain and obstructions in the vicinity of the airport, equipment on the aircraft, and the qualifications of the crew. For example, Reno-Tahoe International Airport (KRNO) in a mountainous region has significantly different instrument approaches for aircraft landing on the same runway surface, but from opposite directions. Aircraft approaching from the north must make visual contact with the airport at a higher altitude than when approaching from the south because of rapidly rising terrain south of the airport. This higher altitude allows a flight crew to clear the obstacle if a landing is aborted. In general, each specific instrument approach specifies the minimum weather conditions to permit landing.
Although large airliners, and increasingly, smaller aircraft, carry their own terrain awareness and warning system (TAWS), these are primarily backup systems providing a last layer of defense if a sequence of errors or omissions causes a dangerous situation.
Navigation.
Because IFR flights often take place without visual reference to the ground, a means of navigation other than looking outside the window is required. A number of navigational aids are available to pilots, including ground-based systems such as DME/VORs and NDBs as well as the satellite-based GPS/GNSS system. Air traffic control may assist in navigation by assigning pilots specific headings ("radar vectors"). The majority of IFR navigation is given by ground- and satellite-based systems, while radar vectors are usually reserved by ATC for sequencing aircraft for a busy approach or transitioning aircraft from takeoff to cruise, among other things.
Autopilot.
Autopilot allows automatic piloting.
Modern flight management systems have evolved to allow a crew to plan a flight as to route and altitude and to specific time of arrival at specific locations. This capability is used in several trial projects experimenting with "four-dimensional" approach clearances for commercial aircraft, with time as the fourth dimension. These clearances allow ATC to optimize the arrival of aircraft at major airports, which increases airport capacity and uses less fuel providing monetary and environmental benefits to airlines and the public.
Procedures.
Specific procedures allow IFR aircraft to transition safely through every stage of flight. These procedures specify how an IFR pilot should respond, even in the event of a complete radio failure, and loss of communications with ATC, including the expected aircraft course and altitude.
Departures are described in an IFR clearance issued by ATC prior to takeoff. The departure clearance may contain an assigned heading, one or more waypoints, and an initial altitude to fly. The clearance can also specify a departure procedure (DP) or standard instrument departure (SID) that should be followed unless "NO DP" is specified in the notes section of the filed flight plan.
Here is an example of an IFR clearance for a Cessna aircraft traveling from Palo Alto airport (KPAO) to Stockton airport (KSCK).
Detailed explanation:
The clearance scheme, used by ATC, can be easily remembered using the acronym
En route flight is described by IFR charts showing navigation aids, fixes, and standard routes called "airways". Aircraft with appropriate navigational equipment such as GPS, are also often cleared for a "direct-to" routing, where only the destination, or a few navigational waypoints are used to describe the route that the flight will follow. ATC will assign altitudes in its initial clearance or amendments thereto, and navigational charts indicate minimum safe altitudes for airways.
The approach portion of an IFR flight may begin with a standard terminal arrival route (STAR), describing common routes to fly to arrive at an initial approach fix (IAF) from which an instrument approach commences. 
An instrument approach terminates either by the pilot acquiring sufficient visual reference to proceed to the runway, or with a missed approach because the required visual reference is not seen in time.
Qualifications.
Pilot.
To fly under IFR, a pilot must have an instrument rating and must be "current" (meet recency of experience requirements).
In the United States, to file and fly under IFR, a pilot must be instrument-rated and, within the preceding six months, have flown six instrument approaches, as well as holding procedures and course interception and tracking with navaids. Flight under IFR beyond six months after meeting these requirements is not permitted; however, currency may be reestablished within the next six months by completing the requirements above. Beyond the twelfth month, examination ("instrument proficiency check") by an instructor is required.
Practicing instrument approaches can be done either in the instrument meteorological conditions or in visual meteorological conditions – in the latter case, a safety pilot is required so that the pilot practicing instrument approaches can wear a view-limiting device which restricts his field of view to the instrument panel. A safety pilot's primary duty is to observe and avoid other traffic.
For all ILS Cat II or Cat III approaches, additional crew training is required and a certain number of low visibility approaches must either be performed or simulated within a fixed time for pilots to be 'current' in performing them.
In the UK, an IR (UK restricted) - formerly the "IMC rating" - which permits flight under IFR in airspace classes B to G in instrument meteorological conditions, a non-instrument-rated pilot can also elect to fly under IFR in visual meteorological conditions outside controlled airspace. Compared to the rest of the world, the UK's flight crew licensing regime is somewhat unusual in its licensing for meteorological conditions and airspace, rather than flight rules.
Aircraft.
The aircraft must be equipped and type-certified for instrument flight, and the related navigational equipment must have been inspected or tested within a specific period of time prior to the instrument flight.
In the United States, instruments required for IFR flight in addition to those that are required for VFR flight are: heading indicator, sensitive altimeter adjustable for barometric pressure, clock with a sweep-second pointer or digital equivalent, attitude indicator, radios and suitable avionics for the route to be flown, alternator or generator, gyroscopic rate-of-turn indicator that is either a turn coordinator or the turn and bank indicator. From 1999 single-engine helicopters could not be FAA-certified for IFR, and Helicopter Association International estimates that 326 lives were lost in 133 accidents that would likely not have happened if those helicopters had been flying in IFR.

</doc>
<doc id="15245" url="https://en.wikipedia.org/wiki?curid=15245" title="Ismail Khan">
Ismail Khan

Mohammad Ismail Khan (Persian: محمد اسماعیل خان) (born 1946) is a warlord and politician in Afghanistan, serving as Minister of Water and Energy since 2005. He was previously the Governor of Herat Province. He is widely known as a warlord because of his rise to power during the Soviet war in Afghanistan. He controlled a large sized mujahideen force, mainly his fellow Tajiks from western Afghanistan. He is a key member of the political party Jamiat-e Islami and was a member of the now defunct United National Front party.
Early years and rise to power.
Khan was born in or about 1946 in the Shindand District of Herat Province in Afghanistan. His family are Tajiks from the Chahar-Mahal neighbourhood of Shindand.
In early 1979 Ismail Khan was a Captain in the Afghan National Army based in the western city of Herat. In early March of that year, there was a protest in front of the Communist governor's palace against the arrests and assassinations being carried out in the countryside. The governor's troops opened fire on the demonstrators, who proceeded to storm the palace and hunt down Soviet advisers. The Herat garrison mutinied and joined the revolt, with Ismail Khan and other officers distributing all available weapons to the insurgents. Hundreds of civil workers and people not dressed in traditional Muslim clothes were murdered. A garrison of Soviet advisors was overtaken and all of its inhabitants: Soviet advisors along with their wives and children were massacred. The mob put severed heads of the victims on sticks and paraded them through the city of Herat. The government led by Nur Mohammed Taraki responded, pulverizing the city using Soviet supplied bombers and killing an estimated 24,000 citizens in less than a week. This event marked the opening salvo of the rebellion which led to the Soviet invasion of Afghanistan in December 1979. Ismail Khan escaped to the countryside where he began to assemble a local mujahideen rebel army.
During the ensuing war, he became the leader of the western command of Burhanuddin Rabbani's Jamiat-e-Islami, political party associated with neighboring Pakistan's Jamaat-e-Islami. With Ahmad Shah Massoud, he was one of the most respected mujahideen leaders. In 1992, two years after the Soviet withdrawal from Afghanistan, the mujahideen captured Herat and Ismail Khan became Governor.
Escaping to Iran.
In 1995, he successfully defended his province against the Taliban, in cooperation with defense minister Ahmad Shah Massoud. Khan even attacked the Taliban stronghold of Kandahar, but was repulsed. Later, an ally of the Jamiat, Uzbek General Abdul Rashid Dostum changed sides, and attacked Herat. Ismail Khan was forced to flee to neighboring Iran with 8,000 men and the Taliban took over Herat Province.
Two years later, while organising opposition to the Taliban in Faryab area, he was betrayed and captured by Abdul Majid Rouzi who had defected to the Taliban along with Abdul Malik Pahlawan, then one of Dostum's deputies. Then in March 1999 he escaped from Kandahar prison. During the U.S. intervention in Afghanistan, he fought against the Taliban within the United Islamic Front for the Salvation of Afghanistan (Northern Alliance) and thus regained his position as Governor of Herat.
Karzai administration and return to Afghanistan.
After returning to Herat, Ismail Khan quickly consolidated his control over the region. He took over control of the city from the local ulema and quickly established control over the trade route between Herat and Iran, a large source of revenue. As Emir of Herat, Ismail Khan exercised great autonomy, providing social welfare for Heratis, expanding his power into neighbouring provinces, and maintaining direct international contacts. Although hated by the educated in Herat and often accused of human rights abuses, Ismail Khan's regime provided security, paid government employees, and made investments in public services. However, during his tenure as Governor, Ismail Khan was accused of ruling his province like a private fiefdom, leading to increasing tensions with the Afghan Transitional Administration. In particular, he refused to pass on to the government the revenues gained from custom taxes on goods from Iran and Turkmenistan.
On 13 August 2003, President Karzai removed Governor Ismail Khan from his command of the 4th Corps. This was announced as part of a programme removing the ability of officials to hold both civilian and military posts.
Ismail Khan was ultimately removed from power in March 2004 due to pressure by neighbouring warlords and the central Afghan government. Various sources have presented different versions of the story, and the exact dynamics cannot be known with certainty. What is known is that Ismail Khan found himself at odds with a few regional commanders who, although theoretically his subordinates, attempted to remove him from power. Ismail Khan claims that these efforts began with a botched assassination attempt. Afterwards, these commanders moved their forces near Herat. Ismail Khan, unpopular with the Herati military class, was slow to mobilise his forces, perhaps waiting for the threat to Herat to become existential as a means to motivate his forces. However, the conflict was stopped with the intervention of International Security Assistance Force forces and soldiers of the Afghan National Army, freezing the conflict in its tracks. Ismail Khan's forces even fought skirmishes with the Afghan National Army, in which his son, Mirwais Sadiq was killed. Because Ismail Khan was contained by the Afghan National Army, the warlords who opposed him were quickly able to occupy strategic locations unopposed. Ismail Khan was forced to give up his governorship and to go to Kabul, where he served in Hamid Karzai's cabinet as the Minister of Energy.
In 2005 Ismail Khan became the Minister of Water and Energy.
In late 2012, the Government of Afghanistan accused Ismail Khan of illegally distributing weapons to his supporters. About 40 members of the country's Parliament requested Ismail Khan to answer their queries. The government believes that Khan is attempting to create some kind of disruption in the country.
Assassination attempt.
On September 27, 2009, Ismail Khan survived a suicide blast that killed 4 of his bodyguards in Herat, in western Afghanistan. He was driving to Herat Airport when a powerful explosion occurred on the way there. Taliban spokesman, Zabiullah Mujahid, claimed responsibility and said the target was Khan.
Testimony requested by a Guantanamo captive.
Guantanamo captive Abdul Razzaq Hekmati requested Ismail Khan's testimony, when he was called before a Combatant Status Review Tribunal. 
Ismail Khan, like Afghan Minister of Defense Rahim Wardak, was one of the high profile Afghans that those conducting the Tribunals ruled were "not reasonably available" to give a statement on a captive's behalf because they could not be located.
Hekmati had played a key role in helping Ismail Khan escape from the Taliban in 1999.
Hekmati stood accused of helping Taliban leaders escape from the custody of Hamid Karzai's government.
Carlotta Gall and Andy Worthington interviewed Ismail Khan for a new "New York Times" article after Hekmati died of cancer in Guantanamo. 
According to the "New York Times"
Ismail Khan said he personally buttonholed the American ambassador to tell him that Hekmati was innocent, and should be released. In contrast, Hekmati was told that the State Department had been unable to locate Khan.
Controversy.
Ismail Khan is a controversial figure. Reporters Without Borders has charged him with muzzling the press and ordering attacks on journalists. Also Human Rights Watch has accused him of human rights abuses.
Nevertheless, he remains a popular figure for some in Afghanistan. Unlike other mujahideen commanders, Khan has not been linked to large-scale massacres and atrocities such as those committed after the capture of Kabul in 1992. Following news of his dismissal, rioting broke out in the streets of Herat, and President Karzai had to ask him to make a personal appeal for calm.

</doc>
<doc id="15250" url="https://en.wikipedia.org/wiki?curid=15250" title="Indigo">
Indigo

Indigo is a color that is traditionally regarded as a color on the visible spectrum, as well as one of the seven colors of the rainbow: the color between blue and violet. Although traditionally considered one of seven major spectral colors, sources differ as to its actual position in the electromagnetic spectrum. Indigo is a deep and bright color close to the color wheel blue (a primary color in the RGB color space), as well as to some variants of ultramarine.
The color indigo was named after the indigo dye derived from the plant "Indigofera tinctoria" and related species.
The first known recorded use of indigo as a color name in English was in 1289.
History.
Species of "Indigofera" were cultivated in India, East Asia and Egypt in antiquity. Pliny mentions India as the source of the dye, imported in small quantities via the Silk Road.
The Greek term for the dye was Ἰνδικὸν φάρμακον ("Indian dye"), which, adopted to Latin as "indicum" and via Portuguese gave rise to the modern word "indigo".
El Salvador has lately been the biggest producer of indigo.
The same indigo dye is contained in the woad plant, "Isatis tinctoria", for a long time the main source of blue dye in Europe. Woad was replaced by true indigo as trade routes opened up, and both are now largely replaced by synthetic dyes.
The Early Modern English word "indigo" referred to the dye, and not the the color (hue) itself, and "indigo" is not traditionally part of the basic color-naming system.
Classification as a spectral color.
Many modern books place indigo on the spectrum between 450 and 420 nanometers, which lies on the short-wave side of color wheel (RGB) blue, towards (spectral) violet. However, the correspondence of this definition with colors of actual indigo dyes is disputed. Optical scientists Hardy and Perrin list indigo as between 446 and 464 nm wavelength, which occupies a spectrum segment from roughly the color wheel (RGB) blue extending to the long-wave side, towards azure.
Isaac Newton introduced indigo as one of the seven colors in his spectrum. In the mid-1660s, when Newton bought a pair of prisms at a fair near Cambridge, the East India Company had begun importing indigo dye into England, supplanting the homegrown woad as the source of blue dye. In a pivotal experiment in the history of optics, the young Newton shone a narrow beam of sunlight through a prism to produce a rainbow-like band of colors on the wall. In describing this optical spectrum, Newton acknowledged that the spectrum had a continuum of colors, but named seven colors: "The originall or primary colours are Red, yellow, Green, Blew, & a violet purple; together with Orang, Indico, & an indefinite varietie of intermediate gradations." He linked the seven prismatic colors to the seven notes of a western major scale, as shown in his color wheel, with orange and indigo as the semitones. Having decided upon seven colors, he asked a friend to repeatedly divide up the spectrum that was projected from the prism onto the wall:
"I desired a friend to draw with a pencil lines cross the image, or pillar of colours, where every one of the seven aforenamed colours was most full and brisk, and also where he judged the truest confines of them to be, whilst I held the paper so, that the said image might fall within a certain compass marked on it. And this I did, partly because my own eyes are not very critical in distinguishing colours, partly because another, to whom I had not communicated my thoughts about this matter, could have nothing but his eyes to determine his fancy in making those marks."
Indigo is therefore counted as one of the traditional colors of the rainbow, the order of which is given by the mnemonic Roy G. Biv. James Clerk Maxwell and Hermann von Helmholtz accepted indigo as an appropriate name for the color flanking violet in the spectrum.
Later scientists conclude that Newton named the colors differently from current usage.
According to Gary Waldman, "A careful reading of Newton's work indicates that the color he called indigo, we would normally call blue; his blue is then what we would name blue-green or cyan." If this is true, Newton's seven spectral colors would have been:
Red: Orange: Yellow: Green: Blue: Indigo: Violet:
The human eye does not readily differentiate hues in the wavelengths between blue and violet. If this is where Newton meant indigo to lie, most individuals would have difficulty distinguishing indigo from its neighbors. According to Isaac Asimov, "It is customary to list indigo as a color lying between blue and violet, but it has never seemed to me that indigo is worth the dignity of being considered a separate color. To my eyes it seems merely deep blue."
Modern color scientists typically divide the spectrum between violet and blue at about 450 nm, with no indigo.
Distinction between the four major tones of indigo.
Like many other colors (orange, rose, and violet are the best-known), indigo gets its name from an object in the natural world—the plant named indigo once used for dyeing cloth (see also Indigo dye).
The color 'electric indigo' is a bright and saturated color between the traditional indigo and violet. This is the brightest color indigo that can be approximated on a computer screen—it is a color located between the (primary) blue and the color violet on the RGB color wheel.
The web color 'blue violet' or 'deep indigo' is a tone of indigo brighter than pigment indigo, but not as bright as electric indigo.
The color 'pigment indigo' is equivalent to the web color indigo and approximates the color indigo that is usually reproduced in pigments and colored pencils.
The color of indigo dye is a different color from either spectrum indigo or pigment indigo. This is the actual color of the dye. A vat full of this dye is a darker color, approximating the web color midnight blue.
Below are displayed these four major tones of indigo. When specifying the color indigo, it is important to indicate which of these four major tones is desired.
Electric indigo.
The color 'electric indigo' is much brighter than the pigment indigo reproduced below. When plotted on the CIE chromaticity diagram, this color is at 435 nanometers, in the middle of the portion of the spectrum traditionally considered indigo, i.e., between 450 and 420 nanometers. This color is only an approximation of spectral indigo, since actual spectral colors are outside the gamut of the sRGB color system.
Deep indigo (web color blue-violet).
At right is displayed the web color 'blue-violet', a color intermediate in brightness between electric indigo and pigment indigo. This color is also called 'deep indigo'.
Light indigo (web color indigo).
The color box at right displays the web color indigo which is equivalent to 'light indigo', the color indigo as it would be reproduced by artists' paints as opposed to the brighter indigo above (electric indigo) that is possible to reproduce on a computer screen. Its hue is closer to violet than to indigo dye for which the color is named. Pigment indigo can be obtained by mixing 55% pigment cyan with about 45% pigment magenta.
Compare the subtractive colors to the additive colors in the two primary color charts in the article on primary colors to see the distinction between electric colors as reproducible from light on a computer screen (additive colors) and the pigment colors reproducible with pigments (subtractive colors); the additive colors are significantly brighter because they are produced from light instead of pigment.
Light indigo (web color indigo) represents the way the color indigo was always reproduced in pigments, paints, or colored pencils in the 1950s. By the 1970s, because of the advent of psychedelic art, artists became used to brighter pigments, and pigments called "bright indigo" or "bright blue-violet" that are the pigment equivalent of the electric indigo reproduced in the section above became available in artists' pigments and colored pencils.
Tropical indigo.
'Tropical Indigo' is the color that is called "añil" (the Spanish word for "tropical indigo") in the "Guía de coloraciones" (Guide to colorations) by Rosa Gallego and
Juan Carlos Sanz, a color dictionary published in 2005 that is widely popular in the Hispanophone realm.
In nature.
Fungi
Birds
Snakes
In culture.
Spirituality.
The tone of indigo used in the spiritualist applications is electric indigo because the color is represented as being the color of the spectrum between blue and violet.

</doc>
<doc id="15251" url="https://en.wikipedia.org/wiki?curid=15251" title="International Monetary Fund">
International Monetary Fund

The International Monetary Fund (IMF) is an international organization headquartered in Washington, D.C., of "189 countries working to foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, and reduce poverty around the world." Formed in 1944 at the Bretton Woods Conference, it came into formal existence in 1945 with 29 member countries and the goal of reconstructing the international payment system. Countries contribute funds to a pool through a quota system from which countries experiencing balance of payments difficulties can borrow money. , the fund had SDR476.8 billion, about US$755.7 billion at then exchange rates.
Through the fund, and other activities such as statistics-keeping and analysis, surveillance of its members' economies and the demand for particular policies, the IMF works to improve the economies of its member countries. The organization's objectives stated in the Articles of Agreement are: to promote international monetary cooperation, international trade, high employment, exchange-rate stability, sustainable economic growth, and making resources available to member countries in financial difficulty.
Functions.
According to the IMF itself, it works to foster global growth and economic stability by providing policy, advice and financing to members, by working with developing nations to help them achieve macroeconomic stability and reduce poverty. The rationale for this is that private international capital markets function imperfectly and many countries have limited access to financial markets. Such market imperfections, together with balance-of-payments financing, provide the justification for official financing, without which many countries could only correct large external payment imbalances through measures with adverse economic consequences. The IMF provides alternate sources of financing.
Upon the founding of the IMF, its three primary functions were: to oversee the fixed exchange rate arrangements between countries, thus helping national governments manage their exchange rates and allowing these governments to prioritise economic growth, and to provide short-term capital to aid balance of payments. This assistance was meant to prevent the spread of international economic crises. The IMF was also intended to help mend the pieces of the international economy after the Great Depression and World War II. As well, to provide capital investments for economic growth and projects such as infrastructure.
The IMF's role was fundamentally altered by the floating exchange rates post-1971. It shifted to examining the economic policies of countries with IMF loan agreements to determine if a shortage of capital was due to economic fluctuations or economic policy. The IMF also researched what types of government policy would ensure economic recovery. The new challenge is to promote and implement policy that reduces the frequency of crises among the emerging market countries, especially the middle-income countries that are vulnerable to massive capital outflows. Rather than maintaining a position of oversight of only exchange rates, their function became one of surveillance of the overall macroeconomic performance of member countries. Their role became a lot more active because the IMF now manages economic policy rather than just exchange rates.
In addition, the IMF negotiates conditions on lending and loans under their policy of conditionality, which was established in the 1950s. Low-income countries can borrow on concessional terms, which means there is a period of time with no interest rates, through the Extended Credit Facility (ECF), the Standby Credit Facility (SCF) and the Rapid Credit Facility (RCF). Nonconcessional loans, which include interest rates, are provided mainly through Stand-By Arrangements (SBA), the Flexible Credit Line (FCL), the Precautionary and Liquidity Line (PLL), and the Extended Fund Facility. The IMF provides emergency assistance via the Rapid Financing Instrument (RFI) to members facing urgent balance-of-payments needs.
Surveillance of the global economy.
The IMF is mandated to oversee the international monetary and financial system and monitor the economic and financial policies of its member countries. This activity is known as surveillance and facilitates international cooperation. Since the demise of the Bretton Woods system of fixed exchange rates in the early 1970s, surveillance has evolved largely by way of changes in procedures rather than through the adoption of new obligations. The responsibilities changed from those of guardian to those of overseer of members’ policies.
The Fund typically analyzes the appropriateness of each member country’s economic and financial policies for achieving orderly economic growth, and assesses the consequences of these policies for other countries and for the global economy.
In 1995 the International Monetary Fund began work on data dissemination standards with the view of guiding IMF member countries to disseminate their economic and financial data to the public. The International Monetary and Financial Committee (IMFC) endorsed the guidelines for the dissemination standards and they were split into two tiers: The General Data Dissemination System (GDDS) and the Special Data Dissemination Standard (SDDS).
The executive board approved the SDDS and GDDS in 1996 and 1997 respectively, and subsequent amendments were published in a revised "Guide to the General Data Dissemination System". The system is aimed primarily at statisticians and aims to improve many aspects of statistical systems in a country. It is also part of the World Bank Millennium Development Goals and Poverty Reduction Strategic Papers.
The primary objective of the GDDS is to encourage member countries to build a framework to improve data quality and statistical capacity building in order to evaluate statistical needs, set priorities in improving the timeliness, transparency, reliability and accessibility of financial and economic data. Some countries initially used the GDDS, but later upgraded to SDDS.
Some entities that are not themselves IMF members also contribute statistical data to the systems:
Conditionality of loans.
IMF conditionality is a set of policies or conditions that the IMF requires in exchange for financial resources. The IMF does require collateral from countries for loans but also requires the government seeking assistance to correct its macroeconomic imbalances in the form of policy reform. If the conditions are not met, the funds are withheld. Conditionality is perhaps the most controversial aspect of IMF policies. The concept of conditionality was introduced in a 1952 Executive Board decision and later incorporated into the Articles of Agreement.
Conditionality is associated with economic theory as well as an enforcement mechanism for repayment. Stemming primarily from the work of Jacques Polak, the theoretical underpinning of conditionality was the "monetary approach to the balance of payments".
Structural adjustment.
Some of the conditions for structural adjustment can include:
These conditions are known as the Washington Consensus.
Benefits.
These loan conditions ensure that the borrowing country will be able to repay the IMF and that the country will not attempt to solve their balance-of-payment problems in a way that would negatively impact the international economy. The incentive problem of moral hazard—when economic agents maximize their own utility to the detriment of others because they do not bear the full consequences of their actions—is mitigated through conditions rather than providing collateral; countries in need of IMF loans do not generally possess internationally valuable collateral anyway.
Conditionality also reassures the IMF that the funds lent to them will be used for the purposes defined by the Articles of Agreement and provides safeguards that country will be able to rectify its macroeconomic and structural imbalances. In the judgment of the IMF, the adoption by the member of certain corrective measures or policies will allow it to repay the IMF, thereby ensuring that the resources will be available to support other members.
, borrowing countries have had a very good track record for repaying credit extended under the IMF's regular lending facilities with full interest over the duration of the loan. This indicates that IMF lending does not impose a burden on creditor countries, as lending countries receive market-rate interest on most of their quota subscription, plus any of their own-currency subscriptions that are loaned out by the IMF, plus all of the reserve assets that they provide the IMF.
History.
The IMF was originally laid out as a part of the Bretton Woods system exchange agreement in 1944. During the Great Depression, countries sharply raised barriers to trade in an attempt to improve their failing economies. This led to the devaluation of national currencies and a decline in world trade.
This breakdown in international monetary co-operation created a need for oversight. The representatives of 45 governments met at the Bretton Woods Conference in the Mount Washington Hotel in Bretton Woods, New Hampshire, in the United States, to discuss a framework for postwar international economic cooperation and how to rebuild Europe.
There were two views on the role the IMF should assume as a global economic institution. British economist John Maynard Keynes imagined that the IMF would be a cooperative fund upon which member states could draw to maintain economic activity and employment through periodic crises. This view suggested an IMF that helped governments and to act as the U.S. government had during the New Deal in response to World War II. American delegate Harry Dexter White foresaw an IMF that functioned more like a bank, making sure that borrowing states could repay their debts on time. Most of White's plan was incorporated into the final acts adopted at Bretton Woods.
The IMF formally came into existence on 27 December 1945, when the first 29 countries ratified its Articles of Agreement. By the end of 1946 the IMF had grown to 39 members. On 1 March 1947, the IMF began its financial operations, and on 8 May France became the first country to borrow from it.
The IMF was one of the key organisations of the international economic system; its design allowed the system to balance the rebuilding of international capitalism with the maximisation of national economic sovereignty and human welfare, also known as embedded liberalism. The IMF's influence in the global economy steadily increased as it accumulated more members. The increase reflected in particular the attainment of political independence by many African countries and more recently the 1991 dissolution of the Soviet Union because most countries in the Soviet sphere of influence did not join the IMF.
The Bretton Woods system prevailed until 1971, when the U.S. government suspended the convertibility of the US$ (and dollar reserves held by other governments) into gold. This is known as the Nixon Shock.
Since 2000.
In May 2010, the IMF participated, in 3:11 proportion, in the first Greek bailout that totalled €110 billion, to address the great accumulation of public debt, caused by continuing large public sector deficits. As part of the bailout, the Greek government agreed to adopt austerity measures that would reduce the deficit from 11% in 2009 to "well below 3%" in 2014. The bailout did not include debt restructuring measures such as a haircut, to the chagrin of the Swiss, Brazilian, Indian, Russian, and Argentinian Directors of the IMF, with the Greek authorities themselves (at the time, PM George Papandreou and Finance Minister Giorgos Papakonstantinou) ruling out a haircut.
A second bailout package of more than €100 billion was agreed over the course of a few months from October 2011, during which time Papandreou was forced from office. The so-called Troika, of which the IMF is part, are joint managers of this programme, which was approved by the Executive Directors of the IMF on 15 March 2012 for SDR23.8 billion, and which saw private bondholders take a haircut of upwards of 50%. In the interval between May 2010 and February 2012 the private banks of Holland, France and Germany reduced exposure to Greek debt from €122 billion to €66 billion.
As of January 2012, the largest borrowers from the IMF in order were Greece, Portugal, Ireland, Romania, and Ukraine.
On 25 March 2013, a €10 billion international bailout of Cyprus was agreed by the Troika, at the cost to the Cypriots of its agreement: to close the country's second-largest bank; to impose a one-time bank deposit levy on Bank of Cyprus uninsured deposits. No insured deposit of €100k or less were to be affected under the terms of a novel bail-in scheme.
The topic of sovereign debt restructuring was taken up by the IMF in April 2013 for the first time since 2005, in a report entitled "Sovereign Debt Restructuring: Recent Developments and Implications for the Fund’s Legal and Policy Framework". The paper, which was discussed by the board on 20 May, summarised the recent experiences in Greece, St Kitts and Nevis, Belize, and Jamaica. An explanatory interview with Deputy Director Hugh Bredenkamp was published a few days later, as was a deconstruction by Matina Stevis of the "Wall Street Journal".
In the October 2013 Fiscal Monitor publication, the IMF suggested that a capital levy capable of reducing Euro-area government debt ratios to "end-2007 levels" would require a very high tax rate of about 10%.
The Fiscal Affairs department of the IMF, headed at the time by Acting Director Sanjeev Gupta, produced a January 2014 report entitled "Fiscal Policy and Income Inequality" that stated that "Some taxes levied on wealth, especially on immovable property, are also an option for economies seeking more progressive taxation ... Property taxes are equitable and efficient, but underutilized in many economies ... There is considerable scope to exploit this tax more fully, both as a revenue source and as a redistributive instrument."
At the end of March 2014, the IMF secured an $18 billion bailout fund for the provisional government of Ukraine in the aftermath of the 2014 Ukrainian revolution.
Member countries.
Not all member countries of the IMF are sovereign states, and therefore not all "member countries" of the IMF are members of the United Nations. Amidst "member countries" of the IMF that are not member states of the UN are non-sovereign areas with special jurisdictions that are officially under the sovereignty of full UN member states, such as Aruba, Curaçao, Hong Kong, and Macau, as well as Kosovo. The corporate members appoint "ex-officio" voting members, who are listed below. All members of the IMF are also International Bank for Reconstruction and Development (IBRD) members and vice versa.
Former members are Cuba (which left in 1964), Venezuela (which left in 2007), Mexico (which left in 2011) and the Republic of China (Taiwan), which was ejected from the UN in 1980 after losing the support of then U.S. President Jimmy Carter and was replaced by the People's Republic of China. However, "Taiwan Province of China" is still listed in the official IMF indices.
Apart from Cuba, Venezuela and Mexico, the other UN states that do not belong to the IMF are Andorra, Liechtenstein, Monaco, and North Korea.
The former Czechoslovakia was expelled in 1954 for "failing to provide required data" and was readmitted in 1990, after the Velvet Revolution. Poland withdrew in 1950—allegedly pressured by the Soviet Union—but returned in 1986.
Qualifications.
Any country may apply to be a part of the IMF. Post-IMF formation, in the early postwar period, rules for IMF membership were left relatively loose. Members needed to make periodic membership payments towards their quota, to refrain from currency restrictions unless granted IMF permission, to abide by the Code of Conduct in the IMF Articles of Agreement, and to provide national economic information. However, stricter rules were imposed on governments that applied to the IMF for funding.
The countries that joined the IMF between 1945 and 1971 agreed to keep their exchange rates secured at rates that could be adjusted only to correct a "fundamental disequilibrium" in the balance of payments, and only with the IMF's agreement.
Some members have a very difficult relationship with the IMF and even when they are still members they do not allow themselves to be monitored. Argentina, for example, refuses to participate in an Article IV Consultation with the IMF.
Benefits.
Member countries of the IMF have access to information on the economic policies of all member countries, the opportunity to influence other members’ economic policies, technical assistance in banking, fiscal affairs, and exchange matters, financial support in times of payment difficulties, and increased opportunities for trade and investment.
Leadership.
Board of Governors.
The Board of Governors consists of one governor and one alternate governor for each member country. Each member country appoints its two governors. The Board normally meets once a year and is responsible for electing or appointing executive directors to the Executive Board. While the Board of Governors is officially responsible for approving quota increases, Special Drawing Right allocations, the admittance of new members, compulsory withdrawal of members, and amendments to the Articles of Agreement and By-Laws, in practice it has delegated most of its powers to the IMF's Executive Board.
The Board of Governors is advised by the International Monetary and Financial Committee and the Development Committee. The International Monetary and Financial Committee has 24 members and monitors developments in global liquidity and the transfer of resources to developing countries. The Development Committee has 25 members and advises on critical development issues and on financial resources required to promote economic development in developing countries. They also advise on trade and environmental issues.
Executive Board.
24 Executive Directors make up Executive Board. The Executive Directors represent all 188 member countries in a geographically based roster. Countries with large economies have their own Executive Director, but most countries are grouped in constituencies representing four or more countries.
Following the "2008 Amendment on Voice and Participation" which came into effect in March 2011, eight countries each appoint an Executive Director: the United States, Japan, Germany, France, the UK, China, the Russian Federation, and Saudi Arabia. The remaining 16 Directors represent constituencies consisting of 4 to 22 countries. The Executive Director representing the largest constituency of 22 countries accounts for 1.55% of the vote. This Board usually meets several times each week. The Board membership and constituency is scheduled for periodic review every eight years.
List of Executive Directors of the IMF, as of April 2015
Managing Director.
The IMF is led by a managing director, who is head of the staff and serves as Chairman of the Executive Board. The managing director is assisted by a First Deputy managing director and three other Deputy Managing Directors. Historically the IMF's managing director has been European and the president of the World Bank has been from the United States. However, this standard is increasingly being questioned and competition for these two posts may soon open up to include other qualified candidates from any part of the world.
In 2011 the world's largest developing countries, the BRIC nations, issued a statement declaring that the tradition of appointing a European as managing director undermined the legitimacy of the IMF and called for the appointment to be merit-based.
Previous managing director Dominique Strauss-Kahn was arrested in connection with charges of sexually assaulting a New York hotel room attendant and resigned on 18 May. On 28 June 2011 Christine Lagarde was confirmed as managing director of the IMF for a five-year term starting on 5 July 2011. In 2012, Lagarde was paid a tax-exempt salary of US$467,940, and this is automatically increased every year according to inflation. In addition, the director receives an allowance of US$83,760 and additional expenses for entertainment.
Voting power.
Voting power in the IMF is based on a quota system. Each member has a number of basic votes (each member's number of basic votes equals 5.502% of the total votes), plus one additional vote for each Special Drawing Right (SDR) of 100,000 of a member country's quota. The Special Drawing Right is the unit of account of the IMF and represents a claim to currency. It is based on a basket of key international currencies. The basic votes generate a slight bias in favour of small countries, but the additional votes determined by SDR outweigh this bias.
In December 2015, the U.S. Congress adopted a legislation authorizing the 2010 Quota and Governance Reforms. As a result, 
Effects of the quota system.
The IMF's quota system was created to raise funds for loans. Each IMF member country is assigned a quota, or contribution, that reflects the country's relative size in the global economy. Each member's quota also determines its relative voting power. Thus, financial contributions from member governments are linked to voting power in the organisation.
This system follows the logic of a shareholder-controlled organisation: wealthy countries have more say in the making and revision of rules. Since decision making at the IMF reflects each member's relative economic position in the world, wealthier countries that provide more money to the IMF have more influence than poorer members that contribute less; nonetheless, the IMF focuses on redistribution.
Developing countries.
Quotas are normally reviewed every five years and can be increased when deemed necessary by the Board of Governors. Currently, reforming the representation of developing countries within the IMF has been suggested. These countries' economies represent a large portion of the global economic system but this is not reflected in the IMF's decision making process through the nature of the quota system. Joseph Stiglitz argues, "There is a need to provide more effective voice and representation for developing countries, which now represent a much larger portion of world economic activity since 1944, when the IMF was created." In 2008, a number of quota reforms were passed including shifting 6% of quota shares to dynamic emerging markets and developing countries.
Overcoming borrower/creditor divide.
The IMF's membership is divided along income lines: certain countries provide the financial resources while others use these resources. Both developed country "creditors" and developing country "borrowers" are members of the IMF. The developed countries provide the financial resources but rarely enter into IMF loan agreements; they are the creditors. Conversely, the developing countries use the lending services but contribute little to the pool of money available to lend because their quotas are smaller; they are the borrowers. Thus, tension is created around governance issues because these two groups, creditors and borrowers, have fundamentally different interests.
The criticism is that the system of voting power distribution through a quota system institutionalises borrower subordination and creditor dominance. The resulting division of the IMF's membership into borrowers and non-borrowers has increased the controversy around conditionality because the borrowers are interested in increasing loan access while creditors want to maintain reassurance that the loans will be repaid.
Use.
A recent source revealed that the average overall use of IMF credit per decade increased, in real terms, by 21% between the 1970s and 1980s, and increased again by just over 22% from the 1980s to the 1991–2005 period. Another study has suggested that since 1950 the continent of Africa alone has received $300 billion from the IMF, the World Bank, and affiliate institutions.
A study by Bumba Mukherjee found that developing democratic countries benefit more from IMF programs than developing autocratic countries because policy-making, and the process of deciding where loaned money is used, is more transparent within a democracy. One study done by Randall Stone found that although earlier studies found little impact of IMF programs on balance of payments, more recent studies using more sophisticated methods and larger samples "usually found IMF programs improved the balance of payments".
Exceptional Access Framework – Sovereign Debt.
The Exceptional Access Framework was created in 2003 when John B. Taylor was Under Secretary of the U.S. Treasury for International Affairs. The new Framework became fully operational in February 2003 and it was applied in the subsequent decisions on Argentina and Brazil. Its purpose was to place some sensible rules and limits on the way the IMF makes loans to support governments with debt problem—especially in emerging markets—and thereby move away from the bailout mentality of the 1990s. Such a reform was essential for ending the crisis atmosphere that then existed in emerging markets. The reform was closely related to, and put in place nearly simultaneously with, the actions of several emerging market countries to place collective action clauses in their bond contracts.
In 2010, the framework was abandoned so the IMF could make loans to Greece in an unsustainable and political situation.
The topic of sovereign debt restructuring was taken up by IMF staff in April 2013 for the first time since 2005, in a report entitled "Sovereign Debt Restructuring: Recent Developments and Implications for the Fund's Legal and Policy Framework". The paper, which was discussed by the board on 20 May, summarised the recent experiences in Greece, St Kitts and Nevis, Belize and Jamaica. An explanatory interview with Deputy Director Hugh Bredenkamp was published a few days later, as was a deconstruction by Matina Stevis of the "Wall Street Journal".
The staff was directed to formulate an updated policy, which was accomplished on 22 May 2014 with a report entitled "The Fund's Lending Framework and Sovereign Debt: Preliminary Considerations", and taken up by the Executive Board on 13 June. The staff proposed that "in circumstances where a (Sovereign) member has lost market access and debt is considered sustainable ... the IMF would be able to provide Exceptional Access on the basis of a debt operation that involves an extension of maturities", which was labelled a "reprofiling operation". These reprofiling operations would "generally be less costly to the debtor and creditors—and thus to the system overall—relative to either an upfront debt reduction operation or a bail-out that is followed by debt reduction ... (and) would be envisaged only when both (a) a member has lost market access and (b) debt is assessed to be sustainable, but not with high probability ... Creditors will only agree if they understand that such an amendment is necessary to avoid a worse outcome: namely, a default and/or an operation involving debt reduction ... Collective action clauses, which now exist in most—but not all—bonds, would be relied upon to address collective action problems."
IMF and globalization.
Globalization encompasses three institutions: global financial markets and transnational companies, national governments linked to each other in economic and military alliances led by the United States, and rising "global governments" such as World Trade Organization (WTO), IMF, and World Bank. Charles Derber argues in his book "People Before Profit," "These interacting institutions create a new global power system where sovereignty is globalized, taking power and constitutional authority away from nations and giving it to global markets and international bodies". Titus Alexander argues that this system institutionalises global inequality between western countries and the Majority World in a form of global apartheid, in which the IMF is a key pillar.
The establishment of globalised economic institutions has been both a symptom of and a stimulus for globalization. The development of the World Bank, the IMF regional development banks such as the European Bank for Reconstruction and Development (EBRD), and multilateral trade institutions such as the WTO signals a move away from the dominance of the state as the exclusive unit of analysis in international affairs. Globalization has thus been transformative in terms of a reconceptualising of state sovereignty.
Following U.S. President Bill Clinton's administration's aggressive financial deregulation campaign in the 1990s, globalisation leaders overturned longstanding restrictions by governments that limited foreign ownership of their banks, deregulated currency exchange, and eliminated restrictions on how quickly money could be withdrawn by foreign investors.
Fund report in May 2015, the world's governments indirectly subsidize fossil fuel companies with $5.3tn (£3.4tn) a year. Most this is due to polluters not paying the costs imposed on governments by the burning of coal, oil and gas: air pollution, health problems, the floods, droughts and storms driven by climate change.
Criticisms.
Overseas Development Institute (ODI) research undertaken in 1980 included criticisms of the IMF which support the analysis that it is a pillar of what activist Titus Alexander calls global apartheid.
ODI conclusions were that the IMF's very nature of promoting market-oriented approaches attracted unavoidable criticism. On the other hand, the IMF could serve as a scapegoat while allowing governments to blame international bankers. The ODI conceded that the IMF was insensitive to political aspirations of LDCs, while its policy conditions were inflexible.
Argentina, which had been considered by the IMF to be a model country in its compliance to policy proposals by the Bretton Woods institutions, experienced a catastrophic economic crisis in 2001, which some believe to have been caused by IMF-induced budget restrictions—which undercut the government's ability to sustain national infrastructure even in crucial areas such as health, education, and security—and privatisation of strategically vital national resources. Others attribute the crisis to Argentina's misdesigned fiscal federalism, which caused subnational spending to increase rapidly. The crisis added to widespread hatred of this institution in Argentina and other South American countries, with many blaming the IMF for the region's economic problems. The current—as of early 2006—trend toward moderate left-wing governments in the region and a growing concern with the development of a regional economic policy largely independent of big business pressures has been ascribed to this crisis.
In an interview, the former Romanian Prime Minister Călin Popescu-Tăriceanu claimed that "Since 2005, IMF is constantly making mistakes when it appreciates the country's economic performances". Former Tanzanian President Julius Nyerere, who claimed that debt-ridden African states were ceding sovereignty to the IMF and the World Bank, famously asked, "Who elected the IMF to be the ministry of finance for every country in the world?"
Former chief economist of IMF and current Reserve Bank of India (RBI) Governor Raghuram Rajan who predicted Financial crisis of 2007–08 criticized IMF for remaining a sideline player to the Developed world. He criticized IMF for praising monetary policies of USA which are wreaking havoc in emerging markets. He had been critical of the ultra-loose money policies of the Western nations and IMF.
Conditionality.
The IMF has been criticised for being "out of touch" with local economic conditions, cultures, and environments in the countries they are requiring policy reform. The economic advice the IMF gives might not always take into consideration the difference between what spending means on paper and how it is felt by citizens.
Jeffrey Sachs argues that the IMF's "usual prescription is 'budgetary belt tightening to countries who are much too poor to own belts'". Sachswho says it? wrote that the IMF's role as a generalist institution specialising in macroeconomic issues needs reform. Conditionality has also been criticised because a country can pledge collateral of "acceptable assets" to obtain waivers—if one assumes that all countries are able to provide "acceptable collateral".
One view is that conditionality undermines domestic political institutions. The recipient governments are sacrificing policy autonomy in exchange for funds, which can lead to public resentment of the local leadership for accepting and enforcing the IMF conditions. Political instability can result from more leadership turnover as political leaders are replaced in electoral backlashes. IMF conditions are often criticised for reducing government services, thus increasing unemployment.
Another criticism is that IMF programs are only designed to address poor governance, excessive government spending, excessive government intervention in markets, and too much state ownership. This assumes that this narrow range of issues represents the only possible problems; everything is standardised and differing contexts are ignored. A country may also be compelled to accept conditions it would not normally accept had they not been in a financial crisis in need of assistance.
On top of that, regardless of what methodologies and data sets used, it comes to same conclusion of exacerbating income inequality. With Gini coefficient, it became clear that countries with IMF programs face increased income inequality.
It is claimed that conditionalities retard social stability and hence inhibit the stated goals of the IMF, while Structural Adjustment Programs lead to an increase in poverty in recipient countries. The IMF sometimes advocates “austerity programmes”, cutting public spending and increasing taxes even when the economy is weak, to bring budgets closer to a balance, thus reducing budget deficits. Countries are often advised to lower their corporate tax rate. In "Globalization and Its Discontents", Joseph E. Stiglitz, former chief economist and senior vice-president at the World Bank, criticizes these policies. He argues that by converting to a more monetarist approach, the purpose of the fund is no longer valid, as it was designed to provide funds for countries to carry out Keynesian reflations, and that the IMF "was not participating in a conspiracy, but it was reflecting the interests and ideology of the Western financial community".
International politics play an important role in IMF decision making. The clout of member states is roughly proportional to its contribution to IMF finances. The United States has the greatest number of votes and therefore wields the most influence. Domestic politics often come into play, with politicians in developing countries using conditionality to gain leverage over the opposition in order to influence policy.
Reform.
Function and policies.
The IMF is only one of many international organisations, and it is a generalist institution that deals only with macroeconomic issues; its core areas of concern in developing countries are very narrow. One proposed reform is a movement towards close partnership with other specialist agencies such as UNICEF, the Food and Agriculture Organization (FAO), and the United Nations Development Program (UNDP).
Jeffrey Sachs argues in "The End of Poverty" that the IMF and the World Bank have "the brightest economists and the lead in advising poor countries on how to break out of poverty, but the problem is development economics". Development economics needs the reform, not the IMF. He also notes that IMF loan conditions should be paired with other reforms—e.g., trade reform in developed nations, debt cancellation, and increased financial assistance for investments in basic infrastructure. IMF loan conditions cannot stand alone and produce change; they need to be partnered with other reforms or other conditions as applicable.
U.S. dominance and voting reform.
The scholarly consensus is that IMF decision-making is not simply technocratic, but also guided by political and economic concerns. The United States is the IMF's most powerful member, and its influence reaches even into decision-making concerning individual loan agreements. The North American giant is openly opposed to losing what Treasury Secretary Jacob Lew describes as its "leadership role" at the IMF, "our ability to shape international norms and practices".
Reforms to give more powers to emerging economies were agreed by the G20 in 2010; however, they are yet to be ratified by the U.S. Congress. The 2010 reforms cannot pass without American approval, since 85% of the Fund's voting power is required, and the Americans hold more than 16% of voting power. The U.S. executive board veto was brought up again by IMF junior members in April 2014, who also expressed their ongoing frustration with U.S. failure to ratify the 2010 reforms. Singapore's Finance Minister and IMF steering committee chairman Tharman Shanmugaratnam said it could cause "disruptive change" in the global economy: "We are more likely over time to see a weakening of multilateralism, the emergence of regionalism, bilateralism and other ways of dealing with global problems", and that would make the world a "less safe" place. In May 2015, the Obama administration made clear it would not sacrifice its IMF veto, in order to assure Congressional approval.
Support of military dictatorships.
The role of the Bretton Woods institutions has been controversial since the late Cold War, because of claims that the IMF policy makers supported military dictatorships friendly to American and European corporations and other anti-communist regimes. Critics also claim that the IMF is generally apathetic or hostile to human rights, and labour rights. The controversy has helped spark the anti-globalization movement.
An example of IMF's support for a dictatorship was its ongoing support for Mobutu's rule in Zaire, although its own envoy, Erwin Blumenthal, provided a sobering report about the entrenched corruption and embezzlement and the inability of the country to pay back any loans.
Arguments in favour of the IMF say that economic stability is a precursor to democracy; however, critics highlight various examples in which democratised countries fell after receiving IMF loans.
Impact on access to food.
A number of civil society organisations have criticised the IMF's policies for their impact on access to food, particularly in developing countries. In October 2008, former U.S. president Bill Clinton delivered a speech to the United Nations on World Food Day, criticizing the World Bank and IMF for their policies on food and agriculture:
Impact on public health.
A 2009 study concluded that the strict conditions resulted in thousands of deaths in Eastern Europe by tuberculosis as public health care had to be weakened. In the 21 countries to which the IMF had given loans, tuberculosis deaths rose by 16.6%.
In 2009, a book by Rick Rowden titled "The Deadly Ideas of Neoliberalism: How the IMF has Undermined Public Health and the Fight Against AIDS", claimed that the IMF’s monetarist approach towards prioritising price stability (low inflation) and fiscal restraint (low budget deficits) was unnecessarily restrictive and has prevented developing countries from scaling up long-term investment in public health infrastructure. The book claimed the consequences have been chronically underfunded public health systems, leading to demoralising working conditions that have fuelled a "brain drain" of medical personnel, all of which has undermined public health and the fight against HIV/AIDS in developing countries.
Impact on environment.
IMF policies have been repeatedly criticised for making it difficult for indebted countries to say no to environmentally harmful projects that nevertheless generate revenues such as oil, coal, and forest-destroying lumber and agriculture projects. Ecuador for example had to defy IMF advice repeatedly to pursue the protection of its rain forests, though paradoxically this need was cited in IMF argument to support that country. The IMF acknowledged this paradox in the 2010 report that proposed the IMF Green Fund, a mechanism to issue special drawing rights directly to pay for climate harm prevention and potentially other ecological protection as pursued generally by other environmental finance.
While the response to these moves was generally positive possibly because ecological protection and energy and infrastructure transformation are more politically neutral than pressures to change social policy. Some experts voiced concern that the IMF was not representative, and that the IMF proposals to generate only US$200 billion a year by 2020 with the SDRs as seed funds, did not go far enough to undo the general incentive to pursue destructive projects inherent in the world commodity trading and banking systems—criticisms often levelled at the World Trade Organization and large global banking institutions.
In the context of the European debt crisis, some observers noted that Spain and California, two troubled economies within Europe and the United States, and also Germany, the primary and politically most fragile supporter of a euro currency bailout would benefit from IMF recognition of their leadership in green technology, and directly from Green Fund–generated demand for their exports, which could also improve their credit ratings.
Alternatives.
In March 2011 the Ministers of Economy and Finance of the African Union proposed to establish an African Monetary Fund.
At the 6th BRICS summit in July 2014 the BRICS nations (Brazil, Russia, India, China, and South Africa) announced the BRICS Contingent Reserve Arrangement (CRA) with an initial size of US$100 billion, a framework to provide liquidity through currency swaps in response to actual or potential short-term balance-of-payments pressures.
In 2014, the China-led Asian Infrastructure Investment Bank was established as a rival to the IMF and World Bank.
In the media.
"Life and Debt", a documentary film, deals with the IMF's policies' influence on Jamaica and its economy from a critical point of view. "Debtocracy", a 2011 independent Greek documentary film, also criticizes the IMF. Portuguese musician José Mário Branco's 1982 album FMI is inspired by the IMF's intervention in Portugal through monitored stabilization programs in 1977–78.

</doc>
<doc id="15252" url="https://en.wikipedia.org/wiki?curid=15252" title="Islands of the Clyde">
Islands of the Clyde

The Islands of the Firth of Clyde are the fifth largest of the major Scottish island groups after the Inner and Outer Hebrides, Orkney and Shetland. They are situated in the Firth of Clyde between Ayrshire and Argyll. There are about forty islands and skerries, of which only four are inhabited and only nine larger than . The largest and most populous are Arran and Bute, and Great Cumbrae and Holy Isle are also served by dedicated ferry routes. Unlike the four larger Scottish archipelagos, none of the isles in this group are connected to one another or to the mainland by bridges.
The geology and geomorphology of the area is complex and the islands and the surrounding sea lochs each have distinctive features. The influence of the Atlantic Ocean and the North Atlantic Drift create a mild, damp oceanic climate.
The larger islands have been continuously inhabited since Neolithic times, were influenced by the emergence of the kingdom of Dál Riata from 500 AD and then absorbed into the emerging Kingdom of Alba under Kenneth MacAlpin. They experienced Norse incursions during the early Middle Ages and then became part of the Kingdom of Scotland in the 13th century. There is a diversity of wildlife, including three species of rare endemic tree.
Geology and geography.
The Highland Boundary Fault runs past Bute and through the northern part of Arran, so from a geological perspective some of the islands are in the Highlands and some in the Central Lowlands. As a result, Arran is sometimes referred to as "Scotland in miniature" and the island is a popular destination for geologists, who come to see intrusive igneous landforms such as sills and dykes as well as sedimentary and metasedimentary rocks ranging widely in age. Visiting in 1787, the geologist James Hutton found his first example of an unconformity there and this spot is one of the most famous places in the study of geology. A group of weakly metamorphosed rocks that form the Highland Border Complex lie discontinuously along the Highland Boundary Fault. One of the most prominent exposures is along Loch Fad on Bute. Ailsa Craig, which lies some south of Arran, has been quarried for a rare type of micro-granite containing riebeckite known as "Ailsite" which is used to make curling stones. As of 2004, 60 to 70% of all curling stones in use were made from granite from the island.
In common with the rest of Scotland the Firth of Clyde was covered by ice sheets during the Pleistocene ice ages and the landscape is much affected by glaciation. Arran's highest peaks may have been nunataks at this time. After the last retreat of the ice sea level changes and the isostatic rise of land makes charting post glacial coastlines a complex task but the resultant clifflines behind raised beaches are a prominent feature of the entire coastline.
The soils of the islands reflect the diverse geology. Bute has the most productive land, and a pattern of deposits that is typical of the southwest of Scotland. There is a mixture of boulder clay and other glacial deposits in the eroded valleys, and raised beach and marine deposits elsewhere, especially to the south and west which result in a machair landscape in places, inland from the sandy bays, such as Stravanan.
The Firth of Clyde, in which these island lie, is north of the Irish Sea and has numerous branching inlets, some of them substantial features in their own right. These include Loch Goil, Loch Long, Gare Loch, Loch Fyne and the estuary of the River Clyde. In places the effect of glaciation on the seabed is pronounced. For example, the Firth is deep between Arran and Bute, although they are only apart. The islands are all exposed to wind and tide and various lighthouses, such as those on Ailsa Craig, Pladda and Davaar act as an aid to navigation.
Climate.
The Firth of Clyde lies between 55 and 56 degrees north, at the same latitude as Labrador in Canada and north of the Aleutian Islands, but the influence of the North Atlantic Drift—the northern extension of the Gulf Stream—ameliorates the winter weather and the area enjoys a mild, damp oceanic climate. Temperatures are generally cool, averaging about in January and in July at sea level. Snow seldom lies at sea level and frosts are generally less frequent than the mainland. In common with most islands of the west coast of Scotland, rainfall is generally high at between per annum on Bute, the Cumbraes and in the south of Arran and per annum in the north of Arran. The Arran mountains are wetter still with the summits receiving over annually. May, June and July are the sunniest months, with upwards of 200 hours of bright sunshine being recorded on average, southern Bute benefiting from a particularly high level of sunny days.
History.
Prehistory.
Mesolithic humans arrived in the Firth of the Clyde during the fourth millennium BC, probably from Ireland. This was followed by a wave of Neolithic peoples using the same route and there is some evidence that the Firth of Clyde was a significant route via which mainland Scotland was colonised at this time. A particular style of megalithic structure developed in Argyll, the Clyde estuary and elsewhere in western Scotland that has become known as the Clyde cairn. They are rectangular or trapezoidal in shape with a small enclosing chamber faced with large slabs of stone set on end and sometimes subdivided into smaller compartments. A forecourt area may have been used for displays or rituals associated with the interment of the dead, who were placed inside the chambers. They are concentrated in Arran, Bute and Kintyre and it is likely that the Clyde cairns were the earliest forms of Neolithic monument constructed by incoming settlers although few of the 100 or so examples have been given a radiocarbon dating. An example at Monamore on Arran has been dated to 3160 BC, although it was almost certainly built earlier than that, possibly c. 4000BC. There are also numerous standing stones dating from prehistoric times, including six stone circles on Machrie Moor, Arran and other examples on Great Cumbrae and Bute.
Bronze Age settlers also constructed megaliths at various sites, many of them dating from the second millennium BC, although the chambered cairns were replaced by burial cists, found on for example, Inchmarnock. Settlement evidence, especially from the early part of this era is however poor. The Queen of the Inch necklace is an article of jewellery made of jet found on Bute that dates from circa 2000 BC. During the early Iron Age Brythonic culture held sway, there being no evidence that the Roman occupation of southern Scotland extended to these islands.
Early Scots rule.
During the 2nd century AD Irish influence was at work in the region and by the 6th century the kingdom of Dál Riata was established. Unlike the P-Celtic speaking Brythons, these Gaels spoke a form of Gaelic that still survives in the Hebrides. Through the efforts of Saint Ninian and others Christianity slowly supplanted Druidism. Dál Riata flourished from the time of Fergus Mór in the late fifth century until the Viking incursions that commenced in the late eighth century. Islands close to the shores of modern Ayrshire would have remained part of the Kingdom of Strathclyde during this period, whilst the main islands became part of the emerging Kingdom of Alba founded by Kenneth MacAlpin (Cináed mac Ailpín).
Viking influence.
The Islands of the Clyde historically formed the border zone between the Norse-dominated "Sudreyor" and Scotland. As such many of these islands fell under Norwegian and Ui Imair hegemony between the 9th and 13th centuries and this Norse influence would see almost constant warfare on the western seaboard of Scotland until the partitioning of the Hebrides in 1156.
Latterly, the Outer Hebrides remained under the control of Godred V of the Isle of Man while the Inner Hebrides south of Ardnamurchan and the islands of the Clyde became part of the Kingdom of the Hebrides controlled by Somerled. This began a process whereby the islands of the Clyde became Scottish in language and culture rather than Norse. After Somerled's death in 1164 his kingdom was split between his three sons, Ragnall in Islay and Kintyre, Dughall in Lorne and the other Argyll islands, and Angus holding Arran and Bute.
Nearly a century later in the 1230s invading Norse forces took Rothesay Castle, hacking through the walls with their axes. In 1263 troops commanded by Haakon Haakonarson repeated the feat but the ensuing Battle of Largs between Scots and Norse forces, which took place on the shores of the Firth of Clyde, was inconclusive as a military contest. This marked an ultimately terminal weakening of Norse power in Scotland. Haakon retreated to Orkney, where he died in December 1263, entertained on his death bed by recitations of the sagas. Following this ill-fated expedition, all rights that the Norwegian crown "had of old therein" in relation to the islands were yielded to the Kingdom of Scotland as a result of the 1266 Treaty of Perth.
Modern Scotland.
From the mid thirteenth century to the present day all of the islands of the Clyde have remained part of Scotland.
From the commencement of the early medieval period until 1387 all of these isles were part of the Diocese of Sodor and Man, based at Peel, on the Isle of Man. Thereafter, the seat of the Bishopric of the Isles was relocated to the north, firstly to Snizort on Skye and then Iona, a state of affairs which continued until the 16th century Scottish Reformation.
The century following 1750 was time of significant change. New forms of transport, industry and agriculture brought sweeping changes, and an end to traditional ways of life that had endured for centuries. The aftermath of the Battle of Culloden marked the beginning of the end for the clan system and whilst there were marked improvements in living standards for some, these transformations came at a cost for others. In the early 19th century Alexander, 10th Duke of Hamilton (1767–1852) embarked on a programme of clearances that had a devastating effect on Arran's population. Whole villages were removed and the Gaelic culture of the island dealt a terminal blow. A memorial to this early form of ethnic cleansing has been constructed on the shore at Lamlash, paid for by a Canadian descendant of the emigrants.
From the 1850s to the late 20th century the Clyde Puffer, made famous by the "Vital Spark", was the workhorse of the islands, carrying all kinds of produce and products to and from the islands. The Caledonian Steam Packet Company (CSP) was formed in May 1889 to operate steamer services to and from Gourock for the Caledonian Railway and soon expanded by taking over rival steamer operators. David MacBrayne Ltd operated the Glasgow to Ardrishaig steamer service, as part of the "Royal Route" to Oban. During the 20th century many of the islands were developed as tourist resorts for Glaswegians who went "Doon the Watter", in parallel to mainland resorts such as Largs and Troon.
In 1973 CSP and MacBraynes commenced joint Clyde and West Highland operations under the new name of Caledonian MacBrayne. A publicly owned company, they serve Great Cumbrae, Arran and Bute as well as running mainland-to-mainland ferries across the firth. Private companies operate services from Arran to Holy Isle and from McInroy's Point (Gourock) to Hunter's Quay on the Cowal peninsula.
The majority of the islands at one time made up the traditional County of Bute. Today the islands are split more or less equally between the modern unitary authorities of Argyll and Bute and North Ayrshire with only Ailsa Craig and Lady Isle in South Ayrshire falling outwith these two council areas.
Islands.
The following table gives a list of the islands of the Firth of Clyde with an area greater than 40 hectares (approximately 100 acres) plus adjacent smaller uninhabited islets, tidal islets only separated at higher stages of the tide, and skerries which are only exposed at lower stages of the tide.
Six islands were inhabited in 2001 including Davaar and Sanda with 2 and 1 residents respectively. By the time of the 2011 census neither had a usually resident population.
Outlying islands.
Some islets lie remote from the larger islands and are listed separately here by location.
Gare Loch is a small loch which hosts the Faslane Naval Base, the home of the UK's Trident nuclear submarines. At its southern end, the loch opens into the Firth of Clyde, via the Rhu narrows. It contains two islets: Green Island and Perch Rock.
The Kilbrannan Sound, which lies between Arran and the Kintyre peninsula, contains several islets: An Struthlag, Cour Island, Eilean Carrach (Carradale), Eilean Carrach (Skipness), Eilean Grianain, Eilean Sunadale, Gull Isle, Island Ross and Thorn Isle. In the late 11th century Magnus Barefoot, King of Norway, made an arrangement with King Malcolm III of Scotland that he could take possession of land on the west coast around which a ship could sail. He had his longship dragged across the long isthmus in the north of Kintyre between East Loch Tarbert and West Loch Tarbert as part of a campaign to increase his possessions. Magnus declared that Kintyre had "better land than the best of the Hebrides", and by taking command of his ship's tiller and "sailing" across the isthmus he was able to claim the entire peninsula was an island, which remained under Norse rule for more than a dozen years as a result.
Loch Fyne, which extends inland from the Sound of Bute is the longest of Scotland's sea lochs and contains several islets and skerries. These are Duncuan Island, Eilean Ardgaddan, Eilean a' Bhuic, Eilean Aoghainn, Eilean a' Chomhraig, Eilean an Dúnain, Eilean Buidhe (Ardmarnock), Eilean Buidhe (Portavadie), Eilean Fraoch, Eilean Math-ghamhna, Eilean Mór, Glas Eilean, Heather Island, Inverneil Island, Kilbride Island and Liath Eilean.
The North Ayrshire islets of Broad Rock, East Islet, Halftide Rock, High Rock and North Islet are all found surrounding Horse Isle. Lady Isle, which lies off the South Ayrshire coast near Troon once housed "ane old chapell with an excellent spring of water". However, in June 1821 someone set fire to the "turf and pasture", and permanently destroyed the island's grazing, with gales blowing much of the island's soil into the sea.
Neither Loch Goil nor Loch Long, which are fjord-like arms of the firth to the north, contain islands.
Non-islands.
The following are places along that shores of the Firth of Clyde that are not islands and have misleading names, "eilean" being Gaelic for "island": Eilean na Beithe, Portavadie; Eilean Beag, Cove; Eilean Dubh, Dalchenna, Loch Fyne; Eilean nan Gabhar, Melldalloch, Kyles of Bute; Barmore Island, just north of Tarbert, Kintyre; Eilean Aoidh, south of Portavadie; Eilean Leathan, Kilbrannan Sound just south of Torrisdale Bay; Island Muller, Kilbrannan Sound north of Campbeltown.
Natural history.
There are populations of red deer, red squirrel, badger, otter, adder and common lizard. Offshore there are harbour porpoises, basking sharks and various species of dolphin. Davaar is home to a population of wild goats.
Over 200 species of bird have been recorded in the area including black guillemot, eider, peregrine falcon and the golden eagle. In 1981 there were 28 ptarmigan on Arran, but in 2009 it was reported that extensive surveys had been unable to record any. Similarly, the red-billed chough no longer breeds on the island.
Arran also has three rare endemic species of tree, the Arran Whitebeams. These are the Scottish or Arran whitebeam, the cut-leaved whitebeam and the Catacol whitebeam, which are amongst the most endangered tree species in the world. They are found in a protected national nature reserve, and are monitored by staff from Scottish Natural Heritage. Only 283 Arran whitebeam and 236 cut-leaved whitebeam were recorded as mature trees in 1980. The Catacol whitebeam was discovered in 2007 and steps have been taken to protect the two known specimens.
Etymology.
The Roman historian Tacitus refers to the "Clota" meaning the Clyde. The derivation is not certain but probably from the Brythonic "Clouta" which became "Clut" in Old Welsh. The name's literal meaning is "wash" but probably refers to the idea of a river goddess being "the washer" or "strongly flowing one". Bute's derivation is also uncertain. "Bót" is the Norse name and this is the Old Irish word for "fire", possibly a reference to signal fires. The etymology of Arran is no more clear—Haswell-Smith (2004) offers a Brythonic derivation and a meaning of "high place" although Watson (1926) suggests it may be pre-Celtic.

</doc>
<doc id="15253" url="https://en.wikipedia.org/wiki?curid=15253" title="International Bank Account Number">
International Bank Account Number

The International Bank Account Number (IBAN) is an internationally agreed system of identifying bank accounts across national borders to facilitate the communication and processing of cross border transactions with a reduced risk of transcription errors. It was originally adopted by the European Committee for Banking Standards (ECBS), and later as an international standard under ISO 13616:1997. The current standard is ISO 13616:2007, which indicates SWIFT as the formal registrar. Initially developed to facilitate payments within the European Union, it has been implemented by most European countries and many countries in the other parts of the world, especially in the Middle East and in the Caribbean. As of February 2016, 69 countries were using the IBAN numbering system.
The IBAN consists of up to 34 alphanumeric characters, comprising a country code, two check digits and a long and detailed bank account-number. The check digits enable a sanity check of the bank account number to confirm its integrity before submitting a transaction.
Background.
Before IBAN, differing national standards for bank account identification (i.e. bank, branch, routing codes, and account number) were confusing for some users. This often led to necessary routing information being missing from payments. Routing information as specified by ISO 9362 (also known as Business Identifier Codes (BIC code), SWIFT ID or SWIFT code, and SWIFT-BIC) does not require a specific format for the transaction so the identification of accounts and transaction types is left to agreements of the transaction partners. It also does not contain check digits, so errors of transcription were not detectable and it was not possible for a sending bank to validate the routing information prior to submitting the payment. Routing errors caused delayed payments and incurred extra costs to the sending and receiving banks and often to intermediate routing banks.
In 1997, to overcome these difficulties, the International Organization for Standardization (ISO) published ISO 13616:1997. This proposal had a degree of flexibility, which the European Committee for Banking Standards (ECBS) believed would make it unworkable, and they produced a "slimmed down" version of the standard which, amongst other things, permitted only upper-case letters and required that the IBAN for each country have a fixed length. ISO 13616:1997 was subsequently withdrawn and replaced by ISO 13616:2003. The standard was revised again in 2007 when it was split into two parts. ISO 13616-1:2007 "specifies the elements of an international bank account number (IBAN) used to facilitate the processing of data internationally in data interchange, in financial environments as well as within and between other industries" but "does not specify internal procedures, file organization techniques, storage media, languages, etc. to be used in its implementation". ISO 13616-2:2007 describes "the Registration Authority (RA) responsible for the registry of IBAN formats that are compliant with ISO 13616-1 the procedures for registering ISO 13616-compliant IBAN formats". The official IBAN registrar under ISO 13616-2:2007 is SWIFT.
IBAN imposes a flexible but regular format sufficient for account identification and contains validation information to avoid errors of transcription. It carries all the routing information needed to get a payment from one bank to another wherever it may be; it contains key bank account details such as country code, branch codes (known as sort codes in the UK and Ireland) and account numbers, and it contains "check digits" which can be validated at source according to a single standard procedure. Where used, IBANs have reduced trans-national money transfer errors to under 0.1% of total payments.
Structure.
The IBAN consists of up to 34 alphanumeric characters, as follows:
The check digits enable a sanity check of the bank account number to confirm its integrity before submitting a transaction.
The IBAN should not contain spaces when transmitted electronically. When printed it is expressed in groups of four characters separated by a single space, the last group being of variable length as shown in the example below:
Permitted IBAN characters are the digits "0" to "9" and the 26 upper-case Latin alphabetic characters "A" to "Z". This applies even in countries (e.g., Thailand) where these characters are not used in the national language.
Basic Bank Account Number.
The Basic Bank Account Number (BBAN) format is decided by the national central bank or designated payment authority of each country. There is no consistency between the formats adopted. The national authority may register its BBAN format with SWIFT, but is not obliged to do so. It may adopt IBAN without registration. SWIFT also acts as the registration authority for the SWIFT system, which is used by most countries that have not adopted IBAN. A major difference between the two systems is that under SWIFT there is no requirement that BBANs used within a country be of a pre-defined length.
The BBAN must be of a fixed length for the country and comprise case-insensitive alphanumeric characters. It includes the domestic bank account number, branch identifier, and potential routing information. Each country can have a different national routing/account numbering system, up to a maximum of 30 alphanumeric characters.
Check digits.
The check digits enable the sending bank (or its customer) to perform a sanity check of the routing destination and account number from a single string of data at the time of data entry. This check is guaranteed to detect any instances where a single character has been omitted, duplicated, mistyped or where two characters have been transposed. Thus routing and account number errors are virtually eliminated.
Processing.
One of the design aims of the IBAN was to enable as much validation as possible to be done at the point of data entry. In particular, the computer program that accepts an IBAN will be able to validate:
The check digits are calculated using MOD-97-10 as per ISO/IEC 7064:2003 (abbreviated to "mod-97" in this article), which specifies a set of check character systems capable of protecting strings against errors which occur when people copy or key data. In particular, the standard states that the following can be detected:
The underlying rules for IBANs is that the account-servicing financial institution should issue an IBAN, as there are a number of areas where different IBANs could be generated from the same account and branch numbers that would satisfy the generic IBAN validation rules. In particular cases where 00 is a valid check digit, 97 will not be a valid check digit, likewise, if 01 is a valid check digit, 98 will not be a valid check digit, similarly with 02 and 99.
The UN CEFACT TBG5 has published a free IBAN validation service in 32 languages for all 57 countries that have adopted the IBAN standard. They have also published the Javascript source code of the verification algorithm.
An English language IBAN checker for ECBS member country bank accounts is available on its website.
Algorithms.
Validating the IBAN.
An IBAN is validated by converting it into an integer and performing a basic "mod-97" operation (as described in ISO 7064) on it. If the IBAN is valid, the remainder equals 1. The algorithm of IBAN validation is as follows:
If the remainder is 1, the check digit test is passed and the IBAN might be valid.
Example (fictitious United Kingdom bank, sort code 12-34-56, account number 98765432):
Generating IBAN check digits.
According to the ECBS "generation of the IBAN shall be the exclusive responsibility of the bank/branch servicing the account". The ECBS document replicates part of the ISO/IEC 7064:2003 standard as a method for generating check digits in the range 02 to 98. Check digits in the ranges 00 to 96, 01 to 97, and 03 to 99 will also provide validation of an IBAN, but the standard is silent as to whether or not these ranges may be used.
The preferred algorithm is:
Modulo operation on IBAN.
Any computer programming language or software package that is used to compute "D" mod "97" directly must have the ability to handle integers of more than 30 digits. In practice, this can only be done by software that either supports arbitrary-precision arithmetic or that can handle 220 bit (unsigned) integers, features that are often not standard. If the application software in use does not provide the ability to handle integers of this size, the modulo operation can be performed in a piece-wise manner (as is the case with the UN CEFACT TBG5 Javascript program).
Piece-wise calculation can be done in many ways. One such way is as follows:
The result of the final calculation in step 2 will be "D" mod 97 = "N" mod "97".
Example
In this example, the above algorithm for "D" mod 97 will be applied to "D" = 3214282912345698765432161182. (The digits are colour-coded to aid the description below.) If the result is one, the IBAN corresponding to "D" passes the check digit test.
From step 8, the final result is "D" mod 97 = 1 and the IBAN has passed this check digit test.
Adoption.
International bank transactions use either an IBAN or the ISO 9362 Bank Identifier Code system (BIC or SWIFT code) in conjunction with the BBAN.
The banks of most countries in Europe publish account numbers using both the IBAN format and the nationally recognised identifiers, this being mandatory within the European Economic Area. Banks in many other countries including most states of the Middle East, North Africa and the Caribbean have implemented the IBAN format for account identification.
Day-to-day administration of banking in British Overseas Territories varies from territory to territory — some, such as South Georgia and the South Sandwich Islands, have too small a population to warrant a banking system while others, such as Bermuda, have a thriving financial sector. The use of the IBAN is up to the local government — Gibraltar, being part of the European Union is required to use the IBAN, as are the Crown dependencies, which use the British clearing system and the British Virgin Islands have elected to do so. , no other British Overseas Territories have elected to use the IBAN. Banks in the Caribbean Netherlands also do not use the IBAN. In some countries the IBAN is used on an "ad hoc" basis, an example being Ukraine where account numbers used for international transfers of four of the national banks have additional aliases that follow the IBAN format as a precursor to formal SWIFT registration.
The degree to which bank verifies the validity of a recipient's bank account number depends of the configuration of the transmitting bank's software—many major software packages supply bank account validation as a standard function. Some banks outside Europe may not recognize IBAN, though this is expected to diminish with time. Non-European banks usually accept IBANs for accounts in Europe, although they might not treat IBANs differently from other foreign bank account numbers. In particular, they might not check the IBAN's validity prior to sending the transfer.
Banks in the United States do not use IBAN as account numbers for US accounts. Any adoption of the IBAN standard by US banks would likely be initiated by ANSI ASC X9, the US financial services standards development organization: a working group (WGAB20) was established as an X9 subcommittee to generate an IBAN construction for US Bank accounts.
Canadian financial institutions have not adopted IBAN and use bank transit numbers issued by the Canadian Payments Association for domestic transfers, and SWIFT for international transfers. There is no formal governmental or private sector regulatory requirement in Canada for the major banks to use IBAN. Financial institutions in Australia and New Zealand do not use IBAN. They use Bank State Branch codes for domestic transfers and SWIFT for international transfers.
Single Euro Payments Area (SEPA).
The IBAN designation scheme was chosen as the foundation for electronic straight-through processing in the European Economic Area. The European Parliament mandated that a bank charge needs to be the same amount for domestic credit transfers as for cross-border credit transfers regulated in decision 2560/2001 (updated in 924/2009). This regulation took effect in 2003. Only payments in euro up to €12,500 to a bank account designated by its IBAN were covered by the regulation.
The Euro Payments regulation has been the foundation for the decision to create a Single Euro Payments Area (SEPA). The European Central Bank has created the TARGET2 interbank network that unifies the technical infrastructure of the 26 central banks of the European Union (although Sweden and the UK have opted-out). SEPA is a self-regulatory initiative by the banking sector of Europe as represented in the European Payments Council (EPC). The European Union made the scheme mandatory through the Payment Services Directive published in 2007. Since January 2008, all countries must support SEPA credit transfer, and SEPA direct debit must be supported since November 2009. The regulation on SEPA payments increases the charge cap (same price for domestic payments as for cross-border payments) to €50,000.
With a further decision of the European Parliament, the IBAN scheme for bank accounts fully replaced the domestic numbering schemes from 31 December 2012. On 16 December 2010, the European Commission published proposed regulations that will make IBAN support mandatory for domestic credit transfer by 2013 and for domestic direct debit by 2014 (with a 12 and 24 months transition period respectively). Some countries have already replaced their traditional bank account scheme by IBAN. This includes Switzerland where IBAN was introduced for national credit transfer on 1 January 2006 and the support for the old bank account numbers has not been required from 1 January 2010.
Based on a 20 December 2011 memorandum, the EU parliament resolved the mandatory dates for the adoption of the IBAN on 14 February 2012. From 1 February 2014, all national systems for credit transfer and direct debit must be abolished and replaced by an IBAN-based system. This will be extended to all cross-border SEPA transactions from 1 February 2016 (Article 5 Section 7). After these dates the IBAN will be sufficient to identify an account for home and foreign financial transactions in SEPA countries and banks will no longer be permitted to require that the customer supply the BIC for the beneficiary's bank.
In the run-up to the 1 February 2014 deadline, it became apparent that many old bank account numbers had not been allocated IBANs—an issue that has to be addressed on a country-by-country basis. In Germany, for example, the German Federal Bank and the German Banking Industry Committee require that all holders of German bank codes ("Bankleitzahl") publish the specifics of their IBAN generation format taking into account not only the generation of check digits but also the handling of legacy bank codes, thereby enabling third parties to generate IBANs independently of the bank. The first such catalogue was published in June 2013 as a variant of the old bank code catalog ("Bankleitzahlendatei").
IBAN formats by country.
This table summarises the IBAN formats by country:
In addition to the above list, Nordea has catalogued IBANs for countries listed below.
In this list
Criticism.
There is criticism about the length and readability of IBAN. Printed on paper the IBAN is often difficult to read. Therefore, it is popular to group the IBAN with four symbols. However, for electronic documents (e.g. PDF invoice) the copy and paste of grouped IBAN can result in errors with online banking forms. Only a few user friendly bank institutes allow and detect the copy and paste of both grouped and ungrouped IBAN.

</doc>
<doc id="15254" url="https://en.wikipedia.org/wiki?curid=15254" title="Infinitive">
Infinitive

Infinitive is a grammatical term referring to certain verb forms existing in many languages. As with many linguistic concepts, there is not a single definition applicable to all languages. The word is derived from Late Latin " infinitivus", a derivative of "infinitus" meaning "infinite". They are most often used as non-finite verbs.
In traditional descriptions of English, the infinitive is the basic dictionary form of a verb when used non-finitely, with or without the particle "to". Thus "to go" is an infinitive, as is "go" in a sentence like "I must go there" (but not in "I go there", where it is a finite verb). The form without "to" is called the bare infinitive, and the form with "to" is called the full infinitive or "to"-infinitive.
In many other languages the infinitive is a single word, often with a characteristic inflective ending, like "morir" ("(to) die") in Spanish, "manger" ("(to) eat") in French, "portare" ("(to) carry") in Latin, "lieben" ("(to) love") in German, etc. However some languages have no forms which can be considered to be infinitives. Many Native American languages and some languages in Africa and Australia do not have direct equivalents to infinitives or verbal nouns; in their place they use finite verb forms in ordinary clauses or various special constructions.
Being a verb, an infinitive may take objects and other complements and modifiers to form a verb phrase (called an infinitive phrase). Like other non-finite verb forms (like participles, converbs, gerunds and gerundives) infinitives do not generally have an expressed subject; thus an infinitive verb phrase also constitutes a complete non-finite clause, called an infinitive (infinitival) clause. Such phrases or clauses may play a variety of roles within sentences, often being nouns (for example being the subject of a sentence or being a complement of another verb), and sometimes being adverbs or other types of modifier. Infinitives are not usually inflected for tense, person, etc. in the way that finite verbs are, although some degree of inflection sometimes occurs; for example Latin has distinct active and passive infinitives.
Infinitive phrases and clauses.
An "infinitive phrase" is a verb phrase constructed with the verb in infinitive form. This consists of the verb together with its objects and other complements and modifiers. Some examples of infinitive phrases in English are given below – these may be based on either the full infinitive (introduced by the particle "to") or the bare infinitive (without the particle "to").
Infinitive phrases often have an implied grammatical subject making them effectively clauses rather than phrases. Such "infinitive clauses" or "infinitival clauses", are one of several kinds of non-finite clause. They can play various grammatical roles like a constituent of a larger clause or sentence; for example it may form a noun phrase or adverb. Infinitival clauses may be embedded within each other in complex ways, like in the sentence:
Here the infinitival clause "to get married" is contained within the finite dependent clause "that Brett Favre is going to get married"; this in turn is contained within another infinitival clause, which is contained in the finite independent clause (the whole sentence).
The grammatical structure of an infinitival clause may differ from that of a corresponding finite clause. For example, in German, the infinitive form of the verb usually goes to the end of its clause, whereas a finite verb (in an independent clause) typically comes in second position.
Infinitive clauses with subject in the objective case.
Following certain verbs or prepositions, infinitives commonly "do" have an expressed subject, e.g. 
As these examples illustrate, the subject of the infinitive is in the objective case (them, him) in contrast to the nominative case that would be used with a finite verb, e.g. "They ate their dinner." 
Such accusative and infinitive constructions are present in Latin and Ancient Greek, as well as many modern languages. The unusual case for the subject of an infinitive is an example of exceptional case-marking, where the infinitive clause's role being an object of a verb or preposition (want, for) overpowers the pronoun's subjective role within the clause.
Marking for tense, aspect and voice.
In some languages, infinitives may be marked for grammatical categories like voice, aspect, and to some extent tense. This may be done by inflection, like with the Latin perfect and passive infinitives, or by periphrasis (with the use of auxiliary verbs), like with the Latin future infinitives or the English perfect and progressive infinitives.
Latin has present, perfect and future infinitives, with active and passive forms of each. For details see .
English has infinitive constructions which are marked (periphrastically) for aspect: perfect, progressive (continuous), or a combination of the two (perfect progressive). These can also be marked for passive voice (as can the plain infinitive):
Further constructions can be made with other auxiliary-like expressions, like "(to) be going to eat" or "(to) be about to eat", which have future meaning. For more examples of the above types of construction, see .
Perfect infinitives are also found in other European languages which have perfect forms with auxiliaries similarly to English. For example, "avoir mangé" means "(to) have eaten" in French.
English.
Regarding English, the term "infinitive" is traditionally applied to the unmarked form of the verb (the "plain form") when it forms a non-finite verb, whether or not introduced by the particle "to". Hence "sit" and "to sit", like used in the following sentences, would each be considered an infinitive:
The form without "to" is called the "bare infinitive"; the form introduced by "to" is called the "full infinitive" or "to-infinitive".
The other non-finite verb forms in English are the gerund or present participle (the "-ing" form), and the past participle – these are not considered infinitives. Moreover the unmarked form of the verb is not considered an infinitive when it is forms a finite verb: like a present indicative ("I "sit" every day"), subjunctive ("I suggest that he "sit""), or imperative (""Sit" down!"). (For some irregular verbs the form of the infinitive coincides additionally with that of the past tense and/or past participle, like in the case of "put".)
Certain auxiliary verbs are defective in that they do not have infinitives (or any other non-finite forms). This applies to the modal verbs ("can", "must", etc.), as well as certain related auxiliaries like the "had" of "had better" and the "used" of "used to". (Periphrases can be used instead in some cases, like "(to) be able to" for "can", and "(to) have to" for "must".) It also applies to the auxiliary "do", like used in questions, negatives and emphasis like described under "do"-support. (Infinitives are negated by simply preceding them with "not". Of course the verb "do" when forming a main verb can appear in the infinitive.) However, the auxiliary verbs "have" (used to form the perfect) and "be" (used to form the passive voice and continuous aspect) both commonly appear in the infinitive: "I should have finished by now"; "It's thought to have been a burial site"; "Let him be released"; "I hope to be working tomorrow."
Huddleston and Pullum's "Cambridge Grammar of the English Language" (2002) does not use the notion of the "infinitive" ("there is no form in the English verb paradigm called 'the infinitive'"), only that of the "infinitival clause", noting that English uses the same form of the verb, the "plain form", in infinitival clauses that it uses in imperative and present-subjunctive clauses.
A matter of controversy among prescriptive grammarians and style writers has been the appropriateness of separating the two words of the "to"-infinitive (as in "I expect "to" happily "sit" here"). For details of this, see split infinitive. Modern linguistic theories typically do not consider the "to"-infinitive to be a distinct constituent, instead regarding the scope of the particle "to" to cover an entire verb phrase; thus, "to buy a car" is parsed like "to [a car]", rather not like "buy car".
Uses of the infinitive.
The bare infinitive and the "to"-infinitive have a variety of uses in English. The two forms are mostly in complementary distribution – certain contexts call for one, and certain contexts for the other; they are not normally interchangeable, except in occasional instances like after the verb "help", where either can be used.
The main uses of infinitives (or infinitive phrases) are like follows:
The infinitive is also the usual dictionary form or citation form of a verb. The form listed in dictionaries is the bare infinitive, although the "to"-infinitive is often used in referring to verbs or in defining other verbs: "The word 'amble' means 'to walk slowly'"; "How do we conjugate the verb "to go"?"
For further detail and examples of the uses of infinitives in English, see Bare infinitive and "To"-infinitive in the article on uses of English verb forms.
Other Germanic languages.
The original Proto-Germanic ending of the infinitive was "-an", with verbs derived from other words ending in "-jan" or "-janan".
In German it is "-en" ("sagen"), with "-eln" or "-ern" endings on a few words based on -l or -r roots ("segeln", "ändern"). The use of "zu" with infinitives is similar to English "to", but is less frequent than in English. German infinitives can form nouns, often expressing abstractions of the action, in which case they are of neuter gender: "das Essen" means "the eating", but also "the food".
In Dutch infinitives also end in "-en" ("zeggen" — "to say"), sometimes used with "te" similar to English "to", e.g. "Het is niet moeilijk te begrijpen" → "It is not hard to understand." The few verbs with stems ending in "-a" have infinitives in -n ("gaan" — "to go", "slaan" — "to hit"). Afrikaans has lost the distinction between the infinitive and present forms of verbs, with the exception of the verbs "wees" (to be), which admits the present form "is", and the verb "hê" (to have), whose present form is "het".
In North Germanic languages the final "-n" was lost from the infinitive as early as 500–540 AD, reducing the suffix to "-a". Later it has been further reduced to "-e" in Danish and some Norwegian dialects (including the written majority language bokmål). In the majority of Eastern Norwegian dialects and a few bordering Western Swedish dialects the reduction to "-e" was only partial, leaving some infinitives in "-a" and others in "-e" (å laga vs. å kaste). In northern parts of Norway the infinitive suffix is completely lost (å lag’ vs. å kast’) or only the "-a" is kept (å laga vs. å kast’). The infinitives of these languages are inflected for passive voice through the addition of "-s" or "-st" to the active form. This suffix appearance in Old Norse was a contraction of "mik" (“me”, forming "-mk") or "sik" (reflexive pronoun, forming "-sk") and was originally expressing reflexive actions: (hann) "kallar" (“(he) calls”) + "-sik" (“himself”) > (hann) "kallask" (“(he) calls himself”). The suffixes "-mk" and "-sk" later merged to "-s", which evolved to "-st" in the western dialects. The loss or reduction of "-a" in active voice in Norwegian did not occur in the passive forms ("-ast", "-as"), except for some dialects that have "-es". The other North Germanic languages have the same vowel in both forms.
Latin and Romance languages.
The formation of the infinitive in the Romance languages reflects that in their ancestor, Latin, almost all verbs had an infinitive ending with "-re" (preceded by one of various thematic vowels). For example, in Italian infinitives end in "-are", "-ere", "-rre" (rare), or "-ire" (which is still identical to the Latin forms), and in "-arsi", "-ersi", "-rsi", "-irsi" for the reflexive forms. In Spanish and Portuguese, infinitives end in "-ar", "-er", or "-ir", while similarly in French they typically end in "-re", "-er", "oir", and "-ir". In Romanian the so-called "long infinitives" end in "-are, -ere, -ire" and they are converted into verbal nouns by articulation (verbs that cannot be converted into the nominal long infinitive are very rare). The "short infinitives" used in verbal contexts (e.g. after an auxiliary verb) have the endings "-a","-ea", "-e", and "-i" (basically removing the ending in "-re"). In Romanian, the infinitive is usually replaced by a clause containing the conjunction "sǎ" plus the subjunctive mood. The only verb that is modal in common modern Romanian is the verb "a putea", to be able to. However, in popular speech the infinitive after "a putea" is also increasingly replaced by the subjunctive.
In all Romance languages, infinitives can also form nouns.
Latin infinitives challenged several of the generalizations about infinitives. They did inflect for voice ("amare", "to love", "amari", to be loved) and for aspect ("amare", "to love", "amavisse", "to have loved"), and allowed for an overt expression of the subject ("video Socratem currere", "I see Socrates running"). See .
Romance languages inherited from Latin the possibility of an overt expression of the subject (as in Italian "vedo Socrate correre"). Moreover, the "inflected infinitive" (or "personal infinitive") found in Portuguese and Galician inflects for person and number. These are the only Indo-European languages that allow infinitives to take person and number endings. This helps to make infinitive clauses very common in these languages; for example, the English finite clause "in order that you/she/we have..." would be translated to Portuguese like "para teres/ela ter/termos..." (Portuguese is a null-subject language). The Portuguese personal infinitive has no proper tenses, only aspects (imperfect and perfect), but tenses can be expressed using periphrastic structures. For instance, "even though you sing/have sung/are going to sing" could be translated to "apesar de cantares/teres cantado/ires cantar".
Other Romance languages (including Spanish, Romanian, Catalan, and some Italian dialects) allow uninflected infinitives to combine with overt nominative subjects. For example, Spanish "al abrir yo los ojos" ("when I opened my eyes") or "sin yo saberlo" ("without my knowing about it").
Hellenic languages.
Ancient Greek.
In Ancient Greek the infinitive has four tenses (present, future, aorist, perfect) and three voices (active, middle, passive). Present and perfect have the same infinitive for both middle and passive, while future and aorist have separate middle and passive forms.
Thematic verbs form present active infinitives by adding to the stem the thematic vowel and the infinitive ending , and contracts to , e.g. . Athematic verbs, and perfect actives and aorist passives, add the suffix instead, e.g. . In the middle and passive, the present middle infinitive ending is , e.g. and most tenses of thematic verbs add an additional between the ending and the stem, e.g. .
Modern Greek.
The infinitive per se does not exist in Modern Greek. To see this, consider the ancient Greek "ἐθέλω γράφειν" "I want to write". In modern Greek this become "θέλω να γράψω" "I want that I write". In modern Greek, the infinitive has thus changed form and is used mainly in the formation of tenses and not with an article or alone. Instead of the Ancient Greek infinitive "γράφειν", Modern Greek uses the aorist infinitive "γράψει", which does not inflect. The modern Greek infinitive has only two forms according to voice: for example, "γράψει" for the active voice and "γραφ(τ)εί" for the passive voice.
Balto-Slavic languages.
The infinitive in Russian usually ends in "-t’" (ть) preceded by a thematic vowel, or "-ti" (ти), if not preceded by one; some verbs have a stem ending in a consonant and change the "t" to "č’", like "*mogt’ → moč’" (*могть → мочь) "can". Some other Balto-Slavic languages have the infinitive typically ending in, for example, "-ć" (sometimes "-c") in Polish, "-t’" in Slovak, "-t" (formerly "-ti") in Czech and Latvian (with a handful ending in -s on the latter), "-ty" (-ти) in Ukrainian, -ць ("-ts"') in Belarusian. Lithuanian infinitives end in -"ti", Slovenian end on -"ti" or -"či", and Croatian on -"ti" or -"ći".
Serbian officially retains infinitives -"ti" or -"ći", but is more flexible than the other Slavs in breaking the infinitive through a clause. The infinitive nevertheless remains the dictionary form. Bulgarian and Macedonian have lost the infinitive altogether (it usually ended in -ти). For that reason, the present first-person singular conjugation is the dictionary form in Bulgarian, while Macedonian uses the third person singular form of the verb in present tense.
Biblical Hebrew.
Hebrew has "two" infinitives, the infinitive absolute and the infinitive construct. The infinitive construct is used after prepositions and is inflected with pronominal endings to indicate its subject or object: "bikhtōbh hassōphēr" "when the scribe wrote", "ahare lekhtō" "after his going". When the infinitive construct is preceded by ל ("lə-", "li-", "lā-", "lo-") "to", it has a similar meaning to the English "to"-infinitive, and this is its most frequent use in Modern Hebrew. The infinitive absolute is used for verb focus, like in מות ימות "mōth yāmūth" (literally "a dying he will die"; figuratively, "he shall indeed/surely die"). This usage is commonplace in the Bible, but in Modern Hebrew it is restricted to high-flown literary works.
Note, however, that the "to"-infinitive of Hebrew is not the dictionary form; that is the third person singular perfect form.
Finnish.
The Finnish grammatical tradition includes many non-finite forms that are generally labeled as (numbered) infinitives although many of these are functionally converbs. To form the so-called first infinitive, the strong form of the root (without consonant gradation or epenthetic 'e') is used, and these changes occur:
As such, it is inconvenient for dictionary use, because the imperative would be closer to the root word. Nevertheless, dictionaries use the first infinitive.
There are also four other infinitives, plus a "long" form of the first:
Note that all of these must change to reflect vowel harmony, so the fifth infinitive (with a third-person suffix) of "hypätä" "jump" is "hyppäämäisillään" "he was about to jump", not "*hyppäämaisillaan".
Seri.
The Seri language of northwestern Mexico has infinitival forms which are used in two constructions (with the verb meaning 'want' and with the verb meaning 'be able'). The infinitive is formed by adding a prefix to the stem: either "iha-" (plus a vowel change of certain vowel-initial stems) if the complement clause is transitive, or "ica-" (and no vowel change) if the complement clause is intransitive. The infinitive shows agreement in number with the controlling subject. Examples are: "icatax ihmiimzo" 'I want to go', where "icatax" is the singular infinitive of the verb 'go' (singular root is "-atax"), and "icalx hamiimcajc" 'we want to go', where "icalx" is the plural infinitive. Examples of the transitive infinitive: "ihaho" 'to see it/him/her/them' (root "-aho"), and "ihacta" 'to look at it/him/her/them' (root "-oocta").
Translation to languages without an infinitive.
In languages without an infinitive, the infinitive is translated either as a "that"-clause or as a verbal noun. For example, in Literary Arabic the sentence "I want to write a book" is translated as either "urīdu an aktuba kitāban" (lit. "I want that I write a book", with a verb in the subjunctive mood) or "urīdu kitābata kitābin" (lit. "I want the writing of a book", with the "masdar" or verbal noun), and in Levantine Colloquial Arabic "biddi aktub kitāb" (subordinate clause with verb in subjunctive).
Even in languages that have infinitives, similar constructions are sometimes necessary where English would allow the infinitive. For example, in French the sentence "I want you to come" translates to "Je veux que vous veniez" (lit. "I want that you come", with "come" being in the subjunctive mood). However, "I want to come" is simply "Je veux venir", using the infinitive, just as in English. In Russian, sentences such as "I want you to leave" do not use an infinitive. Rather, they use the conjunction чтобы "in order to/so that" with the past tense form (most probably remnant of subjunctive) of the verb: "Я хочу, чтобы вы ушли" (literally, "I want so that you left").

</doc>
<doc id="15256" url="https://en.wikipedia.org/wiki?curid=15256" title="Immaculate Conception">
Immaculate Conception

The Immaculate Conception, according to the teaching of the Catholic Church, was the conception of the Blessed Virgin Mary in the womb of her mother, Saint Anne, free from original sin by virtue of the foreseen merits of her son Jesus Christ. The Catholic Church teaches that Mary was conceived by normal biological means, but God acted upon her soul (keeping her "immaculate") at the time of her conception.
The Immaculate Conception is commonly and mistakenly taken to mean the conception of Mary's son Jesus Christ in her own womb, and the Virgin Birth of Jesus. These are covered by the Doctrine of Incarnation, while the Immaculate Conception deals with the conception of Mary "herself", not that of her son.
Although the belief that Mary was sinless and conceived immaculate has been widely held since Late Antiquity, the doctrine was not dogmatically defined until 1854, by Pope Pius IX in his papal bull "Ineffabilis Deus". The Catholic Church celebrates the Feast of the Immaculate Conception on December 8; in many Catholic countries, it is a holy day of obligation or patronal feast, and in some a national public holiday.
Distinctions.
Original sin and actual (personal) sin.
The defined dogma of the Immaculate Conception regards original sin only, saying that Mary was preserved from any "stain" (in Latin, "macula" or "labes", the second of these two synonymous words being the one used in the formal definition). The proclaimed Roman Catholic dogma states "that the most Blessed Virgin Mary, in the first instance of her conception, by a singular grace and privilege granted by Almighty God, in view of the merits of Jesus Christ, the Saviour of the human race, was preserved free from all stain of original sin." Therefore, being always free from original sin, the doctrine teaches that from her conception Mary received the sanctifying grace that would normally come with baptism after birth.
The definition makes no declaration about the Church's belief that the Blessed Virgin was sinless in the sense of freedom from actual or personal sin. However, the Church holds that Mary was also sinless personally, "free from all sin, original or personal". The Council of Trent decreed: "If anyone shall say that a man once justified can sin no more, nor lose grace, and that therefore he who falls and sins was never truly justified; or, on the contrary, that throughout his whole life he can avoid all sins even venial sins, except by a special privilege of God, as the Church holds in regard to the Blessed Virgin: let him be anathema."
Virginal conception.
The doctrine of the immaculate conception (Mary being conceived free from original sin) is not to be confused with her virginal conception of her son Jesus. This misunderstanding of the term "immaculate conception" is frequently met in the mass media. Catholics believe that Mary was not the product of a virginal conception herself but was the daughter of a human father and mother, traditionally known by the names of Saint Joachim and Saint Anne. In 1677, the Holy See condemned the belief that Mary was virginally conceived, which had been a belief surfacing occasionally since the 4th century. The Church celebrates the Feast of the Immaculate Conception (when Mary was conceived free from original sin) on 8 December, exactly nine months before celebrating the Nativity of Mary. The feast of the Annunciation (which commemorates the virginal conception and the Incarnation of Jesus) is celebrated on 25 March, nine months before Christmas Day.
Redemption.
Another misunderstanding is that, by her immaculate conception, Mary did not need a saviour. When defining the dogma in "Ineffabilis Deus", Pope Pius IX explicitly affirmed that Mary was redeemed in a manner more sublime. He stated that Mary, rather than being cleansed after sin, was completely prevented from contracting Original Sin in view of the foreseen merits of Jesus Christ, the Savior of the human race. In , Mary proclaims: "My spirit has rejoiced in God my Saviour." This is referred to as Mary's pre-redemption by Christ. Since the Second Council of Orange against semi-pelagianism, the Catholic Church has taught that even had man never sinned in the Garden of Eden and was sinless, he would still require God's grace to remain sinless.
History.
A feast of the Conception of the Most Holy and All Pure Mother of God was celebrated in Syria on 8 December perhaps as early as the 5th century. Note that the title of "achrantos" (spotless, immaculate, all-pure) refers to the holiness of Mary, not specifically to the holiness of her conception.
Mary's complete sinlessness and concomitant exemption from any taint from the first moment of her existence was a doctrine familiar to Greek theologians of Byzantium. Beginning with St. Gregory Nazianzen, his explanation of the "purification" of Jesus and Mary at the circumcision (Luke 2:22) prompted him to consider the primary meaning of "purification" in Christology (and by extension in Mariology) to refer to a perfectly sinless nature that manifested itself in glory in a moment of grace (e.g., Jesus at his Baptism). St. Gregory Nazianzen designated Mary as "prokathartheisa (prepurified)." Gregory likely attempted to solve the riddle of the Purification of Jesus and Mary in the Temple through considering the human natures of Jesus and Mary as equally holy and therefore both purified in this manner of grace and glory. Gregory's doctrines surrounding Mary's purification were likely related to the burgeoning commemoration of the Mother of God in and around Constantinople very close to the date of Christmas. Nazianzen's title of Mary at the Annunciation as "prepurified" was subsequently adopted by all theologians interested in his Mariology to justify the Byzantine equivalent of the Immaculate Conception. This is especially apparent in the Fathers St. Sophronios of Jerusalem and St. John Damascene, who will be treated below in this article at the section on Church Fathers. About the time of Damascene, the public celebration of the "Conception of St. Ann of the Theotokos in her womb" was becoming popular. After this period, the "purification" of the perfect natures of Jesus and Mary would not only mean moments of grace and glory at the Incarnation and Baptism and other public Byzantine liturgical feasts, but purification was eventually associated with the feast of Mary's very conception (along with her Presentation in the Temple as a toddler) by Orthodox authors of the 2nd millennium (e.g., St. Nicholas Cabasilas and Joseph Bryennius).
Church Fathers.
It is admitted that the doctrine as defined by Pius IX was not explicitly mooted before the 12th century. It is also agreed that "no direct or categorical and stringent proof of the dogma can be brought forward from Scripture". But it is claimed that the doctrine is implicitly contained in the teaching of the Fathers. Their expressions on the subject of the sinlessness of Mary are, it is pointed out, so ample and so absolute that they must be taken to include original sin as well as actual. Thus in the first five centuries such epithets as "in every respect holy", "in all things unstained", "super-innocent", and "singularly holy" are applied to her; she is compared to Eve before the fall, as ancestress of a redeemed people; she is "the earth before it was accursed". The well-known words of St. Augustine (d. 430) may be cited: "As regards the mother of God," he says, "I will not allow any question whatever of sin." It is true that he is here speaking directly of actual or personal sin. But his argument is that all men are sinners; that they are so through original depravity; that this original depravity may be overcome by the grace of God, and he adds that he does not know but that Mary may have had sufficient grace to overcome sin "of every sort" ("omni ex parte").
Although the doctrine of Mary's Immaculate Conception appears only later among Latin (and particularly Frankish) theologians, it became ever more manifest among Byzantine theologians reliant on Gregory Nazianzen's Mariology in the Medieval or Byzantine East. Although hymnographers and scholars, like the Emperor Justinian I, were accustomed to call Mary "prepurified" in their poetic and credal statements, the first point of departure for more fully commenting on Nazianzen's meaning occurs in Sophronius of Jerusalem. In other places Sophronius explains that the Theotokos was already immaculate, when she was "purified" at the Annunciation and goes so far as to note that John the Baptist is literally "holier than all 'Men' born of woman" since Mary's surpassing holiness signifies that she was holier than even John after his sanctification in utero. Sophronius' teaching is augmented and incorporated by St. John Damascene (d. 749/750). John, besides many passages wherein he extolls the Theotokos for her purification at the Annunciation, grants her the unique honor of "purifying the waters of baptism by touching them." This honor was most famously and firstly attributed to Christ, especially in the legacy of Nazianzen. As such, Nazianzen's assertion of parallel holiness between the prepurified Mary and purified Jesus of the New Testament is made even more explicit in Damascene in his discourse on Mary's holiness to also imitate Christ's baptism at the Jordan. The Damascene's hymnongraphy and De fide Orthodoxa explicitly use Mary's "pre purification" as a key to understanding her absolute holiness and unsullied human nature. In fact, Damascene (along with Nazianzen) serves as the source for nearly all subsequent promotion of Mary's complete holiness from her Conception by the "all pure seed" of Joachim and the womb "wider than heaven" of St. Ann.
Feast day.
By 750, the feast of her conception was widely celebrated in the Byzantine East, under the name of the Conception (active) of Saint Anne. In the West it was known as the feast of the Conception (passive) of Mary, and was associated particularly with the Normans, whether these introduced it directly from the East or took it from English usage. The spread of the feast, by now with the adjective "Immaculate" attached to its title, met opposition on the part of some, on the grounds that sanctification was possible only after conception. Critics included Saints Bernard of Clairvaux, Albertus Magnus and Thomas Aquinas. Other theologians defended the expression "Immaculate Conception", pointing out that sanctification could be conferred at the first moment of conception in view of the foreseen merits of Christ, a view held especially by Franciscans.
William of Ware and Blessed John Duns Scotus pointed out that Mary’s Immaculate Conception enhances Jesus’ redemptive work. One of the chief proponents of the doctrine was the Hungarian Franciscan Pelbartus Ladislaus of Temesvár.
On 28 February 1476, Pope Sixtus IV, authorized those dioceses that wished to introduce the feast to do so, and introduced it to his own diocese of Rome in 1477, with a specially composed Mass and Office of the feast. With his bull "Cum praeexcelsa" of 28 February 1477, in which he referred to the feast as that of the Conception of Mary, without using the word "Immaculate", he granted indulgences to those who would participate in the specially composed Mass or Office on the feast itself or during its octave, and he used the word "immaculate" of Mary, but applied instead the adjective "miraculous" to her conception. On 4 September 1483, referring to the feast as that of "the Conception of Immaculate Mary ever Virgin", he condemned both those who called it mortally sinful and heretical to hold that the "glorious and immaculate mother of God was conceived "without" the stain of original sin" and those who called it mortally sinful and heretical to hold that "the glorious Virgin Mary was conceived "with" original sin", since, he said, "up to this time there has been no decision made by the Roman Church and the Apostolic See." This decree was reaffirmed by the Council of Trent.
Pope Pius V, while including the feast in the Tridentine Calendar, removed the adjective "Immaculate" and suppressed the existing special Mass for the feast, directing that the Mass for the Nativity of Mary (with the word "Nativity" replaced by "Conception") be used instead. Part of that earlier Mass was revived in the Mass that Pope Pius IX ordered to be used on the feast and that is still in use.
On 6 December 1708, Pope Clement XI made the feast of the Conception of Mary, at that time still with the Nativity of Mary formula for the Mass, a Holy Day of Obligation. Until Pope Pius X reduced in 1911 the number of Holy Days of Obligation to 8, there were in the course of the year 36 such days, apart from Sundays. Writers such as Sarah Jane Boss interpret the existence of the feast as a strong indication of the Church's traditional belief in the Immaculate Conception.
Definition of the dogma.
During the reign of Pope Gregory XVI the bishops in various countries began to press for a definition as dogma of the teaching of Mary's immaculate conception.
In 1839 Mariano Spada (1796 - 1872), professor of theology at the Roman College of Saint Thomas, published "Esame Critico sulla dottrina dell’ Angelico Dottore S. Tommaso di Aquino circa il Peccato originale, relativamente alla Beatissima Vergine Maria" critical examination of the doctrine of St. Thomas Aquinas, the Angelic Doctor, regarding original sin with respect to the Most Blessed Virgin Mary, in which Aquinas is interpreted not as treating the question of the Immaculate Conception later formulated in the papal bull "Ineffabilis Deus" but rather the sanctification of the fetus within Mary's womb. Spada furnished an interpretation whereby Pius IX was relieved of the problem of seeming to foster a doctrine not in agreement with the Aquinas' teaching. Pope Pius IX would later appoint Spada Master of the Sacred Palace in 1867.
Pius IX, at the beginning of his pontificate, and again after 1851, appointed commissions to investigate the whole subject, and he was advised that the doctrine was one which could be defined and that the time for a definition was opportune.
It was not until 1854 that Pope Pius IX, with the support of the overwhelming majority of Roman Catholic bishops, whom he had consulted between 1851–1853, promulgated the papal bull "Ineffabilis Deus" (Latin for "Ineffable God"), which defined "ex cathedra" the dogma of the Immaculate Conception:
The dogma was defined in accordance with the conditions of papal infallibility, which would be defined in 1870 by the First Vatican Council.
The papal definition of the dogma declares with absolute certainty and authority that Mary possessed sanctifying grace from the first instant of her existence and was free from the lack of grace caused by the original sin at the beginning of human history. Mary's salvation was won by her son Jesus Christ through his passion, death, and resurrection and was not due to her own merits.
Later developments.
For the Roman Catholic Church the dogma of the Immaculate Conception gained additional significance from the reputed apparitions of Our Lady of Lourdes in 1858. At Lourdes a 14-year-old girl, Bernadette Soubirous, claimed that a beautiful woman appeared to her and said, "I am the Immaculate Conception". Many believe the woman to have been the Blessed Virgin Mary and pray to her as such.
Pope Pius IX defined the dogma of the Immaculate Conception "not so much because of proofs in Scripture or ancient tradition, but due to a profound "sensus fidelium" and the Magisterium".
Speaking of the witness of the Church Fathers in claiming for Mary titles such as "Free from all contagion of sin", Pope Pius XII wrote:
The Roman Catholic tradition has a well-established philosophy for the study of the Immaculate Conception and the veneration of the Blessed Virgin Mary in the field of Mariology, with Pontifical schools such as the Marianum specifically devoted to this.
According to Bernard Ullathorne, a 19th-century English Roman Catholic prelate, "the expressions - The Immaculate Conception - The Immaculate Preservation - The Immunity - and Exception from original sin, are all phrases which bear the same signification, and are used equally to express one and the same mystery."
Medieval dispute about the doctrine.
It seems to have been St Bernard of Clairvaux who, in the 12th century, explicitly raised the question of the Immaculate Conception. A feast of the Conception of the Blessed Virgin had already begun to be celebrated in some churches of the West. St Bernard blames the canons of the metropolitan church of Lyon for instituting such a festival without the permission of the Holy See. In doing so, he takes occasion to repudiate altogether the view that the conception of Mary was sinless. It is doubtful, however, whether he was using the term "conception" in the same sense in which it is used in the definition of Pope Pius IX. Bernard would seem to have been speaking of conception in the active sense of the mother's cooperation, for in his argument he says: "How can there be absence of sin where there is concupiscence ("libido")?" and stronger expressions follow, showing that he is speaking of the mother and not of the child.
Saint Thomas Aquinas refused to concede the Immaculate Conception, on the ground that, unless the Blessed Virgin had at one time or other been one of the sinful, she could not justly be said to have been redeemed by Christ.
Saint Bonaventure (d. 1274), second only to Saint Thomas in his influence on the Christian schools of his age, hesitated to accept it for a similar reason. He believed that Mary was completely free from sin, but that she was not given this grace at the instant of her conception.
The celebrated John Duns Scotus (d. 1308), a Friar Minor like Saint Bonaventure, argued, on the contrary, that from a rational point of view it was certainly as little derogatory to the merits of Christ to assert that Mary was by him preserved from all taint of sin, as to say that she first contracted it and then was delivered. Proposing a solution to the theological problem of reconciling the doctrine with that of universal redemption in Christ, he argued that Mary's immaculate conception did not remove her from redemption by Christ; rather it was the result of a more perfect redemption granted her because of her special role in salvation history.
The arguments of Scotus, combined with a better acquaintance with the language of the early Fathers, gradually prevailed in the schools of the Western Church. In 1387 the university of Paris strongly condemned the opposite view.
Scotus's arguments remained controversial, however, particularly among the Dominicans, who were willing enough to celebrate Mary's "sanctificatio" (being made free from sin) but, following the Dominican Thomas Aquinas' arguments, continued to insist that her sanctification could not have occurred until after her conception.
Popular opinion remained firmly behind the celebration of Mary's conception. In 1439, the Council of Basel, which is not reckoned an ecumenical council, stated that belief in the immaculate conception of Mary is in accord with the Catholic faith. By the end of the 15th century the belief was widely professed and taught in many theological faculties, but such was the influence of the Dominicans, and the weight of the arguments of Thomas Aquinas (who had been canonised in 1323 and declared "Doctor Angelicus" of the Church in 1567) that the Council of Trent (1545–63)—which might have been expected to affirm the doctrine—instead declined to take a position.
The papal bull defining the dogma, "Ineffabilis Deus", mentioned in particular the patrististic interpretation of as referring to a woman, Mary, who would be eternally at enmity with the evil serpent and completely triumphing over him. It said the Fathers saw foreshadowings of Mary's "wondrous abundance of divine gifts and original innocence" "in that ark of Noah, which was built by divine command and escaped entirely safe and sound from the common shipwreck of the whole world; in the ladder which Jacob saw reaching from the earth to heaven, by whose rungs the angels of God ascended and descended, and on whose top the Lord himself leaned; in that bush which Moses saw in the holy place burning on all sides, which was not consumed or injured in any way but grew green and blossomed beautifully; in that impregnable tower before the enemy, from which hung a thousand bucklers and all the armor of the strong; in that garden enclosed on all sides, which cannot be violated or corrupted by any deceitful plots; in that resplendent city of God, which has its foundations on the holy mountains; in that most august temple of God, which, radiant with divine splendours, is full of the glory of God; and in very many other biblical types of this kind."
The bull recounts that the Fathers interpreted the angel's address to Mary, "highly favoured one" or "full of grace", as indicating that "she was never subject to the curse and was, together with her Son, the only partaker of perpetual benediction"; they "frequently compare her to Eve while yet a virgin, while yet innocence, while yet incorrupt, while not yet deceived by the deadly snares of the most treacherous serpent".
Patronages.
A number of countries are considered to be under the patronage of the Immaculate Conception by pontifical decree.
These include Argentina, Brazil, Korea, Nicaragua, Paraguay, Philippines, Spain (old kingdoms and the present state), the United States and Uruguay.
By royal decree under the House of Braganza, it is the principal Patroness of Portugal.
Other churches.
For differing reasons, belief in Mary's immaculate conception in the Catholic doctrinal form is not part of the official doctrines of the Eastern Orthodox, Oriental Orthodox, Anglican and Protestant churches.
Eastern and Oriental Orthodox.
Contemporary Eastern Orthodox Christians often object to the dogmatic declaration of her immaculate conception as an "over-elaboration" of the faith and because they see it as too closely connected with a particular interpretation of the doctrine of ancestral sin. All the same, the historical and authentic tradition of Mariology in Byzantium took its historical point of departure from Sophronios, Damascene, and their imitators. The most famous Eastern Orthodox theologian to imply Mary's Immaculate Conception was St. Gregory Palamas. Though many passages from his works were long known to extol and attribute to Mary a Christlike holiness in her human nature, traditional objections to Palamas' disposition toward the Immaculate Conception typically rely on a poor understanding of his doctrine of "the purification of Mary" at the Annunciation. Not only did he explicitly cite St. Gregory Nazianzen for his understanding of Jesus' purification at His baptism and Mary's at the Annunciation, but Theophanes of Nicaea, Joseph Bryennius, and Gennadios Scholarios all explicitly placed Mary's Conception as the first moment of her all-immaculate participation in the divine energies to such a degree that she was always completely without spot and graced. In addition to Emperor Manuel II and Gennadius Scholarius, St. Mark of Ephesus also fervently defended Mary's title as "prepurified" against the Dominican, Manuel Calecas, who was perhaps promoting thomistic Mariology that denied Mary's all-holiness from the first moment of her existence.
In the tradition of Ethiopian Orthodoxy, the Kebra Nagast says:
Old Catholic.
While Old Catholics do not reject the Immaculate Conception of Mary, and some of their parishes venerate Mary as immaculately conceived and celebrate the feast of her Immaculate Conception, they do not accept its definition as a dogma, since they reject papal infallibility and with it the Pope's authority to define dogma.
Protestantism.
Martin Luther, who initiated the Protestant Reformation, said: "Mother Mary, like us, was born in sin of sinful parents, but the Holy Spirit covered her, sanctified and purified her so that this child was born of flesh and blood, but not with sinful flesh and blood. The Holy Spirit permitted the Virgin Mary to remain a true, natural human being of flesh and blood, just as we. However, he warded off sin from her flesh and blood so that she became the mother of a pure child, not poisoned by sin as we are. For in that moment when she conceived, she was a holy mother filled with the Holy Spirit and her fruit is a holy pure fruit, at once God and truly man, in one person." Some Lutherans, such as the members of the Anglo-Lutheran Catholic Church, support the doctrine.
Most Protestants reject the doctrine because they do not consider the development of dogmatic theology to be authoritative apart from biblical exegesis, and because the doctrine of the Immaculate Conception is not taught in the Bible. The formal pronouncement of Mary's Immaculate Conception by the Catholic Church in 1854 alienated some Protestant churches partly due to its implication that not all have sinned.
Anglicanism.
Belief in Mary's immaculate conception is not a doctrine within Anglicanism, although it is shared by many Anglo-Catholics. In the Church of England's "Common Worship" prayer book, 8 December is designated a Lesser Festival of the "Conception of the Blessed Virgin Mary" (without the adjective "immaculate").
The report "Mary: Faith and Hope in Christ", by the Anglican-Roman Catholic International Commission, concluded that the teaching about Mary in the two definitions of the Assumption and the Immaculate Conception can be said to be consonant with the teaching of the Scriptures and the ancient common traditions. But the report expressed concerns that the Roman Catholic dogmatic definitions of these concepts implies them to be "revealed by God", stating: "The question arises for Anglicans, however, as to whether these doctrines concerning Mary are revealed by God in a way which must be held by believers as a matter of faith."
Other than Anglo-Catholics, most Anglicans reject the doctrine that Mary was sinless and conceived without original sin, often citing that it is not within the Holy Scripture and is against the Redemptive role and purpose of Jesus Christ merited for all human beings.
Islam.
"Main article": Mary in Islam
Official Islamic teachings highly regard the Virgin Mary as both a sublime model of purity and piety. An entire Sura chapter of the Qur'an is dedicated to her nobility, holiness, and fiat obedience to God. Among Islamic circles and discussions, she is often given a prominent status being the supreme feminine model of sanctity and maternal virtue.
Some Western writers claim that the immaculate conception of Mary is a teaching of Islam. Thus, commenting in 1734 on the passage in the Qur'an, "I have called her Mary; and I commend her to thy protection, and also her issue, against Satan driven away with stones", George Sale stated: "It is not improbable that the pretended immaculate conception of the virgin Mary is intimated in this passage. For according to a tradition of Mohammed, every person that comes into the world, is touched at his birth by the devil, and therefore cries out, Mary and her son only excepted; between whom, and the evil spirit God placed a veil, so that his touch did not reach them. And for this reason they say, neither of them were guilty of any sin, like the rest of the children of Adam."
Others have rejected that the doctrine of Immaculate Conception exists in Islam, the Quranic account does not confirm the Immaculate Conception "exclusively" for Mary as in Islam every human child is born pure and immaculate, her sinless birth is thus independent of the Christian docrtrine of original sin as no such doctrine exists in Islam. Moreover, Hannah's prayer in the Quran for her child to remain protected from Satan (Shayṭān) was said "after" it had already been born, not before and expresses a natural concern any righteous parent would have. The Muslim tradition or "hadith", which states that the only children born without the "touch of Satan," were Mary and Jesus. should therefore not be taken in isolation from the Quran, and is to be interpreted within the specific context of exonerating Mary and her child from the charges that were made against them and is not a general statement. The specific mention of Mary and Jesus in this hadith may also be taken to represent a class of people, in keeping with the Arabic language and the Quranic verse "Satan surely thou shalt have no power over My servants, except such of the erring ones as choose to follow thee" (15:42)
Further claims were made that the Roman Catholic Church derives its doctrine from the Islamic teaching. In volume 5 of his "Decline and Fall of the Roman Empire", published in 1788, Edward Gibbon wrote: "The Latin Church has not disdained to borrow from the Koran the immaculate conception of his virgin mother." That he was speaking of her immaculate conception by her mother, not of her own virginal conception of Jesus, is shown by his footnote: "In the xiith century the immaculate conception was condemned by St. Bernard as a presumptuous novelty." In the aftermath of the definition of the dogma in 1854, this charge was repeated: "Strange as it may appear, that the doctrine which the church of Rome has promulgated, with so much pomp and ceremony, 'for the destruction of all heresies, and the confirmation of the faith of her adherents', should have its origin in the Mohametan Bible; yet the testimony of such authorities as Gibbon, and Sale, and Forster, and Gagnier, and Maracci, leave no doubt as to the marvellous fact."
Without making Islamic belief the origin of the doctrine defined in 1854, a similarity between the two has been noted also by Roman Catholic writers such as Thomas Patrick Hughes, William Bernard Ullathorne, Giancarlo Finazzo.
Prayers and hymns.
The Roman Missal and the Roman Rite Liturgy of the Hours naturally includes references to Mary's immaculate conception in the feast of the Immaculate Conception. An example is the antiphon that begins: "Tota pulchra es, Maria, et macula originalis non est in te" (You are all beautiful, Mary, and the original stain sin is not in you. Your clothing is white as snow, and your face is like the sun. You are all beautiful, Mary, and the original stain sin is not in you. You are the glory of Jerusalem, you are the joy of Israel, you give honour to our people. You are all beautiful, Mary.) On the basis of the original Gregorian chant music, polyphonic settings have been composed by Anton Bruckner, Pablo Casals, Maurice Duruflé, Grzegorz Gerwazy Gorczycki, :no:Ola Gjeilo, José Maurício Nunes Garcia, and Nikolaus Schapfl,
Other prayers honouring Mary's immaculate conception are in use outside the formal liturgy. The hymn "Immaculate Mary", addressed to Mary as the Immaculately Conceived One, is closely associated with Lourdes. The Immaculata prayer, composed by Saint Maximillian Kolbe, is a prayer of entrustment to Mary as the Immaculata. A novena of prayers, with a specific prayer for each of the nine days has been composed under the title of the Immaculate Conception Novena.
Artistic representations.
The 1476 extension of the feast of the Immaculate Conception to the entire Latin Church reduced the likelihood of controversy for the artist or patron in depicting an image, so that emblems depicting "The Immaculate Conception" began to appear.
Many artists in the 15th century faced the problem of how to depict an abstract idea such as the Immaculate Conception, and the problem was not fully solved for 150 years. The Italian Renaissance artist Piero di Cosimo was among those artists who tried new solutions, but none of these became generally adopted so that the subject matter would be immediately recognisable to the faithful.
The definitive iconography for the Immaculate Conception, drawing on the emblem tradition, seems to have been finally established by the master and then father-in-law of Diego Velázquez, the painter and theorist Francisco Pacheco. Pacheco's iconography influenced other Spanish artists such as Bartolomé Murillo, Diego Velázquez, and Francisco Zurbarán, who each produced a number of artistic masterpieces based on the use of these same symbols.
The popularity of this particular representation of "The Immaculate Conception" spread across the rest of Europe, and has since remained the best known artistic depiction of the concept: in a heavenly realm, moments after her creation, the spirit of Mary (in the form of a young woman) looks up in awe at (or bows her head to) God. The moon is under her feet and a halo of twelve stars surround her head, possibly a reference to "a woman clothed with the sun" from Revelation 12:1-2. Additional imagery may include clouds, a golden light, and cherubs. In some paintings the cherubim are holding lilies and roses, flowers often associated with Mary.

</doc>
<doc id="15260" url="https://en.wikipedia.org/wiki?curid=15260" title="Islands of the North Atlantic">
Islands of the North Atlantic

IONA (Islands of the North Atlantic) is an acronym suggested in 1980 by Sir John Biggs-Davison to refer to a loose linkage of England, Wales, Scotland, Ireland, the Isle of Man and Channel Islands, similar to the present day British-Irish Council. Its intended purpose was as a more politically acceptable alternative to British Isles, which is disliked by many people in Ireland.
It has been criticised on the grounds that it in fact excludes most of the islands in the North Atlantic, including Iceland, Greenland, the Faroe Islands, Newfoundland, Prince Edward Island, Cape Breton Island, and the Azores, and also that the only island referred to by the term that is actually in the North Atlantic Ocean is Ireland. Great Britain is in fact in between the Irish Sea and The North Sea. It has been used particularly in the context of the Northern Irish peace process during the negotiation of the Good Friday Agreement, as a neutral name for the proposed council.
One feature of this name is that IONA has the same spelling as the island of Iona which is off the coast of Scotland but with which Irish people have strong cultural associations. It is therefore a name with which people of both main islands might identify. Taoiseach Bertie Ahern noted the symbolism in a 2006 address in Edinburgh:Island of Iona is a powerful symbol of relationships between these islands, with its ethos of service not dominion. Iona also radiated out towards the Europe of the Dark Ages, not to mention Pagan England at Lindisfarne. The British-Irish Council is the expression of a relationship that at the origin of the Anglo-Irish process in 1981 was sometimes given the name Iona, islands of the North Atlantic, and sometimes Council of the Isles, with its evocation of the Lords of the Isles of the 14th and 15th centuries who spanned the North Channel. In the 17th century, Highland warriors and persecuted Presbyterian Ministers criss-crossed the North Channel.
In a Dáil Éireann debate, Proinsias De Rossa was less enthusiastic: The acronym IONA is a useful way of addressing the coming together of these two islands. However, the island of Iona is probably a green heaven in that nobody lives on it and therefore it cannot be polluted in any way.
Outside the Northern Ireland peace process the term IONA is used by the World Universities Debating Championship and in inter-varsity debating competitions throughout Britain and Ireland. In this context IONA is one of the regions which appoint a representative onto the committee of the World Universities Debating Council. Greenland, the Faroe Islands and Iceland would be included in the definition of IONA used in this context, while Newfoundland and Prince Edward Island would be in North America. However, none of these islands have yet participated in the World Universities Debating Championships. Otherwise, the term has achieved very little popular usage in any context.

</doc>
<doc id="15261" url="https://en.wikipedia.org/wiki?curid=15261" title="Intel DX4">
Intel DX4

The IntelDX4 is a clock-tripled i486 microprocessor with 16 kB L1 cache. Intel named it DX4 (rather than "DX3") as a consequence of litigation with AMD over trademarks. The product was officially named the IntelDX4, but OEMs continued using the i486 naming convention.
Intel produced IntelDX4s with two clock speed steppings: A 75 MHz version (3× 25 MHz multiplier), and a 100 MHz version (usually 3× 33.3 MHz, but sometimes also 2× 50 MHz). Both chips were released in March 1994. A version of the IntelDX4 featuring write-back cache was released in October 1994. The original write-through versions of the chip are marked with a laser embossed "&E", while the write-back enabled versions are marked "&EW". i486 OverDrive editions of the IntelDX4 had locked multipliers, and therefore can only run at 3× the external clock-speed. The 100 MHz model of the processor had an iCOMP rating of 435, while the 75 MHz processor had a rating of 319. The IntelDX4 was an OEM-only product, but the DX4 Overdrive could be purchased at a retail store.
The IntelDX4 microprocessor is mostly pin-compatible with the 80486, but requires a lower 3.3V supply. Normal 80486 and DX2 processors use a 5V supply; plugging a DX4 into an unmodified socket will destroy it. Motherboards lacking support for the 3.3V CPUs can sometimes make use of them using a voltage regulator (VRM) that fits between the socket and the CPU.

</doc>
<doc id="15264" url="https://en.wikipedia.org/wiki?curid=15264" title="Iapetus">
Iapetus

Iapetus may refer to:

</doc>
<doc id="15266" url="https://en.wikipedia.org/wiki?curid=15266" title="Interactive Fiction Competition">
Interactive Fiction Competition

The Interactive Fiction Competition (also known as IFComp) is one of several annual competitions for works of interactive fiction. It has been held since 1995. It is intended for fairly short games, as judges are only allowed to spend two hours playing a game before deciding how many points to award it. The competition has been described as the "Super Bowl" of interactive fiction.
A reviewer for "The A.V. Club" said of the 2008 competition, "Once again, the IF Competition delivers some of the best writing in games."
The 2008 competition was described as containing "some real standouts both in quality of puzzles and a willingness to stretch the definition of text adventures/interactive fiction." The competition differs from the XYZZY Awards, as authors must specifically submit games to the Interactive Fiction Competition, but all games released in the past year are eligible for the XYZZY Awards. Many games win awards in both competitions.
The competition is organized by "Stephen Granade". Although the first competition had separate sections for Inform and TADS games, subsequent competitions have not been divided into sections and are open to games produced by any method, provided that the software used to play the game is freely available. Anyone can judge the games, and anyone can donate a prize. Almost always, there are enough prizes donated that anyone who enters will get one. Entries are required to be released as freeware or public domain, reflecting the general non-profit ethos of the IF community.
In addition to the main competition, the entries take part in the Miss Congeniality contest, where the participating authors vote for three games (not including their own). This was started in 1998 to distribute that year's surplus prizes; this additional contest has remained unchanged since then, even without the original reason for its existence.
The following is a list of winners to date:

</doc>
<doc id="15267" url="https://en.wikipedia.org/wiki?curid=15267" title="Immunity">
Immunity

Immunity may refer to:

</doc>
<doc id="15268" url="https://en.wikipedia.org/wiki?curid=15268" title="Inquests in England and Wales">
Inquests in England and Wales

Inquests in England and Wales are held into sudden and unexplained deaths and also into the circumstances of discovery of a certain class of valuable artefacts known as "treasure trove". In England and Wales inquests are the responsibility of a coroner, who operates under the jurisdiction of the Coroners and Justice Act 2009.
Where an inquest is needed.
There is a general duty upon every person to report a death to the coroner if an inquest is likely to be required. However, this duty is largely unenforceable in practice and the duty falls on the responsible registrar. The registrar must report a death where:
The coroner must hold an inquest where the death was:
Where the cause of death is unknown, the coroner may order a post mortem examination in order to determine whether the death was violent. If the death is found to be non-violent, an inquest is unnecessary.
In 2004 in England and Wales, there were 514,000 deaths of which 225,500 were referred to the coroner. Of those, 115,800 resulted in post-mortem examinations and there were 28,300 inquests, 570 with a jury. In 2014 the Royal College of Pathologists claimed that up to 10,000 deaths a year recorded as being from natural causes should have been investigated by inquests. They were particularly concerned about people whose death occurred as a result of medical errors. "We believe a medical examiner would have been alerted to what was going on in Mid-Staffordshire long before this long list of avoidable deaths reached the total it did," said Archie Prentice, the pathologists' president.
Juries.
A coroner must summon a jury for an inquest if the death occurred in prison or in police custody, or in the execution of a police officer's duty, or if it falls under the Health and Safety at Work etc. Act 1974, or if it affects public health or safety. The coroner can also call a jury at his or her own discretion. This discretion has been heavily litigated in light of the Human Rights Act 1998, which means that juries are required now in a broader range of situations than expressly required by statute.
Scope of inquest.
The purpose of the inquest is to answer four questions:
Evidence must be solely for the purpose of answering these questions and no other evidence is admitted. It is not for the inquest to ascertain "how the deceased died" or "in what broad circumstances", but "how the deceased came by his death", a more limited question. Moreover, it is not the purpose of the inquest to determine, or appear to determine, criminal or civil liability, to apportion guilt or attribute blame. For example, where a prisoner hanged himself in a cell, he came by his death by hanging and it was not the role of the inquest to enquire into the broader circumstances such as the alleged neglect of the prison authorities that might have contributed to his state of mind or given him the opportunity. However, the inquest should set out as many of the facts as the public interest requires.
Under the terms of article 2 of the European Convention of Human Rights, governments are required to "establish a framework of laws, precautions, procedures and means of enforcement which will, to the greatest extent reasonably practicable, protect life." The European Court of Human Rights has interpreted this as mandating independent official investigation of any death where public servants may be implicated. Since the Human Rights Act 1998 came into force, in those cases alone, the inquest is now to consider the broader question "by what means and in what circumstances".
In disasters, such as the King's Cross fire, a single inquest may be held into several deaths. However, when several protesters were shot and killed by police in Mitchelstown in 1887, the findings of a common inquest were quashed because the killings had taken place at different times and in different places.
Procedure.
Inquests are governed by the Coroners Rules. The coroner gives notice to near relatives, those entitled to examine witnesses and those whose conduct is likely to be scrutinised. Inquests are held in public except where there are real issues of national security.
Individuals with an interest in the proceedings, such as relatives of the deceased, individuals appearing as witnesses, and organisations or individuals who may face some responsibility in the death of the individual, may be represented by lawyers at the discretion of the coroner. Witnesses may be compelled to testify subject to the privilege against self-incrimination.
Verdict.
The following verdicts are not mandatory but are strongly recommended:
In 2004, 37% of inquests recorded an outcome of death by accident / misadventure, 21% by natural causes, 13% suicide, 10% open verdicts, and 19% other outcomes.
If an open verdict is returned, the inquest can be reopened if new evidence is found and presented to the coroner.
Modernisation.
Owing in particular to the failures to notice the murder spree of Harold Shipman, the Coroners and Justice Act 2009 modernised the system with:

</doc>
<doc id="15270" url="https://en.wikipedia.org/wiki?curid=15270" title="Index">
Index

Index may refer to:

</doc>
<doc id="15271" url="https://en.wikipedia.org/wiki?curid=15271" title="Information retrieval">
Information retrieval

Information retrieval (IR) is the activity of obtaining information resources relevant to an information need from a collection of information resources. Searches can be based on metadata or on full-text (or other content-based) indexing.
Automated information retrieval systems are used to reduce what has been called "information overload". Many universities and public libraries use IR systems to provide access to books, journals and other documents. Web search engines are the most visible IR applications.
Overview.
An information retrieval process begins when a user enters a query into the system. Queries are formal statements of information needs, for example search strings in web search engines. In information retrieval a query does not uniquely identify a single object in the collection. Instead, several objects may match the query, perhaps with different degrees of relevancy.
An object is an entity that is represented by information in a content collection or database. User queries are matched against the database information. However, as opposed to classical SQL queries of a database, in information retrieval the results returned may or may not match the query, so results are typically ranked. This ranking of results is a key difference of information retrieval searching compared to database searching.
Depending on the application the data objects may be, for example, text documents, images, audio, mind maps or videos. Often the documents themselves are not kept or stored directly in the IR system, but are instead represented in the system by document surrogates or metadata.
Most IR systems compute a numeric score on how well each object in the database matches the query, and rank the objects according to this value. The top ranking objects are then shown to the user. The process may then be iterated if the user wishes to refine the query.
History.
The idea of using computers to search for relevant pieces of information was popularized in the article "As We May Think" by Vannevar Bush in 1945. It would appear that Bush was inspired by patents for a 'statistical machine' - filed by Emanuel Goldberg in the 1920s and '30s - that searched for documents stored on film. The first description of a computer searching for information was described by Holmstrom in 1948, detailing an early mention of the Univac computer. Automated information retrieval systems were introduced in the 1950s: one even featured in the 1957 romantic comedy, Desk Set. In the 1960s, the first large information retrieval research group was formed by Gerard Salton at Cornell. By the 1970s several different retrieval techniques had been shown to perform well on small text corpora such as the Cranfield collection (several thousand documents). Large-scale retrieval systems, such as the Lockheed Dialog system, came into use early in the 1970s.
In 1992, the US Department of Defense along with the National Institute of Standards and Technology (NIST), cosponsored the Text Retrieval Conference (TREC) as part of the TIPSTER text program. The aim of this was to look into the information retrieval community by supplying the infrastructure that was needed for evaluation of text retrieval methodologies on a very large text collection. This catalyzed research on methods that scale to huge corpora. The introduction of web search engines has boosted the need for very large scale retrieval systems even further.
Model types.
For effectively retrieving relevant documents by IR strategies, the documents are typically transformed into a suitable representation. Each retrieval strategy incorporates a specific model for its document representation purposes. The picture on the right illustrates the relationship of some common models. In the picture, the models are categorized according to two dimensions: the mathematical basis and the properties of the model.
Performance and correctness measures.
The evaluation of an information retrieval system is the process of assessing how well a system meets the information needs of its users. Traditional evaluation metrics, designed for Boolean retrieval or top-k retrieval, include precision and recall. Many more measures for evaluating the performance of information retrieval systems have also been proposed. In general, measurement considers a collection of documents to be searched and a search query. All common measures described here assume a ground truth notion of relevancy: every document is known to be either relevant or non-relevant to a particular query. In practice, queries may be ill-posed and there may be different shades of relevancy.
Virtually all modern evaluation metrics (e.g., mean average precision, discounted cumulative gain) are designed for ranked retrieval without any explicit rank cutoff, taking into account the relative order of the documents retrieved by the search engines and giving more weight to documents returned at higher ranks.
The mathematical symbols used in the formulas below mean:
Precision.
Precision is the fraction of the documents retrieved that are relevant to the user's information need.
In binary classification, precision is analogous to positive predictive value. Precision takes all retrieved documents into account. It can also be evaluated at a given cut-off rank, considering only the topmost results returned by the system. This measure is called "precision at n" or "P@n".
Note that the meaning and usage of "precision" in the field of information retrieval differs from the definition of accuracy and precision within other branches of science and statistics.
Recall.
Recall is the fraction of the documents that are relevant to the query that are successfully retrieved.
In binary classification, recall is often called sensitivity. So it can be looked at as "the probability that a relevant document is retrieved by the query".
It is trivial to achieve recall of 100% by returning all documents in response to any query. Therefore, recall alone is not enough but one needs to measure the number of non-relevant documents also, for example by computing the precision.
Fall-out.
The proportion of non-relevant documents that are retrieved, out of all non-relevant documents available:
In binary classification, fall-out is closely related to specificity and is equal to formula_9. It can be looked at as "the probability that a non-relevant document is retrieved by the query".
It is trivial to achieve fall-out of 0% by returning zero documents in response to any query.
F-score / F-measure.
The weighted harmonic mean of precision and recall, the traditional F-measure or balanced F-score is:
This is also known as the formula_11 measure, because recall and precision are evenly weighted.
The general formula for non-negative real formula_12 is:
Two other commonly used F measures are the formula_14 measure, which weights recall twice as much as precision, and the formula_15 measure, which weights precision twice as much as recall.
The F-measure was derived by van Rijsbergen (1979) so that formula_16 "measures the effectiveness of retrieval with respect to a user who attaches formula_12 times as much importance to recall as precision". It is based on van Rijsbergen's effectiveness measure formula_18. Their relationship is:
F-measure can be a better single metric when compared to precision and recall; both precision and recall give different information that can complement each other when combined. If one of them excels more than the other, F-measure will reflect it.
Average precision.
Precision and recall are single-value metrics based on the whole list of documents returned by the system. For systems that return a ranked sequence of documents, it is desirable to also consider the order in which the returned documents are presented. By computing a precision and recall at every position in the ranked sequence of documents, one can plot a precision-recall curve, plotting precision formula_21 as a function of recall formula_22. Average precision computes the average value of formula_21 over the interval from formula_24 to formula_25:
That is the area under the precision-recall curve.
This integral is in practice replaced with a finite sum over every position in the ranked sequence of documents:
where formula_28 is the rank in the sequence of retrieved documents, formula_29 is the number of retrieved documents, formula_30 is the precision at cut-off formula_28 in the list, and formula_32 is the change in recall from items formula_33 to formula_28.
This finite sum is equivalent to:
where formula_36 is an indicator function equaling 1 if the item at rank formula_28 is a relevant document, zero otherwise. Note that the average is over all relevant documents and the relevant documents not retrieved get a precision score of zero.
Some authors choose to interpolate the formula_21 function to reduce the impact of "wiggles" in the curve. For example, the PASCAL Visual Object Classes challenge (a benchmark for computer vision object detection) computes average precision by averaging the precision over a set of evenly spaced recall levels {0, 0.1, 0.2, ... 1.0}:
where formula_40 is an interpolated precision that takes the maximum precision over all recalls greater than formula_22:
An alternative is to derive an analytical formula_21 function by assuming a particular parametric distribution for the underlying decision values. For example, a "binormal precision-recall curve" can be obtained by assuming decision values in both classes to follow a Gaussian distribution.
Precision at K.
For modern (Web-scale) information retrieval, recall is no longer a meaningful metric, as many queries have thousands of relevant documents, and few users will be interested in reading all of them. Precision at k documents (P@k) is still a useful metric (e.g., P@10 or "Precision at 10" corresponds to the number of relevant results on the first search results page), but fails to take into account the positions of the relevant documents among the top k. Another shortcoming is that on a query with fewer relevant results than k, even a perfect system will have a score less than 1. It easier to score manually since only the top k results need to be examined to determine if they are relevant or not.
R-Precision.
R-precision requires knowing all documents that are relevant to a query. The number of relevant documents, formula_44, is used as the cutoff for calculation, and this varies from query to query. For example, if there are 15 documents relevant to "red" in a corpus (R=15), R-precision for "red" looks at the top 15 documents returned, counts the number that are relevant formula_22 turns that into a relevancy fraction: formula_46.
Precision is equal to recall at the R-th position.
Empirically, this measure is often highly correlated to mean average precision.
Mean average precision.
Mean average precision for a set of queries is the mean of the average precision scores for each query.
where "Q" is the number of queries.
Discounted cumulative gain.
DCG uses a graded relevance scale of documents from the result set to evaluate the usefulness, or gain, of a document based on its position in the result list. The premise of DCG is that highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result.
The DCG accumulated at a particular rank position formula_48 is defined as:
Since result set may vary in size among different queries or systems, to compare performances the normalised version of DCG uses an ideal DCG. To this end, it sorts documents of a result list by relevance, producing an ideal DCG at position p (formula_50), which normalizes the score:
The nDCG values for all queries can be averaged to obtain a measure of the average performance of a ranking algorithm. Note that in a perfect ranking algorithm, the formula_52 will be the same as the formula_50 producing an nDCG of 1.0. All nDCG calculations are then relative values on the interval 0.0 to 1.0 and so are cross-query comparable.
Visualization.
Visualizations of information retrieval performance include:

</doc>
<doc id="15272" url="https://en.wikipedia.org/wiki?curid=15272" title="List of Italian-language poets">
List of Italian-language poets

List of poets who wrote in Italian (or Italian dialects):

</doc>
<doc id="15274" url="https://en.wikipedia.org/wiki?curid=15274" title="International Criminal Tribunal for the former Yugoslavia">
International Criminal Tribunal for the former Yugoslavia

The International Tribunal for the Prosecution of Persons Responsible for Serious Violations of International Humanitarian Law Committed in the Territory of the Former Yugoslavia since 1991, more commonly referred to as the International Criminal Tribunal for the former Yugoslavia or ICTY, is a body of the United Nations established to prosecute serious crimes committed during the Yugoslav Wars, and to try their perpetrators. The tribunal is an ad hoc court which is located in The Hague, Netherlands.
The Court was established by Resolution 827 of the United Nations Security Council, which was passed on 25 May 1993. It has jurisdiction over four clusters of crimes committed on the territory of the former Yugoslavia since 1991: grave breaches of the Geneva Conventions, violations of the laws or customs of war, genocide, and crimes against humanity. The maximum sentence it can impose is life imprisonment. Various countries have signed agreements with the UN to carry out custodial sentences.
A total of 161 persons were indicted; the final indictments were issued in December 2004, the last of which were confirmed and unsealed in the spring of 2005. The final fugitive, Goran Hadžić, was arrested on 20 July 2011.
The ICTY is slated to close upon the completion of the remaining trials of first instance (, there are two—those of Hadžić and Ratko Mladić) and any appeal proceedings that had been initiated prior to 1 July 2013 (, there are two cases involving eight individuals). Any appeal proceedings initiated since 1 July 2013 have been under the jurisdiction of a successor body, the Mechanism for International Criminal Tribunals.
History.
Yugoslav Wars and Genocide.
The former state of Yugoslavia was divided into separate republics, leading to a war that caused severe civilian casualties on all sides. When discussing the events of the 1990s, historians and sociologists have used the phrases war crimes and genocide to describe the actions of military leaders, especially those of Croatia and Bosnia. The term genocide is often controversial – and is separate in meaning to mass killing – because it implies the killing and displacement of an entire ethnic, national, racial, religious or political group During the Yugoslav Wars the Srebrenica Massacre became the most infamous systematic killing of a religious group on European soil since the Holocaust. At least 7,475 Muslim men, women and children were killed by Serbian paramilitary troops.
Coined after World War Two by Rafael Lemkin and adopted by the United Nations General Assembly in 1948, the term has developed into one of the most crucial laws of international co-operation. In its brief history in international law, the understanding of genocide has helped law makers to create a reasonable method for prosecuting accused perpetrators of “the crimes of crimes” as stated by historian William Schabas which has led to the creation of Tribunals, such as the ICTY.
Creation.
United Nations Security Council Resolution 808 of 22 February 1993 decided that "an international tribunal shall be established for the prosecution of persons responsible for serious violations of international humanitarian law committed in the territory of the former Yugoslavia since 1991", and calling on the Secretary-General to "submit for consideration by the Council … a report on all aspects of this matter, including specific proposals and where appropriate options … taking into account suggestions put forward in this regard by Member States".
The Court was originally proposed by German Foreign Minister Klaus Kinkel. By 25 May 1993, the international community had tried to pressure the leaders of the former Yugoslavian republics diplomatically, militarily, politically, economically, and – with Resolution 827 – through juridical means. Resolution 827 of 25 May 1993 approved S/25704 report of the Secretary-General and adopted the Statute of the International Tribunal annexed to it, formally creating the ICTY. It would have jurisdiction over four clusters of crime committed on the territory of the former Yugoslavia since 1991: grave breaches of the Geneva Conventions, violations of the laws or customs of war, genocide, and crime against humanity. The maximum sentence it can impose is life imprisonment.
Implementation.
In 1993, the ICTY built its internal infrastructure. 17 states have signed an agreement with the ICTY to carry out custodial sentences.
1993-94: In the first year of its existence, the Tribunal laid the foundations for its existence as a judicial organ. The Tribunal established the legal framework for its operations by adopting the rules of procedure and evidence, as well as its rules of detention and directive for the assignment of defense counsel. Together these rules established a legal aid system for the Tribunal. As the ICTY is part of the United Nations and as it was the first "international" court for "criminal" justice, the development of a juridical infrastructure was considered quite a challenge. However after the first year the first ICTY judges had drafted and adopted all the rules for court proceedings.
1994-95: The ICTY established its offices within the Aegon Insurance Building in The Hague (which was, at the time, still partially in use by Aegon) and detention facilities in Scheveningen in The Hague (The Netherlands). The ICTY hired now many staff members. By July 1994 there were sufficient staff members in the office of the prosecutor to begin field investigations and by November 1994 the first indictment was presented and confirmed. In 1995, the entire staff numbered more than 200 persons and came from all over the world. Moreover, some governments assigned their legally trained people to the ICTY.
Operation.
In 1994 the first indictment was issued against the Bosnian-Serb concentration camp commander Dragan Nikolić. This was followed on 13 February 1995 by two indictments comprising 21 individuals which were issued against a group of 21 Bosnian-Serbs charged with committing atrocities against Muslim and Croat civilian prisoners. While the war in the former Yugoslavia was still raging, the ICTY prosecutors showed that an international court was viable. However, no accused was arrested.
The court confirmed 8 indictments against 46 individuals and issued arrest warrants. Bosnian Serb indictee Duško Tadić became the subject of the Tribunal's first trial. Tadić was arrested by German police in Munich in 1994 for his alleged actions in the Prijedor region in Bosnia-Herzegovina (especially his actions in the Omarska, Trnopolje and Keraterm detention camps). He made his first appearance before the ICTY Trial Chamber on 26 April 1995, and pleaded not guilty to all of the charges in the indictment.
1995–96: Between June 1995 and June 1996, 10 public indictments had been confirmed against a total of 33 individuals. Six of the newly indicted persons were transferred in the Tribunal's detention unit. In addition to Duško Tadic, by June 1996 the tribunal had Tihomir Blaškić, Dražen Erdemović, Zejnil Delalić, Zdravko Mucić, Esad Landžo and Hazim Delić in custody. Erdemović became the first person to enter a guilty plea before the tribunal's court. Between 1995 and 1996, the ICTY dealt with miscellaneous cases involving several detainees, which never reached the trial stage. Some of the accused had been arrested and others surrendered to the ICTY.
Accomplishments.
In 2004, the ICTY published a list of five accomplishments "in justice and law":
Planned closure.
The United Nations Security Council passed resolutions 1503 in August 2003 and 1534 in March 2004, which both called for the completion of all cases at both both the ICTY and its sister tribunal, the International Criminal Tribunal for Rwanda (ICTR) by 2010.
In December 2010, the Security Council adopted Resolution 1966, which established the Mechanism for International Criminal Tribunals (MICT), a body intended to gradually assume residual functions from both the ICTY and the ICTR as they wound down their mandate. Resolution 1966 called upon the Tribunal to finish its work by 31 December 2014 to prepare for its closure and transfer of its responsibilities.
In a "Completion Strategy Report" issued in May 2011, the ICTY indicated it aimed to complete all trials by the end of 2012 and all appeals by 2015, with the exception of Radovan Karadžić whose trial was expected to end in 2014 and Ratko Mladić and Goran Hadžić, who were at large at that time and were not arrested until later that year.
The MICT's ICTY branch began functioning on 1 July 2013. It was decided that the ICTY would conduct and complete all outstanding first instance trials, including those of Karadžić, Mladić and Hadžić. The ICTY will conduct and complete all appeal proceedings for which the notice of appeal against the judgement or sentence was filed before 1 July 2013. Any appeals for which notice is filed after that date will be handled by the MICT.
Organization.
The Tribunal employs around 900 staff. Its organisational components are Chambers, Registry and the Office of the Prosecutor (OTP).
Prosecutors.
The Prosecutor is responsible for investigating crimes, gathering evidence and prosecutions and is head of the Office of the Prosecutor (OTP). The Prosecutor is appointed by the UN Security Council upon nomination by the UN Secretary-General.
The current prosecutor is Serge Brammertz. Previous Prosecutors have been Ramón Escovar Salom of Venezuela (1993–1994), Richard Goldstone of South Africa (1994–1996), Louise Arbour of Canada (1996–1999), Eric Östberg of Sweden, and Carla Del Ponte of Switzerland (1999–2007), who until 2003, simultaneously served as the Prosecutor of the International Criminal Tribunal for Rwanda where she led the OTP since 1999. David Tolbert, the President of the International Center for Transitional Justice, was also appointed Deputy Prosecutor of the ICTY.
Chambers.
Chambers encompasses the judges and their aides. The Tribunal operates three Trial Chambers and one Appeals Chamber. The President of the Tribunal is also the presiding Judge of the Appeals Chamber.
Judges.
There are ten permanent judges and one "ad litem" judge who serve on the Tribunal.
UN member and observer states can each submit up to two nominees of different nationalities to the UN Secretary-General. The UN Secretary-General submits this list to the UN Security Council which selects from 28 to 42 nominees and submits these nominees to the UN General Assembly. The UN General Assembly then elects 14 judges from that list. Judges serve for 4 years and are eligible for re-election. The UN Secretary-General appoints replacements in case of vacancy for the remainder of the term of office concerned.
On 21 October 2015, Judge Carmel Agius of Malta was elected President of the ICTY and Liu Daqun of China was elected Vice-President; they will assume their new positions on 17 November 2015. His predecessors were Antonio Cassese of Italy (1993–97), Gabrielle Kirk McDonald of the United States (1997–99), Claude Jorda of France (1999–2002), Meron (again; 2002–05), Fausto Pocar of Italy (2005–08), Patrick Robinson of Jamaica (2008–11), and Theodor Meron of the United States (2011–15).
Registry.
The Registry is responsible for handling the administration of the Tribunal; activities include keeping court records, translating court documents, transporting and accommodating those who appear to testify, operating the Public Information Section, and such general duties as payroll administration, personnel management and procurement. It is also responsible for the Detention Unit for indictees being held during their trial and the Legal Aid program for indictees who cannot pay for their own defence. It is headed by the Registrar, currently John Hocking of Australia (since May 2009). His predecessors were Hans Holthuis of the Netherlands (2001–2009), Dorothée de Sampayo Garrido-Nijgh of the Netherlands (1995–2000), and Theo van Boven of the Netherlands (February 1994 to December 1994).
Detention facilities.
Those defendants on trial and those who were denied a provisional release are detained at the United Nations Detention Unit on the premises of the Penitentiary Institution Haaglanden, location Scheveningen, located some 3 km by road from the courthouse. The indicted are housed in private cells which have a toilet, shower, radio, satellite TV, personal computer (without Internet access) and other luxuries. They are allowed to phone family and friends daily and can have conjugal visits. There is also a library, a gym and various rooms used for religious observances. The inmates are allowed to cook for themselves. All of the inmates mix freely and are not segregated on the basis of nationality. As the cells are more akin to a university residence instead of a jail, some have derisively referred to the ICT as the “Hague Hilton”. The reason for this luxury relative to other prisons is that the first president of the court wanted to emphasise that the indictees are innocent until proven guilty.
Indictees.
The very first hearing at the ICTY was referral request in the Tadić case on 8 November 1994.
The Tribunal indicted 161 individuals between 1997 and 2004; , it has completed proceedings with regard to 151 of them:
Proceedings for the remaining 10 indictees are still ongoing at the ICTY — 2 are in the trial phase and 8 are before the Appeals Chamber.
The indictees ranged from common soldiers to generals and police commanders all the way to prime ministers. Slobodan Milošević was the first sitting head of state indicted for war crimes. Other "high level" indictees included Milan Babić, former President of the Republika Srpska Krajina; Ramush Haradinaj, former Prime Minister of Kosovo; Radovan Karadžić, former President of the Republika Srpska; Ratko Mladić, former Commander of the Bosnian Serb Army and Ante Gotovina, former General of the Croatian Army.
Croat Serb General and former President of the Republic of Serbian Krajina Goran Hadžić was the last fugitive wanted by the Tribunal to be arrested on 20 July 2011.
An additional 23 individuals have been the subject of contempt proceedings.
Active cases.
, the trials of Goran Hadžić and Ratko Mladić are incomplete; the Mladić case is in the process of judgement by the courts, while the Hadžić case is in an adjournment for reasons related to the accused's health.
Two cases encompassing eight individuals are at the appeals stage.
Criticism.
Skeptics argued that an international court could not function while the war in the former Yugoslavia was still going on. This would be a huge undertaking for any court, but for the ICTY it would be an even greater one, as the new tribunal still needed judges, a prosecutor, a registrar, investigative and support staff, an extensive interpretation and translation system, a legal aid structure, premises, equipment, courtrooms, detention facilities, guards and all the related funding.
Criticisms of the court include:
Response to criticism.
Supporters of the work of the ICTY responded to critics in various publications. In a response to David Harland's "Selective Justice", Jelena Subotić, an assistant professor of political science at Georgia State University and author of "Hijacked Justice: Dealing with the Past in the Balkans", responded that the critics of the Tribunal miss the point, "which is not to deliver justice for past wrongs equally for 'all sides', fostering reconciliation, but to carefully measure each case on its own merits ... We should judge the work of the tribunal by its legal expertise, not by the political outcomes we desire."
Marko Hoare claims the accusations of the tribunal's "selective justice" stem from Serbian nationalist propaganda. He wrote: "This is, of course, the claim that hardline Serb nationalists and supporters of Slobodan Milosevic have been making for about the last two decades. Instead of carrying out any research into the actual record of the ICTY in order to support his thesis, Harland simply repeats a string of cliches of the kind that frequently appear in anti-Hague diatribes by Serb nationalists."

</doc>
<doc id="15275" url="https://en.wikipedia.org/wiki?curid=15275" title="ISO 216">
ISO 216

ISO 216 specifies international standard (ISO) paper sizes used in most countries in the world today, although not in Canada or the United States. The standard defines the "A" and "B" series of paper sizes, including A4, the most commonly available size. Two supplementary standards, ISO 217 and ISO 269, define related paper sizes; the ISO 269 "C" series is commonly listed alongside the A and B sizes.
All ISO 216, ISO 217 and ISO 269 paper sizes (except DL) have the same aspect ratio, 1:, at least to within the rounding to whole numbers of millimetres. This ratio has the unique property that when cut or folded in half widthwise, the halves also have the same aspect ratio. Each ISO paper size is one half of the area of the next larger size.
History.
The advantages of basing a paper size upon an aspect ratio of were already noted in 1786 by the German scientist Georg Christoph Lichtenberg, in a letter to Johann Beckmann. The formats that became A2, A3, B3, B4 and B5 were developed in France, and published in 1798 during the French Revolution.
Early in the twentieth century, Dr Walter Porstmann turned Lichtenberg's idea into a proper system of different paper sizes. Porstmann's system was introduced as a DIN standard (DIN 476) in Germany in 1922, replacing a vast variety of other paper formats. Even today the paper sizes are called "DIN A"x"" in everyday use in Germany, Austria, Spain and Portugal.
The main advantage of this system is its scaling: if a sheet with an aspect ratio of is divided into two equal halves parallel to its shortest sides, then the halves will again have an aspect ratio of . Folded brochures of any size can be made by using sheets of the next larger size, e.g. A4 sheets are folded to make A5 brochures. The system allows scaling without compromising the aspect ratio from one size to another – as provided by office photocopiers, e.g. enlarging A4 to A3 or reducing A3 to A4. Similarly, two sheets of A4 can be scaled down to fit exactly one A4 sheet without any cutoff or margins.
The weight of each sheet is also easy to calculate given the basis weight in grams per square metre (g/m2 or "gsm"). Since an A0 sheet has an area of 1 m2, its weight in grams is the same as its basis weight in g/m2. A standard A4 sheet made from 80 g/m2 paper weighs 5 g, as it is (four halvings, ignoring roundings to exact mm) of an A0 page. Thus the weight, and the associated postage rate, can be easily approximated by counting the number of sheets used.
ISO 216 and its related standards were first published between 1975 and 1995:
A series.
Paper in the A series format has a 1: ≈ 1.414 aspect ratio, although this is rounded to the nearest millimetre. A0 is defined so that it has an area of 1 square metre, prior to the rounding. Successive paper sizes in the series (A1, A2, A3, etc.) are defined by halving the preceding paper size, cutting parallel to its shorter side so that the long side of A("n" + 1) is the same length as the short side of A"n" prior to rounding.
The most frequently used of this series is the size A4 which is and square metres in area. For comparison, the letter paper size commonly used in North America () is approximately 6 mm (0.24 in) wider and 18 mm (0.71 in) shorter than A4.
The geometric rationale behind the square root of 2 is to maintain the aspect ratio of each subsequent rectangle after cutting or folding an A series sheet in half, perpendicular to the larger side. Given a rectangle with a longer side, "x", and a shorter side, "y", ensuring that its aspect ratio, , will be the same as that of a rectangle half its size, , means that  = , which reduces to  = ; in other words, an aspect ratio of 1:.
The formula that gives the larger border of the paper size A"n" in metres and without rounding off is the geometric sequence: formula_1. The paper size A"n" thus has the dimension "a" × "a" and area (prior to rounding off) 2 m.
The exact millimetre measurement of the long side of A"n" is given by formula_2, in which the modified brackets represent the floor function.
B series.
The B series is defined in the standard as follows: "A subsidiary series of sizes is obtained by placing the geometrical means between adjacent sizes of the A series in sequence." The use of the "geometric means", means that each step in size: B0, A0, B1, A1, B2 … is smaller than the previous by an equal scaling. As with the A series, the lengths of the B series have the ratio 1:, and folding one in half gives the next in the series. The shorter side of B0 is exactly 1 metre.
There is also an incompatible Japanese B series which the JIS defines to have 1.5 times the area of the corresponding JIS A series (which is identical to the ISO A series). Thus, the lengths of JIS B series paper are  ≈ 1.22 times those of A-series paper. By comparison, the lengths of ISO B series paper are  ≈ 1.19 times those of A-series paper.
For the ISO B series, the exact millimetre measurement of the long side of B"n" is given by formula_3.
C series.
The C series formats are geometric means between the B series and A series formats with the same number (e.g., C2 is the geometric mean between B2 and A2). The width to height ratio is as in the A and B series. The C series formats are used mainly for envelopes. An A4 page will fit into a C4 envelope. C series envelopes follow the same ratio principle as the A series pages. For example, if an A4 page is folded in half so that it is A5 in size, it will fit into a C5 envelope (which will be the same size as a C4 envelope folded in half). The lengths of ISO C series paper are therefore times those of A-series paper – i.e., about 9% larger.
A, B, and C paper fit together as part of a geometric progression, with ratio of successive side lengths of , though there is no size half-way between B"n" and A("n" − 1): A4, C4, B4, "D4", A3, …; there is such a D-series in the Swedish extensions to the system.
The exact millimetre measurement of the long side of C"n" is given by formula_4.
Tolerances.
The tolerances specified in the standard are:
Application.
The ISO 216 formats are organized around the ratio 1:; two sheets next to each other together have the same ratio, sideways. In scaled photocopying, for example, two A4 sheets reduced to A5 size fit exactly onto one A4 sheet, and an A4 sheet in magnified size onto an A3 sheet; in each case, there is neither waste nor want.
The principal countries not generally using the ISO paper sizes are the United States and Canada, which use the Letter, Legal and Executive system. Although they have also officially adopted the ISO 216 paper format, Mexico, Panama, Venezuela, Colombia, the Philippines, and Chile also use mostly U.S. paper sizes.
Rectangular sheets of paper with the ratio 1: are popular in paper folding, such as origami, where they are sometimes called "A4 rectangles" or "silver rectangles". In other contexts, the term "silver rectangle" can also refer to a rectangle in the proportion 1:(1 + ), known as the silver ratio.

</doc>
<doc id="15276" url="https://en.wikipedia.org/wiki?curid=15276" title="ISO 3864">
ISO 3864

ISO 3864 specifies international standards for safety symbols. These labels are graphical, to overcome language barriers.
ANSI standard ANSI Z535.6-2006 defines an optional accompanying text in one or more languages.

</doc>
<doc id="15281" url="https://en.wikipedia.org/wiki?curid=15281" title="Isaac Abendana">
Isaac Abendana

Isaac Abendana (ca. 1640 – 1699) was the younger brother of Jacob Abendana, and became "hakam" of the Spanish Portuguese Synagogue in London after his brother died. 
Abendana moved to England before his brother, in 1662, and taught Hebrew at Cambridge University. He completed an unpublished Latin translation of the "Mishnah" for the university in 1671. 
While he was at Cambridge, Abendana sold Hebrew books to the Bodleian Library of Oxford, and in 1689 he took a teaching position in Magdalen College. In Oxford, he wrote a series of Jewish almanacs for Christians, which he later collected and compiled as the "Discourses on the Ecclesiastical and Civil Polity of the Jews" (1706). Like his brother, he maintained an extensive correspondence with leading Christian scholars of his time, most notably with the philosopher Ralph Cudworth, master of Christ's College, Cambridge. 

</doc>
