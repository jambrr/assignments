<doc id="14189" url="https://en.wikipedia.org/wiki?curid=14189" title="Haryana">
Haryana

Haryana is one of the 29 states in India, situated in North India. It was carved out of the former state of East Punjab on 1November 1966 on a linguistic basis. It stands 21st in terms of its area, which is spread about . census of India, the state is eighteenth largest by population with 25,353,081 inhabitants.
Haryana is one of the wealthier states of India and had the second highest per capita income in the country at in the year 2012–13 (See List of Indian states by GDP) and in the year 2013–14, including the largest number of rural crorepatis in India. Haryana is also one of the most economically developed regions in South Asia, and its agricultural and manufacturing industries have experienced sustained growth since the 1970s. Since 2000, the state has emerged as the largest recipient of investment per capita in India.
It is bordered by Punjab and Himachal Pradesh to the north, and by Rajasthan to the west and south. The river Yamuna defines its eastern border with Uttar Pradesh. Haryana surrounds the country's capital Delhi on three sides, forming the northern, western and southern borders of Delhi. Consequently, a large area of south Haryana is included in the National Capital Region for purposes of planning for development.
Etymology.
The name Haryana is found in the works of the 12th-century AD Apabhramsha writer Vibudh Shridhar (VS 1189–1230).
The name "Haryana" may be derived from the Sanskrit words "Hari" (the Hindu god Vishnu) and "ayana" (home), meaning "the Abode of God". However, scholars such as Muni Lal, Murli Chand Sharma, HA Phadke and Sukhdev Singh Chib believe that the name comes from a compound of the words "Hari" (Sanskrit "Harit", "green") and "Aranya" (forest). Budh Prakash opines that the name may be a corruption of "Abhirayana", as its ancient inhabitants were called "Ahirs" and ruled Haryana under the Moguls.
History.
Pre-history.
Rakhigarhi village in the Hisar district is home to the largest and one of the oldest ancient Indus Valley Civilization sites, dated as over 5,000 years old. Evidence of paved roads, a drainage system, a large-scale rainwater collection storage system, terracotta brick and statue production, and skilled metal working (in both bronze and precious metals) have been uncovered. According to archeologists, Rakhigarhi may be the origin of Harappan civilisation, which arose in the Ghaggar basin in Haryana and gradually and slowly moved to the Indus valley. Other notable Indus Valley Civilization sites in the state are Mitathal and Banawali.
Medieval.
Ancient idols of Jain Tirthankara (made of bronze and stone) were found in archaeological expeditions in Badli, Bhiwani (Ranila, Charkhi Dadri, Badhara village), Dadri, Gurgaon (Ferozpur Jhirka), Hansi, Hisar (Agroha), Kasan, Nahad, Narnaul, Pehowa, Rewari, Rohad, Rohtak (Asthal-Abohar) and Sonepat in Haryana.
The area that is now Haryana has been ruled by major empires of India. Panipat is known for three seminal battles in the history of India. In the First Battle of Panipat (1526), Babur defeated the Lodis, leading to the establishment of Mughal Empire in India. In the Second Battle of Panipat (1556), his grandson Akbar defeated the Hindu king Hemu. In the Third Battle of Panipat (1761), the Afghan king Ahmad Shah Abdali defeated the Marathas.
Formation.
Haryana state was formed on 1November 1966. The Indian government set up the Shah Commission under the chairmanship of Justice JC Shah on 23 April 1966 to divide the existing Punjab, India and determine the boundaries of the new state of Haryana after consideration of the languages spoken by the people. The commission delivered its report on 31May 1966 whereby the then-districts of Hisar, Mahendragarh, Gurgaon, Rohtak and Karnal were to be a part of the new state of Haryana. Further, the tehsils of Jind and Narwana in the Sangrur district—along with Naraingarh, Ambala and Jagadhri—were to be included.
The commission recommended that the tehsil of Kharad, which includes Chandigarh, the state capital of Punjab, should be a part of Haryana. However, only a small portion of Kharad was given to Haryana. The city of Chandigarh was made a union territory, serving as the capital of both Punjab and Haryana.
Bhagwat Dayal Sharma became first Chief Minister of Haryana.
Geography.
Haryana is a landlocked state in northern India. It is between 27°39' to 30°35' N latitude and between 74°28' and 77°36' E longitude. The total geographical area of the state is 4.42 m ha, which is 1.4% of the geographical area of the country. The altitude of Haryana varies between 700 and 3600 ft (200 metres to 1200 metres) above sea level. As per India State of Forest Report, FSI, 2013, the Forest Cover in the state is 1586 km2 which is 3.59% of the state's geographical area and the Tree Cover in the state is 1282 km2 which is 2.90% of the geographical area. Thus the Forest and Tree Cover of the Haryana state is 6.49% of its geographical area.
Haryana has four main geographical features.
Rivers.
The Yamuna flows along the state's eastern boundary while the ancient Sarasvati River is said to have flowed from Yamuna Nagar, but has now disappeared.
Haryana's main seasonal river, the Ghaggar rises in the outer Himalayas, between the Yamuna and the Satluj and enters the state near Pinjore in the Panchkula district. Passing through Ambala and Sirsa, it reaches Bikaner in Rajasthan and runs for before disappearing into the deserts of Rajasthan. Important tributaries include the Chautang and Tangri.
The seasonal Markanda River is a stream, which in ancient times was known as the Aruna. It originates from the lower Shivalik Hills and enters Haryana west of Ambala. During monsoons, this stream swells into a raging torrent notorious for its devastating power. The surplus water is carried on to the Sanisa Lake where the Markanda joins the Saraswati and later the Ghaggar.
Three other rivulets in and around the Mewat hills, the Indori, Dohan and Kasavati all flow from East to West and once were tributaries of the Drishadwati/Saraswati rivers.
Climate.
Haryana is extremely hot in summer at around and mild in winter. The hottest months are May and June and the coldest December and January. The climate is arid to semi-arid with average rainfall of 354.5 mm. Around 29% of rainfall is received during the months from July to September, and the remaining rainfall is received during the period from December to February.
Flora and fauna.
Thorny, dry, deciduous forest and thorny shrubs can be found all over the state. During the monsoon, a carpet of grass covers the hills. Mulberry, eucalyptus, pine, kikar, shisham and babul are some of the trees found here. The species of fauna found in the state of Haryana include black buck, nilgai, panther, fox, mongoose, jackal and wild dog. More than 450 species of birds are found here.
Protected wildlife areas
Haryana has two national parks, eight wildlife sanctuaries, two wildlife conservation areas, four animal and bird breeding centers, one deer park and three zoos, all of which are managed by the Haryana Forest Department of the Government of Haryana.
Administrative divisions.
The state is divided into four divisions for administrative purposes: Ambala, Rohtak, Gurgaon and Hisar. Within these there are 21 districts, 62 sub-divisions, 83 tehsils, 47 sub-tehsils and 126 blocks. Haryana has a total of 154 cities and towns and 6,841 villages.
Governance.
On 28 December 2015, the Panchkula district of Haryana was awarded for being the top-performing district in the state under the Digital India campaign. The Common Service Centres (CSCs) have been upgraded in all districts and the number of e-services has now reached 105, which includes application of new water connection, sewer connection, electricity bill collection, ration card member registration, result of HBSE, admit cards for board examinations, online admission form for government colleges, long route booking of buses, admission forms for Kurukshetra University and HUDA plots status inquiry. Haryana has became the first state to implement Aadhaar-enabled birth registration in all the districts.
Law and order.
Haryana Police force is the law enforcement agency of Haryana. It has a modern cybercrime investigation cell, in Gurgaon's Sector 51.
The Judicial authority is the Punjab and Haryana High Court, which became the first in the country to have a fully Wi-Fi complex. It also inched towards becoming a paperless court with the introduction of an e-filing facility.
Economy.
The economy of Haryana relies on manufacturing, business process outsourcing, agriculture and retail.
Agriculture.
There are two agroclimatic zones in Haryana. The northwestern part is suitable for rice, wheat, vegetables and temperate fruits, and the southwestern part is suitable for high-quality agricultural produce, tropical fruits, exotic vegetables and herbal and medicinal plants. The cultivable area is 3.7 m ha, which is 84% of the geographical area of the state. 3.64 m ha, i.e. 98% of cultivable area, is under cultivation. The gross cropped area of the state is 6.51 m ha and net cropped area is 3.64 m ha with a cropping intensity of 184.91%.
Transport.
The Haryana and Delhi governments have constructed the international standard Delhi Faridabad Skyway, the first of its kind in North India, to connect Delhi and Faridabad. The Delhi-Agra Expressway (NH-2) that passes through Faridabad is being widened to six lanes from current four lanes. It will further boost Faridabad's connectivity with Delhi.
Delhi Metro Rail Corporation connects Faridabad and Gurgaon with Delhi. Faridabad has the longest metro network in the NCR Region consisting of 9 stations and track length being 14 km.
Haryana has a total road length of . There are 29 national highways with a total length of and many state highways, which have a total length of . The most remote parts of the state are linked with metaled roads. Its modern bus fleet of 3,864 buses covers a distance of 1.15 million km per day, and it was the first state in the country to introduce luxury video coaches.
The Grand Trunk Road, commonly abbreviated to GT Road, is one of South Asia's oldest and longest major roads. It passes through the districts of Sonipat, Panipat, Karnal, Kurukshetra and Ambala in north Haryana where it enters Delhi and subsequently the industrial town of Faridabad on its way. The state government proposes to construct Express highways and freeways for speedier vehicular traffic. The Kundli-Manesar-Palwal Expressway(KMP) will provide a high-speed link to northern Haryana with its southern districts such as Sonepat, Gurgaon, Jhajjar and Faridabad. The work on the project has already started and is scheduled to be completed by July 2013.
Haryana State has always given high priority to the expansion of electricity infrastructure, as it is one of the most important inputs for the development of the state. Haryana was the first state in the country to achieve 100% rural electrification in 1970 as well as the first in the country to link all villages with all-weather roads and provide safe drinking water facilities throughout the state.
Demographics.
According to the 2011 census, Hindus (87.45%) constitute the majority of the state's population with Sikhs (4.91%), Muslims (7.03%) (mainly Meos) being the largest minorities.
Jats form the largest caste in Haryana with approximately 25% population. Out of 80 castes, 63 castes/communities have been notified either as a Scheduled Caste or Backward Class in Haryana. The reservation limit in state is 47% as of now.
Muslims are mainly found in the Mewat and Yamuna Nagar districts, while Sikhs live mostly in the districts adjoining Punjab, Hisar, Sirsa, Jind, Fatehabad, Kaithal, Kurukshetra, Ambala, Narnaul and Panchkula. Haryana has the second largest Sikh population in India after the state of Punjab. In May 2014, the Haryana Government published the "Haryana Anand Marriages Registration Rules, 2014", allowing Sikhs to register their marriages under these rules.
Agriculture and related industries have been the backbone of the local economy. Since 2001, the state has witnessed a massive
influx of immigrants from across the nation, primarily from Bihar, Bengal, Uttrakhand, Rajasthan, Uttar Pradesh and Nepal. Scheduled Castes form 19.3% of the population.
Haryana's sex ratio crossed the mark of 900 and reached 903 in December 2015.
Education.
Literacy rate in Haryana has seen an upward trend and is 76.64 percent as per 2011 population census. Male literacy stands at 85.38 percent, while female literacy is at 66.67 percent. In 2001, the literacy rate in Haryana stood at 67.91 percent of which male and female were 78.49 percent and 55.73 percent literate respectively. , Gurgaon city had the highest literacy rate in Haryana at 86.30% followed by Panchkula at 81.9 per cent and Ambala at 81.7 percent. In terms of districts, Rewari had the highest literacy rate in Haryana at 74%, higher than the national average of 59.5%: male literacy was 79%, and female 67%.
Hisar has three universities: Chaudhary Charan Singh Haryana Agricultural University - Asia's largest agricultural university, Guru Jambheshwar University of Science and Technology, Lala Lajpat Rai University of Veterinary & Animal Sciences); several national agricultural and veterinary research centres (National Research Centre on Equines), Central Sheep Breeding Farm, National Institute on Pig Breeding and Research, Northern Region Farm Machinery Training and Testing Institute and Central Institute for Research on Buffaloes (CIRB); and more than 20 colleges including Maharaja Agrasen Medical College, Agroha.
In 2001–02, there were 11,013 primary schools, 1,918 middle schools, 3,023 high schools and 1,301 senior secondary schools in the state. Haryana Board of School Education, established in September 1969 and shifted to Bhiwani in 1981, conducts public examinations at middle, matriculation, and senior secondary levels twice a year. Over seven lac candidates attend annual examinations in February and March; 150,000 attend supplementary examinations each November. The Board also conducts examinations for Haryana Open School at senior and senior secondary levels twice a year. The Haryana government provides free education to women up to the bachelor's degree level.
Haryana boasts of some of the finest colleges in research, technology and management in the country such as National Brain Research Centre, NIT Kurukshetra, Management Development Institute and IIM Rohtak.
The National Brain Research Centre is the only institute in India dedicated to neuroscience research and education. Scientists and students of NBRC come from diverse academic backgrounds, including biology, computing, mathematics, physics, engineering and medical sciences, and use multidisciplinary approaches to understand the brain. In the foothills of the Aravali range in Manesar, Haryana, NBRC is an autonomous institute funded by the Department of Biotechnology, Government of India, and is a Deemed University.
Union Minister Ravi Shankar Prasad announced on 27 February 2016 that National Institute of Electronics and Information Technology (NIELIT) would be set up in Kurukshetra to provide computer training to youth and a Software Technology Park of India (STPI) would be set up in Panchkula’s existing HSIIDC IT Park in Sector 23.
Healthcare.
The Total Fertility Rate of Haryana is 2.3. The Infant Mortality Rate is 41 (SRS 2013) and Maternal Mortality Ratio is 146 (SRS 2010–2012).
Languages.
Haryanvi has traditionally been the dominant mother tongue in Haryana, with Standard Hindi being spoken as a second language. Haryanvi has no official status, as it is seen as a dialect of Hindi; thus Hindi is the official language and the most commonly spoken language in the state. Since it was the Punjabi Suba movement that had led to formation of Haryana, Bansi Lal thought, "Let any language other than Punjabi be the second language of the state". Hence, Tamil became the second state language even though there might not have been even a single Tamil native family in the state. Since 1947, Punjabi has been spoken by many people in Haryana especially by those Hindus and Sikhs who migrated from West Punjab, following the Partition of India. As such, Punjabi edged out Tamil as the secondary official language of the state, other than Hindi and English, in 2010. Punjabi speakers account for 11% of the state's population. Haryana has second largest Punjabi speaking population in India after the state of Punjab.
Communication and media.
Haryana has a statewide network of telecommunication facilities. Haryana Government has its own statewide area network by which all government offices of 21 districts and 127 blocks across the state are connected with each other thus making it the first SWAN of the country. Bharat Sanchar Nigam Limited and most of the leading private sector players (such as Reliance Infocom, Tata Teleservices, Bharti Telecom, Idea Vodafone Essar, Aircel, Uninor and Videocon) have operations in the state. Important areas around Delhi are an integral part of the local Delhi Mobile Telecommunication System. This network system would easily cover major towns like Faridabad and Gurgaon.
Electronic media channels include, MTV, 9XM, Star Group, SET Max, News Time, NDTV 24x7 and Zee Group. The radio stations include All India Radio and other FM stations.
The major newspapers of Haryana include "Dainik Bhaskar", "Punjab Kesari", "Jag Bani", "Dainik Jagran", "The Tribune", "Amar Ujala", "Hindustan Times", "Dainik Tribune", "The Times of India" and "Hari-Bhumi".
Utilities.
Haryana Power Generation Corporation Ltd (HPGCL) is setting up a solar power plant at the site of a defunct thermal power plant in Faridabad. The power generator plans to set up the plant over 151.78 acres near Bata Chowk in the district that generated coal-based energy in the past.
Sports.
Haryana has produced some of the best Indian players in a variety of sports. In the 2010 Commonwealth Games at Delhi, 22 out of 38 gold medals that India won came from Haryana. During the 33rd National Games held in Assam in 2007, Haryana stood first in the nation with a medal tally of 80, including 30 gold, 22 silver and 28 bronze medals.
Cricket is very popular in Haryana. Indian World-Cup-winning captain Kapil Dev is from Haryana. Other notable players from Haryana cricket team include Chetan Sharma, Ajay Jadeja, Amit Mishra and Mohit Sharmaand virender sehwag. Nahar Singh Stadium was built in Faridabad in the year 1981 for international cricket. This ground has the capacity to hold around 25,000 people as spectators. Tejli Sports Complex is an Ultra-Modern sports complex in Yamuna Nagar. Tau Devi Lal Stadium in Panchkula is a multi-sport complex.
Chief Minister of Haryana Manohar Lal Khattar announced the "Haryana Sports and Physical Fitness Policy", a policy to support 26 Olympic sports, on 12 January 2015 with the words "We will develop Haryana as the sports hub of the country."
Tourism.
There are 21 tourism hubs created by Haryana Tourism Corporation Limited, which are located in Ambala, Bhiwani, Faridabad, Fatehabad, Gurgaon, Hisar, Jhajjar, Jind, Kaithal, Karnal, Kurukshetra, Panchkula, Sirsa, Sonipat, Panipat, Rewari, Rohtak, Yamunanagar, Palwal and Mahendergarh.
Rules and Regulations.
The Haryana government has reduced the charge for filing an application under Right to Information Act, 2005 from to . The Haryana Right to Information Rules, 2009, has been amended and now will be known as the Haryana Right to Information (Amendment) Rules, 2016.

</doc>
<doc id="14190" url="https://en.wikipedia.org/wiki?curid=14190" title="Himachal Pradesh">
Himachal Pradesh

Himachal Pradesh (; literally "Snow-laden Region") is a state in North India.Its area is , and is bordered by Jammu and Kashmir on the north, Punjab on the west, Haryana on the south-west, Uttarakhand on the south-east and by the Tibet Autonomous Region on the east. Hima means snow in Sanskrit, and the literal meaning of the state’s name is in the lap of the Himalayas. It was named by Acharya Diwakar Datt Sharma, one of the most eminent Sanskrit scholars of Himachal Pradesh.
According to a 2005 Transparency International survey, Himachal Pradesh is ranked the second-least corrupt state in the country after Kerala.
History.
The history of the area that now constitutes Himachal Pradesh dates back to the time when the Indus valley civilisation flourished between 2250 and 1750 BCE. Tribes such as the Koilis, Halis, Dagis, Dhaugris, Dasa, Khasas, Kinnars, and Kirats inhabited the region from the prehistoric era. During the Vedic period, several small republics known as "Janapada" existed which were later conquered by the Gupta Empire. After a brief period of supremacy by King Harshavardhana, the region was once again divided into several local powers headed by chieftains, including some Rajput principalities. These kingdoms enjoyed a large degree of independence and were invaded by Delhi Sultanate a number of times. Mahmud Ghaznavi conquered Kangra at the beginning of the 10th century. Timur and Sikander Lodi also marched through the lower hills of the state and captured a number of forts and fought many battles. Several hill states acknowledged Mughal suzerainty and paid regular tribute to the Mughals.
The Gurkhas, a martial tribe, came to power in Nepal in the year 1768. They consolidated their military power and began to expand their territory. Gradually, the Gorkhas annexed Sirmour and Shimla. Under the leadership of Amar Singh Thapa, Gorkhas laid siege to Kangra. They managed to defeat Sansar Chand Katoch, the ruler of Kangra, in 1806 with the help of many provincial chiefs. However, Gurkhas could not capture Kangra fort which came under Maharaja Ranjeet Singh in 1809. After the defeat, the Gurkhas began to expand towards the south of the state. However, Raja Ram Singh, Raja of Siba State managed to capture the fort of Siba from the remnants of Lahore Darbar in Samvat 1846, during the First Anglo-Sikh War. They came into direct conflict with the British along the "tarai" belt after which the British expelled them from the provinces of the Satluj. The British gradually emerged as the paramount power. In the revolt of 1857, or first Indian war of independence, arising from a number of grievances against the British, the people of the hill states were not as politically active as were those in other parts of the country. They and their rulers, with the exception of Bushahr, remained more or less inactive. Some, including the rulers of Chamba, Bilaspur, Bhagal and Dhami, rendered help to the British government during the revolt.
The British territories came under the British Crown after Queen Victoria's proclamation of 1858. The states of Chamba, Mandi and Bilaspur made good progress in many fields during the British rule. During World War I, virtually all rulers of the hill states remained loyal and contributed to the British war effort, both in the form of men and materials. Among these were the states of Kangra, Jaswan, Datarpur, Guler, Nurpur, Chamba, Suket, Mandi, and Bilaspur.
After independence, the Chief Commissioner's Province of H.P. came into being on 15 April 1948 as a result of integration of 28 petty princely states (including feudal princes and "zaildars") in the promontories of the western Himalaya, known in full as the Simla Hills States and four Punjab southern hill states by issue of the Himachal Pradesh (Administration) Order, 1948 under Sections 3 and 4 of the Extra-Provincial Jurisdiction Act, 1947 (later renamed as the Foreign Jurisdiction Act, 1947 vide A.O. of 1950). The State of Bilaspur was merged into Himachal Pradesh on 1 April 1954 by the Himachal Pradesh and Bilaspur (New State) Act, 1954. Himachal became a part C state on 26 January 1950 with the implementation of the Constitution of India and the Lieutenant Governor was appointed. The Legislative Assembly was elected in 1952. Himachal Pradesh became a union territory on 1 November 1956. Some areas of Punjab State—namely Simla, Kangra, Kulu and Lahul and Spiti Districts, Nalagarh tehsil of Ambala District, Lohara, Amb and Una kanungo circles, some area of Santokhgarh kanungo circle and some other specified area of Una tehsil of Hoshiarpur District besides some parts of Dhar Kalan Kanungo circle of Pathankot tehsil of Gurdaspur District—were merged with Himachal Pradesh on 1 November 1966 on enactment of Punjab Reorganisation Act, 1966 by the Parliament. On 18 December 1970, the State of Himachal Pradesh Act was passed by Parliament, and the new state came into being on 25 January 1971. Thus Himachal emerged as the 18th state of the Indian Union.
Geography and climate.
Himachal is in the western Himalayas. Covering an area of , it is a mountainous state. Most of the state lies on the foothills of the Dhauladhar Range. At 6,816 m Reo Purgyil is the highest mountain peak in the state of Himachal Pradesh.
The drainage system of Himachal is composed both of rivers and glaciers. Himalayan rivers criss-cross the entire mountain chain.
Himachal Pradesh provides water to both the Indus and Ganges basins. The drainage systems of the region are the Chandra Bhaga or the Chenab, the Ravi, the Beas, the Sutlej, and the Yamuna. These rivers are perennial and are fed by snow and rainfall. They are protected by an extensive cover of natural vegetation.
Due to extreme variation in elevation, great variation occurs in the climatic conditions of Himachal . The climate varies from hot and subhumid tropical in the southern tracts to, with more elevation, cold, alpine, and glacial in the northern and eastern mountain ranges. The state has areas like Dharamsala that receive very heavy rainfall, as well as those like Lahaul and Spiti that are cold and almost rainless. Broadly, Himachal experiences three seasons: summer, winter, and rainy season. Summer lasts from mid-April till the end of June and most parts become very hot (except in the alpine zone which experiences a mild summer) with the average temperature ranging from . Winter lasts from late November till mid March. Snowfall is common in alpine tracts (generally above i.e. in the higher and trans-Himalayan region).
Flora and fauna.
According to 2003 Forest Survey of India report, legally defined forest areas constitute 66.52% of the area of Himachal Pradesh. Vegetation in the state is dictated by elevation and precipitation. The state endows with a high diversity of medicinal and aromatic plants. Lahaul-Spiti region of the state being a cold desert area support quite unique medicinal plants, including Ferula jaeschkeana, Hyoscyamus Niger, Lancea tibetica, and Saussurea bracteata.
Himachal is also said to be the fruit bowl of the country, with orchards being widespread. Meadows and pastures are also seen clinging to steep slopes. After the winter season, the hillsides and orchards bloom with wild flowers, while gladiolas, carnations, marigolds, roses, chrysanthemums, tulips and lilies are carefully cultivated. The state government is gearing up to make Himachal Pradesh as the flower basket of the world.
Himachal Pradesh has around 463 bird and 359 animal species.
Government.
The Legislative Assembly of Himachal Pradesh has no pre-Constitution history. The State itself is a post-Independence creation. It came into being as a centrally administered territory on 15 April 1948 from the integration of thirty erstwhile princely states.
Himachal Pradesh is governed through a parliamentary system of representative democracy, a feature the state shares with other Indian states. Universal suffrage is granted to residents. The legislature consists of elected members and special office bearers such as the Speaker and the Deputy Speaker who are elected by the members. Assembly meetings are presided over by the Speaker or the Deputy Speaker in the Speaker's absence. The judiciary is composed of the Himachal Pradesh High Court and a system of lower courts. Executive authority is vested in the Council of Ministers headed by the Chief Minister, although the titular head of government is the Governor. The Governor is the head of state appointed by the President of India. The leader of the party or coalition with a majority in the Legislative Assembly is appointed as the Chief Minister by the Governor, and the Council of Ministers are appointed by the Governor on the advice of the Chief Minister. The Council of Ministers reports to the Legislative Assembly. The Assembly is unicameral with 68 Members of the Legislative Assembly (MLA). Terms of office run for 5 years, unless the Assembly is dissolved prior to the completion of the term. Auxiliary authorities known as "panchayats", for which local body elections are regularly held, govern local affairs.
In the assembly elections held in November 2012, the Congress secured an absolute majority. The Congress won 36 of the 68 seats while the BJP won only 26 of the 68 seats. Virbhadra Singh was sworn-in as Himachal Pradesh's Chief Minister for a record sixth term in Shimla on 25 December 2012. Virbhadra Singh who has held the top office in Himachal five times in the past, was administered the oath of office and secrecy by Governor Urmila Singh at an open ceremony at the historic Ridge Maidan in Shimla.
Agriculture.
Land husbandry initiatives such as the Mid-Himalayan Watershed Development Project, which includes the Himachal Pradesh Reforestation Project (HPRP), the world's largest clean development mechanism (CDM) undertaking, have improved agricultural yields and productivity, and raised rural household incomes.
Economy.
The era of planning in Himachal Pradesh started in 1948 along with the rest of India. The first five-year plan allocated 52.7 million to Himachal. More than 50% of this expenditure was incurred on road construction since it was felt that without proper transport facilities, the process of planning and development could not be carried to the people, who mostly lived an isolated existence in faraway areas. Himachal now ranks fourth in per capita income among the states of the Indian Union.
Agriculture contributes over 45% to the net state domestic product. It is the main source of income and employment in Himachal. Over 93% of the population in Himachal depends directly upon agriculture, which provides direct employment to 71% of its people. The main cereals grown are wheat, maize, rice and barley.
Hydropower is also one of the major sources of income generation for the state. The identified Hydroelectric Potential for the state is 23,000.43 MW in five river basins.
As per the current prices, the total GDP was estimated at 254 billion as against 230 billion in the year 2004–05, showing an increase of 10.5%.
Transportation.
Himachal has three domestic airports in Shimla, Kullu and Kangra districts. The air routes connect the state with Delhi and Chandigarh.
Himachal is famous for its narrow-gauge railways. One is the Kalka-Shimla Railway, a UNESCO World Heritage Site, and another is the Pathankot–Jogindernagar. The total length of these two tracks is . The Kalka-Shimla Railway passes through many tunnels, while the Pathankot–Jogindernagar meanders through a maze of hills and valleys. It also has standard-gauge railway track, which connects Amb (Una district) to Delhi. A survey is being conducted to extend this railway line to Kangra (via Nadaun). Other proposed railways in the state are Baddi-Bilaspur, Dharamsala-Palampur and Bilaspur-Manali-Leh.
Roads are the major mode of transport in the hilly terrains. The state has road network of , including eight National Highways (NH) that constitute and 19 State Highways with a total length of . Some roads get closed during winter and monsoon seasons due to snow and landslides. Hamirpur has the highest road density in the state.
Population.
Demographics.
Himachal Pradesh has a total population of 6,856,509 including 3,473,892 males and 3,382,617 females as per the provisional results of the Census of India 2011. This is only 0.57 per cent of India's total population, recording a growth of 12.81 per cent. The total fertility rate (TFR) per woman is 1.8, one of lowest in India.
In the census, the state is placed 21st on the population chart, followed by Tripura at 22nd place. Kangra district was top ranked with a population strength of 1,507,223 (21.98%), Mandi district 999,518 (14.58%), Shimla district 813,384 (11.86%), Solan district 576,670 (8.41%), Sirmaur district 530,164 (7.73%), Una district 521,057 (7.60%), Chamba district 518,844 (7.57%), Hamirpur district 454,293 (6.63%), Kullu district 437,474 (6.38%), Bilaspur district 382,056 (5.57%), Kinnaur district 84,298 (1.23%) and Lahaul Spiti 31,528 (0.46%).
The life expectancy at birth in Himachal Pradesh is 62.8 years (higher than the national average of 57.7 years) for 1986–1990. The infant mortality rate stood at 40 in 2010, and the crude birth rate has declined from 37.3 in 1971 to 16.9 in 2010, below the national average of 26.5 in 1998. The crude death rate was 6.9 in 2010. Himachal Pradesh's literacy rate almost doubled between 1981 and 2011 (see table to right).
Languages.
Hindi is both the official language and the lingua franca of Himachal Pradesh. However, most of the population speaks Pahari in everyday conversation, which includes nearly all Western Pahari dialects. People in Kinnaur and Lahul & Spiti speak Sino-Tibetan languages.HP culture Dept
Religion.
Hinduism is the main religion in Himachal Pradesh, which ranks first in India in terms of the proportion of Hindus present within it. More than 95% of the total population belongs to the Hindu faith, the distribution of which is evenly spread throughout the state.
Himachal Pradesh thus has the one of the highest proportions of Hindu population in India (95.17%).
Other religions that form a small percentage are Buddhism and Sikhism. The Lahaulis of Lahaul and Spiti region are mainly Buddhists. Sikhs mostly live in towns and cities and constitute 1.16% of the state population. The Buddhists, who constitute 1.15%, are mainly natives and tribals from Lahaul and Spiti, where they form a majority of 60%, and Kinnaur, where they form 40%.
Culture.
There are tribal populations in the state that are mainly made up of Gaddis, Gujjars, Kinnars, Lahaulis, and Pangawals. Many people of Himachal Pradesh live a very simple traditional 'Pahari' lifestyle.
Shimla, the state capital, is home to Asia's only natural ice skating rink.
Notable people.
Prominent people associated with Himachal include:
Education.
Hamirpur District is among the top districts in the country for literacy. Education rates among women are quite encouraging in the state. The standard of education in the state has reached a considerably high level as compared to other states in India with several reputed educational institutes for higher studies.
The Indian Institute of Technology Mandi, Himachal Pradesh University Shimla, Institute of Himalayan Bioresource Technology (IHBT, CSIR Lab), Palampur, the National Institute of Technology, Hamirpur, 
Indian Institute of Information Technology, Una the Central University Dharamshala, AP Goyal (Alakh Prakash Goyal) Shimla University, The Bahra University (Waknaghat, Solan) the Baddi University of Emerging Sciences and Technologies Baddi, IEC University, Shoolini University Of Biotechnology and Management Sciences, Solan, Manav Bharti University Solan, the Jaypee University of Information Technology Waknaghat, Eternal University, Sirmaur & Chitkara University Solan are some of the pioneer universities in the state. CSK Himachal Pradesh Krishi Vishwavidyalya Palampur is one of the most renowned hill agriculture institutes in world. Dr. Yashwant Singh Parmar University of Horticulture and Forestry has earned a unique distinction in India for imparting teaching, research and extension education in horticulture, forestry and allied disciplines. Further, state-run Jawaharlal Nehru Government Engineering College started in 2006 at Sundernagar.
There are over 10,000 primary schools, 1,000 secondary schools and more than 1,300 high schools in Himachal. The state government has decided to start three major nursing colleges to develop the health system in the state. In meeting the constitutional obligation to make primary education compulsory, Himachal has become the first state in India to make elementary education accessible to every child.
The state has Indira Gandhi Medical College and Hospital, Homoeopathic Medical College & Hospital, Kumarhatti. Besides that there is Himachal Dental College which is the state's first recognised dental institute.
State profile.
Source: "Department of Information and Public Relations."
Census 2011-
Largest District (km²)
(1) Lahul and Spiti 13841
(2) Chamba 6522
(3) Kinnaur 6401
(4) Kangra 5739
(5) Kullu 5503
Percentage of Child
(1) Chamba 13.55%
(2) Sirmaur 13.14%
(3) Solan 11.74%
(4) Kullu 11.52%
(5) Una 11.36%
High Density
(1) Hamirpur 407
(2) Una 338
(3) Bilaspur 327
(4) Solan 300
(5) Kangra 263
Top Population Growth
(1) Una 16.26%
(2) Solan 15.93%
(3) Sirmaur 15.54%
(4) Kullu 14.76%
(5) Kangra 12.77%
High Literacy
(1) Hamirpur 89.01%
(2) Una 87.23%
(3) Kangra 86.49%
(4) Blaspur 85.87%
(5) Solan 85.02%
High Sex Ratio
(1) Hamirpur 1095
(2) Kangra 1012
(3) Mandi 1007
(4) Chamba 986
(5) Bilaspur 981

</doc>
<doc id="14192" url="https://en.wikipedia.org/wiki?curid=14192" title="Helene">
Helene

Helene may refer to:

</doc>
<doc id="14193" url="https://en.wikipedia.org/wiki?curid=14193" title="Hyperion">
Hyperion

Hyperion is the name of a Greek Titan (pre-deity), see Hyperion (mythology)
Hyperion may also refer to:

</doc>
<doc id="14194" url="https://en.wikipedia.org/wiki?curid=14194" title="History of medicine">
History of medicine

This article deals with medicine as practiced by trained professionals from ancient times to the present. Early medical traditions include those of Babylon, China, Egypt and India. The Greeks went even further, introducing the concepts of medical diagnosis, prognosis, and advanced medical ethics. The Hippocratic Oath, still taken (although significantly changed from the original) by doctors up to today, was written in Greece in the 5th century BCE. In the medieval age, surgical practices inherited from the ancient masters were improved and then systematized in Rogerius's "The Practice of Surgery". Universities began systematic training of physicians around the years 1220 in Italy. During the Renaissance, understanding of anatomy improved, and the microscope was invented. The germ theory of disease in the 19th century led to cures for many infectious diseases. Military doctors advanced the methods of trauma treatment and surgery. Public health measures were developed especially in the 19th century as the rapid growth of cities required systematic sanitary measures. Advanced research centers opened in the early 20th century, often connected with major hospitals. The mid-20th century was characterized by new biological treatments, such as antibiotics. These advancements, along with developments in chemistry, genetics, and lab technology (such as the x-ray) led to . Medicine was heavily professionalized in the 20th century, and new careers opened to women as nurses (from the 1870s) and as physicians (especially after 1970). The 21st century is characterized by highly advanced research involving numerous fields of science.
Prehistoric medicine.
Although there is no record to establish when plants were first used for medicinal purposes (herbalism), the use of plants as healing agents, as well as clays and soils is ancient. Over time through emulation of the behavior of fauna a medicinal knowledge base developed and passed between generations. As tribal culture specialized specific castes, shamans and apothecaries fulfilled the role of healer. 
The first known dentistry dates to about 7,000 B.C.E. in Baluchistan, where Neolithic dentists used flint-tipped drills and bowstrings.
The first known trepanning operation was carried out about 5,000 B.C.E. in Ensisheim, France.
The earliest known surgery, an amputation was carried out about 4,900 B.C.E. in Buthiers-Bulancourt, France.
Early civilizations.
Egypt.
Ancient Egypt developed a large, varied and fruitful medical tradition. Herodotus described the Egyptians as "the healthiest of all men, next to the Libyans", because of the dry climate and the notable public health system that they possessed. According to him, "the practice of medicine is so specialized among them that each physician is a healer of one disease and no more." Although Egyptian medicine, to a good extent, dealt with the supernatural, it eventually developed a practical use in the fields of anatomy, public health, and clinical diagnostics.
Medical information in the Edwin Smith Papyrus may date to a time as early as 3000 BC. Imhotep in the 3rd dynasty is sometimes credited with being the founder of ancient Egyptian medicine and with being the original author of the "Edwin Smith Papyrus", detailing cures, ailments and anatomical observations. The "Edwin Smith Papyrus" is regarded as a copy of several earlier works and was written c. 1600 BC. It is an ancient textbook on surgery almost completely devoid of magical thinking and describes in exquisite detail the "examination, diagnosis, treatment," and "prognosis" of numerous ailments.
The Kahun Gynaecological Papyrus treats women's complaints, including problems with conception. Thirty four cases detailing diagnosis and treatment survive, some of them fragmentarily. Dating to 1800 BCE, it is the oldest surviving medical text of any kind.
Medical institutions, referred to as "Houses of Life" are known to have been established in ancient Egypt as early as the 1st Dynasty.
The earliest known physician is also credited to ancient Egypt: Hesy-Ra, "Chief of Dentists and Physicians" for King Djoser in the 27th century BCE. Also, the earliest known woman physician, Peseshet, practiced in Ancient Egypt at the time of the 4th dynasty. Her title was "Lady Overseer of the Lady Physicians." In addition to her supervisory role, Peseshet trained midwives at an ancient Egyptian medical school in Sais.
Babylonia.
The oldest Babylonian texts on medicine date back to the Old Babylonian period in the first half of the 2nd millennium BCE. The most extensive Babylonian medical text, however, is the "Diagnostic Handbook" written by the "ummânū", or chief scholar, Esagil-kin-apli of Borsippa, during the reign of the Babylonian king Adad-apla-iddina (1069–1046 BCE).
Along with the Egyptians the Babylonians introduced the practice of diagnosis, prognosis, physical examination, and remedies. In addition, the "Diagnostic Handbook" introduced the methods of therapy and etiology. The text contains a list of medical symptoms and often detailed empirical observations along with logical rules used in combining observed symptoms on the body of a patient with its diagnosis and prognosis.
The "Diagnostic Handbook" was based on a logical set of axioms and assumptions, including the modern view that through the examination and inspection of the symptoms of a patient, it is possible to determine the patient's disease, its aetiology and future development, and the chances of the patient's recovery. The symptoms and diseases of a patient were treated through therapeutic means such as bandages, herbs and creams.
There was little development after the medieval era. Major European treatises on medicine took 200 years to reach the Middle East, where local rulers might consult Western doctors to get the latest treatments. Medical works in Arabic, Turkish, and Persian as late as 1800 were based on medieval Islamic medicine.
India.
The Atharvaveda, a sacred text of Hinduism dating from the Early Iron Age, is one of the first Indian text dealing with medicine, like the medicine of the Ancient Near East based on concepts of the exorcism of demons and magic. The Atharvaveda also contain prescriptions of herbs for various ailments. The use of herbs to treat ailments would later form a large part of Ayurveda.
Ayurveda, meaning the "complete knowledge for long life" is another medical system of India. Its two most famous texts belong to the schools of Charaka and Sushruta. The earliest foundations of Ayurveda were built on a synthesis of traditional herbal practices together with a massive addition of theoretical conceptualizations, new nosologies and new therapies dating from about 600 BCE onwards, and coming out of the communities of thinkers who included the Buddha and others.
According to the compendium of Charaka, the Charakasamhitā, health and disease are not predetermined and life may be prolonged by human effort. The compendium of Suśruta, the Suśrutasamhitā defines the purpose of medicine to cure the diseases of the sick, protect the healthy, and to prolong life. Both these ancient compendia include details of the examination, diagnosis, treatment, and prognosis of numerous ailments. The Suśrutasamhitā is notable for describing procedures on various forms of surgery, including rhinoplasty, the repair of torn ear lobes, perineal lithotomy, cataract surgery, and several other excisions and other surgical procedures. Most remarkable is Sushruta's penchant for scientific classification:
His medical treatise consists of 184 chapters, 1,120 conditions are listed, including injuries and illnesses relating to aging and mental illness. The Sushruta Samhita describe 125 surgical instrument, 300 surgical procedures and classifies human surgery in 8 categories.
The Ayurvedic classics mention eight branches of medicine: kāyācikitsā (internal medicine), śalyacikitsā (surgery including anatomy), śālākyacikitsā (eye, ear, nose, and throat diseases), kaumārabhṛtya (pediatrics), bhūtavidyā (spirit medicine), and agada tantra (toxicology), rasāyana
(science of rejuvenation), and vājīkaraṇa (Aphrodisiac). Apart from learning these, the student of Āyurveda was expected to know ten arts that were indispensable in the preparation and application of his medicines: distillation, operative skills, cooking, horticulture, metallurgy, sugar manufacture, pharmacy, analysis and separation of minerals, compounding of metals, and preparation of alkalis. The teaching of various subjects was done during the instruction of relevant clinical subjects. For example, teaching of anatomy was a part of the teaching of surgery, embryology was a part of training in pediatrics and obstetrics, and the knowledge of physiology and pathology was interwoven in the teaching of all the clinical disciplines.
The normal length of the student's training appears to have been seven years. But the physician was to continue to learn.
As an alternative form of medicine in India, Unani medicine got deep roots and royal patronage during medieval times. It progressed during Indian sultanate and mughal periods. Unani medicine is very close to Ayurveda. Both are based on theory of the presence of the elements (in Unani, they are considered to be fire, water, earth and air) in the human body. According to followers of Unani medicine, these elements are present in different fluids and their balance leads to health and their imbalance leads to illness.
By the 18th century A.D., Sanskrit medical wisdom still dominated. Muslim rulers built large hospitals in 1595 in Hyderabad, and in Delhi in 1719, and numerous commentaries on ancient texts were written.
China.
China also developed a large body of traditional medicine. Much of the philosophy of traditional Chinese medicine derived from empirical observations of disease and illness by Taoist physicians and reflects the classical Chinese belief that individual human experiences express causative principles effective in the environment at all scales. These causative principles, whether material, essential, or mystical, correlate as the expression of the natural order of the universe.
The foundational text of Chinese medicine is the Huangdi neijing, (or "Yellow Emperor's Inner Canon"), written 5th century to 3rd century BCE. Near the end of the 2nd century AD, during the Han dynasty, Zhang Zhongjing, wrote a "Treatise on Cold Damage", which contains the earliest known reference to the "Neijing Suwen". The Jin Dynasty practitioner and advocate of acupuncture and moxibustion, Huangfu Mi (215-282), also quotes the Yellow Emperor in his "Jiayi jing", c. 265. During the Tang Dynasty, the "Suwen" was expanded and revised, and is now the best extant representation of the foundational roots of traditional Chinese medicine. Traditional Chinese Medicine that is based on the use of herbal medicine, acupuncture, massage and other forms of therapy has been practiced in China for thousands of years.
In the 18th century, during the Qing dynasty, there was a proliferation of popular books as well as more advanced encyclopedias on traditional medicine. Jesuit missionaries introduced Western science and medicine to the royal court, the Chinese physicians ignored them.
Finally in the 19th century, Western medicine was introduced at the local level by Christian medical missionaries from the London Missionary Society (Britain), the Methodist Church (Britain) and the Presbyterian Church (USA). Benjamin Hobson (1816–1873) in 1839, set up a highly successful Wai Ai Clinic in Guangzhou, China. The Hong Kong College of Medicine for Chinese was founded in 1887 by the London Missionary Society, with its first graduate (in 1892) being Sun Yat-sen, who later led the Chinese Revolution (1911). The Hong Kong College of Medicine for Chinese was the forerunner of the School of Medicine of the University of Hong Kong, which started in 1911.
Because of the social custom that men and women should not be near to one another, the women of China were reluctant to be treated by male doctors. The missionaries sent women doctors such as Dr. Mary Hannah Fulton(1854–1927). Supported by the Foreign Missions Board of the Presbyterian Church (USA) she in 1902 founded the first medical college for women in China, the Hackett Medical College for Women, in Guangzhou.
Greece and Roman Empire.
Around 800 BCE Homer in The Iliad gives descriptions of wound treatment by the two sons of Asklepios, the admirable physicians Podaleirius and Machaon and one acting doctor, Patroclus. Because Machaon is wounded and Podaleirius is in combat Eurypylus asks Patroclus to "cut out this arrow from my thigh, wash off the blood with warm water and spread soothing ointment on the wound". Askelpios like Imhotep becomes god of healing over time.
Temples dedicated to the healer-god Asclepius, known as "Asclepieia" (, sing. , "'Asclepieion"), functioned as centers of medical advice, prognosis, and healing. At these shrines, patients would enter a dream-like state of induced sleep known as "enkoimesis" () not unlike anesthesia, in which they either received guidance from the deity in a dream or were cured by surgery. Asclepeia provided carefully controlled spaces conducive to healing and fulfilled several of the requirements of institutions created for healing. In the Asclepeion of Epidaurus, three large marble boards dated to 350 BCE preserve the names, case histories, complaints, and cures of about 70 patients who came to the temple with a problem and shed it there. Some of the surgical cures listed, such as the opening of an abdominal abscess or the removal of traumatic foreign material, are realistic enough to have taken place, but with the patient in a state of enkoimesis induced with the help of soporific substances such as opium. Alcmaeon of Croton wrote on medicine between 500 and 450 BCE. He argued that channels linked the sensory organs to the brain, and it is possible that he discovered one type of channel, the optic nerves, by dissection.
Hippocrates.
A towering figure in the history of medicine was the physician Hippocrates of Kos (c. 460 – c. 370 BCE), considered the "father of Western medicine." The Hippocratic Corpus is a collection of around seventy early medical works from ancient Greece strongly associated with Hippocrates and his students. Most famously, Hippocrates invented the Hippocratic Oath for physicians, which is still relevant and in use today.
Hippocrates and his followers were first to describe many diseases and medical conditions. He is given credit for the first description of clubbing of the fingers, an important diagnostic sign in chronic suppurative lung disease, lung cancer and cyanotic heart disease. For this reason, clubbed fingers are sometimes referred to as "Hippocratic fingers". Hippocrates was also the first physician to describe Hippocratic face in "Prognosis". Shakespeare famously alludes to this description when writing of Falstaff's death in Act II, Scene iii. of "Henry V".
Hippocrates began to categorize illnesses as acute, chronic, endemic and epidemic, and use terms such as, "exacerbation, relapse, resolution, crisis, paroxysm, peak, and convalescence."
Another of Hippocrates's major contributions may be found in his descriptions of the symptomatology, physical findings, surgical treatment and prognosis of thoracic empyema, i.e. suppuration of the lining of the chest cavity. His teachings remain relevant to present-day students of pulmonary medicine and surgery. Hippocrates was the first documented person to practise cardiothoracic surgery, and his findings are still valid.
Some of the techniques and theories developed by Hippocrates are now put into practice by the fields of Environmental and Integrative Medicine. These include recognizing the importance of taking a complete history which includes environmental exposures as well as foods eaten by the patient which might play a role in his or her illness.
Herophilus and Erasistratus.
Two great Alexandrians laid the foundations for the scientific study of anatomy and physiology, Herophilus of Chalcedon and Erasistratus of Ceos. Other Alexandrian surgeons gave us ligature (hemostasis), lithotomy, hernia operations, ophthalmic surgery, plastic surgery, methods of reduction of dislocations and fractures, tracheotomy, and mandrake as an anaesthetic. Some of what we know of them comes from Celsus and Galen of Pergamum.
Herophilus of Chalcedon, working at the medical school of Alexandria placed intelligence in the brain, and connected the nervous system to motion and sensation. Herophilus also distinguished between veins and arteries, noting that the latter pulse while the former do not. He and his contemporary, Erasistratus of Chios, researched the role of veins and nerves, mapping their courses across the body. Erasistratus connected the increased complexity of the surface of the human brain compared to other animals to its superior intelligence. He sometimes employed experiments to further his research, at one time repeatedly weighing a caged bird, and noting its weight loss between feeding times. In Erasistratus' physiology, air enters the body, is then drawn by the lungs into the heart, where it is transformed into vital spirit, and is then pumped by the arteries throughout the body. Some of this vital spirit reaches the brain, where it is transformed into animal spirit, which is then distributed by the nerves.
Galen.
The Greek Galen (129–c. 216 ce) was one of the greatest physicians of the ancient world, studying and traveling widely in ancient Rome. He dissected animals to learn about the body, and performed many audacious operations—including brain and eye surgeries— that were not tried again for almost two millennia. In "Ars medica" ("Arts of Medicine"), he explained mental properties in terms of specific mixtures of the bodily parts.
Galen's medical works were regarded as authoritative until well into the Middle Ages. Galen left a physiological model of the human body that became the mainstay of the medieval physician's university anatomy curriculum, but it suffered greatly from stasis and intellectual stagnation because some of Galen's ideas were incorrect; he did not dissect a human body nor did the medieval lecturers.
The Renaissance rediscovered Galen . In 1523 Galen's "On the Natural Faculties" was published in London. In the 1530s Belgian anatomist and physician Andreas Vesalius launched a project to translate many of Galen's Greek texts into Latin. Vesalius's most famous work, "De humani corporis fabrica" was greatly influenced by Galenic writing and form.
Roman contributions.
The Romans invented numerous surgical instruments, including the first instruments unique to women, as well as the surgical uses of forceps, scalpels, cautery, cross-bladed scissors, the surgical needle, the sound, and speculas. Romans also performed cataract surgery.
The Roman army physician Dioscorides (c. 40–90 AD), was a Greek botanist and pharmacologist. He wrote the encyclopedia "De Materia Medica" describing over 600 herbal cures, forming an influential pharmacopoeia which was used extensively for the following 1,500 years.
The Middle Ages, 400 to 1400 AD.
Islamic World.
The Islamic civilization rose to primacy in medical science as its physicians contributed significantly to the field of medicine, including anatomy, ophthalmology, pharmacology, pharmacy, physiology, surgery, and the pharmaceutical sciences. The Arabs were influenced by ancient Indian, Greek, Roman and Byzantine medical practices, and developed these further. Galen & Hippocrates were pre-eminent authorities. The translation of 129 of Galen's works into Arabic by the Nestorian Christian Hunayn ibn Ishaq and his assistants, and in particular Galen's insistence on a rational systematic approach to medicine, set the template for Islamic medicine, which rapidly spread throughout the Arab Empire.(cf. Dr. A. Zahoor and Dr. Z. Haq (1997), Quotations From Famous Historians of Science, Cyberistan.</ref>
Europe.
After 400 A.D., the study and practice of medicine in the Western Roman Empire went into deep decline. Medical services were provided, especially for the poor, in the thousands of monastic hospitals that sprang up across Europe, but the care was rudimentary and mainly palliative. Most of the writings of Galen and Hippocrates were lost to the West, with the summaries and compendia of St. Isidore of Seville being the primary channel for transmitting Greek medical ideas. The Carolingian renaissance brought increased contact with Byzantium and a greater awareness of ancient medicine, but only with the twelfth century renaissance and the new translations coming from Muslim and Jewish sources in Spain, and the fifteenth century flood of resources after the fall of Constantinople did the West fully recover its acquaintance with classical antiquity.
Wallis identifies a prestige hierarchy with university educated physicians on top, followed by learned surgeons; craft-trained surgeons; barber surgeons; itinerant specialists such as dentist and oculists; empirics; and midwives.
Schools.
The first medical schools were opened in the 9th century, most notably the Schola Medica Salernitana at Salerno in southern Italy. The cosmopolitan influences from Greek, Latin, Arabic, and Hebrew sources gave it an international reputation as the Hippocratic City. Students from wealthy families came for three years of preliminary studies and five of medical studies. By the thirteenth century the medical school at Montpellier began to eclipse the Salernitan school. In the 12th century universities were founded in Italy, France and England which soon developed schools of medicine. The University of Montpellier in France and Italy's University of Padua and University of Bologna were leading schools. Nearly all the learning was from lectures and readings in Hippocrates, Galen, Avicenna and Aristotle. There was little clinical work or dissection.
Humours.
The underlying principle of most medieval medicine was Galen's theory of humours. This was derived from the ancient medical works, and dominated all western medicine until the 19th century. The theory stated that within every individual there were four humours, or principal fluids - black bile, yellow bile, phlegm, and blood, these were produced by various organs in the body, and they had to be in balance for a person to remain healthy. Too much phlegm in the body, for example, caused lung problems; and the body tried to cough up the phlegm to restore a balance. The balance of humours in humans could be achieved by diet, medicines, and by blood-letting, using leeches. The four humours were also associated with the four seasons, black bile-autumn, yellow bile-summer, phlegm-winter and blood-spring.
Healing included both physical and spiritual therapeutics, such as the right herbs, a suitable diet, clean bedding, and the sense that care was always at hand. Other procedures used to help patients included the Mass, prayers, relics of saints, and music used to calm a troubled mind or quickened pulse.
Renaissance to Early Modern period 16th-18th century.
The Renaissance brought an intense focus on scholarship to Christian Europe. A major effort to translate the Arabic and Greek scientific works into Latin emerged. Europeans gradually became experts not only the ancient writings of the Romans and Greeks, but in the contemporary writings of Islamic scientists. During the later centuries of the Renaissance came an increase in experimental investigation, particularly in the field of dissection and body examination, thus advancing our knowledge of human anatomy.
The development of modern neurology began in the 16th century with Vesalius, who described the anatomy of the brain and other organs; he had little knowledge of the brain's function, thinking that it resided mainly in the ventricles. Over his lifetime he corrected over 200 of Galen's mistakes. Understanding of medical sciences and diagnosis improved, but with little direct benefit to health care. Few effective drugs existed, beyond opium and quinine. Folklore cures and potentially poisonous metal-based compounds were popular treatments.
Independently from Ibn al-Nafis, Michael Servetus rediscovered the pulmonary circulation, but this discovery did not reach the public because it was written down for the first time in the "Manuscript of Paris" in 1546, and later published in the theological work which he paid with his life in 1553. Later this was perfected by Renaldus Columbus and Andrea Cesalpino. Later William Harvey correctly described the circulatory system. The most useful tomes in medicine used both by students and expert physicians were "De Materia Medica" and Pharmacopoeia.
Bacteria and protists were first observed with a microscope by Antonie van Leeuwenhoek in 1676, initiating the scientific field of microbiology.
Paracelsus.
Paracelsus (1493–1541), was an erratic and abusive innovator who rejected Galen and bookish knowledge, calling for experimental research, with heavy doses of mysticism, alchemy and magic mixed in. The point is that he rejected sacred magic (miracles) under Church auspisces and looked for cures in nature. He preached but he also pioneered the use of chemicals and minerals in medicine. His hermetical views were that sickness and health in the body relied on the harmony of man (microcosm) and Nature (macrocosm). He took an approach different from those before him, using this analogy not in the manner of soul-purification but in the manner that humans must have certain balances of minerals in their bodies, and that certain illnesses of the body had chemical remedies that could cure them. Most of his influence came after his death. Paracelsus is a highly controversial figure in the history of medicine, with most experts hailing him as a Father of Modern Medicine for shaking off religious orthodoxy and inspiring many researchers; others say he was a mystic more than a scientist and downplay his importance.
Padua and Bologna.
University training of physicians began in the 13th century.
The University of Padua was founded about 1220 by walkouts from the University of Bologna, and began teaching medicine in 1222. It played a leading role in the identification and treatment of diseases and ailments, specializing in autopsies and the inner workings of the body. Starting in 1595, Padua's famous anatomical theatre drew artists and scientists studying the human body during public dissections. The intensive study of Galen led to critiques of Galen modeled on his own writing, as in the first book of Vesalius's "De humani corporis fabrica." Andreas Vesalius held the chair of Surgery and Anatomy ("explicator chirurgiae") and in 1543 published his anatomical discoveries in De Humani Corporis Fabrica. He portrayed the human body as an interdependent system of organ groupings. The book triggered great public interest in dissections and caused many other European cities to establish anatomical theatres.
At the University of Bologna the training of physicians began in 1219. The Italian city attracted students from across Europe. Taddeo Alderotti built a tradition of medical education that established the characteristic features of Italian learned medicine and was copied by medical schools elsewhere. Turisanus (d. 1320) was his student. The curriculum was revised and strengthened in 1560–1590. A representative professor was Julius Caesar Aranzi (Arantius) (1530–89). He became Professor of Anatomy and Surgery at the University of Bologna in 1556, where he established anatomy as a major branch of medicine for the first time. Aranzi combined anatomy with a description of pathological processes, based largely on his own research, Galen, and the work of his contemporary Italians. Aranzi discovered the 'Nodules of Aranzio' in the semilunar valves of the heart and wrote the first description of the superior levator palpebral and the coracobrachialis muscles. His books (in Latin) covered surgical techniques for many conditions, including hydrocephalus, nasal polyp, goitre and tumours to phimosis, ascites, haemorrhoids, anal abscess and fistulae.
Women.
Catholic women played large roles in health and healing in medieval and early modern Europe. A life as a nun was a prestigious role; wealthy families provided dowries for their daughters, and these funded the convents, while the nuns provided free nursing care for the poor.
The Catholic elites provided hospital services because of their theology of salvation that good works were the route to heaven. The Protestant reformers rejected the notion that rich men could gain God's grace through good works—and thereby escape purgatory—by providing cash endowments to charitable institutions. They also rejected the Catholic idea that the poor patients earned grace and salvation through their suffering. Protestants generally closed all the convents and most of the hospitals, sending women home to become housewives, often against their will. On the other hand, local officials recognized the public value of hospitals, and some were continued in Protestant lands, but without monks or nuns and in the control of local governments.
In London, the crown allowed two hospitals to continue their charitable work, under nonreligious control of city officials. The convents were all shut down but Harkness finds that women—some of them former nuns—were part of a new system that delivered essential medical services to people outside their family. They were employed by parishes and hospitals, as well as by private families, and provided nursing care as well as some medical, pharmaceutical, and surgical services.
Meanwhile, in Catholic lands such as France, rich families continued to fund convents and monasteries, and enrolled their daughters as nuns who provided free health services to the poor. Nursing was a religious role for the nurse, and there was little call for science.
Age of Enlightenment.
During the Age of Enlightenment, the 18th-century, science was held in high esteem and physicians upgraded their social status by becoming more scientific. The health field was crowded with self-trained barber-surgeons, apothecaries, midwives, drug peddlers, and charlatans.
Across Europe medical schools relied primarily on lectures and readings. In the final year student would have limited clinical experience by trailing the professor through the wards. Laboratory work was uncommon, and dissections were rarely done because of legal restrictions on cadavers. Most schools were small, and only Edinburgh, Scotland, with 11,000 alumni, produced large numbers of graduates.
Britain.
In Britain, there were but three small hospitals after 1550. Pelling and Webster estimate that in London in the 1580 to 1600 period, out of a population of nearly 200,000 people, there were about 500 medical practitioners. Nurses and midwives are not included. There were about 50 physicians, 100 licensed surgeons, 100 apothecaries, and 250 additional unlicensed practitioners. In the last category about 25% were women. All across Britain—and indeed all of the world—the vast majority of the people in city, town or countryside depended for medical care on local amateurs with no professional training but with a reputation as wise healers who could diagnose problems and advise sick people what to do—and perhaps set broken bones, pull a tooth, give some traditional herbs or brews or perform a little magic to cure what ailed them.
The London Dispensary opened in 1696, the first clinic in the British Empire to dispense medicines to poor sick people. The innovation was slow to catch on, but new dispensaries were open in the 1770s. In the colonies, small hospitals opened in Philadelphia in 1752, New York in 1771, and Boston (Massachusetts General Hospital) in 1811.
Guy's Hospital, the first great British hospital opened in 1721 in London, with funding from businessman Thomas Guy. In 1821 a bequest of £200,000 by William Hunt in 1829 funded expansion for an additional hundred beds. Samuel Sharp (1709–78), a surgeon at Guy's Hospital, from 1733 to 1757, was internationally famous; his "A Treatise on the Operations of Surgery" (1st ed., 1739), was the first British study focused exclusively on operative technique.
English physician Thomas Percival (1740–1804) wrote a comprehensive system of medical conduct, "Medical Ethics, or a Code of Institutes and Precepts, Adapted to the Professional Conduct of Physicians and Surgeons" (1803) that set the standard for many textbooks.
Mec
Spain and Spanish Empire.
In the Spanish empire, the viceregal capital of Mexico City was a site of medical training for physicians and the creation of hospitals. Epidemic disease had decimated indigenous populations starting with the early sixteenth-century Spanish conquest of the Aztec empire, when a black auxiliary in the armed forces of conqueror Hernán Cortés, with an active case of smallpox, set off a virgin land epidemic among indigenous peoples, Spanish allies and enemies alike. Aztec emperor Cuitlahuac died of smallpox. Disease was a significant factor in the Spanish conquest elsewhere as well.
Medical education was instituted at the Royal and Pontifical University of Mexico, and their clientele was urban elites. Male and female "curanderos" or lay practitioners, attended to the ills of the popular classes. The Spanish crown began regulating the medical profession just a few years after the conquest, setting up the Royal Tribunal of the Protomedicato, a board for licensing medical personnel in 1527. It became more systematic after 1646, licensing physicians, druggists, surgeons, and bleeders, and requiring a license before public practice. Crown regulation of medical practice became more general in the Spanish empire.
Elites and the popular classes alike called on divine intervention in personal and society-wide health crises, such as the epidemic of 1737. The intervention of the Virgin of Guadalupe was depicted in a scene of dead and dying Indians, with elites on their knees praying for her aid. In the late eighteenth century, the crown began implementing secularizing policies on the Iberian peninsula and its overseas empire that sought to control disease more systematically and scientifically.
19th century: Rise of modern medicine.
The practice of medicine changed in the face of rapid advances in science, as well as new approaches by physicians. Hospital doctors began much more systematic analysis of patients' symptoms in diagnosis. Among the more powerful new techniques were anaesthesia, and the development of both antiseptic and aseptic operating theatres. Actual cures were developed for certain endemic infectious diseases. However the decline in many of the most lethal diseases was more due to improvements in public health and nutrition than to medicine.
Medicine was revolutionized in the 19th century and beyond by advances in chemistry and laboratory techniques and equipment, old ideas of infectious disease epidemiology were replaced with bacteriology and virology.
Germ theory and bacteriology.
In the 1830s in Italy, Agostino Bassi traced the silkworm disease muscardine to microorganisms. Meanwhile, in Germany, Theodor Schwann led researches on alcoholic fermentation by yeast and proposed that they were alive—that is, microorganisms—a claim derided by leading chemists, such as Justus von Liebig, seeking solely physicochemical explanation, and alleging that Schwann's was regressing to vitalism. In 1847 in Vienna, Ignaz Semmelweis (1818–1865), by requiring physicians to clean their hands before attending childbirth, dramatically cut new mothers' death rate due to childbed fever, yet his principles were marginalized and attacked by professional peers.
Starting in 1857 by confirming Schwann's fermentation experiments, Louis Pasteur in France placed his eminent reputation behind the belief that yeast are microorganisms, and closed his paper by indicating that such process might also explain contagious diseases. In 1860, Pasteur's report on bacterial fermention to butyric acid motivated fellow Frenchman Casimir Davaine to establish a similar species, which he called "bacteridia", as the pathogen of the disease anthrax, costly to the cattle industry. Yet "bacteridia" were found inconsistently and dismissed as a disease byproduct, not cause. British surgeon Joseph Lister, however, already took cue and introduced antisepsis to wound treatment in 1865.
German physician Robert Koch, noting fellow German Ferdinand Cohn's report of a spore stage of a certain bacterial species, traced the life cycle of Davaine's "bacteridia", identified spores, inoculated laboratory animals with them, and reproduced anthrax—a breakthrough for experimental pathology and germ theory of disease. Pasteur's group added ecological investigations confirming spores' role in the natural setting, while Koch published a landmark treatise in 1878 on the bacterial pathology of wounds. In 1881, Koch reported discovery of the "tubercle bacillus", cementing germ theory and Koch's acclaim.
Upon the outbreak of a cholera epidemic in Alexandria, Egypt, two medical missions went to investigate and attend the sick, one was sent out by Pasteur and the other actually led by Koch. Koch's group returned victorious in 1883, having discovered the cholera pathogen. In Germany, however, Koch's bacteriologists had to vie against Max von Pettenkofer, Germany's leading proponent of miasmatic theory. Pettenkofer conceded bacteria's casual involvement, but maintained that other, environmental factors were required to turn it pathogenic, and opposed water treatment as a misdirected effort amid more important ways to improve public health. The massive cholera epidemic in Hamburg in 1892 devastasted Pettenkoffer's position, and yielded German public health to "Koch's bacteriology".
On losing the 1883 rivalry in Alexandria, Pasteur switched research direction, and introduced his third vaccine—rabies vaccine—the first vaccine for humans since Jenner's for smallpox. From across the globe, donations poured in, funding the founding of Pasteur Institute, the globe's first biomedical institute, which opened in 1888. Along with Koch's bacteriologists, Pasteur's group—which preferred the term "microbiology"—led medicine into the new era of "scientific medicine" upon bacteriology and germ theory. Accepted from Jakob Henle, Koch's steps to confirm a species' pathogenicity became famed as "Koch's postulates". Although his proposed tuberculosis treatment, tuberculin, seemingly failed, it soon was used to test for infection with the involved species. In 1905, Koch was awarded the Nobel Prize in Physiology or Medicine, and remains renowned as the founder of medical microbiology.
Women.
Women as nurses.
Women had always served in ancillary roles, and as midwives and healers. The professionalization of medicine forced them increasingly to the sidelines. As hospitals multiplied they relied in Europe on orders of Roman Catholic nun-nurses, and German Protestant and Anglican deaconesses in the early 19th century. They were trained in traditional methods of physical care that involved little knowledge of medicine. The breakthrough to professionalization based on knowledge of advanced medicine was led by Florence Nightingale in England. She resolved to provide more advanced training than she saw on the Continent. At Kaiserswerth, where the first German nursing schools were founded in 1836 by Theodor Fliedner, she said, "The nursing was nil and the hygiene horrible.") Britain's male doctors preferred the old system, but Nightingale won out and her Nightingale Training School opened in 1860 and became a model. The Nightingale solution depended on the patronage of upper class women, and they proved eager to serve. Royalty became involved. In 1902 the wife of the British king took control of the nursing unit of the British army, became its president, and renamed it after herself as the Queen Alexandra's Royal Army Nursing Corps; when she died the next queen became president. Today its Colonel In Chief is the daughter-in-law of Queen Elizabeth. In the United States, upper middle class women who already supported hospitals promoted nursing. The new profession proved highly attractive to women of all backgrounds, and schools of nursing opened in the late 19th century. They soon a function of large hospitals, where they provided a steady stream of low-paid idealistic workers. The International Red Cross began operations in numerous countries in the late 19th century, promoting nursing as an ideal profession for middle class women.
The Nightingale model was widely copied. Linda Richards (1841 – 1930) studied in London and became the first professionally trained American nurse. She established nursing training programs in the United States and Japan, and created the first system for keeping individual medical records for hospitalized patients. The Russian Orthodox Church sponsored seven orders of nursing sisters in the late 19th century. They ran hospitals, clinics, almshouses, pharmacies, and shelters as well as training schools for nurses. In the Soviet era (1917–1991), with the aristocratic sponsors gone, nursing became a low-prestige occupation based in poorly maintained hospitals.
Women as physicians.
It was very difficult for women to become doctors in any field before the 1970s. Elizabeth Blackwell (1821–1910) became the first woman to formally study and practice medicine in the United States. She was a leader in women's medical education. While Blackwell viewed medicine as a means for social and moral reform, her student Mary Putnam Jacobi (1842–1906) focused on curing disease. At a deeper level of disagreement, Blackwell felt that women would succeed in medicine because of their humane female values, but Jacobi believed that women should participate as the equals of men in all medical specialties using identical methods, values and insights. In the Soviet Union although the majority of medical doctors were women, they were paid less than the mostly male factory workers.
Paris.
Paris (France) and Vienna were the two leading medical centers on the Continent in the era 1750–1914.
In the 1770s-1850s Paris became a world center of medical research and teaching. The "Paris School" emphasized that teaching and research should be based in large hospitals and promoted the professionalization of the medical profession and the emphasis on sanitation and public health. A major reformer was Jean-Antoine Chaptal (1756–1832), a physician who was Minister of Internal Affairs. He created the Paris Hospital, health councils, and other bodies.
Louis Pasteur (1822–1895) was one of the most important founders of medical microbiology. He is remembered for his remarkable breakthroughs in the causes and preventions of diseases. His discoveries reduced mortality from puerperal fever, and he created the first vaccines for rabies and anthrax. His experiments supported the germ theory of disease. He was best known to the general public for inventing a method to treat milk and wine in order to prevent it from causing sickness, a process that came to be called pasteurization. He is regarded as one of the three main founders of microbiology, together with Ferdinand Cohn and Robert Koch. He worked chiefly in Paris and in 1887 founded the Pasteur Institute there to perpetuate his commitment to basic research and its practical applications. As soon as his institute was created, Pasteur brought together scientists with various specialties. The first five departments were directed by Emile Duclaux (general microbiology research) and Charles Chamberland (microbe research applied to hygiene), as well as a biologist, Ilya Ilyich Mechnikov (morphological microbe research) and two physicians, Jacques-Joseph Grancher (rabies) and Emile Roux (technical microbe research). One year after the inauguration of the Institut Pasteur, Roux set up the first course of microbiology ever taught in the world, then entitled "Cours de Microbie Technique" (Course of microbe research techniques). It became the model for numeous research centers around the world named "Pasteur Institutes."
Vienna.
The First Viennese School of Medicine, 1750–1800, was led by the Dutchman Gerard van Swieten (1700–1772), who aimed to put medicine on new scientific foundations - promoting unprejudiced clinical observation, botanical and chemical research, and introducing simple but powerful remedies. When the Vienna General Hospital opened in 1784, it at once became the world's largest hospital and physicians acquired a facility that gradually developed into the most important research centre. Progress ended with the Napoleonic wars and the government shutdown in 1819 of all liberal journals and schools; this caused a general return to traditionalism and eclecticism in medicine.
Vienna was the capital of a diverse empire and attracted not just Germans but Czechs, Hungarians, Jews, Poles and others to its world-class medical facilities. After 1820 the Second Viennese School of Medicine emerged with the contributions of physicians such as Carl Freiherr von Rokitansky, Josef Škoda, Ferdinand Ritter von Hebra, and Ignaz Philipp Semmelweis. Basic medical science expanded and specialization advanced. Furthermore, the first dermatology, eye, as well as ear, nose, and throat clinics in the world were founded in Vienna. The textbook of ophthalmologist Georg Joseph Beer (1763–1821) "Lehre von den Augenkrankheiten" combined practical research and philosophical speculations, and became the standard reference work for decades.
Berlin.
After 1871 Berlin, the capital of the new German Empire, became a leading center for medical research. Robert Koch (1843–1910) was a representative leader. He became famous for isolating "Bacillus anthracis" (1877), the "Tuberculosis bacillus" (1882) and "Vibrio cholerae" (1883) and for his development of Koch's postulates. He was awarded the Nobel Prize in Physiology or Medicine in 1905 for his tuberculosis findings. Koch is one of the founders of microbiology, inspiring such major figures as Paul Ehrlich and Gerhard Domagk.
U.S. Civil War.
In the American Civil War (1861–65), as was typical of the 19th century, more soldiers died of disease than in battle, and even larger numbers were temporarily incapacitated by wounds, disease and accidents. Conditions were poor in the Confederacy, where doctors and medical supplies were in short supply. The war had a dramatic long-term impact on medicine in the U.S., from surgical technique to hospitals to nursing and to research facilities.
The hygiene of the training and field camps was poor, especially at the beginning of the war when men who had seldom been far from home were brought together for training with thousands of strangers. First came epidemics of the childhood diseases of chicken pox, mumps, whooping cough, and, especially, measles. Operations in the South meant a dangerous and new disease environment, bringing diarrhea, dysentery, typhoid fever, and malaria. There were no antibiotics, so the surgeons prescribed coffee, whiskey, and quinine. Harsh weather, bad water, inadequate shelter in winter quarters, poor policing of camps, and dirty camp hospitals took their toll.
This was a common scenario in wars from time immemorial, and conditions faced by the Confederate army were even worse. The Union responded by building army hospitals in every state. What was different in the Union was the emergence of skilled, well-funded medical organizers who took proactive action, especially in the much enlarged United States Army Medical Department, and the United States Sanitary Commission, a new private agency. Numerous other new agencies also targeted the medical and morale needs of soldiers, including the United States Christian Commission as well as smaller private agencies.
The U.S. Army learned many lessons and in August 1886, it established the Hospital Corps.
Statistical methods.
A major breakthrough in epidemiology came with the introduction of statistical maps and graphs. They allowed careful analysis of seasonality issues in disease incidents, and the maps allowed public health officials to identifical critical loci for the dissemination of disease. John Snow in London developed the methods. English nurse Florence Nightingale pioneered analysis of large amounts of statistical data, using graphs and tables, regarding the condition of thousands of patients in the Crimean War to evaluate the efficacy of hospital services. Her methods proved convincing and led to reforms in military and civilian hospitals, usually with the full support of the government.
By the late 19th and early 20th century English statisticians led by Francis Galton, Karl Pearson and Ronald Fisher developed the mathematical tools such as correlations and hypothesis tests that made possible much more sophisticated analysis of statistical data.
During the U.S. Civil War the Sanitary Commission collected enormous amounts of statistical data, and opened up the problems of storing information for fast access and mechanically searching for data patterns. The pioneer was John Shaw Billings (1838–1913). A senior surgeon in the war, Billings built the Library of the Surgeon General's Office (now the National Library of Medicine, the centerpiece of modern medical information systems. Billings figured out how to mechanically analyze medical and demographic data by turning facts into numbers and punching the numbers onto cardboard cards that could be sorted and counted by machine. The applications were developed by his assistant Herman Hollerith; Hollerith invented the punch card and counter-sorter system that dominated statistical data manipulation until the 1970s. Hollerith's company became International Business Machines (IBM) in 1911.
Worldwide dissemination.
United States.
Johns Hopkins Hospital, founded in 1889, originated several modern medical practices, including residency and rounds.Donuts
Japan.
European ideas of modern medicine were spread widely through the world by medical missionaries, and the dissemination of textbooks. Japanese elites enthusiastically embraced Western medicine after the Meiji Restoration of the 1860s. However they had been prepared by their knowledge of the Dutch and German medicine, for they had some contact with Europe through the Dutch. Highly influential was the 1765 edition of Hendrik van Deventer's pioneer work "Nieuw Ligt" ("A New Light") on Japanese obstetrics, especially on Katakura Kakuryo's publication in 1799 of "Sanka Hatsumo" ("Enlightenment of Obstetrics"). A cadre of Japanese physicians began to interact with Dutch doctors, who introduced smallpox vaccinations. By 1820 Japanese ranpô medical practitioners not only translated Dutch medical texts, they integrated their readings with clinical diagnoses. These men became leaders of the modernization of medicine in their country. They broke from Japanese traditions of closed medical fraternities and adopted the European approach of an open community of collaboration based on expertise in the latest scientific methods.
Kitasato Shibasaburō (1853–1931) studied bacteriology in Germany under Robert Koch. In 1891 he founded the Institute of Infectious Diseases in Tokyo, which introduced the study of bacteriology to Japan. He and French researcher Alexandre Yersin went to Hong Kong in 1894, where; Kitasato confirmed Yersin's discovery that the bacterium "Yersinia pestis" is the agent of the plague. In 1897 he isolates and described the organism that caused dysentery. He became the first dean of medicine at Keio University, and the first president of the Japan Medical Association.
Japanese physicians immediately recognized the values of X-Rays. They were able to purchase the equipment locally from the Shimadzu Company, which developed, manufactured, marketed, and distributed X-Ray machines after 1900. Japan not only adopted German methods of public health in the home islands, but implemented them in its colonies, especially Korea and Taiwan, and after 1931 in Manchuria. A heavy investment in sanitation resulted in a dramatic increase of life expectancy.
Psychiatry.
Until the nineteenth century, the care of the insane was largely a communal and family responsibility rather than a medical one. The vast majority of the mentally ill were treated in domestic contexts with only the most unmanageable or burdensome likely to be institutionally confined. This situation was transformed radically from the late eighteenth century as, amid changing cultural conceptions of madness, a new-found optimism in the curability of insanity within the asylum setting emerged. Increasingly, lunacy was perceived less as a physiological condition than as a mental and moral one to which the correct response was persuasion, aimed at inculcating internal restraint, rather than external coercion. This new therapeutic sensibility, referred to as moral treatment, was epitomised in French physician Philippe Pinel's quasi-mythological unchaining of the lunatics of the Bicêtre Hospital in Paris and realised in an institutional setting with the foundation in 1796 of the Quaker-run York Retreat in England.
From the early nineteenth century, as lay-led lunacy reform movements gained in influence, ever more state governments in the West extended their authority and responsibility over the mentally ill. Small-scale asylums, conceived as instruments to reshape both the mind and behaviour of the disturbed, proliferated across these regions. By the 1830s, moral treatment, together with the asylum itself, became increasingly medicalised and asylum doctors began to establish a distinct medical identity with the establishment in the 1840s of associations for their members in France, Germany, the United Kingdom and America, together with the founding of medico-psychological journals. Medical optimism in the capacity of the asylum to cure insanity soured by the close of the nineteenth century as the growth of the asylum population far outstripped that of the general population. Processes of long-term institutional segregation, allowing for the psychiatric conceptualisation of the natural course of mental illness, supported the perspective that the insane were a distinct population, subject to mental pathologies stemming from specific medical causes. As degeneration theory grew in influence from the mid-nineteenth century, heredity was seen as the central causal element in chronic mental illness, and, with national asylum systems overcrowded and insanity apparently undergoing an inexorable rise, the focus of psychiatric therapeutics shifted from a concern with treating the individual to maintaining the racial and biological health of national populations.
Emil Kraepelin (1856–1926) introduced new medical categories of mental illness, which eventually came into psychiatric usage despite their basis in behavior rather than pathology or etiology. Shell shock among frontline soldiers exposed to heavy artillery bombardment was first diagnosed by British Army doctors in 1915. By 1916, similar symptoms were also noted in soldiers not exposed to explosive shocks, leading to questions as to whether the disorder was physical or psychiatric. In the 1920s surrealist opposition to psychiatry was expressed in a number of surrealist publications. In the 1930s several controversial medical practices were introduced including inducing seizures (by electroshock, insulin or other drugs) or cutting parts of the brain apart (leucotomy or lobotomy). Both came into widespread use by psychiatry, but there were grave concerns and much opposition on grounds of basic morality, harmful effects, or misuse.
In the 1950s new psychiatric drugs, notably the antipsychotic chlorpromazine, were designed in laboratories and slowly came into preferred use. Although often accepted as an advance in some ways, there was some opposition, due to serious adverse effects such as tardive dyskinesia. Patients often opposed psychiatry and refused or stopped taking the drugs when not subject to psychiatric control. There was also increasing opposition to the use of psychiatric hospitals, and attempts to move people back into the community on a collaborative user-led group approach ("therapeutic communities") not controlled by psychiatry. Campaigns against masturbation were done in the Victorian era and elsewhere. Lobotomy was used until the 1970s to treat schizophrenia. This was denounced by the anti-psychiatric movement in the 1960s and later.donu
20th century and beyond.
Twentieth Century Warfare and Medicine.
The ABO blood group system was discovered in 1901, and the Rhesus group in 1937, facilitating blood transfusion.
During the 20th century, large-scale wars were attended with medics and mobile hospital units which developed advanced techniques for healing massive injuries and controlling infections rampant in battlefield conditions. During the Mexican Revolution (1910-1920), General Pancho Villa organized hospital trains for wounded soldiers. Boxcars marked "Servicio Sanitario" ("sanitary service") were re-purposed as surgical operating theaters and areas for recuperation, and staffed by up to 40 Mexican and U.S. physicians. Severely wounded soldiers were shuttled back to base hospitals. Canadian physician Norman Bethune, M.D. developed a mobile blood-transfusion service for frontline operations in the Spanish Civil War (1936-1939), but ironically, he himself died of blood poisoning.
Thousands of scarred troops provided the need for improved prosthetic limbs and expanded techniques in plastic surgery or reconstructive surgery. Those practices were combined to broaden cosmetic surgery and other forms of elective surgery.
During the First World War, Alexis Carrel and Henry Dakin developed the Carrel-Dakin method of treating wounds with an irrigation, Dakin's solution, a germicide which helped prevent gangrene.
The Great War spurred the usage of Roentgen's X-ray, and the electrocardiograph, for the monitoring of internal bodily functions. This was followed in the inter-war period by the development of the first anti-bacterial agents such as the sulpha antibiotics.
Public health.
Public health measures became particular important during the 1918 flu pandemic, which killed at least 50 million people around the world. It became an important case study in epidemiology. Bristow shows there was a gendered response of health caregivers to the pandemic in the United States. Male doctors were unable to cure the patients, and they felt like failures. Women nurses also saw their patients die, but they took pride in their success in fulfilling their professional role of caring for, ministering, comforting, and easing the last hours of their patients, and helping the families of the patients cope as well.
From 1917 to 1923, the American Red Cross moved into Europe with a battery of long-term child health projects. It built and operated hospitals and clinics, and organized antituberculosis and antityphus campaigns. A high priority involved child health programs such as clinics, better baby shows, playgrounds, fresh air camps, and courses for women on infant hygiene. Hundreds of U.S. doctors, nurses, and welfare professionals administered these programs, which aimed to reform the health of European youth and to reshape European public health and welfare along American lines.
Second World War.
The advances in medicine made a dramatic difference for Allied troops, while the Germans and especially the Japanese and Chinese suffered from a severe lack of newer medicines, techniques and facilities. Harrison finds that the chances of recovery for a badly wounded British infantryman were as much as 25 times better than in the First World War. The reason was that:
Nazi and Japanese medicine.
Unethical human subject research, and killing of patients with disabilities, peaked during the Nazi era, with Nazi human experimentation and Aktion T4 during the Holocaust as the most significant examples. Many of the details of these and related events were the focus of the Doctors' Trial. Subsequently, principles of medical ethics, such as the Nuremberg Code, were introduced to prevent a recurrence of such atrocities. After 1937, the Japanese Army established programs of biological warfare in China. In Unit 731, Japanese doctors and research scientists conducted large numbers of vivisections and experiments on human beings, mostly Chinese victims.
Malaria.
Starting in World War II, DDT was used as insecticide to combat insect vectors carrying malaria, which was endemic in most tropical regions of the world. The first goal was to protect soldiers, but it was widely adopted as a public health device. In Liberia, for example, the United States had large military operations during the war and the U.S. Public Health Service began the use of DDT for indoor residual spraying (IRS) and as a larvicide, with the goal of controlling malaria in Monrovia, the Liberian capital. In the early 1950s, the project was expanded to nearby villages. In 1953, the World Health Organization (WHO) launched an antimalaria program in parts of Liberia as a pilot project to determine the feasibility of malaria eradication in tropical Africa. However these projects encountered a spate of difficulties that foreshadowed the general retreat from malaria eradication efforts across tropical Africa by the mid-1960s.
Post-World War II.
The World Health Organization was founded in 1948 as a United Nations agency to improve global health. In most of the world, life expectancy has improved since then, and was about 67 years as of 2010, and well above 80 years in some countries. Eradication of infectious diseases is an international effort, and several new vaccines have been developed during the post-war years, against infections such as measles, mumps, several strains of influenza and human papilloma virus. The long-known vaccine against Smallpox finally eradicated the disease in the 1970s, and Rinderpest was wiped out in 2011. Eradication of polio is underway. Tissue culture is important for development of vaccines. Though the early success of antiviral vaccines and antibacterial drugs, antiviral drugs were not introduced until the 1970s. Through the WHO, the international community has developed a response protocol against epidemics, displayed during the SARS epidemic in 2003, the Influenza A virus subtype H5N1 from 2004, the Ebola virus epidemic in West Africa and onwards.
As infectious diseases have become less lethal, and the most common causes of death in developed countries are now tumors and cardiovascular diseases, these conditions have received increased attention in medical research. Tobacco smoking as a cause of lung cancer was first researched in the 1920s, but was not widely supported by publications until the 1950s. Cancer treatment has been developed with radiotherapy, chemotherapy and surgical oncology.
Oral rehydration therapy has been extensively used since the 1970s to treat cholera and other diarrhea-inducing infections.
The sexual revolution included taboo-breaking research in human sexuality such as the 1948 and 1953 Kinsey reports, invention of hormonal contraception, ant the normalization of abortion and homosexuality in many countries. Family planning has promoted a demographic transition in most of the world. With threatening sexually transmitted infections, not least HIV, use of barrier contraception has become imperative. The struggle against HIV has improved antiretroviral treatments, and in the late 2000s (decade), male circumcision was cited to diminish infection risk (see circumcision and HIV).
X-ray imaging was the first kind of medical imaging, and later ultrasonic imaging, CT scanning, MR scanning and other imaging methods became available.
Genetics have advanced with the discovery of the DNA molecule, genetic mapping and gene therapy. Stem cell research took off in the 2000s (decade), with stem cell therapy as a promising method.
Evidence-based medicine is a modern concept, not introduced to literature until the 1990s.
Prosthetics have improved. In 1958, Arne Larsson in Sweden became the first patient to depend on an artificial cardiac pacemaker. He died in 2001 at age 86, having outlived its inventor, the surgeon, and 26 pacemakers. Lightweight materials as well as neural prosthetics emerged in the end of the 20th century.
Modern surgery.
Cardiac surgery was revolutionized in the 1948 as open-heart surgery was introduced for the first time since 1925.
In 1954 Joseph Murray, J. Hartwell Harrison and others accomplished the first kidney transplantation. Transplantations of other organs, such as heart, liver and pancreas, were also introduced during the latter 20th century. The first partial face transplant was performed in 2005, and the first full one in 2010. By the end of the 20th century, microtechnology had been used to create tiny robotic devices to assist microsurgery using micro-video and fiber-optic cameras to view internal tissues during surgery with minimally invasive practices.
Laparoscopic surgery was broadly introduced in the 1990s. Natural orifice surgery has followed. Remote surgery is another recent development, with the Lindbergh operation in 2001 as a groundbreaking example.

</doc>
<doc id="14196" url="https://en.wikipedia.org/wiki?curid=14196" title="Hamoaze">
Hamoaze

The Hamoaze (; ) is an estuarine stretch of the tidal River Tamar, between its confluence with the River Lynher and Plymouth Sound, England.
The name first appears as "ryver of Hamose" in 1588 and it originally most likely applied just to a creek of the estuary that led up to the manor of Ham, north of the present-day Devonport Dockyard. The name evidently later came to be used for the estuary's main channel. The "ose" element possibly derives from Old English "wāse" meaning 'mud' (as in 'ooze') – the creek consisting of mud-banks at low tide – although this is not confirmed.
The Hamoaze flows past Devonport Dockyard, which is one of three major bases of the Royal Navy today. The presence of large numbers of small watercraft are a challenge and hazard to the warships using the naval base and dockyard. Navigation on the waterway is controlled by the Queen's Harbour Master for Plymouth.
Settlements on the banks of the Hamoaze are Saltash, Wilcove, Torpoint and Cremyll in Cornwall, as well as Devonport and Plymouth in Devon.
Two regular ferry services crossing the Hamoaze exist: the Torpoint Ferry (a chain ferry that takes vehicles) and the Cremyll Ferry (passengers and cyclists only).

</doc>
<doc id="14197" url="https://en.wikipedia.org/wiki?curid=14197" title="Hanover">
Hanover

Hanover or Hannover (; , ), on the River Leine, is the capital of the federal state of Lower Saxony ("Niedersachsen"), Germany and was once by personal union the family seat of the Hanoverian Kings of Great Britain, under their title as the dukes of Brunswick-Lüneburg (later described as the Elector of Hanover). At the end of the Napoleonic Wars, the Electorate was enlarged to become the capital of the Kingdom of Hanover.
From 1868 to 1946 Hanover was the capital of the Prussian Province of Hanover and also of the Hanover administrative region until that was abolished in 2005. It is now the capital of the "Land" of Lower Saxony. Since 2001 it has been part of the Hanover district ("Region Hannover"), which is a municipal body made up from the former district ("Landkreis Hannover") and city of Hanover (note: although both "Region" and "Landkreis" are translated as "district" they are not the same).
With a population of 518,000, Hanover is a major centre of Northern Germany and the country's thirteenth largest city. Hanover also hosts annual commercial trade fairs such as the Hanover Fair and the CeBIT. Every year Hanover hosts the Schützenfest Hannover, the world's largest marksmen's festival, and the Oktoberfest Hannover, the second largest Oktoberfest in the world (beside Oktoberfest of Blumenau). In 2000, Hanover hosted the world fair Expo 2000. The Hanover fairground, due to numerous extensions, especially for the Expo 2000, is the largest in the world. Hanover is of national importance because of its universities and medical school, its international airport and its large zoo. The city is also a major crossing point of railway lines and highways (Autobahnen), connecting European main lines in both the east-west (Berlin–Ruhr area) and north-south (Hamburg–Munich, etc.) directions.
"Hanover" is the traditional English spelling. The German spelling (with a double n) is becoming more popular in English; recent editions of encyclopaedias prefer the German spelling, and the local government uses the German spelling on English websites. The English pronunciation , with stress on the first syllable and a reduced second syllable, is applied to both the German and English spellings, which is different from German pronunciation , with stress on the second syllable and a long second vowel. The traditional English spelling is still used in historical contexts, especially when referring to the British House of Hanover.
History.
Hanover was founded in medieval times on the east bank of the River Leine. Its original name "Honovere" may mean "high (river)bank", though this is debated (cf. "das Hohe Ufer"). Hanover was a small village of ferrymen and fishermen that became a comparatively large town in the 13th century due to its position at a natural crossroads. As overland travel was relatively difficult, its position on the upper navigable reaches of the river helped it to grow by increasing trade. It was connected to the Hanseatic League city of Bremen by the Leine, and was situated near the southern edge of the wide North German Plain and north-west of the Harz mountains, so that east-west traffic such as mule trains passed through it. Hanover was thus a gateway to the Rhine, Ruhr and Saar river valleys, their industrial areas which grew up to the southwest and the plains regions to the east and north, for overland traffic skirting the Harz between the Low Countries and Saxony or Thuringia.
In the 14th century the main churches of Hanover were built, as well as a city wall with three city gates. The beginning of industrialization in Germany led to trade in iron and silver from the northern Harz Mountains, which increased the city's importance.
In 1636 George, Duke of Brunswick-Lüneburg, ruler of the Brunswick-Lüneburg principality of Calenberg, moved his residence to Hanover. The Dukes of Brunswick-Lüneburg were elevated by the Holy Roman Emperor to the rank of Prince-Elector in 1692, and this elevation was confirmed by the Imperial Diet in 1708. Thus the principality was upgraded to the Electorate of Brunswick-Lüneburg, colloquially known as the Electorate of Hanover after Calenberg's capital (see also: House of Hanover). Its electors would later become monarchs of Great Britain (and from 1801, of the United Kingdom of Great Britain and Ireland). The first of these was George I Louis, who acceded to the British throne in 1714. The last British monarch who ruled in Hanover was William IV. Semi-Salic law, which required succession by the male line if possible, forbade the accession of Queen Victoria in Hanover. As a male-line descendant of George I, Queen Victoria was herself a member of the House of Hanover. Her descendants, however, bore her husband's titular name of Saxe-Coburg-Gotha. Three kings of Great Britain, or the United Kingdom, were concurrently also Electoral Princes of Hanover.
During the time of the personal union of the crowns of the United Kingdom and Hanover (1714–1837), the monarchs rarely visited the city. In fact, during the reigns of the final three joint rulers (1760–1837), there was only one short visit, by George IV in 1821. From 1816 to 1837 Viceroy Adolphus represented the monarch in Hanover.
During the Seven Years' War, the Battle of Hastenbeck was fought near the city on 26 July 1757. The French army defeated the Hanoverian Army of Observation, leading to the city's occupation as part of the Invasion of Hanover. It was recaptured by Anglo-German forces led by Ferdinand of Brunswick the following year.
19th century.
After Napoleon imposed the Convention of Artlenburg (Convention of the Elbe) on July 5, 1803, about 30,000 French soldiers occupied Hanover. The Convention also required disbanding the army of Hanover. However, George III did not recognize the Convention of the Elbe. This resulted in a great number of soldiers from Hanover eventually emigrating to Great Britain, where the King's German Legion was formed. It was the only German army to fight against France throughout the entire Napoleonic wars. The Legion later played an important role in the Battle of Waterloo in 1815. The Congress of Vienna in 1815 elevated the electorate to the Kingdom of Hanover. The capital town Hanover expanded to the western bank of the Leine and since then has grown considerably.
In 1837, the personal union of the United Kingdom and Hanover ended because William IV's heir in the United Kingdom was female (Queen Victoria). Hanover could be inherited only by male heirs. Thus, Hanover passed to William IV's brother, Ernest Augustus, and remained a kingdom until 1866, when it was annexed by Prussia during the Austro-Prussian war. Despite being expected to defeat Prussia at the Battle of Langensalza, Prussia employed Moltke the Elder's Kesselschlacht order of battle to instead destroy the Hanoverian army. The city of Hanover became the capital of the Prussian Province of Hanover. After the annexation, the people of Hanover generally opposed the Prussian government.
For Hanover's industry, however, the new connection with Prussia meant an improvement in business. The introduction of free trade promoted economic growth, and led to the recovery of the Gründerzeit (the founders' era). Between 1871 and 1912 Hanover's population grew from 87,600 to 313,400.
In 1872 the first horse railway was inaugurated, and from 1893 an electric tram was installed. In 1887 Hanover's Emile Berliner invented the record and the gramophone.
Nazi Germany.
After 1937 the Lord Mayor and the state commissioners of Hanover were members of the NSDAP (Nazi party). A large Jewish population then existed in Hanover. In October 1938, 484 Hanoverian Jews of Polish origin were expelled to Poland, including the Grynszpan family. However, Poland refused to accept them, leaving them stranded at the border with thousands of other Polish-Jewish deportees, fed only intermittently by the Polish Red Cross and Jewish welfare organisations. The Gryszpan's son Herschel Grynszpan was in Paris at the time. When he learned of what was happening, he drove to the German embassy in Paris and shot the German diplomat Eduard Ernst vom Rath, who died shortly afterwards.
The Nazis took this act as a pretext to stage a nationwide pogrom known as Kristallnacht. It was in Hanover on 9 November 1938 that the synagogue, designed in 1870 by Edwin Oppler in neo-romantic style, was burnt by the Nazis.
In September 1941, through the "Action Lauterbacher" plan, a ghettoisation of the remaining Hanoverian Jewish families began. Even before the Wannsee Conference, on 15 December 1941, the first Jews from Hanover were deported to Riga. A total of 2,400 people were deported, and very few survived. During the war seven concentration camps were constructed in Hanover, in which many Jews were confined. Of the approximately 4,800 Jews who had lived in Hannover in 1938, fewer than 100 were still in the city when troops of the United States Army arrived on 10 April 1945 to occupy Hanover at the end of the war. Today, a memorial at the Opera Square is a reminder of the persecution of the Jews in Hanover. 
After the war a large group of Orthodox Jewish survivors of the nearby Bergen-Belsen concentration camp settled in Hanover.
World War II.
As an important railroad and road junction and production center, Hanover was a major target for strategic bombing during World War II, including the Oil Campaign. Targets included the AFA (Stöcken), the Deurag-Nerag refinery (Misburg), the Continental plants (Vahrenwald and Limmer), the United light metal works (VLW) in Ricklingen and Laatzen (today Hanover fairground), the Hanover/Limmer rubber reclamation plant, the Hanomag factory (Linden) and the tank factory "M.N.H. Maschinenfabrik Niedersachsen" (Badenstedt). Forced labourers were sometimes used from the Hannover-Misburg subcamp of the Neuengamme concentration camp. Residential areas were also targeted, and more than 6,000 civilians were killed by the Allied bombing raids. More than 90% of the city center was destroyed in a total of 88 bombing raids. After the war, the Aegidienkirche was not rebuilt and its ruins were left as a war memorial.
The Allied ground advance into Germany reached Hanover in April 1945. The US 84th Infantry Division captured the city on 10 April 1945.
Hanover was in the British zone of occupation of Germany, and became part of the new state (Land) of Lower Saxony in 1946.
Today Hanover is a Vice-President City of Mayors for Peace, an international mayoral organisation mobilising cities and citizens worldwide to abolish and eliminate nuclear weapons by the year 2020.
Geography.
Climate.
Hanover experiences an oceanic climate (Köppen climate classification "Cfb").
Main sights.
One of the most famous sights is the "Royal Gardens of Herrenhausen":
The "Great Garden" is an important European baroque garden. The palace itself, however, was largely destroyed by Allied bombing but is currently under reconstruction. Some points of interest are the "Grotto" (the interior was designed by the French artist Niki de Saint-Phalle), the "Gallery Building", the "Orangerie" and the two pavilions by Remy de la Fosse. The Great Garden consists of several parts. The most popular ones are the "Great Ground" and the "Nouveau Jardin". At the centre of the Nouveau Jardin is Europe's highest garden fountain. The historic "Garden Theatre" "inter alia" hosted the musicals of the German rock musician Heinz Rudolf Kunze.
The "Berggarten" is an important European botanical garden. Some points of interest are the "Tropical House", the "Cactus House", the "Canary House" and the "Orchid House", which hosts one of the world's biggest collection of orchids, and free-flying birds and butterflies. Near the entrance to the Berggarten is the historic "Library Pavillon". The "Mausoleum" of the Guelphs is also located in the Berggarten. Like the Great Garden, the Berggarten also consists of several parts, for example the "Paradies" and the "Prairie Garden". There is also the "Sea Life Centre Hanover", which is the first tropical aquarium in Germany.
The "Georgengarten" is an English landscape garden. The "Leibniz Temple" and the "Georgen Palace" are two points of interest there.
The landmark of Hanover is the New Town Hall ("Neues Rathaus"). Inside the building are four scale models of the city. A worldwide unique diagonal/arch elevator goes up the large dome to an observation deck.
The "Hanover Zoo" is one of the most spectacular and best zoos in Europe. The zoo received the Park Scout Award for the fourth year running in 2009/10, placing it among the best zoos in Germany.
The zoo consists of several theme areas: Sambesi, Meyers Farm, Gorilla-Mountain, Jungle-Palace, and Mullewapp. Some smaller areas are Australia, the wooded area for wolves, and the so-called swimming area with many seabirds. There is also a tropical house, a jungle house, and a show arena. The new Canadian-themed area, Yukon Bay, opened in 2010. In 2010 the Hanover Zoo had over 1.6 million visitors.
Another point of interest is the "Old Town". In the centre are the large Marktkirche (Church St. Georgii et Jacobi, preaching venue of the bishop of the Lutheran Landeskirche Hannovers) and the "Old Town Hall". Nearby are the "Leibniz House", the "Nolte House", and the "Beguine Tower". A very nice quarter of the Old Town is the "Kreuz-Church-Quarter" around the "Kreuz Church" with many nice little lanes. Nearby is the old royal sports hall, now called the "Ballhof" theatre. On the edge of the Old Town are the "Market Hall", the "Leine Palace", and the ruin of the "Aegidien Church" which is now a monument to the victims of war and violence. Through the "Marstall Gate" you arrive at the bank of the river "Leine", where the world-famous "Nanas" of Niki de Saint-Phalle are located. They are part of the "Mile of Sculptures", which starts from Trammplatz, leads along the river bank, crosses Königsworther Square, and ends at the entrance of the Georgengarten. Near the Old Town is the district of Calenberger Neustadt where the Catholic Basilica Minor of "St. Clemens", the "Reformed Church" and the Lutheran Neustädter Hof- und Stadtkirche St. Johannis are located.
Some other popular sights are the "Waterloo Column", the "Laves House", the "Wangenheim Palace", the "Lower Saxony State Archives", the "Hanover Playhouse", the "Kröpcke Clock", the "Anzeiger Tower Block", the "Administration Building of the NORD/LB", the "Cupola Hall" of the Congress Centre, the "Lower Saxony Stock", the "Ministry of Finance", the "Garten Church", the "Luther Church", the "Gehry Tower" (designed by the American architect Frank O. Gehry), the specially designed "Bus Stops", the "Opera House", "the Central Station", the "Maschsee" lake and the city forest "Eilenriede", which is one of the largest of its kind in Europe. With around 40 parks, forests and gardens, a couple of lakes, two rivers and one canal, Hanover offers a large variety of leisure activities.
Since 2007 the historic "Leibniz Letters", which can be viewed in the "Gottfried Wilhelm Leibniz Library", are on UNESCO's Memory of the World Register.
Outside the city centre is the "EXPO-Park", the former site of EXPO 2000. Some points of interest are the "Planet M.", the former "German Pavillon", some nations' vacant pavilions, the "Expowale", the "EXPO-Plaza" and the "EXPO-Gardens" (Parc Agricole, EXPO-Park South and the Gardens of change). The fairground can be reached by the "Exponale", one of the largest pedestrian bridges in Europe.
The "Hanover fairground" is the largest Exhibition Centre in the world.
It provides 496,000 square metres of covered indoor space, 58,000 square metres of open-air space, 27 halls and pavilions. Many of the Exhibition Centre's halls are architectural highlights. Furthermore, it offers the Convention Center with its 35 function rooms, glassed-in areas between halls, grassy park-like recreation zones and its own heliport.
Two important sights on the fairground are the "Hermes Tower" (88.8 metres high) and the "EXPO Roof", the largest wooden roof in the world.
In the district of Anderten is the "European Cheese Centre", the only Cheese Experience Centre in Europe. Another tourist sight in Anderten is the "Hindenburg Lock", which was the biggest lock in Europe at the time of its construction in 1928. The "Tiergarten" (literally the "animals' garden") in the district of Kirchrode is a large forest originally used for deer and other game for the king's table.
In the district of Groß-Buchholz the 282-metre-high "Telemax" is located, which is the tallest building in Lower Saxony and the highest television tower in Northern Germany. Some other notable towers are the "VW-Tower" in the city centre and the old towers of the former middle-age defence belt: "Döhrener Tower", "Lister Tower" and the "Horse Tower".
The 36 most important sights of the city centre are connected with a -long red line, which is painted on the pavement. This so-called "Red Thread" marks out a walk that starts at the Tourist Information Office and ends on the Ernst-August-Square in front of the central station. There is also a guided sightseeing-bus tour through the city.
Society and culture.
Museums and galleries.
The "Historic Museum" describes the history of Hanover, from the medieval settlement "Honovere" to the world-famous Exhibition City of today. The museum focuses on the period from 1714 to 1834 when Hanover had a strong relationship with the British royal house.
With more than 4,000 members, the "Kestnergesellschaft" is the largest art society in Germany. The museum hosts exhibitions from classical modernist art to contemporary art. One big focus is put on film, video, contemporary music and architecture, room installments and big presentations of contemporary paintings, sculptures and video art.
The "Kestner-Museum" is located in the "House of 5.000 windows". The museum is named after August Kestner and exhibits 6,000 years of applied art in four areas: Ancient cultures, ancient Egypt, applied art and a valuable collection of historic coins.
The "KUBUS" is a forum for contemporary art. It features mostly exhibitions and projects of famous and important artists from Hanover.
The "Kunstverein Hannover" (Art Society Hanover) shows contemporary art and was established in 1832 as one of the first art societies in Germany. It is located in the "Künstlerhaus" (House of artists). There are around 7 international monografic and thematic Exhibitions in one year.
The "Lower Saxony State Museum" is the largest museum in Hanover. The "State Gallery" shows the European Art from the 11th to the 20th century, the "Nature Department" shows the zoology, geology, botanic, geology and a "Vivarium" with fishes, insects, reptiles and amphibians. The "Primeval Department" shows the primeval history of Lower Saxony and the "Folklore Department" shows the cultures from all over the world.
The "Sprengel Museum" shows the art of the 20th century. It is one of the most notable art museums in Germany. The focus is put on the classical modernist art with the collection of "Kurt Schwitters", works of German expressionism, and French cubism, the cabinet of abstracts, the graphics and the department of photography and media. Furthermore, the museum shows the famous works of the French artist Niki de Saint-Phalle.
The "Theatre Museum" shows an exhibition of the history of the theatre in Hanover from the 17th century up to now: opera, concert, drama and ballet. The museum also hosts several touring exhibitions during the year.
The "Wilhelm Busch Museum" is the "German Museum of Caricature and Critical Graphic Arts". The collection of the works of Wilhelm Busch and the extensive collection of cartoons and critical graphics is this museum unique in Germany. Furthermore, the museum hosts several exhibitions of national and international artists during the year.
A cabinet of coins is the "Münzkabinett der TUI-AG". The "Polizeigeschichtliche Sammlung Niedersachsen" is the largest police museum in Germany. Textiles from all over the world can be visited in the "Museum for textile art". The "EXPOseeum" is the museum of the world-exhibition "EXPO 2000 Hannover". Carpets and objects from the orient can be visited in the "Oriental Carpet Museum". The "Blind Man Museum" is a rarity in Germany, another one is only in Berlin. The "Museum of veterinary medicine" is unique in Germany. The "Museum for Energy History" describes the 150 years old history of the application of energy. The "Home Museum Ahlem" shows the history of the district of Ahlem. The "Mahn- und Gedenkstätte Ahlem" describes the history of the Jewish people in Hanover and the "Stiftung Ahlers Pro Arte / Kestner Pro Arte" shows modern art. Modern art is also the main topic of the "Kunsthalle Faust", the "Nord/LB Art Gellery" and of the "Foro Artistico / Eisfabrik".
Some leading art events in Hanover are the "Long Night of the museums" and the "Zinnober Kunstvolkslauf" which features all the galleries in Hanover.
People who are interested in astronomy should visit the "Observatory Geschwister Herrschel" on the Lindener Mountain or the small planetarium inside of the Bismarck School.
Theatre, cabaret and musical.
Around 40 theatres are located in Hanover. The "Opera House", the "Schauspielhaus" (Play House), the "Ballhofeins", the "Ballhofzwei" and the "Cumberlandsche Galerie" belong to the "Lower Saxony State Theatre". The "Theater am Aegi" is Hanover's big theatre for musicals, shows and guest performances. The "Neues Theater" (New Theatre) is the Boulevard Theatre of Hanover. The "Theater für Niedersachsen" is another big theatre in Hanover, which also has an own Musical-Company. Some of the most important Musical-Productions are the rock musicals of the German rock musician Heinz Rudolph Kunze, which take place at the "Garden-Theatre" in the Great Garden.
Some important theatre-events are the "Tanztheater International", the "Long Night of the Theatres", the "Festival Theaterformen" and the "International Competition for Choreographs".
Hanover's leading cabaret-stage is the "GOP Variety theatre" which is located in the "Georgs Palace". Some other famous cabaret-stages are the "Variety Marlene", the "Uhu-Theatre". the theatre "Die Hinterbühne", the "Rampenlich Variety" and the revue-stage "TAK". The most important Cabaret-Event is the "Kleines Fest im Großen Garten" (Little Festival in the Great Garden) which is the most successful Cabaret Festival in Germany. It features artists from around the world. Some other important events are the "Calenberger Cabaret Weeks", the "Hanover Cabaret Festival" and the "Wintervariety".
Music.
Classical Music.
Hanover has two symphony orchestras: The Lower Saxon State Orchestra Hanover and The North German Radio Philharmonic Orchestra (NDR Radiophilharmonie). Two notable choirs have their homes in Hanover: the Girls Choir Hanover (Mädchenchor Hannover) and the Boys Choir Hanover (Knabenchor Hannover).
Rock Music.
The rock bands Scorpions and Fury in the Slaughterhouse are originally from Hanover. Acclaimed DJ Mousse T also has his main recording studio in the area. Rick J. Jordan, member of the band Scooter was born here in 1968. Eurovision Song Contest winner of 2010, Lena (Lena Meyer-Landrut), is also from Hanover.
There are/were two big international competitions for classical music in Hanover:
Sport.
Hannover 96 (nickname "Die Roten" or 'The Reds') is the top local football team that plays in the Bundesliga top division. Home games are played at the HDI-Arena, which hosted matches in the 1974 and 2006 World Cups and the Euro 1988. Their reserve team "Hannover 96 II" plays in the fourth league. Their home games were played in the traditional "Eilenriedestadium" till they moved to the HDI Arena due to DFL directives. "Arminia Hannover" is another very traditional soccer team in Hanover that has played in the first league for years and plays now in the "Niedersachsen-West Liga" (Lower Saxony League West). Home matches are played in the "Rudolf-Kalweit-Stadium".
The Hannover Indians are the local ice hockey team. They play in the third tier. Their home games are played at the traditional Eisstadion am Pferdeturm. The Hannover Scorpions played in Hanover in Germany's top league until 2013 when they sold their license and moved to Langenhagen.
Hanover is one of the Rugby union capitals in Germany. The first German Rugby team was founded in Hanover in 1878. Hanover-based teams dominated the German Rugby scene for a long time. "DRC Hannover" plays in the first division, and "SV Odin von 1905" as well as "SG 78/08 Hannover" play in the second division.
The first German Fencing Club was founded in Hanover in 1862. Today there are three more Fencing Clubs in Hanover.
Hanover is a centre for Water sports. Thanks to the lake "Maschsee", the rivers "Ihme" and "Leine" and to the channel "Mittellandkanal" Hanover hosts sailing schools, yacht schools, waterski clubs, rowing clubs, canoe clubs and paddle clubs. The water polo team "WASPO W98" plays in the first division.
The "Hannover Regents" play in the third Bundesliga (baseball) division.
The "Hannover Grizzlies" are the local American Football Team.
The "Hannover Marathon" is the biggest running event in Hanover with more than 11.000 participants and usually around 200.000 spectators. Some other important running events are the "Gilde Stadtstaffel" (relay), the "Sport-Check Nachtlauf" (night-running), the "Herrenhäuser Team-Challenge", the "Hannoversche Firmenlauf" (company running) and the "Silvesterlauf" (sylvester running).
Hanover hosts also an important international cycle race: The "Nacht von Hannover" (night of Hanover). The race takes place around the Market Hall.
The lake "Maschsee" hosts the "International Dragon Boat Races" and the "Canoe　Polo-Tournament". Many regattas take place during the year. "Head of the river Leine" on the river "Leine" is one of the biggest rowing regattas in Hanover.
One of Germanys most successful dragon boat teams, the All Sports Team Hannover, which has won since its foundation in year 2000 more than 100 medals on national and international competitions, is doing practising on the Maschsee in the heart of Hannover. The All Sports Team has received the award "Team of the Year 2013" in Lower Saxony 
Some other important sport events are the "Lower Saxony Beach Volleyball Tournament", the international horse show "German Classics" and the international ice hockey tournament "Nations Cup".
Regular events.
Hanover is one of the leading Exhibition Cities in the world. Each year Hanover hosts more than 60 international and national exhibitions. The most popular ones are the "CeBIT", the "Hanover Fair", the "Domotex", the "Ligna", the "IAA Nutzfahrzeuge" and the "Agritechnica". Hanover also hosts a huge number of congresses and symposiums like "International Symposium on Society and Resource Management"
But Hanover is not only one of the most important Exhibition Cities in the world, it is also one of the German capitals for marksmen. The "Schützenfest Hannover" is the largest Marksmen's Fun Fair in the world and takes place once a year (late June to early July) (2014 - July 4th to the 13th). It consists of more than 260 rides and inns, five large beer tents and a big entertainment programme. The highlight of this fun fair is the long "Parade of the Marksmen" with more than 12.000 participants from all over the world, among them around 5.000 marksmen, 128 bands and more than 70 wagons, carriages and big festival vehicles. It is the longest procession in Europe. Around 2 million people visit this fun fair every year. The landmark of this Fun Fair is the biggest transportable Ferris Wheel in the world ( high). The origins of this fun fair is located in the year 1529.
Hanover also hosts one of the two largest Spring Festivals in Europe with around 180 rides and inns, 2 large beer tents and around 1.5 million visitors each year. The Oktoberfest Hannover is the second largest Oktoberfest in the world with around 160 rides and inns, two large beer tents and around 1 million visitors each year.
The "Maschsee Festival" takes place around the Maschsee Lake. Each year around 2 million visitors come to enjoy live music, comedy, cabaret and much more. It is the largest Volksfest of its kind in Northern Germany.
The Great Garden hosts every year the "International Fireworks Competition", and the "International Festival Weeks Herrenhausen" with lots of music and cabaret.
The "Carnival Procession" is around long and consists of 3.000 participants, around 30 festival vehicles and around 20 bands and takes place every year.
Some more festivals are for example the Festival "Feuer und Flamme" (Fire and Flames), the "Gartenfestival" (Garden Festival), the "Herbstfestival" (Autumn Festival), the "Harley Days", the "Steintor Festival" (Steintor is a party area in the city centre) and the "Lister-Meile-Festival" (Lister Meile is a large pedestrian area).
Hanover also hosts Food Festivals, for example the "Wine Festival" and the "Gourmet Festival".
Furthermore, Hanover hosts some special markets. The "Old Town Flea Market" is the oldest flea market in Germany and the "Market for Art and Trade" has a high reputation. Some other big markets are of course the "Christmas Markets of the City of Hanover" in the Old Town and city centre and the Lister Meile.
Transport.
Rail.
The city's central station, Hannover Hauptbahnhof, is a hub of the German high-speed ICE network. It is the starting point of the Hanover-Würzburg high-speed rail line and also the central hub for the Hanover S-Bahn. It offers many international and national connections.
Air.
Hanover and its area is served by Hanover/Langenhagen International Airport (IATA code: HAJ; ICAO code: EDDV)
Road.
Hanover is also an important hub of Germany's Autobahn network; the junction of two major autobahns, the A2 and A7 is at "Kreuz Hannover-Ost", at the northeastern edge of the city.
Local autobahns are A 352 (a short cut between A7 (north) and A2 (west), also known as the "airport autobahn" because it passes "Hanover Airport") and the A 37.
The Schnellweg "(en: expressway)" system, a number of Bundesstraße roads, forms a structure loosely resembling a large ring road together with A2 and A7. The roads are B 3, B 6 and B 65, called Westschnellweg (B6 on the northern part, B3 on the southern part), Messeschnellweg (B3, becomes A37 near Burgdorf, crosses A2, becomes B3 again, changes to B6 at "Seelhorster Kreuz", then passes the Hanover fairground as B6 and becomes A37 again before merging into A7) and Südschnellweg (starts out as B65, becomes B3/B6/B65 upon crossing "Westschnellweg", then becomes B65 again at "Seelhorster Kreuz").
Bus and light rail.
Hanover has an extensive Stadtbahn and bus system, operated by üstra. The city is famous for its designer buses and tramways, the TW 6000 and TW 2000 trams being the most well-known examples.
Bicycle.
Cycle paths are very common in the city centre. At off-peak hours you are allowed to take your bike on a tram or bus.
Economy.
Various industrial businesses are located in Hannover. The Volkswagen Commercial Vehicles Transporter (VWN) factory at Hannover-Stöcken is the biggest employer in the region and operates a huge plant at the northern edge of town adjoining the Mittellandkanal and Motorway A2. Jointly with a factory of German tire and automobile parts manufacturer Continental AG, they have a coal-burning power plant. Continental AG, founded in Hanover in 1871, is one of the city's major companies, as is Sennheiser. Since 2008 a take-over is in progress: the Schaeffler Group from Herzogenaurach (Bavaria) holds the majority of the stock but were required due to the financial crisis to deposit the options as securities at banks.
TUI AG has its HQ in Hanover.
Hanover is home to many insurance companies, many of which operate only in Germany. One major global reinsurance company is Hannover Re, whose headquarters are east of the city centre.
Key figures.
In 2012, the city generated a GDP of €29,5 million which is equivalent to €74,822 per employee. The Gross value of production in 2012 was €26,4 million which is equivalent to €66,822 per employee.
Around 300,000 employees were counted in 2014. 189,000 of these had their primary residence in Hanover while 164,892 commute into the city every day.
In 2014 the city was home to 34,198 businesses, of which 9,342 were registered in the German Trade Register and 24,856 counted as small businesses. Hence, more than half of the metropolitan area's businesses in the German Trade Register are located in Hanover (17,485 total).
Business development.
Hannoverimpuls is a joint business development company from the city and region of Hannover. The company was founded in 2003 and supports the start-up, growth and relocation of businesses in the Hannover Region. The focus is on seven sectors, which stand for sustainable economic growth: Automotive, Energy Solutions, Information and Communications Technology, Life Sciences, Optical Technologies, Creative Industries and Production Engineering.
A range of programmes supports companies from the key industries in their expansion plans in Hannover or abroad. Three regional centres specifically promote international economic relations with Russia, India and Turkey.
Education.
The Leibniz University Hannover is the largest funded institution in Hanover for providing higher education to the students from around the world. Below are the names of the universities and some of the important schools including newly opened Hannover Medical Research School in 2003 for attracting the students from biology background from around the world.
There are several universities in Hanover:
There is one University of Applied Science and Arts in Hanover:
The "Schulbiologiezentrum Hannover" maintains practical biology schools in four locations (Botanischer Schulgarten Burg, Freiluftschule Burg, Zooschule Hannover, and Botanischer Schulgarten Linden). The University of Veterinary Medicine Hanover also maintains its own botanical garden specializing in medicinal and poisonous plants, the Heil- und Giftpflanzengarten der Tierärztlichen Hochschule Hannover.
People and residents of Hanover.
The following is a selection of famous Hanover-natives, personalities connected with the city and honorary citizens:
International relations.
Hanover is twinned with:

</doc>
<doc id="14199" url="https://en.wikipedia.org/wiki?curid=14199" title="Handheld game console">
Handheld game console

A handheld game console is a lightweight, portable video game console with a built-in screen, game controls, and speakers. Handheld game consoles are smaller than home video game consoles and contain the console, screen, speakers, and controls in one unit, allowing people to carry them and play them at any time or place.
In 1976, Mattel introduced the first handheld electronic game with the release of "Auto Race". Later, several companies—including Coleco and Milton Bradley—made their own single-game, lightweight table-top or handheld electronic game devices. The oldest true handheld game console with interchangeable cartridges is the Milton Bradley Microvision in 1979.
Nintendo is credited with popularizing the handheld console concept with the release of the Game Boy in 1989 and as of 2014 continues to dominate the handheld console market with their Nintendo 2DS and 3DS systems.
History.
Origins.
The origins of handheld game consoles are found in handheld and tabletop electronic game devices of the 1970s and early 1980s. These electronic devices are capable of playing only a single game, they fit in the palm of the hand or on a tabletop, and they may make use of a variety of video displays such as LED, VFD, or LCD. In 1978, handheld electronic games were described by "Popular Electronics" magazine as "nonvideo electronic games" and "non-TV games" as distinct from devices that required use of a television screen. Handheld electronic games, in turn, find their origins in the synthesis of previous handheld and tabletop electro-mechanical devices such as Waco's "Electronic Tic-Tac-Toe" (1972) Cragstan's "Periscope-Firing Range" (1951), and the emerging optoelectronic-display-driven calculator market of the early 1970s. This synthesis happened in 1976, when "Mattel began work on a line of calculator-sized sports games that became the world's first handheld electronic games. The project began when Michael Katz, Mattel's new product category marketing director, told the engineers in the electronics group to design a game the size of a calculator, using LED (light-emitting diode) technology."
The result was the 1976 release of "Auto Race". Followed by "Football" later the same year, the two games were so successful that according to Katz, "these simple electronic handheld games turned into a '$400 million category.'" Mattel would later win the honor of being recognized by the industry for innovation in handheld game device displays. Soon, other manufacturers including Coleco, Parker Brothers, Milton Bradley, Entex, and Bandai began following up with their own tabletop and handheld electronic games.
In 1979 the LCD-based Microvision, designed by Smith Engineering and distributed by Milton-Bradley, became the first handheld game console and the first to use interchangeable game cartridges. The Microvision game "Cosmic Hunter" (1981) also introduced the concept of a directional pad on handheld gaming devices, and is operated by using the thumb to manipulate the on-screen character in any of four directions.
In 1979, Gunpei Yokoi, traveling on a bullet train, saw a bored businessman playing with an LCD calculator by pressing the buttons. Yokoi then thought of an idea for a watch that doubled as a miniature game machine for killing time. Starting in 1980, Nintendo began to release a series of electronic games designed by Yokoi called the Game & Watch games. Taking advantage of the technology used in the credit-card-sized calculators that had appeared on the market, Yokoi designed the series of LCD-based games to include a digital time display in the corner of the screen. For later, more complicated Game & Watch games, Yokoi invented a cross shaped directional pad or "D-pad" for control of on-screen characters. Yokoi also included his directional pad on the NES controllers, and the cross-shaped thumb controller soon became standard on game console controllers and ubiquitous across the video game industry as a replacement for the joystick. When Yokoi began designing Nintendo's first handheld game console, he came up with a device that married the elements of his Game & Watch devices and the Famicom console, including both items' D-pad controller. The result was the Nintendo Game Boy.
In 1982, the Bandai LCD Solarpower was the first solar-powered gaming device. Some of its games, such as the horror-themed game "Terror House", featured two LCD panels, one stacked on the other, for an early 3D effect. In 1983, Takara Tomy's Tomytronic 3D simulated 3D by having two LED panels that were lit by external light through a window on top of the device, making it the first dedicated home video 3D hardware.
Beginnings.
The late 1980s and early 1990s saw the beginnings of the handheld game console industry as we know it, after the demise of the Microvision. As backlit LCD game consoles with color graphics consume a lot of power, they were not battery-friendly like the non-backlit original Game Boy whose monochrome graphics allowed longer battery life. By this point, rechargeable battery technology had not yet matured and so the more advanced game consoles of the time such as the Sega Game Gear and Atari Lynx did not have nearly as much success as the Game Boy.
Even though third-party rechargeable batteries were available for the battery-hungry alternatives to the Game Boy, these batteries employed a nickel-cadmium process and had to be completely discharged before being recharged to ensure maximum efficiency; lead-acid batteries could be used with automobile circuit limiters (cigarette lighter plug devices); but the batteries had mediocre portability. The later NiMH batteries, which do not share this requirement for maximum efficiency, were not released until the late 1990s, years after the Game Gear, Atari Lynx, and original Game Boy had been discontinued. During the time when technologically superior handhelds had strict technical limitations, batteries had a very low mAh rating since batteries with heavy power density were not yet available.
Modern game systems such as the Nintendo DS and PlayStation Portable have rechargeable Lithium-Ion batteries with proprietary shapes. Other seventh-generation consoles such as the GP2X use standard alkaline batteries. Because the mAh rating of alkaline batteries has increased since the 1990s, the power needed for handhelds like the GP2X may be supplied by relatively few batteries.
Game Boy.
Nintendo released the Game Boy on April 21, 1989 (or in September 1990 for UK). The design team headed by Gunpei Yokoi had also been responsible for the Game & Watch system, as well as the Nintendo Entertainment System games "Metroid" and "Kid Icarus". The Game Boy came under scrutiny by some industry critics, saying that the monochrome screen was too small, and the processing power was inadequate. The design team had felt that low initial cost and battery economy were more important concerns, and when compared to the Microvision, the Game Boy was a huge leap forward.
Yokoi recognized that the Game Boy needed a killer app—at least one game that would define the console, and persuade customers to buy it. In June 1988, Minoru Arakawa, then-CEO of Nintendo of America saw a demonstration of the game "Tetris" at a trade show. Nintendo purchased the rights for the game, and packaged it with the Game Boy system. It was almost an immediate hit. By the end of the year more than a million units were sold in the US, and 25 million were sold by 1992. As of March 31, 2005, the Game Boy and Game Boy Color combined to sell 118.69 million units worldwide.
Atari Lynx.
In 1987, Epyx created the Handy Game; a device that would turn into the Atari Lynx in 1989. It was the first color handheld console ever made, as well as the first with a backlit screen. It also featured networking support with up to 17 other players, and advanced hardware that allowed the zooming and scaling of sprites. The Lynx could also be turned upside down to accommodate left-handed players. However, all these features came at a very high price point, which drove consumers to seek cheaper alternatives. The Lynx was also very unwieldy, consumed batteries very quickly, and lacked the third-party support enjoyed by its competitors. Due to its high price, short battery life, production shortages, a dearth of compelling games, and Nintendo's aggressive marketing campaign, and despite a redesign in 1991, the Lynx became a commercial failure. Despite this, companies like Telegames helped to keep the system alive long past its commercial relevance, and when new owner Hasbro released the rights to develop for the public domain, independent developers like Songbird have managed to release new commercial games for the system every year until 2004's "Winter Games".
TurboExpress.
The TurboExpress was a portable version of the TurboGrafx, released in 1990 for $249.99 (the price was briefly raised to $299.99, soon dropped back to $249.99, and by 1992 it was $199.99). Its Japanese equivalent was the PC Engine GT.
It was the most advanced handheld of its time and could play all the TurboGrafx-16's games (which were on a small, credit-card sized media called HuCards). It had a 66 mm (2.6 in.) screen, the same as the original Game Boy, but in a much higher resolution. And could display 64 sprites at once, 16 per scanline, in 512 colors. Although the hardware could only handle 481 simultaneous colors. It had 64 kilobytes of RAM. The Turbo ran its two 6820 CPUs at 3.58 MHz in parallel.
The optional "TurboVision" TV tuner included RCA audio/video input, allowing users to use TurboExpress as a video monitor. The "TurboLink" allowed two-player play. "Falcon", a flight simulator, included a "head-to-head" dogfight mode that could only be accessed via TurboLink. However, very few TG-16 games offered co-op play modes especially designed with the TurboExpress in mind.
Bitcorp Gamate.
The Bitcorp Gamate was the one of the first handheld game systems created in response to the Nintendo Game Boy. It was released in Asia in 1990 and distributed worldwide by 1991.
Like the Sega Game Gear, it was horizontal in orientation and like the Game Boy, required 4 AA batteries. Unlike many later Game Boy clones, its internal components were professionally assembled (no "glop-top" chips). Unfortunately the system's fatal flaw was its screen. Even by the standards of the day, its screen was rather difficult to use, suffering from similar motion blur problems that were common complaints with the first generation Game Boys. Likely because of this fact sales were quite poor, and Bitcorp closed by 1992. However, new games continued to be published for the Asian market, possibly as late as 1994. The total number of games released for the system remains unknown.
Interestingly, Gamate games were designed for stereo sound, but the console was only equipped with a mono speaker. To appreciate the full sound palette, a user must plug into the head phone jack. Doing so reveals very sophisticated music.
Game Gear.
The Game Gear was the third color handheld console produced by Sega, after the Lynx and the TurboExpress. Released in Japan in 1990 and in North America and Europe in 1991, it was based on the Master System, which gave Sega the ability to quickly create Game Gear games from its large library of games for the Master System. While never reaching the level of success enjoyed by Nintendo, the Game Gear proved to be a fairly durable competitor, lasting longer than any other Game Boy rivals.
While the Game Gear is most frequently seen in black or navy blue, it was also released in a variety of additional colors: red, light blue, yellow, clear, and violet. All of these variations were released in small quantities and frequently only in the Asian market.
Following Sega's success with the Game Gear, they began development on a successor during the early 1990s, which was intended to feature a touchscreen interface, many years before the Nintendo DS. However, such a technology was very expensive at the time, and the handheld itself was estimated to have cost around $289 were it to be released. Sega eventually chose to shelve the idea and instead release the Genesis Nomad, a handheld version of the Genesis, as the successor.
Watara Supervision.
The Watara Supervision was released in 1992 in an attempt to compete with the Nintendo Game Boy. The first model was designed very much like a Game Boy, but it was grey in color and had a slightly larger screen. The second model was made with a hinge across the center and could be bent slightly to provide greater comfort for the user. While the system did enjoy a modest degree of success, it never impacted the sales of Nintendo or Sega. The Supervision was redesigned a final time as "The Magnum". Released in limited quantities it was roughly equivalent to the Game Boy Pocket. It was available in three colors: yellow, green and grey. Watara designed many of the games themselves, but did receive some third party support, most notably from Sachen.
A TV adapter was available in both PAL and NTSC formats that could transfer the Supervision's black-and-white palette to 4 colors, similar in some regards to the Super Game Boy from Nintendo.
Hartung Game Master.
The Hartung Game Master was an obscure handheld released at an unknown point in the early 1990s. Its graphics were much lower than most of its contemporaries, similar in complexity to the Atari 2600. It was available in black, white, and purple, and was frequently rebranded by its distributors, such as Delplay, Videojet and Virella.
The exact number of games released is not known, but is likely around 20. The system most frequently turns up in Europe and Australia.
Late 1990s.
By this time, the lack of significant development in Nintendo's product line began allowing more advanced systems such as the Neo Geo Pocket Color and the WonderSwan Color to achieve moderate success.
Game.com.
The Game.com (pronounced in TV commercials as "game com", not "game dot com", and not capitalized in marketing material) was a handheld game console released by Tiger Electronics in September 1997. It featured many new ideas for handheld consoles and was aimed at an older target audience, sporting PDA-style features and functions such as a touch screen and stylus. However, Tiger hoped it would also challenge Nintendo's Game Boy and gain a following among younger gamers too. Unlike other handheld game consoles, the first game.com consoles included two slots for game cartridges, which would not happen again until the Tapwave Zodiac, the DS and DS Lite, and could be connected to a 14.4 kbit/s modem. Later models had only a single cartridge slot.
Game Boy Color.
The Game Boy Color (also referred to as GBC or CGB) is Nintendo's successor to the Game Boy and was released on October 21, 1998, in Japan and in November of the same year in the United States. It features a color screen, and is slightly bigger than the Game Boy Pocket. The processor is twice as fast as a Game Boy's and has twice as much memory. It also had an infrared communications port for wireless linking which did not appear in later versions of the Game Boy, such as the Game Boy Advance.
The Game Boy Color was a response to pressure from game developers for a new system, as they felt that the Game Boy, even in its latest incarnation, the Game Boy Pocket, was insufficient. The resulting product was backward compatible, a first for a handheld console system, and leveraged the large library of games and great installed base of the predecessor system. This became a major feature of the Game Boy line, since it allowed each new launch to begin with a significantly larger library than any of its competitors. As of March 31, 2005, the Game Boy and Game Boy Color combined to sell 118.69 million units worldwide.
The console was capable of displaying up to 56 different colors simultaneously on screen from its palette of 32,768, and could add basic four-color shading to games that had been developed for the original Game Boy. It could also give the sprites and backgrounds separate colors, for a total of more than four colors.
Neo Geo Pocket Color.
The Neo Geo Pocket Color (or NGPC) was released in 1999 in Japan, and later that year in the United States and Europe. It was a 16-bit color handheld game console designed by SNK, the maker of the Neo Geo home console and arcade machine. It came after SNK's original Neo Geo Pocket monochrome handheld, which debuted in 1998 in Japan.
In 2000 following SNK's purchase by Japanese Pachinko manufacturer Aruze, the Neo Geo Pocket Color was dropped from both the US and European markets, purportedly due to commercial failure.
The system seemed well on its way to being a success in the U.S. It was more successful than any Game Boy competitor since Sega's Game Gear, but was hurt by several factors, such as SNK's infamous lack of communication with third-party developers, and anticipation of the Game Boy Advance. The decision to ship U.S. games in cardboard boxes in a cost-cutting move rather than hard plastic cases that Japanese and European releases were shipped in may have also hurt US sales.
Wonderswan Color.
The WonderSwan Color is a handheld game console designed by Bandai. It was released on December 9, 2000, in Japan, and was a moderate success.
The original WonderSwan had only a black and white screen. Although the WonderSwan Color was slightly larger and heavier (7 mm and 2 g) compared to the original WonderSwan, the color version featured 512 kB of RAM and a larger color LCD screen. In addition, the WonderSwan Color is compatible with the original WonderSwan library of games.
Prior to WonderSwan's release, Nintendo had virtually a monopoly in the Japanese video game handheld market. After the release of the WonderSwan Color, Bandai took approximately 8% of the market share in Japan partly due to its low price of 6800 yen (approximately US$65).
Another reason for the WonderSwan's success in Japan was the fact that Bandai managed to get a deal with Square to port over the original Famicom "Final Fantasy" games with improved graphics and controls. However, with the popularity of the Game Boy Advance and the reconciliation between Square and Nintendo, the WonderSwan Color and its successor, the SwanCrystal quickly lost its competitive advantage.
Early 2000s.
The 2000s saw a major leap in innovation, particularly in the second half with the release of the DS and PSP.
Game Boy Advance.
In 2001, Nintendo released the Game Boy Advance (GBA or AGB), which added two shoulder buttons, a larger screen, and more computing power than the Game Boy Color.
The design was revised two years later when the Game Boy Advance SP (GBA SP), a more compact version, was released. The SP featured a "clamshell" design (folding open and closed, like a laptop computer), as well as a frontlit color display and rechargeable battery. Despite the smaller form factor, the screen remained the same size as that of the original. In 2005, the Game Boy Micro was released. This revision sacrificed screen size and backwards compatibility with previous Game Boys for a dramatic reduction in total size and a brighter backlit screen. A new SP model with a backlit screen was released in some regions around the same time.
Along with the Nintendo GameCube, the GBA also introduced the concept of "connectivity": using a handheld system as a console controller. A handful of games use this feature, most notably "Animal Crossing", "Pac-Man Vs.", "Final Fantasy Crystal Chronicles", ', ', "Metroid Prime", and "".
As of December 31, 2007, the GBA, GBA SP, and the Game Boy Micro combined have sold 80.72 million units worldwide.
Game Park 32.
The original GP32 was released in 2001 by the South Korean company Game Park a few months after the launch of the Game Boy Advance. It featured a 32-bit CPU, 133 MHz processor, MP3 and Divx player, and e-book reader. SmartMedia cards were used for storage, and could hold up to 128mb of anything downloaded through a USB cable from a PC. The GP32 was redesigned in 2003. A front-lit screen was added and the new version was called GP32 FLU (Front Light Unit). In summer 2004, another redesign, the GP32 BLU, was made, and added a backlit screen. This version of the handheld was planned for release outside South Korea; in Europe, and it was released for example in Spain (VirginPlay was the distributor). While not a commercial success on a level with mainstream handhelds (only 30,000 units were sold), it ended up being used mainly as a platform for user-made applications and emulators of other systems, being popular with developers and more technically adept users.
N-Gage.
Nokia released the N-Gage in 2003. It was designed as a combination MP3 player, cellphone, PDA, radio, and gaming device. The system received much criticism alleging defects in its physical design and layout, including its vertically oriented screen and requirement of removing the battery to change game cartridges. The most well known of these was "sidetalking", or the act of placing the phone speaker and receiver on an edge of the device instead of one of the flat sides, causing the user to appear as if they are speaking into a taco.
The N-Gage QD was later released to address the design flaws of the original. However, certain features available in the original N-Gage, including MP3 playback, FM radio reception, and USB connectivity were removed.
Second generation of N-Gage launched on April 3, 2008 in the form of a service for selected Nokia Smartphones.
Cybiko.
The Cybiko was a Russian hand-held computer introduced in May 2000 by David Yang's company and designed for teenage audiences, featuring its own two-way radio text messaging system. It had over 430 "official" freeware games and applications. Because of the text messaging system, it features a QWERTY keyboard that was used with a stylus. An MP3 player add-on was made for the unit as well as a SmartMedia card reader. The company stopped manufacturing the units after two product versions and only a few years on the market. Cybikos can communicate with each other up to a maximum range of 300 metres (0.19 miles). Several Cybikos can chat with each other in a wireless chatroom.
Cybiko Classic:
There were two models of the Classic Cybiko. Visually, the only difference was that the original version had a power switch on the side, whilst the updated version used the "escape" key for power management. Internally, the differences between the two models were in the internal memory, and the location of the firmware.
Cybiko Xtreme:
The Cybiko Xtreme was the second-generation Cybiko handheld. It featured various improvements over the original Cybiko, such as a faster processor, more RAM, more ROM, a new operating system, a new keyboard layout and case design, greater wireless range, a microphone, improved audio output, and smaller size.
Tapwave Zodiac.
In 2003, Tapwave released the Zodiac. It was designed to be a PDA-handheld game console hybrid. It supported photos, movies, music, Internet, and documents. The Zodiac used a special version Palm OS 5, 5.2T, that supported the special gaming buttons and graphics chip. Two versions were available, Zodiac 1 and 2, differing in memory and looks. The Zodiac line ended in July 2005 when Tapwave declared bankruptcy.
Mid 2000s.
Nintendo DS.
The Nintendo DS was released in November 2004. Among its new features were the incorporation of two screens, a touchscreen, wireless connectivity, and a microphone port. As with the Game Boy Advance SP, the DS features a clamshell design, with the two screens aligned vertically on either side of the hinge.
The DS's lower screen is touch sensitive, designed to be pressed with a stylus, a user's finger or a special "thumb pad" (a small plastic pad attached to the console's wrist strap, which can be affixed to the thumb to simulate an analog stick). More traditional controls include four face buttons, two shoulder buttons, a D-pad, and "Start" and "Select" buttons. The console also features online capabilities via the Nintendo Wi-Fi Connection and ad-hoc wireless networking for multiplayer games with up to sixteen players. It is backwards-compatible with all Game Boy Advance games, but not games designed for the Game Boy or Game Boy Color.
In January 2006, Nintendo revealed an updated version of the DS: the Nintendo DS Lite (released on March 2, 2006, in Japan) with an updated, smaller form factor (42% smaller and 21% lighter than the original Nintendo DS), a cleaner design, longer battery life, and brighter, higher-quality displays, with adjustable brightness. It is also able to connect wirelessly with Nintendo's Wii console.
In October 2008, Nintendo announced the Nintendo DSi, with larger, 3.25-inch screens and two integrated cameras. It has an SD card storage slot in place of the Game Boy Advance slot, plus internal flash memory for storing downloaded games. It was released on November 1, 2008, in Japan, and was released in North America April 5, 2009, and April 3, 2009, in Europe.
As of December 31, 2009, the Nintendo DS, Nintendo DS Lite and Nintendo DSi combined have sold 125.13 million units worldwide. In 2010 Nintendo released a larger version of the DSi, called the DSi XL.
Game King.
The GameKing was a handheld game console released by the Chinese company TimeTop in 2004. The first model while original in design owes a large debt to Nintendo's Game Boy Advance. The second model, the GameKing 2, is believed to be inspired by Sony's PSP. This model also was upgraded with a backlit screen, with a distracting background transparency (which can be removed by opening up the console). A color model, the GameKing 3 apparently exists, but was only made for a brief time and was difficult to purchase outside of Asia. Whether intentionally or not, the GameKing has the most primitive graphics of any handheld released since the Game Boy of 1989. 
As many of the games have an "old school" simplicity, the device has developed a small cult following. The Gameking's speaker is quite loud and the cartridges' sophisticated looping soundtracks (sampled from other sources) are seemingly at odds with its primitive graphics.
TimeTop made at least one additional device sometimes labeled as "GameKing", but while it seems to possess more advanced graphics, is essentially an emulator that plays a handful of multi-carts (like the GB Station Light II). Outside of Asia (especially China) however the Gameking remains relatively unheard of due to the enduring popularity of Japanese handhelds such as those manufactured by Nintendo and Sony.
PlayStation Portable.
The PlayStation Portable (officially abbreviated PSP) is a handheld game console manufactured and marketed by Sony Computer Entertainment. Development of the console was first announced during E3 2003, and it was unveiled on May 11, 2004, at a Sony press conference before E3 2004. The system was released in Japan on December 12, 2004, in North America on March 24, 2005, and in the PAL region on September 1, 2005.
The PlayStation Portable is the first handheld video game console to use an optical disc format, Universal Media Disc (UMD), for distribution of its games. UMD Video discs with movies and television shows were also released. The PSP utilized the Sony/SanDisk Memory Stick Pro Duo format as its primary storage medium. Other distinguishing features of the console include its large viewing screen, multi-media capabilities, and connectivity with the PlayStation 3, other PSPs, and the Internet.
Gizmondo.
Tiger's Gizmondo came out in the UK during March 2005 and it was released in the U.S. during October 2005. It is designed to play music, movies, and games, have a camera for taking and storing photos, and have GPS functions. It also has Internet capabilities. It has a phone for sending text and multimedia messages. Email was promised at launch, but was never released before Gizmondo, and ultimately Tiger Telematics', downfall in early 2006. Users obtained a second service pack, unreleased, hoping to find such functionality. However, Service Pack B did not activate the e-mail functionality.
GP2X Series.
The GP2X is an open-source, Linux-based handheld video game console and media player created by GamePark Holdings of South Korea, designed for homebrew developers as well as commercial developers. It is commonly used to run emulators for game consoles such as Neo-Geo, Genesis, Master System, Game Gear, Amstrad CPC, Commodore 64, Nintendo Entertainment System, TurboGrafx-16, MAME and others.
A new version called the "F200" was released October 30, 2007, and features a touchscreen, among other changes. Followed by GP2X Wiz (2009) and GP2X Caanoo (2010).
Late 2000s.
Dingoo.
The Dingoo A-320 is a micro-sized gaming handheld that resembles the Game Boy Micro and is open to game development. It also supports music, radio, emulators (8 bit and 16 bit) and video playing capabilities with its own interface much like the PSP. There is also an onboard radio and recording program. It is currently available in two colors — white and black. Other similar products from the same manufacturer are the Dingoo A-330 (also known as Geimi), Dingoo A-360, Dingoo A-380 (available in pink, white and black) and the recently released Dingoo A-320E.
PSP Go.
The PSP Go is a version of the PlayStation Portable handheld game console manufactured by Sony. It was released on October 1, 2009, in American and European territories, and on November 1 in Japan. It was revealed prior to E3 2009 through Sony's Qore VOD service. Although its design is significantly different from other PSPs, it is not intended to replace the PSP 3000, which Sony continued to manufacture, sell, and support. On April 20, 2011, the manufacturer announced that the PSP Go would be discontinued so that they may concentrate on the PlayStation Vita. Sony later said that only the European and Japanese versions were being cut, and that the console would still be available in the US.
Unlike previous PSP models, the PSP Go does not feature a UMD drive, but instead has 16 GB of internal flash memory to store games, video, pictures, and other media. This can be extended by up to 32 GB with the use of a Memory Stick Micro (M2) flash card. Also unlike previous PSP models, the PSP Go's rechargeable battery is not removable or replaceable by the user. The unit is 43% lighter and 56% smaller than the original PSP-1000, and 16% lighter and 35% smaller than the PSP-3000. It has a 3.8" 480 × 272 LCD (compared to the larger 4.3" 480 × 272 pixel LCD on previous PSP models). The screen slides up to reveal the main controls. The overall shape and sliding mechanism are similar to that of Sony's mylo COM-2 internet device.
Pandora.
The Pandora is a handheld game console/UMPC/PDA hybrid designed to take advantage of existing open source software and to be a target for home-brew development. It runs a full distribution of Linux, and in functionality is like a small PC with gaming controls. It is developed by OpenPandora, which is made up of former distributors and community members of the GP32 and GP2X handhelds.
OpenPandora began taking pre-orders for one batch of 4000 devices in November 2008 and after manufacturing delays, began shipping to customers on May 21, 2010.
FC-16 Go.
The FC-16 Go is a portable Super NES hardware clone manufactured by Yobo Gameware in 2009. It features a 3.5-inch display, two wireless controllers, and CRT cables that allow cartridges to be played on a television screen. Unlike other Super NES clone consoles, it has region tabs that only allow NTSC North American cartridges to be played. Later revisions feature stereo sound output, larger shoulder buttons, and a slightly re-arranged button, power, and A/V output layout.
2010s.
Nintendo 3DS.
The Nintendo 3DS is the successor to Nintendo's DS handheld. The autostereoscopic device is able to project stereoscopic three-dimensional effects without requirement of active shutter or passive polarized glasses, which are required by most current 3D televisions to display the 3D effect. The 3DS was released in Japan on February 26, 2011; in Europe on March 25, 2011; in North America on March 27, 2011, and in Australia on March 31, 2011. The system features backward compatibility with Nintendo DS series software, including Nintendo DSi software. It also features an online service called the Nintendo eShop, launched on June 6, 2011, in North America and June 7, 2011, in Europe and Japan, which allows owners to download games, demos, applications and information on upcoming film and game releases. On November 24, 2011, a limited edition Legend of Zelda 25th Anniversary 3DS was released that contained a unique Cosmo Black unit decorated with gold Legend of Zelda related imagery, along with a copy of The Legend of Zelda: Ocarina of Time 3D.
There are also other models including the Nintendo 2DS and the New Nintendo 3DS, the latter with a larger (XL/LL) variant, like the original Nintendo 3DS.
Xperia Play.
The Sony Ericsson Xperia PLAY is a handheld game console smartphone produced by Sony Ericsson under the Xperia smartphone brand. The device runs Android 2.3 Gingerbread, and is the first to be part of the PlayStation Certified program which means that it can play PlayStation Suite games. The device is a horizontally sliding phone with its original form resembling the Xperia X10 while the slider below resembles the slider of the PSP Go. The slider features a D-pad on the left side, a set of standard PlayStation buttons (, , and ) on the right, a long rectangular touchpad in the middle, start and select buttons on the bottom right corner, a menu button on the bottom left corner, and two shoulder buttons (L and R) on the back of the device. It is powered by a 1 GHz Qualcomm Snapdragon processor, a Qualcomm Adreno 205 GPU, and features a display measuring 4.0 inches (100 mm) (854 × 480), an 8-megapixel camera, 512 MB RAM, 8 GB internal storage, and a micro-USB connector. It supports microSD cards, versus the Memory Stick variants used in PSP consoles. The device was revealed officially for the first time in a Super Bowl ad on Sunday, February 6, 2011. On February 13, 2011, at Mobile World Congress (MWC) 2011, it was announced that the device would be shipping globally in March 2011, with a launch lineup of around 50 software titles.
PlayStation Vita.
The PlayStation Vita is the successor to Sony's PlayStation Portable (PSP) Handheld series. It was released in Japan on December 17, 2011 and in Europe, Australia, North and South America on February 22, 2012.
The handheld includes two analog sticks, a 5-inch (130 mm) OLED/LCD multi-touch capacitive touchscreen, and supports Bluetooth, Wi-Fi and optional 3G. Internally, the PS Vita features a 4 core ARM Cortex-A9 MPCore processor and a 4 core SGX543MP4+ graphics processing unit, as well as LiveArea software as its main user interface, which succeeds the XrossMediaBar.
The device is fully backwards-compatible with PlayStation Portable games digitally released on the PlayStation Network via the PlayStation Store. However, PSone Classics and PS2 titles were not compatible at the time of the primary public release in Japan. The Vita's dual analog sticks will be supported on selected PSP games. The graphics for PSP releases will be up-scaled, with a smoothing filter to reduce pixelation.
Razer Switchblade.
The Razer Switchblade was a prototype pocket-sized like a Nintendo DSi XL designed to run Windows 7, featured a multi-touch LCD screen and an adaptive keyboard that changed keys depending on the game you play. It also was to feature a full mouse.
It was first unveiled on January 5, 2011, on the Consumer Electronics Show (CES). The Switchblade won The Best of CES 2011 People's Voice award. It has since been in development and the release date is still unknown. The device has likely been suspended indefinitely.
Nvidia Shield.
Project Shield is a handheld system developed by Nvidia announced at CES 2013. It runs on Android 4.2 and uses Nvidia Tegra 4 SoC. The hardware includes a 5-inches multitouch screen with support for HD graphics (720p). The console allows for the streaming of games running on a compatible desktop PC, or laptop.

</doc>
<doc id="14200" url="https://en.wikipedia.org/wiki?curid=14200" title="Heinrich Abeken">
Heinrich Abeken

Heinrich Abeken (August 19, 1809 – August 8, 1872) was a German theologian and Prussian Privy Legation Councillor in the Ministry of Foreign Affairs in Berlin.
Abeken was born and raised in the city of Osnabrück as a son of a merchant, he was incited to a higher education by the example of his uncle Bernhard Rudolf Abeken. After finishing the college in Osnabrück, he moved in 1827 to visit the University of Berlin to study theology. He soon combined philosophical and philological studies and was interested in art and modern literature.
In 1831, Abeken acquired a licenciate of theology. At the end of the year he visited Rome, and was welcomed in the house of Christian Karl Josias, Freiherr von Bunsen. Abeken participated in Bunsen's works, namely an evangelic prayer and hymn-book. In 1834 became chaplain to the Prussian embassy in Rome. He married his first wife, who died soon thereafter.
Bunsen left Rome in 1838 and Abeken followed soon thereafter to Germany. In 1841, he was sent to England to help founding a German-English evangelic episcopacy in Jerusalem. In the same year, he was sent by Frederick William IV of Prussia to Egypt and Ethiopia, where he joined an expedition led by professor Karl Richard Lepsius. In 1845 and 1846 he returned via Jerusalem and Rome to Germany. He became Legation Councillor in Berlin, later Council Referee at the Ministry of Foreign Affairs.
In 1848 he received an appointment in the Prussian ministry for foreign affairs, and in 1853 was promoted to be privy councillor of legation ("Geheimer Legationsrath"). Abeken remained in charge for more than twenty years of Prussian politics, assisting Otto Theodor Freiherr von Manteuffel and Chancellor Otto von Bismarck. The latter was so much pleased with Abeken's work that officials started to call Abeken "the quill the scribe of Bismarck." Abeken married in 1866 Hedwig von Olfers, daughter of the general director of the royal museums, Privy Council von Olfers.
He was much employed by Bismarck in the writing of official despatches, and stood high in the favour of King William, whom he often accompanied on his journeys as representative of the foreign office. He was present with the king during the campaigns of 1866 and 1870-71. In 1851 he published anonymously "Babylon und Jerusalem," a slashing criticism of the views of the Countess von Hahn-Hahn.
During the war against Austria in 1866 as well as in the wars against France in 1870 and 1871, Abeken stayed in the Prussian headquarters. A major part of the dispatches of the time have been written by him. Unfortunately his health was damaged by the endeavours of these travels, and he died after an illness of several months. Emperor Wilhelm I described Abeken in a condolence letter to his widow: "One of my most reliable advisors, standing on my side in the most decisive moments; His loss is irreplaceable to me; In him his fatherland has lost one of the most noble and most loyal men and officials."
Despite his engagement in politics, Abeken never lost his interest in theology and continued to publish and speak in this sector during all of his life. He was interested in art and archeology, and was sponsor of the Archeological Institute of Rome and member of the Archeological Society of Rome. He founded a Circle of Friends of the Greek Literature in Berlin and was member of the prize commission for the royal Schiller-Prize.
See "Heinrich Abeken, ein schlichtes Leben in bewegter Zeit" (Berlin, 1898), by his widow. This is valuable by reason of the letters written from the Prussian headquarters.

</doc>
<doc id="14201" url="https://en.wikipedia.org/wiki?curid=14201" title="Henry Bruce, 1st Baron Aberdare">
Henry Bruce, 1st Baron Aberdare

Henry Austin Bruce, 1st Baron Aberdare (16 April 1815 – 25 February 1895) was a British Liberal Party politician, who served in government most notably as Home Secretary (1868–1873) and as Lord President of the Council.
Background and education.
Henry Bruce was born at Duffryn, Aberdare, Glamorganshire, the son of John Bruce, a Glamorganshire landowner, and his first wife Sarah, daughter of Reverend Hugh Williams Austin. John Bruce's original family name was Knight, but on coming of age in 1805 he assumed the name of Bruce: his mother, through whom he inherited the Duffryn estate, was the daughter of William Bruce, high sheriff of Glamorganshire.
Henry was educated from the age of twelve at the Bishop Gore School, Swansea (Swansea Grammar School). In 1837 he was called to the bar from Lincoln's Inn. Shortly after he had begun to practice, the discovery of coal beneath the Duffryn and other Aberdare Valley estates brought his family great wealth. From 1847 to 1854 Bruce was stipendiary magistrate for Merthyr Tydfil and Aberdare, resigning the position in the latter year, after entering parliament as Liberal member for Merthyr Tydfil.
Industrialist and politician, 1852–1868.
Bruce was returned unopposed as MP for Merthyr in December 1852, with the enthusiastic support of the late member's political allies, notably the iron masters of Dowlais, and he was thereafter regarded by his political opponents, most notably in the Aberdare Valley, as their nominee. Even os, Bruce's parliamentary record demonstrated support for liberal policies, with the exception of the ballot. The electorate in the constituency at this time remained relatively small, excluding the vast majority of the working classes. 
Significantly, however, Bruce's relationship with the miners of the Aberdare Valley, in particular, deteriorated as a result of the Aberdare Strike of 1857-8. In a speech to a large audience of miners at the Aberdare Market Hall, Bruce sought to strike a conciliatory tone in persuading the miners to return to work. In a second speech, however, he delivered a broadside against the trade union movement generally, referring to the violence engendered elsewhere as a result of strikes and to alleged examples of intimidation and violence in the immediate locality. The strike damaged his reputation and may well have contributed to his eventual election defeat ten years later.
In 1855, Bruce was appointed a trustee of the Dowlais Iron Company and played a role in the further development of the iron industry.
In November 1862, after nearly ten years in Parliament, he became Under-Secretary of State for the Home Department, and held that office until April 1864. He became a Privy Councillor and a Charity Commissioner for England and Wales in 1864.
1868 General Election.
At the 1868 General Election, Merthyr Tydfil became a two-member constituency with a much-increased electorate as a result of the Second Reform Act of 1867. Since the formation of the constituency, Merthyr Tydfil had dominated representation as the vast majority of the electorate lived in the town and its vicinity, whereas there was a much lower number of electors in the neighbouring Aberdare Valley. During the 1850s and 1860s, however, the population of Aberdare grew rapidly, and the franchise changes in 1867 gave the vote to large numbers of miners in that valley. Amongst these new electors, Bruce, as noted above, remained unpopular as a result of his actions during the 1857 -8 dispute. Initially, it appeared that the Aberdare iron master, Richard Fothergill, would be elected to the second seat alongside Bruce. However, the appearance of a third Liberal candidate, Henry Richard, a nonconformist radical popular in both Merthyr and Aberdare, left Bruce on the defensive and he was ultimately defeated, finishing in third place behind both Richard and Fothergill.
Later Political Career.
After losing his seat, Bruce was elected for Renfrewshire, he was made Home Secretary by William Ewart Gladstone. His tenure of this office was conspicuous for a reform of the licensing laws, and he was responsible for the Licensing Act 1872, which made the magistrates the licensing authority, increased the penalties for misconduct in public-houses and shortened the number of hours for the sale of drink. In 1873 Bruce relinquished the home secretaryship, at Gladstone's request, to become Lord President of the Council, and was raised to the peerage as Baron Aberdare, of Duffryn in the County of Glamorgan, on 23 August that year.
Public career after 1874.
The defeat of the Liberal government in the following year terminated Lord Aberdare's official political life, and he subsequently devoted himself to social, educational and economic questions.
Education became one of Lord Aberdare's main interests in later life. His interest had been shown by the speech on Welsh education which he had made on 5 May 1862. In 1880, he was appointed to chair the Departmental Committee on Intermediate and Higher Education in Wales and Monmouthshire, whose report ultimately led to the Welsh Intermediate Education Act of 1889. The report also stimulated the campaign for the provision of university education in Wales. In 1883, Lord Aberdare was elected the first president of the University College of South Wales and Monmouthshire. In his inaugural address he declared that the framework of Welsh education would not be complete until there was a University of Wales. The University was eventually founded in 1893 and Aberdare became its first chancellor.
In 1876 he was elected a Fellow of the Royal Society; from 1878 to 1891 he was president of the Royal Historical Society; and in 1881 he became president of both the Royal Geographical Society and the Girls' Day School Trust. In 1888 he headed the commission that established the Official Table of Drops, listing how far a person of a particular weight should be dropped when hanged for a capital offence (the only method of 'judicial execution' in the United Kingdom at that time), to ensure an instant and painless death, by cleanly breaking the neck between the 2nd and 3rd vertebrae, an 'exacting science', eventually brought to perfection by Chief Executioner Albert Pierrepoint.
In 1882 he began a connection with West Africa which lasted the rest of his life, by accepting the chairmanship of the National African Company, formed by Sir George Goldie, which in 1886 received a charter under the title of the Royal Niger Company and in 1899 was taken over by the British government, its territories being constituted the protectorate of Nigeria. West African affairs, however, by no means exhausted Lord Aberdare's energies, and it was principally through his efforts that a charter was in 1894 obtained for the University College of South Wales and Monmouthshire,a constituent institution of the University of Wales. This is now Cardiff University. Lord Aberdare, who in 1885 was made a Knight Grand Cross of the Order of the Bath, presided over several Royal Commissions at different times.
Family.
Henry Bruce married firstly Annabella, daughter of Richard Beadon, in 1846. They had one son and three daughters. After her death in July 1852 he married secondly Norah Creina Blanche, daughter of Sir William Napier, the historian of the Peninsular War, whose biography he edited. They had seven daughters and two sons, of whom the youngest was the mountaineer Charles Granville Bruce. Their daughter Sarah was married to Montague Muir Mackenzie, barrister.
Lord Aberdare died in London on 25 February 1895, aged 79, and was succeeded in the barony by his only son from his first marriage, Henry. Lady Aberdare, born 1827, died in April 1897 and was a proponent of women's education and active in the establishment of Aberdare Hall in Cardiff.
Memorial.
Henry Austin Bruce is buried at Aberffrwd Cemetery in Mountain Ash, Wales. His large family plot is surrounded by a chain, and his grave is a simple Celtic cross with double plinth and kerb. In place is written "To God the Judge of all and to the spirits of just men more perfect."

</doc>
<doc id="14203" url="https://en.wikipedia.org/wiki?curid=14203" title="Harpers Ferry (disambiguation)">
Harpers Ferry (disambiguation)

Harpers Ferry is the name of several places in the United States of America:
Harpers Ferry may also refer to:

</doc>
<doc id="14204" url="https://en.wikipedia.org/wiki?curid=14204" title="Halophile">
Halophile

Halophiles are organisms that thrive in high salt concentrations. They are a type of extremophile organism. The name comes from the Greek word for "salt-loving". While most halophiles are classified into the Archaea domain, there are also bacterial halophiles and some eukaryota, such as the alga "Dunaliella salina" or fungus "Wallemia ichthyophaga". Some well-known species give off a red color from carotenoid compounds, notably bacteriorhodopsin. Halophiles can be found anywhere with a concentration of salt five times greater than the salt concentration of the ocean, such as the Great Salt Lake in Utah, Owens Lake in California, the Dead Sea, and in evaporation ponds.
Classification.
Halophiles are categorized as slight, moderate, or extreme, by the extent of their halotolerance. Slight halophiles prefer 0.3 to 0.8 M (1.7 to 4.8% — seawater is 0.6 M or 3.5%), moderate halophiles 0.8 to 3.4 M (4.7 to 20%), and extreme halophiles 3.4 to 5.1 M (20 to 30%) salt content. Halophiles require sodium chloride (salt) for growth, in contrast to halotolerant organisms, which do not require salt but can grow under saline conditions.
Lifestyle.
High salinity represents an extreme environment that relatively few organisms have been able to adapt to and occupy. Most halophilic and all halotolerant organisms expend energy to exclude salt from their cytoplasm to avoid protein aggregation ('salting out'). In order to survive the high salinities, halophiles employ two differing strategies to prevent desiccation through osmotic movement of water out of their cytoplasm. Both strategies work by increasing the internal osmolarity of the cell. In the first (which is employed by the majority of halophilic bacteria, some archaea, yeasts, algae and fungi), organic compounds are accumulated in the cytoplasm — osmoprotectants which are known as compatible solutes. These can be either synthesised or accumulated from the environment. The most common compatible solutes are neutral or zwitterionic, and include amino acids, sugars, polyols, betaines and ectoines, as well as derivatives of some of these compounds.
The second, more radical, adaptation involves the selective influx of potassium (K+) ions into the cytoplasm. This adaptation is restricted to the moderately halophilic bacterial order "Halanerobiales", the extremely halophilic archaeal family "Halobacteriaceae", and the extremely halophilic bacterium "Salinibacter ruber". The presence of this adaptation in three distinct evolutionary lineages suggests convergent evolution of this strategy, it being unlikely to be an ancient characteristic retained in only scattered groups or passed on through massive lateral gene transfer. The primary reason for this is that the entire intracellular machinery (enzymes, structural proteins, etc.) must be adapted to high salt levels, whereas in the compatible solute adaptation little or no adjustment is required to intracellular macromolecules — in fact, the compatible solutes often act as more general stress protectants as well as just osmoprotectants.
Of particular note are the extreme halophiles or haloarchaea (often known as halobacteria), a group of archaea, which require at least a 2 M salt concentration and are usually found in saturated solutions (about 36% w/v salts). These are the primary inhabitants of salt lakes, inland seas, and evaporating ponds of seawater, such as the deep salterns, where they tint the water column and sediments bright colors. These species will most likely perish if they are exposed to anything other than a very high-concentration salt-conditioned environment. These prokaryotes require salt for growth. The high concentration of sodium chloride in their environment limits the availability of oxygen for respiration. Their cellular machinery is adapted to high salt concentrations by having charged amino acids on their surfaces, allowing the retention of water molecules around these components. They are heterotrophs that normally respire by aerobic means. Most halophiles are unable to survive outside their high-salt native environment. Indeed, many cells are so fragile that when placed in distilled water they immediately lyse from the change in osmotic conditions.
Halophiles may use a variety of energy sources. They can be aerobic or anaerobic. Anaerobic halophiles include phototrophic, fermentative, sulfate-reducing, homoacetogenic and methanogenic species.
Haloarchaea, and particularly, the family "Halobacteriaceae", are members of the domain "Archaea", and comprise the majority of the prokaryotic population in hypersaline environments. There are currently 15 recognised genera in the family. The domain "Bacteria" (mainly "Salinibacter ruber") can comprise up to 25% of the prokaryotic community, but is more commonly a much lower percentage of the overall population. At times, the alga "Dunaliella salina" can also proliferate in this environment.
A comparatively wide range of taxa have been isolated from saltern crystalliser ponds, including members of the following genera: "Haloferax, Halogeometricum, Halococcus, Haloterrigena, Halorubrum, Haloarcula" and "Halobacterium". However, the viable counts in these cultivation studies have been small when compared to total counts, and the numerical significance of these isolates has been unclear. Only recently has it become possible to determine the identities and relative abundances of organisms in natural populations, typically using PCR-based strategies that target 16S small subunit ribosomal ribonucleic acid (16S rRNA) genes. While comparatively few studies of this type have been performed, results from these suggest that some of the most readily-isolated and studied genera may not in fact be significant in the in-situ community. This is seen in cases such as the genus "Haloarcula", which is estimated to make up less than 0.1% of the in situ community but commonly appears in isolation studies.
Genomic and proteomic signature of halophiles.
The comparative genomic and proteomic analysis showed that there is a distinct molecular signatures for environmental adaptation of halophiles. At the protein level, the halophilic species are characterized by low hydrophobicity, overrepresentation of acidic residues, underrepresentation of Cys, lower propensities for helix formation and higher propensities for coil structure. It is also evident that the core of these proteins is less hydrophobic, such as DHFR, that was found to have narrower β-strands 
At the DNA level, the halophiles exhibit distinct dinucleotide and codon usage.
Examples.
Halobacterium is a group of Archaea that have a high tolerance for elevated levels of salinity. Some species of halobacteria have acidic proteins that resist the denaturing effects of salts. "Halococcus" is a specific genus of the family Halobacterium.
Some hypersaline lakes are a habitat to numerous families of halophiles. For example, the Makgadikgadi Pans in Botswana is a vast seasonal high salinity water body that manifests halophilic species within the diatom genus "Nitzschia" in the family Bacillariaceae as well as species within the genus "Lovenula" in the family Diaptomidae. Owens Lake in California also contains a large population of the halophilic bacteria Halobacterium halobium.
"Wallemia ichthyophaga" is a basidiomycetous fungus, which requires at least 1.5 M Sodium chloride for in-vitro growth, and it thrives even in medium saturated with salt. Obligate requirement for salt is an exception in fungi. Even species that can tolerate salt concentrations close to saturation (for example "Hortaea werneckii") in almost all cases grow well in standard microbiological media without the addition of salt.
The fermentation of salty foods (such as soy sauce, Chinese fermented beans, salted cod, salted anchovies, sauerkraut etc.) often involves halobacteria, as either essential ingredients or accidental contaminants. One example is "Chromohalobacter beijerinckii", found in salted beans preserved in brine and in salted herring. "Tetragenococcus halophilus" is found in salted anchovies and soy sauce.

</doc>
<doc id="14205" url="https://en.wikipedia.org/wiki?curid=14205" title="Herbert A. Simon">
Herbert A. Simon

Herbert Alexander Simon (June 15, 1916 – February 9, 2001), a Nobel Prize laureate, was an American political scientist, economist, sociologist, psychologist, and computer scientist whose research ranged across the fields of cognitive psychology, cognitive science, computer science, public administration, economics, management, philosophy of science, sociology, and political science, unified by studies of decision-making. With almost a thousand highly cited publications, he was one of the most influential social scientists of the twentieth century. For many years he held the post of Richard King Mellon Professor at Carnegie Mellon University
Simon was among the founding fathers of several of today's important scientific domains, including artificial intelligence, information processing, decision-making, problem-solving, organization theory, complex systems, and computer simulation of scientific discovery.
He coined the terms "bounded rationality" and "satisficing", and was among the earliest to analyze the architecture of complexity and to propose a preferential attachment mechanism to explain power law distributions.
He also received many top-level honors later in life. These include: becoming a fellow of the American Academy of Arts and Sciences in 1959; election to the National Academy of Sciences in 1967; APA Award for Distinguished Scientific Contributions to Psychology (1969);the ACM's Turing Award for making "basic contributions to artificial intelligence, the psychology of human cognition, and list processing" (1975); the Nobel Memorial Prize in Economics "for his pioneering research into the decision-making process within economic organizations" (1978); the National Medal of Science (1986); the APA's Award for Outstanding Lifetime Contributions to Psychology (1993); ACM fellow (1994); and IJCAI Award for Research Excellence (1995). Simon is currently, as of 2016 the most cited person in Artificial Intelligence and Cognitive Psychology on Google Scholar.
As a testament to his interdisciplinary approach, Simon was affiliated with such varied Carnegie Mellon departments as the School of Computer Science, Tepper School of Business, departments of Philosophy, Social and Decision Sciences, and Psychology. Simon received an honorary Doctor of Political science degree from University of Pavia in 1988 and an honorary Doctor of Laws (LL.D.) degree from Harvard University in 1990.
Early life and education.
Herbert Alexander Simon was born in Milwaukee, Wisconsin on June 15, 1916. His father, Arthur Simon (1881–1948), was an electrical engineer who had come to the United States from Germany in 1903 after earning his engineering degree from the Technische Hochschule of Darmstadt. An inventor who was granted "several dozen patents", his father also was an independent patent attorney. His mother, Edna Marguerite Merkel, was an accomplished pianist whose ancestors had come from Prague and Cologne. His European ancestors had been piano makers, goldsmiths, and vintners. Simon's father was Jewish and his mother came from a family with Jewish, Lutheran, and Catholic backgrounds. Simon called himself an atheist.
Simon was educated as a child in the public school system in Milwaukee where he developed an interest in science. He found schoolwork to be interesting and easy. Unlike many children, Simon was exposed to the idea that human behavior could be studied scientifically at a relatively young age due to the influence of his mother’s younger brother, Harold Merkel, who had studied economics at the University of Wisconsin–Madison under John R. Commons. Through his uncle’s books on economics and psychology, Simon discovered the social sciences. Among his earliest influences, Simon has cited Richard Ely’s economics textbook, Norman Angell’s "The Great Illusion", and Henry George’s "Progress and Poverty".
In 1933, Simon entered the University of Chicago, and following those early influences, he studied the social sciences and mathematics. He was interested in biology, but chose not to study it because of his "color-blindness and awkwardness in the laboratory". He chose instead to focus on political science and economics. His most important mentor at the University was Henry Schultz who was an econometrician and mathematical economist. Simon received both his B.A. (1936) and his Ph.D. (1943) in political science, from the University of Chicago, where he studied under Harold Lasswell, Nicholas Rashevsky, Rudolf Carnap, Henry Schultz, and Charles Edward Merriam.
After enrolling in a course on "Measuring Municipal Governments," Simon was invited to be a research assistant for Clarence Ridley, with whom he coauthored the book, "Measuring Municipal Activities", in 1938, the same year that he and Dorothea married. Eventually his studies led him to the field of organizational decision-making, which would become the subject of his doctoral dissertation.
Academic career.
After graduating with his undergraduate degree, Simon obtained a research assistantship in municipal administration which turned into a directorship at the University of California, Berkeley.
From 1942 to 1949, Simon was a professor of political science and also served as department chairman at Illinois Institute of Technology. Back in Chicago, he began participating in the seminars held by the staff of the Cowles Commission who at that time included Trygve Haavelmo, Jacob Marschak, and Tjalling Koopmans. He thus began a more in-depth study of economics in the area of institutionalism. Marschak brought Simon in to assist in the study he was currently undertaking with Sam Schurr of the “prospective economic effects of atomic energy”.
From 1949 to 2001, Simon was a faculty at Carnegie Mellon. In 1949, Simon became a professor of administration and chairman of the Department of Industrial Management at Carnegie Tech (later to become Carnegie Mellon University). Simon later also taught psychology and computer science in the same university, (occasionally visiting other universities.).
Personal life and interests.
Simon married Dorothea Pye in 1938. Their marriage lasted 63 years until his death from a cancerous tumor. In January 2001, Simon underwent surgery at UPMC Presbyterian to remove a cancerous tumor in his abdomen. Although the surgery was successful, Simon later succumbed to the complications that followed.
They had three children, Katherine, Peter, and Barbara. His wife died in 2002, during the year following his death in 2001.
From 1950 to 1955, Simon studied mathematical economics and during this time, together with David Hawkins, discovered and proved the Hawkins–Simon theorem on the “conditions for the existence of positive solution vectors for input-output matrices." He also developed theorems on near-decomposability and aggregation. Having begun to apply these theorems to organizations, by 1954 Simon determined that the best way to study problem-solving was to simulate it with computer programs, which led to his interest in computer simulation of human cognition. Founded during the 1950s, he was among the first members of the Society for General Systems Research.
Simon had a keen interest in the arts, as he was a pianist. He was a friend of Robert Lepper and Richard Rappaport. Rappaport also painted Simon's commissioned portrait at Carnegie Mellon University.
Works.
Seeking to replace the highly simplified classical approach to economic modeling, Simon became best known for his theory of corporate decision in his book "Administrative Behavior". In this book he based his concepts with an approach that recognized multiple factors that contribute to decision making. His organization and administration interest allowed him to not only serve three times as an university department chairman, but he also played a big part in the creation of the Economic Cooperation Administration in 1948; administrative team that administered aid to the Marshall Plan for the U. S Government , serving on President Johnson's Science Advisory Committee, and also the National Academy of Science. Herbert Simon has made a great number of profound and in depth contributions to both economic analysis and applications. Because of this, his work can be found in a number of economic literary works, making contributions to areas such as mathematical economics including theorum, human rationality, behavioral study of firms, theory of casual ordering, and the analysis of the identification problem in econometrics.
Study of decision-making.
"Administrative Behavior",
first appearing in 1947, and updated across the years was based on Simon’s doctoral dissertation. It served as the foundation for his life's work. The centerpiece of this book is the behavioral and cognitive processes of humans making rational choices, that is, decisions. By his definition, an operational administrative decision should be correct and efficient, and it must be practical to implement with a set of coordinated means.
Simon recognised that a theory of administration is largely a theory of human decision making, and as such must be based on both economics and on psychology. He states:
Contrary to the "homo economicus" stereotype, Simon argued that alternatives and consequences may be partly known, and means and ends imperfectly differentiated, incompletely related, or poorly detailed.
Simons defined the task of rational decision making is to select the alternative that results in the more preferred set of all the possible consequences. Correctness of administrative decisions was thus measured by:
The task of choice was divided into three required steps:
Any given individual or organization attempting to implement this model in a real situation would be unable to comply with the three requirements. Simon argued that knowledge of all alternatives, or all consequences that follow from each alternative is impossible in many realistic cases.
Simon attempted to determine the techniques and/or behavioral processes that a person or organization could bring to bear to achieve approximately the best result given limits on rational decision making. Simon writes:
Simon therefore, describes work in terms of an economic framework, conditioned on human cognitive limitations: Economic man and Administrative man.
"Administrative Behavior", as a text, addresses a wide range of human behaviors, cognitive abilities, management techniques, personnel policies, training goals and procedures, specialized roles, criteria for evaluation of accuracy and efficiency, and all of the ramifications of communication processes. Simon is particularly interested in how these factors influence the making of decisions, both directly and indirectly.
Simons argued that the two outcomes of a choice require monitoring and that many members of the organization would be expected to focus on adequacy, but that administrative management must pay particular attention to the efficiency with which the desired result was obtained.
Simon followed Chester Barnard who pointed out that “the decisions that an individual makes as a member of an organization are quite distinct from his personal decisions”. Personal choices may be determined whether an individual joins a particular organization, and continue to be made in his or her extra–organizational private life. As a member of an organization, however, that individual makes decisions not in relationship to personal needs and results, but in an impersonal sense as part of the organizational intent, purpose, and effect. Organizational inducements, rewards, and sanctions are all designed to form, strengthen, and maintain this identification.
Simon saw two universal elements of human social behavior as key to creating the possibility of organizational behavior in human individuals: Authority (addressed in Chapter VII—The Role of Authority) and in Loyalties and Identification (Addressed in Chapter X: Loyalties, and Organizational Identification).
Authority is a well studied, primary mark of organizational behavior, straightforwardly defined in the organizational context as the ability and right of an individual of higher rank to guide the decisions of an individual of lower rank. The actions, attitudes, and relationships of the dominant and subordinate individuals constitute components of role behavior that may vary widely in form, style, and content, but do not vary in the expectation of obedience by the one of superior status, and willingness to obey from the subordinate.
Loyalty was defined by Simon as the "process whereby the individual substitutes organizational objectives (service objectives or conservation objectives) for his own aims as the value-indices which determine his organizational decisions". This entailed evaluating alternative choices in terms of their consequences for the group rather than only for onself or ones family.
Decisions can be complex admixtures of facts and values. Information about facts, especially empirically-proven facts or facts derived from specialized experience, are more easily transmitted in the exercise of authority than are the expressions of values. Simon is primarily interested in seeking identification of the individual employee with the organizational goals and values. Following Lasswell, he states that “a person identifies himself with a group when, in making a decision, he evaluates the several alternatives of choice in terms of their consequences for the specified group”. A person may identify himself with any number of social, geographic, economic, racial, religious, familial, educational, gender, political, and sports groups. Indeed, the number and variety are unlimited. The fundamental problem for organizations is to recognize that personal and group identifications may either facilitate or obstruct correct decision making for the organization. A specific organization has to determine deliberately, and specify in appropriate detail and clear language, its own goals, objectives, means, ends, and values.
Simon's contributions to research in the area of administrative decision-making have become increasingly mainstream in the business community.
Artificial intelligence and psychology.
Simon was a pioneer in the field of artificial intelligence, creating with Allen Newell the Logic Theory Machine (1956) and the General Problem Solver (GPS) (1957) programs. GPS may possibly be the first method developed for separating problem solving strategy from information about particular problems. Both programs were developed using the Information Processing Language (IPL) (1956) developed by Newell, Cliff Shaw, and Simon. Donald Knuth mentions the development of list processing in IPL, with the linked list originally called "NSS memory" for its inventors. In 1957, Simon predicted that computer chess would surpass human chess abilities within "ten years" when, in reality, that transition took about forty years.
In the early 1960s psychologist Ulric Neisser asserted that while machines are capable of replicating 'cold cognition' behaviors such as reasoning, planning, perceiving, and deciding, they would never be able to replicate 'hot cognition' behaviors such as pain, pleasure, desire, and other emotions. Simon responded to Neisser's views in 1963 by writing a paper on emotional cognition, which he updated in 1967 and published in "Psychological Review". Simon's work on emotional cognition was largely ignored by the artificial intelligence research community for several years, but subsequent work on emotions by Sloman and Picard helped refocus attention on Simon's paper and eventually, made it highly influential on the topic.
Simon also collaborated with James G. March on several works in organization theory.
With Allen Newell, Simon developed a theory for the simulation of human problem solving behavior using production rules. The study of human problem solving required new kinds of human measurements and, with Anders Ericsson, Simon developed the experimental technique of verbal protocol analysis. Simon was interested in the role of knowledge in expertise. He said that to become an expert on a topic required about ten years of experience and he and colleagues estimated that expertise was the result of learning roughly 50,000 chunks of information. A chess expert was said to have learned about 50,000 chunks or chess position patterns.
He was awarded the ACM A.M. Turing Award along with Allen Newell in 1975. "In joint scientific efforts extending over twenty years, initially in collaboration with J. C. (Cliff) Shaw at the RAND Corporation, and with numerous faculty and student colleagues at Carnegie Mellon University, they have made basic contributions to artificial intelligence, the psychology of human cognition, and list processing."
Psychology.
Simon was interested in how humans learn and, with Edward Feigenbaum, he developed the EPAM (Elementary Perceiver and Memorizer) theory, one of the first theories of learning to be implemented as a computer program. EPAM was able to explain a large number of phenomena in the field of verbal learning. Later versions of the model were applied to concept formation and the acquisition of expertise. With Fernand Gobet, he has expanded the EPAM theory into the CHREST computational model. The theory explains how simple chunks of information form the building blocks of schemata, which are more complex structures. CHREST has been used predominantly, to simulate aspects of chess expertise.
Sociology and economics.
Simon has been credited for revolutionary changes in microeconomics. He is responsible for the concept of organizational decision-making as it is known today. He also was the first to discuss this concept in terms of uncertainty; i.e. it is impossible to have perfect and complete information at any given time to make a decision. While this notion was not entirely new, Simon is best known for its origination. It was in this area that he was awarded the Nobel Prize in 1978.
At the Cowles Commission, Simon’s main goal was to link economic theory to mathematics and statistics. His main contributions were to the fields of general equilibrium and econometrics. He was greatly influenced by the marginalist debate that began in the 1930s. The popular work of the time argued that it was not apparent empirically that entrepreneurs needed to follow the marginalist principles of profit-maximization/cost-minimization in running organizations. The argument went on to note that profit-maximization was not accomplished, in part, because of the lack of complete information. In decision-making, Simon believed that agents face uncertainty about the future and costs in acquiring information in the present. These factors limit the extent to which agents may make a fully rational decision, thus they possess only “bounded rationality” and must make decisions by “satisficing,” or choosing that which might not be optimal, but which will make them happy enough. Bounded rationality is a central theme in behavioral economics. It is concerned with the ways in which the actual decision making process influences decision. Theoryies of bounded rationality relax one or more assumptions of standard expected utility theory.
However, there is also a term, procedural rationality. Gustavos Barros, from the Brazilian Journal of Political Economy, argued that proceduaral rationality contrary to bounded rationality better synthesizes Simon's view of tational behavior. However according to Barros, the procedural rationality concept does not have a significant presence in the economic science field and has never had nearly as much weight as the concept of bounded rationality.
Simon was known for his research on industrial organization. He determined that the internal organization of firms and the external business decisions thereof, did not conform to the Neoclassical theories of “rational” decision-making. Simon wrote many articles on the topic over the course of his life mainly focusing on the issue of decision-making within the behavior of what he termed “bounded rationality”. “Rational behavior, in economics, means that individuals maximize their utility function under the constraints they face (e.g., their budget constraint, limited choices, ...) in pursuit of their self-interest. This is reflected in the theory of subjective expected utility. The term, bounded rationality, is used to designate rational choice that takes into account the cognitive limitations of both knowledge and cognitive capacity. Bounded rationality is a central theme in behavioral economics. It is concerned with the ways in which the actual decision-making process influences decisions. Theories of bounded rationality relax one or more assumptions of standard expected utility theory”.
Simon determined that the best way to study these areas was through computer simulation modeling. As such, he developed an interest in computer science. Simon's main interests in computer science were in artificial intelligence, human-computer interaction, principles of the organization of humans and machines as information processing systems, the use of computers to study (by modeling) philosophical problems of the nature of intelligence and of epistemology, and the social implications of computer technology.
Some of Simon's economic research was directed toward understanding technological change in general and the information processing revolution in particular.
Pedagogy.
Simon's work has strongly influenced John Mighton, developer of a program that has achieved significant success in improving mathematics performance among elementary and high school students. Mighton cites a 2000 paper by Simon and two co-authors that counters arguments by French mathematics educator, Guy Brousseau, and others suggesting that excessive practice hampers children's understanding:
Selected publications.
Simon was prolific, and authored 27 books and almost a thousand papers.

</doc>
<doc id="14207" url="https://en.wikipedia.org/wiki?curid=14207" title="Hematite">
Hematite

Hematite, also spelled as haematite, is the mineral form of iron(III) oxide (Fe2O3), one of several iron oxides. Hematite crystallizes in the rhombohedral lattice system, and it has the same crystal structure as ilmenite and corundum. Hematite and ilmenite form a complete solid solution at temperatures above .
Hematite is a mineral, colored black to steel or silver-gray, brown to reddish brown, or red. It is mined as the main ore of iron. Varieties include "kidney ore", "martite" (pseudomorphs after magnetite), "iron rose" and "specularite" (specular hematite). While the forms of hematite vary, they all have a rust-red streak. Hematite is harder than pure iron, but much more brittle. Maghemite is a hematite- and magnetite-related oxide mineral.
Huge deposits of hematite are found in banded iron formations. Gray hematite is typically found in places that can have still standing water or mineral hot springs, such as those in Yellowstone National Park in North America. The mineral can precipitate out of water and collect in layers at the bottom of a lake, spring, or other standing water. Hematite can also occur without water, however, usually as the result of volcanic activity.
Clay-sized hematite crystals can also occur as a secondary mineral formed by weathering processes in soil, and along with other iron oxides or oxyhydroxides such as goethite, is responsible for the red color of many tropical, ancient, or otherwise highly weathered soils.
Etymology and history.
The name hematite is derived from the Greek word for blood αἷμα "haima" because hematite can be red, as in rouge, a powdered form of hematite. The color of hematite lends itself to use as a pigment. The English name of the stone is derived from Middle French: Hématite Pierre, which was imported from Latin: Lapis Hæmatites around the 15th century, which originated from Ancient Greek: αἱματίτης λίθος ("haimatitēs" lithos, "blood-red stone").
Ochre is a clay that is colored by varying amounts of hematite, varying between 20% and 70%. Red ochre contains unhydrated hematite, whereas yellow ochre contains hydrated hematite (Fe2O3 • H2O). The principal use of ochre is for tinting with a permanent color.
The red chalk writing of this mineral was one of the earliest in the history of humans. The powdery mineral was first used 164,000 years ago by the Pinnacle-Point man possibly for social purposes. Hematite residues are also found in old graveyards from 80,000 years ago. Near Rydno in Poland and Lovas in Hungary, palaeolithic red chalk mines have been found that are from 5000 BC, belonging to the Linear Pottery culture at the Upper Rhine.
Rich deposits of hematite have been found on the island of Elba that have been mined since the time of the Etruscans.
Magnetism.
Hematite is an antiferromagnetic material below the Morin transition at 250 kelvin (K) or -9.7 degrees Fahrenheit (°F), and a canted antiferromagnet or weakly ferromagnetic above the Morin transition and below its Néel temperature at 948 K, above which it is paramagnetic.
The magnetic structure of a-hematite was the subject of considerable discussion and debate in the 1950s because it appeared to be ferromagnetic with a Curie temperature of around 1000 K, but with an extremely tiny moment (0.002 µB). Adding to the surprise was a transition with a decrease in temperature at around 260 K to a phase with no net magnetic moment. It was shown that the system is essentially antiferromagnetic, but that the low symmetry of the cation sites allows spin–orbit coupling to cause canting of the moments when they are in the plane perpendicular to the c axis. The disappearance of the moment with a decrease in temperature at 260 K is caused by a change in the anisotropy which causes the moments to align along the c axis. In this configuration, spin canting does not reduce the energy. The magnetic properties of bulk hematite differ from their nanoscale counterparts. For example, the Morin transition temperature of hematite decreases with a decrease in the particle size. The suppression of this transition has also been observed in some of the hematite nanoparticles, and the presence of impurities, water molecules and defects in the crystals were attributed to the absence of a Morin transition. Hematite is part of a complex solid solution oxyhydroxide system having various contents of water, hydroxyl groups and vacancy substitutions that affect the mineral's magnetic and crystal chemical properties. Two other end-members are referred to as protohematite and hydrohematite.
Enhanced magnetic coercivities for hematite have been achieved by dry-heating a 2-line ferrihydrite precursor prepared from solution. Hematite exhibited temperature-dependent magnetic coercivity values ranging from 289 to 5,027 Oe. The origin of these high coercivity values has been interpreted as a consequence of the subparticle structure induced by the different particle and crystallite size growth rates at increasing annealing temperature. These differences in the growth rates are translated into a progressive development of a subparticle structure at the nanoscale. At lower temperatures (350–600 °C), single particles crystallize however; at higher temperatures (600-1000 °C), the growth of crystalline aggregates with a subparticle structure is favored.
Mine tailings.
Hematite is present in the waste tailings of iron mines. A recently developed process, magnetation, uses magnets to glean waste hematite from old mine tailings in Minnesota's vast Mesabi Range iron district. Falu red is a pigment used in traditional Swedish house paints. Originally, it was made from tailings of the Falu mine.
Mars.
The spectral signature of hematite was seen on the planet Mars by the infrared spectrometer on the NASA Mars Global Surveyor ("MGS") and 2001 Mars Odyssey spacecraft in orbit around Mars. The mineral was seen in abundance at two sites on the planet, the Terra Meridiani site, near the Martian equator at 0° longitude, and the Aram Chaos site near the Valles Marineris. Several other sites also showed hematite, e.g., Aureum Chaos. Because terrestrial hematite is typically a mineral formed in aqueous environments or by aqueous alteration, this detection was scientifically interesting enough that the second of the two Mars Exploration Rovers was sent to a site in the Terra Meridiani region designated Meridiani Planum. In-situ investigations by the Opportunity rover showed a significant amount of hematite, much of it in the form of small spherules that were informally named "blueberries" by the science team. Analysis indicates that these spherules are apparently concretions formed from a water solution.
"Knowing just how the hematite on Mars was formed will help us characterize the past environment and determine whether that environment was favorable for life".
Jewelry.
Hematite's popularity in jewelry was at its highest in Europe during the Victorian era. Certain types of hematite or iron oxide-rich clay, especially Armenian bole, have been used in gilding. Hematite is also used in art such as in the creation of intaglio engraved gems. Hematine is a synthetic material sold as "magnetic hematite".

</doc>
<doc id="14208" url="https://en.wikipedia.org/wiki?curid=14208" title="Holocene extinction">
Holocene extinction

The Holocene extinction, otherwise referred to as the Sixth extinction or Anthropocene extinction, is a name for the ongoing extinction event of species during the present Holocene epoch (since around 10,000 BCE) mainly due to human activity. The large number of extinctions span numerous families of plants and animals including mammals, birds, amphibians, reptiles and arthropods. Although 875 extinctions occurring between 1500 and 2009 have been documented by the International Union for Conservation of Nature and Natural Resources, with widespread degradation of highly biodiverse habitats such as coral reefs and rainforest, as well as other areas, the vast majority are thought to be undocumented. According to the species-area theory and based on upper-bound estimating, the present rate of extinction may be up to 140,000 species per year, making it the greatest loss of biodiversity since the Cretaceous–Paleogene extinction event.
The Holocene extinction includes the disappearance of large land animals known as megafauna, starting between 9,000 and 13,000 years ago, the end of the last Ice Age. Megafauna outside of the African continent, that did not evolve alongside humans, proved highly sensitive to the introduction of new predation, and many died out shortly after early humans began spreading and hunting across the Earth (additionally, many African species have also gone extinct in the Holocene). The extinction of the mammoths allowed grasslands they had maintained through grazing habits to become birch forests. The new forest and the resulting forest fires may have induced climate change. Such disappearances might be the result of the proliferation of modern humans. These extinctions, occurring near the Pleistocene–Holocene boundary, are sometimes referred to as the Quaternary extinction event.
There is no general agreement on where the Holocene, or anthropogenic, extinction begins, and the Quaternary extinction event which includes climate change resulting in the end of the last ice age ends, or if they should be considered separate events at all. Some have suggested that anthropogenic extinctions may have begun as early as when the first modern humans spread out of Africa between 100,000 and 200,000 years ago, which is supported by rapid megafaunal extinction following recent human colonisation in Australia, New Zealand and Madagascar, in a similar way that any large, adaptable predator moving into a new ecosystem would. In many cases, it is suggested even minimal hunting pressure was enough to wipe out large fauna, particularly on geographically isolated islands. Only during the most recent parts of the extinction have plants also suffered large losses.
The ecology of "Homo sapiens" has been noted as being that of an unprecedented 'global superpredator' that regularly preys on the adults of other apex predators and has worldwide effects on food webs. Extinctions of species have occurred on every land mass and ocean, with many famous examples within Africa, Asia, Europe, Australia, North and South America, and on smaller islands. Overall, the Holocene extinction can be characterized by the human impact on the environment. The Holocene extinction continues into the 21st century, with overfishing, ocean acidification and the amphibian crisis being a few broader examples of an almost universal, cosmopolitan decline of biodiversity.
It has been suggested human activity has made the period following the mid-20th century different enough from the Holocene to consider it a new geological epoch, known as the Anthropocene, which will be considered for implementation into the timeline of Earth's history by the International Commission on Stratigraphy in 2016.
Human influence on extinction.
Extinction of animals, plants, and other organisms caused by human actions may go as far back as the late Pleistocene, over 12,000 years ago. There is evidence that abrupt climate change has especially played an enormous role in the extinction of larger mammals. However, while previous mass extinctions were due to natural environmental causes, research shows that wherever on Earth humans have migrated, other species have gone extinct, and human population growth, most prominently in the past two centuries, is regarded as one of the underlying causes of extinction. In terms of how humans have contributed, three major factors include the increased global concentration of greenhouse gases, affecting the global climate; oceanic devastation, such as through overfishing and contamination; and the modification and destruction of vast tracts of land and river systems around the world to meet solely human-centered ends (with 13 percent of Earth's ice-free land surface now used as row-crop agricultural sites, 26 percent used as pastures, and 4 percent urban-industrial areas), thus ruining the local ecosystems. Other, related human causes of the extinction event include deforestation, hunting, pollution, the introduction in various regions of non-native species, and the widespread transmission of infectious diseases. At present, the rate of extinction of species is estimated at 100 to 1,000 times higher than the "base" or historically typical rate of extinction (in terms of the natural evolution of the planet) and also the current rate of extinction is, therefore, 10 to 100 times higher than any of the previous mass extinctions in the history of Earth. It is also the only known mass extinction of plants.
The abundance of species extinctions considered "anthropogenic", or due to human activity, have sometimes (especially when referring to hypothesized future events) been collectively called the "Anthropocene extinction". The Anthropocene is a term introduced in 2000. It is now posited by some that a new geological epoch has begun, characterised by the most abrupt and widespread extinction of species since the Cretaceous–Paleogene extinction event 66 million years ago. In "The Future of Life" (2002), E.O. Wilson of Harvard calculated that, if the current rate of human disruption of the biosphere continues, one-half of Earth's higher lifeforms will be extinct by 2100. A 1998 poll conducted by the American Museum of Natural History found that seventy percent of biologists believe that we are in the midst of an anthropogenic extinction. Numerous scientific studies—such as a 2004 report published in "Nature", and papers authored by the 10,000 scientists who contribute to the IUCN's annual Red List of threatened species—have since reinforced this conviction.
Extinction of the Megafauna in the Late-Pleistocene.
The evidence of all previous extinctions is geological in nature, and shorter geological time scale is of the order of several hundred thousand to several million years. Even extinctions caused by instantaneous events such as the impact of the asteroid in Chicxulub, which is currently the best example, extend the equivalent of many human lives, due to complex ecological interactions that were triggered by the event.
Three hypotheses have been proposed to explain the extinction of megafauna in the late Pleistocene. Of these, only two have much scientific credibility. Although Ross McPhee proposed that a hyper-disease may have been the cause of the extinction, a study by Lyons "et al.", demonstrated conclusively that a hyperdisease was unlikely to have caused the extinction. The two main theories to the extinction are climate change and human hunting. The climate change theory has suggested that a change in climate near the end of the late Pleistocene stressed the megafauna to the point of extinction. Some scientists favor abrupt climate change as the catalyst for the extinction of the mega-fauna at the end of the Pleistocene, but there are many who believe increased hunting from early modern humans also played a part, with others even suggesting that the two interacted. In the Americas, a controversial explanation for the shift in climate is presented under the Younger Dryas impact hypothesis.
Megafauna was once found on every continent of the world and large islands such as New Zealand and Madagascar, but is now almost exclusively found on the continent of Africa, with notable comparisons on Australia and the islands previously mentioned experiences population crashes and trophic cascades shortly after the earliest human settlers. It has been suggested that the African megafauna survived as they evolved alongside humans. The timing of South American megafaunal extinction does not appear to correspond to human arrival, although the possibility of whether human activity at the time may have impacted the global climate enough to cause such an extinction has been suggested.
It has been noted, in the face of such evidence, "Homo sapiens" is unique in its ecology as an unprecedented 'global superpredator', regularly preying on large numbers of fully grown terrestrial and marine apex predators, and with a great deal of influence over food webs and climatic systems worldwide.
Anthropogenic impact on Climate during the Holocene.
In order to constitute the Holocene as an extinction event, scientists must determine exactly when anthropogenic greenhouse gas emissions began to measurably alter natural atmospheric levels at a global scale and when these alterations caused changes to global climate. Employing chemical proxies from Antarctic ice cores, researchers have estimated the fluctuations of carbon dioxide (C02) and methane gases (CH4) in the earth’s atmosphere for the late Pleistocene and Holocene epochs. Based on these studies, general argumentation of when the peak of the Anthropocene occurred pertains to the timeframe within the previous two centuries; typically beginning with the Industrial Revolution, when greenhouse gas levels were recorded by contemporary methods at its highest. However, scientists that are employing a variance of archaeological and paleoecological data argue that the processes contributing to substantial human modification of the environment spanned many thousands of years ago on a global scale and thus, not originating as early as the Industrial Revolution. Gaining popularity on his uncommon hypothesis, Palaeoclimatologist William Ruddiman in 2003, stipulated that in the early Holocene 11,000 years ago, atmospheric carbon dioxide and methane levels has fluctuated at a different pattern than the Pleistocene epoch before it. He argued that the patterns of the significant decline of CO2 levels during the last ice age of the Pleistocene inversely correlates to the Holocene where there has been dramatic increases of CO2 around 8000 years ago and CH4 levels 3000 years after that. The correlation between the downfall of CO2 in the Pleistocene and the uprising of it during the Holocene implies that the causation of this spark of greenhouse gases into the atmosphere are due to the growth of human agriculture during the Holocene such as the anthropogenic expansion of land and irrigation.
Recent extinctions described are well-documented, but the nomenclature used varies. The term Anthropocene is a term that is used by few scientists, and some commentators may refer to the current and projected future extinctions as part of a longer Holocene extinction. The Holocene–Anthropocene boundary is contested, with some commentators asserting significant human influence on climate for much of what is normally regarded as the Holocene Epoch. Other commentators place the Holocene–Anthropocene boundary at the industrial revolution while also saying that "Formal adoption of this term in the near future will largely depend on its utility, particularly to earth scientists working on late Holocene successions."
Agriculture.
Human civilization flourished in accordance to the efficiency and intensification of prevailing subsistence systems. Local communities that acquire more subsistence strategies increased in number to combat competitive pressures of land utilization. Therefore, the Holocene developed competition on the basis of agriculture. The growth of agriculture has then introduced newer means of climate change and pollution.
Recent investigations about hunter-gatherer landscape burning has a major implication for the current debate about the timing of the Anthropocene and the role that humans may have played in the production of greenhouse gases prior to the Industrial Revolution. Studies on early hunter-gatherers raises questions about the current use of population size or density as a proxy for the amount of land clearance and anthropogenic burning that took place in preindustrial times. Scientists have questioned the correlation between population size and early territorial alterations. Ruddiman and Ellis' research paper in 2009 makes the case that early farmers involved in systems of agriculture used more land per capita than growers more later in the Holocene, who intensified their labor to produce more food per unit of area; arguing that agricultural involvement in rice production implemented thousands of years ago by relatively small populations have created significant environmental impacts through large-scale means of deforestation.
While a number of human-derived factors are recognized as potentially contributing to rising atmospheric concentrations of CH4 and C02, deforestation and territorial clearance practices associated with agricultural development may be contributing most to these concentrations globally.
Climate.
Climate change in the Early Holocene was distinguished prior to the last glacial maximum 15,000 years ago which then started the current period of the glacial retreat where climate started to increase significantly 11,000 years ago. The Holocene Epoch contained a vast number of temperature fluctuations that can be dated from the warm period of the "Holocene Climatic Optimum" in 5000 to 3000 BC that consisted of temperatures that were 1-2 degrees Celsius warmer than today to the more recent emergence of the "Industrial Revolution". During this period, came the development of ancient civilizations of the earliest "Homo sapiens" and the growth of agriculture due to the increase of tropical regions. Deepening the understanding of the anthropogenic impact in the early Holocene is a vital factor for analyzing interglacial climate instability due to their involvement in producing of atmospheric carbon dioxide.
Methodologies of the Holocene Climatic Optimum.
To undermine the present and future human-induced climatic changes, climatologists and paleontologists have correlated the increases of temperatures with the variations of solar radiation exposed to certain latitudinal earth bands during the Early Holocene. Thus, believing that the Holocene warming was solar in origin where only certain parts of the world experienced warmer climates during seasons such as summer. Moreover, scientists have conducted numerous oceanic sediments that can be dated back to the "Holocene Climatic Optimum", and discovered drastic increases of sea-levels and their sea-level highstands. This evidence of drastic increases of sea levels indicates that the deterioration of ice cores is crucial to understanding how the Holocene Climatic Optimum began and how it played as one of the major transgressions during the Holocene Maximum. As speculations of how the Holocene Climatic Optimum began remain scientifically unclear, impurities in gaseous chemistry inside these ice cores have been conducted as a valuable method of obtaining evidence of abnormal temperature fluctuations. The Nile River showed to have a greater volume and much larger in the Holocene than what it is today and the Sahara to have been more fertile. This in turn, led many anthropogenic hypotheses to claim that more tropical territories encouraged agricultural processes. However, there is greater complexity as to whether such changes are heavily caused by anthropogenic effects on climate because of limited methods that can directly identify an empirical correlation.
Prehistoric extinctions.
Although significant debate exists as to how much human predation and indirect effects contributed to prehistoric extinctions, certain population crashes have been directly correlated with human arrival.
Australia.
Australia was once home to a large assemblage of megafauna, with many parallels to those found on the African continent today. Australia's fauna is characterised by primarily marsupial mammals, and many reptiles and birds, all existing as giant forms until recently. Humans arrived on the continent very early, about 50,000 years ago. The extent human arrival contributed is controversial; climatic drying of Australia 40,000-60,000 years ago was an unlikely cause, as it was less severe in speed or magnitude than previous regional climate change which failed to kill off megafauna.
Due to the older timeframe and the soil chemistry on the continent, very little subfossil preservation evidence exists than elsewhere. However, continent-wide extinction of all genera weighing over 100 kilograms, and six of seven genera weighing between 45 and 100 kilograms occurred around 46,400 years ago (4,000 years after human arrival) and the fact that megafauna survived until a later date on the island of Tasmania following the establishment of a land bridge suggest direct hunting or anthropogenic ecosystem disruption such as fire-stick farming as likely causes. The first evidence of direct human predation leading to extinction in Australia was published in 2016.
Extinctions in Australia continued from original settlement until today in both plants and animals, whilst many more animals and plants have declined or are endangered.
North and South America.
There has been a debate as to the extent to which the disappearance of megafauna at the end of the last glacial period can be attributed to human activities by hunting, or even by slaughter of prey populations. Discoveries at Monte Verde in South America and at Meadowcroft Rock Shelter in Pennsylvania have caused a controversy regarding the Clovis culture. There likely would have been human settlements prior to the Clovis Culture, and the history of humans in the Americas may extend back many thousands of years before the Clovis culture. The amount of correlation between human arrival and megafauna extinction is still being debated: for example, in Wrangel Island in Siberia the extinction of dwarf woolly mammoths (approximately 2000 BCE) did not coincide with the arrival of humans, nor did megafaunal mass extinction on the South American continent, although it has been suggested climate changes induced by anthropogenic effects elsewhere in the world may have contributed.
Comparisons are sometimes made between recent extinctions (approximately since the industrial revolution) and the Pleistocene extinction near the end of the last glacial period. The latter is exemplified by the extinction of large herbivores such as the woolly mammoth and the carnivores that preyed on them. We know that humans of this era actively hunted the mammoth and the mastodon but it is not known if this hunting was the cause of the subsequent massive ecological changes, widespread extinctions and climate changes.
The ecosystems encountered by the first Americans had not been exposed to human interaction, and may have been far less resilient to human made changes than the ecosystems encountered by industrial era humans. Therefore, the actions of the Clovis people, despite seeming insignificant by today's standards could indeed have had a profound effect on the ecosystems and wild life which was entirely unused to human influence.
The following species, among many others, became extinct in this period.
Caribbean.
Human arrival around 6,000 years ago is correlated with the extinction of many species. Examples include:
Pacific islands.
Recent research, based on archaeological and paleontological digs on 70 different islands, has shown that numerous species became extinct as people moved across the Pacific, starting 30,000 years ago in the Bismarck Archipelago and Solomon Islands. It is currently estimated that among the bird species of the Pacific some 2000 species have gone extinct since the arrival of humans, representing a 20% drop in the biodiversity of birds worldwide. Among the extinctions were:
[[File:Cretanelephant-petermaas.jpg|thumb|
"Mammuthus creticus",a dwarf elephant once endemic to Crete. It was one of many species of small elephants found on islands in the Mediterranean.
Extinctions into the Common Era.
More recent settlement of isolated land masses where megafauna continued to survive almost immediately resulted in their extinction. Calculations suggest this occurred even if only a small number of animals were hunted. It has been suggested this contemporary evidence supports the theory that humans were capable of causing or at least contributing to the extinctions of the Quaternary extinction event.
Hawaiian islands.
The first settlers are thought to have arrived in the islands between 300 and 800 CE, with European arrival in the 16th century. Hawaii is notable for its endemism of plants, birds, insects, mollusks and fish; 30% of its organisms are endemic. Many of its species are endangered or have gone extinct, primarily due to accidentally introduced species and livestock grazing. Over 40% of its bird species have gone extinct, and it is the location of 75% of extinctions in the United States.
Extinction has increased in Hawaii over the last 200 years and is relatively well documented, with extinctions among native snails used as estimates for global extinction rates.
Indian Ocean Islands.
Starting circa 1500 years ago, a number of species became extinct upon human settlement of the islands, including:
Madagascar.
Within 500 years of the arrival of humans between 2,500-2,000 years ago, nearly all of Madagascar's distinct, endemic and geographically isolated megafauna became extinct. The largest animals, of more than 150 kg, were extincted very shortly after the first human arrival, with large and medium-sized species dying out after prolonged hunting pressure from an expanding human population moving into more remote regions of the island around 1000 years ago. Smaller fauna experienced initial increases due to decreased competition, and then subsequent declines over the last 500 years. All fauna weighing over 10 kg died out. The primary reasons for this are human hunting and habitat loss from early aridification, both of which persist and threaten Madagascar's remaining taxa today.
Recent extinctions - 1500 onwards.
One scientist estimates the current extinction rate may be 10,000 times the background extinction rate. Nevertheless, most scientists predict a much lower extinction rate than this outlying estimate. Stuart Pimm stated "the current rate of species extinction is about 100 times the natural rate" for plants. Mass extinctions are characterized by the loss of at least 75% of species within a geologically short period of time.
In a pair of studies published in 2015, extrapolation from observed extinction of Hawaiian snails led to the conclusion that 7% of all species on Earth may have been lost already.
Megafaunal extinctions continue into the 21st century. Modern extinctions are more directly attributable to human influences. Extinction rates are minimized in the popular imagination by the survival of captive populations of animals that are "extinct in the wild" (such as the Père David's deer, Hawaiian crow) and by marginal survivals of highly publicized megafauna that are "ecologically extinct" (such as the giant panda, Sumatran rhinoceros, North American black-footed ferret). However, the Holocene can also be characterisied by widespread extinctions among arthropods, widespread "local" extinctions of populations of species that still exist elsewhere (such as the extinction of gray whales in the Atlantic and of the leatherback sea turtle in Malaysia) and by universal declines in range and population of various animal and plant species throughout all of the world.
The IUCN characterises 'recent' extinction as those that have occurred past the cut-off point of 1500. The extinct species listed below are not comprehensive, but are some of the most famous examples.
New Zealand.
[[File:Dinornithidae SIZE 01.png|thumb|A size comparison between 4 recently extinct New Zealand moa species and a human.
1. "Dinornis novaezealandiae"
2. "Emeus crassus"
3. "Anomalopteryx didiformis"
4. "Dinornis robustus"
New Zealand is characterised by its geographic isolation and island biogeography, and had been isolated from mainland Australia for 80 million years. It was the last large land mass to be colonised by humans. The arrival of Polynesian settlers circa 12th century resulted in the extinction of all of the islands' megafaunal birds within several hundred years. The Polynesians also introduced kiore (rats) as a food source. This may have put some pressure on other birds but at the time of early European contact (18th Century) and colonisation (19th Century) the bird life was prolific. With them, the Europeans brought ship rats, possums, cats and mustelids which decimated native bird life, some of which had adapted flightlessness and ground nesting habits and others had no defensive behavior as a result of having no extant endemic mammalian predators. The Kakapo, the world's biggest parrot, which is flightless, now only exists in managed breeding sanctuaries and NZ's national emblem, the Kiwi, is on the endangered bird list.
Extinctions include, among many others:
Other notable recent extinctions.
Mammals.
Some examples of modern extinctions of "charismatic" mammal fauna include:
Birds.
Many birds have become extinct as a result of human activity, especially birds endemic to islands, including many flightless birds ("see a more complete list under "extinct birds). Notable extinct birds include:
Ten species or subspecies of birds have disappeared from the Hawaiian islands since the 1980s, primarily due to invasive species and habitat loss. These include:
Contemporary crises.
Peter Raven, past president of the American Association for the Advancement of Science (AAAS), states in the foreword to their publication "AAAS Atlas of Population and Environment": "We have driven the rate of biological extinction, the permanent loss of species, up several hundred times beyond its historical levels, and are threatened with the loss of a majority of all species by the end of the 21st century."
189 countries which are signatory to the Convention on Biological Diversity (Rio Accord) have committed to preparing a Biodiversity Action Plan, a first step at identifying specific endangered species and habitats, country by country.
Various species are predicted to become extinct in the near future.
Amphibian crisis.
The decline of amphibian populations has also been identified as an indicator of environmental degradation. As well as habitat loss, introduced predators and pollution, Chytridiomycosis, a fungal infection thought to have been accidentally spread by human travel, has caused severe population drops of several species of frogs, including (among many others) the extinction of the golden toad in Costa Rica and the Gastric-brooding frog in Australia. Many other amphibian species now face extinction, including the reduction of Rabb's fringe-limbed treefrog to an endling, and the extinction of the Panamanian golden frog in the wild. Chytrid fungus has spread across Australia, New Zealand, Central America and Africa, including countries with high amphibian diversity such as cloud forests in Honduras and Madagascar. "Batrachochytrium salamandrivorans" is a similar infection currently threatening salamanders. Amphibians are now the most endangered vertebrate group, having existed for more than 300 million years through three other mass extinctions.
Mass bat deaths.
Millions of bats in the US have been dying off since 2012 due to a fungal infection spread from European bats, which appear to be immune. Population drops have been as great as 90% within five years, and extinction of at least one bat species is predicted. There is currently no form of treatment, and such declines have been described as "unprecedented" in bat evolutionary history by Alan Hicks of the New York State Department of Environmental Conservation.
Global warming.
Global warming is widely accepted as being a contributor to extinction worldwide, in a similar way that previous extinction events have generally included a rapid change in global climate and meteorology. It is also expected to disrupt sex ratios in many reptiles which have temperature-dependent sex determination.
Degradation of marine habitats.
Rising levels of carbon dioxide are resulting in influx of this gas into the ocean, increasing its acidity. Marine organisms which possess Calcium Carbonate shells or exoskeletons experience physiological pressure as the carbonate reacts with acid. This is already resulting in coral bleaching on various coral reefs worldwide, which provide valuable habitat for very high biodiversity. Marine gastropods, bivalves and other invertebrates are also affected, as are any organisms that feed on them.
Fishing has had a devastating effect on marine organism populations for several centuries even before the explosion of destructive and highly effective fishing practices like trawling. Humans are unique among predators in that they regularly predate on other adult apex predators, particularly in marine environments; bluefin tuna and various sharks in particular are particularly vulnerable to predation pressure from human fishing.
Pollinator decline.
The term pollinator decline refers to the reduction in abundance of insect and other animal pollinators in many ecosystems worldwide beginning at the end of the twentieth century, and continuing into the present day.

</doc>
<doc id="14209" url="https://en.wikipedia.org/wiki?curid=14209" title="Hollywood-style Lindy Hop">
Hollywood-style Lindy Hop

Hollywood-style Lindy Hop is a variety of Lindy Hop, an American vernacular dance. It is also sometimes referred to as Dean Collins or Smooth-style, but these terms also sometimes refer to different styles of Lindy Hop.
Hollywood is the style reconstructed by Erik Robison and Sylvia Skylar based on movies from 1930s and 1940s featuring dancers like Dean Collins, Jewel McGowan, Jean Veloz and others.. They were the first to call it "Hollywood Style".
The swingout (the basic step of Lindy) is danced in a position often described as someone about to sit on a stool, thereby bringing their center point of balance closer to the ground. This piked position is the classic look of Hollywood with the back straight and a slight forward tilt. The Hollywood style is also a slotted dance, meaning the follower travels in a straight line instead of the more elliptical or circular Savoy-style Lindy Hop.
A popular variation of Hollywood-Style Lindy Hop called LA-style Lindy Hop has a few technical changes in the footwork and fewer steps. The steps are shortened or "cheated" to create this look. The style is geared towards performance and is heavily based on short choreographies. Originating in Los Angeles, California, LA-style is a favorite on the West Coast of the United States.

</doc>
<doc id="14210" url="https://en.wikipedia.org/wiki?curid=14210" title="Harrison Narcotics Tax Act">
Harrison Narcotics Tax Act

The Harrison Narcotics Tax Act (Ch. 1, ) was a United States federal law that regulated and taxed the production, importation, and distribution of opiates and coca products. The act was proposed by Representative Francis Burton Harrison of New York and was approved on December 17, 1914.
"An Act To provide for the registration of, with collectors of internal revenue, and to impose a special tax on all persons who produce, import, manufacture, compound, deal in, dispense, sell, distribute, or give away opium or coca leaves, their salts, derivatives, or preparations, and for other purposes." The courts interpreted this to mean that physicians could prescribe narcotics to patients in the course of normal treatment, but not for the treatment of addiction.
The Harrison Anti-Narcotic legislation consisted of three U.S. House bills imposing restrictions on the availability and consumption of the psychoactive drug opium. U.S. House bills and passed conjointly with House bill or the Opium and Coca Leaves Trade Restrictions Act.
Although technically illegal for purposes of distribution and use, the distribution, sale and use of cocaine was still legal for registered companies and individuals.
History.
International background.
Following the Spanish–American War the U.S. acquired the Philippines from Spain. At that time, opium addiction constituted a significant problem in the civilian population of the Philippines.
Charles Henry Brent was an American Episcopal bishop who served as Missionary Bishop of the Philippines beginning in 1901. He convened a Commission of Inquiry, known as the Brent Commission, for the purpose of examining alternatives to a licensing system for opium addicts. The Commission recommended that narcotics should be subject to international control. The recommendations of the Brent Commission were endorsed by the United States Department of State and in 1906 President Theodore Roosevelt called for an international conference, the International Opium Commission, which was held in Shanghai in February 1909. A second conference was held at The Hague in May 1911, and out of it came the first international drug control treaty, the International Opium Convention of 1912.
Domestic Background.
In the 1800s opiates and cocaine were mostly unregulated drugs. In the 1890s the Sears & Roebuck catalogue, which was distributed to millions of Americans homes, offered a syringe and a small amount of cocaine for $1.50. On the other hand, as early as 1880 some states and localities had already passed laws against smoking opium, at least in public.
At the beginning of the 20th century, cocaine began to be linked to crime. In 1900, the "Journal of the American Medical Association" published an editorial stating, "Negroes in the South are reported as being addicted to a new form of vice – that of 'cocaine sniffing' or the 'coke habit.'" Some newspapers later claimed cocaine use caused blacks to rape white women and was improving their pistol marksmanship. Chinese immigrants were blamed for importing the opium-smoking habit to the U.S. The 1903 blue-ribbon citizens' panel, the Committee on the Acquirement of the Drug Habit, concluded, "If the Chinaman cannot get along without his dope we can get along without him."
Theodore Roosevelt appointed Dr. Hamilton Wright as the first Opium Commissioner of the United States in 1908. In 1909, Wright attended the International Opium Commission in Shanghai as the American delegates. He was accompanied by Charles Henry Brent, the Episcopal Bishop. On March 12, 1911, Dr. Wright was quoted in as follows in an article in the New York Times: "Of all the nations of the world, the United States consumes most habit-forming drugs per capita. Opium, the most pernicious drug known to humanity, is surrounded, in this country, with far fewer safeguards than any other nation in Europe fences it with." Wright further claimed that "it has been authoritatively stated that cocaine is often the direct incentive to the crime of rape by the negroes of the South and other sections of the country," though he failed to mention specifically "which" authorities had stated that, and did not provide any evidence for his claim. Wright also stated that "one of the most unfortunate phases of smoking opium in this country is the large number of women who have become involved and were living as common-law wives or cohabitating with Chinese in the Chinatowns of our various cities".
Opium usage had begun to decline by 1914 after rising dramatically in the post Civil War Era, peaking at around one-half million pounds per year in 1896. Demand gradually declined thereafter in response to mounting public concern, local and state regulations, and the Pure Food and Drugs Act of 1906, which required labeling of patent medicines that contained opiates, cocaine, alcohol, cannabis and other intoxicants. As of 1911, an estimated one U.S. citizen in 400 (0.25%) was addicted to some form of opium. The opium addicts were mostly women who were prescribed and dispensed legal opiates by physicians and pharmacist for “female problems” (probably pain at menstruation) or white men and Chinese at the Opium dens. Between two-thirds and three-quarters of these addicts were women. By 1914, forty-six states had regulations on cocaine and twenty-nine states had laws against opium, morphine, and heroin.
Several authors have argued that the debate was merely to regulate trade and collect a tax. However, the committee report prior to the debate on the house floor and the debate itself, discussed the rise of opiate use in the United States. Harrison stated that "The purpose of this Bill can hardly be said to raise revenue, because it prohibits the importation of something upon which we have hitherto collected revenue." Later Harrison stated, "We are not attempting to collect revenue, but regulate commerce." House representative Thomas Sisson stated, "The purpose of this bill—and we are all in sympathy with it—is to prevent the use of opium in the United States, destructive as it is to human happiness and human life."
The drafters played on fears of “drug-crazed, sex-mad negroes” and made references to Negroes under the influence of drugs murdering whites, degenerate Mexicans smoking marijuana, and “Chinamen” seducing white women with drugs. Dr. Hamilton Wright, testified at a hearing for the Harrison Act. Wright alleged that drugs made blacks uncontrollable, gave them superhuman powers and caused them to rebel against white authority. Dr. Christopher Koch of the State Pharmacy Board of Pennsylvania testified that "Most of the attacks upon the white women of the South are the direct result of a cocaine-crazed Negro brain".
Before the Act was passed, on February 8, 1914, The "New York Times" published an article entitled "Negro Cocaine 'Fiends' Are New Southern Menace: Murder and Insanity Increasing Among Lower-Class Blacks" by Edward Huntington Williams, which reported that Southern sheriffs had increased the caliber of their weapons from .32 to .38 to bring down Negroes under the effect of cocaine.
Despite the extreme racialization of the issue that took place in the buildup to the Act's passage, the contemporary research on the subject indicated that black Americans were in fact using cocaine and opium at much "lower" rates than white Americans.
Effect.
Enforcement began in 1915.
The act appears to be concerned about the marketing of opiates. However a clause applying to doctors allowed distribution "in the course of his professional practice only." This clause was interpreted after 1917 to mean that a doctor could not prescribe opiates to an addict, since addiction was not considered a disease. A number of doctors were arrested and some were imprisoned. The medical profession quickly learned not to supply opiates to addicts. In "United States v. Doremus", 249 U.S. 86 (1919), the Supreme Court ruled that the Harrison Act was constitutional, and in "Webb v. United States", 249 U.S. 96, 99 (1919) that physicians could not prescribe narcotics solely for maintenance.
The impact of diminished supply was obvious by mid-1915. A 1918 commission called for sterner law enforcement, while newspapers published sensational articles about addiction-related crime waves. Congress responded by tightening up the Harrison Act—the importation of heroin for any purpose was banned in 1924.
After other complementary laws (for example implementing the Uniform State Narcotic Act in 1932), and other actions by the government the number of addicts of opium started to decrease fast from 1925 to a level that in 1945 that was about one tenth of the level in 1914.
The use of the term 'narcotics' in the title of the act to describe not just opiates but also cocaine—which is a central nervous system stimulant, not a narcotic—initiated a precedent of frequent legislative and judicial misclassification of various substances as 'narcotics'. Today, law enforcement agencies, popular media, the United Nations, other nations and even some medical practitioners can be observed applying the term very broadly and often pejoratively in reference to a wide range of illicit substances, regardless of the more precise definition existing in medical contexts. For this reason, however, 'narcotic' has come to mean any illegally used drug, but it is useful as a shorthand for referring to a controlled drug in a context where its legal status is more important than its physiological effects.
The remaining effect of this act, which has largely been superseded by the Controlled Substances Act of 1970, is the warning "*Warning: May be habit forming" on labels, package inserts, and other places where ingredients are listed in the case of many opioids, barbiturates, medicinal formulations of cocaine, and chloral hydrate.
The act also marks the beginning of the creation of the modern, criminal drug addict and the American black market for drugs. Within five years the Rainey Committee, a Special Committee on Investigation appointed by Secretary of the Treasury William Gibbs McAdoo and led by Congressman T. Rainey, reported in June, 1919 that drugs were being smuggled into the country by sea, and across the Mexican and Canadian borders by nationally established organisations and that the United States consumed 470,000 pounds of opium annually, compared to 17,000 pounds in both France and Germany. The Monthly Summary of Foreign Commerce of the United States recorded that in the 7 months to January 1920, 528,635 pounds of opium was imported, compared to 74,650 pounds in the same period in 1919.
Challenge.
The Act's applicability in prosecuting doctors who prescribe narcotics to addicts was successfully challenged in "Linder v. United States" in 1925, as Justice McReynolds ruled that the federal government has no power to regulate medical practice.

</doc>
<doc id="14215" url="https://en.wikipedia.org/wiki?curid=14215" title="Horse tack">
Horse tack

Tack is a piece of equipment or accessory equipped on horses in the course of their use as domesticated animals. Saddles, stirrups, bridles, halters, reins, bits, harnesses, martingales, and breastplates are all forms of horse tack. Equipping a horse is often referred to as tacking up. A room to store such equipment, usually near or in a stable, is a tack room.
Saddles.
Saddles are seats for the rider, fastened to the horse's back by means of a "girth" (English-style riding), known as a "cinch" in the Western US, a wide strap that goes around the horse at a point about four inches behind the forelegs. Some western saddles will also have a second strap known as a "flank" or "back cinch" that fastens at the rear of the saddle and goes around the widest part of the horse's belly.
It is important that the saddle be comfortable for both the rider and the horse as an improperly fitting saddle may create pressure points on the horse's back muscle (Latissimus dorsi) and cause the horse pain and can lead to the horse, rider, or both getting injured.
There are many types of saddle, each specially designed for its given task.
Saddles are usually divided into two major categories: "English saddles" and "Western saddles" according to the riding discipline they are used in. Other types of saddles, such as racing saddles, Australian saddles, sidesaddles and endurance saddles do not necessarily fit neatly in either category.
Stirrups.
Stirrups are supports for the rider's feet that hang down on either side of the saddle. They provide greater stability for the rider but can have safety concerns due to the potential for a rider's feet to get stuck in them. If a rider is thrown from a horse but has a foot caught in the stirrup, they could be dragged if the horse runs away. To minimize this risk, a number of safety precautions are taken. First, most riders wear riding boots with a heel and a smooth sole. Next, some saddles, particularly English saddles, have safety bars that allow a stirrup leather to fall off the saddle if pulled backwards by a falling rider. Other precautions are done with stirrup design itself. Western saddles have wide stirrup treads that make it more difficult for the foot to become trapped. A number of saddle styles incorporate a tapedero, which is covering over the front of the stirrup that keeps the foot from sliding all the way through the stirrup. The English stirrup (or "iron") has several design variations which are either shaped to allow the rider's foot to slip out easily or are closed with a very heavy rubber band. The invention of stirrups was of great historic significance in mounted combat, giving the rider secure foot support while on horseback.
Headgear.
"Bridles", hackamores, "halters" or "headcollars", and similar equipment consist of various arrangements of straps around the horse's head, and are used for control and communication with the animal.
Halters.
A "halter" (US) or "headcollar" (UK) (occasionally "headstall") consists of a noseband and headstall that buckles around the horse's head and allows the horse to be led or tied. The lead rope is separate, and it may be short (from six to ten feet, two to three meters) for everyday leading and tying, or much longer (up to , eight meters) for tasks such as for leading packhorses or for picketing a horse out to graze.
Some horses, particularly stallions, may have a chain attached to the lead rope and placed over the nose or under the jaw to increase the control provided by a halter while being led. Most of the time, horses are not ridden with a halter, as it offers insufficient precision and control. Halters have no bit.
In Australian and British English, a "halter" is a rope with a spliced running loop around the nose and another over the poll, used mainly for unbroken horses or for cattle. The lead rope cannot be removed from the halter. A show halter is made from rolled leather and the lead attaches to form the chinpiece of the noseband. These halters are not suitable for paddock usage or in loose stalls. An "underhalter" is a lightweight halter or headcollar which is made with only one small buckle, and can be worn under a bridle for tethering a horse without untacking.
Bridles.
Bridles usually have a "bit" attached to "reins" and are used for riding and driving horses.
"English Bridles" have a "cavesson" style noseband and are seen in English riding. Their reins are buckled to one another, and they have little adornment or flashy hardware.
"Western Bridles" used in Western riding usually have no noseband, are made of thin bridle leather. They may have long, separated "Split" reins or shorter closed reins, which sometimes include an attached "Romal". Western bridles are often adorned with silver or other decorative features.
"Double bridles" are a type of English bridle that use two bits in the mouth at once, a snaffle and a curb. The two bits allow the rider to have very precise control of the horse. As a rule, only very advanced horses and riders use double bridles. Double bridles are usually seen in the top levels of dressage, but also are seen in certain types of show hack and Saddle seat competition.
Hackamores and other bitless designs.
A "hackamore" is a headgear that utilizes a heavy noseband of some sort, rather than a bit, most often used to train young horses or to go easy on an older horse's mouth. Hackamores are more often seen in western riding. Some related styles of headgear that control a horse with a noseband rather than a bit are known as bitless bridles.
The word "hackamore" is derived from the Spanish word "jáquima." Hackamores are seen in western riding disciplines, as well as in endurance riding and English riding disciplines such as show jumping and the stadium phase of eventing. While the classic bosal-style hackamore is usually used to start young horses, other designs, such as various bitless bridles and the mechanical hackamore are often seen on mature horses with dental issues that make bit use painful, horses with certain training problems, and on horses with mouth or tongue injuries. Some riders also like to use them in the winter to avoid putting a frozen metal bit into a horse's mouth.
Like bitted bridles, noseband-based designs can be gentle or harsh, depending on the hands of the rider. It is a myth that a bit is cruel and a hackamore is gentler. The horse's face is very soft and sensitive with many nerve endings. Misuse of a hackamore can cause swelling on the nose, scraping on the nose and jawbone, and extreme misuse may cause damage to the bones and cartilage of the horse's head.
Other headgear.
A "longeing cavesson" (UK: "lungeing") is a special type of halter or noseband used for longeing a horse. Longeing is the activity of having a horse walk, trot and/or canter in a large circle around the handler at the end of a rope that is 25 to long. It is used for training and exercise.
Reins.
Reins consist of leather straps or rope attached to the outer ends of a "bit" and extend to the rider's or driver's hands. Reins are the means by which a horse rider or driver communicates directional commands to the horse's head. Pulling on the reins can be used to steer or stop the horse. The sides of a horse's mouth are sensitive, so pulling on the reins pulls the bit, which then pulls the horse's head from side to side, which is how the horse is controlled.
On some types of harnesses there might be supporting rings to carry the reins over the horse's back. When pairs of horses are used in drawing a wagon or coach it is usual for the outer side of each pair to be connected to reins and the inside of the bits connected by a short bridging strap or rope. The driver carries "four-in-hand" or "six-in-hand" being the number of reins connecting to the pairs of horses.
A rein may be attached to a halter to lead or guide the horse in a circle for training purposes or to lead a packhorse, but a simple lead rope is more often used for these purposes. A longe line is sometimes called a "longe rein," but it is actually a flat line about long, usually made of nylon or cotton web, about one inch wide, thus longer and wider than even a driving rein.
Horses should never be tied by the reins. Not only do they break easily, but, being attached to a bit in the horse's sensitive mouth, a great deal of pain can be inflicted if a bridled horse sets back against being tied.
Bits.
A bit is a device placed in a horse's mouth, kept on a horse's head by means of a headstall. There are many types, each useful for specific types of riding and training.
The mouthpiece of the bit does not rest on the teeth of the horse, but rather rests on the gums or "bars" of the horse's mouth in an interdental space behind the front incisors and in front of the back molars. It is important that the style of bit is appropriate to the horse's needs and is fitted properly for it to function properly and be as comfortable as possible for the horse.
The basic "classic" styles of bits are:
While there are literally hundreds of types of bit mouthpieces, bit rings and bit shanks, essentially there are really only two broad categories: direct pressure bits, broadly termed snaffle bits; and leverage bits, usually termed curbs.
Bits that act with direct pressure on the tongue and lips of the bit are in the general category of "snaffle" bits. Snaffle bits commonly have a single jointed mouthpiece and act with a nutcracker effect on the bars, tongue and occasionally roof of the mouth. However, regardless of mouthpiece, any bit that operates only on direct pressure is a "snaffle" bit.
Leverage bits have shanks coming off the mouthpiece to create leverage that applies pressure to the poll, chin groove and mouth of the horse are in the category of "curb" bits. Any bit with shanks that works off of leverage is a "curb" bit, regardless of whether the mouthpiece is solid or jointed.
Some combination or hybrid bits combine direct pressure and leverage, such as the Kimblewick or Kimberwicke, which adds slight leverage to a two-rein design that resembles a snaffle; and the four rein designs such as the single mouthpiece Pelham bit and the double bridle, which places a curb and a snaffle bit simultaneously in the horse's mouth.
In the wrong hands even the mildest bit can hurt the horse. Conversely, a very severe bit, in the right hands, can transmit subtle commands that cause no pain to the horse. Bit commands should be given with only the quietest movements of the hands, and much steering and stopping should be done with the legs and seat.
Harness.
A horse harness is a set of devices and straps that attaches a horse to a cart, carriage, sledge or any other load. There are two main styles of harnesses - breaststrap and collar and hames style. These differ in how the weight of the load is attached. Most Harnesses are made from leather, which is the traditional material for harnesses, though some designs are now made of nylon webbing or synthetic biothane.
A breaststrap harness has a wide leather strap going horizontally across the horses' breast, attached to the traces and then to the load. This is used only for lighter loads. A collar and hames harness has a collar around the horses' neck with wood or metal hames in the collar. The traces attach from the hames to the load. This type of harness is needed for heavy draft work.
Both types will also have a bridle and reins. A harness that is used to support shafts, such as on a cart pulled by a single horse, will also have a "saddle" attached to the harness to help the horse support the shafts and "breeching" to brake the forward motion of the vehicle, especially when stopping or moving downhill. Horses guiding vehicles by means of a pole, such as two-horse teams pulling a wagon, a hay-mower, or a dray, will have "pole-straps" attached to the lower part of the horse collar.
Breastplates and martingales.
Breastplates, breastcollars or breastgirths attach to the front of the saddle, cross the horse's chest, and usually have a strap that runs between the horse's front legs and attaches to the girth. They keep the saddle from sliding back or sideways. They are usually seen in demanding, fast-paced sports. They are crucial pieces of safety equipment for English riding activities requiring jumping, such as eventing, show jumping, polo, and fox hunting. They are also seen in Western riding events, particularly in rodeo, reining and cutting, where it is particularly important to prevent a saddle from shifting. They may also be worn in other horse show classes for decorative purposes.
A martingale is a piece of equipment that keeps a horse from raising its head too high. Various styles can be used as a control measure, to prevent the horse from avoiding rider commands by raising its head out of position; or as a safety measure to keep the horse from tossing its head high or hard enough to smack its rider in the face.
They are allowed in many types of competition, especially those where speed or jumping may be required, but are not allowed in most "flat" classes at horse shows, though an exception is made in a few classes limited exclusively to young or "green" horses who may not yet be fully trained.
Martingales are usually attached to the horse one of two ways. They are either attached to the center chest ring of a breastplate or, if no breastplate is worn, they are attached by two straps, one that goes around the horse's neck, and the other that attaches to the girth, with the martingale itself beginning at the point in the center of the chest where the neck and girth straps intersect.
Martingale types include:
There are other training devices that fall loosely in the martingale category, in that they use straps attached to the reins or bit which limit the movement of the horse's head or add leverage to the rider's hands in order to control the horse's head. Common devices of this nature include the overcheck, the chambon, de Gogue, grazing reins, draw reins and the "bitting harness" or "bitting rig". However, most of this equipment is used for training purposes and is not legal in any competition. In some disciplines, use of leverage devices, even in training, is controversial.

</doc>
<doc id="14216" url="https://en.wikipedia.org/wiki?curid=14216" title="Hausa language">
Hausa language

Hausa () ("Yaren Hausa" or "Harshen Hausa") is the Chadic language (a branch of the Afroasiatic language family) with the largest number of speakers, spoken as a first language by about 35 million people, and as a second language by millions more in Nigeria, and millions more in other countries, for a total of at least 41 million speakers. Originally the language of the Hausa people stretching across southern Niger and northern Nigeria, it has developed into a lingua franca across much of western Africa for purposes of trade. In the 20th and 21st centuries, it has become more commonly published in print and online.
There are a few traditional dialects, differing mostly due to tonality. The language was commonly written with a variant of the Arabic script known as ajami but is more often written with the Latin alphabet known as boko.
Classification.
Hausa belongs to the West Chadic languages subgroup of the Chadic languages group, which in turn is part of the Afroasiatic language family.
Geographic distribution.
Native speakers of Hausa, the Hausa people, are mostly to be found in Niger, in the north of Nigeria, and Chad. Furthermore, the language is used as a trade language across a much larger swathe of West Africa (Benin, Ghana, Cameroon, Togo, Ivory Coast etc.), Central Africa (Chad, Central African Republic, Gabon) and northwestern Sudan, particularly amongst Muslims.
It is taught at universities in Africa and around the world. The language is the most commonly spoken language in Nigeria, but unlike Yoruba and Igbo, it is also widely spoken outside Nigeria, especially in Niger, Ghana, Cameroon and Sudan. Radio stations like BBC, Radio France Internationale, China Radio International, Voice of Russia, Voice of America, Arewa 24 Deutsche Welle, and IRIB broadcast in Hausa.
Dialects.
Traditional dialects.
Eastern Hausa dialects include "Dauranchi" in Daura, "Kananci" which is spoken in Kano, "Bausanchi" in Bauchi, "Gudduranci" in Katagum Misau and part of Borno, "Kutebanci" in Taraba, and "Hadejanci" in Hadejiya.
Western Hausa dialects include "Sakkwatanci" in Sokoto, "Katsinanci" in Katsina, "Arewanci" in Gobir, Adar, Kebbi, and Zamfara, and "Kurhwayanci" in Kurfey in Niger. Katsina is transitional between Eastern and Western dialects.
Northern Hausa dialects include "Arewa" and "Arawci".
"Zazzaganci" in Zaria is the major Southern dialect.
The Daura ("Dauranchi") and Kano ("Kananci") dialect are the standard. The BBC, Deutsche Welle, Radio France Internationale and Voice of America offer Hausa services on their international news web sites using Dauranci and Kananci.
Northernmost dialects and loss of tonality.
The western to eastern Hausa dialects of "Kurhwayanci", "Daragaram" and "Aderawa", represent the traditional northernmost limit of native Hausa communities. These are spoken in the northernmost sahel and mid-Saharan regions in west and central Niger in the Tillaberi, Tahoua, Dosso, Maradi, Agadez and Zinder regions. While mutually comprehensible with other dialects (especially "Sakkwatanci", and to a lesser extent "Gaananci"), the northernmost dialects have slight grammatical and lexical differences owing to frequent contact with the Zarma and Tuareg groups and cultural changes owing to the geographical differences between the grassland and desert zones. These dialects also have the quality of being non-tonal or pitch accent dialects.
This link between non-tonality and geographic location is not limited to Hausa alone, but is exhibited in other northern dialects of neighbouring languages; such as the difference within Songhay language (between the non-tonal northernmost dialects of Koyra Chiini in Timbuktu and Koyraboro Senni in Gao; and the tonal southern Zarma dialect, spoken from western Niger to northern Ghana), and within the Soninke language (between the non-tonal northernmost dialects of Imraguen and Nemadi spoken in east-central Mauritania; and the tonal southern dialects of Senegal, Mali and the sahel).
Ghanaian Hausa dialect.
The Zaria Hausa dialect ("Gaananci"), spoken in Ghana, Togo, and western Ivory Coast, is a distinct western native Hausa dialect-bloc with adequate linguistic and media resources available. Separate smaller Hausa dialects are spoken by an unknown number of Hausa further west in parts of Burkina Faso, and in the Haoussa Foulane, Badji Haoussa, Guezou Haoussa, and Ansongo districts of northeastern Mali (where it is designated as a minority language by the Malian government), but there are very little linguistic resources and research done on these particular dialects at this time.
Gaananci forms a separate group from other Western Hausa dialects, as it now falls outside the contiguous Hausa-dominant area, and is usually identified by the use of "c" for "ky", and "j" for "gy". This is attributed to the fact that Ghana's Hausa population descend from Hausa-Fulani traders settled in the zongo districts of major trade-towns up and down the previous Asante, Gonja and Dagomba kingdoms stretching from the sahel to coastal regions, in particular the cities of Tamale, Salaga, Bawku, Bolgatanga, Achimota, Nima and Kumasi.
Gaananci exhibits noted inflected influences from Zarma, Gur, Dyula and Soninke, as Ghana is the westernmost area in which the Hausa language is a major lingua-franca; as well as it being the westernmost area both the Hausa and Djerma ethnic groups inhabit in large numbers. Immediately west from Ghana (in Ivory Coast, Togo, and Burkina Faso), Hausa is abruptly replaced with Dioula–Bambara as the main lingua-franca of what become predominantly Mandinka areas, and native Hausa populations plummet to a very small urban minority.
Because of this, and the presence of surrounding Akan, Gur and Mande languages, Gaananci was historically isolated from the other Hausa dialects. Despite this difference, grammatical similarities between "Sakkwatanci" and Ghanaian Hausa determine that the dialect, and the origin of the Ghanaian Hausa people themselves, are derived from the northwestern Hausa area surrounding Sokoto.
Hausa is also widely spoken by non-native Gur and Mande Ghanaian Muslims, but differs from Gaananci, and rather has features consistent with non-native Hausa dialects.
Other native dialects.
Hausa is also spoken various parts of Cameroon and Chad, which combined the mixed dialects of northern Nigeria and Niger. In addition, Arabic has had a great influence in the way Hausa is spoken by the native Hausa speakers in these areas.
Non-native Hausa.
In West Africa, Hausa's use as a lingua franca has given rise to non-native pronunciation that differs vastly from native pronunciation by way of key omissions of implosive and ejective consonants present in native Hausa dialects, such as "ɗ", "ɓ" and "kʼ/ƙ", which are pronounced by non-native speakers as "d", "b" and "k" respectively. This creates confusion among non-native and native Hausa speakers, as non-native pronunciation does not distinguish words like ' ("correct") and ' ("one-by-one"). Another difference between native and non-native Hausa is the omission of vowel length in words and change in the standard tone of native Hausa dialects (ranging from native Fulani and Tuareg Hausa-speakers omitting tone altogether, to Hausa speakers with Gur or Yoruba mother tongues using additional tonal structures similar to those used in their native languages). Use of masculine and feminine gender nouns and sentence structure are usually omitted or interchanged, and many native Hausa nouns and verbs are substituted with non-native terms from local languages.
Non-native speakers of Hausa numbered more than 25 million and, in some areas, live close to native Hausa. It has replaced many other languages especially in the north-central and north-eastern part of Nigeria and continues to gain popularity in other parts of Africa as a result of Hausa movies and musics which spread out throughout the region.
There are several pidgin forms of Hausa. Barikanchi was formerly used in the colonial army of Nigeria. Gibanawa is currently in widespread use in Jega in northwestern Nigeria, south of the native Hausa area.
Phonology.
Consonants.
Hausa has between 23 and 25 consonant phonemes depending on the speaker.
The three-way contrast between palatalized velars , plain velars , and labialized velars is found only before long and short , e.g. ('grass'), ('to increase'), ('shea-nuts'). Before front vowels, only palatalized and labialized velars occur, e.g. ('jealousy') vs. ('side of body'). Before rounded vowels, only labialized velars occur, e.g. ('ringworm').
Glottalic consonants.
Hausa has glottalic consonants (implosives and ejectives) at four or five places of articulation (depending on the dialect). They require movement of the glottis during pronunciation and have a staccato sound.
They are written with modified versions of Latin letters. They can also be denoted with an apostrophe, either before or after depending on the letter, as shown below.
Vowels.
Hausa has five phonetic vowel sounds, which can be either short or long, giving a total of 10 monophthongs. In addition, there are four joint vowels (diphthongs), giving a total number of 14 vowel phonemes.
Tones.
Hausa is a tonal language. Each of its five vowels may have low tone, high tone or falling tone. In standard written Hausa, tone is not marked. In recent linguistic and pedagogical materials, tone is marked by means of diacritics.
An acute accent () may be used for high tone, but the usual practice is to leave high tone unmarked.
Writing systems.
"Boko" (Latin).
Hausa's modern official orthography is a Latin-based alphabet called "boko", which was introduced in the 1930s by the British colonial administration.
The letter "ƴ" (y with a right hook) is used only in Niger; in Nigeria it is written "ʼy".
Tone, vowel length, and the distinction between and (which does not exist for all speakers) are not marked in writing. So, for example, "from" and "battle" are both written "daga".
"Ajami" (Arabic).
Hausa has also been written in "ajami", an Arabic alphabet, since the early 17th century. There is no standard system of using "ajami", and different writers may use letters with different values. Short vowels are written regularly with the help of vowel marks, which are seldom used in Arabic texts other than the Quran. Many medieval Hausa manuscripts in "ajami", similar to the Timbuktu Manuscripts, have been discovered recently; some of them even describe constellations and calendars.
In the following table, vowels are shown with the Arabic letter for "t" () as an example.
Other systems.
Hausa is one of three indigenous languages of Nigeria which has been rendered in braille.
At least three other writing systems for Hausa have been proposed or "discovered." None of these are in active use beyond perhaps some individuals.

</doc>
<doc id="14220" url="https://en.wikipedia.org/wiki?curid=14220" title="History of mathematics">
History of mathematics

The area of study known as the history of mathematics is primarily an investigation into the origin of discoveries in mathematics and, to a lesser extent, an investigation into the mathematical methods and notation of the past.
Before the modern age and the worldwide spread of knowledge, written examples of new mathematical developments have come to light only in a few locales. The most ancient mathematical texts available are "Plimpton 322" (Babylonian c. 1900 BC), the "Rhind Mathematical Papyrus" (Egyptian c. 2000-1800 BC) and the "Moscow Mathematical Papyrus" (Egyptian c. 1890 BC). All of these texts concern the so-called Pythagorean theorem, which seems to be the most ancient and widespread mathematical development after basic arithmetic and geometry.
The study of mathematics as a demonstrative discipline begins in the 6th century BC with the Pythagoreans, who coined the term "mathematics" from the ancient Greek "μάθημα" ("mathema"), meaning "subject of instruction". Greek mathematics greatly refined the methods (especially through the introduction of deductive reasoning and mathematical rigor in proofs) and expanded the subject matter of mathematics. Chinese mathematics made early contributions, including a place value system. The Hindu-Arabic numeral system and the rules for the use of its operations, in use throughout the world today, likely evolved over the course of the first millennium AD in India and were transmitted to the west via Islamic mathematics through the work of Muḥammad ibn Mūsā al-Khwārizmī. Islamic mathematics, in turn, developed and expanded the mathematics known to these civilizations. Many Greek and Arabic texts on mathematics were then translated into Latin, which led to further development of mathematics in medieval Europe.
From ancient times through the Middle Ages, periods of mathematical discovery were often followed by centuries of stagnation. Beginning in Renaissance Italy in the 16th century, new mathematical developments, interacting with new scientific discoveries, were made at an increasing pace that continues through the present day.
Prehistoric mathematics.
The origins of mathematical thought lie in the concepts of number, magnitude, and form. Modern studies of animal cognition have shown that these concepts are not unique to humans. Such concepts would have been part of everyday life in hunter-gatherer societies. The idea of the "number" concept evolving gradually over time is supported by the existence of languages which preserve the distinction between "one", "two", and "many", but not of numbers larger than two.
Prehistoric artifacts discovered in Africa, dated 20,000 years old or more suggest early attempts to quantify time. The Ishango bone, found near the headwaters of the Nile river (northeastern Congo), may be more than 20,000 years old and consists of a series of tally marks carved in three columns running the length of the bone. Common interpretations are that the Ishango bone shows either the earliest known demonstration of sequences of prime numbers or a six-month lunar calendar. Peter Rudman argues that the development of the concept of prime numbers could only have come about after the concept of division, which he dates to after 10,000 BC, with prime numbers probably not being understood until about 500 BC. He also writes that "no attempt has been made to explain why a tally of something should exhibit multiples of two, prime numbers between 10 and 20, and some numbers that are almost multiples of 10." The Ishango bone, according to scholar Alexander Marshack, may have influenced the later development of mathematics in Egypt as, like some entries on the Ishango bone, Egyptian arithmetic also made use of multiplication by 2; this, however, is disputed.
Predynastic Egyptians of the 5th millennium BC pictorially represented geometric designs. It has been claimed that megalithic monuments in England and Scotland, dating from the 3rd millennium BC, incorporate geometric ideas such as circles, ellipses, and Pythagorean triples in their design. All of the above are disputed however, and the currently oldest undisputed mathematical documents are from Babylonian and dynastic Egyptian sources.
Babylonian mathematics.
Babylonian mathematics refers to any mathematics of the peoples of Mesopotamia (modern Iraq) from the days of the early Sumerians through the Hellenistic period almost to the dawn of Christianity. The majority of Babylonian mathematical work comes from two widely separated periods: The first few hundred years of the second millennium BC (Old Babylonian period), and the last few centuries of the first millennium BC (Seleucid period). It is named Babylonian mathematics due to the central role of Babylon as a place of study. Later under the Arab Empire, Mesopotamia, especially Baghdad, once again became an important center of study for Islamic mathematics.
In contrast to the sparsity of sources in Egyptian mathematics, our knowledge of Babylonian mathematics is derived from more than 400 clay tablets unearthed since the 1850s. Written in Cuneiform script, tablets were inscribed whilst the clay was moist, and baked hard in an oven or by the heat of the sun. Some of these appear to be graded homework.
The earliest evidence of written mathematics dates back to the ancient Sumerians, who built the earliest civilization in Mesopotamia. They developed a complex system of metrology from 3000 BC. From around 2500 BC onwards, the Sumerians wrote multiplication tables on clay tablets and dealt with geometrical exercises and division problems. The earliest traces of the Babylonian numerals also date back to this period.
Babylonian mathematics were written using a sexagesimal (base-60) numeral system. From this derives the modern day usage of 60 seconds in a minute, 60 minutes in an hour, and 360 (60 x 6) degrees in a circle, as well as the use of seconds and minutes of arc to denote fractions of a degree. It is likely the sexagesimal system was chosen because 60 can be evenly divided by 2, 3, 4, 5, 6, 10, 12, 15, 20 and 30. Also, unlike the Egyptians, Greeks, and Romans, the Babylonians had a true place-value system, where digits written in the left column represented larger values, much as in the decimal system. The power of the Babylonian notational system lay in that it could be used to represent fractions as easily as whole numbers; thus multiplying two numbers that contained fractions was no different than multiplying integers, similar to our modern notation. The notational system of the Babylonians was the best of any civilization until the Renaissance, and its power allowed it to achieve remarkable computation accuracy and power; for example, the Babylonian tablet YBC 7289 gives an approximation of √2 accurate to five decimal places. The Babylonians lacked, however, an equivalent of the decimal point, and so the place value of a symbol often had to be inferred from the context. By the Seleucid period, the Babylonians had developed a zero symbol as a placeholder for empty positions; however it was only used for intermediate positions. This zero sign does not appear in terminal positions, thus the Babylonians came close but did not develop a true place value system.
Other topics covered by Babylonian mathematics include fractions, algebra, quadratic and cubic equations, and the calculation of regular reciprocal pairs. The tablets also include multiplication tables and methods for solving linear, quadratic equations and cubic equations, a remarkable achievement for the time. Tablets from the Old Babylonian period also contain the earliest known statement of the Pythagorean theorem. However, as with Egyptian mathematics, Babylonian mathematics shows no awareness of the difference between exact and approximate solutions, or the solvability of a problem, and most importantly, no explicit statement of the need for proofs or logical principles.
Egyptian mathematics.
Egyptian mathematics refers to mathematics written in the Egyptian language. From the Hellenistic period, Greek replaced Egyptian as the written language of Egyptian scholars. Mathematical study in Egypt later continued under the Arab Empire as part of Islamic mathematics, when Arabic became the written language of Egyptian scholars.
The most extensive Egyptian mathematical text is the Rhind papyrus (sometimes also called the Ahmes Papyrus after its author), dated to c. 1650 BC but likely a copy of an older document from the Middle Kingdom of about 2000-1800 BC. It is an instruction manual for students in arithmetic and geometry. In addition to giving area formulas and methods for multiplication, division and working with unit fractions, it also contains evidence of other mathematical knowledge, including composite and prime numbers; arithmetic, geometric and harmonic means; and simplistic understandings of both the Sieve of Eratosthenes and perfect number theory (namely, that of the number 6). It also shows how to solve first order linear equations as well as arithmetic and geometric series.
Another significant Egyptian mathematical text is the Moscow papyrus, also from the Middle Kingdom period, dated to c. 1890 BC. It consists of what are today called "word problems" or "story problems", which were apparently intended as entertainment. One problem is considered to be of particular importance because it gives a method for finding the volume of a frustum: "If you are told: A truncated pyramid of 6 for the vertical height by 4 on the base by 2 on the top. You are to square this 4, result 16. You are to double 4, result 8. You are to square 2, result 4. You are to add the 16, the 8, and the 4, result 28. You are to take one third of 6, result 2. You are to take 28 twice, result 56. See, it is 56. You will find it right."
Finally, the Berlin Papyrus 6619 (c. 1800 BC) shows that ancient Egyptians could solve a second-order algebraic equation.
Greek mathematics.
Greek mathematics refers to the mathematics written in the Greek language from the time of Thales of Miletus (~600 BC) to the closure of the Academy of Athens in 529 AD. Greek mathematicians lived in cities spread over the entire Eastern Mediterranean, from Italy to North Africa, but were united by culture and language. Greek mathematics of the period following Alexander the Great is sometimes called Hellenistic mathematics.
Greek mathematics was much more sophisticated than the mathematics that had been developed by earlier cultures. All surviving records of pre-Greek mathematics show the use of inductive reasoning, that is, repeated observations used to establish rules of thumb. Greek mathematicians, by contrast, used deductive reasoning. The Greeks used logic to derive conclusions from definitions and axioms, and used mathematical rigor to prove them.
Greek mathematics is thought to have begun with Thales of Miletus (c. 624–c.546 BC) and Pythagoras of Samos (c. 582–c. 507 BC). Although the extent of the influence is disputed, they were probably inspired by Egyptian and Babylonian mathematics. According to legend, Pythagoras traveled to Egypt to learn mathematics, geometry, and astronomy from Egyptian priests.
Thales used geometry to solve problems such as calculating the height of pyramids and the distance of ships from the shore. He is credited with the first use of deductive reasoning applied to geometry, by deriving four corollaries to Thales' Theorem. As a result, he has been hailed as the first true mathematician and the first known individual to whom a mathematical discovery has been attributed. Pythagoras established the Pythagorean School, whose doctrine it was that mathematics ruled the universe and whose motto was "All is number". It was the Pythagoreans who coined the term "mathematics", and with whom the study of mathematics for its own sake begins. The Pythagoreans are credited with the first proof of the Pythagorean theorem, though the statement of the theorem has a long history, and with the proof of the existence of irrational numbers.
Plato (428/427 BC – 348/347 BC) is important in the history of mathematics for inspiring and guiding others. His Platonic Academy, in Athens, became the mathematical center of the world in the 4th century BC, and it was from this school that the leading mathematicians of the day, such as Eudoxus of Cnidus, came. Plato also discussed the foundations of mathematics,
Eudoxus (408–c.355 BC) developed the method of exhaustion, a precursor of modern integration and a theory of ratios that avoided the problem of incommensurable magnitudes. The former allowed the calculations of areas and volumes of curvilinear figures, while the latter enabled subsequent geometers to make significant advances in geometry. Though he made no specific technical mathematical discoveries, Aristotle (384—c.322 BC) contributed significantly to the development of mathematics by laying the foundations of logic.
In the 3rd century BC, the premier center of mathematical education and research was the Musaeum of Alexandria. It was there that Euclid (c. 300 BC) taught, and wrote the "Elements", widely considered the most successful and influential textbook of all time. The "Elements" introduced mathematical rigor through the axiomatic method and is the earliest example of the format still used in mathematics today, that of definition, axiom, theorem, and proof. Although most of the contents of the "Elements" were already known, Euclid arranged them into a single, coherent logical framework. The "Elements" was known to all educated people in the West until the middle of the 20th century and its contents are still taught in geometry classes today. In addition to the familiar theorems of Euclidean geometry, the "Elements" was meant as an introductory textbook to all mathematical subjects of the time, such as number theory, algebra and solid geometry, including proofs that the square root of two is irrational and that there are infinitely many prime numbers. Euclid also wrote extensively on other subjects, such as conic sections, optics, spherical geometry, and mechanics, but only half of his writings survive.
Archimedes (c.287–212 BC) of Syracuse, widely considered the greatest mathematician of antiquity, used the method of exhaustion to calculate the area under the arc of a parabola with the summation of an infinite series, in a manner not too dissimilar from modern calculus. He also showed one could use the method of exhaustion to calculate the value of π with as much precision as desired, and obtained the most accurate value of π then known, 3 < π < 3. He also studied the spiral bearing his name, obtained formulas for the volumes of surfaces of revolution (paraboloid, ellipsoid, hyperboloid), and an ingenious system for expressing very large numbers. While he is also known for his contributions to physics and several advanced mechanical devices, Archimedes himself placed far greater value on the products of his thought and general mathematical principles. He regarded as his greatest achievement his finding of the surface area and volume of a sphere, which he obtained by proving these are 2/3 the surface area and volume of a cylinder circumscribing the sphere.
Apollonius of Perga (c. 262-190 BC) made significant advances to the study of conic sections, showing that one can obtain all three varieties of conic section by varying the angle of the plane that cuts a double-napped cone. He also coined the terminology in use today for conic sections, namely parabola ("place beside" or "comparison"), "ellipse" ("deficiency"), and "hyperbola" ("a throw beyond"). His work "Conics" is one of the best known and preserved mathematical works from antiquity, and in it he derives many theorems concerning conic sections that would prove invaluable to later mathematicians and astronomers studying planetary motion, such as Isaac Newton. While neither Apollonius nor any other Greek mathematicians made the leap to coordinate geometry, Apollonius' treatment of curves is in some ways similar to the modern treatment, and some of his work seems to anticipate the development of analytical geometry by Descartes some 1800 years later.
Around the same time, Eratosthenes of Cyrene (c. 276-194 BC) devised the Sieve of Eratosthenes for finding prime numbers. The 3rd century BC is generally regarded as the "Golden Age" of Greek mathematics, with advances in pure mathematics henceforth in relative decline. Nevertheless, in the centuries that followed significant advances were made in applied mathematics, most notably trigonometry, largely to address the needs of astronomers. Hipparchus of Nicaea (c. 190-120 BC) is considered the founder of trigonometry for compiling the first known trigonometric table, and to him is also due the systematic use of the 360 degree circle. Heron of Alexandria (c. 10–70 AD) is credited with Heron's formula for finding the area of a scalene triangle and with being the first to recognize the possibility of negative numbers possessing square roots. Menelaus of Alexandria (c. 100 AD) pioneered spherical trigonometry through Menelaus' theorem. The most complete and influential trigonometric work of antiquity is the "Almagest" of Ptolemy (c. AD 90-168), a landmark astronomical treatise whose trigonometric tables would be used by astronomers for the next thousand years. Ptolemy is also credited with Ptolemy's theorem for deriving trigonometric quantities, and the most accurate value of π outside of China until the medieval period, 3.1416.
Following a period of stagnation after Ptolemy, the period between 250 and 350 AD is sometimes referred to as the "Silver Age" of Greek mathematics. During this period, Diophantus made significant advances in algebra, particularly indeterminate analysis, which is also known as "Diophantine analysis". The study of Diophantine equations and Diophantine approximations is a significant area of research to this day. His main work was the "Arithmetica", a collection of 150 algebraic problems dealing with exact solutions to determinate and indeterminate equations. The "Arithmetica" had a significant influence on later mathematicians, such as Pierre de Fermat, who arrived at his famous Last Theorem after trying to generalize a problem he had read in the "Arithmetica" (that of dividing a square into two squares). Diophantus also made significant advances in notation, the "Arithmetica" being the first instance of algebraic symbolism and syncopation.
The first woman mathematician recorded by history was Hypatia of Alexandria (AD 350 - 415). She succeeded her father as Librarian at the Great Library and wrote many works on applied mathematics. Because of a political dispute, the Christian community in Alexandria punished her, presuming she was involved, by stripping her naked and scraping off her skin with clamshells (some say roofing tiles).
Chinese mathematics.
Early Chinese mathematics is so different from that of other parts of the world that it is reasonable to assume independent development. The oldest extant mathematical text from China is the "Chou Pei Suan Ching", variously dated to between 1200 BC and 100 BC, though a date of about 300 BC appears reasonable.
Of particular note is the use in Chinese mathematics of a decimal positional notation system, the so-called "rod numerals" in which distinct ciphers were used for numbers between 1 and 10, and additional ciphers for powers of ten. Thus, the number 123 would be written using the symbol for "1", followed by the symbol for "100", then the symbol for "2" followed by the symbol for "10", followed by the symbol for "3". This was the most advanced number system in the world at the time, apparently in use several centuries before the common era and well before the development of the Indian numeral system. Rod numerals allowed the representation of numbers as large as desired and allowed calculations to be carried out on the "suan pan", or Chinese abacus. The date of the invention of the "suan pan" is not certain, but the earliest written mention dates from AD 190, in Xu Yue's "Supplementary Notes on the Art of Figures".
The oldest existent work on geometry in China comes from the philosophical Mohist canon c. 330 BC, compiled by the followers of Mozi (470–390 BC). The "Mo Jing" described various aspects of many fields associated with physical science, and provided a small number of geometrical theorems as well.
In 212 BC, the Emperor Qin Shi Huang (Shi Huang-ti) commanded all books in the Qin Empire other than officially sanctioned ones be burned. This decree was not universally obeyed, but as a consequence of this order little is known about ancient Chinese mathematics before this date. After the book burning of 212 BC, the Han dynasty (202 BC–220 AD) produced works of mathematics which presumably expanded on works that are now lost. The most important of these is "The Nine Chapters on the Mathematical Art", the full title of which appeared by AD 179, but existed in part under other titles beforehand. It consists of 246 word problems involving agriculture, business, employment of geometry to figure height spans and dimension ratios for Chinese pagoda towers, engineering, surveying, and includes material on right triangles and values of π. It created mathematical proof for the Pythagorean theorem, and a mathematical formula for Gaussian elimination. Liu Hui commented on the work in the 3rd century AD, and gave a value of π accurate to 5 decimal places. Though more of a matter of computational stamina than theoretical insight, in the 5th century AD Zu Chongzhi computed the value of π to seven decimal places, which remained the most accurate value of π for almost the next 1000 years. He also established a method which would later be called Cavalieri's principle to find the volume of a sphere.
The high-water mark of Chinese mathematics occurs in the 13th century (latter part of the Song period), with the development of Chinese algebra. The most important text from that period is the "Precious Mirror of the Four Elements" by Chu Shih-chieh (fl. 1280-1303), dealing with the solution of simultaneous higher order algebraic equations using a method similar to Horner's method. The "Precious Mirror" also contains a diagram of Pascal's triangle with coefficients of binomial expansions through the eighth power, though both appear in Chinese works as early as 1100. The Chinese also made use of the complex combinatorial diagram known as the magic square and magic circles, described in ancient times and perfected by Yang Hui (AD 1238–1298).
Even after European mathematics began to flourish during the Renaissance, European and Chinese mathematics were separate traditions, with significant Chinese mathematical output in decline from the 13th century onwards. Jesuit missionaries such as Matteo Ricci carried mathematical ideas back and forth between the two cultures from the 16th to 18th centuries, though at this point far more mathematical ideas were entering China than leaving.
Indian mathematics.
The earliest civilization on the Indian subcontinent is the Indus Valley Civilization that flourished between 2600 and 1900 BC in the Indus river basin. Their cities were laid out with geometric regularity, but no known mathematical documents survive from this civilization.
The Hindu-Arabic numerals were invented by mathematicians in India. They were called "Hindu numerals". They were later called "Arabic" numerals by Europeans, because they were introduced in the West by Arab merchants.
Various symbol sets are used to represent numbers in the Hindu–Arabic numeral system, all of which evolved from the Brahmi numerals. Each of the roughly dozen major scripts of India has its own numeral glyphs (as one will note when perusing Unicode character charts). This table shows two examples:
The oldest extant mathematical records from India are the Sulba Sutras (dated variously between the 8th century BC and the 2nd century AD), appendices to religious texts which give simple rules for constructing altars of various shapes, such as squares, rectangles, parallelograms, and others. As with Egypt, the preoccupation with temple functions points to an origin of mathematics in religious ritual. The Sulba Sutras give methods for constructing a circle with approximately the same area as a given square, which imply several different approximations of the value of π. In addition, they compute the square root of 2 to several decimal places, list Pythagorean triples, and give a statement of the Pythagorean theorem. All of these results are present in Babylonian mathematics, indicating Mesopotamian influence. It is not known to what extent the Sulba Sutras influenced later Indian mathematicians. As in China, there is a lack of continuity in Indian mathematics; significant advances are separated by long periods of inactivity.
Pāṇini (c. 5th century BC) formulated the rules for Sanskrit grammar. His notation was similar to modern mathematical notation, and used metarules, transformations, and recursion. Pingala (roughly 3rd-1st centuries BC) in his treatise of prosody uses a device corresponding to a binary numeral system. His discussion of the combinatorics of meters corresponds to an elementary version of the binomial theorem. Pingala's work also contains the basic ideas of Fibonacci numbers (called "mātrāmeru").
The next significant mathematical documents from India after the "Sulba Sutras" are the "Siddhantas", astronomical treatises from the 4th and 5th centuries AD (Gupta period) showing strong Hellenistic influence. They are significant in that they contain the first instance of trigonometric relations based on the half-chord, as is the case in modern trigonometry, rather than the full chord, as was the case in Ptolemaic trigonometry. Through a series of translation errors, the words "sine" and "cosine" derive from the Sanskrit "jiya" and "kojiya".
In the 5th century AD, Aryabhata wrote the "Aryabhatiya", a slim volume, written in verse, intended to supplement the rules of calculation used in astronomy and mathematical mensuration, though with no feeling for logic or deductive methodology. Though about half of the entries are wrong, it is in the "Aryabhatiya" that the decimal place-value system first appears. Several centuries later, the Muslim mathematician Abu Rayhan Biruni described the "Aryabhatiya" as a "mix of common pebbles and costly crystals".
In the 7th century, Brahmagupta identified the Brahmagupta theorem, Brahmagupta's identity and Brahmagupta's formula, and for the first time, in "Brahma-sphuta-siddhanta", he lucidly explained the use of zero as both a placeholder and decimal digit, and explained the Hindu-Arabic numeral system. It was from a translation of this Indian text on mathematics (c. 770) that Islamic mathematicians were introduced to this numeral system, which they adapted as Arabic numerals. Islamic scholars carried knowledge of this number system to Europe by the 12th century, and it has now displaced all older number systems throughout the world. In the 10th century, Halayudha's commentary on Pingala's work contains a study of the Fibonacci sequence and Pascal's triangle, and describes the formation of a matrix.
In the 12th century, Bhāskara II lived in southern India and wrote extensively on all then known branches of mathematics. His work contains mathematical objects equivalent or approximately equivalent to infinitesimals, derivatives, the mean value theorem and the derivative of the sine function. To what extent he anticipated the invention of calculus is a controversial subject among historians of mathematics.
In the 14th century, Madhava of Sangamagrama, the founder of the so-called Kerala School of Mathematics, found the Madhava–Leibniz series, and, using 21 terms, computed the value of π as 3.14159265359. Madhava also found the Madhava-Gregory series to determine the arctangent, the Madhava-Newton power series to determine sine and cosine and the Taylor approximation for sine and cosine functions. In the 16th century, Jyesthadeva consolidated many of the Kerala School's developments and theorems in the "Yukti-bhāṣā". However, the Kerala School did not formulate a systematic theory of differentiation and integration, nor is there any direct evidence of their results being transmitted outside Kerala.
Islamic mathematics.
The Islamic Empire established across Persia, the Middle East, Central Asia, North Africa, Iberia, and in parts of India in the 8th century made significant contributions towards mathematics. Although most Islamic texts on mathematics were written in Arabic, most of them were not written by Arabs, since much like the status of Greek in the Hellenistic world, Arabic was used as the written language of non-Arab scholars throughout the Islamic world at the time. Persians contributed to the world of Mathematics alongside Arabs.
In the 9th century, the Persian mathematician Muḥammad ibn Mūsā al-Khwārizmī wrote several important books on the Hindu-Arabic numerals and on methods for solving equations. His book "On the Calculation with Hindu Numerals", written about 825, along with the work of Al-Kindi, were instrumental in spreading Indian mathematics and Indian numerals to the West. The word "algorithm" is derived from the Latinization of his name, Algoritmi, and the word "algebra" from the title of one of his works, "Al-Kitāb al-mukhtaṣar fī hīsāb al-ğabr wa’l-muqābala" ("The Compendious Book on Calculation by Completion and Balancing"). He gave an exhaustive explanation for the algebraic solution of quadratic equations with positive roots, and he was the first to teach algebra in an elementary form and for its own sake. He also discussed the fundamental method of "reduction" and "balancing", referring to the transposition of subtracted terms to the other side of an equation, that is, the cancellation of like terms on opposite sides of the equation. This is the operation which al-Khwārizmī originally described as "al-jabr". His algebra was also no longer concerned "with a series of problems to be resolved, but an exposition which starts with primitive terms in which the combinations must give all possible prototypes for equations, which henceforward explicitly constitute the true object of study." He also studied an equation for its own sake and "in a generic manner, insofar as it does not simply emerge in the course of solving a problem, but is specifically called on to define an infinite class of problems."
In Egypt, Abu Kamil extended algebra to the set of irrational numbers, accepting square roots and fourth roots as solutions and coefficients to quadratic equations. He also developed techniques used to solve three non-linear simultaneous equations with three unknown variables. One unique feature of his works was trying to find all the possible solutions to some of his problems, including one where he found 2676 solutions. His works formed an important foundation for the development of algebra and influenced later mathematicians, such as al-Karaji and Fibonacci.
Further developments in algebra were made by Al-Karaji in his treatise "al-Fakhri", where he extends the methodology to incorporate integer powers and integer roots of unknown quantities. Something close to a proof by mathematical induction appears in a book written by Al-Karaji around 1000 AD, who used it to prove the binomial theorem, Pascal's triangle, and the sum of integral cubes. The historian of mathematics, F. Woepcke, praised Al-Karaji for being "the first who introduced the theory of algebraic calculus." Also in the 10th century, Abul Wafa translated the works of Diophantus into Arabic. Ibn al-Haytham was the first mathematician to derive the formula for the sum of the fourth powers, using a method that is readily generalizable for determining the general formula for the sum of any integral powers. He performed an integration in order to find the volume of a paraboloid, and was able to generalize his result for the integrals of polynomials up to the fourth degree. He thus came close to finding a general formula for the integrals of polynomials, but he was not concerned with any polynomials higher than the fourth degree.
In the late 11th century, Omar Khayyam wrote "Discussions of the Difficulties in Euclid", a book about what he perceived as flaws in Euclid's "Elements", especially the parallel postulate. He was also the first to find the general geometric solution to cubic equations. He was also very influential in calendar reform.
In the 13th century, Nasir al-Din Tusi (Nasireddin) made advances in spherical trigonometry. He also wrote influential work on Euclid's parallel postulate. In the 15th century, Ghiyath al-Kashi computed the value of π to the 16th decimal place. Kashi also had an algorithm for calculating "n"th roots, which was a special case of the methods given many centuries later by Ruffini and Horner.
Other achievements of Muslim mathematicians during this period include the addition of the decimal point notation to the Arabic numerals, the discovery of all the modern trigonometric functions besides the sine, al-Kindi's introduction of cryptanalysis and frequency analysis, the development of analytic geometry by Ibn al-Haytham, the beginning of algebraic geometry by Omar Khayyam and the development of an algebraic notation by al-Qalasādī.
During the time of the Ottoman Empire and Safavid Empire from the 15th century, the development of Islamic mathematics became stagnant.
Medieval European mathematics.
Medieval European interest in mathematics was driven by concerns quite different from those of modern mathematicians. One driving element was the belief that mathematics provided the key to understanding the created order of nature, frequently justified by Plato's "Timaeus" and the biblical passage (in the "Book of Wisdom") that God had "ordered all things in measure, and number, and weight".
Boethius provided a place for mathematics in the curriculum in the 6th century when he coined the term "quadrivium" to describe the study of arithmetic, geometry, astronomy, and music. He wrote "De institutione arithmetica", a free translation from the Greek of Nicomachus's "Introduction to Arithmetic"; "De institutione musica", also derived from Greek sources; and a series of excerpts from Euclid's "Elements". His works were theoretical, rather than practical, and were the basis of mathematical study until the recovery of Greek and Arabic mathematical works.
In the 12th century, European scholars traveled to Spain and Sicily seeking scientific Arabic texts, including al-Khwārizmī's "The Compendious Book on Calculation by Completion and Balancing", translated into Latin by Robert of Chester, and the complete text of Euclid's "Elements", translated in various versions by Adelard of Bath, Herman of Carinthia, and Gerard of Cremona.
These new sources sparked a renewal of mathematics. Fibonacci, writing in the "Liber Abaci", in 1202 and updated in 1254, produced the first significant mathematics in Europe since the time of Eratosthenes, a gap of more than a thousand years. The work introduced Hindu-Arabic numerals to Europe, and discussed many other mathematical problems. 
The 14th century saw the development of new mathematical concepts to investigate a wide range of problems. One important contribution was development of mathematics of local motion.
Thomas Bradwardine proposed that speed (V) increases in arithmetic proportion as the ratio of force (F) to resistance (R) increases in geometric proportion. Bradwardine expressed this by a series of specific examples, but although the logarithm had not yet been conceived, we can express his conclusion anachronistically by writing:
V = log (F/R). Bradwardine's analysis is an example of transferring a mathematical technique used by al-Kindi and Arnald of Villanova to quantify the nature of compound medicines to a different physical problem.
One of the 14th-century Oxford Calculators, William Heytesbury, lacking differential calculus and the concept of limits, proposed to measure instantaneous speed "by the path that would be described by body if... it were moved uniformly at the same degree of speed with which it is moved in that given instant".
Heytesbury and others mathematically determined the distance covered by a body undergoing uniformly accelerated motion (today solved by integration), stating that "a moving body uniformly acquiring or losing that increment speed will traverse in some given time a completely equal to that which it would traverse if it were moving continuously through the same time with the mean degree [of speed".
Nicole Oresme at the University of Paris and the Italian Giovanni di Casali independently provided graphical demonstrations of this relationship, asserting that the area under the line depicting the constant acceleration, represented the total distance traveled. In a later mathematical commentary on Euclid's "Elements", Oresme made a more detailed general analysis in which he demonstrated that a body will acquire in each successive increment of time an increment of any quality that increases as the odd numbers. Since Euclid had demonstrated the sum of the odd numbers are the square numbers, the total quality acquired by the body increases as the square of the time.
Renaissance mathematics.
During the Renaissance, the development of mathematics and of accounting were intertwined. While there is no direct relationship between algebra and accounting, the teaching of the subjects and the books published often intended for the children of merchants who were sent to reckoning schools (in Flanders and Germany) or abacus schools (known as "abbaco" in Italy), where they learned the skills useful for trade and commerce. There is probably no need for algebra in performing bookkeeping operations, but for complex bartering operations or the calculation of compound interest, a basic knowledge of arithmetic was mandatory and knowledge of algebra was very useful.
Piero della Francesca (c.1415–1492) wrote books on solid geometry and linear perspective, including "De Prospectiva Pingendi (On Perspective for Painting)", "Trattato d’Abaco (Abacus Treatise)", and "De corporibus regularibus (Regular Solids)".
Luca Pacioli's "Summa de Arithmetica, Geometria, Proportioni et Proportionalità" (Italian: "Review of Arithmetic, Geometry, Ratio and Proportion") was first printed and published in Venice in 1494. It included a 27-page treatise on bookkeeping, ""Particularis de Computis et Scripturis"" (Italian: "Details of Calculation and Recording"). It was written primarily for, and sold mainly to, merchants who used the book as a reference text, as a source of pleasure from the mathematical puzzles it contained, and to aid the education of their sons. In "Summa Arithmetica", Pacioli introduced symbols for plus and minus for the first time in a printed book, symbols that became standard notation in Italian Renaissance mathematics. "Summa Arithmetica" was also the first known book printed in Italy to contain algebra. Pacioli obtained many of his ideas from Piero Della Francesca whom he plagiarized.
In Italy, during the first half of the 16th century, Scipione del Ferro and Niccolò Fontana Tartaglia discovered solutions for cubic equations. Gerolamo Cardano published them in his 1545 book "Ars Magna", together with a solution for the quartic equations, discovered by his student Lodovico Ferrari. In 1572 Rafael Bombelli published his "L'Algebra" in which he showed how to deal with the imaginary quantities that could appear in Cardano's formula for solving cubic equations.
Simon Stevin's book "De Thiende" ('the art of tenths'), first published in Dutch in 1585, contained the first systematic treatment of decimal notation, which influenced all later work on the real number system.
Driven by the demands of navigation and the growing need for accurate maps of large areas, trigonometry grew to be a major branch of mathematics. Bartholomaeus Pitiscus was the first to use the word, publishing his "Trigonometria" in 1595. Regiomontanus's table of sines and cosines was published in 1533.
During the Renaissance the desire of artists to represent the natural world realistically, together with the rediscovered philosophy of the Greeks, led artists to study mathematics. They were also the engineers and architects of that time, and so had need of mathematics in any case. The art of painting in perspective, and the developments in geometry that involved, were studied intensely.
Mathematics during the Scientific Revolution.
17th century.
The 17th century saw an unprecedented increase of mathematical and scientific ideas across Europe. Galileo observed the moons of Jupiter in orbit about that planet, using a telescope based on a toy imported from Holland. Tycho Brahe had gathered an enormous quantity of mathematical data describing the positions of the planets in the sky. By his position as Brahe's assistant, Johannes Kepler was first exposed to and seriously interacted with the topic of planetary motion. Kepler's calculations were made simpler by the contemporaneous invention of logarithms by John Napier and Jost Bürgi. Kepler succeeded in formulating mathematical laws of planetary motion.
The analytic geometry developed by René Descartes (1596–1650) allowed those orbits to be plotted on a graph, in Cartesian coordinates.
Building on earlier work by many predecessors, Isaac Newton discovered the laws of physics explaining Kepler's Laws, and brought together the concepts now known as calculus. Independently, Gottfried Wilhelm Leibniz, who is arguably one of the most important mathematicians of the 17th century, developed calculus and much of the calculus notation still in use today. Science and mathematics had become an international endeavor, which would soon spread over the entire world.
In addition to the application of mathematics to the studies of the heavens, applied mathematics began to expand into new areas, with the correspondence of Pierre de Fermat and Blaise Pascal. Pascal and Fermat set the groundwork for the investigations of probability theory and the corresponding rules of combinatorics in their discussions over a game of gambling. Pascal, with his wager, attempted to use the newly developing probability theory to argue for a life devoted to religion, on the grounds that even if the probability of success was small, the rewards were infinite. In some sense, this foreshadowed the development of utility theory in the 18th–19th century.
18th century.
The most influential mathematician of the 18th century was arguably Leonhard Euler. His contributions range from founding the study of graph theory with the Seven Bridges of Königsberg problem to standardizing many modern mathematical terms and notations. For example, he named the square root of minus 1 with the symbol "i", and he popularized the use of the Greek letter formula_1 to stand for the ratio of a circle's circumference to its diameter. He made numerous contributions to the study of topology, graph theory, calculus, combinatorics, and complex analysis, as evidenced by the multitude of theorems and notations named for him.
Other important European mathematicians of the 18th century included Joseph Louis Lagrange, who did pioneering work in number theory, algebra, differential calculus, and the calculus of variations, and Laplace who, in the age of Napoleon, did important work on the foundations of celestial mechanics and on statistics.
Modern mathematics.
19th century.
Throughout the 19th century mathematics became increasingly abstract. Carl Friedrich Gauss (1777–1855) epitomizes this trend. He did revolutionary work on functions of complex variables, in geometry, and on the convergence of series, leaving aside his many contributions to science. He also gave the first satisfactory proofs of the fundamental theorem of algebra and of the quadratic reciprocity law.
This century saw the development of the two forms of non-Euclidean geometry, where the parallel postulate of Euclidean geometry no longer holds.
The Russian mathematician Nikolai Ivanovich Lobachevsky and his rival, the Hungarian mathematician János Bolyai, independently defined and studied hyperbolic geometry, where uniqueness of parallels no longer holds. In this geometry the sum of angles in a triangle add up to less than 180°. Elliptic geometry was developed later in the 19th century by the German mathematician Bernhard Riemann; here no parallel can be found and the angles in a triangle add up to more than 180°. Riemann also developed Riemannian geometry, which unifies and vastly generalizes the three types of geometry, and he defined the concept of a manifold, which generalizes the ideas of curves and surfaces.
The 19th century saw the beginning of a great deal of abstract algebra. Hermann Grassmann in Germany gave a first version of vector spaces, William Rowan Hamilton in Ireland developed noncommutative algebra. The British mathematician George Boole devised an algebra that soon evolved into what is now called Boolean algebra, in which the only numbers were 0 and 1. Boolean algebra is the starting point of mathematical logic and has important applications in computer science.
Augustin-Louis Cauchy, Bernhard Riemann, and Karl Weierstrass reformulated the calculus in a more rigorous fashion.
Also, for the first time, the limits of mathematics were explored. Niels Henrik Abel, a Norwegian, and Évariste Galois, a Frenchman, proved that there is no general algebraic method for solving polynomial equations of degree greater than four (Abel–Ruffini theorem). Other 19th-century mathematicians utilized this in their proofs that straightedge and compass alone are not sufficient to trisect an arbitrary angle, to construct the side of a cube twice the volume of a given cube, nor to construct a square equal in area to a given circle. Mathematicians had vainly attempted to solve all of these problems since the time of the ancient Greeks. On the other hand, the limitation of three dimensions in geometry was surpassed in the 19th century through considerations of parameter space and hypercomplex numbers.
Abel and Galois's investigations into the solutions of various polynomial equations laid the groundwork for further developments of group theory, and the associated fields of abstract algebra. In the 20th century physicists and other scientists have seen group theory as the ideal way to study symmetry.
In the later 19th century, Georg Cantor established the first foundations of set theory, which enabled the rigorous treatment of the notion of infinity and has become the common language of nearly all mathematics. Cantor's set theory, and the rise of mathematical logic in the hands of Peano, L. E. J. Brouwer, David Hilbert, Bertrand Russell, and A.N. Whitehead, initiated a long running debate on the foundations of mathematics.
The 19th century saw the founding of a number of national mathematical societies: the London Mathematical Society in 1865, the Société Mathématique de France in 1872, the Circolo Matematico di Palermo in 1884, the Edinburgh Mathematical Society in 1883, and the American Mathematical Society in 1888. The first international, special-interest society, the Quaternion Society, was formed in 1899, in the context of a vector controversy.
In 1897, Hensel introduced p-adic numbers.
20th century.
The 20th century saw mathematics become a major profession. Every year, thousands of new Ph.D.s in mathematics were awarded, and jobs were available in both teaching and industry. An effort to catalogue the areas and applications of mathematics was undertaken in Klein's encyclopedia.
In a 1900 speech to the International Congress of Mathematicians, David Hilbert set out a list of 23 unsolved problems in mathematics. These problems, spanning many areas of mathematics, formed a central focus for much of 20th-century mathematics. Today, 10 have been solved, 7 are partially solved, and 2 are still open. The remaining 4 are too loosely formulated to be stated as solved or not.
Notable historical conjectures were finally proven. In 1976, Wolfgang Haken and Kenneth Appel used a computer to prove the four color theorem. Andrew Wiles, building on the work of others, proved Fermat's Last Theorem in 1995. Paul Cohen and Kurt Gödel proved that the continuum hypothesis is independent of (could neither be proved nor disproved from) the standard axioms of set theory. In 1998 Thomas Callister Hales proved the Kepler conjecture.
Mathematical collaborations of unprecedented size and scope took place. An example is the classification of finite simple groups (also called the "enormous theorem"), whose proof between 1955 and 1983 required 500-odd journal articles by about 100 authors, and filling tens of thousands of pages. A group of French mathematicians, including Jean Dieudonné and André Weil, publishing under the pseudonym "Nicolas Bourbaki", attempted to exposit all of known mathematics as a coherent rigorous whole. The resulting several dozen volumes has had a controversial influence on mathematical education.
Differential geometry came into its own when Einstein used it in general relativity. Entire new areas of mathematics such as mathematical logic, topology, and John von Neumann's game theory changed the kinds of questions that could be answered by mathematical methods. All kinds of structures were abstracted using axioms and given names like metric spaces, topological spaces etc. As mathematicians do, the concept of an abstract structure was itself abstracted and led to category theory. Grothendieck and Serre recast algebraic geometry using sheaf theory. Large advances were made in the qualitative study of dynamical systems that Poincaré had begun in the 1890s.
Measure theory was developed in the late 19th and early 20th centuries. Applications of measures include the Lebesgue integral, Kolmogorov's axiomatisation of probability theory, and ergodic theory. Knot theory greatly expanded. Quantum mechanics led to the development of functional analysis. Other new areas include, Laurent Schwartz's distribution theory, fixed point theory, singularity theory and René Thom's catastrophe theory, model theory, and Mandelbrot's fractals. Lie theory with its Lie groups and Lie algebras became one of the major areas of study.
Non-standard analysis, introduced by Abraham Robinson, rehabillitated the infinitesimal approach to calculus, which had fallen into disrepute in favour of the theory of limits, by extending the field of real numbers to the Hyperreal numbers which include infinitesimal and infinite quantities. An even larger number system, the surreal numbers were discovered by John Horton Conway in connection with combinatorial games.
The development and continual improvement of computers, at first mechanical analog machines and then digital electronic machines, allowed industry to deal with larger and larger amounts of data to facilitate mass production and distribution and communication, and new areas of mathematics were developed to deal with this: Alan Turing's computability theory; complexity theory; Derrick Henry Lehmer's use of ENIAC to further number theory and the Lucas-Lehmer test; Claude Shannon's information theory; signal processing; data analysis; optimization and other areas of operations research. In the preceding centuries much mathematical focus was on calculus and continuous functions, but the rise of computing and communication networks led to an increasing importance of discrete concepts and the expansion of combinatorics including graph theory. The speed and data processing abilities of computers also enabled the handling of mathematical problems that were too time-consuming to deal with by pencil and paper calculations, leading to areas such as numerical analysis and symbolic computation. Some of the most important methods and algorithms of the 20th century are: the simplex algorithm, the Fast Fourier Transform, error-correcting codes, the Kalman filter from control theory and the RSA algorithm of public-key cryptography.
At the same time, deep insights were made about the limitations to mathematics. In 1929 and 1930, it was proved the truth or falsity of all statements formulated about the natural numbers plus one of addition and multiplication, was decidable, i.e. could be determined by some algorithm. In 1931, Kurt Gödel found that this was not the case for the natural numbers plus both addition and multiplication; this system, known as Peano arithmetic, was in fact incompletable. (Peano arithmetic is adequate for a good deal of number theory, including the notion of prime number.) A consequence of Gödel's two incompleteness theorems is that in any mathematical system that includes Peano arithmetic (including all of analysis and geometry), truth necessarily outruns proof, i.e. there are true statements that cannot be proved within the system. Hence mathematics cannot be reduced to mathematical logic, and David Hilbert's dream of making all of mathematics complete and consistent needed to be reformulated.
One of the more colorful figures in 20th-century mathematics was Srinivasa Aiyangar Ramanujan (1887–1920), an Indian autodidact who conjectured or proved over 3000 theorems, including properties of highly composite numbers, the partition function and its asymptotics, and mock theta functions. He also made major investigations in the areas of gamma functions, modular forms, divergent series, hypergeometric series and prime number theory.
Paul Erdős published more papers than any other mathematician in history, working with hundreds of collaborators. Mathematicians have a game equivalent to the Kevin Bacon Game, which leads to the Erdős number of a mathematician. This describes the "collaborative distance" between a person and Paul Erdős, as measured by joint authorship of mathematical papers.
Emmy Noether has been described by many as the most important woman in the history of mathematics. She studied the theories of rings, fields, and algebras.
As in most areas of study, the explosion of knowledge in the scientific age has led to specialization: by the end of the century there were hundreds of specialized areas in mathematics and the Mathematics Subject Classification was dozens of pages long. More and more mathematical journals were published and, by the end of the century, the development of the world wide web led to online publishing.
21st century.
In 2000, the Clay Mathematics Institute announced the seven Millennium Prize Problems, and in 2003 the Poincaré conjecture was solved by Grigori Perelman (who declined to accept an award, as he was critical of the mathematics establishment).
Most mathematical journals now have online versions as well as print versions, and many online-only journals are launched. There is an increasing drive towards open access publishing, first popularized by the arXiv.
Future of mathematics.
There are many observable trends in mathematics, the most notable being that the subject is growing ever larger, computers are ever more important and powerful, the application of mathematics to bioinformatics is rapidly expanding, the volume of data to be analyzed being produced by science and industry, facilitated by computers, is explosively expanding.

</doc>
<doc id="14223" url="https://en.wikipedia.org/wiki?curid=14223" title="HSK">
HSK

HSK may refer to:

</doc>
<doc id="14225" url="https://en.wikipedia.org/wiki?curid=14225" title="Hydrogen atom">
Hydrogen atom

A hydrogen atom is an atom of the chemical element hydrogen. The electrically neutral atom contains a single positively charged proton and a single negatively charged electron bound to the nucleus by the Coulomb force. Atomic hydrogen constitutes about 75% of the elemental (baryonic) mass of the universe.
In everyday life on Earth, isolated hydrogen atoms (usually called "atomic hydrogen" or, more precisely, "monatomic hydrogen") are extremely rare. Instead, hydrogen tends to combine with other atoms in compounds, or with itself to form ordinary (diatomic) hydrogen gas, H2. "Atomic hydrogen" and "hydrogen atom" in ordinary English use have overlapping, yet distinct, meanings. For example, a water molecule contains two hydrogen atoms, but does not contain atomic hydrogen (which would refer to isolated hydrogen atoms).
Attempts to develop a theoretical understanding of the hydrogen atom have been important to the history of quantum mechanics.
Isotopes.
The most abundant isotope, hydrogen-1, protium, or light hydrogen, contains no neutrons and is just a proton and an electron. Protium is stable and makes up 99.9885% of naturally occurring hydrogen by absolute number (not mass).
Deuterium contains one neutron and one proton. Deuterium is stable and makes up 0.0115% of naturally occurring hydrogen and is used in industrial processes like nuclear reactors and Nuclear Magnetic Resonance.
Tritium contains two neutrons and one proton and is not stable, decaying with a half-life of 12.32 years. Because of the short half life, Tritium does not exist in nature except in trace amounts.
Higher isotopes of hydrogen are only created in artificial accelerators and reactors and have half lives around the order of 10−22 seconds.
The formulas below are valid for all three isotopes of hydrogen, but slightly different values of the Rydberg constant (correction formula given below) must be used for each hydrogen isotope.
Hydrogen ion.
Hydrogen is not found without its electron in ordinary chemistry (room temperatures and pressures), as ionized hydrogen is highly chemically reactive. When ionized hydrogen is written as "H+" as in the solvation of classical acids such as hydrochloric acid, the hydronium ion, H3O+, is meant, not a literal ionized single hydrogen atom. In that case, the acid transfers the proton to H2O to form H3O+.
Ionized hydrogen without its electron, or free protons, are common in the interstellar medium, and solar wind.
Theoretical analysis.
The hydrogen atom has special significance in quantum mechanics and quantum field theory as a simple two-body problem physical system which has yielded many simple analytical solutions in closed-form.
Failed classical description.
Experiments by Rutherford in 1909 showed the structure of the atom be a dense, positive nucleus with a light, negative charge orbiting around it. This immediately caused problems on how such a system could be stable. Classical electromagnetism had shown that any accelerating charge radiates energy described through the Larmor formula. If the electron is assumed to orbit in a perfect circle and radiates energy continuously, the electron would spiral into the nucleus with a fall time of:
Where formula_2 is the Bohr radius and formula_3 is the classical electron radius. If this were true, all atoms would instantly collapse, however atoms seem to be stable. Furthermore, the spiral inward would release a smear of electromagnetic frequencies as the orbit got smaller. Instead, atoms were observed to only emit discrete frequencies of light. The resolution would lie in the development of quantum mechanics.
Bohr-Sommerfeld Model.
In 1913, Niels Bohr obtained the energy levels and spectral frequencies of the hydrogen atom after making a number of simple assumptions in order to correct the failed classical model. The assumptions included:
Bohr supposed that the electron's angular momentum is quantized with possible values:
formula_4 where formula_5
and formula_6 is Planck constant over formula_7. He also supposed that the centripetal force which keeps the electron in its orbit is provided by the Coulomb force, and that energy is conserved. Bohr derived the energy of each orbit of the hydrogen atom to be:
where formula_9 is the electron mass, formula_10 is the electron charge, formula_11 is the electric permeability, and formula_12 is the quantum number (now known as the principal quantum number). Bohr's predictions matched experiments measuring the hydrogen spectral series to the first order, giving more confidence to a theory that used quantized values.
For formula_13, the value
is called the Rydberg constant. This constant is often used in atomic physics in the form of the Rydberg unit of energy:
The exact value of the Rydberg constant above assumes that the nucleus is infinitely massive with respect to the electron. For hydrogen-1, hydrogen-2 (deuterium), and hydrogen-3 (tritium) the constant must be slightly modified to use the reduced mass of the system, rather than simply the mass of the electron. However, since the nucleus is much heavier than the electron, the values are nearly the same. The Rydberg constant "RM" for a hydrogen atom (one electron), "R" is given by
formula_16
where formula_17 is the mass of the atomic nucleus. For hydrogen-1, the quantity formula_18 is about 1/1836 (i.e. the electron-to-proton mass ratio). For deuterium and tritium, the ratios are about 1/3670 and 1/5497 respectively. These figures, when added to 1 in the denominator, represent very small corrections in the value of "R", and thus only small corrections to all energy levels in corresponding hydrogen isotopes.
There were still problems with Bohr's model: 
Most of these shortcomings were repaired by Sommerfeld's modification of the Bohr model. Sommerfeld introduced two additional degrees of freedom allowing an electron to move on an elliptical orbit, characterized by its eccentricity and declination with respect to a chosen axis. This introduces two additional quantum numbers, which are equivalent to the orbital angular momentum and its projection on the chosen axis. Thus the correct multiplicity of states (except for the factor 2 accounting for the yet unknown electron spin) was found. Further applying special relativity theory to the elliptic orbits, Sommerfeld succeeded in deriving the correct expression for the fine structure of hydrogen spectra (which happens to be exactly the same as in the most elaborate Dirac theory). However some observed phenomena such as the anomalous Zeeman effect remain unexplained. These issues were resolved with the full development of quantum mechanics and the Dirac equation. It is often alleged, that the Schrödinger equation is superior to the Bohr-Sommerfeld theory in describing the hydrogen atom. This is however not the case, as the results of both approaches coincide or are very close and their main shortcomings result from the absence of the electron spin in the theory. It was the complete failure of the Bohr-Sommerfeld theory to explain many-electron systems (such as the helium atom or the hydrogen molecule) which demonstrated its inadequacy in describing quantum phenomena.
Schrödinger equation.
The Schrödinger equation allows one to calculate the development of quantum systems with time and can give exact, analytical answers for the non-relativistic hydrogen atom.
Wavefunction.
The Hamiltonian of the hydrogen atom is the radial kinetic energy operator and coulomb attraction force between the positive proton and negative electron. Using the time-independent Schrödinger equation, ignoring all spin-coupling interactions and using the reduced mass formula_21, the equation is written as:
formula_22
Expanding the Laplacian in spherical coordinates:
formula_23
This is a separable, partial differential equation which can be solved in terms of special functions. By setting Z=1 (for one proton), the normalized position wavefunctions, given in spherical coordinates are:
where:
The quantum numbers can take the following values: 
Additionally, these wavefunctions are "normalized" (i.e., the integral of their modulus square equals 1) and orthogonal:
where formula_35 is the state represented by the wavefunction formula_36 in Dirac notation, and formula_37 is the Kronecker delta function.
The wavefunctions in momentum space are related to the wavefunctions in position space through a Fourier transform
which, for the bound states, results in 
where formula_40 denotes a Gegenbauer polynomial and formula_41 is in units of formula_42.
The solutions to the Schrödinger equation for hydrogen are analytical, giving a simple expression for the hydrogen energy levels and thus the frequencies of the hydrogen spectral lines and fully reproduced the Bohr model and went beyond it. It also yields two other quantum numbers and the shape of the electron's wave function ("orbital") for the various possible quantum-mechanical states, thus explaining the anisotropic character of atomic bonds.
The Schrödinger equation also applies to more complicated atoms and molecules. When there is more than one electron or nucleus the solution is not analytical and either computer calculations are necessary or simplifying assumptions must be made.
Since the Schrödinger equation is only valid for non-relativistic quantum mechanics, the solutions it yields for the hydrogen atom are not entirely correct. The Dirac equation of relativistic quantum theory improves these solutions (see below).
Results of Schrödinger equation.
The solution of the Schrödinger equation (wave equation) for the hydrogen atom uses the fact that the Coulomb potential produced by the nucleus is isotropic (it is radially symmetric in space and only depends on the distance to the nucleus). Although the resulting energy eigenfunctions (the "orbitals") are not necessarily isotropic themselves, their dependence on the angular coordinates follows completely generally from this isotropy of the underlying potential: the eigenstates of the Hamiltonian (that is, the energy eigenstates) can be chosen as simultaneous eigenstates of the angular momentum operator. This corresponds to the fact that angular momentum is conserved in the orbital motion of the electron around the nucleus. Therefore, the energy eigenstates may be classified by two angular momentum quantum numbers, "ℓ" and "m" (both are integers). The angular momentum quantum number determines the magnitude of the angular momentum. The magnetic quantum number determines the projection of the angular momentum on the (arbitrarily chosen) "z"-axis.
In addition to mathematical expressions for total angular momentum and angular momentum projection of wavefunctions, an expression for the radial dependence of the wave functions must be found. It is only here that the details of the 1/"r" Coulomb potential enter (leading to Laguerre polynomials in "r"). This leads to a third quantum number, the principal quantum number . The principal quantum number in hydrogen is related to the atom's total energy.
Note that the maximum value of the angular momentum quantum number is limited by the principal quantum number: it can run only up to "n" − 1, i.e. .
Due to angular momentum conservation, states of the same "ℓ" but different "m" have the same energy (this holds for all problems with rotational symmetry). In addition, for the hydrogen atom, states of the same "n" but different "ℓ" are also degenerate (i.e. they have the same energy). However, this is a specific property of hydrogen and is no longer true for more complicated atoms which have an (effective) potential differing from the form 1/"r" (due to the presence of the inner electrons shielding the nucleus potential).
Taking into account the spin of the electron adds a last quantum number, the projection of the electron's spin angular momentum along the "z"-axis, which can take on two values. Therefore, any eigenstate of the electron in the hydrogen atom is described fully by four quantum numbers. According to the usual rules of quantum mechanics, the actual state of the electron may be any superposition of these states. This explains also why the choice of "z"-axis for the directional quantization of the angular momentum vector is immaterial: an orbital of given "ℓ" and "m"′ obtained for another preferred axis "z"′ can always be represented as a suitable superposition of the various states of different "m" (but same "l") that have been obtained for "z".
Mathematical summary of eigenstates of hydrogen atom.
In 1928, Paul Dirac found an equation that was fully compatible with Special Relativity, and (as a consequence) made the wave function a 4-component "Dirac spinor" including "up" and "down" spin components, with both positive and "negative" energy (or matter and antimatter). The solution to this equation gave the following results, more accurate than the Schrödinger solution.
Energy levels.
The energy levels of hydrogen, including fine structure (excluding Lamb shift and hyperfine structure), are given by the Sommerfeld fine structure expression:
where "α" is the fine-structure constant and "j" is the "total angular momentum" quantum number, which is equal to |"ℓ" ± | depending on the direction of the electron spin. This formula represents a small correction to the energy obtained by Bohr and Schrödinger as given above. The factor in square brackets in the last expression is nearly one; the extra term arises from relativistic effects (for details, see #Features going beyond the Schrödinger solution). It is worth noting that this expression was first obtained by A. Sommerfeld in 1916 based on the relativistic version of the old Bohr theory. Sommerfeld has however used different notation for the quantum numbers.
Visualizing the hydrogen electron orbitals.
The image to the right shows the first few hydrogen atom orbitals (energy eigenfunctions). These are cross-sections of the probability density that are color-coded (black represents zero density and white represents the highest density). The angular momentum (orbital) quantum number "ℓ" is denoted in each column, using the usual spectroscopic letter code ("s" means "ℓ" = 0, "p" means "ℓ" = 1, "d" means "ℓ" = 2). The main (principal) quantum number "n" (= 1, 2, 3, ...) is marked to the right of each row. For all pictures the magnetic quantum number "m" has been set to 0, and the cross-sectional plane is the "xz"-plane ("z" is the vertical axis). The probability density in three-dimensional space is obtained by rotating the one shown here around the "z"-axis.
The "ground state", i.e. the state of lowest energy, in which the electron is usually found, is the first one, the 1"s" state (principal quantum level "n" = 1, "ℓ" = 0).
Black lines occur in each but the first orbital: these are the nodes of the wavefunction, i.e. where the probability density is zero. (More precisely, the nodes are spherical harmonics that appear as a result of solving Schrödinger's equation in polar coordinates.)
The quantum numbers determine the layout of these nodes. There are:
Features going beyond the Schrödinger solution.
There are several important effects that are neglected by the Schrödinger equation and which are responsible for certain small but measurable deviations of the real spectral lines from the predicted ones:
Both of these features (and more) are incorporated in the relativistic Dirac equation, with predictions that come still closer to experiment. Again the Dirac equation may be solved analytically in the special case of a two-body system, such as the hydrogen atom. The resulting solution quantum states now must be classified by the total angular momentum number "j" (arising through the coupling between electron spin and orbital angular momentum). States of the same "j" and the same "n" are still degenerate. Thus, direct analytical solution of Dirac equation predicts 2S() and 2P() levels of Hydrogen to have exactly the same energy, which is in a contradiction with observations (Lamb-Retherford experiment).
For these developments, it was essential that the solution of the Dirac equation for the hydrogen atom could be worked out exactly, such that any experimentally observed deviation had to be taken seriously as a signal of failure of the theory.
Alternatives to the Schrödinger theory.
In the language of Heisenberg's matrix mechanics, the hydrogen atom was first solved by Wolfgang Pauli using a rotational symmetry in four dimension [O(4)-symmetry] generated by the angular momentum 
and the Laplace–Runge–Lenz vector. By extending the symmetry group O(4) to the dynamical group O(4,2),
the entire spectrum and all transitions were embedded in a single irreducible group representation.
In 1979 the (non relativistic) hydrogen atom was solved for the first time within Feynman's path integral formulation
of quantum mechanics. This work greatly extended the range of applicability of Feynman's method.

</doc>
<doc id="14227" url="https://en.wikipedia.org/wiki?curid=14227" title="Elagabalus">
Elagabalus

Elagabalus or Heliogabalus (; ; 203 – March 11, 222), was Roman emperor from 218 to 222. A member of the Severan dynasty, he was Syrian, the second son of Julia Soaemias and Sextus Varius Marcellus. In his early youth he served as a priest of the god Elagabal in the hometown of his mother's family, Emesa. As a private citizen, he was probably named Sextus Varius Avitus Bassianus. Upon becoming emperor he took the name Marcus Aurelius Antoninus Augustus. He was called Elagabalus only after his death.
In 217, the emperor Caracalla was assassinated and replaced by his Praetorian prefect, Marcus Opellius Macrinus. Caracalla's maternal aunt, Julia Maesa, successfully instigated a revolt among the Legio III Gallica to have her eldest grandson (and Caracalla's cousin), Elagabalus, declared emperor in his place. Macrinus was defeated on 8 June 218 at the Battle of Antioch. Elagabalus, barely fourteen years old, became emperor, initiating a reign remembered mainly for sex scandals and religious controversy.
Later historians suggest Elagabalus showed a disregard for Roman religious traditions and sexual taboos. He replaced the traditional head of the Roman pantheon, Jupiter, with the deity of whom he was high priest, Elagabalus. He forced leading members of Rome's government to participate in religious rites celebrating this deity, over which he personally presided. Elagabalus was married as many as five times, lavished favours on male courtiers popularly thought to have been his lovers, and was reported to have prostituted himself in the imperial palace. His behavior estranged the Praetorian Guard, the Senate, and the common people alike. Amidst growing opposition, Elagabalus, just 18 years old, was assassinated and replaced by his cousin Severus Alexander on 11 March 222, in a plot formulated by his grandmother, Julia Maesa, and carried out by disaffected members of the Praetorian Guard.
Elagabalus developed a reputation among his contemporaries for extreme eccentricity, decadence and zealotry. This tradition has persisted, and in writers of the early modern age he suffers one of the worst reputations among Roman emperors. Edward Gibbon, for example, wrote that Elagabalus "abandoned himself to the grossest pleasures and ungoverned fury." According to Barthold Georg Niebuhr, "The name Elagabalus is branded in history above all others" because of his "unspeakably disgusting life."
Family and priesthood.
Elagabalus was born around the year 203 to a Greek father, Sextus Varius Marcellus and Julia Soaemias Bassiana. His father was initially a member of the equestrian class, but was later elevated to the rank of senator. His grandmother, Julia Maesa, was the widow of the consul Julius Avitus, the sister of Julia Domna, and the sister-in-law of the emperor Septimius Severus. He had at least one sibling: an unnamed elder brother. His mother, Julia Soaemias, was a cousin of the Roman emperor Caracalla. Other relatives included his aunt Julia Avita Mamaea and uncle Marcus Julius Gessius Marcianus and among their children, their son Severus Alexander. Elagabalus's family held hereditary rights to the priesthood of the sun god Elagabal, of whom Elagabalus was the high priest at Emesa (modern Homs) in Syria.
The deity Elagabalus was initially venerated at Emesa. This form of the god's name is a Latinized version of the Syrian "Ilāh hag-Gabal", which derives from "Ilāh" (a Semitic word for "god") and "gabal" (an Aramaic word for "mountain"), resulting in "the God of the Mountain," the Emesene manifestation of the deity. The cult of the deity spread to other parts of the Roman Empire in the 2nd century; a dedication has been found as far away as Woerden (Netherlands), near the Roman "limes". The god was later imported and assimilated with the Roman sun god known as Sol Indiges in republican times and as Sol Invictus during the 2nd and 3rd centuries CE. In Greek the sun god is Helios, hence "Heliogabalus", a variant of "Elagabalus".
Rise to power.
When the emperor Macrinus came to power, he suppressed the threat against his reign by the family of his assassinated predecessor, Caracalla, by exiling them—Julia Maesa, her two daughters, and her eldest grandson Elagabalus—to their estate at Emesa in Syria. Almost upon arrival in Syria, Maesa began a plot with her advisor and Elagabalus' tutor Gannys, to overthrow Macrinus and elevate the fourteen-year-old Elagabalus to the imperial throne.
His mother publicly declared that he was the illegitimate son of Caracalla, therefore due the loyalties of Roman soldiers and senators who had sworn allegiance to Caracalla. After Julia Maesa displayed her wealth to the Third Legion at Raphana they swore allegiance to Elagabalus. At sunrise on 16 May 218, Publius Valerius Comazon, commander of the legion, declared him emperor. To strengthen his legitimacy through further propaganda, Elagabalus assumed Caracalla's names, "Marcus Aurelius Antoninus".
In response Macrinus dispatched his Praetorian prefect Ulpius Julianus to the region with a contingent of troops he considered strong enough to crush the rebellion. However, this force soon joined the faction of Elagabalus when, during the battle, they turned on their own commanders. The officers were killed and Julianus' head was sent back to the emperor.
Macrinus now sent letters to the Senate denouncing Elagabalus as the "False Antoninus" and claiming he was insane. Both consuls and other high-ranking members of Rome's leadership condemned Elagabalus, and the Senate subsequently declared war on both Elagabalus and Julia Maesa.
Macrinus and his son, weakened by the desertion of the Second Legion due to bribes and promises circulated by Julia Maesa, were defeated on 8 June 218 at the Battle of Antioch by troops commanded by Gannys. Macrinus fled toward Italy, disguised as a courier, but was later intercepted near Chalcedon and executed in Cappadocia. His son Diadumenianus, sent for safety to the Parthian court, was captured at Zeugma and also put to death.
Elagabalus declared the date of the victory at Antioch to be the beginning of his reign and assumed the imperial titles without prior senatorial approval, which violated tradition but was a common practice among 3rd-century emperors nonetheless. Letters of reconciliation were dispatched to Rome extending amnesty to the Senate and recognizing the laws, while also condemning the administration of Macrinus and his son.
The senators responded by acknowledging Elagabalus as emperor and accepting his claim to be the son of Caracalla. Caracalla and Julia Domna were both deified by the Senate, both Julia Maesa and Julia Soaemias were elevated to the rank of Augustae, and the memory of both Macrinus and Diadumenianus was condemned by the Senate. The former commander of the Third Legion, Comazon, was appointed commander of the Praetorian Guard.
Emperor (218–222).
Elagabalus and his entourage spent the winter of 218 in Bithynia at Nicomedia, where the emperor's religious beliefs first presented themselves as a problem. The contemporary historian Cassius Dio suggests that Gannys was in fact killed by the new emperor because he was forcing Elagabalus to live "temperately and prudently." To help Romans adjust to the idea of having an oriental priest as emperor, Julia Maesa had a painting of Elagabalus in priestly robes sent to Rome and hung over a statue of the goddess Victoria in the Senate House. This placed senators in the awkward position of having to make offerings to Elagabalus whenever they made offerings to Victoria.
The legions were dismayed by his behaviour and quickly came to regret having supported his accession. While Elagabalus was still on his way to Rome, brief revolts broke out by the Fourth Legion at the instigation of Gellius Maximus, and by the Third Legion, which itself had been responsible for the elevation of Elagabalus to the throne, under the command of Senator Verus. The rebellion was quickly put down, and the Third Legion disbanded.
When the entourage reached Rome in the autumn of 219, Comazon and other allies of Julia Maesa and Elagabalus were given powerful and lucrative positions, to the outrage of many senators who did not consider them worthy of such privileges. After his tenure as Praetorian prefect, Comazon would serve as the city prefect of Rome three times, and as consul twice. Elagabalus soon devalued the Roman currency. He decreased the silver purity of the "denarius" from 58% to 46.5% — the actual silver weight dropping from 1.82 grams to 1.41 grams. He also demonetized the "antoninianus" during this period in Rome.
Elagabalus tried to have his presumed lover, the charioteer Hierocles, declared Caesar, while another alleged lover, the athlete Aurelius Zoticus, was appointed to the non-administrative but influential position of Master of the Chamber, or "Cubicularius". His offer of amnesty for the Roman upper class was largely honoured, though the jurist Ulpian was exiled.
The relationships between Julia Maesa, Julia Soaemias, and Elagabalus were strong at first. His mother and grandmother became the first women to be allowed into the Senate, and both received senatorial titles: Soaemias the established title of "Clarissima," and Maesa the more unorthodox "Mater Castrorum et Senatus" ("Mother of the army camp and of the Senate"). While Julia Maesa tried to position herself as the power behind the throne and thus the most powerful woman in the world, Elagabalus would prove to be highly independent, set in his ways, and impossible to control.
Religious controversy.
Since the reign of Septimius Severus, sun worship had increased throughout the Empire. Elagabalus saw this as an opportunity to install Elagabal as the chief deity of the Roman pantheon. The god was renamed "Deus Sol Invictus", meaning "God the Undefeated Sun", and honored above Jupiter.
As a token of respect for Roman religion, however, Elagabalus joined either Astarte, Minerva, Urania, or some combination of the three to Elagabal as wife. Before constructing a temple in dedication to Elagabal, Elagabalus placed the meteorite of Elagabal next to the throne of Jupiter at the temple of Jupiter Optimus Maximus.
He stirred further discontent when he himself married the Vestal Virgin Aquilia Severa, claiming the marriage would produce "godlike children". This was a flagrant breach of Roman law and tradition, which held that any Vestal found to have engaged in sexual intercourse was to be buried alive.
A lavish temple called the Elagabalium was built on the east face of the Palatine Hill to house Elagabal, who was represented by a black conical meteorite from Emesa. Herodian wrote "this stone is worshipped as though it were sent from heaven; on it there are some small projecting pieces and markings that are pointed out, which the people would like to believe are a rough picture of the sun, because this is how they see them".
In order to become the high priest of his new religion, Elagabalus had himself circumcised. He forced senators to watch while he danced around the altar of Deus Sol Invictus to the accompaniment of drums and cymbals. Each summer solstice he held a festival dedicated to the god, which became popular with the masses because of the free food distributed on such occasions. During this festival, Elagabalus placed the Emesa stone on a chariot adorned with gold and jewels, which he paraded through the city:
The most sacred relics from the Roman religion were transferred from their respective shrines to the Elagabalium, including the emblem of the Great Mother, the fire of Vesta, the Shields of the Salii and the Palladium, so that no other god could be worshipped except in company with Elagabal.
Sex/gender controversy.
Elagabalus' sexual orientation is the subject of much debate. Elagabalus married and divorced five women, three of whom are known. His first wife was Julia Cornelia Paula; the second was the Vestal Virgin Julia Aquilia Severa.
Within a year, he abandoned her and married Annia Aurelia Faustina, a descendant of Marcus Aurelius and the widow of a man recently executed by Elagabalus. He had returned to his second wife Severa by the end of the year. According to Cassius Dio, his most stable relationship seems to have been with his chariot driver, a blond slave from Caria named Hierocles, whom he referred to as his husband.
The "Augustan History" claims that he also married a man named Zoticus, an athlete from Smyrna, in a public ceremony at Rome. Cassius Dio reported that Elagabalus would paint his eyes, epilate his hair and wear wigs before prostituting himself in taverns, brothels, and even in the imperial palace:
Herodian commented that Elagabalus enhanced his natural good looks by the regular application of cosmetics. He was described as having been "delighted to be called the mistress, the wife, the queen of Hierocles" and was reported to have offered vast sums of money to any physician who could equip him with female genitalia. Elagabalus has been characterized by some modern writers as transgender, perhaps transsexual.
Fall from power.
By 221 Elagabalus' eccentricities, particularly his relationship with Hierocles, increasingly provoked the soldiers of the Praetorian Guard. When Elagabalus' grandmother Julia Maesa perceived that popular support for the emperor was waning, she decided that he and his mother, who had encouraged his religious practices, had to be replaced. As alternatives, she turned to her other daughter, Julia Avita Mamaea, and her daughter's son, the thirteen-year-old Severus Alexander.
Prevailing on Elagabalus, she arranged that he appoint his cousin Alexander as his heir and be given the title of "Caesar". Alexander shared the consulship with the emperor that year. However, Elagabalus reconsidered this arrangement when he began to suspect that the Praetorian Guard preferred his cousin over himself.
Following the failure of various attempts on Alexander's life, Elagabalus stripped his cousin of his titles, revoked his consulship, and circulated the news that Alexander was near death, in order to see how the Praetorians would react. A riot ensued, and the guard demanded to see Elagabalus and Alexander in the Praetorian camp.
Assassination.
The emperor complied and on 11 March 222 he publicly presented his cousin along with his own mother, Julia Soaemias. On their arrival the soldiers started cheering Alexander while ignoring Elagabalus, who ordered the summary arrest and execution of anyone who had taken part in this display of insubordination. In response, members of the Praetorian Guard attacked Elagabalus and his mother:
Following his assassination, many associates of Elagabalus were killed or deposed, including his lover Hierocles. His religious edicts were reversed and the stone of Elagabal was sent back to Emesa. Women were again barred from attending meetings of the Senate. The practice of "damnatio memoriae"—erasing from the public record a disgraced personage formerly of note—was systematically applied in his case.
Sources.
Augustan History.
The source of many of these stories of Elagabalus's depravity is the "Augustan History" ("Historia Augusta"), which includes controversial claims. The "Historia Augusta" was most likely written toward the end of the 4th century during the reign of emperor Theodosius I. The life of Elagabalus as described in the "Augustan History" is of uncertain historical merit. Sections 13 to 17, relating to the fall of Elagabalus, are less controversial among historians.
Cassius Dio.
Sources often considered more credible than the "Augustan History" include the contemporary historians Cassius Dio and Herodian. Cassius Dio lived from the second half of the 2nd century until sometime after 229. Born into a patrician family, he spent the greater part of his life in public service. He was a senator under emperor Commodus and governor of Smyrna after the death of Septimius Severus. Afterwards he served as suffect consul around 205, and as proconsul in Africa and Pannonia.
Severus Alexander held him in high esteem and made him his consul again. His "Roman History" spans nearly a millennium, from the arrival of Aeneas in Italy until the year 229. As a contemporary of Elagabalus, Cassius Dio's account of his reign is generally considered more reliable than the "Augustan History", although by his own admission Dio spent the greater part of the relevant period outside of Rome and had to rely on second-hand accounts.
Furthermore, the political climate in the aftermath of Elagabalus' reign, as well as Dio's own position within the government of Alexander, likely influenced the truth of this part of his history for the worse. Dio regularly refers to Elagabalus as Sardanapalus, partly to distinguish him from his divine namesake, but chiefly to do his part in maintaining the "damnatio memoriae" enforced after the emperor's death and to associate him with another autocrat notorious for a dissolute life.
Herodian.
Another contemporary of Elagabalus was Herodian, who was a minor Roman civil servant who lived from c. 170 until 240. His work, "History of the Roman Empire since Marcus Aurelius", commonly abbreviated as "Roman History", is an eyewitness account of the reign of Commodus until the beginning of the reign of Gordian III. His work largely overlaps with Dio's own "Roman History", but both texts seem to be independently consistent with each other.
Although Herodian is not deemed as reliable as Cassius Dio, his lack of literary and scholarly pretensions make him less biased than senatorial historians. Herodian is considered the most important source for the religious reforms which took place during the reign of Elagabalus, which have been confirmed by numismatic and archaeological evidence.
Edward Gibbon and later historians.
For readers of the modern age, "The History of the Decline and Fall of the Roman Empire" by Edward Gibbon (1737–94) further cemented the scandalous reputation of Elagabalus. Gibbon not only accepted and expressed outrage at the allegations of the ancient historians, but might have added some details of his own; he is the first historian known to state that Gannys was a eunuch, for example. Gibbon wrote:
Some recent historians argue for a more favourable picture of his life and reign. Martijn Icks in "Images of Elagabalus" (2008; republished as "The Crimes of Elagabalus" in 2012) doubts the reliability of the ancient sources and argues that it was the emperor's unorthodox religious policies that alienated the power elite of Rome, to the point that his grandmother saw fit to eliminate him and replace him with his cousin. Leonardo de Arrizabalaga y Prado, in "The Emperor Elagabalus: Fact or Fiction?" (2008), is also critical of the ancient historians and speculates that neither religion nor sexuality played a role in the fall of the young emperor, who was simply the loser in a power struggle within the imperial family; the loyalty of the Praetorian Guards was up for sale, and Julia Maesa had the resources to outmaneuver and outbribe her grandson. According to this version, once Elagabalus, his mother, and his immediate circle had been murdered, a wholesale propaganda war against his memory resulted in a vicious caricature which has persisted to the present, repeated and often embellished by later historians displaying their own prejudices against effeminacy and other vices which Elagabalus had come to epitomize.
Legacy.
Due to the ancient tradition about him, Elagabalus became something of an (anti-)hero in the Decadent movement of the late 19th century. He often appears in literature and other creative media as the epitome of a young, amoral aesthete. His life and character have informed or at least inspired many famous works of art, by Decadents, even by contemporary artists. The most notable of these works include:

</doc>
<doc id="14229" url="https://en.wikipedia.org/wiki?curid=14229" title="Homeopathy">
Homeopathy

Homeopathy () is a system of alternative medicine created in 1796 by Samuel Hahnemann, based on his doctrine of "like cures like" ("similia similibus curentur"), a claim that a substance that causes the symptoms of a disease in healthy people would cure similar symptoms in sick people. Homeopathy is a pseudoscience – a belief that is incorrectly presented as scientific. Homeopathic preparations are not effective for treating any condition; large-scale studies have found homeopathy to be no more effective than a placebo, suggesting that any positive feelings that follow treatment are only due to the placebo effect and normal recovery from illness.
Hahnemann believed the underlying causes of disease were phenomena that he termed "miasms", and that homeopathic preparations addressed these. The preparations are manufactured using a process of homeopathic dilution, in which a chosen substance is repeatedly diluted in alcohol or distilled water, each time with the containing vessel being bashed against an elastic material, (commonly a leather-bound book). Dilution typically continues well past the point where no molecules of the original substance remain. --> Homeopaths select homeopathics by consulting reference books known as "repertories", and by considering the totality of the patient's symptoms, personal traits, physical and psychological state, and life history.
Homeopathy is not a plausible system of treatment, as its dogmas about how drugs, illness, the human body, liquids and solutions operate are contradicted by a wide range of discoveries across biology, psychology, physics and chemistry made in the two centuries since its invention. Although some clinical trials produce positive results, multiple systematic reviews have indicated that this is because of chance, flawed research methods, and reporting bias. Continued homeopathic practice, despite the evidence that it does not work, has been criticized as unethical because it discourages the use of effective treatments, with the World Health Organisation warning against using homeopathy to try to treat severe diseases such as HIV and malaria. The continued practice of homeopathy, despite a lack of evidence of efficacy, has led to it being characterized within the scientific and medical communities as nonsense, quackery, and a sham.
Assessments by the Australian National Health and Medical Research Council, the British National Health and Medical Research Council, and the Swiss Federal Health Office have each concluded that homeopathy is ineffective, recommending against the practice receiving any further funding.
History.
Historical context.
Homeopaths claim that Hippocrates may have originated homeopathy around 400 BC, when he prescribed a small dose of mandrake root to treat mania, knowing it produces mania in much larger doses. In the 16th century, the pioneer of pharmacology Paracelsus declared that small doses of "what makes a man ill also cures him". Samuel Hahnemann (1755–1843) gave homeopathy its name and expanded its principles in the late 18th century.
In the late 18th and 19th centuries, mainstream medicine used methods like bloodletting and purging, and administered complex mixtures, such as Venice treacle, which was made from 64 substances including opium, myrrh, and viper's flesh. These treatments often worsened symptoms and sometimes proved fatal. Hahnemann rejected these practices – which had been extolled for centuries – as irrational and inadvisable;
instead, he advocated the use of single drugs at lower doses and promoted an immaterial, vitalistic view of how living organisms function, believing that diseases have spiritual, as well as physical causes.
Hahnemann's concept.
The term "homeopathy" was coined by Hahnemann and first appeared in print in 1807.
Hahnemann conceived of homeopathy while translating a medical treatise by the Scottish physician and chemist William Cullen into German. Being skeptical of Cullen's theory concerning cinchona's use for curing malaria, Hahnemann ingested some bark specifically to investigate what would happen. He experienced fever, shivering and joint pain: symptoms similar to those of malaria itself. From this, Hahnemann came to believe that all effective drugs produce symptoms in healthy individuals similar to those of the diseases that they treat, in accord with the "law of similars" that had been proposed by ancient physicians. An account of the effects of eating cinchona bark noted by Oliver Wendell Holmes, and published in 1861, failed to reproduce the symptoms Hahnemann reported. Hahnemann's law of similars is a postulate rather than a scientific law. This led to the name ""homeopathy"", which comes from the "hómoios", "-like" and "páthos", "suffering")
Subsequent scientific work showed that cinchona cures malaria because it contains quinine, which kills the "Plasmodium falciparum" parasite that causes the disease; the mechanism of action is unrelated to Hahnemann's ideas.
"Provings".
Hahnemann began to test what effects substances produced in humans, a procedure that would later become known as "homeopathic proving". These tests required subjects to test the effects of ingesting substances by clearly recording all of their symptoms as well as the ancillary conditions under which they appeared. He published a collection of provings in 1805, and a second collection of 65 preparations appeared in his book, "Materia Medica Pura", in 1810.
Because Hahnemann believed that large doses of drugs that caused similar symptoms would only aggravate illness, he advocated extreme dilutions of the substances; he devised a technique for making dilutions that he believed would preserve a substance's therapeutic properties while removing its harmful effects. Hahnemann believed that this process aroused and enhanced "the spirit-like medicinal powers of the crude substances".
He gathered and published a complete overview of his new medical system in his 1810 book, "The Organon of the Healing Art", whose 6th edition, published in 1921, is still used by homeopaths today.
Miasms and disease.
In "The Organon of the Healing Art", Hahnemann introduced the concept of "miasms" as "infectious principles" underlying chronic disease. Hahnemann associated each miasm with specific diseases, and thought that initial exposure to miasms causes local symptoms, such as skin or venereal diseases. If, however, these symptoms were suppressed by medication, the cause went deeper and began to manifest itself as diseases of the internal organs. Homeopathy maintains that treating diseases by directly alleviating their symptoms, as is sometimes done in conventional medicine, is ineffective because all "disease can generally be traced to some latent, deep-seated, underlying chronic, or inherited tendency". The underlying imputed miasm still remains, and deep-seated ailments can be corrected only by removing the deeper disturbance of the vital force.
Hahnemann’s hypotheses for the direct or remote cause of all chronic diseases (miasms) originally presented only three, psora (the itch), syphilis (venereal disease) or sycosis (fig-wart disease). Of these three the most important was "psora" (Greek for "itch"), described as being related to any itching diseases of the skin, supposed to be derived from suppressed scabies, and claimed to be the foundation of many further disease conditions. Hahnemann believed psora to be the cause of such diseases as epilepsy, cancer, jaundice, deafness, and cataracts.
Since Hahnemann's time, other miasms have been proposed, some replacing one or more of psora's proposed functions, including tuberculosis and cancer miasms.
The law of susceptibility implies that a negative state of mind can attract hypothetical disease entities called "miasms" to invade the body and produce symptoms of diseases. Hahnemann rejected the notion of a disease as a separate thing or invading entity, and insisted it was always part of the "living whole". Hahnemann coined the expression "allopathic medicine", which was used to pejoratively refer to traditional Western medicine.
Hahnemann's miasm theory remains disputed and controversial within homeopathy even in modern times. The theory of miasms has been criticized as an explanation developed by Hahnemann to preserve the system of homeopathy in the face of treatment failures, and for being inadequate to cover the many hundreds of sorts of diseases, as well as for failing to explain disease predispositions, as well as genetics, environmental factors, and the unique disease history of each patient.
19th century: rise to popularity and early criticism.
Homeopathy achieved its greatest popularity in the 19th century. It was introduced to the United States in 1825 by Hans Birch Gram, a student of Hahnemann. The first homeopathic school in the US opened in 1835, and in 1844, the first US national medical association, the American Institute of Homeopathy, was established. Throughout the 19th century, dozens of homeopathic institutions appeared in Europe and the United States, and by 1900, there were 22 homeopathic colleges and 15,000 practitioners in the United States. Because medical practice of the time relied on ineffective and often dangerous treatments, patients of homeopaths often had better outcomes than those of the doctors of the time. Homeopathic preparations, even if ineffective, would almost surely cause no harm, making the users of homeopathic preparations less likely to be killed by the treatment that was supposed to be helping them. The relative success of homeopathy in the 19th century may have led to the abandonment of the ineffective and harmful treatments of bloodletting and purging and to have begun the move towards more effective, science-based medicine.
One reason for the growing popularity of homeopathy was its apparent success in treating people suffering from infectious disease epidemics.
During 19th-century epidemics of diseases such as cholera, death rates in homeopathic hospitals were often lower than in conventional hospitals, where the treatments used at the time were often harmful and did little or nothing to combat the diseases.
From its inception, however, homeopathy was criticized by mainstream science. Sir John Forbes, physician to Queen Victoria, said in 1843 that the extremely small doses of homeopathy were regularly derided as useless, "an outrage to human reason". James Young Simpson said in 1853 of the highly diluted drugs: "No poison, however strong or powerful, the billionth or decillionth of which would in the least degree affect a man or harm a fly."
19th-century American physician and author Oliver Wendell Holmes, Sr. was also a vocal critic of homeopathy and published an essay in 1842 entitled "Homœopathy and Its Kindred Delusions". The members of the French Homeopathic Society observed in 1867 that some leading homeopathists of Europe not only were abandoning the practice of administering infinitesimal doses but were also no longer defending it. The last school in the US exclusively teaching homeopathy closed in 1920.
Revival in the 20th century.
According to Paul Ulrich Unschuld, the Nazi regime in Germany was fascinated by homeopathy, and spent large sums of money on researching its mechanisms, but without gaining a positive result. Unschuld further argues that homeopathy never subsequently took root in the United States, but remained more deeply established in European thinking.
In the United States, the "Food, Drug, and Cosmetic Act" of 1938 (sponsored by Royal Copeland, a Senator from New York and homeopathic physician) recognized homeopathic preparations as drugs. In the 1950s, there were only 75 pure homeopaths practicing in the U.S. However, by the mid to late 1970s, homeopathy made a significant comeback and sales of some homeopathic companies increased tenfold. Some homeopaths give credit for the revival to Greek homeopath George Vithoulkas, who performed a "great deal of research to update the scenarios and refine the theories and practice of homeopathy", beginning in the 1970s, but Ernst and Singh consider it to be linked to the rise of the New Age movement. Whichever is correct, mainstream pharmacy chains recognized the business potential of selling homeopathic preparations. The Food and Drug Administration held a hearing April 20 and 21, 2015, requesting public comment on regulation of homeopathic drugs. The FDA cited the growth of sales of over the counter homeopathic medicines, $2.7 billion as of 2007, many labeled as "natural, safe, and effective".
Bruce Hood has argued that the increased popularity of homeopathy in recent times may be due to the comparatively long consultations practitioners are willing to give their patients, and to an irrational preference for "natural" products which people think are the basis of homeopathic preparations.
Preparations and treatment.
Homeopathic preparations are referred to as "homeopathics" or "remedies". Practitioners rely on two types of reference when prescribing: "materia medica" and repertories. A homeopathic "materia medica" is a collection of "drug pictures", organised alphabetically. These entries describe the symptom patterns associated with individual preparations. A homeopathic repertory is an index of disease symptoms that lists preparations associated with specific symptoms. In both cases different compilers may dispute particular inclusions. The first symptomatic homeopathic "materia medica" was arranged by Hahnemann. The first homeopathic repertory was Georg Jahr's "Symptomenkodex", published in German in 1835, and translated into English as the "Repertory to the more Characteristic Symptoms of Materia Medica" by Constantine Hering in 1838.
This version was less focused on disease categories and would be the forerunner to later works by James Tyler Kent. Repertories, in particular, may be very large.
Homeopathy uses animal, plant, mineral, and synthetic substances in its preparations, generally referring to them using Latin or faux-Latin names. Examples include "arsenicum album" (arsenic oxide), "natrum muriaticum" (sodium chloride or table salt), "Lachesis muta" (the venom of the bushmaster snake), "opium", and "thyroidinum" (thyroid hormone).
Some homeopaths use so-called "nosodes" (from the Greek "nosos", disease) made from diseased or pathological products such as fecal, urinary, and respiratory discharges, blood, and tissue. Conversely, preparations made from "healthy" specimens are called "sarcodes".
Some modern homeopaths use preparations they call "imponderables" because they do not originate from a substance but some other phenomenon presumed to have been "captured" by alcohol or lactose. Examples include X-rays
and sunlight.
Other minority practices include paper preparations, where the substance and dilution are written on pieces of paper and either pinned to the patients' clothing, put in their pockets, or placed under glasses of water that are then given to the patients, and the use of radionics to manufacture preparations. Such practices have been strongly criticised by classical homeopaths as unfounded, speculative, and verging upon magic and superstition.
Preparation.
Hahnemann found that undiluted doses caused reactions, sometimes dangerous ones, so specified that preparations be given at the lowest possible dose. He found that this reduced potency as well as side-effects, but formed the view that vigorous shaking and striking on an elastic surface – a process he termed "Schütteln", translated as "succussion" – nullified this. A common explanation for his settling on this process is said to be that he found preparations subjected to agitation in transit, such as in saddle bags or in a carriage, were more "potent". Hahnemann had a saddle-maker construct a special wooden striking board covered in leather on one side and stuffed with horsehair. Insoluble solids, such as granite, diamond, and platinum, are diluted by grinding them with lactose ("trituration").
The process of dilution and succussion is termed "dynamisation" or "potentisation" by homeopaths. In industrial manufacture this may be done by machine.
Serial dilution is achieved by taking an amount of the mixture and adding solvent, but the "Korsakovian" method may also be used, whereby the vessel in which the preparations are manufactured is emptied, refilled with solvent, and the volume of fluid adhering to the walls of the vessel is deemed sufficient for the new batch. The Korsakovian method is sometimes referred to as K on the label of a homeopathic preparation, e.g. 200CK is a 200C preparation made using the Korsakovian method.
Fluxion and radionics methods of preparation do not require succussion. There are differences of opinion on the number and force of strikes, and some practitioners dispute the need for succussion at all while others reject the Korsakovian and other non-classical preparations. There are no laboratory assays and the importance and techniques for succussion cannot be determined with any certainty from the literature.
Dilutions.
Three main logarithmic potency scales are in regular use in homeopathy. Hahnemann created the "centesimal" or "C scale", diluting a substance by a factor of 100 at each stage. The centesimal scale was favored by Hahnemann for most of his life.
A 2C dilution requires a substance to be diluted to one part in 100, and then some of that diluted solution diluted by a further factor of 100.
This works out to one part of the original substance in 10,000 parts of the solution. A 6C dilution repeats this process six times, ending up with the original substance diluted by a factor of 100−6=10−12 (one part in one trillion or 1/1,000,000,000,000). Higher dilutions follow the same pattern.
In homeopathy, a solution that is more dilute is described as having a higher "potency", and more dilute substances are considered by homeopaths to be stronger and deeper-acting. The end product is often so diluted as to be indistinguishable from the diluent (pure water, sugar or alcohol). There is also a decimal potency scale (notated as "X" or "D") in which the preparation is diluted by a factor of 10 at each stage.
Hahnemann advocated 30C dilutions for most purposes (that is, dilution by a factor of 1060). Hahnemann regularly used potencies up to 300C but opined that "there must be a limit to the matter, it cannot go on indefinitely".
In Hahnemann's time, it was reasonable to assume the preparations could be diluted indefinitely, as the concept of the atom or molecule as the smallest possible unit of a chemical substance was just beginning to be recognized.
The greatest dilution reasonably likely to contain even one molecule of the original substance is 12C.
Critics and advocates of homeopathy alike commonly attempt to illustrate the dilutions involved in homeopathy with analogies.
Hahnemann is reported to have joked that a suitable procedure to deal with an epidemic would be to empty a bottle of poison into Lake Geneva, if it could be succussed 60 times.
Another example given by a critic of homeopathy states that a 12C solution is equivalent to a "pinch of salt in both the North and South Atlantic Oceans", which is approximately correct.
One-third of a drop of some original substance diluted into all the water on earth would produce a preparation with a concentration of about 13C. A popular homeopathic treatment for the flu is a 200C dilution of duck liver, marketed under the name Oscillococcinum. As there are only about 1080 atoms in the entire observable universe, a dilution of one molecule in the observable universe would be about 40C. Oscillococcinum would thus require 10320 more universes to simply have one molecule in the final substance.
The high dilutions characteristically used are often considered to be the most controversial and implausible aspect of homeopathy.
Not all homeopaths advocate high dilutions. Preparations at concentrations below 4X are considered an important part of homeopathic heritage. Many of the early homeopaths were originally doctors and generally used lower dilutions such as "3X" or "6X", rarely going beyond "12X".
The split between lower and higher dilutions followed ideological lines.
Those favoring low dilutions stressed pathology and a stronger link to conventional medicine, while those favoring high dilutions emphasised vital force, miasms and a spiritual interpretation of disease.
Some products with such relatively lower dilutions continue to be sold, but like their counterparts, they have not been conclusively demonstrated to have any effect beyond that of a placebo.
Provings.
A homeopathic "proving" is the method by which the profile of a homeopathic preparation is determined.
At first Hahnemann used undiluted doses for provings, but he later advocated provings with preparations at a 30C dilution, and most modern provings are carried out using ultradilute preparations in which it is highly unlikely that any of the original molecules remain. During the proving process, Hahnemann administered preparations to healthy volunteers, and the resulting symptoms were compiled by observers into a "drug picture".
The volunteers were observed for months at a time and made to keep extensive journals detailing all of their symptoms at specific times throughout the day. They were forbidden from consuming coffee, tea, spices, or wine for the duration of the experiment; playing chess was also prohibited because Hahnemann considered it to be "too exciting", though they were allowed to drink beer and encouraged to exercise in moderation.
After the experiments were over, Hahnemann made the volunteers take an oath swearing that what they reported in their journals was the truth, at which time he would interrogate them extensively concerning their symptoms.
Provings are claimed to have been important in the development of the clinical trial, due to their early use of simple control groups, systematic and quantitative procedures, and some of the first application of statistics in medicine. The lengthy records of self-experimentation by homeopaths have occasionally proven useful in the development of modern drugs: For example, evidence that nitroglycerin might be useful as a treatment for angina was discovered by looking through homeopathic provings, though homeopaths themselves never used it for that purpose at that time.
The first recorded provings were published by Hahnemann in his 1796 "Essay on a New Principle".
His "Fragmenta de Viribus" (1805) contained the results of 27 provings, and his 1810 "Materia Medica Pura" contained 65.
For James Tyler Kent's 1905 "Lectures on Homoeopathic Materia Medica", 217 preparations underwent provings and newer substances are continually added to contemporary versions.
Though the proving process has superficial similarities with clinical trials, it is fundamentally different in that the process is subjective, not blinded, and modern provings are unlikely to use pharmacologically active levels of the substance under proving. As early as 1842, Holmes noted the provings were impossibly vague, and the purported effect was not repeatable among different subjects.
Homeopathic consultation.
Homeopaths generally begin with detailed examinations of their patients' histories, including questions regarding their physical, mental and emotional states, their life circumstances and any physical or emotional illnesses. The homeopath then attempts to translate this information into a complex formula of mental and physical symptoms, including likes, dislikes, innate predispositions and even body type.
From these symptoms, the homeopath chooses how to treat the patient using "materia medica" and repertories. In classical homeopathy, the practitioner attempts to match a single preparation to the totality of symptoms (the "simlilum"), while "clinical homeopathy" involves combinations of preparations based on the various symptoms of an illness.
Pills and active ingredients.
Homeopathic pills are made from an inert substance (often sugars, typically lactose), upon which a drop of liquid homeopathic preparation is placed and allowed to evaporate.
The process of homeopathic dilution results in no objectively detectable active ingredient in most cases, but some preparations (e.g. calendula and arnica creams) do contain pharmacologically active doses. One product, Zicam Cold Remedy, which was marketed as an "unapproved homeopathic" product, contains two ingredients that are only "slightly" diluted: zinc acetate (2X = 1/100 dilution) and zinc gluconate (1X = 1/10 dilution), which means both are present in a biologically active concentration strong enough to have caused some people to lose their sense of smell, a condition termed anosmia. Zicam also listed several normal homeopathic potencies as "inactive ingredients", including "galphimia glauca", histamine dihydrochloride (homeopathic name, "histaminum hydrochloricum"), "luffa operculata", and sulfur.
Related and minority treatments and practices.
Isopathy.
Isopathy is a therapy derived from homeopathy, invented by Johann Joseph Wilhelm Lux in the 1830s. Isopathy differs from homeopathy in general in that the preparations, known as "nosodes", are made up either from things that cause the disease or from products of the disease, such as pus. Many so-called "homeopathic vaccines" are a form of isopathy.
Flower preparations.
Flower preparations can be produced by placing flowers in water and exposing them to sunlight. The most famous of these are the Bach flower remedies, which were developed by the physician and homeopath Edward Bach. Although the proponents of these preparations share homeopathy's vitalist world-view and the preparations are claimed to act through the same hypothetical "vital force" as homeopathy, the method of preparation is different. Bach flower preparations are manufactured in allegedly "gentler" ways such as placing flowers in bowls of sunlit water, and the preparations are not succussed. There is no convincing scientific or clinical evidence for flower preparations being effective.
Veterinary use.
The idea of using homeopathy as a treatment for other animals, termed "veterinary homeopathy", dates back to the inception of homeopathy; Hahnemann himself wrote and spoke of the use of homeopathy in animals other than humans. The FDA has not approved homeopathic products as veterinary medicine in the U.S. In the UK, veterinary surgeons who use homeopathy may belong to the Faculty of Homeopathy and/or to the British Association of Homeopathic Veterinary Surgeons. Animals may be treated only by qualified veterinary surgeons in the UK and some other countries. Internationally, the body that supports and represents homeopathic veterinarians is the International Association for Veterinary Homeopathy.
The use of homeopathy in veterinary medicine is controversial; the little existing research on the subject is not of a high enough scientific standard to provide reliable data on efficacy. Other studies have also found that giving animals placebos can play active roles in influencing pet owners to believe in the effectiveness of the treatment when none exists. The British Veterinary Association's position statement on alternative medicines says that it "cannot endorse" homeopathy, and the Australian Veterinary Association includes it on its list of "ineffective therapies".
The UK's Department for Environment, Food and Rural Affairs (Defra) has adopted a robust position against use of "alternative" pet preparations including homeopathy.
Electrohomeopathy.
Electrohomeopathy is a treatment devised by Count Cesare Mattei (1809–1896), who proposed that different "colors" of electricity could be used to treat cancer. Popular in the late nineteenth century, electrohomeopathy has been described as "utter idiocy".
Homeoprophylaxis.
The use of homeopathy as a preventive for serious infectious diseases is especially controversial, in the context of ill-founded public alarm over the safety of vaccines stoked by the anti-vaccination movement. Promotion of homeopathic alternatives to vaccines has been characterised as dangerous, inappropriate and irresponsible. In December 2014, Australian homeopathy supplier Homeopathy Plus! were found to have acted deceptively in promoting homeopathic alternatives to vaccines.
Evidence and efficacy.
The low concentration of homeopathic preparations, which often lack even a single molecule of the diluted substance, has been the basis of questions about the effects of the preparations since the 19th century. Modern advocates of homeopathy have proposed a concept of "water memory", according to which water "remembers" the substances mixed in it, and transmits the effect of those substances when consumed. This concept is inconsistent with the current understanding of matter, and water memory has never been demonstrated to have any detectable effect, biological or otherwise. Pharmacological research has found instead that stronger effects of an active ingredient come from higher, not lower doses.
James Randi and the groups have highlighted the lack of active ingredients in most homeopathic products by taking large 'overdoses'. None of the hundreds of demonstrators in the UK, Australia, New Zealand, Canada and the US were injured and "no one was cured of anything, either".
Outside of the alternative medicine community, scientists have long considered homeopathy a sham or a pseudoscience, and the mainstream medical community regards it as quackery. There is an overall absence of sound statistical evidence of therapeutic efficacy, which is consistent with the lack of any biologically plausible pharmacological agent or mechanism.
Abstract concepts within theoretical physics have been invoked to suggest explanations of how or why preparations might work, including quantum entanglement, quantum nonlocality, the theory of relativity and chaos theory. Contrariwise, quantum superposition has been invoked to explain why homeopathy does "not" work in double-blind trials. However, the explanations are offered by nonspecialists within the field, and often include speculations that are incorrect in their application of the concepts and not supported by actual experiments. Several of the key concepts of homeopathy conflict with fundamental concepts of physics and chemistry. The use of quantum entanglement to explain homeopathy's purported effects is "patent nonsense", as entanglement is a delicate state which rarely lasts longer than a fraction of a second. While entanglement may result in certain aspects of individual subatomic particles acquiring linked quantum states, this does not mean the particles will mirror or duplicate each other, nor cause health-improving transformations.
Plausibility.
The proposed mechanisms for homeopathy are precluded from having any effect by the laws of physics and physical chemistry. The extreme dilutions used in homeopathic preparations usually leave none of the original substance in the final product.
A number of speculative mechanisms have been advanced to counter this, the most widely discussed being water memory, though this is now considered erroneous since short-range order in water only persists for about 1 picosecond. No evidence of stable clusters of water molecules was found when homeopathic preparations were studied using nuclear magnetic resonance, and many other physical experiments in homeopathy have been found to be of low methodological quality, which precludes any meaningful conclusion. Existence of a pharmacological effect in the absence of any true active ingredient is inconsistent with the law of mass action and the observed dose-response relationships characteristic of therapeutic drugs (whereas placebo effects are non-specific and unrelated to pharmacological activity).
Homeopaths contend that their methods produce a therapeutically active preparation, selectively including only the intended substance, though critics note that any water will have been in contact with millions of different substances throughout its history, and homeopaths have not been able to account for a reason why only the selected homeopathic substance would be a special case in their process. For comparison, ISO 3696: 1987 defines a standard for water used in laboratory analysis; this allows for a contaminant level of ten parts per billion, 4C in homeopathic notation. This water may not be kept in glass as contaminants will leach out into the water.
Practitioners of homeopathy hold that higher dilutions―described as being of higher "potency"―produce stronger medicinal effects. This idea is also inconsistent with observed dose-response relationships, where effects are dependent on the concentration of the active ingredient in the body. This dose-response relationship has been confirmed in myriad experiments on organisms as diverse as nematodes, rats, and humans. Some homeopaths contend that the phenomenon of hormesis may support the idea of dilution increasing potency, but the dose-response relationship outside the zone of hormesis declines with dilution as normal, and nonlinear pharmacological effects do not provide any credible support for homeopathy.
Physicist Robert L. Park, former executive director of the American Physical Society, is quoted as saying,
"since the least amount of a substance in a solution is one molecule, a 30C solution would have to have at least one molecule of the original substance dissolved in a minimum of 1,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000 1060 molecules of water. This would require a container more than 30,000,000,000 times the size of the Earth."
Park is also quoted as saying that, "to expect to get even one molecule of the 'medicinal' substance allegedly present in 30X pills, it would be necessary to take some two billion of them, which would total about a thousand tons of lactose plus whatever impurities the lactose contained".
The laws of chemistry state that there is a limit to the dilution that can be made without losing the original substance altogether. This limit, which is related to Avogadro's number, is roughly equal to homeopathic dilutions of 12C or 24X (1 part in 1024).
Scientific tests run by both the BBC's "Horizon" and ABC's "20/20" programs were unable to differentiate homeopathic dilutions from water, even when using tests suggested by homeopaths themselves.
Efficacy.
No individual preparation has been unambiguously shown by research to be different from placebo. The methodological quality of the primary research was generally low, with such problems as weaknesses in study design and reporting, small sample size, and selection bias. Since better quality trials have become available, the evidence for efficacy of homeopathy preparations has diminished; the highest-quality trials indicate that the preparations themselves exert no intrinsic effect. A review conducted in 2010 of all the pertinent studies of "best evidence" produced by the Cochrane Collaboration concluded that "the most reliable evidence – that produced by Cochrane reviews – fails to demonstrate that homeopathic medicines have effects beyond placebo."
Government level reviews.
Government-level reviews have been conducted in recent years by Switzerland (2005), the United Kingdom (2009) and Australia (2015).
The Swiss "programme for the evaluation of complementary medicine" (PEK) resulted in the peer-reviewed Shang publication (see "Systematic reviews and meta-analyses of efficacy") and a controversial competing analysis by homeopaths and advocates led by Gudrun Bornhöft and Peter Matthiessen, which has misleadingly been presented as a Swiss government report by homeopathy proponents, a claim that has been repudiated by the Swiss Federal Office of Public Health. The Swiss Government terminated reimbursement, though it was subsequently reinstated after a political campaign and referendum for a further six-year trial period.
The United Kingdom's House of Commons Science and Technology Committee sought written evidence and submissions from concerned parties and, following a review of all submissions, concluded that there was no compelling evidence of effect other than placebo and recommended that the Medicines and Healthcare products Regulatory Agency (MHRA) should not allow homeopathic product labels to make medical claims, that homeopathic products should no longer be licensed by the MHRA, as they are not medicines, and that further clinical trials of homeopathy could not be justified. They recommended that funding of homeopathic hospitals should not continue, and NHS doctors should not refer patients to homeopaths. The Secretary of State for Health deferred to local NHS on funding homeopathy, in the name of patient choice. By February 2011 only one third of primary care trusts still funded homeopathy. By 2012, no British universities offered homeopathy courses.
The Australian National Health and Medical Research Council completed a comprehensive review of the effectiveness of homeopathic preparations in 2015, in which it concluded that "there were no health conditions for which there was reliable evidence that homeopathy was effective. No good-quality, well-designed studies with enough participants for a meaningful result reported either that homeopathy caused greater health improvements than placebo, or caused health improvements equal to those of another treatment."
Publication bias and other methodological issues.
The fact that individual randomized controlled trials have given positive results is not in contradiction with an overall lack of statistical evidence of efficacy. A small proportion of randomized controlled trials inevitably provide false-positive outcomes due to the play of chance: a "statistically significant" positive outcome is commonly adjudicated when the probability of it being due to chance rather than a real effect is no more than 5%―a level at which about 1 in 20 tests can be expected to show a positive result in the absence of any therapeutic effect. Furthermore, trials of low methodological quality (i.e. ones which have been inappropriately designed, conducted or reported) are prone to give misleading results. In a systematic review of the methodological quality of randomized trials in three branches of alternative medicine, Linde "et al." highlighted major weaknesses in the homeopathy sector, including poor randomization. A separate 2001 systematic review that assessed the quality of clinical trials of homeopathy found that such trials were generally of lower quality than trials of conventional medicine.
A related issue is publication bias: researchers are more likely to submit trials that report a positive finding for publication, and journals prefer to publish positive results. Publication bias has been particularly marked in alternative medicine journals, where few of the published articles (just 5% during the year 2000) tend to report null results. Regarding the way in which homeopathy is represented in the medical literature, a systematic review found signs of bias in the publications of clinical trials (towards negative representation in mainstream medical journals, and "vice versa" in alternative medicine journals), but not in reviews.
Positive results are much more likely to be false if the prior probability of the claim under test is low.
Systematic reviews and meta-analyses of efficacy.
Both meta-analyses, which statistically combine the results of several randomized controlled trials, and other systematic reviews of the literature are essential tools to summarize evidence of therapeutic efficacy. Early systematic reviews and meta-analyses of trials evaluating the efficacy of homeopathic preparations in comparison with placebo more often tended to generate positive results, but appeared unconvincing overall. In particular, reports of three large meta-analyses warned readers that firm conclusions could not be reached, largely due to methodological flaws in the primary studies and the difficulty in controlling for publication bias. The positive finding of one of the most prominent of the early meta-analyses, published in "The Lancet" in 1997 by Linde et al., was later reframed by the same research team, who wrote:
The evidence of bias the primary studies weakens the findings of our original meta-analysis. Since we completed our literature search in 1995, a considerable number of new homeopathy trials have been published. The fact that a number of the new high-quality trials ... have negative results, and a recent update of our review for the most "original" subtype of homeopathy (classical or individualized homeopathy), seem to confirm the finding that more rigorous trials have less-promising results. It seems, therefore, likely that our meta-analysis at least overestimated the effects of homeopathic treatments.
Subsequent work by John Ioannidis and others has shown that for treatments with no prior plausibility, the chances of a positive result being a false positive are much higher, and that any result not consistent with the null hypothesis should be assumed to be a false positive.
In 2002, a systematic review of the available systematic reviews confirmed that higher-quality trials tended to have less positive results, and found no convincing evidence that any homeopathic preparation exerts clinical effects different from placebo.
In 2005, "The Lancet" medical journal published a meta-analysis of 110 placebo-controlled homeopathy trials and 110 matched medical trials based upon the Swiss government's Program for Evaluating Complementary Medicine, or PEK. The study concluded that its findings were "compatible with the notion that the clinical effects of homeopathy are placebo effects". This was accompanied by an editorial pronouncing "The end of homoeopathy", which was denounced by the homeopath Peter Fisher.
Other meta-analyses include homeopathic treatments to reduce cancer therapy side-effects following radiotherapy and chemotherapy, allergic rhinitis, attention-deficit hyperactivity disorder and childhood diarrhea, adenoid vegetation, asthma, upper respiratory tract infection in children, insomnia, fibromyalgia, psychiatric conditions and Cochrane Library reviews of homeopathic treatments for asthma, dementia, attention-deficit hyperactivity disorder, induction of labor, and irritable bowel syndrome. Other reviews covered osteoarthritis, migraines delayed-onset muscle soreness, or eczema and other dermatological conditions.
The results of these reviews are generally negative or only weakly positive, and reviewers consistently report the poor quality of trials. The finding of Linde "et. al." that more rigorous studies produce less positive results is supported in several and contradicted by none.
Some clinical trials have tested individualized homeopathy, and there have been reviews of this, specifically. A 1998 review found 32 trials that met their inclusion criteria, 19 of which were placebo-controlled and provided enough data for meta-analysis. These 19 studies showed a pooled odds ratio of 1.17 to 2.23 in favor of individualized homeopathy over the placebo, but no difference was seen when the analysis was restricted to the methodologically best trials. The authors concluded that "the results of the available randomized trials suggest that individualized homeopathy has an effect over placebo. The evidence, however, is not convincing because of methodological shortcomings and inconsistencies." Jay Shelton, author of a book on homeopathy, has stated that the claim assumes without evidence that classical, individualized homeopathy works better than nonclassical variations. A systematic review and meta-analysis of trials of individualised homeopathy published in December 2014 concluded that individualised homeopathy may have small effects, but that caution was needed in interpreting the results because of study quality issues – no study included was assessed as being at low risk of bias.
Statements by major medical organisations.
Health organisations such as the UK's National Health Service, the American Medical Association, the FASEB, and the National Health and Medical Research Council of Australia, have issued statements of their conclusion that there is "no good-quality evidence that homeopathy is effective as a treatment for any health condition". In 2009, World Health Organization official Mario Raviglione cricitized the use of homeopathy to treat tuberculosis; similarly, another WHO spokesperson argued there was no evidence homeopathy would be an effective treatment for diarrhea.
The American College of Medical Toxicology and the American Academy of Clinical Toxicology recommend that no one use homeopathic treatment for disease or as a preventive health measure. These organizations report that no evidence exists that homeopathic treatment is effective, but that there is evidence that using these treatments produces harm and can bring indirect health risks by delaying conventional treatment.
Explanations of perceived effects.
Science offers a variety of explanations for how homeopathy may appear to cure diseases or alleviate symptoms even though the preparations themselves are inert:
Purported effects in other biological systems.
While some articles have suggested that homeopathic solutions of high dilution can have statistically significant effects on organic processes including the growth of grain, histamine release by leukocytes, and enzyme reactions, such evidence is disputed since attempts to replicate them have failed. A 2007 systematic review of high-dilution experiments found that none of the experiments with positive results could be reproduced by all investigators.
In 1987, French immunologist Jacques Benveniste submitted a paper to the journal "Nature" while working at INSERM. The paper purported to have discovered that basophils, a type of white blood cell, released histamine when exposed to a homeopathic dilution of anti-immunoglobulin E antibody. The journal editors, skeptical of the results, requested that the study be replicated in a separate laboratory. Upon replication in four separate laboratories the study was published. Still sceptical of the findings, "Nature" assembled an independent investigative team to determine the accuracy of the research, consisting of "Nature" editor and physicist Sir John Maddox, American scientific fraud investigator and chemist Walter Stewart, and sceptic James Randi. After investigating the findings and methodology of the experiment, the team found that the experiments were "statistically ill-controlled", "interpretation has been clouded by the exclusion of measurements in conflict with the claim", and concluded, "We believe that experimental data have been uncritically assessed and their imperfections inadequately reported." James Randi stated that he doubted that there had been any conscious fraud, but that the researchers had allowed "wishful thinking" to influence their interpretation of the data.
In 2001 and 2004, Madeleine Ennis published a number of studies which reported that homeopathic dilutions of histamine exerted an effect on the activity of basophils. In response to the first of these studies, "Horizon" aired a program in which British scientists attempted to replicate Ennis' results; they were unable to do so.
Ethics and safety.
The provision of homeopathic preparations has been described as unethical. Michael Baum, Professor Emeritus of Surgery and visiting Professor of Medical Humanities at University College London (UCL), has described homoeopathy as a "cruel deception".
Edzard Ernst, the first "Professor of Complementary Medicine" in the United Kingdom and a former homeopathic practitioner, has expressed his concerns about pharmacists who violate their ethical code by failing to provide customers with "necessary and relevant information" about the true nature of the homeopathic products they advertise and sell:
Patients who choose to use homeopathy rather than evidence-based medicine risk missing timely diagnosis and effective treatment of serious conditions such as cancer.
In 2013 the UK Advertising Standards Authority concluded that the Society of Homeopaths were targeting vulnerable ill people and discouraging the use of essential medical treatment while making misleading claims of efficacy for homeopathic products.
In 2015 the Federal Court of Australia imposed penalties on a homeopathic company, Homeopathy Plus! Pty Ltd and its director, for making false or misleading statements about the efficacy of the whooping cough vaccine and homeopathic remedies as an alternative to the whooping cough vaccine, in breach of the Australian Consumer Law. 
Adverse effects.
Some homeopathic preparations involve poisons such as Belladonna, arsenic, and poison ivy, which are highly diluted in the homeopathic preparation. In rare cases the original ingredients are present at detectable levels. This may be due to improper preparation or intentional low dilution. Serious adverse effects such as seizures and death have been reported or associated with some homeopathic preparations. Instances of arsenic poisoning have occurred after use of arsenic-containing homeopathic preparations. Zicam Cold remedy Nasal Gel, which contains 2X (1:100) zinc gluconate, reportedly caused a small percentage of users to lose their sense of smell; 340 cases were settled out of court in 2006 for . In 2009, the FDA advised consumers to stop using three discontinued cold remedy Zicam products because it could cause permanent damage to users' sense of smell. Zicam was launched without a New Drug Application (NDA) under a provision in the FDA's Compliance Policy Guide called "Conditions under which homeopathic drugs may be marketed" (CPG 7132.15), but the FDA warned Matrixx Initiatives, its manufacturer, via a Warning Letter that this policy does not apply when there is a health risk to consumers.
A 2000 review by homeopaths reported that homeopathic preparations are "unlikely to provoke severe adverse reactions". In 2012, a systematic review evaluating evidence of homeopathy's possible adverse effects concluded that "homeopathy has the potential to harm patients and consumers in both direct and indirect ways". One of the reviewers, Edzard Ernst, supplemented the article on his blog, writing: "I have said it often and I say it again: if used as an alternative to an effective cure, even the most 'harmless' treatment can become life-threatening."
Lack of efficacy.
The lack of convincing scientific evidence supporting its efficacy and its use of preparations without active ingredients have led to characterizations as pseudoscience and quackery, or, in the words of a 1998 medical review, "placebo therapy at best and quackery at worst". The Chief Medical Officer for England, Dame Sally Davies, has stated that homeopathic preparations are "rubbish" and do not serve as anything more than placebos. Jack Killen, acting deputy director of the National Center for Complementary and Alternative Medicine, says homeopathy "goes beyond current understanding of chemistry and physics". He adds: "There is, to my knowledge, no condition for which homeopathy has been proven to be an effective treatment." Ben Goldacre says that homeopaths who misrepresent scientific evidence to a scientifically illiterate public, have "... walled themselves off from academic medicine, and critique has been all too often met with avoidance rather than argument". Homeopaths often prefer to ignore meta-analyses in favour of cherry picked positive results, such as by promoting a particular observational study (one which Goldacre describes as "little more than a customer-satisfaction survey") as if it were more informative than a series of randomized controlled trials.
Referring specifically to homeopathy, the British House of Commons Science and Technology Committee has stated:
The National Center for Complementary and Alternative Medicine of the United States' National Institutes of Health states:
Ben Goldacre noted that in the early days of homeopathy, when medicine was dogmatic and frequently worse than doing nothing, homeopathy at least failed to make matters worse:
In lieu of standard medical treatment.
On clinical grounds, patients who choose to use homeopathy in preference to normal medicine risk missing timely diagnosis and effective treatment, thereby worsening the outcomes of serious conditions. Critics of homeopathy have cited individual cases of patients of homeopathy failing to receive proper treatment for diseases that could have been easily diagnosed and managed with conventional medicine and who have died as a result, and the "marketing practice" of criticizing and downplaying the effectiveness of mainstream medicine. Homeopaths claim that use of conventional medicines will "push the disease deeper" and cause more serious conditions, a process referred to as "suppression". Some homeopaths (particularly those who are non-physicians) advise their patients against immunisation. Some homeopaths suggest that vaccines be replaced with homeopathic "nosodes", created from biological materials such as pus, diseased tissue, bacilli from sputum or (in the case of "bowel nosodes") feces. While Hahnemann was opposed to such preparations, modern homeopaths often use them although there is no evidence to indicate they have any beneficial effects. Cases of homeopaths advising against the use of anti-malarial drugs have been identified. This puts visitors to the tropics who take this advice in severe danger, since homeopathic preparations are completely ineffective against the malaria parasite. Also, in one case in 2004, a homeopath instructed one of her patients to stop taking conventional medication for a heart condition, advising her on 22 June 2004 to "Stop ALL medications including homeopathic", advising her on or around 20 August that she no longer needed to take her heart medication, and adding on 23 August, "She just cannot take ANY drugs – I have suggested some homeopathic remedies ... I feel confident that if she follows the advice she will regain her health." The patient was admitted to hospital the next day, and died eight days later, the final diagnosis being "acute heart failure due to treatment discontinuation".
In 1978, Anthony Campbell, then a consultant physician at the Royal London Homeopathic Hospital, criticised statements by George Vithoulkas claiming that syphilis, when treated with antibiotics, would develop into secondary and tertiary syphilis with involvement of the central nervous system, saying that "The unfortunate layman might well be misled by Vithoulkas' rhetoric into refusing orthodox treatment".
Vithoulkas' claims echo the idea that treating a disease with external medication used to treat the symptoms would only drive it deeper into the body and conflict with scientific studies, which indicate that penicillin treatment produces a complete cure of syphilis in more than 90% of cases.
A 2006 review by W. Steven Pray of the College of Pharmacy at Southwestern Oklahoma State University recommends that pharmacy colleges include a required course in unproven medications and therapies, that ethical dilemmas inherent in recommending products lacking proven safety and efficacy data be discussed, and that students should be taught where unproven systems such as homeopathy depart from evidence-based medicine.
In an article entitled "Should We Maintain an Open Mind about Homeopathy?" published in the "American Journal of Medicine", Michael Baum and Edzard Ernstwriting to other physicianswrote that "Homeopathy is among the worst examples of faith-based medicine... These axioms homeopathy are not only out of line with scientific facts but also directly opposed to them. If homeopathy is correct, much of physics, chemistry, and pharmacology must be incorrect...".
In 2013, Mark Walport, the UK Government Chief Scientific Adviser and head of the Government Office for Science, had this to say: "My view scientifically is absolutely clear: homoeopathy is nonsense, it is non-science. My advice to ministers is clear: that there is no science in homoeopathy. The most it can have is a placebo effect – it is then a political decision whether they spend money on it or not." His predecessor, John Beddington, referring to his views on homeopathy being "fundamentally ignored" by the Government, said: "The only one being ignored I could think of was homoeopathy, which is mad. It has no underpinning of scientific basis. In fact all the science points to the fact that it is not at all sensible. The clear evidence is saying this is wrong, but homoeopathy is still used on the NHS."
Regulation and prevalence.
Homeopathy is fairly common in some countries while being uncommon in others; is highly regulated in some countries and mostly unregulated in others. It is practised worldwide and professional qualifications and licences are needed in most countries. In some countries, there are no specific legal regulations concerning the use of homeopathy, while in others, licences or degrees in conventional medicine from accredited universities are required. In Germany, to become a homeopathic physician, one must attend a three-year training program, while France, Austria and Denmark mandate licences to diagnose any illness or dispense of any product whose purpose is to treat any illness.
Some homeopathic treatment is covered by the public health service of several European countries, including France, the United Kingdom and Luxembourg. In other countries, such as Belgium, homeopathy is not covered. In Austria, the public health service requires scientific proof of effectiveness in order to reimburse medical treatments and homeopathy is listed as not reimbursable, but exceptions can be made; private health insurance policies sometimes include homeopathic treatment. The Swiss government, after a 5-year trial, withdrew coverage of homeopathy and four other complementary treatments in 2005, stating that they did not meet efficacy and cost-effectiveness criteria, but following a referendum in 2009 the five therapies have been reinstated for a further 6-year trial period from 2012.
The Indian government recognises homeopathy as one of its national systems of medicine; it has established AYUSH or the Department of Ayurveda, Yoga and Naturopathy, Unani, Siddha and Homoeopathy under the Ministry of Health & Family Welfare. The south Indian state of Kerala also gives the final nod for AYUSH department where homeopathy and Ayurveda are the main streams along with Sidha, Unani and Yoga. The Central Council of Homoeopathy was established in 1973 to monitor higher education in homeopathy, and National Institute of Homoeopathy in 1975. A minimum of a recognised diploma in homeopathy and registration on a state register or the Central Register of Homoeopathy is required to practice homeopathy in India.
Public opposition.
In the April 1997 edition of FDA Consumer, William T. Jarvis, the President of the National Council Against Health Fraud, said "Homeopathy is a fraud perpetrated on the public with the government's blessing, thanks to the abuse of political power of Sen. Royal S. Copeland sponsor of the 1938 Food, Drug, and Cosmetic Act."
Mock "overdosing" on homeopathic preparations by individuals or groups in "mass suicides" have become more popular since James Randi began taking entire bottles of homeopathic sleeping pills before giving lectures. In 2010 The Merseyside Skeptics Society from the United Kingdom launched the , encouraging groups to publicly overdose as groups. In 2011 the 10:23 campaign expanded and saw sixty-nine groups participate; fifty-four submitted videos. In April 2012, at the Berkeley SkeptiCal conference, over 100 people participated in a mass overdose, taking "coffea cruda", which is supposed to treat sleeplessness.
In 2011, the non-profit, educational organizations Center for Inquiry (CFI) and the associated Committee for Skeptical Inquiry (CSI) have petitioned the U.S. Food and Drug Administration (FDA) to initiate 'rulemaking that would require all over-the-counter homeopathic drugs to meet the same standards of effectiveness as non-homeopathic drugs' and 'to place warning labels on homeopathic drugs until such time as they are shown to be effective'. In a separate petition, CFI and CSI request FDA to issue warning letters to Boiron, maker of Oscillococcinum, regarding their marketing tactic and criticize Boiron for misleading labeling and advertising of Oscillococcinum. CFI in Canada is calling for persons that feel they were harmed by homeopathic products to contact them.
In August 2011, a class action lawsuit was filed against Boiron on behalf of "all California residents who purchased Oscillo at any time within the past four years". The lawsuit charged that it "is nothing more than a sugar pill", "despite falsely advertising that it contains an active ingredient known to treat flu symptoms". In March 2012, Boiron agreed to spend up to $12 million to settle the claims of falsely advertising the benefits of its homeopathic preparations.
In July 2012, CBC News reporter Erica Johnson for "Marketplace" conducted an investigation on the homeopathy industry in Canada; her findings were that it is "based on flawed science and some loopy thinking". Center for Inquiry (CFI) Vancouver skeptics participated in a mass overdose outside an emergency room in Vancouver, B.C., taking entire bottles of "medications" that should have made them sleepy, nauseous or dead; after 45 minutes of observation no ill effects were felt. Johnson asked homeopaths and company representatives about cures for cancer and vaccine claims. All reported positive results but none could offer any science backing up their statements, only that "it works". Johnson was unable to find any evidence that homeopathic preparations contain any active ingredient. Analysis performed at the University of Toronto's chemistry department found that the active ingredient is so small "it is equivalent to 5 billion times less than the amount of aspirin ... in a single pellet". Belladonna and ipecac "would be indistinguishable from each other in a blind test".
Following a threat of legal action by the Good Thinking Society campaign group, the British government has stated that the Department of Health will hold a consultation in 2016 regarding whether homeopathic treatments should be added to the NHS treatments blacklist (officially, Schedule 1 of the National Health Service (General Medical Services Contracts) (Prescription of Drugs etc.) Regulations 2004), that specifies a blacklist of medicines not to be prescribed under the NHS.
United States Food and Drug Administration (FDA) 2015 hearing.
On April 20–21, 2015, the FDA held a hearing on homeopathic product regulation. Invitees representing the scientific and medical community, and various pro-homeopathy stakeholders, gave testimonials on homeopathic products and the regulatory role played by the FDA.
Michael de Dora, a representative from the Center for Inquiry (CFI), on behalf of the organization and dozens of doctors and scientists associated with CFI and the Committee for Skeptical Inquiry (CSI) gave a testimonial which summarized the basis of the organization's objection to homeopathic products, the harm done to the general public and proposed regulatory actions:
The CFI testimonial stated that the principle of homeopathy is at complete odds with the basic principle of modern biology, chemistry and physics and that decades of scientific examination of homeopathic products shows that there is no evidence that it is effective in treating illnesses other than acting as a placebo. Further, it noted a 2012 report by the American Association of Poison Control Centers which listed 10,311 reported cases of poison exposure related to homeopathic agents, among which 8,788 cases were attributed to young children five years of age or younger, as well as examples of harm – including deaths – caused to patients who relied on homeopathics instead of proven medical treatment.
The CFI urged the FDA to announce and implement strict guidelines that 'require all homeopathic products meet the same standards as non-homeopathic drugs', arguing that the consumers can only have true freedom of choice (an often used argument from the homeopathy proponents) if they are fully informed on the choices. CFI proposed that the FDA take these three steps:
Official conclusions and recommendations.
In March 2015, the National Health and Medical Research Council of Australia issued the following conclusions and recommendations:

</doc>
<doc id="14231" url="https://en.wikipedia.org/wiki?curid=14231" title="Hairpin">
Hairpin

A hair pin or hairpin is a long device used to hold a person's hair in place. It may be used simply to secure long hair out of the way for convenience or as part of an elaborate hairstyle or coiffure. The earliest evidence for dressing the hair may be seen in carved "venus figurines" such as the Venus of Brassempouy and the Venus of Willendorf. The creation of different hairstyles, especially among women, seems to be common to all cultures and all periods and many past, and current, societies use hairpins.
Hairpins made of metal, ivory, bronze, carved wood, etc. were used in ancient Assyria and Egypt for securing decorated hairstyles. Such hairpins suggest, as graves show, that many were luxury objects among the Egyptians and later the Greeks, Etruscans, and Romans. Major success came in 1901 with the invention of the spiral hairpin by New Zealand inventor Ernest Godward. This was a predecessor of the hair clip.
The hairpin may be decorative and encrusted with jewels and ornaments, or it may be utiliarian, and designed to be almost invisible while holding a hairstyle in place.
Some hairpins are a single straight pin, but modern versions are more likely to be constructed from different lengths of wire that are bent in half with a u-shaped end and a few kinks along the two opposite portions. The finished pin may vary from two to six inches in final length. The length of the wires enables placement in several styles of hairdos to hold the style in place. The kinks enable retaining the pin during normal movements.
A hairpin patent was issued to Kelly Chamandy in 1925.
Hairpins in Chinese culture.
Hairpins (generally known as ; ) are an important symbol in Chinese culture. In ancient China, hairpins were worn by all genders, and they were essential items for everyday hairstyling, mainly for securing and decorating a hair bun. Furthermore, hairpins worn by women could also represent their social status.
In Han Chinese culture, when young girls reached the age of fifteen, they were allowed to take part in a rite of passage known as "" (), or “hairpin initiation” . This ceremony marks the coming of age of young women. Particularly, before the age of fifteen, girls did not use hairpins as they wore their hair in braids, and they were considered as children. When they turned fifteen, they could be considered as young women after the ceremony, and they started to style their hair as buns secured and embellished by hairpins. This practice indicated these young women may now enter into marriage. However, if a young woman hadn't been consented to marriage before age twenty, or she hadn't yet participated in a coming of age ceremony, she must attend a ceremony when she turned twenty.
In comparison with “”, the male equivalent known as “guan li” () or “hat initiation”, usually took place five years later, at the age of twenty. In the 21st century Hanfu Movement, an attempt to revive the traditional Han Chinese coming-of-age ceremonies has been made, and the ideal age to attend the ceremony is twenty years old for all genders.
While hairpins can symbolize the transition from childhood to adulthood, they were closely connected to the concept of marriage as well. At the time of an engagement, the fiancée may take a hairpin from her hair and give it to her fiancé as a pledge: this can be seen as a reversal of the Western tradition, such as the future groom presents an engagement ring to his betrothed. After the wedding ceremony, the husband should put the hairpin back into his spouse’s hair.
Hair has always carried many psychological, philosophical, romantic, and cultural meanings in Chinese culture. In Han ethnicity, people call the union between two people “” (), literally means “tying hair”. During the wedding ceremony, some Chinese couples exchange a lock of hair as a pledge, while others break a hairpin into two parts, and then, each of the betrothed take one part with them for keeping. If this couple ever get separated in the future, when they reunite, they can piece the two halves together, and this completed hairpin will serve as a proof of their identities as well as a symbol of their reunion. In addition, a married heterosexual couple is sometimes referred to as “” (), an idiom which implies the relationship between the pair is very intimate and happy, just like how their hair has been tied together.

</doc>
<doc id="14233" url="https://en.wikipedia.org/wiki?curid=14233" title="Hate speech">
Hate speech

Hate speech, outside the law, is speech that attacks a person or group on the basis of attributes such as gender, ethnic origin, religion, race, disability, or sexual orientation.
In the law of some countries, hate speech is any speech, gesture or conduct, writing, or display which is forbidden because it may incite violence or prejudicial action against or by a protected individual or group, or because it disparages or intimidates a protected individual or group. The law may identify a protected group by certain characteristics. In the law of other countries, hate speech is not a legal term.
In some countries, a victim of hate speech may seek redress under civil law, criminal law, or both. A website that uses hate speech is called a "hate site". Most of these sites contain Internet forums and news briefs that emphasize a particular viewpoint. There has been debate over how freedom of speech applies to the Internet as well as hate speech in general.
Critics have argued that the term "hate speech" is a contemporary example of Newspeak, used to silence critics of social policies that have been poorly implemented in a rush to appear politically correct.
International.
The International Covenant on Civil and Political Rights (ICCPR) states that "any advocacy of national, racial or religious hatred that constitutes incitement to discrimination, hostility or violence shall be prohibited by law". The Convention on the Elimination of All Forms of Racial Discrimination (ICERD) prohibits all incitement of racism. On 3 May 2011, Michael O'Flaherty with the United Nations Human Rights Committee published General Comment No. 34 on the ICCPR, which among other comments expresses concern that many forms of "hate speech" do not meet the level of seriousness set out in Article 20. Concerning the debate over how freedom of speech applies to the Internet, conferences concerning such sites have been sponsored by the United Nations High Commissioner for Refugees.
Enforcement of hate speech laws.
Hate law regulations can be divided into two types: those that are designed for public order and those that are designed to protect human dignity. Those designed to protect public order seem to be somewhat ineffective because they are rarely enforced. For example, in Northern Ireland, as of 1992 only one person was prosecuted for violating the regulation in twenty one years. Those meant to protect human dignity, however, like those in Canada, Denmark, France, Germany and the Netherlands seem to be frequently enforced.
Harm of hate speech.
Communication theory provides some insight into the harms caused by hate speech. According to the ritual model of communication, racist expressions allow minorities to be categorized with negative attributes tied to them, and are directly harmful to them. Matsuda "et al". (1993) found that racist speech could cause in the recipient of the message direct physical and emotional changes. The repeated use of such expressions cause and reinforce the subordination of these minorities. This has been enough to sway the court in previous cases such as Brown v. Board of Education in USA, in which the Court stated that segregation "generates a feeling of inferiority as to their Americans’ status in the community that may affect their hearts and minds in a way unlikely ever to be undone." The idea that hate speech is a mechanism of subordination is supported by scholarly evidence.
Hate speech on Facebook.
Following a campaign that involved the participation of Women, Action and the Media, the Everyday Sexism Project and the activist Soraya Chemaly, who were among 100 advocacy groups, Facebook agreed to update its policy on hate speech. The campaign highlighted content that promoted domestic and sexual violence against women, and used over 57,000 tweets and more than 4,900 emails to create outcomes such as the withdrawal of advertising from Facebook by 15 companies, including Nissan UK, House of Burlesque, and Nationwide UK. The social media website initially responded by stating that "While it may be vulgar and offensive, distasteful content on its own does not violate our policies", but then agreed to take action on May 29, 2013, after it had "become clear that our systems to identify and remove hate speech have failed to work as effectively as we would like, particularly around issues of gender-based hate."
By country.
Australia.
Australia's hate speech laws vary by jurisdiction, and seek especially to prevent victimisation on account of race.
Belgium.
The Belgian Anti-Racism Law, in full, the "Law of 30 July 1981 on the Punishment of Certain Acts inspired by Racism or Xenophobia", is a law against hate speech and discrimination passed by the Federal Parliament of Belgium in 1981 which made certain acts motivated by racism or xenophobia illegal. It is also known as the "Moureaux Law".
The Belgian Holocaust denial law, passed on 23 March 1995, bans public Holocaust denial. Specifically, the law makes it illegal to publicly "deny, play down, justify or approve of the genocide committed by the German National Socialist regime during the Second World War". Prosecution is led by the Belgian Centre for Equal Opportunities. The offense is punishable by imprisonment of up to one year and fines of up to 2500 EUR.
Brazil.
In Brazil, according to the 1988 Brazilian Constitution, racism and other forms of race-related hate speech are "imprescriptible crime(s) with no right to bail to its accused".
Canada.
In Canada, advocating genocide and inciting hatred against any "identifiable group" are indictable offences under the "Criminal Code" with maximum prison terms of two to fourteen years. An "identifiable group" is defined as "any section of the public distinguished by colour, race, religion, national or ethnic origin, age, sex, sexual orientation, or mental or physical disability". It makes exceptions for cases of statements of truth, and subjects of public debate and religious doctrine. The landmark judicial decision on the constitutionality of this law was "R. v. Keegstra" (1990).
Chile.
Article 31 of the "Ley sobre Libertades de Opinión e Información y Ejercicio del Periodismo" (statute on freedom of opinion and information and the performance of journalism), punishes with a high fine those who “through any means of social communication makes publications or transmissions intended to promote hatred or hostility towards persons or a group of persons due to their race, sex, religion or nationality". This norm has been applied to expressions proffered through the internet. There is also a rule aggravating the penalties of crimes when they are motivated by discriminatory hatred.
Council of Europe.
The Council of Europe has worked intensively on this issue. While Article 10 of the European Convention on Human Rights does not prohibit criminal laws against revisionism such as denial or minimization of genocides or crimes against humanity, as interpreted by the European Court of Human Rights (ECtHR), the Committee of Ministers of the Council of Europe went further and recommended to member governments to combat hate speech under its Recommendation R (97) 20. The ECtHR does not offer an accepted definition for "hate speech" but instead offers only parameters by which prosecutors can decide if the "hate speech" is entitled to the protection of freedom of speech.
The Council of Europe also created the European Commission against Racism and Intolerance, which has produced country reports and several general policy recommendations, for instance against anti-Semitism and intolerance against Muslims.
Croatia.
The Croatian Constitution guarantees freedom of speech, but Croatian penal code prohibits and punishes anyone "who based on differences of race, religion, language, political or any other belief, wealth, birth, education, social status or other properties, gender, skin color, nationality or ethnicity violates basic human rights and freedoms recognized from international community".
Denmark.
Denmark prohibits hate speech, and defines it as publicly making statements by which a group is threatened ('), insulted (') or degraded ("") due to race, skin colour, national or ethnic origin, faith or sexual orientation.
Finland.
There has been considerable debate over the definition of "hate speech" ("vihapuhe") in the Finnish language.
If "hate speech" is taken to mean ethnic agitation, it is prohibited in Finland and defined in the section 11 of the penal code, "War crimes and crimes against humanity", as publishing data, an opinion or other statement that threatens or insults a group on basis of race, nationality, ethnicity, religion or conviction, sexual orientation, disability, or any comparable basis. Ethnic agitation is punishable with a fine or up to 2 years in prison, or 4 months to 4 years if aggravated (such as incitement to genocide).
Critics claim that, in political contexts, labeling certain opinions and statements "hate speech" can be used to silence unfavorable or critical opinions and play down debate. Certain politicians, including Member of Parliament Jussi Halla-aho, consider the term "hate speech" problematic because of the lack of an easy definition.
France.
France prohibits by its penal code and by its press laws public and private communication which is defamatory or insulting, or which incites discrimination, hatred, or violence against a person or a group of persons on account of place of origin, ethnicity or lack thereof, nationality, race, specific religion, sex, sexual orientation, or handicap. The law prohibits declarations that justify or deny crimes against humanity, for example, the Holocaust (Gayssot Act).
Germany.
In Germany, Volksverhetzung ("incitement of popular hatred") is a punishable offense under Section 130 of the Strafgesetzbuch (Germany's criminal code) and can lead to up to five years imprisonment. Section 130 makes it a crime to publicly incite hatred against parts of the population or to call for violent or arbitrary measures against them or to insult, maliciously slur or defame them in a manner violating their (constitutionally protected) human dignity. Thus for instance it is illegal to publicly call certain ethnic groups "maggots" or "freeloaders". Volksverhetzung is punishable in Germany even if committed abroad and even if committed by non-German citizens, if only the incitement of hatred takes effect within German territory, e.g., the seditious sentiment was expressed in German writ or speech and made accessible in Germany (German criminal code's Principle of Ubiquity, Section 9 §1 Alt. 3 and 4 of the Strafgesetzbuch).
Iceland.
In Iceland, the hate speech law is not confined to inciting hatred, as one can see from Article 233 a. in the Icelandic Penal Code, but includes simply expressing such hatred publicly:
India.
Freedom of speech and expression is protected by article 19 (1) of the constitution of India, but under article 19(2) "reasonable restrictions" can be imposed on freedom of speech and expression in the interest of "the sovereignty and integrity of India, the security of the State, friendly relations with foreign States, public order, decency or morality, or in relation to contempt of court, defamation or incitement to an offence".
Indonesia.
Indonesia has been a signatory to the International Covenant on Civil and Political Rights since 2006, but has not promulgated comprehensive legislation against hate-speech crimes. Calls for a comprehensive anti-hate speech law and associated educational program have followed statements by a leader of a hard-line Islamic organization that Balinese Hindus were mustering forces to protect the "lascivious Miss World pageant" in “a war against Islam" and that "those who fight on the path of Allah are promised heaven". The statements are said to be an example of similar messages intolerance being preached throughout the country by radical clerics.
The National Police ordered all of their personnel to anticipate any potential conflicts in society caused by hate speech. The order is stipulated in the circular signed by the National Police chief General Badrodin Haiti on Oct. 8, 2015.
Ireland.
In Ireland, the right to free speech is guaranteed under the Constitution (Article 40.6.1.i), however, this is only an implied right provided that liberty of expression "shall not be used to undermine public order or morality or the authority of the State". The Prohibition of Incitement to Hatred Act 1989, proscribes words or behaviours which are "threatening, abusive or insulting and are intended or, having regard to all the circumstances, are likely to stir up hatred" against "a group of persons in the State or elsewhere on account of their race, colour, nationality, religion, ethnic or national origins, membership of the travelling community or sexual orientation".
Japan.
Japanese law covers threats and slander, but it "does not apply to hate speech against general groups of people". Japan became a member of the United Nations International Convention on the Elimination of All Forms of Racial Discrimination in 1995. Article 4 of the convention sets forth provisions calling for the criminalization of hate speech. But the Japanese government has suspended the provisions, saying actions to spread or promote the idea of racial discrimination have not been taken in Japan to such an extent that legal action is necessary. The Foreign Ministry says that this assessment remains unchanged.
In May 2013, the United Nations Committee on Economic, Social and Cultural Rights (CESCR) warned the Japanese government that it needs to take measures to curb hate speech against so-called "comfort women", or Asian women forced into sexual slavery by the Japanese military during World War II. The committee's recommendation called for the Japanese government to better educate Japanese society on the plight of women who were forced into sexual slavery to prevent stigmatization, and to take necessary measures to repair the lasting effects of exploitation, including addressing their right to compensation.
In 2013, following demonstrations, parades, and comments posted on the Internet threatening violence against foreign residents of Japan, especially Koreans, there are concerns that hate speech is a growing problem in Japan. Prime Minister Shinzo Abe and Justice Minister Sadakazu Tanigaki have expressed concerns about the raise in hate speech, saying that it "goes completely against the nation's dignity", but so far have stopped short of proposing any legal action against protesters.
On 22 September 2013 around 2,000 people participated in the "March on Tokyo for Freedom" campaigning against recent hate speech marches. Participants called on the Japanese government to "sincerely adhere" to the International Convention on the Elimination of All Forms of Racial Discrimination. Sexual minorities and the disabled also participated in the march.
On 25 September 2013 a new organization, "An international network overcoming hate speech and racism" (Norikoenet), that is opposed to hate speech against ethnic Koreans and other minorities in Japan was launched.
On 7 October 2013, in a rare ruling on racial discrimination against ethnic Koreans, a Japanese court ordered an anti-Korean group, Zaitokukai, to stop "hate speech" protests against a Korean school in Kyoto and pay the school 12.26 million yen ($126,400 U.S.) in compensation for protests that took place in 2009 and 2010.
A United Nations panel urged Japan to ban hate speech.
Jordan.
Several Jordanian laws seek to prevent the publication or dissemination of material that would provoke strife or hatred: 
Netherlands.
The Dutch penal code prohibits both insulting a group (article 137c) and inciting hatred, discrimination or violence (article 137d). The definition of the offences as outlined in the penal code is as follows:
In January 2009, a court in Amsterdam ordered the prosecution of Geert Wilders, a Dutch Member of Parliament, for breaching articles 137c and 137d. On 23 June 2011, Wilders was acquitted of all charges.
New Zealand.
New Zealand prohibits hate speech under the Human Rights Act 1993. Section 61 (Racial Disharmony) makes it unlawful to publish or distribute "threatening, abusive, or insulting...matter or words likely to excite hostility against or bring into contempt any group of persons...on the ground of the colour, race, or ethnic or national or ethnic origins of that group of persons". Section 131 (Inciting Racial Disharmony) lists offences for which "racial disharmony" creates liability.
Norway.
Norway prohibits hate speech, and defines it as publicly making statements that threaten or ridicule someone or that incite hatred, persecution or contempt for someone due to their skin colour, ethnic origin, homosexual orientation, religion or philosophy of life. At the same time, the Norwegian Constitution guarantees the right to free speech, and there has been an ongoing public and judicial debate over where the right balance between the ban against hate speech and the right to free speech lies. Norwegian courts have been restrictive in the use of the hate speech law and only few persons have been sentenced for violating the law since its implementation in 1970. A public Free Speech committee (1996-1999) recommended to abolish the hate speech law but the Norwegian Parliament instead voted to slightly strengthen it.
Poland.
The hate speech laws in Poland punish those who offend the feelings of the religious by e.g. disturbing a religious ceremony or creating public calumny. They also prohibit public expression that insults a person or a group on account of national, ethnic, racial, or religious affiliation or the lack of a religious affiliation.
Serbia.
The Serbian constitution guarantees freedom of speech, but restricts it in certain cases to protect the rights of others. The criminal charge of "Provoking ethnic, racial and religion based animosity and intolerance" carries a minimum six months prison term and a maximum of ten years.
Singapore.
Singapore has passed numerous laws that prohibit speech that causes disharmony among various religious groups. The Maintenance of Religious Harmony Act is an example of such legislation. The Penal Code criminalizes the deliberate promotion by someone of enmity, hatred or ill-will between different racial and religious groups on grounds of race or religion. It also makes it an offence for anyone to deliberately wound the religious or racial feelings of any person.
South Africa.
In South Africa, hate speech (along with incitement to violence and propaganda for war) is specifically excluded from protection of free speech in the Constitution. The Promotion of Equality and Prevention of Unfair Discrimination Act, 2000 contains the following clause:
The "prohibited grounds" include race, gender, sex, pregnancy, marital status, ethnic or social origin, colour, sexual orientation, age, disability, religion, conscience, belief, culture, language and birth.
The crime of "crimen injuria" ("unlawfully, intentionally and seriously impairing the dignity of another") may also be used to prosecute hate speech.
In 2011, a South African court banned "Dubula iBhunu (Shoot the Boer)", a derogatory song degrading Afrikaners, on the basis that it violated a South African law prohibiting speech that demonstrates a clear intention to be hurtful, to incite harm, or to promote hatred.
Sweden.
Sweden prohibits hate speech, and defines it as publicly making statements that threaten or express disrespect for an ethnic group or similar group regarding their race, skin colour, national or ethnic origin, faith, or sexual orientation. The crime does not prohibit a pertinent and responsible debate ("en saklig och vederhäftig diskussion"), nor statements made in a completely private sphere. There are constitutional restrictions pertaining to which acts are criminalized, as well limits set by the European Convention on Human Rights. The crime is called "Hets mot folkgrupp" in Swedish which directly translated can be translated to "Incitement (of hatred/violence) towards population groups."
The sexual orientation provision, added in 2002, was used to convict Pentecostalist pastor Åke Green of hate speech based on a 2003 sermon. His conviction was later overturned.
Switzerland.
In Switzerland public discrimination or invoking to rancor against persons or a group of people because of their race, ethnicity, is getting penalized with a term of imprisonment until 3 years or a mulct. In 1934, the authorities of the Basel-Stadt canton criminalized anti-Jewish hate speech, e.g., the accusation of ritual murders, mostly in reaction against a pro-Nazi antisemitic group and newspaper, the Volksbund.
United Kingdom.
In the United Kingdom, several statutes criminalize hate speech against several categories of persons. The statutes forbid communication which is hateful, threatening, abusive, or insulting and which targets a person on account of disability, ethnic or national origin, nationality (including citizenship), race, religion, sexual orientation, or skin colour. The penalties for hate speech include fines, imprisonment, or both. Legislation against Sectarian hate in Scotland, which is aimed principally at football matches, does not criminalise jokes about people's beliefs, nor outlaw “harsh” comment about their religious faith.
United States.
Constitutional framework.
The 1789 Constitution of the United States of America dealt only with the three heads of power—legislative, executive, and judicial—and sketched the basic outlines of federalism in the last four articles. The protection of civil rights was not written into the original Constitution but was added two years later with the Bill of Rights, implemented as several amendments to the Constitution. The First Amendment, ratified December 15, 1791, states:
Although this section was considered only to apply to the federal congress (i.e. the legislative branch), the 14th Amendment, ratified on July 9, 1868, clarifies that this prohibition applies to laws of the states as well.
Some state constitutions also have a "free speech" provision, most notably, California.
Supreme Court case law.
Some limits on expression were contemplated by the framers and have been read into the Constitution by the Supreme Court. In 1942, Justice Frank Murphy summarized the case law: "There are certain well-defined and limited classes of speech, the prevention and punishment of which have never been thought to raise a Constitutional problem. These include the lewd and obscene, the profane, the libelous and the insulting or 'fighting' words – those which by their very utterances inflict injury or tend to incite an immediate breach of the peace."
Traditionally, however, if the speech did not fall within one of the above categorical exceptions, it was protected speech. In 1969, the Supreme Court protected a Ku Klux Klan member’s racist speech and created the "imminent danger" test to permit hate speech. The court ruled in "Brandenburg v. Ohio" that; "The constitutional guarantees of free speech and free press do not permit a state to forbid or proscribe advocacy of the use of force, or of law violation except where such advocacy is directed to inciting imminent lawless action and is likely to incite or produce such action."
This test has been modified very little from its inception in 1969 and the formulation is still good law in the United States. Only speech that poses an imminent danger of unlawful action, where the speaker has the intention to incite such action and there is the likelihood that this will be the consequence of his or her speech, may be restricted and punished by that law.
In "R.A.V. v. City of St. Paul", (1992), the issue of freedom to express hatred arose again when a gang of white people burned a cross in the front yard of a black family. The local ordinance in St. Paul, Minnesota, criminalized such racist and hate-filled expressions and the teenager was charged thereunder. Associate justice Antonin Scalia, writing for the Supreme Court, held that the prohibition against hate speech was unconstitutional as it contravened the First Amendment. The Supreme Court struck down the ordinance. Scalia explicated the fighting words exception as follows: “The reason why fighting words are categorically excluded from the protection of the First Amendment is not that their content communicates any particular idea, but that their content embodies a particularly intolerable (and socially unnecessary) mode of expressing whatever idea the speaker wishes to convey”. Because the hate speech ordinance was not concerned with the mode of expression, but with the content of expression, it was a violation of the freedom of speech. Thus, the Supreme Court embraced the idea that hate speech is permissible unless it will lead to imminent hate violence. The opinion noted "This conduct, if proved, might well have violated various Minnesota laws against arson, criminal damage to property", among a number of others, none of which was charged, including threats to any person, not to only protected classes.
In 2011, the Supreme Court issued their ruling on "Snyder v. Phelps," which concerned the right of the Westboro Baptist Church to protest with signs found offensive by many Americans. The issue presented was whether the 1st Amendment protected the expressions written on the signs. In an 8-1 decision the court sided with Phelps, the head of Westboro Baptist Church, thereby confirming their historically strong protection of hate speech, so long as it doesn't promote imminent violence. The Court explained, "speech deals with matters of public concern when it can 'be fairly considered as relating to any matter of political, social, or other concern to the community' or when it 'is a subject of general interest and of value and concern to the public." 
Societal implementation.
In the 1980s and 1990s, more than 350 public universities adopted "speech codes" regulating discriminatory speech by faculty and students. These codes have not fared well in the courts, where they are frequently overturned as violations of the First Amendment. Debate over restriction of "hate speech" in public universities has resurfaced with the adoption of anti-harassment codes covering discriminatory speech.
NTIA report.
In 1992, Congress directed the National Telecommunications and Information Administration (NTIA) to examine the role of telecommunications, including broadcast radio and television, cable television, public access television, and computer bulletin boards, in advocating or encouraging violent acts and the commission of hate crimes against designated persons and groups. The NTIA study investigated speech that fostered a climate of hatred and prejudice in which hate crimes may occur. The study failed to link telecommunication to hate crimes, but did find that "individuals have used telecommunications to disseminate messages of hate and bigotry to a wide audience." Its recommendation was that the best way to fight hate speech was through additional speech promoting tolerance, as opposed to government regulation.

</doc>
<doc id="14236" url="https://en.wikipedia.org/wiki?curid=14236" title="Henrik Ibsen">
Henrik Ibsen

Henrik Johan Ibsen (; ; 20 March 1828 – 23 May 1906) was a major 19th-century Norwegian playwright, theatre director, and poet. He is often referred to as "the father of realism" and is one of the founders of Modernism in theatre. His major works include "Brand", "Peer Gynt", "An Enemy of the People", "Emperor and Galilean", "A Doll's House", "Hedda Gabler", "Ghosts", "The Wild Duck", "Rosmersholm", and "The Master Builder". He is the most frequently performed dramatist in the world after Shakespeare, and "A Doll's House" became the world's most performed play by the early 20th century.
Several of his later dramas were considered scandalous to many of his era, when European theatre was expected to model strict morals of family life and propriety. Ibsen's later work examined the realities that lay behind many façades, revealing much that was disquieting to many contemporaries. It utilized a critical eye and free inquiry into the conditions of life and issues of morality. The poetic and cinematic early play "Peer Gynt", however, has strong surreal elements.
Ibsen is often ranked as one of the most distinguished playwrights in the European tradition. Richard Hornby describes him as "a profound poetic dramatist—the best since Shakespeare". He is widely regarded as the most important playwright since Shakespeare. He influenced other playwrights and novelists such as George Bernard Shaw, Oscar Wilde, Arthur Miller, James Joyce, Eugene O'Neill and Miroslav Krleža. Ibsen was nominated for the Nobel Prize in Literature in 1902, 1903 and 1904.
Ibsen wrote his plays in Danish (the common written language of Denmark and Norway) and they were published by the Danish publisher Gyldendal. Although most of his plays are set in Norway—often in places reminiscent of Skien, the port town where he grew up—Ibsen lived for 27 years in Italy and Germany, and rarely visited Norway during his most productive years. Born into a merchant family connected to the patriciate of Skien, his dramas were shaped by his family background. He was the father of Prime Minister Sigurd Ibsen. Ibsen's dramas continue in their influence upon contemporary culture and film with notable film productions including "A Doll's House" featuring Jane Fonda and "A Master Builder" featuring Wallace Shawn.
Early life.
Ibsen was born to Knud Ibsen (1797–1877) and Marichen Altenburg (1799–1869), a well-to-do merchant family, in the small port town of Skien in Telemark county, a city which was noted for shipping timber. As he wrote in an 1882 letter to critic and scholar Georg Brandes, "my parents were members on both sides of the most respected families in Skien", explaining that he was closely related with "just about all the patrician families who then dominated the place and its surroundings", mentioning the families Paus, Plesner, von der Lippe, Cappelen and Blom. Ibsen's grandfather, ship captain Henrich Ibsen (1765–1797), had died at sea in 1797, and Knud Ibsen was raised on the estate of ship-owner Ole Paus (1776–1855), after his mother Johanne, Plesner (1770–1847), remarried. Knud Ibsen's half brothers included lawyer and politician Christian Cornelius Paus, banker and ship-owner Christopher Blom Paus, and lawyer Henrik Johan Paus, who grew up with Ibsen's mother in the Altenburg home and after whom Henrik (Johan) Ibsen was named.
Knud Ibsen's paternal ancestors were ship captains of Danish origin, but he decided to become a merchant, having initial success. His marriage to Marichen Altenburg, a daughter of ship-owner Johan Andreas Altenburg (1763–1824) and Hedevig Christine Paus (1763–1848), was a successful match. Theodore Jorgenson points out that "Henrik's ancestry reached back into the important Telemark family of Paus both on the father's and on the mother's side. Hedvig Paus must have been well known to the young dramatist, for she lived until 1848." Henrik Ibsen was fascinated by his parents' "strange, almost incestuous marriage," and would treat the subject of incestuous relationships in several plays, notably his masterpiece "Rosmersholm".
When Henrik Ibsen was around seven years old, however, his father's fortunes took a significant turn for the worse, and the family was eventually forced to sell the major Altenburg building in central Skien and move permanently to their small summer house, Venstøp, outside of the city. Henrik's sister Hedvig would write about their mother: "She was a quiet, lovable woman, the soul of the house, everything to her husband and children. She sacrificed herself time and time again. There was no bitterness or reproach in her." The Ibsen family eventually moved to a city house, Snipetorp, owned by Knud Ibsen's half-brother, wealthy banker and ship-owner Christopher Blom Paus.
His father's financial ruin would have a strong influence on Ibsen's later work; the characters in his plays often mirror his parents, and his themes often deal with issues of financial difficulty as well as moral conflicts stemming from dark secrets hidden from society. Ibsen would both model and name characters in his plays after his own family. A central theme in Ibsen's plays is the portrayal of suffering women, echoing his mother Marichen Altenburg; Ibsen's sympathy with women would eventually find significant expression with their portrayal in dramas such as "A Doll's House" and "Rosmersholm".
At fifteen, Ibsen was forced to leave school. He moved to the small town of Grimstad to become an apprentice pharmacist and began writing plays. In 1846, when Ibsen was age 18, a liaison with a servant produced an illegitimate child, whose upbringing Ibsen had to pay for until the boy was in his teens, though Ibsen never saw the boy. Ibsen went to Christiania (later renamed Kristiania and then Oslo) intending to matriculate at the university. He soon rejected the idea (his earlier attempts at entering university were blocked as he did not pass all his entrance exams), preferring to commit himself to writing. His first play, the tragedy "Catilina" (1850), was published under the pseudonym "Brynjolf Bjarme", when he was only 22, but it was not performed. His first play to be staged, "The Burial Mound" (1850), received little attention. Still, Ibsen was determined to be a playwright, although the numerous plays he wrote in the following years remained unsuccessful. Ibsen's main inspiration in the early period, right up to "Peer Gynt", was apparently Norwegian author Henrik Wergeland and the Norwegian folk tales as collected by Peter Christen Asbjørnsen and Jørgen Moe. In Ibsen's youth, Wergeland was the most acclaimed, and by far the most read, Norwegian poet and playwright.
Life and writings.
He spent the next several years employed at Det norske Theater (Bergen), where he was involved in the production of more than 145 plays as a writer, director, and producer. During this period, he published five new, though largely unremarkable, plays. Despite Ibsen's failure to achieve success as a playwright, he gained a great deal of practical experience at the Norwegian Theater, experience that was to prove valuable when he continued writing.
Ibsen returned to Christiania in 1858 to become the creative director of the Christiania Theatre. He married Suzannah Thoresen on 18 June 1858 and she gave birth to their only child Sigurd on 23 December 1859. The couple lived in very poor financial circumstances and Ibsen became very disenchanted with life in Norway. In 1864, he left Christiania and went to Sorrento in Italy in self-imposed exile. He didn't return to his native land for the next 27 years, and when he returned to it he was a noted, but controversial, playwright.
His next play, "Brand" (1865), brought him the critical acclaim he sought, along with a measure of financial success, as did the following play, "Peer Gynt" (1867), to which Edvard Grieg famously composed incidental music and songs. Although Ibsen read excerpts of the Danish philosopher Søren Kierkegaard and traces of the latter's influence are evident in "Brand", it was not until after "Brand" that Ibsen came to take Kierkegaard seriously. Initially annoyed with his friend Georg Brandes for comparing Brand to Kierkegaard, Ibsen nevertheless read "Either/Or" and "Fear and Trembling". Ibsen's next play "Peer Gynt" was consciously informed by Kierkegaard.
With success, Ibsen became more confident and began to introduce more and more of his own beliefs and judgements into the drama, exploring what he termed the "drama of ideas". His next series of plays are often considered his Golden Age, when he entered the height of his power and influence, becoming the center of dramatic controversy across Europe.
Ibsen moved from Italy to Dresden, Germany, in 1868, where he spent years writing the play he regarded as his main work, "Emperor and Galilean" (1873), dramatizing the life and times of the Roman emperor Julian the Apostate. Although Ibsen himself always looked back on this play as the cornerstone of his entire works, very few shared his opinion, and his next works would be much more acclaimed. Ibsen moved to Munich in 1875 and began work on his first contemporary realist drama "The Pillars of Society", first published and performed in 1877. "A Doll's House" followed in 1879. This play is a scathing criticism of the marital roles accepted by men and women which characterized Ibsen's society.
"Ghosts" followed in 1881, another scathing commentary on the morality of Ibsen's society, in which a widow reveals to her pastor that she had hidden the evils of her marriage for its duration. The pastor had advised her to marry her fiancé despite his philandering, and she did so in the belief that her love would reform him. But his philandering continued right up until his death, and his vices are passed on to their son in the form of syphilis. The mention of venereal disease alone was scandalous, but to show how it could poison a respectable family was considered intolerable.
In "An Enemy of the People" (1882), Ibsen went even further. In earlier plays, controversial elements were important and even pivotal components of the action, but they were on the small scale of individual households. In "An Enemy", controversy became the primary focus, and the antagonist was the entire community. One primary message of the play is that the individual, who stands alone, is more often "right" than the mass of people, who are portrayed as ignorant and sheeplike. Contemporary society's belief was that the community was a noble institution that could be trusted, a notion Ibsen challenged. In "An Enemy of the People", Ibsen chastised not only the conservatism of society, but also the liberalism of the time. He illustrated how people on both sides of the social spectrum could be equally self-serving. "An Enemy of the People" was written as a response to the people who had rejected his previous work, "Ghosts". The plot of the play is a veiled look at the way people reacted to the plot of "Ghosts". The protagonist is a physician in a vacation spot whose primary draw is a public bath. The doctor discovers that the water is contaminated by the local tannery. He expects to be acclaimed for saving the town from the nightmare of infecting visitors with disease, but instead he is declared an 'enemy of the people' by the locals, who band against him and even throw stones through his windows. The play ends with his complete ostracism. It is obvious to the reader that disaster is in store for the town as well as for the doctor.
As audiences by now expected, Ibsen's next play again attacked entrenched beliefs and assumptions; but this time, his attack was not against society's mores, but against overeager reformers and their idealism. Always an iconoclast, Ibsen was equally willing to tear down the ideologies of any part of the political spectrum, including his own.
"The Wild Duck" (1884) is by many considered Ibsen's finest work, and it is certainly the most complex. It tells the story of Gregers Werle, a young man who returns to his hometown after an extended exile and is reunited with his boyhood friend Hjalmar Ekdal. Over the course of the play, the many secrets that lie behind the Ekdals' apparently happy home are revealed to Gregers, who insists on pursuing the absolute truth, or the "Summons of the Ideal". Among these truths: Gregers' father impregnated his servant Gina, then married her off to Hjalmar to legitimize the child. Another man has been disgraced and imprisoned for a crime the elder Werle committed. Furthermore, while Hjalmar spends his days working on a wholly imaginary "invention", his wife is earning the household income.
Ibsen displays masterful use of irony: despite his dogmatic insistence on truth, Gregers never says what he thinks but only insinuates, and is never understood until the play reaches its climax. Gregers hammers away at Hjalmar through innuendo and coded phrases until he realizes the truth; Gina's daughter, Hedvig, is not his child. Blinded by Gregers' insistence on absolute truth, he disavows the child. Seeing the damage he has wrought, Gregers determines to repair things, and suggests to Hedvig that she sacrifice the wild duck, her wounded pet, to prove her love for Hjalmar. Hedvig, alone among the characters, recognizes that Gregers always speaks in code, and looking for the deeper meaning in the first important statement Gregers makes which does not contain one, kills herself rather than the duck in order to prove her love for him in the ultimate act of self-sacrifice. Only too late do Hjalmar and Gregers realize that the absolute truth of the "ideal" is sometimes too much for the human heart to bear.
Late in his career, Ibsen turned to a more introspective drama that had much less to do with denunciations of society's moral values. In such later plays as "Hedda Gabler" (1890) and "The Master Builder" (1892), Ibsen explored psychological conflicts that transcended a simple rejection of current conventions. Many modern readers, who might regard anti-Victorian didacticism as dated, simplistic or hackneyed, have found these later works to be of absorbing interest for their hard-edged, objective consideration of interpersonal confrontation. "Hedda Gabler" is probably Ibsen's most performed play, with the title role regarded as one of the most challenging and rewarding for an actress even in the present day. "Hedda Gabler" and "A Doll's House" center on female protagonists whose almost demonic energy proves both attractive and destructive for those around them, and while Hedda has a few similarities with the character of Nora in "A Doll's House", many of today's audiences and theatre critics feel that Hedda's intensity and drive are much more complex and much less comfortably explained than what they view as rather routine feminism on the part of Nora.
Ibsen had completely rewritten the rules of drama with a realism which was to be adopted by Chekhov and others and which we see in the theatre to this day. From Ibsen forward, challenging assumptions and directly speaking about issues has been considered one of the factors that makes a play art rather than entertainment. His works were brought to an English-speaking audience, largely thanks to the efforts of William Archer and Edmund Gosse. These in turn had a profound influence on the young James Joyce who venerates him in his early autobiographical novel "Stephen Hero". Ibsen returned to Norway in 1891, but it was in many ways not the Norway he had left. Indeed, he had played a major role in the changes that had happened across society. Modernism was on the rise, not only in the theatre, but across public life.
Death.
On 23 May 1906, Ibsen died in his home at Arbins gade 1 in Kristiania (now Oslo) after a series of strokes in March 1900. When, on 22 May, his nurse assured a visitor that he was a little better, Ibsen spluttered his last words "On the contrary" ("Tvertimod!"). He died the following day at 2:30 P.M.
Ibsen was buried in Vår Frelsers gravlund ("The Graveyard of Our Savior") in central Oslo.
Centenary.
The 100th anniversary of Ibsen's death in 2006 was commemorated with an "Ibsen year" in Norway and other countries. This year the homebuilding company Selvaag also opened "Peer Gynt" Sculpture Park in Oslo, Norway, in Henrik Ibsen's honour, making it possible to follow the dramatic play "Peer Gynt" scene by scene. Will Eno's adaptation of Ibsen's "Peer Gynt", titled "Gnit", had its world premiere at the 37th Humana Festival of New American Plays in March 2013.
On 23 May 2006, The Ibsen Museum in Oslo reopened to the public the house where Ibsen had spent his last eleven years, completely restored with the original interior, colors, and decor.
Ancestry.
Ibsen's ancestry has been a much studied subject, due to his perceived foreignness and due to the influence of his biography and family on his plays. Ibsen often made references to his family in his plays, sometimes by name, or by modelling characters after them.
The oldest documented member of the Ibsen family was ship's captain Rasmus Ibsen (1632–1703) from Stege, Denmark. His son, ship's captain Peder Ibsen became a burgher of Bergen in Norway in 1726. Henrik Ibsen has Danish, German, Norwegian and some distant Scottish ancestry. Most of his ancestors belonged to the merchant class of original Danish/German extraction, and many of his ancestors were ship's captains. His biographer Henrik Jæger famously wrote in 1888 that Ibsen did not have a drop of Norwegian blood in his veins, stating that "the ancestral Ibsen was a Dane". This, however, is not completely accurate; notably through his grandmother Hedevig Paus, Ibsen was descended from one of the very few families of the patrician class of original Norwegian extraction, known since the 15th century. Ibsen's ancestors had mostly lived in Norway for several generations, even though many had foreign ancestry.
The name Ibsen is originally a patronymic, meaning "son of Ib" (Ib is a Danish variant of Jacob). The patronymic became "frozen", i.e. it became a permanent family name, already in the 17th century. The phenomenon of patronymics becoming frozen started in the 17th century in bourgeois families in Denmark, and the practice was only widely adopted in Norway from around 1900.
Descendants.
From his marriage with Suzannah Thoresen, Ibsen had one son, lawyer and government minister Sigurd Ibsen. Sigurd Ibsen married Bergljot Bjørnson, the daughter of Bjørnstjerne Bjørnson. Their only son was Tancred Ibsen, who became a film director and who was married to Lillebil Ibsen. Their only child was diplomat Tancred Ibsen, Jr. Sigurd Ibsen's daughter, Irene Ibsen, married Josias Bille, a member of the Danish ancient noble Bille family. Their son was Danish actor Joen Bille.
Adaptations.
There have been numerous adaptations of Ibsen's work, particularly in film, theatre and music. Notable are Torstein Blixfjord's "Terje" and "Identity of the Soul" - two multimedia, film and dance pieces first presented in Yokohama in 2006, based on the poem "Terje Vigen".
Legacy.
On the occasion of the 100th anniversary of Ibsen's death in 2006, the Norwegian government organised the Ibsen Year, which included celebrations around the world. The NRK produced a miniseries on Ibsen's childhood and youth in 2006, "An Immortal Man". Several prizes are awarded in the name of Henrik Ibsen, among them the International Ibsen Award, the Norwegian Ibsen Award and the Ibsen Centennial Commemoration Award.
Every year, since 2008, the annual "Delhi Ibsen Festival", is held in Delhi, India, organized by the Dramatic Art and Design Academy (DADA) in collaboration with The Royal Norwegian Embassy in India. It features plays by Ibsen, performed by artists from various parts of the world in varied languages and styles.
Honours.
Ibsen was decorated Knight in 1873, Commander in 1892, and with the Grand Cross of the Order of St. Olav in 1893. He received the Grand Cross of the Danish Order of the Dannebrog, and the Grand Cross of the Swedish Order of the Polar Star, and was Knight, First Class of the Order of Vasa.
In 1995, the asteroid (5696) Ibsen was named in his memory.
English translations.
The authoritative translation in the English language for Ibsen remains the 1928 ten-volume version of the "Complete Works of Henrik Ibsen" from Oxford University Press. Many other translations of individual plays by Ibsen have appeared since 1928 though none have purported to be a new version of the complete works of Ibsen.

</doc>
