<doc id="18209" url="https://en.wikipedia.org/wiki?curid=18209" title="Lossless compression">
Lossless compression

Lossless compression is a class of data compression algorithms that allows the original data to be perfectly reconstructed from the compressed data. By contrast, lossy compression permits reconstruction only of an approximation of the original data, though this usually improves compression rates (and therefore reduces file sizes).
Lossless data compression is used in many applications. For example, it is used in the ZIP file format and in the GNU tool gzip. It is also often used as a component within lossy data compression technologies (e.g. lossless mid/side joint stereo preprocessing by the LAME MP3 encoder and other lossy audio encoders).
Lossless compression is used in cases where it is important that the original and the decompressed data be identical, or where deviations from the original data could be deleterious. Typical examples are executable programs, text documents, and source code. Some image file formats, like PNG or GIF, use only lossless compression, while others like TIFF and MNG may use either lossless or lossy methods. Lossless audio formats are most often used for archiving or production purposes, while smaller lossy audio files are typically used on portable players and in other cases where storage space is limited or exact replication of the audio is unnecessary.
Lossless compression techniques.
Most lossless compression programs do two things in sequence: the first step generates a "statistical model" for the input data, and the second step uses this model to map input data to bit sequences in such a way that "probable" (e.g. frequently encountered) data will produce shorter output than "improbable" data.
The primary encoding algorithms used to produce bit sequences are Huffman coding (also used by DEFLATE) and arithmetic coding. Arithmetic coding achieves compression rates close to the best possible for a particular statistical model, which is given by the information entropy, whereas Huffman compression is simpler and faster but produces poor results for models that deal with symbol probabilities close to 1.
There are two primary ways of constructing statistical models: in a "static" model, the data is analyzed and a model is constructed, then this model is stored with the compressed data. This approach is simple and modular, but has the disadvantage that the model itself can be expensive to store, and also that it forces using a single model for all data being compressed, and so performs poorly on files that contain heterogeneous data. "Adaptive" models dynamically update the model as the data is compressed. Both the encoder and decoder begin with a trivial model, yielding poor compression of initial data, but as they learn more about the data, performance improves. Most popular types of compression used in practice now use adaptive coders.
Lossless compression methods may be categorized according to the type of data they are designed to compress. While, in principle, any general-purpose lossless compression algorithm ("general-purpose" meaning that they can accept any bitstring) can be used on any type of data, many are unable to achieve significant compression on data that are not of the form for which they were designed to compress. Many of the lossless compression techniques used for text also work reasonably well for indexed images.
Text and image.
Statistical modeling algorithms for text (or text-like binary data such as executables) include:
Multimedia.
These techniques take advantage of the specific characteristics of images such as the common phenomenon of contiguous 2-D areas of similar tones.
Every pixel but the first is replaced by the difference to its left neighbor. This leads to small values having a much higher probability than large values.
This is often also applied to sound files, and can compress files that contain mostly low frequencies and low volumes.
For images, this step can be repeated by taking the difference to the top pixel, and then in videos, the difference to the pixel in the next frame can be taken.
A hierarchical version of this technique takes neighboring pairs of data points, stores their difference and sum, and on a higher level with lower resolution continues with the sums. This is called discrete wavelet transform. JPEG2000 additionally uses data points from other pairs and multiplication factors to mix them into the difference. These factors must be integers, so that the result is an integer under all circumstances. So the values are increased, increasing file size, but hopefully the distribution of values is more peaked. 
The adaptive encoding uses the probabilities from the previous sample in sound encoding, from the left and upper pixel in image encoding, and additionally from the previous frame in video encoding. In the wavelet transformation, the probabilities are also passed through the hierarchy.
Historical legal issues.
Many of these methods are implemented in open-source and proprietary tools, particularly LZW and its variants. Some algorithms are patented in the United States and other countries and their legal usage requires licensing by the patent holder. Because of patents on certain kinds of LZW compression, and in particular licensing practices by patent holder Unisys that many developers considered abusive, some open source proponents encouraged people to avoid using the Graphics Interchange Format (GIF) for compressing still image files in favor of Portable Network Graphics (PNG), which combines the LZ77-based deflate algorithm with a selection of domain-specific prediction filters. However, the patents on LZW expired on June 20, 2003.
Many of the lossless compression techniques used for text also work reasonably well for indexed images, but there are other techniques that do not work for typical text that are useful for some images (particularly simple bitmaps), and other techniques that take advantage of the specific characteristics of images (such as the common phenomenon of contiguous 2-D areas of similar tones, and the fact that color images usually have a preponderance of a limited range of colors out of those representable in the color space).
As mentioned previously, lossless sound compression is a somewhat specialized area. Lossless sound compression algorithms can take advantage of the repeating patterns shown by the wave-like nature of the data – essentially using autoregressive models to predict the "next" value and encoding the (hopefully small) difference between the expected value and the actual data. If the difference between the predicted and the actual data (called the "error") tends to be small, then certain difference values (like 0, +1, −1 etc. on sample values) become very frequent, which can be exploited by encoding them in few output bits.
It is sometimes beneficial to compress only the differences between two versions of a file (or, in video compression, of successive images within a sequence). This is called delta encoding (from the Greek letter Δ, which in mathematics, denotes a difference), but the term is typically only used if both versions are meaningful outside compression and decompression. For example, while the process of compressing the error in the above-mentioned lossless audio compression scheme could be described as delta encoding from the approximated sound wave to the original sound wave, the approximated version of the sound wave is not meaningful in any other context.
Lossless compression methods.
By operation of the pigeonhole principle, no lossless compression algorithm can efficiently compress all possible data. For this reason, many different algorithms exist that are designed either with a specific type of input data in mind or with specific assumptions about what kinds of redundancy the uncompressed data are likely to contain.
Some of the most common lossless compression algorithms are listed below.
Video.
See this list of lossless video codecs.
Cryptography.
Cryptosystems often compress data (the "plaintext") "before" encryption for added security. When properly implemented, compression greatly increases the unicity distance by removing patterns that might facilitate cryptanalysis. However, many ordinary lossless compression algorithms produce headers, wrappers, tables, or other predictable output that might instead make cryptanalysis easier. Thus, cryptosystems must utilize compression algorithms whose output does not contain these predictable patterns.
Genetics.
Genetics compression algorithms (not to be confused with genetic algorithms) are the latest generation of lossless algorithms that compress data (typically sequences of nucleotides) using both conventional compression algorithms and specific algorithms adapted to genetic data. In 2012, a team of scientists from Johns Hopkins University published the first genetic compression algorithm that does not rely on external genetic databases for compression. HAPZIPPER was tailored for HapMap data and achieves over 20-fold compression (95% reduction in file size), providing 2- to 4-fold better compression and in much faster time than the leading general-purpose compression utilities.
Executables.
Self-extracting executables contain a compressed application and a decompressor. When executed, the decompressor transparently decompresses and runs the original application. This is especially often used in demo coding, where competitions are held for demos with strict size limits, as small as 1k.
This type of compression is not strictly limited to binary executables, but can also be applied to scripts, such as JavaScript.
Lossless compression benchmarks.
Lossless compression algorithms and their implementations are routinely tested in head-to-head benchmarks. There are a number of better-known compression benchmarks. Some benchmarks cover only the data compression ratio, so winners in these benchmarks may be unsuitable for everyday use due to the slow speed of the top performers. Another drawback of some benchmarks is that their data files are known, so some program writers may optimize their programs for best performance on a particular data set. The winners on these benchmarks often come from the class of context-mixing compression software.
The benchmarks listed in the 5th edition of the "Handbook of Data Compression" (Springer, 2009) are:
Matt Mahoney, in his February 2010 edition of the free booklet "Data Compression Explained", additionally lists the following:
Compression Ratings publishes a chart summary of the "frontier" in compression ratio and time.
The Compression Analysis Tool is a Windows application that enables end users to benchmark the performance characteristics of streaming implementations of LZF4, DEFLATE, ZLIB, GZIP, BZIP2 and LZMA using their own data. It produces measurements and charts with which users can compare the compression speed, decompression speed and compression ratio of the different compression methods and to examine how the compression level, buffer size and flushing operations affect the results.
The Squash Compression Benchmark uses the Squash library to compare more than 25 compression libraries in many different configurations using numerous different datasets on several different machines, and provides a web interface to help explore the results. There are currently over 50,000 results to compare.
Limitations.
Lossless data compression algorithms cannot guarantee compression for all input data sets. In other words, for any lossless data compression algorithm, there will be an input data set that does not get smaller when processed by the algorithm, and for any lossless data compression algorithm that makes at least one file smaller, there will be at least one file that it makes larger. This is easily proven with elementary mathematics using a counting argument, as follows:
Any lossless compression algorithm that makes some files shorter must necessarily make some files longer, but it is not necessary that those files become "very much" longer. Most practical compression algorithms provide an "escape" facility that can turn off the normal coding for files that would become longer by being encoded. In theory, only a single additional bit is required to tell the decoder that the normal coding has been turned off for the entire input; however, most encoding algorithms use at least one full byte (and typically more than one) for this purpose. For example, DEFLATE compressed files never need to grow by more than 5 bytes per 65,535 bytes of input.
In fact, if we consider files of length N, if all files were equally probable, then for any lossless compression that reduces the size of some file, the expected length of a compressed file (averaged over all possible files of length N) must necessarily be "greater" than N. So if we know nothing about the properties of the data we are compressing, we might as well not compress it at all. A lossless compression algorithm is useful only when we are more likely to compress certain types of files than others; then the algorithm could be designed to compress those types of data better.
Thus, the main lesson from the argument is not that one risks big losses, but merely that one cannot always win. To choose an algorithm always means implicitly to select a "subset" of all files that will become usefully shorter. This is the theoretical reason why we need to have different compression algorithms for different kinds of files: there cannot be any algorithm that is good for all kinds of data.
The "trick" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger. Algorithms are generally quite specifically tuned to a particular type of file: for example, lossless audio compression programs do not work well on text files, and vice versa.
In particular, files of random data cannot be consistently compressed by any conceivable lossless data compression algorithm: indeed, this result is used to "define" the concept of randomness in algorithmic complexity theory.
It's provably impossible to create an algorithm that can losslessly compress any data. While there have been many claims through the years of companies achieving "perfect compression" where an arbitrary number "N" of random bits can always be compressed to "N" − 1 bits, these kinds of claims can be safely discarded without even looking at any further details regarding the purported compression scheme. Such an algorithm contradicts fundamental laws of mathematics because, if it existed, it could be applied repeatedly to losslessly reduce any file to length 0. Allegedly "perfect" compression algorithms are often derisively referred to as "magic" compression algorithms for this reason.
On the other hand, it has also been proven that there is no algorithm to determine whether a file is incompressible in the sense of Kolmogorov complexity. Hence it's possible that any particular file, even if it appears random, may be significantly compressed, even including the size of the decompressor. An example is the digits of the mathematical constant "pi", which appear random but can be generated by a very small program. However, even though it cannot be determined whether a particular file is incompressible, a simple theorem about incompressible strings shows that over 99% of files of any given length cannot be compressed by more than one byte (including the size of the decompressor).
Mathematical background.
Abstractly, a compression algorithm can be viewed as a function on sequences (normally of octets). Compression is successful if the resulting sequence is shorter than the original sequence (and the instructions for the decompression map). For a compression algorithm to be lossless, the compression map must form a bijection between "plain" and "compressed" bit sequences.
The pigeonhole principle prohibits a bijection between the collection of sequences of length "N" and any subset of the collection of sequences of length "N"−1. Therefore it is not possible to produce an algorithm that reduces the size of every possible input sequence.
Psychological background.
Most everyday files are relatively 'sparse' in an information entropy sense, and thus, most lossless algorithms a layperson is likely to apply on regular files compress them relatively well. This may, through misapplication of intuition, lead some individuals to conclude that a well-designed compression algorithm can compress "any" input, thus, constituting a "magic compression algorithm".
Points of application in real compression theory.
Real compression algorithm designers accept that streams of high information entropy cannot be compressed, and accordingly, include facilities for detecting and handling this condition. An obvious way of detection is applying a raw compression algorithm and testing if its output is smaller than its input. Sometimes, detection is made by heuristics; for example, a compression application may consider files whose names end in ".zip", ".arj" or ".lha" uncompressible without any more sophisticated detection. A common way of handling this situation is quoting input, or uncompressible parts of the input in the output, minimising the compression overhead. For example, the zip data format specifies the 'compression method' of 'Stored' for input files that have been copied into the archive verbatim.
The Million Random Number Challenge.
Mark Nelson, in response to claims of magic compression algorithms appearing in comp.compression, has constructed a 415,241 byte binary file of highly entropic content, and issued a public challenge of $100 to anyone to write a program that, together with its input, would be smaller than his provided binary data yet be able to reconstitute ("decompress") it without error.
The FAQ for the comp.compression newsgroup contains a challenge by Mike Goldman offering $5,000 for a program that can compress random data. Patrick Craig took up the challenge, but rather than compressing the data, he split it up into separate files all of which ended in the number "5", which was not stored as part of the file. Omitting this character allowed the resulting files (plus, in accordance with the rules, the size of the program that reassembled them) to be smaller than the original file. However, no actual compression took place, and the information stored in the names of the files was necessary to reassemble them in the correct order in the original file, and this information was not taken into account in the file size comparison. The files themselves are thus not sufficient to reconstitute the original file; the file names are also necessary. Patrick Craig agreed that no meaningful compression had taken place, but argued that the wording of the challenge did not actually require this. A full history of the event, including discussion on whether or not the challenge was technically met, is on Patrick Craig's web site.

</doc>
<doc id="18210" url="https://en.wikipedia.org/wiki?curid=18210" title="Larry Niven">
Larry Niven

Laurence van Cott Niven (; born April 30, 1938) — known as Larry Niven — is an American science fiction writer. His best-known work is "Ringworld" (1970), which received Hugo, Locus, Ditmar, and Nebula awards. The Science Fiction Writers of America named him the 2015 recipient of the Damon Knight Memorial Grand Master Award. His work is primarily hard science fiction, using big science concepts and theoretical physics. It also often includes elements of detective fiction and adventure stories. His fantasy includes the series "The Magic Goes Away", rational fantasy dealing with magic as a non-renewable resource.
Biography.
Niven was born in Los Angeles. He briefly attended the California Institute of Technology and graduated with a Bachelor of Arts in mathematics (with a minor in psychology) from Washburn University, Topeka, Kansas, in 1962. He did a year of graduate work in mathematics at the University of California at Los Angeles. On September 6, 1969, he married Marilyn Joyce "Fuzzy Pink" Wisowaty, a science fiction and Regency literature fan. He is an agnostic.
Work.
Niven is the author of numerous science fiction short stories and novels, beginning with his 1964 story "The Coldest Place". In this story, the coldest place concerned is the dark side of Mercury, which at the time the story was written was thought to be tidally locked with the Sun (it was found to rotate in a 2:3 resonance after Niven received payment for the story, but before it was published).
In addition to the Nebula award in 1970 and the Hugo and Locus awards in 1971 for "Ringworld", Niven won the Hugo Award for Best Short Story for "Neutron Star" in 1967. He won the same award in 1972, for "Inconstant Moon", and in 1975 for "The Hole Man". In 1976, he won the Hugo Award for Best Novelette for "The Borderland of Sol".
Niven has written scripts for three science fiction television series: the original "Land of the Lost" series; "", for which he adapted his early story "The Soft Weapon"; and "The Outer Limits", for which he adapted his story "Inconstant Moon" into an episode of the same name.
Niven has also written for the DC Comics character Green Lantern including in his stories hard science fiction concepts such as universal entropy and the redshift effect.
He has included limited psi gifts (mind over matter) in some characters in his stories; like Gil Hamilton's psychic arm which can only reach as far as a corporeal arm could, though it can, for example, reach through solid materials and manipulate objects on the other side, or Matt Keller's ability to make people not see him in "A Gift From Earth".
Many of Niven's stories—sometimes called the Tales of Known Space— take place in his Known Space universe, in which humanity shares the several habitable star systems nearest to the Sun with over a dozen alien species, including the aggressive feline Kzinti and the very intelligent but cowardly Pierson's Puppeteers, which are frequently central characters. The "Ringworld" series is part of the Tales of Known Space, and Niven has shared the setting with other writers at least since a 1988 anthology, "The Man-Kzin Wars" (Baen Books, jointly edited with Jerry Pournelle and Dean Ing).
Niven has also written a logical fantasy series "The Magic Goes Away", which utilizes an exhaustible resource called "mana" to power a rule-based "technological" magic. "The Draco Tavern" series of short stories take place in a more light-hearted science fiction universe, and are told from the point of view of the proprietor of an omni-species bar. The whimsical "Svetz" series consists of a collection of short stories, "The Flight of the Horse", and a novel, "Rainbow Mars", which involve a nominal time machine sent back to retrieve long-extinct animals, but which travels, in fact, into alternative realities and brings back mythical creatures such as a Roc and a Unicorn. Much of his writing since the 1970s has been in collaboration, particularly with Jerry Pournelle and Steven Barnes, but also Brenda Cooper and Edward M. Lerner.
Influence.
Niven's most famous contribution to the SF genre comes from his novel "Ringworld", in which he envisions a Ringworld: a band of material, roughly a million miles wide, of approximately the same diameter as Earth's orbit, rotating around a star. The idea's genesis came from Niven's attempts to imagine a more efficient version of a Dyson Sphere, which could produce the effect of surface gravity through rotation. Given that spinning a Dyson Sphere would result in the atmosphere pooling around the equator, the Ringworld removes all the extraneous parts of the structure, leaving a spinning band landscaped on the sun-facing side, with the atmosphere and inhabitants kept in place through centrifugal force and 1000 mile high perimeter walls (rim walls). After publication of "Ringworld", Dan Alderson and Ctien, two fannish friends of Niven, analyzed the structure and told Niven that the Ringworld was dynamically unstable such that if the center of rotation drifts away from the central sun, gravitational forces will not 're-center' it, thus allowing the ring to eventually contact the sun and be destroyed. Niven used this as a core plot element in the sequel novel, "The Ringworld Engineers".
This idea proved influential, serving as an alternative to a full Dyson Sphere that required fewer assumptions (such as artificial gravity) and allowed a day/night cycle to be introduced (through the use of a smaller ring of "shadow squares", rotating between the ring and its sun). This was further developed by Iain M. Banks in his Culture series, which features about 1/100th ringworld–size megastructures called Orbitals that orbit a star rather than encircling it entirely (actual "Rings" and Dyson "Spheres" are also mentioned but are much rarer). Alastair Reynolds also uses ringworlds in his 2008 novel "House of Suns". The Ringworld-like namesake of the "Halo" video game series is the eponymous Halo megastructure/superweapon.
The original release of "" paid homage to Larry Niven on a card called "Nevinyrral's Disk", with Nevinyrral being "Larry Niven" spelled backwards. Subsequent sets have featured no new cards featuring Nevinyrral, although the character is sporadically quoted on the flavor text of various cards. "Netrunner" paid a similar homage to Larry Niven with the card "Nevinyrral".
Policy involvement.
According to author Michael Moorcock, in 1967 Niven was among those Science Fiction Writers of America members who voiced opposition to the Vietnam War. However, in 1968 Niven's name appeared in a pro-war ad in "Galaxy Science Fiction" magazine.
Niven was an adviser to Ronald Reagan on the creation of the Strategic Defense Initiative antimissile policy, as part of the Citizens' Advisory Council on National Space Policy – as covered in the BBC documentary "Pandora's Box" by Adam Curtis. The council also convinced Vice President Dan Quayle to support the Single-stage-to-orbit (SSTO) concept for a reusable space ship that led to the building of the DC-X.
In 2007, Niven, in conjunction with a group of science fiction writers known as SIGMA, led by Pournelle, began advising the U.S. Department of Homeland Security as to future trends affecting terror policy and other topics.
Other works.
One of Niven's best known humorous works is "Man of Steel, Woman of Kleenex", in which he uses real-world physics to underline the difficulties of Superman and a human woman (Lois Lane or Lana Lang) mating.
Niven appeared in the 1980 science documentary film "Target... Earth?"
Niven's Laws.
Larry Niven is also known in science fiction fandom for "Niven's Law": "There is no cause so right that one cannot find a fool following it". Over the course of his career Niven has added to this first law a list of Niven's Laws which he describes as "how the Universe works" as far as he can tell.

</doc>
<doc id="18212" url="https://en.wikipedia.org/wiki?curid=18212" title="Linux distribution">
Linux distribution

A Linux distribution (often called a distro for short) is an operating system made from a software collection, which is based upon the Linux kernel and, often, a package management system. Linux users usually obtain their operating system by downloading one of the Linux distributions, which are available for a wide variety of systems ranging from embedded devices (for example, OpenWrt) and personal computers to powerful supercomputers (for example, Rocks Cluster Distribution).
A typical Linux distribution comprises a Linux kernel, GNU tools and libraries, additional software, documentation, a window system (the most common being the X Window System), a window manager, and a desktop environment. Most of the included software is free and open-source software made available both as compiled binaries and in source code form, allowing modifications to the original software. Usually, Linux distributions optionally include some proprietary software that may not be available in source code form, such as binary blobs required for some device drivers. Almost all Linux distributions are Unix-like; the most notable exception is Android, which does not include a command-line interface and programs made for typical Linux distributions.
A Linux distribution may also be described as a particular assortment of application and utility software (various GNU tools and libraries, for example), packaged together with the Linux kernel in such a way that its capabilities meet the needs of many users. The software is usually adapted to the distribution and then packaged into software packages by the distribution's maintainers. The software packages are available online in so-called repositories, which are storage locations usually distributed around the world. Beside glue components, such as the distribution installers (for example, Debian-Installer and Anaconda) or the package management systems, there are only very few packages that are originally written from the ground up by the maintainers of a Linux distribution.
Almost six hundred Linux distributions exist, with close to five hundred out of those in active development, constantly being revised and improved. Because of the huge availability of software, distributions have taken a wide variety of forms, including those suitable for use on desktops, servers, laptops, netbooks, mobile phones and tablets, as well as minimal environments typically for use in embedded systems. There are commercially backed distributions, such as Fedora (Red Hat), openSUSE (SUSE) and Ubuntu (Canonical Ltd.), and entirely community-driven distributions, such as Debian, Slackware, Gentoo and Arch Linux. Most distributions come ready to use and pre-compiled for a specific instruction set, while some distributions (such as Gentoo) are distributed mostly in source code form and compiled locally during installation.
History.
Linus Torvalds developed the Linux kernel and distributed its first version, 0.01, in 1991. Linux was initially distributed as source code only, and later as a pair of downloadable floppy disk images one bootable and containing the Linux kernel itself, and the other with a set of GNU utilities and tools for setting up a file system. Since the installation procedure was complicated, especially in the face of growing amounts of available software, distributions sprang up to simplify this.
Early distributions included the following:
The two oldest and still active distribution projects started in 1993. The SLS distribution was not well maintained, so in July 1993 a new distribution, called Slackware and based on SLS, was released by Patrick Volkerding. Also dissatisfied with SLS, Ian Murdock set to create a free distribution by founding Debian, which had its first release in December 1993.
Users were attracted to Linux distributions as alternatives to the DOS and Microsoft Windows operating systems on IBM PC compatible computers, Mac OS on the Apple Macintosh, and proprietary versions of Unix. Most early adopters were familiar with Unix from work or school. They embraced Linux distributions for their low (if any) cost, and availability of the source code for most or all of the software included.
Originally, the distributions were simply a convenience, but later they became the usual choice even for Unix or Linux experts.
To date, Linux has proven more popular in the server market, primarily for Web and database servers (for example, in the LAMP stack), and in embedded devices market than in the desktop market.
Components.
Many Linux distributions provide an installation system akin to that provided with other modern operating systems. On the other hand, some distributions, including Gentoo Linux, provide only the binaries of a basic kernel, compilation tools, and an installer; the installer compiles all the requested software for the specific architecture of the user's computer, using these tools and the provided source code.
Package management.
Distributions are normally segmented into "packages". Each package contains a specific application or service. Examples of packages are a library for handling the PNG image format, a collection of fonts or a web browser.
The package is typically provided as compiled code, with installation and removal of packages handled by a package management system (PMS) rather than a simple file archiver. Each package intended for such a PMS contains meta-information such as a package description, version, and "dependencies". The package management system can evaluate this meta-information to allow package searches, to perform an automatic upgrade to a newer version, to check that all dependencies of a package are fulfilled, and/or to fulfill them automatically.
Although Linux distributions typically contain much more software than proprietary operating systems, it is normal for local administrators to also install software not included in the distribution. An example would be a newer version of a software application than that supplied with a distribution, or an alternative to that chosen by the distribution (for example, KDE Plasma Workspaces rather than GNOME or vice versa for the user interface layer). If the additional software is distributed in source-only form, this approach requires local compilation. However, if additional software is locally added, the "state" of the local system may fall out of synchronization with the state of the package manager's database. If so, the local administrator will be required to take additional measures to ensure the entire system is kept up to date. The package manager may no longer be able to do so automatically.
Most distributions install packages, including the kernel and other core operating system components, in a predetermined configuration. Few now require or even permit configuration adjustments at first install time. This makes installation less daunting, particularly for new users, but is not always acceptable. For specific requirements, much software must be carefully configured to be useful, to work correctly with other software, or to be secure, and local administrators are often obliged to spend time reviewing and reconfiguring assorted software.
Some distributions go to considerable lengths to specifically adjust and customize most or all of the software included in the distribution. Not all do so. Some distributions provide configuration tools to assist in this process.
By replacing "everything" provided in a distribution, an administrator may reach a "distribution-less" state: everything was retrieved, compiled, configured, and installed locally. It is possible to build such a system from scratch, avoiding a distribution altogether. One needs a way to generate the first binaries until the system is "self-hosting". This can be done via compilation on another system capable of building binaries for the intended target (possibly by cross-compilation). For example, see Linux From Scratch.
Types and trends.
In broad terms, Linux distributions may be:
The diversity of Linux distributions is due to technical, organizational, and philosophical variation among vendors and users. The permissive licensing of free software means that any user with sufficient knowledge and interest can customize an existing distribution or design one to suit his or her own needs.
Installation-free distributions (live CD/USB).
A "live" distribution is a Linux distribution that can be booted from removable storage media such as optical discs or USB flash drives, instead of being installed on and booted from a hard disk drive. The portability of installation-free distributions makes them advantageous for applications such as demonstrations, borrowing someone else's computer, rescue operations, or as installation media for a standard distribution.
When the operating system is booted from a read-only medium such as a CD or DVD, any user data that needs to be retained between sessions cannot be stored on the boot device but must be written to another storage device, such as a USB flash drive or a hard disk drive.
Many Linux distributions provide a "live" form in addition to their conventional form, which is a network-based or removable-media image intended to be used only for installation; such distributions include SUSE, Ubuntu, Linux Mint, MEPIS and Fedora. Some distributions, including Knoppix, Puppy Linux, Devil-Linux, SuperGamer, SliTaz GNU/Linux and , are designed primarily for live use. Additionally, some minimal distributions can be run directly from as little space as one floppy disk without the need to change the contents of the system's hard disk drive.
Examples.
The website DistroWatch lists many Linux distributions, and displays some of the ones that have the most web traffic on the site. The WikiMediaFoundation released an analysis of the browser User Agents of visitors to WMF websites until 2015, which includes details of the most popular Operating System identifiers, including some Linux distributions. Many of the popular distributions are listed below.
Niche distributions.
Other distributions target specific niches, such as:
Android.
Whether Google's Android counts as a Linux distribution is a matter of definition. It uses the Linux kernel, so the Linux Foundation and Chris DiBona, Google's open source chief, agree that Android is a Linux distribution; others, such as Google engineer Patrick Brady, disagree by noting the lack of support for many GNU tools in Android, including the glibc.
Interdistribution issues.
The Free Standards Group is an organization formed by major software and hardware vendors that aims to improve interoperability between different distributions. Among their proposed standards are the Linux Standard Base, which defines a common ABI and packaging system for Linux, and the Filesystem Hierarchy Standard which recommends a standard filenaming chart, notably the basic directory names found on the root of the tree of any Linux filesystem. Those standards, however, see limited use, even among the distributions developed by members of the organization.
The diversity of Linux distributions means that not all software runs on all distributions, depending on what libraries and other system attributes are required. Packaged software and software repositories are usually specific to a particular distribution, though cross-installation is sometimes possible on closely related distributions.
Tools for choosing a distribution.
Virtual machines such as VirtualBox and VMware Workstation virtualize hardware allowing users to test live media on a virtual machine. Some websites like DistroWatch offer lists of popular distributions, and link to screenshots of operating systems as a way to get a first impression of various distributions.
There are tools available to help people select an appropriate distribution, such as several versions of the Linux Distribution Chooser, and the universal package search tool "whohas". There are easy ways to try out several Linux distributions before deciding on one: Multi Distro is a Live CD that contains nine space-saving distributions.
Installation.
There are many ways to install a Linux distribution. The most common method of installing Linux is by booting from an optical disk that contains the installation program and installable software. Such a disk can be burned from a downloaded ISO image, purchased alone for a low price, provided as a cover disk with a magazine, shipped for free by request, or obtained as part of a box set that may also include manuals and additional commercial software.
Early Linux distributions were installed using sets of floppies but this has been abandoned by all major distributions. Nowadays most distributions offer CD and DVD sets with the vital packages on the first disc and less important packages on later ones. They usually also allow installation over a network after booting from either a set of floppies or a CD with only a small amount of data on it.
New users tend to begin by partitioning a hard drive in order to keep their previously installed operating system. The Linux distribution can then be installed on its own separate partition without affecting previously saved data.
In a Live CD setup, the computer boots the entire operating system from CD without first installing it on the computer's hard disk. Some distributions have a Live CD "installer", where the computer boots the operating system from the disk, and then proceeds to install it onto the computer's hard disk, providing a seamless transition from the OS running from the CD to the OS running from the hard disk.
Both servers and personal computers that come with Linux already installed are available from vendors including Hewlett-Packard, Dell and System76.
On embedded devices, Linux is typically held in the device's firmware and may or may not be consumer-accessible. 
Anaconda, one of the more popular installers, is used by Red Hat Enterprise Linux, Fedora and other distributions to simplify the installation process. Debian, Ubuntu and many others use Debian-Installer.
Installation via an existing operating system.
Some distributions let the user install Linux on top of their current system, such as WinLinux or coLinux. Linux is installed to the Windows hard disk partition, and can be started from inside Windows itself
Virtual machines (such as VirtualBox or VMware) also make it possible for Linux to be run inside another OS. The VM software simulates a separate computer onto which the Linux system is installed. After installation, the virtual machine can be booted as if it were an independent computer.
Various tools are also available to perform full dual-boot installations from existing platforms without a CD, most notably:
Proprietary software.
Some specific proprietary software products are not available in any form for Linux. As of September 2015, the Steam gaming service has 1,500 games available on Linux, compared to 2,323 games for Mac and 6,500 Windows games. Emulation and API-translation projects like Wine and CrossOver make it possible to run non-Linux-based software on Linux systems, either by emulating a proprietary operating system or by translating proprietary API calls (e.g., calls to Microsoft's Win32 or DirectX APIs) into native Linux API calls. A virtual machine can also be used to run a proprietary OS (like Microsoft Windows) on top of Linux.
OEM contracts.
Computer hardware is usually sold with an operating system other than Linux already installed by the original equipment manufacturer (OEM). In the case of IBM PC compatibles the OS is usually Microsoft Windows; in the case of Apple Macintosh computers it has always been a version of Apple's OS, currently OS X; Sun Microsystems sold SPARC hardware with the Solaris installed; video game consoles such as the Xbox, PlayStation, and Wii each have their own proprietary OS. This limits Linux's market share: consumers are unaware that an alternative exists, they must make a conscious effort to use a different operating system, and they must either perform the actual installation themselves, or depend on support from a friend, relative, or computer professional.
However, it is possible to buy hardware with Linux already installed. Lenovo, Hewlett-Packard, Dell, Affordy, and System76 all sell general-purpose Linux laptops, and custom-order PC manufacturers will also build Linux systems (but possibly with the Windows key on the keyboard). Fixstars Solutions (formerly Terra Soft) sells Macintosh computers and PlayStation 3 consoles with Yellow Dog Linux installed.
It is more common to find embedded devices sold with Linux as the default manufacturer-supported OS, including the Linksys NSLU2 NAS device, TiVo's line of personal video recorders, and Linux-based cellphones (including Android smartphones), PDAs, and portable music players. 
The end user license agreement (EULA) for Apple gives the consumer the opportunity to reject the license and obtain a refund. The current Microsoft Windows license lets the manufacturer determine the refund policy. With previous versions of Windows, it was possible to obtain a refund if the manufacturer failed to provide the refund by litigation in the small claims courts. On 15 February 1999, a group of Linux users in Orange County, California held a "Windows Refund Day" protest in an attempt to pressure Microsoft into issuing them refunds. In France, the Linuxfrench and AFUL (French speaking Libre Software Users' Association) organizations along with free software activist Roberto Di Cosmo started a "Windows Detax" movement, which led to a 2006 petition against "racketiciels" (translation: Racketware) with 39,415 signatories and the DGCCRF branch of the French government filing several complaints against bundled software. On March 24, 2014, a new international petition was launched by AFUL on the Avaaz platform, translated into several languages and supported by many organizations around the world.

</doc>
<doc id="18213" url="https://en.wikipedia.org/wiki?curid=18213" title="Los Angeles Dodgers">
Los Angeles Dodgers

The Los Angeles Dodgers are a professional baseball team in Los Angeles, California, who are members of the National League West division of Major League Baseball (MLB). Established in 1883 in Brooklyn, New York, the team moved to Los Angeles before the 1958 season. They played for four seasons at the Los Angeles Memorial Coliseum before moving to their current home of Dodger Stadium.
The Dodgers as a franchise have won six World Series titles and 21 National League pennants. 11 NL MVP award winners have played for the Dodgers, winning a total of 13 MVP Awards, Eight Cy Young Award winners have pitched for the Dodgers, winning a total of twelve Cy Young Awards. The team has also produced 16 Rookie of the Year Award winners, including four consecutive from 1979 to 1982 and five consecutive from 1992 to 1996.
History.
In the 20th century, the team, then known as the Robins, won league pennants in 1916 and 1920, losing the World Series both times, first to Boston and then Cleveland. In the 1930s, the team changed its name to the Dodgers, named after the Brooklyn pedestrians who dodged the streetcars in the city. In 1941, the Dodgers captured their third National League pennant, only to lose again to the New York Yankees. This marked the onset of the Dodgers–Yankees rivalry, as the Dodgers would face them in their next six World Series appearances. Led by Jackie Robinson, the first black Major League Baseball player of the modern era; and three-time National League Most Valuable Player Roy Campanella, also signed out of the Negro Leagues, the Dodgers captured their first World Series title in 1955 by defeating the Yankees for the first time, a story notably described in the 1972 book "The Boys of Summer".
Following the 1957 season the team left Brooklyn. In just their second season in Los Angeles, the Dodgers won their second World Series title, beating the Chicago White Sox in six games in 1959. Spearheaded by the dominant pitching style of Sandy Koufax and Don Drysdale, the Dodgers captured three pennants in the 1960s and won two more World Series titles, sweeping the Yankees in four games in 1963, and edging the Minnesota Twins in seven in 1965. The 1963 sweep was their second victory against the Yankees, and their first against them as a Los Angeles team. The Dodgers won four more pennants in 1966, 1974, 1977 and 1978, but lost in each World Series appearance. They went on to win the World Series again in 1981, thanks to pitching sensation Fernando Valenzuela. The early 1980s were affectionately dubbed "Fernandomania." In 1988, another pitching hero, Orel Hershiser, again led them to a World Series victory, aided by one of the most memorable home runs of all time, by their injured star outfielder Kirk Gibson coming off the bench to pinch hit with two outs in the bottom of the ninth inning of game 1, in his only appearance of the series.
The Dodgers share a fierce rivalry with the San Francisco Giants, the oldest rivalry in baseball, dating back to when the two franchises played in New York City. Both teams moved west for the 1958 season. The Brooklyn Dodgers and Los Angeles Dodgers have collectively appeared in the World Series 18 times, while the New York Giants and San Francisco Giants have collectively appeared 20 times and have been invited 21 times. The Giants have won two more World Series (8); the Dodgers have won 21 National League pennants, while the Giants hold the record with 23. Although the two franchises have enjoyed near equal success, the city rivalries are rather lopsided and in both cases, a team's championships have predated to the other's first one in that particular location. When the two teams were based in New York, the Giants won five World Series championships, and the Dodgers one. After the move to California, the Dodgers have won five in Los Angeles, the Giants have won three in San Francisco.
Team history.
Brooklyn Dodgers.
The Dodgers were originally founded in 1883 as the Brooklyn Atlantics, taking the name of a defunct team that had played in Brooklyn before them. The team joined the American Association in 1884 and won the AA championship in 1889 before joining the National League in 1890. They promptly won the NL Championship their first year in the League. The team was known alternatively as the Bridegrooms, Grooms, Superbas, Robins, and Trolley Dodgers before officially becoming the Dodgers in the 1930s.
In Brooklyn, the Dodgers won the NL pennant several times (1890, 1899, 1900, 1916, 1920, 1941, 1947, 1949, 1952, 1953, 1955, 1956) and the World Series in 1955. After moving to Los Angeles, the team won National League pennants in 1959, 1963, 1965, 1966, 1974, 1977, 1978, 1981, and 1988, with World Series championships in 1959, 1963, 1965, 1981, 1988. In all, the Dodgers have appeared in 18 World Series: 9 in Brooklyn and 9 in Los Angeles.
Jackie Robinson.
For most of the first half of the 20th century, no Major League Baseball team employed an African American player. Jackie Robinson became the first African American to play for a Major League Baseball team when he played his first major league game on April 15, 1947, as a member of the Brooklyn Dodgers. This was mainly due to general manager Branch Rickey's efforts. The deeply religious Rickey's motivation appears to have been primarily moral, although business considerations were also a factor. Rickey was a member of The Methodist Church, the antecedent denomination to The United Methodist Church of today, which was a strong advocate for social justice and active later in the American Civil Rights Movement.
This event was the harbinger of the integration of professional sports in the United States, the concomitant demise of the Negro Leagues, and is regarded as a key moment in the history of the American Civil Rights movement. Robinson was an exceptional player, a speedy runner who sparked the team with his intensity. He was the inaugural recipient of the Rookie of the Year award, which is now named the Jackie Robinson Award in his honor. The Dodgers' willingness to integrate, when most other teams refused to, was a key factor in their 1947–1956 success. They won six pennants in those 10 years with the help of Robinson, three-time MVP Roy Campanella, Cy Young Award winner Don Newcombe, Jim Gilliam and Joe Black. Robinson would eventually go on to become the first African-American elected to the Baseball Hall of Fame in 1962.
Move to Los Angeles.
Real estate businessman Walter O'Malley had acquired majority ownership of the Dodgers in 1950, when he bought the shares of his co-owners, Branch Rickey and the estate of James L. Smith. Before long he was working to buy new land in Brooklyn to build a more accessible and better arrayed ballpark than Ebbets Field. Beloved as it was, Ebbets Field was no longer well-served by its aging infrastructure and the Dodgers could no longer sell out the park even in the heat of a pennant race, despite largely dominating the National League from 1946 to 1957.
O'Malley wanted to build a new, state of the art stadium in Brooklyn. But City Planner Robert Moses and New York politicians refused to grant him the eminent domain authority required to build pursuant to O'Malley's plans. To put pressure on the city, during the 1955 season, O'Malley announced that the team would play seven regular season games and one exhibition game at Jersey City's Roosevelt Stadium in 1956. Moses and the City considered this an empty threat, and did not believe O'Malley would go through with moving the team from New York City.
After teams began to travel to and from games by air instead of train, it became possible to include locations in the far west. Los Angeles officials attended the 1956 World Series looking to the Washington Senators to move to the West Coast. When O'Malley heard that LA was looking for a club, he sent word to the Los Angeles officials that he was interested in talking. LA offered him what New York would not: a chance to buy land suitable for building a ballpark, and own that ballpark, giving him complete control over all revenue streams. When the news came out, NYC Mayor Robert F. Wagner, Jr. and Moses made an offer to build a ballpark on the World's Fair Grounds in Queens that would be shared by the Giants and Dodgers. However, O'Malley was interested in his park only under his conditions, and the plans for a new stadium in Brooklyn seemed like a pipe dream. O'Malley decided to move the Dodgers to California, convincing Giants owner Horace Stoneham to move to San Francisco instead of Minneapolis to keep another team on the West Coast to ease approval of the moves. There was no turning back: the Dodgers were heading for Hollywood.
The Dodgers played their final game at Ebbets Field on September 24, 1957, which the Dodgers won 2–0 over the Pittsburgh Pirates.
New York would remain a one-team town with the New York Yankees until 1962, when Joan Payson founded the New York Mets and brought National League baseball back to the city. The blue background used by the Dodgers, would be adopted by the Mets, honoring their New York NL forebears with a blend of Dodgers blue and Giants orange.
Los Angeles Dodgers.
The Dodgers were the first Major League Baseball team to ever play in Los Angeles. On April 18, 1958, the Dodgers played their first LA game, defeating the former New York and now new San Francisco Giants, 6–5, before 78,672 fans at the Los Angeles Memorial Coliseum. Catcher Roy Campanella, left partially paralyzed in an off-season accident, was never able to play in Los Angeles.
Construction on Dodger Stadium was completed in time for Opening Day 1962. With its clean, simple lines and its picturesque setting amid hills and palm trees, the ballpark quickly became an icon of the Dodgers and their new California lifestyle. O'Malley was determined that there would not be a bad seat in the house, achieving this by cantilevered grandstands that have since been widely imitated. More importantly for the team, the stadium's spacious dimensions, along with other factors, gave defense an advantage over offense and the Dodgers moved to take advantage of this by assembling a team that would excel with its pitching.
Since moving to Los Angeles, the Dodgers have won nine more National League Championships and five World Series rings.
Other historical notes.
The team's nickname.
The Dodgers' official history tells us that, "he term "Trolley Dodgers" was attached to the Brooklyn ballclub due to the complex maze of trolley cars that weaved its way through the borough of Brooklyn."
In 1892, the city of Brooklyn (Brooklyn was an independent city until annexed by New York City in 1898) began replacing its slow-moving, horse-drawn trolley lines with the faster, more powerful electric trolley lines. Within less than three years, by the end of 1895, electric trolley accidents in Brooklyn had resulted in more than 130 deaths and maimed well over 500 people. Brooklyn's high-profile, the significant number of widely-reported accidents, and a trolley strike in early 1895, combined to create a strong association in the public's mind between Brooklyn and trolley dodging.
Sportswriters started using the name "trolley dodgers" to refer to the Brooklyn team early in the 1895 season. The name was shortened to, on occasion, the "Brooklyn Dodgers" as early as 1898.
Sportswriters in the early 20th century began referring to the Dodgers as the "Bums", in reference to the team's fans and possibly because of the "street character" nature of Jack Dawkins, the "Artful Dodger" in Charles Dickens' "Oliver Twist".
Other team names used by the franchise were the Atlantics, Grays, Grooms, Bridegrooms, Superbas and Robins. All of these nicknames were used by fans and sportswriters to describe the team, but not in any official capacity. The team's legal name was the Brooklyn Base Ball Club. However, the Trolley Dodger nickname was used throughout this period, simultaneously with these other nicknames, by fans and sportswriters of the day. The team did not use the name in any formal sense until 1932, when the word "Dodgers" appeared on team jerseys. The "conclusive shift" came in 1933, when both home and road jerseys for the team bore the name "Dodgers".
Examples of how the many popularized names of the team were used are available from newspaper articles before 1932. A New York Times article describing a game in 1916 starts out: "Jimmy Callahan, pilot of the Pirates, did his best to wreck the hopes the Dodgers have of gaining the National League pennant", but then goes on to comment: "the only thing that saved the Superbas from being toppled from first place was that the Phillies lost one of the two games played". What is interesting about the use of these two nicknames is that most baseball statistics sites and baseball historians generally now refer to the pennant-winning 1916 Brooklyn team as the Robins. A 1918 New York Times article uses the nickname in its title: "Buccaneers Take Last From Robins", but the subtitle of the article reads: "Subdue The Superbas By 11 To 4, Making Series An Even Break".
Another example of the use of the many nicknames is found on the program issued at Ebbets Field for the 1920 World Series which identifies the matchup in the series as "Dodgers vs. Indians" despite the fact that the Robins nickname had been in consistent use for around six years. The "Robins" nickname was derived from the name of their Hall of Fame manager, Wilbert Robinson, who led the team from 1914 to 1931.
Uniforms.
The Dodgers uniforms haven't changed at all for more than 70 years. The home jersey is white with "Dodgers" written in script across the chest in Dodger Blue. The road jersey is grey with "Los Angeles" written in script across the chest in Dodger Blue. The word "Dodgers" was first used on the front of the team's home jersey in 1933; the uniform was white with red pinstripes, and the stylized B on the left shoulder. The Dodgers also wore green outlined uniforms and green caps throughout the 1937 season but reverted to blue the following year.
The current design was created in 1939, and has remained the same ever since with only small cosmetic changes. Since 1952, the home uniform has had a red uniform number under the "Dodgers" script. The road jerseys also have a red uniform number under the script. The most obvious change is the removal of "Brooklyn" from the road jerseys and the replacement of the stylized "B" with the interlocking "LA" on the caps in 1958. In 1970, the Dodgers removed the city name from the road jerseys and had "Dodgers" on both the home and away uniforms. The city script returned to the road jerseys in 1999, and the tradition-rich Dodgers flirted with an alternate uniform for the first time since 1944 (when all-blue satin uniforms were introduced). These 1999 alternate jerseys had a royal blue top with the "Dodgers" script in white across the chest, and the red number on the front. These were worn with white pants and a new cap with silver brim, top button and Dodger logo. These alternates proved unpopular and the team abandoned them after only one season. In 2014, the Dodgers introduced an alternate road jersey: a grey version of the home jersey (w/the Dodgers script).
Asian players.
The Dodgers have been groundbreaking in their signing of players from Asia; mainly, Japan, South Korea, and Taiwan. Former owner Peter O'Malley began reaching out in 1980 by starting clinics in China and South Korea, building baseball fields in two Chinese cities, and in 1998 becoming the first major league team to open an office in Asia. The Dodgers were the second team to start a Japanese player in recent history, pitcher Hideo Nomo, the first team to start a South Korean player, pitcher Chan Ho Park, and the first Taiwanese player, Chin-Feng Chen. In addition, they were the first team to send out three Asian pitchers, from different Asian countries, in one game: Park, Hong-Chih Kuo of Taiwan, and Takashi Saito of Japan. In the 2008 season, the Dodgers had the most Asian players on its roster of any major league team with five. They included Japanese pitchers Takashi Saito and Hiroki Kuroda; South Korean pitcher Chan Ho Park; and Taiwanese pitcher Hong-Chih Kuo and infielder Chin-Lung Hu. In 2005, the Dodgers' Hee Seop Choi became the first Asian player to compete in the Home Run Derby. For the 2013 season, the Dodgers signed starting pitcher Hyun-Jin Ryu with a six-year, $36 million contract, after posting a bid of nearly $27 million to acquire him from the KBO's Hanhwa Eagles. For the 2016 season, the Dodgers signed starting pitcher Kenta Maeda with an eight-year, $25 million contract, after posting a bid of $20 million to acquire him from the NPB's Hiroshima Toyo Carp.
Rivalries.
The Dodgers' rivalry with the San Francisco Giants dates back to the 19th century, when the two teams were based in New York; the rivalry with the New York Yankees took place when the Dodgers were based in New York, but was revived with their East Coast/West Coast World Series battles in 1963, 1977, 1978, and 1981. The Dodgers also had a heated rivalry with the Cincinnati Reds during the 1970s, 1980s and early 1990s. The rivalry with the Los Angeles Angels of Anaheim and the San Diego Padres dates back to the Angels' and Padres' respective inaugural seasons (Angels in 1961, Padres in 1969). Regional proximity is behind the rivalries with both the Angels and the Padres.
San Francisco Giants.
The Dodgers–Giants rivalry is one of the longest-standing rivalries in American baseball.
The feud between the Dodgers and the San Francisco Giants began in the late 19th century when both clubs were based in New York City, with the Dodgers playing in Brooklyn and the Giants playing at the Polo Grounds in Manhattan. After the 1957 season, Dodgers owner Walter O'Malley moved the team to Los Angeles for financial and other reasons. Along the way, he managed to convince Giants owner Horace Stoneham—who was considering moving his team to Minnesota—to preserve the rivalry by bringing his team to California as well. New York baseball fans were stunned and heartbroken by the move. Given that the cities of Los Angeles and San Francisco have been bitter rivals in economic, cultural, and political arenas for over a century and a half, the new venue in California became fertile ground for its transplantation.
Each team's ability to endure for over a century while moving across an entire continent, as well as the rivalry's leap from a cross-city to a cross-state engagement, have led to the rivalry being considered one of the greatest in sports history.
Unlike many other historic baseball match-ups in which one team remains dominant for most of their history, the Dodgers–Giants rivalry has exhibited a persistent balance in the respective successes of the two teams. While the Giants have more wins in franchise history, and lead all NL teams with 23 National League pennants, the Dodgers are second, having won 21; the Giants have won eight World Series titles, while the Dodgers have won six. The 2010 World Series was the Giants' first championship since moving to California, while the Dodgers' last title came in the 1988 World Series.
Los Angeles Angels of Anaheim.
This rivalry refers to a series of games played with the Los Angeles Angels of Anaheim. The series takes its name from the massive freeway system in the greater Los Angeles metropolitan area, the home of both teams; one could travel from one team's stadium to the other simply by traveling along Interstate 5. The term is akin to "Subway Series" which refers to meetings between New York City baseball teams. The term ""Freeway Series"" also inspired the official name of the regions' NHL rivalry: the "Freeway Face-Off"
Historical rivalry.
New York Yankees.
The Dodgers–Yankees rivalry is one of the most well-known rivalries in Major League Baseball. The two teams have met eleven times in the World Series, more times than any other pair from the American and National Leagues. The initial significance was embodied in the two teams' proximity in New York City, when the Dodgers initially played in Brooklyn. After the Dodgers moved to Los Angeles in 1958, the rivalry retained its significance as the two teams represented the dominant cities on each coast of the United States, and since the 1980s, the two largest cities in the United States.
Although the rivalry's significance arose from the two teams' numerous World Series meetings, the Yankees and Dodgers have not met in the World Series since . They would not play each other in a non-exhibition game until 2004, when they played a three-game interleague series. Their last meeting was in July 2013, when they split a two-game series in Los Angeles.
Fan support.
The Dodgers have a loyal fanbase, evidenced by the fact that the Dodgers were the first MLB team to attract more than 3 million fans in a season (in 1978), and accomplished that feat six more times before any other franchise did it once. The Dodgers drew at least 3 million fans for 15 consecutive seasons from 1996 to 2010, the longest such streak in all of MLB. On July 3, 2007, Dodgers management announced that total franchise attendance, dating back to 1901, had reached 175 million, a record for all professional sports. In 2007, the Dodgers set a franchise record for single-season attendance, attracting over 3.8 million fans. In 2009, the Dodgers led MLB in total attendance. The Dodger baseball cap is consistently in the top three in sales. During the 2011-2012 season, Frank McCourt, the owner of the Dodgers at that time, was going through a rough divorce with his wife over who should be the owner of the Dodger team. Instead, Frank McCourt paid $131 million to his wife as part of the divorce settlement. As a result, the team payroll was financially low for a big-budget team crippling the Dodgers in the free-agent market. Collectively, the team performance waned due to the distracting drama in the front office resulting in low attendance numbers.
Given the team's proximity to Hollywood, numerous celebrities can often be seen attending home games at Dodger Stadium. Celebrities such as Magic Johnson, Mary Hart, Larry King, Tiger Woods, Alyssa Milano and Shia LaBeouf are known to sit at field box seats behind home plate where they sign autographs for fellow Dodger fans. Actor Bryan Cranston is a lifelong Dodger fan.
The Dodgers set the world record for the largest attendance for a single baseball game during an exhibition game against the Boston Red Sox on March 28, 2008 at the Los Angeles Memorial Coliseum in honor of the Dodgers 50th anniversary, with 115,300 fans in attendance. All proceeds from the game benefited the official charity of the Dodgers, ThinkCure! which supports cancer research at Children's Hospital Los Angeles and City of Hope.
Radio and television.
Vin Scully has called Dodgers games since 1950. His longtime partners were Jerry Doggett (1956–1987) and Ross Porter (1977–2004). In 1976, he was selected by Dodgers fans as the Most Memorable Personality (on the field or off) in the team's history. He is also a recipient of the Baseball Hall of Fame's Ford C. Frick Award for broadcasters (inducted in 1982). Unlike the modern style in which multiple sportscasters have an on-air conversation (usually with one functioning as play-by-play announcer and the other as color commentator), Scully, Doggett and Porter generally called games solo, trading with each other inning-by-inning. In the 1980s and 1990s, Scully would call the entire radio broadcast except for the third and seventh inning, allowing the other Dodger commentators to broadcast an inning.
When Doggett retired after the 1987 season, he was replaced by Hall-of-Fame Dodgers pitcher Don Drysdale, who previously broadcast games for the California Angels and Chicago White Sox. Drysdale died in his hotel room following a heart attack before a game in Montreal in 1993. This was a difficult broadcast for Scully and Porter who could not mention it on-air until Drysdale's family had been notified and the official announcement made. He was replaced by former Dodgers outfielder Rick Monday. Porter's tenure ended after the 2004 season, after which the format of play-by-play announcers and color commentators was installed, led by Monday and newcomer Charley Steiner. Scully, however, continues to announce solo.
Scully calls roughly 100 games per season (all home games and road games in California and Arizona) for both flagship radio station KLAC and on television for SportsNet LA. Scully is simulcast for the first three innings of each of his appearances, then announces only for the TV audience. If Scully is calling the game, Steiner takes over play-by-play on radio beginning with the fourth inning, with Monday as color commentator. If Scully is not calling the game, Steiner and Orel Hershiser call the entire game on television while Monday and Kevin Kennedy do the same on radio. In the event the Dodgers are in post-season play, Scully calls the first three and last three innings of the radio broadcast alone and Steiner and Monday handle the middle innings.
The Dodgers also broadcast on radio in Spanish, and the play-by-play is voiced by another Frick Award winner, Jaime Jarrín, who has been with the Dodgers since 1959. The color analyst for some games is former Dodger pitcher Fernando Valenzuela, for whom Jarrin once translated post-game interviews. The Spanish-language radio flagship station is KTNQ.
Achievements.
Retired numbers.
Koufax, Campanella, and Robinson were the first Dodgers to have their numbers retired, in a ceremony at Dodger Stadium on June 4, 1972. This was the year in which Koufax was inducted into the Baseball Hall of Fame; Robinson and Campanella were already Hall-of-Famers.
Alston's number was retired in the year following his retirement as the Dodgers manager, six years before he was inducted into the Hall of Fame.
Gilliam died suddenly in 1978 after a 28-year career with the Dodgers organization. The Dodgers retired his number two days after his death, prior to Game 1 of the 1978 World Series. He is the only non-Hall-of-Famer to have his number retired by the Dodgers.
Beginning in 1980, the Dodgers have retired the numbers of longtime Dodgers (Snider, Reese, Drysdale, Lasorda, and Sutton) during the seasons in which each was inducted into the Hall of Fame.
In 1997, 50 years after he broke the color barrier and 25 years after the Dodgers retired his number, Robinson's No.42 was retired throughout Major League Baseball. Robinson is the only major league baseball player to have this honor bestowed upon him. Starting in the 2007 season, Jackie Robinson Day (April 15, commemorating Opening Day of Robinson's rookie season of 1947) has featured many or all players and coaches wearing the number 42 as a tribute to Robinson.
The Dodgers have not issued No.34 since the departure of Fernando Valenzuela in 1991, although it has not been officially retired.
Personnel.
Managers.
Since 1884, the Dodgers have used a total of 31 Managers, the most current being Dave Roberts, who was appointed following the 2015 postseason, after the departure of Don Mattingly.
The managers of the Los Angeles Dodgers (1958–present) are as follows:
Public address announcers.
From the Dodgers' move to Los Angeles from Brooklyn in 1958, the Dodgers employed a handful of well-known public address announcers; the most famous of which was John Ramsey, who served as the PA voice of the Dodgers from 1958 until his retirement in 1982; as well as announcing at other venerable Los Angeles venues, including the Los Angeles Memorial Coliseum and Sports Arena, and the Forum. Ramsey died in 1990.
From 1958 to 1982, Doug Moore, a local businessman; Philip Petty, an Orange County Superior Court Judge; and Dennis Packer; served as back-up voices for John Ramsey for the Dodgers, California Angels, Los Angeles Chargers, USC football and Los Angeles Rams. Packer was Ramsey's primary backup for the Los Angeles Lakers and Los Angeles Kings until Ramsey's retirement from the Forum in 1978. Thereafter, Packer became the public address announcer for the Lakers, Kings, indoor soccer and indoor tennis events at the Forum.
Nick Nickson, a radio broadcaster for the Los Angeles Kings, replaced John Ramsey as the Dodger Stadium public address announcer in 1983 and served in that capacity through the 1989 season to work with the Kings full-time.
Dennis Packer and Pete Arbogast were emulators of John Ramsey, using the same stentorian style of announcing Ramsey was famous for. Packer and Arbogast shared the stadium announcing chores for the 1994 FIFA World Cup matches at the Rose Bowl. Arbogast won the Dodgers job on the day that Ramsey died on January 25, 1990, by doing a verbatim imitation of Ramsey's opening and closing remarks that were standard at each game. His replacement, in 1993 was Mike Carlucci, who remained as the Dodgers' PA voice until 2003 to concentrate on his voiceover and acting career along with his Olympics announcing duties.
Through 2014, the Dodgers public address announcer was Eric Smith, who also announces for the Los Angeles Clippers and USC Trojans.
On April 3, 2015 the Dodgers announced that former radio broadcaster Todd Leitz would become their new public address announcer. Leitz was an anchor and news reporter in Los Angeles at KNX 1070 AM for 10 years, and a news reporter at KABC 790 for two years.
Other.
Vin Scully is permanently honored in the Hall's "Scribes & Mikemen" exhibit as a result of winning the Ford C. Frick Award in 1982. As with all Frick Award recipients, he is not officially considered an inducted member of the Hall of Fame.
Sue Falsone, served as the first female physical therapist in Major League baseball, and from 2012 to 2013, was the first female head athletic trainer.

</doc>
<doc id="18214" url="https://en.wikipedia.org/wiki?curid=18214" title="Louis Andriessen">
Louis Andriessen

Louis Andriessen (; born 6 June 1939) is a Dutch composer and pianist based in Amsterdam. He is a lecturer at the Royal Conservatory of The Hague. He was recipient of the Gaudeamus International Composers Award in 1959.
Life and career.
Andriessen was born in Utrecht into a musical family, the son of the composer Hendrik Andriessen (1892–1981), brother of composers Jurriaan Andriessen (1925–1996) and Caecilia Andriessen (born 1931), and nephew of Willem Andriessen (1887–1964).
Andriessen originally studied with his father and Kees van Baaren at the Royal Conservatory of The Hague, before embarking upon two years of study with Italian composer Luciano Berio in Milan and Berlin. He later joined the faculty of the Royal Conservatory. 
In 1969 Andriessen co-founded STEIM in Amsterdam. He also helped found the instrumental groups Orkest de Volharding and Hoketus, both of which performed compositions of the same names. He later became closely involved in the ongoing Schonberg and Asko ensembles and inspired the formation of the British ensemble Icebreaker.
Andriessen, a widower, was married to guitarist Jeanette Yanikian (1935–2008). They were a couple for over 40 years and were married in 1996.
Style and notable works.
Andriessen's early works show experimentation with various contemporary trends: post war serialism ("Series", 1958), pastiche ("Anachronie I", 1966–67), and tape ("Il Duce", 1973). His reaction to what he perceived as the conservatism of much of the Dutch contemporary music scene quickly moved him to form a radically alternative musical aesthetic of his own. Since the early 1970s he has refused to write for conventional symphony orchestras and has instead opted to write for his own idiosyncratic instrumental combinations, which often retain some traditional orchestral instruments alongside electric guitars, electric basses, and congas.
Andriessen's mature music combines the influences of jazz, American minimalism, Igor Stravinsky and Claude Vivier. His harmonic writing eschews the consonant modality of much minimalism, preferring post war European dissonance, often crystallised into large blocks of sound. Large scale pieces such as "De Staat" ['Republic'] (1972–76), for example, are influenced by the energy of the big band music of Count Basie and Stan Kenton and the repetitive procedures of Steve Reich, both combined with bright, clashing dissonances. Andriessen's music is thus anti-Germanic and anti-Romantic, and marks a departure from post war European serialism and its offshoots. He has also played a role in providing alternatives to traditional performance practice techniques, often specifying forceful, rhythmic articulations, and amplified, non-vibrato, singing.
Other notable works include "Workers Union" (1975), a melodically indeterminate piece "for any loud sounding group of instruments"; "Mausoleum" (1979) for 2 baritones and large ensemble; "De Tijd" ['Time'] (1979–81) for female singers and ensemble; "De Snelheid" ['Velocity'] (1982–83), for 3 amplified ensembles; "De Materie" ['Matter'] (1984–88), a large four-part work for voices and ensemble; collaborations with filmmaker and librettist Peter Greenaway on the film "M is for Man, Music, Mozart" and the operas "Rosa: A Horse Drama" (1994) and "Writing to Vermeer" (1998); and the recent "La Passione" (2000–02) for female voice, violin and ensemble.

</doc>
<doc id="18217" url="https://en.wikipedia.org/wiki?curid=18217" title="Leonard Peltier">
Leonard Peltier

Leonard Peltier (born September 12, 1944) is a Native American activist and member of the American Indian Movement (AIM). In 1977 he was convicted and sentenced to two consecutive terms of life imprisonment for first degree murder in the shooting of two Federal Bureau of Investigation (FBI) agents during a 1975 conflict on the Pine Ridge Indian Reservation.
Peltier's indictment and conviction have been the subject of much controversy; Amnesty International placed his case under the "Unfair Trials" category of its "Annual Report: USA 2010".
Peltier is incarcerated at the United States Penitentiary, Coleman in Florida. Peltier's next scheduled parole hearing will be in July 2024. Barring appeals, parole or presidential pardon, his projected release date is October 11, 2040.
Early life and education.
Peltier was born in Grand Forks, North Dakota, the eleventh of thirteen children, to Leo Peltier and Alvina Robideau. His father was Turtle Mountain Chippewa on his paternal side and French on his maternal side, and his mother was Dakota Sioux and French on her mother's side and Chippewa on her father's. Peltier's parents divorced when he was four years old. At this time, Leonard and his sister Betty Ann were taken to live with their paternal grandparents Alex and Mary Dubois-Peltier in the Turtle Mountain Indian Reservation of the Turtle Mountain Chippewa near Belcourt, North Dakota.
In September 1953, at the age of nine, Leonard was enrolled at the Wahpeton Indian School in Wahpeton, North Dakota, an Indian boarding school run by the Bureau of Indian Affairs (BIA). He graduated at Wahpeton in May 1957, and attended the Flandreau Indian School in Flandreau, South Dakota. After dropping out in the ninth grade, he returned to the Turtle Mountain Reservation to live with his father.
Career and activism.
In 1965, Peltier relocated to Seattle, Washington. He worked for several years and became the owner of an auto body station. In the city, Peltier became involved in a variety of causes championing Native American civil rights, and eventually joined the American Indian Movement.
In the early 1970s, he learned about the factional tensions at the Pine Ridge Indian Reservation in South Dakota between supporters of Richard Wilson, elected tribal chairman in 1972, and traditionalist members of the tribe. Wilson had created a private militia, known as the Guardians of the Oglala Nation (GOON), whose members were reputed to have attacked political opponents. Protests over a failed impeachment hearing of Wilson contributed to the AIM and Lakota armed takeover of Wounded Knee in February 1973, which resulted in a 71-day siege by federal forces, known as the Wounded Knee Incident. They demanded the resignation of Wilson. Peltier, however, spent most of the occupation in a Milwaukee jail charged with attempted murder. When Peltier secured bail at the end of April, he took part in an AIM protest outside the federal building in Milwaukee and was on his way to Wounded Knee with the group to deliver supplies when the incident ended.
The takeover did not end Wilson's leadership, the actions of the GOONs or the violence; the Oglala Sioux Tribal Government recently asked U.S Attorney Brendan Johnson to look at 45 unresolved deaths since that time. In 1975 Peltier traveled to the Pine Ridge reservation as a member of AIM to try to help reduce the continuing violence among political opponents. At the time, he was a fugitive, with a warrant issued in Milwaukee, Wisconsin. It charged him with unlawful flight to avoid prosecution for the attempted murder of an off-duty Milwaukee police officer, a crime of which he was later acquitted.
Shootout at Pine Ridge.
On June 26, 1975, Special Agents Jack R. Coler and Ronald A. Williams of the Federal Bureau of Investigation (FBI) were on the Pine Ridge Reservation searching for a young man named Jimmy Eagle, who was wanted for questioning in connection with the recent assault and robbery of two local ranch hands. Eagle had been involved in a physical altercation with a friend, during which he had stolen a pair of leather cowboy boots. At approximately 11:50 a.m., Williams and Coler, driving two separate unmarked cars, spotted, reported, and followed a red pick-up truck which matched the description of Eagle's.
Soon after his initial report, Williams radioed into a local dispatch that he and Coler had come under high-powered rifle fire from the occupants of the vehicle and were unable to return fire with their .38 Special revolvers. Williams radioed that they would be killed if reinforcements did not arrive. He next radioed that he was hit. FBI Special Agent Gary Adams was the first to respond to Williams' call for assistance, and he also came under intense gun fire; he was unable to reach Coler and Williams.
The FBI, BIA, and the local police spent the afternoon waiting for other law enforcement officers. At 2:30 p.m., a BIA rifleman fatally shot Joe Stuntz, an AIM member who had taken part in the shootout. At 4:31 p.m., authorities recovered the bodies of Williams and Coler from their vehicles. At 6:30 p.m. they ignited tear gas and stormed the Jumping Bull houses, where they found the body of a Native American, Joseph Stuntz. Stuntz was clad in Coler's green FBI field jacket, which he appeared to have taken from the agent's car. The two FBI Agents were later confirmed to have died on June 26, 1975. Stuntz appeared to have died later, during subsequent shooting.
The FBI reported that Williams had received a defensive wound to his right hand (as he attempted to shield his face) from a bullet which passed through his hand into his head, killing him instantly. Williams received two gunshot injuries, to his body and foot, prior to the contact shot that killed him. Coler, incapacitated from earlier bullet wounds, had been shot twice in the head. In total, 125 bullet holes were found in the agents' vehicles, many from a .223 Remington (5.56 mm) rifle.
Leonard Peltier provided numerous alibis, to different people, about his activities on the morning of the attacks. In an interview with the author Peter Matthiessen ("In the Spirit of Crazy Horse" 1983), Peltier described working on a car in Oglala, claiming to have driven back to the Jumping Bull Compound about an hour before the shooting started. In an interview with Lee Hill, he described being woken up in the tent city at the ranch by the sound of gunshots. To Harvey Arden, for "Prison Writings", he described enjoying a beautiful morning before he heard the firing.
Aftermath.
On September 5, 1975, Agent Williams' .38 Special service revolver and shells from both agents' handguns were found in a vehicle near a residence where Dino Butler was arrested. On September 9, 1975, Peltier purchased a Plymouth station wagon in Denver, Colorado. The FBI sent out descriptions of the vehicle and a recreational vehicle (RV) in which Peltier and associates were believed to be traveling. An Oregon State Trooper stopped the vehicles and ordered the driver of the RV to exit; but, after a brief exchange of gunfire, the driver escaped on foot. Authorities later identified the driver as Peltier. Agent Coler's .38 Special service revolver was found in a bag under the front seat of the RV, where authorities later reported finding Peltier's thumb print.
On September 10, 1975, a station wagon exploded on the Kansas Turnpike near Wichita. A burned AR-15 rifle was recovered, along with Agent Coler's .308 rifle. The car was loaded with weapons and explosives, which apparently ignited when placed too close to a hole in the exhaust pipe. Injured in the blast were Robert Robideau, Norman Charles, and Michael Anderson, who were all members of AIM.
On December 22, 1975, Peltier was named to the FBI Ten Most Wanted Fugitives list.
Peltier fled to Hinton, Alberta, where he hid in a friend's cabin. On February 6, 1976, he was arrested and extradited from Canada based on an affidavit signed by Myrtle Poor Bear, a local Native American woman. She claimed to have been Peltier's girlfriend at the time and to have witnessed the murders. But, according to Peltier and others at the scene, Poor Bear did not know Peltier, nor was she present at the time of the shooting. She later claimed that she was pressured and threatened by FBI agents into giving the statements. Poor Bear attempted to testify about the FBI's intimidation at Peltier's trial; however, the judge barred her testimony on the grounds of mental incompetence.
Peltier fought extradition to the United States, even as Bob Robideau and Darrelle “Dino” Butler, AIM members also present on the Jumping Bull compound at the time of the shootings, were found not guilty on the grounds of self-defense by a federal jury in Cedar Rapids, Iowa. Peltier returned too late to be tried with Robideau and Butler, and he was subsequently tried separately. 
Peltier's trial was held in Fargo, North Dakota, where a jury convicted Peltier of the murders of Coler and Williams. Unlike the trial for Butler and Robideau, the jury was informed that the two FBI agents were killed by close-range shots to their heads, when they were already defenseless due to previous gunshot wounds. They also saw autopsy and crime scene photographs of the two agents, which had not been shown to the jury at Cedar Rapids. In April 1977, Peltier was convicted and sentenced to two consecutive life sentences. Upon hearing the appeals case on February 11, 1986, Federal Appeals Judge Gerald W. Heaney, concluded, "When all is said and done ... a few simple but very important facts remain. The casing introduced into evidence had in fact been extracted from the Wichita AR-15." In his 1999 memoir, Peltier admitted that he fired at the agents, but denies that he fired the fatal shots that killed them.
A cartridge case from the Wichita AR-15 was found in the trunk of Agent Coler's car, and admitted as evidence at Peltier's trial in Fargo, North Dakota. Also admitted as evidence was the fact that no person involved in shooting at the agents, other than Peltier, possessed an AR-15 rifle.
The journalist Scott Anderson said that in a 1995 interview with Peltier, he sought answers to the contradictions he had found in Peltier's accounts of the incident on 26 June 1975. When asked about the guns he carried that day, Peltier listed a .30-30, a .303, a .306, a .250 and a .22, but he did not remember the AR-15.
The former United States Attorney General Ramsey Clark has served "pro bono" as one of Peltier's lawyers and has aided in filing a series of appeals on Peltier's behalf. In all appeals, the conviction and sentence have been affirmed by the 8th Circuit Court of Appeals. The last two appeals were "Peltier v. Henman", 997 F. 2d 461 in July 1993 and "United States v. Peltier", 446 F.3d 911 (8th Cir. 2006) (Peltier IV) in 2006.
Doubts about legal proceedings.
Numerous doubts have been raised over Peltier's guilt and the fairness of his trial, based on allegations and inconsistencies regarding the FBI and prosecution's handling of this case:
Post-trial debate.
Peltier's conviction sparked great controversy and has drawn criticism from a number of sources. Numerous appeals have been filed on his behalf; none of the resulting rulings has been made in his favor. Peltier is considered by the AIM to be a political prisoner and has received support from individuals and groups including Nelson Mandela, Rigoberta Menchú, Soviet Peace Committee, Amnesty International, the United Nations High Commissioner for Human Rights, the Zapatista Army of National Liberation, Tenzin Gyatso (the 14th Dalai Lama), Mikhail Gorbachev, Zack de la Rocha, the European Parliament, the Belgian Parliament, the Italian Parliament, the Kennedy Memorial Center for Human Rights, Archbishop Desmond Tutu, and Rev. Jesse Jackson.
Peltier's supporters have asserted that he did not commit the murders, and that he either had no knowledge of the murders (as he told CNN in 1999), or that he has knowledge implicating others which he will never reveal, or (as told in Peter Matthiessen's "In the Spirit of Crazy Horse ", 1983) that he approached and searched the agents but did not execute them.
The film "Incident at Oglala" (1992) included the AIM activist Robert Robideau saying the FBI agents had been shot by a 'Mr X'. When Peltier was interviewed about 'Mr X', he said he knew who the man was. In 1995 Dino Butler, in an interview with E.K. Caldwell of "News From Indian Country", said that 'Mr X' had been invented as the murderer in an attempt to achieve Peltier's release. In a 2001 interview with "News From Indian Country", Bernie Lafferty said that she had witnessed Peltier's referring to his murder of one of the agents.
21st-century developments.
Near the end of the Clinton administration in 2000, rumors began circulating that Bill Clinton was considering granting Peltier clemency. Opponents campaigned against that, culminating in a protest outside the White House by about 500 FBI agents and families, and a letter opposing clemency from FBI director Louis Freeh. Clinton did not grant or deny Peltier clemency. In 2002, Peltier filed a civil rights lawsuit in the U.S. District Court for the District of Columbia against the FBI, Louis Freeh, and FBI agents who had participated in the campaign against his clemency petition, alleging that they "engaged in a systematic and officially sanctioned campaign of misinformation and disinformation." On March 22, 2004, the suit was dismissed. In January 2009, President George W. Bush denied Peltier's clemency petition before leaving office.
Editorial about deaths of agents and Aquash.
In January 2002 in the "News from Indian Country", the publisher Paul DeMain wrote an editorial that an "unnamed delegation" told him, "Peltier was responsible for the close range execution of the agents. ..." DeMain described the delegation as "grandfathers and grandmothers, AIM activists, Pipe carriers and others who have carried a heavy unhealthy burden within them that has taken its toll." DeMain said he was told the motive for the execution-style murder of the AIM activist Anna Mae Aquash in December 1975 "allegedly was her knowledge that Leonard Peltier had shot the two agents, as he was convicted." DeMain did not accuse Peltier of participation in the Aquash murder. In 2003 two Native American men were indicted and later convicted for the murder.
On May 1, 2003, Peltier sued DeMain for libel for similar statements about the case published on March 10, 2003, in "News from Indian Country". On May 25, 2004, Peltier withdrew the suit after he and DeMain settled the case. DeMain issued the following statement:
DeMain did not retract his allegations that Peltier was guilty of the murders of the FBI agents and that the motive for Aquash's murder was the fear that she might inform on the activist.
Indictments and trials for the murder of Aquash.
Bruce Ellison, Leonard Peltier's lawyer since the 1970s, invoked his Fifth Amendment rights against self-incrimination and refused to testify at the 2003 federal grand jury hearings on charges against Arlo Looking Cloud and John Graham for the murder of Aquash. Ellison also refused to testify at Looking Cloud's trial in 2004. During the trial, the federal prosecutor named Ellison as a co-conspirator in the Aquash case. Witnesses said that Ellison participated in interrogating Aquash about being an informant on December 11, 1975, shortly before her murder.
In February 2004, Fritz Arlo Looking Cloud, an Oglala Sioux, was tried and convicted for the murder of Aquash. In Looking Cloud's trial, the federal prosecution argued that AIM's suspicion of Aquash stemmed from her having heard Peltier admit to the murders. Darlene "Kamook" Nichols, former wife of the AIM leader Dennis Banks, was a witness for the prosecution. She testified that in late 1975, Peltier told her and a small group of AIM fugitive activists about shooting the FBI agents. At the time all were fleeing law enforcement after the Pine Ridge shootout. The other fugitives included her sister Bernie Nichols, her husband Dennis Banks, and Anna Mae Aquash, among several others. Bernie Nichols-Lafferty testified with a similar account of Peltier's statement.
Earlier in 1975, the AIM member Douglass Durham had been revealed to be an FBI agent and dismissed from the organization. AIM leaders were fearful of infiltration. Other witnesses have testified that, once Aquash was suspected of being an informant, Peltier interrogated her while holding a gun to her head. Peltier and David Hill were said to have Aquash participate in bomb-making so that her fingerprints would be on the bombs. Prosecutors alleged in court documents that the trio planted these bombs at two power plants on the Pine Ridge reservation on Columbus Day 1975.
During the trial, Nichols acknowledged receiving $42,000 from the FBI in connection with her cooperation on the case. She said it was compensation for travel expenses to collect evidence and moving expenses to be farther from her ex-husband Dennis Banks, whom she feared because she had implicated him as a witness. Peltier has claimed that Kamook Nichols committed perjury with her testimony.
On June 26, 2007, the Supreme Court of British Columbia ordered the extradition of John Graham to the United States to stand trial for his alleged role in the murder of Aquash. He was eventually tried by the state of South Dakota in 2010. During his trial, Darlene "Kamook" Ecoffey said Peltier told both her and Aquash that he had killed the FBI agents in 1975. Ecoffey testified under oath, "He (Peltier) held his hand like this," she said, pointing her index finger like a gun, "and he said 'that (expletive) was begging for his life but I shot him anyway.'" Graham was convicted of murder as the gunman who shot Aquash and sentenced to life imprisonment.
Presidential candidate.
Peltier was the candidate for the Peace and Freedom Party in the 2004 Presidential race. While numerous states have laws that prohibit prison inmates convicted of felonies from voting (Maine and Vermont are exceptions), the United States Constitution has no prohibition against felons being elected to Federal offices, including President. The Peace and Freedom Party secured ballot status for Peltier only in California, where his presidential candidacy received 27,607 votes, approximately 0.2% of the vote in that state.
Ruling on FBI documents.
In a February 27, 2006, decision, U.S. District Judge William Skretny ruled that the FBI did not have to release five of 812 documents relating to Peltier and held at their Buffalo field office. He ruled that the particular documents were exempted on the grounds of "national security and FBI agent/informant protection." In his opinion Judge Skretny wrote, "Plaintiff has not established the existence of bad faith or provided any evidence contradicting (the FBI's) claim that the release of these documents would endanger national security or would impair this country's relationship with a foreign government." In response, Michael Kuzma, a member of Peltier's defense team, said, "We're appealing. It's incredible that it took him 254 days to render a decision." Kuzma further said, "The pages we were most intrigued about revolved around a teletype from Buffalo ... a three-page document that seems to indicate that a confidential source was being advised by the FBI not to engage in conduct that would compromise attorney-client privilege." Peltier's supporters have tried to obtain more than 100,000 pages of documents from FBI field offices, claiming that the files should have been turned over at the time of his trial or following a Freedom of Information Act (FOIA) request filed soon after.
On July 20, 2012, a federal judge refused a request by Kuzma to review more than 900 pages of FBI documents related to Frank Blackhorse, who was among the approximately 24 AIM members or supporters the FBI identified as having participated in the fatal shootout on June 26, 1975. Blackhorse was arrested with Peltier but faced no extradition effort.
2007 political controversy.
In 2007, billionaire David Geffen, a Peltier supporter, shifted his financial support from Hillary Clinton's presidential campaign to that of Barack Obama. Geffen said he switched his support because he was disillusioned by Bill Clinton's refusal to pardon Peltier, although he had pardoned Marc Rich.
Beaten in Canaan.
On January 13, 2009, Peltier was severely beaten by fellow inmates at the United States Penitentiary, Canaan, where he had been transferred from USP Lewisburg. He was sent back to Lewisburg, where he remained until the fall of 2011 when he was transferred to a federal penitentiary in Florida. As of 2016, Leonard Peltier is housed at Coleman Federal Correctional Complex in Coleman, Florida.

</doc>
<doc id="18221" url="https://en.wikipedia.org/wiki?curid=18221" title="LambdaMOO">
LambdaMOO

LambdaMOO is an online community of the variety called a MOO. It is the oldest MOO today.
"LambdaMOO" was founded in late 1990 or early 1991 by Pavel Curtis at Xerox PARC. Now hosted in the state of Washington, it is operated and administered entirely on a volunteer basis. Guests are allowed, and membership is free to anyone with an e-mail address.
"LambdaMOO" gained some notoriety when Julian Dibbell wrote a book called "My Tiny Life" describing his experiences there. Over its history, "LambdaMOO" has been highly influential in the examination of virtual-world social issues.
History.
LambdaMOO has its roots in the 1978–1980 work by Roy Trubshaw and Richard Bartle to create and expand the concept of Multi-User Dungeon (MUD) – virtual communities. Around 1987–1988, the expansion of the global internet allowed more users to experience the MUD. Pavel Curtis at Xerox Parc noted that they were "almost exclusively for recreational purposes." Curtis determined to explore whether the MUD could be non-recreational. He developed "LambdaMOO" software to run on the LambdaMOO server, which implements the MOO programming language. This software was subsequently made available to the public. Several starter databases, known as cores, are available for MOOs; "LambdaMOO" itself uses the LambdaCore database. The "Lambda" name is from Curtis's own username on earlier MUD systems.
LambdaMOO can refer to the software, the server, or the community of users.
Joining.
To join LambdaMOO requires a working email. Once you submit your email, you must wait a few days before you receive a randomized character name and password. In the meantime, you can play LambdaMOO as a guest.
Once you get your randomized character name you are able to log in to LambdaMOO and change your character name and password. After you choose your unique character name you are able to select your gender as well as editing your characters physical description and personality. LambdaMOO allows you a lot of freedom when it comes to customizing your character. You are offered a wide range of genders and are able to write anything you want in a paragraph about yourself. After you customize these settings you are equipped to begin exploring LambdaMOO.
Geography.
"LambdaMOO" central geography was based on Pavel Curtis's California home. New players and guests traditionally connected in "The Coat Closet", but a second area, "The Linen Closet" (specially programmed as a silent area) was later added as an alternative connection point. The coat closet opens onto the center of the house in The Living Room, a common hangout and place for conversation; its fixtures include a fireplace (where things can be roasted), The Living Room Couch (which periodically causes players' objects to 'fall through' to underneath the couch), and a pet Cockatoo who repeats overheard phrases (which is often found with its beak gagged). From time to time the Cockatoo is replaced with a more seasonal creature: a Turkey near Thanksgiving, a Raven near Halloween, et cetera.
To the north of the Living Room is the Entrance Hall, the Front Yard, and a limited residential area along LambdaStreet. There is an extensive subterranean complex located down the manhole, including a sewage system.
Players walking to the far west along LambdaStreet may be given the option to 'jump off the end of the world', which disables access to their account for three months. To the south of the Living Room is a pool deck, a hot tub, and some of the extensive grounds of the mansion, featuring gardens, hot air balloon landing pads, open fields, fishing holes, and the like.
To the northwest of the living room are the laundry room, garage, dining room, smoking room, drawing room, housekeeper's quarters, and kitchen; a popular command allows players in the living room to push others into the kitchen and ask them to "fetch me a cup of tea"; since players can prevent themselves from being moved in such a fashion, this command is more often used on new users, who may have difficulty finding their way back to the Living Room. (There is direct access to the kitchen leading northwest from the living room, but as with the actual house you must head north, east, and then south from the Kitchen to return.)
To the east of the entry hall, hallways provide access to some individual rooms, the Linen Closet, and to the eastern wing of the house. In the eastern wing can be found the Library of online books, the Museum of generic objects (which account-holders may create instances of), and an extensive area for the "LambdaMOO" RPG.
Since the creation of the original LambdaMOO map, many users have expanded the MOO by making additional rooms with the command "@dig."
Politics.
While most MOOs are run by administrative fiat, in summer of 1993 "LambdaMOO" implemented a petition/ballot mechanism, allowing the community to propose and vote on new policies and other administrative actions. A petition may be created by anyone eligible to participate in politics (those who have maintained accounts at the MOO for at least 30 days), can be signed by other players, and may then be submitted for administrative 'vetting'. Once vetted, the petition has a limited time to collect enough signatures to become valid and be made into a ballot. Ballots are subsequently voted on; those with a 66% approval rating are passed and will be implemented. This system suffered quite a lot of evolution and eventually passed into a state where wizards took back the power they'd passed into the hands of the people, but still maintain the ballot system as a way for the community to express its opinions.
Demographics.
While the population of "LambdaMOO" once numbered close to 10,000 with over 300 actively connected at any time, these days it is rare to see more than a few dozen actively participating connected players at one time.
As of November 13, 2005, "LambdaMOO" had 10 official wizards (administrators) and approximately 2,900 general users. Of these, approximately 1410 players reported themselves as male, and 916 as female; the remaining players either stayed with the default neuter gender, or deliberately chose another. ("LambdaMOO" supports custom designations of gender, and comes with the following presets: neuter, male, female, either, Spivak, splat, plural, egotistical, royal, and 2nd-person).

</doc>
<doc id="18223" url="https://en.wikipedia.org/wiki?curid=18223" title="Lorica segmentata">
Lorica segmentata

The lorica segmentata ("segmented cuirass") is a type of personal armour used by soldiers of the Roman Empire, consisting of metal strips ("girth hoops" fashioned into circular bands), fastened to internal leather straps. The Latin name was first used in the 16th century; the ancient form is unknown, although it is possible that the Romans referred to the armour as ""lorica laminata"" (laminated cuirass).
The plates of lorica segmentata armour were soft iron inside and (some at least) were mild steel on the outside, making the plates hardened against damage without becoming brittle. This was a deliberate act, called case hardening, and is carried out by enriching the surface iron with carbon from organic materials packed tightly around the piece which is then heated in a forge. 
The strips were arranged horizontally on the body, overlapping downwards, and they surrounded the torso in two halves, being fastened at the front and back. The upper body and shoulders were protected by additional strips ("shoulder guards") and breast- and backplates. The form of the armour allowed it to be stored very compactly, since it was possible to separate it into four sections each of which would collapse on itself into a compact mass. The fitments that closed the various plate sections together (buckles, lobate hinges, hinged straps, tie-hooks, tie-rings, etc.) were made of brass. In later variants dating from around 75–80 A.D., the fastenings of the armour were simplified. Bronze hinges were removed in favour of simple rivets, belt fastenings utilised small hooks, and the lowest two girdle plates were replaced by one broad plate.
History.
During the time of their use, this style of armour evolved and changed, the currently recognised types being the Kalkriese, Corbridge and Newstead types, named after their places of discovery. There was, however, a considerable overlap between these types in use and the Corbridge and Newstead types are often found at the same site (e.g. at Caerleon in Wales, Carnuntum in Austria, Carlisle in England and León in Spain). It is possible that there was a fourth type, covering the body with segmented armour joined to scale shoulder defences. However, this is only known from one badly damaged statue originating at Alba Iulia in Romania. The currently accepted range for the use of the armour is from about 9 B.C. (Dangstetten) to the late 3rd century A.D. (León). Its use was geographically widespread, but mail may have been more common at all times.
Uses.
The question as to precisely who used the armour is debated. There is a clear difference in armour between the two corps shown on Trajan's Column. This is a monument erected in 113 in Rome to commemorate the conquest of Dacia by Emperor Trajan (ruled 98–117): its bas-reliefs are a key source for Roman military equipment. "Auxilia" are generally shown wearing mail ("lorica hamata") cuirasses and carrying oval shields. Legionaries are uniformly depicted wearing the "lorica segmentata" and carrying the curved rectangular shield. On this basis, it has been supposed that lorica segmentata was used by legionaries only. However, some historians consider Trajan's Column to be inaccurate as a historical source due to its inaccurate and stylised portrayal of Roman armour: "it is probably safest to interpret the Column reliefs as ‘impressions’, rather than accurate representations." 
The view that "auxilia" were light troops originates from Vegetius' comment that ""auxilia" are always joined as light troops with the legions in the line". It is true that some specialist units in the "auxilia", such as Syrian archers and Numidian cavalry wore light armour (or none). But they were a small minority of the "auxilia". Most auxiliary "cohortes" contained heavy infantry similar to legionaries.
However, on another Trajanic monument (the Adamclisi "Tropaeum") the "lorica segmentata" does not appear at all, and legionaries and "auxilia" alike are depicted wearing either mail or scales ("lorica squamata"). Some experts are of the opinion that the Adamclisi monument is a more accurate portrayal of the situation, the "segmentata" used rarely, maybe only for set-piece battles and parades. This viewpoint considers the figures in Trajan's Column to be highly stereotyped, in order to distinguish clearly between different types of troops. In any event, both corps were equipped with the same weapons: "gladius" (a close-combat stabbing sword) and javelins, although the type of javelin known as "pilum" seems to have been provided to legionaries only. Goldsworthy points out that the equipment of both corps were roughly equal in weight.
In recent years archaeologists have found fittings of "loricae segmentatae" in many fort sites that are thought to have been garrisoned by only auxiliary troops, "i.e.", where the legions were not based. If the legions were, indeed, broken up and distributed around all these small bases, then it implies a tactical use of the legions that has not previously been considered. Hitherto, the legions were regarded as shock troops employed only "en masse" and not broken up into detachments. M.C. Bishop, however, has argued that we need to examine the way in which the various troop types were armed and deduce from this what their battle roles were, rather than trying to consider who-wore-what. Succinctly put, the legions were armed and trained for close-order combat while the auxiliary forces, just as numerous, were more accustomed to open order fighting, although they could be employed as the legions were (e.g. at Mons Graupius) if circumstances demanded this.
Last uses and disappearance.
During the 3rd century, all "peregrini" were granted Roman citizenship, and therefore legionaries lost their social superiority. The "lorica segmentata" eventually disappeared from Roman use, most likely due to its high cost and difficult maintenance despite its good qualities, although it appears to have still been in use into the early 4th century, being depicted in the Arch of Constantine erected in 315 during the reign of Constantine I to commemorate his military achievements.(However, it has been argued that these depictions are from an earlier monument by Marcus Aurelius, from which Constantine incorporated portions into his Arch.) Recently there has been evidence of a "lorica segmentata" found in Spain, dating from the third century.[http://www.romanarmytalk.com/rat/viewtopic.php?f=17&t=26427 What is more surprising is that it was found in an area where, as far as we know, only "limitanei" operated. ("Limitanei" are frontier troops, from Latin limes, boundary or frontier, while the mobile field armies are the "comitatenses"; it used to be thought they were inferior second-line units or militia; their quality did not diminish until the mid-5th century.)
Popular culture.
The Lorica Segmentata has come to be viewed as a symbol of the Roman legions in popular culture. This tendency even extends to time periods where its employment is so early or late as to be anachronistic.

</doc>
<doc id="18224" url="https://en.wikipedia.org/wiki?curid=18224" title="Known Space">
Known Space

Known Space is the fictional setting of about a dozen science fiction novels and several collections of short stories written by Larry Niven. It has also become a shared universe in the spin-off "Man-Kzin Wars" anthologies. ISFDB catalogs all works set in the fictional universe that includes Known Space under the series name Tales of Known Space, which was the title of a 1975 collection of Niven's short stories. The first-published work in the series, which was Niven's first published piece was "The Coldest Place", in the December 1964 issue of "If" magazine, edited by Frederik Pohl. This was the first-published work in the 1975 collection.
The stories span approximately one thousand years of future history, from the first human explorations of the Solar System to the colonization of dozens of nearby systems. Late in the series, Known Space is an irregularly shaped "bubble" about 60 light-years across.
Within the Tales of Known Space, the epithet "Known Space" refers to a relatively small region in the Milky Way galaxy, one centered on Earth. In the future that the series depicts, spanning roughly the third millennium, humans have explored this region and colonized many of its worlds. Contact has been made with other species, such as the two-headed Pierson's Puppeteers and the aggressive felinoid Kzinti. Stories in the Known Space series include events and places outside of the region called "Known Space" such as the Ringworld, the Pierson's Puppeteers' Fleet of Worlds and the Pak homeworld.
The Tales were originally conceived as two separate series, the "Belter" stories set roughly from 2000 to 2350 CE and the "Neutron Star"/"Ringworld" stories set in 2651 CE and later. The earlier, Belter period features solar-system colonization and slower-than-light travel with fusion-powered and Bussard ramjet ships. The later, Neutron Star period features faster-than-light ships using "hyperdrive". Niven implicitly joined the two settings as a single fictional universe in the short story "A Relic of the Empire" ("If", December 1966), by using background elements of the Slaver civilization from the "Belter" series as a plot element in the faster-than-light setting. In the late 1980s—having written almost no Tales of Known Space in more than a decade—Niven opened the 300-year gap in the Known Space timeline as a shared universe, and the stories of the "Man-Kzin Wars" volumes fill in that history, bridging the two settings.
Overview.
Species.
In the process of exploring space, humankind encounters several intelligent alien species, including the following (in alphabetical order):
Also figuring in some stories are dolphins and other intelligent cetaceans, and various offshoots of "Homo sapiens" including the associate lineage of the hominids of the Ringworld. Most life in Known Space shares similar biochemistries, since they evolved from the Thrintun practice of seeding barren worlds with food yeast which they used to feed their slaves. Over a billion years, the Thrintun food yeast evolved into the different life forms in Known Space.
Locations.
One aspect of the "Known Space" universe is that most of the early human colonies are on planets suboptimal for "Homo sapiens". During the first phase of human interstellar colonization (i.e. before humanity acquired FTL), simple robotic probes were sent to nearby stars to assess their planets for habitation. The programming of these probes was flawed: they sent back a "good for colonization" message if they found a habitable "point", rather than a habitable "planet". Sleeper ships containing human colonists were sent to the indicated star systems. Too often, those colonists had to make the best of a bad situation.
Technology.
The series features a number of "superscience" inventions which figure as plot devices. Stories earlier in the timeline feature technology such as Bussard ramjets, Drouds (wires capable of directly stimulating the pleasure centers of the brain) and explore how organ transplantation technology enables the new crime of "organlegging" (as well as the general sociological effects of widespread transplant technology), while later stories feature hyperdrive, invulnerable starship hulls, stasis fields, molecular monofilaments, transfer booths (teleporters used only on planetary surfaces), the lifespan-extending drug boosterspice, and the tasp which is an extension of the wirehead development which works without direct contact.
The impact of inventions and technology on society is a recurring, if not central theme in Niven's work: for example, addiction to electric brain stimulation resulting in "wireheads", or the secondary and tertiary effects of an invention such as teleportation on social behavior, problems, and mores.
The milieu can be viewed as representing the last gasp of Campbell-era science fiction, as the iconoclastic, counterculture influences of "new wave" science fiction of the sixties play no part in most of the stories. However, there are notable exceptions in the "Gil the ARM" stories; and "Jigsaw Man" first appeared in Harlan Ellison's landmark "new wave" anthology, "Dangerous Visions".
Boosterspice.
Boosterspice is a compound that increases the longevity and reverses aging of human beings. With the use of boosterspice, humans can easily live hundreds of years and, theoretically, indefinitely.
Developed by the Institute of Knowledge on Jinx, it is said to be made from genetically engineered ragweed (although early stories have it ingested in the form of edible seeds). In "Ringworld's Children", it is suggested boosterspice may actually be adapted from Tree-of-Life, without the symbiotic virus that enabled hominids to metamorphose from Pak Breeder stage to Pak Protector stage (mutated Pak breeders were the ancestors of both "Homo sapiens" and the hominids of the Ringworld).
On the Ringworld, there is an analogous (and apparently more potent) compound developed from Tree-of-Life, but they are mutually incompatible; in "The Ringworld Engineers", Louis Wu learns that the character Halrloprillalar died when in ARM custody after leaving the Ringworld, as a result of having taken boosterspice after having used the Ringworld equivalent. Boosterspice only works on "Homo sapiens", whereas the Tree-of-Life compound will work on any hominid descended from the Pak.
Hyperdrive.
Faster-than-light (FTL) propulsion, or hyperdrive, was obtained from the Outsiders at the end of the First Man-Kzin War. In addition to winning the war for humanity, it allowed the re-integration of all the human colonies, which were previously separated by distance. Standard hyperdrive covers a distance of one light-year every three days (121.75 x c). A more advanced Quantum II Hyperdrive introduced later is able to cover the same distance in one and a quarter minutes (420,768 x c).
In Niven's first novel, "World of Ptavvs", the hyperdrive used by the Thrintun required a ship to be going faster than 93% of the speed of light. However, this is the only time that Hyperdrive is described this way.
In the vast majority of "Known Space" material, hyperdrive requires that a ship be outside a star's gravity well to use. Ships which activate hyperdrive close to a star are likely to disappear without a trace. This effect is regarded as a limitation based on the laws of physics. In Niven's novel "Ringworld's Children" the Ringworld itself is converted into a gigantic Quantum II hyperdrive and launched into hyperspace while within its star's gravity well. "Ringworld's Children" reveals that there is life in hyperspace around gravity wells and that hyperspace predators eat spaceships which appear in hyperspace close to large masses, thus explaining why a structure as large as the Ringworld can safely engage the hyperdrive in a star's gravity well.
One phenomenon travellers in hyperspace can experience is the so-called 'blind spot' should they look through a porthole or camera screen, giving the impression that the walls around the porthole or sides of the camera view screen are expanding to 'cover up the outside'. The phenomenon is the result of hyperspace being so fundamentally different from 'normal/Einstein' space that a traveller's senses can not truly comprehend it, and instead the observer 'sees' a form of nothingness that can be hypnotic and dangerous.
Staring too long into the 'blind' spot can be insanity inducing, so as a precaution all view ports on ships are blinded when a ship enters hyperspace.
Invulnerable hulls.
The Puppeteer firm, General Products, produces an invulnerable starship hull, known simply as a General Products Hull. The hulls are impervious to any type of matter or energy, with the exception of antimatter (which destroys the hull), gravitation, and visible light (which pass through the hull). While invulnerable themselves, this is no guarantee that the contents are likewise protected. For example, though a high speed impact with the surface of a planet or star may cause no harm to the hull, the occupants will be crushed if they are not protected by additional measures such as a stasis field or a gravity compensating field.
In "Fleet of Worlds", the characters tour a General Products factory and receive clues that allow them to destroy a General Products hull from the inside using only a high-powered interstellar communications laser. In "Juggler of Worlds", the Puppeteers, attempting to surmise how this was done without antimatter, identify another technique which can be used to destroy the otherwise invulnerable hulls, one which does suggest some potential defense options.
Organ transplantation.
On Earth in the mid-21st century, it became possible to transplant any organ from any person to another, with the exception of brain and central nervous system tissue. Individuals were categorized according to their so-called "rejection spectrum" which allowed doctors to counter any immune system responses to the new organs, allowing transplants to "take" for life. It also enabled the crime of "organlegging" which lasted well into the 24th century.
Stasis fields.
A Slaver stasis field creates a bubble of space/time disconnected from the entropy gradient of the rest of the universe. Time slows effectively to a stop for an object in stasis, at a ratio of some billions of years outside to a second inside. An object in stasis is invulnerable to anything occurring outside the field, as well as being preserved indefinitely. A stasis field may be recognized by its perfectly reflecting surface, so perfect in fact that it reflects 100% of all radiation and particles, including neutrinos. However one stasis field cannot exist inside another. This is used in World of Ptavvs where humans develop a stasis field technology and realize that a mirrored artifact known as the "Silver Statue" must be actually an alien in a stasis field. They place it with a human envoy, who is a telepath, and envelop both in field. By doing this, they unleash the last living member of the Slaver species on the world.
Stepping disks.
Stepping disks are a fictional teleportation technology. They were invented by the Pierson's Puppeteers, and their existence is not generally known to other races until the events of "The Ringworld Engineers".
The stepping disks are an outgrowth and improvement of the transfer booth technology used by humans and other Known Space races. Unlike the booths, the disks do not require an enclosed chamber, and somehow can differentiate between solid masses and air, for example. They also have a far greater range than transfer booths, extending several Astronomical Units.
Several limitations to stepping disks are mentioned in the Ringworld novels. If there is a difference in velocity between two disks, any matter transferred between them must be accelerated by the disk accordingly. If there is not enough energy to do so, the transfer cannot take place. This becomes a problem with disks that are a significant distance apart on the Ringworld surface, as they will have different velocities: same speed, different direction.
Transfer booths.
Transfer booths are an inexpensive form of teleportation. Short-range booths are similar in appearance to an old style telephone booth: one enters, "dials" one's desired destination, and is immediately deposited in a corresponding booth at the destination. Longer-range booths operate similarly, but are housed in former airports due to requiring "equipment to compensate for the difference in rotational velocity between different points on the Earth". They are inexpensive: a trip anywhere on Earth costs only a "tenth-star" (presumably equivalent to a dime). Introduced by one of Gregory Pelton's ancestors, apparently bought from and based on Puppeteer technology.
Paranormal abilities.
Some individuals in the stories display limited paranormal or "psionic" abilities. Gil Hamilton can move objects with his mind using his phantom arm, which he gained after losing an arm in an asteroid mining accident. When he finally had the arm replaced from an organ bank on Earth, the ability persisted. "Plateau Eyes" (introduced in "A Gift From Earth") is an ability to hide in plain sight, by causing others not to notice you. Population control is tight on Earth, but these abilities can gain the possessor a license to have more children. The Pierson's Puppeteers engineer a lottery for child licenses on Earth to increase the occurrence of "Luck", which they think is a paranormal ability humans have that has enabled them to defeat races such as the Kzinti. In "Ringworld", the character Teela Brown is said to be the ultimate expression of this ability.
Organizations.
ARM.
The ARM is the police force of the United Nations. ARM originated as an acronym for "Amalgamation of Regional Militia", though this is not a term in current usage by the time of the "Known Space" novels. An agent of the ARM, Gil Hamilton, is the protagonist of Niven's sci-fi detective stories, a series-within-a-series gathered in the collection "Flatlander" (Confusingly, "Flatlander" is also the name of an unrelated "Known Space" story.)
Their basic function is to enforce mandatory birth control on overcrowded Earth, and restrict research which might lead to dangerous weapons. In short, the ARM hunts down women who have illegal pregnancies and suppresses all new technologies. They also hunt organleggers, especially in the era of the "organ bank problem". Among the many technologies they control and outlaw are all trained forms of armed and unarmed combat. By the 25th century, ARM agents were kept in an artificially induced state of paranoid schizophrenia to enhance their usefulness as law enforcement officials, which led to them sometimes being referred to as ""Schizes"". Agents with natural tendencies toward paranoia were medicated into docility during their off duty hours, through the aforementioned science of psychistry (see "Madness Has Its Place" and "Juggler of Worlds").
Their jurisdiction is limited to the Earth-Moon system; other human colonies have their own militia. Nevertheless, in many "Known Space" stories, ARM agents operate or exert influence in other human star systems through the "Bureau of Alien Affairs" (see "In the Hall of the Mountain King", "Procrustes", "The Borderland of Sol", and "Neutron Star"). These interventions begin following the Man-Kzin Wars and the introduction of hyperdrive, presumably as part of a general re-integration of human societies.
Stories in Known Space.
The Tales of Known Space were first published primarily as short stories or serials in science fiction magazines. Generally the short fiction was subsequently released in one or more collections and the serial novels as books. Some of the shorter novels (novellas) published in magazines were expanded as, or incorporated in, book-length novels. Due to the large number of stories, it is particularly difficult for a completionist fan to read every story in the series. There are also two or three short stories which share common themes and some background elements with "Known Space" stories, but which are not considered a part of the "Known Space" universe: "One Face" (1965) and "Bordered in Black" (1966) —both in the 1979 collection "Convergent Series"—and possibly "The Color of Sunfire", published online and listed here.
In the "Known Space" stories, Niven had created a number of technological devices (GP hull, stasis field, Ringworld material) which, combined with the "Teela Brown gene", made it very difficult to construct engaging stories beyond a certain date—the combination of factors made it tricky to produce any kind of creditable threat/problem without complex contrivances. Niven demonstrated this, to his own satisfaction, with "Safe at Any Speed" (1967). He used the setting for much less short fiction after 1968 and much less for novels after two published in 1980. Late in that decade, however, Niven invited other authors to participate in a series of shared-universe novels, with the Man-Kzin Wars as their setting. The first volume was published in 1988.
"Ringworld" (1970) won the annual Nebula, Hugo, and Locus best novel awards.
"Protector" (1973) and "The Ringworld Engineers" (1980) were nominated for the Hugo and Locus Awards.
Playground.
Niven has described his fiction as "playground equipment", encouraging fans to speculate and extrapolate on the events described. Debates have been made, for example, on who built the Ringworld (Pak Protectors and the Outsiders being the traditional favorites, but see "Ringworld's Children" for a possibly definitive answer), and what happened to the Tnuctipun. However, Niven also states that this is "not" an invitation to violate his copyrights, so fans should try to avoid publishing works that are too obviously based in the "Known Space" universe without Niven's given permission.
Niven was also reported to have said that "Known Space should be seen as a possible future history told by people that may or may not have all their facts right."
The author also published an "outline" for a story which would "destroy" the Known Space Series (or more precisely, reveal much of the Known Space background to be an in-universe hoax), in an article entitled "Down in Flames". Although the article is written as though Niven intended to write the story, he later wrote that the article was only an elaborate joke, and he never intended to write such a novel. The article itself notes that the outline was made obsolete by the publication of "Ringworld". "Down in Flames" was a result of a conversation between Norman Spinrad and Niven in 1968, but at the time of its first publication in 1977 some of the concepts were invalidated by Niven's writings between '68 and '77. (A further edited version of the outline was published in "N-Space" in 1990.)

</doc>
<doc id="18225" url="https://en.wikipedia.org/wiki?curid=18225" title="LeRoy Homer, Jr.">
LeRoy Homer, Jr.

LeRoy Wilton Homer, Jr. (August 27, 1965September 11, 2001) was the First Officer of United Airlines Flight 93, which was hijacked as part of the September 11 attacks in 2001, and crashed into a field near Shanksville, Pennsylvania, killing all 37 passengers and seven crew members.
Biography.
Homer, son of a West German and an American soldier who was stationed in West Germany, grew up on Long Island in New York where he always dreamed of flying. As a child, he assembled model airplanes, collected aviation memorabilia and read books on aviation. He was 15 years old when he started flight instruction in a Cessna 152. Working part-time jobs after school to pay for flying lessons, he completed his first solo trip at the age of 16 and obtained his private pilot's certificate in 1983.
Homer was graduated from Ss. Cyril and Methodius School in 1979 and St. John the Baptist Diocesan High School in 1983.
He entered the United States Air Force Academy as a member of the class of 1987. As an upperclassman, he was a member of Cadet Squadron 31. He graduated on May 27, 1987, and was commissioned as a second lieutenant in the U.S. Air Force.
After completing his USAF pilot training in 1988, he was assigned to McGuire Air Force Base in New Jersey, flying a Lockheed C-141 Starlifter. While on active duty, he served in the Gulf War and later supported operations in Somalia. He received many commendations, awards and medals during his military career. In 1993, he was named the Twenty-First Air Force "Aircrew Instructor of the Year". Homer achieved the rank of captain before his honorable discharge from active duty in 1995 and his acceptance of a Reserve Commission in order to continue his career as an Air Force officer.
Homer continued his military career as a member of the U.S. Air Force Reserve, initially as a C-141 instructor pilot with the 356th Airlift Squadron at Wright-Patterson Air Force Base in Ohio, then subsequently as an Academy Liaison Officer, recruiting potential candidates for both the Air Force Academy and the Air Force Reserve Officer Training Corps. During his time in the Air Force Reserve, he achieved the rank of major.
He continued his flying career by joining United Airlines in May 1995. His first assignment was Second Officer on the Boeing 727. He then upgraded to First Officer on the Boeing 757/Boeing 767 in 1996, where he remained until September 11, 2001.
He married Melodie on May 24, 1998, and his first child, Laurel, was born in late November 2000. They resided together in Marlton, New Jersey.
September 11 attacks.
On September 11, 2001, Homer was flying with Captain Jason M. Dahl on United Airlines Flight 93 from Newark, New Jersey, to San Francisco. The plane was hijacked by four al-Qaeda terrorists as part of the September 11 attacks. Homer was stabbed to death by the hijackers, while Jason Dahl remained until he could no longer be heard on the cockpit voice recorder. While struggling for control of the plane after the hijackers had breached the cockpit, Dahl managed to transmit to the ground twice, screaming; "Mayday! Mayday! Mayday! Get out of here!" (Cleveland central ATC audio tramission). After learning of the earlier crashes at the World Trade Center and the Pentagon, the crew and passengers attempted to foil the hijacking and reclaim the aircraft. During this struggle, the hijackers were not able to disengage the autopilot. Realizing they needed help, they were heard to say "bring back the pilot" (CVR transcripts). However, given the uprising of crew and passengers, and knowing they would not make it to their intended target, which was the US Capitol, they instead chose to crash the plane into a field near Shanksville, Pennsylvania.
Homer received many awards and citations posthumously, including honorary membership in the historic Tuskegee Airmen; the Congress of Racial Equality's Dr. Martin Luther King, Jr. Award; the Southern Christian Leadership Conference Drum Major for Justice Award; and the Westchester County Trailblazer Award.
He is survived by his wife Melodie and his daughter Laurel, along with his mother, seven sisters, his brother, and other family.
At the National 9/11 Memorial, Homer, Jr. is memorialized at the South Pool, on Panel S-67, along with other crew and passengers on Flight 93.

</doc>
<doc id="18227" url="https://en.wikipedia.org/wiki?curid=18227" title="LGB">
LGB

LGB may refer to:

</doc>
<doc id="18230" url="https://en.wikipedia.org/wiki?curid=18230" title="La Jetée">
La Jetée

La Jetée () ("The Jetty," here referring to an outdoor viewing pier at an airport), is a 1962 French science fiction featurette by Chris Marker. Constructed almost entirely from still photos, it tells the story of a post-nuclear war experiment in time travel. It is 28 minutes long and shot in black and white. It won the Prix Jean Vigo for short film.
The 1995 science fiction film "12 Monkeys" was inspired by and borrows several concepts directly from "La Jetée".
Plot summary.
A man (Davos Hanich) is a prisoner in the aftermath of World War III in post-apocalyptic Paris where survivors live underground in the "Palais de Chaillot" galleries. Scientists research time travel, hoping to send test subjects to different time periods "to call past and future to the rescue of the present". They have difficulty finding subjects who can mentally withstand the shock of time travel. The scientists eventually settle upon the prisoner; his key to the past is a vague but obsessive memory from his pre-war childhood of a woman (Hélène Chatelain) he had seen on the observation platform ("the jetty") at Orly Airport shortly before witnessing a startling incident there. He had not understood exactly what happened but knew he had seen a man die.
After several attempts, he reaches the pre-war period. He meets the woman from his memory, and they develop a romantic relationship. After his successful passages to the past, the experimenters attempt to send him into the far future. In a brief meeting with the technologically advanced people of the future, he is given a power unit sufficient to regenerate his own destroyed society.
Upon his return, with his mission accomplished, he discerns that he is to be executed by his jailers. He is contacted by the people of the future, who offer to help him escape to their time permanently; but he asks instead to be returned to the pre-war time of his childhood, hoping to find the woman again. He is returned to the past, placed on the jetty at the airport, and it occurs to him that the child version of himself is probably also there at the same time. But he is more concerned with locating the woman and he quickly spots her. However, as he rushes to her, he notices an agent of his jailers who has followed him and realizes the agent is about to kill him. In his final moments, he comes to understand that the incident he witnessed as a child, which has haunted him ever since, was his own death.
Interpretation.
Carol Mavor, in a book on postwar French fiction, "Black and Blue", describes "La Jetée" as taking "place in a no-place (u-topia) in no-time (u-chronia)" which she connects to the time and place of the fairy tale. She goes on by saying "even the sound of the title resonates with the fairy-tale surprise of finding oneself in another world: La Jetée evokes 'là j'étais' (there I was)". By "u-topia", Mavor does not refer to "utopia" as the word is commonly; she also describes an ambiguity of dystopia/utopia in the film, separately: "It is dystopia with the hope of utopia, or is it utopia cut by the threat of dystopia."
Tor Books blogger Jake Hinkson summed up his interpretation in the title of an essay about the film, "There's No Escape Out of Time". He elaborated: Hinkson also addresses the symbolic use of imagery: "The Man is blindfolded with some kind of padded device and he sees images. The Man is chosen for this assignment because ... he has maintained a sharp mind because of his attachment to certain images. Thus a film told through the use of still photos becomes about looking at images." He further observes that Marker himself did not refer to "La Jetée" as a film, but as photo novel.
The "FilmsLie" blog suggests that: 
Production.
"La Jetée" is constructed almost entirely from optically printed photographs playing out as a photomontage of varying rhythm. It contains only one brief shot (of the woman mentioned above sleeping and suddenly waking up) originating on a motion-picture camera, this due to the fact that Marker could only afford to hire one for an afternoon. The stills were taken with a Pentax Spotmatic and the motion-picture segment was shot with a 35mm Arriflex. The film has no dialogue aside from small sections of muttering in German and people talking in an airport terminal. The story is told by a voice-over narrator. The scene in which the hero and the woman look at a cut-away trunk of a tree is a reference to Alfred Hitchcock's 1958 film "Vertigo" which Marker also references in his 1983 film "Sans soleil".
Influence and legacy.
Terry Gilliam's "12 Monkeys" (1995) was inspired by and takes several concepts directly from "La Jetée" (acknowledging this debt in the opening credits). In 2015, the SyFy Channel released a television show also titled "12 Monkeys" that is "based on "La Jetée"" (as by the closing credits). In 1996, Zone Books released a book which reproduced the film's original images along with the script in both English and French; re-released in 2008, it is now out of print. The 2003 short film, "La puppé", is both an homage to and a parody of "La Jetée". The video for Sigue Sigue Sputnik's 1989 single "Dancerama" is also an homage to "La Jetée". The film is one of the influences in the video for David Bowie's "Jump They Say" (1993). The music video for Isis's "In Fiction", from 2004's "Panopticon", drew comparisons with "La Jetée". The song "Last Night at the Jetty" by Panda Bear has lyrics inspired by the themes of the film.
"The Time Traveler's Wife" (2009) also takes inspiration in the relationship between the woman and the time traveller. In 2010, "Time" ranked "La Jetée" first in its list of "Top 10 time-travel movies". Kode9 (music, script) in collaboration with Ms. Haptic (narration, script), Marcel Weber (aka MFO) (images, script) and Lucy Benson (images, script) created an homage to "La Jetée" in 2011, for the Unsound Festival. The plot of the homage centers around the "woman" instead of the "man" and is a "reimagining" rather than a "remix" in that it features a completely new, original script that further develops the narrative whilst remaining true to the original plot. The two stories function in harmony with one another. The images and music of "Her Ghost" are almost exclusively sourced from the original film, however they are significantly reworked so as to create an original piece. A live performance of "Her Ghost" was part of the Chris Marker retrospective at Centre Pompidou in Paris 2013. In 2012, in correspondence with the Sight & Sound Poll, the British Film Institute deemed "La Jetée" as the 50th greatest film of all time.
Home media release.
In Region 2, the film is available with English subtitles in the "La Jetée/Sans soleil" digipack released by Arte Video. In Region 1, the Criterion Collection has released a "La Jetée/Sans soleil" combination DVD / Blu-ray, which features the option of hearing the English or French narration.

</doc>
<doc id="18232" url="https://en.wikipedia.org/wiki?curid=18232" title="Little penguin">
Little penguin

The little penguin ("Eudyptula minor") is the smallest species of penguin. It grows to an average of in height and in length, though specific measurements vary by subspecies. It is found on the coastlines of southern Australia and New Zealand, with possible records from Chile. In Australia, they are often called fairy penguins because of their small size. In New Zealand, they are more commonly known as little blue penguins or blue penguins owing to their slate-blue plumage. They are also known by their Māori name: kororā.
Taxonomy.
The little penguin was first described by German naturalist Johann Reinhold Forster in 1781. There are several subspecies but a precise classification of these is still a matter of dispute. The holotypes of the subspecies "Eudyptula minor variabilis" and "Eudyptula minor chathamensis" are in the collection of the Museum of New Zealand Te Papa Tongarewa. The white-flippered penguin is sometimes considered a subspecies, sometimes a distinct species, and sometimes a morph. As the Australian and Otago (southeastern coast of South Island) little penguins may be a distinct species to which the specific name "minor" would apply, the white-flippered birds indeed belong to a distinct species, although not exactly as originally assumed.
Mitochondrial and nuclear DNA evidence suggests the split between "Eudyptula" and "Spheniscus" occurred around 25 million years ago, with the ancestors of the white-flippered and little penguins diverging about 2.7 million years ago.
Description.
Like those of all penguins, the little penguin's wings have developed into flippers used for swimming. The little penguin typically grows to between 30 and 33 cm (12 to 13 inches) tall and usually weighs about 1.5 kilogram on average (3.3 pounds). The head and upperparts are blue in colour, with slate-grey ear coverts fading to white underneath, from the chin to the belly. Their flippers are blue in colour. The dark grey-black beak is 3–4 cm long, the irises pale silvery- or bluish-grey or hazel, and the feet pink above with black soles and webbing. An immature individual will have a shorter bill and lighter upperparts.
Like most seabirds, they have a long lifespan. The average for the species is 6.5 years, but flipper ringing experiments show in very exceptional cases up to 25 years in captivity.
Distribution and habitat.
The little penguin breeds along the entire coastline of New Zealand, the Chatham Islands, and southern Australia (including roughly 20,000 pairs on Babel Island). Australian colonies exist in New South Wales, Victoria, Tasmania, South Australia and Western Australia. Little penguins have also been reported from Chile (where they are known as Pingüino pequeño or Pingüino azul) (Isla Chañaral 1996, Playa de Santo Domingo, San Antonio, 16 March 1997) and South Africa, but it is unclear whether these birds were vagrants. As new colonies continue to be discovered, rough estimates of the world population are around 350,000-600,000 animals.
New Zealand.
Overall, little penguin populations in New Zealand have been decreasing. Some colonies have gone extinct and others continue to be at risk. Some new colonies have been established in urban areas. The species is not considered endangered in New Zealand, with the exception of the white-flippered subspecies found only on Banks Peninsula and nearby Motunau Island. Since the 1960s, the mainland population has declined by 60-70%; though there has been a small increase on Motunau Island.
Australia.
Australian little penguin colonies primarily exist on offshore islands where they are protected from feral terrestrial predators and human disturbance. Colonies are found from Port Stephens in northern New South Wales around the southern coast to Fremantle, Western Australia.
New South Wales.
An endangered population of little penguins exists at Manly, North Sydney Harbor. The population is protected under the NSW Threatened Species Conservation Act 1995 and has been managed in accordance with a Recovery Plan since the year 2000. The population once numbered in the hundreds, but has decreased to around 60 pairs of birds. The decline is believed to be mainly due to loss of suitable habitat, attacks by foxes and dogs and disturbance at nesting sites.
The largest colony in New South Wales is on Montague Island. Up to 8000 breeding pairs are known to nest there each year.
Jervis Bay Territory.
A population of approximately 5,000 breeding pairs exists on Bowen Island. The colony has increased from 500 pairs in 1979 and 1500 pairs in 1985. During this time, the island was privately leased. The island was vacated in 1986 and is currently controlled by the federal government.
South Australia.
In South Australia, many little penguin colony declines have been identified across the state. In some cases, colonies have declined to extinction (including the Neptune Islands, West Island, Wright Island, Pullen Island and several colonies on western Kangaroo Island), while others have declined from thousands of animals to few (Granite Island and Kingscote). A report released in 2011 presented evidence supporting the listing of the statewide population or the more closely monitored sub-population from St. Vincent's Gulf as Vulnerable under South Australia's "National Parks & Wildlife Act 1972". As of 2014, the little penguin is not listed as a species of conservation concern, despite ongoing declines at many colonies.
Tasmania.
Tasmanian little penguin population estimates range from 110,000–190,000 breeding pairs of which less than 5% are found on mainland Tasmania. Ever-increasing human pressure is predicted to result in the extinction of colonies on mainland Tasmania.
Victoria.
The largest colony of little penguins in Victoria is located at Phillip Island, where the nightly 'parade' of penguins across Summerland Beach has been a major tourist destination, and more recently a major conservation effort, since the 1920s. Phillip Island is home to an estimated 32,000 breeding pairs (70,000 birds). Little penguins can also be seen in the vicinity of the St Kilda, Victoria pier and breakwater. The breakwater is home to a colony of little penguins which have been the subject of a conservation study since 1986.
Little penguin habitats also exist at a number of other locations, including London Arch and The Twelve Apostles along the Great Ocean Road, Wilson's Promontory and Gabo Island.
Western Australia.
The largest colony of little penguins in Western Australia is believed to be located on Penguin Island. An estimated 1,000 pairs nest there during the winter. Penguins are also known to nest on Garden Island and Carnac Island which lie north of Penguin Island. Many islands along Western Australia's southern coast are likely to support little penguin colonies, though the status of these populations are largely unknown. An account of little penguins on Bellinger Island published in 1928 numbered them in their thousands. Visiting naturalists in November 1986 estimated the colony at 20 breeding pairs. The account named another substantial colony 12 miles from Bellinger Island and the same distance from Cape Pasley. Little penguins are known to breed on some islands of the Recherche Archipelago, including Woody Island where day-tripping tourists can view the animals. A penguin colony exists on Mistaken Island in King George Sound near Albany. Historical accounts of little penguins on Newdegate Island at the mouth of Deep River and on Breaksea Island near Torbay also exist.
Threats.
Culling.
In 1930 in Tasmania, it was believed that little penguins were competing with mutton-birds, which were being commercially exploited. An "open season" in which penguins would be permitted to be killed was planned in response to requests from members of the mutton-birding industry.
Human development.
The impacts of human habitation in proximity to little penguin colonies include collisions with vehicles, direct harassment, burning and clearing of vegetation and housing development.
Human interference.
Penguins are vulnerable to interference by humans, especially while they are ashore during molt or nesting periods. In 1949, penguins on Phillip Island in Victoria became victims of human cruelty, with some kicked and others thrown off a cliff and shot at. These acts of cruelty prompted the state government to fence off the rookeries. More recent examples of destructive interference can be found at Granite island, where in 1994 a penguin chick was taken from a burrow and abandoned on the mainland, a burrow containing penguin chicks was trampled and litter was discarded down active burrows. In 1998, two incidents in six months resulted in penguin deaths. The latter, which occurred in May, saw 13 penguins apparently kicked to death. In March 2016, two little penguins were kicked and attacked by humans during separate incidents at the St Kilda colony, Victoria.
Interactions with fishing.
Some little penguins are drowned when amateur fishermen set gill nets near penguin colonies. Discarded fishing line can also present an entanglement risk and contact can result in physical injury, reduced mobility or drowning. In 2014, a group of 25 dead little penguins were found on Altona Beach in Victoria. Necropsies concluded that the animals had died after becoming entangled in net fishing equipment, prompting community calls for a ban on net fishing in Port Phillip Bay.
In the 20th century, little penguins were intentionally shot or caught by fishermen to use as bait in pots for catching crayfish (Southern rock lobster) or by line fishermen. Colonies were targeted for this purpose in various parts of Tasmania including Bruny Island and West Island, South Australia.
Oil spills.
Oil spills can be lethal for penguins and other sea birds. Oil is toxic when ingested and penguins' buoyancy and the insulative quality of their plumage is damaged by contact with oil. Little penguin populations have been significantly affected during two major oil spills at sea: the Iron Baron oil spill off Tasmania's north coast in 1995 and the grounding of the Rena off New Zealand in 2011.
Plastic pollution.
Plastics are swallowed by little penguins, who mistake them for prey items. They present a choking hazard and also occupying space in the animal's stomach. Indigestible material in a penguin's stomach can contribute to malnutrition or starvation. Other larger plastic items, such as bottle packaging rings can become entangled around penguins' necks, affecting their mobility.
Predation.
Threats to little penguin populations include predation (both adult and nest predation) by a variety of terrestrial animals including cats, dogs, rats, foxes, large reptiles, ferrets and stoats. Due to their diminutive size and the introduction of new predators, some colonies have been reduced in size by as much as 98% in just a few years, such as the small colony on Middle Island, near Warrnambool, Victoria, which was reduced from approximately 600 penguins in 2001 to less than 10 in 2005. Because of this threat of colony collapse, conservationists pioneered an experimental technique using Maremma Sheepdogs to protect the colony and fend off would-be predators.
Uncontrolled dogs or feral cats can have sudden and severe impacts on penguin colonies (more than the penguin's natural predators) and may kill many individuals. Examples of colonies affected by dog attacks include Manly, New South Wales, Penneshaw, South Australia, Red Chapel Beach, Tasmania, Penguin Island, Western Australia and Little Kaiteriteri Beach, New Zealand.
A suspected stoat or ferret attack at Doctor's Point near Dunedin, New Zealand claimed the lives of 29 little blue penguins in November 2014.
A fox was believed responsible for the deaths of 53 little penguins over several nights on Granite Island in 1994. In June 2015, 26 penguins from the Manly colony were killed in 11 days. A fox believed responsible was eventually shot in the area and an autopsy is expected to prove or disprove its involvement. In November 2015 a fox entered the little penguin enclosure at the Melbourne Zoo and killed 14 penguins, prompting measures to further "fox proof" the enclosure.
Prey availability.
Variation in prey abundance and distribution from year to year causes young birds to be washed up dead from starvation or in weak condition.
Predator management.
Little penguins in the wild are sometimes preyed upon by New Zealand fur seals. A study conducted by researchers from the South Australian Research and Development Institute found that roughly 40 percent of seal droppings in South Australia's Granite Island area contained little penguin remains.
They are also preyed upon by white-bellied sea eagles. These large birds-of-prey are endangered in South Australia and not considered a threat to colony viability.
On land, little penguins are vulnerable to attack from domestic and feral dogs and cats. Attacks on Kangaroo Island, at Manly in Tasmania and in New Zealand have resulted in significant impacts to several populations. Management strategies to mitigate the risk of attack include establishing dog-free zones near penguin colonies and introducing regulations to ensure dogs to remain on leashes at all times in adjacent areas.
Little penguins on Middle Island off Warrnambool, Victoria were subject to heavy predation by foxes, which were able to reach the island at low tide by a tidal sand bridge. The deployment of Maremma sheepdogs to protect the penguin colony has deterred the foxes and enabled the penguin population to rebound.
This is in addition to the support from groups of volunteers who work to protect the penguins from attack at night. The first Maremma sheepdog to prove the concept was Oddball, whose story inspired a feature film of the same name. The film "Oddball" is scheduled for release in 2015. In December 2015, the BBC reported, "The current dogs patrolling Middle Island are Eudy and Tula, named after the scientific term for the fairy penguin: Eudyptula. They are the sixth and seventh dogs to be used and a new puppy is being trained up [...] to start work in 2016.
In Sydney, snipers have been deployed to protect a colony of little penguins. This effort is in addition to support from local volunteers who work to protect the penguins from attack at night.
Behaviour.
Little penguins are diurnal and like many penguin species, spend the largest part of their day swimming and foraging at sea. During the breeding and chick rearing seasons, little penguins will leave their nest at sunrise, forage for food throughout the day and return to their nests just after dusk. Thus, sunlight, moonlight and artificial lights can affect the behaviour of attendance to the colony. Little penguins preen their feathers to keep them waterproof. They do this by rubbing a tiny drop of oil onto every feather from a special gland above the tail.
Diet.
These birds feed by hunting small clupeoid fish, cephalopods and crustaceans, for which they travel and dive quite extensively. In New Zealand, important prey items include arrow squid, slender sprat, Graham's gudgeon, red cod and ahuru. Since the year 2000, the little penguins of Port Phillip Bay's diet has consisted mainly of barracouta, anchovy, and arrow squid. Sardines previously featured more prominently in southern Australian little penguin diets prior to mass sardine mortality events of the 1990s. These mass mortality events affected sardine stocks over 5,000 kilometres of coastline.
They are generally inshore feeders. The use of data loggers has provided information of the diving behaviour of little penguins. 50% of their dives go no deeper than 2 m and the mean diving time is 21 seconds. Yet, they are able to dive as deep as 20 m and remained submerged as long as 60 seconds. Little penguins play an important role in the ecosystem as not only a predator to parasites but also a host. Recent studies have shown a new species of feather mite that feeds on the preening oil on the feathers of the penguin.
Reproduction.
Little penguins mature at different ages. The female matures at 2 years old. The male, however, matures at 3 years old. Little penguins only remain faithful to their partner in breeding seasons and whilst hatching eggs. At other times of the year they do tend to swap burrows. They exhibit site fidelity to their nesting colonies and nesting sites over successive years.
Little penguins can breed as isolated pairs, in colonies, or semi-colonially. Nests are situated close to the sea in burrows excavated by the birds or other species, or in caves, rock crevices, under logs or in or under a variety of man-made structures including nest boxes, pipes, stacks of wood or timber, and buildings. They are monogamous within a breeding season, and share incubation and chick rearing duties. They are the only species of penguin capable of producing more than one clutch of eggs per breeding season, but few populations do so.
The timing of breeding seasons varies across the species' range. Eastern Australian populations (including at Phillip Island, Victoria) lay their eggs from July through December. In South Australia's Gulf St. Vincent, eggs are laid between April and October.
The one or two white or lightly mottled brown eggs are laid with rarer second (or even third) clutches following. Incubation takes up to 36 days. Chicks are brooded for 18–38 days, and fledge after 7–8 weeks. On Australia's east coast, chicks are raised from August through March. In Gulf St. Vincent, chicks are raised from June through November.
Little penguins typically return to their colonies to feed their chicks at dusk. The birds will tend to come ashore in small groups to provide some defence against predators which might pick off individuals one by one. In Australia, the strongest colonies are usually on cat-free and fox-free islands. However, the population on Granite Island (which is a fox, cat and dog-free island) has been severely depleted, from around 2000 penguins in 2001 down to 146 in 2009.
Relationship with humans.
Little penguins have long been a curiosity to humans, and to children in particular. Captive animals are often exhibited in zoos. Historically, the animals have also been used as bait to catch Southern rock lobster, captured for amusement and eaten by ship-wrecked sailors and castaways to avoid starvation. They have also been the victims of malicious attacks by humans and incidental bycatch by fishermen using nets. The sites of many breeding colonies have developed into tourist destinations which provide an economic boost for coastal and island communities in Australia and New Zealand. These locations also often provide facilities and volunteer staff to support population surveys, habitat improvement works and little penguin research programs.
Nocturnal Tours.
South of Perth, Western Australia, visitors to Penguin Island are able to view penguins in a natural environment. Less than one hour from the centre of the city, it is possible to see little penguins in all months, including visiting sensitive areas where they remain on land for extended periods for the purposes of moulting.
At Phillip Island, Victoria, a viewing area has been established at the Phillip Island Nature Park to allow visitors to view the nightly "penguin parade". Lights and concrete stands have been erected to allow visitors to see but not photograph or film the birds (this is because it can blind or scare them) interacting in their colony.
In Otago, New Zealand town of Oamaru, where visitors may view the birds returning to their colony at dusk. In Oamaru it is not uncommon for penguins to nest within the cellars and foundations of local shorefront properties, especially in the old historic precinct of the town. More recently, little penguin viewing facilities have been established at Pilots Beach, Otago Peninsula and Dunedin in New Zealand. Here visitors are guided by volunteer wardens to watch penguins returning to their burrows at dusk.
Visitors to Kangaroo Island, South Australia, have nightly opportunities to observe penguins at the Kangaroo Island Marine Centre in Kingscote and at the Penneshaw Penguin Centre. Granite Island at Victor Harbor, South Australia continues to offer guided tours at dusk, despite its colony dropping from thousands in the 1990s to dozens in 2014. There is also a Penguin Centre located on the island where the penguins can be viewed in captivity.
In Bicheno, Tasmania, evening penguin viewing tours are offered by a local tour operator at a rookery on private land.
Habitat restoration.
Several efforts have been made to improve breeding sites on Kangaroo Island, including augmenting habitat with artificial burrows and revegetation work. The Knox School's habitat restoration efforts were filmed and broadcast in 2008 by "Totally Wild".
Zoological exhibits.
Australia.
Exhibits currently exist at the Adelaide Zoo, Melbourne Zoo, the National Zoo & Aquarium in Canberra, Perth Zoo and the Taronga Zoo in Sydney.
A colony of little penguins is also exhibited at Sea World, on the Gold Coast, Queensland, Australia. In early March, 2007, 25 of the 37 penguins died from an unknown toxin following a change of gravel in their enclosure. It is still not known what caused the deaths of the little penguins, and it was decided not to return the 12 surviving penguins to the same enclosure in which the penguins became ill. A new enclosure for the little penguin colony was opened at Sea World in 2008.
New Zealand.
Exhibits currently exist at the Auckland Zoo, the Wellington Zoo and the National Aquarium of New Zealand.
North America.
A colony of little blue penguins exists at the New England Aquarium in Boston, Massachusetts. The penguins are one of three species on exhibit and are part of the Association of Zoos and Aquariums' Species Survival Plan for little blue penguins.
Mascots & logos.
Linus Torvalds, the original creator of Linux (a popular operating system kernel), was once pecked by a little penguin while on holiday in Australia. Reportedly, this encounter encouraged Torvalds to select Tux as the official Linux mascot.
A Linux kernel programming challenge called the Eudyptula Challenge has attracted thousands of persons; its creator(s) use the name "Little Penguin".
Penny the Little Penguin was the mascot for the 2007 FINA World Swimming Championships held in Melbourne, Victoria.

</doc>
<doc id="18233" url="https://en.wikipedia.org/wiki?curid=18233" title="Lake Balaton">
Lake Balaton

Lake Balaton (German: "Plattensee") is a freshwater lake in the Transdanubian region of Hungary. It is the largest lake in Central Europe, and one of the region's foremost tourist destinations. The Zala River provides the largest inflow of water to the lake, and the canalised Sió is the only outflow.
The mountainous region of the northern shore is known both for its historic character and as a major wine region, while the flat southern shore is known for its resort towns. Balatonfüred and Hévíz developed early as resorts for the wealthy, but it was not until the late 19th century when landowners, ruined by "Phylloxera" attacking their grape vines, began building summer homes to rent out to the burgeoning middle classes.
Name.
In Hungarian, the lake is known simply as "Balaton". It was called "lacus Pelsodis" or "Pelso" by the Romans. The name is Illyrian, and therefore Indo-European (cf. Czech "pleso" ‘sinkhole, deep end of a lake’), later replaced by the Slavic *"bolto" (cf. Serbo-Croatian "blȁto", Czech "bláto") meaning 'mud, swamp' (from earlier Proto-Slavic "boltьno", , ). Slavic prince Pribina began to build in January 846 a fortress as his seat of power and several churches in the region of Lake Balaton, in a territory of modern Zalavár surrounded by forests and swamps along the river Zala. His well fortified castle and capital of Balaton Principality that became known as "Blatnohrad" or "Moosburg" ("Swamp Fortress") served as a bulwark both against the Bulgarians and the Moravians.
The German name for the lake is '. It is unlikely that the Germans named the lake so for being shallow since the adjective ' is a Greek loanword that was borrowed via French and entered the general German vocabulary in the 17th century. It is also noteworthy that the average depth of Balaton (3.2m) is not extraordinary for the area (cf. the average depth of the neighbouring Neusiedler See, which is roughly 1m).
Climate.
Lake Balaton affects the local area precipitation every year. The area receives approximately more precipitation than most of Hungary, resulting in more cloudy days and less extreme temperatures. The lake's surface freezes during winters. The microclimate around Lake Balaton has also made the region ideal for viniculture. The lake, acting as a mirror, greatly increases the amount of sunlight that the grapevines of the region receive. The Mediterranean-like climate, combined with the soil (containing volcanic rock), has made the region notable for its production of wines since the Roman period two thousand years ago.
History.
While a few settlements on Lake Balaton, including Balatonfüred and Hévíz, have long been resort centres for the Hungarian aristocracy, it was only in the late 19th century that the Hungarian middle class began to visit the lake. The construction of railways in 1861 and 1909 increased tourism substantially, but the post-war boom of the 1950s was much larger.
The last major German offensive of World War II, Operation Frühlingserwachen, was conducted in the region of Lake Balaton in March 1945, being referred to as "the Lake Balaton Offensive" in many British histories of the war. The battle was a German attack by Sepp Dietrich's Sixth Panzer Army and the Hungarian Third Army between 6 March and 16 March 1945, and in the end, resulted in a Red Army victory. Several Ilyushin Il-2 wrecks have been pulled out of the lake after having been shot down during the later months of the war.
During the 1960s and 1970s, Balaton became a major tourist destination for ordinary working Hungarians and especially for subsidised holiday excursions for union members. It also attracted many East Germans and other residents of the Eastern Bloc. West Germans could also visit, making Balaton a common meeting place for families and friends separated by the Berlin Wall until 1989. The collapse of Communism after 1991 and the dismantling of the unions saw the gradual but steady reduction in numbers of lower-paid Hungarian visitors.
Tourism.
The major resorts around the lake are Siófok, Keszthely, and Balatonfüred. Zamárdi, another resort town on the southern shore, has been the site of Balaton Sound, a notable electronic music festival since 2007. Balatonkenese has hosted numerous traditional gastronomic events. Siófok is known for attracting young people to it because of its large clubs. Keszthely is the site of the Festetics Palace and Balatonfüred is a historical bathing town which hosts the annual Anna Ball.
The peak tourist season extends from June until the end of August. The average water temperature during the summer is 25 °C, which makes bathing and swimming popular on the lake. Most of the beaches consist of either grass, rocks, or the silty sand that also makes up most of the bottom of the lake. Many resorts have artificial sandy beaches and all beaches have step access to the water. Other tourist attractions include sailing, fishing, and other water sports, as well as visiting the countryside and hills, wineries on the north coast, and nightlife on the south shore. The Tihany Peninsula is a historical district. Badacsony is a volcanic mountain and wine-growing region as well as a lakeside resort. The lake is almost completely surrounded by separated bike lanes to facilitate bicycle tourism.
Although the peak season at the lake is the summer, Balaton is also frequented during the winter, when visitors go ice-fishing or even skate, sledge, or ice-sail on the lake if it freezes over.
Sármellék International Airport provides air service to Balaton (although most service is only seasonal).
Other resort towns include: Balatonalmádi, Balatonboglár, Balatonlelle, Fonyód and Vonyarcvashegy.
Towns and villages.
North shore.
From east to west:
Balatonfőkajár - Balatonakarattya - Balatonkenese - Balatonfűzfő - Balatonalmádi - Alsóörs - Paloznak - Csopak - Balatonarács - Balatonfüred - Tihany - Aszófő - Örvényes - Balatonudvari - Fövenyes - Balatonakali - Zánka - Balatonszepezd - Szepezdfürdő - Révfülöp - Pálköve - Ábrahámhegy - Balatonrendes - Badacsonytomaj - Badacsony - Badacsonytördemic - Szigliget - Balatonederics - Balatongyörök - Vonyarcvashegy - Gyenesdiás - Keszthely
South shore.
From east to west:
Balatonakarattya - Balatonaliga - Balatonvilágos - Sóstó - Szabadifürdő - Siófok - Széplak - Zamárdi - Szántód - Balatonföldvár - Balatonszárszó - Balatonszemes - Balatonlelle - Balatonboglár - Fonyód - Bélatelep - Balatonfenyves - Balatonmáriafürdő - Balatonkeresztúr - Balatonberény - Fenékpuszta

</doc>
<doc id="18234" url="https://en.wikipedia.org/wiki?curid=18234" title="Libro de los juegos">
Libro de los juegos

The Libro de los Juegos, ("Book of games"), or Libro de axedrez, dados e tablas, ("Book of chess, dice and tables", in Old Spanish) was commissioned by Alfonso X of Castile, Galicia and León and completed in his scriptorium in Toledo in 1283, is an exemplary piece of Alfonso’s medieval literary legacy.
The book consists of ninety-seven leaves of parchment, many with color illustrations, and contains 150 miniatures. The text is a treatise that addresses the playing of three games: a game of skill, or chess; a game of chance, or dice; and a third game, backgammon, which combines elements of both skill and chance. The book contains the earliest known description of these games. These games are discussed in the final section of the book at both an astronomical and astrological level. Examining further, the text can also be read as an allegorical initiation tale and as a metaphysical guide for leading a balanced, prudent, and virtuous life. In addition to the didactic, although not overly moralistic, aspect of the text, the manuscript’s illustrations reveal a rich cultural, social, and religious complexity.
It is one of the most important documents for researching the history of board games. The only known original is held in the library of the monastery of San Lorenzo del Escorial near Madrid in Spain. The book is bound in sheepskin and is 40 cm high and 28 cm wide (16 in × 11 in). A 1334 copy is held in the library of the Spanish Royal Academy of History in Madrid.
Background.
Alfonso was likely influenced by his contact with scholars in the Arab world. Unlike many contemporary texts on the topic, he does not engage the games in the text with moralistic arguments; instead, he portrays them in an astrological context. He conceives of gaming as a dichotomy between the intellect and chance. The book is divided into three parts reflecting this: the first on chess (a game purely of abstract strategy), the second on dice (with outcomes controlled strictly by chance), and the last on tables (combining elements of both). The text may have been influenced by Frederick II's text on falconry.
Chess.
The Libro de juegos contains an extensive collection of writings on chess, with over 100 chess problems and variants. Among its more notable entries is a depiction of what Alfonso calls the "ajedrex de los quatro tiempos" ("chess of the four seasons"). This game is a chess variant for four players, described as representing a conflict between the four elements and the four humors. The chessmen are marked correspondingly in green, red, black, and white, and pieces are moved according to the roll of dice. Alfonso also describes a game entitled "astronomical chess", played on a board of seven concentric circles, divided radially into twelve areas, each associated with a constellation of the Zodiac.
Tables.
The book describes the rules for a number of games in the tables family. One notable entry is "todas tablas", which has an identical starting position to modern backgammon and follows the same rules for movement and bearoff. Alfonso also describes a variant played on a board with seven points in each table. Players rolled seven-sided dice to determine the movement of pieces, an example of Alfonso's preference for the number seven.
Art.
The miniatures in the "Libro de juegos" vary between half- and full-page illustrations. The half-page miniatures typically occupy the upper half of a folio, with text explaining the game "problem" solved in the image occupying the bottom half. The back or second (verso) side of Folio 1, in a half-page illustration, depicts the initial stages of the creation of the "Libro de juegos", accompanied by text on the bottom half of the page, and the front or first (recto) side of Folio 2 depicts the transmission of the game of chess from an Indian Philosopher-King to three followers. The full-page illustrations are almost exclusively on the verso side of later folios and are faced by accompanying text on the recto side of the following folio. The significance of the change in miniature size and placement may indicate images of special emphasis, could merely function as a narrative or didactic technique, or could indicate different artisans at work in Alfonso’s scriptorium as the project developed over time.
Having multiple artisans working on the "Libro de juegos" would have been a typical practice for medieval chanceries and scriptoria, where the labor of producing a manuscript was divided amongst individuals of varying capacities, for example the positions of scribe, draftsman, and apprentice cutting pages. But in addition to performing different tasks, various artisans could have labored at the same job, such as the work of illustration in the "Libro de juegos", thereby revealing a variety hands or styles. The "Libro de Juegos" offers such evidence in the difference in size between the half- and full-page illustrations in addition to changes in framing techniques amongst the folios: geometrical frames with embellished corners, architectural frames established by loosely perspectival rooftops and colonnades, and games played under tents. Other stylistic variances are found in figural representation, in facial types, and in a repertoire of different postures assumed by the players in different folios in the manuscript.
For example, in a comparison of two miniatures, found on Folios 53v and 76r, examples of these different styles are apparent, although the trope of a pair of gamers is maintained. In Folio 53v, two men are playing chess, both wearing turbans and robes. Although they may be seated on rugs on the ground, as suggested by the ceramic containers that are placed on or front of the rug near the man on the right side of the board, the figures’ seated positions, which are full frontal with knees bent at right angles, suggests that they are seated on stools or perhaps upholstered benches. The figures’ robes display a Byzantine conservatism, with their modeled three-dimensionality and allusion to a Classical style, yet the iconic hand gestures are reminiscent of a Romanesque energy and theatricality. Although the figures are seated with their knees and torsos facing front, their shoulders and heads rotate in three-quarter profile toward the center of the page, the chess board, and each other. The proximal, inner arm of each player (the arm that is closest to the board) is raised in a speaking gesture; the distal, outside arms of the players are also raised and are bent at the elbows, creating a partial crossing of each player’s torso as the hands lift in speaking gestures. The faces reveal a striking specificity of subtle detail, particular to a limited number of miniatures throughout the "Libro de juegos", perhaps indicative of a particular artist’s hand. These details include full cheeks, realistic wrinkles around the eyes and across the brow, and a red, full-lipped mouth that hints at the Gothic affectations in figural representation coming out of France during the late twelfth and early thirteenth centuries.
The style in the miniature in Folio 76v is markedly different from the style in Folio 53v. In this case, the framed miniature contains two men, perhaps Spanish, with uncovered wavy light brown hair that falls to the jaw line. The men seem young, as the player on the left has no facial hair and his face is unlined. In both folios, both pairs of players are playing backgammon and seem to be well-dressed, although there is no addition of gold detailing to their robes as seen in the wardrobes of aristocratic players in other miniatures. These players are seated on the ground, leaning on pillows that are placed next to a backgammon board. In this miniature, the figure on the left side of the board faces the reader, while the figure on the right leans in to the board with his back to the reader. In other words, each player is leaning on his left elbow, using his right hand to reach across his body to play. In the miniatures of this style, the emphasis seems to be more on the posture of the player than the detail of their faces; this crossed, lounging style is only found in the folios of the "Libro de tablas", the third section of the "Libro de juegos" which explicates the game of backgammon, again perhaps indicative of the work of a particular artist.
Other visual details contemporaneous of Alfonso’s court and social and cultural milieu infuse the "Libro de juegos". Although some of the miniatures are framed by simple rectangles with corners embellished by the golden castles and lions of Castile and León, other are framed by medieval Spanish architectural motifs, including Gothic and Mudéjar arcades of columns and arches. At times, the figural depictions are hierarchical, especially in scenes with representations of Alfonso, where the king is seated on a raised throne while dictating to scribes or meting out punishments to gamblers. Yet a contemporary atmosphere of Spanish "convivencia" is evoked by the inclusion nobility, rogues, vagrants, young and old, men, women, Christian, Muslim, and Jewish characters. Alfonso himself is depicted throughout the text, both as participant and spectator and as an older man and as a younger. The pages are filled with many social classes and ethnicities in various stages of solving the challenges presented by games.
Iconography.
The "Libro de juegos" can be divided into three parts: the games and problems it explores textually, the actual illuminations themselves, and the metaphysical allegories, where an analysis of the texts and illuminations reveals the movements of the macrocosmos of the universe and the microcosmos of man. The symbolism within the medieval illuminations, as explained by the accompanying texts, reveal allusions to medieval literature, art, science, law and philosophy. Intended as a didactic text, the manuscript functions as a manual that documents and explains how and why one plays games ranging from pure, intellectual strategy (chess), to games of pure chance (dice), to games that incorporate both elements (backgammon). Conceivably, Alfonso hoped to elucidate for himself how to better play the game of life, while also providing a teaching tool for others. The game of "ajedrex", or chess, is not the only game explicated in the "Libro de Juegos", but it does occupy the primary position in the text and is given the most attention to detail.
In the thirteenth century, chess had been played in Europe for almost two hundred years, having been introduced into Europe by Arabs around the year 1000. The Arabs had become familiar with the game as early as the eighth century when the Islamic empire conquered Persia, where the game of chess was alleged to have been originated. It is said that a royal advisor had invented the game in order to teach his king prudence without having to overtly correct him. As Arab contact with the West expanded, so too did the game and its various permutations, and by the twelfth century, chess was becoming an entertaining diversion among a growing population of Europeans, including some scholars, clergy, the aristocracy, and the merchant classes; thus, by the thirteenth century, the iconography and symbolism associated with chess would have been accessible and familiar to Alfonso and his literate court culture, who may have had access to the private library, and manuscripts, of Alfonso, including the "Libro de juegos".
The "Libro de juegos" manuscript was a Castilian translation of Arabic texts, which were themselves translations of Persian manuscripts. The visual trope portrayed in the "Libro de juegos" miniatures is seen in other European transcriptions of the Arabic translations, most notably the German Carmina Burana Manuscript: two figures, one on either side of the board, with the board tilted up to reveal to the readers the moves made by the players. The juxtaposition of chess and dice in Arabic tradition, indicating the opposing values of skill (chess) and ignorance (dice), was given a different spin in Alfonso’s manuscript, however. As Alfonso elucidates in the opening section of the "Libro de Juegos", the "Libro de ajedrex" (Book of chess) demonstrates the value of the intellect, the "Libro de los dados" (Book of dice) illustrates that chance has supremacy over pure intellect, and the" Libro de las tablas" (Book of tables) celebrates a conjoined use of both intellect and chance. Further, the iconographic linkage between chess and kingship in the Western tradition continued to evolve and became symbolic of kingly virtues, including skill, prudence, and intelligence.
Significance.
Most of the work accomplished in Alfonso’s scriptorium consisted of translations into the Castilian vernacular from Arabic translations of Greek texts or classical Jewish medicinal texts. As a result, very few original works were produced by this scholar-king, relative to the huge amount of work that was translated under his auspices. This enormous focus on translation was perhaps an attempt by Alfonso to continue the legacy of academic openness in Castile, initiated by Islamic rulers in Córdoba, where the emirates had also employed armies of translators in order to fill their libraries with Arabic translations of classic Greek texts. Alfonso was successful in promoting Castilian society and culture through his emphasis on the use of Galaico-Portuguese and Castilian, in academic, juridical, diplomatic, literary, and historical works. This emphasis, on languages other than Romance languages, also had the effect of reducing the universality of his translated works and original academic writings, as Latin was the "lingua franca" in both Iberia and Europe; yet Alfonso never desisted in his promotion of the Castilian vernacular.
Legacy.
In 1217, Alfonso had captured the Kingdom of Murcia, on the Mediterranean coast south of Valencia, for his father, King Alfonso IX, thereby unifying the kingdoms of Castile and León, bringing together the northern half of the Iberian Peninsula under one Christian throne. With the Christian re-conquest of the Peninsula underway, inroads into Islamic territories were successfully incorporating lands previously held by the "taifa" kingdoms. The arts and sciences prospered in the Kingdom of Castile under the confluence of Latin and Arabic traditions of academic curiosity as Alfonso sponsored scholars, translators, and artists of all three religions of the Book (Jewish, Christian, and Muslim) in his chanceries and scriptoria. Clerical and secular scholars from Europe turned their eyes to Iberian Peninsula as the arts and sciences prospered in an early Spanish "renaissance" under the patronage of Alfonso X, who was continuing the tradition of (relatively) enlightened and tolerant "convivencia" established by the Muslim emirate several centuries earlier.
As an inheritor of a dynamic mixture of Arabic and Latin culture, Alfonso was steeped in the rich heritage of humanistic philosophy, and the production of his "Libro de juegos" reveals the compendium of world views that comprised the eclectic thirteenth century admixture of faith and science. According to this approach, man’s actions could be traced historically and his failures and successes could be studied as lessons to be applied to his future progress. These experiences can be played out and studied as they are lived, or as game moves played and analyzed in the pages of the "Libro de juegos". It is a beautiful and luxurious document, rich not only in workmanship but also in the amount of scholarship of multiple medieval disciplines that are integrated in its pages.

</doc>
<doc id="18236" url="https://en.wikipedia.org/wiki?curid=18236" title="Lithium citrate">
Lithium citrate

Lithium citrate (Li3C6H5O7) is a chemical compound of lithium and citrate that is used as a mood stabilizer in psychiatric treatment of manic states and bipolar disorder. There is extensive pharmacology of lithium, the active component of this salt.
Lithia water contains various lithium salts, including the citrate. An early version of Coca-Cola available in pharmacies' soda fountains called Lithia Coke was a mixture of Coca-Cola syrup and lithia water. The soft drink 7Up was originally named "Bib-Label Lithiated Lemon-Lime Soda" when it was formulated in 1929 because it contained lithium citrate. The beverage was a patent medicine marketed as a cure for hangover. Lithium citrate was removed from 7Up in 1948.

</doc>
<doc id="18237" url="https://en.wikipedia.org/wiki?curid=18237" title="Lithium carbonate">
Lithium carbonate

Lithium carbonate is an inorganic compound, the lithium salt of carbonate with the formula . This white salt is widely used in the processing of metal oxides.
For the treatment of bipolar disorder, it is on the World Health Organization's List of Essential Medicines, the most important medication needed in a basic health system.
Uses.
Lithium carbonate is an important industrial chemical. It forms low-melting fluxes with silica and other materials. Glasses derived from lithium carbonate are useful in ovenware. Lithium carbonate is a common ingredient in both low-fire and high-fire ceramic glaze. Its alkaline properties are conducive to changing the state of metal oxide colorants in glaze particularly red iron oxide (). Cement sets more rapidly when prepared with lithium carbonate, and is useful for tile adhesives. When added to aluminium trifluoride, it forms LiF which gives a superior electrolyte for the processing of aluminium. It is also used in the manufacture of most lithium-ion battery cathodes, which are made of lithium cobalt oxide.
Medical uses.
In 1843, lithium carbonate was used as a new solvent for stones in the bladder. In 1859, some doctors recommended a therapy with lithium salts for a number of ailments, including gout, urinary calculi, rheumatism, mania, depression, and headache. In 1948, John Cade discovered the antimanic effects of lithium ions. This finding led lithium, specifically lithium carbonate, to be used to treat mania associated with bipolar disorder.
Lithium carbonate is used to treat mania, the elevated phase of bipolar disorder. Lithium ions interfere with ion transport processes (see “sodium pump”) that relay and amplify messages carried to the cells of the brain. Mania is associated with irregular increases in protein kinase C (PKC) activity within the brain. Lithium carbonate and sodium valproate, another drug traditionally used to treat the disorder, act in the brain by inhibiting PKC’s activity and help to produce other compounds that also inhibit the PKC. Despite these findings, a great deal remains unknown regarding lithium's mood-controlling properties.
Use of lithium salts exhibit a number of risks and side effects, especially at higher doses. Lithium intoxication affects the central nervous and renal systems and is potentially lethal.
Properties and reactions.
Unlike sodium carbonate, which forms at least three hydrates, lithium carbonate exists only in the anhydrous form. Its solubility in water is low relative to other lithium salts. The isolation of lithium from aqueous extracts of lithium ores capitalizes on this poor solubility. Its apparent solubility increases 10-fold under a mild pressure of carbon dioxide; this effect is due to the formation of the metastable bicarbonate, which is more soluble:
The extraction of lithium carbonate at high pressures of and its precipitation upon depressuring is the basis of the Quebec process.
Lithium carbonate can also be purified by exploiting its diminished solubility in hot water. Thus, heating a saturated aqueous solution causes crystallization of .
Lithium carbonate, and other carbonates of group 1, do not decarboxylate readily. decomposes at temperatures around 1300 °C.
Production.
Lithium is extracted from primarily two sources: pegmatite crystals and lithium salt from brine pools. About 30,000 tons were produced in 1989. It also exists as the rare mineral zabuyelite.
Lithium carbonate is generated by combining lithium peroxide with carbon dioxide. This reaction is the basis of certain air purifiers, e.g., in spacecraft, used to absorb carbon dioxide: 

</doc>
<doc id="18238" url="https://en.wikipedia.org/wiki?curid=18238" title="Lunar Roving Vehicle">
Lunar Roving Vehicle

The Lunar Roving Vehicle (LRV) or "lunar rover" was a battery-powered four-wheeled rover used on the Moon in the last three missions of the American Apollo program (15, 16, and 17) during 1971 and 1972. It was popularly known as the moon buggy, a play on the phrase "dune buggy".
The LRV was transported to the Moon on the Apollo Lunar Module (LM) and, once unpacked on the surface, could carry one or two astronauts, their equipment, and lunar samples. The three LRVs remain on the Moon.
History.
The concept of a lunar rover predated Apollo, with a 1952–1954 series in "Collier's Weekly" magazine by Wernher von Braun and others, "Man Will Conquer Space Soon!" In this, von Braun described a six-week stay on the Moon, featuring 10-ton tractor trailers for moving supplies.
In 1956, Mieczyslaw G. Bekker published two books on land locomotion. At the time, Bekker was a University of Michigan professor and a consultant to the U.S. Army Tank-Automotive Command's Land Locomotion Laboratory. The books provided much of the theoretical base for future lunar vehicle development.
Early lunar mobility studies.
In the February 1964 issue of "Popular Science", von Braun, then director of NASA's Marshall Space Flight Center (MSFC), discussed the need for a lunar surface vehicle, and revealed that studies had been underway at MSFC in conjunction with Lockheed, Bendix, Boeing, General Motors, Brown Engineering, Grumman, and Bell Aerospace.
Beginning in the early 1960s, a series of studies centering on lunar mobility were conducted under MSFC. This began with the Lunar Logistics System (LLS), followed by the Mobility Laboratory (MOLAB), then the Lunar Scientific Survey Module (LSSM), and finally the Mobility Test Article (MTA). In early planning for the Apollo program, it had been assumed that two Saturn V launch vehicles would be used for each lunar mission: one for sending the crew aboard a Lunar Surface Module (LSM) to lunar orbit, landing, and returning, and a second for sending an LSM-Truck (LSM-T) with all of the equipment, supplies, and transport vehicle for use by the crew while on the surface. All of the first MSFC studies were based on this dual-launch assumption, allowing a large, heavy, roving vehicle.
The LLS studies were begun by Grumman and Northrop in the fall of 1962; these were designs for pressurized cabin vehicles with electric motors for each wheel. At about this same time, Bendix and Boeing were conducting internal studies on lunar transportation systems. Bekker, now with General Motors Defense Research Laboratories (GMDRL) at Santa Barbara, California, was completing a study for NASA's Jet Propulsion Laboratory on a small, unmanned lunar roving vehicle for the Surveyor program. Ferenc Pavlics, originally from Hungary, used a wire-mesh design for "resilient wheels," a design that would be followed in future small rovers.
In early 1963, NASA selected MSFC for studies in an Apollo Logistics Support System (ALSS). Following reviews of all earlier efforts, this resulted in a 10-volume report. Included was the need for a pressurized vehicle in the weight range, accommodating two men with their expendables and instruments for traverses up to two weeks in duration. This was called a Mobility Laboratory (MOLAB). In June 1964, MSFC awarded contracts for MOLAB studies and Mobility Test Articles (MTAs) to Bendix and to Boeing, with GMDRL as vehicle technology subcontractor. Bell Aerospace was already under contract for studies of Lunar Flying Vehicles.
Even as ALSS was underway, MSFC was examining a less ambitious surface exploration activity, the Local Scientific Surface Module (LSSM). This would be composed of a fixed, habitable shelter-laboratory (SHELAB) with a small lunar-traversing vehicle (LTV) that could either carry one man or be remotely controlled. LSSM would be carried on an LSM-T, thus still requiring a dual launch. The Propulsion and Vehicle Engineering (P&VE) support contractor Hayes International made a preliminary study of the shelter and vehicle. Also, for the potential need of a MOLAB-like vehicle in future, enlarged lunar explorations, the MOLAB efforts were continued for some time, resulting in several full-scale MTAs.
With pressure from Congress to hold down Apollo costs, Saturn V production was reduced, allowing only a single booster per mission. It would then be necessary for any roving vehicle to be carried on the same Lunar Module as transporting the astronauts. In November 1964, ALSS was put on indefinite hold, but Bendix and Boeing were given study contracts for small rovers under the LSSM program. The name of the Lunar Excursion Module was changed to simply the Lunar Module, indicating that the capability for powered "excursions" away from a lunar-lander base did not yet exist. There could be no SHELAB — the astronauts would work out of the LM — and the LTV accommodating two persons took the name Local Scientific Surface Module (LSSM). MSFC was also examining unmanned robotic rovers that could be controlled from the Earth.
From the start of MSFC, Huntsville, Alabama-based Brown Engineering Company (BECO) had participated in all of its lunar mobility efforts. In 1965, BECO became the prime support contractor for MSFC's P&VE Laboratory. With an urgent need to determine the feasibility of a two-man LSSM, von Braun bypassed the usual procurement process and had P&VE's Advanced Studies Office directly task BECO to design, build, and test a MTA for the vehicle. While Bendix and Boeing would continue with work leading to LSSM concepts and designs, the MTA was vital for MSFC human factors studies involving spacesuit-clad astronauts interfacing with power, telemetry, navigation, and life-support equipment on the rover.
In designing the LSSM MTA, full use was made of all earlier small-rover studies, and commercially available components were incorporated wherever possible. The selection of wheels was of great importance, and almost nothing was known at that time about the lunar surface. The MSFC Space Sciences Laboratory (SSL) was responsible for predicting surface properties. BECO was also the prime support contractor for the SSL and set up a test area to examine a wide variety of wheel-surface conditions. To simulate Pavlics' "resilient wheel," a four-foot-diameter inner tube wrapped with nylon ski rope was used. On the MTA, each wheel had a small electric motor, with overall power provided by standard truck batteries. A roll bar gave protection from overturn accidents.
In early 1966, BECO's MTA became available for examining human factors and other testing. MSFC built a small test track with craters and rock debris where the LSSM and MOLAB MTAs were compared; it was soon obvious that a small rover would be best for the proposed missions. The vehicle was also operated in remote mode to determine characteristics in tests that might be dangerous to the operator, such as acceleration, bounce-height, and turn-over tendency as it traveled at higher speeds and over simulated obstacles. The LSSM performance under one-sixth gravity was obtained through flights on a KC-135A aircraft in a Reduced Gravity parabolic maneuver; among other things, the need for a very soft wheel and suspension combination was shown. Although Pavlics' wire-mesh wheels were not available for the MTA, testing of these was conducted on various soils at the Waterways Experiment Station of the U.S. Army Corps of Engineers at Vicksburg, Mississippi. Later, when wire-mesh wheels were tested on low-g flights, the need for wheel fenders to reduce dust contamination was found. The LSSM MTA was extensively tested at the U.S. Army's Yuma Proving Ground in Arizona, as well as the Army's Aberdeen Proving Ground in Maryland.
Apollo Lunar Roving Vehicle.
During 1965 and 1967, the Summer Conference on Lunar Exploration and Science brought together leading scientists to assess NASA's planning for exploring the Moon and to make recommendations. One of their findings was that the LSSM was critical to a successful program and should be given major attention. At MSFC, von Braun established the Lunar Roving Task team, and in May 1969, NASA selected the Lunar Roving Vehicle (LRV) for use in manned lunar missions and approved the Manned Lunar Rover Vehicle Program as a MSFC hardware development. Saverio F. "Sonny" Morea was named the LRV program manager.
On 11 July 1969, just before the successful Moon landing of Apollo 11, a request for proposal for the final development and building the Apollo LRV was released by MSFC. Boeing, Bendix, Grumman, and Chrysler submitted proposals. Following three months of proposal evaluation and negotiations, Boeing was selected as the Apollo LRV prime contractor on 28 October 1969. Boeing would manage the LRV project under Henry Kudish in Huntsville, Alabama. As a major subcontractor, General Motors' Defense Research Laboratories in Santa Barbara, California, would furnish the mobility system (wheels, motors, and suspension); this effort would be led by Ferenc Pavlics. Boeing in Seattle, Washington, would furnish the electronics and navigation system. Vehicle testing would take place at the Boeing facility in Kent, Washington, and the chassis manufacturing and overall assembly would be at the Boeing facility in Huntsville.
The first cost-plus-incentive-fee contract to Boeing was for $19,000,000 and called for delivery of the first LRV by 1 April 1971. Cost overruns, however, led to a final cost of $38,000,000, which was about the same as NASA's original estimate. Four lunar rovers were built, one each for Apollo missions 15, 16, and 17; and one used for spare parts after the cancellation of further Apollo missions. Other LRV models were built: a static model to assist with human factors design; an engineering model to design and integrate the subsystems; two one-sixth gravity models for testing the deployment mechanism; a one-gravity trainer to give the astronauts instruction in the operation of the rover and allow them to practice driving it; a mass model to test the effect of the rover on the LM structure, balance, and handling; a vibration test unit to study the LRV's durability and handling of launch stresses; and a qualification test unit to study integration of all LRV subsystems. A paper by Savero Morea gives details of the LRV system and its development.
LRVs were used for greater surface mobility during the Apollo J-class missions, "Apollo 15", "Apollo 16", and "Apollo 17". The rover was first used on 31 July 1971, during the Apollo 15 mission. This greatly expanded the range of the lunar explorers. Previous teams of astronauts were restricted to short walking distances around the landing site due to the bulky space suit equipment required to sustain life in the lunar environment. The range, however, was operationally restricted to remain within walking distance of the lunar module, in case the rover broke down at any point. The rovers were designed with a top speed of about , although Eugene Cernan recorded a maximum speed of , giving him the (unofficial) lunar land-speed record.
The LRV was developed in only 17 months and performed all its functions on the Moon with no major anomalies. Scientist-astronaut Harrison Schmitt of Apollo 17 said, "The Lunar Rover proved to be the reliable, safe and flexible lunar exploration vehicle we expected it to be. Without it, the major scientific discoveries of Apollo 15, 16, and 17 would not have been possible; and our current understanding of lunar evolution would not have been possible."
The LRVs experienced some minor problems. The rear fender extension on the Apollo 16 LRV was lost during the mission's second extra-vehicular activity (EVA) at station 8 when John Young bumped into it while going to assist Charles Duke. The dust thrown up from the wheel covered the crew, the console, and the communications equipment. High battery temperatures and resulting high power consumption ensued. No repair attempt was mentioned.
The fender extension on the Apollo 17 LRV broke when accidentally bumped by Eugene Cernan with a hammer handle. Cernan and Schmitt taped the extension back in place, but due to the dusty surfaces, the tape did not adhere and the extension was lost after about one hour of driving, causing the astronauts to be covered with dust. For their second EVA, a replacement "fender" was made with some EVA maps, duct tape, and a pair of clamps from inside the Lunar Module that were nominally intended for the moveable overhead light. This repair was later undone so that the clamps could be taken inside for the return launch. The maps were brought back to Earth and are now on display at the National Air and Space Museum. The abrasion from the dust is evident on some portions of the makeshift fender.
The color TV camera mounted on the front of the LRV could be remotely operated by Mission Control in pan and tilt axes as well as zoom. This allowed far better television coverage of the EVA than the earlier missions. On each mission, at the conclusion of the astronauts' stay on the surface, the commander drove the LRV to a position away from the Lunar Module so that the camera could record the ascent stage launch. The camera operator in Mission Control experienced difficulty in timing the various delays so that the LM ascent stage was in frame through the launch. On the third and final attempt (Apollo 17), the launch and ascent were successfully tracked.
NASA's rovers, left behind, are among the artificial objects on the Moon, as are the Soviet Union's unmanned rovers, Lunokhod 1 and Lunokhod 2.
Features and specifications.
The Apollo Lunar Roving Vehicle was an electric-powered vehicle designed to operate in the low-gravity vacuum of the Moon and to be capable of traversing the lunar surface, allowing the Apollo astronauts to extend the range of their surface extravehicular activities. Three LRVs were used on the Moon, one on Apollo 15 by astronauts David Scott and Jim Irwin, one on Apollo 16 by John Young and Charles Duke, and one on Apollo 17 by Eugene Cernan and Harrison Schmitt. The mission commander served as the driver, occupying the left-hand seat of each LRV. Features are available in papers by Morea, Baker, and Kudish.
Mass and payload.
The Lunar Roving Vehicle had a mass of , and was designed to hold a payload of . This resulted in weights in the approximately one-sixth g on the lunar surface of empty and fully loaded. The frame was long with a wheelbase of . The height of the vehicle was . The frame was made of 2219 aluminium alloy tubing welded assemblies and consisted of a three-part chassis that was hinged in the center so it could be folded up and hung in the Lunar Module Quadrant 1 bay. It had two side-by-side foldable seats made of tubular aluminium with nylon webbing and aluminum floor panels. An armrest was mounted between the seats, and each seat had adjustable footrests and a Velcro-fastened seat belt. A large mesh dish antenna was mounted on a mast on the front center of the rover. The suspension consisted of a double horizontal wishbone with upper and lower torsion bars and a damper unit between the chassis and upper wishbone. Fully loaded, the LRV had a ground clearance of .
Wheels and power.
The wheels were designed and manufactured by General Motors Defense Research Laboratories in Santa Barbara, California. Ferenc Pavlics was given special recognition by NASA for developing the "resilient wheel". They consisted of a spun aluminum hub and a diameter, wide tire made of zinc-coated woven diameter steel strands attached to the rim and discs of formed aluminum. Titanium chevrons covered 50% of the contact area to provide traction. Inside the tire was a diameter bump stop frame to protect the hub. Dust guards were mounted above the wheels. Each wheel had its own electric drive made by Delco, a direct current (DC) series-wound motor capable of at 10,000 rpm, attached to the wheel via an 80:1 harmonic drive, and a mechanical brake unit.
Maneuvering capability was provided through the use of front and rear steering motors. Each series-wound DC steering motor was capable of . The front and rear wheels would turn in opposite directions to achieve a tight turning radius of , or could be decoupled so only front or rear would be used for steering. They could free-wheel in case of drive failure.
Power was provided by two 36-volt silver-zinc potassium hydroxide non-rechargeable batteries with a capacity of 121 A·h each (a total of 242 A·h), yielding a range of . These were used to power the drive and steering motors and also a 36-volt utility outlet mounted on the front of the LRV to power the communications relay unit or the TV camera. LRV batteries and electronics were passively cooled, using change-of-phase wax thermal capacitor packages and reflective, upward-facing radiating surfaces. While driving, radiators were covered with mylar blankets to minimize dust accumulation. When stopped, the astronauts would open the blankets, and manually remove excess dust from the cooling surfaces with hand brushes.
Control and navigation.
A T-shaped hand controller situated between the two seats controlled the four drive motors, two steering motors, and brakes. Moving the stick forward powered the LRV forward, left and right turned the vehicle left or right, and pulling backwards activated the brakes. Activating a switch on the handle before pulling back would put the LRV into reverse. Pulling the handle all the way back activated a parking brake. The control and display modules were situated in front of the handle and gave information on the speed, heading, pitch, and power and temperature levels.
Navigation was based on continuously recording direction and distance through use of a directional gyro and odometer and feeding this data to a computer that would keep track of the overall direction and distance back to the LM. There was also a Sun-shadow device that could give a manual heading based on the direction of the Sun, using the fact that the Sun moved very slowly in the sky.
Usage.
Each rover was used on three traverses, one per day over the three-day course of each mission, with the individual performances logged as follows:
An operational constraint on the use of the LRV was that the astronauts must be able to walk back to the LM if the LRV were to fail at any time during the EVA (called the "Walkback Limit"). Thus, the traverses were limited in the distance they could go at the start and at any time later in the EVA. Therefore, they went to the farthest point away from the LM and worked their way back to it so that, as the life support consumables were depleted, their remaining walk back distance was equally diminished. This constraint was relaxed during the longest traverse on Apollo 17, based on the demonstrated reliability of the LRV and spacesuits on previous missions. A paper by Burkhalter and Sharp provides details on usage.
Deployment.
Deployment of the LRV from the LM's Quadrant 1 bay by the astronauts was achieved with a system of pulleys and braked reels using ropes and cloth tapes. The rover was folded and stored in the bay with the underside of the chassis facing out. One astronaut would climb the egress ladder on the LM and release the rover, which would then be slowly tilted out by the second astronaut on the ground through the use of reels and tapes. As the rover was let down from the bay, most of the deployment was automatic. The rear wheels folded out and locked in place. When they touched the ground, the front of the rover could be unfolded, the wheels deployed, and the entire frame let down to the surface by pulleys.
The rover components locked into place upon opening. Cabling, pins, and tripods would then be removed and the seats and footrests raised. After switching on all the electronics, the vehicle was ready to back away from the LM.
Current locations.
A total of four flight-ready rovers were manufactured. Three were transported to and left on the moon via the Apollo 15, 16, and 17 missions, with the fourth rover used for spare parts on the first three following the cancellation of Apollo 18. Since only the upper stages of the lunar excursion modules could return to lunar orbit from the surface, the vehicles, along with the lower stages were abandoned. As a result, the only lunar rovers on display are test vehicles, trainers, and mock-ups. The rover used on Apollo 15 was left on the lunar surface at Hadley-Apennine (
). The rover used on Apollo 16 was left on the lunar surface at Descartes (
). The rover used on Apollo 17 was left on the lunar surface at Taurus-Littrow (
) and was seen by the Lunar Reconnaissance Orbiter during passes in 2009 and 2011.
Several rovers were created for testing, training, or validation purposes. The engineering mockup is on display at the Museum of Flight in Seattle, Washington. The Qualification Test Unit is on display at the National Air and Space Museum in Washington, D.C. The rover used for vibration testing is on display in the Davidson Saturn V Center at the Marshall Space Flight Center in Huntsville, Alabama. Additional test units are on display at the Johnson Space Center in Houston, Texas, and the Kennedy Space Center Visitors Complex in Cape Canaveral, Florida. Replicas of rovers are on display at the National Museum of Naval Aviation in Pensacola, Florida, the Evergreen Aviation & Space Museum in McMinnville, Oregon, and the Kansas Cosmosphere and Space Center in Hutchinson, Kansas. A replica on loan from the Smithsonian Institution is on display at the attraction at Epcot at the Walt Disney World Resort near Orlando, Florida.

</doc>
<doc id="18240" url="https://en.wikipedia.org/wiki?curid=18240" title="Lake Kickapoo">
Lake Kickapoo

Lake Kickapoo is a reservoir in Archer County, Texas. Created in 1947. It has a surface area of . Named after the Kickapoo tribe native to the area.
One of the nine Air Force Space Surveillance System (formerly NAVSPASUR) sites is located at Lake Kickapoo (). It is the master transmitter and the most powerful continuous wave (CW) station in the world, at 768 kW radiated power.

</doc>
<doc id="18243" url="https://en.wikipedia.org/wiki?curid=18243" title="Land (disambiguation)">
Land (disambiguation)

Land is the solid surface of the Earth that is not covered by water. It may also refer to:
In music:
As a synonym for a region belonging to a people:
As a geographical place:
As a division of a country:
Other usages:

</doc>
<doc id="18245" url="https://en.wikipedia.org/wiki?curid=18245" title="Labyrinth">
Labyrinth

In Greek mythology, the labyrinth (Greek λαβύρινθος "labyrinthos") was an elaborate structure designed and built by the legendary artificer Daedalus for King Minos of Crete at Knossos. Its function was to hold the Minotaur eventually killed by the hero Theseus. Daedalus had so cunningly made the Labyrinth that he could barely escape it after he built it.
Although early Cretan coins occasionally exhibit branching (multicursal) patterns, the single-path (unicursal) seven-course "Classical" design without branching or dead ends became associated with the Labyrinth on coins as early as 430 BC, and similar non-branching patterns became widely used as visual representations of the Labyrinth – even though both logic and literary descriptions make it clear that the Minotaur was trapped in a complex branching maze. Even as the designs became more elaborate, visual depictions of the mythological Labyrinth from Roman times until the Renaissance are almost invariably unicursal. Branching mazes were reintroduced only when garden mazes became popular during the Renaissance.
In English, the term "labyrinth" is generally synonymous with "maze". As a result of the long history of unicursal representation of the mythological Labyrinth, however, many contemporary scholars and enthusiasts observe a distinction between the two. In this specialized usage "maze" refers to a complex branching multicursal puzzle with choices of path and direction, while a unicursal "labyrinth" has only a single path to the center. A labyrinth in this sense has an unambiguous route to the center and back and is not difficult to navigate.
Unicursal labyrinths appeared as designs on pottery or basketry, as body art, and in etchings on walls of caves or churches. The Romans created many primarily decorative unicursal designs on walls and floors in tile or mosaic. Many labyrinths set in floors or on the ground are large enough that the path can be walked. Unicursal patterns have been used historically both in group ritual and for private meditation, and are increasingly found for therapeutic use in hospitals and hospices.
Ancient labyrinths.
"Labyrinth" is a word of Pre-Greek (Minoan) origin, which the Greeks used for the palace of Knossos in Crete, and it is derived from the Lydian word "labrys" ("double-edged axe"). This was a symbol of royal power, which suggests that the labyrinth was originally the royal Minoan palace in Crete and meant "palace of the double-axe" (the suffix -nth as in Korinth). This designation may not have been limited to the palace of Knossos, because the same symbols were discovered in other palaces of Crete.
Pliny's "Natural History" mentions four ancient labyrinths: the Cretan labyrinth, an Egyptian labyrinth, a Lemnian labyrinth, and an Italian labyrinth.
'Labrys' was a cult-word introduced from Anatolia. In Labraunda of Caria the double-axe accompanies the storm-god Zeus Labrandeus (). It also accompanies the Hurrian god of sky and storm Teshub (his Hittite and Luwian name was Tarhun). A lot of these symbols were found in the Minoan palaces in Crete, and they usually accompanied goddesses. It seems that the double-axe was the symbol of the beginning ("arche") of the creation.
The goddess of the double-axe probably presided over the Minoan palaces, and especially over the palace of Knossos. The Linear B (Mycenaean) inscription on tablet ΚΝ Gg 702, is interpreted as "da-pu2-ri-to-jo,po-ti-ni-ja" ("labyrinthoio potnia", "Mistress of the labyrinth), and she was undoubtedly the goddess of the palace. The word "daburinthos" ("labyrinthos") may possibly show the same equivocation between initial "d-" and "l-" as is found in the variation of the early Hittite royal name "Tabarna" / "Labarna" (where written "t-" may represent phonetic "d-").
The complex palace of Knossos in Crete is usually implicated, though the actual dancing ground, depicted in frescoes at Knossos, has not been found. Something was being shown to visitors as a labyrinth at Knossos in the 1st century AD (Philostratos, "De vita Apollonii Tyanei" iv.34).
The labyrinth is the referent in the familiar Greek patterns of the endlessly running meander, to give the "Greek key" its common modern name. In the 3rd century BC, coins from Knossos were still struck with the labyrinth symbol. The predominant labyrinth form during this period is the simple seven-circuit style known as the "classical" labyrinth.
The term "labyrinth" came to be applied to any unicursal maze, whether of a particular circular shape (illustration) or rendered as square. At the center, a decisive turn brought one out again. In Plato's dialogue "Euthydemus", Socrates describes the labyrinthine line of a logical argument:
Cretan labyrinth.
Knossos has been supposed since Classical times to be the site of the labyrinth. When the Bronze Age site at Knossos was excavated by explorer Arthur Evans, he found various bull motifs, including an image of a man leaping over the horns of a bull, as well as depictions of a labrys carved into the walls. On the strength of a passage in the "Iliad", it has been suggested that the palace was the site of a dancing-ground made for Ariadne by the craftsman Daedalus, where young men and women, of the age of those sent to Crete as prey for the Minotaur, would dance together. By extension, in popular legend the palace is associated with the myth of the Minotaur.
In the 2000s, archaeologists explored other potential sites of the labyrinth. Oxford University geographer Nicholas Howarth believes that 'Evans’s hypothesis that the palace of Knossos is also the Labyrinth must be treated sceptically.' Howarth and his team conducted a search of an underground complex known as the Skotino cave but concluded that it was formed naturally. Another contender is a series of underground tunnels at Gortyn, accessed by a narrow crack but expanding into interlinking caverns. Unlike the Skotino cave, these caverns have smooth walls and columns, and appear to have been at least partially man-made. This site corresponds to an unusual labyrinth symbol on a 16th-century map of Crete contained in a book of maps in the library of Christ Church, Oxford. A map of the caves themselves was produced by the French in 1821. The site was also used by German soldiers to store ammunition during the Second World War. Howarth's investigation was shown on a documentary produced for the National Geographic Channel.
Herodotus' Egyptian labyrinth.
Even more generally, "labyrinth" might be applied to any extremely complicated maze-like structure. Herodotus, in Book II of his "Histories", describes as a "labyrinth" a building complex in Egypt, "near the place called the City of Crocodiles", that he considered to surpass the pyramids:
During the 19th century, the remains of the Labyrinth were discovered "11½ miles from the pyramid of Hawara, in the province of Faioum." The Labyrinth was likely modified and added upon "at various times. The names of more than one king have been found there, the oldest" name being that of Amenemhat III. "It is unnecessary to imagine more than that it was monumental, and a monument of more than one king of Egypt."
In 1898, the "Harpers Dictionary of Classical Antiquities" described the structure as "the largest of all the temples of Egypt, the so-called Labyrinth, of which, however, only the foundation stones have been preserved."
Herodotus' description of the Egyptian Labyrinth inspired some central scenes in Bolesław Prus' 1895 historical novel, "Pharaoh".
Pliny's Lemnian labyrinth.
Pliny the Elder's "Natural History" (36.90) lists the legendary Smilis, reputed to be a contemporary of Daedalus, together with the historical mid-sixth-century BC architects and sculptors Rhoikos and Theodoros as two of the makers of the Lemnian labyrinth, which Andrew Stewart regards as "evidently a misunderstanding of the Samian temple's location "en limnais" ['in the marsh']."
Pliny's Italian labyrinth.
According to Pliny, the tomb of the great Etruscan general Lars Porsena contained an underground maze. Pliny's description of the exposed portion of the tomb is intractable; Pliny, it seems clear, had not observed this structure himself, but is quoting the historian and Roman antiquarian Varro.
Ancient labyrinths outside Europe.
At about the same time as the appearance of the Greek labyrinth, an essentially identical pattern appeared in Native American culture, the Tohono O'odham people labyrinth which features I'itoi, the "Man in the Maze". The Tonoho O'odham pattern has two distinct differences from the Greek: it is radial in design, and the entrance is at the top, where traditional Greek labyrinths have the entrance at the bottom (see below).
A prehistoric petroglyph on a riverbank in Goa shows the same pattern and has been dated to circa 2500 BC. Other examples have been found among cave art in northern India and on a dolmen shrine in the Nilgiri Mountains, but are difficult to date accurately. Early labyrinths in India all follow the Classical pattern; some have been described as plans of forts or cities.
Labyrinths appear in Indian manuscripts and Tantric texts from the 17th century onward. They are often called "Chakravyuha" in reference to an impregnable battle formation described in the ancient Mahabharata epic. Lanka, the capital city of mythic Rāvana, is described as a labyrinth in the 1910 translation of Al-Beruni's "India" (c. 1030 AD) p. 306 (with a diagram on the following page).
By the White Sea, notably on the Solovetsky Islands, there have been preserved more than 30 stone labyrinths. The most remarkable monument is the Stone labyrinths of Bolshoi Zayatsky Island - a group of 13–14 stone labyrinths on 0.4 km2 area of one small island. These labyrinths are thought to be 2,000–3,000 years old.
Labyrinth as pattern.
In antiquity, the less complicated labyrinth pattern familiar from medieval examples was already developed. In Roman floor mosaics, the simple classical labyrinth is framed in the meander border pattern, squared off as the medium requires, but still recognisable. Often an image of the Minotaur appears in the center of these mosaic labyrinths. Roman meander patterns gradually developed in complexity towards the fourfold shape that is now familiarly known as the medieval form. The labyrinth retains its connection with death and a triumphant return: at Hadrumentum in North Africa (now Sousse), a Roman family tomb has a fourfold labyrinth mosaic floor with a dying minotaur in the center and a mosaic inscription: HICINCLUSUS.VITAMPERDIT "Enclosed here, he loses life" (Kern 169; Kerényi fig.31).
Medieval labyrinths and turf mazes.
When the early humanist Benzo d'Alessandria visited Verona before 1310, he noted the ""Laberinthum" which is now called the Arena"; perhaps he was seeing the "cubiculi" beneath the arena's missing floor.
The full flowering of the medieval labyrinth came about from the twelfth through fourteenth centuries with the grand pavement labyrinths of the gothic cathedrals, notably Chartres, Reims and Amiens in northern France. These labyrinths may have originated as symbolic allusion to the Holy City; and some modern thinkers have theorized that prayers and devotions may have accompanied the perambulation of their intricate paths. Although some books (in particular guidebooks) suggest that the mazes on cathedral floors served as substitutes for pilgrimage paths, the earliest attested use of the phrase "chemin de Jerusalem" (path to Jerusalem) dates to the late 18th century when it was used to describe mazes at Reims and Saint-Omer. The accompanying ritual, supposedly involving pilgrims following the maze on their knees while praying, may have been practiced at Chartres during the 17th century. However, no contemporary evidence supports the idea that labyrinths had such a purpose for early Christians. The cathedral labyrinths are thought to be the inspiration for the many turf mazes in the UK, such as survive at Wing, Hilton, Alkborough, and Saffron Walden.
Over the same general period, some 500 or more non-ecclesiastical labyrinths were constructed in Scandinavia. These labyrinths, generally in coastal areas, are marked out with stones, most often in the simple 7- or 11-course classical forms. They often have names which translate as "Troy Town". They are thought to have been constructed by fishing communities: trapping malevolent trolls or winds in the labyrinth's coils might ensure a safe fishing expedition. There are also stone labyrinths on the Isles of Scilly, although none is known to date from before the nineteenth century.
There are examples of labyrinths in many disparate cultures. The symbol has appeared in various forms and media (petroglyphs, classic-form, medieval-form, pavement, turf, and basketry) at some time throughout most parts of the world, from Native North and South America to Australia, Java, India, and Nepal.
Modern labyrinths.
In recent years, there has been a resurgence of interest in the labyrinth symbol, which has inspired a revival in labyrinth building.
Countless video games depict mazes and labyrinths.
On bobsled, luge, and skeleton tracks, a labyrinth is where there are three to four curves in succession without a straight line in between any of the turns.
In modern imagery, the labyrinth of Daedalus is often represented by a multicursal maze, in which one may become lost.
The Argentine writer Jorge Luis Borges was entranced with the idea of the labyrinth, and used it extensively in his short stories (such as "The House of Asterion" in "The Aleph"). His use of it has inspired other authors' works (e.g. Umberto Eco's "The Name of the Rose", Mark Z. Danielewski's "House of Leaves"). Additionally, Roger Zelazny's fantasy series, "The Chronicles of Amber", features a labyrinth, called "the Pattern", which grants those who walk it the power to move between parallel worlds. The avant-garde multi-screen film, "In the Labyrinth", presents a search for meaning in a symbolic modern labyrinth. In Rick Riordan's series Percy Jackson & the Olympians, the events of the fourth novel "The Battle of the Labyrinth" predominantly take place within the labyrinth of Daedalus, which has followed the heart of the West to settle beneath the United States. Australian author Sara Douglass incorporated some labyrinthine ideas in her series The Troy Game, in which the Labyrinth on Crete is one of several in the ancient world, created with the cities as a source of magical power. Lawrence Durrell's "The Dark Labyrinth" depicts travelers trapped underground in Crete.
The labyrinth is also treated in contemporary fine arts. Examples include Piet Mondrian's "Dam and Ocean" (1915), Joan Miró's "Labyrinth" (1923), Pablo Picasso's "Minotauromachia" (1935), M. C. Escher's "Relativity" (1953), Friedensreich Hundertwasser's "Labyrinth" (1957), Jean Dubuffet's "Logological Cabinet" (1970), Richard Long's "Connemara sculpture" (1971), Joe Tilson's "Earth Maze" (1975), Richard Fleischner's "Chain Link Maze" (1978), István Orosz's "Atlantis Anamorphosis" (2000), Dmitry Rakov's "Labyrinth" (2003), and Labyrinthine projection by contemporary American artist Mo Morales (2000). The Italian painter Davide Tonato has dedicated many of his artistic works to the labyrinth theme.
In February 2013 it was announced that Mark Wallinger has created a set of 270 enamel plaques of unicursal labyrinth designs, one for every tube station, to mark the 150th anniversary of the London Underground; each will be numbered according to its position in the route taken by the contestants in the 2009 Guinness World Record Tube Challenge.
Cultural meanings.
Prehistoric labyrinths are believed to have served as traps for malevolent spirits or as defined paths for ritual dances. In medieval times, the labyrinth symbolized a hard path to God with a clearly defined center (God) and one entrance (birth). In their cross-cultural study of signs and symbols, "Patterns that Connect", Carl Schuster and Edmund Carpenter present various forms of the labyrinth and suggest various possible meanings, including not only a sacred path to the home of a sacred ancestor, but also, perhaps, a representation of the ancestor him/herself: "...many World Indians who make the labyrinth regard it as a sacred symbol, a beneficial ancestor, a deity. In this they may be preserving its original meaning: the ultimate ancestor, here evoked by two continuous lines joining its twelve primary joints."
One can think of labyrinths as symbolic of pilgrimage; people can walk the path, ascending toward salvation or enlightenment. Many people could not afford to travel to holy sites and lands, so labyrinths and prayer substituted for such travel. Later, the religious significance of labyrinths faded, and they served primarily for entertainment, though recently their spiritual aspect has seen a resurgence. Author Ben Radford conducted an investigation into some of the claims of spiritual and healing effects of labyrinths, reporting on his findings in his book Mysterious New Mexico.
Many newly made labyrinths exist today, in churches and parks. Modern mystics use labyrinths to help them achieve a contemplative state. Walking among the turnings, one loses track of direction and of the outside world, and thus quiets the mind. The Labyrinth Society provides a locator for modern labyrinths all over the world.
In addition, the labyrinth can serve as a metaphor for situations that are difficult to be extricated from, as an image that suggests getting lost in a subterranean dungeon-like world. Octavio Paz titled his book on Mexican identity "The Labyrinth of Solitude", describing the Mexican condition as orphaned and lost.
Christian use.
Labyrinths have on various occasions been used in Christian tradition as a part of worship. The earliest known example is from a fourth-century pavement at the Basilica of St Reparatus, at Orleansville, Algeria, with the words "Sancta Eclesia" at the center, though it is unclear how it might have been used in worship.
In medieval times, labyrinths began to appear on church walls and floors around 1000 C.E.. The most famous medieval labyrinth, with great influence on later practice, was created in Chartres Cathedral. The purpose of the labyrinths is not clear, though there are surviving descriptions of French clerics performing a ritual Easter dance along the path on Easter Sunday. Some books (guidebooks in particular) suggest that mazes on cathedral floors originated in the medieval period as alternatives to pilgrimage to the Holy Land, but the earliest attested use of the phrase "chemin de Jerusalem" (path to Jerusalem) dates to the late 18th century when it was used to describe mazes at Reims and Saint-Omer. The accompanying ritual, depicted in Romantic illustrations as involving pilgrims following the maze on their knees while praying, may have been practiced at Chartres during the 17th century.
The use of labyrinths has recently been revived in some contexts of Christian worship. For example, a labyrinth was set up on the floor of St Paul's Cathedral for a week in March 2000.

</doc>
<doc id="18246" url="https://en.wikipedia.org/wiki?curid=18246" title="Lyon &amp; Healy">
Lyon &amp; Healy

Lyon & Healy is an American harp manufacturer based in Chicago, Illinois. Their Chicago headquarters and manufacturing facility contains a showroom and concert hall. George W. Lyon and Patrick J. Healy began the company in 1864 as a sheet music shop. By the end of the 19th century, they manufactured a wide range of musical instruments—including guitars, mandolins, banjos, and various brass and percussion instruments.
Lyon & Healy harps are widely played by professional musicians, since they are one of the few makers of harps for orchestral use—which are known as "concert harps" or "pedal harps". Lyon & Healy also makes smaller "folk harps" or lever harps (based on traditional Irish and Scottish instruments) that use levers to change string pitch instead of pedals. In the 1980s, Lyon & Healy also began to manufacture electroacoustic harps and, later, solid body electric harps.
History.
George W. Lyon and Patrick J. Healy founded the company in 1864, after they moved from Boston to start a sheet music shop for music publisher Oliver Ditson. Determining Lyon & Healy's history is complicated because its building and company records were destroyed in two fires, including the Great Chicago Fire of 1871. Two smaller fires did little damage to the firm and did not result in data loss.
Company letters and trade catalogs don't provide exact dates that would reveal when Lyon & Healy began manufacturing instruments. An article in the "Musical Courier" states that Lyon & Healy began manufacturing instruments in 1885. Clearly, Lyon & Healy was making fretted string instruments in the 1880s, with Washburn (guitars, mandolins, banjos, and zithers) as their premier line. By the 1900s, if not earlier, Lyon & Healy might well have been manufacturing bowed string instruments.
Lyon & Healy also made various percussion instruments. Later, Lyon & Healy began manufacturing brass instruments, possibly as early as the 1890s. Lyon & Healy also repaired instruments, and offered engraving services. Complicating matters still further, Lyon & Healy engraved instruments that it retailed but did not actually manufacture. In its 1892 catalog, it claimed that it manufactured 100,000 instruments annually.
The company is known to have made other instruments, including reed organs and pianos. Lyon & Healy evidently began manufacturing these instruments around 1876 in its factories in Chicago and nearby cities. George W. Lyon patented his cottage upright in 1878 and it was sold under the Lyon & Healy name.
Lyon retired in 1889, and Healy died in 1905.
Lyon & Healy built their first harp in 1889. Healy wanted to develop a harp better suited to the rigors of the American climate than available European models. They successfully produced a harp notable for its strength, pitch reliability, and freedom from unwanted vibration. Previously, most harps in North America where made by small groups of craftsmen in France, England, Ireland, or Italy.
In 1890, Lyon & Healy introduced the Style 23 Harp, still a popular and recognizable design. It has 47 strings, highly decorative floral carving on the top of the column, base, and feet, and a fleur de lis pattern at the bottom of the column. It is available in a gold version. It is tall, and weighs about . Lyon & Healy produces one of the most ornate and elaborate harps in the world, the Louis XV, which includes carvings of leaves, flowers, scrolls, and shells along its neck and kneeblock, as well the soundboard edges.
In the 1890s the company—which used the slogan,"Everything in music"—began building pipe organs. In 1894 Robert J. Bennett came to Lyon & Healy from the Hutchens company of Boston to head their organ department. The largest surviving Lyon & Healy pipe organ is at the Our Lady of Sorrows Basilica in Chicago. It is a large organ of four manuals and 57 ranks of pipes.
They also made small pipe organs. An example survives at St. Mary's Catholic Church in Aspen Colorado. It is a two manual tracker with a 30 note straight pedalboard and 7 ranks. It is believed to have been built around 1900, and can still be pumped by hand.
By the 1900s, Lyon & Healy was one of the largest music publishers in the world, and was a major producer of musical instruments. However, In late 1920s, Lyon & Healy sold its brass musical instrument manufacturing branch (see "New Langwill Index"). In the 1970s, the firm concentrated solely upon making and selling harps.
In 1928, Lyon & Healy introduced one of the most unusual harps ever mass-produced, the "Salzedo Model". The company designed it in collaboration with the harpist Carlos Salzedo. It an Art Deco style instrument that incorporates bold red and white lines on the soundboard to create a stylized and distinct appearance.
In the 1960s, Lyon & Healy introduced a smaller lever harp, the "Troubadour", a 36-string harp for young beginners with smaller hands, and for casual players. This harp stands , and weighs .
In the late 1970s, Steinway & Sons (then owned by CBS) purchased Lyon & Healy and soon after closed all retail stores—that sold sheet music and musical instruments, and their education departments—to focus on harp production.
By 1985, Lyon & Healy also made folk harps, also known as "Irish harps", which are even smaller than the Troubadour. The ""Shamrock model folk harp"" has 34 strings. It stands tall with its legs. The legs can be removed so the player can hold the instrument lap—style on the knees. It weighs about . It features Celtic designs on the soundboard. An Irish or folk harp player is sometimes called a "harper" rather than "harpist". 
DePaul University now owns the Wabash building. Lyon & Healy harps are still in Chicago, Illinois, at 168 North Ogden Avenue. The building was once home to the recording studios of Orlando R. Marsh.
The firm still exists in one of its buildings producing a range of harps, including a relatively new addition an electronic harp.
Craftsmanship.
Wood in harp construction varies by instrument, but Sitka Spruce (Picea sitchensis) is the most common soundboard wood. Various Lyon & Healy guitars, mandolins, and many other instrument types reside in major musical instrument museums in the U.S. and Europe.
Lyon and Healy now primarily manufactures four types of harps—the "lever harp", "petite pedal harp", "semi-grande pedal harp", and "concert grand harp". They also make limited numbers of "special harps" called "concert grands". Lyon & Healy makes electric lever harps in nontraditional colors such as pink, green, blue, and red.

</doc>
<doc id="18247" url="https://en.wikipedia.org/wiki?curid=18247" title="Index of philosophy articles (A–C)">
Index of philosophy articles (A–C)


</doc>
<doc id="18271" url="https://en.wikipedia.org/wiki?curid=18271" title="Lamborghini">
Lamborghini

Automobili Lamborghini S.p.A. () is an Italian brand and manufacturer of luxury sports cars and, formerly, SUVs, which is owned by the Volkswagen Group through its subsidiary brand division Audi. Lamborghini's production facility and headquarters are located in Sant'Agata Bolognese, Italy. In 2011, Lamborghini's 831 employees produced 1,711 vehicles.
Ferruccio Lamborghini, an Italian manufacturing magnate, founded Automobili Ferruccio Lamborghini S.p.A. in 1963 to compete with established marques, including Ferrari. The company gained wide acclaim in 1966 for the Miura sports coupé, which established rear mid-engine, rear wheel drive as the standard layout for high-performance cars of the era. Lamborghini grew rapidly during its first decade, but sales plunged in the wake of the 1973 worldwide financial downturn and the oil crisis. The firm's ownership changed three times after 1973, including a bankruptcy in 1978. American Chrysler Corporation took control of Lamborghini in 1987 and sold it to Malaysian investment group Mycom Setdco and Indonesian group V'Power Corporation in 1994. In 1998, Mycom Setdco and V'Power sold Lamborghini to the Volkswagen Group where it was placed under the control of the group's Audi division.
New products and model lines were introduced to the brand's portfolio and brought to the market and saw an increased productivity for the brand Lamborghini. In the late 2000s, during the worldwide financial crisis and the subsequent economic crisis, Lamborghini's sales saw a drop of nearly 50 percent.
Lamborghini produces sports cars and V12 engines for offshore powerboat racing. Lamborghini currently produces the V12-powered Aventador and the V10-powered Huracán.
History.
Manufacturing magnate Italian Ferruccio Lamborghini founded the company in 1963 with the objective of producing a refined grand touring car to compete with offerings from established marques such as Ferrari. The company's first models were released in the mid-1960s and were noted for their refinement, power and comfort. Lamborghini gained wide acclaim in 1966 for the Miura sports coupé, which established rear mid-engine, rear wheel drive as the standard layout for high-performance cars of the era.
Lamborghini grew rapidly during its first ten years, but sales plunged in the wake of the 1973 worldwide financial downturn and the oil crisis. Ferruccio Lamborghini sold ownership of the company to Georges-Henri Rossetti and René Leimer and retired in 1974. The company went bankrupt in 1978, and was placed in the receivership of brothers Jean-Claude and Patrick Mimran in 1980. The Mimrans purchased the company out of receivership by 1984 and invested heavily in the company's expansion. Under the Mimrans' management, Lamborghini's model line was expanded from the Countach to include the Jalpa sports car and the LM002 high performance off-road vehicle.
The Mimrans sold Lamborghini to the Chrysler Corporation in 1987. After replacing the Countach with the Diablo and discontinuing the Jalpa and the LM002, Chrysler sold Lamborghini to Malaysian investment group Mycom Setdco and Indonesian group V'Power Corporation in 1994. In 1998, Mycom Setdco and V'Power sold Lamborghini to the Volkswagen Group where it was placed under the control of the group's Audi division. New products and model lines were introduced to the brand's portfolio and brought to the market and saw an increased productivity for the brand Lamborghini. In the late 2000s, during the worldwide financial crisis and the subsequent economic crisis, Lamborghini's sales saw a drop of nearly 50 percent.
Products.
Automobiles.
As of the 2015 model year, Lamborghini's automobile product range consists of two model lines, both of which are mid-engine two-seat sports cars. The V12-powered Aventador line consists of the LP 700–4 coupé and roadster. The V10-powered Huracán line currently includes only the LP 610-4 coupé.
Marine engines.
Motori Marini Lamborghini produces a large V12 marine engine block for use in World Offshore Series Class 1 powerboats. A Lamborghini branded marine engine displaces approximately and outputs approximately .
Lamborghini motorcycle.
In the mid-1980s, Lamborghini produced a limited-production run of a 1,000 cc sports motorcycle. UK weekly newspaper "Motor Cycle News" reported in 1994 – when featuring an example available through an Essex motorcycle retailer - that 24 examples were produced with a Lamborghini alloy frame having adjustable steering head angle, Kawasaki GPz1000RX engine/transmission unit, Ceriani front forks and "Marvic" wheels. The bodywork was plastic and fully integrated with front fairing merged into fuel tank and seat cover ending in a rear tail-fairing. The motorcycles were designed by Lamborghini stylists and produced by French business "Boxer Bikes".
Branded merchandise.
Lamborghini licenses its brand to manufacturers that produce a variety of Lamborghini-branded consumer goods including scale models, clothing, accessories, bags, electronics and laptop computers.
Motorsport.
In contrast to his rival Enzo Ferrari, Ferruccio Lamborghini had decided early on that there would be no factory-supported racing of Lamborghinis, viewing motorsport as too expensive and too draining on company resources. This was unusual for the time, as many sports car manufacturers sought to demonstrate the speed, reliability, and technical superiority through motorsport participation. Enzo Ferrari in particular was known for considering his road car business mostly a source of funding for his participation in motor racing. Ferruccio's policy led to tensions between him and his engineers, many of whom were racing enthusiasts; some had previously worked at Ferrari. When Dallara, Stanzani, and Wallace began dedicating their spare time to the development of the P400 prototype, they designed it to be a road car with racing potential, one that could win on the track and also be driven on the road by enthusiasts. When Ferruccio discovered the project, he allowed them to go ahead, seeing it as a potential marketing device for the company, while insisting that it would not be raced. The P400 went on to become the Miura. The closest the company came to building a true race car under Lamborghini's supervision were a few highly modified prototypes, including those built by factory test driver Bob Wallace, such as the Miura SV-based "Jota" and the Jarama S-based "Bob Wallace Special".
In the mid-1970s, while Lamborghini was under the management of Georges-Henri Rossetti, Lamborghini entered into an agreement with BMW to develop, then manufacture 400 cars for BMW in order to meet Group 4 homologation requirements. BMW lacked experience developing a mid-engined vehicle and believed that Lamborghini's experience in that area would make Lamborghini an ideal choice of partner. Due to Lamborghini's shaky finances, Lamborghini fell behind schedule developing the car's structure and running gear. When Lamborghini failed to deliver working prototypes on time, BMW took the program in house, finishing development without Lamborghini. BMW contracted with Baur to produce the car, which BMW named the M1, delivering the first vehicle in October 1978.
In 1985, Lamborghini's British importer developed the Countach QVX, in conjunction with Spice Engineering, for the 1986 Group C championship season. One car was built, but lack of sponsorship caused it to miss the season. The QVX competed in only one race, the non-championship 1986 Southern Suns 500 km race at Kyalami in South Africa, driven by Tiff Needell. Despite the car finishing better than it started, sponsorship could once again not be found and the programme was cancelled.
Lamborghini was an engine supplier in Formula One between the 1989 and 1993 Formula One seasons. It supplied engines to Larrousse (1989–1990,1992–1993), Lotus (1990), Ligier (1991), Minardi (1992), and to the Modena team in 1991. While the latter is commonly referred to as a factory team, the company saw themselves as a supplier, not a backer. The 1992 Larrousse–Lamborghini was largely uncompetitive but noteworthy in its tendency to spew oil from its exhaust system. Cars following closely behind the Larrousse were commonly coloured yellowish-brown by the end of the race. Lamborghini's best result was achieved with Larrousse at the 1990 Japanese Grand Prix, when Aguri Suzuki finished third on home soil.
In late 1991, a Lamborghini Formula One motor was used in the Konrad KM-011 Group C sports car, but the car only lasted a few races before the project was canceled. The same engine, re-badged a Chrysler, Lamborghini's then-parent company, was tested by McLaren towards the end of the 1993 season, with the intent of using it during the 1994 season. Although driver Ayrton Senna was reportedly impressed with the engine's performance, McLaren pulled out of negotiations, choosing a Peugeot engine instead, and Chrysler ended the project.
Two racing versions of the Diablo were built for the Diablo Supertrophy, a single-model racing series held annually from 1996 to 1999. In the first year, the model used in the series was the Diablo SVR, while the Diablo 6.0 GTR was used for the remaining three years. Lamborghini developed the Murciélago R-GT as a production racing car to compete in the FIA GT Championship, the Super GT Championship and the American Le Mans Series in 2004. The car's highest placing in any race that year was the opening round of the FIA GT Championship at Valencia, where the car entered by Reiter Engineering finished third from a fifth-place start. In 2006, during the opening round of the Super GT championship at Suzuka, a car run by the Japan Lamborghini Owners Club garnered the first victory (in class) by an R-GT. A GT3 version of the Gallardo has been developed by Reiter Engineering. A Murciélago R-GT entered by All-Inkl.com racing, driven by Christophe Bouchut and Stefan Mücke, won the opening round of the FIA GT Championship held at Zhuhai International Circuit, achieving the first major international race victory for Lamborghini.
Complete Formula One results.
(key) (results in bold indicate pole position) 
Marketing.
Brand identity.
The world of bullfighting is a key part of Lamborghini's identity. In 1962, Ferruccio Lamborghini visited the Seville ranch of Don Eduardo Miura, a renowned breeder of Spanish fighting bulls. Lamborghini, a Taurus himself, was so impressed by the majestic Miura animals that he decided to adopt a raging bull as the emblem for the automaker he would open shortly.
Vehicle nomenclature.
After producing two cars with alphanumeric designations, Lamborghini once again turned to the bull breeder for inspiration. Don Eduardo was filled with pride when he learned that Ferruccio had named a car for his family and their line of bulls; the fourth Miura to be produced was unveiled to him at his ranch in Seville.
The automaker would continue to draw upon the bullfighting connection in future years. The Islero was named for the Miura bull that killed the famed bullfighter Manolete in 1947. "Espada" is the Spanish word for sword, sometimes used to refer to the bullfighter himself. The Jarama's name carried a special double meaning; though it was intended to refer only to the historic bullfighting region in Spain, Ferruccio was concerned about confusion with the also historic Jarama motor racing track.
After christening the Urraco after a bull breed, in 1974, Lamborghini broke from tradition, naming the Countach not for a bull, but for contacc (pronounced ), a Piedmontese expletive. Legend has it that stylist Nuccio Bertone uttered the word in surprise when he first laid eyes on the Countach prototype, "Project 112". The LM002 (LM for Lamborghini Militaire) sport utility vehicle and the Silhouette (named after the popular racing category of the time) were other exceptions to the tradition.
The Jalpa of 1982 was named for a bull breed; Diablo, for the Duke of Veragua's ferocious bull famous for fighting an epic battle against "El Chicorro" in Madrid in 1869; Murciélago, the legendary bull whose life was spared by "El Lagartijo" for his performance in 1879; Gallardo, named for one of the five ancestral castes of the Spanish fighting bull breed; and Reventón, the bull that defeated young Mexican "torero" Félix Guzmán in 1943. The Estoque concept of 2008 was named for the estoc, the sword traditionally used by "matadors" during bullfights.
Concept vehicles.
Throughout its history, Lamborghini has envisioned and presented a variety of concept cars, beginning in 1963 with the very first Lamborghini prototype, the 350GTV. Other famous models include Bertone's 1967 Marzal, 1974 Bravo, and 1980 Athon, Chrysler's 1987 Portofino, the Italdesign-styled Cala from 1995, the Zagato-built Raptor from 1996.
A retro-styled Lamborghini Miura concept car, the first creation of chief designer Walter de'Silva, was presented in 2006. President and CEO Stephan Winkelmann denied that the concept would be put into production, saying that the Miura concept was "a celebration of our history, but Lamborghini is about the future. Retro design is not what we are here for. So we won’t do the Miura.”
At the 2008 Paris Motor Show, Lamborghini revealed the Estoque, a four-door sedan concept. Although there had been much speculation regarding the Estoque's eventual production, Lamborghini management has not made a decision regarding production of what might be the first four-door car to roll out of the Sant'Agata factory.
At the 2010 Paris Motor Show, Lamborghini unveiled the Sesto Elemento. The concept car is made almost entirely of carbon fibre making it extremely light, weighing only 999 kg. The Sesto Elemento shares the same V10 engine found in the Lamborghini Gallardo. Lamborghini hopes to signal a shift in the company's direction from making super cars focused on top speed to producing more agile, track focused cars with the Sesto Elemento. The concept car can reach 0–62 in 2.5 seconds and can reach a top speed of over 180 mph.
At the 2012 Geneva Motor Show, Lamborghini unveiled the Aventador J – a roofless, windowless version of the Lamborghini Aventador. The Aventador J uses the same 700 hp engine and seven-speed transmission as the standard Aventador.
At the 2012 Beijing Motor Show, Lamborghini unveiled the Urus SUV. This is the first SUV By Lamborghini since the LM002.
As part of the celebration of 50 years of Lamborghini, the company unveiled the Egoista. Egoista is for one person's driving and only one of Egoista is to be made.
At the 2014 Paris Motor Show, Lamborghini unveiled the Asterion LPI910-4 hybrid concept car. Named after the actual half-man, half-bull hybrid (Minotaur) of Greek legend, it is the first hybrid Lamborghini in the history of the company ("Asterion" was the traditional proper name of another hybrid – namely, . Utilizing the Huracán's 5.2 litre V10 producing 607 horsepower, along with one electric motor mounted on the transaxle and an additional two on the front axle, developing an additional 300 horsepower. This puts the power at a combined figure of 907 horsepower. 0–100 km/h is claimed to be "just above 3 seconds," with a claimed top speed of 185 mph.
Corporate affairs.
Structure.
As of 2011, Lamborghini is structured as a wholly owned subsidiary of AUDI AG named Automobili Lamborghini S.p.A.
Automobili Lamborghini S.p.A. controls five principal subsidiaries: Ducati Motor Holding S.p.A., a manufacturer of motorcycles; Italdesign Giugiaro S.p.A., a 90.1%-owned design and prototyping firm that provides services to the entire Volkswagen Group; MML S.p.A. (Motori Marini Lamborghini), a manufacturer of marine engine blocks; and VOLKSWAGEN GROUP ITALIA S.p.A. (formerly AUTOGERMA S.p.A.), which sells Audi and other Volkswagen Group vehicles in Italy.
Sales results.
By sales, the most important markets in 2004 for Lamborghini's sports cars are the U.S. (41%), Germany (13%), Great Britain (9%) and Japan (8%). Prior to the launch of the Gallardo in 2003, Lamborghini produced approximately 400 vehicles per year; in 2011 Lamborghini produced 1,711 vehicles.
Licensing.
Automóviles Lamborghini Latinoamérica.
Automóviles Lamborghini Latinoamérica S.A. de C.V. (Lamborghini Automobiles of Latin America Public Limited Company) is an authorized distributor and manufacturer of Lamborghini-branded vehicles and merchandise in Latin America and South America.
Automóviles Lamborghini has produced two rebodied versions of the Diablo called the Eros and the Coatl. In 2015, Automóviles Lamborghini transferred the IP-rights to the Coatl foundation (chamber of commerce no. 63393700) in The Netherlands in order to secure these rights and to make them more marketable. The company has announced the production of a speedboat called the Lamborghini Glamour.
Museo Lamborghini.
This two story museum is attached to the headquarters, and covers the history of Lamborghini cars and sport utility vehicles, showcasing a variety of modern and vintage models. The museum uses displays of cars, engines and photos to provide a history and review important milestones of Lamborghini.

</doc>
<doc id="18272" url="https://en.wikipedia.org/wiki?curid=18272" title="LaGrand case">
LaGrand case

The LaGrand case was a legal action heard before the International Court of Justice (ICJ) which concerned the Vienna Convention on Consular Relations. In the case the ICJ found that its own temporary court orders were legally binding and that the rights contained in the convention could not be denied by the application of domestic legal procedures.
Background.
On January 7, 1982, brothers Karl-Heinz and Walter Bernhard LaGrand bungled an armed bank robbery in Marana, Arizona, United States, killing a man and severely injuring a woman in the process. They were subsequently charged and convicted of murder and sentenced to death. The LaGrands were German nationals, having been born in Germany. While they had both lived in the United States since they were four and five, respectively, neither had officially obtained U.S. citizenship. As foreigners the LaGrands should have been informed of their right to consular assistance, under the Vienna Convention, from their state of nationality, Germany. However the Arizona authorities failed to do this even after they became aware that the LaGrands were German nationals. The LaGrand brothers later contacted the German consulate of their own accord, having learned of their right to consular assistance. They appealed their sentences and convictions on the grounds that they were not informed of their right to consular assistance, and that with consular assistance they might have been able to mount a better defense. The federal courts rejected their argument on grounds of procedural default, which provides that issues cannot be raised in federal court appeals unless they have first been raised in state courts.
Diplomatic efforts, including pleas by German ambassador Jürgen Chrobog and German Member of Parliament Claudia Roth, and the recommendation of Arizona's clemency board, failed to sway Arizona Governor Jane Dee Hull, who insisted that the executions be carried out. Karl LaGrand was subsequently executed by the state of Arizona on February 24, 1999, by lethal injection. Walter LaGrand was then executed March 3, 1999, by lethal gas.
The case.
Germany then initiated legal action in the International Court of Justice against the United States regarding Walter LaGrand. Hours before Walter LaGrand was due to be executed, Germany applied for the Court to grant a provisional court order, requiring the United States to delay the execution of Walter LaGrand, which the court granted.
Germany then initiated action in the U.S. Supreme Court for enforcement of the provisional order. In its judgment, the U.S. Supreme Court held that it lacked jurisdiction with respect to Germany's complaint against Arizona due to the Eleventh Amendment of the U.S. constitution, which prohibits federal courts from hearing lawsuits of foreign states against a U.S. state. With respect to Germany's case against the United States, it held that the doctrine of procedural default was not incompatible with the Vienna Convention, and that even if procedural default did conflict with the Vienna Convention it had been overruled by later federal law – the Antiterrorism and Effective Death Penalty Act of 1996, which explicitly legislated the doctrine of procedural default. (Subsequent federal legislation overrides prior self-executing treaty provisions, "Whitney v. Robertson", ).
The U.S. Solicitor General sent a letter to the Supreme Court, as part of these proceedings, arguing that provisional measures of the International Court of Justice are not legally binding. The United States Department of State also conveyed the ICJ's provisional measure to the Governor of Arizona without comment. The Arizona clemency board recommended a stay to the governor, on the basis of the pending ICJ case; but the governor of Arizona ignored the recommendation and Walter LaGrand was executed on March 3, 1999. As of 2013 this is the last use of lethal gas in the U.S., although five states still permit its use in varying circumstances. 
Germany then modified its complaint in the case before the ICJ, alleging furthermore that the U.S. violated international law by failing to implement the provisional measures. In opposition to the German submissions, the United States argued that the Vienna Convention did not grant rights to individuals, only to states; that the convention was meant to be exercised subject to the laws of each state party, which in the case of the United States meant subject to the doctrine of procedural default; and that Germany was seeking to turn the ICJ into an international court of criminal appeal.
ICJ decision.
On June 27, 2001, the ICJ, rejecting all of the United States' arguments, ruled in favor of Germany. The ICJ held that the Vienna Convention on Consular Relations of 24 April 1963 (Vienna Convention) granted rights to individuals on the basis of its plain meaning, and that domestic laws could not limit the rights of the accused under the convention, but only specify the means by which those rights were to be exercised. The ICJ also found that its own provisional measures were legally binding. The nature of provisional measures has been a subject of great dispute in international law; the English text of the Statute of the International Court of Justice implies they are not binding, while the French text implies that they are. Faced with a contradiction between two equally authentic texts of the statute, the court considered which interpretation better served the objects and purposes of the statute, and hence found that they are binding. This was the first time in the court's history it had ruled as such.
The court also found that the United States violated the Vienna Convention through its application of procedural default. The court was at pains to point out that it was not passing judgment on the doctrine itself, but only its application to cases involving the Vienna Convention.

</doc>
<doc id="18273" url="https://en.wikipedia.org/wiki?curid=18273" title="Lotus 1-2-3">
Lotus 1-2-3

Lotus 1-2-3 is a spreadsheet program from Lotus Software (now part of IBM). It was the IBM PC's first killer application, was hugely popular in the 1980s and contributed significantly to the success of the IBM PC.
The first spreadsheet, VisiCalc, had helped launch the Apple II as one of the earliest personal computers in business use. With IBM's entry into the market, VisiCalc was slow to respond, and when they did, they launched what was essentially a straight port of their existing system in spite of the greatly expanded hardware capabilities. Lotus' solution was marketed as a three-in-one, integrated solution, which handled spreadsheet calculations, database functionality, and graphical charts. Thus the name "1-2-3", though how much database capability was debatable given Lotus' spare memory. 1-2-3 quickly overtook VisiCalc, as well as Multiplan and SuperCalc, two VisiCalc competitors.
1-2-3 was the spreadsheet standard throughout the 1980s and into the 1990s, part of a suite of three office automation products that included dBase and WordPerfect, to build a complete business platform. With the acceptance of Windows 3.0, the market for desktop software grew even more. None of the major spreadsheet developers had seriously considered the graphical user interface to supplement their DOS offerings, and so they responded slowly to Microsoft's own graphical based products, Excel and Word. Lotus was passed by Microsoft in the early 1990s and never recovered. IBM purchased Lotus and continued to sell Lotus offerings, only officially ending sales in 2013.
History.
VisiCalc.
VisiCalc was launched in 1979 on the Apple II and immediately became a best-seller. Compared to earlier programs, VisiCalc allowed one to easily construct free-form calculation systems for practically any purpose, the limitations being primarily memory and speed related. The application was so compelling that there were numerous stories of people buying Apple II machines to run the program. VisiCalc's runaway success on the Apple led to direct bug compatible ports to other platforms, including the Atari 8-bit family, Commodore PET and many others. This included the IBM PC when it launched in 1981, where it quickly became another best-seller, with an estimated 300,000 sales in the first six months on the market.
There were well known problems with VisiCalc, and several competitors appeared to address some of these issues. One early example was 1980's SuperCalc, which solved the problem of circular references, while a slightly later example was Microsoft Multiplan from 1981, which offered larger sheets and other improvements. In spite of these, and others, VisiCalc continued to outsell them all.
Beginnings.
The Lotus Development Corporation was founded by Mitchell Kapor, a friend of the developers of VisiCalc. 1-2-3 was originally written by Jonathan Sachs, who had written two spreadsheet programs previously while working at Concentric Data Systems, Inc. To aid its growth, in the UK, and possibly elsewhere, Lotus 1-2-3 was the very first computer software to use television consumer advertising.
1-2-3 was released on 26 January 1983, and immediately overtook Visicalc in sales. Unlike Microsoft Multiplan, it stayed very close to the model of VisiCalc, including the "A1" letter and number cell notation, and slash-menu structure. It was cleanly programmed and relatively bug-free, gained speed from being written completely in x86 assembly language (this remained the case for all DOS versions until 3.0, when Lotus switched to C) and wrote directly to video memory rather than use the slow DOS and/or BIOS text output functions.
The reliance on the specific hardware of the IBM PC led to 1-2-3 being utilized as one of the two stress test applications, with Microsoft Flight Simulator, for true 100% compatibility when PC clones appeared in the early 1980s. 1-2-3 required two disk drives and at least 192K of memory, which made it incompatible with the IBM PCjr; Lotus produced a version for the PCjr that was on two cartridges but otherwise identical.
By early 1984 the software was a killer app for the IBM PC and compatibles, while hurting sales of computers that could not run it. "They're looking for 1-2-3. Boy, are they looking for 1-2-3!" "InfoWorld" wrote. Noting that computer purchasers did not want PC compatibility as much as compatibility with certain PC software, the magazine suggested "let's tell it like it is. Let's not say 'PC compatible,' or even 'MS-DOS compatible.' Instead, let's say '1-2-3 compatible.'" PC clones' advertising did often prominently state that they were compatible with 1-2-3. An Apple II software company promised that its spreadsheet had "the power of 1-2-3". Because spreadsheets use large amounts of memory, 1‐2‐3 helped popularize greater RAM capacities in PCs, and especially the advent of expanded memory, which allowed greater than 640k to be accessed.
Rivals.
Lotus 1-2-3 inspired imitators, the first of which was Mosaic Software's "The Twin", written in the fall of 1985 largely in the C language, followed by VP-Planner, which was backed by Adam Osborne. These were able to not only read 1-2-3 files, but also execute many or most macro programs by incorporating the same command structure. Copyright law had first been understood to only cover the source code of a program. After the success of lawsuits which claimed that the very "look and feel" of a program were covered, Lotus sought to ban any program which had a compatible command and menu structure. Program commands had not been considered to be covered before, but the commands of 1-2-3 were embedded in the words of the menu displayed on the screen. 1-2-3 won its case against Mosaic Software. However, when they sued Borland over its Quattro Pro spreadsheet in Lotus v. Borland, the courts ruled that it was not a copyright violation to merely have a compatible command menu or language. In 1995, the First Circuit found that command menus are an uncopyrightable "method of operation" under section 102(b) of the Copyright Act. The 1-2-3 menu structure (example, slash File Erase) was itself an advanced version of single letter menus introduced in VisiCalc.
Decline.
Microsoft's early spreadsheet Multiplan eventually gave way to Excel, which debuted on the Macintosh in 1985. It arrived on PCs with the release of Windows 2.x in 1987, but as Windows was not yet popular, it posed no serious threat to Lotus' stranglehold on spreadsheet sales. However, Lotus suffered technical setbacks in this period. Version 3 of Lotus 1-2-3, fully rewritten from its original macro assembler into the more portable C language, was delayed by more than a year as the totally new 1-2-3 had to be made portable across platforms and fully compatible with existing macro sets and file formats. The inability to fit the larger code size of compiled C into lower-powered machines forced the company to split its spreadsheet offerings, with 1-2-3 release 3 only for higher-end machines, and a new version 2.2, based on the 2.01 assembler code base, available for PCs without extended memory. By the time these versions were released in 1989, Microsoft was well on its way to breaking through Lotus' market share.
During the early 1990s, Windows grew in popularity and along with it Excel, which gradually displaced Lotus from its leading position. A planned total revamp of 1-2-3 for Windows fell apart and all that the company could manage was a Windows adaptation of their existing spreadsheet with no changes except using a graphical interface. Additionally, several versions of 1-2-3 had different features and slightly different interfaces.
1-2-3's intended successor, Lotus Symphony, was Lotus' entry into the anticipated "integrated software" market. It intended to expand the rudimentary all-in-one 1-2-3 into a fully-fledged spreadsheet, graph, database and word processor for DOS, but none of the integrated packages ever really succeeded. 1-2-3 migrated to the Windows platform, as part of Lotus SmartSuite.
IBM's continued development and marketing of Lotus SmartSuite and OS/2 during the 1990s placed it in direct competition with Microsoft Office and Microsoft Windows, respectively. As a result, Microsoft "punished the IBM PC Company with higher prices, a late license for Windows 95, and the withholding of technical and marketing support." IBM wasn't granted OEM rights for Windows 95 until 15 minutes prior to the release of Windows 95, 24 August 1995. Because of this uncertainty, IBM machines were sold without Windows 95, while Compaq, HP, and other companies sold machines with Windows 95 from day one.
On 11 June 2013, IBM announced it would withdraw the Lotus brand: IBM Lotus 123 Millennium Edition V9.x, IBM Lotus SmartSuite 9.x V9.8.0, and Organizer V6.1.0. IBM stated, "Customers will no longer be able to receive support for these offerings after September 30, 2014. No service extensions will be offered. There will be no replacement programs." 
User features.
The name "1-2-3" stemmed from the product's integration of three main capabilities. Along with being a spreadsheet, it also offered integral charting/graphing and rudimentary database operations.
Data features included sorting data in any defined rectangle, by order of information in one or two columns in the rectangular area. Justifying text in a range into paragraphs allowed it to be used as a primitive word processor.
It had keyboard-driven pop-up menus as well as one-key commands, making it fast to operate. It was also user-friendly, introducing an early instance of context-sensitive help accessed by the F1 key.
Macros in version one and add-ins (introduced in version 2.0) contributed much to 1-2-3's popularity, allowing dozens of outside vendors to sell macro packages and add-ins ranging from dedicated financial worksheets like F9 to full-fledged word processors. In the single-tasking MS-DOS, 1-2-3 was sometimes used as a complete office suite. All major graphics standards were supported; initially CGA and Hercules, and later EGA, AT&T, and VGA. Early versions used the filename extension "WKS". In version 2.0, the extension changed first to "WK1", then "WK2". This later became "WK3" for version 3.0 and "WK4" for version 4.0.
Version 2 introduced macros with syntax and commands similar in complexity to an advanced BASIC interpreter, as well as string variable expressions. Later versions supported multiple worksheets and were written in C. The charting/graphing routines were written in Forth by Jeremy Sagan (son of Carl Sagan) and the printing routines by Paul Funk (founder of Funk Software).
PC Version History.
DOS.
Real Mode (8088+).
These editions of 1-2-3 for DOS were primarily written in x86 assembly language.
Protected Mode (80286+).
These editions of 1-2-3 for DOS were primarily written in C.
Reception.
After previewing "1-2-3" on the IBM PC in 1982, "BYTE" called it "modestly revolutionary" for elegantly combining spreadsheet, database, and graphing functions. It praised the application's speed and ease of use, stating that with the built-in help screens and tutorial "1-2-3 is one of the few pieces of software that can literally be used by anybody. You can buy 1-2-3 and IBM PC and be running the two together the same day". "PC Magazine" in 1983 called 1-2-3 "a powerful and impressive program ... as a spreadsheet, it's excellent", and attributed its very fast performance to being written in assembly language.

</doc>
<doc id="18274" url="https://en.wikipedia.org/wiki?curid=18274" title="List of facilities named after Lyndon B. Johnson">
List of facilities named after Lyndon B. Johnson

Many facilities have been named after Lyndon B. Johnson, thirty-sixth President of the United States, including the following:

</doc>
<doc id="18278" url="https://en.wikipedia.org/wiki?curid=18278" title="Liberation Day (Netherlands)">
Liberation Day (Netherlands)

In the Netherlands, Liberation Day () is celebrated each year on May the 5th to mark the end of the occupation by Nazi Germany during World War II.
The nation was liberated largely by the First Canadian Army, which included in addition to Canadian forces the British I Corps, and the 1st Polish Armoured Division, as well as, at various times, American, Belgian, Dutch and Czechoslovak troops. Parts of the country, in particular the south-east, were liberated by the British Second Army, which included American and Polish airborne forces, (see Operation Market Garden) and French airbornes (see Operation Amherst). On 5 May 1945, the Canadian General Charles Foulkes and the German Commander-in-Chief Johannes Blaskowitz reached an agreement on the capitulation of German forces in the Netherlands in Hotel de Wereld in Wageningen. One day later, the capitulation document was signed in the auditorium of Wageningen University, located next door.
After the liberation in 1945, Liberation Day was commemorated every five years. Finally, in 1990, the day was declared to be a national holiday, when the liberation would be commemorated and celebrated every year.
On 4 May, the Dutch hold "Dodenherdenking," Remembrance of the Dead for the people who fought and died during World War II and in wars in general. There are remembrance gatherings all over cities and in the country, the better-known at the National Monument on Dam Square in Amsterdam and at the Waalsdorpervlakte in the dunes near The Hague, one of the infamous Nazi execution places. Throughout the country, two minutes of silence are observed at 8 p.m. On May 5, the liberation is celebrated and festivals are held at most places in the Netherlands, with parades of veterans and 14 musical festivals through the whole country.

</doc>
<doc id="18279" url="https://en.wikipedia.org/wiki?curid=18279" title="Light pollution">
Light pollution

Light pollution, also known as photopollution or luminous pollution, is excessive, misdirected, or obtrusive artificial light. Pollution is the adding-of/added light itself, in analogy to added sound, carbon dioxide, etc. Adverse consequences are multiple; some of them may not be known yet. Scientific definitions thus include the following:
The first three of the above four scientific definitions describe the state of the environment. The fourth (and newest) one describes the process of polluting by light.
Light pollution competes with starlight in the night sky for urban residents, interferes with astronomical observatories, and, like any other form of pollution, disrupts ecosystems and has adverse health effects. Light pollution can be divided into two main types:
Light pollution is a side effect of industrial civilization. Its sources include building exterior and interior lighting, advertising, commercial properties, offices, factories, streetlights, and illuminated sporting venues. It is most severe in highly industrialized, densely populated areas of North America, Europe, and Japan and in major cities in the Middle East and North Africa like Tehran and Cairo, but even relatively small amounts of light can be noticed and create problems. Since the early 1980s, a global dark-sky movement has emerged, with concerned people campaigning to reduce the amount of light pollution. The International Dark-Sky Association (IDA) is one non-profit advocacy group involved in this movement.
Impact on energy usage.
Energy conservation advocates contend that light pollution must be addressed by changing the habits of society, so that lighting is used more efficiently, with less waste and less creation of unwanted or unneeded illumination. Several industry groups also recognize light pollution as an important issue. For example, the Institution of Lighting Engineers in the United Kingdom provides its members with information about light pollution, the problems it causes, and how to reduce its impact.
Since not everyone is irritated by the same lighting sources, it is common for one person's light "pollution" to be light that is desirable for another. One example of this is found in advertising, when an advertiser wishes for particular lights to be bright and visible, even though others find them annoying. Other types of light pollution are more certain. For instance, light that "accidentally" crosses a property boundary and annoys a neighbor is generally wasted and pollutive light.
Disputes are still common when deciding appropriate action, and differences in opinion over what light is considered reasonable, and who should be responsible, mean that negotiation must sometimes take place between parties. Where objective measurement is desired, light levels can be quantified by field measurement or mathematical modeling, with results typically displayed as an isophote map or light contour map. Authorities have also taken a variety of measures for dealing with light pollution, depending on the interests, beliefs and understandings of the society involved. Measures range from doing nothing at all, to implementing strict laws and regulations about how lights may be installed and used.
Types.
Light pollution is a broad term that refers to multiple problems, all of which are caused by inefficient, unappealing, or (arguably) unnecessary use of artificial light. Specific categories of light pollution include light trespass, over-illumination, glare, light clutter, and skyglow. A single offending light source often falls into more than one of these categories.
Light trespass.
Light trespass occurs when unwanted light enters one's property, for instance, by shining over a neighbor's fence. A common light trespass problem occurs when a strong light enters the window of one's home from the outside, causing problems such as sleep deprivation.
A number of cities in the U.S. have developed standards for outdoor lighting to protect the rights of their citizens against light trespass. To assist them, the International Dark-Sky Association has developed a set of model lighting ordinances.
The Dark-Sky Association was started to reduce the light going up into the sky which reduces visibility of stars (see Skyglow below). This is any light which is emitted more than 90° above nadir. By limiting light at this 90° mark they have also reduced the light output in the 80–90° range which creates most of the light trespass issues.
U.S. federal agencies may also enforce standards and process complaints within their areas of jurisdiction. For instance, in the case of light trespass by white strobe lighting from communication towers in excess of FAA minimum lighting requirements the Federal Communications Commission maintains an Antenna Structure Registration database information which citizens may use to identify offending structures and provides a mechanism for processing citizen inquiries and complaints. The U.S. Green Building Council (USGBC) has also incorporated a credit for reducing the amount of light trespass and sky glow into their environmentally friendly building standard known as LEED.
Light trespass can be reduced by selecting light fixtures which limit the amount of light emitted more than 80° above the nadir. The IESNA definitions include full cutoff (0%), cutoff (10%), and semi-cutoff (20%). (These definitions also include limits on light emitted above 90° to reduce sky glow.)
Over-illumination.
Over-illumination is the excessive use of light. Specifically within the United States, over-illumination is responsible for approximately two million barrels of oil per day in energy wasted. This is based upon U.S. consumption of equivalent of of petroleum. It is further noted in the same U.S. Department of Energy source that over 30% of all primary energy is consumed by commercial, industrial and residential sectors. Energy audits of existing buildings demonstrate that the lighting component of residential, commercial and industrial uses consumes about 20–40% of those land uses, variable with region and land use. (Residential use lighting consumes only 10–30% of the energy bill while commercial buildings' major use is lighting.) Thus lighting energy accounts for about four or five million barrels of oil (equivalent) per day. Again energy audit data demonstrates that about 30–60% of energy consumed in lighting is unneeded or gratuitous.
An alternative calculation starts with the fact that commercial building lighting consumes in excess of 81.68 terawatts (1999 data) of electricity, according to the U.S. DOE. Thus commercial lighting alone consumes about four to five million barrels per day (equivalent) of petroleum, in line with the alternate rationale above to estimate U.S. lighting energy consumption. Even among developed countries there are large differences in patterns of light use. American cities emit 3–5 times more light to space per capita compared to German cities.
Over-illumination stems from several factors:
Most of these issues can be readily corrected with available, inexpensive technology, and with resolution of landlord/tenant practices that create barriers to rapid correction of these matters. Most importantly, public awareness would need to improve for industrialized countries to realize the large payoff in reducing over-illumination.
In certain cases an over-illumination lighting technique may be needed. For example, indirect lighting is often used to obtain a "softer" look, since hard direct lighting is generally found less desirable for certain surfaces, such as skin. The indirect lighting method is perceived as more cozy and suits bars, restaurants and living quarters. It is also possible to block the direct lighting effect by adding softening filters or other solutions, though intensity will be reduced.
Glare.
Glare can be categorized into different types. One such classification is described in a book by Bob Mizon, coordinator for the British Astronomical Association's Campaign for Dark Skies. According to this classification:
According to Mario Motta, president of the Massachusetts Medical Society, "... glare from bad lighting is a public-health hazard—especially the older you become. Glare light scattering in the eye causes loss of contrast and leads to unsafe driving conditions, much like the glare on a dirty windshield from low-angle sunlight or the high beams from an oncoming car." In essence bright and/or badly shielded lights around roads can partially blind drivers or pedestrians and contribute to accidents.
The blinding effect is caused in large part by reduced contrast due to light scattering in the eye by excessive brightness, or to reflection of light from dark areas in the field of vision, with luminance similar to the background luminance. This kind of glare is a particular instance of disability glare, called veiling glare. (This is not the same as loss of accommodation of night vision which is caused by the direct effect of the light itself on the eye.)
Light clutter.
Light clutter refers to excessive groupings of lights. Groupings of lights may generate confusion, distract from obstacles (including those that they may be intended to illuminate), and potentially cause accidents. Clutter is particularly noticeable on roads where the street lights are badly designed, or where brightly lit advertising surrounds the roadways. Depending on the motives of the person or organization that installed the lights, their placement and design can even be intended to distract drivers, and can contribute to accidents.
Clutter may also present a hazard in the aviation environment if aviation safety lighting must compete for pilot attention with non-relevant lighting. For instance, runway lighting may be confused with an array of suburban commercial lighting and aircraft collision avoidance lights may be confused with ground lights.
Skyglow.
Skyglow refers to the diffuse glow that can be seen over populated areas. It arises from light reflected from illuminated surfaces and from light escaping directly upward from incompletely shielded or upward-directed light fixtures, which then is scattered (redirected) by the atmosphere back toward the ground. The brightness of skyglow is affected strongly by the amount of light used, the shielding characteristics of the light fixtures, and by the color or spectral content of the light sources. Though it is commonly thought that Rayleigh scattering strongly increases the brightness of skyglow arising from white sources with strong blue and green emission, the dominant spectral effect has been shown to arise from the Purkinje effect instead. Because of the eye's increased sensitivity to blue and green light when adapted to very low luminance levels (such as those in even moderately polluted clear night skies), white light sources such as white LEDs contribute significantly more to skyglow than an equal amount of yellow light from sources such as high-pressure sodium, low-pressure sodium, or amber AlGaInP LEDs. Sky glow is of particular irritation to astronomers, as it interferes with astronomical observations, but multitudes suffer from the decreased visibility of star-filled night skies.
Skyglow brightness can be measured with instruments such as the Sky Quality Meters (SQM), or visually using the Bortle Dark-Sky Scale. The nine-class Bortle Scale rates the darkness of the night sky and the visibility of its phenomena, such as the Milky Way, gegenschein and the zodiacal light (easily masked by skyglow), providing a detailed description of each level on the scale (with Class 1 being the best).
Light is particularly problematic for amateur astronomers, whose ability to observe the night sky from their property is inhibited by any stray light from nearby. Most major optical astronomical observatories are surrounded by zones of strictly enforced restrictions on light emissions to limit skyglow.
Direct skyglow is reduced by selecting lighting fixtures which limit the amount of light emitted above the horizontal (90° above the nadir). Indirect skyglow produced by reflections from illuminated surfaces is harder to manage; the only effective method for limiting it is by minimizing over-illumination. But it has to be taken into account that, according to late 2010 publications, Italian regions using full cut off lighting only does not increase skyglow. Anyway, light reflected upwards by dark surfaces such as roads or buildings can be considered as minor, so debate about the contribution of indirect skyglow will continue.
Skyglow is made considerably worse when clouds are present. While this has no effect on astronomical observations (which are not possible at visible wavelengths under cloud cover), it is very important in the context of ecological light pollution. Since cloudy nights in artificially lit areas can be up to ten thousand times brighter than in natural areas, any organisms that are affected by sky glow (e.g. zooplankton and fish that visually prey on them) are much more likely to have their ordinary behavior disturbed on cloudy nights.
Measurement and global effects.
Measuring the effect of sky glow on a global scale is a complex procedure. The natural atmosphere is not completely dark, even in the absence of terrestrial sources of light and illumination from the Moon. This is caused by two main sources: "airglow" and "scattered light".
At high altitudes, primarily above the mesosphere, there is enough UV radiation from the sun of very short wavelength to cause ionization. When the ions collide with electrically neutral particles they recombine and emit photons in the process, causing airglow. The degree of ionization is sufficiently large to allow a constant emission of radiation even during the night when the upper atmosphere is in the Earth's shadow. Lower in the atmosphere all of the solar photons with energies above the ionization potential of N2 and O2 have already been absorbed by the higher layers and thus no appreciable ionization occurs.
Apart from emitting light, the sky also scatters incoming light, primarily from distant stars and the Milky Way, but also the zodiacal light, sunlight that is reflected and backscattered from interplanetary dust particles.
The amount of airglow and zodiacal light is quite variable (depending, amongst other things on sunspot activity and the Solar cycle) but given optimal conditions the darkest possible sky has a brightness of about 22 magnitude/square arcsecond. If a full moon is present, the sky brightness increases to about 18 magnitude/sq. arcsecond depending on local atmospheric transparency, 40 times brighter than the darkest sky. In densely populated areas a sky brightness of 17 magnitude/sq. arcsecond is not uncommon, or as much as 100 times brighter than is natural.
To precisely measure how bright the sky gets, night time satellite imagery of the earth is used as raw input for the number and intensity of light sources. These are put into a physical model of scattering due to air molecules and aerosoles to calculate cumulative sky brightness. Maps that show the enhanced sky brightness have been prepared for the entire world.
Inspection of the area surrounding Madrid reveals that the effects of light pollution caused by a single large conglomeration can be felt up to away from the center.
Global effects of light pollution are also made obvious. The entire area consisting of southern England, Netherlands, Belgium, west Germany, and northern France have a sky brightness of at least 2 to 4 times above normal (see above right). The only places in continental Europe where the sky can attain its natural darkness are in northern Scandinavia and in islands far from the continent.
In North America the situation is comparable. There is a significant problem with light pollution ranging from the Canadian Maritime Provinces to the American Southwest. The International Dark-Sky Association works to designate areas that have high quality night skies. These areas are supported by communities and organizations that are dedicated to reducing light pollution (e.g.Dark-sky preserve). The National Park Service Natural Sounds and Night Skies Division has measured night sky quality in national park units across the U.S. Sky quality in the U.S. ranges from pristine (Capitol Reef National Park and Big Bend National Park) to severely degraded (Santa Monica Mountains National Recreation Area and Biscayne National Park). The National Park Service Night Sky Program monitoring database is available online (2015).
Light pollution in Hong Kong was declared the 'worst on the planet' in March 2013.
Consequences.
Energy waste.
Lighting is responsible for one-fourth of all electricity consumption worldwide, and case studies have shown that several forms of over-illumination constitute energy wastage, including non-beneficial upward direction of night-time lighting. In 2007, Terna, the company responsible for managing electricity flow in Italy, reported a saving of 645.2 million kWh in electricity consumption during the daylight saving period from April to October. It attributes this saving to the delayed need for artificial lighting during the evenings.
In Australia,
Effects on animal and human health and psychology.
Medical research on the effects of excessive light on the human body suggests that a variety of adverse health effects may be caused by light pollution or excessive light exposure, and some lighting design textbooks use human health as an explicit criterion for proper interior lighting. Health effects of over-illumination or improper spectral composition of light may include: increased headache incidence, worker fatigue, medically defined stress, decrease in sexual function and increase in anxiety. Likewise, animal models have been studied demonstrating unavoidable light to produce adverse effect on mood and anxiety. For those who need to be awake at night, light at night also has an acute effect on alertness and mood.
In 2007, "shift work that involves circadian disruption" was listed as a probable carcinogen by the World Health Organization's International Agency for Research on Cancer. (IARC Press release No. 180). Multiple studies have documented a correlation between night shift work and the increased incidence of breast and prostate cancer.
A more recent discussion (2009), written by Professor Steven Lockley, Harvard Medical School, can be found in the CfDS handbook "Blinded by the Light?". Chapter 4, "Human health implications of light pollution" states that "... light intrusion, even if dim, is likely to have measurable effects on sleep disruption and melatonin suppression. Even if these effects are relatively small from night to night, continuous chronic circadian, sleep and hormonal disruption may have longer-term health risks". The New York Academy of Sciences hosted a meeting in 2009 on Circadian Disruption and Cancer. Red light suppresses melatonin the least.
In June 2009, the American Medical Association developed a policy in support of control of light pollution. News about the decision emphasized glare as a public health hazard leading to unsafe driving conditions. Especially in the elderly, glare produces loss of contrast, obscuring night vision.
Disruption of ecosystems.
When artificial light affects organisms and ecosystems it is called ecological light pollution. While light at night can be beneficial, neutral, or damaging for individual species, its presence invariably disturbs ecosystems. For example, some species of spiders avoid lit areas, while other species are happy to build their spider web directly on a lamp post. Since lamp posts attract many flying insects, the spiders that don't mind light gain an advantage over the spiders that avoid it. This is a simple example of the way in which species frequencies and food webs can be disturbed by the introduction of light at night.
Light pollution poses a serious threat in particular to nocturnal wildlife, having negative impacts on plant and animal physiology. It can confuse animal navigation, alter competitive interactions, change predator-prey relations, and cause physiological harm. The rhythm of life is orchestrated by the natural diurnal patterns of light and dark, so disruption to these patterns impacts the ecological dynamics.
Studies suggest that light pollution around lakes prevents zooplankton, such as Daphnia, from eating surface algae, causing algal blooms that can kill off the lakes' plants and lower water quality. Light pollution may also affect ecosystems in other ways. For example, lepidopterists and entomologists have documented that nighttime light may interfere with the ability of moths and other nocturnal insects to navigate. Night-blooming flowers that depend on moths for pollination may be affected by night lighting, as there is no replacement pollinator that would not be affected by the artificial light. This can lead to species decline of plants that are unable to reproduce, and change an area's longterm ecology.
A 2009 study also suggests deleterious impacts on animals and ecosystems because of perturbation of polarized light or artificial polarisation of light (even during the day, because direction of natural polarization of sun light and its reflexion is a source of information for a lot of animals). This form of pollution is named polarized light pollution (PLP). Unnatural polarized light sources can trigger maladaptive behaviors in polarization-sensitive taxa and alter ecological interactions.
Lights on tall structures can disorient migrating birds. Estimates by the U.S. Fish and Wildlife Service of the number of birds killed after being attracted to tall towers range from 4 to 5 million per year to an order of magnitude higher. The Fatal Light Awareness Program (FLAP) works with building owners in Toronto, Canada and other cities to reduce mortality of birds by turning out lights during migration periods.
Similar disorientation has also been noted for bird species migrating close to offshore production and drilling facilities. Studies carried out by Nederlandse Aardolie Maatschappij b.v. (NAM) and Shell have led to development and trial of new lighting technologies in the North Sea. In early 2007, the lights were installed on the Shell production platform L15. The experiment proved a great success since the number of birds circling the platform declined by 50 to 90%.
Sea turtle hatchlings emerging from nests on beaches are another casualty of light pollution. It is a common misconception that hatchling sea turtles are attracted to the moon. Rather, they find the ocean by moving away from the dark silhouette of dunes and their vegetation, a behavior with which artificial lights interfere. The breeding activity and reproductive phenology of toads, however, are cued by moonlight. Juvenile seabirds may also be disoriented by lights as they leave their nests and fly out to sea. Amphibians and reptiles are also affected by light pollution. Introduced light sources during normally dark periods can disrupt levels of melatonin production. Melatonin is a hormone that regulates photoperiodic physiology and behaviour. Some species of frogs and salamanders utilize a light-dependent "compass" to orient their migratory behaviour to breeding sites. Introduced light can also cause developmental irregularities, such as retinal damage, reduced sperm production, and genetic mutation.
In September 2009, the 9th European Dark-Sky Symposium in Armagh, Northern Ireland had a session on the environmental effects of light at night (LAN). It dealt with bats, turtles, the "hidden" harms of LAN, and many other topics. The environmental effects of LAN were mentioned as early as 1897, in a "Los Angeles Times" article—the text of which can be obtained from Dr. Travis Longcore of the Urban Wildlands Group, California. The following is an excerpt from that article, called "Electricity and English songbirds":
Effect on astronomy.
Astronomy is very sensitive to light pollution. The night sky viewed from a city bears no resemblance to what can be seen from dark skies. Skyglow (the scattering of light in the atmosphere) reduces the contrast between stars and galaxies and the sky itself, making it much harder to see fainter objects. This is one factor that has caused newer telescopes to be built in increasingly remote areas. Some astronomers use narrow-band "nebula filters" which only allow specific wavelengths of light commonly seen in nebulae, or broad-band "light pollution filters" which are designed to reduce (but not eliminate) the effects of light pollution by filtering out spectral lines commonly emitted by sodium- and mercury-vapor lamps, thus enhancing contrast and improving the view of dim objects such as galaxies and nebulae. Unfortunately these light pollution reduction (LPR) filters are not a cure for light pollution. LPR filters reduce the brightness of the object under study and this limits the use of higher magnifications. LPR filters work by blocking light of certain wavelengths, which alters the color of the object, often creating a pronounced green cast. Furthermore, LPR filters only work on certain object types (mainly emission nebulae) and are of little use on galaxies and stars. No filter can match the effectiveness of a dark sky for visual or photographic purposes. Due to their low surface brightness, the visibility of diffuse sky objects such as nebulae and galaxies is affected by light pollution more than are stars. Most such objects are rendered invisible in heavily light polluted skies around major cities. A simple method for estimating the darkness of a location is to look for the Milky Way, which from truly dark skies appears bright enough to cast a shadow.
In addition to skyglow, light trespass can impact observations when artificial light directly enters the tube of the telescope and is reflected from non-optical surfaces until it eventually reaches the eyepiece. This direct form of light pollution causes a glow across the field of view which reduces contrast. Light trespass also makes it hard for a visual observer to become sufficiently dark adapted. The usual measures to reduce this glare, if reducing the light directly is not an option, include flocking the telescope tube and accessories to reduce reflection, and putting a light shield (also usable as a dew shield) on the telescope to reduce light entering from angles other than those near the target. Under these conditions, some astronomers prefer to observe under a black cloth to ensure maximum dark adaptation. In one Italian regional lighting code this effect of stray light is defined as "optical pollution", due to the fact that there is a direct path from the light source to the "optic" – the observer's eye or telescope.
Increase in atmospheric pollution.
A study presented at the American Geophysical Union meeting in San Francisco found that light pollution destroys nitrate radicals thus preventing the normal night time reduction of atmospheric smog produced by fumes emitted from cars and factories. The study was presented by Harald Stark from the National Oceanic and Atmospheric Administration.
Reduction of natural sky polarization.
In the night, the polarization of the moonlit sky is very strongly reduced in the presence of urban light pollution, because scattered urban light is not strongly polarized. Polarized moonlight can't be seen by humans, but is believed to be used by many animals for navigation.
Reduction.
Reducing light pollution implies many things, such as reducing sky glow, reducing glare, reducing light trespass, and reducing clutter. The method for best reducing light pollution, therefore, depends on exactly what the problem is in any given instance. Possible solutions include:
Improving lighting fixtures.
The use of "full cutoff" lighting fixtures, as much as possible, is advocated by most campaigners for the reduction of light pollution. It is also commonly recommended that lights be spaced appropriately for maximum efficiency, and that number of luminaires being used as well as the wattage of each luminaire match the needs of the particular application (based on local lighting design standards).
Full cutoff fixtures first became available in 1959 with the introduction of General Electric's M100 fixture.
A full cutoff fixture, when correctly installed, reduces the chance for light to escape above the plane of the horizontal. Light released above the horizontal may sometimes be lighting an intended target, but often serves no purpose. When it enters into the atmosphere, light contributes to sky glow. Some governments and organizations are now considering, or have already implemented, full cutoff fixtures in street lamps and stadium lighting.
The use of full cutoff fixtures help to reduce sky glow by preventing light from escaping above the horizontal. Full cutoff typically reduces the visibility of the lamp and reflector within a luminaire, so the effects of glare are also reduced. Campaigners also commonly argue that full cutoff fixtures are more efficient than other fixtures, since light that would otherwise have escaped into the atmosphere may instead be directed towards the ground. However, full cutoff fixtures may also trap more light in the fixture than other types of luminaires, corresponding to lower luminaire efficiency, suggesting a re-design of some luminaires may be necessary.
The use of full cutoff fixtures can allow for lower wattage lamps to be used in the fixtures, producing the same or sometimes a better effect, due to being more carefully controlled. In every lighting system, some sky glow also results from light reflected from the ground. This reflection can be reduced, however, by being careful to use only the lowest wattage necessary for the lamp, and setting spacing between lights appropriately. Assuring luminaire setback is greater than 90° from highly reflective surfaces also diminishes reflectance.
A common criticism of full cutoff lighting fixtures is that they are sometimes not as aesthetically pleasing to look at. This is most likely because historically there has not been a large market specifically for full cutoff fixtures, and because people typically like to see the source of illumination. Due to the specificity with their direction of light, full cutoff fixtures sometimes also require expertise to install for maximum effect.
The effectiveness of using full cutoff roadway lights to combat light pollution has also been called into question. According to design investigations, luminaires with full cutoff distributions (as opposed to "cutoff" or "semi cutoff", compared here) have to be closer together to meet the same light level, uniformity and glare requirements specified by the IESNA. These simulations optimized the height and spacing of the lights while constraining the overall design to meet the IESNA requirements, and then compared total uplight and energy consumption of different luminaire designs and powers. Cutoff designs performed better than full cutoff designs, and semi-cutoff performed better than either cutoff or full cutoff. This indicates that, in roadway installations, over-illumination or poor uniformity produced by full cutoff fixtures may be more detrimental than direct uplight created by fewer cutoff or semi-cutoff fixtures. Therefore, the overall performance of existing systems could be improved more by reducing the number of luminaires than by switching to full cutoff designs.
However, using the definition of "light pollution" from some Italian regional bills (i.e., "every irradiance of artificial light outside competence areas and particularly upward the sky") only full cutoff design prevents light pollution. The Italian Lombardy region, where only full cutoff design is allowed (Lombardy act no. 17/2000, promoted by Cielobuio-coordination for the protection of the night sky), in 2007 had the lowest per capita energy consumption for public lighting in Italy. The same legislation also imposes a minimum distance between street lamps of about four times their height, so full cut off street lamps are the best solution to reduce both light pollution and electrical power usage.
Adjusting types of light sources.
Several different types of light sources exist, each having different properties that affect their appropriateness for certain tasks, particularly efficiency and spectral power distribution. It is often the case that inappropriate light sources have been selected for a task, either due to ignorance or because more sophisticated light sources were unavailable at the time of installation. Therefore, badly chosen light sources often contribute unnecessarily to light pollution and energy waste. By re-assessing and changing the light sources used, it is often possible to reduce energy use and pollutive effects while simultaneously greatly improving efficiency and visibility.
Some types of light sources are listed in order of energy efficiency in the table below.
Many astronomers request that nearby communities use low pressure sodium lights as much as possible, because the principal wavelength emitted is comparably easy to work around or in rare cases filter out. The low cost of operating sodium lights is another feature. In 1980, for example, San Jose, California, replaced all street lamps with low pressure sodium lamps, whose light is easier for nearby Lick Observatory to filter out. Similar programs are now in place in Arizona and Hawaii.
Disadvantages of low pressure sodium lighting are that fixtures must usually be larger than competing fixtures, and that color cannot be distinguished, due to its emitting principally a single wavelength of light (see security lighting). Due to the substantial size of the lamp, particularly in higher wattages such as 135 W and 180 W, control of light emissions from low pressure sodium luminaires is more difficult. For applications requiring more precise direction of light (such as narrow roadways) the native lamp efficacy advantage of this lamp type is decreased and may be entirely lost compared to high pressure sodium lamps. Allegations that this also leads to higher amounts of light pollution from luminaires running these lamps arise principally because of older luminaires with poor shielding, still widely in use in the UK and in some other locations. Modern low-pressure sodium fixtures with better optics and full shielding, and the decreased skyglow impacts of yellow light preserve the luminous efficacy advantage of low-pressure sodium and result in most cases is less energy consumption and less visible light pollution. Unfortunately, due to continued lack of accurate information, many lighting professionals continue to disparage low-pressure sodium, contributing to its decreased acceptance and specification in lighting standards and therefore its use. Another disadvantage of low-pressure sodium lamps is that some people find the characteristic yellow light very displeasing aesthetically.
Because of the scatter of light by the atmosphere, different sources produce dramatically different amounts of skyglow from the same amount of light sent into the atmosphere.
Re-designing lighting plans.
In some cases, evaluation of existing plans has determined that more efficient lighting plans are possible. For instance, light pollution can be reduced by turning off unneeded outdoor lights, and only lighting stadiums when there are people inside. Timers are especially valuable for this purpose. One of the world's first coordinated "legislative" efforts to reduce the adverse effect of this pollution on the environment began in Flagstaff, Arizona, in the U.S. There, over three decades of ordinance development has taken place, with the full support of the population, often with government support, with community advocates, and with the help of major local observatories, including the United States Naval Observatory Flagstaff Station. Each component helps to educate, protect and enforce the imperatives to intelligently reduce detrimental light pollution.
One example of a lighting plan assessment can be seen in a report originally commissioned by the Office of the Deputy Prime Minister in the United Kingdom, and now available through the Department for Communities and Local Government. The report details a plan to be implemented throughout the UK, for designing lighting schemes in the countryside, with a particular focus on preserving the environment.
In another example, the city of Calgary has recently replaced most residential street lights with models that are comparably energy efficient. The motivation is primarily operation cost and environmental conservation. The costs of installation are expected to be regained through energy savings within six to seven years.
The Swiss Agency for Energy Efficiency (SAFE) uses a concept that promises to be of great use in the diagnosis and design of road lighting, ""consommation électrique spécifique" ("CES")", which can be translated into English as "specific electric power consumption (SEC)". Thus, based on observed lighting levels in a wide range of Swiss towns, SAFE has defined target values for electric power consumption per metre for roads of various categories. Thus, SAFE currently recommends an SEC of 2 to 3 watts per meter for roads of less than 10 metre width (4 to 6 watts per metre for wider roads). Such a measure provides an easily applicable environmental protection constraint on conventional "norms", which usually are based on the recommendations of lighting manufacturing interests, who may not take into account environmental criteria. In view of ongoing progress in lighting technology, target SEC values will need to be periodically revised downwards.
A newer method for predicting and measuring various aspects of light pollution was described in the journal Lighting Research Technology (September 2008). Scientists at Rensselaer Polytechnic Institute's Lighting Research Center have developed a comprehensive method called Outdoor Site-Lighting Performance (OSP), which allows users to quantify, and thus optimize, the performance of existing and planned lighting designs and applications to minimize excessive or obtrusive light leaving the boundaries of a property. OSP can be used by lighting engineers immediately, particularly for the investigation of glow and trespass (glare analyses are more complex to perform and current commercial software does not readily allow them), and can help users compare several lighting design alternatives for the same site.
In the effort to reduce light pollution, researchers have developed a "Unified System of Photometry," which is a way to measure how much or what kind of street lighting is needed. The Unified System of Photometry allows light fixtures to be designed to reduce energy use while maintaining or improving perceptions of visibility, safety, and security. There was a need to create a new system of light measurement at night because the biological way in which the eye’s rods and cones process light is different in nighttime conditions versus daytime conditions. Using this new system of photometry, results from recent studies have indicated that replacing traditional, yellowish, high-pressure sodium (HPS) lights with "cool" white light sources, such as induction, fluorescent, ceramic metal halide, or LEDs can actually reduce the amount of electric power used for lighting while maintaining or improving visibility in nighttime conditions.
The International Commission on Illumination, also known as the CIE from its French title, la Commission Internationale de l'Eclairage, will soon be releasing its own form of unified photometry for outdoor lighting.

</doc>
<doc id="18285" url="https://en.wikipedia.org/wiki?curid=18285" title="Lagrangian point">
Lagrangian point

In celestial mechanics, the Lagrangian points (; also Lagrange points, L-points, or libration points) are positions in an orbital configuration of two large bodies where a small object affected only by gravity can maintain a stable position relative to the two large bodies. The Lagrange points mark positions where the combined gravitational pull of the two large masses provides precisely the centripetal force required to orbit with them. There are five such points, labeled L1 to L5, all in the orbital plane of the two large bodies. The first three are on the line connecting the two large bodies and the last two, L4 and L5, each form an equilateral triangle with the two large bodies. The two latter points are stable, which implies that objects can orbit around them in a rotating coordinate system tied to the two large bodies.
Several planets have minor planets near their L4 and L5 points (trojans) with respect to the Sun, with Jupiter in particular having more than a million of these. Artificial satellites have been placed at L1 and L2 with respect to the Sun and Earth, and Earth and the Moon for various purposes, and the Lagrangian points have been proposed for a variety of future uses in space exploration.
History.
The three collinear Lagrange points (L1, L2, L3) were discovered by Leonhard Euler a few years before Lagrange discovered the remaining two.
In 1772, Joseph-Louis Lagrange published an "Essay on the three-body problem". In the first chapter he considered the general three-body problem. From that, in the second chapter, he demonstrated two special constant-pattern solutions, the collinear and the equilateral, for any three masses, with circular orbits.
Lagrange points.
The five Lagrangian points are labeled and defined as follows:
The point lies on the line defined by the two large masses M1 and M2, and between them. It is the most intuitively understood of the Lagrangian points: the one where the gravitational attraction of M2 partially cancels M1's gravitational attraction.
The point lies on the line through the two large masses, beyond the smaller of the two. Here, the gravitational forces of the two large masses balance the centrifugal effect on a body at .
The point lies on the line defined by the two large masses, beyond the larger of the two.
The ' and ' points lie at the third corners of the two equilateral triangles in the plane of orbit whose common base is the line between the centers of the two masses, such that the point lies behind () or ahead () of the smaller mass with regard to its orbit around the larger mass.
The triangular points ( and ) are stable equilibria, provided that the ratio of M1/M2 is greater than 24.96. This is the case for the Sun–Earth system, the Sun–Jupiter system, and, by a smaller margin, the Earth–Moon system. When a body at these points is perturbed, it moves away from the point, but the factor opposite of that which is increased or decreased by the perturbation (either gravity or angular momentum-induced speed) will also increase or decrease, bending the object's path into a stable, kidney-bean-shaped orbit around the point (as seen in the corotating frame of reference).
In contrast to and , where stable equilibrium exists, the points , , and are positions of unstable equilibrium. Any object orbiting at , , or will tend to fall out of orbit; it is therefore rare to find natural objects there, and spacecraft inhabiting these areas must employ station keeping in order to maintain their position.
Natural objects at Lagrangian points.
It is common to find objects at or orbiting the and points of natural orbital systems. These are commonly called "trojans"; in the 20th century, asteroids discovered orbiting at the Sun–Jupiter and points were named after characters from Homer's "Iliad". Asteroids at the point, which leads Jupiter, are referred to as the "Greek camp", whereas those at the point are referred to as the "Trojan camp".
Other examples of natural objects orbiting at Lagrange points:
Mathematical details.
Lagrangian points are the constant-pattern solutions of the restricted three-body problem. For example, given two massive bodies in orbits around their common barycenter, there are five positions in space where a third body, of comparatively negligible mass, could be placed so as to maintain its position relative to the two massive bodies. As seen in a rotating reference frame that matches the angular velocity of the two co-orbiting bodies, the gravitational fields of two massive bodies combined with the minor body's centrifugal force are in balance at the Lagrangian points, allowing the smaller third body to be relatively stationary with respect to the first two.
The location of L1 is the solution to the following equation, balancing gravitation and the centrifugal force:
formula_1
where "r" is the distance of the L1 point from the smaller object, "R" is the distance between the two main objects, and M1 and M2 are the masses of the large and small object, respectively. (The quantity in parentheses on the right is the distance of L1 from the center of mass.) Solving this for "r" involves solving a quintic function, but if the mass of the smaller object (M2) is much smaller than the mass of the larger object (M1) then and are at approximately equal distances "r" from the smaller object, equal to the radius of the Hill sphere, given by:
This distance can be described as being such that the orbital period, corresponding to a circular orbit with this distance as radius around M2 in the absence of M1, is that of M2 around M1, divided by formula_3:
The location of L2 is the solution to the following equation, balancing gravitation and inertia:
formula_5
with parameters defined as for the L1 case. Again, if the mass of the smaller object (M2) is much smaller than the mass of the larger object (M1) then L2 is at approximately the radius of the Hill sphere, given by:
L3.
The location of L3 is the solution to the following equation, balancing gravitation and the centrifugal force:
formula_7
with parameters defined as for the L1 and L2 cases except that "r" now indicates how much closer L3 is to the more massive object than the smaller object. If the mass of the smaller object (M2) is much smaller than the mass of the larger object (M1) then:
and.
The reason these points are in balance is that, at and , the distances to the two masses are equal. Accordingly, the gravitational forces from the two massive bodies are in the same ratio as the masses of the two bodies, and so the resultant force acts through the barycenter of the system; additionally, the geometry of the triangle ensures that the resultant acceleration is to the distance from the barycenter in the same ratio as for the two massive bodies. The barycenter being both the center of mass and center of rotation of the three-body system, this resultant force is exactly that required to keep the smaller body at the Lagrange point in orbital equilibrium with the other two larger bodies of system. (Indeed, the third body need not have negligible mass.) The general triangular configuration was discovered by Lagrange in work on the three-body problem.
Stability.
Although the , , and points are nominally unstable, it turns out that it is possible to find (unstable) periodic orbits around these points, at least in the restricted three-body problem. These periodic orbits, referred to as "halo" orbits, do not exist in a full "n"-body dynamical system such as the Solar System. However, quasi-periodic (i.e. bounded but not precisely repeating) orbits following Lissajous-curve trajectories do exist in the "n"-body system. These quasi-periodic Lissajous orbits are what most of Lagrangian-point missions to date have used. Although they are not perfectly stable, a relatively modest effort at station keeping can allow a spacecraft to stay in a desired Lissajous orbit for an extended period of time. It also turns out that, at least in the case of Sun–Earth- missions, it is actually preferable to place the spacecraft in a large-amplitude () Lissajous orbit, instead of having it sit at the Lagrangian point, because this keeps the spacecraft off the direct line between Sun and Earth, thereby reducing the impact of solar interference on Earth–spacecraft communications. Similarly, a large-amplitude Lissajous orbit around can keep a probe out of Earth's shadow and therefore ensures a better illumination of its solar panels.
Spaceflight applications.
Earth–Moon allows comparatively easy access to Lunar and Earth orbits with minimal change in velocity and this has as an advantage to position a half-way manned space station intended to help transport cargo and personnel to the Moon and back.
Earth–Moon would be a good location for a communications satellite covering the Moon's far side and would be "an ideal location" for a propellant depot as part of the proposed depot-based space transportation architecture.
Sun–Earth is suited for making observations of the Sun–Earth system. Objects here are never shadowed by Earth or the Moon. The first mission of this type was the International Sun Earth Explorer 3 (ISEE-3) mission used as an interplanetary early warning storm monitor for solar disturbances.
Sun–Earth is a good spot for space-based observatories. Because an object around will maintain the same relative position with respect to the Sun and Earth, shielding and calibration are much simpler. It is, however, slightly beyond the reach of Earth's umbra, so solar radiation is not completely blocked. From this point, the Sun, Earth and Moon are relatively closely positioned together in the sky, and hence leave a large field of view without interference – this is especially helpful for infrared astronomy.
Sun–Earth was a popular place to put a "Counter-Earth" in pulp science fiction and comic books. Once space-based observation became possible via satellites and probes, it was shown to hold no such object. The Sun–Earth is unstable and could not contain an object, large or small, for very long. This is because the gravitational forces of the other planets are stronger than that of Earth (Venus, for example, comes within 0.3 AU of this every 20 months).
A spacecraft orbiting near Sun–Earth would be able to closely monitor the evolution of active sunspot regions before they rotate into a geoeffective position, so that a 7-day early warning could be issued by the NOAA Space Weather Prediction Center. Moreover, a satellite near Sun–Earth would provide very important observations not only for Earth forecasts, but also for deep space support (Mars predictions and for manned mission to near-Earth asteroids). In 2010, spacecraft transfer trajectories to Sun–Earth were studied and several designs were considered.
Scientists at the B612 Foundation are planning to use Venus's L3 point to position their planned Sentinel telescope, which aims to look back towards Earth's orbit and compile a catalogue of near-Earth asteroids.
Missions to Lagrangian points generally orbit the points rather than occupy them directly.
Another interesting and useful property of the collinear Lagrangian points and their associated Lissajous orbits is that they serve as "gateways" to control the chaotic trajectories of the Interplanetary Transport Network.
Spacecraft at Sun–Earth L1.
International Sun Earth Explorer 3 (ISEE-3) began its mission at the Sun–Earth L1 before leaving to intercept a comet in 1982. The Sun–Earth L1 is also the point to which the Reboot ISEE-3 mission was attempting to return the craft as the first phase of a recovery mission (as of September 25, 2014 all efforts have failed and contact was lost).
Solar and Heliospheric Observatory (SOHO) is stationed in a halo orbit at , and the Advanced Composition Explorer (ACE) in a Lissajous orbit. WIND is also at .
Deep Space Climate Observatory (DSCOVR), launched on 11 February 2015, began orbiting L1 on 8 June 2015 to study the solar wind and its effects on Earth. DSCOVR is unofficially known as GORESAT, because it carries a camera always oriented to Earth and capturing full-frame photos the planet similar to the Blue Marble. This concept was proposed by then-Vice President of the United States Al Gore in 1998 and was a centerpiece in his film An Inconvenient Truth.
LISA Pathfinder (LPF) was launched on 3 December 2015, and arrived at on 22 January 2016, where, among other experiments, it will test the technology needed by (e)LISA to detect gravitational waves. LISA Pathfinder uses an instrument consisting of two small gold alloy cubes.
Spacecraft at Sun–Earth L2.
Spacecraft at the Sun–Earth L2 point are in a Lissajous orbit until decommissioned, when they are sent into a heliocentric graveyard orbit.
List of missions to Lagrangian points.
Color key:

</doc>
<doc id="18286" url="https://en.wikipedia.org/wiki?curid=18286" title="Lucid dream">
Lucid dream

A lucid dream is any dream during which the dreamer is aware that they are dreaming.
During lucid dreaming, the dreamer may allegedly be able to exert some degree of control over the dream characters, narrative, and environment.
The term 'lucid dream' was coined by Dutch author and psychiatrist Frederik van Eeden in his 1913 article "A Study of Dreams," though descriptions of dreamers being aware that they are dreaming predates the term, and is closely related to ancient meditative praxis originating in India.
History.
Western history.
Ancient.
The earliest references to a phenomenon comparable to that now signified by the term 'lucid dream' In Western culture are found in ancient Greek writings. For example, the philosopher Aristotle wrote: 'often when one is asleep, there is something in consciousness which declares that what then presents itself is but a dream'. Meanwhile, the physician Galen of Pergamon used lucid dreams as a form of therapy. In addition, a letter written by St. Augustine of Hippo in 415 AD tells the story of a dreamer, Doctor Gennadius, and refers to lucid dreaming.
17th century.
Philosopher and physician Sir Thomas Browne (1605–1682) was fascinated by dreams and described his own ability to lucid dream in his "Religio Medici", stating: '...yet in one dream I can compose a whole Comedy, behold the action, apprehend the jests and laugh my self awake at the conceits thereof'.
Also, Samuel Pepys in his diary entry for 15 August 1665 records a dream, stating: "I had my Lady Castlemayne in my arms and was admitted to use all the dalliance I desired with her, and then dreamt that this could not be awake, but that it was only a dream".
19th century.
In 1867, the French sinologist Marie-Jean-Léon, Marquis d'Hervey de Saint Denys anonymously published "Les Reves et Les Moyens de Les Diriger: Observations Pratiques" ('Dreams and the ways to direct them: practical observations'), in which describes his own experiences of lucid dreaming, and proposes that it is possible for anyone to learn to dream consciously.
20th century.
In 1923, Dutch psychiatrist and writer Frederik (Willem) van Eeden (1860–1932) coined the term 'lucid dream' in an article entitled ""A Study of Dreams"".
Some have suggested that the term is a misnomer because van Eden was referring to a phenomenon more specific than a 'vivid' or 'lucid' dream. Van Eden intended the term lucid to denote "having insight", as in the phrase "a lucid interval" applied to someone in temporary remission from a psychosis, rather than as a reference to the perceptual quality of the experience, which may or may not be clear and vivid
Eastern history.
Cultivating the dreamer's ability to be aware that he or she is dreaming is central to both the Tibeatan Buddhist practice of dream Yoga, and the ancient Indian Hindu practice of Yoga nidra. Furthermore, the cultivation of such awareness was common practice among early Buddhists.
Definition.
Paul Tholey, a German oneirologist and Gestalt theorist, laid the epistemological basis for the research of lucid dreams, proposing seven different conditions of clarity that a dream must fulfill in order to be defined as a lucid dream:
Later, In 1992, a study by Deirdre Barrett examined whether lucid dreams contained four "corollaries" of lucidity:
Barrett found less than a quarter of lucidity accounts exhibited all four.
Subsequently, Stephen LaBerge, a psychophysiologist and a leader in the scientific study of lucid dreaming, studied the prevalence of being able to control the dream scenario among lucid dreams, and found that while dream control and dream awareness are correlated, neither requires the other. LaBerge found dreams that exhibit one clearly without the capacity for the other; also, in some dreams where the dreamer is lucid and aware they could exercise control, they choose simply to observe.
Induction.
Currently, there are two ways that lucid dreams can be induced. Lucid dreams can be induced during the dream, in which case this is called a Dream Induced Lucid dream (DILD). In a DILD, it is usually the unrealistic or strange nature of a dream that causes the dreamer to suddenly come to the realization that they are indeed dreaming, and thus potentially entering the lucid dream state. Triggers such as reality checks or doing "real-life" tasks such as trying to read a piece of text in a dream may be enough to push an individual who is experienced with lucid dreams into a DILD. There are many other ways of triggering lucid dream states that even beginners can try, including meditation and dream incubation, dream signs, and self-hypnosis.
The second type of lucid dream, and the more difficult type to achieve, is a Wake Induced Lucid Dream (WILD), which stems from Tibetan Dream Yoga. During a WILD, the consciousness is passed from the awakened state to the sleep state directly by the dreamer. This lucid dreaming technique can take a very long time to master, but can also be an incredibly useful tool for individuals who suffer from anxiety disorders, PTSD, night terrors, and other mental illnesses that can affect the sleep cycles and the emotional well beings of an individual. In addition, a WILD can be triggered on command, and is often more vivid than a DILD. Achieving a WILD usually involves heavy meditation, concentration and patience, but the results can be both beneficial and enlightening.
Scientific commentary.
In 1968, Celia Green analyzed the main characteristics of such dreams, reviewing previously published literature on the subject and incorporating new data from participants of her own. She concluded that lucid dreams were a category of experience quite distinct from ordinary dreams, and predicted that they would turn out to be associated with rapid eye movement sleep (REM sleep). Green was also the first to link lucid dreams to the phenomenon of false awakenings.
Lucid dreaming was subsequently researched by asking dreamers to perform pre-determined physical responses while experiencing a dream, including eye movement signals. The first experiment of this type was conducted in the late 1970s by British parapsychologist Keith Hearne. A volunteer named Alan Worsley used eye movements to signal the onset of lucidity, which were recorded by a polysomnograph machine.
The first peer-reviewed article on the subject was published by Stephen LaBerge at Stanford University, who developed such techniques as part of his doctoral dissertation. In 1985, LaBerge performed a pilot study that showed that time perception while counting during a lucid dream is about the same as during waking life. Lucid dreamers counted out ten seconds while dreaming, signaling the start and the end of the count with a pre-arranged eye signal measured with electrooculogram recording. LaBerge's results were confirmed by German researchers D. Erlacher and M. Schredl, in 2004.
In a further study by Stephen LaBerge, four subjects were compared either singing while dreaming or counting while dreaming. LaBerge found that the right hemisphere was more active during singing and the left hemisphere was more active during counting.
Neuroscientist J. Allan Hobson has hypothesized what might be occurring in the brain while lucid. The first step to lucid dreaming is recognizing one is dreaming. This recognition might occur in the dorsolateral prefrontal cortex, which is one of the few areas deactivated during REM sleep and where working memory occurs. Once this area is activated and the recognition of dreaming occurs, the dreamer must be cautious to let the dream continue but be conscious enough to remember that it is a dream. While maintaining this balance, the amygdala and parahippocampal cortex might be less intensely activated. To continue the intensity of the dream hallucinations, it is expected the pons and the parieto-occipital junction stay active.
Using Electroencephalography (EEG) and other Polysomnographical measurments, LaBerge and others have shown that lucid dreams begin in the Rapid Eye Movement (REM) stage of sleep. LaBerge also proposes that there are higher amounts of beta-1 frequency band (13–19 Hz) brain wave activity experienced by lucid dreamers, hence there is an increased amount of activity in the parietal lobes making lucid dreaming a conscious process.
Clinical application in treating nightmares.
It has been suggested that sufferers of nightmares could benefit from the ability to be aware they are indeed dreaming. A pilot study was performed in 2006 that showed that lucid dreaming therapy treatment was successful in reducing nightmare frequency. This treatment consisted of exposure to the idea, mastery of the technique, and lucidity exercises. It was not clear what aspects of the treatment were responsible for the success of overcoming nightmares, though the treatment as a whole was successful.
Australian psychologist Milan Colic has explored the application of principles from narrative therapy with clients' lucid dreams, to reduce the impact not only of nightmares during sleep, but also depression, self-mutilation, and other problems in waking life. Colic found that clients preferred direction for their lives, as identified during therapeutic conversations, could lessen the distressing content of dreams, while understandings about life—and even characters—from lucid dreams could be invoked in "real" life with marked therapeutic benefits.
Psychotherapists have applied lucid dreaming as an application for therapy. Studies have shown that by inducing a lucid dream recurrent nightmares can be alleviated. This alleviation is unclear whether it is due to lucidity or the ability to alter the dream itself. A study performed by and van den Bout (2006) evaluated the validity of lucid dreaming treatment (LDT) in chronic nightmare sufferers. LDT is composed of exposure, mastery, and lucidity exercises.
Results of lucid dreaming treatment revealed that the nightmare frequency of the treatment groups had decreased. In another study, Spoormaker, van den Bout, and Meijer (2003) investigated lucid dreaming treatment for nightmares by testing eight subjects who received a one-hour individual session, which consisted of lucid dreaming exercises. The results of the study revealed that the nightmare frequency had decreased and the sleep quality had slightly increased. Holzinger, Klösch, and Saletu managed a psychotherapy study under the working name of ‘Cognition during dreaming – a therapeutic intervention in nightmares’, which included 40 subjects, men and women, 18–50 years old, whose life quality was significantly altered by nightmares. The test subjects were administered Gestalt group therapy and 24 of them were also taught to enter the state of lucid dreaming by Holzinger. This was purposefully taught in order to change the course of their nightmares. The subjects then reported the diminishment of their nightmare prevalence from 2–3 times a week to 2–3 times per month.
Creative application.
In her book "The Committee of Sleep," Deirdre Barrett describes how some experienced lucid dreamers have learned to remember specific practical goals such as artists looking for inspiration seeking a show of their own work once they become lucid or computer programmers looking for a screen with their desired code. However, most of these dreamers had many experiences of failing to recall waking objectives before gaining this level of control.
Skepticism.
Some skeptics of lucid dreaming suggest that it is not a state of sleep, but of brief wakefulness, or 'micro-awakening'. Experiments by Stephen LaBerge used 'perception of the outside world' as a criterion for wakefulness while studying lucid dreamers, and their sleep state was corroborated with physiological measurements. Nonetheless, LaBerge admits the criterion is subjective.
Others point out that there is no way to prove the truth of lucid dreaming other than to ask the dreamer. According to Dr. Patrick McNamara of Boston University, there is no scientific way to know for certain that someone is dreaming other than to wake them up and ask them. Meanwhile, philosopher Norman Malcolm argued against the possibility of checking the accuracy of dream reports, pointing out that 'the only criterion of the truth of a statement that someone has had a certain dream is, essentially, his saying so'. Malcolm further describes lucid dreaming as absurd and impossible, recalling as an example, "I dreamt that I realised I was dreaming, dreamt that I was affecting the course of my dream, and then dreamt that I woke myself up by telling myself to wake up."
References.
Notes
Further reading

</doc>
<doc id="18288" url="https://en.wikipedia.org/wiki?curid=18288" title="Lyric">
Lyric

Lyric may refer to:

</doc>
<doc id="18290" url="https://en.wikipedia.org/wiki?curid=18290" title="Light-emitting diode">
Light-emitting diode

A light-emitting diode (LED) is a two-lead semiconductor light source. It is a p–n junction diode, which emits light when activated. When a suitable voltage is applied to the leads, electrons are able to recombine with electron holes within the device, releasing energy in the form of photons. This effect is called electroluminescence, and the color of the light (corresponding to the energy of the photon) is determined by the energy band gap of the semiconductor.
An LED is often small in area (less than 1 mm2) and integrated optical components may be used to shape its radiation pattern.
Appearing as practical electronic components in 1962, the earliest LEDs emitted low-intensity infrared light.
Infrared LEDs are still frequently used as transmitting elements in remote-control circuits, such as those in remote controls for a wide variety of consumer electronics.
The first visible-light LEDs were also of low intensity, and limited to red. Modern LEDs are available across the visible, ultraviolet, and infrared wavelengths, with very high brightness.
Early LEDs were often used as indicator lamps for electronic devices, replacing small incandescent bulbs. They were soon packaged into numeric readouts in the form of seven-segment displays, and were commonly seen in digital clocks.
Recent developments in LEDs permit them to be used in environmental and task lighting. LEDs have many advantages over incandescent light sources including lower energy consumption, longer lifetime, improved physical robustness, smaller size, and faster switching. Light-emitting diodes are now used in applications as diverse as aviation lighting, automotive headlamps, advertising, general lighting, traffic signals, camera flashes and lighted wallpaper. , LEDs powerful enough for room lighting remain somewhat more expensive, and require more precise current and heat management, than compact fluorescent lamp sources of comparable output.
LEDs have allowed new text, video displays, and sensors to be developed, while their high switching rates are also used in advanced communications technology.
History.
Discoveries and early devices.
Electroluminescence as a phenomenon was discovered in 1907 by the British experimenter H. J. Round of Marconi Labs, using a crystal of silicon carbide and a cat's-whisker detector.
Soviet inventor Oleg Losev reported creation of the first LED in 1927. His research was distributed in Soviet, German and British scientific journals, but no practical use was made of the discovery for several decades. Kurt Lehovec, Carl Accardo and Edward Jamgochian, explained these first light-emitting diodes in 1951 using an apparatus employing SiC crystals with a current source of battery or pulse generator and with a comparison to a variant, pure, crystal in 1953.
Rubin Braunstein of the Radio Corporation of America reported on infrared emission from gallium arsenide (GaAs) and other semiconductor alloys in 1955. Braunstein observed infrared emission generated by simple diode structures using gallium antimonide (GaSb), GaAs, indium phosphide (InP), and silicon-germanium (SiGe) alloys at room temperature and at 77 Kelvin.
In 1957, Braunstein further demonstrated that the rudimentary devices could be used for non-radio communication across a short distance. As noted by Kroemer Braunstein".. had set up a simple optical communications link: Music emerging from a record player was used via suitable electronics to modulate the forward current of a GaAs diode. The emitted light was detected by a PbS diode some distance away. This signal was fed into an audio amplifier, and played back by a loudspeaker. Intercepting the beam stopped the music. We had a great deal of fun playing with this setup." This setup presaged the use of LEDs for optical communication applications.
In September 1961, while working at Texas Instruments in Dallas, Texas, James R. Biard and Gary Pittman discovered near-infrared (900 nm) light emission from a tunnel diode they had constructed on a GaAs substrate. By October 1961, they had demonstrated efficient light emission and signal coupling between a GaAs p-n junction light emitter and an electrically-isolated semiconductor photodetector. On August 8, 1962, Biard and Pittman filed a patent titled "Semiconductor Radiant Diode" based on their findings, which described a zinc diffused p–n junction LED with a spaced cathode contact to allow for efficient emission of infrared light under forward bias. After establishing the priority of their work based on engineering notebooks predating submissions from G.E. Labs, RCA Research Labs, IBM Research Labs, Bell Labs, and Lincoln Lab at MIT, the U.S. patent office issued the two inventors the patent for the GaAs infrared (IR) light-emitting diode (U.S. Patent US3293513), the first practical LED. Immediately after filing the patent, Texas Instruments (TI) began a project to manufacture infrared diodes. In October 1962, TI announced the first LED commercial product (the SNX-100), which employed a pure GaAs crystal to emit a 890 nm light output. In October 1963, TI announced the first commercial hemispherical LED, the SNX-110.
The first visible-spectrum (red) LED was developed in 1962 by Nick Holonyak, Jr., while working at General Electric Company. Holonyak first reported his LED in the journal "Applied Physics Letters" on the December 1, 1962.
M. George Craford, a former graduate student of Holonyak, invented the first yellow LED and improved the brightness of red and red-orange LEDs by a factor of ten in 1972. In 1976, T. P. Pearsall created the first high-brightness, high-efficiency LEDs for optical fiber telecommunications by inventing new semiconductor materials specifically adapted to optical fiber transmission wavelengths.
Initial commercial development.
The first commercial LEDs were commonly used as replacements for incandescent and neon indicator lamps, and in seven-segment displays, first in expensive equipment such as laboratory and electronics test equipment, then later in such appliances as TVs, radios, telephones, calculators, as well as watches (see list of signal uses).
Until 1968, visible and infrared LEDs were extremely costly, in the order of US$200 per unit, and so had little practical use.
The Monsanto Company was the first organization to mass-produce visible LEDs, using gallium arsenide phosphide (GaAsP) in 1968 to produce red LEDs suitable for indicators. Hewlett Packard (HP) introduced LEDs in 1968, initially using GaAsP supplied by Monsanto. These red LEDs were bright enough only for use as indicators, as the light output was not enough to illuminate an area. Readouts in calculators were so small that plastic lenses were built over each digit to make them legible. Later, other colors became widely available and appeared in appliances and equipment. In the 1970s commercially successful LED devices at less than five cents each were produced by Fairchild Optoelectronics. These devices employed compound semiconductor chips fabricated with the planar process invented by Dr. Jean Hoerni at Fairchild Semiconductor. The combination of planar processing for chip fabrication and innovative packaging methods enabled the team at Fairchild led by optoelectronics pioneer Thomas Brandt to achieve the needed cost reductions. These methods continue to be used by LED producers.
Most LEDs were made in the very common 5 mm T1¾ and 3 mm T1 packages, but with rising power output, it has grown increasingly necessary to shed excess heat to maintain reliability, so more complex packages have been adapted for efficient heat dissipation. Packages for state-of-the-art high-power LEDs bear little resemblance to early LEDs.
Blue LED.
Blue LEDs were first developed by RCA in 1972. SiC-types were first commercially sold in the United States by Cree in 1989. However, neither of these initial blue LEDs were very bright.
The first high-brightness blue LED was demonstrated by Shuji Nakamura of Nichia Corporation in 1994 and was based on InGaN. In parallel, Isamu Akasaki and Hiroshi Amano in Nagoya were working on developing the important GaN nucleation on sapphire substrates and the demonstration of p-type doping of GaN. Nakamura, Akasaki and Amano were awarded the 2014 Nobel prize in physics for their work. In 1995, Alberto Barbieri at the Cardiff University Laboratory (GB) investigated the efficiency and reliability of high-brightness LEDs and demonstrated a "transparent contact" LED using indium tin oxide (ITO) on (AlGaInP/GaAs).
In 2001 and 2002, processes for growing gallium nitride (GaN) LEDs on silicon were successfully demonstrated. In January 2012, Osram demonstrated high-power InGaN LEDs grown on silicon substrates commercially.
White LEDs and the Illumination breakthrough.
The attainment of high efficiency in blue LEDs was quickly followed by the development of the first white LED. In this device a :Ce (known as "YAG") phosphor coating on the emitter absorbs some of the blue emission and produces yellow light through fluorescence. The combination of that yellow with remaining blue light appears white to the eye. However using different phosphors (fluorescent materials) it also became possible to instead produce green and red light through fluorescence. The resulting mixture of red, green and blue is not only perceived by humans as white light but is superior for illumination in terms of color rendering, whereas one cannot appreciate the color of red or green objects illuminated only by the yellow (and remaining blue) wavelengths from the YAG phosphor.
The first white LEDs were expensive and inefficient. However, the light output of LEDs has increased exponentially, with a doubling occurring approximately every 36 months since the 1960s (similar to Moore's law). This trend is generally attributed to the parallel development of other semiconductor technologies and advances in optics and materials science, and has been called Haitz's law after Dr. Roland Haitz.
The light output and efficiency of blue and near-ultraviolet LEDs rose as the cost of reliable devices fell: this led to the use of (relatively) high-power white-light LEDs for the purpose of illumination which are replacing incandescent and fluorescent lighting.
White LEDs can now produce over 300 lumens per watt of electricity while lasting up to 100,000 hours. Compared to incandescent bulbs, this amounts not only to a huge increase in electrical efficiency, but a similar or better prorated cost for the bulbs.
Working principle.
A P-N junction can convert absorbed light energy into a proportional electric current. The same process is reversed here (i.e. the P-N junction emits light when electrical energy is applied to it). This phenomenon is generally called electroluminescence, which can be defined as the emission of light from a semi-conductor under the influence of an electric field. The charge carriers recombine in a forward-biased P-N junction as the electrons cross from the N-region and recombine with the holes existing in the P-region. Free electrons are in the conduction band of energy levels, while holes are in the valence energy band. Thus the energy level of the holes will be lesser than the energy levels of the electrons. Some portion of the energy must be dissipated in order to recombine the electrons and the holes. This energy is emitted in the form of heat and light.
The electrons dissipate energy in the form of heat for silicon and germanium diodes but in gallium arsenide phosphide (GaAsP) and gallium phosphide (GaP) semiconductors, the electrons dissipate energy by emitting photons. If the semiconductor is translucent, the junction becomes the source of light as it is emitted, thus becoming a light-emitting diode, but when the junction is reverse biased no light will be produced by the LED and, on the contrary, the device may also be damaged.
Technology.
Physics.
The LED consists of a chip of semiconducting material doped with impurities to create a "p-n junction". As in other diodes, current flows easily from the p-side, or anode, to the n-side, or cathode, but not in the reverse direction. Charge-carriers—electrons and holes—flow into the junction from electrodes with different voltages. When an electron meets a hole, it falls into a lower energy level and releases energy in the form of a photon.
The wavelength of the light emitted, and thus its color, depends on the band gap energy of the materials forming the "p-n junction". In silicon or germanium diodes, the electrons and holes usually recombine by a "non-radiative transition", which produces no optical emission, because these are indirect band gap materials. The materials used for the LED have a direct band gap with energies corresponding to near-infrared, visible, or near-ultraviolet light.
LED development began with infrared and red devices made with gallium arsenide. Advances in materials science have enabled making devices with ever-shorter wavelengths, emitting light in a variety of colors.
LEDs are usually built on an n-type substrate, with an electrode attached to the p-type layer deposited on its surface. P-type substrates, while less common, occur as well. Many commercial LEDs, especially GaN/InGaN, also use sapphire substrate.
Most materials used for LED production have very high refractive indices. This means that much of the light will be reflected back into the material at the material/air surface interface. Thus, light extraction in LEDs is an important aspect of LED production, subject to much research and development.
Refractive index.
Bare uncoated semiconductors such as silicon exhibit a very high refractive index relative to open air, which prevents passage of photons arriving at sharp angles relative to the air-contacting surface of the semiconductor due to total internal reflection. This property affects both the light-emission efficiency of LEDs as well as the light-absorption efficiency of photovoltaic cells. The refractive index of silicon is 3.96 (at 590 nm), while air is 1.0002926.
In general, a flat-surface uncoated LED semiconductor chip will emit light only perpendicular to the semiconductor's surface, and a few degrees to the side, in a cone shape referred to as the "light cone", "cone of light", or the "escape cone". The maximum angle of incidence is referred to as the critical angle. When this angle is exceeded, photons no longer escape the semiconductor but are instead reflected internally inside the semiconductor crystal as if it were a mirror.
Internal reflections can escape through other crystalline faces, if the incidence angle is low enough and the crystal is sufficiently transparent to not re-absorb the photon emission. But for a simple square LED with 90-degree angled surfaces on all sides, the faces all act as equal angle mirrors. In this case most of the light can not escape and is lost as waste heat in the crystal.
A convoluted chip surface with angled facets similar to a jewel or fresnel lens can increase light output by allowing light to be emitted perpendicular to the chip surface while far to the sides of the photon emission point.
The ideal shape of a semiconductor with maximum light output would be a microsphere with the photon emission occurring at the exact center, with electrodes penetrating to the center to contact at the emission point. All light rays emanating from the center would be perpendicular to the entire surface of the sphere, resulting in no internal reflections. A hemispherical semiconductor would also work, with the flat back-surface serving as a mirror to back-scattered photons.
Transition coatings.
After the doping of the wafer, it is cut apart into individual dies. Each die is commonly called a chip.
Many LED semiconductor chips are encapsulated or potted in clear or colored molded plastic shells. The plastic shell has three purposes:
The third feature helps to boost the light emission from the semiconductor by acting as a diffusing lens, allowing light to be emitted at a much higher angle of incidence from the light cone than the bare chip is able to emit alone.
Efficiency and operational parameters.
Typical indicator LEDs are designed to operate with no more than 30–60 milliwatts (mW) of electrical power. Around 1999, Philips Lumileds introduced power LEDs capable of continuous use at one watt. These LEDs used much larger semiconductor die sizes to handle the large power inputs. Also, the semiconductor dies were mounted onto metal slugs to allow for heat removal from the LED die.
One of the key advantages of LED-based lighting sources is high luminous efficacy. White LEDs quickly matched and overtook the efficacy of standard incandescent lighting systems. In 2002, Lumileds made five-watt LEDs available with luminous efficacy of 18–22 lumens per watt (lm/W). For comparison, a conventional incandescent light bulb of 60–100 watts emits around 15 lm/W, and standard fluorescent lights emit up to 100 lm/W.
, Philips had achieved the following efficacies for each color. The lumen-per-watt efficiency value is derived using the luminosity function:
In September 2003, a new type of blue LED was demonstrated by Cree that consumes 24 mW at 20 milliamperes (mA). This produced a commercially packaged white light giving 65 lm/W at 20 mA, becoming the brightest white LED commercially available at the time, and more than four times as efficient as standard incandescents. In 2006, they demonstrated a prototype with a record white LED luminous efficacy of 131 lm/W at 20 mA. Nichia Corporation has developed a white LED with luminous efficacy of 150 lm/W at a forward current of 20 mA. Cree's XLamp XM-L LEDs, commercially available in 2011, produce 100 lm/W at their full power of 10 W, and up to 160 lm/W at around 2 W input power. In 2012, Cree announced a white LED giving 254 lm/W, and 303 lm/W in March 2014.
Practical general lighting needs high-power LEDs, of one watt or more. Typical operating currents for such devices begin at 350 mA.
These efficiencies are for the light-emitting diode only, held at low temperature in a lab. Since LEDs installed in real fixtures operate at higher temperature and with driver losses, real-world efficiencies are much lower. United States Department of Energy (DOE) testing of commercial LED lamps designed to replace incandescent lamps or CFLs showed that average efficacy was still about 46 lm/W in 2009 (tested performance ranged from 17 lm/W to 79 lm/W).
Efficiency droop.
Efficiency droop is the decrease in luminous efficiency of LEDs as the electric current increases above tens of milliamperes.
This effect was initially theorized to be related to elevated temperatures. Scientists proved the opposite to be true that, although the life of an LED would be shortened, the efficiency droop is less severe at elevated temperatures. The mechanism causing efficiency droop was identified in 2007 as Auger recombination, which was taken with mixed reaction. In 2013, a study confirmed Auger recombination as the cause of efficiency droop.
In addition to being less efficient, operating LEDs at higher electric currents creates higher heat levels which compromise the lifetime of the LED. Because of this increased heating at higher currents, high-brightness LEDs have an industry standard of operating at only 350 mA, which is a compromise between light output, efficiency, and longevity.
Possible solutions.
Instead of increasing current levels, luminance is usually increased by combining multiple LEDs in one bulb. Solving the problem of efficiency droop would mean that household LED light bulbs would need fewer LEDs, which would significantly reduce costs.
Researchers at the U.S. Naval Research Laboratory have found a way to lessen the efficiency droop. They found that the droop arises from non-radiative Auger recombination of the injected carriers. They created quantum wells with a soft confinement potential to lessen the non-radiative Auger processes.
Researchers at Taiwan National Central University and Epistar Corp are developing a way to lessen the efficiency droop by using ceramic aluminium nitride (AlN) substrates, which are more thermally conductive than the commercially used sapphire. The higher thermal conductivity reduces self-heating effects.
Lifetime and failure.
Solid-state devices such as LEDs are subject to very limited wear and tear if operated at low currents and at low temperatures. Typical lifetimes quoted are 25,000 to 100,000 hours, but heat and current settings can extend or shorten this time significantly.
The most common symptom of LED (and diode laser) failure is the gradual lowering of light output and loss of efficiency. Sudden failures, although rare, can also occur. Early red LEDs were notable for their short service life. With the development of high-power LEDs the devices are subjected to higher junction temperatures and higher current densities than traditional devices. This causes stress on the material and may cause early light-output degradation. To quantitatively classify useful lifetime in a standardized manner it has been suggested to use L70 or L50, which are the runtimes (typically given in thousands of hours) at which a given LED reaches 70% and 50% of initial light output, respectively.
LED performance is temperature dependent. Most manufacturers' published ratings of LEDs are for an operating temperature of . LEDs used outdoors, such as traffic signals or in-pavement signal lights, and that are used in climates where the temperature within the light fixture gets very high, could result in low signal intensities or even failure.
Since LED efficacy is inversely proportional to operating temperature, LED technology is well suited for supermarket freezer lighting. Because LEDs produce less waste heat than incandescent lamps, their use in freezers can save on refrigeration costs as well. However, they may be more susceptible to frost and snow buildup than incandescent lamps, so some LED lighting systems have been designed with an added heating circuit. Additionally, research has developed heat sink technologies that will transfer heat produced within the junction to appropriate areas of the light fixture.
Colors and materials.
Conventional LEDs are made from a variety of inorganic semiconductor materials. The following table shows the available colors with wavelength range, voltage drop and material:
Blue and ultraviolet.
The first blue-violet LED using magnesium-doped gallium nitride was made at Stanford University in 1972 by Herb Maruska and Wally Rhines, doctoral students in materials science and engineering. At the time Maruska was on leave from RCA Laboratories, where he collaborated with Jacques Pankove on related work. In 1971, the year after Maruska left for Stanford, his RCA colleagues Pankove and Ed Miller demonstrated the first blue electroluminescence from zinc-doped gallium nitride, though the subsequent device Pankove and Miller built, the first actual gallium nitride light-emitting diode, emitted green light. In 1974 the U.S. Patent Office awarded Maruska, Rhines and Stanford professor David Stevenson a patent for their work in 1972 (U.S. Patent US3819974 A) and today magnesium-doping of gallium nitride continues to be the basis for all commercial blue LEDs and laser diodes. These devices built in the early 1970s had too little light output to be of practical use and research into gallium nitride devices slowed. In August 1989, Cree introduced the first commercially available blue LED based on the indirect bandgap semiconductor, silicon carbide (SiC). SiC LEDs had very low efficiency, no more than about 0.03%, but did emit in the blue portion of the visible light spectrum.
In the late 1980s, key breakthroughs in GaN epitaxial growth and p-type doping ushered in the modern era of GaN-based optoelectronic devices. Building upon this foundation, Dr. Moustakas at Boston University patented a method for producing high-brightness blue LEDs using a new two-step process. Two years later, in 1993, high-brightness blue LEDs were demonstrated again by Shuji Nakamura of Nichia Corporation using a gallium nitride growth process similar to Dr. Moustakas's. Both Dr. Moustakas and Mr. Nakamura were issued separate patents, which confused the issue of who was the original inventor (partly because although Dr. Moustakas invented his first, Dr. Nakamura filed first). This new development revolutionized LED lighting, making high-power blue light sources practical, leading to the development of technologies like BlueRay, as well as allowing the bright high resolution screens of modern tablets and phones.
Nakamura was awarded the 2006 Millennium Technology Prize for his invention.
Nakamura, Hiroshi Amano and Isamu Akasaki were awarded the Nobel Prize in Physics in 2014 for the invention of the blue LED. In 2015, a US court ruled that three companies (i.e. the litigants who had not previously settled out of court) that had licensed Mr. Nakamura's patents for production in the United States had infringed Dr. Moustakas's prior patent, and order them to pay licensing fees of not less than 13 million USD.
By the late 1990s, blue LEDs became widely available. They have an active region consisting of one or more InGaN quantum wells sandwiched between thicker layers of GaN, called cladding layers. By varying the relative In/Ga fraction in the InGaN quantum wells, the light emission can in theory be varied from violet to amber. Aluminium gallium nitride (AlGaN) of varying Al/Ga fraction can be used to manufacture the cladding and quantum well layers for ultraviolet LEDs, but these devices have not yet reached the level of efficiency and technological maturity of InGaN/GaN blue/green devices. If un-alloyed GaN is used in this case to form the active quantum well layers, the device will emit near-ultraviolet light with a peak wavelength centred around 365 nm. Green LEDs manufactured from the InGaN/GaN system are far more efficient and brighter than green LEDs produced with non-nitride material systems, but practical devices still exhibit efficiency too low for high-brightness applications.
With nitrides containing aluminium, most often AlGaN and AlGaInN, even shorter wavelengths are achievable. Ultraviolet LEDs in a range of wavelengths are becoming available on the market. Near-UV emitters at wavelengths around 375–395 nm are already cheap and often encountered, for example, as black light lamp replacements for inspection of anti-counterfeiting UV watermarks in some documents and paper currencies. Shorter-wavelength diodes, while substantially more expensive, are commercially available for wavelengths down to 240 nm. As the photosensitivity of microorganisms approximately matches the absorption spectrum of DNA, with a peak at about 260 nm, UV LED emitting at 250–270 nm are to be expected in prospective disinfection and sterilization devices. Recent research has shown that commercially available UVA LEDs (365 nm) are already effective disinfection and sterilization devices.
UV-C wavelengths were obtained in laboratories using aluminium nitride (210 nm), boron nitride (215 nm) and diamond (235 nm).
RGB.
RGB LEDs consist of one red, one green, and one blue LED. By independently attenuating each of the three, RGB LEDs are capable of producing a wide color gamut.
White.
There are two primary ways of producing white light-emitting diodes (WLEDs), LEDs that generate high-intensity white light. One is to use individual LEDs that emit three primary colors—red, green, and blue—and then mix all the colors to form white light. The other is to use a phosphor material to convert monochromatic light from a blue or UV LED to broad-spectrum white light, much in the same way a fluorescent light bulb works.
There are three main methods of mixing colors to produce white light from an LED:
Because of metamerism, it is possible to have quite different spectra that appear white. However, the appearance of objects illuminated by that light may vary as the spectrum varies.
RGB systems.
White light can be formed by mixing differently colored lights; the most common method is to use red, green, and blue (RGB). Hence the method is called multi-color white LEDs (sometimes referred to as RGB LEDs). Because these need electronic circuits to control the blending and diffusion of different colors, and because the individual color LEDs typically have slightly different emission patterns (leading to variation of the color depending on direction) even if they are made as a single unit, these are seldom used to produce white lighting. Nonetheless, this method has many applications because of the flexibility of mixing different colors, and in principle, this mechanism also has higher quantum efficiency in producing white light.
There are several types of multi-color white LEDs: di-, tri-, and tetrachromatic white LEDs. Several key factors that play among these different methods, include color stability, color rendering capability, and luminous efficacy. Often, higher efficiency will mean lower color rendering, presenting a trade-off between the luminous efficacy and color rendering. For example, the dichromatic white LEDs have the best luminous efficacy (120 lm/W), but the lowest color rendering capability. However, although tetrachromatic white LEDs have excellent color rendering capability, they often have poor luminous efficacy. Trichromatic white LEDs are in between, having both good luminous efficacy (>70 lm/W) and fair color rendering capability.
One of the challenges is the development of more efficient green LEDs. The theoretical maximum for green LEDs is 683 lumens per watt but as of 2010 few green LEDs exceed even 100 lumens per watt. The blue and red LEDs get closer to their theoretical limits.
Multi-color LEDs offer not merely another means to form white light but a new means to form light of different colors. Most perceivable colors can be formed by mixing different amounts of three primary colors. This allows precise dynamic color control. As more effort is devoted to investigating this method, multi-color LEDs should have profound influence on the fundamental method that we use to produce and control light color. However, before this type of LED can play a role on the market, several technical problems must be solved. These include that this type of LED's emission power decays exponentially with rising temperature,
resulting in a substantial change in color stability. Such problems inhibit and may preclude industrial use. Thus, many new package designs aimed at solving this problem have been proposed and their results are now being reproduced by researchers and scientists.
Correlated color temperature (CCT) dimming for LED technology is regarded as a difficult task, since binning, age and temperature drift effects of LEDs change the actual color value output. Feedback loop systems are used for example with color sensors, to actively monitor and control the color output of multiple color mixing LEDs.
Phosphor-based LEDs.
This method involves coating LEDs of one color (mostly blue LEDs made of InGaN) with phosphors of different colors to form white light; the resultant LEDs are called phosphor-based or phosphor-converted white LEDs (pcLEDs). A fraction of the blue light undergoes the Stokes shift being transformed from shorter wavelengths to longer. Depending on the color of the original LED, phosphors of different colors can be employed. If several phosphor layers of distinct colors are applied, the emitted spectrum is broadened, effectively raising the color rendering index (CRI) value of a given LED.
Phosphor-based LED efficiency losses are due to the heat loss from the Stokes shift and also other phosphor-related degradation issues. Their luminous efficacies compared to normal LEDs depend on the spectral distribution of the resultant light output and the original wavelength of the LED itself. For example, the luminous efficacy of a typical YAG yellow phosphor based white LED ranges from 3 to 5 times the luminous efficacy of the original blue LED because of the human eye's greater sensitivity to yellow than to blue (as modeled in the luminosity function). Due to the simplicity of manufacturing the phosphor method is still the most popular method for making high-intensity white LEDs. The design and production of a light source or light fixture using a monochrome emitter with phosphor conversion is simpler and cheaper than a complex RGB system, and the majority of high-intensity white LEDs presently on the market are manufactured using phosphor light conversion.
Among the challenges being faced to improve the efficiency of LED-based white light sources is the development of more efficient phosphors. As of 2010, the most efficient yellow phosphor is still the YAG phosphor, with less than 10% Stoke shift loss. Losses attributable to internal optical losses due to re-absorption in the LED chip and in the LED packaging itself account typically for another 10% to 30% of efficiency loss. Currently, in the area of phosphor LED development, much effort is being spent on optimizing these devices to higher light output and higher operation temperatures. For instance, the efficiency can be raised by adapting better package design or by using a more suitable type of phosphor. Conformal coating process is frequently used to address the issue of varying phosphor thickness.
Some phosphor-based white LEDs encapsulate InGaN blue LEDs inside phosphor-coated epoxy. Alternatively, the LED might be paired with a remote phosphor, a preformed polycarbonate piece coated with the phosphor material. Remote phosphors provide more diffuse light, which is desirable for many applications. Remote phosphor designs are also more tolerant of variations in the LED emissions spectrum. A common yellow phosphor material is cerium-doped yttrium aluminium garnet (Ce3+:YAG).
White LEDs can also be made by coating near-ultraviolet (NUV) LEDs with a mixture of high-efficiency europium-based phosphors that emit red and blue, plus copper and aluminium-doped zinc sulfide (ZnS:Cu, Al) that emits green. This is a method analogous to the way fluorescent lamps work. This method is less efficient than blue LEDs with YAG:Ce phosphor, as the Stokes shift is larger, so more energy is converted to heat, but yields light with better spectral characteristics, which render color better. Due to the higher radiative output of the ultraviolet LEDs than of the blue ones, both methods offer comparable brightness. A concern is that UV light may leak from a malfunctioning light source and cause harm to human eyes or skin.
Other white LEDs.
Another method used to produce experimental white light LEDs used no phosphors at all and was based on homoepitaxially grown zinc selenide (ZnSe) on a ZnSe substrate that simultaneously emitted blue light from its active region and yellow light from the substrate.
A new style of wafers composed of gallium-nitride-on-silicon (GaN-on-Si) is being used to produce white LEDs using 200-mm silicon wafers. This avoids the typical costly sapphire substrate in relatively small 100- or 150-mm wafer sizes. The sapphire apparatus must be coupled with a mirror-like collector to reflect light that would otherwise be wasted. It is predicted that by 2020, 40% of all GaN LEDs will be made with GaN-on-Si. Manufacturing large sapphire material is difficult, while large silicon material is cheaper and more abundant. LED companies shifting from using sapphire to silicon should be a minimal investment.
Organic light-emitting diodes (OLEDs).
In an organic light-emitting diode (OLED), the electroluminescent material comprising the emissive layer of the diode is an organic compound. The organic material is electrically conductive due to the delocalization of pi electrons caused by conjugation over all or part of the molecule, and the material therefore functions as an organic semiconductor. The organic materials can be small organic molecules in a crystalline phase, or polymers.
The potential advantages of OLEDs include thin, low-cost displays with a low driving voltage, wide viewing angle, and high contrast and color gamut. Polymer LEDs have the added benefit of printable and flexible displays. OLEDs have been used to make visual displays for portable electronic devices such as cellphones, digital cameras, and MP3 players while possible future uses include lighting and televisions.
Quantum dot LEDs.
Quantum dots (QD) are semiconductor nanocrystals that possess unique optical properties. Their emission color can be tuned from the visible throughout the infrared spectrum. This allows quantum dot LEDs to create almost any color on the CIE diagram. This provides more color options and better color rendering than white LEDs since the emission spectrum is much narrower, characteristic of quantum confined states. There are two types of schemes for QD excitation.
One uses photo excitation with a primary light source LED (typically blue or UV LEDs are used). The other is direct electrical excitation first demonstrated by Alivisatos et al.
One example of the photo-excitation scheme is a method developed by Michael Bowers, at Vanderbilt University in Nashville, involving coating a blue LED with quantum dots that glow white in response to the blue light from the LED. This method emits a warm, yellowish-white light similar to that made by incandescent light bulbs. Quantum dots are also being considered for use in white light-emitting diodes in liquid crystal display (LCD) televisions.
In February 2011 scientists at PlasmaChem GmbH were able to synthesize quantum dots for LED applications and build a light converter on their basis, which was able to efficiently convert light from blue to any other color for many hundred hours. Such QDs can be used to emit visible or near infrared light of any wavelength being excited by light with a shorter wavelength.
The structure of QD-LEDs used for the electrical-excitation scheme is similar to basic design of OLEDs. A layer of quantum dots is sandwiched between layers of electron-transporting and hole-transporting materials. An applied electric field causes electrons and holes to move into the quantum dot layer and recombine forming an exciton that excites a QD. This scheme is commonly studied for quantum dot display. The tunability of emission wavelengths and narrow bandwidth is also beneficial as excitation sources for fluorescence imaging. Fluorescence near-field scanning optical microscopy
(NSOM) utilizing an integrated QD-LED has been demonstrated.
In February 2008, a luminous efficacy of 300 lumens of visible light per watt of radiation (not per electrical watt) and warm-light emission was achieved by using nanocrystals.
Types.
The main types of LEDs are miniature, high-power devices and custom designs such as alphanumeric or multi-color.
Miniature.
These are mostly single-die LEDs used as indicators, and they come in various sizes from 2 mm to 8 mm, through-hole and surface mount packages. They usually do not use a separate heat sink. Typical current ratings ranges from around 1 mA to above 20 mA. The small size sets a natural upper boundary on power consumption due to heat caused by the high current density and need for a heat sink.
Common package shapes include round, with a domed or flat top, rectangular with a flat top (as used in bar-graph displays), and triangular or square with a flat top.
The encapsulation may also be clear or tinted to improve contrast and viewing angle.
Researchers at the University of Washington have invented the thinnest LED. It is made of two-dimensional (2-D) flexible materials. It is three atoms thick, which is 10 to 20 times thinner than three-dimensional (3-D) LEDs and is also 10,000 times smaller than the thickness of a human hair. These 2-D LEDs are going to make it possible to create smaller, more energy-efficient lighting, optical communication and nano lasers.
There are three main categories of miniature single die LEDs:
5 V and 12 V LEDs are ordinary miniature LEDs that incorporate a suitable series resistor for direct connection to a 5 V or 12 V supply.
High-power.
High-power LEDs (HP-LEDs) or high-output LEDs (HO-LEDs) can be driven at currents from hundreds of mA to more than an ampere, compared with the tens of mA for other LEDs. Some can emit over a thousand lumens. LED power densities up to 300 W/cm2 have been achieved. Since overheating is destructive, the HP-LEDs must be mounted on a heat sink to allow for heat dissipation. If the heat from a HP-LED is not removed, the device will fail in seconds. One HP-LED can often replace an incandescent bulb in a flashlight, or be set in an array to form a powerful LED lamp.
Some well-known HP-LEDs in this category are the Nichia 19 series, Lumileds Rebel Led, Osram Opto Semiconductors Golden Dragon, and Cree X-lamp. As of September 2009, some HP-LEDs manufactured by Cree now exceed 105 lm/W.
Examples for Haitz's law, which predicts an exponential rise in light output and efficacy of LEDs over time, are the CREE XP-G series LED which achieved 105 lm/W in 2009 and the Nichia 19 series with a typical efficacy of 140 lm/W, released in 2010.
AC driven.
LEDs have been developed by Seoul Semiconductor that can operate on AC power without the need for a DC converter. For each half-cycle, part of the LED emits light and part is dark, and this is reversed during the next half-cycle. The efficacy of this type of HP-LED is typically 40 lm/W. A large number of LED elements in series may be able to operate directly from line voltage. In 2009, Seoul Semiconductor released a high DC voltage LED, named as 'Acrich MJT', capable of being driven from AC power with a simple controlling circuit. The low-power dissipation of these LEDs affords them more flexibility than the original AC LED design.
Application-specific variations.
Flashing.
Flashing LEDs are used as attention seeking indicators without requiring external electronics. Flashing LEDs resemble standard LEDs but they contain an integrated multivibrator circuit that causes the LED to flash with a typical period of one second. In diffused lens LEDs, this circuit is visible as a small black dot. Most flashing LEDs emit light of one color, but more sophisticated devices can flash between multiple colors and even fade through a color sequence using RGB color mixing.
Bi-color.
Bi-color LEDs contain two different LED emitters in one case. There are two types of these. One type consists of two dies connected to the same two leads antiparallel to each other. Current flow in one direction emits one color, and current in the opposite direction emits the other color. The other type consists of two dies with separate leads for both dies and another lead for common anode or cathode, so that they can be controlled independently.
Tri-color.
Tri-color LEDs contain three different LED emitters in one case. Each emitter is connected to a separate lead so they can be controlled independently. A four-lead arrangement is typical with one common lead (anode or cathode) and an additional lead for each color.
RGB.
RGB LEDs are tri-color LEDs with red, green, and blue emitters, in general using a four-wire connection with one common lead (anode or cathode). These LEDs can have either common positive or common negative leads. Others however, have only two leads (positive and negative) and have a built-in tiny electronic control unit.
Decorative-multicolor.
Decorative-multicolor LEDs incorporate several emitters of different colors supplied by only two lead-out wires. Colors are switched internally by varying the supply voltage.
Alphanumeric.
Alphanumeric LEDs are available in seven-segment, starburst and dot-matrix format. Seven-segment displays handle all numbers and a limited set of letters. Starburst displays can display all letters. Dot-matrix displays typically use 5x7 pixels per character. Seven-segment LED displays were in widespread use in the 1970s and 1980s, but rising use of liquid crystal displays, with their lower power needs and greater display flexibility, has reduced the popularity of numeric and alphanumeric LED displays.
Digital-RGB.
Digital-RGB LEDs are RGB LEDs that contain their own "smart" control electronics. In addition to power and ground, these provide connections for data-in, data-out, and sometimes a clock or strobe signal. These are connected in a daisy chain, with the data in of the first LED sourced by a microprocessor, which can control the brightness and color of each LED independently of the others. They are used where a combination of maximum control and minimum visible electronics are needed such as strings for Christmas and LED matrices. Some even have refresh rates in the kHz range, allowing for basic video applications.
Filament.
An LED filament consists of multiple LED dice connected in series on a common longitudinal substrate that form a thin rod reminiscent of a traditional incandescent filament. These are being used as a low cost decorative alternative for traditional light bulbs that are being phased out in many countries. The filaments require a rather high voltage to light to nominal brightness, allowing them to work efficiently and simply with mains voltages. Often a simple rectifier and capacitive current limiting are employed to create a low-cost replacement for a traditional light bulb without the complexity of creating a low voltage, high current converter which is required by single die LEDs. Usually they are packaged in a sealed enclosure with a shape similar to lamps they were designed to replace (e.g. a bulb), and filled with inert nitrogen or carbon dioxide gas to remove heat efficiently.
Considerations for use.
Power sources.
The current–voltage characteristic of an LED is similar to other diodes, in that the current is dependent exponentially on the voltage (see Shockley diode equation). This means that a small change in voltage can cause a large change in current. If the applied voltage exceeds the LED's forward voltage drop by a small amount, the current rating may be exceeded by a large amount, potentially damaging or destroying the LED. The typical solution is to use constant-current power supplies to keep the current below the LED's maximum current rating. Since most common power sources (batteries, mains) are constant-voltage sources, most LED fixtures must include a power converter, at least a current-limiting resistor.
However, the high resistance of three-volt coin cells combined with the high differential resistance of nitride-based LEDs makes it possible to power such an LED from such a coin cell without an external resistor.
Electrical polarity.
As with all diodes, current flows easily from p-type to n-type material.
However, no current flows and no light is emitted if a small voltage is applied in the reverse direction. If the reverse voltage grows large enough to exceed the breakdown voltage, a large current flows and the LED may be damaged. If the reverse current is sufficiently limited to avoid damage, the reverse-conducting LED is a useful noise diode.
Safety and health.
The vast majority of devices containing LEDs are "safe under all conditions of normal use", and so are classified as "Class 1 LED product"/"LED Klasse 1". At present, only a few LEDs—extremely bright LEDs that also have a tightly focused viewing angle of 8° or less—could, in theory, cause temporary blindness, and so are classified as "Class 2".
The opinion of the French Agency for Food, Environmental and Occupational Health & Safety (ANSES) of 2010, on the health issues concerning LEDs, suggested banning public use of lamps which were in the moderate Risk Group 2, especially those with a high blue component in places frequented by children.
In general, laser safety regulations—and the "Class 1", "Class 2", etc. system—also apply to LEDs.
While LEDs have the advantage over fluorescent lamps that they do not contain mercury, they may contain other hazardous metals such as lead and arsenic. Regarding the toxicity of LEDs when treated as waste, a study published in 2011 stated: "According to federal standards, LEDs are not hazardous except for low-intensity red LEDs, which leached Pb at levels exceeding regulatory limits (186 mg/L; regulatory limit: 5). However, according to California regulations, excessive levels of copper (up to 3892 mg/kg; limit: 2500), lead (up to 8103 mg/kg; limit: 1000), nickel (up to 4797 mg/kg; limit: 2000), or silver (up to 721 mg/kg; limit: 500) render all except low-intensity yellow LEDs hazardous."
Applications.
LED uses fall into four major categories:
Indicators and signs.
The low energy consumption, low maintenance and small size of LEDs has led to uses as status indicators and displays on a variety of equipment and installations. Large-area LED displays are used as stadium displays and as dynamic decorative displays. Thin, lightweight message displays are used at airports and railway stations, and as destination displays for trains, buses, trams, and ferries.
One-color light is well suited for traffic lights and signals, exit signs, emergency vehicle lighting, ships' navigation lights or lanterns (chromacity and luminance standards being set under the Convention on the International Regulations for Preventing Collisions at Sea 1972, Annex I and the CIE) and LED-based Christmas lights. In cold climates, LED traffic lights may remain snow-covered. Red or yellow LEDs are used in indicator and alphanumeric displays in environments where night vision must be retained: aircraft cockpits, submarine and ship bridges, astronomy observatories, and in the field, e.g. night time animal watching and military field use.
Because of their long life, fast switching times, and their ability to be seen in broad daylight due to their high output and focus, LEDs have been used in brake lights for cars' high-mounted brake lights, trucks, and buses, and in turn signals for some time, but many vehicles now use LEDs for their rear light clusters. The use in brakes improves safety, due to a great reduction in the time needed to light fully, or faster rise time, up to 0.5 second faster than an incandescent bulb. This gives drivers behind more time to react. In a dual intensity circuit (rear markers and brakes) if the LEDs are not pulsed at a fast enough frequency, they can create a phantom array, where ghost images of the LED will appear if the eyes quickly scan across the array. White LED headlamps are starting to be used. Using LEDs has styling advantages because LEDs can form much thinner lights than incandescent lamps with parabolic reflectors.
Due to the relative cheapness of low output LEDs, they are also used in many temporary uses such as glowsticks, throwies, and the photonic textile Lumalive. Artists have also used LEDs for LED art.
Weather and all-hazards radio receivers with Specific Area Message Encoding (SAME) have three LEDs: red for warnings, orange for watches, and yellow for advisories and statements whenever issued.
Lighting.
With the development of high-efficiency and high-power LEDs, it has become possible to use LEDs in lighting and illumination. To encourage the shift to LED lamps and other high-efficiency lighting, the US Department of Energy has created the L Prize competition. The Philips Lighting North America LED bulb won the first competition on August 3, 2011 after successfully completing 18 months of intensive field, lab, and product testing.
LEDs are used as street lights and in other architectural lighting. The mechanical robustness and long lifetime is used in automotive lighting on cars, motorcycles, and bicycle lights. LED light emission may be efficiently controlled by using nonimaging optics principles.
LED street lights are employed on poles and in parking garages. In 2007, the Italian village of Torraca was the first place to convert its entire illumination system to LEDs.
LEDs are used in aviation lighting. Airbus has used LED lighting in its Airbus A320 Enhanced since 2007, and Boeing uses LED lighting in the 787. LEDs are also being used now in airport and heliport lighting. LED airport fixtures currently include medium-intensity runway lights, runway centerline lights, taxiway centerline and edge lights, guidance signs, and obstruction lighting.
LEDs are also used as a light source for DLP projectors, and to backlight LCD televisions (referred to as LED TVs) and laptop displays. RGB LEDs raise the color gamut by as much as 45%. Screens for TV and computer displays can be made thinner using LEDs for backlighting.
The lack of IR or heat radiation makes LEDs ideal for stage lights using banks of RGB LEDs that can easily change color and decrease heating from traditional stage lighting, as well as medical lighting where IR-radiation can be harmful. In energy conservation, the lower heat output of LEDs also means air conditioning (cooling) systems have less heat in need of disposal.
LEDs are small, durable and need little power, so they are used in handheld devices such as flashlights. LED strobe lights or camera flashes operate at a safe, low voltage, instead of the 250+ volts commonly found in xenon flashlamp-based lighting. This is especially useful in cameras on mobile phones, where space is at a premium and bulky voltage-raising circuitry is undesirable.
LEDs are used for infrared illumination in night vision uses including security cameras. A ring of LEDs around a video camera, aimed forward into a retroreflective background, allows chroma keying in video productions.
LEDs are used in mining operations, as cap lamps to provide light for miners. Research has been done to improve LEDs for mining, to reduce glare and to increase illumination, reducing risk of injury to the miners.
LEDs are now used commonly in all market areas from commercial to home use: standard lighting, AV, stage, theatrical, architectural, and public installations, and wherever artificial light is used.
LEDs are increasingly finding uses in medical and educational applications, for example as mood enhancement, and new technologies such as AmBX, exploiting LED versatility. NASA has even sponsored research for the use of LEDs to promote health for astronauts.
Data communication and other signaling.
Light can be used to transmit data and analog signals. For example, lighting white LEDs can be used in systems assisting people to navigate in closed spaces while searching necessary rooms or objects.
Assistive listening devices in many theaters and similar spaces use arrays of infrared LEDs to send sound to listeners' receivers. Light-emitting diodes (as well as semiconductor lasers) are used to send data over many types of fiber optic cable, from digital audio over TOSLINK cables to the very high bandwidth fiber links that form the Internet backbone. For some time, computers were commonly equipped with IrDA interfaces, which allowed them to send and receive data to nearby machines via infrared.
Because LEDs can cycle on and off millions of times per second, very high data bandwidth can be achieved.
Sustainable lighting.
Efficient lighting is needed for sustainable architecture. In 2009, US Department of Energy testing results on LED lamps showed an average efficacy of 35 lm/W, below that of typical CFLs, and as low as 9 lm/W, worse than standard incandescent bulbs. A typical 13-watt LED lamp emitted 450 to 650 lumens, which is equivalent to a standard 40-watt incandescent bulb.
However, as of 2011, there are LED bulbs available as efficient as 150 lm/W and even inexpensive low-end models typically exceed 50 lm/W, so that a 6-watt LED could achieve the same results. A standard 40-watt incandescent bulb has an expected lifespan of 1,000 hours, whereas an LED can continue to operate with reduced efficiency for more than 50,000 hours.
See the chart below for a comparison of common light types:
Energy consumption.
In the US, one kilowatt-hour (3.6 MJ) of electricity currently causes an average of emission. Assuming the average light bulb is on for 10 hours a day, a 40-watt bulb will cause of emission per year. The 6-watt LED equivalent will only cause of over the same time span. A building’s carbon footprint from lighting can therefore be reduced by 85% by exchanging all incandescent bulbs for new LEDs if a building previously used only incandescent bulbs.
In practice, most buildings that use a lot of lighting use fluorescent lighting, which has 22% luminous efficiency compared with 5% for filaments, so changing to LED lighting would still give a 34% reduction in electrical power use and carbon emissions.
The reduction in carbon emissions depends on the source of electricity. Nuclear power in the United States produced 19.2% of electricity in 2011, so reducing electricity consumption in the U.S. reduces carbon emissions more than in France (75% nuclear electricity) or Norway (almost entirely hydroelectric).
Replacing lights that spend the most time lit results in the most savings, so LED lights in infrequently used locations bring a smaller return on investment.
Light sources for machine vision systems.
Machine vision systems often require bright and homogeneous illumination, so features of interest are easier to process.
LEDs are often used for this purpose, and this is likely to remain one of their major uses until the price drops low enough to make signaling and illumination uses more widespread. Barcode scanners are the most common example of machine vision, and many low cost products use red LEDs instead of lasers. Optical computer mice are an example of LEDs in machine vision, as it is used to provide an even light source on the surface for the miniature camera within the mouse. LEDs constitute a nearly ideal light source for machine vision systems for several reasons:
Other applications.
The light from LEDs can be modulated very quickly so they are used extensively in optical fiber and free space optics communications. This includes remote controls, such as for TVs, VCRs, and LED Computers, where infrared LEDs are often used. Opto-isolators use an LED combined with a photodiode or phototransistor to provide a signal path with electrical isolation between two circuits. This is especially useful in medical equipment where the signals from a low-voltage sensor circuit (usually battery-powered) in contact with a living organism must be electrically isolated from any possible electrical failure in a recording or monitoring device operating at potentially dangerous voltages. An optoisolator also allows information to be transferred between circuits not sharing a common ground potential.
Many sensor systems rely on light as the signal source. LEDs are often ideal as a light source due to the requirements of the sensors. LEDs are used as motion sensors, for example in optical computer mice. The Nintendo Wii's sensor bar uses infrared LEDs. Pulse oximeters use them for measuring oxygen saturation. Some flatbed scanners use arrays of RGB LEDs rather than the typical cold-cathode fluorescent lamp as the light source. Having independent control of three illuminated colors allows the scanner to calibrate itself for more accurate color balance, and there is no need for warm-up. Further, its sensors only need be monochromatic, since at any one time the page being scanned is only lit by one color of light. Since LEDs can also be used as photodiodes, they can be used for both photo emission and detection. This could be used, for example, in a touchscreen that registers reflected light from a finger or stylus. Many materials and biological systems are sensitive to, or dependent on, light. Grow lights use LEDs to increase photosynthesis in plants, and bacteria and viruses can be removed from water and other substances using UV LEDs for sterilization.
LEDs have also been used as a medium-quality voltage reference in electronic circuits. The forward voltage drop (e.g. about 1.7 V for a normal red LED) can be used instead of a Zener diode in low-voltage regulators. Red LEDs have the flattest I/V curve above the knee. Nitride-based LEDs have a fairly steep I/V curve and are useless for this purpose. Although LED forward voltage is far more current-dependent than a Zener diode, Zener diodes with breakdown voltages below 3 V are not widely available.

</doc>
<doc id="18291" url="https://en.wikipedia.org/wiki?curid=18291" title="Luxembourgish language">
Luxembourgish language

Luxembourgish, Luxemburgish () or Letzeburgesch ( or ) (Luxembourgish: "Lëtzebuergesch") is a West Germanic language that is spoken mainly in Luxembourg. Worldwide, about 390,000 people speak Luxembourgish.
While it can be considered a standardized variety (i.e., a dialect with a written form) of German, its official use in the state of Luxembourg and the existence of a separate regulatory body removed Luxembourgish, at least in part, from the domain of the "Dachsprache" Standard German. Despite the lack of a sharp boundary between Luxembourgish and the neighboring German dialects, this has led several linguists (from Luxembourg as well as Germany) to regard it as a separate, yet closely related language.
Language family.
Luxembourgish belongs to the West Central German group of High German languages and is the primary example of a Moselle Franconian language.
Usage.
Luxembourgish is the national language of Luxembourg and one of three administrative languages, alongside French and German.
Luxembourgish is also spoken in the Arelerland region of Belgium (part of the Province of Luxembourg) and in small parts of Lorraine in France.
In the German Eifel and Hunsrück regions, and in Lorraine, similar local Moselle Franconian dialects of German are spoken. Furthermore, the language is spoken by a few descendants of Luxembourg immigrants in the United States, and another similar Moselle Franconian dialect is spoken by ethnic Germans long settled in Transylvania, Romania (Siebenbürgen).
Moselle Franconian dialects outside the Luxembourg state border tend to have far fewer French loan words, and these mostly remain from the French revolution.
Varieties.
There are several distinct dialect forms of Luxembourgish including Areler (from Arlon), Eechternoacher (Echternach), Kliärrwer (Clervaux), Miseler (Moselle), Stater (Luxembourg), Veiner (Vianden), Minetter (Southern Luxembourg) and Weelzer (Wiltz). Further small vocabulary differences may be seen even between small villages.
Increasing mobility of the population and the dissemination of the language through mass media such as radio and television are leading to a gradual standardisation towards a "Standard Luxembourgish" through the process of koineization.
Surrounding languages.
There is no distinct geographic boundary between the use of Luxembourgish and the use of other closely related High German dialects (for example Lorraine Franconian); it instead forms a dialect continuum of gradual change.
Spoken Luxembourgish is relatively hard to understand for speakers of German who are generally not familiar with Moselle Franconian dialects (or at least other West Central German dialects). However, they can usually read the language to some degree. For those Germans familiar with Moselle Franconian dialects, it is relatively easy to understand and speak Luxembourgish as far as the everyday vocabulary is concerned. However, the large number of French loanwords in Luxembourgish may hamper communication about certain topics, or with certain speakers (who use surpassingly many French loanwords).
There is no intelligibility between Luxembourgish and French or any of the Romance dialects spoken in the adjacent parts of Belgium and France.
Erna Hennicot-Schoepges, President of the Christian Social People's Party of Luxembourg 1995–2003, was active in promoting the language beyond Luxembourg's borders.
Written Luxembourgish.
Standardisation.
A number of proposals for standardising the orthography of Luxembourgish can be documented, going back to the middle of the 19th century. There was no officially recognised system, however, until the adoption of the "OLO" ("ofizjel lezebuurjer ortografi") on 5 June 1946. This orthography provided a system for speakers of all varieties of Luxembourgish to transcribe words the way they pronounced them, rather than imposing a single, standard spelling for the words of the language. The rules explicitly rejected certain elements of German orthography (e.g., the use of "ä" and "ö", the capitalisation of nouns). Similarly, new principles were adopted for the spelling of French loanwords.
This proposed orthography, so different from existing "foreign" standards that people were already familiar with, did not enjoy widespread approval.
A more successful standard eventually emerged from the work of the committee of specialists charged with the task of creating the "Luxemburger Wörterbuch", published in 5 volumes between 1950 and 1977. The orthographic conventions adopted in this decades-long project, set out in Bruch (1955), provided the basis of the standard orthography that became official on 10 October 1975. Modifications to this standard were proposed by the "Conseil permanent de la langue luxembourgeoise" and adopted officially in the spelling reform of 30 July 1999. A detailed explanation of current practice for Luxembourgish can be found in Schanen & Lulling (2003).
Alphabet.
The Luxembourgish alphabet consists of the 26 Latin letters plus three letters with diacritics: "é", "ä", and "ë". In loanwords from French and Standard German, other diacritics are usually preserved:
Eifeler Regel.
Like many other varieties of Western High German, Luxembourgish has a rule of final "n"-deletion in certain contexts. The effects of this rule (known as the "Eifel Rule") are indicated in writing, and therefore must be taken into account when spelling words and morphemes ending in or . For example:
Phonology.
Consonants.
The consonant inventory of Luxembourgish is quite similar to that of Standard German.
Grammar.
Nominal syntax.
Luxembourgish has three genders (masculine, feminine, and neuter), and has three cases (nominative, accusative, and dative). These are marked morphologically on determiners and pronouns. As in German, there is no morphological gender distinction in the plural.
The forms of the articles and of some selected determiners are given below:
As seen above, Luxembourgish has plural forms of "en" ("a, an"), namely "eng" in the nominative/accusative and "engen" in the dative. They are not used as indefinite articles, which—as in German and English—do not exist in the plural, but they do occur in the compound pronouns "wéi en" ("what, which") and "sou en" ("such"). For example: "wéi eng Saachen" ("what things"); "sou eng Saachen" ("such things"). Moreover, they are used before numbers to express an estimation: "eng 30.000 Spectateuren" ("some 30,000 spectators").
Distinct nominative forms survive in a few nominal phrases such as "der Däiwel" ("the devil") and "eiser Herrgott" ("our Lord"). Rare examples of the genitive are also found: "Enn des Mounts" ("end of the month"), "Ufanks der Woch" ("at the beginning of the week"). The functions of the genitive are normally expressed using a combination of the dative and a possessive determiner: e.g. "dem Mann säi Buch" (lit. "to the man his book", i.e. "the man's book"). This is known as a periphrastic genitive, and is a phenomenon also commonly seen in dialectal and colloquial German, and in Dutch.
The forms of the personal pronouns are given in the following table (unstressed forms appear in parentheses):
The 2pl form is also used as a polite singular (like French "vous", see T-V distinction); the forms are capitalised in writing:
Like most varieties of colloquial German, but even more invariably, Luxembourgish uses definite articles with personal names. They are obligatory and not to be translated:
A feature Luxembourgish shares with only some western dialects of German is that women and girls are most often referred to with forms of the "neuter" pronoun "hatt":
Adjectives.
Luxembourgish morphology distinguishes two types of adjective: attributive and predicative. Predicative adjectives appear with verbs like "sinn" ("to be"), and receive no extra ending:
Attributive adjectives are placed before the noun they describe, and change their ending according to the grammatical gender, number, and case:
Interesting to note is how the definite article changes with the use of an attributive adjective: feminine "d" goes to "déi" (or "di"), neuter "d'" goes to "dat", and plural "d'" changes to "déi".
The comparative in Luxembourgish is formed analytically, i.e. the adjective itself is not altered (compare the use of -"er" in German and English; "tall" → "taller", "klein" → "kleiner"). Instead it is formed using the adverb "méi": e.g. "schéin" → "méi schéin"
The superlative involves a synthetic form consisting of the adjective and the suffix "-st": e.g. "schéin" → "schéinst " (compare German "schönst", English "prettiest"). Attributive modification requires the emphatic definite article and the inflected superlative adjective:
Predicative modification uses either the same adjectival structure or the adverbial structure "am"+ -"sten": e.g. "schéin" → "am schéinsten":
Some common adjectives have exceptional comparative and superlative forms:
Several other adjectives also have comparative forms. However, these are not commonly used as normal comparatives, but in special senses:
Word-order.
Luxembourgish exhibits "verb second" word order in clauses. More specifically, Luxembourgish is a V2-SOV language, like German and Dutch. In other words, we find the following finite clausal structures:
Non-finite verbs (infinitives and participles) generally appear in final position:
These rules interact so that in subordinate clauses, the finite verb and any non-finite verbs must all cluster at the end. Luxembourgish allows different word orders in these cases:
This is also the case when two non-finite verb forms occur together:
Luxembourgish (like Dutch and German) allows prepositional phrases to appear after the verb cluster in subordinate clauses:
Vocabulary.
Luxembourgish has borrowed many French words. For example, the name for a bus driver is "Buschauffeur" (also Dutch), which would be "Busfahrer" in German and "chauffeur de bus" in French.
Some words are different from Standard German but have equivalents in German dialects. An example is gromperen (potatoes – German: Kartoffeln). Other words are exclusive to Luxembourgish.
Selected common phrases.
"Note: Words spoken in sound clip do not reflect all words on this list."
Neologisms.
Neologisms in Luxembourgish include both entirely new words, and the attachment of new meanings to old words in everyday speech. The most recent neologisms come from the English language in the fields of telecommunications, computer science, and the Internet.
Recent neologisms in Luxembourgish include:
Academic projects.
Between 2000 and 2002, Luxembourgish linguist Jérôme Lulling compiled a lexical database of 125,000 word forms as the basis for the very first Luxembourgish spellchecker (Projet C.ORT.IN.A).
The LaF ("Lëtzebuergesch als Friemsprooch" – Luxembourgish as a Foreign Language) is a set of four language proficiency certifications for Luxembourgish and follows the ALTE framework of language examination standards. The tests are administered by the Institut National des Langues Luxembourg.
The "Centre for Luxembourg Studies" at the University of Sheffield was founded in 1995 on the initiative of Professor Gerald Newton. It is supported by the government of Luxembourg which funds an endowed chair in Luxembourg Studies at the university.
The first class of students to study the language outside of the country as undergraduate students began their studies at the 'Centre for Luxembourg Studies' at Sheffield in the academic year 2011–2012.
Further reading.
In English
In French
In Luxembourgish
In German
External links.
Spellcheckers and dictionaries

</doc>
<doc id="18292" url="https://en.wikipedia.org/wiki?curid=18292" title="Lev Kuleshov">
Lev Kuleshov

Lev Vladimirovich Kuleshov (; – 29 March 1970) was a Russian and Soviet filmmaker and film theorist, one of the founders of the world's first film school, the Moscow Film School. People's Artist of the RSFSR (1969).
Life and career.
Lev Kuleshov was born in 1899 into intelligent Russian family. His father Vladimir Sergeevich Kuleshov was of noble heritage. He studied art in the Moscow School of Painting, Sculpture and Architecture, despite his own father's disapproval. He then married a village schoolteacher Pelagia Alexandrovna Shubina who was raised in an orphanage, which only lead to more confrontation. They gave birth to two sons: Boris and Lev. At the time Lev was born, the family became financially broke, lost their estate and moved to Tambov, living a modest life. In 1911 Vladimir Kuleshov died; three years later Lev and his mother moved to Moscow where his elder brother was studying and working as an engineer. Lev Kuleshov decided to follow the steps of his father and entered the Moscow School of Painting, although he didn't finish it. In 1916 he applied to work at the film company led by Aleksandr Khanzhonkov. He produced scenery for Yevgeni Bauer's pictures, such as "The King of Paris", "For Happiness" and others. With time Kuleshov became more interested in film theory. He co-directed his first movie "Twilight" in 1917. His next film was released under the Soviet patronage.
During the 1918-1920 he covered the Russian Civil War with a documentary crew. In 1919 he headed the first Soviet film courses at the National Film School. Kuleshov may well be the very first film theorist as he was a leader in the Soviet montage theory — developing his theories of editing before those of Sergei Eisenstein (briefly a student of Kuleshov). Among his other notable students were Vsevolod Pudovkin, Boris Barnet, Mikhail Romm, Sergey Komarov, Porfiri Podobed, Vladimir Fogel and Aleksandra Khokhlova who became his wife. For Kuleshov, the essence of the cinema was editing, the juxtaposition of one shot with another. To illustrate this principle, he created what has come to be known as the Kuleshov Effect. In this now-famous editing exercise, shots of an actor were intercut with various meaningful images (a casket, a bowl of soup, etc.) in order to show how editing changes viewers' interpretations of images. Another one of his famous inventions was creative geography, also known as artificial landscape. Those techniques were described in his book "The Basics of Film Direction" (1941) which was later translated into many languages.
In addition to his theoretical and teaching work, Kuleshov also directed a number of feature-length films. Among his most notable works is an action-comedy "The Extraordinary Adventures of Mr. West in the Land of the Bolsheviks" (1924), a psychological drama By the Law (1926) adapted from the short story by Jack London and a biographical drama The Great Consoler (1933) based on O. Henry's life and works. After directing his last film in 1943, Kuleshov served as an artistic director and an academic rector at VGIK where he worked for the next 25 years. He was a member of the jury at the 27th Venice International Film Festival, as well as a special guest during other international film festivals.
Lev Kuleshov died in Moscow in 1970. He was buried at the Novodevichy Cemetery. He was survived by his wife Aleksandra Khokhlova (1897—1985) — an actress, film director and educator, granddaughter of Pavel Tretyakov and Sergey Botkin — and Aleksandra's son from the first marriage.

</doc>
<doc id="18295" url="https://en.wikipedia.org/wiki?curid=18295" title="Legacy system">
Legacy system

In computing, a legacy system is an old method, technology, computer system, or application program, "of, relating to, or being a previous or outdated computer system." Often a pejorative term, referencing a system as "legacy" often implies that the system is out of date or in need of replacement.
Overview.
The first use of the term legacy to describe computer systems probably occurred in the 1970s. By the 1980s it was commonly used to refer to existing computer systems to distinguish them from the design and implementation of new systems. Legacy was often heard during a conversion process, for example, when moving data from the legacy system to a new database.
While this term may indicate that some engineers may feel that a system is out of date, a legacy system may continue to be used for a variety of reasons. It may simply be that the system still provides for the users' needs. In addition, the decision to keep an old system may be influenced by economic reasons such as return on investment challenges or vendor lock-in, the inherent challenges of change management, or a variety of other reasons other than functionality. Backward compatibility (such as the ability of newer systems to handle legacy file formats and character encodings) is a goal that software developers often include in their work.
Even if it is no longer used, a legacy system may continue to impact the organization due to its historical role. Historic data may not have been converted into the new system format and may exist within the new system with the use of a customized schema crosswalk, or may exist only in a data warehouse. In either case, the effect on business intelligence and operational reporting can be significant. A legacy system may include procedures or terminology which are no longer relevant in the current context, and may hinder or confuse understanding of the methods or technologies used.
Organizations can have compelling reasons for keeping a legacy system, such as:
Problems posed by legacy computing.
Legacy systems are considered to be potentially problematic by some software engineers for several reasons (for example, see Bisbal et al., 1999). 
Improvements on legacy software systems.
Where it is impossible to replace legacy systems through the practice of application retirement, it is still possible to enhance (or "re-face") them. Most development often goes into adding new interfaces to a legacy system. The most prominent technique is to provide a Web-based interface to a terminal-based mainframe application. This may reduce staff productivity due to slower response times and slower mouse-based operator actions, yet it is often seen as an "upgrade", because the interface style is familiar to unskilled users and is easy for them to use. John McCormick discusses such strategies that involve middleware.
Printing improvements are problematic because legacy software systems often add no formatting instructions, or they use protocols that are not usable in modern PC/Windows printers. A print server can be used to intercept the data and translate it to a more modern code. Rich Text Format (RTF) or PostScript documents may be created in the legacy application and then interpreted at a PC before being printed.
Biometric security measures are difficult to implement on legacy systems. A workable solution is to use a telnet or http proxy server to sit between users and the mainframe to implement secure access to the legacy application.
The change being undertaken in some organizations is to switch to automated business process (ABP) software which generates complete systems. These systems can then interface to the organizations' legacy systems and use them as data repositories. This approach can provide a number of significant benefits: the users are insulated from the inefficiencies of their legacy systems, and the changes can be incorporated quickly and easily in the ABP software .
Model-driven reverse and forward engineering approaches can be also used for the improvement of legacy software. Model-driven tools and methodologies can support the migration of legacy software to Cloud computing environments and allow for its modernization, in the notion of Software as a service, exploiting the advanced business and technical characteristics of clouds.
NASA example.
Andreas Hein, from the University of Stuttgart, researched the use of legacy systems in space exploration. According to Hein, legacy systems are attractive for reuse if an organization has the capabilities for verification, validation, testing, and operational history. These capabilities must be integrated into various software life cycle phases such as development, implementation, usage, or maintenance. For software systems, the capability to use and maintain the system are crucial. Otherwise the system will become less and less understandable and maintainable.
According to Hein, verification, validation, testing, and operational history increases the confidence in a system's reliability and quality. However, accumulating this history is often expensive. NASA's now retired Space Shuttle program used a large amount of 1970s-era technology. Replacement was cost-prohibitive because of the expensive requirement for flight certification. The original hardware completed the expensive integration and certification requirement for flight, but any new equipment would have had to go through that entire process again. This long and detailed process required extensive tests of the new components in their new configurations before a single unit could be used in the Space Shuttle program. Thus any new system that started the certification process becomes a "de facto" legacy system by the time it is approved for flight.
Additionally, the entire Space Shuttle system, including ground and launch vehicle assets, was designed to work together as a closed system. Since the specifications did not change, all of the certified systems and components performed well in the roles for which they were designed. Even before the Shuttle was scheduled to be retired in 2010, NASA found it advantageous to keep using many pieces of 1970s technology rather than to upgrade those systems and recertify the new components.
Additional uses of the term "Legacy" in computing.
The term "legacy support" is often used in conjunction with legacy systems. The term may refer to a feature of modern software. For example, Operating systems with "legacy support" can detect and use older hardware. The term may also be used to refer to a business function; e.g. A software or hardware vendor that is supporting, or providing software maintenance, for older products.
A "legacy" product may be a product that is no longer sold, has lost substantial market share, or is a version of a product that is not current. A legacy product may have some advantage over a modern product making it appealing for customers to keep it around. A product is only truly "obsolete" if it has an advantage to nobody – if no person making a rational decision would choose to acquire it new.
The term "legacy mode" often refers specifically to backward compatibility. A software product that is capable of performing as though it were a previous version of itself, is said to be "running in legacy mode." This kind of feature is common in operating systems and internet browsers, where many applications depend on these underlying components.
The computer mainframe era saw many applications running in legacy mode. In the modern business computing environment, n-tier, or 3-tier architectures are more difficult to place into legacy mode as they include many components making up a single system.
Virtualization technology is a recent innovation allowing legacy systems to continue to operate on modern hardware by running older operating systems and browsers on a software system that emulates legacy hardware.
Brownfield architecture.
The field of Information Technology has borrowed the term "brownfield" from the building industry, where undeveloped land (and especially unpolluted land) is described as "greenfield" and previously developed land – which is often polluted and abandoned – is described as "brownfield".
Alternative view.
There is an alternate point of view — growing since the "Dot Com" bubble burst in 1999 — that legacy systems are simply computer systems that are both installed and working. In other words, the term is not pejorative, but the opposite. Bjarne Stroustrup, creator of the C++ language, addressed this issue succinctly:
IT analysts estimate that the cost of replacing business logic is about five times that of reuse, and that is not counting the risks involved in wholesale replacement. Ideally, businesses would never have to rewrite most core business logic; debits must equal credits — they always have, and they always will. New software may increase the risk of system failures and security breaches.
The IT industry is responding to these concerns. "Legacy modernization" and "legacy transformation" refer to the act of reusing and refactoring existing core business logic by providing new user interfaces (typically Web interfaces), sometimes through the use of techniques such as screen scraping and service-enabled access (e.g. through web services). These techniques allow organizations to understand their existing code assets (using discovery tools), provide new user and application interfaces to existing code, improve workflow, contain costs, minimize risk, and enjoy classic qualities of service (near 100% uptime, security, scalability, etc.).
The re-examination of attitudes toward legacy systems is also inviting more reflection on what makes legacy systems as durable as they are. Technologists are relearning that sound architecture, practiced up front, helps businesses avoid costly and risky rewrites in the first place. The most common legacy systems tend to be those which embraced well-known IT architectural principles, with careful planning and strict methodology during implementation. Poorly designed systems often don't last, both because they wear out and because their reliability or usability are low enough that no one is inclined to make an effort to extend their term of service when replacement is an option. Thus, many organizations are rediscovering the value of both their legacy systems themselves and those systems' philosophical underpinnings.

</doc>
<doc id="18297" url="https://en.wikipedia.org/wiki?curid=18297" title="Lamentations">
Lamentations

Lamentations may refer to:

</doc>
<doc id="18298" url="https://en.wikipedia.org/wiki?curid=18298" title="Lunar eclipse">
Lunar eclipse

A lunar eclipse occurs when the Moon passes directly behind the Earth into its umbra (shadow). This can occur only when the sun, Earth and moon are aligned (in "syzygy") exactly, or very closely so, with the Earth in the middle. Hence, a lunar eclipse can occur only the night of a full moon. The type and length of an eclipse depend upon the Moon's location relative to its orbital nodes.
A total lunar eclipse has the direct sunlight completely blocked by the earth's shadow. The only light seen is refracted through the earth's shadow. This light looks red for the same reason that the sunset looks red, due to rayleigh scattering of the more blue light. Because of its reddish color, a total lunar eclipse is sometimes called a blood moon.
Unlike a solar eclipse, which can be viewed only from a certain relatively small area of the world, a lunar eclipse may be viewed from anywhere on the night side of the Earth. A lunar eclipse lasts for a few hours, whereas a total solar eclipse lasts for only a few minutes at any given place, due to the smaller size of the Moon's shadow. Also unlike solar eclipses, lunar eclipses are safe to view without any eye protection or special precautions, as they are dimmer than the full moon.
For the date of the next eclipse see the section "Recent and forthcoming lunar eclipses".
Types of lunar eclipse.
The shadow of the Earth can be divided into two distinctive parts: the umbra and penumbra. Within the umbra, there is no direct solar radiation. However, as a result of the Sun's large angular size, solar illumination is only partially blocked in the outer portion of the Earth's shadow, which is given the name penumbra.
A penumbral eclipse occurs when the moon passes through the Earth's penumbra. The penumbra causes a subtle darkening of the moon's surface. A special type of penumbral eclipse is a total penumbral eclipse, during which the Moon lies exclusively within the Earth's penumbra. Total penumbral eclipses are rare, and when these occur, that portion of the moon which is closest to the umbra can appear somewhat darker than the rest of the moon.
A partial lunar eclipse occurs when only a portion of the moon enters the umbra. When the moon travels completely into the Earth's umbra, one observes a total lunar eclipse. The moon's speed through the shadow is about one kilometer per second (2,300 mph), and totality may last up to nearly 107 minutes. Nevertheless, the total time between the moon's first and last contact with the shadow is much longer, and could last up to four hours. The relative distance of the moon from the Earth at the time of an eclipse can affect the eclipse's duration. In particular, when the moon is near its apogee, the farthest point from the Earth in its orbit, its orbital speed is the slowest. The diameter of the umbra does not decrease appreciably within the changes in the orbital distance of the moon. Thus, a totally eclipsed moon occurring near apogee will lengthen the duration of totality.
A central lunar eclipse is a total lunar eclipse during which the moon passes through the centre of the Earth's shadow. These are relatively rare.
Selenelion.
A selenelion or selenehelion occurs when both the Sun and the eclipsed Moon can be observed at the same time. This can happen only just before sunset or just after sunrise, and both bodies will appear just above the horizon at nearly opposite points in the sky. This arrangement has led to the phenomenon being referred to as a horizontal eclipse. There are typically a number of high ridges undergoing sunrise or sunset that can see it. Although the moon is in the Earth’s umbra, the Sun and the eclipsed Moon can both be seen at the same time because the refraction of light through the Earth’s atmosphere causes each of them to appear higher in the sky than their true geometric position.
Danjon scale.
The following scale (the Danjon scale) was devised by André Danjon for rating the overall darkness of lunar eclipses:
Lunar versus solar eclipse.
There is often confusion between a solar and lunar eclipse. While both involve interactions between the sun, Earth and moon, they are very different in their interactions.
Lunar eclipse appearance.
The moon does not completely disappear as it passes through the umbra because of the refraction of sunlight by the Earth's atmosphere into the shadow cone; if the Earth had no atmosphere, the Moon would be completely dark during an eclipse. The reddish coloration arises because sunlight reaching the Moon must pass through a long and dense layer of the Earth's atmosphere, where it is scattered. Shorter wavelengths are more likely to be scattered by the air molecules and the small particles, and so by the time the light has passed through the atmosphere, the longer wavelengths dominate. This resulting light we perceive as red. This is the same effect that causes sunsets and sunrises to turn the sky a reddish color; an alternative way of considering the problem is to realize that, as viewed from the moon, the sun would appear to be setting (or rising) behind the Earth.
The amount of refracted light depends on the amount of dust or clouds in the atmosphere; this also controls how much light is scattered. In general, the dustier the atmosphere, the more that other wavelengths of light will be removed (compared to red light), leaving the resulting light a deeper red color. This causes the resulting coppery-red hue of the moon to vary from one eclipse to the next. Volcanoes are notable for expelling large quantities of dust into the atmosphere, and a large eruption shortly before an eclipse can have a large effect on the resulting color.
Solar eclipse appearance.
A solar eclipse occurs when the Moon casts its shadow on Earth whilst passing between the sun and Earth. Because the Moon's orbit is 5 degrees tilted to the Earth's orbit around the sun, a solar eclipse is rare. The moon has an elliptical orbit around the Earth, so the separation of the two varies from about 221,000 to 252,000 miles. When the moon's distance from the Earth is low, the moon appears significantly larger and can completely obscure the sun causing a total solar eclipse. An annular solar eclipse occurs when the moon is furthest from the Earth. On these occasions the moon will appear to be smaller and not fully eclipse the sun.
March 1504 lunar eclipse.
When Christopher Columbus came to the New World—specifically, the north coast of Jamaica—he was able to use European scientific understanding to correctly predict a lunar eclipse. The event is known as the March 1504 lunar eclipse, and occurred when Columbus, after he wanted to be seen as god-like, stated that he would make the moon disappear during the night of February 29, 1504. The reason Columbus wanted to prove he could make the moon disappear is because he and his crew were eating a great deal of the inhabitants' food, and the inhabitants refused to feed them anymore. Columbus was right in his prediction, for he used astronomical tables and local clocks in order to predict when the lunar eclipse would happen, and was able to convince the inhabitants that he had the power to make the moon disappear and then reappear. After the inhabitants believed that Columbus was truly able to make the moon disappear, they begged him to return the moon to its previous form, and after roughly an allotted amount of time (the amount of time Columbus discerned to be how long the eclipse would last), Columbus agreed to return the moon, and the moon began to reappear. The next day, the inhabitants gave Columbus and his crew the food they desired.
Lunar eclipse in culture.
Several cultures have myths related to lunar eclipses or allude to the lunar eclipse as being a good or bad omen. The Egyptians saw the eclipse as a sow swallowing the moon for a short time; other cultures view the eclipse as the moon being swallowed by other animals, such as a jaguar in Mayan tradition, or a three legged toad in China. Some societies thought it was a demon swallowing the moon, and that they could chase it away by throwing stones and curses at it. The Greeks were ahead of their time when they said the Earth was round and used the shadow from the lunar eclipse as evidence. Some Hindus believe in the importance of bathing in the Ganges River following an eclipse because it will help you achieve salvation.
Incans.
Similarly to the Mayans, the Incans believed that lunar eclipses occurred when a jaguar would eat the moon, which is why a blood moon looks red. The Incans also believed that once the jaguar finished eating the moon, it could come down and devour all the animals on Earth, so they would take spears and shout at the moon to keep it away.
Mesopotamians.
The ancient Mesopotamians believed that a lunar eclipse was when the moon was being attacked by seven demons. This attack was more than just one on the moon, however, for the Mesopotamians linked what happened in the sky with what happened on the land, and because the king of Mesopotamia represented the land, the seven demons were thought to be also attacking the king. In order to prevent this attack on the king, the Mesopotamians made someone pretend to be the king so they would be attacked instead of the true king. After the lunar eclipse was over, the substitute king was made to disappear (possibly by poisoning).
Chinese.
In some Chinese cultures, people would ring bells to prevent a dragon or other wild animals from biting the moon. In the nineteenth century, during a lunar eclipse, the Chinese navy fired its artillery because of this belief. During the Zhou Dynasty in the Book of Songs, the sight of a red moon engulfed in darkness was believed to foreshadow famine or disease.
Blood moon.
Due to its reddish color, a totally eclipsed moon is sometimes referred to as a "blood moon". In addition, in the 2010s the media started to associate the term with the four full moons of a lunar tetrad, especially the 2014–15 tetrad coinciding with the feasts of Passover and Tabernacles. A lunar tetrad is a series of four consecutive total lunar eclipses, spaced six months apart.
"Blood Moon" is not a scientific term, but has come to be used due to the reddish color seen on a "Super Moon" during the lunar eclipse. When sunlight passes through the earth's atmosphere, it filters and reflects in such a way that the green to violet lights on the spectrum scatters more strongly than the red light.This results the moon to get more red light
Occurrence.
Every year, there are at least two lunar eclipses and as many as five, although total lunar eclipses are significantly less common. If one knows the date and time of an eclipse, it is possible to predict the occurrence of other eclipses using an eclipse cycle like the saros.
Recent and forthcoming lunar eclipses.
Eclipses only occur during an eclipse season, when the Sun is close to either the ascending or descending node of the Moon.

</doc>
<doc id="18303" url="https://en.wikipedia.org/wiki?curid=18303" title="Liber Pontificalis">
Liber Pontificalis

The Liber Pontificalis (Latin for "Book of the Popes") is a book of biographies of popes from Saint Peter until the 15th century. The original publication of the "Liber Pontificalis" stopped with Pope Adrian II (867–872) or Pope Stephen V (885–891), but it was later supplemented in a different style until Pope Eugene IV (1431–1447) and then Pope Pius II (1458–1464). Although quoted virtually uncritically from the 8th to 18th century, the "Liber Pontificalis" has undergone intense modern scholarly scrutiny. The work of the French priest Louis Duchesne (who compiled the major scholarly edition), and of others has highlighted some of the underlying redactional motivations of different sections, though such interests are so disparate and varied as to render improbable one popularizer's claim that it is an "unofficial instrument of pontifical propaganda."
The title "Liber Pontificalis" goes back to the 12th century, although it only became current in the 15th century, and the canonical title of the work since the edition of Duchesne in the 19th century. In the earliest extant manuscripts it is referred to as Liber episcopalis in quo continentur acta beatorum pontificum Urbis Romae, and later the Gesta or Chronica pontificum.
Authorship.
During the Middle Ages, Saint Jerome was considered the author of all the biographies up until those of Pope Damasus I (366–383), based on an apocryphal letter between Saint Jerome and Pope Damasus published as a preface to the Medieval manuscripts. The attribution originated with Rabanus Maurus and is repeated by Martin of Opava, who extended the work into the 13th century. Other sources attribute the early work to Hegesippus and Irenaeus, having been continued by Eusebius of Caesarea.
In the 16th century, Onofrio Panvinio attributed the biographies after Damasus until Pope Nicholas I (858–867) to Anastasius Bibliothecarius; Anastasius continued to be cited as the author into the 17th century, although this attribution was disputed by the scholarship of Caesar Baronius, Ciampini, Schelstrate and others.
The modern interpretation, following that of Louis Duchesne, is that the "Liber Pontificalis" was gradually and unsystematically compiled, and that the authorship is impossible to determine, with a few exceptions (e.g. the biography of Pope Stephen II (752–757) to papal "Primicerius" Christopher; the biographies of Pope Nicholas I and Pope Adrian II (867–872) to Anastasius). Duchesne and others have viewed the beginning of the "Liber Pontificalis" up until the biographies of Pope Felix III (483–492) as the work of a single author, who was a contemporary of Pope Anastasius II (496-498), relying on "Catalogus Liberianus", which in turn draws from the papal catalogue of Hippolytus of Rome, and the "Leonine Catalogue", which is no longer extant. Most scholars believe the "Liber Pontificalis" was first compiled in the 5th or 6th century.
Because of the use of the "vestiarium", the records of the papal treasury, some have hypothesized that the author of the early "Liber Pontificalis" was a clerk of the papal treasury. Edward Gibbon's "Decline and Fall of the Roman Empire" (1788) summarised the scholarly consensus as being that the "Liber Pontificalis" was composed by "apostolic librarians and notaries of the viiith and ixth centuries" with only the most recent portion being composed by Anastasius.
Duchesne and others believe that the author of the first addition to the "Liber Pontificalis" was a contemporary of Pope Silverius (536–537), and that the author of another (not necessarily the second) addition was a contemporary of Pope Conon (686–687), with later popes being added individually and during their reigns or shortly after their deaths.
Content.
The "Liber Pontificalis" originally only contained the names of the bishops of Rome and the durations of their pontificates. As enlarged in the 6th century, each biography consists of: the birth name of the pope and that of his father, place of birth, profession before elevation, length of pontificate, historical notes of varying thoroughness, major theological pronouncements and decrees, administrative milestones (including building campaigns, especially of Roman churches), ordinations, date of death, place of burial, and the duration of the ensuing "sede vacante".
Pope Adrian II (867–872) is the last pope for which there are extant manuscripts of the original "Liber Pontificalis": the biographies of Pope John VIII, Pope Marinus I, and Pope Adrian III are missing and the biography of Pope Stephen V (885–891) is incomplete. From Stephen V through the 10th and 11th centuries, the historical notes are extremely abbreviated, usually with only the pope's origin and reign duration.
Extension.
It was only in the 12th century that the "Liber Pontificalis" was systematically continued, although papal biographies exist in the interim period in other sources.
Petrus Guillermi.
Duchesne refers to the 12th century work by Petrus Guillermi in 1142 at the monastery of St. Gilles (Diocese of Reims) as the "Liber Pontificalis of Petrus Guillermi (son of William)". Guillermi's version is mostly copied from other works with small additions or excisions from the papal biographies of Pandulf, nephew of Hugo of Alatri, which in turn was copied almost verbatim from the original "Liber Pontificalis" (with the notable exception of the biography of Pope Leo IX), then from other sources until Pope Honorius II (1124–1130), and with contemporary information from Pope Paschal II (1099–1118) to Pope Urban II (1088–1099).
Duchesne attributes all biographies from Pope Gregory VII to Urban II to Pandulf, while earlier historians like Giesebrecht and Watterich attributed the biographies of Gregory VII, Victor III, and Urban II to Petrus Pisanus, and the subsequent biographies to Pandulf. These biographies until those of Pope Martin IV (1281–1285) are extant only as revised by Petrus Guillermi in the manuscripts of the monastery of St. Gilles having been taken from the Chronicle of Martin of Opava.
Early in the 14th century, an unknown author built upon the continuation of Petrus Guillermi, adding the biographies of popes Martin IV (d. 1285) through John XXII (1316–1334), with information taken from the "Chronicon Pontificum" of Bernardus Guidonis, stopping abruptly in 1328.
Boso.
Independently, the cardinal-nephew of Pope Adrian IV, Cardinal Boso intended to extend the "Liber Pontificalis" from where it left off with Stephen V, although his work was only published posthumously as the "Gesta Romanorum Pontificum" alongside the "Liber Censuum" of Pope Honorius III. Boso drew on Bonizo of Sutri for popes from John XII to Gregory VII, and wrote from his own experiences about the popes from Gelasius II (1118–1119) to Alexander III (1179–1181).
Western Schism.
An independent continuation appeared in the reign of Pope Eugene IV (1431–1447), appending biographies from Pope Urban V (1362–1370) to Pope Martin V (1417–1431), encompassing the period of the Western Schism. A later recension of this continuation was expanded under Pope Eugene IV.
15th century.
The two collections of papal biographies of the 15th century remain independent, although they may have been intended to be continuations of the "Liber Pontificalis". The first extends from popes Benedict XII (1334–1342) to Martin V (1417–1431), or in one manuscript to Eugene IV (1431–1447). The second extends from Pope Urban VI (1378–1389) to Pope Pius II (1458–1464).
Editions.
The "Liber Pontificalis" was first edited by J. Busæus under the title "Anastasii bibliothecarii Vitæ seu Gesta. Romanorum Pontificum" (Mainz, 1602). A new edition, including the "Historia ecclesiastica" of Anastasius, was edited by Fabrotti (Paris, l647). Another edition, editing the older "Liber Pontificalis" up to Pope Adrian II and adding Pope Stephen VI, was compiled by Fr. Bianchini (4 vols., Rome, 1718–35; a projected fifth volume did not appear). Muratori reprinted Bianchini's edition, adding the remaining popes through John XXII (Scriptores rerum Italicarum, III). Migne also republished Bianchini's edition, adding several appendixes (P. L., CXXVII-VIII).
Modern editions include those of Louis Duchesne ("Liber Pontificalis. Texte, introduction et commentaire", 2 vols., Paris, 1886–92) and Theodor Mommsen ("Gestorum Pontificum Romanorum pars I: Liber Pontificalis", Mon. Germ. hist., Berlin, 1898). Duchesne incorporates the "Annales Romani" (1044–1187) into his edition of the "Liber Pontificalis", which otherwise relies on the two earliest known recensions of the work (530 and 687). Mommsen's edition is incomplete, extending only until 715. Translations and further commentaries appeared throughout the 20th century.

</doc>
<doc id="18306" url="https://en.wikipedia.org/wiki?curid=18306" title="Latin alphabet">
Latin alphabet

The classical Latin alphabet, also known as the Roman alphabet, is a writing system that evolved from the visually similar Cumaean Greek version of the Greek alphabet. The Greek alphabet, including the Cumaean version, descended from the Phoenician abjad while the Phoenician alphabet is derived from Egyptian hieroglyphics. The Etruscans who ruled early Rome adopted and modified the Cumaean Greek alphabet. The Etruscan alphabet was in turn adopted and further modified by the ancient Romans to write the Latin language.
During the Middle Ages scribes adapted the Latin alphabet for writing Romance languages, direct descendants of Latin, as well as Celtic, Germanic, Baltic, and some Slavic languages. With the age of colonialism and Christian evangelism, the Latin script spread beyond Europe, coming into use for writing indigenous American, Australian, Austronesian, Austroasiatic, and African languages. More recently, linguists have also tended to prefer the Latin script or the International Phonetic Alphabet (itself largely based on Latin script) when transcribing or creating written standards for non-European languages, such as the African reference alphabet.
The term "Latin alphabet" may refer to either the alphabet used to write Latin (as described in this article), or other alphabets based on the Latin script, which is the basic set of letters common to the various alphabets descended from the classical Latin one, such as the English alphabet. These Latin alphabets may discard letters, like the Rotokas alphabet, or add new letters, like the Danish and Norwegian alphabets. Letter shapes have evolved over the centuries, including the creation for Medieval Latin of lower-case forms which did not exist in the Classical period alphabet.
History.
Origins.
It is generally believed that the Romans adopted the Cumae alphabet, a variant of the Greek alphabet, in the 7th century BC from Cumae, a Greek colony in Southern Italy. (Gaius Julius Hyginus in "Fab. 277" mentions the legend that it was Carmenta, the Cimmerian Sibyl, who altered fifteen letters of the Greek alphabet to become the Latin alphabet, which her son Evander introduced into Latium, supposedly 60 years before the Trojan War, but there is no historically sound basis to this tale.) The Ancient Greek alphabet was in turn based upon the Phoenician abjad. From the Cumae alphabet, the Etruscan alphabet was derived and the Romans eventually adopted 21 of the original 27 Etruscan letters:
Archaic Latin alphabet.
The letter was the western form of the Greek gamma, but it was used for the sounds and alike, possibly under the influence of Etruscan, which might have lacked any voiced plosives. Later, probably during the 3rd century BC, the letter — unneeded to write Latin properly — was replaced with the new letter , a modified with a small vertical stroke, which took its place in the alphabet. From then on, represented the voiced plosive , while was generally reserved for the voiceless plosive . The letter was used only rarely, in a small number of words such as "Kalendae", often interchangeably with .
Classical Latin alphabet.
After the Roman conquest of Greece in the 1st century BC, Latin adopted the Greek letters and (or readopted, in the latter case) to write Greek loanwords, placing them at the end of the alphabet. An attempt by the emperor Claudius to introduce three additional letters did not last. Thus it was during the classical Latin period that the Latin alphabet contained 23 letters:
The letter when introduced was probably called "hy" as in Greek, the name upsilon not being in use yet, but this was changed to "i Graeca" (Greek i) as Latin speakers had difficulty distinguishing its foreign sound from . was given its Greek name, zeta. This scheme has continued to be used by most modern European languages that have adopted the Latin alphabet. For the Latin sounds represented by the various letters see Latin spelling and pronunciation; for the names of the letters in English see English alphabet.
The primary diacritic was the apex used to mark long vowels, which had previously been written double. However, in place of taking an apex, the letter i was written taller: . For example, what is today transcribed "lūciī a filiī" was written in the inscription at right.
The primary mark of punctuation was the interpunct, which was used as a word divider, though it fell out of use after 200 AD.
Old Roman cursive script, also called majuscule cursive and capitalis cursive, was the everyday form of handwriting used for writing letters, by merchants writing business accounts, by schoolchildren learning the Latin alphabet, and even emperors issuing commands. A more formal style of writing was based on Roman square capitals, but cursive was used for quicker, informal writing. It was most commonly used from about the 1st century BC to the 3rd century, but it probably existed earlier than that. It led to Uncial, a majuscule script commonly used from the 3rd to 8th centuries AD by Latin and Greek scribes.
New Roman cursive script, also known as minuscule cursive, was in use from the 3rd century to the 7th century, and uses letter forms that are more recognizable to modern eyes; , , , and had taken a more familiar shape, and the other letters were proportionate to each other. This script evolved into the medieval scripts known as Merovingian and Carolingian minuscule.
Medieval and later developments.
It was not until the Middle Ages that the letter (originally a ligature of two s) was added to the Latin alphabet, to represent sounds from the Germanic languages which did not exist in medieval Latin, and only after the Renaissance did the convention of treating and as vowels, and and as consonants, become established. Prior to that, the former had been merely allographs of the latter.
With the fragmentation of political power, the style of writing changed and varied greatly throughout the Middle Ages, even after the invention of the printing press. Early deviations from the classical forms were the uncial script, a development of the Old Roman cursive, and various so-called minuscule scripts that developed from New Roman cursive, of which the Carolingian minuscule was the most influential, introducing the lower case forms of the letters, as well as other writing conventions that have since become standard.
The languages that use the Latin script today generally use capital letters to begin paragraphs and sentences and proper nouns. The rules for capitalization have changed over time, and different languages have varied in their rules for capitalization. Old English, for example, was rarely written with even proper nouns capitalized; whereas Modern English of the 18th century had frequently all nouns capitalized, in the same way that Modern German is written today, e.g. "Alle Schwestern der alten Stadt hatten die Vögel gesehen" ("All of the sisters of the old city had seen the birds").
Spread.
The Latin alphabet spread, along with the Latin language, from the Italian Peninsula to the lands surrounding the Mediterranean Sea with the expansion of the Roman Empire. The eastern half of the Empire, including Greece, Turkey, the Levant, and Egypt, continued to use Greek as a lingua franca, but Latin was widely spoken in the western half, and as the western Romance languages evolved out of Latin, they continued to use and adapt the Latin alphabet.
With the spread of Western Christianity during the Middle Ages, the script was gradually adopted by the peoples of northern Europe who spoke Celtic languages (displacing the Ogham alphabet) or Germanic languages (displacing earlier Runic alphabets), Baltic languages, as well as by the speakers of several Uralic languages, most notably Hungarian, Finnish and Estonian. 
The Latin alphabet came into use for writing the West Slavic languages and several South Slavic languages, as the people who spoke them adopted Roman Catholicism. In the 20th century romanization schemes were applied to many languages. The Kazakh government announced in 2015 that the Latin alphabet will replace Cyrillic as the writing system for the Kazakh language by 2025.
The spread of the Latin alphabet among previously illiterate peoples has inspired the creation of new writing systems, such as the Avoiuli alphabet in Vanuatu, which replaces the letters of the Latin alphabet with alternative symbols.

</doc>
<doc id="18307" url="https://en.wikipedia.org/wiki?curid=18307" title="Lugh">
Lugh

Lugh or Lug (; modern Irish: "Lú" ) is an Irish deity represented in mythological texts as a hero and High King of the distant past. He is known by the epithets "Lámhfhada" (, meaning "long arm" or "long hand"), for his skill with a spear or sling, "Ildánach" ("skilled in many arts"), "Samhildánach" ("Equally skilled in many arts"), "Lonnbeimnech" ("fierce striker" or perhaps "sword-shouter") and "Macnia" ("boy hero"), and by the matronymic "mac Ethlenn" or "mac Ethnenn" ("son of Ethliu or Ethniu"). He is a reflex of the pan-Celtic god Lugus, and his Welsh counterpart is Lleu Llaw Gyffes, "The Bright One with the Strong Hand".
Lugh in Irish tradition.
Birth.
Lugh's father is Cian of the Tuatha Dé Danann, and his mother is Ethniu, daughter of Balor, of the Fomorians. In "Cath Maige Tuired" their union is a dynastic marriage following an alliance between the Tuatha Dé and the Fomorians. In the "Lebor Gabála Érenn" Cian gives the boy to Tailtiu, queen of the Fir Bolg, in fosterage.
A folktale told to John O'Donovan by Shane O'Dugan of Tory Island in 1835 recounts the birth of a grandson of Balor who grows up to kill his grandfather. The grandson is unnamed, his father is called Mac Cinnfhaelaidh and the manner of his killing of Balor is different, but it has been taken as a version of the birth of Lugh, and was adapted as such by Lady Gregory. In this tale, Balor hears a druid's prophecy that he will be killed by his own grandson. To prevent this he imprisons his only daughter in the Tór Mór (great tower) of Tory Island, cared for by twelve women, who are to prevent her ever meeting or even learning of the existence of men. On the mainland, Mac Cinnfhaelaidh owns a magic cow who gives such abundant milk that everyone, including Balor, wants to possess her. While the cow is in the care of Mac Cinnfhaelaidh's brother Mac Samthainn, Balor appears in the form of a little red-haired boy and tricks him into giving him the cow. Looking for revenge, Mac Cinnfhaelaidh calls on a "leanan sídhe" (fairy woman) called Biróg, who transports him by magic to the top of Balor's tower, where he seduces Eithne. In time she gives birth to triplets, which Balor gathers up in a sheet and sends to be drowned in a whirlpool. The messenger drowns two of the babies, but unwittingly drops one child into the harbour, where he is rescued by Biróg. She takes him to his father, who gives him to his brother, Gavida the smith, in fosterage.
There may be further triplism associated with his birth. His father in the folktale is one of a triad of brothers, Mac Cinnfhaelaidh, Gavida and Mac Samthainn, and his father in the medieval texts, Cian, is often mentioned together with his brothers Cú and Cethen. Two characters called Lugaid, a popular medieval Irish name thought to derive from Lugh, have three fathers: Lugaid Riab nDerg (Lugaid of the Red Stripes) was the son of the three "Findemna" or fair triplets, and Lugaid mac Con Roí was also known as "mac Trí Con", "son of three hounds". In Ireland's other great "sequestered maiden" story, the tragedy of Deirdre, the king's intended is carried off by three brothers, who are hunters with hounds. The canine imagery continues with Cian's brother Cú ("hound"), another Lugaid, Lugaid Mac Con (son of a hound), and Lugh's son Cúchulainn ("Culann's Hound"). A fourth Lugaid was Lugaid Loígde, a legendary King of Tara and ancestor of (or inspiration for) Lugaid Mac Con.
Lugh joins the Tuatha Dé Danann.
As a young man Lugh travels to Tara to join the court of king Nuada of the Tuatha Dé Danann. The doorkeeper will not let him in unless he has a skill with which to serve the king. He offers his services as a wright, a smith, a champion, a swordsman, a harpist, a hero, a poet and historian, a sorcerer, and a craftsman, but each time is rejected as the Tuatha Dé Danann already have someone with that skill. But when Lugh asks if they have anyone with all those skills simultaneously, the doorkeeper has to admit defeat, and Lugh joins the court and is appointed Chief Ollam of Ireland. He wins a flagstone-throwing contest against Ogma, the champion, and entertains the court with his harp. The Tuatha Dé Danann are at that time oppressed by the Fomorians, and Lugh is amazed how meekly they accept this. Nuada wonders if this young man could lead them to freedom. Lugh is given command over the Tuatha Dé Danann, and he begins making preparations for war.
The sons of Tuireann.
When the sons of Tuireann: Brian, Iuchar and Iucharba kill Lugh's father, Cian (who was in the form of a pig at the time), Lugh sets them a series of seemingly impossible quests as recompense. They achieve them all but are fatally wounded in completing the last one. Despite Tuireann's pleas, Lugh denies them the use of one of the items they have retrieved, a magic pigskin which heals all wounds. They die of their wounds and Tuireann dies of grief over their bodies.
The Battle of Magh Tuireadh.
Using the magic artifacts the sons of Tuireann have gathered, Lugh leads the Tuatha Dé Danann in the Second Battle of Mag Tuireadh against the Fomorians. Nuada is killed in the battle by Balor. Lugh faces Balor, who opens his terrible, poisonous eye that kills all it looks upon, but Lugh shoots a sling-stone that drives his eye out the back of his head, wreaking havoc on the Fomorian army behind. After the victory Lugh finds Bres, the half-Fomorian former king of the Tuatha Dé Danann, alone and unprotected on the battlefield, and Bres begs for his life. If he is spared, he promises, he will ensure that the cows of Ireland always give milk. The Tuatha Dé Danann refuse the offer. He then promises four harvests a year, but the Tuatha Dé Danann say one harvest a year suits them. But Lugh spares his life on the condition that he teach the Tuatha Dé Danann how and when to plough, sow and reap.
Later life and death.
Lugh instituted an event similar to the Olympic games called the Assembly of Talti which finished on Lughnasadh (1 August) in memory of his foster-mother, Tailtiu, at the town that bears her name (now Teltown, County Meath). He likewise instituted Lughnasadh fairs in the areas of Carman and Naas in honour of Carman and Nás, the eponymous tutelary goddess of these two regions. Horse races and displays of martial arts were important activities at all three fairs. However, Lughnasadh itself is a celebration of Lugh's triumph over the spirits of the Otherworld who had tried to keep the harvest for themselves. It survived long into Christian times and is still celebrated under a variety of names. "Lúnasa" is now the Irish name for the month of August.
According to a poem of the "dindsenchas", Lugh was responsible for the death of Bres. He made 300 wooden cows, and filled them with a bitter, poisonous red liquid which was then "milked" into pails and offered to Bres to drink. Bres, who was under an obligation not to refuse hospitality, drank it down without flinching, and it killed him.
Lugh is said to have invented the board game fidchell. He had a dog called Failinis.
He had several wives, including Buí and Nás, daughters of Ruadri, king of Britain. Buí lived and was buried at Knowth. Nás was buried at Naas, County Kildare, which is named after her. Lugh had a son, Ibic, by Nás. His daughter or sister was Ebliu, who married Fintan. One of his wives, unnamed, had an affair with Cermait, son of the Dagda. Lugh killed him in revenge, but Cermait's sons, Mac Cuill, Mac Cecht and Mac Gréine, killed Lugh in return, drowning him in Loch Lugborta. He had ruled for forty years.
Lugh's possessions.
Lug possessed a number of magical items, retrieved by the sons of Tuirill Piccreo in Middle Irish redactions of the Lebor Gabála. Not all the items are listed here. The late narrative "Fate of the Children of Tuireann" not only gives a list of items gathered for Lugh, but also endows him with such gifts from the sea god Manannán as the sword Fragarach, the horse Enbarr (Aonbarr), the boat / ("Wave-Sweeper"), his armour and helmet.
Lugh's Spear.
The lore around Lug's Spear is traced as follows:
Four Treasures Spear of Lugh.
Lugh's spear (), according to the text of The Four Jewels of the Tuatha Dé Danann, was said to be impossible to overcome, taken to Ireland from Gorias (or Findias).
Gae Assail.
Lugh obtained the Spear of Assal () as fine () imposed on the children of Tuirill Piccreo (or Biccreo), according to the short account in (Poem LXV, 319), which adds that the incantation "Ibar (Yew)" made the cast always hit its mark, and "Athibar (Re-Yew)" caused the spear to return.
Areadbhar.
In a full narrative version called (The Fate of the Children of Tuireann), from copies no earlier than the 18th century, Lugh demands the spear named "Ar-éadbair" or "Areadbhair" (Early Modern Irish: ) which belonged to Pisear, king of Persia. Its tip had to be kept immersed in a pot of water to keep it from igniting, a property similar to the Lúin of Celtchar. This spear is also called "Slaughterer" in translation.
Finest Yew of the Wood.
There is yet another name that Lugh's spear goes by: "A tree, the finest of the wood" (Early Modern Irish: ),
Sling-stone.
Lugh used the "sling-stone" ("cloich tabaill") to slay his grandfather, Balor the Strong-Smiter in the Battle of Magh Tuired according to the brief accounts in the Lebor Gabála Érenn. The narrative , preserved in a unique 16th century copy, words it slightly different saying that Lugh used the sling-stone (here § 133, i.e. "stone" of the ' "sling") to destroy the evil eye of Balor of the Piercing Eye (Bolur Birugderc).
Tathlum.
A certain poem recorded by O'Curry in English translation says that the missile fired by Lugh was a tathlum ( "(slingstone made of) cement").
Nature Myth Items.
Lugh's projectile weapon, whether a dart or missile, was envisioned by symbolic of lightning-weapon T. F. O'Rahilly. Lugh's sling rod, named "Lugh's Chain", was the rainbow and the Milky Way. Unlike the rod-sling, Lugh had no need to wield the spear himself. It was alive and thirsted so for blood that only by steeping its head in a sleeping-draught of pounded fresh poppy seeds could it be kept at rest. When battle was near, it was drawn out; then it roared and struggled against its thongs, fire flashed from it, and it tore through the ranks of the enemy once slipped from the leash, never tired of slaying.
Fragarach.
Lugh is also seen girt with the Freagarthach (better known as Fragarach), the sword of Manannán, in the assembly of the Tuatha Dé Danann in the "Fate of the Children of Tuireann".
Lugh's horse(s) and magic boat.
Lugh had a horse named Aenbharr which could fare over both land and sea. Like much of his equipment, it was furnished to him by the sea god Manannán mac Lir. When the Children of Tuireann asked to borrow this horse, Lugh begrudged them, saying it would not be proper to make a loan of a loan. Consequently, Lugh was unable to refuse their request to use Lugh's currach (coracle) or boat, the "Wave-Sweeper" ().
In the Lebor Gabála, Gainne and Rea were the names of the pair of horses belonging to the king of the isle of Sicily the (Tyrrhene sea), which Lug demanded as éric from the sons of Tuirill Briccreo.
Lugh's hound Failinis.
Failinis was the name of the whelp of the King of Ioruaidhe that Lugh demanded as éiric (a forfeit) in the "Oidhead Chloinne Tuireann". This concurs with the name of the hound mentioned in an "Ossianic Ballad", sometimes referred to by its opening line " (They came here as a band of three)". In the ballad the hound is called Ṡalinnis (Shalinnis) or Failinis (in the Lismore text), and belonged to a threesome from Iruaide whom the Fianna encounter. It is described as "the ancient grayhound... that had been with Lugh of the Mantles, / Given him by the sons of Tuireann Bicreann;..."
O'Curry's excerpt ends here, but the subsequent verse runs "The three full-fledged heroes are called Sél, Donait and Domhnán. The dog of the fairest figure, Failinis was brought to Finn". These threesome also appear in though in that work the wonder-dog is called Fer Mac.
Lugh's name and nature.
Lugh's name has been interpreted as deriving from the Proto-Indo-European root *"leuk-", "flashing light", and he is often surrounded by solar imagery, so from Victorian times he has often been considered a sun god, similar to the Greco-Roman Apollo though historically he is only ever equated with Mercury. He appears in folklore as a trickster, and in County Mayo thunderstorms were referred to as battles between Lugh and Balor, so he is sometimes considered a storm god: Alexei Kondratiev notes his epithet "lonnbeimnech" ("fierce striker") and concludes that "if his name has any relation to 'light' it more properly means 'lightning-flash' (as in Breton "luc'h" and Cornish "lughes")". However, Breton and Cornish are Brythonic languages in which Proto-Celtic *"k" did undergo systematic sound changes into "-gh-" and "-ch-".
Words containing Lu, as in the word Lugh itself, or lo or le, have appeared for millennia always meaning light or sun or sun god. Luwian Apaliunas, Hurrian Aplu, Etruscan Apulu, Homeric Greek: Ἀπόλλων, that is λω, Latin Apollo. The form Apaliunas (]x-ap-pa-li-u-na-aš) is attested as a god of Wilusa in a treaty between Alaksandu of Wilusa interpreted as "Alexander of Ilios", and the Hittite great king Muwatalli II ca. 1280 BC.
Luwian is closely related to Hittite, and was among the languages spoken during the second and first millennia BC by population groups in central Anatolia, Anatolia (from Greek Aνατολή Anatolē—"East"; also Asia Minor. When the Illyrians migrated to Italy and founded Luceria in Apulia, a temple to Minerva was built. Minerva is the Etruscan and Roman equivalent of Athena. The arms (armament and weapons) of Diomedes, given to him by Athena in the Trojan War, were said to be were preserved in her temple.
The Lusitanians (or Lusitani in Latin) were an Indo-European people living in the Western Iberian Peninsula. Endovelicus was the most important god. António da Visitação Freire classified the name of "Endovelicus" as a mixed Celtic and Phoenician name, adapted to the Roman language. The "end-" radical would be from Celtic languages, "bel" (or "vel-") would be Phoenician for "lord", and "-cus" is a usual word termination in Latin. The name would suggest Bal, Bel, or Vel, the god Belenus (also Belenos) was a deity worshipped in Gaul, Britain, and Celtic areas of Austria and Spain. In the Roman period Belenus was identified with Apollo. Belisama has been claimed to be the consort of Belenus and she was identified with Minerva/Athena. It would seem that the word Lugh is related to every Indo-European language word meaning light.
Lugh's mastery of all arts has led many to link him with the unnamed Gaulish god Julius Caesar identifies with Mercury, whom he describes as the "inventor of all the arts". Caesar describes the Gaulish Mercury as the most revered deity in Gaul, overseeing journeys and business transactions. Juliette Wood interprets Lugh's name as deriving from the Celtic root *"lugios", "oath", and the Irish word "lugh" connotes ideas of "blasphemy, cussing, lies, bond, joint, binding oath", which strengthens the identification with Mercury, who was, among other attributes, a god of contracts.
It is also worth noting that parallels exist between the Irish Lugh, Gaulish Lugus, German Wotan, the English Woden, and Norse Odin. Odin was worshipped by the Norse as a god of war among other things, including poetry and the arts. Odin may have replaced Tyr as god of war among north Germanic peoples. As such, it may be that Lugh was also worshipped as a god of war by the Irish. On that note it is worth noting that the ultimate Irish warrior hero Cu Chulainn is cited as the son of Lugh.

</doc>
