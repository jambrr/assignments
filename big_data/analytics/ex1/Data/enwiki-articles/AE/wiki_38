<doc id="26787" url="https://en.wikipedia.org/wiki?curid=26787" title="Science fiction">
Science fiction

Science fiction is a genre of speculative fiction dealing with imaginative concepts such as futuristic science and technology, space travel, time travel, faster than light travel, parallel universes and extraterrestrial life. Science fiction often explores the potential consequences of scientific and other innovations, and has been called a "literature of ideas." It usually eschews the supernatural, and unlike the related genre of fantasy, historically science fiction stories were intended to have at least a faint grounding in science-based fact or theory at the time the story was created, but this connection has become tenuous or non-existent in much of science fiction.
Definitions.
Science fiction is difficult to define, as it includes a wide range of subgenres and themes. Author and editor Damon Knight summed up the difficulty, saying "science fiction is what we point to when we say it", a definition echoed by author Mark C. Glassy, who argues that the definition of science fiction is like the definition of pornography: you do not know what it is, but you know it when you see it.
Hugo Gernsback, who was one of the first in using the term "science fiction", described his vision of the genre: "By 'scientifiction' I mean the Jules Verne, H. G. Wells and Edgar Allan Poe type of story—a charming romance intermingled with scientific fact and prophetic vision."
In 1970 William Atheling Jr. wrote about the English term "science fiction": "Wells used the term originally to cover what we would today call ‘hard’ science fiction, in which a conscientious attempt to be faithful to already known facts (as of the date of writing) was the substrate on which the story was to be built, and if the story was also to contain a miracle, it ought at least not to contain a whole arsenal of them."
According to science fiction writer Robert A. Heinlein, "a handy short definition of almost all science fiction might read: realistic speculation about possible future events, based solidly on adequate knowledge of the real world, past and present, and on a thorough understanding of the nature and significance of the scientific method." Rod Serling's definition is "fantasy is the impossible made probable. Science fiction is the improbable made possible." Lester del Rey wrote, "Even the devoted aficionado—or fan—has a hard time trying to explain what science fiction is", and that the reason for there not being a "full satisfactory definition" is that "there are no easily delineated limits to science fiction."
Science fiction is largely based on writing rationally about alternative possible worlds or futures. It is similar to, but differs from fantasy in that, within the context of the story, its imaginary elements are largely possible within scientifically established or scientifically postulated physical laws (though some elements in a story might still be pure imaginative speculation).
The settings of science fiction are often contrary to those of consensus reality, but most science fiction relies on a considerable degree of suspension of disbelief, which is facilitated in the reader's mind by potential scientific explanations or solutions to various fictional elements. Science fiction elements include:
History.
As a means of understanding the world through speculation and storytelling, science fiction has antecedents which go back to an era when the dividing line separating the mythological from the historical tends to become somewhat blurred, though precursors to science fiction as literature can be seen in Lucian's "True History" in the 2nd century, some of the "Arabian Nights" tales, "The Tale of the Bamboo Cutter" in the 10th century and Ibn al-Nafis's "Theologus Autodidactus" in the 13th century.
A product of the budding Age of Reason and the development of modern science itself, Margaret Cavendish's "The Blazing World" (1666) and Jonathan Swift's "Gulliver's Travels" (1726) are some of the first true science fantasy works, which both feature the adventures of the protagonist in fictional and fantastical places. together with Voltaire's "Micromégas" (1752) and Johannes Kepler's "Somnium" (1620–1630). Isaac Asimov and Carl Sagan considered the latter work the first science fiction story. It depicts a journey to the Moon and how the Earth's motion is seen from there. "The Blazing World" (1666), by English noblewoman Margaret Cavendish, has also been described as an early forerunner of science fiction. Another example is Ludvig Holberg's novel "Nicolai Klimii Iter Subterraneum" (1741).
Following the 18th-century development of the novel as a literary form, in the early 19th century, Mary Shelley's books "Frankenstein" (1818) and "The Last Man" helped define the form of the science fiction novel, and Brian Aldiss has argued that "Frankenstein" was the first work of science fiction. Later, Edgar Allan Poe wrote a story about a flight to the moon. More examples appeared throughout the 19th century.
Then with the dawn of new technologies such as electricity, the telegraph, and new forms of powered transportation, writers including H. G. Wells and Jules Verne created a body of work that became popular across broad cross-sections of society. Wells' "The War of the Worlds" (1898) describes an invasion of late Victorian England by Martians using tripod fighting machines equipped with advanced weaponry. It is a seminal depiction of an alien invasion of Earth.
In the late 19th century, the term "scientific romance" was used in Britain to describe much of this fiction. This produced additional offshoots, such as the 1884 novella "Flatland: A Romance of Many Dimensions" by Edwin Abbott Abbott. The term would continue to be used into the early 20th century for writers such as Olaf Stapledon.
In the early 20th century, pulp magazines helped develop a new generation of mainly American SF writers, influenced by Hugo Gernsback, the founder of "Amazing Stories" magazine. In 1912 Edgar Rice Burroughs published "A Princess of Mars", the first of his three-decade-long series of Barsoom novels, situated on Mars and featuring John Carter as the hero. The 1928 publication of Philip Nolan's original Buck Rogers story, "Armageddon 2419", in "Amazing Stories" was a landmark event. This story led to comic strips featuring Buck Rogers (1929), "Brick Bradford" (1933), and "Flash Gordon" (1934). The comic strips and derivative movie serials greatly popularized science fiction.
In the late 1930s, John W. Campbell became editor of "Astounding Science Fiction", and a critical mass of new writers emerged in New York City in a group called the Futurians, including Isaac Asimov, Damon Knight, Donald A. Wollheim, Frederik Pohl, James Blish, Judith Merril, and others. Other important writers during this period include E.E. (Doc) Smith, Robert A. Heinlein, Arthur C. Clarke, Olaf Stapledon, and A. E. van Vogt. Working outside the Campbell influence were Ray Bradbury and Stanisław Lem. Campbell's tenure at "Astounding" is considered to be the beginning of the Golden Age of science fiction, characterized by hard SF stories celebrating scientific achievement and progress. This lasted until post-war technological advances, new magazines such as "Galaxy", edited by H. L. Gold, and a new generation of writers began writing stories with less emphasis on the hard sciences and more on the social sciences.
In the 1950s, the Beat generation included speculative writers such as William S. Burroughs. In the 1960s and early 1970s, writers like Frank Herbert, Samuel R. Delany, Roger Zelazny, and Harlan Ellison explored new trends, ideas, and writing styles, while a group of writers, mainly in Britain, became known as the New Wave for their embrace of a high degree of experimentation, both in form and in content, and a highbrow and self-consciously "literary" or artistic sensibility. In the 1970s, writers like Larry Niven brought new life to hard science fiction. Ursula K. Le Guin and others pioneered soft science fiction.
In the 1980s, cyberpunk authors like William Gibson turned away from the optimism and support for progress of traditional science fiction. This dystopian vision of the near future is described in the work of Philip K. Dick, such as "Do Androids Dream of Electric Sheep?" and "We Can Remember It for You Wholesale", which resulted in the films "Blade Runner" and "Total Recall". The "Star Wars" franchise helped spark a new interest in space opera, focusing more on story and character than on scientific accuracy. C. J. Cherryh's detailed explorations of alien life and complex scientific challenges influenced a generation of writers.
Emerging themes in the 1990s included environmental issues, the implications of the global Internet and the expanding information universe, questions about biotechnology and nanotechnology, as well as a post-Cold War interest in post-scarcity societies; Neal Stephenson's "The Diamond Age" comprehensively explores these themes. Lois McMaster Bujold's "Vorkosigan" novels brought the character-driven story back into prominence. The television series ' (1987) began a torrent of new SF shows, including three further "Star Trek" spin-off shows (, , and ) and "Babylon 5". "Stargate", a movie about an ancient portal to other gates across the galaxy, was released in 1994. "Stargate SG-1", a TV series, premiered on July 27, 1997 and lasted 10 seasons with 214 episodes. Spin-offs include the animated television series "Stargate Infinity", the TV series "Stargate Atlantis" and "Stargate Universe", and the direct-to-DVD films ' and "". "Stargate SG-1" surpassed "The X-Files" as the longest-running North American science fiction television series, a record later broken by "Smallville".
Concern about the rapid pace of technological change crystallized around the concept of the technological singularity, popularized by Vernor Vinge's novel "Marooned in Realtime" and then taken up by other authors.
The term "sci-fi".
Forrest J Ackerman is credited with first using the term sci-fi (analogous to the then-trendy "hi-fi") in 1954. As science fiction entered popular culture, writers and fans active in the field came to associate the term with low-budget, low-tech "B-movies" and with low-quality pulp science fiction. By the 1970s, critics within the field such as Terry Carr and Damon Knight were using "sci-fi" to distinguish hack-work from serious science fiction.
Around 1978 critic Susan Wood and others introduced the use of the odd pronunciation "skiffy" which is intended to be self-deprecating humor but is inconsistent with the documented genesis of the term "sci-fi" (i.e., one would not pronounce "hi-fi" as "hiffy") and Ackerman's own words engraved on his crypt plaque which read "Sci-Fi was My High".
Peter Nicholls writes that "SF" (or "sf") is "the preferred abbreviation within the community of sf writers and readers." David Langford's monthly fanzine "Ansible" includes a regular section "As Others See Us" which offers numerous examples of "sci-fi" being used in a pejorative sense by people outside the genre.
Innovation.
Science fiction has criticized developing and future technologies, but also initiates innovation and new technology. This topic has been more often discussed in literary and sociological than in scientific forums. Cinema and media theorist Vivian Sobchack examines the dialogue between science fiction films and the technological imagination. Technology impacts artists and how they portray their fictionalized subjects, but the fictional world gives back to science by broadening imagination. "How William Shatner Changed the World" is a documentary that gave a number of real-world examples of actualized technological imaginations. While more prevalent in the early years of science fiction with writers like Arthur C. Clarke, new authors still find ways to make currently impossible technologies seem closer to being realized.
Categories.
Hard science fiction.
Hard science fiction, or "hard SF", is characterized by rigorous attention to accurate detail in the natural sciences, especially physics, astrophysics, and chemistry, or on accurately depicting worlds that more advanced technology may make possible. Some accurate predictions of the future come from the hard science fiction subgenre, but numerous inaccurate predictions have emerged as well. Some hard SF authors have distinguished themselves as working scientists, including Gregory Benford, Geoffrey A. Landis, David Brin, and Robert L. Forward, while mathematician authors include Rudy Rucker and Vernor Vinge. Other noteworthy hard SF authors include Isaac Asimov, Arthur C. Clarke, Hal Clement, Greg Bear, Larry Niven, Robert J. Sawyer, Stephen Baxter, Alastair Reynolds, Charles Sheffield, Ben Bova, Kim Stanley Robinson, Anne McCaffery and Greg Egan.
Soft science fiction.
The description "soft" science fiction may describe works based on social sciences such as psychology, economics, political science, sociology, and anthropology. The term is sometimes used to describe improbable plots, absurd "science", and cardboard characters. Noteworthy writers in this category include Ursula K. Le Guin, Frank Herbert and Philip K. Dick. The term can describe stories focused primarily on character and emotion; SFWA Grand Master Ray Bradbury was an acknowledged master of this art. The Eastern Bloc produced a large quantity of social science fiction, including works by Polish authors Stanislaw Lem and Janusz Zajdel, as well as Soviet authors such as the Strugatsky brothers, Kir Bulychov, Yevgeny Zamyatin and Ivan Yefremov. Some writers blur the boundary between hard and soft science fiction.
Related to social SF and soft SF are utopian and dystopian stories; George Orwell's "Nineteen Eighty-Four", Aldous Huxley's "Brave New World", and Margaret Atwood's "The Handmaid's Tale" and "Oryx and Crake" are examples. Satirical novels with fantastic settings such as "Gulliver's Travels" by Jonathan Swift may also be considered science fiction or speculative fiction.
Subgenres.
Cyberpunk.
The cyberpunk genre emerged in the early 1980s; combining cybernetics and punk,
the term was coined by author Bruce Bethke for his 1980 short story "Cyberpunk".
The time frame is usually near-future and the settings are often dystopian in nature and characterized by misery. Common themes in cyberpunk include advances in information technology and especially the Internet, visually abstracted as cyberspace, artificial intelligence, and cybernetics and post-democratic societal control where corporations have more influence than governments. Nihilism, post-modernism, and film noir techniques are common elements, and the protagonists may be disaffected or reluctant anti-heroes. Noteworthy authors in this genre are William Gibson, Bruce Sterling, Neal Stephenson, and Pat Cadigan. James O'Ehley has called the 1982 film "Blade Runner" a definitive example of the "cyberpunk" visual style.
Time travel.
Time-travel stories have antecedents in the 18th and 19th centuries. The first major time-travel novel was Mark Twain's "A Connecticut Yankee in King Arthur's Court". The most famous is H. G. Wells' 1895 novel "The Time Machine", which uses a vehicle that allows an operator to travel purposefully and selectively, while Twain's time traveler is struck in the head. The term "time machine", coined by Wells, is now universally used to refer to such a vehicle. "Back to the Future" is one of the most popular movie franchises in this category. Also "Doctor Who" goes in this category. Stories of this type are complicated by logical problems such as the grandfather paradox. Time travel continues to be a popular subject in modern science fiction, in print, movies, and television.
Alternate history.
Alternative history stories are based on the premise that historical events might have turned out differently. These stories may use time travel to change the past, or may simply set a story in a universe with a different history from our own. Classics in the genre include "Bring the Jubilee" by Ward Moore, in which the South wins the American Civil War, and "The Man in the High Castle" by Philip K. Dick, in which Germany and Japan win World War II. The Sidewise Award acknowledges the best works in this subgenre; the name is taken from Murray Leinster's 1934 story "Sidewise in Time". Harry Turtledove is one of the most prominent authors in the subgenre and is sometimes called the "master of alternate history."
Military science fiction.
Military science fiction is set in the context of conflict between national, interplanetary, or interstellar armed forces; the primary viewpoint characters are usually soldiers. Stories include detail about military technology, procedure, ritual, and history; military stories may use parallels with historical conflicts. Heinlein's "Starship Troopers" is an early example, along with the Dorsai novels of Gordon Dickson. Joe Haldeman's "The Forever War" is a critique of the genre, a Vietnam-era response to the World War II–style stories of earlier authors. Prominent military SF authors include John Scalzi, John Ringo, David Drake, David Weber, Tom Kratman, Michael Z. Williamson, S. M. Stirling, and John Carr. The publishing company Baen Books is known for cultivating several of these military science fiction authors.
Superhuman.
Superhuman stories deal with the emergence of humans who have abilities beyond the norm. This can stem either from natural causes such as in Olaf Stapledon's novel "Odd John", Theodore Sturgeon's "More Than Human", and Philip Wylie's "Gladiator", or be the result of scientific advances, such as the intentional augmentation in A. E. van Vogt's novel "Slan". These stories usually focus on the alienation that these beings feel as well as society's reaction to them. These stories have played a role in the real life discussion of human enhancement. Frederik Pohl's "Man Plus" also belongs to this category.
Apocalyptic and post-apocalyptic.
Apocalyptic fiction is concerned with the end of civilization through war ("On the Beach"), pandemic ("The Last Man"), astronomic impact ("When Worlds Collide"), ecological disaster ("The Wind from Nowhere"), or some other general disaster or with a world or civilization after such a disaster. Typical of the genre are George R. Stewart's novel "Earth Abides" and Pat Frank's novel "Alas, Babylon". Apocalyptic fiction generally concerns the disaster itself and the direct aftermath, while post-apocalyptic fiction can deal with anything from the near aftermath (as in Cormac McCarthy's "The Road") to 375 years in the future (as in "By The Waters of Babylon") to hundreds or thousands of years in the future, as in Russell Hoban's novel "Riddley Walker" and Walter M. Miller, Jr.'s "A Canticle for Leibowitz". Apocalyptic science-fiction is a popular genre in video games. The critically acclaimed role-playing action adventure video game series, "Fallout", is set on a post-apocalyptic Earth, where civilization is recovering from a nuclear war as survivors struggle to survive and seek to rebuild society.
Space opera.
Space opera is adventure science fiction set mainly or entirely in outer space or on multiple (sometimes distant) planets. The conflict is heroic, and typically on a large scale. It is also used nostalgically, and modern space opera may be an attempt to recapture the sense of wonder of the golden age of science fiction. The pioneer of this subgenre is generally recognized to be Edward E. (Doc) Smith, with his "Skylark" and "Lensman" series. George Lucas's "Star Wars" series is among the most popular and famous franchises in cinematic space opera. It covers epic battles between good and evil throughout an entire galaxy. Alastair Reynolds's "Revelation Space" series, Peter F. Hamilton's "Void", "Night's Dawn", "Pandora's Star" series, Stephen Hunt's "Sliding Void" series, Vernor Vinge's "A Fire Upon the Deep", "A Deepness in the Sky" are newer examples of this genre. A prime example of the space opera genre seen in video games is the "Mass Effect" series.
Space Western.
The space Western transposes themes of American Western books and films to a backdrop of futuristic space frontiers. These stories typically involve colony worlds that have only recently been terraformed and/or settled serving as stand-ins for the backdrop of lawlessness and economic expansion that were predominant in the American west. Examples include the Sean Connery film "Outland", Heinlein's "Farmer in the Sky", Sparks Nevada: Marshall on Mars from the Thrilling Adventure Hour, the "Firefly" television series, and the film sequel "Serenity" by Joss Whedon, as well as the manga and anime series "Cowboy Bebop", "Outlaw Star", and "Trigun".
Social science fiction.
Social science fiction focuses on themes of society and human nature in a science fiction setting. Since it usually focuses more on speculation about humanity and less on scientific accuracy, it's usually placed within soft science fiction.
Climate fiction.
Climate fiction is a genre based around themes of reaction to major climate change. It is sometimes called "cli-fi", much as "science fiction" is often shortened to "sci-fi". Cli-fi novels and films are often set in either the present or the near or distant future, but they can also be set in the past. Many cli-fi works raise awareness about the major threats that global warming and climate change present to life on Earth.
Maritime science fiction.
Maritime science fiction is a subgenre of science fiction that takes place in the ocean or the sea and commonly has sea monsters and/or maritime technology.
There are various science fiction works, such as "Star Trek", which do not take place at sea but in a comparable setting, such as space; where the threat and theme of the dangers of the unknown (e.g.: Sea/space Monsters) is still present.
Biopunk.
"Biopunk" focuses on biotechnology and subversives. The main underlying theme within these stories is the attempt to change the human body and engineer humans for specific purposes through enhancements in genetic and molecular makeups. Many examples of this subgenre include subjects such as human experimentation, the misuse of biotechnology and synthetic biotechnology. This subgenre also includes works involving human cloning and how clones might exists within human society in the future.
Related genres.
Other speculative fiction, fantasy, and horror.
The broader category of speculative fiction includes science fiction, fantasy, alternate histories (which may have no particular scientific or futuristic component), and even literary stories that contain fantastic elements, such as the work of Jorge Luis Borges or John Barth. For some editors, magic realism is considered to be within the broad definition of speculative fiction.
Fantasy.
Fantasy is commonly associated with science fiction, and a number of writers have worked in both genres, while writers such as Anne McCaffrey, Ursula K. Le Guin, and Marion Zimmer Bradley have written works that appear to blur the boundary between the two related genres. The authors' professional organization is called the Science Fiction and Fantasy Writers of America (SFWA). SF conventions routinely have programming on fantasy topics, and fantasy authors such as J. K. Rowling have won the highest honor within the science fiction field, the Hugo Award.
In general, science fiction differs from fantasy in that the former concerns things that might someday be possible or that at least embody the pretense of realism. Supernaturalism, usually absent in science fiction, is the distinctive characteristic of fantasy literature. A dictionary definition referring to fantasy literature is "fiction characterized by highly fanciful or supernatural elements." Examples of fantasy supernaturalism include magic (spells, harm to opponents), magical places (Narnia, Oz, Middle Earth, Hogwarts), supernatural creatures (witches, vampires, orcs, trolls), supernatural transportation (flying broomsticks, ruby slippers, windows between worlds), and shapeshifting (beast into man, man into wolf or bear, lion into sheep). Such things are basic themes in fantasy.
Literary critic Fredric Jameson has characterized the difference between the two genres by describing science fiction as turning "on a formal framework determined by concepts of the mode of production rather than those of religion" – that is, science fiction texts are bound by an inner logic based more on historical materialism than on magic or the forces of good and evil. Some narratives are described as being essentially science fiction but "with fantasy elements." The term "science fantasy" is sometimes used to describe such material.
Science fantasy.
"Science fantasy" is a genre where elements of science fiction and fantasy co-exist or combine. Stories and franchises that display fictional science as well as supernatural elements, sorcery or/and "magical technology" are considered science fantasy.
Horror fiction.
Horror fiction is the literature of the unnatural and supernatural, with the aim of unsettling or frightening the reader, sometimes with graphic violence. Historically it has also been known as weird fiction. Although horror is not "per se" a branch of science fiction, some works of horror literature incorporates science fictional elements. One of the defining classical works of horror, Mary Shelley's novel "Frankenstein", is the first fully realized work of science fiction, where the manufacture of the monster is given a rigorous science-fictional grounding. The works of Edgar Allan Poe also helped define both the science fiction and the horror genres. Today horror is one of the most popular categories of films. Horror is often mistakenly categorized as science fiction at the point of distribution by libraries, video rental outlets, etc.
Supernatural fiction.
Supernatural fiction is a genre that features supernatural and other paranormal phenomenon in stories and settings.
Spy-fi.
A mixed genre that combines elements of science fiction with spy fiction.
Mystery fiction.
Works in which science and technology are a dominant theme, but based on current reality, may be considered mainstream fiction. Much of the thriller genre would be included, such as the novels of Tom Clancy or Michael Crichton, or the James Bond films. Modernist works from writers like Kurt Vonnegut, Philip K. Dick, and Stanisław Lem have focused on speculative or existential perspectives on contemporary reality and are on the borderline between SF and the mainstream. According to Robert J. Sawyer, "Science fiction and mystery have a great deal in common. Both prize the intellectual process of puzzle solving, and both require stories to be plausible and hinge on the way things really do work." Isaac Asimov, Walter Mosley, and other writers incorporate mystery elements in their science fiction, and vice versa.
Distinct from the above, a full-fledged Science Fiction Mystery is one which is set in a completely different world from ours, in which the circumstances and motives of the crime committed and the identity of the detective(s) seeking to solve it are of an essentially science fictional character. A prime example is Isaac Asimov's "The Caves of Steel" and its sequels, set in a world thousands of years in the future and presenting the Robot detective R. Daneel Olivaw. An allied genre is the Fantasy Mystery, a detective mystery set in a world of fantasy - such as the Lord Darcy mysteries taking place in a world where magic works, or "The Idylls of the Queen" set in the mythical King Arthur's court.
Superhero fiction.
Superhero fiction is a genre characterized by beings with much higher than usual capability and prowess, generally with a desire or need to help the citizens of their chosen country or world by using their powers to defeat natural or superpowered threats. A number of superhero fiction characters involve themselves (either intentionally or accidentally) with science fiction and fact, including advanced technologies, alien worlds, time travel, and interdimensional travel; but the standards of scientific plausibility are lower than with actual science fiction. Authors of this genre include Stan Lee (co-creator of "Spider-Man", the "Fantastic Four", the "Iron Man", the "X-Men", and the "Hulk"); Marv Wolfman, the creator of "Blade" for Marvel Comics, and "The New Teen Titans" for DC Comics; Dean Wesley Smith ("Smallville", "Spider-Man", and "X-Men" novels) and "Superman" writers Roger Stern and Elliot S! Maggin.
Fandom and community.
Science fiction fandom is the "community of the literature of ideas... the culture in which new ideas emerge and grow before being released into society at large." Members of this community, "fans", are in contact with each other at conventions or clubs, through print or online fanzines, or on the Internet using web sites, mailing lists, and other resources.
SF fandom emerged from the letters column in "Amazing Stories" magazine. Soon fans began writing letters to each other, and then grouping their comments together in informal publications that became known as fanzines. Once they were in regular contact, fans wanted to meet each other, and they organized local clubs. In the 1930s, the first science fiction conventions gathered fans from a wider area. Conventions, clubs, and fanzines were the dominant form of fan activity, or "fanac", for decades, until the Internet facilitated communication among a much larger population of interested people.
Authors.
Science fiction is being written worldwide by a diverse population of authors. According to 2013 statistics by the science fiction publisher Tor Books, men outnumber women by 78% to 22% among submissions to the publisher. A controversy about voting slates in the 2015 Hugo Awards highlighted tensions in the science fiction community between a trend of increasingly diverse works and authors being honored by awards, and a backlash by groups of authors and fans who preferred what they considered more traditional science fiction.
Awards.
Among the most respected awards for science fiction are the Hugo Award, presented by the World Science Fiction Society at Worldcon; the Nebula Award, presented by SFWA and voted on by the community of authors; and the John W. Campbell Memorial Award for Best Science Fiction Novel and Theodore Sturgeon Memorial Award for short fiction. One notable award for science fiction films is the Saturn Award. It is presented annually by The Academy of Science Fiction, Fantasy, and Horror Films.
There are national awards, like Canada's Prix Aurora Awards, regional awards, like the Endeavour Award presented at Orycon for works from the Pacific Northwest, special interest or subgenre awards like the Chesley Award for art or the World Fantasy Award for fantasy. Magazines may organize reader polls, notably the Locus Award.
Conventions, clubs, and organizations.
Conventions (in fandom, shortened as "cons"), are held in cities around the world, catering to a local, regional, national, or international membership. General-interest conventions cover all aspects of science fiction, while others focus on a particular interest like media fandom, filking, etc. Most are organized by volunteers in non-profit groups, though most media-oriented events are organized by commercial promoters. The convention's activities are called the "program", which may include panel discussions, readings, autograph sessions, costume masquerades, and other events. Activities that occur throughout the convention are not part of the program; these commonly include a dealer's room, art show, and hospitality lounge (or "con suites").
Conventions may host award ceremonies; Worldcons present the Hugo Awards each year. SF societies, referred to as "clubs" except in formal contexts, form a year-round base of activities for science fiction fans. They may be associated with an ongoing science fiction convention, or have regular club meetings, or both. Most groups meet in libraries, schools and universities, community centers, pubs or restaurants, or the homes of individual members. Long-established groups like the New England Science Fiction Association and the Los Angeles Science Fantasy Society have clubhouses for meetings and storage of convention supplies and research materials. The Science Fiction and Fantasy Writers of America (SFWA) was founded by Damon Knight in 1965 as a non-profit organization to serve the community of professional science fiction authors, 24 years after his essay "Unite or Fie!" had led to the organization of the National Fantasy Fan Federation. Fandom has helped incubate related groups, including media fandom, the Society for Creative Anachronism, gaming, filking, and furry fandom.
Fanzines and online fandom.
The first science fiction fanzine, "The Comet", was published in 1930. Fanzine printing methods have changed over the decades, from the hectograph, the mimeograph, and the ditto machine, to modern photocopying. Distribution volumes rarely justify the cost of commercial printing. Modern fanzines are printed on computer printers or at local copy shops, or they may only be sent as email. The best known fanzine (or "'zine") today is "Ansible", edited by David Langford, winner of numerous Hugo awards. Other fanzines to win awards in recent years include "File 770", "Mimosa", and "Plokta". Artists working for fanzines have risen to prominence in the field, including Brad W. Foster, Teddy Harvia, and Joe Mayhew; the Hugos include a category for Best Fan Artists. The earliest organized fandom online was the SF Lovers community, originally a mailing list in the late 1970s with a text archive file that was updated regularly. In the 1980s, Usenet groups greatly expanded the circle of fans online. In the 1990s, the development of the World-Wide Web exploded the community of online fandom by orders of magnitude, with thousands and then literally millions of web sites devoted to science fiction and related genres for all media. Most such sites are small, ephemeral, and/or very narrowly focused, though sites like SF Site and SFcrowsnest offer a broad range of references and reviews about science fiction.
Fan fiction.
Fan fiction, known to aficionados as "fanfic", is non-commercial fiction created by fans in the setting of an established book, film, video game, or television series. This modern meaning of the term should not be confused with the traditional (pre-1970s) meaning of "fan fiction" within the community of fandom, where the term meant original or parody fiction written by fans and published in fanzines, often with members of fandom as characters therein. Examples of this would include the Goon Defective Agency stories, written starting in 1956 by Irish fan John Berry and published in his and Arthur Thomson's fanzine "Retribution". In the last few years, sites have appeared such as Orion's Arm and Galaxiki, which encourage collaborative development of science fiction universes. In some cases, the copyright owners of the books, films, or television series have instructed their lawyers to issue "cease and desist" letters to fans.
Science fiction studies.
The study of science fiction, or science fiction studies, is the critical assessment, interpretation, and discussion of science fiction literature, film, new media, fandom, and fan fiction. Science fiction scholars take science fiction as an object of study in order to better understand it and its relationship to science, technology, politics, and culture-at-large. Science fiction studies has a long history dating back to the turn of the 20th century, but it was not until later that science fiction studies solidified as a discipline with the publication of the academic journals Extrapolation (1959), Foundation - The International Review of Science Fiction (1972), and Science Fiction Studies (1973), and the establishment of the oldest organizations devoted to the study of science fiction, the Science Fiction Research Association and the Science Fiction Foundation, in 1970. The field has grown considerably since the 1970s with the establishment of more journals, organizations, and conferences with ties to the science fiction scholarship community, and science fiction degree-granting programs such as those offered by the University of Liverpool and Kansas University.
The National Science Foundation has conducted surveys of "Public Attitudes and Public Understanding" of "Science Fiction and Pseudoscience." They write that "Interest in science fiction may affect the way people think about or relate to science...one study found a strong relationship between preference for science fiction novels and support for the space program...The same study also found that students who read science fiction are much more likely than other students to believe that contacting extraterrestrial civilizations is both possible and desirable (Bainbridge 1982).
As serious literature.
Mary Shelley wrote a number of science fiction novels including "Frankenstein", and is treated as a major Romantic writer. A number of science fiction works have received critical acclaim including "Childhood's End" and "Do Androids Dream of Electric Sheep?" (the inspiration for the movie "Blade Runner"). A number of respected writers of mainstream literature have written science fiction, including Aldous Huxley's "Brave New World", George Orwell's "Nineteen Eighty-Four", Anthony Burgess' "A Clockwork Orange" and Margaret Atwood's "The Handmaid's Tale". Nobel Laureate Doris Lessing wrote a series of SF novels, "Canopus in Argos", and nearly all of Kurt Vonnegut's works contain science fiction premises or themes.
The scholar Tom Shippey asks a perennial question of science fiction: "What is its relationship to fantasy fiction, is its readership still dominated by male adolescents, is it a taste which will appeal to the mature but non-eccentric literary mind?" In her much reprinted essay "Science Fiction and Mrs Brown," the science fiction writer Ursula K. Le Guin has approached an answer by first citing the essay written by the English author Virginia Woolf entitled "Mr Bennett and Mrs Brown" in which she states:
Le Guin argues that these criteria may be successfully applied to works of science fiction and so answers in the affirmative her rhetorical question posed at the beginning of her essay: "Can a science fiction writer write a novel?"
Tom Shippey in his essay does not dispute this answer but identifies and discusses the essential differences that exists between a science fiction novel and one written outside the field. To this end, he compares George Orwell's "Coming Up for Air" with Frederik Pohl and C. M. Kornbluth's "The Space Merchants" and concludes that the basic building block and distinguishing feature of a science fiction novel is the presence of the "novum", a term Darko Suvin adapts from Ernst Bloch and defines as "a discrete piece of information recognizable as not-true, but also as not-unlike-true, not-flatly- (and in the current state of knowledge) impossible."
In science fiction the style of writing is often relatively clear and straightforward compared to classical literature. Orson Scott Card, an author of both science fiction and non-SF fiction, has postulated that in science fiction the message and intellectual significance of the work is contained within the story itself and, therefore, there need not be stylistic gimmicks or literary games; but that some writers and critics confuse clarity of language with lack of artistic merit. In Card's words:
Science fiction author and physicist Gregory Benford has declared that: "SF is perhaps the defining genre of the twentieth century, although its conquering armies are still camped outside the Rome of the literary citadels." This sense of exclusion was articulated by Jonathan Lethem in an essay published in the "Village Voice" entitled "Close Encounters: The Squandered Promise of Science Fiction." Lethem suggests that the point in 1973 when Thomas Pynchon's "Gravity's Rainbow" was nominated for the Nebula Award, and was passed over in favor of Arthur C. Clarke's "Rendezvous with Rama", stands as "a hidden tombstone marking the death of the hope that SF was about to merge with the mainstream." Among the responses to Lethem was one from the editor of the "Magazine of Fantasy and Science Fiction" who asked: "When is it SF genre ever going to realize it can't win the game of trying to impress the mainstream?" On this point the journalist and author David Barnett has remarked:
Barnett, in an earlier essay had pointed to a new development in this "endless war":
World-wide examples.
Although perhaps most developed as a genre and community in the United States, Canada, and the United Kingdom, science fiction is a worldwide phenomenon. Organisations devoted to promotion and even translation in particular countries are commonplace, as are country- or language-specific genre awards.
Africa.
Mohammed Dib, an Algerian writer, wrote a science fiction allegory about his nation's politics, "Qui se souvient de la mer" ("Who Remembers the Sea?") in 1962.
Masimba Musodza, a Zimbabwean author, published "MunaHacha Maive Nei?" the first science-fiction novel in the Shona language, which also holds the distinction of being the first novel in the Shona language to appear as an ebook first before it came out in print. In South Africa, a movie titled "District 9" came out in 2009, an apartheid allegory featuring extraterrestrial life forms, produced by Peter Jackson.
Science fiction examines society through shifting power structures (such as the shift of power from humanity to alien overlords). African science fiction often uses this genre norm to situate slavery and the slave trade as an alien abduction. Commonalities in experiences with unknown languages, customs, and culture lend themselves well to this comparison. The subgenre also commonly employs the mechanism of time travel to examine the effects of slavery and forced emigration on the individual and the family.
Asia.
Indian science fiction, defined loosely as science fiction by writers of Indian descent, began with the English-language publication of Kylas Chundar Dutt's "A Journal of Forty-Eight Hours of the Year 1945" in the "Calcutta Literary Gazette" (June 6, 1835). Since this story was intended as a political polemic, credit for the first science fiction story is often given to later Bengali authors such as Jagadananda Roy, Hemlal Dutta and the polymath Jagadish Chandra Bose. Eminent film maker and writer Satyajit Ray also enriched Bengali science fiction by writing many short stories as well as science fiction series, Professor Shonku (see Bengali science fiction). Similar traditions exist in Hindi, Marathi, Tamil and English. In English, the modern era of Indian speculative fiction began with the works of authors such as Samit Basu, Payal Dhar, Vandana Singh and Anil Menon. Works such as Amitav Ghosh's "The Calcutta Chromosome", Salman Rushdie's "Grimus", and Boman Desai's "The Memory of Elephants" are generally classified as magic realist works but make essential use of SF tropes and techniques. In recent years authors in some other Indian languages have begun telling stories in this genre; for example in Punjabi IP Singh and Roop Dhillon have written stories that can clearly be defined as Punjabi science fiction. The latter has coined the term Vachitarvaad to describe such literature.
Bangladesh has a strong Science fiction literature in South Asia. After Qazi Abdul Halim's "Mohasunner Kanna" ("Tears of the Cosmos") (1970), Humayun Ahmed wrote the first modern Bengali SF novel, "Tomader Jonno Valobasa" ("Love For You All"). It was published in 1973. This book is treated as the first full-fledged Bangladeshi science fiction novel. Then he wrote "Tara Tinjon" ("They were Three"), "Irina", "Anonto Nakshatra Bithi" ("Endless Galaxy"), "Fiha Somikoron" ("Fiha Equation") etc.
But Bengali science fiction leaves its cocoon phase holding the hands of Muhammed Zafar Iqbal. Mr. Iqbal wrote a story named "Copotronic Sukh Dukho" when he was a student of Dhaka University. This story was later included in a compilation of Iqbal's work in a book by the same name. Muktodhara, a famous publishing house of Dhaka was the publisher of this book. This collection of science fiction stories gained huge popularity and the new trend of science fiction emerged among Bengali writers and readers. After his first collection, Mr. Iqbal transformed his own science fiction cartoon strip "Mohakashe Mohatrash" ("Terror in the Cosmos") into a novel. All told, Muhammed Zafar Iqbal has written the greatest number of science fiction works in Bengali science fiction.
Following the footsteps of the ancestors, more and more writers, especially young writers started writing science fiction and a new era started in Bengali literature.
Modern science fiction in China mainly depends on the magazine "Science Fiction World". A number of works were originally published in it in installments, including the highly successful novel "The Three-Body Problem", written by Liu Cixin.
Until recently, there has been little domestic science fiction literature in Korea. Within the small field, the author and critic writing under the nom de plume Djuna has been credited with being the major force. Kim Boyoung, Bae Myunghoon and Kwak Jaesik are also often mentioned as the new generation of Korean science fiction writers of 2010s. The upswing that began in 2009 has been attributed by Shin Junebong to a combination of factors. Shin quotes Djuna as saying, "'It looks like the various literary awards established by one newspaper after another, with hefty sums of prize money, had a big impact.'" Another factor cited was the active use of Web bulletin boards among the then-young writers brought up on translations of Western SF. In spite of the increase, there were still no more than sixty or so authors writing in the field at that time.
"Chalomot Be'aspamia" is an Israeli magazine of short science fiction and fantasy stories. "The Prophecies Of Karma", published in 2011, is advertised as the first work of science fiction by an Arabic author, the Lebanese writer Nael Gharzeddine.
Europe.
France and Belgium.
Jules Verne, a 19th-century French novelist known for his pioneering science fiction works ("Twenty Thousand Leagues Under the Sea", "Journey to the Center of the Earth", "From the Earth to the Moon") is the prime representative of the French legacy of science fiction. French science fiction of the 19th century was also represented with such artists as Albert Robida and Isidore Grandville. In the 20th century, traditions of French science fiction were carried on by writers like Pierre Boulle (best known for his "Planet of the Apes"), Serge Brussolo, Bernard Werber, René Barjavel and Robert Merle, among others.
In Franco-Belgian comics, "bande dessinée" ("BD") science-fiction is a well established genre. Notable French science fiction comics include "Valerian et Laureline" by Pierre Christin and Jean-Claude Mézières, a space opera franchise that has lasted since 1967. "Metal Hurlant" magazine (known in US as "Heavy Metal") was one of the largest contributors to francophone science-fiction comics. Its major authors include Jean "Moebius" Giraud, creator of "Arzach"; Chilean Alejandro Jodorowsky, who created a series of comics, including "L'Incal" and "Les Metabarons", set in Jodoverse; and Enki Bilal with "The Nikopol Trilogy". Giraud also contributed to French SF animation, collaborating with René Laloux on several animated features. A number of artists from neighboring countries, such as Spain and Italy, create science fiction and fantasy comics in French aimed at a Franco-Belgian market.
In French cinema, science fiction began with silent film director and visual effects pioneer George Méliès, whose most famous film was "Voyage to the Moon", loosely based on books by Verne and Wells. In the 20th and 21st centuries, French science fiction films were represented by René Laloux's animated features, as well as Enki Bilal's adaptation of the Nikopol Trilogy, "Immortal". Luc Besson filmed "The Fifth Element" as a joint Franco-American production.
In the French-speaking world, the colloquial use of the term "sci-fi" is an accepted Anglicism for the term "science fiction". This probably stems from the fact that science fiction writing never expanded there to the extent it did in the English-speaking world, particularly with the dominance of the United States. Nevertheless, France has made a tremendous contribution to science fiction in its seminal stages of development. Although the term "science fiction" is understood in France, their penchant for the "weird and wacky" has a long tradition and is sometimes called "le culte du merveilleux." This uniquely French tradition certainly encompasses what the anglophone world would call French science fiction but also ranges across fairies, Dadaism, and surrealism.
Italy.
Italy has a vivid history in science fiction, though almost unknown outside her borders. 
The history of Italian science fiction recognizes a varied roadmap of this genre which spread to a popular level after World War Two, and in particular in the second half of the 1950s, on the wave of American and British literature.
The earliest pioneers may be found in the literature of the fantastic voyage and of the Renaissance Utopia, even in previous masterpieces such as "The Million" of Marco Polo. 
In the second half of the 19th century stories and short novels of "scientific fantasies" (also known as "incredible stories" or "fantastic" or "adventuristic", "novels of the future times" or "utopic", "of the tomorrow") appeared in Sunday newspaper supplements, in literary magazines, and as booklets published in installments. Added to these, at the beginning of the 20th century, were the most futuristic masterpieces of the great Emilio Salgari, considered by most the father of Italian science fiction, and Yambo and Luigi Motta, the most renowned authors of popular novels of the time, with extraordinary adventures in remote and exotic places, and even works of authors representing known figures of the "top" literature, among them Massimo Bontempelli, Luigi Capuana, Guido Gozzano, Ercole Luigi Morselli.
The true birth of Italian science fiction is placed in 1952, with the publishing of the first specialized magazines, "Scienza Fantastica" (Fantastic Science) and "Urania," and with the appearance of the term ""fantascienza"" which has become the usual translation of the English term "science fiction." The "Golden Years" span the period 1957-1960.
From the end of the 1950s science fiction became in Italy one of the most popular genres, although its popular success was not followed by critical success. In spite of an active and organized fandom there hasn't been an authentic sustained interest on the part of the Italian cultural élite towards science fiction.
Popular Italian science fiction writers include Gianluigi Zuddas, Giampietro Stocco, Lino Aldani, as well as comic artists, such as Milo Manara. Valerio Evangelisti is the best known modern author of Italian science fiction and fantasy.
Also, popular Italian children's writer Gianni Rodari often turned to science fiction aimed at children, most notably, in "Gip in the Television".
Germany.
The main German science fiction writer in the 19th century was Kurd Laßwitz. According to Austrian SF critic Franz Rottensteiner, though significant German novels of a science-fiction nature were published in the first half of the 20th century, SF did not exist as a genre in the country until after World War II and the heavy importing and translation of American works. In the 20th century, during the years of divided Germany, both East and West spawned a number of successful writers. Top East German writers included Angela and Karlheinz Steinmüller, as well as Günther Krupkat. West German authors included Carl Amery, Gudrun Pausewang, Wolfgang Jeschke and Frank Schätzing, among others. A well known science fiction book series in the German language is "Perry Rhodan", which started in 1961. Having sold over one billion copies (in pulp format), it claims to be the most successful science fiction book series ever written, worldwide. Current well-known SF authors from Germany are five-time "Kurd-Laßwitz-Award" winner Andreas Eschbach, whose books "The Carpet Makers" and "Eine Billion Dollar" are big successes, and Frank Schätzing, who in his book "The Swarm" mixes elements of the science thriller with SF elements to an apocalyptic scenario. The most prominent German-speaking author, according to "Die Zeit", is Austrian Herbert W. Franke.
In the 1920s Germany produced a number of critically acclaimed high-budget science fiction and horror films. "Metropolis" by director Fritz Lang is credited as one of the most influential science fiction films ever made. Other films of the era included "Woman in the Moon", "Alraune", "Algol", "Gold", "Master of the World", among others. In the second half of the 20th century, East Germany also became a major science fiction film producer, often in a collaboration with fellow Eastern Bloc countries. Films of this era include "Eolomea", "First Spaceship on Venus" and "Hard to Be a God".
Russia and ex-Soviet countries.
Russians made their first steps to science fiction in the mid-19th century, with utopias by Faddei Bulgarin and Vladimir Odoevsky.
However, it was the Soviet era that became the genre's golden age. Soviet writers were prolific,
despite limitations set up by state censorship. Early Soviet writers, such as Alexander Belayev, Alexey N. Tolstoy and Vladimir Obruchev, employed Vernian/Wellsian hard science fiction based on scientific predictions.
The most notable books of the era include Belayev's "Amphibian Man", "The Air Seller" and "Professor Dowell's Head"; Tolstoy's "Aelita" and "Engineer Garin's Death Ray". Early Soviet science fiction was influenced by communist ideology and often featured a leftist agenda or anti-capitalist satire.
Those few early Soviet books that challenged the communist worldview and satirized the Soviets, such as Yevgeny Zamyatin's dystopia "We" or Mikhail Bulgakov's "Heart of a Dog" and "Fatal Eggs", were banned from publishing until the 1980s, although they still circulated in fan-made copies.
In the second half of the 20th century, a new generation of writers developed a more complex approach. Social science fiction, concerned with philosophy, ethics, utopian and dystopian ideas, became the prevalent subgenre.
The breakthrough was started by Ivan Yefremov's utopian novel "Andromeda Nebula" (1957). He was soon followed by brothers Arkady and Boris Strugatsky, who explored darker themes and social satire in their Noon Universe novels, such as "Hard to be a God" (1964) and "Prisoners of Power" (1969), as well as in their science fantasy trilogy "Monday Begins on Saturday" (1964). A good share of Soviet science fiction was aimed at children. Probably the best known
was Kir Bulychov, who created "Alisa Selezneva" (1965-2003), a children's space adventure series about a teenage girl from the future.
The Soviet film industry also contributed to the genre, starting from the 1924 film "Aelita". Some of early Soviet films, namely "Planet of the Storms" (1962) and "Battle Beyond the Sun" (1959), were pirated, re-edited and released in the West under new titles.
Late Soviet science fiction films include "Mystery of the Third Planet" (1981), "" (1973) and "Kin-dza-dza!" (1986), as well as Andrey Tarkovsky's "Solaris" and "Stalker", among others.
After the fall of the Soviet Union, science fiction in the former Soviet republics is still written mostly in Russian, which allows an appeal to a broader audience. Aside from Russians themselves, especially notable are Ukrainian writers, who have greatly contributed to science fiction and fantasy in Russian language.
Among the most notable post-Soviet authors are H. L. Oldie, Sergey Lukyanenko, Alexander Zorich and Vadim Panov. Russia's film industry, however, has been less successful recently, producing only a few science fiction films, most of them are adaptations of books by the Strugatskys ("The Inhabited Island, The Ugly Swans") or Bulychov ("Alice's Birthday"). Science fiction media in Russia is represented with such magazines as "Mir Fantastiki" and "Esli".
Other European countries.
Poland is a traditional producer of science fiction and fantasy. The country's most influential science fiction writer of all time is Stanisław Lem, who is probably best known for his science fiction books, such as "Solaris" and the stories involving "Ijon Tichy", but who also wrote very successful hard sci-fi such as "The Invincible" and the stories involving Pilot Pirx. A number of Lem's books were adapted for screen, both in Poland and abroad. Other notable Polish writers of the genre include Jerzy Żuławski, Janusz A. Zajdel, Konrad Fiałkowski, Jacek Dukaj and Rafał A. Ziemkiewicz.
Czech writer and playwright Karel Čapek in his play "R.U.R." (1920) introduced the word "robot" into science fiction. Čapek is also known for his satirical science fiction novels and plays, such as "War with the Newts" and "The Absolute at Large". Traditions of Czech science fiction were carried on by writers like Ludvík Souček, Josef Nesvadba and Ondřej Neff.
Oceania.
Australia: American David G. Hartwell noted there is "nothing essentially Australian about Australian science-fiction." A number of Australian science-fiction (and fantasy and horror) writers are in fact international English language writers, and their work is published worldwide. This is further explainable by the fact that the Australian inner market is small (with Australian population being around 21 million), and sales abroad are crucial to most Australian writers.
North America.
In Canadian Francophone province Québec, Élisabeth Vonarburg and other authors developed a tradition of French-Canadian SF, related to the European French literature. The Prix Boreal was established in 1979 to honor Canadian science fiction works in French. The Prix Aurora Awards (briefly preceded by the Casper Award) were founded in 1980 to recognize and promote the best works of Canadian science fiction in both French and English. Also, due to Canada's bilingualism and the US publishing almost exclusively in English, translation of science fiction prose into French thrives and runs nearly parallel upon a book's publishing in the original English. A sizeable market also exists within Québec for European-written Francophone science fiction literature.
Latin America.
Although there is still some controversy as to when science fiction began in Latin America, the earliest works date from the late 19th century. All published in 1875, "O Doutor Benignus" by the Brazilian Augusto Emílio Zaluar, "El Maravilloso Viaje del Sr. Nic-Nac" by the Argentinian Eduardo Holmberg, and "Historia de un Muerto" by the Cuban Francisco Calcagno are three of the earliest novels which appeared in the continent.
Up to the 1960s, science fiction was the work of isolated writers who did not identify themselves with the genre, but rather used its elements to criticize society, promote their own agendas or tap into the public's interest in pseudo-sciences. It received a boost of respectability after authors such as Horacio Quiroga and Jorge Luis Borges used its elements in their writings. This, in turn, led to the permanent emergence of science fiction in the 1960s and mid-1970s, notably in Argentina, Brazil, Chile, Mexico, and Cuba. Magic realism enjoyed parallel growth in Latin America, with a strong regional emphasis on using the form to comment on social issues, similar to social science fiction and speculative fiction in the English world.
Economic turmoil and the suspicious eye of the dictatorial regimes in place reduced the genre's dynamism for the following decade. In the mid-1980s, it became increasingly popular once more. Although led by Argentina, Brazil and Mexico, Latin America now hosts dedicated communities and writers with an increasing use of regional elements to set them apart from English-language science-fiction.

</doc>
<doc id="26788" url="https://en.wikipedia.org/wiki?curid=26788" title="Spirotrich">
Spirotrich

The spirotrichs are a large and distinctive group of ciliate protozoa. They typically have prominent oral cilia in the form of a series of polykinetids, called the adoral zone of membranelles, beginning anterior to the oral cavity and running down to the left side of the mouth. There may also be one or two paroral membranes on its right side. The body cilia are fused to form polykinetids called cirri in some, and are sparse to absent in others.
Forms with cirri are common throughout soil, freshwater, and marine environments. Individuals tend to be flattened, with cirri confined to the ventral surface. These are variously used for crawling over objects, acting as feet, swimming, or assisting in food capture. They are generally divided into hypotrichs and stichotrichs, but were originally all considered hypotrichs.
Forms with sparse or absent body cilia tend to be smaller and are mostly marine, but a few are common in freshwater. Again, they are generally divided into oligotrichs and choreotrichs, but were originally all considered oligotrichs. The latter group includes the tintinnids, which produce loricae or shells and are the predominant fossil ciliates.
As first defined by Bütschli in 1889 the spirotrichs were one of two orders, together with the now-abandoned holotrichs, and included all ciliates with prominent oral cilia: heterotrichs, hypotrichs, oligotrichs, and peritrichs, although the last were soon separated. The heterotrichs have an adoral zone of membranelles, but molecular and ultrastructure studies have shown they are a separate group that diverged from most other ciliates early on. A few of the smaller groups included with them may be genuine spirotrichs, however, such as the Protocruziida.
The remaining spirotrichs form a monophyletic group, but their relationships are uncertain. For the most part the oligotrichs and choreotrichs appear to form closely related, natural groups. However "Halteria" and its close relatives, originally considered oligotrichs, form a separate group and may even be modified stichotrichs. Studies also suggest the hypotrichs are paraphyletic to the stichotrichs, and possibly to the oligotrichs and choreotrichs as well. This stands in contrast to the earlier belief that they were the most advanced of all protozoa.

</doc>
<doc id="26789" url="https://en.wikipedia.org/wiki?curid=26789" title="Sexual selection">
Sexual selection

Sexual selection is a mode of natural selection where members of one biological sex choose mates of the other sex to mate with (intersexual selection), and compete with members of the same sex for access to members of the opposite sex (intrasexual selection). These two forms of selection mean that some individuals have better reproductive success than others within a population, either from being more attractive or preferring more attractive partners to produce offspring. For instance in the breeding season sexual selection in frogs occurs with the males first gathering at the water's edge and making their mating calls: croaking. The females then arrive and choose the males with the deepest croaks and best territories. Generalizing, males benefit from frequent mating and monopolizing access to a group of fertile females. Females have a limited number of offspring they can have and they maximize the return on the energy they invest in reproduction.
The concept was first articulated by Charles Darwin and Alfred Russel Wallace who described it as driving speciation and that many organisms had evolved features whose function was deleterious to their individual survival, and then developed by Ronald Fisher in the early 20th century. Sexual selection can lead typically males to extreme efforts to demonstrate their fitness to be chosen by females, producing sexual dimorphism in secondary sexual characteristics, such as the ornate plumage of birds such as birds of paradise and peafowl, or the antlers of deer, or the manes of lions, caused by a positive feedback mechanism known as a Fisherian runaway, where the passing on of the desire for a trait in one sex is as important as having the trait in the other sex in producing the runaway effect. Although the sexy son hypothesis indicates that females would prefer male offspring, Fisher's principle explains why the sex ratio is 1:1 almost without exception. Sexual selection is also found in plants and fungi.
The maintenance of sexual reproduction in a highly competitive world has long been one of the major mysteries of biology given that asexual reproduction can reproduce much more quickly as 50% of offspring are not males, unable to produce offspring themselves. However, research published in 2015 indicates that sexual selection can explain the persistence of sexual reproduction.
In organisms.
Sexual selection has been observed to occur in plants, animals and fungi. In certain hermaphroditic snail and slug species of molluscs the throwing of love darts is a form of sexual selection. Certain male insects of the lepidoptera order of insects cement the vaginal pores of their females.
Today, biologists say that certain evolutionary traits can be explained by intraspecific competition - competition between members of the same species - distinguishing between competition "before" or "after" sexual intercourse.
Finally, sexual conflict is said to occur between breeding partners, sometimes leading to an evolutionary arms race between males and females. Sexual selection can also occur as a product of pheromone release, such as with the Stingless Bee, Trigona corvina.
Female mating preferences are widely recognized as being responsible for the rapid and divergent evolution of male secondary sexual traits. Females of many animal species prefer to mate with males with external ornaments - exaggerated features of morphology such as elaborate sex organs. These preferences may arise when an arbitrary female preference for some aspect of male morphology — initially, perhaps, a result of genetic drift — creates, in due course, selection for males with the appropriate ornament. One interpretation of this is known as the sexy son hypothesis. Alternatively, genes that enable males to develop impressive ornaments or fighting ability may simply show off greater disease resistance or a more efficient metabolism, features that also benefit females. This idea is known as the good genes hypothesis.
In humans.
Darwin conjectured that heritable traits such as beards and hairlessness, significant in the geographical differentiation of human appearance, are results of sexual selection. Geoffrey Miller has hypothesized that many human behaviours not clearly tied to survival benefits, such as humour, music, visual art, verbal creativity, and some forms of altruism, are courtship adaptations that have been favoured through sexual selection. In that view, many human artefacts could be considered subject to sexual selection as part of the extended phenotype, for instance clothing that enhances sexually selected traits. Some argue that the evolution of human intelligence is a sexually selected trait, as it would not confer enough fitness in itself relative to its high maintenance costs.
Darwin and the development of the theory.
The theory was first proposed by Charles Darwin in "The Origin of Species" (1859) and developed in "The Descent of Man and Selection in Relation to Sex" (1871) because Darwin felt that natural selection alone was unable to account for certain types of non-survival adaptations. He once wrote to a colleague that "The sight of a feather in a peacocks tail, whenever I gaze at it, makes me sick!" His work divided sexual selection into male-male competition and female choice.
These views were opposed by Alfred Russel Wallace, though much of his opposition took place after Darwin's death. He argued that male-male competitions were forms of natural selection, but that the "drab" peahen's coloration is itself adaptive as camouflage, and that ascribing mate choice to females was, in his opinion, attributing the ability to judge standards of beauty to animals far too cognitively undeveloped to be capable of aesthetic feeling (such as beetles).
Ronald Fisher.
Ronald Fisher, the English statistician and evolutionary biologist developed a number of ideas about sexual selection in his 1930 book "The Genetical Theory of Natural Selection" including the sexy son hypothesis and Fisher's principle. The Fisherian runaway describes how sexual selection accelerates the preference for a specific ornament, causing the preferred trait and female preference for it to increase together in a positive feedback runaway cycle. In a remark that was not widely understood for another 50 years he said:
This causes a dramatic increase in both the male's conspicuous feature and in female preference for it, until practical, physical constraints halt further exaggeration. A positive feedback loop is created, producing extravagant physical structures in the non-limiting sex. A classic example of female choice and potential runaway selection is the long-tailed widowbird (left). While males have long tails that are selected for by female choice, female tastes in tail length are still more extreme with females being attracted to tails longer than those that naturally occur. Fisher understood that female preference for long tails may be passed on genetically, in conjunction with genes for the long tail itself. Long-tailed widowbird offspring of both sexes will inherit both sets of genes, with females expressing their genetic preference for long tails, and males showing off the coveted long tail itself.
Richard Dawkins presents a non-mathematical explanation of the runaway sexual selection process in his book "The Blind Watchmaker". Females who prefer long tailed males tend to have mothers that chose long-tailed fathers. As a result, they carry both sets of genes in their bodies. That is, genes for long tails and for preferring long tails become linked. The taste for long tails and tail length itself may therefore become correlated, tending to increase together. The more tails lengthen, the more long tails are desired. Any slight initial imbalance between taste and tails may set off an explosion in tail lengths. Fisher corresponded that:
The female widow bird will desire to mate with the most attractive long-tailed male so that her progeny, if male, will themselves be attractive to females of the next generation - thereby fathering many offspring who will carry the female's genes. Since the rate of change in preference is proportional to the average taste amongst females, and as females desire to secure the services of the most sexually attractive males, an additive effect is created that, if unchecked, can yield exponential increases in a given taste and in the corresponding desired sexual attribute.
Since Fisher's initial conceptual model of the 'runaway' process, Russell Lande and Peter O'Donald have provided detailed mathematical proofs that define the circumstances under which runaway sexual selection can take place.
Reproductive success.
The reproductive success of an organism is measured by the number of offspring left behind, and their quality or probable fitness.
Sexual preference creates a tendency towards assortative mating or homogamy. The general conditions of sexual discrimination appear to be (1) the acceptance of one mate precludes the effective acceptance of alternative mates, and (2) the rejection of an offer will be followed by other offers, either certainly, or at such high chance that the risk of non-occurrence will be smaller than the chance advantage to be gained by selecting a mate.
The conditions determining which sex becomes the more limited resource in intersexual selection can be best understood by way of Bateman's principle which states that "the sex which invests the most in producing offspring becomes a limiting resource over which the other sex will compete", illustrated by the greater nutritional investment of an egg in a zygote, and the limited capacity of females to reproduce; for example in humans a woman can only give birth every ten months whereas in theory a male can become a father every day.
Modern interpretation.
The sciences of evolutionary psychology, human behavioural ecology, and sociobiology study the influence of sexual selection in humans, and are often controversial fields.
Darwin's ideas on sexual selection were met with scepticism by his contemporaries and not considered of great importance in the 20th century, so that in the 1930s biologists decided to include sexual selection as a mode of natural selection. Only in the 21st century have they become more important in biology.
New theories highlight intrinsically useful qualities of such traits. Antlers, horns and the like can be used in physical defence from a predator, and also in competition among males in a tournament species. The winner, which typically becomes the dominant animal in the population, is granted access to females, and therefore increases his reproductive output. Antlers are not the only mechanism that can be used to counteract predation. Predators typically look for the eyes of their prey so they can attack that end of the creature. The conspicuousness of eyespots on many species of butterflies and fishes confuses predators and helps to prevent the prey from suffering serious damage.
Research published in 2015 indicates that sexual selection and the mate choices which "improves population health and protects against extinction, even in the face of genetic stress from high levels of inbreeding" and "ultimately dictates who gets to reproduce their genes into the next generation - so it's a widespread and very powerful evolutionary force." The study involved the flour beetle over a ten-year period where the only changes were in the intensity of sexual selection.
Another, more recently developed, theory, the handicap principle of Amotz Zahavi, Russell Lande and W. D. Hamilton, holds that the fact that the male is able to survive until and through the age of reproduction with such a seemingly maladaptive trait is effectively considered by the female to be a testament to his overall fitness. Such handicaps might prove he is either free of or resistant to disease, or it might demonstrate that this animal possesses more speed or a greater physical strength that is used to combat the troubles brought on by the exaggerated trait.
Zahavi's work spurred a re-examination of the field, which has produced an ever-accelerating number of theories. In 1984, Hamilton and Marlene Zuk introduced the "Bright Male" hypothesis, suggesting that male elaborations might serve as a marker of health, by exaggerating the effects of disease and deficiency. In 1990, Michael Ryan and A.S. Rand, working with the tungara frog, proposed the hypothesis of "Sensory Exploitation", where exaggerated male traits may provide a sensory stimulation that females find hard to resist. Subsequently the theories of the "Gravity Hypothesis" by Jordi Moya-Larano et al. and "Chase Away" by Brett Holland and William R. Rice have also been added. In addition, in the late 1970s Janzen and Mary Willson, noting that male flowers are often larger than female flowers, expanded the field of sexual selection into plants.
In the past few years, the field has exploded to include many additional observations and areas of study, not all of which are clearly included under Darwin's definition of sexual selection. These include cuckoldry, nuptial gifts, sperm competition, infanticide, physical beauty, mating by subterfuge, species isolation mechanisms, male parental care, ambiparental care, mate location, polygamy, and homosexual rape in certain male animals,
Focusing on the effect of sexual conflict, as hypothesized by William Rice, Locke Rowe et Göran Arnvist, Thierry Lodé underlines that the divergence of interest constitutes a key for evolutionary process. Sexual conflict leads to an antagonistic co-evolution in which one sex tends to control the other, resulting in a tug of war. Besides, "the sexual propaganda theory" only argued that mate were opportunistically lead, on the basis of various factors determining the choice such as phenotypic characteristics, apparent vigour of individual, strength of mate signals, trophic resources, territoriality etc. and could explain the maintenance of genetic diversity within populations.
Several workers have brought attention to the fact that elaborated characters that ought to be costly in one way or another for their bearers (e.g., the tails of some species of Xiphophorus fish) do not always appear to have a cost in terms of energetics, performance or even survival. One possible explanation for the apparent lack of costs is that "compensatory traits" have evolved in concert with the sexually selected traits.
As a toolkit of natural selection.
Sexual selection may explain how certain characteristics (such as feathers) had distinct survival value at an early stage in their evolution.
Geoffrey Miller proposes that sexual selection might have contributed by creating evolutionary modules such as "Archaeopteryx" feathers as sexual ornaments, at first. The earliest proto-birds such as China's "Protarchaeopteryx", discovered in the early 1990s, had well-developed feathers but no sign of the top/bottom asymmetry that gives wings lift. Some have suggested that the feathers served as insulation, helping females incubate their eggs. But perhaps the feathers served as the kinds of sexual ornaments still common in most bird species, and especially in birds such as peacocks and birds-of-paradise today. If proto-bird courtship displays combined displays of forelimb feathers with energetic jumps, then the transition from display to aerodynamic functions could have been relatively smooth.
Sexual selection sometimes generates features that may help cause a species' extinction, as has been suggested for the giant antlers of the Irish elk ("Megaloceros giganteus") that became extinct in Pleistocene Europe. However, sexual selection can also do the opposite, driving species divergence - sometimes through elaborate changes in genitalia - such that new species emerge.
Sexual dimorphism.
Sex differences directly related to reproduction and serving no direct purpose in courtship are called primary sexual characteristics. Traits amenable to sexual selection, which give an organism an advantage over its rivals (such as in courtship) without being directly involved in reproduction, are called secondary sex characteristics.
In most sexual species the males and females have different equilibrium strategies, due to a difference in relative investment in producing offspring. As formulated in Bateman's principle, females have a greater initial investment in producing offspring (pregnancy in mammals or the production of the egg in birds and reptiles), and this difference in initial investment creates differences in variance in expected reproductive success and bootstraps the sexual selection processes. Classic examples of reversed sex-role species include the pipefish, and Wilson's phalarope. Also, unlike a female, a male (except in monogamous species) has some uncertainty about whether or not he is the true parent of a child, and so will be less interested in spending his energy helping to raise offspring that may or may not be related to him. As a result of these factors, males are typically more willing to mate than females, and so females are typically the ones doing the choosing (except in cases of forced copulations, which can occur in certain species of primates, ducks, and others). The effects of sexual selection are thus held to typically be more pronounced in males than in females.
Differences in secondary sexual characteristics between males and females of a species are referred to as sexual dimorphisms. These can be as subtle as a size difference (sexual size dimorphism, often abbreviated as SSD) or as extreme as horns and colour patterns. Sexual dimorphisms abound in nature. Examples include the possession of antlers by only male deer, the brighter coloration of many male birds in comparison with females of the same species, or even more distinct differences in basic morphology, such as the drastically increased eye-span of the male stalk-eyed fly. The peacock, with its elaborate and colourful tail feathers, which the peahen lacks, is often referred to as perhaps the most extraordinary example of a dimorphism. Male and female black-throated blue warblers and Guianan cock-of-the-rocks also differ radically in their plumage. Early naturalists even believed the females to be a separate species. The largest sexual size dimorphism in vertebrates is the shell dwelling cichlid fish "Neolamprologus callipterus" in which males are up to 30 times the size of females. Many other fish such as guppies also exhibit sexual dimorphism. Extreme sexual size dimorphism, with females larger than males, is quite common in spiders and birds of prey

</doc>
<doc id="26790" url="https://en.wikipedia.org/wiki?curid=26790" title="Stanisław Lem">
Stanisław Lem

Stanisław Lem (; 12 September 1921 – 27 March 2006) was a Polish writer of science fiction, philosophy, and satire, and a trained physician. Lem's books have been translated into forty-one languages and have sold over forty-five million copies. Though raised a Roman Catholic, he later became an atheist "for moral reasons . . . the world appears to me to be put together in such a painful way that I prefer to believe that it was not created . . . intentionally". Lem called himself both an "agnostic". and an atheist later in life. After the Soviet invasion and occupation of Eastern Poland, he was not allowed to study at the Polytechnic as he wished because of his "bourgeois origin," and only due to his father's connections was accepted to study medicine at Lwów University in 1940. During the subsequent Nazi occupation (1941–1944), Lem's family, which had Jewish roots, avoided imprisonment in a ghetto, surviving with false papers. During that time, Lem earned a living as a car mechanic and welder. Lem declared:
In 1945, Polish eastern Kresy was annexed into Soviet Ukraine and the family, like many other Poles, was resettled to Kraków, where Lem, at his father's insistence, took up medical studies at the Jagiellonian University. He did not take his final examinations on purpose, so as not to be obliged to become a military doctor. Earlier, he had started working as an assistant in a hospital and writing stories in his spare time.
Rise to fame.
Lem made his literary debut in 1946 with a number of works of different genres, including poetry as well as a science fiction novel "The Man from Mars" ("Człowiek z Marsa") serialized in ' ("New World of Adventures"). Between 1948 and 1950 Lem was working as a scientific research assistant at the Jagiellonian University, and published a number of short stories, poems, reviews and similar works, particularly at "Tygodnik Powszechny". In 1951, he published his first book, "The Astronauts" ("Astronauci"). In 1954, he published a short story anthology, "Sesame and other stories" ('). That year he also married Barbara Leśniak. The following year, 1955, saw the publication of another science fiction novel, "The Magellanic Cloud" ("Obłok Magellana").
During the era of Stalinism, which had begun in Poland in the late '40s, all published works had to be directly approved by the communist regime. Thus "Astronauci" was not, in fact, the first novel Lem finished, just the first that made it past the censors. Going by the date of finished manuscript, Lem's first book was a partly autobiographical novella "Hospital of the Transfiguration" ("Szpital Przemienienia"), finished in 1948. It would be published seven years later, in 1955, as a trilogy under a title "Czas nieutracony" ("Time Not Lost"). The experience of trying to push "Czas.." through the censors was one of the major reasons Lem decided to focus on the less-censored genre of science fiction. Nonetheless, most of Lem's works published in the 1950s also contain—forced upon him by the censors and editors—various references to socialist realism as well as the "glorious future of communism". Lem later criticized several of his early pieces as compromised by the ideological pressure.
Lem became truly productive after 1956, when the de-Stalinization period in the Soviet Union led to the "Polish October", when Poland experienced an increase in freedom of speech. Between 1956 and 1968, Lem authored seventeen books. His writing over the next three decades or so was split between science fiction (primarily prose) and essays about science and culture.
In 1957, he published his first non-fiction, philosophical book, "Dialogues" (), as well as a science-fiction anthology, "The Star Diaries" ("Dzienniki gwiazdowe"), collecting short stories about one of his most popular characters, Ijon Tichy. 1959 saw the publication of three books: "Eden", "Śledztwo" and the short story anthology, "Inwazja z Aldebarana". 1961 saw two more books, the first regarded as being among his top works: "Pamiętnik znaleziony w wannie", "Solaris", as well as "Powrót z gwiazd". This was followed by a collections of his essays and non-fiction prose, "Wejście na orbitę" (1962), and a short-story anthology "Noc księżycowa" (1963). In 1964, Lem published a large work on the border of philosophy and sociology of science and futurology, "Summa Technologiae", as well as a novel, "The Invincible" ("Niezwyciężony").
1965 saw the publication of "The Cyberiad" ("Cyberiada"). That year also saw the publication of a short-story anthology, "The Hunt" (). 1966 is the year of "Wysoki Zamek", and 1968, "Głos Pana" and "Opowieści o pilocie Pirxie". "Wysoki Zamek" was another of Lem's autobiographical works, and touched upon a theme that usually was not favored by the censors: Lem's youth in the pre-war, then-Polish, Lviv. 1967 and 1970 saw two more non-fiction treatises, "Filozofia przypadku" and "Fantastyka i futurologia". Ijon Tichy returns in 1971's "The Futurological Congress" "Kongres futurologiczny", the year of a genre-mixing experiment, "Doskonała próżnia" (a collection of reviews of non-existent books). 1973 sees a similar work, "Wielkość urojona". In 1976, Lem published two novels: "Maska" and "Katar". In 1980, he published another set of reviews of non-existent works, "Prowokacja". The following year sees another Tichy novel, "Wizja lokalna", and "Golem XIV". Later in that decade, he published "Pokój na Ziemi" (1984) and "Fiasko" (1986), Lem's final science-fiction novel.
In the late '70s and early '80s, Lem cautiously supported the Polish dissident movement, and started publishing essays in Paris-based "Kultura". In 1982, with martial law in Poland declared, Lem moved to West Berlin, where he became a fellow of the Institute for Advanced Study, Berlin ("Wissenschaftskolleg zu Berlin"). After that, he settled in Vienna. He returned to Poland in 1988.
Final years.
From the late 1980s onwards, he tended to concentrate on philosophical texts and essays, published in a number of Polish magazines ("Tygodnik Powszechny", "Odra", "Przegląd", and others). They were later collected in a number of anthologies.
In the early 1990s, Lem met with the literary scholar and critic Peter Swirski for a series of extensive interviews, published together with other critical materials and translations as "A Stanislaw Lem Reader" (1997); in the book, Lem speaks about a range of issues rarely touched on before in any interview. Moreover, the book includes Swirski's translation of Lem's retrospective essay "Thirty Years Later", devoted to Lem's legendary nonfictional treatise "Summa Technologiae". During later interviews in 2005, Lem expressed his disappointment with the genre of science fiction, and his general pessimism regarding technical progress. He viewed the human body as unsuitable for space travel, held that information technology drowns people in a glut of low-quality information, and considered truly intelligent robots as both undesirable and impossible to construct. Subsequently, Peter Swirski has published a series of in-depth studies of Lem as a writer, philosopher, and futurologist; notable among them are the recent "From Literature to Biterature: Lem, Turing, Darwin" (2013), "Stanislaw Lem: Selected Letters to Michael Kandel" (2014), "Lemography" (2014), and "Stanislaw Lem: Philosopher of the Future" (2015).
In 1996, Lem received the prestigious Polish award, the Order of the White Eagle.
Lem died from heart disease in Kraków on 27 March 2006 at the age of 84.
Controversies.
SFWA.
Lem was awarded an honorary membership in the Science Fiction Writers of America (SFWA) in 1973. SFWA Honorary membership is given to people who do not meet the publishing criteria for joining the regular membership, but who "would" be welcomed as members had their work appeared in the qualifying English-language publications. Lem, however, never had a high opinion of American science fiction, describing it as ill-thought-out, poorly written, and interested more in making money than in ideas or new literary forms. After his eventual American publication, when he became eligible for regular membership, his honorary membership was rescinded, an action that some of the SFWA members apparently intended as a rebuke, and it seems that Lem interpreted it as such. Lem was invited to stay on with the organization with a regular membership, but declined. After many members (including Ursula K. Le Guin) protested Lem's treatment by the SFWA, a member offered to pay his dues. Lem never accepted the offer.
Philip K. Dick.
Lem singled out only one American SF writer for praise, Philip K. Dick—see the 1986 English-language anthology of his critical essays, "Microworlds". Dick thought that Stanisław Lem was probably a false name used by a composite committee operating on orders of the Communist party to gain control over public opinion, and wrote a letter to the FBI to that effect. Stanisław Lem was also responsible for Polish translation of Dick's work, and when Dick felt monetarily short-changed by the publisher, he held Lem personally responsible (see "Microworlds").
Significance.
Lem has become one of the most highly acclaimed science-fiction writers, hailed by critics as equal to such classic authors as H. G. Wells and Olaf Stapledon. In 1976, Theodore Sturgeon wrote that Lem was the most widely read science-fiction writer in the world.
In Poland, in the '60s and '70s, Lem remained under the radar of mainstream critics, who dismissed him as a "mass market", low-brow, youth-oriented writer; such dismissal might have given him a form of invisibility from censorship.
The total volume of his published works is over twenty-eight million volumes. His works were widely translated abroad, appearing in over forty languages, though the bulk of them were in Eastern Bloc countries (Poland, Germany, and the Soviet Union). Franz Rottensteiner, Lem's former agent abroad, had this to say about Lem's reception on international markets: 
His best-known novels include "Solaris" (1961), "His Master's Voice" ("Głos pana", 1968), and the late "Fiasco" ("Fiasko", 1987). "Solaris" was made into a film in 1968 by Russian director Boris Nirenburg, a film in 1972 by Russian director Andrei Tarkovsky—which won a Special Jury Prize at the Cannes Film Festival in 1972—and an American re-adaptation in 2002 by American director Steven Soderbergh, starring George Clooney.
"Solaris" is not the only work of Lem's to be made into a movie. Over ten movie, film, and television adaptations of his work exist, such as adaptations of "The Astronauts" ("First Spaceship on Venus", 1960) and "The Magellan Nebula" ("Ikarie XB-1", 1963). Lem himself was, however, critical of most of the screen adaptations, with the sole exception of "Przekładaniec" in 1968 by Andrzej Wajda. More recently, in 2013, the Israeli–Polish co-production "The Congress" was released, inspired by Lem's novel "The Futurological Congress".
Lem's works have been used in education, for example as teaching texts for philosophy students.
Lem's works have influenced not only the realm of literature, but that of science as well. For example, "Return from the Stars" includes the "opton", which is often cited as the first published appearance of the idea of electronic paper.
In 1981, the philosophers Douglas R. Hofstadter and Daniel C. Dennett included three extracts from Lem's fiction in their annotated anthology "The Mind's I", accompanied by Hofstadter's comment, which says in part that Lem's "literary and intuitive approach . . . does a better job of convincing readers of his views than any hard-nosed scientific article . . . might do".
Other influences exerted by Lem's works include Will Wright's popular city planning game "SimCity", which was partly inspired by Lem's short story "The Seventh Sally".
Writings.
Science fiction.
Stanisław Lem works were influenced by such masters of Polish literature as Cyprian Norwid and Stanisław Witkiewicz. His prose show a mastery of numerous genres and themes.
One of Lem's major recurring themes, beginning from his very first novel, "The Man from Mars", was the impossibility of communication between profoundly alien beings, which may have no common ground with human intelligence, and humans. The best known example is the living planetary ocean in Lem's novel "Solaris". Other examples include swarms of mechanical insects (in "The Invincible"), and strangely ordered societies of more human-like beings in "Fiasco" and "Eden", describing the failure of the first contact. In "His Master's Voice", Lem describes the failure of humanity's intelligence to decipher and truly comprehend an apparent message from space.
Two overlapping arcs of short stories, "Fables for Robots" ("Bajki Robotów"), translated in the collection "Mortal Engines"), and "The Cyberiad" ("Cyberiada") provide a commentary on humanity in the form of a series of grotesque, humorous, fairytale-like short stories about a mechanical universe inhabited by robots (who have occasional contact with biological "slimies" and human "palefaces"). 
"Śledztwo" and "Katar" are crime novels (the latter without a murderer); "Pamiętnik . . ." is a psychological drama inspired by Kafka. "Doskonała próżnia" and "Wielkość urojona" are collections of reviews of non-existent books and introductions to them. Similarly, "Prowokacja" purports to review a Holocaust-themed work.
Essays.
Lem's criticism of most science fiction surfaced in literary and philosophical essays "Science Fiction and Futurology" and interviews. In the 1990s, Lem forswore science fiction and returned to futurological prognostications, most notably those expressed in "Blink of an Eye" (""). He became increasingly critical of modern technology in his later life, criticizing inventions such as the Internet.
"Dialogi" and "Summa Technologiae" (1964) are Lem's two most famous philosophical texts. The "Summa" is notable for being a unique analysis of prospective social, cybernetic, and biological advances; in this work, Lem discusses philosophical implications of technologies that were completely in the realm of science fiction at the time, but are gaining importance today—for instance, virtual reality and nanotechnology.

</doc>
<doc id="26791" url="https://en.wikipedia.org/wiki?curid=26791" title="Satire">
Satire

Satire is a genre of literature, and sometimes graphic and performing arts, in which vices, follies, abuses, and shortcomings are held up to ridicule, ideally with the intent of shaming individuals, corporations, government or society itself, into improvement. Although satire is usually meant to be humorous, its greater purpose is often constructive social criticism, using wit to draw attention to both particular and wider issues in society.
A feature of satire is strong irony or sarcasm—"in satire, irony is militant"—but parody, burlesque, exaggeration, juxtaposition, comparison, analogy, and double entendre are all frequently used in satirical speech and writing. This "militant" irony or sarcasm often professes to approve of (or at least accept as natural) the very things the satirist wishes to attack.
Satire is nowadays found in many artistic forms of expression, including literature, plays, commentary, television shows, and media such as lyrics.
Etymology and roots.
The word satire comes from the Latin word "satur" and the subsequent phrase "." "Satur" meant "full" but the juxtaposition with "lanx" shifted the meaning to "miscellany or medley": the expression "lanx satura" literally means "a full dish of various kinds of fruits."
The word "satura" as used by Quintilian, however, was used to denote only Roman verse satire, a strict genre that imposed hexameter form, a narrower genre than what would be later intended as "satire". Quintilian famously said that "satura," that is a satire in hexameter verses, was a literary genre of wholly Roman origin ("satura tota nostra est"). He was aware of and commented on Greek satire, but at the time did not label it as such, although today the origin of satire is considered to be Aristophanes' Old Comedy. The first critic to use satire in the modern broader sense was Apuleius.
To Quintilian, the satire was a strict literary form, but the term soon escaped from the original narrow definition. Robert Elliott writes:
The word "satire" derives from "satura", and its origin was not influenced by the Greek mythological figure of the "satyr". In the 17th century, philologist Isaac Casaubon was the first to dispute the etymology of satire from satyr, contrary to the belief up to that time.
Satire and humor.
Laughter is not an essential component of satire; in fact there are types of satire that are not meant to be "funny" at all. Conversely, not all humour, even on such topics as politics, religion or art is necessarily "satirical", even when it uses the satirical tools of irony, parody, and burlesque.
Even light-hearted satire has a serious "after-taste": the organizers of the Ig Nobel Prize describe this as "first make people laugh, and then make them think".
Social and psychological functions.
Satire and irony in some cases have been regarded as the most effective source to understand a society, the oldest form of social study. They provide the keenest insights into a group's collective psyche, reveal its deepest values and tastes, and the society's structures of power. Some authors have regarded satire as superior to non-comic and non-artistic disciplines like history or anthropology. In a prominent example from ancient Greece, philosopher Plato, when asked by a friend for a book to understand Athenian society, referred him to the plays of Aristophanes.
Historically, satire has satisfied the popular need to debunk and ridicule the leading figures in politics, economy, religion and other prominent realms of power. Satire confronts public discourse and the collective imaginary, playing as a public opinion counterweight to power (be it political, economic, religious, symbolic, or otherwise), by challenging leaders and authorities. For instance, it forces administrations to clarify, amend or establish their policies. Satire's job is to expose problems and contradictions, and it's not obligated to solve them. Karl Kraus set in the history of satire a prominent example of a satirist role as confronting public discourse.
For its nature and social role, satire has enjoyed in many societies a special freedom license to mock prominent individuals and institutions. The satiric impulse, and its ritualized expressions, carry out the function of resolving social tension. Institutions like the ritual clowns, by giving expression to the antisocial tendencies, represent a safety valve which reestablishes equilibrium and health in the collective imaginary, which are jeopardized by the repressive aspects of society.
The state of political satire in a given society reflects the tolerance or intolerance that characterizes it, and the state of civil liberties and human rights. Under totalitarian regimes any criticism of a political system, and especially satire, is suppressed. A typical example is the Soviet Union where the dissidents, such as Aleksandr Solzhenitsyn and Andrei Sakharov were under strong pressure from the government. While satire of everyday life in the USSR was allowed, the most prominent satirist being Arkady Raikin, political satire existed in the form of anecdotes that made fun of Soviet political leaders, especially Brezhnev, famous for his narrow-mindness and love for awards and decorations.
Classifications of satire.
Satire is a diverse genre which is complex to classify and define, with a wide range of satiric "modes".
Horatian, Juvenalian, Menippean.
Satirical literature can commonly be categorized as either Horatian, Juvenalian, or Menippean.
Horatian.
Horatian satire, named for the Roman satirist Horace (65–8 BCE), playfully criticizes some social vice through gentle, mild, and light-hearted humour. Horace (Quintus Horatius Flaccus) wrote Satires to gently ridicule the dominant opinions and "philosophical beliefs of ancient Rome and Greece" (Rankin). Rather than writing in harsh or accusing tones, he addressed issues with humor and clever mockery. Horatian satire follows this same pattern of "gently the absurdities and follies of human beings" (Drury). 
It directs wit, exaggeration, and self-deprecating humour toward what it identifies as folly, rather than evil. Horatian satire's sympathetic tone is common in modern society.
A Horatian satirist's goal is to heal the situation with smiles, rather than by anger. Horatian satire is a gentle reminder to take life less seriously and evokes a wry smile. A Horatian satirist makes fun of general human folly rather than engaging in specific or personal attacks. Shamekia Thomas suggests, "In a work using Horatian satire, readers often laugh at the characters in the story who are the subject of mockery as well as themselves and society for behaving in those ways." Alexander Pope has been established as an author whose satire "heals with morals what it hurts with wit" (Green). Alexander Pope—and Horatian satire—attempt to teach.
Examples:
Juvenalian.
Juvenalian satire, named after the Roman satirist Juvenal (late 1st century – early 2nd century AD), is more contemptuous and abrasive than the Horatian. Juvenal disagreed with the opinions of the public figures and institutions of the Republic and actively attacked them through his literature. "He utilized the satirical tools of exaggeration and parody to make his targets appear monstrous and incompetent" (Podzemny). Juvenal satire follows this same pattern of abrasively ridiculing societal structures. Unlike Horace, Juvenal attacked public officials and governmental organizations through his satires. He regarded their opinions not just as wrong, but instead as evil. Juvenalian satire thus is more contemptuous and abrasive, and uses strong irony and sarcasm. Polarized political satire is often of this nature, and aims to provoke political and societal change.
Examples:
Satire versus teasing.
In the history of theatre there has always been a conflict between engagement and disengagement on politics and relevant issue, between satire and grotesque on one side, and jest with teasing on the other. Max Eastman defined the spectrum of satire in terms of "degrees of biting", as ranging from satire proper at the hot-end, and "kidding" at the violet-end; Eastman adopted the term kidding to denote what is just satirical in form, but is not really firing at the target. Nobel laureate satirical playwright Dario Fo pointed out the difference between satire and teasing ("sfottò"). Teasing is the reactionary side of the comic; it limits itself to a shallow parody of physical appearance. The side-effect of teasing is that it humanizes and draws sympathy for the powerful individual towards which it is directed. Satire instead uses the comic to go against power and its oppressions, has a subversive character, and a moral dimension which draws judgement against its targets. Fo formulated an operational criteria to tell real satire from "sfottò", saying that real satire arouses an outraged and violent reaction, and that the more they try to stop you, the better is the job you are doing. Fo contends that, historically, people in positions of power have welcomed and encouraged good-humoured buffoonery, while modern day people in positions of power have tried to censor, ostracize and repress satire.
Teasing ("sfottò") is an ancient form of simple buffoonery, a form of comedy without satire's subversive edge. Teasing includes light and affectionate parody, good-humoured mockery, simple one-dimensional poking fun, and benign spoofs. Teasing typically consists of an impersonation of someone monkeying around with his exterior attributes, tics, physical blemishes, voice and mannerisms, quirks, way of dressing and walking, and/or the phrases he typically repeats. By contrast, teasing never touches on the core issue, never makes a serious criticism judging the target with irony; it never harms the target's conduct, ideology and position of power; it never undermines the perception of his morality and cultural dimension. "Sfottò" directed towards a powerful individual makes him appear more human and draws sympathy towards him. Hermann Göring propagated jests and jokes against himself, with the aim of humanizing his image.
Classifications by topics.
Types of satire can also be classified according to the topics it deals with. From the earliest times, at least since the plays of Aristophanes, the primary topics of literary satire have been politics, religion and sex. This is partly because these are the most pressing problems that affect anybody living in a society, and partly because these topics are usually taboo. Among these, politics in the broader sense is considered the pre-eminent topic of satire. Satire which targets the clergy is a type of political satire, while religious satire is that which targets religious beliefs. Satire on sex may overlap with blue comedy, off-color humor and dick jokes.
Scatology has a long literary association with satire,<refname="Clark91p116"/> as it is a classical mode of the grotesque, the grotesque body and the satiric grotesque. Shit plays a fundamental role in satire because it symbolizes death, the turd being "the ultimate dead object". The satirical comparison of individuals or institutions with human excrement, exposes their "inherent inertness, corruption and dead-likeness". The ritual clowns of clown societies, like among the Pueblo Indians, have ceremonies with filth-eating. In other cultures, sin-eating is an apotropaic rite in which the sin-eater (also called filth-eater), by ingesting the food provided, takes "upon himself the sins of the departed". Satire about death overlaps with black humor and gallows humor.
Another classification by topics is the distinction between political satire, religious satire and satire of manners. Political satire is sometimes called topical satire, satire of manners is sometimes called satire of everyday life, and religious satire is sometimes called philosophical satire. Comedy of manners, sometimes also called satire of manners, criticizes mode of life of common people; political satire aims at behavior, manners of politicians, and vices of political systems. Historically, comedy of manners, which first appeared in British theater in 1620, has uncritically accepted the social code of the upper classes. Comedy in general accepts the rules of the social game, while satire subverts them.
Another analysis of satire is the spectrum of his possible tones: wit, ridicule, irony, sarcasm, cynicism, the sardonic and invective.
Classifications by medium.
Satire is found not only in written literary forms. In preliterate cultures it manifests itself in ritual and folk forms, as well as in trickster tales and oral poetry.
It appears also in graphic arts, music, sculpture, dance, cartoon strips, and graffiti. Examples are Dada sculptures, Pop Art works, music of Gilbert and Sullivan and Erik Satie, punk and rock music. In modern media culture, stand-up comedy is an enclave in which satire can be introduced into mass media, challenging mainstream discourse. Comedy roasts, mock festivals, and stand-up comedians in nightclubs and concerts are the modern forms of ancient satiric rituals.
Development.
Ancient Egypt.
One of the earliest examples of what we might call satire, The Satire of the Trades, is in Egyptian writing from the beginning of the 2nd millennium BC. The text's apparent readers are students, tired of studying. It argues that their lot as scribes is useful, and their lot far superior to that of the ordinary man. Scholars such as Helck think that the context was meant to be serious.
The Papyrus Anastasi I (late 2nd millennium BC) contains a satirical letter which first praises the virtues of its recipient, but then mocks the reader's meagre knowledge and achievements.
Ancient Greece.
The Greeks had no word for what later would be called "satire", although the terms cynicism and parody were used. Modern critics call the Greek playwright Aristophanes one of the best known early satirists: his plays are known for their critical political and societal commentary, particularly for the political satire by which he criticized the powerful Cleon (as in "The Knights"). He is also notable for the persecution he underwent. Aristophanes' plays turned upon images of filth and disease. His bawdy style was adopted by Greek dramatist-comedian Menander. His early play "Drunkenness" contains an attack on the politician Callimedon.
The oldest form of satire still in use is the Menippean satire by Menippus of Gadara. His own writings are lost. Examples from his admirers and imitators mix seriousness and mockery in dialogues and present parodies before a background of diatribe. As in the case of Aristophanes plays, menippean satire turned upon images of filth and disease.
Roman world.
The first Roman to discuss satire critically was Quintilian, who invented the term to describe the writings of Lucilius. The two most prominent and influential ancient Roman satirists are Horace and Juvenal, who wrote during the early days of the Roman Empire. Other important satirists in ancient Latin are Lucilius and Persius. "Satire" in their work is much wider than in the modern sense of the word, including fantastic and highly coloured humorous writing with little or no real mocking intent. When Horace criticized Augustus, he used veiled ironic terms. In contrast, Pliny reports that the 6th century BC poet Hipponax wrote "satirae" that were so cruel that the offended hanged themselves.
Medieval Islamic world.
Medieval Arabic poetry included the satiric genre "hija". Satire was introduced into Arabic prose literature by the Afro-Arab author Al-Jahiz in the 9th century. While dealing with serious topics in what are now known as anthropology, sociology and psychology, he introduced a satirical approach, "based on the premise that, however serious the subject under review, it could be made more interesting and thus achieve greater effect, if only one leavened the lump of solemnity by the insertion of a few amusing anecdotes or by the throwing out of some witty or paradoxical observations. He was well aware that, in treating of new themes in his prose works, he would have to employ a vocabulary of a nature more familiar in "hija", satirical poetry." For example, in one of his zoological works, he satirized the preference for longer human penis size, writing: "If the length of the penis were a sign of honor, then the mule would belong to the (honorable tribe of) Quraysh". Another satirical story based on this preference was an "Arabian Nights" tale called "Ali with the Large Member".
In the 10th century, the writer Tha'alibi recorded satirical poetry written by the Arabic poets As-Salami and Abu Dulaf, with As-Salami praising Abu Dulaf's wide breadth of knowledge and then mocking his ability in all these subjects, and with Abu Dulaf responding back and satirizing As-Salami in return. An example of Arabic political satire included another 10th-century poet Jarir satirizing Farazdaq as "a transgressor of the Sharia" and later Arabic poets in turn using the term "Farazdaq-like" as a form of political satire.
The terms "comedy" and "satire" became synonymous after Aristotle's "Poetics" was translated into Arabic in the medieval Islamic world, where it was elaborated upon by Islamic philosophers and writers, such as Abu Bischr, his pupil Al-Farabi, Avicenna, and Averroes. Due to cultural differences, they disassociated comedy from Greek dramatic representation and instead identified it with Arabic poetic themes and forms, such as "hija" (satirical poetry). They viewed comedy as simply the "art of reprehension", and made no reference to light and cheerful events, or troubled beginnings and happy endings, associated with classical Greek comedy. After the Latin translations of the 12th century, the term "comedy" thus gained a new semantic meaning in Medieval literature.
Ubayd Zakani introduced satire in Persian literature during the 14th century. His work is noted for its satire and obscene verses, often political or bawdy, and often cited in debates involving homosexual practices. He wrote the "Resaleh-ye Delgosha", as well as "Akhlaq al-Ashraf" ("Ethics of the Aristocracy") and the famous humorous fable "Masnavi Mush-O-Gorbeh" (Mouse and Cat), which was a political satire. His non-satirical serious classical verses have also been regarded as very well written, in league with the other great works of Persian literature. Between 1905 and 1911, Bibi Khatoon Astarabadi and other Iranian writers wrote notable satires.
Medieval Europe.
In the Early Middle Ages, examples of satire were the songs by Goliards or vagants now best known as an anthology called Carmina Burana and made famous as texts of a composition by the 20th-century composer Carl Orff. Satirical poetry is believed to have been popular, although little has survived. With the advent of the High Middle Ages and the birth of modern vernacular literature in the 12th century, it began to be used again, most notably by Chaucer. The disrespectful manner was considered "Unchristian" and ignored but for the moral satire, which mocked misbehaviour in Christian terms. Examples are "Livre des Manières" by (~1178), and some of Chaucer's "Canterbury Tales". The epos was mocked, and even the feudal society, but there was hardly a general interest in the genre.
Two major satirists of Europe in the Renaissance were Giovanni Boccaccio and François Rabelais. Other examples of Renaissance satire include "Till Eulenspiegel", "Reynard the Fox", Sebastian Brant's "Narrenschiff" (1494), Erasmus' "Moriae Encomium" (1509), Thomas More's "Utopia" (1516), and "Carajicomedia" (1519).
Early modern western satire.
Direct social commentary via satire returned with a vengeance in the 16th century, when farcical texts such as the works of François Rabelais tackled more serious issues (and incurred the wrath of the crown as a result).
The Elizabethan (i.e. 16th-century English) writers thought of satire as related to the notoriously rude, coarse and sharp satyr play. Elizabethan "satire" (typically in pamphlet form) therefore contains more straightforward abuse than subtle irony. The French Huguenot Isaac Casaubon pointed out in 1605 that satire in the Roman fashion was something altogether more civilised. Casaubon discovered and published Quintilian's writing and presented the original meaning of the term (satira, not satyr), and the sense of wittiness (reflecting the "dishfull of fruits") became more important again. 17th-century English satire once again aimed at the "amendment of vices" (Dryden).
In the 1590s a new wave of verse satire broke with the publication of Hall's "Virgidemiarum", six books of verse satires targeting everything from literary fads to corrupt noblemen. Although Donne had already circulated satires in manuscript, Hall's was the first real attempt in English at verse satire on the Juvenalian model. The success of his work combined with a national mood of disillusion in the last years of Elizabeth's reign triggered an avalanche of satire – much of it less conscious of classical models than Hall's — until the fashion was brought to an abrupt stop by censorship.
Age of Enlightenment.
The Age of Enlightenment, an intellectual movement in the 17th and 18th century advocating rationality, produced a great revival of satire in Britain. This was fuelled by the rise of partisan politics, with the formalisation of the Tory and Whig parties — and also, in 1714, by the formation of the Scriblerus Club, which included Alexander Pope, Jonathan Swift, John Gay, John Arbuthnot, Robert Harley, Thomas Parnell, and Henry St John, 1st Viscount Bolingbroke. This club included several of the notable satirists of early 18th century Britain. They focused their attention on Martinus Scriblerus, "an invented learned fool... whose work they attributed all that was tedious, narrow-minded, and pedantic in contemporary scholarship". In their hands astute and biting satire of institutions and individuals became a popular weapon. The turn to the 18th century was characterized by a switch from Horatian, soft, pseudo-satire, to biting "juvenal" satire.
Jonathan Swift was one of the greatest of Anglo-Irish satirists, and one of the first to practise modern journalistic satire. For instance, In his "A Modest Proposal" Swift suggests that Irish peasants be encouraged to sell their own children as food for the rich, as a solution to the "problem" of poverty. His purpose is of course to attack indifference to the plight of the desperately poor. In his book "Gulliver's Travels" he writes about the flaws in human society in general and English society in particular. John Dryden wrote an influential essay entitled "A Discourse Concerning the Original and Progress of Satire" that helped fix the definition of satire in the literary world. His satirical "Mac Flecknoe" was written in response to a rivalry with Thomas Shadwell and eventually inspired Alexander Pope to write his satirical "The Rape of the Lock". Other satirical works by Pope include the "Epistle to Dr Arbuthnot".
Alexander Pope b. May 21, 1688 was a satirist known for his Horatian satirist style and translation of the Illiad. Famous throughout and after the long 18th century, Pope died in 1744. Pope, in his "The Rape of the Lock", is delicately chiding society in a sly but polished voice by holding up a mirror to the follies and vanities of the upper class. Pope does not actively attack the self-important pomp of the British aristocracy, but rather presents it in such a way that gives the reader a new perspective from which to easily view the actions in the story as foolish and ridiculous. A mockery of the upper class, more delicate and lyrical than brutal, Pope nonetheless is able to effectively illuminate the moral degradation of society to the public. "The Rape of the Lock" assimilates the masterful qualities of a heroic epic, such as the "Iliad", which Pope was translating at the time of writing "The Rape of the Lock". However, Pope applied these qualities satirically to a seemingly petty egotistical elitist quarrel to prove his point wryly.
Daniel Defoe pursued a more journalistic type of satire, being famous for his "The True-Born Englishman" which mocks xenophobic patriotism, and "The Shortest-Way with the Dissenters" – advocating religious toleration by means of an ironical exaggeration of the highly intolerant attitudes of his time.
The pictorial satire of William Hogarth is a precursor to the development of political cartoons in 18th-century England. The medium developed under the direction of its greatest exponent, James Gillray from London. With his satirical works calling the king (George III), prime ministers and generals (especially Napoleon) to account, Gillray's wit and keen sense of the ridiculous made him the pre-eminent cartoonist of the era.
Ebenezer Cooke (1665–1732), author of "The Sot-Weed Factor" (1708), was among the first American colonialists to write literary satire. Benjamin Franklin (1706–1790) and others followed, using satire to shape an emerging nation's culture through its sense of the ridiculous.
Satire in Victorian England.
Several satiric papers competed for the public's attention in the Victorian era (1837–1901) and Edwardian period, such as "Punch" (1841) and "Fun" (1861).
Perhaps the most enduring examples of Victorian satire, however, are to be found in the Savoy Operas of Gilbert and Sullivan. In fact, in "The Yeomen of the Guard", a jester is given lines that paint a very neat picture of the method and purpose of the satirist, and might almost be taken as a statement of Gilbert's own intent:
Novelists such as Charles Dickens often used passages of satiric writing in their treatment of social issues.
In the same period, in the United States, Mark Twain (1835–1910) was a great American satirist: his novel "Huckleberry Finn" (1884) is set in the antebellum South, where the moral values Twain wishes to promote are completely turned on their heads. His hero, Huck, is a rather simple but goodhearted lad who is ashamed of the "sinful temptation" that leads him to help a runaway slave. In fact his conscience, warped by the distorted moral world he has grown up in, often bothers him most when he is at his best. Ironically, he is prepared to do good, believing it to be wrong.
Twain's younger contemporary Ambrose Bierce (1842–1913) gained notoriety as a cynic, pessimist and black humorist with his dark, bitterly ironic stories, many set during the American Civil War, which satirized the limitations of human perception and reason. Bierce's most famous work of satire is probably "The Devil's Dictionary" (1906), in which the definitions mock cant, hypocrisy and received wisdom.
20th century satire.
Karl Kraus is considered the first major European satirist since Jonathan Swift. In 20th century literature, satire was used by authors such as Aldous Huxley (1930s) and George Orwell (1940s), which under the inspiration of Zamyatin's Russian 1921 novel "We", made serious and even frightening commentaries on the dangers of the sweeping social changes taking place throughout Europe. Many social critics of this same time in the United States, such as Dorothy Parker and H. L. Mencken, used satire as their main weapon, and Mencken in particular is noted for having said that "one horse-laugh is worth ten thousand syllogisms" in the persuasion of the public to accept a criticism. Novelist Sinclair Lewis was known for his satirical stories such as "Main Street" (1920), "Babbitt" (1922), "Elmer Gantry" (1927; dedicated by Lewis to H.L. Menchen), and "It Can't Happen Here" (1935), and his books often explored and satirized contemporary American values. The film "The Great Dictator" (1940) by Charlie Chaplin is itself a parody of Adolf Hitler; Chaplin later declared that he would have not made the film if he had known about the concentration camps.
In the United States 1950s, satire was introduced into American stand-up comedy most prominently by Lenny Bruce and Mort Sahl. As they challenged the taboos and conventional wisdom of the time, were ostracized by the mass media establishment as "sick comedians". In the same period, Paul Krassner's magazine "The Realist" began publication, to become immensely popular during the 1960s and early 1970s among people in the counterculture; it had articles and cartoons that were savage, biting satires of politicians such as Lyndon Johnson and Richard Nixon, the Vietnam War, the Cold War and the War on Drugs. Prominent satiric stand-up comedian George Carlin acknowledged the influence "The Realist" had in his 1970s conversion to a satiric comedian.
A more humorous brand of satire enjoyed a renaissance in the UK in the early 1960s with the satire boom, led by such luminaries as Peter Cook, Alan Bennett, Jonathan Miller, and Dudley Moore, whose stage show "Beyond the Fringe" was a hit not only in Britain, but also in the United States. Other significant influences in 1960s British satire include David Frost, Eleanor Bron and the television program "That Was The Week That Was".
Joseph Heller's most famous work, "Catch-22" (1961), satirizes bureaucracy and the military, and is frequently cited as one of the greatest literary works of the twentieth century. The film "Dr. Strangelove" from 1964 was a popular satire on the Cold War.
Contemporary satire.
Contemporary popular usage of the term "satire" is often very imprecise. While satire often uses caricature and parody, by no means are all uses of these or other humorous devices, satiric. Refer to the careful definition of satire that heads this article.
Satire is used on many UK television programmes, particularly popular panel shows and quiz shows such as "Mock the Week" (2005) and "Have I Got News for You" (1990–ongoing). Similarly it is found on radio quiz shows such as "The News Quiz" (1977–ongoing) and "The Now Show" (1998–ongoing). One of the most-watched UK television shows of the 1980s and early 1990s, the puppet show "Spitting Image" was a satire of the royal family, politics, entertainment, sport and British culture of the era. Created by DMA Design in 1997, satire also features prominently in the British video game series "Grand Theft Auto".
The television program "South Park" (1997–ongoing) relies almost exclusively on satire to address issues in American culture, with episodes addressing anti-Semitism, militant atheism, homophobia, environmentalism, corporate culture, political correctness and anti-Catholicism, among many other issues.
Australian Chris Lilley produces comedy art in the style of mockumentaries ("", "Summer Heights High", "Angry Boys") and his work is often described as complex social satire.
Stephen Colbert’s television program, "The Colbert Report" (2005–14), is instructive in the methods of contemporary American satire. Colbert's character is an opinionated and self-righteous commentator who, in his TV interviews, interrupts people, points and wags his finger at them, and "unwittingly" uses a number of logical fallacies. In doing so, he demonstrates the principle of modern American political satire: the ridicule of the actions of politicians and other public figures by taking all their statements and purported beliefs to their furthest (supposedly) logical conclusion, thus revealing their perceived hypocrisy or absurdity.
The American sketch comedy television show "Saturday Night Live" is also known for its satirical impressions and parodies of prominent persons and politicians, among some of the most notable, their parodies of U.S. political figures Hillary Clinton and of Sarah Palin.
Other political satire includes various political causes in the past, including the relatively successful Polish Beer-Lovers' Party and the joke political candidates Molly the Dog and Brian Miner.
In the United Kingdom, a popular modern satirist is Sir Terry Pratchett, author of the internationally best-selling "Discworld" book series. One of the most well-known and controversial British satirists is Chris Morris, co-writer and director of "Four Lions".
In Canada, satire has become an important part of the comedy scene. Stephen Leacock was one of the best known early Canadian satirists, and in the early 20th century, he achieved fame by targeting the attitudes of small town life. In more recent years, Canada has had several prominent satirical television series and radio shows. Some, including "CODCO", "The Royal Canadian Air Farce", "This Is That", and "This Hour Has 22 Minutes" deal directly with current news stories and political figures, while others, like "History Bites" present contemporary social satire in the context of events and figures in history. The Canadian organization "Canada News Network" provides commentary on contemporary news events that are primarily Canadian in nature. Canadian songwriter Nancy White uses music as the vehicle for her satire, and her comic folk songs are regularly played on CBC Radio.
Cartoonists often use satire as well as straight humour. Al Capp's satirical comic strip "Li'l Abner" was censored in September 1947. The controversy, as reported in "Time", centred on Capp's portrayal of the US Senate. Said Edward Leech of Scripps-Howard, "We don't think it is good editing or sound citizenship to picture the Senate as an assemblage of freaks and crooks... boobs and undesirables." Walt Kelly's "Pogo" was likewise censored in 1952 over his overt satire of Senator Joe McCarthy, caricatured in his comic strip as "Simple J. Malarky". Garry Trudeau, whose comic strip "Doonesbury" focuses on satire of the political system, and provides a trademark cynical view on national events. Trudeau exemplifies humour mixed with criticism. For example, the character Mark Slackmeyer lamented that because he was not legally married to his partner, he was deprived of the "exquisite agony" of experiencing a nasty and painful divorce like heterosexuals. This, of course, satirized the claim that gay unions would denigrate the sanctity of heterosexual marriage.
Like some literary predecessors, many recent television satires contain strong elements of parody and caricature; for instance, the popular animated series "The Simpsons" and "South Park" both parody modern family and social life by taking their assumptions to the extreme; both have led to the creation of similar series. As well as the purely humorous effect of this sort of thing, they often strongly criticise various phenomena in politics, economic life, religion and many other aspects of society, and thus qualify as satirical. Due to their animated nature, these shows can easily use images of public figures and generally have greater freedom to do so than conventional shows using live actors.
Fake News is also a very popular form of contemporary satire, appearing in as wide an array of formats as the news media itself: print (e.g. "The Onion", "Canada News Network", "Private Eye"), "Not Your Homepage," radio (e.g. "On the Hour"), television (e.g. "The Day Today", "The Daily Show", "Brass Eye") and the web (e.g. Mindry.in, The Fruit Dish, Scunt News, Faking News, El Koshary Today, The Giant Napkin, Unconfirmed Sources and The "Onion"s website). Other satires are on the list of satirists and satires. Another internet-driven form of satire is to lampoon bad internet performers. An example of this is the Internet meme character Miranda Sings.
In an interview with "Wikinews", Sean Mills, President of "The Onion", said angry letters about their news parody always carried the same message. "It’s whatever affects that person", said Mills. "So it’s like, 'I love it when you make a joke about murder or rape, but if you talk about cancer, well my brother has cancer and that’s not funny to me.' Or someone else can say, 'Cancer’s "hilarious", but don’t talk about rape because my cousin got raped.' Those are rather extreme examples, but if it affects somebody personally, they tend to be more sensitive about it."
Zhou Libo, a comedian from Shanghai, is the most popular satirist in China. His humour has interests middle-class people and has sold out shows ever since his rise to fame.
Techniques.
Literary satire is usually written out of earlier satiric works, reprising previous conventions, commonplaces, stance, situations and tones of voice. Exaggeration is one of the most common satirical techniques.
Legal status.
For its nature and social role, satire has enjoyed in many societies a special freedom license to mock prominent individuals and institutions. In Germany, and Italy satire is protected by the constitution.
Since satire belongs to the realm of art and artistic expression, it benefits from broader lawfulness limits than mere freedom of information of journalistic kind. In some countries a specific "right to satire" is recognized and its limits go beyond the "right to report" of journalism and even the "right to criticize." Satire benefits not only of the protection to freedom of speech, but also to that to culture, and that to scientific and artistic production.
Censorship and criticism of satire.
Descriptions of satire's biting effect on its target include 'venomous', 'cutting', 'stinging', vitriol. Because satire often combines anger and humor, as well as the fact that it addresses and calls into question many controversial issues, it can be profoundly disturbing.
Typical arguments.
Because it is essentially ironic or sarcastic, satire is often misunderstood. A typical misunderstanding is to confuse the satirist with his persona.
Bad taste.
Common uncomprehending responses to satire include revulsion (accusations of poor taste, or that "it's just not funny" for instance), to the idea that the satirist actually does support the ideas, policies, or people he is attacking. For instance, at the time of its publication, many people misunderstood Swift’s purpose in "A Modest Proposal", assuming it to be a serious recommendation of economically motivated cannibalism.
Targeting the victim.
Some critics of Mark Twain see "Huckleberry Finn" as racist and offensive, missing the point that its author clearly intended it to be satire (racism being in fact only one of a number of Mark Twain's known concerns attacked in "Huckleberry Finn"). This same misconception was suffered by the main character of the 1960s British television comedy satire "Till Death Us Do Part". The character of Alf Garnett (played by Warren Mitchell) was created to poke fun at the kind of narrow-minded, racist, little Englander that Garnett represented. Instead, his character became a sort of anti-hero to people who actually agreed with his views. The same thing happened in regard to the main character in the American TV Show "All in the Family", Archie Bunker.
The Australian satirical television comedy show "The Chaser's War on Everything" has suffered repeated attacks based on various perceived interpretations of the "target" of its attacks. The "Make a Realistic Wish Foundation" sketch (June 2009), which attacked in classical satiric fashion the heartlessness of people who are reluctant to donate to charities, was widely interpreted as an attack on the Make a Wish Foundation, or even the terminally ill children helped by that organisation. Prime Minister of the time Kevin Rudd stated that The Chaser team "should hang their heads in shame". He went on to say that "I didn't see that but it's been described to me. ...But having a go at kids with a terminal illness is really beyond the pale, absolutely beyond the pale." Television station management suspended the show for two weeks and reduced the third season to eight episodes.
Romantic prejudice.
The romantic prejudice against satire is the belief spread by the romantic movement that satire is something unworthy of serious attention; this prejudice has held considerable influence to this day. Such prejudice extends to humor and everything that arouses laughter, which are often underestimated as frivolous and unworthy of serious study. For instance, humor is generally neglected as a topic of anthropological research and teaching.
History of opposition toward notable satires.
Because satire criticises in an ironic, essentially indirect way, it frequently escapes censorship in a way more direct criticism might not. Periodically, however, it runs into serious opposition, and people in power who perceive themselves as attacked attempt to censor it or prosecute its practitioners. In a classic example, Aristophanes was persecuted by the demagogue Cleon.
1599 book ban.
In 1599, the Archbishop of Canterbury John Whitgift and the Bishop of London Richard Bancroft, whose offices had the function of licensing books for publication in England, issued a decree banning verse satire. The decree, now known as the Bishops' Ban of 1599, ordered the burning of certain volumes of satire by John Marston, Thomas Middleton, Joseph Hall, and others; it also required histories and plays to be specially approved by a member of the Queen's Privy Council, and it prohibited the future printing of satire in verse.
The motives for the ban are obscure, particularly since some of the books banned had been licensed by the same authorities less than a year earlier. Various scholars have argued that the target was obscenity, libel, or sedition. It seems likely that lingering anxiety about the Martin Marprelate controversy, in which the bishops themselves had employed satirists, played a role; both Thomas Nashe and Gabriel Harvey, two of the key figures in that controversy, suffered a complete ban on all their works. In the event, though, the ban was little enforced, even by the licensing authority itself.
21st century polemics.
In 2005, the Jyllands-Posten Muhammad cartoons controversy caused global protests by offended Muslims and violent attacks with many fatalities in the Near East. It was not the first case of Muslim protests against criticism in the form of satire, but the Western world was surprised by the hostility of the reaction: Any country's flag in which a newspaper chose to publish the parodies was being burnt in a Near East country, then embassies were attacked, killing 139 people in mainly four countries; politicians throughout Europe agreed that satire was an aspect of the freedom of speech, and therefore to be a protected means of dialogue. Iran threatened to start an International Holocaust Cartoon Competition, which was immediately responded to by Jews with an Israeli Anti-Semitic Cartoons Contest.
In 2006 British comedian Sacha Baron Cohen released "Borat: Cultural Learnings of America for Make Benefit Glorious Nation of Kazakhstan", a "mockumentary" that satirized everyone, from high society to frat boys. The film was criticized by many. Although Baron Cohen is Jewish, some complained that it was antisemitic, and the government of Kazakhstan boycotted the film. The film itself had been a reaction to a longer quarrel between the government and the comedian.
In 2008, popular South African cartoonist and satirist Jonathan Shapiro (who is published under the pen name Zapiro) came under fire for depicting then-president of the ANC Jacob Zuma in the act of undressing in preparation for the implied rape of 'Lady Justice' which is held down by Zuma loyalists. The cartoon was drawn in response to Zuma's efforts to duck corruption charges, and the controversy was heightened by the fact that Zuma was himself acquitted of rape in May 2006. In February 2009, the South African Broadcasting Corporation, viewed by some opposition parties as the mouthpiece of the governing ANC, shelved a satirical TV show created by Shapiro, and in May 2009 the broadcaster pulled a documentary about political satire (featuring Shapiro among others) for the second time, hours before scheduled broadcast. Apartheid South Africa also had a long history of censorship.
On December 29, 2009, Samsung sued Mike Breen, and the "Korea Times" for $1 million, claiming criminal defamation over a satirical column published on Christmas Day, 2009.
On April 29, 2015, the UK Independence Party (UKIP) requested Kent Police investigate the BBC, claiming that comments made about Party leader Nigel Farage by a panelist on the comedy show "Have I Got News For You" might hinder his chances of success in the general election (which would take place a week later), and claimed the BBC breached the Representation of the People Act. Kent Police rebuffed the request to open an investigation, and the BBC released a statement, "Britain has a proud tradition of satire, and everyone knows that the contributors on "Have I Got News for You" regularly make jokes at the expense of politicians of all parties."
Satirical prophecy.
Satire is occasionally prophetic: the jokes precede actual events. Among the eminent examples are:

</doc>
<doc id="26792" url="https://en.wikipedia.org/wiki?curid=26792" title="Samuel Butler (poet)">
Samuel Butler (poet)

Samuel Butler (baptized 14 February 1613 – 25 September 1680) was a poet and satirist. He is remembered now chiefly for a long satirical poem entitled "Hudibras".
Biography.
Samuel Butler was born in Strensham, Worcestershire, and was the son of a farmer and churchwarden, also named Samuel. His date of birth is unknown, but there is documentary evidence for the date of his baptism of 14 February. The date of Butler's baptism is given as 8 February by Treadway Russell Nash in his 1793 edition of "Hudibras". Nash had already mentioned Butler in his "Collections for a History of Worcestershire" (1781), and perhaps because the latter date seemed to be a revised account, it has been repeated by many writers and editors. However, The parish register of Strensham records under the year 1612: "Item was christened Samuell Butler the sonne of Samuell Butler the xiiijth of February anno ut supra". Lady Day, 25 March, was New Year's Day in England at the time, so the year of his baptism was 1613 according to the modern Gregorian calendar. Nash also claims in his 1793 edition of "Hudibras" that Butler's father entered his son's baptism into the register, an error that was also repeated in later publications; however, the entry was clearly written by a different hand.
He was educated at the King's School, Worcester, under Henry Bright whose teaching is recorded favourably by Thomas Fuller, a contemporary writer, in his "Worthies of England". In early youth he was a servant to the Countess of Kent. Through Lady Kent he met her steward, the jurist John Selden who influenced his later writings. He also tried his hand at painting but was reportedly not very good at it; one of his editors reporting that "his pictures served to stop windows and save the tax" (on window glass).
After the Restoration he became secretary, or steward, to Richard Vaughan, 2nd Earl of Carbery, Lord President of Wales, which entailed living at least a year in Ludlow, Shropshire, until January 1662 while he was paying craftsmen working on repairing the castle there. In late 1662 the first part of "Hudibras", which he began writing when lodging at Holborn, London, in 1658 and continued to work on while in Ludlow, was published, and the other two in 1664 and 1678 respectively. One early purchaser of the first two parts was Samuel Pepys. While the diarist acknowledged that the book was the "greatest fashion" he could not see why it was found to be so witty.
Despite the popularity of "Hudibras", Butler was not offered a place at Court. However, Butler is thought to have been in the employment of the Duke of Buckingham in the summer of 1670, and accompanied him on a diplomatic mission to France. Butler also received financial support in the form of a grant from King Charles II.
Butler was buried at St. Paul's, Covent Garden. Aubrey in "Brief Lives" describes his grave as "being in the north part next to the church at the east end.. 2 yards distant from the pillaster of the dore". Also, a monument to him was placed in Westminster Abbey in 1732 by a printer with the surname Barber, and the Lord Mayor of London. There is also a memorial plaque to him in the small village church of Strensham, Worcestershire, near the town of Upton upon Severn, his birthplace.
"Hudibras".
"Hudibras" is directed against religious sectarianism. The poem was very popular in its time, and several of its phrases have passed into the dictionary. It was sufficiently popular to spawn imitators. "Hudibras" takes some of its characterization from "Don Quixote" but unlike that work, it has many more references to personalities and events of the day. Butler was also influenced by satirists such as John Skelton and Paul Scarron's "Virgile travesti"; a satire on classical literature, particularly Virgil.
"Hudibras" was reprinted many times in the centuries following Butler's death. Two of the more noteworthy editions are those edited by Zachery Grey (1752) and Treadway Russell Nash (1793). The standard edition of the work was edited by John Wilders (1967).
Other writings.
Most of his other writings never saw print until they were collected and published by Robert Thyer in 1759. Butler wrote many short biographies, epigrams and verses the earliest surviving from 1644. Of his verses, the best known is "The Elephant on the Moon", about a mouse trapped in a telescope, a satire on Sir Paul Neale of the Royal Society. Butler's taste for the mock heroic is shown by another early poem "Cynarctomachy", or Battle between Bear and Dogs, which is both a homage to and a parody of a Greek poem ascribed to Homer, "Batrachomyomachia". His supposed lack of money later in life is strange as he had numerous unpublished works which could have offered him income including a set of Theophrastan character sketches which were not printed until 1759. Many other works are dubiously attributed to him.

</doc>
<doc id="26794" url="https://en.wikipedia.org/wiki?curid=26794" title="List of science fiction and fantasy artists">
List of science fiction and fantasy artists

This is a list of science fiction and fantasy artists, 20th- and 21st-century artists who have created book covers or interior illustrations for books, or who have published their own books or comic books of fantastic art with science fiction or fantasy themes. Artists known exclusively for their work in comic books are not included. Many of the artists are known for their work in both the fantasy and sf fields. Artists who have won the Hugo Award, the World Fantasy Award, or the Chesley Award are noted, as are inductees into the Science Fiction Hall of Fame.

</doc>
<doc id="26795" url="https://en.wikipedia.org/wiki?curid=26795" title="Saxophone">
Saxophone

The saxophone (also referred to as the sax) is a family of woodwind instruments. Saxophones are usually made of brass and played with a single-reed mouthpiece similar to that of the clarinet. The saxophone family was invented by the Belgian instrument maker Adolphe Sax in 1840. Adolphe Sax wanted to create a group or series of instruments that would be the most powerful and vocal of the woodwinds, and the most adaptive of the brass instruments, that would fill the vacant middle ground between the two sections. He patented the saxophone on June 28, 1846, in two groups of seven instruments each. Each series consisted of instruments of various sizes in alternating transposition. The series pitched in B and E, designed for military bands, have proved extremely popular and most saxophones encountered today are from this series. Instruments from the so-called "orchestral" series, pitched in C and F, never gained a foothold, and the B and E instruments have now replaced the C and F instruments when the saxophone is used in the orchestra.
The saxophone is used in classical music (such as concert bands, chamber music, and solo repertoire), military bands (such as military concert bands, marching bands, etc.), marching bands, and jazz (such as big bands, jazz combos, etc.). Saxophone players are called "saxophonists".
History.
The saxophone was developed in 1846 by Adolphe Sax, a Belgian instrument maker, flautist, and clarinetist born in Dinant and originally based in Brussels, he moved to Paris in 1842 to establish his musical instrument business. Prior to his work on the saxophone, he had made several improvements to the bass clarinet by improving its keywork and acoustics and extending its lower range. Sax was also a maker of the then-popular ophicleide, a large conical brass instrument in the bass register with keys similar to a woodwind instrument. His experience with these two instruments allowed him to develop the skills and technologies needed to make the first saxophones. As an outgrowth of his work improving the bass clarinet, Sax began developing an instrument with the projection of a brass instrument and the agility of a woodwind. He wanted it to overblow at the octave, unlike the clarinet, which rises in pitch by a twelfth when overblown. An instrument that overblew at the octave, would have identical fingering for both registers.
Sax created an instrument with a single-reed mouthpiece like a clarinet, conical brass body like an ophicleide, and some acoustic properties of both the horn and the clarinet.
Having constructed saxophones in several sizes in the early 1840s, Sax applied for, and received, a 15-year patent for the instrument on June 28, 1846. The patent encompassed 14 versions of the fundamental design, split into two categories of seven instruments each, and ranging from sopranino to contrabass. Although the instruments transposed at either F or C have been considered "orchestral", there is no evidence that Sax intended this. As only 3 percent of Sax's surviving production were pitched in F and C, and as contemporary composers used the E alto and B bass saxophone freely in orchestral music, it is almost certain that Sax experimented to find the most suitable keys for these instruments, settling upon instruments alternating between E and B rather than those pitched in F or C, for reasons of tone and economy (the saxophones were the most expensive wind instruments of their day). The C soprano saxophone was the only instrument to sound at concert pitch. All the instruments were given an initial written range from the B below the treble staff to the F, one space above the three ledger lines above staff, giving each saxophone a range of two and a half octaves.
Sax's patent expired in 1866; thereafter, numerous saxophonists and instrument manufacturers implemented their own improvements to the design and keywork. The first substantial modification was by a French manufacturer who extended the bell slightly and added an extra key to extend the range downwards by one semitone to B. It is suspected that Sax himself may have attempted this modification. This extension is now commonplace in almost all modern designs, along with other minor changes such as added keys for alternate fingerings. Using alternate fingerings will allow the player to play easily and as fast as they can. The player may also use alternate fingerings to bend the pitch. Some of the alternate fingerings are good for trilling, scales, and big interval jumps.
Sax's original keywork, which was based on the Triebert system 3 oboe for the left hand and the Boehm clarinet for the right, was very simplistic and made playing some legato passages and wide intervals extremely difficult to finger, so numerous developers added extra keys and alternate fingerings to make chromatic playing less difficult. While the early saxophone had two separate octave vents to assist in the playing of the upper registers just as modern instruments do, players of Sax's original design had to operate these via two separate octave keys operated by the left thumb. A substantial advancement in saxophone keywork was the development of a method by which the left thumb operates both tone holes with a single octave key, which is now universal on modern saxophones. Further developments were made by Selmer in the 1930s and 40s, including offsetting tone holes and revamping the octave key mechanism, beginning with their balanced action instruments and continuing through their celebrated Mark VI line. One of the most radical, however temporary, revisions of saxophone keywork was made in the 1950s by M. Houvenaghel of Paris, who completely redeveloped the mechanics of the system to allow a number of notes (C, B, A, G, F and E) to be flattened by a semitone simply by pressing the right middle finger. This enables a chromatic scale to be played over two octaves simply by playing the diatonic scale combined with alternately raising and lowering this one digit. However, this keywork never gained much popularity, and is no longer in use.
Uses.
Uses in military bands and classical music.
The saxophone first gained popularity in one of the uses it was designed for: the military band. Although the instrument was studiously ignored in Germany at first, French and Belgian military bands took full advantage of the instrument that Sax had designed. Most French and Belgian military bands incorporate at least a quartet of saxophones comprising at least the E baritone, B tenor, E alto and B soprano. These four instruments have proved the most popular of all of Sax's creations, with the E contrabass and B bass usually considered impractically large and the E sopranino insufficiently powerful. British military bands tend to include at minimum two saxophonists on the alto and tenor. Today, the saxophone is used in military bands all around the world.
The saxophone was subsequently introduced into the concert band, which generally calls for the E alto saxophone, the B tenor saxophone, and the E baritone saxophone. The typical high-level concert band includes two altos, one tenor, and one baritone. The B soprano saxophone is also occasionally used, in which case it is normally played by the first alto saxophonist. The bass saxophone in B is called for in some concert band music (especially music by Percy Grainger).
The saxophone is used in chamber music, such as the saxophone quartet, reed quintet, and other chamber combinations of instruments.
The classical saxophone quartet consists of the soprano saxophone, alto saxophone, tenor saxophone, and baritone saxophone. There is a repertoire of classical compositions and arrangements for the SATB instrumentation dating back to the nineteenth century, particularly by French composers who knew Adolphe Sax. Classical saxophone quartets include Quatuor Habanera, the h2 quartet, Raschèr Saxophone Quartet, the Aurelia Saxophone Quartet, the New Century Saxophone Quartet, and others. Historically, the quartets led by Marcel Mule and Daniel Deffayet, saxophone professors at the Conservatoire de Paris, were started in 1928 and 1953, respectively, and were highly regarded. The Mule quartet is often considered the prototype for future quartets, due the level of virtuosity demonstrated by its members and its central role in the development of the quartet repertoire. However, organised quartets did exist before Mule's ensemble, the prime example being the quartet headed by Eduard Lefebre (1834–1911), former soloist with the Sousa band, in the United States "c." 1904–1911. Other ensembles most likely existed at this time as part of the saxophone sections of the many touring professional bands that existed in the late 19th and early 20th centuries.
The saxophone is a member of the reed quintet. The reed quintet consists of an oboe, a clarinet, a saxophone, a bass clarinet, and a bassoon.
In the 20th and 21st centuries, the saxophone has found increased popularity in the symphony orchestra. In one or other size, the instrument has also been found as a useful accompaniment to genres as wide-ranging as opera and choral music. Many musical theatre scores include parts for the saxophone, sometimes doubling another woodwind or brass instrument. In this way, the sax serves as a middle point between other woodwinds and the brass section, helping to blend the two sections.
Uses in jazz and popular music.
The saxophone is also commonly used in jazz music, where the saxophone is one of the signature sounds. Beginning in the early 20th century, the saxophone became popular in dance orchestras, which were not jazz ensembles but influenced the format of the big swing era bands that were soon to follow. The arrival of the saxophone as a jazz instrument is attributed to tenor saxophonist Coleman Hawkins' stint with the Fletcher Henderson Orchestra starting in 1923. The saxophone was soon embraced by Chicago style musicians who added it, along with chordal instruments such as a piano, banjo, or guitar, to the trumpet-clarinet-trombone-bass-drums ensemble format inherited from New Orleans jazz. The Duke Ellington Orchestra of the late 1920s featured saxophone-based ensemble sounds and solos by saxophonists Otto Hardwick, Johnny Hodges, and Harry Carney. The swing bands of the 1930s utilized arrangements of saxophone and brass sections playing off each other in call-response patterns. The influence of tenor saxophonist Lester Young with the Count Basie Orchestra in the late 1930s and the tremendous popularity of Coleman Hawkins' 1939 recording of Body and Soul marked the saxophone as an influence on jazz equal to that of the trumpet, which had been the defining instrument of jazz since its beginnings in New Orleans. But the greatest influence of the saxophone on jazz was to occur just a few years later, as alto saxophonist Charlie Parker became an icon of the bebop revolution that influenced generations of jazz musicians. The small group format of bebop and post-bebop jazz ensembles, typically with one to three lead instruments(usually including a saxophone), a chordal instrument, bass, and drums, gained ascendancy in the 1940s as musicians emphasized extended exploration utilizing the new harmonic and melodic freedoms that bebop provided, thanks to Charlie Parker and a few other pioneers such as Dizzy Gillespie, Thelonious Monk, and Bud Powell.
In addition to the colossal brilliance and virtuosity of Parker, the alto sax was also popularized in the 1950s by top saxophonists such as Sonny Stitt, Cannonball Adderley, Sonny Criss and Paul Desmond (latter of the Dave Brubeck Quartet). The tenor sax, which some consider to be the more popular form of saxophone as a solo instrument in jazz, was popularized by jazz greats such as Lester Young, Coleman Hawkins, Dexter Gordon, John Coltrane, Sonny Rollins, Stan Getz and Zoot Sims. The baritone sax, featured more in big bands (notably by Harry Carney in the Duke Ellington Orchestra) and larger ensembles than as a solo instrument, was popularized in jazz as a solo instrument within small groups by musicians such as Serge Chaloff, Gerry Mulligan, Pepper Adams and Leo Parker. The soprano saxophone was popularized by Sidney Bechet in early jazz, but then largely fell out of favor on the jazz scene until John Coltrane began to feature the instrument. Popular smooth jazz/contemporary pop musician Kenny G also features the soprano sax as his principal instrument.
Saxophone players such as John Coltrane, Ornette Coleman, Sam Rivers and Pharoah Sanders again defined the forefront of creative exploration with the avant-garde movement of the 1960s. Modal, harmolodic, and free jazz again removed boundaries and the new space was explored with every device that saxophone players could conceive of. Sheets of sound, tonal exploration, upper harmonics, and multiphonics were hallmarks of the creative possibilities that saxophones offered in the new realm. One lasting influence of the avant-garde movement has been the exploration of non-western ethnic sounds on the saxophone, for example, the Africanized sounds used by Pharoah Sanders. The devices of the avant-garde movement have continued to be influential in music that challenges the boundaries between avant-garde and other categories of jazz, such as that of alto saxophonists Steve Coleman and Greg Osby.
The jazz saxophone quartet is usually made up of one B soprano, one E alto, one B tenor and one E baritone (SATB). On occasion, the soprano is replaced with a second alto sax (AATB); a few professional saxophone quartets have featured non-standard instrumentation, such as James Fei's Alto Quartet (four altos) and Hamiet Bluiett's Bluiett Baritone Nation (four baritones). Recently, the World Saxophone Quartet has become known as the preeminent jazz saxophone quartet.
The saxophone, as a solo instrument or as part of a horn section, may also be heard in blues, soul music, rhythm and blues, reggae, ska, funk, rock and roll and other forms of popular music. Some players of these genres include King Curtis, Maceo Parker, Bobby Keys, Clarence Clemons, the Memphis Horns, and the Phenix Horns.
The saxophone family.
The primary (military band) saxophone family alternates instruments in B and E. The other (orchestral) family patented by Sax, alternating instruments in C and F, has always been marginal, although some manufacturers tried to popularise the soprano in C (or C soprano saxophone), the alto in F (or mezzo-soprano saxophone), and the tenor in C (or C melody saxophone) early in the twentieth century. The C melody enjoyed some success in the late 1920s and early 1930s as a parlor instrument. One company has recently revived production of the C soprano and C melody. Instruments in F are rare.
Description.
The saxophone consists of an approximately conical tube, usually of thin brass, flared at the tip to form a bell. At intervals along the tube are between 20 and 23 tone holes of varying size and two very small vent holes to assist the playing of the upper register. These holes are covered by keys (also known as pad cups), containing soft leather pads, which are closed to produce an airtight seal. At rest some of the holes stand open and others are closed. The keys are activated by keytouches pressed by the fingers, either directly on the pad cup or connected to it with levers, either directly or with joints called "linkages." The right thumb sits under a thumb rest to stabilize and balance the saxophone, while the weight of most saxophones is supported by a neckstrap attached to a strap ring on the rear of the body of the instrument. The fingering for the saxophone is a combination of that of the oboe with the Boehm system, and is very similar to the flute or the upper register of the clarinet. Instruments that play to low A have a left thumb key for that note.
The simplest design of saxophone is a straight conical tube, and the sopranino and soprano saxophones are usually of this straight design. However, as the lower-pitched instruments would be unacceptably long if straight, for ergonomic reasons, the larger instruments usually incorporate a U-bend ("bow") at, or slightly above, the third-lowest tone hole. As this would cause the bell of the instrument to point almost directly upward, the end of the instrument is either beveled or tilted slightly forward. This U-shape has become a distinctive feature of the saxophone family, to the extent that soprano and even sopranino saxes are sometimes made in the curved style, even though not strictly necessary. By contrast, tenors and even baritones have occasionally been made in the straight style. Most commonly, however, the alto and tenor saxophones incorporate a detachable, curved "neck" above the highest tone hole, directing the mouthpiece to the player's mouth while the instrument is held in a playing stance. The baritone, bass and contrabass saxophones accommodate the length of the bore with extra bows and right angle bends between the main body and the mouthpiece.
Materials.
Most saxophones, both past and present, are made from brass. Despite this, they are categorized as woodwind instruments rather than brass, as the sound waves are produced by an oscillating wood reed, not the player's lips against a mouthpiece as in a brass instrument, and because different pitches are produced by breath wind passing opening and closing keys. The screw pins that connect the rods to the posts, as well as the needle and leaf springs that cause the keys to return to their rest position after being released, are generally made of blued or stainless steel. Since 1920, most saxophones have 'key touches' (smooth replaceable pieces placed where the fingers touch the instrument) made from either plastic or mother of pearl. Recently, some saxophones are offered with abalone or stone keytouches.
Other materials have been tried with varying degrees of success, such as the 1950s Grafton plastic alto saxophone and its recent successor, the polycarbonate saxophone, VibratoSax. There is also the wooden Sawat saxophone created in Thailand on a small scale. Recent years have seen use higher copper alloys substituted for the "yellow brass" or "cartridge brass" that are most common, for visual and tonal effect. Yanagisawa's 902 and 992 series saxophones are made with phosphor bronze, which is claimed to offer slightly different, more "vintage" tonal qualities from the brass 901 and 991 models of identical design. Other saxophones made of high copper alloys are sold under the brands Chateau, Kessler, Saxgourmet, and Bauhaus Walstein. Yanagisawa and other manufacturers, starting with the King Super 20 around 1950, have made saxophone necks, bells, or entire instruments from sterling silver. Keilwerth and P. Mauriat have made saxes with a nickel silver body. Opinions vary on the significance of body materials to sound. With the exception of the identical brass and phosphor bronze Yanagisawa models, opportunities to isolate body materials from other variables in design and construction are lacking.
Prior to final assembly, the manufacturers usually apply a thin coating of clear or colored acrylic lacquer, or silver plate, over the bare brass. The lacquer or plating serves to protect the brass from oxidation, and maintains its shiny appearance. Several different types and colors of surface finish have been used over the years. It is also possible to plate the instrument with nickel or gold, and a number of gold-plated saxophones have been produced. Plating saxophones with gold is an expensive process because gold does not adhere directly to brass. As a result, the brass is first plated with silver, then gold.
Some players, sellers, and repair technicians argue that the type of lacquer or plating, or absence thereof, may enhance an instrument's tone quality. The possible effects of different finishes on tone are difficult to isolate from the other variables that affect an instrument's tone colors. In any case, what constitutes a pleasing tone is a matter of personal preference.
Mouthpiece and reed.
The saxophone uses a single-reed mouthpiece similar to that of the clarinet. Most saxophonists use reeds made from "Arundo donax" cane, but since the 20th century some have also been made of fiberglass and other composite materials. Saxophone reeds are proportioned slightly differently from clarinet reeds, being wider for the same length, although some soprano saxophonists use clarinet reeds on the soprano saxophone. Each size of saxophone (alto, tenor, etc.) uses a different size of reed. Reeds are commercially available in a vast array of brands, styles, and strengths. Players experiment with reeds of different strength (hardnesses) and material to find which strength and cut suits their mouthpiece, embouchure, physiology, and playing style.
The saxophone mouthpiece is larger than that of the clarinet, has a wider inner chamber, and lacks the cork-covered tenon of a clarinet mouthpiece because the saxophone neck inserts into the mouthpiece whereas the clarinet mouthpiece piece is inserted into the barrel. Saxophone and clarinet embouchures differ from each other in firmness, position of the lower lip, and range of entry angles. The "long tones" exercise is used to develop embouchure, along with airstream and breath control.
Mouthpieces come in a wide variety of materials, including vulcanized rubber (sometimes called hard rubber or ebonite), plastic, and metals such as bronze or surgical steel. Less common materials that have been used include wood, glass, crystal, porcelain, and even bone. According to Larry Teal, the mouthpiece material has little, if any, effect on the sound, and the physical dimensions give a mouthpiece its tone colour. There are examples of "dark" sounding metal pieces and "bright" sounding hard rubber pieces – Marcel Mule, for example, used a metal mouthpiece to perform classical music. Some contend that instability at the mouthpiece/neck connection moves harmonic frequencies off series with the fundamental frequency and each other, resulting in a "spread" sound, and that the weight of a metal mouthpiece counteracts that instability, increasing tonal "focus." Mouthpiece design has a profound impact on tone.
Early mouthpieces were designed to produce a warm and round sound for classical playing. Among classical mouthpieces, those with a concave ("excavated") chamber are more true to Adolphe Sax's original design; these provide a softer or less piercing tone favored by some saxophonists, including students of Sigurd Raschèr, for classical playing. Saxophonists who follow the French school of classical saxophone playing, influenced by Marcel Mule, generally use mouthpieces with smaller chambers than Rascher style mouthpieces. The use of the saxophone in dance orchestras and jazz ensembles put a premium on dynamic range, projection, and tonal richness, leading to rapid innovation in chamber shape and tip design, and metal construction. At the opposite extreme from the classical mouthpieces are those with a small chamber and a low clearance above the reed between the tip and the chamber, called high baffle. These produce a bright sound with maximum projection, suitable for having a sound stand out among amplified instruments and typical of modern pop and smooth jazz. Most saxophonists who play different styles have a mouthpiece suited for each style.
Unusual saxophone variants.
A number of saxes and saxophone-related instruments have appeared since Sax's original work, most with no significant success. These include the saxello, essentially a straight B soprano, but with a slightly curved neck and tipped bell; the straight alto; and the straight B tenor. Since a straight-bore tenor is approximately five feet long, the cumbersome size of such a design makes it almost impossible to either play or transport. "King" Saxellos, made by the H. N. White Company in the 1920s, now command prices up to US$4,000. A number of companies, including Keilwerth, Rampone & Cazzani ("altello" model), L.A. Sax and Sax Dakota USA, are marketing straight-bore, tipped-bell soprano saxophones as saxellos (or "saxello sopranos").
The "contralto" saxophone, similar in size to the orchestral soprano, was developed in the late 20th century by California instrument maker Jim Schmidt. This instrument has a larger bore and a new fingering system, and does not resemble the C melody instrument except for its key and register. Another new arrival to the sax scene is the soprillo sax, a piccolo-sized straight instrument with the upper speaker hole built into the mouthpiece. The instrument, which extends Sax's original family, as it is pitched a full octave higher than the B soprano sax, is manufactured by Benedikt Eppelsheim, of Munich, Germany. There is a rare prototype slide tenor saxophone, but few were ever made. One company that produced a slide soprano saxophone was Reiffel & Husted, Chicago, ca. 1922 (catalog NMM 5385).
Two of these variants were championed by jazz musician Rahsaan Roland Kirk, who called his straight Buescher alto a stritch and his modified saxello a manzello; the latter featured a larger-than-usual bell and modified key work. Among some saxophonists, Kirk's terms have taken on a life of their own in that it is believed that these were "special" or "new" saxophones that might still be available. Though rare, the Buescher straight alto was a production item instrument while the manzello was indeed a saxello with a custom-made bell.
Another unusual variant of the saxophone was the "Conn-O-Sax", a straight-conical bore instrument in F (one step above the E alto) with a slightly curved neck and spherical bell. The instrument, which combined a saxophone bore and keys with a bell shaped similar to that of a heckelphone, was intended to imitate the timbre of the English horn and was produced only in 1929 and 1930. The instrument had a key range from low A to high G. Fewer than 100 Conn-O-Saxes are in existence, and they are eagerly sought by collectors.
The tubax, developed in 1999 by the German instrument maker Benedikt Eppelsheim, plays the same range, and with the same fingering, as the E contrabass saxophone; its bore, however, is narrower than that of a contrabass saxophone, making for a more compact instrument with a "reedier" tone (akin to the double-reed contrabass sarrusophone). It can be played with the smaller (and more commonly available) baritone saxophone mouthpiece and reeds. Eppelsheim has also produced subcontrabass tubaxes in C and B, the latter being the lowest saxophone ever made. Among the most recent developments is the aulochrome, a double soprano saxophone invented by Belgian instrument maker François Louis in 2001.
The fingering scheme of the saxophone, which has had only minor changes since the instrument's original invention, has presented inherent acoustic problems related to closed keys below the first open tonehole that affect response of, and slightly muffle, some notes. There is also a lack of tactile consistency moving between key centers. In other words, extra effort is required from the player to adjust modes of muscle memory when moving between key centers. Two efforts to remedy the acoustic problems and awkward aspects of the original fingering system are noteworthy.
The Leblanc Rationale and System saxophones had key mechanics designed to remedy the acoustic problems associated with closed keys below the first open tonehole. They also enabled the player to make half-step shifts of scales by depressing one key while keeping the rest of the fingering consistent with that of the fingering a half step away (which could also trip up players used to certain alternate fingerings on a regular saxophone). Some Leblanc System features were built into the Vito Model 35 saxophones of the 1950s and 1960s. The acceptance of what was arguably a superior system was impaired by the adjustment required of players switching between System and non-System horns, and the added costs associated with the added complexity of certain key mechanisms.
The chromatic, or linear fingering, saxophone is a project of instrument designer and builder Jim Schmidt, developing a horn maximizing tactile and logical consistency between every interval on the horn regardless of key, and avoiding the acoustic problems associated closed keys below the first open tone hole. Several working prototypes have been built and presented at trade shows. Production of this fascinating and expensive saxophone is on an individual order basis according to the designer's website referenced above.
Related instruments.
Although not true saxophones, inexpensive keyless folk versions of the saxophone made of bamboo (recalls a Chalumeau) were developed in the 20th century by instrument makers in Hawaii, Jamaica, Thailand, Indonesia, Ethiopia, and Argentina. The Hawaiian instrument, called a xaphoon, was invented during the 1970s and is also marketed as a "bamboo sax," although its cylindrical bore more closely resembles that of a clarinet, and its lack of any keywork makes it more akin to a recorder. Jamaica's best known exponent of a similar type of homemade bamboo "saxophone" was the mento musician and instrument maker 'Sugar Belly' (William Walker). In the Minahasa region of the Indonesian island of Sulawesi, there exist entire bands made up of bamboo "saxophones" and "brass" instruments of various sizes. These instruments are imitations of European instruments, made using local materials. Very similar instruments are produced in Thailand. In Argentina, Ángel Sampedro del Río and Mariana García have produced bamboo saxophones of various sizes since 1985, the larger of which have bamboo keys to allow for the playing of lower notes.
Composition.
Music for most saxophones is usually notated using treble clef. The standard written range extends from a B below the staff to an F or F three ledger lines above the staff. Most, if not all, intermediate and professional saxophones made today are built with F keys, with F included on even student instruments.
There are many models of soprano saxophone that have a key for high G, and most modern models of baritone saxophone have an extended bore and key to produce low A; it is also possible to play a low A on any saxophone by blocking the end of the bell, usually with the foot or inside of the left thigh. Low A keys however were not limited to just the baritone saxophone. For a short time Selmer Paris produced mark VI alto saxophones with the low A key. Notes above F are considered part of the altissimo register of any sax, and can be produced using advanced embouchure techniques and fingering combinations. Sax himself had mastered these techniques; he demonstrated the instrument as having a range of just beyond three octaves up to a (written) high B4. Modern saxophone players have extended this range to over 4 octaves on tenor and alto.
Because all saxophones use the same key arrangement and fingering to produce a given notated pitch, it is not difficult for a competent player to switch among the various sizes when the music has been suitably transposed, and many do so. Since the baritone and alto are pitched in E, players can read concert pitch music notated in the bass clef by reading it as if it were treble clef and adding three sharps to the key signature. This process, referred to as "clef substitution", makes it possible for the Eb instruments to play from parts written for bassoon, tuba, trombone, or string bass. This can be useful if a band or orchestra lacks one of those instruments.

</doc>
<doc id="26797" url="https://en.wikipedia.org/wiki?curid=26797" title="Sackbut">
Sackbut

A sackbut is a type of trombone from the Renaissance and Baroque eras, characterised by a telescopic slide that is used to vary the length of the tube to change pitch. Unlike the earlier slide trumpet from which it evolved, the sackbut possesses a "double" slide, which allows for playing scales in a lower range. Sackbuts adjust tuning at the joint between the bell and slide. The sackbut differs from modern trombones by its smaller, more cylindrically-proportioned bore, its less-flared bell, and in the lack of a leadpipe, water key, slide lock, and tuning slide on the bell curve.
Terminological history.
The first reference to a slide instrument was probably "trompette des ménestrels", first found in Burgundy in the 1420s and later in other regions of Europe. The name distinguished the instrument from the "trompettes de guerre" (war trumpets), which were of fixed length.
The next word to appear in the 15th century that implied a slide was the "sackbut" group of words. There are two theories for the sources: it is either derived from the Middle French "sacquer" (to pull) and "bouter" (to push) or from the Spanish "sacar" (to draw or pull) and "bucha" (a tube or pipe). The term survives in numerous English spelling variations including sacbut, sackbutte, sagbut, shagbolt, sacabushe, shakbusse and shakbusshe.
Closely related to "sackbut" was the name used in France: "sacqueboute" and in Spain, where it was "sacabuche". These terms were used in England and France until the 18th century.
In Scotland in 1538 the slide instrument is referred to as "draucht trumpet" (drawn trumpet) as opposed to a "weir trumpet" (war trumpet), which had a fixed length.
In Germany, the original word was "Posaune", appearing about 1450 and is still used today. This (as well as "bason") derives from "busine," which is Latinate and meant straight trumpet.
In Italy it was (and remains) "trombone", which derived from trumpet in the Latin "tromba" or "drompten", used in the Low Countries. The first records of it being used are around 1440, but it is not clear whether this was just a nickname for a trumpet player. In 1487 a writer links the words "trompone" and "sacqueboute" and mentions the instrument as playing the contratenor part in a danceband.
History.
The trombone developed from the trumpet. Up until 1375 trumpets were simply a long straight tube with a bell flare.
There are various uses of "sackbut"-like words in the Bible, which has led to a faulty translation from the Latin bible that suggested the trombones date back as far as 600 BC, but there is no evidence of slides at this time.
From 1375 the iconography sees trumpets being made with bends, and some in 'S' shapes. Around 1400 we see the "loop"-shaped trumpet appear in paintings and at some point in the 15th century, a single slide was added. This slide trumpet was known as a "trompette des ménestrels" in the alta capella bands.
The earliest clear evidence of a double slide instrument is in a fresco painting by Filippino Lippi in Rome, "The Assumption of the Virgin", dating from 1488–93.
From the 15th to the 19th centuries, the instrument designs changed very little overall, apart from a slight widening of the bell in classical era. Since the 19th century, trombone bore sizes and bells have increased significantly.
It was one of the most important instruments in Baroque polychoral works, along with the cornett and organ.
Instrument sizes.
Sackbuts come in several sizes. According to Michael Praetorius, these were:
The pitch of the trombones has (notionally) moved up a semi-tone since the 17th century, and this is explained in the section on pitch.
Because the tenor instrument is described as "Gemeine" (common or ordinary), this is probably the most widely used trombone.
The basses, due to their longer slides, have a hinged handle on the slide stay, which is used to reach the long positions.
The giant Octav-Posaun / double bass trombone / contra-bass trombone in the style of the those made in 16th/17th centuries is represented by only a few existing instruments. There is an original instrument made by Georg Nicolaus Oller built in Stockholm in 1639 and housed in the Musikmuseet. In addition, Ewald Meinl has made a modern copy of this instrument, and it is currently owned and played by Wim Becu.
Construction.
The bore size of renaissance/baroque trombones is approximately and the bell rarely more than in diameter. This compares with modern tenor trombones, which commonly have bores to and bells to .
Modern reproductions of sackbuts sacrifice some authenticity to harness manufacturing techniques and inventions that make them more comfortable for modern players, while retaining much of the original character of the old instruments.
Some original instruments could be disassembled into the constituent straight tubes, bowed tubes, bell flare, and stays, with ferrules at the joints. Mersenne has a diagram. (Little imagination is needed to see how it could be reassembled—with an extra tube—into something approaching a natural trumpet.) There is a debate as to whether they used tight fittings, wax or another joining substance. Modern sackbut reproductions are usually soldered together. Some modern sackbut reproductions use glue as a compromise to give a loose fitting for high resonance without risk of falling apart.
Tuning slides came in during the very late 18th century. Early trombonists adjusted pitch with the slide, and by adding variously shaped and sized crooks. Modern reproductions often have a bell bow tuning slide or telescopic slide between the slide and bell sections. Crooks are still used, as are variously sized bell bow sections for larger changes.
The stays on period sackbuts are flat. While the bell stay remained flat, from about 1660 the slide stays became tubular. On many modern reproductions round slide stays are much more comfortable to play and easier to make.
A loose connection between the bell stay and the bell is thought key to a resonant bell, and thus a better sackbut sound. Original instruments have a hinge joint. Modern copies with a tuning slide in the bell can need more support for operation of the slide, so either an extra stay by the tuning slide is provided or a joint without play in only one axis is employed.
The original way to make the slide tubes was to roll a flat piece of metal around a solid cylinder mandrel, and the joining edges soldered together. Modern manufacturers now draw the tubes. They also tend to have stockings, which were only invented around 1850. In addition, modern made slides are usually made of nickel silver with chrome plating, giving a smoother finish and quieter action than simply the brass that would have originally been used.
The water key was added in the 19th century, but modern reproductions often have them.
Pitch.
Until some time in the 18th century, the trombone was in A and the pitch of that A was about a half-step higher than it is today—460–480 Hz. There was a transition around the 18th century when trombones started to be thought of in B at around 440 Hz. This change did not require a change in the instrument, merely a new set of slide positions for each note. But it does mean that the baroque and renaissance repertoire was intended to be played at the higher pitch. There are many examples of evidence for this:
The tenor trombones that survive are pitched closest to B at A=440 Hz, which is the same as A at A=466 Hz. So what we now think of as a tenor trombone with B in first position, pitched at A=440 was actually thought of as a trombone in A (in first position), pitched at A=466. Surviving basses in D at A=466 (E at 440)—for example: Ehe, 1612 (Leipzig) and Hainlein, c.1630 (Nuremberg) confirm Praetorius' description. It is also worth noting that Rognoni's "Suzanne ung jour" setting descends repeatedly to BB, which is a tone lower than the lowest note playable on a bass in F; on a bass in D, it falls in (modern) fifth position.
Many groups now perform at A=466 Hz for the sake of greater historical accuracy.
Timbre.
The sackbut was described as suitable for playing with the 'loud' ensembles in the outdoors, as well as the 'soft' ensembles inside.
The alta capella bands are seen in drawings as entertaining outside with ensembles including shawms, trumpets and trombones. When pushed, sackbuts can easily make a loud and brassy sound.
The sackbut also responds very well to rather soft playing—more so than a modern trombone. The sound is characterized by a more delicate, vocal timbre. The flat rims and shallow cups of the older mouthpieces are instrumental in providing the player with a much wider palette of articulations and tonal colours. This flexibility lends itself to a vocal style of playing and facilitates very characterful phrasing.
Mersenne wrote in 1636, "It should be blown by a skillful musician so that it may not imitate the sounds of the trumpet, but rather assimilate itself to the sweetness of the human voice, lest it should emit a warlike rather than a peaceful sound."
The Lorenzo da Lucca was said to have had "in his playing a certain grace and lightness with a manner so pleasing".
Performance practice.
Musicians of the 16th and 17th centuries benefited from a broader base of skills than the average performer today.
These traditions continued into the baroque with musicians expected to give expression to the written music by ornamenting with a mixture of one-note “graces” and whole passage “divisions” (also known as “diminutions”). The suggestions for producing effective ornaments without disrupting the line and harmony are discussed alongside countless examples in the 16th and early 17th century Italian division tutors. Graces such as the accento, portar della voce, tremolo, groppo, trillo, esclamationo and intonatio are all to be considered by performers of any music in this period.
“Cornetts and trombones...play divisions that are neither scrappy, nor so wild and involved that they spoil the underlying melody and the composer's design: but are introduced at such moments and with such vivacity and charm that they give the music the greatest beauty and spirit”
Bottrigari, Venice 1594
Along with the improvisation, many of these tutors discuss articulation. Francesco Rognoni in 1620 describes the tonguing as the most important part of producing “a good and beautiful effect in playing wind instruments, and principally the cornett” (which of course had a very similar role to the trombone). The treatises discuss the various strengths of consonants from “le” through “de” to “te”. But the focus of the text is for playing rapid notes “similar to the gorgia of the human voice” with “soft and smooth” double tonguing (“lingua riversa”) using “le re le re”. This is opposed to using “te che te che,” which is described as “harsh, barbarous and displeasing”. The natural ‘pairing’ of notes these articulations provide is similar to the instructions for string players who are instructed to slur (“lireggiar”) pairs of eighth notes with one bow stroke per quarter beat.
Another integral part of the early music sound-world is the musical temperament. Music in the middle-ages favours intervals of the fourth and fifth, which is why Pythagorean tuning was used. The interval of a third was used as a clash until the Renaissance, when it became consonant in compositions, which went hand-in-hand with the widespread use of meantone temperament. During the 17th century, Well temperament began to become more and more popular as the range of keys increased. Temperament affects the colour of a composition, and therefore modern performances, typically employing equal temperament, may not be true representations of the composers' intentions.
These old tunings can come naturally on a sackbut. As the bell is smaller than a modern trombone, the harmonic series is closer to a perfect harmonic series, which is the basis for just tuning. Without adjusting the slide, the first to second harmonic is a perfect octave, second to third harmonic is a fifth slightly wider than equal temperament and fourth to fifth harmonic is a major third slightly narrower than in equal temperament. These adjusted intervals make chords ring and are the basis of meantone. In fact, Speer says, “Once you have found a good C (third position), this is also the place you will find your F.” Playing C and F in exactly the same position on a modern orchestra sounds out of tune, but it tunes perfectly well on a sackbut if everyone plays meantone.
Plenty of musical understanding can be gathered from reading the original music print. Publishers such as SPES and Arnaldo Forni Edition provide facsimile copies of plenty of music for trombone from this era. To read these it one needs to become familiar with the old clefs, time signatures, ligatures and notational conventions of the era.
Repertoire.
Before 1600.
The sackbut replaced the slide trumpet in the 15th century alta capella wind bands that were common in towns throughout Europe playing courtly dance music. See Waits.
Another key use of the trombone was in ceremonies, in conjunction with the trumpet. In many towns in Germany and Northern Italy, 'piffari' bands were employed by local governments throughout the 16th century to give regular concerts in public squares and would lead processions for festivals. Piffari usually contained a mix of wind, brass and percussion instruments and sometimes viols.
Venice's doge had his own piffari company and they gave an hour-long concert in the Piazza each day, as well as sometimes performing for services in St. Mark's. Each of the six confraternities in Venice also had their own independent piffari groups too, which would all play at a lavish procession on the feast of Corpus Domini. These groups are in addition to the musicians employed by St. Mark's to play in the balconies with the choir (the piffari would play on the main level).
It also was used in church music both for instrumental service music and as a doubling instrument for choral music. The treble and high alto parts were most often played by cornetts or shawms, with the violin sometimes replacing the cornett in 17th century Italian music.
The first record of trombones being used in churches was in Innsbruck 1503. Seville Cathedral's records show employment of trombonists in 1526, followed by several other Spanish cathedrals during the 16th century, used not only for ceremonial music and processionals, but also for accompaniment of the liturgical texts as well, doubling voices.
The sacred use of trombones was brought to a fine art by the Andrea Gabrieli, Giovanni Gabrieli and their contemporaries c.1570-1620 Venice and there is also evidence of trombonists being employed in churches and cathedrals in Italy at times during the second half of the 16th century in Bologna, Rome, Padua, Mantua and Modena.
Since ensembles had flexible instrumentation at this time, there is relatively little music before Giovanni Gabrieli's publication "Symphoniae sacrae" (1597) that specifically mentions trombones. The only example currently known is the music by Francesco Corteccia for the Medici wedding 1539.
1600–1700.
Solo.
The 17th century brings two pieces of real solo trombone repertoire.
Giovanni Martino Cesare wrote "La Hieronyma," (Musikverlag Max Hieber, MH6012) the earliest known piece for accompanied solo trombone. It comes from Cesare's collection "Musicali Melodie per voci et instrumenti a una, due, tre, quattro, cinque, e sei" published in Munich 1621 of 28 pieces for a mixture of violins, cornetts, trombone, vocal soloists and organ continuo. The collection also contains "La Bavara" for four trombones.
The other solo trombone piece of the 17th century, "Sonata trombone & basso" (modern edition by H Weiner, Ensemble Publications), was written around 1665. This anonymous piece is also known as the 'St. Thomas Sonata' because it was kept in the library of the Saint Thomas Augustinian Monastery in Brno, Czech Republic.
Francesco Rognoni was another composer who specified the trombone in a set of divisions (variations) on the well-known song "Suzanne ung jour" (London Pro Musica, REP15). Rognoni was a master violin and gamba player whose treatise "Selva di Varie passaggi secondo l'uso moderno" (Milan 1620 and facsimile reprint by Arnaldo Forni Editore 2001) details improvisation of diminutions and Suzanne is given as one example. Although most diminutions are written for organ, string instruments or cornett, Suzanne is "per violone over Trombone alla bastarda". With virtuosic semiquaver passages across the range of the instrument, it reflects Praetorius' comments about the large range of the tenor and bass trombones, and good players of the Quartposaune (bass trombone in F) could play fast runs and leaps like a viola bastarda or cornetto. The term "bastarda" describes a technique that made variations on all the different voices of a part song, rather than just the melody or the bass: "considered illegitimate because it was not polyphonic".
Chamber music.
In the 17th century, a considerable repertoire of chamber music using sackbut with various combinations of violins, cornetts and dulcians, often with continuo, appeared. Composers included Dario Castello, Giovanni Battista Fontana, Giovanni Paolo Cima, Andrea Cima, Johann Heinrich Schmelzer and Matthias Weckmann.
Giovanni Paolo Cima, organist of S. Celso wrote the oldest known trio sonata and solo violin sonata. Contained in his "Concerti ecclesiastici" (Milan 1610) is his brother Andrea's "Capriccio" 'for cornett and trombone or violin and violone'.
Antonio Bertali wrote several trio sonatas for 2 violins, trombone and bass continuo in the mid-17th century. One such "Sonata a 3" is freely available in facsimile form from the Düben Collection website hosted by Uppsala universitet. A "Sonata a3 in C" is published by Musica Rara and attributed to Biber, although the authorship is unclear and it is more likely to have been written by Bertali.
Dario Castello, a wind player at St. Mark's Venice in the early 17th century had two books of "Sonate Concertate" published in 1621 and 1629. The sonatas of 1-4 parts with bass continuo often specify trombones, as well as cornett, violin and bassoon. The numerous reprints during the 17th century affirm his popularity then, as perhaps now.
Giuseppe Scarani joined St. Mark's Venice in 1629 as a singer and in the following year published "Sonate concertate", a volume of works for 2 or 3 (unspecified) instruments (and b.c.). The title has been suggested was chosen to try and capture some of Castello's success.
Tiburtio Massaino wrote a Canzona for eight trombones, published in Raverio's 1608 collection.
Johann Heinrich Schmelzer wrote several sonatas that included trombones—such as his "Sonata à 7" for two cornetts, two trumpets, three trombones, and basso continuo.
Daniel Speer published a four-part sonata in "Neu-gebachene Taffel-Schnitz" (1685). In 1687, Speer published the first written instruction in sackbut (and several other instruments) playing: "Grund-richtiger/kurtz/leicht und noethiger Unterricht der Musicalischen Kunst". The second edition in 1697 provides two three part sonatas for trombones.
An English work of note from this period is Matthew Locke's "Music for His Majestys Sagbutts and Cornetts", a suite for Charles II's coronation 1661.
Light music.
Non-serious music, often based on dances for festive occasions, rarely had specified instrumentation. Often you find something like "per diversi musici". Indeed, the groups that would perform them would often be full of multi-instrumentalists.
Johann Pezel wrote for Stadtpfeifer with his "Hora decima musicorum" (1670), containing sonatas, as well as "Fünff-stimmigte blasende Music" (1685) with five-part intradas and dance pieces.
Well known pieces from Germany includes Samuel Scheidt's "Ludi Musici" (1621) and Johann Hermann Schein's "Banchetto musicale" (1617).
The first English piece scored for trombone is John Adson's "Courtly Masquing Ayres" (1611). Another light collection suitable for including trombones is Anthony Holborne's "Pavans, Galliards, Allmains, and other short Aeirs both Grave and Light in Five Parts for Viols, Violins or Other Musicall Winde Instruments" (1599).
Sacred music.
Venice.
Trombonists were in the regular ensemble at St. Mark's Venice from its formation in 1568 until they left the payroll in 1732. The first two ensemble directors—"maestro di concerti"—Girolamo Dalla Casa (1568–1601) and Giovanni Bassano (1601–1617)—were cornett players and the nucleus of the group was two cornetts and two trombones, although for the larger ceremonies many extra players were hired. During a mass attended by the Doge, evidence suggests they would have played a canzona in the Gradual after the Epistle and the Agnus Dei, a sonata in the Offertory as well as reinforcing vocal parts or substituting for absent singers.
This ensemble was used extensively by Giovanni Gabrieli in pieces substantially for brass, voices and organ in Venice up until his death in 1612. He was greatly influential in Venetian composers in other churches and confraternities, and his early baroque and cori spezzati style is seen in contemporaries like Giovanni Picchi and Giovanni Battista Grillo.
It is suggested that Monteverdi wrote his "Vespro della Beata Vergine" (1610) as a pitch for employment at St. Mark's as successor to Giovanni Gabrieli. In addition to the Magnificat, two movements specify trombones: the opening "Deus in adiutorium" is for six voices, two violins, two cornetts, three trombones, five viole da braccio and basso continuo; Sonata sopra "Sancta Maria, ora pro nobis" is for soprano, two violins, two cornetts, three trombones (one of which can be a viola da braccio), viola da braccio and basso continuo. Monteverdi also leaves the option to use trombones as part of the "sex instrumentis" of the "Dixit Dominus" and in the instrumental "Ritornello a 5" between verses of "Ave maris stella".
From around 1617, when the "maestro de' concerti" at St. Marks changed to violinist Francesco Bonfante and correspondingly the ensemble changed from basically a brass ensemble to being more evenly mixed with brass, wind and string instruments.
Monteverdi arrived at St. Mark's in 1613 and it is unsurprising that he includes trombones and strings for several more sacred works during his time here, published in his "Selva Morale e Spirituale" 1641. Of the c.40 items in this collection, six specify three or four trombones (or viola da braccio, ad lib): SV268 Beatus vir I, SV263 Dixit Dominus I, SV263 Dixit Dominus II, SV261 Et iterum venturus est, SV258 Gloria in excelsis Deo, SV281 Magnificat I. Each is for 3-8 voices with 3 violins (apart from SV261), the trombones/violas and basso continuo. Monteverdi also specified trombones in two more sacred works: SV198 Laetatus sum (i) (1650) for 6 voices, 2 violins, 2 trombones and bassoon and SV272 Laudate Dominum omnes gentes I (1641) for 5 voices ‘concertato’, 4 voice chorus ad lib, 4 viola da braccio or trombones and basso continuo.
Germany/Austria.
A prolific composer for trombones in Germany in the 17th century was Heinrich Schütz. His "Fili me, Absalon" (SWV 269) and "Attendite, popule meus" (SWV 270), are both scored for bass voice, four trombones (of which two are optionally violins) and basso continuo, are well known. They are part of his first "Symphoniae Sacrae" collection dating from 1629 and commentators have noted that the style reflects his studies in Venice with Giovanni Gabrieli 1609-1612. Other pieces that specify trombones (according to Grove) are (grouped by the collection they were published in): Concert mit 11 Stimmen (1618): SWV 21, in "Psalmen Davids" (Psalms of David) Op. 2 (1619): SWV 38, 40-46, Symphoniae Sacrae I Op.6 (1629): SWV 259, 269-271, 274, Symphoniae Sacrae II Op.10 (1647): SWV 344, Symphoniae Sacrae III Op. 12 (1650): SWV 398a, Historia (1664): SWV 435, 448, 449, 453, 461, 452, 466-470, 473, 474-476, Schwanengesang Psalm 119 (1671): SWV 500, although many others are suitable for trombones too.
Johann Hermann Schein specified trombones in some of his sacred vocal works in the "Opella nova, ander Theil, geistlicher Concerten" collection (Leipzig, 1626). For example, "Uns ist ein Kind geboren" is scored for violino, traversa, alto trombone, tenor voice, fagotto and basso continuo. "Mach dich auf, werde licht, Zion" uses Canto 1: violino, cornetto, flauto picciolo e voce, Canto 2: voce e traversa, Alto: Trombone e Voce, Tenore: Voce e Trombone, Basso: Fagotto Trombone e Voce and Basso Continuo, during which solos for each of the trombonists are specified. Of particular interest is "Maria, gegrüsset seist du, Holdselige," which uses soprano and tenor voices, alto trombone, 2 tenor trombones and on the bass line "trombone grosso," which goes down to pedal A, and a couple of diatonic scale passages from bottom C.
German composer Johann Rudolf Ahle wrote some notable sacred pieces for voices and trombones. "Höre, Gott" uses five favoriti singers, two ripieno choirs (which double other parts at intense moments) and seven trombones, with basso continuo. And his most famous "Neu-gepflanzte Thüringische Lust-Garten.." (1657–65) contains several sacred works with 3 or 4 trombones, including "Magnificat a 8" for SATB soloists, cornett, 3 trombones and continuo and "Herr nun lässestu deinen Diener a 5" for bass, 4 trombones and continuo.
Dieterich Buxtehude specifies trombones in a few sacred concertos using style derived from polychoral Venetian works and one secular piece. For example, "Gott fähret auf mit Jauchzen" (BuxWV33 from CW v, 44) is scored for SSB voices, 2 vn, 2 va, trbn, 2 cornetts, 2 tpt, bn and bc.
There are a few vocal works involving trombones in works by Andreas Hammerschmidt. These include "Lob- und Danck Lied aus dem 84. Psalm" for 9 voices, 5 tpt, 3 trbn, 5 va and bc (Freiberg, 1652). There is also "Hochzeitsgesang für Daniel Sartorius: Es ist nicht gut, dass der Mensch allein sei" for 5 voices, 2 vn, 2 trbn, bn and bc.
Johann Schelle has numerous sacred vocal works that use trombones. For instance "Vom Himmel kam der Engel Schar" is scored for soprano, tenor, SSATB choir, 2 violins, 2 violas, 2 cornetts, 3 trombones, 2 trumpets, timpani, basso continuo, and "Lobe den Herrn, meine Seele" is for two choirs of SSATB and similar instruments to the previous work.
The lesser known Austrian composer Christoph Strauss, Kapellmeister to the Habsburg Emperor Mathias 1616-1620, wrote two important collections for trombones, cornetts and voices. His motets published in Nova ac diversimoda sacrarum cantionum composition, seu motettae (Vienna, 1613) are in a similar tradition to Gabrieli's music. Of the sixteen motets in the collection, all are titled "concerto" apart from the "sonata" "Expectans Expectavi Dominum" for 6 trombones, cantus voice and tenor voice. In 1631 he published a number of masses, which were much more baroque, with basso continuo, rhetorical word painting and obligato usage of instruments.
Later in the 17th century, Heinrich Ignaz Franz Biber composed sacred works for voices and orchestra featuring trombones. His "Requiem" mass (1692) uses an orchestra of strings, 3 trombones and basso continuo. A similar ensemble accompanies 8 vocal lines in his "Lux perpetua" (c1673), and three more similar works in the 1690s.
Theatre.
Monteverdi ushers sackbuts into the first great opera, 'L'Orfeo' 1607. The orchestra at the first performance, as shown in the first publication, the list of "stromenti" at the front of the score specifies four trombones, but at one point in Act 3, however, the score calls for five trombones.
1700–1750.
There is relatively little repertoire for the trombone in the late baroque.
Johann Sebastian Bach uses trombones in fourteen of his church cantatas—BWV 2, 3, 4, 21, 23, 25, 28, 38, 64, 68, 96, 101, 121, 135—as well as motet BWV 118. He uses the trombone sound to reflect the (by now) archaic sounds of the Renaissance trombones doubling voices (with cornett playing the soprano line), yet he also uses them independently, which John Eliot Gardiner says prepares the way for their use in Beethoven's "Symphony No. 5". The cantatas were either composed in Leipzig during 1723-1725, or (for BWV 4, 21 & 23) the trombone parts were added to the existing cantata during the same period. The cornett and trombone parts would have been played by the Stadtpfeifer.
In England, George Frideric Handel includes trombones in three of his oratorios: "Saul" (1738), "Israel in Egypt" (1738) and "Samson" (1741). There are no other documented groups or performances with trombone players in England at this time, and it has been suggested that the premiers took place with a visiting group from Germany, as was the custom in Paris at this time.
Vienna's Imperial court used trombones in church music:
Johann Joseph Fux was Hofkapellmeister in Vienna from 1715 until 1741. Many of his masses use the choir strengthened by strings, cornetts and trombones, often with independent moments for the instrumentalists and sometimes. "Missa SS Trinitatis" uses two choirs, which again points to the traditions going back to Gabrieli. His highly successful Requiem is for five vocal parts, two cornetts, two trombones, strings and continuo. He also uses the trombone in smaller motets and antiphons, such as his setting of "Alma Redemptoris mater" for soprano, alto trombone, strings and continuo. Some of his chamber music involves trombones, as do many of his operas, used as an obbligato instrument.
Also in the Vienna court was Antonio Caldara, vice-kapellmeister 1717–1736. Among his output are two Holy Week settings as Da Capo arias: "Deh sciogliete, o mesti lumi" for soprano, unison violins, bassoon, two trombones and organ and "Dio, qual sia" for soprano, trombone, bassoon and basso continuo.
1750–1800.
Again this period suffers from a lack of trombone players. Most of these works derive from Vienna and Salzburg.
Joseph Haydn uses trombones in "Il rotorno di Tobia", "Die Sieben Letzten Worte", The Creation, Die Jahreszeiten, "Der Sturm", "Orfeo de Euridice" and secular cantata choruses.
Wolfgang Amadeus Mozart uses trombones in connection with death or the supernatural. This includes the Requiem (K626, 1791), Great Mass in C minor (K423, 1783), "Coronation Mass (C major)" (K317, 1779), several other masses, "Vesperae Solennes de Confessore" (K339, 1780), "Vesperae de Dominica", his arrangement of Handel's "Messiah" plus two of his three great operas: Don Giovanni (K527, 1787) and Die Zauberflöte (K620, 1791). Mozart's first use of the trombone was an obligato line in the oratorio "Die Schuldigkeit des ersten Gebots" (K35, 1767)
Christoph Willibald Gluck includes trombones in five of his operas: "Iphigénie en Aulide" (1774), Orfeo ed Euridice (1774), "Alceste" (1776), Iphigénie en Tauride (1779) and "Echo et Narcisse" (1779), as well as ballet "Don Juan" (1761).
Some chamber music in this period includes trombone in an obligato role with voice, and also as a concerto instrument with string orchestra. Composers include the likes of Leopold Mozart, Georg Christoph Wagenseil, Johann Albrechtsberger, Michael Haydn and Johann Ernst Eberlin.
For works for trombone post-1800, please see trombone.
Modern performance.
Many groups specializing in period music make frequent and prominent use of the sackbut.
External links:
Recordings.
Plenty of recordings of the authentic sackbut are now available from the groups such as Concerto Palatino, HMSC, Gabrieli Consort and the Toulouse Sacqueboutiers. For a closer examination of the instrument, here are some recommended recordings where the sackbut is heavily featured in a "solo" capacity.
Early surviving instruments.
The earliest instruments:
Other notable sackbuts:
For more information, see Herbert (2006).

</doc>
<doc id="26798" url="https://en.wikipedia.org/wiki?curid=26798" title="Saxhorn">
Saxhorn

The saxhorn is a valved brass instrument with a conical bore and deep cup-shaped mouthpiece. The sound has a characteristic mellow quality, and blends well with other brass.
The saxhorn family.
The saxhorns form a family of seven brass instruments (although at one point ten different sizes seem to have existed). Designed for band use, they are pitched alternately in E-flat and B-flat, like the saxophone group.
Historically much confusion exists as to the nomenclature of the various instruments in different languages. During the 19th century, the debate as to whether the saxhorn family was truly new, or rather a development of members of the previously existing cornet and tuba families, or copied directly from the flügelhorn was the subject of bitter and prolonged lawsuits.
The following table lists the members of the saxhorn family as described in the orchestration texts of Hector Berlioz and Cecil Forsyth, the J. Howard Foote catalog of 1893, and modern names. The modern instrument names continue to exhibit inconsistency, denoted by a "/" between the two names in use. All of the "modern" instrument names represent exceedingly rare instruments with the exception of the E Tenor/Alto (unless one counts, controversially, the baritone horn as the B Tenor/Baritone member of the family). In the table "Pitch" means the concert pitch of notational Middle C on each instrument (2nd partial, no valves depressed) in scientific pitch notation.
This list is not exhaustive of historic nomenclature for the saxhorns, for which there may exist no comprehensive and authoritative source.
Ranges of individual members.
The saxhorn is based on the same three-valve system as most other valved brass instruments. Each member of the family is named after the root note produced by the second partial with no valves actuated. Each member nominally possesses or possessed the typical three-valve brass range from the note one tritone below that root note (second partial, all valves actuated) to the note produced by eighth partial with no valves actuated, i.e., the note two octaves above the root note.
All the modern members of the family are transposing instruments written in the treble clef with the root note produced by the second partial with no valves actuated being written as middle C, though baritone horn (sometimes viewed as being a saxhorn family member despite its being a predominately cylindrical, rather than conical, instrument) often plays bass clef parts, especially those written for the trombone.
History.
Developed during the mid-to-late 1830s, the saxhorn family was patented in Paris in 1845 by Adolphe Sax. Sax's claim to have invented the instrument was hotly contested by other brass instrument makers during his lifetime, leading to various lawsuits. Throughout the mid-1850s, he continued to experiment with the instrument's valve pattern.
The Trojan March ("Marche Troyenne") of the Berlioz opera Les Troyens (185658) features an on-stage band which includes a family of saxhorns.
Saxhorns were popularized by the distinguished Distin Quintet, who toured Europe during the mid-19th century. This family of musicians, publishers and instrument manufacturers had a significant impact on the growth of the brass band movement in Britain during the mid- to late-19th century.
The saxhorn was the most common brass instrument in American Civil War bands. The over-the-shoulder variety of the instrument was used, as the backward-pointing bell of the instrument allowed troops marching behind the band to hear the music.
Contemporary works featuring this instrument are Désiré Dondeyne's "Tubissimo" for bass tuba or saxhorn and piano (1983) and Olivier Messiaen's "Et exspecto resurrectionem mortuorum" (1964).

</doc>
<doc id="26799" url="https://en.wikipedia.org/wiki?curid=26799" title="Scanner">
Scanner

Scanner may refer to:
Other.
Barbara Sher uses the word "scanner" for someone who scans the surface of things, as opposed to "divers" or experts.
Other words for scanner includes polymath, renaissance soul, multitalent, generalist and multipotentialite (as in Multipotentiality)

</doc>
<doc id="26800" url="https://en.wikipedia.org/wiki?curid=26800" title="Sonic Team">
Sonic Team

History.
Consumer Research and Development No. 3 (CS3).
"Sonic the Hedgehog" became Sega's biggest success on home consoles, elevating the creators Yuji Naka and Naoto Ohshima into lofty positions within the company being able to name their CS3 department into Sonic Team. After the creation of the first Sonic the Hedgehog, development resources went two ways. One group of staff went abroad to San Francisco to develop games, however except for collaboration with American staff on "Sonic the Hedgehog 2", the staff was almost completely Japanese throughout. Meanwhile, staff in Japan would develop "Sonic CD". When staff arrived back in Japan in 1995, they developed new IP such as "Burning Rangers" and "Nights Into Dreams...", which were the first titles to be promoted with the Sonic Team moniker on the game's box art.
Sonic Team Inc..
In 2000, all of Sega's in-house Consumer (CS) and Amusement Machine (AM) R&D departments were separated from the main company and established on nine semi-autonomous subsidiaries, with each subsidiary getting an elected president as a studio head. However, for more financial stability, Sega began consolidating its studios into six main ones, (Sega Wow, Sega AM2, Hitmaker, Amusement Vision, Smilebit, Sonic Team) in 2003, and merged them back into a uniform R&D structure in 2004.
Sonic Team was established as a subsidiary with the same name as it had before, and was headed by Yuji Naka. Sonic Team USA was managed by Takashi Iizuka. After the release of "Sonic Adventure", the Japanese Sonic Team mainly focused on making new IPs, which included "Samba de Amigo", "Chu Chu Rocket", and "Phantasy Star Online" for the Dreamcast, "Billy Hatcher and the Giant Egg" for the GameCube, and "" for the Nintendo DS. In 2003, Naka was promoted to the group of executive officers. In the same year, the studio absorbed United Game Artists.
United Game Artists was established and headed by Tetsuya Mizuguchi. After arcade development he established CS4, which was an extension of CS3. His final contribution at Sega were the "Space Channel 5" games and "Rez". In 2003, the United Game Artists staff was absorbed by Sonic Team.
Global Entertainment Research and Development Dept. 1 (GE1).
After the merge back into Sega, the corporate name for Sonic Team was Global Entertainment Research and Development Division No. 1 (GE1). It contained members of both Sonic Team and SEGA WOW. It was again headed by Naka until 2006, when he left Sonic Team to form Prope. GE1 was headed by Akinori Nishiyama. Takashi Iizuka continued to manage Sonic Team USA, now called Sega Studio USA.
Consumer Research and Development Division No. 2 (CS2).
In 2008, another restructure at Sega took place, turning the departments into uniform consumer departments, and Sega Studio USA was dissolved. Akinori Nishiyama was promoted to chief producer, overseeing all software products at Sega, and Iizuka replaced Nishiyama as the general manager of Sonic Team. Since "", he has become the main producer of the series. Since 2009, the "Sonic Team" brand has diminished out of non-Sonic games, despite them being produced by former Sonic Team members or being made in the same CS2 department. Examples of this include "Pole's Big Adventure", "Rhythm Thief & the Emperor’s Treasure", "Phantasy Star Online 2", and "Project 575". The "Puyo Puyo" franchise has also no Sonic Team logos, but is listed on the official Sonic Team website.

</doc>
<doc id="26805" url="https://en.wikipedia.org/wiki?curid=26805" title="Sex">
Sex

Organisms of many species are specialized into male and female varieties, each known as a sex. Sexual reproduction involves the combining and mixing of genetic traits: specialized cells known as gametes combine to form offspring that inherit traits from each parent. Gametes can be identical in form and function (known as isogamy), but in many cases an asymmetry has evolved such that two sex-specific types of gametes (heterogametes) exist (known as anisogamy).
Among humans and other mammals, males typically carry XY chromosomes, whereas females typically carry XX chromosomes, which are a part of the XY sex-determination system. Other animals have a sex-determination system as well, such as the ZW sex-determination system in birds, and the X0 sex-determination system in insects.
The gametes produced by an organism are determined by its sex: males produce male gametes (spermatozoa, or sperm, in animals; pollen in plants) while females produce female gametes (ova, or egg cells); individual organisms which produce both male and female gametes are termed hermaphroditic. Frequently, physical differences are associated with the different sexes of an organism; these sexual dimorphisms can reflect the different reproductive pressures the sexes experience. For instance, mate choice and sexual selection can accelerate the evolution of physical differences between the sexes.
Overview.
One of the basic properties of life is reproduction, the capacity to generate new individuals, and sex is an aspect of this process. Life has evolved from simple stages to more complex ones, and so have the reproduction mechanisms. Initially the reproduction was a replicating process that consists in producing new individuals that contain the same genetic information as the original or parent individual. This mode of reproduction is called "asexual", and it is still used by many species, particularly unicellular, but it is also very common in multicellular organisms. In sexual reproduction, the genetic material of the offspring comes from two different individuals. As sexual reproduction developed by way of a long process of evolution, intermediates exist. Bacteria, for instance, reproduce asexually, but undergo a process by which a part of the genetic material of an individual (donor) is transferred to an other (recipient).
Disregarding intermediates, the basic distinction between asexual and sexual reproduction is the way in which the genetic material is processed. Typically, prior to an asexual division, a cell duplicates its genetic information content, and then divides. This process of cell division is called mitosis. In sexual reproduction, there are special kinds of cells that divide without prior duplication of its genetic material, in a process named meiosis. The resulting cells are called gametes, and contain only half the genetic material of the parent cells. These gametes are the cells that are prepared for the sexual reproduction of the organism. Sex comprises the arrangements that enable sexual reproduction, and has evolved alongside the reproduction system, starting with similar gametes (isogamy) and progressing to systems that have different gamete types, more notably a big ovum (female gamete) and a small male gamete (sperm).
In complex organisms, the sex organs are the parts that are involved in the production and exchange of gametes in sexual reproduction. Many species, particularly animals, have sexual specialization, and their populations are divided into male and female individuals. Conversely, there are also species in which there is no sexual specialization, and the same individuals both contain masculine and feminine reproductive organs, and they are called hermaphrodites. This is very frequent in plants.
Evolution.
Sexual reproduction first probably evolved about a billion years ago within ancestral single-celled eukaryotes. The reason for the evolution of sex, and the reason(s) it has survived to the present, are still matters of debate. Some of the many plausible theories include: that sex creates variation among offspring, sex helps in the spread of advantageous traits, that sex helps in the removal of disadvantageous traits, and that sex facilitates repair of germ-line DNA.
Sexual reproduction is a process specific to eukaryotes, organisms whose cells contain a nucleus and mitochondria. In addition to animals, plants, and fungi, other eukaryotes (e.g. the malaria parasite) also engage in sexual reproduction. Some bacteria use conjugation to transfer genetic material between cells; while not the same as sexual reproduction, this also results in the mixture of genetic traits.
The defining characteristic of sexual reproduction in eukaryotes is the difference between the gametes and the binary nature of fertilization. Multiplicity of gamete types within a species would still be considered a form of sexual reproduction. However, no third gamete is known in multicellular animals.
While the evolution of sex dates to the prokaryote or early eukaryote stage, the origin of chromosomal sex determination may have been fairly early in eukaryotes (see Evolution of anisogamy). The ZW sex-determination system is shared by birds, some fish and some crustaceans. XY sex determination is used by most mammals, but also some insects, and plants ("Silene latifolia"). X0 sex-determination is found in certain insects.
No genes are shared between the avian ZW and mammal XY chromosomes, and from a comparison between chicken and human, the Z chromosome appeared similar to the autosomal chromosome 9 in human, rather than X or Y, suggesting that the ZW and XY sex-determination systems do not share an origin, but that the sex chromosomes are derived from autosomal chromosomes of the common ancestor of birds and mammals.
A paper from 2004 compared the chicken Z chromosome with platypus X chromosomes and suggested that the two systems are related.
Sexual reproduction.
Sexual reproduction in eukaryotes is a process whereby organisms form offspring that combine genetic traits from both parents. Chromosomes are passed on from one generation to the next in this process. Each cell in the offspring has half the chromosomes of the mother and half of the father.
Genetic traits are contained within the deoxyribonucleic acid (DNA) of chromosomes—by combining one of each type of chromosomes from each parent, an organism is formed containing a doubled set of chromosomes. This double-chromosome stage is called "diploid", while the single-chromosome stage is "haploid". Diploid organisms can, in turn, form haploid cells (gametes) that randomly contain one of each of the chromosome pairs, via meiosis. Meiosis also involves a stage of chromosomal crossover, in which regions of DNA are exchanged between matched types of chromosomes, to form a new pair of mixed chromosomes. Crossing over and fertilization (the recombining of single sets of chromosomes to make a new diploid) result in the new organism containing a different set of genetic traits from either parent.
In many organisms, the haploid stage has been reduced to just gametes specialized to recombine and form a new diploid organism; in others, the gametes are capable of undergoing cell division to produce multicellular haploid organisms. In either case, gametes may be externally similar, particularly in size (isogamy), or may have evolved an asymmetry such that the gametes are different in size and other aspects (anisogamy).
By convention, the larger gamete (called an ovum, or egg cell) is considered female, while the smaller gamete (called a spermatozoon, or sperm cell) is considered male. An individual that produces exclusively large gametes is female, and one that produces exclusively small gametes is male. An individual that produces both types of gametes is a hermaphrodite; in some cases hermaphrodites are able to self-fertilize and produce offspring on their own, without a second organism.
Animals.
Most sexually reproducing animals spend their lives as diploid organisms, with the haploid stage reduced to single cell gametes. The gametes of animals have male and female forms—spermatozoa and egg cells. These gametes combine to form embryos which develop into a new organism.
The male gamete, a spermatozoon (produced within a testicle), is a small cell containing a single long flagellum which propels it.
Spermatozoa are extremely reduced cells, lacking many cellular components that would be necessary for embryonic development. They are specialized for motility, seeking out an egg cell and fusing with it in a process called fertilization.
Female gametes are egg cells (produced within ovaries), large immobile cells that contain the nutrients and cellular components necessary for a developing embryo.
Egg cells are often associated with other cells which support the development of the embryo, forming an egg. In mammals, the fertilized embryo instead develops within the female, receiving nutrition directly from its mother.
Animals are usually mobile and seek out a partner of the opposite sex for mating. Animals which live in the water can mate using external fertilization, where the eggs and sperm are released into and combine within the surrounding water. Most animals that live outside of water, however, must transfer sperm from male to female to achieve internal fertilization.
In most birds, both excretion and reproduction is done through a single posterior opening, called the cloaca—male and female birds touch cloaca to transfer sperm, a process called "cloacal kissing". In many other terrestrial animals, males use specialized sex organs to assist the transport of sperm—these male sex organs are called intromittent organs. In humans and other mammals this male organ is the penis, which enters the female reproductive tract (called the vagina) to achieve insemination—a process called sexual intercourse. The penis contains a tube through which semen (a fluid containing sperm) travels. In female mammals the vagina connects with the uterus, an organ which directly supports the development of a fertilized embryo within (a process called gestation).
Because of their motility, animal sexual behavior can involve coercive sex. Traumatic insemination, for example, is used by some insect species to inseminate females through a wound in the abdominal cavity—a process detrimental to the female's health.
Plants.
Like animals, plants have developed specialized male and female gametes. Within seed plants, male gametes are contained within hard coats, forming pollen. The female gametes of plants are contained within ovules; once fertilized by pollen these form seeds which, like eggs, contain the nutrients necessary for the development of the embryonic plant.
Female (left) and male (right) cones are the sex organs of pines and other conifers.
Many plants have flowers and these are the sexual organs of those plants. Flowers are usually hermaphroditic, producing both male and female gametes. The female parts, in the center of a flower, are the pistils, each unit consisting of a carpel, a style and a stigma. One or more of these reproductive units may be merged to form a single compound pistil. Within the carpels are ovules which develop into seeds after fertilization. The male parts of the flower are the stamens: these consist of long filaments arranged between the pistil and the petals that produce pollen in anthers at their tips. When a pollen grain lands upon the stigma on top of a carpel's style, it germinates to produce a pollen tube that grows down through the tissues of the style into the carpel, where it delivers male gamete nuclei to fertilise an ovule that eventually develops into a seed.
In pines and other conifers the sex organs are conifer cones and have male and female forms. The more familiar female cones are typically more durable, containing ovules within them. Male cones are smaller and produce pollen which is transported by wind to land in female cones. As with flowers, seeds form within the female cone after pollination.
Because plants are immobile, they depend upon passive methods for transporting pollen grains to other plants. Many plants, including conifers and grasses, produce lightweight pollen which is carried by wind to neighboring plants. Other plants have heavier, sticky pollen that is specialized for transportation by insects. The plants attract these insects or larger animals such as humming birds and bats with nectar-containing flowers. These animals transport the pollen as they move to other flowers, which also contain female reproductive organs, resulting in pollination.
Fungi.
Most fungi reproduce sexually, having both a haploid and diploid stage in their life cycles. These fungi are typically isogamous, lacking male and female specialization: haploid fungi grow into contact with each other and then fuse their cells. In some of these cases the fusion is asymmetric, and the cell which donates only a nucleus (and not accompanying cellular material) could arguably be considered "male".
Some fungi, including baker's yeast, have mating types that create a duality similar to male and female roles. Yeast with the same mating type will not fuse with each other to form diploid cells, only with yeast carrying the other mating type.
Fungi produce mushrooms as part of their sexual reproduction. Within the mushroom diploid cells are formed, later dividing into haploid spores—the height of the mushroom aids the dispersal of these sexually produced offspring.
Sex determination.
The most basic sexual system is one in which all organisms are hermaphrodites, producing both male and female gametes— this is true of some animals (e.g. snails) and the majority of flowering plants. In many cases, however, specialization of sex has evolved such that some organisms produce only male or only female gametes. The biological cause for an organism developing into one sex or the other is called sex determination.
In the majority of species with sex specialization, organisms are either male (producing only male gametes) or female (producing only female gametes). Exceptions are common—for example, the roundworm "C. elegans" has an hermaphrodite and a male sex (a system called androdioecy).
Sometimes an organism's development is intermediate between male and female, a condition called intersex. Sometimes intersex individuals are called "hermaphrodite"; but, unlike biological hermaphrodites, intersex individuals are unusual cases and are not typically fertile in both male and female aspects.
Genetic.
In genetic sex-determination systems, an organism's sex is determined by the genome it inherits. Genetic sex-determination usually depends on asymmetrically inherited sex chromosomes which carry genetic features that influence development; sex may be determined either by the presence of a sex chromosome or by how many the organism has. Genetic sex-determination, because it is determined by chromosome assortment, usually results in a 1:1 ratio of male and female offspring.
Humans and other mammals have an XY sex-determination system: the Y chromosome carries factors responsible for triggering male development. The "default sex," in the absence of a Y chromosome, is female-like. Thus, XX mammals are female and XY are male. In humans, biological sex is determined by five factors present at birth: the presence or absence of a Y chromosome (which alone determines the individual's "genetic sex"), the type of gonads, the sex hormones, the internal reproductive anatomy (such as the uterus in females), and the external genitalia.
XY sex determination is found in other organisms, including the common fruit fly and some plants. In some cases, including in the fruit fly, it is the number of X chromosomes that determines sex rather than the presence of a Y chromosome (see below).
In birds, which have a ZW sex-determination system, the opposite is true: the W chromosome carries factors responsible for female development, and default development is male. In this case ZZ individuals are male and ZW are female. The majority of butterflies and moths also have a ZW sex-determination system. In both XY and ZW sex determination systems, the sex chromosome carrying the critical factors is often significantly smaller, carrying little more than the genes necessary for triggering the development of a given sex.
Many insects use a sex determination system based on the number of sex chromosomes. This is called X0 sex-determination—the 0 indicates the absence of the sex chromosome. All other chromosomes in these organisms are diploid, but organisms may inherit one or two X chromosomes. In field crickets, for example, insects with a single X chromosome develop as male, while those with two develop as female. In the nematode "C. elegans" most worms are self-fertilizing XX hermaphrodites, but occasionally abnormalities in chromosome inheritance regularly give rise to individuals with only one X chromosome—these X0 individuals are fertile males (and half their offspring are male).
Other insects, including honey bees and ants, use a haplodiploid sex-determination system. In this case diploid individuals are generally female, and haploid individuals (which develop from unfertilized eggs) are male. This sex-determination system results in highly biased sex ratios, as the sex of offspring is determined by fertilization rather than the assortment of chromosomes during meiosis.
Nongenetic.
For many species, sex is not determined by inherited traits, but instead by environmental factors experienced during development or later in life. Many reptiles have temperature-dependent sex determination: the temperature embryos experience during their development determines the sex of the organism. In some turtles, for example, males are produced at lower incubation temperatures than females; this difference in critical temperatures can be as little as 1–2 °C.
Many fish change sex over the course of their lifespan, a phenomenon called sequential hermaphroditism. In clownfish, smaller fish are male, and the dominant and largest fish in a group becomes female. In many wrasses the opposite is true—most fish are initially female and become male when they reach a certain size. Sequential hermaphrodites may produce both types of gametes over the course of their lifetime, but at any given point they are either female or male.
In some ferns the default sex is hermaphrodite, but ferns which grow in soil that has previously supported hermaphrodites are influenced by residual hormones to instead develop as male.
Sexual dimorphism.
Many animals and some plants have differences between the male and female sexes in size and appearance, a phenomenon called sexual dimorphism. Sex differences in humans include, generally, a larger size and more body hair in men; women have breasts, wider hips, and a higher body fat percentage. In other species, the differences may be more extreme, such as differences in coloration or bodyweight.
Sexual dimorphisms in animals are often associated with sexual selection – the competition between individuals of one sex to mate with the opposite sex. Antlers in male deer, for example, are used in combat between males to win reproductive access to female deer. In many cases the male of a species is larger than the female. Mammal species with extreme sexual size dimorphism tend to have highly polygynous mating systems—presumably due to selection for success in competition with other males—such as the elephant seals. Other examples demonstrate that it is the preference of females that drive sexual dimorphism, such as in the case of the stalk-eyed fly.
Other animals, including most insects and many fish, have larger females. This may be associated with the cost of producing egg cells, which requires more nutrition than producing sperm—larger females are able to produce more eggs. For example, female southern black widow spiders are typically twice as long as the males. Occasionally this dimorphism is extreme, with males reduced to living as parasites dependent on the female, such as in the anglerfish. Some plant species also exhibit dimorphism in which the females are significantly larger than the males, such as in the moss "Dicranum" and the liverwort "Sphaerocarpos". There is some evidence that, in these genera, the dimorphism may be tied to a sex chromosome, or to chemical signalling from females.
In birds, males often have a more colourful appearance and may have features (like the long tail of male peacocks) that would seem to put the organism at a disadvantage (e.g. bright colors would seem to make a bird more visible to predators). One proposed explanation for this is the handicap principle. This hypothesis says that, by demonstrating he can survive with such handicaps, the male is advertising his genetic fitness to females—traits that will benefit daughters as well, who will not be encumbered with such handicaps.

</doc>
<doc id="26808" url="https://en.wikipedia.org/wiki?curid=26808" title="Star">
Star

A star is a luminous sphere of plasma held together by its own gravity. The nearest star to Earth is the Sun. Other stars are visible to the naked eye from Earth during the night, appearing as a multitude of fixed luminous points in the sky due to their immense distance from Earth. Historically, the most prominent stars were grouped into constellations and asterisms, and the brightest stars gained proper names. Extensive catalogues of stars have been assembled by astronomers, which provide standardized star designations.
For at least a portion of its life, a star shines due to thermonuclear fusion of hydrogen into helium in its core, releasing energy that traverses the star's interior and then radiates into outer space. When the hydrogen in the core of a star is nearly exhausted, almost all naturally occurring elements heavier than helium are created by stellar nucleosynthesis during the star's lifetime and, for some stars, by supernova nucleosynthesis when it explodes. Near the end of its life, a star can also contain degenerate matter. Astronomers can determine the mass, age, metallicity (chemical composition), and many other properties of a star by observing its motion through space, luminosity, and spectrum respectively. The total mass of a star is the principal determinant of its evolution and eventual fate. Other characteristics of a star, including diameter and temperature, change over its life, while the star's environment affects its rotation and movement. A plot of the temperature of many stars against their luminosities, known as a Hertzsprung–Russell diagram (H–R diagram), allows the age and evolutionary state of a star to be determined.
A star's life begins with the gravitational collapse of a gaseous nebula of material composed primarily of hydrogen, along with helium and trace amounts of heavier elements. When the stellar core is sufficiently dense, hydrogen becomes steadily converted into helium through nuclear fusion, releasing energy in the process. The remainder of the star's interior carries energy away from the core through a combination of radiative and convective processes. The star's internal pressure prevents it from collapsing further under its own gravity. When the hydrogen fuel at the core is exhausted, a star with at least 0.4 times the mass of the Sun expands to become a red giant, in some cases fusing heavier elements at the core or in shells around the core. The star then evolves into a degenerate form, recycling a portion of its matter into the interstellar environment, where it will contribute to the formation of a new generation of stars with a higher proportion of heavy elements. Meanwhile, the core becomes a stellar remnant: a white dwarf, a neutron star, or (if it is sufficiently massive) a black hole.
Binary and multi-star systems consist of two or more stars that are gravitationally bound, and generally move around each other in stable orbits. When two such stars have a relatively close orbit, their gravitational interaction can have a significant impact on their evolution. Stars can form part of a much larger gravitationally bound structure, such as a star cluster or a galaxy.
Observation history.
Historically, stars have been important to civilizations throughout the world. They have been part of religious practices and used for celestial navigation and orientation. Many ancient astronomers believed that stars were permanently affixed to a heavenly sphere, and that they were immutable. By convention, astronomers grouped stars into constellations and used them to track the motions of the planets and the inferred position of the Sun. The motion of the Sun against the background stars (and the horizon) was used to create calendars, which could be used to regulate agricultural practices. The Gregorian calendar, currently used nearly everywhere in the world, is a solar calendar based on the angle of the Earth's rotational axis relative to its local star, the Sun.
The oldest accurately dated star chart appeared in ancient Egyptian astronomy in 1534 BC. The earliest known star catalogues were compiled by the ancient Babylonian astronomers of Mesopotamia in the late 2nd millennium BC, during the Kassite Period ("ca." 1531–1155 BC).
The first star catalogue in Greek astronomy was created by Aristillus in approximately 300 BC, with the help of Timocharis. The star catalog of Hipparchus (2nd century BC) included 1020 stars, and was used to assemble Ptolemy's star catalogue. Hipparchus is known for the discovery of the first recorded "nova" (new star). Many of the constellations and star names in use today derive from Greek astronomy.
In spite of the apparent immutability of the heavens, Chinese astronomers were aware that new stars could appear. In 185 AD, they were the first to observe and write about a supernova, now known as the SN 185. The brightest stellar event in recorded history was the SN 1006 supernova, which was observed in 1006 and written about by the Egyptian astronomer Ali ibn Ridwan and several Chinese astronomers. The SN 1054 supernova, which gave birth to the Crab Nebula, was also observed by Chinese and Islamic astronomers.
</ref>
Medieval Islamic astronomers gave Arabic names to many stars that are still used today, and they invented numerous astronomical instruments that could compute the positions of the stars. They built the first large observatory research institutes, mainly for the purpose of producing "Zij" star catalogues. Among these, the "Book of Fixed Stars" (964) was written by the Persian astronomer Abd al-Rahman al-Sufi, who observed a number of stars, star clusters (including the Omicron Velorum and Brocchi's Clusters) and galaxies (including the Andromeda Galaxy). According to A. Zahoor, in the 11th century, the Persian polymath scholar Abu Rayhan Biruni described the Milky Way galaxy as a multitude of fragments having the properties of nebulous stars, and also gave the latitudes of various stars during a lunar eclipse in 1019.
According to Josep Puig, the Andalusian astronomer Ibn Bajjah proposed that the Milky Way was made up of many stars which almost touched one another and appeared to be a continuous image due to the effect of refraction from sublunary material, citing his observation of the conjunction of Jupiter and Mars on 500 AH (1106/1107 AD) as evidence. 
Early European astronomers such as Tycho Brahe identified new stars in the night sky (later termed "novae"), suggesting that the heavens were not immutable. In 1584 Giordano Bruno suggested that the stars were like the Sun, and may have other planets, possibly even Earth-like, in orbit around them, an idea that had been suggested earlier by the ancient Greek philosophers, Democritus and Epicurus, and by medieval Islamic cosmologists such as Fakhr al-Din al-Razi. By the following century, the idea of the stars being the same as the Sun was reaching a consensus among astronomers. To explain why these stars exerted no net gravitational pull on the Solar System, Isaac Newton suggested that the stars were equally distributed in every direction, an idea prompted by the theologian Richard Bentley.
The Italian astronomer Geminiano Montanari recorded observing variations in luminosity of the star Algol in 1667. Edmond Halley published the first measurements of the proper motion of a pair of nearby "fixed" stars, demonstrating that they had changed positions from the time of the ancient Greek astronomers Ptolemy and Hipparchus.
William Herschel was the first astronomer to attempt to determine the distribution of stars in the sky. During the 1780s, he performed a series of gauges in 600 directions, and counted the stars observed along each line of sight. From this he deduced that the number of stars steadily increased toward one side of the sky, in the direction of the Milky Way core. His son John Herschel repeated this study in the southern hemisphere and found a corresponding increase in the same direction. In addition to his other accomplishments, William Herschel is also noted for his discovery that some stars do not merely lie along the same line of sight, but are also physical companions that form binary star systems.
The science of stellar spectroscopy was pioneered by Joseph von Fraunhofer and Angelo Secchi. By comparing the spectra of stars such as Sirius to the Sun, they found differences in the strength and number of their absorption lines—the dark lines in a stellar spectra due to the absorption of specific frequencies by the atmosphere. In 1865 Secchi began classifying stars into spectral types. However, the modern version of the stellar classification scheme was developed by Annie J. Cannon during the 1900s.
The first direct measurement of the distance to a star (61 Cygni at 11.4 light-years) was made in 1838 by Friedrich Bessel using the parallax technique. Parallax measurements demonstrated the vast separation of the stars in the heavens. Observation of double stars gained increasing importance during the 19th century. In 1834, Friedrich Bessel observed changes in the proper motion of the star Sirius, and inferred a hidden companion. Edward Pickering discovered the first spectroscopic binary in 1899 when he observed the periodic splitting of the spectral lines of the star Mizar in a 104-day period. Detailed observations of many binary star systems were collected by astronomers such as William Struve and S. W. Burnham, allowing the masses of stars to be determined from computation of the orbital elements. The first solution to the problem of deriving an orbit of binary stars from telescope observations was made by Felix Savary in 1827.
The twentieth century saw increasingly rapid advances in the scientific study of stars. The photograph became a valuable astronomical tool. Karl Schwarzschild discovered that the color of a star and, hence, its temperature, could be determined by comparing the visual magnitude against the photographic magnitude. The development of the photoelectric photometer allowed very precise measurements of magnitude at multiple wavelength intervals. In 1921 Albert A. Michelson made the first measurements of a stellar diameter using an interferometer on the Hooker telescope at Mount Wilson Observatory.
Important theoretical work on the physical structure of stars occurred during the first decades of the twentieth century. In 1913, the Hertzsprung-Russell diagram was developed, propelling the astrophysical study of stars. Successful models were developed to explain the interiors of stars and stellar evolution. Cecilia Payne-Gaposchkin first proposed that stars were made primarily of hydrogen and helium in her 1925 PhD thesis. The spectra of stars were further understood through advances in quantum physics. This allowed the chemical composition of the stellar atmosphere to be determined.
With the exception of supernovae, individual stars have primarily been observed in the Local Group, and especially in the visible part of the Milky Way (as demonstrated by the detailed star catalogues available for our
galaxy). But some stars have been observed in the M100 galaxy of the Virgo Cluster, about 100 million light years from the Earth. 
In the Local Supercluster it is possible to see star clusters, and current telescopes could in principle observe faint individual stars in the Local Group (see Cepheids). However, outside the Local Supercluster of galaxies, neither individual stars nor clusters of stars have been observed. The only exception is a faint image of a large star cluster containing hundreds of thousands of stars located at a distance of one billion light years—ten times further than the most distant star cluster previously observed.
Designations.
The concept of the constellation was known to exist during the Babylonian period. Ancient sky watchers imagined that prominent arrangements of stars formed patterns, and they associated these with particular aspects of nature or their myths. Twelve of these formations lay along the band of the ecliptic and these became the basis of astrology. Many of the more prominent individual stars were also given names, particularly with Arabic or Latin designations.
As well as certain constellations and the Sun itself, individual stars have their own myths. To the Ancient Greeks, some "stars", known as planets (Greek πλανήτης (planētēs), meaning "wanderer"), represented various important deities, from which the names of the planets Mercury, Venus, Mars, Jupiter and Saturn were taken. (Uranus and Neptune were also Greek and Roman gods, but neither planet was known in Antiquity because of their low brightness. Their names were assigned by later astronomers.)
Circa 1600, the names of the constellations were used to name the stars in the corresponding regions of the sky. The German astronomer Johann Bayer created a series of star maps and applied Greek letters as designations to the stars in each constellation. Later a numbering system based on the star's right ascension was invented and added to John Flamsteed's star catalogue in his book ""Historia coelestis Britannica"" (the 1712 edition), whereby this numbering system came to be called "Flamsteed designation" or "Flamsteed numbering".
The only internationally recognized authority for naming celestial bodies is the International Astronomical Union (IAU). A number of private companies sell names of stars, which the British Library calls an unregulated commercial enterprise. However, the IAU has disassociated itself from this commercial practice, and these names are neither recognized by the IAU nor used by them. One such star naming company is the International Star Registry, which, during the 1980s, was accused of deceptive practice for making it appear that the assigned name was official. This now-discontinued ISR practice was informally labeled a scam and a fraud, and the New York City Department of Consumer Affairs issued a violation against ISR for engaging in a deceptive trade practice.
Units of measurement.
Although stellar parameters can be expressed in SI units or CGS units, it is often most convenient to express mass, luminosity, and radii in solar units, based on the characteristics of the Sun:
Large lengths, such as the radius of a giant star or the semi-major axis of a binary star system, are often expressed in terms of the astronomical unit —approximately equal to the mean distance between the Earth and the Sun (150 million km or 93 million miles).
Formation and evolution.
Stars form within extended regions of higher density in the interstellar medium, although the density is still lower than the inside of a vacuum chamber. These regions - known as "molecular clouds" - consist mostly of hydrogen, with about 23 to 28 percent helium and a few percent heavier elements. One example of such a star-forming region is the Orion Nebula. Most stars form in groups of dozens to hundreds of thousands of stars.
Massive stars in these groups may powerfully illuminate those clouds, ionizing the hydrogen, and creating H II regions. Such feedback effects from star formation may ultimately disrupt the cloud and prevent further star formation.
All stars spend the majority of their existence as "main sequence stars", fueled primarily by the nuclear fusion of hydrogen into helium within their cores. However, stars of different masses have markedly different properties at various stages of their development. The ultimate fate of more massive stars differs from that of less massive stars, as do their luminosity and the impact they have on their environment. Accordingly, astronomers often group stars by their mass:
Star formation.
The formation of a star begins with gravitational instability within a molecular cloud, caused by regions of higher density - often triggered by compression of clouds by radiation from massive stars, expanding bubbles in the interstellar medium, the collision of different molecular clouds, or the collision of galaxies (as in a starburst galaxy). When a region reaches a sufficient density of matter to satisfy the criteria for Jeans instability, it begins to collapse under its own gravitational force.
As the cloud collapses, individual conglomerations of dense dust and gas form "Bok globules". As a globule collapses and the density increases, the gravitational energy converts into heat and the temperature rises. When the protostellar cloud has approximately reached the stable condition of hydrostatic equilibrium, a protostar forms at the core. These pre–main sequence stars are often surrounded by a protoplanetary disk and powered mainly by the conversion of gravitational energy. The period of gravitational contraction lasts about 10 to 15 million years.
Early stars of less than 2 are called T Tauri stars, while those with greater mass are Herbig Ae/Be stars. These newly formed stars emit jets of gas along their axis of rotation, which may reduce the angular momentum of the collapsing star and result in small patches of nebulosity known as Herbig–Haro objects.
These jets, in combination with radiation from nearby massive stars, may help to drive away the surrounding cloud from which the star was formed.
Early in their development, T Tauri stars follow the Hayashi track—they contract and decrease in luminosity while remaining at roughly the same temperature. Less massive T Tauri stars follow this track to the main sequence, while more massive stars turn onto the Henyey track.
Most stars are observed to be members of binary star systems, and the properties of these binaries are the result of the conditions in which they formed. A gas cloud must lose its angular momentum in order to collapse and form a star, and fragmentation of the cloud into multiple stars uses up some of the angular momentum. The primordial binaries will get processed by gravitational interactions during close encounters with other stars in young stellar clusters. These interactions tend to split apart wider (soft) binaries while causing closer (hard) binaries to become more tightly bound, producing the distribution of binary separations seen in the field.
Main sequence.
Stars spend about 90% of their existence fusing hydrogen into helium in high-temperature and high-pressure reactions near the core. Such stars are said to be on the main sequence, and are called dwarf stars. Starting at zero-age main sequence, the proportion of helium in a star's core will steadily increase, the rate of nuclear fusion at the core will slowly increase, as will the star's temperature and luminosity.
The Sun, for example, is estimated to have increased in luminosity by about 40% since it reached the main sequence 4.6 billion (4.6 × 109) years ago.
Every star generates a stellar wind of particles that causes a continual outflow of gas into space. For most stars, the mass lost is negligible. The Sun loses 10−14 every year, or about 0.01% of its total mass over its entire lifespan. However, very massive stars can lose 10−7 to 10−5 each year, significantly affecting their evolution. Stars that begin with more than 50 can lose over half their total mass while on the main sequence.
The duration that a star spends on the main sequence depends primarily on the amount of fuel it has to fuse and the rate at which it fuses that fuel, i.e. its initial mass and its luminosity. For the Sun, its life is estimated to be about 10 billion (1010) years. Massive stars consume their fuel very rapidly and are short-lived. Low mass stars consume their fuel very slowly. Stars less massive than 0.25 , called red dwarfs, are able to fuse nearly all of their mass as fuel while stars of about 1 can only use about 10% of their mass as fuel. The combination of their slow fuel-consumption and relatively large usable fuel supply allows about 0.25 stars to last for about one trillion (1012) years according to stellar-evolution calculations, while the least-massive hydrogen-fusing stars (0.08 ) will last for about 12 trillion years. Red dwarfs become hotter and more luminous as they accumulate helium. When they eventually run out of hydrogen, they contract into a white dwarf and start to cool. However, since the lifespan of such stars is greater than the current age of the universe (13.8 billion years), no stars under about 0.85 are expected to have moved off the main sequence.
Besides mass, the elements heavier than helium can play a significant role in the evolution of stars. Astronomers consider all elements heavier than helium "metals", and call the chemical concentration of these elements the metallicity. The metallicity can influence the duration that a star will burn its fuel, control the formation of magnetic fields, and modify the strength of the stellar wind. Older, population II stars have substantially less metallicity than the younger, population I stars due to the composition of the molecular clouds from which they formed. Over time these clouds become increasingly enriched in heavier elements as older stars die and shed portions of their atmospheres.
Post–main sequence.
As stars of at least 0.4 exhaust their supply of hydrogen at their core, they start to fuse hydrogen in a shell outside the helium core. Their outer layers expand and cool greatly to form a red giant. In about 5 billion years, when the Sun enters this phase, it will expand to a maximum radius of roughly , 250 times its present size. As a giant, the Sun will lose roughly 30% of its current mass.
As hydrogen shell burning produces more helium, the core increases in mass and temperature. In a red giant of up to 2.25 , the helium core becomes degenerate before it is compressed enough to start helium fusion. When the temperature increases sufficiently helium fusion begins explosively in the helium flash, and the star rapidly shrinks in radius, increases its surface temperature, and moves to the horizontal branch. For more massive stars, the helium core fusion starts before the core becomes degenerate, and the star spends some time in the red clump before the outer convective envelope collapses and the star moves to the horizontal branch.
After the star has consumed the helium at the core, fusion continues in a shell around a hot core of carbon and oxygen. The star then follows an evolutionary path (the asymptotic giant branch or AGB) that parallels the original red giant phase at a higher luminosity. The more massive AGB stars may undergo a brief period of carbon fusion before the core becomes degenerate.
Massive stars.
During their helium-burning phase, very high-mass stars with more than nine solar masses expand to form red supergiants. When this fuel is exhausted at the core, they continue to fuse elements heavier than helium.
The core contracts until the temperature and pressure suffice to fuse carbon (see Carbon burning process). This process continues, with the successive stages being fueled by neon (see neon burning process), oxygen (see oxygen burning process), and silicon (see silicon burning process). Near the end of the star's life, fusion continues along a series of onion-layer shells within the star. Each shell fuses a different element, with the outermost shell fusing hydrogen; the next shell fusing helium, and so forth.
The final stage occurs when a massive star begins producing iron. Since iron nuclei are more tightly bound than any heavier nuclei, any fusion beyond iron does not produce a net release of energy—the process would, on the contrary, consume energy. Likewise, since they are more tightly bound than all lighter nuclei, energy cannot be released by fission. In relatively old, very massive stars, a large core of inert iron will accumulate in the center of the star. The heavier elements in these stars can work their way to the surface, forming evolved objects known as Wolf-Rayet stars that have a dense stellar wind which sheds the outer atmosphere.
Collapse.
As a star's core shrinks, the intensity of radiation from that surface increases, creating such radiation pressure on the outer shell of gas that it will push those layers away, forming a planetary nebula. If what remains after the outer atmosphere has been shed is less than 1.4 , it shrinks to a relatively tiny object about the size of Earth, known as a white dwarf. White dwarfs lack the mass for further gravitational compression to take place. The electron-degenerate matter inside a white dwarf is no longer a plasma, even though stars are generally referred to as being spheres of plasma. Eventually, white dwarfs fade into black dwarfs over a very long period of time.
In larger stars, fusion continues until the iron core has grown so large (more than 1.4 ) that it can no longer support its own mass. This core will suddenly collapse as its electrons are driven into its protons, forming neutrons, neutrinos, and gamma rays in a burst of electron capture and inverse beta decay. The shockwave formed by this sudden collapse causes the rest of the star to explode in a supernova. Supernovae become so bright that they may briefly outshine the star's entire home galaxy. When they occur within the Milky Way, supernovae have historically been observed by naked-eye observers as "new stars" where none seemingly existed before.
Supernova explosions blow away the star's outer layers, leaving remnants such as the Crab Nebula. There remains a neutron star (which sometimes manifests itself as a pulsar or X-ray burster) or, in the case of the largest stars (large enough to leave a remnant greater than roughly 4 ), a black hole. In a neutron star the matter is in a state known as neutron-degenerate matter, with a more exotic form of degenerate matter, QCD matter, possibly present in the core. Within a black hole the matter is in a state that is not currently understood.
The blown-off outer layers of dying stars include heavy elements, which may be recycled during the formation of new stars. These heavy elements allow the formation of rocky planets. The outflow from supernovae and the stellar wind of large stars play an important part in shaping the interstellar medium.
Binary stars.
The post–main-sequence evolution of binary stars may be significantly different from the evolution of single stars of the same mass. If stars in a binary system are sufficiently close, when one of the stars expands to become a red giant it may overflow its Roche lobe, the region around a star where material is gravitationally bound to that star, leading to transfer of material to the other star. A variety of phenomena can result from these systems, including contact binaries, common-envelope binaries, cataclysmic variables, and type Ia supernovae.
Distribution.
In addition to isolated stars, a multi-star system can consist of two or more gravitationally bound stars that orbit each other. The simplest and most common multi-star system is a binary star, but systems of three or more stars are also found. For reasons of orbital stability, such multi-star systems are often organized into hierarchical sets of binary stars. Larger groups called star clusters also exist. These range from loose stellar associations with only a few stars, up to enormous globular clusters with hundreds of thousands of stars.
It has been a long-held assumption that the majority of stars occur in gravitationally bound, multiple-star systems. This is particularly true for very massive O and B class stars, where 80% of the stars are believed to be part of multiple-star systems. However the proportion of single star systems increases for smaller stars, so that only 25% of red dwarfs are known to have stellar companions. As 85% of all stars are red dwarfs, most stars in the Milky Way are likely single from birth.
Stars are not spread uniformly across the universe, but are normally grouped into galaxies along with interstellar gas and dust. A typical galaxy contains hundreds of billions of stars, and there are more than 100 billion (1011) galaxies in the observable universe. In 2010, one estimate of the number of stars in the observable universe was 300 sextillion () in the observable universe.
While it is often believed that stars only exist within galaxies, intergalactic stars have been discovered.
The nearest star to the Earth, apart from the Sun, is Proxima Centauri, which is 39.9 trillion kilometres, or 4.2 light-years away. Travelling at the orbital speed of the Space Shuttle (8 kilometres per second—almost 30,000 kilometres per hour), it would take about 150,000 years to get there. Distances like this are typical inside galactic discs, including in the vicinity of the solar system. Stars can be much closer to each other in the centres of galaxies and in globular clusters, or much farther apart in galactic halos.
Due to the relatively vast distances between stars outside the galactic nucleus, collisions between stars are thought to be rare. In denser regions such as the core of globular clusters or the galactic center, collisions can be more common. Such collisions can produce what are known as blue stragglers. These abnormal stars have a higher surface temperature than the other main sequence stars with the same luminosity in the cluster.
Characteristics.
Almost everything about a star is determined by its initial mass, including essential characteristics such as luminosity and size, as well as its evolution, lifespan, and eventual fate.
Age.
Most stars are between 1 billion and 10 billion years old. Some stars may even be close to 13.8 billion years old—the observed age of the universe. The oldest star yet discovered, HD 140283, nicknamed Methuselah star, is an estimated 14.46 ± 0.8 billion years old. (Due to the uncertainty in the value, this age for the star does not conflict with the age of the Universe, determined by the Planck satellite as 13.799 ± 0.021).
The more massive the star, the shorter its lifespan, primarily because massive stars have greater pressure on their cores, causing them to burn hydrogen more rapidly. The most massive stars last an average of a few million years, while stars of minimum mass (red dwarfs) burn their fuel very slowly and can last tens to hundreds of billions of years.
Chemical composition.
When stars form in the present Milky Way galaxy they are composed of about 71% hydrogen and 27% helium, as measured by mass, with a small fraction of heavier elements. Typically the portion of heavy elements is measured in terms of the iron content of the stellar atmosphere, as iron is a common element and its absorption lines are relatively easy to measure. The portion of heavier elements may be an indicator of the likelihood that the star has a planetary system.
The star with the lowest iron content ever measured is the dwarf HE1327-2326, with only 1/200,000th the iron content of the Sun. By contrast, the super-metal-rich star μ Leonis has nearly double the abundance of iron as the Sun, while the planet-bearing star 14 Herculis has nearly triple the iron. There also exist chemically peculiar stars that show unusual abundances of certain elements in their spectrum; especially chromium and rare earth elements. Stars with cooler outer atmospheres, including the Sun, can form various diatomic and polyatomic molecules.
Diameter.
Due to their great distance from the Earth, all stars except the Sun appear to the unaided eye as shining points in the night sky that twinkle because of the effect of the Earth's atmosphere. The Sun is also a star, but it is close enough to the Earth to appear as a disk instead, and to provide daylight. Other than the Sun, the star with the largest apparent size is R Doradus, with an angular diameter of only 0.057 arcseconds.
The disks of most stars are much too small in angular size to be observed with current ground-based optical telescopes, and so interferometer telescopes are required to produce images of these objects. Another technique for measuring the angular size of stars is through occultation. By precisely measuring the drop in brightness of a star as it is occulted by the Moon (or the rise in brightness when it reappears), the star's angular diameter can be computed.
Stars range in size from neutron stars, which vary anywhere from 20 to in diameter, to supergiants like Betelgeuse in the Orion constellation, which has a diameter approximately 1,070 times that of the Sun—about . Betelgeuse, however, has a much lower density than the Sun.
Kinematics.
The motion of a star relative to the Sun can provide useful information about the origin and age of a star, as well as the structure and evolution of the surrounding galaxy. The components of motion of a star consist of the radial velocity toward or away from the Sun, and the traverse angular movement, which is called its proper motion.
Radial velocity is measured by the doppler shift of the star's spectral lines, and is given in units of km/s. The proper motion of a star is determined by precise astrometric measurements in units of milli-arc seconds (mas) per year. By determining the parallax of a star, the proper motion can then be converted into units of velocity. Stars with high rates of proper motion are likely to be relatively close to the Sun, making them good candidates for parallax measurements.
When both rates of movement are known, the space velocity of the star relative to the Sun or the galaxy can be computed. Among nearby stars, it has been found that younger population I stars have generally lower velocities than older, population II stars. The latter have elliptical orbits that are inclined to the plane of the galaxy. A comparison of the kinematics of nearby stars has also led to the identification of stellar associations. These are most likely groups of stars that share a common point of origin in giant molecular clouds.
Magnetic field.
The magnetic field of a star is generated within regions of the interior where convective circulation occurs. This movement of conductive plasma functions like a dynamo, generating magnetic fields that extend throughout the star. The strength of the magnetic field varies with the mass and composition of the star, and the amount of magnetic surface activity depends upon the star's rate of rotation. This surface activity produces starspots, which are regions of strong magnetic fields and lower than normal surface temperatures. Coronal loops are arching magnetic fields that reach out into the corona from active regions. Stellar flares are bursts of high-energy particles that are emitted due to the same magnetic activity.
Young, rapidly rotating stars tend to have high levels of surface activity because of their magnetic field. The magnetic field can act upon a star's stellar wind, functioning as a brake to gradually slow the rate of rotation with time. Thus, older stars such as the Sun have a much slower rate of rotation and a lower level of surface activity. The activity levels of slowly rotating stars tend to vary in a cyclical manner and can shut down altogether for periods of time. During
the Maunder minimum, for example, the Sun underwent a
70-year period with almost no sunspot activity.
Mass.
One of the most massive stars known is Eta Carinae, which, with 100–150 times as much mass as the Sun, will have a lifespan of only several million years. Studies of the most massive open clusters suggests as an upper limit for stars in the current era of the universe. This represents an empirical value for the theoretical limit on the formation of massive stars due to increasing radiation pressure on the accreting gas cloud. Several stars in the R136 cluster in the Large Magellanic Cloud have been measured with larger masses, but it has been determined that they could have been created through the collision and merger of massive stars in close binary systems, sidestepping the 150 limit on massive star formation.
The first stars to form after the Big Bang may have been larger, up to 300 or more, due to the complete absence of elements heavier than lithium in their composition. This generation of supermassive population III stars is likely to have existed in the very early universe (i.e., at high redshift), and may have started the production of chemical elements heavier than hydrogen that are needed for the later formation of planets and life. In June 2015, astronomers reported evidence for Population III stars in the Cosmos Redshift 7 galaxy at .
With a mass only 80 times that of Jupiter (), 2MASS J0523-1403 is the smallest known star undergoing nuclear fusion in its core. For stars with similar metallicity to the Sun, the theoretical minimum mass the star can have, and still undergo fusion at the core, is estimated to be about 75 . When the metallicity is very low, however, a recent study of the faintest stars found that the minimum star size seems to be about 8.3% of the solar mass, or about 87 . Smaller bodies are called brown dwarfs, which occupy a poorly defined grey area between stars and gas giants.
The combination of the radius and the mass of a star determines the surface gravity. Giant stars have a much lower surface gravity than main sequence stars, while the opposite is the case for degenerate, compact stars such as white dwarfs. The surface gravity can influence the appearance of a star's spectrum, with higher gravity causing a broadening of the absorption lines.
Rotation.
The rotation rate of stars can be determined through spectroscopic measurement, or more exactly determined by tracking the rotation rate of starspots. Young stars can have a rapid rate of rotation greater than 100 km/s at the equator. The B-class star Achernar, for example, has an equatorial rotation velocity of about 225 km/s or greater, causing its equator to be slung outward and giving it an equatorial diameter that is more than 50% larger than the distance between the poles. This rate of rotation is just below the critical velocity of 300 km/s where the star would break apart. By contrast, the Sun only rotates once every 25 – 35 days, with an equatorial velocity of 1.994 km/s. The star's magnetic field and the stellar wind serve to slow a main sequence star's rate of rotation by a significant amount as it evolves on the main sequence.
Degenerate stars have contracted into a compact mass, resulting in a rapid rate of rotation. However they have relatively low rates of rotation compared to what would be expected by conservation of angular momentum—the tendency of a rotating body to compensate for a contraction in size by increasing its rate of spin. A large portion of the star's angular momentum is dissipated as a result of mass loss through the stellar wind. In spite of this, the rate of rotation for a pulsar can be very rapid. The pulsar at the heart of the Crab nebula, for example, rotates 30 times per second. The rotation rate of the pulsar will gradually slow due to the emission of radiation.
Temperature.
The surface temperature of a main sequence star is determined by the rate of energy production at the core and by its radius, and is often estimated from the star's color index. The temperature is normally given as the effective temperature, which is the temperature of an idealized black body that radiates its energy at the same luminosity per surface area as the star. Note that the effective temperature is only a representative value, as the temperature increases toward the core. The temperature in the core region of a star is several million kelvins.
The stellar temperature will determine the rate of ionization of various elements, resulting in characteristic absorption lines in the spectrum. The surface temperature of a star, along with its visual absolute magnitude and absorption features, is used to classify a star (see classification below).
Massive main sequence stars can have surface temperatures of 50,000 K. Smaller stars such as the Sun have surface temperatures of a few thousand K. Red giants have relatively low surface temperatures of about 3,600 K; but they also have a high luminosity due to their large exterior surface area.
Radiation.
The energy produced by stars, as a product of nuclear fusion, radiates into space as both electromagnetic radiation and particle radiation. The particle radiation emitted by a star is manifested as the stellar wind, which streams from the outer layers as electrically charged protons and alpha and beta particles. Although almost massless there also exists a steady stream of neutrinos emanating from the star's core.
The production of energy at the core is the reason stars shine so brightly: every time two or more atomic nuclei fuse together to form a single atomic nucleus of a new heavier element, gamma ray photons are released from the nuclear fusion product. This energy is converted to other forms of electromagnetic energy of lower frequency, such as visible light, by the time it reaches the star's outer layers.
The color of a star, as determined by the most intense frequency of the visible light, depends on the temperature of the star's outer layers, including its photosphere. Besides visible light, stars also emit forms of electromagnetic radiation that are invisible to the human eye. In fact, stellar electromagnetic radiation spans the entire electromagnetic spectrum, from the longest wavelengths of radio waves through infrared, visible light, ultraviolet, to the shortest of X-rays, and gamma rays. From the standpoint of total energy emitted by a star, not all components of stellar electromagnetic radiation are significant, but all frequencies provide insight into the star's physics.
Using the stellar spectrum, astronomers can also determine the surface temperature, surface gravity, metallicity and rotational velocity of a star. If the distance of the star is known, such as by measuring the parallax, then the luminosity of the star can be derived. The mass, radius, surface gravity, and rotation period can then be estimated based on stellar models. (Mass can be calculated for stars in binary systems by measuring their orbital velocities and distances. Gravitational microlensing has been used to measure the mass of a single star.) With these parameters, astronomers can also estimate the age of the star.
Luminosity.
The luminosity of a star is the amount of light and other forms of radiant energy it radiates per unit of time. It has units of power. The luminosity of a star is determined by the radius and the surface temperature. However, many stars do not radiate a uniform flux (the amount of energy radiated per unit area) across their entire surface. The rapidly rotating star Vega, for example, has a higher energy flux at its poles than along its equator.
Surface patches with a lower temperature and luminosity than average are known as starspots. Small, "dwarf" stars such as our Sun generally have essentially featureless disks with only small starspots. Larger, "giant" stars have much larger, more obvious starspots, and they also exhibit strong stellar limb darkening. That is, the brightness decreases towards the edge of the stellar disk. Red dwarf flare stars such as UV Ceti may also possess prominent starspot features.
Magnitude.
The apparent brightness of a star is expressed in terms of its apparent magnitude, which is the brightness of a star and is a function of the star's luminosity, distance from Earth, and the altering of the star's light as it passes through Earth's atmosphere. Intrinsic or absolute magnitude is directly related to a star's luminosity, and is what the apparent magnitude a star would be if the distance between the Earth and the star were 10 parsecs (32.6 light-years).
Both the apparent and absolute magnitude scales are logarithmic units: one whole number difference in magnitude is equal to a brightness variation of about 2.5 times (the 5th root of 100 or approximately 2.512). This means that a first magnitude star (+1.00) is about 2.5 times brighter than a second magnitude (+2.00) star, and approximately 100 times brighter than a sixth magnitude star (+6.00). The faintest stars visible to the naked eye under good seeing conditions are about magnitude +6.
On both apparent and absolute magnitude scales, the smaller the magnitude number, the brighter the star; the larger the magnitude number, the fainter. The brightest stars, on either scale, have negative magnitude numbers. The variation in brightness (Δ"L") between two stars is calculated by subtracting the magnitude number of the brighter star ("m"b) from the magnitude number of the fainter star ("m"f), then using the difference as an exponent for the base number 2.512; that is to say:
Relative to both luminosity and distance from Earth, a star's absolute magnitude ("M") and apparent magnitude ("m") are not equivalent; for example, the bright star Sirius has an apparent magnitude of −1.44, but it has an absolute magnitude of +1.41.
The Sun has an apparent magnitude of −26.7, but its absolute magnitude is only +4.83. Sirius, the brightest star in the night sky as seen from Earth, is approximately 23 times more luminous than the Sun, while Canopus, the second brightest star in the night sky with an absolute magnitude of −5.53, is approximately 14,000 times more luminous than the Sun. Despite Canopus being vastly more luminous than Sirius, however, Sirius appears brighter than Canopus. This is because Sirius is merely 8.6 light-years from the Earth, while Canopus is much farther away at a distance of 310 light-years.
As of 2006, the star with the highest known absolute magnitude is LBV 1806-20, with a magnitude of −14.2. This star is at least 5,000,000 times more luminous than the Sun. The least luminous stars that are currently known are located in the NGC 6397 cluster. The faintest red dwarfs in the cluster were magnitude 26, while a 28th magnitude white dwarf was also discovered. These faint stars are so dim that their light is as bright as a birthday candle on the Moon when viewed from the Earth.
Classification.
The current stellar classification system originated in the early 20th century, when stars were classified from "A" to "Q" based on the strength of the hydrogen line. It was not known at the time that the major influence on the line strength was temperature; the hydrogen line strength reaches a peak at over 9000 K, and is weaker at both hotter and cooler temperatures. When the classifications were reordered by temperature, it more closely resembled the modern scheme.
Stars are given a single-letter classification according to their spectra, ranging from type "O", which are very hot, to "M", which are so cool that molecules may form in their atmospheres. The main classifications in order of decreasing surface temperature are: "O, B, A, F, G, K", and "M". A variety of rare spectral types have special classifications. The most common of these are types "L" and "T", which classify the coldest low-mass stars and brown dwarfs. Each letter has 10 sub-divisions, numbered from 0 to 9, in order of decreasing temperature. However, this system breaks down at extreme high temperatures: class "O0" and "O1" stars may not exist.
In addition, stars may be classified by the luminosity effects found in their spectral lines, which correspond to their spatial size and is determined by the surface gravity. These range from "0" (hypergiants) through "III" (giants) to "V" (main sequence dwarfs); some authors add "VII" (white dwarfs). Most stars belong to the main sequence, which consists of ordinary hydrogen-burning stars. These fall along a narrow, diagonal band when graphed according to their absolute magnitude and spectral type. The Sun is a main sequence "G2V" yellow dwarf of intermediate temperature and ordinary size.
Additional nomenclature, in the form of lower-case letters, can follow the spectral type to indicate peculiar features of the spectrum. For example, an ""e"" can indicate the presence of emission lines; ""m"" represents unusually strong levels of metals, and ""var"" can mean variations in the spectral type.
White dwarf stars have their own class that begins with the letter "D". This is further sub-divided into the classes "DA", "DB", "DC", "DO", "DZ", and "DQ", depending on the types of prominent lines found in the spectrum. This is followed by a numerical value that indicates the temperature index.
Variable stars.
Variable stars have periodic or random changes in luminosity because of intrinsic or extrinsic properties. Of the intrinsically variable stars, the primary types can be subdivided into three principal groups.
During their stellar evolution, some stars pass through phases where they can become pulsating variables. Pulsating variable stars vary in radius and luminosity over time, expanding and contracting with periods ranging from minutes to years, depending on the size of the star. This category includes Cepheid and Cepheid-like stars, and long-period variables such as Mira.
Eruptive variables are stars that experience sudden increases in luminosity because of flares or mass ejection events. This group includes protostars, Wolf-Rayet stars, and flare stars, as well as giant and supergiant stars.
Cataclysmic or explosive variable stars are those that undergo a dramatic change in their properties. This group includes novae and supernovae. A binary star system that includes a nearby white dwarf can produce certain types of these spectacular stellar explosions, including the nova and a Type 1a supernova. The explosion is created when the white dwarf accretes hydrogen from the companion star, building up mass until the hydrogen undergoes fusion. Some novae are also recurrent, having periodic outbursts of moderate amplitude.
Stars can also vary in luminosity because of extrinsic factors, such as eclipsing binaries, as well as rotating stars that produce extreme starspots. A notable example of an eclipsing binary is Algol, which regularly varies in magnitude from 2.3 to 3.5 over a period of 2.87 days.
Structure.
The interior of a stable star is in a state of hydrostatic equilibrium: the forces on any small volume almost exactly counterbalance each other. The balanced forces are inward gravitational force and an outward force due to the pressure gradient within the star. The pressure gradient is established by the temperature gradient of the plasma; the outer part of the star is cooler than the core. The temperature at the core of a main sequence or giant star is at least on the order of 107 K. The resulting temperature and pressure at the hydrogen-burning core of a main sequence star are sufficient for nuclear fusion to occur and for sufficient energy to be produced to prevent further collapse of the star.
As atomic nuclei are fused in the core, they emit energy in the form of gamma rays. These photons interact with the surrounding plasma, adding to the thermal energy at the core. Stars on the main sequence convert hydrogen into helium, creating a slowly but steadily increasing proportion of helium in the core. Eventually the helium content becomes predominant, and energy production ceases at the core. Instead, for stars of more than 0.4 , fusion occurs in a slowly expanding shell around the degenerate helium core.
In addition to hydrostatic equilibrium, the interior of a stable star will also maintain an energy balance of thermal equilibrium. There is a radial temperature gradient throughout the interior that results in a flux of energy flowing toward the exterior. The outgoing flux of energy leaving any layer within the star will exactly match the incoming flux from below.
The radiation zone is the region within the stellar interior where radiative transfer is sufficiently efficient to maintain the flux of energy. In this region the plasma will not be perturbed, and any mass motions will die out. If this is not the case, however, then the plasma becomes unstable and convection will occur, forming a convection zone. This can occur, for example, in regions where very high energy fluxes occur, such as near the core or in areas with high opacity as in the outer envelope.
The occurrence of convection in the outer envelope of a main sequence star depends on the mass. Stars with several times the mass of the Sun have a convection zone deep within the interior and a radiative zone in the outer layers. Smaller stars such as the Sun are just the opposite, with the convective zone located in the outer layers. Red dwarf stars with less than 0.4 are convective throughout, which prevents the accumulation of a helium core. For most stars the convective zones will also vary over time as the star ages and the constitution of the interior is modified.
The portion of a star that is visible to an observer is called the photosphere. This is the layer at which the plasma of the star becomes transparent to photons of light. From here, the energy generated at the core becomes free to propagate out into space. It is within the photosphere that sun spots, or regions of lower than average temperature, appear.
Above the level of the photosphere is the stellar atmosphere. In a main sequence star such as the Sun, the lowest level of the atmosphere is the thin chromosphere region, where spicules appear and stellar flares begin. This is surrounded by a transition region, where the temperature rapidly increases within a distance of only . Beyond this is the corona, a volume of super-heated plasma that can extend outward to several million kilometres. The existence of a corona appears to be dependent on a convective zone in the outer layers of the star. Despite its high temperature, the corona emits very little light. The corona region of the Sun is normally only visible during a solar eclipse.
From the corona, a stellar wind of plasma particles expands outward from the star, propagating until it interacts with the interstellar medium. For the Sun, the influence of its solar wind extends throughout the bubble-shaped region of the heliosphere.
Nuclear fusion reaction pathways.
A variety of different nuclear fusion reactions take place inside the cores of stars, depending upon their mass and composition, as part of stellar nucleosynthesis. The net mass of the fused atomic nuclei is smaller than the sum of the constituents. This lost mass is released as electromagnetic energy, according to the mass-energy equivalence relationship "E" = "mc"2.
The hydrogen fusion process is temperature-sensitive, so a moderate increase in the core temperature will result in a significant increase in the fusion rate. As a result, the core temperature of main sequence stars only varies from 4 million kelvin for a small M-class star to 40 million kelvin for a massive O-class star.
In the Sun, with a 10-million-kelvin core, hydrogen fuses to form helium in the proton-proton chain reaction:
These reactions result in the overall reaction:
where e+ is a positron, γ is a gamma ray photon, νe is a neutrino, and H and He are isotopes of hydrogen and helium, respectively. The energy released by this reaction is in millions of electron volts, which is actually only a tiny amount of energy. However enormous numbers of these reactions occur constantly, producing all the energy necessary to sustain the star's radiation output.
In more massive stars, helium is produced in a cycle of reactions catalyzed by carbon—the carbon-nitrogen-oxygen cycle.
In evolved stars with cores at 100 million kelvin and masses between 0.5 and 10 , helium can be transformed into carbon in the triple-alpha process that uses the intermediate element beryllium:
For an overall reaction of:
In massive stars, heavier elements can also be burned in a contracting core through the neon burning process and oxygen burning process. The final stage in the stellar nucleosynthesis process is the silicon burning process that results in the production of the stable isotope iron-56. Fusion can not proceed any further except through an endothermic process, and so further energy can only be produced through gravitational collapse.
The example below shows the amount of time required for a star of 20 to consume all of its nuclear fuel. As an O-class main sequence star, it would be 8 times the solar radius and 62,000 times the Sun's luminosity.

</doc>
<doc id="26809" url="https://en.wikipedia.org/wiki?curid=26809" title="StarCraft (video game)">
StarCraft (video game)

StarCraft is a military science fiction real-time strategy video game developed and published by Blizzard Entertainment and released for Microsoft Windows on March 31, 1998. The game later spawned a franchise, and is the first game of the "StarCraft" series. A Mac OS version was released in 1999, and a Nintendo 64 adaptation co-developed with Mass Media was released on June 13, 2000. Work on the game started shortly after ""s release in 1995. "StarCraft" debuted at the 1996 E3, where it was unfavorably compared to "Warcraft II". As a result, the project was entirely overhauled and then showcased to public in early 1997, receiving a far more positive response.
Set in a fictitious timeline during the Earth's 25th century, the game revolves around three species fighting for dominance in a distant part of the Milky Way galaxy known as the Koprulu Sector: the Terrans, humans exiled from Earth skilled at adapting to any situation; the Zerg, a race of insectoid aliens in pursuit of genetic perfection, obsessed with assimilating other races; and the Protoss, a humanoid species with advanced technology and psionic abilities, attempting to preserve their civilization and strict philosophical way of living from the Zerg.
Many of the industry's journalists have praised "StarCraft" as one of the best and most important video games of all time, and for having raised the bar for developing real-time strategy games. With more than 11 million copies sold worldwide as of February 2009, "StarCraft" is one of the best-selling games for the personal computer. The game has been praised for pioneering the use of unique factions in real-time strategy gameplay and for a compelling story. "StarCraft"s multiplayer is particularly popular in South Korea, where players and teams participate in , earn sponsorships, and compete in televised tournaments. "StarCraft" has had its storyline adapted and expanded through a series of novels, the expansion pack ' and two authorized add-ons. A sequel, ', was released in July 2010.
Gameplay.
Blizzard Entertainment's use of three distinct races in "StarCraft" is widely credited with revolutionizing the real-time strategy genre. All units are unique to their respective races and while rough comparisons can be drawn between certain types of units in the technology tree, every unit performs differently and requires different tactics for a player to succeed.
The enigmatic Protoss have access to powerful units and machinery and advanced technologies such as energy shields and localized warp capabilities, powered by their psionic traits. However, their forces have lengthy and expensive manufacturing processes, encouraging players to follow a strategy of the quality of their units over the quantity. The insectoid Zerg possess entirely organic units and structures, which can be produced quickly and at a far cheaper cost to resources, but are accordingly weaker, relying on sheer numbers and speed to overwhelm enemies. The Terrans provide a middle ground between the other two races, providing units that are versatile and flexible. They have access to a range of more ballistic military technologies and machinery, such as tanks and nuclear weapons.
Although each race is unique in its composition, no race has an innate advantage over the other. Each species is balanced out so that while they have different strengths, powers, and abilities their overall strength is the same. The balance stays complete via infrequent patches (game updates) provided by Blizzard.
"StarCraft" features artificial intelligence which scales in difficulty, although the player cannot change the difficulty level in the single-player campaigns. Each campaign starts with enemy factions running easy AI modes, scaling through the course of the campaign to the hardest AI modes. In the level editor provided with the game, a designer has access to four levels of AI difficulties: "easy", "medium", "hard" and "insane", each setting differing in the units and technologies allowed to an AI faction and the extent of the AI's tactical and strategic planning. The single-player campaign consists of thirty missions, split into ten for each race.
Resource management.
Each race relies on two resources to sustain their game economies and to build their forces: minerals and vespene gas. Minerals are needed for all units and structures, and are obtained by using a worker unit to harvest the resource directly from mineral nodes scattered around the battlefield. Players require vespene gas to construct advanced units and buildings, and acquire it by constructing a gas extraction building on top of a geyser and using worker units to extract the gas from it. In addition, players need to regulate the supplies for their forces to ensure that they can construct the number of units they need. Although the nature of the supply differs between the races—Terrans use physical supplies held in depots, Protoss use psionic energy channeled from their homeworld via pylons, and Zerg are regulated by the number of controlling overlord units present—the supply mechanic essentially works in exactly the same way for each race (just with differing impacts on gameplay), allowing players to create new units when there are sufficient resources to sustain them.
Base construction.
Protoss and Zerg building construction is limited to specific locations: Protoss buildings need to be linked to a power grid while almost every Zerg structure must be placed on a carpet of biomass, called "creep", that is produced by certain structures. Terran buildings are far less limited, with certain primary base structures possessing the ability to take off and fly slowly to a new location. Terran buildings, however, require the worker unit to continue construction on the building until it is completed. Also, once a Terran building has taken a certain amount of damage, it will catch fire and can eventually burn to the ground without further enemy action if repairs are not performed by a worker unit. The Protoss, by contrast, only require a worker unit to begin the process of transporting a building to the theater of operations via warp, and their buildings' shields (but not their structure) are regenerative. The Zerg worker unit physically transforms into the structure created, which is capable of slowly healing itself.
Multiplayer.
Multiplayer on "StarCraft" is powered through Blizzard Entertainment's Battle.net Internet service. Through this, a maximum of eight players can compete in a variety of game modes, including simply destroying all other players on a level (which may be competitive, as in Ladder play, or non-ranked, as in melee play), to king of the hill and capture the flag objective-based games. In addition, the game incorporates a variety of specialized scenarios for different types of game, such as simulating a football game, using the Terran hoverbike unit to conduct a bike race, or hosting a Zerg hunting competition. "StarCraft" is also one of the few games that include a spawn installation, which allows for limited multiplayer. It must be installed from a disc, and requires a product key to work just as the full version does. However, one product key can support up to eight spawned installations with access to Battle.net. Limitations of a spawned installation include the inability to play single-player missions, create multiplayer games or use the campaign editor. Newer releases of the game available through Battle.net or discs that include the Windows Vista label don't support the spawn installation.
Synopsis.
Setting.
"StarCraft" takes place in a science fiction universe created by Chris Metzen and James Phinney for Blizzard Entertainment. According to the story presented in the game's manual, the overpopulation of Earth in the early 24th century has caused the international government to exile certain members of the human race, such as criminals, the cybernetically enhanced and genetic mutants to colonize the far reaches of the galaxy. An attempt to colonize a nearby solar system goes wrong, resulting in humanity's arrival in the Koprulu Sector. In the distant Koprulu Sector of the galaxy, the exiles form several governments, but quickly fall into conflict with each other. One government, the Confederacy of Man, eventually emerges as the strongest faction, but its oppressive nature and brutal methods of suppressing dissidents stir up major rebel opposition in the form of a terrorist group called the Sons of Korhal. Just prior to the beginning of the game, in December 2499, an alien race possessing advanced technology and psionic power, the Protoss, makes first contact with humanity by destroying a Confederate colony world without any prior warning. Soon after this, the Terrans discover that a second alien race, the insectoid Zerg, has been stealthily infesting the surface of several of the Terran colonies, and that the Protoss are destroying the planets to prevent the Zerg from spreading. With the Confederacy threatened by two alien races and internal rebellion, it begins to crumble.
Characters.
The player assumes the role of three nameless characters over the course of the game. In the first act, the player acts as the Confederate magistrate of an outlying colony world of Mar Sara, threatened by both the Zerg and the Protoss, and is forced through events to join the rebel Sons of Korhal under its leader Arcturus Mengsk. Mengsk's campaign is accompanied by Jim Raynor, a morally conscious law enforcement officer from Mar Sara, and Sarah Kerrigan, a psychic assassin and Mengsk's second-in-command. The second episode of the game sees the player as a cerebrate, a commander within the Zerg Swarm. The player is ruled over by the Zerg Overmind — the manifestation of the collective consciousness of the Swarm and the game's primary antagonist — and is given advice from other cerebrates of higher rank and status while accomplishing the objectives of the Swarm. In the final part of "StarCraft", the player is a newly appointed Executor within the Protoss military reporting to Aldaris, a representative of the Protoss government. Aldaris is at odds with Tassadar — the former occupant of the player's position — over his association with Zeratul, a member of a heretical group known as dark templar.
Plot.
The story of "StarCraft" is presented through its instruction manual, the briefings to each mission and conversations within the missions themselves, along with the use of cinematic cutscenes at key points. The game itself is split into three episodes, one for the player to command each race. In the first segment of the game, the player and Jim Raynor are attempting to control the colony of Mar Sara in the wake of the Zerg attacks on other Terran worlds. After the Confederacy arrests Raynor for destroying Confederate property, despite the fact that it had been infested by the Zerg, the player joins Arcturus Mengsk and the Sons of Korhal. Raynor, who is freed by Mengsk's troops, also joins and frequently accompanies the player on missions. Mengsk then begins to use Confederate technology captured on Mar Sara to lure the Zerg to Confederate installations and further his own goals. After forcing Confederate general Edmund Duke to join him, Mengsk sacrifices his own second-in-command, Sarah Kerrigan, to ensure the destruction of the Confederacy by luring the Zerg to the Confederate capital Tarsonis. Raynor is outraged by Mengsk's true aims of obtaining power at any cost and deserts, taking with him a small army of the former colonial militia of Mar Sara. Mengsk reorganizes what remains of the Terran population into the Terran Dominion, crowning himself as emperor.
The second campaign reveals that Kerrigan was not killed by the Zerg, but rather is captured and infested in an effort to incorporate her psionic traits into the Zerg gene pool. She emerges with far more psionic powers and physical strength, her DNA completely altered. Meanwhile, the Protoss commander Tassadar discovers that the Zerg's cerebrates cannot be killed by conventional means, but that they can be harmed by the powers wielded by the heretical dark templar. Tassadar allies himself with the dark templar prelate Zeratul, who assassinates Zasz, one of the Zerg's cerebrates in their hive clusters on Char. The cerebrate's death results in its forces running amok through the Zerg hives, but briefly links the minds of Zeratul and the Zerg Overmind, allowing the Overmind to finally learn the location of the Protoss homeworld Aiur, which the Overmind has been seeking for millennia. The main Zerg swarm promptly invades Aiur while Kerrigan is dispatched to deal with Tassadar and despite heavy Protoss resistance, the Overmind is able to embed itself into the crust of the planet.
The final episode of the game sees Aldaris and the Protoss government branding Tassadar a traitor and a heretic for conspiring with the dark templar. The player (later hinted to be Artanis) initially serves Aldaris in defending Aiur from the Zerg invasion, but while on a mission to arrest Tassadar, the player joins him instead. A Protoss civil war erupts, pitting Tassadar, Zeratul, and their allies against the Protoss establishment. The dark templar prove their worth when they use their energies to slay two more of the Zerg cerebrates on Aiur, and the Conclave reconciles with them. Aided by Raynor's forces—who sided with Tassadar back on Char—the Protoss break through the Overmind's weakened defenses and destroy the Overmind's outer shell, but take heavy casualties in the process. Tassadar channels his own psionic energies in combination with those of the dark templar through the hull of his command ship and crashes it into the Overmind, sacrificing himself in order to destroy it.
Development.
Blizzard Entertainment began development on "StarCraft" in 1995, shortly after the release of highly successful '. Using the "Tides of Darknesss game engine as a base, "StarCraft" made its debut at E3 1996. The version of the game displayed, assembled by the team's lead programmer Bob Fitch, received a rather weak response from the convention and was criticized by many for being ""Warcraft" in space." As a consequence the entire project was overhauled, bringing the focus onto creating three distinct species. Bill Roper, one of the game's producers, stated this would be a major departure from the "Warcraft" approach, comparing its two equal sides to those of chess and stating that "StarCraft" would allow players to "develop very unique strategies based on which species is being played, and will require players to think of different strategies to combat the other two species." In early 1997, the new version of "StarCraft" was unveiled, receiving a far more positive response.
However, the game was still marred by technical difficulties, so Bob Fitch completely redesigned the "Warcraft II" engine within two months to ensure that many of the features desired by the designers, such as the abilities for units to burrow and cloak, could be implemented. Later improvements to the game included pre-rendered sprites and backgrounds, constructed using 3D Studio Max. An isometric in-game view was also adopted, in contrast to "Warcraft II"s 3/4s birdseye perspective. In addition, the game utilized high quality music, composed by Blizzard's resident composers, and professional voice actors were hired.
Despite the progress, "StarCraft" was slow to emerge. The continual delays inspired a group of "StarCraft" fans on the official forums who labeled themselves "Operation: Can't Wait Any Longer" to write a series of fictional stories in which the members of Operation CWAL attempted to retrieve the beta version of "StarCraft" from Blizzard's headquarters in Irvine, California. To pay homage to their presence on the forums and enthusiasm for the game, Blizzard Entertainment later incorporated the group's name into "StarCraft" as a cheat code to speed up the production of units and gave the group thanks in the game's credits. The game was released for Windows on March 31, 1998, with the Mac OS version following a year later in 1999. Development on a Nintendo 64 version, "StarCraft 64", began in 1999, converted from PC by Mass Media Interactive Entertainment—a subsidiary of THQ—and published by Nintendo. "StarCraft 64" was released on June 13, 2000 in the USA and Europe. It was also released in Australia on May 25, 2001.
Music.
The musical score to "StarCraft" was composed by Blizzard Entertainment's composers. Glenn Stafford composed the Terran and Protoss in-game themes, while Derek Duke, who was a contracted composer at the time, wrote all the in-game music for the Zerg. The cinematic scores were composed by Stafford and Hayes. Hayes also collaborated with Stafford on one of the Protoss in-game tracks. Tracy W. Bush provided additional support in composing. The musical score of the game was received well by reviewers, who have described it as "appropriately melodic and dark" and "impressive", with one reviewer noting that some of the music owed much of its inspiration to Jerry Goldsmith's score for the film "Alien". The first official game soundtrack, "StarCraft: Game Music Vol. 1", was released in 2000, comprising tracks from both "StarCraft" and "", as well as a sizable portion of remix tracks and music inspired by "StarCraft", created by several South Korean disc jockeys. The soundtrack was distributed by Net Vision Entertainment. In September 2008, Blizzard Entertainment announced that a second soundtrack, "StarCraft Original Soundtrack", had been released on iTunes. This soundtrack consisted entirely of the original music from "StarCraft" and "Brood War", both from in-game themes to music used in the cinematic cut scenes.
Expansions and versions.
Computer expansions.
Before the release of "StarCraft", Blizzard Entertainment released a free-to-download game demo entitled "Loomings", comprising three missions and a tutorial. The prequel was made available for the full game in October 1999 as a custom map campaign, adding two extra missions and hosting it on Battle.net. In addition, the full release of "StarCraft" included a secondary campaign entitled "Enslavers". Consisting of five missions played as both the Terrans and the Protoss, "Enslavers" is set in the second campaign in "StarCraft" and follows the story of a Terran smuggler who manages to take control of a Zerg cerebrate and is pursued by both the Protoss and Terran Dominion. "Enslavers" acts as an exemplar single-player campaign for the game's level editor, highlighting how to use the features of the program.
"StarCraft"s first expansion, Insurrection, was released for Windows on July 31, 1998. The expansion was developed by Aztech New Media and authorized by Blizzard Entertainment. Its story focused on a separate Confederate colony alluded to in the manual to "StarCraft", following a group of Terran colonists and a Protoss fleet in their fight against the Zerg and a rising local insurgency. "Insurrection" was not received well, being criticized by reviewers for lacking the quality of the original game. "Insurrection" was followed within a few months by a second expansion, Retribution. Developed by Stardock, published by WizardWorks Software and authorized by Blizzard Entertainment, "Retribution" follows all three races attempting to seize control of a powerful crystal on a Terran Dominion colony. The expansion was not received with critical support, instead being regarded as average but at least challenging. After the release of "Retribution", Blizzard Entertainment announced a new official expansion pack that would continue on the story of "StarCraft". "" was consequently created, developed jointly by Blizzard Entertainment and Saffire. "Brood War" continues the story of "StarCraft" from days after its conclusion, and was released for both Windows and Mac OS to critical praise on November 30, 1998 in the US and in March 1999 in Europe.
Before Insurrection, an unauthorized expansion pack, called Stellar Forces, was published by Micro Star but was recalled weeks later when Blizzard won the court case against it. It consisted of 22 single player maps and 32 multi-player maps which are considered to be rather plain.
Nintendo 64 version.
In 2000, "StarCraft 64" was released In North America for the Nintendo 64, co-developed by Blizzard Entertainment and Mass Media Inc. and published by Nintendo. The game featured all of the missions from both "StarCraft" and the expansion "Brood War", as well as some exclusive missions, such as two different tutorials and a new secret mission, "Resurrection IV". Blizzard Entertainment had previously considered a PlayStation port of the game, but it was decided that the game would instead be released on the Nintendo 64. "Resurrection IV" is set after the conclusion of "Brood War", and follows Jim Raynor embarking on a mission to rescue the "Brood War" character Alexei Stukov, a vice admiral from Earth who has been captured by the Zerg. The "Brood War" missions required the use of a Nintendo 64 memory Expansion Pak to run. In addition, "StarCraft 64" features a split screen cooperative mode, also requiring the expansion pak, allowing two players to control one force in-game. "StarCraft 64" was not as popular as the PC version, and lacked the online multiplayer capabilities and speech in mission briefings. In addition, cut scenes were shortened.
Cultural impact.
Reception.
"StarCraft" was released internationally on March 31, 1998 and became the best-selling PC game for that year, selling over 1.5 million copies worldwide. In the next decade, "StarCraft" sold over 9.5 million copies across the globe, with 4.5 million of these being sold in South Korea. Since the initial release of "StarCraft", Blizzard Entertainment reported that its Battle.net online multiplayer service grew by 800 percent.
Generally, "StarCraft" was received positively by critics, with many contemporary reviewers noting that while the game may not have deviated significantly from the status quo of most real-time strategy games, it was one of the best to have applied the formula. In addition, "StarCraft"s pioneering use of three distinct, unique and balanced races over two equal sides was praised by critics, with GameSpot commenting that this helped the game to "avoid the problem that has plagued every other game in the genre". Many critics also praised the strength of the story accompanying the game, with some reviewers being impressed by how well the story was folded into the gameplay. The game's voice acting in particular was praised; GameSpot later hailed the voice work in the game as one of the ten best in the industry at the time. Equally, the multiplayer aspects of the game were positively received. "StarCraft" has received multiple awards, including being named as one of the best games of all time by GameSpot, IGN, and "Game Informer". According to Blizzard Entertainment "StarCraft" has won 37 awards, and has received a star on the floor of the Metreon as part of the Walk of Game in San Francisco in early 2006.
Although at the time "StarCraft"s graphics and audio were praised by critics, later reviews have noted that the graphics do not compare to more modern games. The capacity for the game's artificial intelligence to navigate units to waypoints also faced some heavy criticism, with "PC Zone" stating that the inability for developers to make an effective pathfinding system was "the single most infuriating element of the real-time strategy genre". In addition, several reviewers expressed concern over some familiarities between the unit structures of each race, as well as over the potential imbalance of players using rushing tactics early in multiplayer games. Blizzard Entertainment has strived to balance rush tactics in later updates. The Nintendo 64 version of the game was not received as positively by reviewers, and was criticized for poor graphics in comparison to the PC version. However, critics did praise the game and Mass Media for using effective controls on the gamepad and maintaining the high quality audio.
Legacy.
GameSpot described "StarCraft" as "The defining game of its genre. It is the standard by which all real-time strategy games are judged." IGN stated that "StarCraft" "is hands down one of the best, if not the best, real-time strategy games ever created." "StarCraft" is frequently included in the industry's best games rankings, for example it ranked 37 in "Edge"s top 100 games of all time. "StarCraft" has even been taken into space, as Daniel Barry took a copy of the game with him on the Space Shuttle mission STS-96 in 1999. "StarCraft"s popularity resulted in "Guinness World Records" awarding the game four world records, including "Best Selling PC Strategy Game," "Largest Income in Professional Gaming," and "Largest Audience for a Game Competition" when 120,000 fans turned out to watch the final of the SKY proleague season 2005 in Busan, South Korea. Researchers have shown that the audience for watching "StarCraft" games is diverse and that "StarCraft" uses instances of information asymmetry to make the game more entertaining for spectators. In addition, "StarCraft" has been the subject of an academic course; the University of California, Berkeley offered a student-run introductory course on theory and strategy in spring 2009.
After its release, "StarCraft" rapidly grew in popularity in South Korea, eventually making its way to become the country's national e-sport after establishing a successful pro-gaming scene. Professional gamers in South Korea are media celebrities, and "StarCraft" games are broadcast over three television channels dedicated to the professional gaming scene. Professional gamers in South Korea have gained television contracts, sponsorships, and tournament prizes, allowing one of the most famous players, Lim "BoxeR" Yo-hwan, to gain a fan club of over half a million people. One player, Lee Yun-yeol, reported earnings in 2005 of .
"StarCraft" was part of the United States Air Force's Air and Space Basic Course, used to teach newly active officers about crisis planning under stress and joint service teamwork. Other efforts to make more 'realistic' current-day battle software led to distractions when simulated hardware didn't align with the real hardware active duty officers knew about. The science fiction setting allowed students to focus on the battle tactics.
The annual Conference on Artificial Intelligence and Interactive Digital Entertainment hosts a competition for AIs playing the game. As of 2015, humans still win.
In 2014 an unofficial version for the Pandora handheld and the ARM architecture became available by static recompilation and reverse engineering of the original x86 version.
Merchandise.
The storyline of "StarCraft" has been adapted into several novels. The first novel, "Uprising", which was written by Blizzard employee Micky Neilson and published in December 2000, acts as a prequel to the events of "StarCraft". Other novels—"Liberty's Crusade" by Jeff Grubb and Aaron Rosenberg's "Queen of Blades"—retell the story of the game from different perspectives. At BlizzCon 2007, "StarCraft" creator Chris Metzen stated that he hoped to novelize the entirety of "StarCraft" and its expansion "Brood War" into a definitive text-based story. Later novels, such as Gabriel Mesta's "Shadow of the Xel'Naga" and Christie Golden's "The Dark Templar Saga", further expand the storyline, creating the setting for "".
A number of action figures and collectable statues based upon the characters and units in "StarCraft" have been produced by ToyCom. A number of model kits, made by Academy Hobby Model Kits, were also produced, displaying 1/30 scale versions of the marine and the hydralisk. In addition, Blizzard Entertainment teamed up with Fantasy Flight Games to create a board game with detailed sculptures of game characters. Blizzard Entertainment also licensed Wizards of the Coast to produce an Alternity based game entitled "StarCraft Adventures".

</doc>
<doc id="26810" url="https://en.wikipedia.org/wiki?curid=26810" title="Skepticism">
Skepticism

Skepticism or scepticism (see spelling differences) is generally any questioning attitude towards unempirical knowledge or opinions/beliefs stated as facts, or doubt regarding claims that are taken for granted elsewhere. Skepticism is often separated into categories, related to morality (right or wrong), religion (religious doubt), or the nature of knowledge ("there is no knowledge beyond how things appear.")
Philosophical skepticism is a systematic approach that questions the notion that absolutely certain knowledge is possible. Classical philosophical skepticism derives from the 'Skeptikoi', a school who "asserted nothing". Adherents of Pyrrhonism (and more recently, partially synonymous with Fallibilism), for instance, suspend judgment in investigations. Skeptics may even doubt the reliability of their own senses. Religious skepticism, on the other hand, is "doubt concerning basic religious principles (such as immortality, providence, and revelation)". Scientific skepticism is about testing beliefs for reliability, by subjecting them to systematic investigation using the scientific method, to discover empirical evidence for them.
Definition.
In ordinary usage, skepticism (US) or scepticism (UK) (Greek: 'σκέπτομαι' "skeptomai", to think, to look about, to consider; see also spelling differences) refers to:
In philosophy, skepticism refers more specifically to any one of several propositions. These include propositions about:
Legal skepticism.
Legal skepticism (aka Legal Realism) is a branch of jurisprudence. It is in essence a critique of the natural law theories and of legal positivism.
Philosophical skepticism.
In philosophical skepticism, pyrrhonism is a position that refrains from making truth claims. A philosophical skeptic does not claim that truth is impossible (which itself would be a truth claim), instead it recommends "suspending belief". The term is commonly used to describe philosophies which are similar to philosophical skepticism, such as academic skepticism, an ancient variant of Platonism that claimed knowledge of truth was impossible. Empiricism is a closely related, but not identical, philosophy to philosophical skepticism. Empiricists claim empiricism is a pragmatic compromise between philosophical skepticism and nomothetic science; philosophical skepticism is in turn sometimes referred to as "radical empiricism."
Western Philosophical skepticism originated in ancient Greek philosophy. The Greek Sophists of the 5th century BC were partially skeptics.
Pyrrho of Elis (365–275 BC) is usually credited with founding the "school" of skepticism. He traveled to India and studied with the "gymnosophists" (naked lovers of wisdom), which could have been any number of Indian sects. From there, he brought back the idea that nothing can be known for certain. The senses are easily fooled, and reason follows too easily our desires. Pyrrhonism was a school of skepticism founded by his follower Aenesidemus in the first century BC and recorded by Sextus Empiricus in the late 2nd century or early 3rd century AD. Subsequently, in the "New Academy" Arcesilaus (c. 315–241 BC) and Carneades (c. 213–129 BC) developed more theoretical perspectives by which conceptions of absolute truth and falsity were refuted as uncertain. Carneades criticized the claims of the Dogmatists, especially supporters of Stoicism, asserting that absolute certainty of knowledge is impossible. Sextus Empiricus (c. AD 200), the main authority for Greek skepticism, developed the philosophy further, incorporating aspects of empiricism into the basis for asserting knowledge.
Greek skeptics criticized the Stoics, accusing them of dogmatism. For the skeptics, the logical mode of argument was untenable, as it relied on propositions which could not be said to be either true or false without relying on further propositions. This was the regress argument, whereby every proposition must rely on other propositions in order to maintain its validity (see the five tropes of Agrippa the Sceptic). In addition, the skeptics argued that two propositions could not rely on each other, as this would create a circular argument (as p implies q and q implies p). For the skeptics, such logic was thus an inadequate measure of truth and could create as many problems as it claimed to have solved. Truth was not, however, necessarily unobtainable, but rather an idea which did not yet exist in a pure form. Although skepticism was accused of denying the possibility of truth, in fact it appears to have mainly been a critical school which merely claimed that logicians had not discovered truth.
In Islamic philosophy, skepticism was established by Al-Ghazali (1058–1111), known in the West as "Algazel", as part of the Ash'ari school of Islamic theology, whose method of skepticism shares many similarities with Descartes' method.
In an effort to avoid skepticism, René Descartes begins his "Meditations on First Philosophy" attempting to find indubitable truth on which to base his knowledge. He later recognizes this truth as "I think, therefore I am," but before he finds this truth, he briefly entertains the skeptical arguments from dreaming and radical deception.
David Hume has also been described as a skeptic.
Pierre Le Morvan has distinguished between three philosophical approaches to skepticism. The first he terms the "Foil Approach." According to this approach, skepticism is treated as a problem to be solved, or challenge to be met, or threat to be parried; skepticism's value according to this method, insofar as it is deemed to have one, accrues from its role as a foil contrastively illuminating what is required for knowledge and justified belief. The second he calls the "Bypass Approach" according to which skepticism is bypassed as a major concern of epistemology. Le Morvan advocates a third approach—he dubs it the "Health Approach"—that explores when skepticism is healthy and when it is not, or when it is virtuous and when it is vicious.
Religious skepticism.
Religious skepticism generally refers to doubting given religious beliefs or claims. Historically, religious skepticism can be traced back to Socrates, who doubted many religious claims of the time. Modern religious skepticism typically emphasizes scientific and historical methods or evidence, with Michael Shermer writing that skepticism is a process for discovering the truth rather than general non-acceptance. For this reason a religious skeptic might believe that Jesus existed while questioning claims that he was the messiah or performed miracles (see historicity of Jesus). Religious skepticism is not the same as atheism or agnosticism, though these often do involve skeptical attitudes toward religion and philosophical theology (for example, towards divine omnipotence). Religious people are generally skeptical about claims of other religions, at least when the two denominations conflict concerning some stated belief. Additionally, they may also be skeptical of the claims made by atheists. The historian Will Durant writes that Plato was "as skeptical of atheism as of any other dogma."
Scientific skepticism.
A scientific (or empirical) skeptic is one who questions beliefs on the basis of scientific understanding. Most scientists, being scientific skeptics, test the reliability of certain kinds of claims by subjecting them to a systematic investigation using some form of the scientific method. As a result, a number of claims are considered "pseudoscience" if they are found to improperly apply or ignore the fundamental aspects of the scientific method. Scientific skepticism may discard beliefs pertaining to things outside perceivable observation and thus outside the realm of systematic, empirical falsifiability/testability.

</doc>
<doc id="26818" url="https://en.wikipedia.org/wiki?curid=26818" title="Stagflation">
Stagflation

In economics, stagflation, a portmanteau of "stagnation" and "inflation", is a situation in which the inflation rate is high, the economic growth rate slows, and unemployment remains steadily high. It raises a dilemma for economic policy, since actions designed to lower inflation may exacerbate unemployment, and vice versa.
The term is generally attributed to a British Conservative Party politician who became chancellor of the exchequer in 1970, Iain Macleod, who coined the phrase in his speech to Parliament in 1965. 
Keynes did not use the term, but some of his work refers to the conditions that most would recognise as stagflation. In the version of Keynesian macroeconomic theory that was dominant between the end of World War II and the late 1970s, inflation and recession were regarded as mutually exclusive, the relationship between the two being described by the Phillips curve. Stagflation is very costly and difficult to eradicate once it starts, both in social terms and in budget deficits.
The Great Inflation.
The term "stagflation" was first coined during a period of inflation and unemployment in the United Kingdom. The United Kingdom experienced an outbreak of inflation in the 1960s and 1970s. On 17 November 1965, Iain Macleod, the spokesman on economic issues for the United Kingdom's Conservative Party, warned of the gravity of the UK economic situation in the House of Commons: "We now have the worst of both worlds—not just inflation on the one side or stagnation on the other, but both of them together. We have a sort of "stagflation" situation. And history, in modern terms, is indeed being made."
He used the term again on 7 July 1970, and the media began also to use it, for example in "The Economist" on 15 August 1970, and Newsweek on 19 March 1973. In a Bank of England working papers series, article authors Edward Nelson and Kalin Nikolov (2002) examined causes and policy errors related to the Great Inflation in the United Kingdom in the 1970s, arguing that as inflation rose in the 1960s and 1970s, UK policy makers failed to recognize the primary role of monetary policy in controlling inflation. Instead, they attempted to use non-monetary policies and devices to respond to the economic crisis. Policy makers also made "inaccurate estimates of the degree of excess demand in the economy, contributed significantly to the outbreak of inflation in the United Kingdom in the 1960s and 1970s.
Stagflation was not limited to the United Kingdom, however. Economists have shown that stagflation was prevalent among seven major economies from 1973 to 1982. After inflation rates began to fall in 1982, economists' focus shifted from the causes of stagflation to the "determinants of productivity growth and the effects of real wages on the demand for labor".
Causes.
Economists offer two principal explanations for why stagflation occurs. First, stagflation can result when the productive capacity of an economy is reduced by an unfavorable supply shock that causes an increase in the price of oil for an oil-importing country. Such an unfavorable supply shock tends to raise prices at the same time that it slows the economy by making production more costly and less profitable. Milton Friedman famously described this situation as "too much money chasing too few goods".
Second, both stagnation and inflation can result from inappropriate macroeconomic policies. For example, central banks can cause inflation by allowing excessive growth of the money supply, and the government can cause stagnation by excessive regulation of goods markets and labour markets. Excessive growth of the money supply, taken to such an extreme that it must be reversed abruptly, can be a cause. Both types of explanations are offered in analyses of the global stagflation of the 1970s: it began with a huge rise in oil prices, but then continued as central banks used excessively stimulative monetary policy to counteract the resulting recession, causing a runaway price/wage spiral.
Postwar Keynesian and monetarist views.
Early Keynesianism and monetarism.
Up to the 1960s, many Keynesian economists ignored the possibility of stagflation, because historical experience suggested that high unemployment was typically associated with low inflation, and vice versa (this relationship is called the Phillips curve). The idea was that high demand for goods drives up prices, and also encourages firms to hire more; and likewise high employment raises demand. However, in the 1970s and 1980s, when stagflation occurred, it became obvious that the relationship between inflation and employment levels was not necessarily stable: that is, the Phillips relationship could shift. Macroeconomists became more skeptical of Keynesian theories, and Keynesians themselves reconsidered their ideas in search of an explanation for stagflation.
The explanation for the shift of the Phillips curve was initially provided by the monetarist economist Milton Friedman, and also by Edmund Phelps. Both argued that when workers and firms begin to expect more inflation, the Phillips curve shifts up (meaning that more inflation occurs at any given level of unemployment). In particular, they suggested that if inflation lasted for several years, workers and firms would start to take it into account during wage negotiations, causing workers' wages and firms' costs to rise more quickly, thus further increasing inflation. While this idea was a severe criticism of early Keynesian theories, it was gradually accepted by most Keynesians, and has been incorporated into New Keynesian economic models.
Neo-Keynesianism.
Neo-Keynesian theory distinguished two distinct kinds of inflation: demand-pull (caused by shifts of the aggregate demand curve) and cost-push (caused by shifts of the aggregate supply curve). Stagflation, in this view, is caused by cost-push inflation. Cost-push inflation occurs when some force or condition increases the costs of production. This could be caused by government policies (such as taxes) or from purely external factors such as a shortage of natural resources or an act of war.
Contemporary Keynesian analyses argue that stagflation can be understood by distinguishing factors that affect aggregate demand from those that affect aggregate supply. While monetary and fiscal policy can be used to stabilise the economy in the face of aggregate demand fluctuations, they are not very useful in confronting aggregate supply fluctuations. In particular, an adverse shock to aggregate supply, such as an increase in oil prices, can give rise to stagflation.
Supply theory.
Fundamentals.
Supply theories are based on the neo-Keynesian cost-push model and attribute stagflation to significant disruptions to the supply side of the supply-demand market equation, for example, when there is a sudden real or relative scarcity of key commodities, natural resources, or natural capital needed to produce goods and services. Other factors may also cause supply problems, for example, social and political conditions such as policy changes, acts of war, extremely restrictive government control of production. In this view, stagflation is thought to occur when there is an adverse supply shock (for example, a sudden increase in the price of oil or a new tax) that causes a subsequent jump in the "cost" of goods and services (often at the wholesale level). In technical terms, this results in contraction or negative shift in an economy's aggregate supply curve.
In the resource scarcity scenario (Zinam 1982), stagflation results when economic growth is inhibited by a restricted supply of raw materials. That is, when the actual or relative supply of basic materials (fossil fuels (energy), minerals, agricultural land in production, timber, etc.) decreases and/or cannot be increased fast enough in response to rising or continuing demand. The resource shortage may be a real physical shortage or a relative scarcity due to factors such as taxes or bad monetary policy which have affected the "cost" or availability of raw materials. This is consistent with the cost-push inflation factors in neo-Keynesian theory (above). The way this plays out is that after supply shock occurs, the economy will first try to maintain momentum – that is, consumers and businesses will begin paying higher prices in order to maintain their level of demand. The central bank may exacerbate this by increasing the money supply, by lowering interest rates for example, in an effort to combat a recession. The increased money supply props up the demand for goods and services, though demand would normally drop during a recession.
In the Keynesian model, higher prices will prompt increases in the supply of goods and services. However, during a supply shock (i.e. scarcity, "bottleneck" in resources, etc.), supplies don't respond as they normally would to these price pressures. So, inflation jumps and output drops, producing stagflation.
Explaining the 1970s stagflation.
Following Richard Nixon's imposition of wage and price controls on 15 August 1971, an initial wave of cost-push shocks in commodities were blamed for causing spiraling prices. The second major shock was the 1973 oil crisis, when the Organization of Petroleum Exporting Countries (OPEC) constrained the worldwide supply of oil. Both events, combined with the overall energy shortage that characterized the 1970s, resulted in actual or relative scarcity of raw materials. The price controls resulted in shortages at the point of purchase, causing, for example, queues of consumers at fuelling stations and increased production costs for industry.
Recent views.
Through the mid-1970s, none of the major macroeconomic models (Keynesian, New Classical, and monetarist) were able to explain stagflation.
After several years of research, a convincing explanation was provided based on the effects of adverse supply shocks on both prices and output. According to Blanchard (2009), these adverse events were one of two components of stagflation; the other was "ideas", which Robert Lucas (famous for the Lucas Supply Curve), Thomas Sargent, and Robert Barro were cited as expressing as "wildly incorrect" and "fundamentally flawed" predictions Keynesian economics which, they said, left stagflation to be explained by "contemporary students of the business cycle". In this discussion, Blanchard hypothesizes that the recent oil price increases could trigger another period of stagflation, although this has not yet happened (pg. 152).
Neoclassical views.
A purely neoclassical view of the macroeconomy rejects the idea that monetary policy can have real effects. Neoclassical macroeconomists argue that real economic quantities, like real output, employment, and unemployment, are determined by real factors only. Nominal factors like changes in the money supply only affect nominal variables like inflation. The neoclassical idea that nominal factors cannot have real effects is often called "monetary neutrality" or also the "classical dichotomy".
Since the neoclassical viewpoint says that real phenomena like unemployment are essentially unrelated to nominal phenomena like inflation, a neoclassical economist would offer two separate explanations for 'stagnation' and 'inflation'. Neoclassical explanations of stagnation (low growth and high unemployment) include inefficient government regulations or high benefits for the unemployed that give people less incentive to look for jobs. Another neoclassical explanation of stagnation is given by real business cycle theory, in which any decrease in labour productivity makes it efficient to work less. The main neoclassical explanation of inflation is very simple: it happens when the monetary authorities increase the money supply too much.
In the neoclassical viewpoint, the real factors that determine output and unemployment affect the aggregate supply curve only. The nominal factors that determine inflation affect the aggregate demand curve only. When some adverse changes in real factors are shifting the aggregate supply curve left at the same time that unwise monetary policies are shifting the aggregate demand curve right, the result is stagflation.
Thus the main explanation for stagflation under a classical view of the economy is simply policy errors that affect both inflation and the labour market. Ironically, a very clear argument in favour of the classical explanation of stagflation was provided by Keynes himself. In 1919, John Maynard Keynes described the inflation and economic stagnation gripping Europe in his book The Economic Consequences of the Peace. Keynes wrote:
Keynes explicitly pointed out the relationship between governments printing money and inflation.
Keynes also pointed out how government price controls discourage production.
Keynes detailed the relationship between German government deficits and inflation.
Keynesian in the short run, classical in the long run.
While most economists believe that changes in money supply can have some real effects in the short run, neoclassical and neo-Keynesian economists tend to agree that there are no long-run effects from changing the money supply. Therefore, even economists who consider themselves neo-Keynesians usually believe that in the long run, money is neutral. In other words, while neoclassical and neo-Keynesian models are often seen as competing points of view, they can also be seen as two descriptions appropriate for different time horizons. Many mainstream textbooks today treat the neo-Keynesian model as a more appropriate description of the economy in the short run, when prices are 'sticky', and treat the neoclassical model as a more appropriate description of the economy in the long run, when prices have sufficient time to adjust fully.
Therefore, while mainstream economists today might often attribute short periods of stagflation (not more than a few years) to adverse changes in supply, they would not accept this as an explanation of very prolonged stagflation. More prolonged stagflation would be explained as the effect of inappropriate government policies: excessive regulation of product markets and labor markets leading to long-run stagnation, and excessive growth of the money supply leading to long-run inflation.
Alternative views.
As differential accumulation.
Political economists Jonathan Nitzan and Shimshon Bichler have proposed an explanation of stagflation as part of a theory they call differential accumulation, which says firms seek to beat the average profit and capitalisation rather than maximise. According to this theory, periods of mergers and acquisitions oscillate with periods of stagflation. When mergers and acquisitions are no longer politically feasible (governments clamp down with anti-monopoly rules), stagflation is used as an alternative to have higher relative profit than the competition. With increasing mergers and acquisitions, the power to implement stagflation increases.
Stagflation appears as a societal crisis, such as during the period of the oil crisis in the 70s and in 2007 to 2010. Inflation in stagflation, however, doesn't affect all firms equally. Dominant firms are able to increase their own prices at a faster rate than competitors. While in the aggregate no one appears to be profiting, differentially dominant firms improve their positions with higher relative profits and higher relative capitalisation. Stagflation is not due to any actual supply shock, but because of the societal crisis that hints at a supply crisis. It is mostly a 20th and 21st century phenomenon that has been mainly used by the "weapondollar-petrodollar coalition" creating or using Middle East crises for the benefit of pecuniary interests.
Demand-pull stagflation theory.
Demand-pull stagflation theory explores the idea that stagflation can result exclusively from monetary shocks without any concurrent supply shocks or negative shifts in economic output potential. Demand-pull theory describes a scenario where stagflation can occur following a period of monetary policy implementations that cause inflation. This theory was first proposed in 1999 by Eduardo Loyo of Harvard University's John F. Kennedy School of Government.
Supply-side theory.
Supply-side economics emerged as a response to US stagflation in the 1970s. It largely attributed inflation to the ending of the Bretton Woods system in 1971 and the lack of a specific price reference in the subsequent monetary policies (Keynesian and Monetarism). Supply-side economists asserted that the contraction component of stagflation resulted from an inflation-induced rise in real tax rates (see bracket creep)
Austrian School of economics.
Adherents to the Austrian School maintain that creation of new money ex nihilo benefits the creators and early recipients of the new money relative to late recipients. Money creation is not wealth creation; it merely allows early money recipients to outbid late recipients for resources, goods, and services.
Since the actual producers of wealth are typically late recipients, increases in the money supply weakens wealth formation and undermines the rate of economic growth. Says Austrian economist Frank Shostak:
"The increase in the money supply rate of growth coupled with the slowdown in the rate of growth of goods produced is what the increase in the rate of price inflation is all about. (Note that a price is the amount of money paid for a unit of a good.) What we have here is a faster increase in price inflation and a decline in the rate of growth in the production of goods. But this is exactly what stagflation is all about, i.e., an increase in price inflation and a fall in real economic growth. Popular opinion is that stagflation is totally made up. It seems therefore that the phenomenon of stagflation is the normal outcome of loose monetary policy. This is in agreement with and Friedman (PF). Contrary to PF, however, we maintain that stagflation is not caused by the fact that in the short run people are fooled by the central bank. Stagflation is the natural result of monetary pumping which weakens the pace of economic growth and at the same time raises the rate of increase of the prices of goods and services."
Jane Jacobs and the influence of cities on stagflation.
In 1984, journalist and activist Jane Jacobs proposed the failure of major macroeconomic theories to explain stagflation was due to their focus on the nation as the salient unit of economic analysis, rather than the city. She proposed the key to avoiding stagflation was for a nation to focus on the development of "import-replacing cities", which would experience economic ups and downs at different times, providing overall national stability and avoiding widespread stagflation. According to Jacobs, import-replacing cities are those which have developed economies balancing their own production with domestic imports, meaning they can respond with flexibility as economic supply and demand cycles change over time. While lauding her originality, clarity, and consistency, urban planning scholars have criticized Jacobs for not comparing her own ideas to those of major theorists (e.g., Adam Smith, Karl Marx) with the same depth and breadth they developed, as well as a lack of scholarly documentation. Despite these issues, Jacobs' work is notable for having widespread public readership and influence on decision-makers.
Responses.
Stagflation undermined support for Keynesian consensus. The rise of conservative theories of economics, including monetarism, can be traced to the failure of Keynesian policies to combat stagflation or explain it to the satisfaction of economists and policy-makers.
Federal Reserve chairman Paul Volcker very sharply increased interest rates from 1979–1983 in what was called a "disinflationary scenario." After U.S. prime interest rates had soared into the double-digits, inflation did come down; these interest rates were the highest long-term prime interest rates that had ever existed in modern capital markets. Volcker is often credited with having stopped at least the inflationary side of stagflation, although the American economy also dipped into recession. Starting in approximately 1983, growth began a recovery. Both fiscal stimulus and money supply growth were policy at this time. A five- to six-year jump in unemployment during the Volcker disinflation suggests Volcker may have trusted unemployment to self-correct and return to its natural rate within a reasonable period.

</doc>
<doc id="26819" url="https://en.wikipedia.org/wiki?curid=26819" title="Soundness">
Soundness

In mathematical logic, a logical system has the soundness property if and only if its inference rules prove only formulas that are valid with respect to its semantics. In most cases, this comes down to its rules having the property of preserving "truth", but this is not the case in general.
Of arguments.
An argument is sound if and only if
1. The argument is valid,
and 
2. All of its premises are true.
For instance,
The argument is valid (because the conclusion is true based on the premises, that is, that the conclusion follows the premises) and since the premises are in fact true, the argument is sound.
The following argument is valid but not sound:
Since the first premise is actually false, the argument, though valid, is not sound.
Logical systems.
Soundness is among the most fundamental properties of mathematical logic. The soundness property provides the initial reason for counting a logical system as desirable. The completeness property means that every validity (truth) is provable. Together they imply that all and only validities are provable.
Most proofs of soundness are trivial. For example, in an axiomatic system, proof of soundness amounts to verifying the validity of the axioms and that the rules of inference preserve validity (or the weaker property, truth). Most axiomatic systems have only the rule of modus ponens (and sometimes substitution), so it requires only verifying the validity of the axioms and one rule of inference.
Soundness properties come in two main varieties: weak and strong soundness, of which the former is a restricted form of the latter.
Soundness.
Soundness of a deductive system is the property that any sentence that is provable in that deductive system is also true on all interpretations or structures of the semantic theory for the language upon which that theory is based. In symbols, where "S" is the deductive system, "L" the language together with its semantic theory, and "P" a sentence of "L": if ⊢"S" "P", then also ⊨"L" "P".
Strong soundness.
Strong soundness of a deductive system is the property that any sentence "P" of the language upon which the deductive system is based that is derivable from a set Γ of sentences of that language is also a logical consequence of that set, in the sense that any model that makes all members of Γ true will also make "P" true. In symbols where Γ is a set of sentences of "L": if Γ ⊢"S" "P", then also Γ ⊨"L" "P". Notice that in the statement of strong soundness, when Γ is empty, we have the statement of weak soundness.
Arithmetic soundness.
If "T" is a theory whose objects of discourse can be interpreted as natural numbers, we say "T" is "arithmetically sound" if all theorems of "T" are actually true about the standard mathematical integers. For further information, see ω-consistent theory.
Relation to completeness.
The converse of the soundness property is the semantic completeness property. A deductive system with a semantic theory is strongly complete if every sentence "P" that is a semantic consequence of a set of sentences Γ can be derived in the deduction system from that set. In symbols: whenever , then also . Completeness of first-order logic was first explicitly established by Gödel, though some of the main results were contained in earlier work of Skolem.
Informally, a soundness theorem for a deductive system expresses that all provable sentences are true. Completeness states that all true sentences are provable.
Gödel's first incompleteness theorem shows that for languages sufficient for doing a certain amount of arithmetic, there can be no effective deductive system that is complete with respect to the intended interpretation of the symbolism of that language. Thus, not all sound deductive systems are complete in this special sense of completeness, in which the class of models (up to isomorphism) is restricted to the intended one. The original completeness proof applies to "all" classical models, not some special proper subclass of intended ones.

</doc>
<doc id="26820" url="https://en.wikipedia.org/wiki?curid=26820" title="Syllabary">
Syllabary

A syllabary is a set of written symbols that represent the syllables or (more frequently) moras which make up words. 
A symbol in a syllabary, called a syllabogram, typically represents an (optional) consonant sound (simple onset) followed by a vowel sound (nucleus)—that is, a CV or V syllable—but other phonographic mappings such as CVC, CV- tone, and C (normally nasals at the end of syllables) are also found in syllabaries.
Types.
A writing system using a syllabary is "complete" when it covers all syllables in the corresponding spoken language without requiring complex orthographic / graphemic rules, like implicit codas ( ⇒ /C1VC2/) silent vowels ( ⇒ /C1V1C2/) or echo vowels ( ⇒ /C1V1C2/). This loosely corresponds to "shallow" orthographies in alphabetic writing systems.
"True" syllabograms are those that encompass all parts of a syllable, i.e. initial onset, medial nucleus and final coda, but since onset and coda are optional in at least some languages, there are "middle" (nucleus), "start" (onset-nucleus), "end" (nucleus-coda) and "full" (onset-nucleus-coda) true syllabograms. Most syllabaries only feature one or two kinds of syllabograms and form other syllables by graphemic rules.
Syllabograms, hence syllabaries, are "pure", "analytic" or "arbitrary" if they do not share graphic similarities that correspond to phonic similarities, i.e. the symbol for "ka" does not resemble in any predictable way the symbol for "ki", nor the symbol for "a".
Otherwise they are "synthetic", if they vary by onset, rime, nucleus "or" coda, or "systematic", if they vary by all of them.
Some scholars, e.g. Daniels, reserve the general term for analytic syllabaries and invent other terms (abugida, abjad) as necessary.
Languages using syllabaries.
Languages that use syllabic writing include Mycenaean Greek (Linear B), the North American language Cherokee, the African language Vai, the English-based creole Ndyuka written with the Afaka script, Yi language and formerly Nü Shu for the language of Xiangnan Tuhua in China. In addition, the undecoded Cretan Linear A is also believed by some to be a syllabic script, though this is not proven. 
The Chinese, Sumerian and Akkadian cuneiform, and Maya scripts are largely syllabic in nature, although based on logograms. They are therefore sometimes referred to as "logosyllabic".
The contemporary Japanese language uses two syllabaries together called kana, namely hiragana and katakana (developed around AD 700). They are mainly used to write some native words and grammatical elements, as well as foreign words, e.g. "hotel" is written with three kana, ホテル ("ho-te-ru"). Because Japanese uses mainly CV (consonant + vowel) syllables, a syllabary is well suited to write the language. As in many syllabaries, however, vowel sequences and final consonants are written with separate glyphs, so that both "atta" and "kaita" are written with three kana: あった ("a-t-ta") and かいた ("ka-i-ta"). It is therefore sometimes called a "moraic" writing system.
Languages that use syllabaries today tend to have simple phonotactics, with a predominance of monomoraic (CV) syllables. 
For example, the modern Yi script is used to write a language that has no diphthongs or syllable codas; unusually among syllabaries, there is a separate glyph for every consonant-vowel-tone combination (CVT) in the language (apart from one tone which is indicated with a diacritic).
Few syllabaries have glyphs for syllables that are not monomoraic, and those that once did have simplified over time to eliminate that complexity. 
For example, the Vai syllabary originally had separate glyphs for syllables ending in a coda "(doŋ)," a long vowel "(soo)," or a diphthong "(bai)," though not enough glyphs to distinguish all CV combinations (some distinctions were ignored). The modern script has been expanded to cover all moras, but at the same time reduced to exclude all other syllables. Bimoraic syllables are now written with two letters, as in Japanese: diphthongs are written with the help of V or "h"V glyphs, and the nasal coda is written with the glyph for "ŋ", which can form a syllable of its own in Vai.
In Linear B, which was used to transcribe Greek, a language with complex syllables, complex consonant onsets were either written with two glyphs or simplified to one, while codas were generally ignored, e.g. "ko-no-so" for "Knōsos", "pe-ma" for "sperma."
The Cherokee syllabary generally uses dummy vowels for coda consonants, but also has a segmental grapheme for /s/, which can be used both as a coda and in an initial /sC/ consonant cluster.
Difference from abugidas.
The languages of South Asia and Southeast Asia, as well as the Ethiopian languages, have a type of alphabet called an "abugida" or "alphasyllabary". In these scripts, unlike in pure syllabaries, syllables starting with the same consonant are generally expressed with characters that are based on the same sign in a regular way, and usually each character representing a syllable consists of several elements which designate the individual sounds of that syllable. In the 19th century these systems were called "syllabics", a term which has survived in the name of Canadian Aboriginal syllabics (also an abugida). In a true syllabary there may be graphic similarity between characters that share a common consonant or vowel sound, but it is not systematic or close to regular. For example, the characters for 'ke', 'ka', and 'ko' in Japanese hiragana have no similarity to indicate their common "k" sound (these being: け, か and こ). Compare abugida, where each grapheme typically represents a syllable but where characters representing related sounds are all similar graphically (typically, a common consonantal base is annotated in a more or less consistent manner to represent the vowel in the syllable). For example, in "Devanagari", an abugida, the same characters for 'ke', 'ka' and 'ko' are के, का and को respectively, with क indicating their common "k" sound.
Comparison to Latin alphabet.
English, along with many other Indo-European languages like German and Russian, allows for complex syllable structures, making it cumbersome to write English words with a syllabary. A "pure" syllabary would require a separate glyph for every syllable in English. Thus one would need separate symbols for "bag", "beg", "big", "bog", "bug"; "bad", "bed", "bid", "bod", "bud", "book", "bay", "bead", "bide", "bode", "boom", "bird", "Boyd", "bow", "blog", "blow", "belch", "blurt", "bore", "black", "breach", "bleak", "brat", "brash", "blight", "blurb", "Borg", "brought", "bot", "bard", "blast", "brand", "brick", "bleed", "blood", "bloom", "broth", "both", "bode", "bloke", "broke", "bloat", "Blake", "break", "bake", "bait", "bade", "blade", "braid", "boon", "bone", "bowl", "barn", "balm", "beach", "bitch", "batch", "botch", "Butch", "borscht", "bald", "bold", "bane", "bit", "Bit", "broad", "bear", "Brock", "block", "board", "binge", "bulk", "breed", "Breen", "brine", "Brat", "boomed", "bleeds", "bats", etc. Since English has well over 10,000 different possibilities for individual syllables, a syllabary would be poorly suited to represent the English language. However, such pure systems are rare. A work-around to this problem, common to several syllabaries around the world (including English loanwords in Japanese), is to write an echo vowel, as if the syllable coda were a second syllable: "ba-gu" for "bag", etc. Another common approach is to simply ignore the coda, so that "bag" would be written "ba". This obviously would not work well for English, but was done in Mycenean Greek when the root word was two or three syllables long and the syllable coda was a weak consonant such as "n" or "s" (example: χρυσος "chrysos" written as "ku-ru-so").

</doc>
<doc id="26822" url="https://en.wikipedia.org/wiki?curid=26822" title="Steve Reich">
Steve Reich

Stephen Michael Reich (; born October 3, 1936) is an American composer who, along with La Monte Young, Terry Riley, and Philip Glass, pioneered minimal music in the mid to late 1960s.
Reich's style of composition influenced many composers and groups. His innovations include using tape loops to create phasing patterns (for example, his early compositions "It's Gonna Rain" and "Come Out"), and the use of simple, audible processes to explore musical concepts (for instance, "Pendulum Music" and "Four Organs"). These compositions, marked by their use of repetitive figures, slow harmonic rhythm and canons, have significantly influenced contemporary music, especially in the US. Reich's work took on a darker character in the 1980s with the introduction of historical themes as well as themes from his Jewish heritage, notably the Grammy Award-winning "Different Trains".
Writing in "The Guardian", music critic Andrew Clements suggested that Reich is one of "a handful of living composers who can legitimately claim to have altered the direction of musical history". The American composer and critic Kyle Gann has claimed that Reich "may...be considered, by general acclamation, America's greatest living composer".
Early life.
Reich was born in New York City to the Broadway lyricist June Sillman and Leonard Reich. When he was one year old, his parents divorced, and Reich divided his time between New York and California. He was given piano lessons as a child and describes growing up with the "middle-class favorites", having no exposure to music written before 1750 or after 1900. At the age of 14 he began to study music in earnest, after hearing music from the Baroque period and earlier, as well as music of the 20th century. Reich studied drums with Roland Kohloff in order to play jazz. While attending Cornell University, he minored in music and graduated in 1957 with a B.A. in Philosophy. Reich's B.A. thesis was on Ludwig Wittgenstein; later he would set texts by that philosopher to music in "Proverb" (1995) and "You Are (variations)" (2006).
For a year following graduation, Reich studied composition privately with Hall Overton before he enrolled at Juilliard to work with William Bergsma and Vincent Persichetti (1958–1961). Subsequently he attended Mills College in Oakland, California, where he studied with Luciano Berio and Darius Milhaud (1961–1963) and earned a master's degree in composition. At Mills, Reich composed "Melodica" for melodica and tape, which appeared in 1986 on the three-LP release "Music from Mills".
Reich worked with the San Francisco Tape Music Center along with Pauline Oliveros, Ramon Sender, Morton Subotnick, and Terry Riley. He was involved with the premiere of Riley's "In C" and suggested the use of the eighth note pulse, which is now standard in performance of the piece.
Career.
1960s.
Reich's early forays into composition involved experimentation with twelve-tone composition, but he found the rhythmic aspects of the number twelve more interesting than the pitch aspects. Reich also composed film soundtracks for "Plastic Haircut", "Oh Dem Watermelons", and "Thick Pucker", three films by Robert Nelson. The soundtrack of "Plastic Haircut", composed in 1963, was a short tape collage, possibly Reich's first. The "Watermelons" soundtrack used two 19th-century minstrel tunes as its basis, and used repeated phrasing together in a large five-part canon. The music for "Thick Pucker" arose from street recordings Reich made walking around San Francisco with Nelson, who filmed in black and white 16mm. This film no longer survives. A fourth film from 1965, about 25 minutes long and tentatively entitled "Thick Pucker II", was assembled by Nelson from outtakes of that shoot and more of the raw audio Reich had recorded. Nelson was not happy with the resulting film and never showed it.
Reich was influenced by fellow minimalist Terry Riley, whose work "In C" combines simple musical patterns, offset in time, to create a slowly shifting, cohesive whole. Reich adopted this approach to compose his first major work, "It's Gonna Rain". Composed in 1965, the piece used a fragment of a sermon about the end of the world given by a black Pentecostal street-preacher known as Brother Walter. Reich built on his early tape work, transferring the last three words of the fragment, "it's gonna rain!", to multiple tape loops which gradually move out of phase with one another.
The 13-minute "Come Out" (1966) uses similarly manipulated recordings of a single spoken line given by Daniel Hamm, one of the falsely accused Harlem Six, who was severely injured by police. The survivor, who had been beaten, punctured a bruise on his own body to convince police about his beating. The spoken line includes the phrase "to let the bruise’s blood come out to show them." Reich rerecorded the fragment "come out to show them" on two channels, which are initially played in unison. They quickly slip out of sync; gradually the discrepancy widens and becomes a reverberation. The two voices then split into four, looped continuously, then eight, and continues splitting until the actual words are unintelligible, leaving the listener with only the speech's rhythmic and tonal patterns. In 1999, Rolling Stone magazine dubbed Reich "The Father of Sampling" and compared his work with the parallel evolution of hip-hop culture by DJs such as Kool Herc and Grandmaster Flash.
Reich's first attempt at translating this phasing technique from recorded tape to live performance was the 1967 "Piano Phase", for two pianos. In "Piano Phase" the performers repeat a rapid twelve-note melodic figure, initially in unison. As one player keeps tempo with robotic precision, the other speeds up very slightly until the two parts line up again, but one sixteenth note apart. The second player then resumes the previous tempo. This cycle of speeding up and then locking in continues throughout the piece; the cycle comes full circle three times, the second and third cycles using shorter versions of the initial figure. "Violin Phase", also written in 1967, is built on these same lines. "Piano Phase" and "Violin Phase" both premiered in a series of concerts given in New York art galleries.
A similar, lesser known example of this so-called process music is "Pendulum Music" (1968), which consists of the sound of several microphones swinging over the loudspeakers to which they are attached, producing feedback as they do so. "Pendulum Music" has never been recorded by Reich himself, but was introduced to rock audiences by Sonic Youth in the late 1990s.
Reich also tried to create the phasing effect in a piece "that would need no instrument beyond the human body". He found that the idea of phasing was inappropriate for the simple ways he was experimenting to make sound. Instead, he composed "Clapping Music" (1972), in which the players do not phase in and out with each other, but instead one performer keeps one line of a 12-quaver-long (12-eighth-note-long) phrase and the other performer shifts by one quaver beat every 12 bars, until both performers are back in unison 144 bars later.
The 1967 prototype piece "Slow Motion Sound" was not performed although Chris Hughes performed it 27 years later as "Slow Motion Blackbird" on his Reich-influenced 1994 album "Shift". It introduced the idea of slowing down a recorded sound until many times its original length without changing pitch or timbre, which Reich applied to "Four Organs" (1970), which deals specifically with augmentation. The piece has maracas playing a fast eighth note pulse, while the four organs stress certain eighth notes using an 11th chord. This work therefore dealt with repetition and subtle rhythmic change. It is unique in the context of Reich's other pieces in being linear as opposed to cyclic like his earlier works— the superficially similar "Phase Patterns", also for four organs but without maracas, is (as the name suggests) a phase piece similar to others composed during the period. "Four Organs" was performed as part of a Boston Symphony Orchestra program, and was Reich's first composition to be performed in a large traditional setting.
1970s.
In 1971, Reich embarked on a five-week trip to study music in Ghana, during which he learned from the master drummer Gideon Alorwoyie. Reich also studied Balinese gamelan in Seattle. From his African experience, as well as A. M. Jones's "Studies in African Music" about the music of the Ewe people, Reich drew inspiration for his 90-minute piece "Drumming", which he composed shortly after his return. Composed for a nine-piece percussion ensemble with female voices and piccolo, "Drumming" marked the beginning of a new stage in his career, for around this time he formed his ensemble, Steve Reich and Musicians, and increasingly concentrated on composition and performance with them. Steve Reich and Musicians, which was to be the sole ensemble to interpret his works for many years, still remains active with many of its original members.
After "Drumming", Reich moved on from the "phase shifting" technique that he had pioneered, and began writing more elaborate pieces. He investigated other musical processes such as augmentation (the temporal lengthening of phrases and melodic fragments). It was during this period that he wrote works such as "Music for Mallet Instruments, Voices and Organ" (1973) and "Six Pianos" (1973).
In 1974, Reich began writing "Music for 18 Musicians". This piece involved many new ideas, although it also hearkened back to earlier pieces. It is based on a cycle of eleven chords introduced at the beginning (called "Pulses"), followed by a small section of music based on each chord ("Sections I-XI"), and finally a return to the original cycle ("Pulses"). This was Reich's first attempt at writing for larger ensembles. The increased number of performers resulted in more scope for psychoacoustic effects, which fascinated Reich, and he noted that he would like to "explore this idea further". Reich remarked that this one work contained more harmonic movement in the first five minutes than any other work he had written. Steve Reich and Musicians made the premier recording of this work on ECM Records.
Reich explored these ideas further in his frequently recorded pieces "Music for a Large Ensemble" (1978) and "Octet" (1979). In these two works, Reich experimented with "the human breath as the measure of musical duration ... the chords played by the trumpets are written to take one comfortable breath to perform". Human voices are part of the musical palette in "Music for a Large Ensemble" but the wordless vocal parts simply form part of the texture (as they do in "Drumming"). With "Octet" and his first orchestral piece "Variations for Winds, Strings and Keyboards" (also 1979), Reich's music showed the influence of Biblical cantillation, which he had studied in Israel since the summer of 1977. After this, the human voice singing a text would play an increasingly important role in Reich's music.
In 1974 Reich published the book "Writings About Music", containing essays on his philosophy, aesthetics, and musical projects written between 1963 and 1974. An updated and much more extensive collection, "Writings On Music (1965–2000)", was published in 2002.
1980s.
Reich's work took on a darker character in the 1980s with the introduction of historical themes as well as themes from his Jewish heritage. "Tehillim" (1981), Hebrew for "psalms", is the first of Reich's works to draw explicitly on his Jewish background. The work is in four parts, and is scored for an ensemble of four women's voices (one high soprano, two lyric sopranos and one alto), piccolo, flute, oboe, English horn, two clarinets, six percussion (playing small tuned tambourines without jingles, clapping, maracas, marimba, vibraphone and crotales), two electronic organs, two violins, viola, cello and double bass, with amplified voices, strings, and winds. A setting of texts from psalms 19:2–5 (19:1–4 in Christian translations), 34:13–15 (34:12–14), 18:26–27 (18:25–26), and 150:4–6, "Tehillim" is a departure from Reich's other work in its formal structure; the setting of texts several lines long rather than the fragments used in previous works makes melody a substantive element. Use of formal counterpoint and functional harmony also contrasts with the loosely structured minimalist works written previously.
"Different Trains" (1988), for string quartet and tape, uses recorded speech, as in his earlier works, but this time as a melodic rather than a rhythmic element. In "Different Trains" Reich compares and contrasts his childhood memories of his train journeys between New York and California in 1939–1941 with the very different trains being used to transport contemporaneous European children to their deaths under Nazi rule. The Kronos Quartet recording of "Different Trains" was awarded the Grammy Award for Best Classical Contemporary Composition in 1990. The composition was described by Richard Taruskin as "the only adequate musical response—one of the few adequate artistic responses in any medium—to the Holocaust", and he credited the piece with earning Reich a place among the great composers of the 20th century.
1990s.
In 1993, Reich collaborated with his wife, the video artist Beryl Korot, on an opera, "The Cave", which explores the roots of Judaism, Christianity and Islam through the words of Israelis, Palestinians, and Americans, echoed musically by the ensemble. The work, for percussion, voices, and strings, is a musical documentary, named for the Cave of Machpelah in Hebron, where a mosque now stands and Abraham is said to have been buried.
Reich and Korot collaborated on the opera "Three Tales", which concerns the "Hindenburg" disaster, the testing of nuclear weapons on Bikini Atoll, and other more modern concerns, specifically Dolly the sheep, cloning, and the technological singularity.
Reich used sampling techniques for pieces like "Three Tales" and "City Life" from 1994. Reich returned to composing purely instrumental works for the concert hall, starting with "Triple Quartet" in 1998 written for the Kronos Quartet that can either be performed by string quartet and tape, three string quartets or 36-piece string orchestra. According to Reich, the piece is influenced by Bartók's and Alfred Schnittke's string quartets, and Michael Gordon's "Yo Shakespeare".
2000s.
The instrumental series for the concert hall continued with "Dance Patterns" (2002), "Cello Counterpoint" (2003), and sequence of works centered around Variations: "You Are (Variations)" (2004), a work which looks back to the vocal writing of works like "Tehillim" or "The Desert Music", "Variations for Vibes, Pianos, and Strings" in 2005, for the London Sinfonietta and "Daniel Variations" (2006).
in 2002 Reich was invited by Walter Fink to the annual Komponistenporträt of the Rheingau Musik Festival, as the 12th composer featured.
In an interview with "The Guardian", Reich stated that he continued to follow this direction with his piece "Double Sextet" (2007), which was commissioned by eighth blackbird, an American ensemble consisting of the instrumental quintet (flute, clarinet, violin or viola, cello and piano) of Schoenberg's piece "Pierrot Lunaire" (1912) plus percussion. Reich states that he was thinking about Stravinsky's "Agon" (1957) as a model for the instrumental writing.
December 2010 Nonesuch Records and Indaba Music held a community remix contest in which over 250 submissions were received, and Steve Reich and Christian Carey judged the finals. Reich spoke in a related BBC interview that once he composed a piece he would not alter it again himself; "When it's done, it's done," he said. On the other hand, he acknowledged that remixes have an old tradition e.g. famous religious music pieces where melodies were further developed into new songs.
2010s.
Reich has the world premiere of a piece, "WTC 9/11", written for String Quartet and Tape, a similar instrumentation to that of "Different Trains". It was premiered in March 2011 by the Kronos Quartet, at Duke University, North Carolina, US.
On March 5, 2013 the London Sinfonietta, conducted by Brad Lubman, at the Royal Festival Hall in London gave the world premiere of "Radio Rewrite" for ensemble with 11 players, inspired by the music of Radiohead. The programme also included "Double Sextet" for ensemble with 12 players, "Clapping Music", for two people and four hands featuring Reich himself alongside percussionist Colin Currie, "Electric Counterpoint", with electric guitar by Mats Bergstrom accompanied by a layered soundtrack, as well as two of Reich's small ensemble pieces, one for acoustic instruments, the other for electric instruments and tape.
Awards.
On January 25, 2007, Reich was named 2007 recipient of the Polar Music Prize with jazz saxophonist Sonny Rollins.
On April 20, 2009, Reich was awarded the 2009 Pulitzer Prize for Music, recognizing "Double Sextet", first performed in Richmond March 26, 2008. The citation called it "a major work that displays an ability to channel an initial burst of energy into a large-scale musical event, built with masterful control and consistently intriguing to the ear".
In May 2011 Steve Reich received an honorary doctorate from the New England Conservatory of Music.
In 2013 Reich received the US$400,000 BBVA Foundation Frontiers of Knowledge Award in contemporary music for bringing a new conception of music, based on the use of realist elements from the realm of daily life and others drawn from the traditional music of Africa and Asia.
In September 2014, Reich was awarded the "Leone d'Oro" (Golden Lion for Lifetime Achievement in Music) from the Venice Biennale.
In March 2016, Reich was awarded an Honorary Doctorate by the Royal College of Music in London.
Influence.
Reich's style of composition has influenced many other composers and musical groups, including John Adams, the progressive rock band King Crimson, the new-age guitarist Michael Hedges, the art-pop and electronic musician Brian Eno, the experimental art/music group The Residents, the composers associated with the Bang on a Can festival (including David Lang, Michael Gordon, and Julia Wolfe), and numerous indie rock musicians including songwriter Sufjan Stevens and instrumental ensembles Tortoise, The Mercury Program (themselves influenced by Tortoise), and Godspeed You! Black Emperor (who titled an unreleased song "Steve Reich").
John Adams commented, "He didn't reinvent the wheel so much as he showed us a new way to ride." He has also influenced visual artists such as Bruce Nauman, and many notable choreographers have made dances to his music, Eliot Feld, Jiří Kylián, Douglas Lee and Jerome Robbins among others; he has expressed particular admiration of Anne Teresa De Keersmaeker's work set to his pieces.
In featuring a sample of Reich's "Electric Counterpoint" (1987) the British ambient techno act the Orb exposed a new generation of listeners to the composer's music with its 1990 production "Little Fluffy Clouds". In 1999 the album "Reich Remixed" featured "re-mixes" of a number of Reich's works by various electronic dance-music producers, such as DJ Spooky, Kurtis Mantronik, Ken Ishii, and Coldcut amongst others.
Reich often cites Pérotin, J.S. Bach, Debussy, Bartók, and Stravinsky as composers whom he admires and who greatly influenced him when he was young. Jazz is a major part of the formation of Reich's musical style, and two of the earliest influences on his work were vocalists Ella Fitzgerald and Alfred Deller, whose emphasis on the artistic capabilities of the voice alone with little vibrato or other alteration was an inspiration to his earliest works. John Coltrane's style, which Reich has described as "playing a lot of notes to very few harmonies", also had an impact; of particular interest was the album "Africa/Brass", which "was basically a half-an-hour in F." Reich's influence from jazz includes its roots, also, from the West African music he studied in his readings and visit to Ghana. Other important influences are Kenny Clarke and Miles Davis, and visual artist friends such as Sol LeWitt and Richard Serra. Reich has also stated that he admires the music of the band Radiohead, which led to his composition "Radio Rewrite". Reich recently contributed the introduction to "Sound Unbound: Sampling Digital Music and Culture" (The MIT Press, 2008) edited by Paul D. Miller, a.k.a. DJ Spooky.

</doc>
<doc id="26823" url="https://en.wikipedia.org/wiki?curid=26823" title="Simon &amp; Garfunkel">
Simon &amp; Garfunkel

Simon & Garfunkel were an American folk rock duo consisting of singer-songwriter Paul Simon and singer Art Garfunkel. They were one of the most popular recording artists of the 1960s and became counterculture icons of the decade's social revolution, alongside artists such as the Beatles, the Beach Boys, and Bob Dylan. Their biggest hits—including "The Sound of Silence" (1964/1965), "Mrs. Robinson" (1968), "Bridge over Troubled Water" (1969), and "The Boxer" (1969)—reached number one on singles charts worldwide. Their often rocky relationship led to artistic disagreements, which resulted in their breakup in 1970. Their final studio record, "Bridge over Troubled Water", was their most successful, becoming one of the world's best-selling albums. Since their split in 1970 they have reunited several times, most famously in 1981 for the "The Concert in Central Park", which attracted more than 500,000 people, the seventh-largest concert attendance in history.
The duo met as children in Queens, New York in 1953, where they learned to harmonize together and began writing original material. By 1957, under the name Tom & Jerry, the teenagers had their first minor success with "Hey Schoolgirl", a song imitating their idols the Everly Brothers. Afterwards, the duo went their separate ways, with Simon making unsuccessful solo records. In 1963, aware of a growing public interest in folk music, they regrouped and were signed to Columbia Records as Simon & Garfunkel. Their début, "Wednesday Morning, 3 A.M.", sold poorly, and they once again disbanded; Simon returned to a solo career, this time in England. A remix of their song "The Sound of Silence" was played widely on U.S. AM radio in 1965, reaching number one on the "Billboard" Hot 100. Simon & Garfunkel reunited, releasing their second studio album "Sounds of Silence" and touring colleges nationwide. On their third release, "Parsley, Sage, Rosemary and Thyme" (1966), the duo assumed more creative control. Their music was featured in the 1967 film "The Graduate", giving them further exposure. "Bookends" (1968), their next album, topped the Billboard 200 chart and included the #1 single "Mrs. Robinson" from the film. After their 1970 breakup following the release of "Bridge over Troubled Water," they both continued recording, Simon releasing a number of highly acclaimed albums, including 1986's "Graceland". Garfunkel also briefly pursued an acting career, with leading roles in two Mike Nichols films, "Catch-22" and "Carnal Knowledge", and in Nicolas Roeg's 1980 "Bad Timing".
Simon & Garfunkel were described by critic Richie Unterberger as "the most successful folk-rock duo of the 1960s" and one of the most popular artists from the decade in general. They won 10 Grammy Awards and were inducted into the Rock and Roll Hall of Fame in 1990. Their "Bridge over Troubled Water" album was nominated at the 1977 Brit Awards for Best International Album and is ranked at #51 on Rolling Stone's 500 Greatest Albums of All Time.
History.
Early years (1953–56).
Paul Simon and Art Garfunkel grew up in the 1940s and 1950s in the predominantly Jewish neighborhood of Forest Hills in Queens, New York, just three blocks away from one another, and attended the same schools, Public School 164 in Flushing, Parsons Junior High School, and Forest Hills High School. Individually, when still young, they developed a fascination with music; both listened to the radio and were taken with rock and roll as it emerged, particularly the Everly Brothers. When Simon first noticed Garfunkel, he was singing in a fourth grade talent show, and Simon thought that was a good way to attract girls; he hoped for a friendship which eventually started in 1953 when they were in the sixth grade and appeared on stage together in a school play adaptation of "Alice in Wonderland". That first stage appearance was followed by the duo forming a street-corner doo-wop group, the Peptones, with three other friends, and learning to harmonize together. They began performing for the first time as a duo at school dances.
They moved to Forest Hills High School in 1955, where, in 1956, they wrote their first song, "The Girl for Me"; Simon's father sent a handwritten copy to the Library of Congress to register a copyright. While trying to remember the lyrics to the Everly's song "Hey Doll Baby", they created their own song, "Hey Schoolgirl", which they recorded themselves for $25 at Sanders Recording Studio in Manhattan. While recording they were overheard by a promoter, Sid Prosen, who – after speaking to their parents – signed them to his independent label Big Records.
From Tom & Jerry to Simon & Garfunkel (1957–1964).
While still aged 15, Simon & Garfunkel now had a recording contract with Sid Prosen's independent label Big Records. Using the name Tom & Jerry (Garfunkel naming himself Tom Graph, a reference to his interest in mathematics) and Simon naming himself Jerry Landis (after the surname of Sue Landis, a girl he had dated) the single "Hey Schoolgirl" was released, with the B-side "Dancin' Wild", in 1957. Prosen, using the payola system, bribed Alan Freed $200 to get the single played on his radio show, where it became a nightly staple. "Hey Schoolgirl" attracted regular rotation on nationwide AM pop stations, leading it to sell over 100,000 copies and to land on "Billboard" charts at number 49. Prosen promoted the group heavily, getting them a spot on Dick Clark's "American Bandstand" (headlining alongside Jerry Lee Lewis). The duo shared approximately $4,000 from the song – earning two percent each from royalties, the rest staying with Prosen. They released three more singles on Big Records: "Our Song", "That's My Story", and "Don't Say Goodbye", none of them successful.
After graduating from Forest Hills High School in 1959, they were still exploring the possibilities of a music career, though continued their education as a back up; Simon studying English at Queens College, City University of New York, Garfunkel studying first architecture, then switching to art history at Columbia College, Columbia University. While still with Big Records as a duo, Simon released a solo single, "True or False", under the name "True Taylor". This recording upset Garfunkel, who regarded it as a betrayal; the emotional tension from that incident occasionally surfacing throughout their relationship. Their last recording with Big Records was a cover of a Jan and Dean single, "Baby Talk", but the company became bankrupt soon after release; the track was reissued on Bell Records, but failed to sell, so Tom & Jerry was dissolved. Both, however, continued recording, albeit as solo artists: Garfunkel composing and recording "Private World" for Octavia Records, and - under the name Artie Garr - "Beat Love" for Warwick; Simon recorded with The Mystics, and Tico & The Triumphs, and wrote and recorded under the names Jerry Landis and Paul Kane. Simon also wrote and performed demos for other artists, working for a while with Carole King and Gerry Goffin.
After graduating in 1963, Simon joined Garfunkel, who was still at Columbia, to perform together again as a duo, this time with a shared interest in folk music. Simon enrolled part-time in Brooklyn Law School, By late 1963, billing themselves as "Kane & Garr", they performed at Gerde's Folk City, a Greenwich club that hosted Monday night open mic performances. The duo performed three new songs — "Sparrow", "He Was My Brother", and "The Sound of Silence" — and got the attention of Columbia producer Tom Wilson, who worked with Bob Dylan. As a "star producer" for the label, he wanted to record "He Was My Brother" with a new British act named the Pilgrims. Simon convinced Wilson to let him and his partner have a studio audition, and they performed "The Sound of Silence". House engineer Roy Halee recorded the audition, and at Wilson's urging, Columbia signed the duo.
Their debut studio album, "Wednesday Morning, 3 A.M.", was recorded over three daytime sessions in March 1964 and released in October. The album contains four original Simon compositions, with the remainder consisting of three traditional folk songs and five folk-influenced singer-songwriter numbers. Simon was adamant that they would no longer use stage names, and they adopted the name Simon & Garfunkel. Columbia set up a promotional showcase at Folk City on March 31, 1964, the duo's first public concert as Simon & Garfunkel. The showcase, as well as other scheduled performances, did not go well.
Simon in England (1964–65).
"Wednesday Morning, 3 A.M." sold only 3,000 copies upon its October release, and its poor sales led Simon to move to England where he had previously visited and played some gigs.
He toured the small folk clubs, appearing on the same bill and befriending British folk artists such as Bert Jansch, Martin Carthy, Al Stewart, and Sandy Denny. He met Kathy Chitty, who became the object of his affection and is the Kathy in "Kathy's Song" and "America".
A small music publishing company, Lorna Music, licensed "Carlos Dominguez", a single Simon had cut two years prior as "Paul Kane", for a cover by Val Doonican that sold very well. Simon visited Lorna to thank them, and the meeting resulted in a publishing and recording contract. He signed to the Oriole label and released "He Was My Brother" as a single. Simon invited Garfunkel to stay for the summer of 1964. Near the end of the season, Garfunkel returned to Columbia for class, and Simon surprised his friends by saying that he would be returning to the States as well. He would resume his studies at Brooklyn Law School for one semester, partially at his parents' insistence. He returned to England in January 1965, now certain that music was his calling. In the meantime, his landlord, Judith Piepe, had compiled a tape from his work at Lorna and sent it to the BBC in hopes they would play it. The demos aired on the "Five to Ten" morning show, and were instantly successful. Oriole had folded into CBS by that point, and hoped to record a new Paul Simon album. "The Paul Simon Songbook" was recorded in June 1965 and featured multiple future Simon & Garfunkel staples, among them "I Am a Rock" and "April Come She Will". CBS flew Wilson over to produce the record, and he stayed at Simon's flat. The album saw release in August, and although sales were poor, Simon felt content with his future in England.
Meanwhile, in the United States, a late-night disc jockey at WBZ-FM in Boston played "The Sound of Silence", where it found a college demographic. It was picked up the next day along the East Coast of the United States, down to Cocoa Beach, Florida. Wilson, inspired by the folk rock sound of the Byrds' cover of "Turn! Turn! Turn!" and Dylan's "Like a Rolling Stone", created a rock remix of the song using studio musicians. The remix of "The Sound of Silence" was issued in September 1965, where it reached the "Billboard" Hot 100. Wilson had not informed the duo of his intention to remix the track; as such, Simon was "horrified" when he first heard it. Garfunkel graduated in 1965, returning to Columbia University to do a master's degree in mathematics.
Mainstream breakthrough and success (1965–66).
By January 1966, "The Sound of Silence" topped the Hot 100, selling over one million copies. Simon reunited with Garfunkel that winter in New York, leaving Chitty and his friends in England behind. CBS demanded a new album from the duo, to be called "Sounds of Silence" to ride the wave of the hit. Recorded in three weeks, and mainly consisting of re-recorded songs from "The Paul Simon Songbook", plus four new tracks, "Sounds of Silence" was rush-released onto the market in mid-January 1966, peaking at number 21 "Billboard" Top LPs chart. A week later, "Homeward Bound" was released as a single, entering the USA top ten, followed by "I Am a Rock" peaking at number three. The duo supported the recordings with a nationwide tour of America, while CBS continued their promotion by re-releasing "Wednesday Morning, 3 A.M.", which promptly charted at number 30. Despite the commercial and popular success, the duo received critical derision, as many considered them a manufactured imitation of folk.
As they considered their previous effort a "rush job" to capitalize on their sudden success, the duo spent more time crafting the follow-up. It was the first time Simon insisted on total control in aspects of recording. Work began in 1966 and took nine months. Garfunkel considered the recording of "Scarborough Fair" to be the point at which they stepped into the role of producer, as they were constantly beside engineer Roy Halee mixing the track. "Parsley, Sage, Rosemary and Thyme" was issued in October 1966, following the release of several singles and receiving sold-out college campus shows. The duo resumed their trek on the college circuit eleven days following the release, crafting an image that was described as "alienated", "weird", and "poetic". Manager Mort Lewis also was responsible for this public perception, as he withheld them from television appearances (unless they were allowed to play an uninterrupted set or choose the setlist). Simon, then 26, felt he had finally "made it" into an upper echelon of rock and roll, while most importantly retaining artistic integrity ("making him spiritually closer to Bob Dylan than to, say, Bobby Darin", wrote biographer Marc Eliot). The duo chose William Morris as their booking agency after a recommendation from Wally Amos, a mutual friend through their producer Tom Wilson.
During the sessions for "Parsley", the duo cut "A Hazy Shade of Winter"; it was released as a single, peaking at number 13 on the national charts. Similarly, they recorded "At the Zoo" for single release in early 1967 (it charted lower, at number 16). Simon began work for their next album around this time, noting to a writer at "High Fidelity" that "I'm not interested in singles anymore". He had hit a dry spell in his writing, which led to no Simon & Garfunkel album on the horizon for 1967. Artists at the time were expected to release two, perhaps three albums each year and the lack of productivity from the duo worried executives at Columbia Records. Amid concerns for Simon's idleness, Columbia Records chairman Clive Davis arranged for up-and-coming record producer John Simon to kick-start the recording. Simon was distrustful of "suits" at the label; on one occasion, he and Garfunkel brought a tape recorder into a meeting with Davis, who was giving a "fatherly talk" on speeding up production, in order to laugh at it later. The rare television appearances at this time saw the duo performing on such diverse network broadcasts as the Ed Sullivan, Mike Douglas and Andy Williams shows in 1966 and twice on The Smothers Brothers Comedy Hour in 1967.
Meanwhile, director Mike Nichols, then filming "The Graduate", had become fascinated with the duo's past two efforts, listening to them nonstop before and after filming. After two weeks of this obsession, he met with Clive Davis to ask for permission to license Simon & Garfunkel music for his film. Davis viewed it as a perfect fit and envisioned a best-selling soundtrack album. Simon was not as immediately receptive, viewing movies akin to "selling out", creating a damper on his artistic integrity. However, after meeting Nichols and becoming impressed by his wit and the script, he agreed to write at least one or two new songs for the film. Leonard Hirshan, a powerful agent at William Morris, negotiated a deal that paid Simon $25,000 to submit three songs to Nichols and producer Lawrence Turman. Several weeks later, Simon re-emerged with two new tracks, "Punky's Dilemma" and "Overs", neither of which Nichols was particularly taken with. The duo offered another new song, which later became "Mrs. Robinson", that was not as developed. Nichols loved it.
Studio time and low profile (1967–68).
The duo's fourth studio album, "Bookends", was recorded in fits and starts over various periods from late 1966 to early 1968. The duo were signed under an older contract that specified the label pay for sessions, and Simon & Garfunkel took advantage of this indulgence, hiring viola and brass players, as well as percussionists. The record's brevity reflects its concise and perfectionist production. The team spent over 50 studio hours recording "Punky's Dilemma", for example, and re-recorded vocal parts, sometimes note by note, until they were satisfied. Garfunkel's songs and voice took a lead role on some of the songs, and the harmonies for which the duo was known gradually disappeared. For Simon, "Bookends" represented the end of the collaboration and became an early indicator of his intentions to go solo. Although the album had been planned long in advance, work did not begin in earnest until the late months of 1967.
Prior to release, the band helped put together and performed at the Monterey Pop Festival, which signaled the beginning of the Summer of Love on the West Coast. "Fakin' It" was issued as a single that summer and found only modest success on AM radio; the duo were much more focused on the rising FM format, which played album cuts and treated their music with respect. In January 1968, the duo appeared on a Kraft Music Hall special, "Three for Tonight", performing ten songs largely culled from their third album. "Bookends" was released by Columbia Records in April 1968. In a historical context, this was just 24 hours before the assassination of Civil Rights Movement activist Martin Luther King, Jr., which spurred nationwide outrage and riots. The album debuted on the "Billboard" Top LPs in the issue dated April 27, 1968, climbing to number one and staying at that position for seven non-consecutive weeks; it remained on the chart as a whole for 66 weeks. "Bookends" received such heavy orders weeks in advance of its release that Columbia was able to apply for award certification before copies left the warehouse, a fact it touted in magazine ads. The record became the duo's best-selling album to date: it fed off the buzz created by the release of "The Graduate" soundtrack album ten weeks earlier, creating an initial combined sales figure of over five million units.
Davis had predicted this fact, and suggested raising the list price of "Bookends" by one dollar to $5.79, above the then standard retail price, to compensate for including a large poster included in vinyl copies. Simon instead scoffed and viewed it as charging a premium on "what was sure to be that year's best-selling Columbia album". According to biographer Marc Eliot, Davis was "offended by what he perceived as their lack of gratitude for what he believed was his role in turning them into superstars". Rather than implement Davis' price increase plan, Simon & Garfunkel signed a contract extension with Columbia that guaranteed them a higher royalty rate. Lead single "Mrs. Robinson" became, at the 1969 Grammy Awards the first rock and roll song to receive Record of the Year; it was also awarded Best Contemporary Pop Performance by a Duo or Group.
Growing apart and final years (1969–70).
"Bookends", alongside "The Graduate" soundtrack, propelled Simon & Garfunkel to become the biggest rock duo in the world. Simon was approached by producers to write music for films or license songs; he turned down Franco Zeffirelli, who was preparing to film "Brother Sun, Sister Moon", and John Schlesinger, who likewise was readying to shoot "Midnight Cowboy". In addition to Hollywood proposals, producers from the Broadway show "Jimmy Shine" (starring Simon's friend Dustin Hoffman, also the lead in "Midnight Cowboy") asked for two original songs and Simon declined. He collaborated briefly with Leonard Bernstein on a sacred mass before withdrawing from the project due to "finding it perhaps too far afield from his comfort zone". Garfunkel took the role of Captain Nately in the Nichols film, "Catch-22", based on the "Catch-22" novel. Initially Simon was to play the character of Dunbar, but screenwriter Buck Henry felt the film was already crowded with characters and subsequently wrote Simon's part out.
The filming of "Catch-22" began in January 1969 and lasted about eight months. The unexpectedly long film production endangered the relationship between the duo; Simon had not completed any new songs at this point, and the duo planned to collaborate when the filming would be finished. Following the end of filming of "Catch-22" in October, the first performance of what was, for a time, their last tour, took place in Ames, Iowa. The US leg of the tour ended in the sold-out Carnegie Hall on November 27. After breaking for Christmas, the duo continued working on the album in early 1970 and finished it in late January. Meanwhile, the duo, working with director Charles Grodin, produced an hourlong CBS special, "Songs of America", which is a mixture of scenes featuring notable political events and leaders concerning the USA, such as the Vietnam War, Martin Luther King, John F. Kennedy's funeral procession, Cesar Chavez and the Poor People's March. It was broadcast only once, due to internal tension at the network regarding its content.
"Bridge over Troubled Water", their final studio album, was released in January 1970 and charted in over 11 countries, topping the charts in 10, including the "Billboard" Top LP's chart in the US and the UK Albums Chart. It was the best-selling album in 1970, 1971 and 1972 and was at that time the best-selling album of all time. It was also CBS Records' best-selling album before the release of Michael Jackson's "Thriller" in 1982. The album topped the "Billboard" charts for 10 weeks and stayed in the charts for 85 weeks. In the United Kingdom, the album topped the charts for 35 weeks, and spent 285 weeks in the top 100, from 1970 to 1975. It has since sold over 25 million copies worldwide. "Bridge over Troubled Water", the album's lead single, hit number one in five countries and became their biggest seller. The song has been covered by over 50 artists since then, including Elvis Presley and Johnny Cash. "Cecilia", the follow-up, hit number four in the US, and "El Condor Pasa" hit number 18.
The recording process was tough for both musicians, and their breakup was almost certain considering the deterioration of their relationship. "At that point, I just wanted out," Simon later said. Their breakup was not intended to be semi-permanent: Garfunkel hoped for a two-year break from Simon & Garfunkel and did not intend to pursue a film-career. Likewise, Simon did not intend to begin a solo career. A brief British tour followed the album release, and the duo's last concert as Simon & Garfunkel occurred at Forest Hills Stadium. In 1971, the album took home six awards at the 13th Annual Grammy Awards, including Album of the Year. Simon's wife, Peggy Harper, pushed for him to make the split official, and he placed a call to Davis to confirm the duo's breakup: "I want you to know I’ve decided to split with Artie. I don’t think we’ll be recording together again." For the next several years, the duo would only speak "two or three" times a year.
Breakup, rifts, and reunions (1971–2003).
In the 1970s, the duo reunited several times. Their first reunion was a benefit concert for presidential candidate George McGovern at New York's Madison Square Garden in June 1972. In 1975, they reconciled once more when they visited a recording session with John Lennon and Harry Nilsson. For the rest of the year, they attempted to make the reunion work, but their collaboration only yielded one song, "My Little Town," that was featured on Simon's "Still Crazy After All These Years" and Garfunkel's "Breakaway". It peaked at number nine on the Hot 100. In 1975, Garfunkel joined Simon for a medley of three songs on the television series "Saturday Night Live" which Simon was guest hosting. In 1977, Garfunkel joined Simon for a brief performance of their old songs on Simon's television special "The Paul Simon Special", and later that year they recorded a cover of Sam Cooke's "(What a) Wonderful World" along with James Taylor. Old tensions finally appeared to dissipate upon Garfunkel's return to New York in 1978, when the duo began interacting more often. On May 1, 1978, Simon joined Garfunkel for a concert held at Carnegie Hall to benefit the hearing disabled.
By 1980, the duo's respective solo efforts were not doing well. To help alleviate New York's economic decline, concert promoter Ron Delsener came up with the idea to throw a free concert in Central Park. Delsener contacted Simon with the idea of a Simon & Garfunkel reunion, and once Garfunkel agreed, plans were made. The Concert in Central Park, performed September 19, 1981, attracted more than 500,000 people, at that time the largest-ever concert attendance. Warner Bros. Records released a live album of the show that went double platinum in the US. A 90-minute recording of the concert was sold to Home Box Office (HBO) for over $1 million. The concert created a renewed interest in the duo's work. They had several "heart-to-heart talks," attempting to put past issues behind them. The duo planned a world tour, kicking off in May 1982, but their relationship grew contentious: for the majority of the tour, they did not speak to one another. Warner Bros. pushed for them to extend the tour and release an all-new Simon & Garfunkel studio album.
After recording several vocal tracks for a possible new Simon & Garfunkel album, Simon decided to adopt it as his own solo album. Garfunkel had refused to learn the songs in the studio, and would not give up cannabis and cigarettes, despite Simon's requests. An official spokesperson remarked, "Paul simply felt the material he wrote is so close to his own life that it had to be his own record. Art was hoping to be on the album, but I'm sure there will be other projects that they will work on together. They are still friends." The material was later released on Simon's 1983 effort "Hearts and Bones". Another rift opened between the duo when the lengthy recording of Simon's 1986 album "Graceland" prevented Garfunkel from working with Roy Halee on a Christmas album. In 1990, the duo was inducted into the Rock and Roll Hall of Fame. Garfunkel thanked his partner, calling him "the person who most enriched my life by putting those songs through me," to which Simon responded, "Arthur and I agree about almost nothing. But it's true, I have enriched his life quite a bit." After three songs, the duo left without speaking.
By 1993, their relationship had thawed again, and Simon invited Garfunkel on an international tour with him. Following a 21-date, sold-out run at the Paramount Theater in New York and an appearance at that year's Bridge School Benefit in California, the duo toured the Far East. The duo had a falling out over the course of the rest of the decade, the details of which have never been disclosed. Simon thanked Garfunkel at his 2001 induction into the Rock and Roll Hall of Fame as a solo artist: "I regret the ending of our friendship. I hope that some day before we die we will make peace with each other," resuming after a pause, "No rush." They were awarded a Lifetime Achievement Award at the 45th Annual Grammy Awards in 2003, for which the promoters convinced them to reconcile and open the show with a performance of "The Sound of Silence." The performance was satisfying for both musicians, and they planned out a full-scale reunion tour over the summer. The Old Friends tour began in October 2003 and played to sold-out audiences across the United States for 30 dates until mid-December. The tour earned an estimated $123 million. Following a twelve-city run in Europe in 2004, they ended their nine-month tour with a free concert at the Colosseum in Rome. It attracted 600,000 fans, more than their The Concert in Central Park.
Recent years (2009–present).
In 2009, the duo reunited again for three songs during Simon's two-night engagement at New York's Beacon Theatre. This led to a reunion tour of Asia and Australia in June 2009. Their headlining set at the 2010 New Orleans Jazz and Heritage Festival was very difficult for Garfunkel, who was experiencing serious vocal problems. "I was terrible, and crazy nervous. I leaned on Paul Simon and the affection of the crowd," he told "Rolling Stone" several years later. Garfunkel was diagnosed with vocal cord paresis, and the remaining tour dates were postponed indefinitely. His manager, John Scher, informed Simon's camp that Garfunkel would be ready within a year, which did not happen, leading to poor relations between the two. He regained his vocal strength over the course of the next four years, performing shows in a Harlem theater and to underground audiences.
Despite this, the duo have not staged a full-scale tour or performed shows since 2010. Garfunkel confirmed to "Rolling Stone" in 2014 that he believes they will tour in the future, although Simon had been too "busy" in recent years. "I know that audiences all over the world like Simon and Garfunkel. I'm with them. But I don't think Paul Simon's with them," he remarked. In a 2016 interview with Rolling Stone when asked about the possibility of reuniting, Simon simply stated; "No. Out of the question. We don't even talk."
Musical style and legacy.
Over the course of their career, Simon & Garfunkel's music gradually moved from a very basic, folk rock sound to incorporate more experimental elements for the time, including Latin and gospel music. Many adolescents of the 1960s found their music relevant, while adults regarded them as intelligent. Their music, according to "Rolling Stone", struck a chord among lonely, alienated young adults near the end of the decade.
Despite its popularity, the group was also criticized sharply, especially in its heyday. "Rolling Stone" critic Arthur Schmidt, for example, described the duo's music as "questionable...it exudes a sense of process, and it is slick, and nothing too much happens." "New York Times" critic Robert Shelton said that the group had "a kind of Mickey Mouse, timid, contrived" approach to music.
Their clean sound and muted lyricism "cost them some hipness points during the psychedelic era" according to Richie Unterberger of AllMusic, who also notes that the duo "inhabited the more polished end of the folk-rock spectrum and was sometimes criticized for a certain collegiate sterility." Unterberger further observes that some critics would later regard Simon's lyricism in his work with Simon & Garfunkel to pale in comparison to his later solo material. But Unterberger himself believed that "the best of S&G's work could stand among Simon's best material, and the duo did progress musically over the course of their five albums, moving from basic folk-rock productions into Latin rhythms and gospel-influenced arrangements that foreshadowed Simon's eclecticism on his solo albums." Their rocky personal relationship led to their "breaking up and making up about every dozen years."
Awards.
The Grammy Awards are held annually by the National Academy of Recording Arts and Sciences. Simon & Garfunkel have won 10 total awards.

</doc>
<doc id="26824" url="https://en.wikipedia.org/wiki?curid=26824" title="State Street Corporation">
State Street Corporation

State Street Corporation, known as State Street, is an American worldwide financial services holding company. State Street was founded in 1792 and is the second oldest financial institution in the United States of America. The company’s headquarters are at One Lincoln Street in Boston and it has offices in 29 countries around the world.
State Street is organized into three main divisions. The Global Services business is a custodian bank with $28 trillion (USD) of assets under custody and administration. The Global Advisors business provides investment management services and has $2.45 trillion (USD) of assets under management. The Global Markets business offers investment research and trading services to institutional investors.
History.
State Street’s past can be dated back to the founding years of Boston’s banking industry. In 1792 the Union Bank became the third bank to be chartered in Boston and was located at the corner of State and Exchange Streets. State Street was known as the “Great Street to the Sea” as Boston became a flourishing maritime capital. The clipper in State Street’s logo today reflects this period.
In 1865 the Union Bank received a national charter and became the National Union Bank of Boston. State Street Deposit & Trust Co opened alongside National Union in 1891. It became the custodian of the first US mutual fund in 1924, the Massachusetts Investors Trust. State Street and National Union merged in 1925.
State Street’s growth during the mid-1900s was fueled by mergers and acquisitions. It merged with the Second National Bank in 1955 and with the Rockland-Atlas National Bank in 1961. William Edgerly gained control in 1975 and shifted the company’s strategy from commercial banking to investments and securities processing.
The company began investing heavily in technologies for securities management and custodian processing. It was helped by a partial acquisition of Boston Financial Data Services in 1973. More than 100 top staff from IBM were headhunted by State Street as it set about implementing IBM mainframe systems.
State Street’s new building was completed in 1966 and became the first high-rise office tower in downtown Boston. In 1972 the company opened its first international office in Munich. For much of the 1980s and 1990s it expanded to foreign markets with offices in Montreal, Toronto, Dublin, London, Paris, Dubai, Sydney, Wellington, Hong Kong, and Tokyo.
It was the early 1990s before State Street brought its technology platform to international markets. By 1992 most of State Street’s revenue came from fees for holding securities, settling trades, keeping records, and performing accounting. It formed a new global asset management business in 1994 and in 1999 divested its retail and commercial banking businesses to Citizens Financial Group.
State Street acquired Kansas City, Missouri-based Investors Fiduciary Trust Co. in 1995 for $162 million (USD) from DST Systems, and Kemper Financial Services. In 2003 it purchased Deutsche Bank’s securities services division for $1.5 billion (USD). State Street purchased Investors Financial Services for $4.5 billion (USD) in 2007. In 2010 it acquired Mourant International Finance Administration and the securities services group of Intesa Sanpaolo.
State Street was named by the G-20 as amongst the world’s 29 systemic banks and must meet all conditions of the Basel III accord. The company now employs 29,530 people around the world. It claims to have funds under management of $2.45 trillion (USD) and assets under custody and administration of $28 trillion (USD), second to The Bank of New York Mellon.
Organization.
State Street Global Advisors.
Global Advisors is State Street’s asset management business and dates back to 1978. It provides investment management, research, and advisory services to corporations, mutual funds, insurance companies, and other institutional investors. Global Advisors develops both passive and active management strategies using both quantitative and fundamental approaches.
It created the first exchange-traded fund in 1993, the SPDR S&P 500, and is now one of the world’s largest ETF providers. Global Advisors has staff in 27 global offices and claims to have over $2.45 trillion (USD) of funds under management.
In November 2014, State Street Global Advisors sold SSARIS to senior management.
State Street Global Markets.
Global Markets is State Street’s securities business. It offers research, trading, and securities lending services for foreign exchange, equities, fixed income, and derivatives. The company claims to be a trading partner free from conflicted interests as it does not run proprietary trading books. Global Markets maintains trading desks in Boston, London, Sydney, Toronto, and Tokyo.
State Street Global Services.
Global Services is the investment servicing division of State Street, also known as the State Street Bank & Trust Co. It provides asset owners and managers with custodian (safekeeping, corporate actions), fund accounting (pricing and valuation), and administration (financial reporting, tax, compliance, and legal) services.
Global Services handles assets from many classes, including equities, derivatives, exchange-traded funds, fixed income assets, private equity, and real estate. State Street now administers 40 percent of the assets under administration in the US mutual fund market. Global Services also provides outsourcing for operations activities and handles $10.2 trillion (USD) of middle-office assets.
Regulation.
State Street is registered with the Board of Governors of the Federal Reserve System as a bank holding company pursuant to the Bank Holding Company Act of 1956. It is a member of the Federal Reserve System and its deposits are insured by the Federal Deposit Insurance Corporation. Certain aspects of State Street’s public disclosure are subject to the requirements of the Sarbanes–Oxley Act of 2002.
State Street’s broker-dealer operation, known as Global Markets, is registered with and regulated by the Securities and Exchange Commission and the New York Stock Exchange in the United States. The Prudential Regulation Authority and the London Stock Exchange regulate State Street in the United Kingdom.
Controversies.
In 2009 the State of California alleged on behalf of its pension funds CalPERS and CalSTRS that State Street had committed fraud on currency trades handled by the custodian bank. Two executives from State Street Global Markets left the company in October 2011 following enquiries over the pricing of a fixed income transaction.
State Street in December 2010 announced that it would be retrenching 5% of its workforce and effectively reducing the wages of remaining employees by 10%. In March 2011 it reversed its wage-reduction decision but declared that it would still require all employees to work a longer 40 hour week.
On 28 February 2012, State Street Global Advisors entered into a consent order with the Massachusetts Securities Division. The Division was investigating SSGA’s role as the investment manager of a $1.65 billion (USD) hybrid collateralized debt obligation. The investigation resulted in a fine of $5 million (USD) for the non-disclosure of certain initial investors taking a short position on portions of the CDO.
State Street Bank has been accused of "stealth outsourcing" or transferring American jobs to their outsourcing partners Syntel and HCL-India under the radar, in small increments to avoid any political backlash. State Street Bank - the second largest client of Syntel - also has a joint venture in the Indian city of Pune with them which they have the option to buy out. The controversy is compounded by the fact State Street bank received an $11.5 million tax incentive from the city of Boston to move into a new location in the South Boston Innovation District as well as 2 billion in TARP assistance all while still sending jobs overseas.
During the May 2012 annual shareholders meeting, chairman and chief executive Jay Hooley was shouted down on numerous occasions by protesters in relation to the outsourcing and other grievances.
See also.
"State Street Bank v. Signature Financial Group" is the landmark case in which the Court of Appeals for the Federal Circuit ruled (23 July 1998) that a computer algorithm can be patented to the extent that it produces "a useful, concrete and tangible result".

</doc>
<doc id="26825" url="https://en.wikipedia.org/wiki?curid=26825" title="Spanish language">
Spanish language

Spanish (, '), also called Castilian'" (, ), is a Romance language that originated in the Castile region of Spain and today has hundreds of millions of native-speakers across the world.
Spanish is a part of the Ibero-Romance group of languages, which evolved from several dialects of common Latin in Iberia after the collapse of the Western Roman Empire in the 5th century. It was first documented in central-northern Iberia in the 9th century and gradually spread with the expansion of the Kingdom of Castile into central and southern Iberia. Beginning in the early 16th century, Spanish was taken to the colonies of the Spanish Empire, most notably to the Americas, as well as territories in Africa, Oceania and the Philippines.
From its beginnings, Spanish vocabulary was influenced by its contact with Basque and Germanic languages, as well as by neighboring Ibero-Romance languages, and later it absorbed many Arabic words during the Al-Andalus era in the Iberian Peninsula. It also adopted words from non-Iberian languages, particularly the Romance languages Occitan, French, Italian and Sardinian, as well as from Nahuatl and other Indigenous languages of the Americas.
Spanish is one of the six official languages of the United Nations. It is also used as an official language by the European Union, the Organization of American States, and the Union of South American Nations, and by many other international organizations.
Estimated number of speakers.
It is estimated that more than 427 million people speak Spanish as a native language, which qualifies it as second on the lists of languages by number of native speakers. Instituto Cervantes claims that there are an estimated 470 million Spanish speakers with native competence and 559 million Spanish speakers as a first or second language, including speakers with limited competence and more than 21 million students of Spanish as a foreign language.
Spanish is the official or national language in Spain, Equatorial Guinea, and 19 countries in the Americas. Speakers in the Western Hemisphere total some 418 million. In the European Union, Spanish is the mother tongue of 8% of the population, with an additional 7% speaking it as a second language. Spanish is the most popular second language learned in the United States. In 2011 it was estimated by the American Community Survey that of the 55 million Hispanic United States residents who are five years of age and over, 38 million speak Spanish at home.
Names of the language.
In Spain and in some other parts of the Spanish-speaking world, Spanish is called ' (Castilian) as well as ' (Spanish), the language of the region of Castile, contrasting it with other languages spoken in Spain such as Galician, Basque and Catalan.
The Spanish Constitution of 1978 uses the term to define the official language of the whole Spanish State in contrast to (lit. "the other Spanish languages"). Article III reads as follows:
The Spanish Royal Academy, on the other hand, currently uses the term "español" in its publications but from 1713 to 1923 called the language "castellano".
The "Diccionario panhispánico de dudas" (a language guide published by the Spanish Royal Academy) states that although the Spanish Royal Academy prefers to use the term "español" in its publications when referring to the Spanish language, both terms, "español" and "castellano", are regarded as synonymous and equally valid.
Two etymologies for "español" have been suggested. The Spanish Royal Academy Dictionary derives the term from the Provençal word "espaignol", and that in turn from the Medieval Latin word "Hispaniolus", 'from—or pertaining to—Hispania'. Other authorities attribute it to a supposed mediaeval Latin *"hispaniōne", with the same meaning.
History.
The Spanish language evolved from Vulgar Latin (colloquial Latin), which was brought to the Iberian Peninsula by the Romans during the Second Punic War, beginning in 210 BC. Previously, several pre-Roman languages (also called Paleohispanic languages)—unrelated to Latin, and some of them unrelated even to Indo-European—were spoken in the Iberian Peninsula. These languages included Basque (still spoken today), Iberian, Celtiberian and Celtic. Traces of Basque especially can be found in the Spanish vocabulary today, mainly in place names.
The first documents to record what is today regarded as the precursor of modern Spanish are from the 9th century (see "Glosas Emilianenses"). Throughout the Middle Ages and into the modern era, the most important influences on the Spanish lexicon came from neighboring Romance languages—Navarro-Aragonese, Leonese, Aragonese, Catalan, Portuguese, Galician, Mirandese, Occitan, Gascon, and later, French and Italian. Spanish also borrowed a considerable number of words from Basque and Arabic, as well as from Germanic languages through the migration of tribes and a period of Visigoth rule in Iberia. In addition, many more words were borrowed from Latin through the influence of written language and the liturgical language of the Church.
Local sociolects of Vulgar Latin evolved into Spanish in the north of Iberia, in an area defined by Álava, Cantabria, Burgos, Soria and La Rioja. The dialect was later brought to the city of Toledo, where the written standard of Spanish was first developed, in the 13th century. In this formative stage, Spanish (Castilian) developed a strongly differing variant from its close cousin, Leonese, and, according to some authors, was distinguished by a heavy Basque influence (see Iberian Romance languages). This distinctive dialect progressively spread south with the advance of the , and so gathered a sizable lexical influence from the Arabic of Al-Andalus, much of it indirectly, through the Romance Mozarabic dialects (some 4,000 Arabic-derived words, make up around 8% of the language today). The written standard for this new language began to be developed in the cities of Toledo, in the 13th to 16th centuries, and Madrid, from the 1570s.
The development of the Spanish sound system from that of Vulgar Latin exhibits most of the changes that are typical of Western Romance languages, including lenition of intervocalic consonants (thus Latin > Spanish ). The diphthongization of Latin stressed short and —which occurred in open syllables in French and Italian, but not at all in Catalan or Portuguese—is found in both open and closed syllables in Spanish, as shown in the following table:
Spanish is marked by the palatalization of the Latin double consonants and (thus Latin
The consonant written "u" or "v" in Latin and pronounced in Classical Latin had probably "fortified" to a bilabial fricative in Vulgar Latin. In early Spanish (but not in Catalan or Portuguese) it merged with the consonant written "b" (a bilabial with plosive and fricative allophones). In modern Spanish, there is no difference between the pronunciation of orthographic "b" and "v", with some exceptions in Caribbean Spanish.
Peculiar to Spanish (as well as to the neighboring Gascon dialect of Occitan, and attributed to a Basque substratum) was the mutation of Latin initial "f" into "h-" whenever it was followed by a vowel that did not diphthongize. The "h-", still preserved in spelling, is now silent in most varieties of the language, although in some Andalusian and Caribbean dialects it is still aspirated in some words. Because of borrowings from Latin and from neighboring Romance languages, there are many f-/h-doublets in modern Spanish: "Fernando" and "Hernando" (both Spanish for "Ferdinand"), "ferrero" and "herrero" (both Spanish for "smith"), "fierro" and "hierro" (both Spanish for "iron"), and "fondo" and "hondo" (both Spanish for "deep", but "fondo" means "bottom" while "hondo" means "deep"); "hacer" (Spanish for "to make") is the root word of "satisfacer" (Spanish for "to satisfy"), and "hecho" ("made") is the root word of "satisfecho" (Spanish for "satisfied").
Compare the examples in the following table:
Some consonant clusters of Latin also produced characteristically different results in these languages, as shown in the examples in the following table:
In the 15th and 16th centuries, Spanish underwent a dramatic change in the pronunciation of its sibilant consonants, known in Spanish as the "", which resulted in the distinctive velar pronunciation of the letter and—in a large part of Spain—the characteristic interdental ("th-sound") for the letter (and for before or ). See History of Spanish (Modern development of the Old Spanish sibilants) for details.
The , written in Salamanca in 1492 by Elio Antonio de Nebrija, was the first grammar written for a modern European language. According to a popular anecdote, when Nebrija presented it to Queen Isabella I, she asked him what was the use of such a work, and he answered that language is the instrument of empire. In his introduction to the grammar, dated August 18, 1492, Nebrija wrote that "... language was always the companion of empire."
From the sixteenth century onwards, the language was taken to America and the Spanish East Indies via Spanish colonization of America. Miguel de Cervantes Saavedra, author of "Don Quixote", is such a well-known reference in the world that Spanish is often called "la lengua de Cervantes" ("the language of Cervantes").
In the twentieth century, Spanish was introduced to Equatorial Guinea and the Western Sahara, and to areas of the United States that had not been part of the Spanish Empire, such as Spanish Harlem in New York City. For details on borrowed words and other external influences upon Spanish, see Influences on the Spanish language.
Grammar.
Spanish is a relatively inflected language, with a two-gender noun system and about fifty conjugated forms per verb, but with inflection of nouns, adjectives, and determiners limited to number and gender. (For a detailed overview of verbs, see Spanish verbs and Spanish irregular verbs.) Spanish syntax is considered right-branching, meaning that subordinate or modifying constituents tend to be placed after their head words. The language uses prepositions (rather than postpositions or inflection of nouns for case), and usually—though not always—places adjectives after nouns, as do most other Romance languages.
Its sentence structure is generally subject–verb–object, although variations are common. It is a "pro-drop", or "null-subject" language—that is, it allows the deletion of subject pronouns when they are pragmatically unnecessary. Spanish is described as a "verb-framed" language, meaning that the "direction" of motion is expressed in the verb while the "mode" of locomotion is expressed adverbially (e.g. "subir corriendo" or "salir volando"; the respective English equivalents of these examples—'to run up' and 'to fly out'—show that English is, by contrast, "satellite-framed", with mode of locomotion expressed in the verb and direction in an adverbial modifier).
Subject/verb inversion is not required in questions, and thus the recognition of declarative or interrogative may depend entirely on intonation.
Phonology.
Segmental phonology.
The Spanish phonemic inventory consists of five vowel phonemes (, , , , ) and 17 to 19 consonant phonemes (the exact number depending on the dialect ). The main allophonic variation among vowels is the reduction of the high vowels and to glides— and respectively—when unstressed and adjacent to another vowel. Some instances of the mid vowels and , determined lexically, alternate with the diphthongs and respectively when stressed, in a process that is better described as morphophonemic rather than phonological, as it is not predictable from phonology alone.
The Spanish consonant system is characterized by (1) three nasal phonemes, and one or two (depending on the dialect) lateral phoneme(s), which in syllable-final position lose their contrast and are subject to assimilation to a following consonant; (2) three voiceless stops and the affricate ; (3) three or four (depending on the dialect) voiceless fricatives; (4) a set of voiced obstruents—, , , and sometimes —which alternate between approximant and plosive allophones depending on the environment; and (5) a phonemic distinction between the "tapped" and "trilled" "r"-sounds (single and double in orthography).
In the following table of consonant phonemes, and are marked with an asterisk (*) to indicate that they are preserved only in some dialects. In most dialects they have been merged, respectively, with and , in the mergers called, respectively, "seseo" and "yeísmo". The phoneme is in parentheses () to indicate that it appears only in loanwords. Each of the voiced obstruent phonemes , , , and appears to the right of a "pair" of voiceless phonemes, to indicate that, while the "voiceless" phonemes maintain a phonemic contrast between plosive (or affricate) and fricative, the "voiced" ones alternate allophonically (i.e. without phonemic contrast) between plosive and approximant pronunciations.
Prosody.
Spanish is classified by its rhythm as a syllable-timed language: each syllable has approximately the same duration regardless of stress.
Spanish intonation varies significantly according to dialect but generally conforms to a pattern of falling tone for declarative sentences and wh-questions (who, what, why, etc.) and rising tone for yes/no questions. There are no syntactic markers to distinguish between questions and statements and thus, the recognition of declarative or interrogative depends entirely on intonation.
Stress most often occurs on any of the last three syllables of a word, with some rare exceptions at the fourth-last or earlier syllables. The "tendencies" of stress assignment are as follows:
In addition to the many exceptions to these tendencies, there are numerous minimal pairs that contrast solely on stress such as "sábana" ('sheet') and "sabána" ('savannah'); "límite" ('boundary'), "limite" (' he/she limits') and "limité" ('I limited'); "líquido" ('liquid'), "liquído" ('I sell off') and "liquidó" ('he/she sold off').
The spelling system unambiguously reflects where the stress occurs: in the absence of an accent mark, the stress falls on the last syllable unless the last letter is , , or a vowel, in which cases the stress falls on the next-to-last syllable. Exceptions to those rules cause an acute accent mark to appear over the stressed syllable.
Geographical distribution.
Spanish is the primary language of 20 countries worldwide. It is estimated that the combined total number of Spanish speakers is between 470 and 500 million, making it the second most widely spoken language in terms of native speakers.
Spanish is the second most spoken language by total number of speakers (after Mandarin). Internet usage statistics for 2007 show Spanish as the third most commonly used language on the Internet, after English and Mandarin.
Europe.
In Europe, Spanish is an official language of Spain, the country after which it is named and from which it originated. It is widely spoken in Gibraltar, although English is the official, international language. It is also commonly spoken in Andorra, although Catalan is the official language.
Spanish is also spoken by small communities in other European countries, such as the United Kingdom, France, Italy, and Germany. Spanish is an official language of the European Union. In Switzerland, which had a massive influx of Spanish migrants in the 20th century, Spanish is the native language of 2.2% of the population.
The Americas.
Hispanic America.
Most Spanish speakers are in Hispanic America; of all countries with a majority of Spanish speakers, only Spain and Equatorial Guinea are outside the Americas. Nationally, Spanish is the official language—either "de facto" or "de jure"—of Argentina, Bolivia (co-official with Quechua, Aymara, Guarani, and 34 other languages), Chile, Colombia, Costa Rica, Cuba, Dominican Republic, Ecuador, El Salvador, Guatemala, Honduras, Mexico (co-official with 63 indigenous languages), Nicaragua, Panama, Paraguay (co-official with Guaraní), Peru (co-official with Quechua, Aymara, and "the other indigenous languages"), Uruguay, and Venezuela. Spanish is co-official with English in Puerto Rico.
Spanish has no official recognition in the former British colony of Belize; however, per the 2000 census, it is spoken by 43% of the population. Mainly, it is spoken by the descendants of Hispanics who have been in the region since the seventeenth century; however, English is the official language.
Due to their proximity to Spanish-speaking countries, Trinidad and Tobago and Brazil have implemented Spanish language teaching into their education systems. The Trinidad government launched the "Spanish as a First Foreign Language" (SAFFL) initiative in March 2005. In 2005, the National Congress of Brazil approved a bill, signed into law by the President, making it mandatory for schools to offer Spanish as an alternative foreign language course in both public and private secondary schools in Brazil. In many border towns and villages along Paraguay and Uruguay, a mixed language known as Portuñol is spoken.
United States.
According to 2006 census data, 44.3 million people of the U.S. population were Hispanic or Hispanic American by origin; 38.3 million people, 13 percent, of the population over five years old speak Spanish at home. The Spanish language has a long history and presence in the United States due to historic Spanish and later, Mexican administration over territories now forming the southwestern states as well as Florida, which was Spanish territory until 1821.
Spanish is by far the most common second language spoken and taught in the country, and with over 50 million total speakers, the United States is now the second largest Spanish-speaking country in the world after Mexico. While English is the "de facto" official language of the country, Spanish is often used in public services and notices at the federal and state levels. Spanish is also used in administration in the state of New Mexico. The language also has a strong influence in major metropolitan areas such as those of Los Angeles, Miami, San Antonio, New York, San Francisco, Dallas, and Phoenix; as well as more recently, Chicago, Las Vegas, Boston, Denver, Houston, Indianapolis, Philadelphia, Cleveland, Salt Lake City, Atlanta, Nashville, Orlando, Tampa, Raleigh and Baltimore-Washington, D.C. due to 20th and 21st century immigration.
Africa.
In Africa, Spanish is official (along with Portuguese and French) in Equatorial Guinea, as well as an official language of the African Union. In Equatorial Guinea, Spanish is the predominant language when native and non-native speakers (around 500,000 people) are counted, while Fang is the most spoken language by number of native speakers.
Spanish is also spoken in the integral territories of Spain in North Africa, which include the Spanish cities of Ceuta and Melilla, the Plazas de soberanía, and the Canary Islands archipelago (population 2,000,000), located some 100 km off the northwest coast of mainland Africa.
Within Northern Morocco, a former Spanish protectorate that is also geographically close to Spain, approximately 20,000 people speak Spanish as a second language, while Arabic is the "de jure" official language. A small number of Moroccan Jews also speak the Sephardic Spanish dialect Haketia (related to the Ladino dialect spoken in Israel). Spanish is spoken by some small communities in Angola because of the Cuban influence from the Cold War and in South Sudan among South Sudanese natives that relocated to Cuba during the Sudanese wars and returned in time for their country's independence.
In Western Sahara, formerly Spanish Sahara, Spanish was officially spoken during the late nineteenth and twentieth centuries. Today, Spanish in this disputed territory is maintained by populations of Sahrawi nomads numbering about 500,000 people, and is de facto official alongside Arabic in the Sahrawi Arab Democratic Republic, although this entity receives limited international recognition.
Asia-Pacific.
Spanish is present on Easter Island, as it was annexed as a Chilean province in 1888.
Spanish was an official language of the Philippines from the beginning of Spanish rule in 1565 to a constitutional change in 1973. During Spanish colonization (1565–1898), it was the language of government, trade and education, and spoken as a first language by Spaniards and educated Filipinos. In the mid-nineteenth century, the colonial government set up a free public education system with Spanish as the medium of instruction. This increased use of Spanish throughout the islands led to the formation of a class of Spanish-speaking intellectuals called the "Ilustrados". However, Spanish was never spoken by the majority of the population.
Despite American administration after the defeat of Spain in the Spanish–American War in 1898, the usage of Spanish continued in Philippine literature and press during the early years of American rule. Gradually, however, the American government began increasingly promoting the use of English, and it characterized Spanish as a negative influence of the past. Eventually, by the 1920s, English became the primary language of administration and education. But despite a significant decrease in influence and speakers, Spanish remained an official language of the Philippines when it became independent in 1946, alongside English and Filipino, a standardized version of Tagalog.
Spanish was removed from official status in 1973 under the administration of Ferdinand Marcos, but regained its status as an official language two months later under Presidential Decree No. 155, dated 15 March 1973. It remained an official language until 1987, with the ratification of the present constitution, in which it was re-designated as a voluntary and optional auxiliary language. In 2010, President Gloria Macapagal-Arroyo encouraged the reintroduction of Spanish-language teaching in the Philippine education system. But by 2012, the number of secondary schools at which the language was either a compulsory subject or an elective had become very limited. Today, despite government promotions of Spanish, less than 0.5% of the population report being able to speak the language proficiently. Estimates indicate that while around 3 million people can speak Spanish with varying degrees of competency, only around 439 thousand people can speak the language at a native level. Aside from standard Spanish, a Spanish-based creole language—Chavacano—developed in the southern Philippines. The number of Chavacano-speakers was estimated at 1.2 million in 1996. However, it is not mutually intelligible with Spanish. Speakers of the Zamboangueño variety of Chavacano were numbered about 360,000 in the 2000 census. The local languages of the Philippines also retain some Spanish influence, with many words being derived from Mexican Spanish, owing to the control of the islands by Spain through Mexico City until 1821, and then directly from Madrid until 1898.
Spanish was also used by the colonial governments and educated classes in the former Spanish East Indies, consisting of modern-day Guam, Northern Mariana Islands, Palau, and Micronesia, in addition to the Philippines. Spanish loan words are present in the local languages of these territories as a legacy of colonial rule. Today, Spanish is not spoken officially in any of these former Spanish territories.
Spanish speakers by country.
The following table shows the number of Spanish speakers in some 79 countries.
Dialectal variation.
There are important variations (phonological, grammatical, and lexical) in the spoken Spanish of the various regions of Spain and throughout the Spanish-speaking areas of the Americas.
The variety with the most speakers is Mexican Spanish. It is spoken by more than twenty percent of the world's Spanish speakers (more than 112 million of the total of more than 500 million, according to the table above). One of its main features is the reduction or loss of unstressed vowels, mainly when they are in contact with the sound /s/.
In Spain, northern dialects are popularly thought of as closer to the standard, although positive attitudes toward southern dialects have increased significantly in the last 50 years. Even so, the speech of Madrid, which has typically southern features such as yeísmo and s-aspiration, is the standard variety for use on radio and television. The educated Madrid variety has most influenced the written standard for Spanish.
Phonology.
The four main phonological divisions are based respectively on (1) the sound of the spelled , (2) the debuccalization of syllable-final , (3) the phoneme ("theta"), (4) and the phoneme ("turned "y""),
Grammar.
The main grammatical variations between dialects of Spanish involve differing uses of pronouns, especially those of the second person and, to a lesser extent, the object pronouns of the third person.
Voseo.
Virtually all dialects of Spanish make the distinction between a formal and a familiar register in the second-person singular and thus have two different pronouns meaning "you": "usted" in the formal and either "tú" or "vos" in the familiar (and each of these three pronouns has its associated verb forms), with the choice of "tú" or "vos" varying from one dialect to another. The use of "vos" (and/or its verb forms) is called "voseo". In a few dialects, all three pronouns are used, with "usted", "tú", and "vos" denote respectively formality, familiarity, and intimacy.
In "voseo", is the subject form (, "you say") and the form for the object of a preposition ("voy con vos", "I am going with you"), while the direct and indirect object forms, and the possessives, are the same as those associated with "tú": "Vos sabés que tus amigos te respetan" ("You know your friends respect you").
The verb forms of "general voseo" are the same as those used with "tú" except in the present tense (indicative and imperative) verbs. The forms for "vos" generally can be derived from those of "vosotros" (the traditional second-person familiar "plural") by deleting the glide , or , where it appears in the ending: "vosotros pensáis" > "vos pensás"; "vosotros volvéis" > "vos volvés", "pensad!" ("vosotros") > "pensá!" ("vos"), "volved!" ("vosotros") > "volvé!" ("vos") .
In Chilean "voseo" on the other hand, almost all verb forms are distinct from their standard "tú"-forms.
The use of the pronoun "vos" with the verb forms of "tú" ("vos piensas") is called "pronominal "voseo"". Conversely, the use of the verb forms of "vos" with the pronoun "tú" ("tú pensás" or "tú pensái") is called "verbal "voseo"". 
In Chile, for example, "verbal voseo" is much more common than the actual use of the pronoun "vos", which is often reserved for deeply informal situations.
And in Central american "voseo", one can see even further distinction.
Distribution in Spanish-speaking regions of the Americas.
Although is not used in Spain, it occurs in many Spanish-speaking regions of the Americas as the primary spoken form of the second-person singular familiar pronoun, with wide differences in social consideration. Generally, it can be said that there are zones of exclusive use of in the following areas: almost all of Mexico, the West Indies, Panama, most of Colombia, Peru, Venezuela and coastal Ecuador.
Areas of generalized include Argentina, Nicaragua, eastern Bolivia, El Salvador, Guatemala, Honduras, Costa Rica, Paraguay, Uruguay and the Colombian departments of Antioquia, Caldas, Risaralda, Quindio and Valle del Cauca.
Ustedes.
"Ustedes" functions as formal and informal second person plural in over 90% of the Spanish-speaking world, including all of Hispanic America, the Canary Islands, and some regions of Andalusia. In Seville, Huelva, Cadiz, and other parts of western Andalusia, the familiar form is constructed as "ustedes vais", using the traditional second-person plural form of the verb. Most of Spain maintains the formal/familiar distinction with "ustedes" and "vosotros" respectively.
Usted.
"Usted" is the usual second-person singular pronoun in a formal context, but it is used joint with the third-person singular voice of the verb. It is used to convey respect toward someone who is a generation older or is of higher authority ("you, sir"/"you, ma'am"). It is also used in a "familiar" context by many speakers in Colombia and Costa Rica and in parts of Ecuador and Panama, to the exclusion of "tú" or "vos". This usage is sometimes called "ustedeo" in Spanish.
In Central America, especially in Honduras, "usted" is often used as a formal pronoun to convey respect between the members of a romantic couple. "Usted" is also used that way as well as between parents and children in the Andean regions of Ecuador, Colombia and Venezuela.
Third-person object pronouns.
Most speakers use (and the "Real Academia Española" prefers) the pronouns "lo" and "la" for "direct" objects (masculine and feminine respectively, regardless of animacy, meaning "him", "her", or "it"), and "le" for "indirect" objects (regardless of gender or animacy, meaning "to him", "to her", or "to it"). The usage is sometimes called "etymological", as these direct and indirect object pronouns are a continuation, respectively, of the accusative and dative pronouns of Latin, the ancestor language of Spanish.
Deviations from this norm (more common in Spain than in the Americas) are called ""leísmo"", ""loísmo"", or ""laísmo"", according to which respective pronoun, "le", "lo", or "la", has expanded beyond the etymological usage ("le" as a direct object, or "lo" or "la" as an indirect object).
Vocabulary.
Some words can be significantly different in different Hispanophone countries. Most Spanish speakers can recognize other Spanish forms even in places where they are not commonly used, but Spaniards generally do not recognize specifically American usages. For example, Spanish "mantequilla", "aguacate" and "albaricoque" (respectively, 'butter', 'avocado', 'apricot') correspond to "manteca", "palta", and "damasco", respectively, in Argentina, Chile (except "manteca"), Paraguay, Peru (except "manteca" and "damasco"), and Uruguay.
The everyday Spanish words "coger" ('to take'), "pisar" ('to step on') and "concha" ('seashell') are considered extremely rude in parts of Hispanic America, where the meaning of "coger" and "pisar" is also "to have sex" and "concha" means "vagina". The Puerto Rican word for "bobby pin" ("pinche") is an obscenity in Mexico, but in Nicaragua, it simply means "stingy", and in Spain, it refers to a chef's helper. Other examples include "taco", which means "swearword" (among other meanings) in Spain, "traffic jam" in Chile and "heels" (shoe) in Argentina, Peru, and Colombia, but it is known to the rest of the world as a Mexican dish.
"Pija" in many countries of Hispanic America and Spain itself is an obscene slang word for "penis" while in Spain the word also signifies "posh girl" or "snobby". "Coche", which means "car" in Spain, central Mexico and Argentina, for the vast majority of Spanish-speakers actually means "baby-stroller" or "pushchair", while "carro" means "car" in some Hispanic American countries and "cart" in others, as well as in Spain. "Papaya" is the slang term for "vagina" in parts of Cuba and Venezuela, where the fruit is instead called "fruta bomba" and "lechosa", respectively. Also, in Argentina and Spain, one would say "piña" when talking about punching someone else (as an alternate, slang usage) whereas in other countries, "piña" refers only to a pineapple.
Relation to other languages.
Spanish is closely related to the other West Iberian Romance languages, including Asturian, Aragonese, Galician, Ladino, Leonese, Mirandese and Portuguese.
It is generally acknowledged that Portuguese- and Spanish-speakers can communicate, although with varying degrees of difficulty.
Meanwhile, mutual intelligibility of the "written" Spanish and Portuguese languages is very high, given that the difficulties of the spoken forms are based more on phonology than on grammatical and lexical dissimilarities. "Ethnologue" gives estimates of the lexical similarity between related languages in terms of precise percentages. For Spanish and Portuguese, that figure is 89%. Italian, on the other hand—although its phonology is more similar to that of Spanish—is said to have a lexical similarity of 82%. Mutual intelligibility between Spanish and French or between Spanish and Romanian is lower still, given lexical similarity ratings of 75% and 71% respectively. And comprehension of Spanish by French speakers who have not studied the language is much lower, at an estimated 45%. In general, thanks to the common features of the writing systems of the Romance languages, interlingual comprehension of the written word is greater than that of oral communication.
The following table compares the forms of some common words in several Romance languages:
1. Also in early modern Portuguese (e.g. "The Lusiads"), and in Galician.
2. Alternatively in French.
3. Also in Southern Italian dialects and languages.
4. Medieval Catalan (e.g. "Llibre dels fets").
5. Depending on the written norm used (see Reintegrationism).
6. From Basque "esku", "hand" + "erdi", "half, incomplete". Notice that this negative meaning also applies for Latin "sinistra(m)" ("dark, unfortunate").
7. Romanian "caș" (from Latin ) means a type of cheese. The universal term for cheese in Romanian is "brânză" (from unknown etymology).
Judaeo-Spanish.
Judaeo-Spanish, also known as Ladino, is a variety of Spanish which preserves many features of medieval Spanish and Portuguese and is spoken by descendants of the Sephardi Jews who were expelled from Spain in the fifteenth century. Conversely, in Portugal the vast majority of the Portuguese Jews converted and became 'New Christians'. Therefore, its relationship to Spanish is comparable with that of the Yiddish language to German. Ladino speakers today are almost exclusively Sephardi Jews, with family roots in Turkey, Greece, or the Balkans, and living mostly in Israel, Turkey, and the United States, with a few communities in Hispanic America. Judaeo-Spanish lacks the Native American vocabulary which was acquired by standard Spanish during the Spanish colonial period, and it retains many archaic features which have since been lost in standard Spanish. It contains, however, other vocabulary which is not found in standard Spanish, including vocabulary from Hebrew, French, Greek and Turkish, and other languages spoken where the Sephardim settled.
Judaeo-Spanish is in serious danger of extinction because many native speakers today are elderly as well as elderly "olim" (immigrants to Israel) who have not transmitted the language to their children or grandchildren. However, it is experiencing a minor revival among Sephardi communities, especially in music. In the case of the Latin American communities, the danger of extinction is also due to the risk of assimilation by modern Castilian.
A related dialect is Haketia, the Judaeo-Spanish of northern Morocco. This too tended to assimilate with modern Spanish, during the Spanish occupation of the region.
Writing system.
Spanish is written in the Latin script, with the addition of the character (, representing the phoneme , a letter distinct from , although typographically composed of an with a tilde) and the digraphs (, representing the phoneme ) and (, representing the phoneme ). However, the digraph (, 'strong r', , 'double r', or simply ), which also represents a distinct phoneme , is not similarly regarded as a single letter. Since 1994 and have been treated as letter pairs for collation purposes, though they remain a part of the alphabet. Words with are now alphabetically sorted between those with and , instead of following as they used to. The situation is similar for .
Thus, the Spanish alphabet has the following 27 letters and 2 digraphs:
The letters "k" and "w" are used only in words and names coming from foreign languages ("kilo, folklore, whisky, kiwi", etc.).
With the exclusion of a very small number of regional terms such as "México" (see Toponymy of Mexico), pronunciation can be entirely determined from spelling. Under the orthographic conventions, a typical Spanish word is stressed on the syllable before the last if it ends with a vowel (not including ) or with a vowel followed by or an ; it is stressed on the last syllable otherwise. Exceptions to this rule are indicated by placing an acute accent on the stressed vowel.
The acute accent is used, in addition, to distinguish between certain homophones, especially when one of them is a stressed word and the other one is a clitic: compare ('the', masculine singular definite article) with ('he' or 'it'), or ('you', object pronoun) with ('tea'), (preposition 'of') versus ('give' imperative/third-person present subjunctive), and (reflexive pronoun) versus ('I know' or imperative 'be').
The interrogative pronouns (, , , , etc.) also receive accents in direct or indirect questions, and some demonstratives (, , , etc.) can be accented when used as pronouns. Accent marks used to be omitted on capital letters (a widespread practice in the days of typewriters and the early days of computers when only lowercase vowels were available with accents), although the "Real Academia Española" advises against this and the orthographic conventions taught at schools enforce the use of the accent.
When "u" is written between "g" and a front vowel "e" or "i", it indicates a "hard g" pronunciation. A diaeresis "ü" indicates that it is not silent as it normally would be (e.g., "cigüeña", 'stork', is pronounced ; if it were written *"cigueña", it would be pronounced *).
Interrogative and exclamatory clauses are introduced with inverted question and exclamation marks ("¿" and "¡", respectively).
Organizations.
Royal Spanish Academy.
The (Royal Spanish Academy), founded in 1713, together with the 21 other national ones (see Association of Spanish Language Academies), exercises a standardizing influence through its publication of dictionaries and widely respected grammar and style guides.
Because of influence and for other sociohistorical reasons, a standardized form of the language (Standard Spanish) is widely acknowledged for use in literature, academic contexts and the media.
Association of Spanish Language Academies.
The Association of Spanish Language Academies ("Asociación de Academias de la Lengua Española", or "ASALE") is the entity which regulates the Spanish language. It was created in Mexico in 1951 and represents the union of all the separate academies in the Spanish-speaking world. It comprises the academies of 22 countries, ordered by date of Academy foundation: Spain (1713), Colombia (1871), Ecuador (1874), Mexico (1875), El Salvador (1876), Venezuela (1883), Chile (1885), Peru (1887), Guatemala (1887), Costa Rica (1923), Philippines (1924), Panama (1926), Cuba (1926),
Paraguay (1927), Dominican Republic (1927), Bolivia (1927), Nicaragua (1928), Argentina (1931), Uruguay (1943), Honduras (1949), Puerto Rico (1955), and United States (1973).
Cervantes Institute.
The "Instituto Cervantes" (Cervantes Institute) is a worldwide non-profit organization created by the Spanish government in 1991. This organization has branched out in over 20 different countries with 54 centers devoted to the Spanish and Hispanic American culture and Spanish Language. The ultimate goals of the Institute are to promote the education, the study and the use of Spanish universally as a second language, to support the methods and activities that would help the process of Spanish language education, and to contribute to the advancement of the Spanish and Hispanic American cultures throughout non-Spanish-speaking countries.
Official use by international organizations.
Spanish is recognised as one of the official languages of the United Nations, the European Union, the World Trade Organization, the Organization of American States, the Organization of Ibero-American States, the African Union, the Union of South American Nations, the Antarctic Treaty Secretariat, the Latin Union, the Caricom and the North American Free Trade Agreement.
See also.
Spanish dialects and varieties

</doc>
<doc id="26826" url="https://en.wikipedia.org/wiki?curid=26826" title="Sodium">
Sodium

Sodium is a chemical element with symbol Na (from Ancient Greek Νάτριο) and atomic number 11. It is a soft, silver-white, highly reactive metal. In the Periodic table it is in column 1 (alkali metals), and like the other six elements in that column, it has a single electron in its outer shell that it readily donates, creating a positively charged atom — a cation. Its only stable isotope is 23Na. The free metal does not occur in nature, but must be prepared from compounds. Sodium is the sixth most abundant element in the Earth's crust, and exists in numerous minerals such as feldspars, sodalite and rock salt (NaCl). Many salts of sodium are highly water-soluble: sodium ions have been leached by the action of water from the Earth's minerals over eons; sodium and chlorine are the most common dissolved elements by weight in the oceans.
Sodium was first isolated by Humphry Davy in 1807 by the electrolysis of sodium hydroxide. Among many other useful sodium compounds, sodium hydroxide (lye) is used in soap manufacture, and sodium chloride (edible salt) is a de-icing agent and a nutrient for humans and cattle.
Sodium is an essential element for all animals and some plants. Sodium ions are the major cation in the extracellular fluid (ECF) and as such are the major contributor to the ECF osmotic pressure and ECF compartment volume. Loss of water from the ECF compartment increases the sodium concentration, a condition called hypernatremia. Isotonic loss of water and sodium from the ECF compartment decreases the size of that compartment in a condition called ECF hypovolemia.
By means of Na+/K+-ATPase, living human cells pump three sodium ions out of the cell in exchange for two potassium ions pumped in; comparing ion concentrations across the cell membrane, inside to outside, potassium measures about 40:1, and sodium, about 1:10. In nerve cells, the electrical charge across the cell membrane enables transmission of the nerve impulse — an action potential — when the charge is dissipated; sodium plays a key role in that activity.
Characteristics.
Physical.
Sodium at standard temperature and pressure is a soft silvery metal that oxidizes to grayish white unless immersed in oil or inert gas. Sodium can be easily cut with a knife and is a good conductor of electricity and heat. These properties change dramatically at elevated pressures: at 1.5 Mbar, the color changes from silvery metallic to black; at 1.9 Mbar the material becomes transparent with a red color; and at 3 Mbar, sodium is a clear and transparent solid. All of these high-pressure allotropes are insulators and electrides.
Sodium gas is at first green, then turns purple at higher temperatures.
In a flame test, sodium and its compounds glow yellow because the excited 3s electrons of sodium emit a photon when they fall from 3p to 3s; the wavelength of this photon corresponds to the D line at 589.3 nm. Spin-orbit interactions involving the electron in the 3p orbital split the D line into two; hyperfine structures involving both orbitals cause many more lines.
Chemical.
When freshly cut, sodium has a bright, silvery luster. When exposed to air, the surface rapidly tarnishes, darkening at first and then forming a white coating of sodium hydroxide and sodium carbonate.
Sodium is generally less reactive than potassium and more reactive than lithium. Like all the alkali metals, it reacts exothermically with water, and sufficiently large pieces melt to a sphere and may explode. The reaction produces caustic soda (sodium hydroxide) and flammable hydrogen gas. When burned in dry air, it forms primarily sodium peroxide with some sodium oxide. In moist air, it forms sodium hydroxide. Sodium metal is highly reducing, with the reduction of sodium ions requiring −2.71 volts, though potassium and lithium have even more negative potentials. Extracting sodium metal from a compound such as sodium chloride uses a significant amount of energy. 
Isotopes.
Twenty isotopes of sodium are known, but only 23Na is stable. Two radioactive, cosmogenic isotopes are the byproduct of cosmic ray spallation: 22Na has a half-life of 2.6 years and 24Na, a half-life of 15 hours; all other isotopes have a half-life of less than one minute. Two nuclear isomers have been discovered, the longer-lived one being 24mNa with a half-life of around 20.2 miliseconds. Acute neutron radiation, as from a nuclear criticality accident, converts some of the stable 23Na in human blood to 24Na; the neutron radiation dosage of a victim can be calculated by measuring the concentration of 24Na relative to 23Na.
Occurrence.
23Na is created in the carbon-burning process in stars by fusing two carbon atoms together; this requires temperatures above 600 megakelvins and a star of at least three solar masses. The Earth's crust contains 2.6% sodium by weight, making it the sixth most abundant element on Earth. Sodium's estimated crustal abundance is 2.36×104 milligrams per kilogram. Sodium's estimated oceanic abundance is 1.08×104 milligrams per liter. Because of its high reactivity, it is never found as a pure element. It is found in many different minerals, some very soluble, such as halite and natron, others much less soluble, such as amphibole and zeolite. The insolubility of certain sodium minerals such as cryolite and feldspar arises from their polymeric anions, which in the case of feldspar is a polysilicate. In the interstellar medium, sodium is identified by the D spectral line; though it has a high vaporization temperature, its abundance in Mercury's atmosphere enabled its detection by Potter and Morgan using ground-based high resolution spectroscopy. Sodium has been detected in at least one comet; astronomers watching Comet Hale-Bopp in 1997 observed a sodium tail consisting of neutral atoms (not ions) and extending to some 50 million kilometres behind the head.
Compounds.
Sodium compounds are of immense commercial importance, being particularly central to industries producing glass, paper, soap, and textiles. The most important sodium compounds are table salt (NaCl), soda ash (Na2CO3), baking soda (NaHCO3), caustic soda (NaOH), sodium nitrate (NaNO3), di- and tri-sodium phosphates, sodium thiosulfate (Na2S2O3·5H2O), and borax (Na2B4O7·10H2O). In compounds, sodium is usually ionically bonded to water and anions, and is viewed as a hard Lewis acid.
Most soaps are sodium salts of fatty acids. Sodium soaps have a higher melting temperature (and seem "harder") than potassium soaps. Sodium chloride is extensively used for anti-icing and de-icing and as a preservative; sodium bicarbonate is mainly used for cooking. Along with potassium, many important medicines have sodium added to improve their bioavailability; though potassium is the better ion in most cases, sodium is chosen for its lower price and atomic weight. Sodium hydride is used as a base for various reactions (such as the aldol reaction) in organic chemistry, and as a reducing agent in inorganic chemistry.
Aqueous solutions.
Sodium tends to form water-soluble compounds, such as halides, sulfates, nitrates, carboxylates and carbonates. The main aqueous species are the aquo complexes [Na(H2O)"n"]+, where "n" = 4–6. The high affinity of sodium for oxygen-based ligands is the basis of crown ethers; macrolide antibiotics, which interfere with Na+ transport in the infecting organism, are functionally related and more complex.
Direct precipitation of sodium salts from aqueous solutions is rare because sodium salts typically have a high affinity for water; an exception is sodium bismuthate (NaBiO3). Because of this, sodium salts are usually isolated as solids by evaporation or by precipitation with an organic solvent, such as ethanol; for example, only 0.35 g/L of sodium chloride will dissolve in ethanol. Crown ethers, like 15-crown-5, may be used as a phase-transfer catalyst.
Sodium content in bulk may be determined by treating with a large excess of uranyl zinc acetate; the hexahydrate (UO2)2ZnNa(CH3CO2)·6H2O precipitates and can be weighed. Caesium and rubidium do not interfere with this reaction, but potassium and lithium do. Lower concentrations of sodium may be determined by atomic absorption spectrophotometry or by potentiometry using ion-selective electrodes.
Electrides and sodides.
Like the other alkali metals, sodium dissolves in ammonia and some amines to give deeply colored solutions; evaporation of these solutions leaves a shiny film of metallic sodium. The solutions contain the coordination complex (Na(NH3)6)+, with the positive charge counterbalanced by electrons as anions; cryptands permit the isolation of these complexes as crystalline solids. Cryptands, like crown ethers and other ionophores, have a high affinity for the sodium ion; derivatives of the alkalide Na− are obtainable by the addition of cryptands to solutions of sodium in ammonia via disproportionation.
Organosodium compounds.
Many organosodium compounds have been prepared. Because of the high polarity of the C-Na bonds, they behave like sources of carbanions (salts with organic anions). Some well known derivatives include sodium cyclopentadienide (NaC5H5) and trityl sodium ((C6H5)3CNa).
History.
Because of its importance in human metabolism, salt has long been an important commodity as shown by the English word "salary", which derives from "salarium", the wafers of salt sometimes given to Roman soldiers along with their other wages. In medieval Europe, a compound of sodium with the Latin name of "sodanum" was used as a headache remedy. The name sodium is thought to originate from the Arabic "suda" , meaning headache, as the headache-alleviating properties of sodium carbonate or soda were well known in early times. The chemical abbreviation for sodium was first published by Jöns Jakob Berzelius in his system of atomic symbols, and is a contraction of the element's New Latin name "natrium", which refers to the Egyptian "natron", a natural mineral salt primarily made of hydrated sodium carbonate. Natron historically had several important industrial and household uses, later eclipsed by other sodium compounds. Although sodium, sometimes called "soda", had long been recognized in compounds, the metal itself was not isolated until 1807 by Sir Humphry Davy through the electrolysis of sodium hydroxide.
Sodium imparts an intense yellow color to flames. As early as 1860, Kirchhoff and Bunsen noted the high sensitivity of a sodium flame test, and stated in Annalen der Physik und Chemie:
In a corner of our 60 m3 room farthest away from the apparatus, we exploded 3 mg. of sodium chlorate with milk sugar while observing the nonluminous flame before the slit. After a while, it glowed a bright yellow and showed a strong sodium line that disappeared only after 10 minutes. From the weight of the sodium salt and the volume of air in the room, we easily calculate that one part by weight of air could not contain more than 1/20 millionth weight of sodium.
Commercial production.
Employed only in rather specialized applications, only about 100,000 tonnes of metallic sodium are produced annually. Metallic sodium was first produced commercially in 1855 by carbothermal reduction of sodium carbonate at 1100 °C, as the first step of the Deville process for the production of aluminium:
The high demand of aluminium created the need for the production of sodium. After the introduction of the Hall–Héroult process for the production of aluminium in by electrolysing a molten salt bath ended the need for large quantities of sodium. A related process based on the reduction of sodium hydroxide was developed in 1886.
Sodium is now produced commercially through the electrolysis of molten sodium chloride, based on a process patented in 1924. This is done in a Downs cell in which the NaCl is mixed with calcium chloride to lower the melting point below 700 °C. As calcium is less electropositive than sodium, no calcium will be deposited at the cathode. This method is less expensive than the previous Castner process (electrolysis sodium hydroxide).
Reagent-grade sodium in tonne quantities sold for about US$3.30/kg in 2009; lower purity metal sells for considerably less. The market for sodium is volatile due to the difficulty in its storage and shipping; it must be stored under a dry inert gas atmosphere or anhydrous mineral oil to prevent the formation of a surface layer of sodium oxide or sodium superoxide. These oxides can react violently in the presence of organic materials. Smaller quantities of sodium cost far more, in the range of US$165/kg; the high cost is partially due to the expense of shipping hazardous material.
Applications.
Though metallic sodium has some important uses, the major applications for sodium use compounds; millions of tons of sodium chloride, hydroxide, and carbonate are produced annually.
Free element.
Metallic sodium is used mainly for the production of sodium borohydride, sodium azide, indigo, and triphenylphosphine. Previous uses were for the making of tetraethyllead and titanium metal; because applications for these chemicals were discontinued, the production of sodium declined after 1970. Sodium is also used as an alloying metal, an anti-scaling agent, and as a reducing agent for metals when other materials are ineffective. Note the free element is not used as a scaling agent, ions in the water are exchanged for sodium ions. Sodium plasma ("vapor") lamps are often used for street lighting in cities, shedding light that ranges from yellow-orange to peach as the pressure increases. By itself or with potassium, sodium is a desiccant; it gives an intense blue coloration with benzophenone when the desiccate is dry. In organic synthesis, sodium is used in various reactions such as the Birch reduction, and the sodium fusion test is conducted to qualitatively analyse compounds. Sodium lasers emitting light at the D line are used to create artificial laser guide stars that assist in the adaptive optics for land-based visible light telescopes.
Heat transfer.
Liquid sodium is used as a heat transfer fluid in some fast reactors because it has the high thermal conductivity and low neutron absorption cross section required to achieve a high neutron flux in the reactor. The high boiling point of sodium allows the reactor to operate at ambient (normal) pressure, but the drawbacks include its opacity, which hinders visual maintenance, and its explosive properties. Radioactive sodium-24 may be produced by neutron bombardment during operation, posing a slight radiation hazard; the radioactivity stops within a few days after removal from the reactor. If a reactor needs to be shut down frequently, NaK is used; because NaK is a liquid at room temperature, the coolant does not not solidify in the pipes. In this case, the pyrophoricity of potassium requires extra precautions to prevent and detect leaks. Another heat transfer application is poppet valves in high-performance internal combustion engines; the valve stems are partially filled with sodium and work as a heat pipe to cool the valves.
Biological role.
In humans, sodium is an essential mineral that regulates blood volume, blood pressure, osmotic equilibrium and pH; the minimum physiological requirement for sodium is 500 milligrams per day. Sodium chloride is the principal source of sodium in the diet, and is used as seasoning and preservative in such commodities as pickled preserves and jerky; for Americans, most sodium chloride comes from processed foods. The UL standard for sodium intake is 2.3 grams per day; and exceeding that threshold can lead to hypertension, but the average person in the United States consumes 3.4 grams per day. Hypertension causes 7.6 million premature deaths worldwide each year. (Note that salt contains about 39.3% sodiumthe rest being chlorine and trace chemicals; thus, 2.3g sodium is about 5.9g, or 2.7ml of saltabout half a US teaspoon.)
The renin-angiotensin system regulates the amount of fluid and sodium concentration in the body. Reduction of blood pressure and sodium concentration in the kidney result in the production of renin, which in turn produces aldosterone and angiotensin, retaining sodium in the urine. When the concentration of sodium increases, the production of renin decreases, and the sodium concentration returns to normal. Sodium is important in neuron function, and in osmoregulation between cells and the extracellular fluid. This is accomplished in all animals by Na+/K+-ATPase, an active transporter pumping ions against the gradient, and sodium/potassium channels. Sodium is the most prevalent metallic ion in extracellular fluid.
Unusually low or high sodium levels in humans are recognized in medicine as hyponatremia and hypernatremia. These conditions may be caused by genetic factors, ageing, or prolonged vomiting or diarrhea.
In C4 plants, sodium is a micronutrient that aids in metabolism, specifically in regeneration of phosphoenolpyruvate and synthesis of chlorophyll. In others, it substitutes for potassium in several roles, such as maintaining turgor pressure and aiding in the opening and closing of stomata. Excess sodium in the soil limits the uptake of water by decreasing the water potential, which may result in plant wilting; excess concentrations in the cytoplasm can lead to enzyme inhibition, which in turn causes necrosis and chlorosis. In response, some plants developed mechanisms to limit sodium uptake in the roots, to store it in cell vacuoles, and restriction of salt transport from roots to leaves; excess sodium may also be stored in old plant tissue, limiting the damage to new growth.
Precautions.
Care is required in handling elemental sodium because it generates flammable hydrogen and caustic sodium hydroxide on contact with water; powdered sodium may spontaneously explode in the presence of an oxidizer. Excess sodium can be safely removed by hydrolysis in a ventilated cabinet; this is typically done by sequential treatment with isopropanol, ethanol and water. Isopropanol reacts very slowly, generating the corresponding alkoxide and hydrogen. Fire extinguishers based on water accelerate sodium fires; those based on carbon dioxide and bromochlorodifluoromethane lose their effectiveness when they dissipate. 
Metal fires are Class D, but not all Class D extinguishers are workable with sodium. An effective extinguishing agent for sodium fires is Met-L-X, which comprises approximately 5% Saran in sodium chloride together with flow agents; it is most commonly hand-applied with a scoop. Other effective agents include Lith-X, which has graphite powder and an organophosphate flame retardant, and dry sand.
See also.
Sodium in biology
Alkali metal

</doc>
