<doc id="38776" url="https://en.wikipedia.org/wiki?curid=38776" title="Major League Baseball">
Major League Baseball

Major League Baseball (MLB) is a professional baseball organization that is the oldest of the four major professional sports leagues in the United States and Canada. A total of 30 teams now play in the American League (AL) and National League (NL), with 15 teams in each league. The AL and NL operated as separate legal entities from 1901 and 1876 respectively. After cooperating but remaining legally separate entities since 1903, the leagues merged into a single organization led by the Commissioner of Baseball in 2000. The organization also oversees Minor League Baseball, which comprises about 240 teams affiliated with the Major League clubs. With the World Baseball Softball Confederation, MLB manages the international World Baseball Classic tournament.
Baseball's first professional team was founded in Cincinnati in 1869. The first few decades of professional baseball were characterized by rivalries between leagues and by players who often jumped from one team or league to another. 
The period before 1920 in baseball was known as the dead-ball era; players rarely hit home runs during this time. Baseball survived a conspiracy to fix the 1919 World Series, which came to be known as the Black Sox Scandal. The sport rose in popularity in the 1920s, and survived potential downturns during the Great Depression and World War II. Shortly after the war, baseball's color barrier was broken by Jackie Robinson.
The 1950s and 1960s were a time of expansion for the AL and NL, then new stadiums and artificial turf surfaces began to change the game in the 1970s and 1980s. Home runs dominated the game during the 1990s, and media reports began to discuss the use of anabolic steroids among Major League players in the mid-2000s. In 2006, an investigation produced the Mitchell Report, which implicated many players in the use of performance-enhancing substances, including at least one player from each team.
Today, MLB is composed of thirty teams: twenty-nine in the United States and one in Canada. Teams play 162 games each season and five teams in each league advance to a four-round postseason tournament that culminates in the World Series, a best-of-seven championship series between the two league champions that dates to 1903. Baseball broadcasts are aired throughout North America and in several other countries throughout the world. Games are aired on television, radio, and the Internet. MLB has the highest season attendance of any sports league in the world with more than 73 million spectators in 2015.
Organizational structure.
MLB is governed by the Major League Baseball Constitution. This document has undergone several incarnations since 1875, with the most recent revisions being made in 2012. Under the direction of the Commissioner of Baseball, MLB hires and maintains the sport's umpiring crews, and negotiates marketing, labor, and television contracts. MLB maintains a unique, controlling relationship over the sport, including most aspects of Minor League Baseball. This is due in large part to the 1922 U.S. Supreme Court ruling in "Federal Baseball Club v. National League", which held that baseball is not interstate commerce and therefore not subject to federal antitrust law. This ruling has been weakened only slightly in subsequent years. The weakened ruling granted more stability to the owners of teams and has resulted in values increasing at double-digit rates. There were several challenges to MLB's primacy in the sport between the 1870s and the Federal League in 1916; the last attempt at a new major league was the aborted Continental League in 1960.
The chief executive of MLB is the commissioner, Rob Manfred. The chief operating officer is Tony Petitti. There are six executive vice-presidents in charge of the following areas: baseball development, business, labor relations and human resources, finance, administration (whose vice-president is MLB's Chief Information Officer), and baseball operations. As of November 19, 2013, the MLB website lists only "five" executive VPs; the office of executive VP for labor relations and human resources is not listed.
The multimedia branch of MLB, which is based in Manhattan, is MLB Advanced Media. This branch oversees MLB.com and each of the 30 teams' websites. Its charter states that MLB Advanced Media holds editorial independence from the league, but it is under the same ownership group and revenue-sharing plan. MLB Productions is a similarly structured wing of the league, focusing on video and traditional broadcast media. MLB also owns 67 percent of MLB Network, with the other 33 percent split between several cable operators and satellite provider DirecTV. It operates out of studios in Secaucus, New Jersey, and also has editorial independence from the league.
League organization.
In 1920, the weak National Commission, which had been created to manage relationships between the two leagues, was replaced with the much more powerful Commissioner of Baseball, who had the power to make decisions for all of professional baseball unilaterally. For 60 years, the American and National Leagues fielded eight teams apiece.
In the 1960s, MLB expansion added eight teams, including the first non-U.S. team (the Montreal Expos). Two teams (the Seattle Mariners and the Toronto Blue Jays) were also added in the 1970s. From 1969 through 1993, each league consisted of an East and West Division. A third division, the Central Division, was added in each league in 1994. Through 1996, the two leagues met on the field only during the World Series and the All-Star Game. Regular-season interleague play was introduced in 1997.
In March 1995, two new franchises—the Arizona Diamondbacks and Tampa Bay Devil Rays (now known simply as the Tampa Bay Rays)—were awarded by MLB, to begin play in 1998. This addition brought the total number of franchises to 30. In early 1997, MLB decided to assign one new team to each league: Tampa Bay joined the AL and Arizona joined the NL. The original plan was to have an odd number of teams in each league (15 per league, with 5 in each division). In order for every team to be able to play daily, this would have required interleague play to be scheduled throughout the entire season. However, it was unclear at the time if interleague play would continue after the 1998 season, as it had to be approved by the players' union. For this and other reasons, it was decided that both leagues should continue to have an even number of teams; one existing club would have to switch leagues. The agreed in November 1997 to move from the AL to the NL, thereby making the NL a 16-team league. Later, when the Houston Astros changed ownership prior to the 2013 season, the team moved from the NL Central to the AL West, resulting in both leagues having three divisions of five teams each and allowing all teams to have a more balanced schedule. Interleague play is held throughout the season.
In 2000, the AL and NL were dissolved as legal entities, and MLB became a single, overall league "de jure", similar to the National Football League (NFL), National Basketball Association (NBA) and National Hockey League (NHL)—albeit with two components called "leagues" instead of "conferences." The same rules and regulations are used in both leagues, with one exception: the AL operates under the designated hitter rule, while the NL does not. This difference in rules between leagues is unique to MLB; the other sports leagues of the U.S. and Canada have one set of rules for all teams.
Current teams.
"An asterisk (*) denotes a relocation of a franchise. See respective team articles for more information."
History.
Founding.
In the 1860s, aided by the Civil War, "New York"-style baseball expanded into a national game and spawned baseball's first governing body, The National Association of Base Ball Players. The NABBP existed as an amateur league for 12 years. By 1867, more than 400 clubs were members. Most of the strongest clubs remained those based in the northeastern U.S. For professional baseball's founding year, MLB uses the year 1869—when the first professional team, the Cincinnati Red Stockings, was established.
A schism developed between professional and amateur ballplayers after the founding of the Cincinnati club. The NABBP split into an amateur organization and a professional organization. The National Association of Professional Base Ball Players, often known as the National Association (NA), was formed in 1871. Its amateur counterpart disappeared after only a few years. The modern Chicago Cubs and Atlanta Braves franchises trace their histories back to the National Association of Professional Base Ball Players in the 1870s.
In 1876, the National League of Professional Base Ball Clubs (later known as the National League or NL) was established after the NA proved ineffective. The league placed its emphasis on clubs rather than on players. Clubs could now enforce player contracts, preventing players from jumping to higher-paying clubs. Clubs were required to play the full schedule of games instead of forfeiting scheduled games when the club was no longer in the running for the league championship, which happened frequently under the NA. A concerted effort was made to curb gambling on games, which was leaving the validity of results in doubt. The first game in the NL—on Saturday, April 22, 1876 (at the Jefferson Street Grounds, Philadelphia)—is often pointed to as the beginning of MLB.
The early years of the NL were tumultuous, with threats from rival leagues and a rebellion by players against the hated "reserve clause", which restricted the free movement of players between clubs. Competitor leagues formed regularly and also disbanded regularly. The most successful was the American Association (1882–1891), sometimes called the "beer and whiskey league" for its tolerance of the sale of alcoholic beverages to spectators. For several years, the NL and American Association champions met in a postseason championship series—the first attempt at a World Series. The two leagues merged in 1892 as a single 12-team NL, but the NL dropped four teams after the 1899 season. This led to the formation of the American League in 1901 under AL president Ban Johnson, and the resulting bidding war for players led to widespread contract-breaking and legal disputes.
The war between the AL and NL caused shock waves throughout the baseball world. At a meeting at the Leland Hotel in Chicago in 1901, the other baseball leagues negotiated a plan to maintain their independence. A new National Association was formed to oversee these minor leagues. While the NA continues to this day (known as Minor League Baseball), at the time Ban Johnson saw it as a tool to end threats from smaller rivals who might expand in other territories and threaten his league's dominance.
After 1902, the NL, AL, and NA signed a new National Agreement which tied independent contracts to the reserve-clause contracts. The agreement also set up a formal classification system for minor leagues, the forerunner of today's system that was refined by Branch Rickey.
Several other early defunct baseball leagues are officially considered major leagues, and their statistics and records are included with those of the two current major leagues. These include the AA, the Union Association (1884), the Players' League (1890), and the Federal League (1914–1915). Both the UA and AA are considered major leagues by many baseball researchers because of the perceived high caliber of play and the number of star players featured. Some researchers dispute the major-league status of the UA by pointing out that franchises came and went and that the St. Louis club was deliberately "stacked"; the St. Louis club was owned by the league's president and it was the only club that was close to major-league caliber.
Dead-ball era.
The period between 1900 and 1919 is commonly called the "dead-ball era." Games of this era tended to be low scoring and were often dominated by pitchers, such as Walter Johnson, Cy Young, Christy Mathewson, Mordecai Brown, and Grover Cleveland Alexander. The term also accurately describes the condition of the baseball itself. The baseball used American rather than the modern Australian wool yarn and was not wound as tightly as it would become later, affecting the distance that it would travel. More significantly, balls were kept in play until they were mangled, soft and sometimes lopsided: a baseball cost three dollars, equal to $ today (in inflation-adjusted U.S. dollars), and owners were reluctant to purchase new balls. Fans were expected to throw back fouls and (rare) home runs. Baseballs also became stained with tobacco juice, grass, and mud, and sometimes the juice of licorice, which some players would chew for the purpose of discoloring the ball.
Also, pitchers could manipulate the ball through the use of the spitball. (In 1921 use of this pitch was restricted to a few pitchers with a grandfather clause). Additionally, many ballparks had large dimensions, such as the West Side Grounds of the Chicago Cubs, which was to the center field fence, and the Huntington Avenue Grounds of the Boston Red Sox, which was to the center field fence, thus home runs were rare, and "small ball" tactics such as singles, bunts, stolen bases, and the hit-and-run play dominated the strategies of the time. Hitting methods like the Baltimore Chop were used to increase the number of infield singles. On a successful Baltimore chop, the batter hits the ball forcefully into the ground, causing it to bounce so high that the batter reaches first base before the ball can be fielded and thrown to the first baseman.
The adoption of the foul strike rule in the early twentieth century quickly sent baseball from a high-scoring game to one where scoring runs became a struggle. Prior to the institution of this rule, foul balls were not counted as strikes: a batter could foul off any number of pitches with no strikes counted against him; this gave an enormous advantage to the batter. In 1901, the NL adopted the foul strike rule, and the AL followed suit in 1903.
After the 1919 World Series between the Chicago White Sox and Cincinnati Reds, baseball was rocked by allegations of a game fixing scheme known as the Black Sox Scandal. Eight players—Joe Jackson, Eddie Cicotte, Claude Williams, Buck Weaver, Arnold "Chick" Gandil, Fred McMullin, Charles "Swede" Risberg, and Oscar "Happy" Felsch—intentionally lost the World Series in exchange for a ring worth $100,000. Despite being acquitted, all were permanently banned from Major League Baseball.
Rise in popularity.
Baseball's popularity increased in the 1920s and 1930s. The 1920 season was notable for the death of Ray Chapman of the Cleveland Indians. Chapman, who was struck in the head by a pitch and died a few hours later, became the only MLB player to die of an on-field injury, a tragedy which led directly to both leagues requiring the placing into play new, white baseballs whenever a ball became scuffed or dirty, helping bring the "dead-ball" era to an end. The following year, the New York Yankees made their first World Series appearance. By the end of the 1930s, the team had appeared in 11 World Series, winning eight of them. Yankees slugger Babe Ruth had set the single season home run record in 1927, hitting 60 home runs; a few years earlier, Ruth had set the same record with 29 home runs.
Affected by the difficulties of the Great Depression, baseball's popularity had begun a downward turn in the early 1930s. By 1932, only two MLB teams turned a profit. Attendance had fallen, due at least in part to a 10% federal amusement tax added to baseball ticket prices. Baseball owners cut their rosters from 25 men to 23 men, and even the best players took pay cuts. Team executives were innovative in their attempts to survive, creating night games, broadcasting games live by radio and rolling out promotions such as free admission for women. Throughout the period of the Great Depression, no MLB teams moved or folded.
World War II era.
The onset of World War II created a significant shortage of professional baseball players, as more than 500 men left MLB teams to serve in the military. Many of them played on service baseball teams that entertained military personnel in the US or in the Pacific. MLB teams of this time largely consisted of young men, older players, and those with a military classification of 4F, indicating mental, physical, or moral unsuitability for service. Men like Pete Gray, a one-armed outfielder, got the chance to advance to the major leagues. However, MLB rosters did not include any black players through the end of the war. Black players, many of whom served in the war, were still restricted to playing Negro league baseball.
Wartime blackout restrictions, designed to keep outdoor lighting at low levels, caused another problem for baseball. These rules limited traveling and night games to the point that the 1942 season nearly had to be cancelled. On January 14, 1942, MLB Commissioner Kenesaw Mountain Landis wrote a letter to U.S. President Franklin D. Roosevelt and pleaded for the continuation of baseball during the war in hopes for a start of a new major league season. President Roosevelt responded, "I honestly feel that it would be best for the country to keep baseball going. There will be fewer people unemployed and everybody will work longer hours and harder than ever before. And that means that they ought to have a chance for recreation and for taking their minds off their work even more than before."
With the approval of President Roosevelt, spring training began in 1942 with few repercussions. The war interrupted the careers of stars including Stan Musial, Ted Williams, and Joe DiMaggio, but baseball clubs continued to field their teams.
Breaking the color barrier.
Branch Rickey, president and general manager of the Brooklyn Dodgers, began making efforts to introduce a black baseball player to the previously all-white professional baseball leagues in the mid-1940s. He selected Jackie Robinson from a list of promising Negro league players. After obtaining a commitment from Robinson to "turn the other cheek" to any racial antagonism directed at him, Rickey agreed to sign him to a contract for $600 a month. In what was later referred to as "The Noble Experiment", Robinson was the first black baseball player in the International League since the 1880s, joining the Dodgers' farm club, the Montreal Royals, for the 1946 season.
The following year, the Dodgers called Robinson up to the major leagues. On April 15, 1947, Robinson made his major league debut at Ebbets Field before a crowd of 26,623 spectators, including more than 14,000 black patrons. Black baseball fans began flocking to see the Dodgers when they came to town, abandoning their Negro league teams which they had followed exclusively. Robinson's promotion met a generally positive, although mixed, reception among newspapers and white major league players. Manager Leo Durocher informed his team, "I do not care if the guy is yellow or black, or if he has stripes like a fuckin' zebra. I'm the manager of this team, and I say he plays. What's more, I say he can make us all rich. And if any of you cannot use the money, I will see that you are all traded."
After a strike threat by some players, NL President Ford Frick and Baseball Commissioner Happy Chandler let it be known that any striking players would be suspended. Robinson received significant encouragement from several major league players, including Dodgers teammate Pee Wee Reese who said, "You can hate a man for many reasons. Color is not one of them." That year, Robinson earned the inaugural Major League Baseball Rookie of the Year Award (separate NL and AL Rookie of the Year honors were not awarded until 1949).
Less than three months later, Larry Doby became the first African-American to break the color barrier in the American League with the Cleveland Indians. The next year, a number of other black players entered the major leagues. Satchel Paige was signed by the Indians and the Dodgers added star catcher Roy Campanella and Don Newcombe, who was later the first winner of the Cy Young Award for his outstanding pitching.
Ban on women.
Major League Baseball banned the signing of women to contracts in 1952, and that ban lasted until 1992.
Expanding west, south, and north.
From 1903 to 1953, the two major leagues consisted of two eight-team leagues. The 16 teams were located in ten cities, all in the northeastern and midwestern United States: New York City had three teams and Boston, Chicago, Philadelphia, and St. Louis each had two teams. St. Louis was the southernmost and westernmost city with a major league team. The longest possible road trip, from Boston to St. Louis, took about 24 hours by railroad. In 1953, the NL's Boston Braves became the Milwaukee Braves. In 1954, the St. Louis Browns became the Baltimore Orioles. In 1955, the Philadelphia Athletics became the Kansas City Athletics.
Baseball experts consider the Brooklyn/Los Angeles Dodgers' boss Walter O'Malley to be "perhaps the most influential owner of baseball's early expansion era." Before the 1958 Major League Baseball season, he moved the Brooklyn Dodgers to Los Angeles. When O'Malley moved the Dodgers from Brooklyn, he appeared on the cover of "TIME". O'Malley was also influential in persuading the rival New York Giants to move west to become the San Francisco Giants. The Giants were already suffering from slumping attendance records at their aging ballpark, the Polo Grounds. Had the Dodgers moved out west alone, the St. Louis Cardinals— away—would have been the closest NL team. The joint move made West Coast road trips economical for visiting teams. O'Malley invited San Francisco Mayor George Christopher to New York to meet with Giants owner Horace Stoneham. Stoneham was considering moving the Giants to Minnesota, but he was convinced to join O'Malley on the West Coast at the end of 1957. The meetings between Stoneham, Christopher and O'Malley occurred against the wishes of Commissioner of Baseball Ford Frick. The dual moves were successful for both franchises—and for MLB. The Dodgers set a single-game MLB attendance record in their first home appearance with 78,672 fans.
In 1961, the first Washington Senators franchise moved to Minneapolis–St. Paul to become the Minnesota Twins. Two new teams were added to the American League at the same time: the Los Angeles Angels (who soon moved from downtown L.A. to nearby Anaheim) and a new Washington Senators franchise. The NL added the Houston Astros and the New York Mets in 1962. The Astros (known as the "Colt .45s" during their first three seasons) became the first southern major league franchise since the Louisville Colonels folded in 1899 and the first franchise to be located along the Gulf Coast. The Mets established a reputation for futility by going 40–120 during their first season of play in the nation's media capital—and by playing only a little better in subsequent campaigns—but in their eighth season (1969) the Mets became the first of the 1960s expansion teams to play in the post-season, culminating in a World Series title over the heavily-favored Baltimore Orioles.
In 1966, the major leagues moved to the "Deep South" when the Braves moved to Atlanta. In 1968, the Kansas City Athletics moved west to become the Oakland Athletics. In 1969, the American and National Leagues both added two expansion franchises. The American League added the Seattle Pilots (who became the Milwaukee Brewers after one disastrous season in Seattle) and the Kansas City Royals. The NL added the first Canadian franchise, the Montreal Expos, as well as the San Diego Padres.
In 1972, the second Washington Senators moved to the Dallas–Fort Worth metroplex to become the Texas Rangers. In 1977, baseball expanded again, adding a second Canadian team, the Toronto Blue Jays, as well as the Seattle Mariners. Subsequently, no new teams were added and no teams moved until the 1990s. In 1993, the NL added the Florida Marlins in the Miami area and the Colorado Rockies in Denver. In 1998, the Brewers switched leagues by joining the National League and two new teams were added: the NL's Arizona Diamondbacks in Phoenix and the American League's Tampa Bay Devil Rays in St. Petersburg, Florida.
After the 2001 season, the team owners voted in favor of contraction. Several MLB teams had been considered for elimination in early talks about contraction, but the Montreal Expos and the Minnesota Twins were the two teams that came closest to folding under the plan. Plans for MLB contraction were halted when the Twins landlord was awarded a court injunction that required the team to play its 2002 home games at their stadium. MLB owners agreed to hold off on reducing the league's size until at least 2006.
The Montreal Expos became the first franchise in over three decades to move when they became the Washington Nationals in 2005. This move left Canada with just one team, but it also returned baseball to the United States capital city after a 33-year absence. This franchise shift, like many previous ones, involved baseball's return to a city which had been previously abandoned. Not counting the short-lived Federal League, Montreal is the only city granted an MLB franchise since 1901 that does not currently host a team.
Pitching dominance and rule changes.
By the late 1960s, the balance between pitching and hitting had swung in favor of the pitchers. In 1968—later nicknamed "the year of the pitcher"—Boston Red Sox player Carl Yastrzemski won the American League batting title with an average of just .301, the lowest in the history of Major League Baseball. Detroit Tigers pitcher Denny McLain won 31 games, making him the only pitcher to win 30 games in a season since Dizzy Dean in 1934. St. Louis Cardinals starting pitcher Bob Gibson achieved an equally remarkable feat by allowing an ERA of just 1.12.
Following these pitching performances, in December 1968 the MLB Playing Rules Committee voted to reduce the strike zone from knees to shoulders to top of knees to armpits and lower the pitcher's mound from 15 to 10 inches, beginning in the 1969 season.
In 1973 the American League, which had been suffering from much lower attendance than the National League, sought to increase scoring even further by initiating the designated hitter (DH) rule.
New stadiums and artificial surfaces.
Throughout the 1960s and 1970s, as baseball expanded, NFL football had been surging in popularity, making it economical for many of these cities to build multi-purpose stadiums instead of single-purpose baseball fields. Because of climate and economic issues many of these facilities had playing surfaces made from artificial turf, as well as the oval designs characteristic of stadiums designed to house both baseball and football. This often resulted in baseball fields with relatively more foul territory than older stadiums. These characteristics changed the nature of professional baseball, putting a higher premium on speed and defense over home-run hitting power, since the fields were often too big for teams to expect to hit many home runs and foul balls hit in the air could more easily be caught for outs.
Teams began to be built around pitching—particularly their bullpens—and speed on the basepaths. Artificial surfaces meant balls traveled quicker and bounced higher, so it became easier to hit ground balls "in the hole" between the corner and middle infielders. Starting pitchers were no longer expected to throw complete games; it was enough for a starter to go 6–7 innings and turn the game over to the team's closer, a position which grew in importance over these decades. As stolen bases increased, home run totals dropped. After Willie Mays hit 52 home runs in 1965, only one player (George Foster) reached that mark until the 1990s.
Power age.
Routinely in the late 1990s and early 2000s, baseball players hit 40 or 50 home runs in a season, a feat that was considered rare even in the 1980s. It has since become apparent that at least some of this power surge was a result of players using steroids and other performance-enhancing drugs. Many modern baseball theorists believe that the need of pitchers to combat the rise in power could lead to a pitching revolution at some point. New pitches, such as the mysterious gyroball, could shift the balance of power back to the defensive side. Several pitches have changed the game of baseball, including the slider in the 1950s and 60s and the split-fingered fastball in the 1970s to 90s. Since the 1990s, the changeup has made a resurgence, being thrown masterfully by pitchers such as Trevor Hoffman, Greg Maddux, Jamie Moyer, Tom Glavine, Johan Santana, Pedro Martínez and Tim Lincecum. Recently, pitchers such as Lincecum, Jonathan Sánchez, and Ubaldo Jiménez have been throwing changeups with a split-finger grip, creating a dropping movement, dubbed the "split change."
Uniforms.
A baseball uniform is a type of uniform worn by baseball players, and by some non-playing personnel, such as field managers and coaches. It is worn to indicate the person's role in the game and—through the use of logos, colors, and numbers—to identify the teams and their players, managers, and coaches.
Traditionally, home uniforms display the team name on the front, while away uniforms display the team's home location. In modern times, however, exceptions to this pattern have become common, with teams using their team name on both uniforms. Most teams also have one or more alternate uniforms, usually consisting of the primary or secondary team color on the vest instead of the usual white or gray. In the past few decades throwback uniforms have become popular.
The New York Knickerbockers were the first baseball team to use uniforms, taking the field on April 4, 1849, in pants made of blue wool, white flannel shirts (jerseys) and straw hats. Caps and other types of headgear have been a part of baseball uniforms from the beginning. Baseball teams often wore full-brimmed straw hats or no cap at all since there was no official rule regarding headgear. Under the 1882 uniform rules, players on the same team wore uniforms of different colors and patterns that indicated which position they played.
In the late 1880s, the Detroit Wolverines and Washington Nationals of the National League and the Brooklyn Bridegrooms of the American Association were the first to wear striped uniforms. By the end of the 19th century, teams began the practice of having two different uniforms, one for when they played at home in their own baseball stadium and a different one for when they played away (on the road) at the other team's ballpark. It became common to wear white pants with a white color vest at home and gray pants with a gray or solid (dark) colored vest when away. By 1900, both home and away uniforms were standard across the major leagues.
Season structure.
Spring training.
Spring training is a series of practices and exhibition games preceding the start of the regular season. Spring training allows new players to audition for roster and position spots, and gives existing team players practice time prior to competitive play. The teams are divided into the Cactus League and the Grapefruit League. Spring training has always attracted fan attention, drawing crowds who travel to the warmer climates to enjoy the weather and watch their favorite teams play, and spring training usually coincides with spring break for many college students. Autograph seekers also find greater access to players during spring training.
Spring training typically lasts almost two months, starting in mid February and running until just before the season opening day, traditionally the first week of April. As pitchers benefit from a longer training period, pitchers and catchers begin spring training several days before the rest of the team.
Regular season.
The current MLB regular season, consisting of 162 games per team, typically begins on the first Sunday in April and ends on the first Sunday in October. Each team's schedule is typically organized into three-game series, with occasional two- or four-game series. Postponed games or continuations of suspended games can result in an ad hoc one-game or five-game series. A team's series are organized into homestands and road trips that group multiple series together. Teams generally play games five to seven days per week, commonly having Monday or Thursday as an off day. Frequently, games are scheduled at night. Sunday games are generally played during the afternoon, allowing teams to travel to their next destination prior to a Monday night game. In addition, teams will play day games frequently on Opening Day, holidays, and getaway days.
Each team plays 19 games against each of its four divisional opponents. It plays one home series and one away series, amounting to six or seven games, against the 10 other teams in its league. A team also plays one of the divisions in the other league, rotating each year, with two opponents in a three-game home series, two in a three-game away series, and one with four games split between home and away. Furthermore, each team has an interleague "natural rival" (in many cases its counterpart in the same metro area) with which it plays two home games and two away games each year.
With an odd number of teams in each league (15), it is necessary to have two teams participate in interleague play for most days in the season, except when two or more teams have a day off. Each team plays 20 interleague games throughout the season, usually with just one interleague game per day, but for one weekend in late May all teams will participate in an interleague series. Use of the DH rule is determined by the home team's league rules. Before 2013 interleague play was structured differently: there would be one weekend in mid-May and another period consisting typically of the last two-thirds of June in which all teams played interleague games (save for two NL teams each day), and no interleague games were scheduled outside those dates.
Over the course of a season, teams compete for one of the five playoff berths in their league. They can win one of these berths by either winning their division, or by capturing a wild card spot.
After the conclusion of the 162-game season, an additional tie-breaking game (or games) may be needed to determine postseason participation.
All-Star Game.
In early-to-mid July, just after the midway point of the season, the Major League Baseball All-Star Game is held during a four-day break from the regular-season schedule. The All-Star game features a team of players from the American League (AL)—led by the manager of the previous AL World Series team—and a team of players from the National League (NL), similarly managed, in an exhibition game. From 1959 to 1961, two games were held each season, one was held in July and one was held in August. The designated-hitter rule was used in the All-Star game for the first time in 1989. Following games used a DH when the game was played in an AL ballpark. Since 2010, the DH rule has been in effect regardless of venue.
The first official All-Star Game was held as part of the 1933 World's Fair in Chicago, Illinois, and was the idea of Arch Ward, then sports editor for "The Chicago Tribune". Initially intended to be a one-time event, its great success resulted in making the game an annual one. Ward's contribution was recognized by Major League Baseball in 1962 with the creation of the "Arch Ward Trophy", given to the All-Star Game's Most Valuable Player each year. (In 2002, this was renamed the Ted Williams Most Valuable Player Award.)
Beginning in 1947, the eight position players in each team's starting lineup have been voted into the game by fans. The fan voting was discontinued after a 1957 ballot-box-stuffing scandal in Cincinnati: seven of the eight slots originally went to Reds players, two of whom were subsequently removed from the lineup to make room for Willie Mays and Hank Aaron. Fan voting was reinstated in 1970 and has continued ever since, including Internet voting in recent years.
The 2002 contest in Milwaukee controversially ended in an 11-inning tie. Since 2003, the league which wins the All-Star game gets home-field advantage in the World Series: the league champion hosts the first two games at its own ballpark as well as the last two (if necessary). The National League did not win an All-Star game and thus gain home-field advantage until 2010; it was able to overcome this disadvantage and win in three of the seven World Series from 2003 to 2009.
MLB All-Star game players from both leagues have worn their team uniforms at the game with one exception. In the 1933 All-Star Game, the National League All-Star Team members wore special gray uniforms with "National League" written in navy blue letters across the front of the jersey.
Postseason.
When the regular season ends after the first Sunday in October (or the last Sunday in September), ten teams enter the postseason playoffs. These ten teams consist of six teams that are division champions by earning the best regular season overall win-loss record for their respective divisions, and four who are "wild-card" teams that are each one of two teams in their respective leagues who have earned the best regular season win-loss record, but are not division champions. Four rounds of series of games are played to determine the champion:
Within each league, the division winners are the #1, #2 and #3 seeds, based on win–loss records. The team with the best record among non division winners will be the first wildcard and the #4 seed. The team with the second best record among non division winners will be the second wildcard and the #5 seed. In the wildcard round, the #5 seed will play at the #4 seed in a one-game playoff. For the division series, the matchup will be the #1 seed against the Wild Card Game winner and the #2 seed against the #3 seed. The team belonging to the league that won the mid-season All-Star Game receives home-field advantage in the World Series.
Because each postseason series is split between the home fields of the two teams, home-field advantage does not usually play a large role in the postseason unless the series goes to its maximum number of games, giving one team an additional game at home. However, the first two games of a postseason series are hosted by the same team. That team may have an increased chance of starting the series with two wins, thereby gaining some momentum for the rest of the series.
Use of the DH rule in the World Series is determined by the home team's league rules.
International play.
Since 1986 an All-Star team from MLB is sent to a biennial end-of-the-season tour of Japan, dubbed as MLB Japan All-Star Series, playing exhibition games in a best-of format against the All-Stars from Nippon Professional Baseball (NPB) or recently as of 2014 their national team Samurai Japan.
In 2008, MLB played the MLB China Series in the People's Republic of China. It was a series of two spring-training games between the San Diego Padres and Los Angeles Dodgers. The games were an effort to popularize baseball in China.
MLB played the MLB Taiwan Series in Taiwan in November 2011. It was a series of five exhibition games played by a team made up of MLB players called the MLB All-Stars and the Chinese Taipei National Team. The MLB All-Stars swept the series, five games to zero. At the end of the 2011 season, it was announced that the Seattle Mariners and the Oakland Athletics would play their season openers in Japan. In October 2013, Phil Rogers of the "Chicago Tribune" wrote that MLB was considering postseason all-star tours in Taiwan and Korea; baseball is increasing in popularity in both countries.
The Arizona Diamondbacks opened the 2014 season against Los Angeles Dodgers on March 22–23 in Australia. The teams played each other at the historic Sydney Cricket Ground, which has a seating capacity of 46,000. The two games represented the first MLB regular-season play held in that country. The games counted as home games for the Diamondbacks, so they played 79 home games at Chase Field.
Together with the World Baseball Softball Confederation, MLB sponsors the World Baseball Classic, an international baseball tournament contested by national teams.
Steroids in baseball.
In 1998, both Mark McGwire and Sammy Sosa hit more than the long-standing single-season MLB record of 61 home runs. Barry Bonds topped the record in 2001 with 73 home runs. McGwire, Bonds and Sosa became the subjects of speculation regarding the use of performance-enhancing substances. McGwire later admitted that he used a steroid hormone that was still legal in baseball during the 1998 season. Baseball's original steroid testing policy, in effect from 2002 to 2005, provided for penalties ranging from a ten-game suspension for a first positive test to a one-year suspension for a fourth positive test. Players were tested at least once per year, with the chance that several players could be tested many times per year.
A 2006 book, "Game of Shadows" by "San Francisco Chronicle" investigative reporters Lance Williams and Mark Fainaru-Wada, chronicled alleged extensive use of performance enhancers, including several types of steroids and growth hormone by baseball superstars Barry Bonds, Gary Sheffield, and Jason Giambi. Former Senate Majority Leader George Mitchell was appointed by Selig on March 30, 2006 to investigate the use of performance-enhancing drugs in MLB. The appointment was made after several influential members of the U.S. Congress made negative comments about both the effectiveness and honesty of MLB's drug policies and Commissioner Selig.
The day before the Mitchell Report was to be released in 2007, Selig said, "I haven't seen the report yet, but I'm proud I did it." The report said that after mandatory random testing began in 2004, HGH treatment for athletic enhancement became popular among players, as HGH is not detectable in tests. It pointed out that HGH is likely a placebo with no performance-enhancing effects. The report included substance use allegations against at least one player from each MLB team.
According to ESPN, some people questioned whether Mitchell's director role with the Boston Red Sox created a conflict of interest, especially because no "prime players were in the report." The report named several prominent Yankees who were parts of World Series clubs; there is a long-running and fierce Yankees–Red Sox rivalry. Former U.S. prosecutor John M. Dowd brought up Mitchell's conflict of interest, but he later said that the former senator had done a good job. Mitchell acknowledged that his "tight relationship with Major League Baseball left him open to criticism", but he said that readers who examine the report closely "will not find any evidence of bias, of special treatment of the Red Sox".
On January 10, 2013, MLB and the players union reached an agreement to add random, in-season HGH testing. They also agreed to implement a new test to reveal the use of testosterone for the 2013 season. The current MLB drug policy provides for a 50-game suspension for a first positive test, a 100-game suspension for a second positive test, and a lifetime suspension for a third positive test. In 2009, allegations surfaced against Alex Rodriguez and David Ortiz, and Manny Ramirez received a 50-game suspension after testing positive for banned substances. In early April 2011, Ramirez retired from baseball rather than face a 100-game suspension for his second positive steroid test.
MLB in media.
Television.
Several networks televise baseball games, including Fox, ESPN, and MLB Network. Since 2008, Fox Sports has broadcast MLB games on "Fox Saturday Baseball" throughout the entire season; Fox previously only broadcast games from May to September. Fox also holds rights to the All-Star Game each season. Fox also alternates League Championship Series broadcasts, broadcasting the American League Championship Series (ALCS) in odd-numbered years and the National League Championship Series (NLCS) in even-numbered years. Fox broadcasts all games of the World Series. ESPN continues to broadcast MLB games through 2013 as well, beginning with national Opening Day coverage. ESPN broadcasts "Sunday Night Baseball", "Monday Night Baseball", "Wednesday Night Baseball", and "Baseball Tonight". ESPN also has rights to the Home Run Derby at the All-Star Game each July.
TBS airs Sunday afternoon regular season games (non-exclusive) nationally. In 2007, TBS began its exclusive rights to any tiebreaker games that determine division or wild card champions; it also airs exclusive coverage of the Division Series round of the playoffs. TBS carries the League Championship Series that are not included under Fox's television agreement; TBS shows the NLCS in odd-numbered years and the ALCS in even-numbered years.
In January 2009, MLB launched the MLB Network, featuring news and coverage from around the league, and airing 26 live games in the 2009 season. Each team also has local broadcasts for all games not carried by Fox on Saturdays or ESPN on Sunday nights. These games are typically split between a local broadcast television station and a local or regional sports network (RSN), though some teams only air local games through RSNs or through their own team networks. As Canada only contains one team, Sportsnet broadcasts Toronto Blue Jays games nationally. The channel is owned by Rogers Communications, who is also the parent company of the Blue Jays. Sportsnet also televises Fox's Saturday afternoon games, the All-Star Game, playoff games, and the World Series. In April 2011, TSN2 began carrying ESPN "Sunday Night Baseball" in Canada.
Blackout policy.
MLB has several blackout rules. A local broadcaster has priority to televise games of the team in their market over national broadcasters. For example, at one time TBS showed many Atlanta Braves games nationally and internationally in Canada. Fox Sports Networks also show many games in other areas. If the Braves played a team that FSN or another local broadcaster showed, the local station will have the broadcast rights for its own local market, while TBS would have been blacked out in the same market during the game. A market that has a local team playing in a weekday ESPN or ESPN2 game and is shown on a local station will see ESPNews, or, in the past, another game scheduled on ESPN or ESPN2 at the same time (if ESPN or ESPN2 operates a regional coverage broadcasting and operates a game choice), or will be subject to an alternative programming feed. MLB's streaming Internet video service is also subject to the same blackout rules.
Radio and Internet.
ESPN Radio holds national broadcast rights and broadcasts "Sunday Night Baseball" weekly throughout the season in addition to all playoff games. The rights to the World Series are exclusive to ESPN.
In addition, each team employs its own announcers, who broadcast during the regular season. Most teams operate regional networks to cover their fan bases; some of these supposedly regional networks (such as the New York Yankees Radio Network) have a national reach with affiliates located across the United States. Major League Baseball has an exclusive rights deal with XM Satellite Radio, which includes the channel MLB Network Radio and live play-by-play of all games. Many teams also maintain a network of stations that broadcast their games in Spanish; the former Montreal Expos broadcast their games in both English and French.
MLB games are also broadcast live on the internet. All television and radio broadcasts of games are available via subscription to MLB.tv at Major League Baseball's website, MLB.com, and radio-only broadcasts are also available via subscription to MLB.com Gameday Audio. Blackout rules are still applied for live television broadcasts, but not radio broadcasts.
International broadcasting.
ESPN Deportes televises a large number of MLB games in Spanish throughout Latin America. Wapa 2 airs games in Puerto Rico, including spring training games and most of the World Baseball Classic games involving the team from Puerto Rico. In Brazil, ESPN Brasil has exclusive rights on TV (ESPN and ESPN+) and Internet (WatchESPN), with Fox Sports also broadcasting some games.
Five in the United Kingdom previously screened MLB games, including the All-Star Game and the postseason games, on Sunday and Wednesday usually starting at 1 am BST. Most recently, Johnny Gould and Josh Chetwynd presented "MLB on Five" on that station. The channel covered baseball beginning on its opening night in 1997, but for financial reasons, the decision was made not to pick up MLB for the 2009 season. ESPN UK show live and recorded games several times a week—it is available with BT Sport and (on a subscriber-basis) Virgin Media in the UK. ESPN America televised a large number of games in the UK and dozens of other countries; in May 2013, ESPN announced that it would shut down the channel on July 31, 2013.
In Australia, MLB games are regularly shown on ESPN Australia (subscription).
In Middle East & North Africa, It is Broadcast On beIN Sports Channels

</doc>
<doc id="38779" url="https://en.wikipedia.org/wiki?curid=38779" title="Andrew Fastow">
Andrew Fastow

Andrew Stuart Fastow (born December 22, 1961) is a convicted criminal and businessman who was the chief financial officer of Enron Corporation, an energy trading company based in Houston, Texas, until he was fired shortly before the company declared bankruptcy. Fastow was one of the key figures behind the complex web of off-balance-sheet special purpose entities (limited partnerships which Enron controlled) used to conceal Enron's massive losses in their quarterly balance sheets. By unlawfully maintaining personal stakes in these ostensibly independent ghost-entities, he was able to defraud Enron out of tens of millions of dollars. The U.S. Securities and Exchange Commission subsequently opened an investigation into his and the company's conduct in 2001. Fastow served a six-year prison sentence for charges related to these acts. His wife Lea Weingarten, was also a former Enron assistant treasurer who plead guilty to conspiracy to commit wire fraud; money laundering conspiracy and filing fraudulent Income Tax returns and served jail time before early release to a half-way house.
Early life and education.
Fastow was born in Washington, D.C. He grew up in New Providence, New Jersey, to middle class Jewish parents, Carl and Joan Fastow, who worked in retail and merchandising. His parents, Carl and Joan Fastow, worked in merchandising. Fastow graduated from New Providence High School, where he took part in student government, played on the tennis team, and played in the school band. He was the sole student representative on the New Jersey State Board of Education.
Fastow graduated from Tufts University in 1983 with B.A.s in economics and Chinese. While there, he met his future wife, Lea Weingarten, daughter of Miriam Hadar Weingarten (a former Miss Israel 1958), whom he married in 1984. Fastow and Weingarten both earned MBAs at Northwestern University and worked for Continental Illinois National Bank and Trust Company in Chicago. Both he and his wife attended Congregation Or Ami, a conservative synagogue in Houston where he taught Hebrew School. 
Early career.
While at Continental Illinois, Fastow worked on the newly emerging "asset-backed securities". The practice spread across the industry "because it provides an obvious advantage for a bank", noted the "Chicago Tribune". "It moves assets off the bank's balance sheet while creating revenue." In 1984, Continental became the largest U.S. bank to fail in American history until the seizure of Washington Mutual in 2008.
Due to his work at Continental, Fastow was hired in 1990 by Jeffrey Skilling at the Enron Finance Corp. Fastow was named the Chief Financial Officer at Enron in 1998.
Rise in Enron.
Deregulation in the US energy markets in the late 1990s provided Enron with trade opportunities, including buying energy from cheap producers and selling it at markets with floating prices. Andrew Fastow was familiar with the market and knowledgeable in how to play it in Enron's favor. This quickly drew the attention of then chief executive officer of Enron Finance Corp Jeffrey Skilling. Skilling, together with Enron founder Kenneth Lay, was constantly concerned with various ways in which he could keep company stock price up, in spite of the true financial condition of the company.
Fastow designed a complex web of companies that solely did business with Enron, with the dual purpose of raising money for the company, and also hiding its massive losses in their quarterly balance sheets. This effectively allowed Enron's audited balance sheet to appear debt free, while in reality it owed more than 30 billion dollars at the height of its debt. While presented to the outside world as being independent entities, the funds Fastow created were to take write-downs off Enron's books and guaranteed not to lose money. Yet, Fastow himself had a personal financial stake in these funds, either directly or through partners amongst them Michael Kopper. Kopper, Fastow's chief lieutenant, pleaded guilty to taking part in a scam with Fastow that defrauded Enron shareholders of many millions. While defrauding Enron in this way, Fastow was also neglecting basic financial practices such as reporting the "cash on hand" and total liabilities. Fastow pressured some of the largest investment banks in the United States, such as Merrill Lynch, Citibank, and others to invest in his funds, threatening to cause them to lose Enron's future business if they did not. Fastow also reportedly got these firms to fire their analysts who dared to report Enron with negative ratings.
Fastow's approach to hiding losses was so effective that the year before Enron actually declared bankruptcy, a year in which the company was already well on its way to financial collapse, the Enron stock was at an all-time high of $90. Ultimately it would drop down to 40 cents per share, but not before many employees had been told to invest their retirement savings in Enron stock.
Legal problems at Enron.
On October 31, 2002, Fastow was indicted by a federal grand jury in Houston, Texas on 78 counts including fraud, money laundering, and conspiracy. On January 14, 2004, he pled guilty to two counts of wire and securities fraud, and agreed to serve a ten-year prison sentence. He also agreed to become an informant and cooperate with federal authorities in the prosecutions of other former Enron executives in order to receive a reduced sentence.
Prosecutors were so impressed with his performance that they ultimately lobbied for an even shorter sentence for Fastow. He was finally sentenced to six years at Oakdale Federal Correctional Complex in Oakdale, Louisiana. On May 18, 2011, Fastow was released to a Houston halfway house for the remainder of his sentence.
On May 6, 2004, his wife, Lea Fastow, a former Enron assistant treasurer, pled guilty to a tax charge and was sentenced to one year in a federal prison in Houston, and an additional year of supervised release. She was released to a halfway house on July 8, 2005.
Sentencing and incarceration.
After entering into a plea agreement with a maximum penalty of 10 years in prison and the forfeiture of US$23.8 million in family assets, on September 26, 2006, Fastow was sentenced to six years, followed by two years of probation. U.S. District Judge Ken Hoyt believed Fastow deserved leniency for his cooperation with the prosecution in several civil and criminal trials involving former Enron employees. Hoyt recommended that Fastow's sentence be served at the low-security Federal Correctional Institution in Bastrop, Texas. Fastow was incarcerated at the Federal Prison Camp near Pollock, Louisiana. Soon after his release on December 16, 2011, he began working as a document review clerk for a law firm in Houston. In March 2012, Fastow spoke on ethics to students at the University of Colorado Boulder Leeds School of Business. In June of 2013, Fastow addressed more than 2,000 anti-fraud professionals at the Association of Certified Fraud Examiners' 24th Annual ACFE Global Fraud Conference. In April 2014, Fastow spoke at Miami University in Oxford, Ohio, regarding business ethics. In February 2015, he spoke at the University of St. Thomas, the University of Minnesota, the University of Texas (Austin campus), the University of Houston Bauer College of Business, the University of Southern California's Leventhal School of Accounting, and the University of Missouri School of Accounting. In April 2016, Fastow spoke at the Ivey Business School via video conference, as he is currently not allowed to enter Canada; Fastow received a standing ovation at the end of his speech.
Other sources.
A number of books have been written about Enron and Fastow.
In 2003, Fastow was a prominent figure in "24 Days: How Two Wall Street Journal Reporters Uncovered the Lies that Destroyed Faith in Corporate America" by the reporters who had broken some of the key stories in the saga, Rebecca Smith and John R. Emshwiller. They painted Fastow as in their words "a screamer, who negotiated by intimidation and tirade".
Also in 2003, Bethany McLean and Peter Elkind wrote the book "The Smartest Guys in the Room: The Amazing Rise and Scandalous Fall of Enron" ISBN 1-59184-008-2. In 2005, the book was made into a documentary film "".
In 2005, Kurt Eichenwald's "Conspiracy of Fools" features Fastow as the book's antagonist.

</doc>
<doc id="38780" url="https://en.wikipedia.org/wiki?curid=38780" title="Mariner 2">
Mariner 2

Mariner 2 (Mariner-Venus 1962), an American space probe to Venus, was the first robotic space probe to conduct a successful planetary encounter. The first successful spacecraft in the NASA Mariner program, it was a simplified version of the Block I spacecraft of the Ranger program and an exact copy of Mariner 1. The missions of Mariner 1 and 2 spacecraft are together sometimes known as the Mariner R missions. Original plans called for the probes to be launched on the Atlas-Centaur, but serious developmental problems with that vehicle forced a switch to the much smaller Agena B stage. As such, the design of the Mariner R vehicles was greatly simplified. Far less instrumentation was carried than on the Soviet Venera probes of this period, including no TV camera as the Atlas-Agena B had only half as much lift capacity as the Soviet 8K78 booster. The Mariner 2 spacecraft was launched from Cape Canaveral on August 27, 1962 and passed as close as to Venus on December 14, 1962.
The Mariner probe consisted of a 100 cm (39.4 in) diameter hexagonal bus, to which solar panels, instrument booms, and antennas were attached. The scientific instruments on board the Mariner spacecraft were two radiometers (one each for the microwave and infrared portions of the spectrum), a micrometeorite sensor, a solar plasma sensor, a charged particle sensor, and a magnetometer. These instruments were designed to measure the temperature distribution on the surface of Venus, as well as making basic measurements of Venus' atmosphere.
The primary mission was to receive communications from the spacecraft in the vicinity of Venus and to perform radiometric temperature measurements of the planet. A second objective was to measure the interplanetary magnetic field and charged particle environment.
En route to Venus, Mariner 2 measured the solar wind, a constant stream of charged particles flowing outwards from the Sun, confirming the measurements by Luna 1 in 1959. It also measured interplanetary dust, which turned out to be scarcer than predicted. In addition, Mariner 2 detected high-energy charged particles coming from the Sun, including several brief solar flares, as well as cosmic rays from outside the Solar System. As it flew by Venus on December 14, 1962, Mariner 2 scanned the planet with its pair of radiometers, revealing that Venus has cool clouds and an extremely hot surface.
Spacecraft and subsystems.
The Mariner 2 spacecraft was designed and built by the Jet Propulsion Laboratory of the California Institute of Technology. It consisted of a hexagonal base, 1.04 meters across and 0.36 meters thick, which contained six magnesium chassis housing the electronics for the science experiments, communications, data encoding, computing, timing, and attitude control, and the power control, battery, and battery charger, as well as the attitude control gas bottles and the rocket engine. On top of the base was a tall pyramid-shaped mast on which the science experiments were mounted, which brought the total height of the spacecraft to 3.66 meters. Attached to either side of the base were rectangular solar panel wings with a total span of 5.05 meters and width of 0.76 meters. Attached by an arm to one side of the base and extending below the spacecraft was a large directional dish antenna.
The power system of Mariner 2 consisted of two solar cell wings, one 183 cm by 76 cm and the other 152 cm by 76 cm (with a 31 cm dacron extension (a solar sail) to balance the solar pressure on the panels), which powered the craft directly or recharged a 1000 watt-hour sealed silver-zinc cell battery. This battery was used before the panels were deployed, when the panels were not illuminated by the Sun, and when loads were heavy. A power-switching and booster regulator device controlled the power flow. Communications consisted of a 3-watt transmitter capable of continuous telemetry operation, the large high gain directional dish antenna, a cylindrical omnidirectional antenna at the top of the instrument mast, and two command antennas, one on the end of either solar panel, which received instructions for midcourse maneuvers and other functions.
Propulsion for midcourse maneuvers was supplied by a monopropellant (anhydrous hydrazine) 225 N retro-rocket. The hydrazine was ignited using nitrogen tetroxide and aluminum oxide pellets, and thrust direction was controlled by four jet vanes situated below the thrust chamber. Attitude control with a 1 degree pointing error was maintained by a system of nitrogen gas jets. The Sun and Earth were used as references for attitude stabilization. Overall timing and control was performed by a digital Central Computer and Sequencer. Thermal control was achieved through the use of passive reflecting and absorbing surfaces, thermal shields, and movable louvers.
Scientific instruments.
Only of the spacecraft could be allocated to scientific experiments. The following scientific instruments were mounted on the instrument mast and base:
The magnetometer was attached to the top of the mast below the omnidirectional antenna. Particle detectors were mounted halfway up the mast, along with the cosmic ray detector. The cosmic dust detector and solar plasma spectrometer were attached to the top edges of the spacecraft base. The microwave radiometer, the infrared radiometer and the radiometer reference horns were rigidly mounted to a 48 cm diameter parabolic radiometer antenna mounted near the bottom of the mast. All instruments were operated throughout the cruise and encounter modes except the radiometers, which were only used in the immediate vicinity of Venus.
In addition to these scientific instruments, Mariner 2 had a data conditioning system (DCS) and a scientific power switching (SPS) unit. The DCS was a solid-state electronic system designed to gather information from the scientific instruments on board the spacecraft. It had four basic functions: analog-to-digital conversion, digital-to-digital conversion, sampling and instrument-calibration timing, and planetary acquisition. The SPS unit was designed to perform the following three functions: control of the application of AC power to appropriate portions of the science subsystem, application of power to the radiometers and removal of power from the cruise experiments during radiometer calibration periods, and control of the speed and direction of the radiometer scans. The DCS sent signals to the SPS unit to perform the latter two functions.
Mission objectives.
The scientific objectives were:
Besides the experiments with the scientific instruments, the objectives of both the Mariner 1 and 2 probes included also engineering objectives:
Mission profile.
Launch.
Mariner 2 was launched from Cape Canaveral Air Force Station Launch Complex 12 at 06:53:14 UTC on August 27, 1962 by a two-stage Atlas-Agena rocket.
The two-stage Atlas-Agena rocket carrying Mariner 1 had veered off-course during its launch on July 22, 1962 due to a defective signal from the Atlas and a bug in the program equations of the ground-based guidance computer, and subsequently the spacecraft was destroyed by the Range Safety Officer. Two days after that launch, the backup probe and booster (Atlas vehicle 179D) were rolled out to LC-12. Mariner 2 nearly met the same fate as its predecessor when one of the Atlas's verniers moved to maximum stop shortly before booster engine cutoff. This caused a rapid roll of the launch vehicle that quickly approached one revolution per second. With the structural integrity of the booster in jeopardy, the range safety officer prepared to issue the destruct command, but almost as soon as it started, the rolling motion stopped and the launch proceeded uneventfully. The incident was traced to a loose wire in the guidance computer which was pushed back into place by the centrifugal force of the roll.
Five minutes after liftoff, the Atlas and Agena-Mariner separated, followed by the first Agena burn and second Agena burn. The Agena-Mariner separation injected the Mariner 2 spacecraft into a geocentric escape hyperbola at 26 minutes 3 seconds after liftoff. The NASA NDIF tracking station at Johannesburg, South Africa, acquired the spacecraft about 31 minutes after launch. Solar panel extension was completed approximately 44 minutes after launch. The Sun lock acquired the Sun about 18 minutes later. The high-gain antenna was extended to its acquisition angle of 72°. The output of the solar panels was slightly above the predicted output. As all subsystems were performing normally, as the battery was fully charged, and the solar panels were providing adequate power, the decision was made on August 29 to turn on cruise science experiments. On September 3, the Earth acquisition sequence was initiated, and Earth lock was established 29 minutes later.
Mid-course maneuver.
The accuracy of the Atlas-Agena was such that a mid-course correction was required to satisfy the mission requirements. The mid-course correction consisted of a roll-turn sequence, followed by a pitch-turn sequence and finally a motor-burn sequence. Preparation commands were sent to the spacecraft at 21:30 UTC on September 4. Initiation of the mid-course maneuver sequence was sent at 22:49:42 UTC and the roll-turn sequence started one hour later. The entire maneuver took approximately 34 minutes.
Due to the mid-course maneuver, the sensors lost their lock with the Sun and Earth. At 00:27:00 UTC the Sun re-acquisition began and at 00:34 UTC the Sun was reacquired. Earth re-acquisition started at 02:07:29 UTC and Earth was reacquired at 02:34 UTC.
Loss of attitude control.
On September 8 at 12:50 UTC, the spacecraft experienced a problem with attitude control. It automatically turned on the gyros, and the cruise science experiments were automatically turned off. The exact cause is unknown as attitude sensors went back to normal before telemetry measurements could be sampled, but it may have been an Earth-sensor malfunction or a collision with a small unidentified object which temporarily caused the spacecraft to lose Sun lock. A similar experience happened on September 29 at 14:34 UTC. Again, all sensors went back to normal before it could be determined which axis had lost lock. By this date, the Earth sensor brightness indication had essentially gone to zero. This time, however, telemetry data indicated that the Earth-brightness measurement had increased to the nominal value for that point in the trajectory.
Solar panel output.
On October 31, the output from one solar panel (with solar sail attached) deteriorated abruptly. It was diagnosed as a partial short circuit in the panel. As a precaution, the cruise science instruments were turned off. A week later, the panel resumed normal function, and cruise science instruments were turned back on. The panel permanently failed on November 15, but Mariner 2 was close enough to the Sun that one panel could supply adequate power; thus, the cruise science experiments were left active.
Encounter with Venus.
Mariner 2 was the first spacecraft to successfully encounter another planet, passing as close as to Venus on December 14, 1962.
Post encounter.
After encounter, cruise mode resumed. Spacecraft perihelion occurred on December 27 at a distance of 105,464,560 km. The last transmission from Mariner 2 was received on January 3, 1963 at 07:00 UTC, making the total time from launch to termination of the Mariner 2 mission 129 days.
Mariner 2 remains in heliocentric orbit.
Results.
The data produced during the flight consisted of two categories, namely tracking data and telemetry data.
Scientific observations.
The microwave radiometer made three scans of Venus in 35 minutes on December 14, 1962 starting at 18:59 UTC. The first scan was made on the dark side, the second was near the terminator, and the third was located on the light side. The scans with the 19 mm band revealed peak temperatures of 490 ± 11 K on the dark side, 595 ± 12 K near the terminator, and 511 ± 14 K on the light side. It was concluded that there is no significant difference in temperature across Venus. However, the results suggest a limb darkening, an effect which presents cooler temperatures near the edge of the planetary disk and higher temperatures near the center. This also supported the theory that the Venusian surface was extremely hot or the atmosphere optically thick.
The infrared radiometer showed that the 8.4 μm and 10.4 μm radiation temperatures were in agreement with radiation temperatures obtained from Earth-based measurements. There was no systematic difference between the temperatures measured on the light side and dark side of the planet, which was also in agreement with Earth-based measurements. The limb darkening effect that the microwave radiometer detected was also present in the measurements by both channels of the infrared radiometer. The effect was only slightly present in the 10.4 μm channel but was more pronounced in the 8.4 μm channel. The 8.4 μm channel also showed a slight phase effect. The phase effect indicated that if a greenhouse effect existed, heat was transported in an efficient manner from the light side to the dark side of the planet. The 8.4 μm and 10.4 μm showed equal radiation temperatures, indicating that the limb darkening effect would appear to come from a cloud structure rather than the atmosphere. Thus, if the measured temperatures were actually cloud temperatures instead of surface temperatures, then these clouds would have to be quite thick.
The magnetometer detected a persistent interplanetary magnetic field varying between 2 γ and 10 γ (nanotesla), which agrees with prior Pioneer 5 observations from 1960. This also means that interplanetary space is rarely empty or field-free. The magnetometer could detect changes of about 4 γ on any of the axes, but no trends above 10 γ were detected near Venus, nor were fluctuations seen like those that appear at Earth's magnetospheric termination. This means that Mariner 2 found no detectable magnetic field near Venus, although that didn't necessarily mean that Venus had none. However, if Venus had a magnetic field, then it would have to be at least smaller than 1/10 the magnetic field of the Earth. In 1980, the Pioneer Venus Orbiter indeed showed that Venus has a small weak magnetic field.
The Anton type 213 Geiger-Müller tube performed as expected. The average rate was 0.6 counts per second. Increases in its counting rate were larger and more frequent than for the two larger tubes, since it was more sensitive to particles of lower energy. It detected 7 small solar bursts of radiation during September and October and 2 during November and December. The absence of a detectable magnetosphere was also confirmed by the tube; it detected no radiation belt at Venus similar to that of Earth. The count rate would have increased by 104, but no change was measured.
It was also shown that in interplanetary space, the solar wind streams continuously
and the cosmic dust density is much lower than the near-Earth region.
Improved estimates of Venus' mass and the value of the Astronomical Unit were made. Also, research, which was later confirmed by other explorations, suggested that Venus rotates very slowly and in a direction opposite that of the Earth.

</doc>
<doc id="38781" url="https://en.wikipedia.org/wiki?curid=38781" title="Particle (disambiguation)">
Particle (disambiguation)

A particle in the physical sciences is a small localized object to which can be ascribed physical properties.
Particle may also refer to:

</doc>
<doc id="38782" url="https://en.wikipedia.org/wiki?curid=38782" title="Mariner 6 and 7">
Mariner 6 and 7

As part of NASA's wider Mariner program, Mariner 6 and Mariner 7 (Mariner Mars 69A and Mariner Mars 69B) completed the first dual mission to Mars in 1969. Mariner 6 was launched from Launch Complex 36B at Cape Kennedy and Mariner 7 from Launch Complex 36A at Cape Kennedy. The craft flew over the equator and south polar regions, analyzing the atmosphere and the surface with remote sensors, and recording and relaying hundreds of pictures. The mission's goals were to study the surface and atmosphere of Mars during close flybys, in order to establish the basis for future investigations, particularly those relevant to the search for extraterrestrial life, and to demonstrate and develop technologies required for future Mars missions. Mariner 6 also had the objective of providing experience and data which would be useful in programming the Mariner 7 encounter five days later.
Launch.
Three Mariner probes were constructed for the mission, with two intended to fly and one as a spare in the event of a mission failure. The spacecraft were shipped to Cape Canaveral with their Atlas-Centaur boosters in December 1968 – January 1969 to begin pre-launch checkouts and testing. On February 14, Mariner 6 was undergoing a simulated countdown on LC-36A, electrical power running, but no propellant loaded in the booster. During the test run, an electrical relay in the Atlas malfunctioned and opened two valves in the pneumatic system which allowed helium pressure gas to escape from the booster's balloon skin. The Atlas began to crumple over, however two pad technicians quickly activated a manual override switch to close the valves and pump helium back in. Although Mariner 6 and its Centaur stage had been saved, the Atlas had sustained structural damage and could not be reused, so they were removed from the booster and placed atop Mariner 7's launch vehicle on the adjacent LC-36B, while a different Atlas was used for Mariner 7. NASA awarded the quick-thinking technicians, Bill McClure and Jack Beverlin, an Exceptional Medal of Bravery for their courage in risking being crushed underneath the 124-foot rocket. In 2014, a recently-discovered escarpment on Mars was named the McClure-Beverlin Ridge in honor of the pair, who had since passed on.
Mariner 6 lifted from LC-36B at Cape Kennedy on February 25, 1969, using Atlas-Centaur AC-20 and Mariner 7, from LC-36A on March 27, using AC-19. The boost phase for both spacecraft went according to plan and no serious anomalies occurred with either launch vehicle. A minor LOX leak froze some telemetry probes in AC-20 which registered as a drop in sustainer engine fuel pressure; however, the engine performed normally through powered flight. In addition, BECO occurred a few seconds early due to a faulty cutoff switch, resulting in longer than intended burn time of the sustainer engine and Centaur, but this had no serious effect on vehicle performance or the flight path. AC-20 was launched at a 180-degree azimuth which would have resulted in the Atlas passing over part of the Caribbean and South America; to avoid this, the guidance computer was programmed to execute a "dog-leg" maneuver and pull the booster away from land.
The Centaur stage on both flights was set up to perform a retrorocket maneuver after capsule separation. This served two purposes, firstly to prevent venting propellant from the spent Centaur from contacting the probe, secondly to put the vehicle on a trajectory that would send it into solar orbit and not impact the Martian surface, potentially contaminating the planet with Earth microbes.
Spaceflight.
On July 29, 1969, less than a week before closest approach, Jet Propulsion Laboratory (JPL) lost contact with Mariner 7. The center regained the signal via the backup low-gain antenna and regained use of the high gain antenna again shortly after Mariner 6's close encounter. Leaking gases from a battery (which later failed) were thought to have caused the anomaly. Based on the observations that Mariner 6 made, Mariner 7 was reprogrammed in flight to take further observations of areas of interest and actually returned more pictures than Mariner 6, despite the battery's failure.
Closest approach for Mariner 6 occurred July 31, 1969, at 05:19:07 UT at a distance of above the martian surface. Closest approach for Mariner 7 occurred August 5, 1969 at 05:00:49 UT at a distance of above the martian surface. This was less than half of the distance used by Mariner 4 on the previous US Mars flyby mission.
Both spacecraft are now defunct in heliocentric orbits.
Science data and findings.
By chance, both spacecraft flew over cratered regions and missed both the giant northern volcanoes and the equatorial grand canyon discovered later. Their approach pictures did, however, photograph about 20 percent of the planet's surface, showing the dark features long seen from Earth, but none of the canals mistakenly observed by ground-based astronomers. In total 201 photos were taken and transmitted back to Earth, adding more detail than the earlier mission, Mariner 4. Both craft also studied the atmosphere of Mars.
Coming a week after Apollo 11, Mariner 6 and 7's flyby of Mars received less than the normal amount of media coverage for a mission of this significance.
The ultraviolet spectrometer onboard Mariners 6 and 7 was constructed by University of Colorado's Laboratory for Atmospheric and Space Physics (LASP).
The engineering model of Mariners 6 and 7 still exists, and is owned by the Jet Propulsion Laboratory (JPL). It is on loan to LASP, and is on display in the lab's lobby.
Spacecraft and subsystems.
The Mariner 6 and 7 spacecraft were identical, consisting of an octagonal magnesium frame base, diagonally and deep. A conical superstructure mounted on top of the frame held the high-gain 1 meter diameter parabolic antenna and four solar panels, each measuring 215 x , were affixed to the top corners of the frame. The tip-to-tip span of the deployed solar panels was 5.79 m. A low-gain omnidirectional antenna was mounted on a 2.23 m high mast next to the high-gain antenna. Underneath the octagonal frame was a two-axis scan platform which held scientific instruments. Overall science instrument mass was . The total height of the spacecraft was 3.35 m.
The spacecraft was attitude stabilized in three axes, referenced to the sun and the star Canopus. It utilized 3 gyros, 2 sets of 6 nitrogen jets, which were mounted on the ends of the solar panels, a Canopus tracker, and two primary and four secondary sun sensors. Propulsion was provided by a 223-newton rocket motor, mounted within the frame, which used the mono-propellant hydrazine. The nozzle, with 4-jet vane vector control, protruded from one wall of the octagonal structure. Power was supplied by 17,472 photovoltaic cells, covering an area of on the four solar panels. These could provide 800 watts of power near Earth, and 449 watts while at Mars. The maximum power requirement was 380 watts, once Mars was reached. A 1200 watt-hour, rechargeable, silver-zinc battery was used to provide backup power. Thermal control was achieved through the use of adjustable louvers on the sides of the main compartment.
Three telemetry channels were available for telecommunications. Channel A carried engineering data at 8⅓ or 33⅓ bit/s, channel B carried scientific data at 66⅔ or 270 bit/s and channel C carried science data at 16,200 bit/s. Communications were accomplished through the high- and low-gain antennas, via dual S-band traveling wave tube amplifiers, operating at 10 or 20 watts, for transmission. The design also included a single receiver. An analog tape recorder, with a capacity of 195 million bits, could store television images for subsequent transmission. Other science data was stored on a digital recorder. The command system, consisting of a central computer and sequencer (CC&S), was designed to actuate specific events at precise times. The CC&S was programmed with both a standard mission and a conservative backup mission before launch, but could be commanded and reprogrammed in flight. It could perform 53 direct commands, 5 control commands, and 4 quantitative commands.
Instrumentation:

</doc>
<doc id="38783" url="https://en.wikipedia.org/wiki?curid=38783" title="David Boies">
David Boies

David Boies (born March 11, 1941) is an American lawyer and chairman of the law firm Boies, Schiller & Flexner. He has been involved in various high-profile cases in the United States.
Early life and education.
Boies was born in Sycamore, Illinois, to two teachers, and raised in a farming community. He has four siblings. His first job was when he was 10 years old—a paper route with 120 customers. Boies has dyslexia and he did not learn to read until the third grade. In 1954, the family moved to California. Boies graduated from Fullerton Union High School in Fullerton, California. Boies attended the University of Redlands, received a B.S. from Northwestern University in 1964, a law degree magna cum laude from Yale Law School in 1966 and an LL.M. from New York University School of Law 1967; he was awarded an hononary LL.D. from the University of Redlands in 2000. He currently serves on the Board of Trustees of the National Constitution Center in Philadelphia, which is a museum dedicated to the U.S. Constitution.
Professional history.
Law firm.
Boies was an attorney at Cravath, Swaine & Moore, where he started upon law school graduation in 1966 and became a partner in 1973. He left Cravath in 1997 after a major client objected to his representation of the New York Yankees even though the firm itself had found no conflict. He left the firm within 48 hours of being informed of the client's objection and created his own firm, now known as Boies, Schiller & Flexner LLP. It is currently rated 17th in "overall prestige" and 12th among New York law firms by Vault.com, a website on legal career information.
Government.
Boies was also Chief Counsel and Staff Director of the United States Senate Antitrust Subcommittee in 1978, and served as Chief Counsel and Staff Director of the United States Senate Judiciary Committee in 1979.
Academia.
Boies has taught courses at New York University Law School and Cardozo School of Law.
Personal life.
Boies owns a home in Westchester County, New York,Hawk and Horse Vineyards in Northern California, an oceangoing yacht, and a large wine collection.
Philanthropy.
David and Mary Boies also fund the "Mary and David Boies Fellowships" for foreign students at the Harvard Kennedy School. The Boies give an annual picnic at their home for the incoming Teach for America corps for New York City (300–500 people). They support the Central European and Eurasian Law Institute (CEELI), a Prague-based institute that trains judges from newly democratized countries in Eastern Europe and the Middle East. There is a "Mary and David Boies Reading Room" at the CEELI Institute in Prague.
Criticism.
In his 2001 book, prosecutor and author Vincent Bugliosi criticized Boies' abilities as a trial lawyer, arguing that Boies "wasn't forceful or eloquent at all in making his points" in "Bush v. Gore". "lthough he seemed to have a very good grasp of the facts, he seemed completely incapable of drawing powerful, irresistible inferences from those facts that painted his opposition into a corner".
References.
Cites.
Breaking Legal News Featured Author

</doc>
<doc id="38785" url="https://en.wikipedia.org/wiki?curid=38785" title="Mariner 10">
Mariner 10

Mariner 10 was an American robotic space probe launched by NASA on November 3, 1973, to fly by the planets Mercury and Venus.
Mariner 10 was launched approximately two years after Mariner 9 and was the last spacecraft in the Mariner program. (Mariner 11 and 12 were allocated to the Voyager program and redesignated Voyager 1 and Voyager 2.)
The mission objectives were to measure Mercury's environment, atmosphere, surface, and body characteristics and to make similar investigations of Venus. Secondary objectives were to perform experiments in the interplanetary medium and to obtain experience with a dual-planet gravity assist mission. Mariner 10's science team was led by Bruce C. Murray at the Jet Propulsion Laboratory.
Design and trajectory.
Mariner 10 was the first spacecraft to make use of an interplanetary gravitational slingshot maneuver, using Venus to bend its flight path and bring its perihelion down to the level of Mercury's orbit. This maneuver, inspired by the orbital mechanics calculations of the Italian scientist Giuseppe Colombo, put the spacecraft into an orbit that repeatedly brought it back to Mercury. Mariner 10 used the solar radiation pressure on its solar panels and its high-gain antenna as a means of attitude control during flight, the first spacecraft to use active solar pressure control.
The components on Mariner 10 can be categorized into four groups based on their common function. The solar panels, power subsystem, attitude control, and computer kept the spacecraft operating properly during the flight. The navigational system, including the hydrazine rocket, would keep Mariner 10 on track to Venus and Mercury. Several scientific instruments would collect data at the two planets. Finally, the antennas would transmit this data to the Deep Space Network back on Earth, as well as receive commands from Mission Control. Mariner 10's various components and scientific instruments were attached to a central hub, which was roughly the shape of an octagonal prism. The hub stored the spacecraft's internal electronics. The Mariner 10 spacecraft was manufactured by Boeing. NASA set a strict limit of $98 million for Mariner 10's total cost, which marked the first time the agency subjected a mission to an inflexible budget constraint. No overruns would be tolerated, so mission planners carefully considered cost efficiency when designing the spacecraft's instruments. Cost control was primarily accomplished by executing contract work closer to the launch date than was recommended by normal mission schedules, as reducing the length of available work time increased cost efficiency. Despite the rushed schedule, very few deadlines were missed. The mission ended up about $1 million under budget.
Attitude control is needed to keep a spacecraft’s instruments and antennas aimed in the correct direction. During course maneuvers, a spacecraft may need to rotate so that its rocket faces the proper direction before being fired. Mariner 10 determined its attitude using two optical sensors, one pointed at the Sun, and the other at a bright star, usually Canopus; additionally, the probe's three gyroscopes provided a second option for calculating the attitude. Nitrogen gas thrusters were used to adjust Mariner 10’s orientation along three axes. The spacecraft’s electronics were intricate and complex: it contained over 32,000 pieces of circuitry, of which resistors, capacitors, diodes, microcircuits, and transistors were the most common devices. Commands for the instruments could be stored on Mariner 10’s computer, but were limited to 512 words. The rest had to be broadcast by the Mission Sequence Working Group from Earth. Supplying the spacecraft components with power required modifying the electrical output of the solar panels. The power subsystem used two redundant sets of circuitry, each containing a booster regulator and an inverter, to convert the panels' DC output to AC and alter the voltage to the necessary level. The subsystem could store up to 20 ampere hours of electricity on a 39 volt nickel-cadmium battery.
The flyby past Mercury posed major technical challenges for scientists to overcome. Due to Mercury's proximity to the Sun, Mariner 10 would have to endure 4.5 times more solar radiation than when it departed Earth—compared to previous Mariner missions, spacecraft parts needed extra shielding against the heat. Thermal blankets and a sunshade were installed on the main body. After evaluating different choices for the sunshade cloth material, mission planners chose beta cloth, a combination of aluminized Kapton and glass-fiber sheets treated with Teflon. However, solar shielding was unfeasible for some of Mariner 10's other components. Mariner 10's two solar panels needed to be kept under 115 °C. Covering the panels would defeat their purpose of producing electricity. The solution was to add an adjustable tilt to the panels, so the angle at which they faced the sun could be changed. Engineers considered folding the panels toward each other, making a V-shape with the main body, but tests found this approach had the potential to overheat the rest of the spacecraft. The alternative chosen was to mount the solar panels in a line and tilt them along that axis, which had the added benefit of increasing the efficiency of the spacecraft’s nitrogen jet thrusters, which could now be placed on the panel tips. The panels could be rotated a maximum of 76 degrees. Additionally, Mariner's 10 hydrazine rocket nozzle had to face the Sun to function properly, but scientists rejected covering the nozzle with a thermal door as an undependable solution. Instead, a special paint was applied to exposed parts on the rocket so as to reduce heat flow from the nozzle to the delicate instruments on the spacecraft.
Accurately performing the gravity assist at Venus posed another hurdle. If Mariner 10 was to maintain a course to Mercury, its trajectory could deviate no more than from a critical point in the vicinity of Venus. To ensure that the necessary course corrections could be made, mission planners tripled the amount of hydrazine fuel Mariner 10 would carry, and also equipped the spacecraft with more nitrogen gas for the thrusters than the previous Mariner mission had held. These upgrades proved crucial in enabling the second and third Mercury flybys.
Even so, the mission still lacked the ultimate safeguard: a sister spacecraft. It was common for probes to be launched in pairs, with complete redundancy to guard against the failure of one or the other. The budget constraint ruled this option out. Even though mission planners stayed sufficiently under budget to divert some funding for constructing a backup spacecraft, the budget did not permit both to be launched at the same time. In the event that Mariner 10 failed, NASA would only allow the backup to be launched if the fatal error was diagnosed and fixed—this would have to be completed in the two-and-a-half weeks between the scheduled launch on November 3 and the last possible launch date of November 21.
Instruments.
Mariner 10 conducted seven experiments at Venus and Mercury. Six of these experiments had a dedicated scientific instrument to collect data. The experiments and instruments were designed by research laboratories and educational institutions from across the United States. Out of forty-six submissions, JPL selected seven experiments on the basis of maximizing science return without exceeding cost guidelines: together, the seven scientific experiments cost 12.6 million dollars, about one-eighth of the total mission budget.
Television photography.
The imaging system, the Television Photography Experiment, consisted of two 15 cm (5.9″) Cassegrain telescopes feeding vidicon tubes. The main telescope could be bypassed to a smaller wide angle optic, but using the same tube. It had an 8-position filter wheel, with one position occupied by a mirror for the wide-angle bypass.
The entire imaging system was imperiled when electric heaters attached to the cameras failed to turn on immediately after launch. To avoid the Sun's damaging heat, the cameras were deliberately placed on the spacecraft side facing away from the Sun. Consequently, the heaters were needed to prevent the cameras from losing heat and become so cold that they would become damaged. JPL engineers found that the vidicons could generate enough heat through normal operation to stay just above the critical temperature of -40 °C; therefore they advised against turning off the cameras during the flight. Fortunately, test photos of the Earth and Moon showed that image quality had not been significantly affected. The mission team was pleasantly surprised when the camera heaters started working on January 17, two months after launch. Later investigation concluded that a short circuit in a different location on the probe had prevented the heater from turning on. This allowed the vidicons to be turned off as needed.
Of the six main scientific instruments, the cameras were by far the most massive device. Requiring 67 watts of electricity, the cameras consumed more power than the other five instruments combined. The system returned about 7000 photographs of Mercury and Venus during Mariner 10's flybys.
Infrared radiometer.
The infrared radiometer detected infrared radiation given off by Mercury's surface and Venus' atmosphere, from which the temperature could be calculated. How quickly the surface lost heat as it rotated into the planet's dark side revealed aspects about the surface's composition, such as whether it was made out of rocks, or out of finer particles. The infrared radiometer contained a pair of Cassegrain telescopes fixed at an angle of 120 degrees to each other, and a pair of detectors made from antimony-bismuth thermopiles. The instrument was designed to measure temperatures as cold as -193 °C and as hot as 427 °C. Stillman C. Chase, Jr. of the Santa Barbara Research Center headed the infrared radiometer experiment.
Ultraviolet spectrometers.
Two ultraviolet spectrometers were involved in this experiment, one to measure UV absorption, the other to sense UV emissions. The occultation spectrometer scanned Mercury's edge as it passed in front of the Sun, and detected whether solar ultraviolet radiation was absorbed at certain wavelengths, which would indicate the presence of gas particles, and therefore an atmosphere. The airglow spectrometer detected extreme ultraviolet radiation emanating from atoms of gaseous hydrogen, helium, carbon, oxygen, neon, and argon. Unlike the occultation spectrometer, it did not require backlighting from the Sun, and could move along with the rotatable scan platform on the spacecraft. The experiment's most important goal was to ascertain whether Mercury had an atmosphere, but would also gather data at Earth and Venus and study the interstellar background radiation.
Plasma detectors.
The plasma experiment's goal was to study the ionized gases (plasma) of the solar wind, the temperature and density of its electrons, and how the planets affected the velocity of the plasma stream. The experiment contained two components, facing in opposite directions. The Scanning Electrostatic Analyzer was aimed toward the Sun, and could detect positive ions and electrons, which were separated by a set of three concentric hemispherical plates. The Scanning Electron Spectrometer was aimed away from the Sun, and detected only electrons, using just one hemispherical plate. The instruments could be rotated about 60 degrees to either side. By gathering data on the solar wind's movement around Mercury, the plasma experiment could be used to verify the magnetometer's observations of Mercury's magnetic field. Using the plasma detectors, Mariner 10 gathered the first "in situ" solar wind data from inside Venus' orbit.
Shortly after launch, scientists found that the Scanning Electrostatic Analyzer had failed because a door shielding the analyzer did not open. An unsuccessful attempt was made to forcibly unfasten the door with the first course correction maneuver. The experiment operators had planned to observe the directions taken by positive ions prior to the ions' collision with the Analyzer, but this data was lost. The experiment was still able to collect some data using the properly functioning Scanning Electron Spectrometer.
Charged particle telescopes.
The goal of the charged particles experiment was to observe how the heliosphere interacted with cosmic radiation. In connection with the plasma detectors and magnetometers, this experiment had the potential to provide additional evidence of a magnetic field around Mercury, by showing whether such a field had captured charged particles. Two telescopes were used to collect highly energetic electrons and atomic nuclei, specifically oxygen nuclei or less massive. These particles then passed through a set of detectors and were counted.
Magnetometers.
Two fluxgate magnetometers were entrusted with discerning whether Mercury produced a magnetic field, and studying the interplanetary magnetic field between flybys. In designing this experiment, scientists had to account for interference from the magnetic field generated by Mariner 10’s many electronic parts. For this reason, the magnetometers had to be situated on a long boom, one closer to the octagonal hub, the other one further away. Data from the two magnetometers would be cross-referenced to filter out the spacecraft’s own magnetic field. Drastically weakening the probe’s magnetic field would have increased costs.
Celestial Mechanics and Radio Science experiment.
This experiment investigated the mass and gravitational characteristics of Mercury. It was of particular interest because of the planet's closeness to the Sun, large orbital eccentricity, and unusual spin-orbit resonance. 
As the spacecraft passed behind Mercury on the first encounter there was an opportunity to probe the atmosphere and to measure the radius of the planet. By observing phase changes in the S-band radio signal, measurements of the atmosphere could be made. The atmosphere was assessed as having a density of about .
Departing the Earth–Moon system.
Boeing finished building the spacecraft at the end of June 1973, and Mariner 10 was delivered from Seattle to JPL's headquarters in California, where JPL comprehensively tested the integrity of the spacecraft and its instruments. After the tests were finished, the probe was transported to the Eastern Test Range in Florida, the launch site. Technicians filled a tank on the spacecraft with of hydrazine fuel so that the probe could make course corrections, and attached squibs, whose detonation would signal Mariner 10 to exit the launch rocket and deploy its instruments. The planned gravity assist at Venus made it feasible to use an Atlas-Centaur rocket instead of a more powerful but more expensive Titan IIIC. The probe and the Atlas-Centaur were attached together ten days prior to liftoff. Launch posed one of the largest risks of failure for the Mariner 10 mission—Mariner 1, Mariner 3, and Mariner 8 all failed minutes after lift-off due to either engineering failures or Atlas rocket malfunctions. The mission had a launch period of about a month in length, from October 16, 1973, to November 21. NASA chose November 3 as the launch date because it would optimize imaging conditions when the spacecraft arrived at Mercury.
On November 3 at 12:45 am Eastern Time, the Atlas-Centaur carrying Mariner 10 lifted off from pad SLC-36B. The Atlas stage burned for around four minutes, after which it was jettisoned, and the Centaur stage took over for an additional five minutes, propelling Mariner 10 to a parking orbit. The temporary orbit took the spacecraft one-third of the distance around Earth: this maneuver was needed to reach the correct spot for a second burn by the Centaur engines, which set Mariner 10 on a path towards Venus. The probe then separated from the rocket; subsequently, the Centaur stage diverted away to avoid the possibility of future collision. Never before had a planetary mission depended upon two separate rocket burns during the launch, and even with Mariner 10, scientists initially viewed the maneuver as too risky.
During its first week of flight, the Mariner 10 camera system was tested by taking five photographic mosaics of the Earth and six of the Moon. It also obtained photographs of the north polar region of the Moon where prior coverage was poor. These photographs provided a basis for cartographers to update lunar maps and improve the lunar control net.
Cruise to Venus.
Far from being an uneventful cruise, Mariner 10’s three-month journey to Venus was fraught with technical malfunctions, which kept mission control on edge. Donna Shirley recounted her team’s frustration: "It seemed as if we were always just patching Mariner 10 together long enough to get it on to the next phase and next crisis." A trajectory correction maneuver was made on November 13, 1973. Immediately afterwards, the star-tracker locked onto a bright flake of paint which had come off the spacecraft and lost tracking on the guide star Canopus. An automated safety protocol recovered Canopus, but the problem of flaking paint recurred throughout the mission. The on-board computer also experienced unscheduled resets occasionally, which necessitated reconfiguring the clock sequence and subsystems. Periodic problems with the high-gain antenna also occurred during the cruise. On January 8, a malfunction thought to be caused by a short-circuited diode occurred in the power subsystem. As a result, the main booster regulator and inverter failed, leaving the spacecraft dependent on the redundant regulator. Mission planners feared that the same problem could recur in the redundant system and cripple the spacecraft.
In January 1974, Mariner 10 made ultraviolet observations of Comet Kohoutek. Another mid-course correction was made on January 21, 1974.
Venus flyby.
The spacecraft passed Venus on February 5, 1974, the closest approach being 5,768 km at 17:01 UT. It was the twelfth spacecraft to reach Venus and the eighth to return data from the planet, as well as the first mission to succeed in broadcasting images of Venus back to Earth. Mariner 10 built upon observations made by Mariner 5 six years earlier; most importantly, Mariner 10 had a camera whereas the prior mission lacked one. As Mariner 10 veered around Venus, from the planet's night side to daylight, the cameras snapped the probe's first image of Venus, showing an illuminated arc of clouds over the north pole emerging from darkness. Engineers initially feared that the star-tracker could mistake the much brighter Venus for Canopus, repeating the mishaps with flaking paint. Fortunately, the star-tracker did not malfunction. Earth occultation occurred between 17:07 UT and 17:11 UT, during which the spacecraft transmitted X-band radio waves through Venus' atmosphere, gathering data on cloud structure and temperature. Although Venus's cloud cover is nearly featureless in visible light, it was discovered that extensive cloud detail could be seen through Mariner's ultraviolet camera filters. Earth-based ultra-violet observation had shown some indistinct blotching even before Mariner 10, but the detail seen by Mariner was a surprise to most researchers. The probe continued photographing Venus until February 13. Among the encounter's 4,165 acquired photographs, one resulting series of images captured a thick and distinctly patterned atmosphere making a full revolution every four days, just as terrestrial observations had suggested.
The mission revealed the composition and meteorological nature of Venus’ atmosphere. Data from the radio science experiment measured the extent to which radio waves passing through the atmosphere were refracted, which was used to calculate the density, pressure, and temperature of the atmosphere at any given altitude. Overall, atmospheric temperature is higher closer to the planet’s surface, but Mariner 10 found four altitudes where the pattern was reversed, which could signify the presence of a layer of clouds. The inversions occurred at the 56, 61, 63, and 81 km levels, confirming previous observations made by the Mariner 5 encounter. The ultraviolet spectrometers identified the chemical substances that comprise Venus’ atmosphere. Analysis of the atmosphere’s hydrogen showed the gas was depleted of deuterium, ruling out the possibility that Venus obtained the element from collisions with comets. Instead, scientists theorized the hydrogen was captured from the solar wind. The elevated concentration of atomic oxygen in the upper atmosphere showed that the atmosphere is stratified into upper and lower layers that do not mix with each other; photographs of the upper and lower cloud layers corroborated this hypothesis. Mariner 10’s ultraviolet photographs were an invaluable information source for studying the churning clouds of Venus’ atmosphere. The mission researchers believed the cloud features they photographed were located in the stratosphere and upper troposphere, created by condensation; they also concluded that the contrast between darker and lighter features was due to differences in the cloud’s absorptivity of UV light. The subsolar region was of particular interest: as the sun is straight overhead, it imparts more solar energy to this area than other part of the planet. Compared to the rest of the planet’s atmosphere, the subsolar region was highly active and irregular. "Cells" of air lifted by convection, each up to 500 km wide, were observed forming and dissipating within the span of a few hours; some had polygonal outlines.
The gravity assist was also a success, coming well within the acceptable margin for error. In the four hours between 16:00 UT and 20:00 UT on February 5, Mariner 10's heliocentric velocity dropped from 82,785 mph to 72,215 mph. This changed the shape of the spacecraft's elliptical orbit around the Sun, so that the perihelion now coincided with the orbit of Mercury.
First Mercury flyby.
The spacecraft flew past Mercury three times. The first Mercury encounter took place at 20:47 UT on March 29, 1974, at a range of , passing on the shadow side.
Second Mercury flyby.
After looping once around the Sun while Mercury completed two orbits, Mariner 10 flew by Mercury again on September 21, 1974, at a more distant range of below the southern hemisphere. 
Third Mercury flyby.
After losing roll control in October 1974, a third and final encounter, the closest to Mercury, took place on March 16, 1975, at a range of , passing almost over the north pole.
End of mission.
With its maneuvering gas just about exhausted, Mariner 10 started another orbit of the Sun. Engineering tests were continued until March 24, 1975, when final depletion of the nitrogen supply was signaled by the onset of an un-programmed pitch turn. Commands were sent immediately to the spacecraft to turn off its transmitter, and radio signals to Earth ceased.
Mariner 10 is presumably still orbiting the Sun, although its electronics have probably been damaged by the Sun's radiation. Mariner 10 has not been spotted or tracked from Earth since it stopped transmitting. The only way it would not be orbiting would be if it had been hit by an asteroid or gravitationally perturbed by a close encounter with a large body. Both of these occurrences are extremely unlikely, so it is assumed to still be in orbit.
Discoveries.
During its flyby of Venus, Mariner 10 discovered evidence of rotating clouds and a very weak magnetic field. Using a near-ultraviolet filter, it photographed Venus's chevron clouds and performed other atmospheric studies.
The spacecraft flew past Mercury three times. Owing to the geometry of its orbit – its orbital period was almost exactly twice Mercury's – the same side of Mercury was sunlit each time, so it was only able to map 40–45% of Mercury’s surface, taking over 2,800 photos. It revealed a more or less Moon-like surface. It thus contributed enormously to our understanding of Mercury, whose surface had not been successfully resolved through telescopic observation. The regions mapped included most or all of the Shakespeare, Beethoven, Kuiper, Michelangelo, Tolstoj, and Discovery quadrangles, half of Bach and Victoria quadrangles, and small portions of Solitudo Persephones (later Neruda), Liguria (later Raditladi), and Borealis quadrangles.
Mariner 10 also discovered that Mercury has a tenuous atmosphere consisting primarily of helium, as well as a magnetic field and a large iron-rich core.
Its radiometer readings suggested that Mercury has a night time temperature of −183 °C (−297 °F) and maximum daytime temperatures of 187 °C (369 °F).
Planning for MESSENGER, a spacecraft that surveyed Mercury until 2015, relied extensively on data and information collected by Mariner 10.
Mariner 10 Commemoration.
In 1975, the US Post Office issued a commemorative stamp featuring the Mariner 10 space probe. The 10-cent Mariner 10 commemorative stamp was issued on April 4, 1975, at Pasadena, California.
Since the backup spacecraft was never launched, it was put on exhibition at the National Air and Space Museum of the Smithsonian Institution. 

</doc>
<doc id="38786" url="https://en.wikipedia.org/wiki?curid=38786" title="Mariner 1">
Mariner 1

Mariner 1 was the first spacecraft of the American Mariner program, designed for a planetary flyby of Venus. It cost $18.5 Million in 1962. It was launched aboard an Atlas-Agena rocket on July 22, 1962. Shortly after takeoff the rocket responded improperly to commands from the guidance systems on the ground, setting the stage for an apparent software-related guidance system failure. With the craft effectively uncontrolled, a range safety officer ordered its destructive abort 294.5 seconds after launch.
According to NASA's current account for the public:
The role of software error in the launch failure remains somewhat mysterious in nature, shrouded in the ambiguities and conflicts among (and in some accounts, even within) the various accounts, official and otherwise. The probe's mission was accomplished by Mariner 2 which launched 5 weeks later.
Spacecraft and subsystems.
The Mariner 1 spacecraft was identical to Mariner 2, launched 27 August 1962. Mariner 1 consisted of a hexagonal base, across and , which contained six magnesium chassis housing the electronics for the science experiments, communications, data encoding, computing, timing, and attitude control and the power control, battery, and battery charger, as well as the attitude control gas bottles and the rocket engine. On top of the base, was a tall pyramid-shaped mast on which the science experiments were mounted which brought the total height of the spacecraft to . Attached to either side of the base were rectangular solar panel wings with a total span of 5.05 meters and width of 0.76 meters (). Attached by an arm to one side of the base and extending below the spacecraft was a large directional dish antenna.
The Mariner 1 power system consisted of the two solar cell wings, one and the other, , with a dacron extension (a solar sail) to balance the solar pressure on the panels. Those panels powered the craft directly or recharged a 1,000-watt-hour sealed silver-zinc cell battery, which was to be used before the panels were deployed, when the panels were not illuminated by the Sun, and when loads were heavy. A power-switching and booster regulator device controlled the power flow. Communications consisted of a 3-watt transmitter capable of continuous telemetry operation, the large high gain directional dish antenna, a cylindrical omnidirectional antenna at the top of the instrument mast, and two command antennas, one on the end of either solar panel, which received instructions for midcourse maneuvers and other functions.
Propulsion for midcourse maneuvers was supplied by a monopropellant (anhydrous hydrazine) 225 N retro-rocket. The hydrazine was ignited using nitrogen tetroxide and aluminium oxide pellets, and thrust direction was controlled by four jet vanes situated below the thrust chamber. Attitude control with a 1 degree pointing error was maintained by a system of nitrogen gas jets. The Sun and Earth were used as references for attitude stabilization. Overall timing and control was performed by a digital Central Computer and Sequencer. Thermal control was achieved through the use of passive reflecting and absorbing surfaces, thermal shields, and movable louvers.
The scientific experiments were mounted on the instrument mast and base. A magnetometer was attached to the top of the mast below the omnidirectional antenna. Particle detectors were mounted halfway up the mast, along with the cosmic ray detector. A cosmic-dust detector and solar plasma spectrometer/detector were attached to the top edges of the spacecraft base. A microwave radiometer and an infrared radiometer and the radiometer reference horns were rigidly mounted to a diameter parabolic radiometer antenna mounted near the bottom of the mast.
In addition, a small 91 × 150 cm (3-by-5-foot) United States flag was folded and stowed onboard Mariner 1 (and Mariner 2), before it was mated to the Agena.
Launch failure.
The launch was aborted due to a combination of two failures, an antenna hardware failure and an onboard guidance system software failure.
First, "the guidance antenna on the Atlas performed poorly, below specifications. When the signal received by the rocket became weak and noisy, the rocket lost its lock on the ground guidance signal that supplied steering commands."
As a result, the rocket had to rely on its onboard guidance system, which had a bug in it. There are differing accounts of the details of this error.
Over bar transcription error.
The most detailed and consistent account was that the error was in hand-transcription of a mathematical symbol in the program specification for the guidance system, in particular a missing overbar. 
The error had occurred when a symbol was being transcribed by hand in the specification for the guidance program. The writer missed the superscript bar (or overline) in
by which was meant "the "n"th smoothed value of the time derivative of a radius R". Since the smoothing function indicated by the bar was left out of the specification for the program, the implementation treated normal minor variations of velocity as if they were serious, causing spurious corrections that sent the rocket off course. It was then destroyed by the Range Safety Officer.
Alternate guidance system failure explanations.
The cryptic nature of the problems that led to the decision to abort Mariner 1, as well as the confusion in various reports on the incident, led to other explanations in the popular press.
"The most expensive hyphen in history".
Many accounts note a missing "hyphen" ('-') rather than the over bar, in either the equations, the computer instructions or the data. For example, Arthur C. Clarke wrote several years later that Mariner 1 was "wrecked by the most expensive hyphen in history".
Several factors contributed to the "missing hyphen" narrative and its longevity, even in official accounts from technical cognoscenti at JPL and NASA. Among the factors cited (or obvious enough):
Regardless of whatever may have given rise to initial reports of a "missing hyphen", the simplest and most consistent-sounding explanation that the public and Congress would accept would probably have been preferable to those who simply wanted to get on with the job of a Venus fly-by mission. The stories had contradictions, perhaps, but they were so technical that nobody who could have interfered with Mariner-program progress was likely to care about them or even notice. (After all, even in one later NASA account, the supposed "hyphen" is reported as missing from instructions at one point in the text, and from equations at another).
Ambiguity of error location.
"The New York Times", reporting on the results of a review board, said that the error stemmed from "the omission of a hyphen in some mathematical data"
The same report also said the hyphen was
This sort of inconsistency or ambiguity was seen in many subsequent variations on the story, official and otherwise. "Missing hyphen" versions of the story gained from official support before the month was out. NASA official Richard B. Morrison testified before Congress that the supposed hyphen
(Note that Morrison says the spacecraft "crashed", not that it was intentionally destroyed). In a NASA account submitted to Congress in 1963, the hyphen is described as missing in two different ways:
In the same 1963 report to Congress, Morrison's testimony from the previous year is recounted differently:
JPL's Mariner Venus Final Project Report in 1965 noted that, at 4 minutes and 25 seconds into the flight, there was an "nscheduled yaw-lift maneuver":
In a NASA report published in 1985, Oran Nicks offered another slightly differing account, but with the software-related error still identified as a missing "hyphen":
NASA's website now says the problem was:
Other punctuation.
In other accounts, the bug consisted of:

</doc>
<doc id="38787" url="https://en.wikipedia.org/wiki?curid=38787" title="Mariner 3">
Mariner 3

Mariner 3 (together with Mariner 4 known as Mariner-Mars 1964) was one of two identical deep-space probes designed and built by the Jet Propulsion Laboratory (JPL) for NASA's Mariner-Mars 1964 project that were intended to conduct close-up (flyby) scientific observations of the planet Mars and transmit information on interplanetary space and the space surrounding Mars, televised images of the Martian surface and radio occultation data of spacecraft signals as affected by the Martian atmosphere back to Earth. It was the third of ten spacecraft within the Mariner program.
Mariner 2 had been a modified Ranger lunar probe, however Mariner 3 used a new, larger bus with four solar panels, a TV camera, and additional instrumentation. Because of the greater mass, the new Agena D stage would be used instead of the Agena B. Mariner 3 also utilized a new, larger fiberglass payload fairing. Of the two Atlas-Agena pads at Cape Canaveral, LC-13 became available first following the launch of an Air Force Vela satellite in July 1964. Atlas vehicle 289D was erected on the pad on August 17, with the backup Mariner probe and booster (Atlas 288D) erected on LC-12 on September 28.
Mariner 3 was launched at 2:22 PM EST on November 5, 1964 from Cape Canaveral Air Force Station Launch Complex 13. After an uneventful boost phase, the Agena completed its burn to place the probe on a trajectory towards Mars. One hour after launch, the first telemetry transmissions from Mariner 3 were received, indicating that the scientific instruments were functioning correctly but there was no indication of any solar panel operation. Unsure of the exact problem, ground controllers issued a command to turn off the rate gyros to conserve power while they worked to figure out what had happened. Telemetry data suggested a separation failure of either the Agena or the payload fairing, however a below-normal velocity appeared to indicate that the fairing had not separated properly. A command was sent to manually jettison the payload shroud, but nothing happened. The ground controllers next considered firing Mariner 3's midcourse correction engine to blow off the shroud, however they ran out of time. Eight hours after launch, the batteries in the probe died and the mission was officially terminated. Even if the shroud could be removed, the mission probably would have failed anyway since the low velocity meant that Mariner 3 would miss Mars by several million miles.
Three weeks later, on November 28, 1964, Mariner 4 was launched successfully on a 7½-month voyage to Mars.
Instruments.
The instruments on Mariner 3 included:

</doc>
<doc id="38788" url="https://en.wikipedia.org/wiki?curid=38788" title="Mariner 5">
Mariner 5

Mariner 5 (Mariner Venus 1967) was a spacecraft of the Mariner program that carried a complement of experiments to probe Venus' atmosphere by radio occultation, measure the hydrogen Lyman-alpha (hard ultraviolet) spectrum, and sample the solar particles and magnetic field fluctuations above the planet. Its goals were to measure interplanetary and Venusian magnetic fields, charged particles, plasma, radio refractivity and UV emissions of the Venusian atmosphere.
Mariner 5 was actually built as a backup to Mariner 4, but after the success of the Mariner 4 mission, it was modified for the Venus mission by removing the TV camera, reversing and reducing the four solar panels, and adding extra thermal insulation.
Liftoff took place on June 14, 1967 from Cape Canaveral Air Force Station Launch Complex 12 on Atlas vehicle 5401. Booster performance was normal through the Atlas portion of the launch and the first Agena burn, with all systems operating at the proper level. During the second Agena burn, abnormal fluctuations in the engine chamber pressure occurred, however they did not preclude successful interplanetary injection. There had been several occurrences of this behavior on previous NASA and Air Force launches and a program was initiated to correct it which led to a redesign of the Agena turbopump gearbox. Mariner 5 flew by Venus on October 19 that year at an altitude of . With more sensitive instruments than its predecessor Mariner 2, Mariner 5 was able to shed new light on the hot, cloud-covered planet and on conditions in interplanetary space.
Radio occultation data from Mariner 5 helped to understand the temperature and pressure data returned by the Venera 4 lander, which arrived at Venus shortly before it. After these missions, it was clear that Venus had a very hot surface and an atmosphere even denser than expected.
The operations of Mariner 5 ended in November 1967 and it is now defunct in a heliocentric orbit.
Further communication attempts.
Further communication attempts were tried, in a joint spacecraft solar wind / solar magnetic fields investigation with Mariner 4, back in communication with Earth after being out of telemetry for about a year or more around superior conjunction. During the experiment, both spacecraft were going to be on the same idealized magnetic field spiral carried out from the sun by the solar wind.
Between April and November 1968 NASA tried to reacquire Mariner 5 to continue probing interplanetary conditions.
Attempts to reacquire Mariner 5 during June, July, and early August 1968 yielded no spacecraft signal.
On October 14, the receiver operator at DSS 14 obtained a lock on the Mariner 5 signal. A carrier wave was detected, but outside expected frequency limits and varying in wavelength. Signal strength changes indicated the spacecraft was in a slow roll. Nevertheless, it was possible to lock the spacecraft to an uplink signal, but no response was observed to any commands sent to it. Without telemetry and without any signal change in response to commands, there was no possibility to repair or continue to use the spacecraft. Operations were terminated at the end of the track from DSS 61 at 07:46 GMT on November 5, 1968.

</doc>
<doc id="38790" url="https://en.wikipedia.org/wiki?curid=38790" title="Mariner 8">
Mariner 8

Mariner-H (Mariner Mars '71), also commonly known as Mariner 8, was (along with Mariner 9) part of the Mariner Mars '71 project. It was intended to go into Mars orbit and return images and data, but a launch vehicle failure prevented Mariner 8 from even achieving an Earth orbit and the spacecraft reentered into the Atlantic Ocean shortly after launch.
Mission.
Mariner 8 was launched on an Atlas-Centaur SLV-3C booster (AC-24). The main Centaur engine was ignited 265 seconds after launch, but the upper stage began to oscillate in pitch and tumbled out of control. The Centaur stage shut down 365 seconds after launch due to starvation caused by the tumbling. The Centaur and spacecraft payload separated and re-entered the Earth's atmosphere approximately 1500 km downrange and fell into the Atlantic Ocean about 560 km north of Puerto Rico.
A guidance system failure was quickly suspected as the culprit, but JPL navigation chief Bill O'Neil dismissed the idea that the entire guidance system had failed. He argued that an autopilot malfunction had occurred since the event had occurred at the exact moment when the system was supposed to activate. Investigation proceeded quickly and the problem was soon discovered to be the result of a malfunction in the pitch rate gyro amplifier. A diode intended to protect the system from transient voltages was thought to have been damaged during repairs/installation of the pitch amplifier's printed circuit board, something that would not have been detected through bench tests.
As of 2015, Mariner 8 is the most recent US planetary probe to be lost in a launch vehicle malfunction.
Mariner Mars 71 Project.
The Mariner Mars 71 project consisted of two spacecraft (Mariners H and I), each of which would be inserted into a Martian orbit, and each of which would perform a separate but complementary mission. Either spacecraft could perform either of the two missions. The two spacecraft would have orbited the planet Mars a minimum of 90 days, during which time data would be gathered on the composition, density, pressure, and temperature of the atmosphere, and the composition, temperature, and topography of the surface. Approximately 70 percent of the planetary surface was to be covered, and temporal as well as spatial variations would be observed. Some of the objectives of the Mariner-H mission were successfully added to the Mariner-I (Mariner 9) mission profile.
Total research, development, launch, and support costs for the Mariner series of spacecraft (Mariners 1 through 10) was approximately $554 million.
Spacecraft and subsystems.
The Mariner 8 spacecraft was built on an octagonal magnesium frame, 45.7 cm deep and 138.4 cm across a diagonal. Four solar panels, each 215 x 90 cm, extended out from the top of the frame. Each set of two solar panels spanned 6.89 meters from tip to tip. Also mounted on the top of the frame were two propulsion tanks, the maneuver engine, a 1.44 m long low gain antenna mast and a parabolic high gain antenna. A scan platform was mounted on the bottom of the frame, on which were attached the mutually bore-sighted science instruments (wide- and narrow-angle TV cameras, infrared radiometer, ultraviolet spectrometer, and infrared interferometer spectrometer). The overall height of the spacecraft was 2.28 m. The launch mass was 997.9 kg, of which 439.1 kg were expendables. The science instrumentation had a total mass of 63.1 kg. The electronics for communications and command and control were housed within the frame.
Spacecraft power was provided by a total of 14,742 solar cells which made up the 4 solar panels with a total area of 7.7 square meters area. The solar panels could produce 800 W at Earth and 500 W at Mars. Power was stored in a 20 ampere-hour nickel-cadmium battery. Propulsion was provided by a gimbaled engine capable of 1340 N thrust and up to 5 restarts. The propellant was monomethyl hydrazine and nitrogen tetroxide. Two sets of 6 attitude control nitrogen jets were mounted on the ends of the solar panels. Attitude knowledge was provided by a Sun sensor, a Canopus star tracker, gyroscopes, an inertial reference unit, and an accelerometer. Passive thermal control was achieved through the use of louvres on the eight sides of the frame and thermal blankets.
Spacecraft control was through the central computer and sequencer which had an onboard memory of 512 words. The command system was programmed with 86 direct commands, 4 quantitative commands, and 5 control commands. Data was stored on a digital reel-to-reel tape recorder. The 168 meter 8-track tape could store 180 million bits recorded at 132 kbit/s. Playback could be done at 16, 8, 4, 2, and 1 kbit/s using two tracks at a time. Telecommunications were via dual S-band 10 W/20 W transmitters and a single receiver through the high gain parabolic antenna, the medium gain horn antenna, or the low gain omnidirectional antenna.

</doc>
<doc id="38791" url="https://en.wikipedia.org/wiki?curid=38791" title="Hunting">
Hunting

Hunting is the practice of killing or trapping any animal, or pursuing or tracking it with the intent of doing so. Hunting wildlife or feral animals is most commonly done by humans for food, recreation, to remove predators which are dangerous to humans or domestic animals, or for trade. In the 2010s, lawful hunting is distinguished from poaching, which is the illegal killing, trapping or capture of the hunted species. The species that are hunted are referred to as game or prey and are usually mammals and birds.
Hunting can also be a means of pest control. Hunting advocates state that hunting can be a necessary component of modern wildlife management, for example, to help maintain a population of healthy animals within an environment's ecological carrying capacity when natural checks such as predators are absent or very rare. However, hunting has also heavily contributed to the endangerment, extirpation and extinction of many animals.
The pursuit, capture and release, or capture for food of fish is called fishing, which is not commonly categorised as a form of hunting. It is also not considered hunting to pursue animals without intent to kill them, as in wildlife photography, birdwatching, or scientific research activities which involve tranquilizing and/or tagging of animals or birds. The practice of foraging or gathering materials from plants and mushrooms is also considered separate from hunting.
Skillful tracking and acquisition of an elusive target has caused the word "hunt" to be used in the vernacular as a metaphor, as in treasure hunting, "bargain hunting", and even "hunting down corruption and waste".
History.
Paleolithic.
Hunting has a long history and may well pre-date the rise of the species "Homo sapiens". While our earliest Hominid ancestors were probably frugivores or omnivores, there is evidence that earlier "Homo" species, and possibly also australopithecine species, utilised larger animals for subsistence. Evidence from western Kenya suggests that hunting has been occurring for more than two million years.
Furthermore, evidence exists that hunting may have been one of the multiple environmental factors leading to extinctions of the holocene megafauna and their replacement by smaller herbivores. North American megafauna extinction was coincidental with the Younger Dryas impact event, possibly making hunting a less critical factor in prehistoric species loss than had been previously thought. However, in other locations such as Australia, humans are thought to have played a very significant role in the extinction of the Australian megafauna that was widespread prior to human occupation.
The closest surviving relatives of the human species are the two species of "Pan": the common chimpanzee ("Pan troglodytes") and bonobos ("Pan paniscus"). Common chimpanzees have an omnivorous diet that includes troop hunting behaviour based on beta males being led by an alpha male. Bonobos have also been observed to occasionally engage in group hunting, but eat a mostly frugivorous diet.
While it is undisputed that early humans were hunters, the importance of this for the emergence of the "Homo" genus from the earlier Australopithecines, including the production of stone tools and eventually the control of fire, are emphasised in the hunting hypothesis and de-emphasised in scenarios that stress omnivory and social interaction, including mating behaviour, as essential in the emergence of human behavioural modernity. With the establishment of language, culture, and religion, hunting became a theme of stories and myths, as well as rituals such as dance and animal sacrifice.
Hunting was a crucial component of hunter-gatherer societies before the domestication of livestock and the dawn of agriculture, beginning about 11,000 years ago. By the Mesolithic, hunting strategies had diversified with the development of the bow 18,000 years ago and the domestication of the dog about 15,000 years ago. There is fossil evidence for spear use in Asian hunting dating from approximately 16,200 years ago.
Many species of animals have been hunted throughout history. It has been suggested that in North America and Eurasia, caribou and wild reindeer "may well be the species of single greatest importance in the entire anthropological literature on hunting" (see also Reindeer Age), although the varying importance of different species would depend on the geographic location.
Hunter-gathering lifestyles remained prevalent in some parts of the New World, Sub-Saharan Africa, and Siberia, as well as all of Australia, until the European Age of Discovery. They still persist in some tribal societies, albeit in rapid decline. Peoples that preserved paleolithic hunting-gathering until the recent past include some indigenous peoples of the Amazonas (Aché), some Central and Southern African (San people), some peoples of New Guinea (Fayu), the Mlabri of Thailand and Laos, the Vedda people of Sri Lanka, and a handful of uncontacted peoples. In Africa, the only remaining full-time hunter-gatherers are the Hadza of Tanzania.
Criticism.
Archaeologist Louis Binford criticised the idea that early hominids and early humans were hunters. On the basis of the analysis of the skeletal remains of the consumed animals, he concluded that hominids and early humans were mostly scavengers, not hunters, and this idea is popular among some archaeologists and paleoanthropologists. Robert Blumenschine proposed the idea of "confrontational scavenging", which involves challenging and scaring off other predators "after" they have made a kill, which he suggests could have been the leading method of obtaining protein-rich meat by early humans.
Antiquity.
Even as animal domestication became relatively widespread and after the development of agriculture, hunting was usually a significant contributor to the human food supply. The supplementary meat and materials from hunting included protein, bone for implements, sinew for cordage, fur, feathers, rawhide and leather used in clothing. Man's earliest hunting weapons would have included rocks, spears, the atlatl, and bows and arrows. Hunting is still vital in marginal climates, especially those unsuited for pastoral uses or agriculture. For example, Inuit people in the Arctic trap and hunt animals for clothing and use the skins of sea mammals to make kayaks, clothing, and footwear.
On ancient reliefs, especially from Mesopotamia, kings are often depicted as hunters of big game such as lions and are often portrayed hunting from a war chariot. The cultural and psychological importance of hunting in ancient societies is represented by deities such as the horned god Cernunnos and lunar goddesses of classical antiquity, the Greek Artemis or Roman Diana. Taboos are often related to hunting, and mythological association of prey species with a divinity could be reflected in hunting restrictions such as a reserve surrounding a temple. Euripides' tale of Artemis and Actaeon, for example, may be seen as a caution against disrespect of prey or impudent boasting.
With the domestication of the dog, birds of prey, and the ferret, various forms of animal-aided hunting developed, including venery (scent hound hunting, such as fox hunting), coursing (sight hound hunting), falconry, and ferreting. While these are all associated with medieval hunting, over time, various dog breeds were selected for very precise tasks during the hunt, reflected in such names as pointer and setter.
Pastoral and agricultural societies.
Even as agriculture and animal husbandry became more prevalent, hunting often remained as a part of human culture where the environment and social conditions allowed. Hunter-gatherer societies persisted, even when increasingly confined to marginal areas. And within agricultural systems, hunting served to kill animals that prey upon domestic and wild animals or to attempt to extirpate animals seen by humans as competition for resources such as water or forage.
When hunting moved from a subsistence activity to a social one, two trends emerged:
The meaning of the word "game" in Middle English evolved to include an animal which is hunted. As game became more of a luxury than a necessity, the stylised pursuit of it also became a luxury. Dangerous hunting, such as for lions or wild boars, often done on horseback or from a chariot, had a function similar to tournaments and manly sports. Hunting ranked as an honourable, somewhat competitive pastime to help the aristocracy practice skills of war in times of peace.
In most parts of medieval Europe, the upper class obtained the sole rights to hunt in certain areas of a feudal territory. Game in these areas was used as a source of food and furs, often provided via professional huntsmen, but it was also expected to provide a form of recreation for the aristocracy. The importance of this proprietary view of game can be seen in the Robin Hood legends, in which one of the primary charges against the outlaws is that they "hunt the King's deer". In contrast, settlers in Anglophone colonies gloried democratically in hunting for all.
In Medieval Europe, hunting was considered by Johannes Scotus Eriugena to be part of the set of "seven mechanical arts".
Use of dogs.
Although various animals have been used to aid the hunter, such as ferrets, none has been as important as the dog. The domestication of the dog has led to a symbiotic relationship in which the dog's independence from humans is deferred. Though dogs can survive independently of humans, and in many cases do, as with feral dogs, where hunger is not a primary factor, the species tends to defer to human control in exchange for habitation, food and support.
Dogs today are used to find, chase, retrieve, and sometimes to kill the game. Hunting dogs allow humans to pursue and kill prey that would otherwise be very difficult or dangerous to hunt. Different breeds of dogs are used for different types of hunting. Waterfowl are commonly hunted using retrieving dogs such as the Labrador Retriever, the Golden Retriever, the Chesapeake Bay Retriever, the Brittany Spaniel, and other similar breeds.
The hunting of wild mammals in England and Wales with dogs was banned under the Hunting Act 2004. The wild mammals include fox, hare, deer, and mink. Hunting with dogs is permissible, however, where it has been carried out in accordance with one of the exceptions in the Act.
Religion.
Many prehistoric deities are depicted as predators or prey of humans, often in a zoomorphic form, perhaps alluding to the importance of hunting for most Palaeolithic cultures.
In many pagan religions, specific rituals are conducted before or after a hunt; the rituals done may vary according to the species hunted or the season the hunt is taking place. Often a hunting ground, or the hunt for one or more species, was reserved or prohibited in the context of a temple cult.
Indian and Eastern religions.
Hindu scriptures describe hunting as an acceptable occupation, as well as a sport of the kingly. Even figures considered godly are described to have engaged in hunting. One of the names of the god Shiva is Mrigavyadha, which translates as "the deer hunter" ("mriga" means deer; "vyadha" means hunter). The word "Mriga", in many Indian languages including Malayalam, not only stands for deer, but for all animals and animal instincts (Mriga Thrishna). Shiva, as Mrigavyadha, is the one who destroys the animal instincts in human beings. In the epic Ramayana, Dasharatha, the father of Rama, is said to have the ability to hunt in the dark. During one of his hunting expeditions, he accidentally killed Shravana, mistaking him for game. During Rama's exile in the forest, Ravana kidnapped his wife, Sita, from their hut, while Rama was asked by Sita to capture a golden deer, and his brother Lakshman went after him. According to the Mahabharat, Pandu, the father of the Pandavas, accidentally killed the sage Kindama and his wife with an arrow, mistaking them for a deer. Krishna is said to have died after being accidentally wounded by an arrow of a hunter.
Jainism teaches followers to have tremendous respect for all of life. Prohibitions for hunting and meat eating are the fundamental conditions for being a Jain.
Buddhism's first precept is the respect for all sentient life. The general approach by all Buddhists is to avoid killing any living animals. Buddha explained the issue by saying "all fear death; comparing others with oneself, one should neither kill nor cause to kill."
Christianity, Judaism, and Islam.
From early Christian times, hunting has been forbidden to Roman Catholic Church clerics. Thus the "Corpus Juris Canonici" (C. ii, X, De cleric. venat.) says, "We forbid to all servants of God hunting and expeditions through the woods with hounds; and we also forbid them to keep hawks or falcons." The Fourth Council of the Lateran, held under Pope Innocent III, decreed (canon xv): "We interdict hunting or hawking to all clerics." The decree of the Council of Trent is worded more mildly: "Let clerics abstain from illicit hunting and hawking" (Sess. XXIV, De reform., c. xii), which seems to imply that not all hunting is illicit, and canonists generally make a distinction declaring noisy ("clamorosa") hunting unlawful, but not quiet ("quieta") hunting.
Ferraris (s.v. "Clericus", art. 6) gives it as the general sense of canonists that hunting is allowed to clerics if it be indulged in rarely and for sufficient cause, as necessity, utility or "honest" recreation, and with that moderation which is becoming to the ecclesiastical state. Ziegler, however (De episc., l. IV, c. xix), thinks that the interpretation of the canonists is not in accordance with the letter or spirit of the laws of the church.
Nevertheless, although a distinction between lawful and unlawful hunting is undoubtedly permissible, it is certain that a bishop can absolutely prohibit all hunting to the clerics of his diocese, as was done by synods at Milan, Avignon, Liège, Cologne, and elsewhere. Benedict XIV (De synodo diœces., l. II, c. x) declared that such synodal decrees are not too severe, as an absolute prohibition of hunting is more conformable to the ecclesiastical law. In practice, therefore, the synodal statutes of various localities must be consulted to discover whether they allow quiet hunting or prohibit it altogether.
It is important to note that most Christian, do not observe kosher dietary laws. Hence Protestant clerics, Catholic lay parishioners, and Protestants have no religious restrictions on hunting. This is in accord with what is found in the Acts of the Apostles 15:28–29, and 1 Timothy 4:4.
In Jewish law hunting is not forbidden although there is an aversion to it. The great 18th century authority Rabbi Yechezkel Landau after a study concluded although "hunting would not be considered cruelty to animals insofar as the animal is generally killed quickly and not tortured...There is an unseemly element in it, namely cruelty." The other issue is that hunting can be dangerous and Judaism has an extreme emphasis on the value of human life.
Islamic Sharia Law permits hunting of lawful animals and birds if they cannot be easily caught and slaughtered.
National traditions.
New Zealand.
New Zealand has a strong hunting culture. The islands making up New Zealand originally had no land mammals apart from bats. However, once Europeans arrived, game animals were introduced by acclimatisation societies to provide New Zealanders with sport and a hunting resource. Deer, pigs, goats, rabbits, hare, tahr and chamois all adapted well to the New Zealand terrain, and with no natural predators, their population exploded. Government agencies view the animals as pests due to their effects on the natural environment and on agricultural production, but hunters view them as a resource.
"Shikar" (Indian subcontinent).
During the feudal and colonial times in British India, hunting was regarded as a regal sport in the numerous princely states, as many maharajas and nawabs, as well as British officers, maintained a whole corps of "shikaris" (big-game hunters), who were native professional hunters. They would be headed by a master of the hunt, who might be styled "mir-shikar". Often, they recruited the normally low-ranking local tribes because of their traditional knowledge of the environment and hunting techniques. Big game, such as Bengal tigers, might be hunted from the back of an elephant.
Regional social norms are generally antagonistic to hunting, while a few sects, such as the Bishnoi, lay special emphasis on the conservation of particular species, such as the antelope. India's Wildlife Protection Act of 1972 bans the killing of all wild animals. However, the Chief Wildlife Warden may, if satisfied that any wild animal from a specified list has become dangerous to human life, or is so disabled or diseased as to be beyond recovery, permit any person to hunt such an animal. In this case, the body of any wild animal killed or wounded becomes government property.
Safari.
A safari, from a Swahili word meaning "a long journey", especially in Africa, is defined as an overland journey.
Safari as a distinctive way of hunting was popularised by the US author Ernest Hemingway and President Theodore Roosevelt. A safari may consist of a several-days- or even weeks-long journey, with camping in the bush or jungle, while pursuing big game. Nowadays, it is often used to describe tours through African national parks to watch or hunt wildlife.
Hunters are usually tourists, accompanied by licensed and highly regulated professional hunters, local guides, skinners, and porters in more difficult terrains. A special safari type is the solo-safari, where all the license acquiring, stalking, preparation, and outfitting is done by the hunter himself.
United Kingdom.
Unarmed fox hunting on horseback with hounds is the type of hunting most closely associated with the United Kingdom; in fact, "hunting" without qualification implies fox hunting. What in other countries is called "hunting" is called "shooting" (birds) or "stalking" (deer) in Britain. Originally a form of vermin control to protect livestock, fox hunting became a popular social activity for newly wealthy upper classes in Victorian times and a traditional rural activity for riders and foot followers alike. Similar to fox hunting in many ways is the chasing of hares with hounds. Pairs of Sight hounds (or long-dogs), such as greyhounds, may be used to pursue a hare in coursing, where the greyhounds are marked as to their skill in coursing the hare (but are not intended to actually catch it), or the hare may be pursued with scent hounds such as beagles or harriers. Other sorts of foxhounds may also be used for hunting stags (deer) or mink. Deer stalking with rifles is carried out on foot without hounds, using stealth.
These forms of hunting have been controversial in the UK. Animal welfare supporters believe that hunting causes unnecessary suffering to foxes, horses, and hounds. Proponents argue that it is culturally and perhaps economically important. Using dogs to chase wild mammals was made illegal in February 2005 by the Hunting Act 2004; there were a number of exemptions (under which the activity may not be illegal) in the act for hunting with hounds, but no exemptions at all for hare-coursing.
Game birds, especially pheasants, are shot with shotguns for sport in the UK; the British Association for Shooting and Conservation says that over a million people per year participate in shooting, including game shooting, clay pigeon shooting, and target shooting.
Shooting as practised in Britain, as opposed to traditional hunting, requires little questing for game—around thirty-five million birds are released onto shooting estates every year, some having been factory farmed. Shoots can be elaborate affairs with guns placed in assigned positions and assistants to help load shotguns. When in position, "beaters" move through the areas of cover, swinging sticks or flags to drive the game out. Such events are often called "drives". The open season for grouse in the UK begins on 12 August, the so-called Glorious Twelfth. The definition of game in the United Kingdom is governed by the Game Act 1831.
United States.
North American hunting pre-dates the United States by thousands of years and was an important part of many pre-Columbian Native American cultures. Native Americans retain some hunting rights and are exempt from some laws as part of Indian treaties and otherwise under federal law—examples include eagle feather laws and exemptions in the Marine Mammal Protection Act. This is considered particularly important in Alaskan native communities.
Hunting is primarily regulated by state law; additional regulations are imposed through United States environmental law in the case of migratory birds and endangered species. Regulations vary widely from state to state and govern the areas, time periods, techniques and methods by which specific game animals may be hunted. Some states make a distinction between protected species and unprotected species (often vermin or varmints for which there are no hunting regulations). Hunters of protected species require a hunting license in all states, for which completion of a hunting safety course is sometimes a prerequisite.
Typically, game animals are divided into several categories for regulatory purposes. Typical categories, along with example species, are as follows:
Hunting big game typically requires a "tag" for each animal harvested. Tags must be purchased in addition to the hunting license, and the number of tags issued to an individual is typically limited. In cases where there are more prospective hunters than the quota for that species, tags are usually assigned by lottery. Tags may be further restricted to a specific area, or wildlife management unit. Hunting migratory waterfowl requires a duck stamp from the Fish and Wildlife Service in addition to the appropriate state hunting license.
Harvest of animals other than big game is typically restricted by a bag limit and a possession limit. A bag limit is the maximum number of a specific animal species that an individual can harvest in a single day. A possession limit is the maximum number of a specific animal species that can be in an individual's possession at any time.
Shooting.
Gun usage in hunting is typically regulated by game category, area within the state, and time period. Regulations for big-game hunting often specify a minimum caliber or muzzle energy for firearms. The use of rifles is often banned for safety reasons in areas with high population densities or limited topographic relief. Regulations may also limit or ban the use of lead in ammunition because of environmental concerns. Specific seasons for bow hunting or muzzle-loading black-powder guns are often established to limit competition with hunters using more effective weapons.
Hunting in the United States is not associated with any particular class or culture; a 2006 poll showed seventy-eight percent of Americans supported legal hunting, although relatively few Americans actually hunt. At the beginning of the 21st century, just six percent of Americans hunted. Southerners in states along the eastern seaboard hunted at a rate of five percent, slightly below the national average, and while hunting was more common in other parts of the South at nine percent, these rates did not surpass those of the Plains states, where twelve percent of Midwesterners hunted. Hunting in other areas of the country fell below the national average. Overall, in the 1996–2006 period, the number of hunters over the age of sixteen declined by ten percent, a drop attributable to a number of factors including habitat loss and changes in recreation habits.
Regulation.
Regulation of hunting within the United States dates from the 19th century. Some modern hunters see themselves as conservationists and sportsmen in the mode of Theodore Roosevelt and the Boone and Crockett Club. Local hunting clubs and national organizations provide hunter education and help protect the future of the sport by buying land for future hunting use. Some groups represent a specific hunting interest, such as Ducks Unlimited, Pheasants Forever, or the Delta Waterfowl Foundation. Many hunting groups also participate in lobbying the federal government and state government.
Each year, nearly $200 million in hunters' federal excise taxes are distributed to state agencies to support wildlife management programs, the purchase of lands open to hunters, and hunter education and safety classes. Since 1934, the sale of Federal Duck Stamps, a required purchase for migratory waterfowl hunters over sixteen years old, has raised over $700 million to help purchase more than of habitat for the National Wildlife Refuge System lands that support waterfowl and many other wildlife species and are often open to hunting. States also collect money from hunting licenses to assist with management of game animals, as designated by law. A key task of federal and state park rangers and game wardens is to enforce laws and regulations related to hunting, including species protection, hunting seasons, and hunting bans.
Varmint hunting.
Varmint hunting is an American phrase for the selective killing of non-game animals seen as pests. While not always an efficient form of pest control, varmint hunting achieves selective control of pests while providing recreation and is much less regulated. Varmint species are often responsible for detrimental effects on crops, livestock, landscaping, infrastructure, and pets. Some animals, such as wild rabbits or squirrels, may be utilised for fur or meat, but often no use is made of the carcass. Which species are varmints depends on the circumstance and area. Common varmints may include various rodents, coyotes, crows, foxes, feral cats, and feral hogs. Some animals once considered varmints are now protected, such as wolves. In the US state of Louisiana, a non-native rodent known as a nutria has become so destructive to the local ecosystem that the state has initiated a bounty program to help control the population.
Fair chase.
The principles of the fair chase have been a part of the American hunting tradition for over one hundred years. The role of the hunter-conservationist, popularised by Theodore Roosevelt, and perpetuated by Roosevelt's formation of the Boone and Crockett Club, has been central to the development of the modern fair chase tradition.
"Beyond Fair Chase: The Ethic and Tradition of Hunting", a book by Jim Posewitz, describes fair chase:
"Fundamental to ethical hunting is the idea of fair chase. This concept addresses the balance between the hunter and the hunted. It is a balance that allows hunters to occasionally succeed while animals generally avoid being taken."
When Internet hunting was introduced in 2005, allowing people to hunt over the Internet using remotely controlled guns, the practice was widely criticised by hunters as violating the principles of fair chase. As a representative of the National Rifle Association (NRA) explained, "The NRA has always maintained that fair chase, being in the field with your firearm or bow, is an important element of hunting tradition. Sitting at your desk in front of your computer, clicking at a mouse, has nothing to do with hunting."
One hunting club declares that a fair chase shall not involve the taking of animals under the following conditions:
Ranches.
Indian blackbuck, nilgai, axis deer, fallow deer, and barasingha can now be found on hunting ranches in Texas, where they were introduced for sport hunting. Hunters can pay upwards of $4000 as fees for hunting a barasingha.
Russia.
The Russian imperial hunts evolved from hunting traditions of early Russian rulers—Grand Princes and Tsars—under the influence of hunting customs of European royal courts. The imperial hunts were organised mainly in Peterhof, Tsarskoye Selo, and Gatchina.
Australia.
Hunting in Australia has evolved around the hunting and eradication of various animals considered to be pests. All native animals are protected by law, and can only be killed under special permit. Hunted introduced species include deer, pigs, goats, foxes, and rabbits.
Japan.
The numbers of licensed hunters in Japan, including those using snares and guns, is generally decreasing, while their average age is increasing. As of 2010, there were approximately 190,000 registered hunters, approximately 65% of whom were sixty years old or older.
Trinidad and Tobago.
There is a very active tradition of hunting of small to medium-sized wild game in Trinidad and Tobago. Hunting is carried out with firearms, and aided by the use of hounds, with the illegal use of trap guns, trap cages and snare nets. With approximately 12,000 sport hunters applying for hunting licences in recent years (in a very small country of about the size of the state of Delaware at about 5128 square kilometers and 1.3 million inhabitants), there is some concern that the practice might not be sustainable. In addition there are at present no bag limits and the open season is comparatively very long (5 months - October to February inclusive). As such hunting pressure from legal hunters is very high. Added to that, there is a thriving and very lucrative black market for poached wild game (sold and enthusiastically purchased as expensive luxury delicacies) and the numbers of commercial poachers in operation is unknown but presumed to be fairly high. As a result, the populations of the five major mammalian game species (red-rumped agouti, lowland paca, nine-banded armadillo, collared peccary, and red brocket deer) are thought to be quite low (although scientifically conducted population studies are only just recently being conducted as of 2013). It appears that the red brocket deer population has been extirpated on Tobago as a result of over-hunting. Various herons, ducks, doves, the green iguana, the gold tegu, the spectacled caiman and the common opossum are also commonly hunted and poached. There is also some poaching of 'fully protected species', including red howler monkeys and capuchin monkeys, southern tamanduas, Brazilian porcupines, yellow-footed tortoises, Trinidad piping guans and even one of the national birds, the scarlet ibis. Legal hunters pay very small fees to obtain hunting licences and undergo no official basic conservation biology or hunting-ethics training. There is presumed to be relatively very little subsistence hunting in the country (with most hunting for either sport or commercial profit). The local wildlife management authority is under-staffed and under-funded, and as such very little in the way of enforcement is done to uphold existing wildlife management laws, with hunting occurring both in and out of season, and even in wildlife sanctuaries. There is some indication that the government is beginning to take the issue of wildlife management more seriously, with well drafted legislation being brought before Parliament in 2015. It remains to be seen if the drafted legislation will be fully adopted and financially supported by the current and future governments, and if the general populace will move towards a greater awareness of the importance of wildlife conservation and change the culture of wanton consumption to one of sustainable management.
Wildlife management.
Hunting is claimed to give resource managers an important tool in managing populations that might exceed the carrying capacity of their habitat and threaten the well-being of other species, or, in some instances, damage human health or safety. However, in most circumstances carrying capacity is determined by a combination habitat and food availability, and hunting for 'population control' has no effect on the annual population of species. In some cases, it can increase the population of predators such as coyotes by removing territorial bounds that would otherwise be established, resulting in excess neighbouring migrations into an area, thus artificially increasing the population. Hunting advocates assert that hunting reduces intraspecific competition for food and shelter, reducing mortality among the remaining animals. Some environmentalists assert that (re)introducing predators would achieve the same end with greater efficiency and less negative effect, such as introducing significant amounts of free lead into the environment and food chain.
In the United States, wildlife managers are frequently part of hunting regulatory and licensing bodies, where they help to set rules on the number, manner and conditions in which game may be hunted.
Management agencies sometimes rely on hunting to control specific animal populations, as has been the case with deer in North America. These hunts may sometimes be carried out by professional shooters, although others may include amateur hunters. Many US city and local governments hire professional and amateur hunters each year to reduce populations of animals such as deer that are becoming hazardous in a restricted area, such as neighbourhood parks and metropolitan open spaces.
A large part of managing populations involves managing the number and, sometimes, the size or age of animals harvested so as to ensure the sustainability of the population. Tools that are frequently used to control harvest are bag limits and season closures, although gear restrictions such as archery-only seasons are becoming increasingly popular in an effort to reduce hunter success rates.
Bag limits.
Bag limits are provisions under the law that control how many animals of a given species or group of species can be killed, although there are often species for which bag limits do not apply. There are also jurisdictions where bag limits are not applied at all or are not applied under certain circumstances. The phrase "bag limits" comes from the custom among hunters of small game to carry successful kills in a small basket, similar to a fishing creel.
Where bag limits are used, there can be daily or seasonal bag limits; for example, ducks can often be harvested at a rate of six per hunter per day. Big game, like moose, most often have a seasonal bag limit of one animal per hunter. Bag limits may also regulate the size, sex, or age of animal that a hunter can kill. In many cases, bag limits are designed to allocate harvest among the hunting population more equitably rather than to protect animal populations.
Closed and open season.
A closed season is a time during which hunting an animal of a given species is contrary to law. Typically, closed seasons are designed to protect a species when they are most vulnerable or to protect them during their breeding season. By extension, the period that is not the closed season is known as the open season.
Laws.
Illegal hunting and harvesting of wild species contrary to local and international conservation and wildlife management laws is called poaching. Game preservation is one of the tactics used to prevent poaching. Violations of hunting laws and regulations involving poaching are normally punishable by law. Punishment can include confiscation of equipment, fines and/or a prison sentence. In Costa Rica, all forms of sport hunting have been illegal since December 10, 2012.
Methods.
Historical, subsistence, and sport hunting techniques can differ radically, with modern hunting regulations often addressing issues of where, when, and how hunts are conducted. Techniques may vary depending on government regulations, a hunter's personal ethics, local custom, hunting equipment, and the animal being hunted. Often a hunter will use a combination of more than one technique. Laws may forbid sport hunters from using some methods used primarily in poaching and wildlife management.
Trophy hunting.
Trophy hunting is the selective seeking of wild game. It may also include the controversial hunting of captive or semi-captive animals expressly bred and raised under controlled or semi-controlled conditions so as to attain trophy characteristics; this is sometimes known as canned hunts.
History.
In the 19th century, southern and central European sport hunters often pursued game only for a trophy, usually the head or pelt of an animal, which was then displayed as a sign of prowess. The rest of the animal was typically discarded. Some cultures, however, disapprove of such waste. In Nordic countries, hunting for trophies was—and still is—frowned upon. Hunting in North America in the 19th century was done primarily as a way to supplement food supplies, although it is now undertaken mainly for sport. The safari method of hunting was a development of sport hunting that saw elaborate travel in Africa, India and other places in pursuit of trophies. In modern times, trophy hunting persists and is a significant industry in some areas.
Conservation tool.
According to the U.S. Fish and Wildlife Service, hunting "provides an economic incentive" for ranchers to continue to breed those species, and that hunting "reduces the threat of the species' extinction."
A scientific study in the journal, "Biological Conservation", states that trophy hunting is of "major importance to conservation in Africa by creating economic incentives for conservation over vast areas, including areas which may be unsuitable for alternative wildlife-based land uses such as photographic ecotourism." However, another study states that less than 3% of a trophy hunters' expenditures reach the local level, meaning that the economic incentive and benefit is "minimal, particularly when we consider the vast areas of land that hunting concessions occupy."
Financial incentives from trophy hunting effectively more than double the land area that is used for wildlife conservation, relative to what would be conserved relying on national parks alone according to "Biological Conservation", although local communities usually derive no more than 18 cents per hectare from trophy hunting.
Trophy hunting has been considered essential for providing economic incentives to conserve large carnivores according to research studies in "Conservation Biology", "Journal of Sustainable Tourism", "Wildlife Conservation by Sustainable Use", and "Animal Conservation". Studies by the Centre for Responsible Tourism and the IUCN state that ecotourism, which includes more than hunting, is a superior economic incentive, generating twice the revenue per acre and 39 times more permanent employment.
Controversy.
Trophy hunting is most often criticised when it involves rare or endangered animals. Opponents may also see trophy hunting as an issue of morality or animal cruelty, criticising the killing of living creatures for recreation. Victorian era dramatist W. S. Gilbert remarked, "Deer-stalking would be a very fine sport if only the deer had guns."
There is also debate about the extent to which trophy hunting benefits the local economy. Hunters argue that fees paid contribute to the local economy and provide value to animals that would otherwise be seen as competition for grazing, livestock, and crops. This analysis is disputed by opponents of trophy hunting. Some argue that the animals are worth more to the community for ecotourism than hunting.
Economics.
A variety of industries benefit from hunting and support hunting on economic grounds. In Tanzania, it is estimated that a safari hunter spends fifty to one hundred times that of the average ecotourist. While the average photo tourist may seek luxury accommodation, the average safari hunter generally stays in tented camps. Safari hunters are also more likely to use remote areas, uninviting to the typical ecotourist. Advocates argue that these hunters allow for anti-poaching activities and revenue for local communities.
In the United Kingdom, the game hunting of birds as an industry is said to be extremely important to the rural economy. The Cobham Report of 1997 suggested it to be worth around £700 million, and hunting and shooting lobby groups claimed it to be worth over a billion pounds less than ten years later.
Hunting also has a significant financial impact in the United States, with many companies specialising in hunting equipment or speciality tourism. Many different technologies have been created to assist hunters, even including iPhone applications. Today's hunters come from a broad range of economic, social, and cultural backgrounds. In 2001, over thirteen million hunters averaged eighteen days hunting, and spent over $20.5 billion on their sport. In the US, proceeds from hunting licenses contribute to state game management programs, including preservation of wildlife habitat.
Environmental problems.
Lead bullets that miss their target or remain in an unretrieved carcass become a persistent toxicant in the environment. Waterfowl or other birds may ingest the lead and poison themselves with the neurotoxicant. Since 1991, US federal law forbids lead shot in waterfowl hunts, and 30 states have some type of restriction.
In December 2014, a federal appeals court denied a lawsuit by environmental groups that the EPA must use the Toxic Substances Control Act to regulate lead in shells and cartridges. The groups sought EPA to regulate "spent lead", yet the court found EPA could not regulate spent lead without also regulating cartridges and shells.
Conservation.
Hunters have been driving forces throughout history in the movement to ensure long-term sustainability of natural resources and wildlife habitats. "The birth of the international conservation movement as we recognize it today was due to the influence of powerful aristocratic hunters who wished to preserve suitable specimens for their sport from the alleged depredations of Africans (Mackenzie, 1988). The international hunting fraternity remains a powerful force behind conservation today."</ref>
However, excessive hunting and poachers have also contributed heavily to the endangerment, extirpation and extinction of many animals, such as the quagga, the great auk, Steller's sea cow, the thylacine, the bluebuck, the Arabian oryx, the Caspian and Javan tigers, the markhor, the Sumatran rhinoceros, the bison, the North American cougar, the Altai argali sheep, the Asian elephant and many more, primarily for commercial sale or sport. All these animals have been hunted to endangerment or extinction.
Legislation.
Pittman–Robertson Wildlife Restoration Act of 1937.
In 1937, American hunters successfully lobbied the US Congress to pass the Pittman-Robertson Wildlife Restoration Act, which placed an eleven percent tax on all hunting equipment. This self-imposed tax now generates over $700 million each year and is used exclusively to establish, restore and protect wildlife habitats. The act is named for Nevada Senator Key Pittman and Virginia Congressman Absalom Willis Robertson.
Federal Duck Stamp program.
On 16 March 1934, President Franklin D. Roosevelt signed the Migratory Bird Hunting Stamp Act, which requires an annual stamp purchase by all hunters over the age of sixteen. The stamps are created on behalf of the program by the US Postal Service and depict wildlife artwork chosen through an annual contest. They play an important role in habitat conservation because ninety-eight percent of all funds generated by their sale go directly toward the purchase or lease of wetland habitat for protection in the National Wildlife Refuge System. In addition to waterfowl, it is estimated that one third of the nation's endangered species seek food and shelter in areas protected using Duck Stamp funds.
Since 1934, the sale of Federal Duck Stamps has generated $670 million, and helped to purchase or lease of habitat. The stamps serve as a license to hunt migratory birds, an entrance pass for all National Wildlife Refuge areas, and are also considered collectors items often purchased for aesthetic reasons outside of the hunting and birding communities. Although non-hunters buy a significant number of Duck Stamps, eighty-seven percent of their sales are contributed by hunters, which is logical, as hunters are required to purchase them. Distribution of funds is managed by the Migratory Bird Conservation Commission (MBCC).
Species.
Arabian oryx.
The Arabian oryx, a species of large antelope, once inhabited much of the desert areas of the Middle East. However, the species' striking appearance made it (along with the closely related scimitar-horned oryx and addax) a popular quarry for sport hunters, especially foreign executives of oil companies working in the region. The use of automobiles and high-powered rifles destroyed their only advantage: speed, and they became extinct in the wild exclusively due to sport hunting in 1972. The scimitar-horned oryx followed suit, while the addax became critically endangered. However, the Arabian oryx has now made a comeback and been upgraded from “extinct in the wild” to “vulnerable” due to conservation efforts like captive breeding
Markhor.
The markhor is an endangered species of wild goat which inhabits the mountains of Central Asia and Pakistan. The colonization of these regions by Britain gave British sport hunters access to the species, and they were hunted heavily, almost to the point of extinction. Only their willingness to breed in captivity and the inhospitability of their mountainous habitat prevented this. Despite these factors, the markhor is still endangered.
American bison.
The American bison is a large bovid which inhabited much of western North America prior to the 1800s, living on the prairies in large herds. However, the vast herds of bison attracted market hunters, who killed dozens of bison for their hides only, leaving the rest to rot. Thousands of these hunters quickly eliminated the bison herds, bringing the population from several million in the early 1800s to a few hundred by the 1880s. Conservation efforts have allowed the population to increase, but the bison remains near-threatened.
White rhino.
The "Journal of International Wildlife Law and Policy" cites that the legalization of white rhinoceros hunting in South Africa motivated private landowners to reintroduce the species onto their lands. As a result, the country saw an increase in white rhinos from fewer than one hundred individuals to more than 11,000, even while a limited number were killed as trophies.
However, the illegal hunting of rhinoceros for their horns is highly damaging to the population and is currently growing globally, with 1004 being killed in South Africa alone according to the most recent estimate.
Other species.
According to Richard Conniff, Namibia is home to 1,750 of the roughly 5,000 black rhinos surviving in the wild because it allows trophy hunting of various species. Namibia's mountain zebra population has increased to 27,000 from 1,000 in 1982. Elephants, which "are gunned down elsewhere for their ivory", have gone to 20,000 from 15,000 in 1995. Lions, which were on the brink of extinction "from Senegal to Kenya", are increasing in Namibia.
In contrast, Botswana has recently been forced to ban trophy hunting following a precipitous wildlife decline. The numbers of antelope plummeted across Botswana, with a resultant decline in predator numbers, while elephant numbers remained stable and hippopotamus numbers rose. According to the government of Botswana, trophy hunting is at least partly to blame for this, but many other factors, such as poaching, drought and habitat loss are also to blame. Uganda recently did the same, arguing that "the share of benefits of sport hunting were lopsided and unlikely to deter poaching or improve [Uganda's] capacity to manage the wildlife reserves."
Studies.
A study issued by the Wildlife Society concluded that hunting and trapping are cost effective tools that reduce wildlife damage by reducing a population below the capacity of the environment to carry it and changing the behaviors of animals to stop them from causing damage. The study furthermore states that the cessation of hunting could cause wildlife to be severely harmed, rural property values to fall, and the incentive of landowners to maintain natural habitats to diminish.

</doc>
<doc id="38796" url="https://en.wikipedia.org/wiki?curid=38796" title="Sausthorpe">
Sausthorpe

Sausthorpe is a small village and civil parish in the East Lindsey district of Lincolnshire, England. It is situated east from Horncastle and north-west from Spilsby. Sausthorpe is within the Lincolnshire Wolds valley of the River Lymn, and on the southern edge of the Lincolnshire Wolds Area of Outstanding Natural Beauty.
The name is believed to derive from "Sauthr's thorpe", a farming settlement here in Viking times. Farming remains the predominant economic activity of the area.
The parish church is dedicated to St Andrew and is a Grade II listed building. It was designed by Charles Kirk and built in 1842 on the site of an earlier medieval church. Its construction was sponsored by Rev. Francis A. Swan, Lord of the Manor and parish rector from 1819 until his death in 1878. The spire is a prominent local landmark, and resembles on a smaller scale the spire of St. James Church, Louth, to the north. T. Pelham Dale SSC, who was prosecuted and imprisoned for ritualist practices in 1876 and 1880, and thus regarded as a martyr by Anglo-Catholics, was the parish priest from 1881-1892; his grave can be seen under the trees on the eastern side of the churchyard. Inside the church, several Dymoke family gravestones dating from the 18th century can be seen; these were left in place from the earlier church.
In 1885 "Kelly's Directory" recorded the Rev. Charles Trollope Swan LLB as living at Sausthorpe Hall, a "modern mansion in a park of 30 acres". (He had inherited the roles of Lord of the Manor and rector from his father Francis Swan in 1878.) 
Charles Trollope Swan gave the rectorate, including the rectory living, residence (the Old Hall, see below) and of glebe land, to T. Pelham Dale in 1882. 
Rev. Francis A. Swan built a National School for 50 children, in 1860. (The school finally closed in 1983.)
"Kelly's Directory" also recorded that in 1885 the area of the parish was , in which were grown wheat, barley and turnips, that Sausthorpe's population at the time of the 1881 census was 141, and that within the parish were a grocer, wheelwright, carrier, two farmers, a farmer-cum-beer retailer, and a farmer-surveyor.
Sausthorpe Hall is a late 18th-century Grade II listed country house, extended and remodelled in 1822. 
The Old Hall is a Grade II* listed 15th-century house, with 16th- and 18th-century alterations. It consists of render over red brick and the remains of a timber frame.

</doc>
<doc id="38797" url="https://en.wikipedia.org/wiki?curid=38797" title="Arthur Andersen">
Arthur Andersen

Arthur Andersen LLP, based in Chicago, is an American holding company and formerly one of the "Big Five" accounting firms among PricewaterhouseCoopers, Deloitte Touche Tohmatsu, Ernst & Young and KPMG, providing auditing, tax, and consulting services to large corporations. In 2002, the firm voluntarily surrendered its licenses to practice as Certified Public Accountants in the United States after being found guilty of criminal charges relating to the firm's handling of the auditing of Enron, an energy corporation based in Texas, which had filed for bankruptcy in 2001.
One of the few revenue-generating assets that the Andersen firm still has is Q Center, a conference and training facility outside of Chicago.
The former consultancy and outsourcing arm of the firm, now known as Accenture, which had separated from the accountancy side in 1987 and renamed themselves after splitting from Andersen Worldwide in 2000, continues to operate and has become one of the largest multinational corporations in the world.
History.
Founding.
The firm of Arthur Andersen was founded in 1913 by Arthur Andersen and Clarence DeLany as Andersen, DeLany & Co. The firm changed its name to Arthur Andersen & Co. in 1918. Arthur Andersen's first client was the Joseph Schlitz Brewing Company of Milwaukee. In 1915, due to his many contacts there, the Milwaukee office was opened as the firm's second office. In 1908, after attending courses at night while working full-time, he graduated from the Kellogg School at Northwestern University with a bachelor's degree in business.
Andersen had an unwavering faith in education as the basis upon which the new profession of accounting should be developed. He created the profession's first centralized training program and believed in training during normal working hours. He was generous in his commitment to aiding educational, civic and charitable organizations. In 1927, he was elected to the Board of Trustees of Northwestern University and served as its president from 1930 to 1932. He was also chairman of the board of certified public accountant examiners of Illinois.
Reputation.
Andersen, who headed the firm until his death in 1947, was a zealous supporter of high standards in the accounting industry. A stickler for honesty, he argued that accountants' responsibility was to investors, not their clients' management. During the early years, it is reputed that Andersen was approached by an executive from a local rail utility to sign off on accounts containing flawed accounting, or else face the loss of a major client. Andersen refused in no uncertain terms, replying that there was "not enough money in the city of Chicago" to make him do it. For many years, Andersen's motto was "Think straight, talk straight."
Arthur Andersen also led the way in a number of areas of accounting standards. Being among the first to identify a possible sub-prime bust, Arthur Andersen dissociated itself from a number of clients in the 1970s. Later, with the emergence of stock options as a form of compensation, Arthur Andersen was the first of the major accountancy firms to propose to the FASB that stock options should be included on expense reports, thus impacting on net profit just as cash compensation would.
By the 1980s, standards throughout the industry fell as accountancy firms struggled to balance their commitment to audit independence against the desire to grow their burgeoning consultancy practices. Having established a reputation for IT consultancy in the 1980s, Arthur Andersen was no exception. The firm rapidly expanded its consultancy practice to the point where the bulk of its revenues were derived from such engagements, while audit partners were continually encouraged to seek out opportunities for consulting fees from existing audit clients. By the late-1990s, Arthur Andersen had succeeded in tripling the per-share revenues of its partners.
Predictably, Arthur Andersen struggled to balance the need to maintain its faithfulness to accounting standards with its clients' desire to maximize profits, particularly in the era of quarterly earnings reports. Arthur Andersen has been alleged to have been involved in the fraudulent accounting and auditing of Sunbeam Products, Waste Management, Inc, Asia Pulp & Paper, and the Baptist Foundation of Arizona, WorldCom, as well as the infamous Enron case, among others.
Two of the last three Comptrollers General of the US General Accounting Office (now the Government Accountability Office) were top executives of Arthur Andersen.
Andersen Consulting and Accenture.
The consulting wing of the firm became increasingly important during the 1970s and 1980s, growing at a much faster rate than the more established accounting, auditing, and tax practice. This disproportionate growth, and the consulting division partners' belief that they were not garnering their fair share of firm profits, created increasing friction between the two divisions.
In 1989, Arthur Andersen and Andersen Consulting became separate units of Andersen Worldwide Société Coopérative. Arthur Andersen increased its use of accounting services as a springboard to sign up clients for Andersen Consulting's more lucrative business.
The two businesses spent most of the 1990s in a bitter dispute. Andersen Consulting saw a huge surge in profits during the decade. The consultants, however, continued to resent transfer payments they were required to make to Arthur Andersen. In August 2000, at the conclusion of International Chamber of Commerce arbitration of the dispute, the arbitrators granted Andersen Consulting its independence from Arthur Andersen, but awarded US$1.2 billion in past payments (held in escrow pending the ruling) to Arthur Andersen, and declared that Andersen Consulting could no longer use the Andersen name. As a result, Andersen Consulting changed its name to Accenture on New Year's Day 2001 and Arthur Andersen meanwhile now having the right to the Andersen Consulting name rebranded itself as "Andersen".
Perhaps most telling about who won the decision was that four hours after the arbitrator made his ruling, Arthur Andersen CEO Jim Wadia suddenly resigned. Industry analysts and business school professors alike viewed the event as a complete victory for Andersen Consulting. Jim Wadia would provide insight on his resignation years later at a Harvard Business school case activity about the split. It turned out that the Arthur Andersen board passed a resolution saying he had to resign if he didn't get at least an incremental US$4 billion (either through negotiation or via the arbitrator decision) for the consulting practice to split off, hence his quick resignation once the decision was announced.
Accounts vary on why the split occurred — executives on both sides of the split cite greed and arrogance on the part of the other side. The executives on the Andersen Consulting side maintained breach of contract when Arthur Andersen created a second consulting group, AABC (Arthur Andersen Business Consulting) which competed directly with Andersen Consulting in the marketplace. AABC grew quickly, most notably its healthcare and technology practices. Many of the AABC firms were bought out by other consulting companies in 2002, most notably, Deloitte (especially in Europe), Hitachi Consulting, PwC Consulting, which was later acquired by IBM, and KPMG Consulting, which later changed its name to BearingPoint.
Enron scandal.
Following the 2001 scandal in which $100bn in revenue from energy giant Enron was found to have sustained itself by means of institutional and systematic accounting fraud, Andersen's performance and alleged complicity as an auditor came under intense scrutiny. The Powers Committee (appointed by Enron's board to look into the firm's accounting in October 2001) came to the following assessment: "The evidence available to us suggests that Andersen did not fulfill its professional responsibilities in connection with its audits of Enron's financial statements, or its obligation to bring to the attention of Enron's Board (or the Audit and Compliance Committee) concerns about Enron's internal contracts over the related-party transactions".
On June 15, 2002, Andersen was convicted of obstruction of justice for shredding documents related to its audit of Enron, resulting in the Enron scandal. Although the conviction was later reversed by the Supreme Court, the impact of the scandal combined with the findings of criminal complicity ultimately destroyed the firm. Nancy Temple (Andersen Legal Dept.) and David Duncan (Lead Partner for the Enron account) were cited as the responsible managers in this scandal as they had given the order to shred relevant documents.
Since the U.S. Securities and Exchange Commission cannot accept audits from convicted felons, the firm agreed to surrender its CPA licenses and its right to practice before the SEC on August 31, 2002—effectively putting the firm out of business. It had already started winding down its American operations after the indictment, and many of its accountants joined other firms. The firm sold most of its American operations to KPMG, Deloitte & Touche, Ernst & Young and Grant Thornton LLP. The damage to Andersen's reputation also destroyed the viability of the firm's international practices. Most of them were taken over by the local firms of the other major international accounting firms.
The Andersen indictment also put a spotlight on its faulty audits of other companies, most notably Waste Management, Sunbeam, the Baptist Foundation of Arizona and WorldCom. The subsequent bankruptcy of WorldCom, which quickly surpassed Enron as the then biggest bankruptcy in history (and has since been passed by the bankruptcies of Lehman Brothers and WaMu in the 2008 financial crisis) led to a domino effect of accounting and like corporate scandals that continue to tarnish American business practices.
On May 31, 2005, in the case "Arthur Andersen LLP v. United States", the Supreme Court of the United States unanimously reversed Andersen's conviction due to what it saw as serious flaws in the jury instructions. In the court's view, the instructions were far too vague to allow a jury to find obstruction of justice had really occurred. The court found that the instructions were worded in such a way that Andersen could have been convicted without any proof that the firm knew it had broken the law or that there had been a link to any official proceeding that prohibited the destruction of documents. The opinion, written by Chief Justice William Rehnquist, was also highly skeptical of the government's concept of "corrupt persuasion"—persuading someone to engage in an act with an improper purpose even without knowing an act is unlawful.
Demise.
Since the ruling vacated Andersen's felony conviction, it theoretically left Andersen free to resume operations. The damage to the Andersen name was so severe, however, that it has not returned as a viable business even on a limited scale. There are over 100 civil suits pending against the firm related to its audits of Enron and other companies. Even before voluntarily surrendering its right to practise before the SEC, it had many of its state licences revoked. A new verb, "Enron-ed" was coined by John M. Cunningham, the former Arthur Andersen Director in the Seattle Office, to describe the demise of Arthur Andersen.
From a high of 28,000 employees in the US and 85,000 worldwide, the firm is now down to around 200, based primarily in Chicago. Most of their attention is on handling the lawsuits and presiding over the orderly dissolution of the company.
, Arthur Andersen LLP has not been formally dissolved nor has it declared bankruptcy. Ownership of the partnership has been ceded to four limited liability corporations named Omega Management I through IV. , Arthur Andersen LLP still operates the Q Center conference center in St. Charles, Illinois. The Q center is currently used for training, primarily for internal Accenture personnel, and other large scale companies.
Migration of partners and local offices to new firms.
Many partners formed new companies or were acquired by other consulting firms. Examples include:

</doc>
<doc id="38798" url="https://en.wikipedia.org/wiki?curid=38798" title="Big Four accounting firms">
Big Four accounting firms

The Big Four are the four largest international professional services networks, offering audit, assurance, tax, consulting, advisory, actuarial, corporate finance, and legal services. They handle the vast majority of audits for publicly traded companies as well as many private companies. It is reported that the Big Four audit 99% of the companies in the FTSE 100, and 96% of the companies in the FTSE 250 Index, an index of the leading mid-cap listing companies. The Big Four firms are shown below, with their latest publicly available data.
This group was once known as the "Big Eight", and was reduced to the "Big Six" and then "Big Five" by a series of mergers. The Big Five became the Big Four after the fall of Arthur Andersen in 2002, following its involvement in the Enron scandal.
BDO International (BDO) and Grant Thornton International (Grant Thornton) are the fifth and sixth largest firms, respectively.
Legal structure.
None of the Big Four firms is a single firm; rather, they are professional services networks. Each is a network of firms, owned and managed independently, which have entered into agreements with other member firms in the network to share a common name, brand and quality standards. Each network has established an entity to co-ordinate the activities of the network. In one case (KPMG), the co-ordinating entity is Swiss, and in three cases (Deloitte Touche Tohmatsu, PricewaterhouseCoopers and Ernst & Young) the co-ordinating entity is a UK limited company. Those entities do not themselves perform external professional services, and do not own or control the member firms. They are similar to law firm networks found in the legal profession.
In many cases each member firm practices in a single country, and is structured to comply with the regulatory environment in that country. In 2007, KPMG announced a merger of four member firms
Ernst & Young also includes separate legal entities which manage three of its four areas: Americas, EMEIA (Europe, The Middle East, India and Africa), and Asia-Pacific. (Note: the Japan area does not have a separate area management entity). These firms coordinate services performed by local firms within their respective areas but do not perform services or hold ownership in the local entities.
The figures in this article refer to the combined revenues of each network of firms.
Mergers and the big auditors.
Since 1989, mergers and one major scandal involving Arthur Andersen have reduced the number of major professional-services firms from eight to four.
Big Eight.
The firms were called the Big Eight for most of the 20th century, reflecting the international dominance of the eight largest firms (presented here in alphabetical order):
Most of the Big Eight originated in alliances formed between British and U.S. audit firms in the 19th or early 20th centuries. Price Waterhouse was a UK firm which opened a U.S. office in 1890 and subsequently established a separate U.S. partnership. The UK and U.S. Peat Marwick Mitchell firms adopted a common name in 1925. Other firms used separate names for domestic business, and did not adopt common names until much later: Touche Ross in 1960, Arthur Young (at first Arthur Young, McLelland Moores) in 1968, Coopers & Lybrand in 1973, Deloitte Haskins & Sells in 1978 and Ernst & Whinney in 1979.
The firms' initial international expansion was driven by the needs of British and U.S.-based multinationals for worldwide service. They expanded by forming local partnerships or by forming alliances with local firms.
Arthur Andersen had a different history. The firm originated in the United States, and expanded internationally by establishing its own offices in other markets, including the United Kingdom.
In the 1980s the Big 8, each now with global branding, adopted modern marketing and grew rapidly. They merged with many smaller firms. One of the largest of these mergers was in 1987, when Peat Marwick merged with the Klynveld Main Goerdeler (KMG) group to become KPMG Peat Marwick, later known simply as KPMG.
Big Six.
Competition among these firms intensified and the Big 8 became the Big Six in 1989 when Ernst & Whinney merged with Arthur Young to form Ernst & Young in June, and Deloitte, Haskins & Sells merged with Touche Ross to form Deloitte & Touche in August.
Confusingly, in the United Kingdom the local firm of Deloitte, Haskins & Sells merged instead with Coopers & Lybrand. For some years after the merger, the merged firm was called Coopers & Lybrand Deloitte and the local firm of Touche Ross kept its original name. In the mid 1990s however, both UK firms changed their names to match those of their respective international organizations. On the other hand, in Australia the local firm of Touche Ross merged instead with KPMG. It is for these reasons that the Deloitte & Touche international organization was known as DRT International (later DTT International), to avoid use of names which would have been ambiguous (as well as contested) in certain markets.
Big Five.
The Big 6 became the Big Five in July 1998 when Price Waterhouse merged with Coopers & Lybrand to form PriceWaterhouseCoopers.
Big Four.
The Enron collapse and ensuing investigation prompted scrutiny of their financial reporting, which was audited by Arthur Andersen. Arthur Andersen was eventually indicted for obstruction of justice for shredding documents related to the audit in the 2001 Enron scandal. The resulting conviction, though later overturned, still effectively meant the end for Arthur Andersen. Most of its country practices around the world have been sold to members of what is now the Big Four—notably Ernst & Young globally; Deloitte & Touche in the UK, Canada, Spain, and Brazil; and PricewaterhouseCoopers (now known as PwC) in China and Hong Kong.
2002 saw the passage of the Sarbanes–Oxley Act into law in the US. It aims to enforce strict compliance to rules for both businesses and their auditors.
In 2010 Deloitte with its 1.8% growth was able to beat PricewaterhouseCoopers with its 1.5% growth to gain first place and become the largest firm in the industry. In 2011, PwC re-gained the first place with 10% revenue growth. In 2013, these two firms still claim the top two spots with only $200 million or 0.5% revenue difference. However, Deloitte has seen faster growth than PwC over the last few years indicating that they may reclaim the #1 spot in future years.
Branding List.
A year at the end indicates year of formation through merger or adoption of single brand name.
Policy issues concerning industry concentration.
In the wake of industry concentration and individual firm failure, the issue of a credible alternative industry structure has been raised. The limiting factor on the growth of additional firms is that although some of the firms in the next tier have become quite substantial, and have formed international networks, effectively all very large public companies insist on having a "Big Four" audit, so the smaller firms have no way to grow into the top end of the market.
Documents published in June 2010 show that some UK companies' banking covenants required them to use one of the Big Four. This approach from the lender prevents firms in the next tier from competing for audit work for such companies. The British Bankers' Association said that such clauses are rare. Current discussions in the UK consider outlawing such clauses.
In 2011,The UK House of Lords completed an inquiry into the financial crisis, and called for an Office of Fair Trading investigation into the dominance of the Big Four. It is reported that the Big Four audit all but one of the companies that constitute the FTSE 100, and 240 of the companies in the FTSE 250, an index of the leading mid-cap listing companies.
In Ireland, the Director of Corporate Enforcement, in February 2011 said, auditors "report surprisingly few types of company law offences to us", with the so-called "big four" auditing firms reporting the least often to his office, at just 5pc of all reports.

</doc>
<doc id="38799" url="https://en.wikipedia.org/wiki?curid=38799" title="Galanthus">
Galanthus

Galanthus (snowdrop; Greek "gála" "milk", "ánthos" "flower") is a small genus of about 20 species of bulbous perennial herbaceous plants in the family Amaryllidaceae. Most flower in winter, before the vernal equinox (20 or 21 March in the Northern Hemisphere), but certain species flower in early spring and late autumn.
Snowdrops are sometimes confused with the two related genera within Galantheae, snowflakes "Leucojum" and "Acis".
Description.
All species of "Galanthus" are perennial, herbaceous plants which grow from bulbs. Each bulb generally produces just two or three linear leaves and an erect, leafless scape (flowering stalk), which bears at the top a pair of bract-like spathe valves joined by a papery membrane. From between them emerges a solitary, pendulous, bell-shaped white flower, held on a slender pedicel. The flower has no petals: it consists of six tepals, the outer three being larger and more convex than the inner series. The six anthers open by pores or short slits. The ovary is three-celled, ripening into a three-celled capsule. Each whitish seed has a small, fleshy tail (elaiosome) containing substances attractive to ants which distribute the seeds. The leaves die back a few weeks after the flowers have faded.
The inner flower segments are usually marked with a green, or greenish-yellow, bridge-shaped mark over the small "sinus" (notch) at the tip of each tepal.
An important feature which helps to distinguish between species (and to help to determine the parentage of hybrids) is their "vernation" (the arrangement of the emerging leaves relative to each other). This can be "applanate", "supervolute" or "explicative". In applanate vernation the two leaf blades are pressed flat to each other within the bud and as they emerge; explicative leaves are also pressed flat against each other, but the edges of the leaves are folded back or sometimes rolled; in supervolute plants one leaf is tightly clasped around the other within the bud and generally remains at the point where the leaves emerge from the soil.
Notable species include:
Taxonomy.
The genus was created by Carl Linnaeus in 1753, based on the type species "Galanthus nivalis". "Galanthus" is from the Greek "gala", meaning "milk", and "anthos", meaning "flower", alluding to the colour of the flowers. The epithet "nivalis" means "of the snow".
Similar genera.
Snowdrops are sometimes confused with the two related genera that constitute the Galantheae, snowflakes or "Leucojum" and "Acis". "Leucojum" are much larger and flower in spring (or early summer, depending on the species), with all six tepals in the flower being the same size, though some "poculiform" (goblet- or cup-shaped) "Galanthus" can have inner segments similar in shape and length to the outer ones.
Species.
, the "World Checklist of Selected Plant Families" recognises 19 species. A 20th species, "Galanthus panjutinii" (Panjutin's snowdrop), was recognised during 2012. Discovered in five locations in a small area (estimated at 20 km2) of the northern Colchis area (western Transcaucasus) of Georgia and Russia, it is classed as Endangered. One of its five known sites, at Sochi, was destroyed by preparations for the 2014 Winter Olympics.
Distribution and habitat.
The genus "Galanthus" is native to Europe and the Middle East, from Spain, France and Germany in the west through to Iran in the east. It has become naturalized in other parts of Europe (Norway, Sweden, Great Britain, Belgium and the Netherlands) as well as in eastern Canada and the United States.
"Galanthus nivalis" is the best-known and most widespread representative of the genus "Galanthus". It is native to a large area of Europe, stretching from the Pyrenees in the west, through France and Germany to Poland in the north, Italy, Northern Greece, Bulgaria, Romania, Ukraine and European Turkey. It has been introduced and is widely naturalised elsewhere. Although it is often thought of as a British native wild flower, or to have been brought to the British Isles by the Romans, it was probably introduced around the early sixteenth century and is currently not a protected species in the UK.
Most other "Galanthus" species are from the eastern Mediterranean, but several are found in southern Russia, Georgia, Armenia and Azerbaijan. "Galanthus fosteri" comes from Jordan, Lebanon, Syria, Turkey and maybe Israel.
Conservation.
Some snowdrop species are threatened in their wild habitats, and in most countries it is now illegal to collect bulbs from the wild. Under CITES regulations, international trade in any quantity of "Galanthus", whether bulbs, live plants or even dead ones, is illegal without a CITES permit. This applies to hybrids and named cultivars as well as species. CITES does, however, allow a limited trade in wild-collected bulbs of just three species ("G. nivalis", "G, elwesii" and "G. woronowii") from Turkey and Georgia.
Cultivation.
Snowdrop gardens.
Celebrated as a sign of spring, snowdrops can form impressive carpets of white in areas where they are native or have been naturalised. These displays may attract large numbers of sightseers. There are a number of snowdrop gardens in England, Wales, Scotland and Ireland. Several gardens open specially in February for visitors to admire the flowers. Sixty gardens took part in Scotland's first Snowdrop Festival (1 Feb–11 March 2007). Several gardens in England open during snowdrop season for the National Gardens Scheme (NGS) and in Scotland for Scotland's Gardens.
Cultivars.
There are numerous single- and double-flowered cultivars of "Galanthus nivalis", and also of several other "Galanthus" species, particularly "G. plicatus" and "G. elwesii". There are also many hybrids between these and other species (there are more than 500 cultivars described in Bishop, Davis & Grimshaw's book, plus lists of many cultivars that have now been lost, and others not seen by the authors). They differ particularly in the size, shape and markings of the flower, the period of flowering, and other characteristics, mainly of interest to the keen (even fanatical) snowdrop collectors, known as "galanthophiles", who hold meetings where the scarcer cultivars change hands. Double-flowered cultivars and forms, such as the extremely common "Galanthus nivalis" f. "pleniflorus" 'Flore Pleno', may be less attractive to some people but they can have greater visual impact in a garden setting.
The following species and cultivars have gained the Royal Horticultural Society's Award of Garden Merit:-
A list of Irish cultivars can be found here [http://www.snowdropinfo.com/irishsnowdrops.htm]
Propagation.
Propagation is by offset bulbs, either by careful division of clumps in full growth ("in the green"), or removed when the plants are dormant, immediately after the leaves have withered; or by seeds sown either when ripe, or in spring. Professional growers and keen amateurs also use such methods as "twin-scaling" to increase the stock of choice cultivars quickly.
Active substances.
It was suggested by Andreas Plaitakis and Roger Duvoisin in 1983 that the mysterious magical herb moly that appears in Homer's Odyssey is actually snowdrop. An active substance in snowdrop is called galantamine, which, as Acetylcholinesterase inhibitor, could have acted as an antidote to Circe's poisons. Galantamine (or galanthamine) can be helpful in the treatment of Alzheimer's disease, though it is not a cure; the substance also occurs naturally in daffodils and other narcissi.
Snowdrops contain also an active lectin or agglutinin named GNA for "Galanthus nivalis" agglutinin.
In 1995 Árpád Pusztai genetically modified potatoes with the GNA gene, which work he discussed on a radio interview in 1998 and published in the Lancet in 1999. In 1998 said in an interview on a World in Action programme that his group had observed damage to the intestines and immune systems of rats fed the genetically modified potatoes. He also said "If I had the choice I would certainly not eat it", and that "I find it's very unfair to use our fellow citizens as guinea pigs". These remarks started the so-called Pusztai affair.

</doc>
<doc id="38800" url="https://en.wikipedia.org/wiki?curid=38800" title="Louis II, Elector of Brandenburg">
Louis II, Elector of Brandenburg

Louis the Roman () (7 May 1328 – 17 May 1365) was the eldest son of Emperor Louis IV the Bavarian by his second wife, Margaret II, Countess of Hainault, and a member of the House of Wittelsbach. Louis was Duke of Bavaria as Louis VI (1347–1365) and Margrave of Brandenburg (1351–1365) as Louis II. As of 1356, he also served as Prince-elector of Brandenburg.
Biography.
Louis was born in Rome when his parents travelled there for his father's coronation as Holy Roman Emperor, hence his nickname "the Roman." When his father died in 1347, Louis succeeded him as Duke of Bavaria (as Louis VI) and Count of Holland and Hainaut together with his five brothers. Louis released Holland and Hainaut for his brothers William I and Albert I in 1349, since he expected to acquire the Polish crown by his marriage with Cunigunde of Poland, a daughter of Casimir III and Aldona Ona of Lithuania. Later claims against William and Albert were not successful. Hence Louis supported his mother during her war with William.
In December of 1351 Louis VI received Brandenburg from his older half-brother Louis V of Bavaria in exchange for the sole rule of Upper Bavaria. Less experienced than Louis V, he was also challenged by the "False Waldemar", an impostor who claimed Brandenburg and got support from several cities and Holy Roman Emperor Charles IV until the Wittelsbachs came to terms with Charles. Louis also had to abandon claims on fiefdoms in Mecklenburg and Pomerania. With the Golden Bull of 1356, Louis secured the electoral dignity. In 1358 Louis was absolved from the papal excommunication.
After Cunigunde's death in 1357, Louis married Ingeborg of Mecklenburg-Schwerin. She was a daughter of Albert II, Duke of Mecklenburg, and Euphemia of Sweden. Louis had no children with her, either, thus his younger brother Otto V succeeded him in Brandenburg. The childless dukes Louis and Otto had already promised Charles IV the succession in Brandenburg in 1364 as revenge for a conflict with their brother Stephen II over the Bavarian succession after the death of their nephew Meinhard, the son of Louis V. Louis the Roman died in Berlin in 1365.

</doc>
<doc id="38801" url="https://en.wikipedia.org/wiki?curid=38801" title="Algebraic topology">
Algebraic topology

Algebraic topology is a branch of mathematics that uses tools from abstract algebra to study topological spaces. The basic goal is to find algebraic invariants that classify topological spaces up to homeomorphism, though usually most classify up to homotopy equivalence.
Although algebraic topology primarily uses algebra to study topological problems, using topology to solve algebraic problems is sometimes also possible. Algebraic topology, for example, allows for a convenient proof that any subgroup of a free group is again a free group.
Main branches of algebraic topology.
Below are some of the main areas studied in algebraic topology:
Homotopy groups.
In mathematics, homotopy groups are used in algebraic topology to classify topological spaces. The first and simplest homotopy group is the fundamental group, which records information about loops in a space. Intuitively, homotopy groups record information about the basic shape, or holes, of a topological space.
Homology.
In algebraic topology and abstract algebra, homology (in part from Greek ὁμός "homos" "identical") is a certain general procedure to associate a sequence of abelian groups or modules with a given mathematical object such as a topological space or a group.
Cohomology.
In homology theory and algebraic topology, cohomology is a general term for a sequence of abelian groups defined from a co-chain complex. That is, cohomology is defined as the abstract study of cochains, cocycles, and coboundaries. Cohomology can be viewed as a method of assigning algebraic invariants to a topological space that has a more refined algebraic structure than does homology. Cohomology arises from the algebraic dualization of the construction of homology. In less abstract language, cochains in the fundamental sense should assign 'quantities' to the "chains" of homology theory.
Manifolds.
A manifold is a topological space that near each point resembles Euclidean space. Examples include the plane, the sphere, and the torus, which can all be realized in three dimensions, but also the Klein bottle and real projective plane which cannot be realized in three dimensions, but can be realized in four dimensions. Typically, results in algebraic topology focus on global, non-differentiable aspects of manifolds; for example Poincaré duality.
Knot theory.
Knot theory is the study of mathematical knots. While inspired by knots that appear in daily life in shoelaces and rope, a mathematician's knot differs in that the ends are joined together so that it cannot be undone. In precise mathematical language, a knot is an embedding of a circle in 3-dimensional Euclidean space, R3. Two mathematical knots are equivalent if one can be transformed into the other via a deformation of R3 upon itself (known as an ambient isotopy); these transformations correspond to manipulations of a knotted string that do not involve cutting the string or passing the string through itself.
Complexes.
A simplicial complex is a topological space of a certain kind, constructed by "gluing together" points, line segments, triangles, and their "n"-dimensional counterparts (see illustration). Simplicial complexes should not be confused with the more abstract notion of a simplicial set appearing in modern simplicial homotopy theory. The purely combinatorial counterpart to a simplicial complex is an abstract simplicial complex.
A CW complex is a type of topological space introduced by J. H. C. Whitehead to meet the needs of homotopy theory. This class of spaces is broader and has some better categorical properties than simplicial complexes, but still retains a combinatorial nature that allows for computation (often with a much smaller complex).
Method of algebraic invariants.
An older name for the subject was combinatorial topology, implying an emphasis on how a space X was constructed from simpler ones (the modern standard tool for such construction is the CW-complex). In the 1920s and 1930s, there was growing emphasis on investigating topological spaces by finding correspondences from them to algebraic groups, which led to the change of name to algebraic topology. The combinatorial topology name is still sometimes used to emphasize an algorithmic approach based on decomposition of spaces.
In the algebraic approach, one finds a correspondence between spaces and groups that respects the relation of homeomorphism (or more general homotopy) of spaces. 
This allows one to recast statements about topological spaces into statements about groups, which have a great deal of manageable structure, often making these statement easier to prove.
Two major ways in which this can be done are through fundamental groups, or more generally homotopy theory, and through homology and cohomology groups. The fundamental groups give us basic information about the structure of a topological space, but they are often nonabelian and can be difficult to work with. The fundamental group of a (finite) simplicial complex does have a finite presentation.
Homology and cohomology groups, on the other hand, are abelian and in many important cases finitely generated. Finitely generated abelian groups are completely classified and are particularly easy to work with.
Setting in category theory.
In general, all constructions of algebraic topology are functorial; the notions of category, functor and natural transformation originated here. Fundamental groups and homology and cohomology groups are not only "invariants" of the underlying topological space, in the sense that two topological spaces which are homeomorphic have the same associated groups, but their associated morphisms also correspond — a continuous mapping of spaces induces a group homomorphism on the associated groups, and these homomorphisms can be used to show non-existence (or, much more deeply, existence) of mappings.
One of the first mathematicians to work with different types of cohomology was Georges de Rham. One can use the differential structure of smooth manifolds via de Rham cohomology, or Čech or sheaf cohomology to investigate the solvability of differential equations defined on the manifold in question. De Rham showed that all of these approaches were interrelated and that, for a closed, oriented manifold, the Betti numbers derived through simplicial homology were the same Betti numbers as those derived through de Rham cohomology. This was extended in the 1950s, when Eilenberg and Steenrod generalized this approach. They defined homology and cohomology as functors equipped with natural transformations subject to certain axioms (e.g., a weak equivalence of spaces passes to an isomorphism of homology groups), verified that all existing (co)homology theories satisfied these axioms, and then proved that such an axiomatization uniquely characterized the theory.
Applications of algebraic topology.
Classic applications of algebraic topology include:

</doc>
<doc id="38802" url="https://en.wikipedia.org/wiki?curid=38802" title="Louis IV, Holy Roman Emperor">
Louis IV, Holy Roman Emperor

Louis IV (; 1 April 1282 – 11 October 1347), called the Bavarian, of the house of Wittelsbach, was King of the Romans from 1314, King of Italy from 1327, and Holy Roman Emperor from 1328.
Louis IV was Duke of Upper Bavaria from 1294/1301 together with his elder brother Rudolf I, served as Margrave of Brandenburg until 1323, as Count Palatine of the Rhine until 1329, and he became Duke of Lower Bavaria in 1340. He obtained the titles Count of Hainaut, Holland, Zeeland, and Friesland in 1345 when his wife Margaret inherited them.
Early reign as Duke of Upper Bavaria.
Louis was born in Munich, the son of Louis II, Duke of Upper Bavaria and Count Palatine of the Rhine, and Matilda, a daughter of King Rudolph I.
Though Louis was partly educated in Vienna and became co-regent of his brother Rudolf I in Upper Bavaria in 1301 with the support of his Habsburg mother and her brother, King Albert I, he quarrelled with the Habsburgs from 1307 over possessions in Lower Bavaria. A civil war against his brother Rudolf due to new disputes on the partition of their lands was ended in 1313, when peace was made at Munich.
In the same year, on November 9, Louis defeated his Habsburg cousin Frederick the Fair who was further aided by duke Leopold I. Originally, he was a friend of Frederick, with whom he had been raised. However, armed conflict arose when the guardianship over the young Dukes of Lower Bavaria (Henry XIV, Otto IV, and Henry XV) was entrusted to Frederick, even though the late Duke Otto III, the former King of Hungary, had chosen Louis. On 9 November 1313, Frederick was defeated by Louis in the Battle of Gamelsdorf and had to renounce the tutelage. This victory caused a stir within the Holy Roman Empire and increased the reputation of the Bavarian Duke.
Election as German King and conflict with Habsburg.
The death of Holy Roman Emperor Henry VII in August 1313 necessitated the election of a successor. Henry's son John, King of Bohemia since 1310, seemed too powerful to most prince-electors, opening the door for other candidates. The most likely choice was Frederick the Fair, the son of Henry's predecessor, Albert I, of the House of Habsburg. In reaction, the pro-Luxemburg party among the prince electors settled on Louis as its candidate to prevent Frederick's election.
On 19 October 1314, Archbishop Henry II Cologne chaired an assembly of four electors assembled at Sachsenhausen, south of Frankfurt. Participants were Louis's brother, Rudolph I of the Palatinate, who objected to the election of his younger brother, Duke Rudolph I of Saxe-Wittenberg, and Henry of Carinthia, whom the Luxemburgs had deposed as King of Bohemia. These four elector chose Frederick as King.
The Luxemburg party did not accept this election and the next day a second election was held. Upon the instigation of Peter of Aspelt, Archbishop of Mainz, five different electors convened at Frankfurt and elected Louis as King. These electors were Archbishop Peter himself, Archbishop Baldwin of Trier and King John of Bohemia - both of the House of Luxemburg - Margrave Waldemar of Brandenburg and Duke John II of Saxe-Lauenburg, who contested his Rudolph of Wittenbergs claim to the electoral vote.
This double election was quickly followed by two coronations: Louis was crowned at Aachen - the customary site of coronations - by Archbishop Peter of Mainz, while the Archbishop of Cologne, who by custom had the right to crown the new king, crowned Frederick at Bonn. In the following conflict between the kings, Louis recognized in 1316 the independence of Switzerland from the Habsburg dynasty.
After several years of bloody war, victory finally seemed within the grasp of Frederick, who was strongly supported by his brother Leopold. However, Frederick's army was decisively defeated in the Battle of Mühldorf on 28 September 1322 on the Ampfing Heath, where Frederick and 1300 nobles from Austria and Salzburg were captured.
Louis held Frederick captive in Trausnitz Castle (Schwandorf) for three years, but the determined resistance by Frederick's brother Leopold, the retreat of John of Bohemia from his alliance, and the Pope's ban induced Louis to release Frederick in the Treaty of Trausnitz of 13 March 1325. In this agreement, Frederick recognized Louis as legitimate ruler and undertook to return to captivity if he did not succeed in convincing his brothers to submit to Louis.
As he did not manage to overcome Leopold's obstinacy, Frederick returned to Munich as a prisoner, even though the Pope had released him from his oath. Louis, who was impressed by such nobility, renewed the old friendship with Frederick, and they agreed to rule the Empire jointly. Since the Pope and the electors strongly objected to this agreement, another treaty was signed at Ulm on 7 January 1326, according to which Frederick would administer Germany as King of the Romans, while Louis would be crowned as Holy Roman Emperor in Italy. However, after Leopold's death in 1326, Frederick withdrew from the regency of the Empire and returned to rule only Austria. He died on 13 January 1330.
Despite Louis' victory, Pope John XXII still refused to ratify his election, and in 1324 he excommunicated Louis, but the sanction had less effect than in earlier disputes between emperors and the papacy.
Coronation as Holy Roman Emperor and conflict with the Pope.
After the reconciliation with the Habsburgs in 1326, Louis marched to Italy and was crowned King of Italy in Milan in 1327. Already in 1323 Louis had sent an army to Italy to protect Milan against the Kingdom of Naples, which was together with France the strongest ally of the papacy. But now the Lord of Milan Galeazzo I Visconti was deposed since he was suspected of conspiring with the pope.
In January 1328 Louis entered Rome and had himself crowned emperor by the aged senator Sciarra Colonna, called "captain of the Roman people". Three months later Louis published a decree declaring "Jacque de Cahors" (Pope John XXII) deposed on grounds of heresy. He then installed a Spiritual Franciscan, Pietro Rainalducci, as Nicholas V, but both left Rome in August 1328. In the meantime Robert, King of Naples had sent both a fleet and an army against Louis and his ally Peter II of Sicily. Louis spent the winter 1328/29 in Pisa and stayed then in Northern Italy until his co-ruler Frederick of Habsburg had died. In fulfilment of an oath, on his return from Italy Louis founded Ettal Abbey on 28 April 1330.
Franciscan theologians Michael of Cesena, and William of Ockham and the philosopher Marsilius of Padua, who were on bad terms with the Pope as well, joined Louis in Italy and accompanied him to his court in Munich.
In 1333, Louis sought to counter French influence in the southwest of the empire, and offered Humbert II of Viennois the Kingdom of Arles, an opportunity to gain full authority over Savoy, Provence, and surrounding territories. Humbert was reluctant to take the crown and the conflict that would follow with all around him, so he declined, telling Louis that he should make peace with the church first.
The failure of later negotiations with the papacy led in 1338 to the declaration at Rhense by six electors to the effect that election by all or the majority of the electors automatically conferred the royal title and rule over the empire, without papal confirmation.
Louis also allied in 1337 with Edward III of England against Philip VI of France, the protector of the new Pope Benedict XII in Avignon. Philip had prevented any agreement between the emperor and the pope. In 1338 Edward III was the emperor's guest at the Imperial Diet in the Kastorkirche at Coblence and was named vicar-general of the Holy Roman Empire. In 1341 Louis deserted Edward but came only temporarily to terms with Philip. The expected English payments were missing and Louis intended to reach an agreement with the pope one more time.
Imperial privileges.
Louis IV was a protector of the Teutonic Knights. In 1337 he allegedly bestowed upon the Teutonic Order a privilege to conquer Lithuania and Russia, although the Order had only petitioned for three small territories. Later he forbade the Order to stand trial before foreign courts in their territorial conflicts with foreign rulers.
Louis concentrated his energies also on the economic development of the cities of the empire, so his name can be found in many city chronicles for the privileges he granted. In 1330 the emperor for example permitted the Frankfurt Trade Fair, and in 1340 Lübeck, as the most powerful member of the future Hanseatic League, received the coinage prerogative for golden gulden.
Dynastic policy.
In 1323 Louis gave Brandenburg as a fiefdom to his eldest son Louis V after the Brandenburg branch of the House of Ascania had died out. With the Treaty of Pavia in 1329 the emperor reconciled the sons of his late brother Rudolph and returned the Palatinate to his nephews Rudolf and Rupert. After the death of Henry of Bohemia the duchy of Carinthia was released as an imperial fief on 2 May 1335 in Linz to his Habsburg cousins Albert II, Duke of Austria and Otto, Duke of Austria, while Tyrol was first placed into Luxemburg hands.
With the death of duke John I in 1340 Louis inherited Lower Bavaria and then reunited the duchy of Bavaria. John's mother, a member of the Luxemburg dynasty, had to return to Bohemia. In 1342 Louis also acquired Tyrol for the Wittelsbach by voiding the first marriage of Margarete Maultasch with John Henry of Bohemia and marrying her to his own son Louis V, thus alienating the House of Luxemburg even more.
In 1345 the emperor further antagonized the lay princes by conferring Hainaut, Holland, Zeeland, and Friesland upon his wife Margaret of Holland. The hereditary titles of Margaret's sisters, one of whom was the queen of England, were ignored. Because of the dangerous hostility of the Luxemburgs, Louis had increased his power base ruthlessly.
Conflict with Luxemburg.
The acquisition of these territories and his restless foreign policy had earned Louis many enemies among the German princes. In the summer of 1346 the Luxemburg Charles IV was elected rival king, with the support of Pope Clement VI. Louis himself obtained much support from the Imperial Free Cities and the knights and successfully resisted Charles, who was widely regarded as a papal puppet ("rex clericorum" as William of Ockham called him). Also the Habsburg dukes stayed loyal to Louis. In the Battle of Crécy Charles' father John of Luxemburg was killed; Charles himself also took part in the battle but escaped.
But then Louis' sudden death avoided a longer civil war. Louis died in October 1347 from a stroke suffered during a bear-hunt in Puch near Fürstenfeldbruck. He is buried in the Frauenkirche in Munich. The sons of Louis supported Günther von Schwarzburg as new rival king to Charles but finally joined the Luxemburg party after Günther's early death in 1349 and divided the Wittelsbach possessions amongst themselves again. In continuance of the conflict of the House of Wittelsbach with the House of Luxemburg, the Wittelsbach family returned to power in the Holy Roman Empire in 1400 with King Rupert of Germany, a great-grandnephew of Louis.
Family and children.
In 1308 Louis IV married his first wife, Beatrix of Świdnica. Their children were:
In 1324 he married his second wife, Margaret II, Countess of Hainaut and Holland.
Their children were:

</doc>
<doc id="38808" url="https://en.wikipedia.org/wiki?curid=38808" title="Compression">
Compression

Compression may refer to:

</doc>
<doc id="38809" url="https://en.wikipedia.org/wiki?curid=38809" title="GNU Privacy Guard">
GNU Privacy Guard

GNU Privacy Guard (GnuPG or GPG) is a free software replacement for Symantec's PGP cryptographic software suite. GnuPG is compliant with RFC 4880, which is the IETF standards track specification of OpenPGP. Modern versions of PGP and Veridis' Filecrypt are interoperable with GnuPG and other OpenPGP-compliant systems.
GnuPG is part of the GNU project, and has received major funding from the German government.
Overview.
GnuPG is a hybrid-encryption software program because it uses a combination of conventional symmetric-key cryptography for speed, and public-key cryptography for ease of secure key exchange, typically by using the recipient's public key to encrypt a session key which is only used once. This mode of operation is part of the OpenPGP standard and has been part of PGP from its first version.
The GnuPG 1.x series uses an integrated library, while the GnuPG 2.x series replaces this with Libgcrypt.
GnuPG encrypts messages using asymmetric keypairs individually generated by GnuPG users. The resulting public keys may be exchanged with other users in a variety of ways, such as Internet key servers. They must always be exchanged carefully to prevent identity spoofing by corrupting public key ↔ "owner" identity correspondences. It is also possible to add a cryptographic digital signature to a message, so the message integrity and sender can be verified, if a particular correspondence relied upon has not been corrupted.
GnuPG also supports symmetric encryption algorithms. By default, GnuPG uses the CAST5 symmetrical algorithm. GnuPG does not use patented or otherwise restricted software or algorithms. Instead, GnuPG uses a variety of other, non-patented algorithms.
For a long time it did not support the IDEA encryption algorithm used in PGP. It was in fact possible to use IDEA in GnuPG by downloading a plugin for it, however this might require a license for some uses in countries in which IDEA was patented. Starting with version 1.4.13/2.0.20, GnuPG supports IDEA because the last patent of IDEA expired in 2012 (Support of IDEA is "to get rid of all the questions from folks either trying to decrypt old data or migrating keys from PGP to GnuPG", and is not recommended for normal use).
As of versions 2.0.26 and 1.4.18, GnuPG supports the following algorithms:
GnuPG 2.1 series also supports elliptic curve cryptography (ECDSA, ECDH and EdDSA).
History.
GnuPG was initially developed by Werner Koch. Version 1.0.0, which was the first production version, was released on September 7, 1999, almost two years after the first GnuPG release (version 0.0.0). The German Federal Ministry of Economics and Technology funded the documentation and the port to Microsoft Windows in 2000.
GnuPG is a system compliant to the OpenPGP standard, thus the history of OpenPGP is of importance; it was designed to interoperate with PGP, the email encryption program initially designed and developed by Phil Zimmermann.
On February 7, 2014, a GnuPG crowdfunding effort closed, raising 36,732 euros for a new web site and infrastructure improvements.
Branches.
, there are three branches of GnuPG:
"Modern" (2.1) and "stable" (2.0) can not be installed at the same time. However, it is possible to install "classic" (1.4) along with any of the other versions.
There are two additional GnuPG branches, which are discontinued :
Platforms.
Although the basic GnuPG program has a command-line interface, there exist various front-ends that provide it with a graphical user interface. For example, GnuPG encryption support has been integrated into KMail and Evolution, the graphical e-mail clients found in KDE and GNOME, the most popular Linux desktops. There are also graphical GnuPG front-ends, for example Seahorse for GNOME and KGPG for KDE. For the OS X, the MacGPG project provides a number of Aqua front-ends for OS integration of encryption and key management as well as GnuPG installations via Installer packages.
Furthermore, the GPGTools Installer installs all related OpenPGP applications (GPG Keychain Access), plugins (GPGMail) and dependencies (MacGPG) to use GnuPG based encryption. Instant messaging applications such as Psi and Fire can automatically secure messages when GnuPG is installed and configured. Web-based software such as Horde also makes use of it. The cross-platform extension Enigmail provides GnuPG support for Mozilla Thunderbird and SeaMonkey. Similarly, Enigform provides GnuPG support for Mozilla Firefox. FireGPG was discontinued June 7, 2010.
In 2005, g10 Code GmbH and Intevation GmbH released Gpg4win, a software suite that includes GnuPG for Windows, GNU Privacy Assistant, and GnuPG plug-ins for Windows Explorer and Outlook. These tools are wrapped in a standard Windows installer, making it easier for GnuPG to be installed and used on Windows systems.
Limitations.
As a command-line-based system, GnuPG 1.x is not written as an API that may be incorporated into other software. To overcome this, "GPGME" (abbreviated from "GnuPG Made Easy") was created as an API wrapper around GnuPG that parses the output of GnuPG and provides a stable and maintainable API between the components. This currently requires an out-of-process call to the GnuPG executable for many GPGME API calls; as a result, possible security problems in an application do not propagate to the actual crypto code due to the process barrier. Various graphical front-ends based on GPGME have been created.
Since GnuPG 2.x, many of the GnuPG functionalities are available directly as C APIs in Libgcrypt.
Vulnerabilities.
The OpenPGP standard specifies several methods of digitally signing messages. In 2003, due to an error in a change to GnuPG intended to make one of those methods more efficient, a security vulnerability was introduced. It affected only one method of digitally signing messages, only for some releases of GnuPG (1.0.2 through 1.2.3), and there were fewer than 1000 such keys listed on the key servers. Most people did not use this method, and were in any case discouraged from doing so, so the damage caused (if any, since none has been publicly reported) would appear to have been minimal. Support for this method has been removed from GnuPG versions released after this discovery (1.2.4 and later).
Two further vulnerabilities were discovered in early 2006; the first being that scripted uses of GnuPG for signature verification may result in false positives, the second that non-MIME messages were vulnerable to the injection of data which while not covered by the digital signature, would be reported as being part of the signed message. In both cases updated versions of GnuPG were made available at the time of the announcement.
Application support.
Applications, frontends and browser extensions that support GPG include the following:
In popular culture.
In May 2014, "The Washington Post" reported on a 12-minute video guide "GPG for Journalists" posted to Vimeo in January 2013 by a user named anon108. The "Post" identified anon108 as fugitive NSA whistleblower Edward Snowden, who it said made the tutorial—"narrated by a digitally disguised voice whose speech patterns sound similar to those of Snowden"—to teach journalist Glenn Greenwald email encryption. Greenwald said that he could not confirm the authorship of the video.

</doc>
<doc id="38811" url="https://en.wikipedia.org/wiki?curid=38811" title="Proline">
Proline

Proline (abbreviated as Pro or P; encoded by the codons CCU, CCC, CCA, and CCG) is an α-amino acid that is used in the biosynthesis of proteins. It contains an α-amino group (which is in the protonated >NH2+ form under biological conditions), an α-carboxylic acid group (which is in the deprotonated −COO− form under biological conditions), and a side chain pyrrolidine, classifying it as a nonpolar(at physiological pH), aliphatic amino acid. It is non-essential in humans, meaning the body can synthesize it from the non-essential amino acid L-glutamate.
Proline is the only amino acid with a secondary amine. Furthermore, it is unique in that the alpha-amino group is attached directly to the side chain, making the α carbon a direct substituent of the side chain.
History and etymology.
Proline was first isolated in 1900 by Richard Willstätter who obtained the amino acid while studying N-methylproline. The year after Emil Fischer published the synthesis of proline from phthalimide propylmalonic ester. The name proline comes from pyrrolidine, one of its constituents.
Biosynthesis.
Proline is biosynthetically derived from the amino acid L-glutamate. Glutamate-5-semialdehyde is first formed by glutamate 5-kinase (ATP-dependent) and glutamate-5-semialdehyde dehydrogenase (which requires NADH or NADPH). This can then either spontaneously cyclize to form 1-pyrroline-5-carboxylic acid, which is reduced to proline by pyrroline-5-carboxylate reductase (using NADH or NADPH), or turned into ornithine by ornithine aminotransferase, followed by cyclisation by ornithine cyclodeaminase to form proline.
Biological activity.
L-Proline has been found to act as a weak agonist of the glycine receptor and of both NMDA and non-NMDA (AMPA/kainate) ionotropic glutamate receptors. It has been proposed to be a potential endogenous excitotoxin. In plants, proline accumulation is a common physiological response to various stresses but is also part of the developmental program in generative tissues (e.g. pollen).
Proline is a phosphorylation marker and is commonly found right before the amino acid serine and threonine to mark them as phosphorylation spots. As a result, Proline preceding these amino acids in an amino acid chain is highly evolutionarily conserved.
Properties in protein structure.
The distinctive cyclic structure of proline's side chain gives proline an exceptional conformational rigidity compared to other amino acids. It also affects the rate of peptide bond formation between proline and other amino acids. When proline is bound as an amide in a peptide bond, its nitrogen is not bound to any hydrogen, meaning it cannot act as a hydrogen bond donor, but can be a hydrogen bond acceptor.
Peptide bond formation with incoming Pro-tRNAPro is considerably slower than with any other tRNAs, which is a general feature of N-alkylamino acids. Peptide bond formation is also slow between an incoming tRNA and a chain ending in proline; with the creation of proline-proline bonds slowest of all.
The exceptional conformational rigidity of proline affects the secondary structure of proteins near a proline residue and may account for proline's higher prevalence in the proteins of thermophilic organisms. Protein secondary structure can be described in terms of the dihedral angles φ, ψ and ω of the protein backbone. The cyclic structure of proline's side chain locks the angle φ at approximately −60°.
Proline acts as a structural disruptor in the middle of regular secondary structure elements such as alpha helices and beta sheets; however, proline is commonly found as the first residue of an alpha helix and also in the edge strands of beta sheets. Proline is also commonly found in turns (another kind of secondary structure), and aids in the formation of beta turns. This may account for the curious fact that proline is usually solvent-exposed, despite having a completely aliphatic side chain.
Multiple prolines and/or hydroxyprolines in a row can create a polyproline helix, the predominant secondary structure in collagen. The hydroxylation of proline by prolyl hydroxylase (or other additions of electron-withdrawing substituents such as fluorine) increases the conformational stability of collagen significantly. Hence, the hydroxylation of proline is a critical biochemical process for maintaining the connective tissue of higher organisms. Severe diseases such as scurvy can result from defects in this hydroxylation, e.g., mutations in the enzyme prolyl hydroxylase or lack of the necessary ascorbate (vitamin C) cofactor.
Cis-trans isomerization.
Peptide bonds to proline, and to other "N"-substituted amino acids (such as sarcosine), are able to populate both the "cis" and "trans" isomers. Most peptide bonds overwhelmingly adopt the "trans" isomer (typically 99.9% under unstrained conditions), chiefly because the amide hydrogen ("trans" isomer) offers less steric repulsion to the preceding Cα atom than does the following Cα atom ("cis" isomer). By contrast, the "cis" and "trans" isomers of the X-Pro peptide bond (where X represents any amino acid) both experience steric clashes with the neighboring substitution and are nearly equal energetically. Hence, the fraction of X-Pro peptide bonds in the "cis" isomer under unstrained conditions ranges from 10-40%; the fraction depends slightly on the preceding amino acid, with aromatic residues favoring the "cis" isomer slightly.
From a kinetic standpoint, "cis"-"trans" proline isomerization is a very slow process that can impede the progress of protein folding by trapping one or more proline residues crucial for folding in the non-native isomer, especially when the native protein requires the "cis" isomer. This is because proline residues are exclusively synthesized in the ribosome as the "trans" isomer form. All organisms possess prolyl isomerase enzymes to catalyze this isomerization, and some bacteria have specialized prolyl isomerases associated with the ribosome. However, not all prolines are essential for folding, and protein folding may proceed at a normal rate despite having non-native conformers of many X-Pro peptide bonds.
Uses.
Proline and its derivatives are often used as asymmetric catalysts in proline organocatalysis reactions. The CBS reduction and proline catalysed aldol condensation are prominent examples.
L-Proline is an osmoprotectant and therefore is used in many pharmaceutical, biotechnological applications.
In brewing, proteins rich in proline combine with polyphenols to produce haze (turbidity).
Specialties.
Proline is one of the two amino acids that do not follow along with the typical Ramachandran plot, along with glycine. Due to the ring formation connected to the beta carbon, the ψ and φ angles about the peptide bond have fewer allowable degrees of rotation. As a result it is often found in "turns" of proteins as its free entropy (ΔS) is not as comparatively large to other amino acids and thus in a folded form vs. unfolded form, the change in entropy is less. Furthermore, proline is rarely found in α and β structures as it would reduce the stability of such structures, because its side chain α-N can only form one hydrogen bond.
Additionally, proline is the only amino acid that does not form a blue/purple colour when developed by spraying with ninhydrin for uses in chromatography. Proline, instead, produces an orange/yellow colour.
History.
Richard Willstätter synthesized proline by the reaction of sodium salt of diethyl malonate with 1,3-dibromopropane in 1900. In 1901, Hermann Emil Fischer isolated proline from casein and the decomposition products of γ-phthalimido-propylmalonic ester.
Synthesis.
Racemic proline can be synthesized from diethyl malonate and acrylonitrile:

</doc>
<doc id="38813" url="https://en.wikipedia.org/wiki?curid=38813" title="Coven">
Coven

A coven or covan usually refers to a gathering of witches.
The word "coven" remained largely unused in English until 1921 when Margaret Murray promoted the idea, now much disputed, that all witches across Europe met in groups of thirteen which they called "covens." 
Neopaganism.
In Wicca and other similar forms of modern neopagan witchcraft, such as Stregheria and Feri, a coven is a gathering or community of witches, much like a in Christian parlance. It is composed of a group of believers who gather together for ceremonies of worship such as Drawing Down the Moon, or celebrating the Sabbats.
The number of persons involved may vary. Although thirteen is considered ideal (probably in deference to Murray's theories), any group of at least three can be a coven. A group of two is usually called a "working couple" (regardless of their sexes). Within the community, many believe that a coven larger than thirteen is unwieldy, citing unwieldy group dynamics and an unfair burden on the leadership. When a coven has grown too large to be manageable, it may split, or "hive". In Wicca this may also occur when a newly made High Priest or High Priestess, also called 3rd Degree ordination, leaves to start their own coven.
Wiccan covens are usually jointly led by a High Priestess and a High Priest, though some are led by only one or the other. In more recent forms of neopagan witchcraft, covens are sometimes run as democracies with a rotating leadership.
Online covens.
With the rise of the internet as a platform for collaborative discussion and media dissemination, it became popular for adherents and practitioners of Wicca to establish (often paid subscription-based) "online covens" which remotely teach tradition-specific crafts to students in a similar method of education as non-religious virtual online schools.
One of the first online covens to take this route is the Coven of the Far Flung Net, which was established in 1998 as the online arm of the Church of Universal Eclectic Wicca.
However, because of potentially-unwieldy membership sizes, many online covens limit their memberships to anywhere between 10 to 100 students. The CFFN, in particular, tried to devolve its structure into a system of sub-coven clans (which governed their own application processes), a system which ended in 2003 due to fears by the CFFN leadership that the clans were becoming communities in their own right.
Usage in literature and popular culture.
In fantasy stories and popular culture, a coven is a gathering of witches to work spells in tandem. Such imagery can be traced back to Renaissance prints depicting witches and to the three "weird sisters" in Shakespeare's "Macbeth". Orgiastic meetings of witches are also depicted in the Robert Burns poem "Tam o' Shanter" and in the Goethe play "Faust". Movies featuring covens include "Suspiria", "Rosemary's Baby", "Four Rooms", "The Covenant", "Underworld", "", "The Craft", "Coven", "Paranormal Activity 3" and " The Witch".
In television, covens have been portrayed in U.S. supernatural dramas "Charmed", "Witches of East End", "The Originals", "The Secret Circle" and "True Blood". In the 1967 "Star Trek" original series episode "", three witches appeared as illusions and acted in unison to voice a warning to Kirk and the landing party to leave the planet. The third season of "American Horror Story" is titled "" and focuses on witches.
In novels such as "The Vampire Chronicles" by Anne Rice and the "Twilight" series by Stephenie Meyer, covens are families or unrelated groups of vampires who live together.

</doc>
<doc id="38817" url="https://en.wikipedia.org/wiki?curid=38817" title="Amstrad">
Amstrad

Amstrad is a British electronics company. , Amstrad's main business is manufacturing Sky Digital interactive boxes.
Amstrad was founded in 1968 by Alan Sugar at the age of 21. The name is a contraction of "Alan Michael Sugar Trading". It was first listed on the London Stock Exchange in 1980. During the late 1980s, Amstrad had a substantial share of the PC market in the UK. Amstrad was once a FTSE 100 Index constituent but since 2007 is wholly owned by BSkyB.
The company has offices in Kings Road, Brentwood, Essex.
History.
1960s and 1970s.
Amstrad was founded in 1968 by Alan Sugar at the age of 21, the name of the original company being AMS Trading (Amstrad) Limited, derived from its founder's initials (Alan Michael Sugar). Amstrad entered the market in the field of consumer electronics. During the 1970s they were at the forefront of low-priced hi-fi, TV and car stereo cassette technologies. Lower prices were achieved by injection moulding plastic hi-fi turntable covers, undercutting competitors who used the vacuum forming process.
Amstrad expanded to the marketing of low cost, low quality amplifiers and tuners, imported from the Far East and badged with the Amstrad name for the UK market. Their first electrical product was the Amstrad 8000 amplifier, which Sugar would describe later as "the biggest load of rubbish I've ever seen in my life."
1980s.
In 1980, Amstrad went public trading on the London Stock Exchange, and doubled in size each year during the early '80s. Amstrad began marketing their own home computers in an attempt to capture the market from Commodore and Sinclair, with the Amstrad CPC range in 1984. The CPC 464 was launched in the UK, France, Australia, New Zealand, Germany, Spain and Italy. It was followed by the CPC 664 and CPC 6128 models. Later "Plus" variants of the 464 and 6128, launched in 1990, increased their functionality slightly.
In 1985, the popular Amstrad PCW range was introduced, which were principally word processors, complete with printer, running the LocoScript word processing program. They were also capable of running the CP/M operating system. The Amsoft division of Amstrad was set up to provide in-house software and consumables.
On 7 April 1986 Amstrad announced it had bought from Sinclair Research ""...the worldwide rights to sell and manufacture all existing and future Sinclair computers and computer products, together with the Sinclair brand name and those intellectual property rights where they relate to computers and computer related products."" which included the ZX Spectrum, for £5 million. This included Sinclair's unsold stock of Sinclair QLs and Spectrums. Amstrad made more than £5 million on selling these surplus machines alone. Amstrad launched two new variants of the Spectrum: the ZX Spectrum +2, based on the ZX Spectrum 128, with a built-in tape drive (like the CPC 464) and, the following year, the ZX Spectrum +3, with a built-in floppy disk drive (similar to the CPC 664 and 6128), taking the 3" disks that many Amstrad machines used.
The company produced a range of affordable MS-DOS-based, but with the GEM graphics interface, and later Windows-based personal computers, the first of which was the PC1512, priced at £399 in 1986. It was a success, capturing more than 25% of the European computer market. In 1988 Amstrad attempted to make the first affordable portable personal computer with the PPC512 and 640 models, introduced a year before the Macintosh Portable. They ran MS-DOS on an 8 MHz processor, and the built-in screen could emulate the Monochrome Display Adapter or Color Graphics Adapter. Amstrad's final (and ill-fated) attempts to exploit the Sinclair brand were based on the company's own PCs; a compact desktop PC derived from the PPC 512, branded as the Sinclair PC200, and the PC1512 rebadged as the Sinclair PC500.
Amstrad's second generation of PCs, the PC2000 series, were launched in 1989. However,
due to a problem with the Seagate ST277R hard disk shipped with the PC2386 model, these had to be recalled and fitted with Western Digital controllers. Amstrad later successfully sued Seagate, but following bad press over the hard disk problems, Amstrad lost its lead in the European PC market.
1990s.
In the early 1990s, Amstrad began to focus on portable computers rather than desktop computers. In 1990, Amstrad tried to enter the video game console market with the Amstrad GX4000, similar to what Commodore did at the same time with the C64 GS. The console, based on the Amstrad 464 Plus hardware, was a complete commercial failure, because it used outdated technology, and most of its game library was straight ports of CPC games that could be bought for much less in their original format.
In 1993, Amstrad was licensed by Sega to produce a system which was similar to the Sega TeraDrive, going by the name of the Amstrad Mega PC, to try to regain their image in the gaming market. The system didn't succeed as well as expected, mostly due to its high initial retail price of £599. In that same year, Amstrad released the PenPad, a PDA similar to the Apple Newton, and released only weeks before it. It was a commercial failure, and had several technical and usability problems. It lacked most features that the Apple Newton included, but had a lower price at $450.
As Amstrad began to concentrate less on computers and more in communication, they purchased several telecommunications businesses including Betacom, Dancall Telecom, Viglen Computers and Dataflex Design Communications during the early 1990s. Amstrad has been a major supplier of set top boxes to UK satellite TV provider Sky since its launch in 1989. Amstrad was key to the introduction of Sky, as the company were responsible for finding methods to produce the requisite equipment at an attractive price for the consumer - Alan Sugar famously approached "someone who bashes out dustbin lids", to manufacture satellite dishes cheaply. Ultimately, it was the only manufacturer producing receiver boxes and dishes at the system's launch, and has continued to manufacture set top boxes for Sky, from analogue to digital and now including Sky's Sky+ digital video recorder.
In 1997, Amstrad PLC was wound up, its shares being split into Viglen and Betacom instead. Betacom PLC was then renamed Amstrad PLC.
The same year, Amstrad supplied set top boxes to Australian broadcaster Foxtel, and in 2004 to Italian broadcaster Sky Italia.
Recent times.
In 2000, Amstrad released the first of its combined telephony and e-mail devices, called the "E-m@iler". This was followed by the "E-m@iler Plus" in 2002, and the "E3 Videophone" in 2004. Amstrad’s UK E-m@iler business is operated through a separate company, Amserve Ltd which is 89.8% owned by Amstrad and 10.2% owned by DSG International plc (formerly Dixons plc).
Amstrad has also produced a variety of home entertainment products over their history, including hi-fi, televisions, VCRs, and DVD players.
BSkyB takeover.
In July 2007, BSkyB announced a takeover of Amstrad for £125m, a 23.7% premium on its market capitalisation. BSkyB had been a major client of Amstrad, accounting for 75% of sales for its 'set top box' business. Having supplied BSkyB with hardware since its inception in 1988, market analysts had noted the two companies becoming increasingly close.
Sugar commented that he wished to play a part in the business, saying: "I turn 60 this year and I have had 40 years of hustling in the business, but now I have to start thinking about my team of loyal staff, many of whom have been with me for many years."
2008.
It was announced on 2 July 2008 that Sugar had stepped down as Chairman of Amstrad, which had been planned since BSkyB took over in 2007.

</doc>
<doc id="38822" url="https://en.wikipedia.org/wiki?curid=38822" title="Power transmission">
Power transmission

Power transmission is the movement of energy from its place of generation to a location where it is applied to perform useful work.
Power is defined formally as units of energy per unit time. In SI units:
Since the development of technology, transmission and storage systems have been of immense interest to technologists and technology users.
Electrical power.
With the widespread establishment of electrical grids, power transmission is usually associated most with electric power transmission. Alternating current is normally preferred as its voltage may be easily stepped up by a transformer in order to minimize resistive loss in the conductors used to transmit power over great distances; another set of transformers is required to step it back down to safer or more usable voltage levels at destination.
Power transmission is usually performed with overhead lines as this is the most economical way to do so. Underground transmission by high-voltage cables is chosen in crowded urban areas and in high-voltage direct-current (HVDC) submarine connections.
Wireless transmission.
Power might also be transmitted by changing electromagnetic fields or by radio waves; microwave energy may be carried efficiently over short distances by a waveguide.
Mechanical power.
Electrical power transmission has replaced mechanical power transmission in all but the very shortest distances. From the 16th century through the industrial revolution to the end of the 19th century mechanical power transmission was the norm. The oldest long-distance power transmission technology involved systems of push-rods ("stängenkunst" or "feldstängen") connecting waterwheels to distant mine-drainage and brine-well pumps. A surviving example from 1780 exists at Bad Kösen that transmits power approximately 200 meters from a waterwheel to a salt well, and from there, an additional 150 meters to a brine evaporator. This technology survived into the 21st century in a handful of oilfields in the US, transmitting power from a central pumping engine to the numerous pump-jacks in the oil field.
Factories were fitted with overhead line shafts providing rotary power. Short line-shaft systems were described by Agricola, connecting a waterwheel to numerous ore-processing machines. While the machines described by Agricola used geared connections from the shafts to the machinery, by the 19th century, drivebelts would become the norm for linking individual machines to the line shafts. One mid 19th century factory had 1,948 feet of line shafting with 541 pulleys.
Mechanical power may be transmitted directly using a solid structure such as a driveshaft; transmission gears can adjust the amount of torque or force vs. speed in much the same way an electrical transformer adjusts voltage vs current.
Hydraulic systems use liquid under pressure to transmit power; canals and hydroelectric power generation facilities harness natural water power to lift ships or generate electricity. Pumping water or pushing mass uphill with (windmill pumps) is one possible means of energy storage. London had a hydraulic network powered by five pumping stations operated by the London Hydraulic Power Company, with a total effect of 5 MW.
Pneumatic systems use gasses under pressure to transmit power; compressed air is commonly used to operate pneumatic tools in factories and repair garages. A pneumatic wrench (for instance) is used to remove and install automotive tires far more quickly than could be done with standard manual hand tools.
A pneumatic system was proposed by proponents of Edison's direct current as the basis of the power grid. Compressed air generated at Niagara Falls would drive far away generators of DC power. The War of Currents ended with alternating current (AC) as the only means of long distance power transmission.
Chemicals and fuels.
Power (and energy) may be transmitted by physically transporting chemical or nuclear fuels. Possible artificial fuels include radioactive isotopes, wood alcohol, grain alcohol, methane, synthetic gas, hydrogen gas (H2), cryogenic gas, and liquefied natural gas (LNG).

</doc>
<doc id="38823" url="https://en.wikipedia.org/wiki?curid=38823" title="Fulda">
Fulda

Fulda () is a city in Hesse, Germany; it is located on the river Fulda and is the administrative seat of the Fulda district ("Kreis"). In 1990, the town hosted the 30th Hessentag state festival.
History.
Middle Ages.
In 744 Saint Sturm, a disciple of Saint Boniface, founded the Benedictine monastery of Fulda as one of Boniface's outposts in the reorganization of the church in Germany. It later served as a base from which missionaries could accompany Charlemagne's armies in their political and military campaign to fully conquer and convert pagan Saxony.
The initial grant for the abbey was signed by Carloman, the son of Charles Martel. The support of the Mayors of the Palace and later, the early Pippinid and Carolingian rulers, was important to Boniface's success. Fulda also received support from many of the leading families of the Carolingian world. Sturm, whose tenure as abbot lasted from 747 until 779, was most likely related to the Agilolfing dukes of Bavaria. Fulda also received large and constant donations from the Etichonids, a leading family in Alsace, and from the Conradines, predecessors of the Salian Holy Roman Emperors. Under Sturm, the donations Fulda received from these and other important families helped in the establishment of daughter-houses -Johannesberg and Petersberg - near Fulda.
Between 790 and 819 the community rebuilt the main monastery church to more fittingly house the relics. They based their new basilica on the original 4th-century (since demolished) Old St. Peter's Basilica in Rome, using the transept and crypt plan of that great pilgrimage church to frame their own saint as the "Apostle to the Germans". The crypt of the original abbey church still holds those relics, but the church itself has been subsumed into a Baroque renovation. A small, 9th-century chapel remains standing within walking distance of the church, as do the foundations of a later women's abbey.
The great scholar Rabanus Maurus served as abbot at Fulda from 822 to 842.
18th and 19th centuries.
The foundation of the abbey Fulda and its territory originated with an Imperial grant, and the sovereign principality therefore was subject only to the German emperor. Fulda became a bishopric in 1752 and the prince-abbots were given the additional title of prince-bishop. The prince-abbots (and later prince-bishops) ruled Fulda and the surrounding region until the bishopric was forcibly dissolved by Napoleon in 1802.
The city went through a baroque building campaign in the 18th century, resulting in the current “Baroque City” status. This included a remodeling of Fulda Cathedral (1704–12) and of the "Stadtschloss "(Castle-Palace, 1707–12) by Johann Dientzenhofer. The city parish church, St. Blasius, was built between 1771–1785.
In 1764 a porcelain factory was started in Fulda under Prince-Bishop, Prince-Abbot Heinrich von Bibra, but shortly after his death it was closed down in 1789 by his successor, Prince-Bishop, Prince-Abbot Adalbert von Harstall.
Because of its quality and rarity, this porcelain is much prized by collectors.
The city was given to Prince William Frederick of Orange-Nassau (the later King William I of the Netherlands) in 1803 (as part of the short-lived Principality of Nassau-Orange-Fulda), was annexed to the Grand Duchy of Berg in 1806, and in 1809 to the Principality of Frankfurt. After the Congress of Vienna of 1814-1815, most of the territory went to the Electorate of Hesse, which Prussia annexed in 1866.
Cold War.
Fulda lends its name to the Fulda Gap, a traditional east-west invasion route used by Napoleon and others. During the Cold War, it was presumed to be an invasion route for any conventional war between NATO and Soviet forces. Downs Barracks in Fulda was the headquarters of the American 14th Armored Cavalry Regiment, later replaced by the 11th Armored Cavalry Regiment. The cavalry had as many a 3,000 soldiers from the end of World War II until 1993. Not all of those soldiers were in Fulda proper, but scattered over observation posts and in the cities of Bad Kissingen and Bad Hersfeld. The strategic importance of this region (along the old West/East German border) led to a large US and Soviet military presence.
Transportation.
Fulda station is an important transport hub and interchange point between local and long distance traffic of the German railway network, and is classified by Deutsche Bahn as a category 2 station. It is on the Hanover–Würzburg high-speed railway; the North-South line ("Nord-Süd-Strecke"), comprising the Bebra-Fulda line north of Fulda, and the Kinzig Valley Railway and Fulda-Main Railway to the south; the Vogelsberg Railway, which connects to the hills of the Vogelsberg in the west; and the Fulda–Gersfeld Railway (Rhön Railway) to Gersfeld in the Rhön Mountains to the east.
Fulda is on the Bundesautobahn 7 (BAB 7) and is at the eastern terminus of the Bundesautobahn 66, which ends at a three-way junction with the BAB 7. It is also on the Bundesstraße 27.
International relations.
Twin towns/sister cities.
Fulda is twinned with:

</doc>
<doc id="38824" url="https://en.wikipedia.org/wiki?curid=38824" title="Electric power transmission">
Electric power transmission

Electric power transmission is the bulk movement of electrical energy from a generating site, such as a power plant, to an electrical substation. The interconnected lines which facilitate this movement are known as a transmission network. This is distinct from the local wiring between high-voltage substations and customers, which is typically referred to as electric power distribution. The combined transmission and distribution network is known as the "power grid" in North America, or just "the grid". In the United Kingdom, the network is known as the "National Grid".
A wide area synchronous grid, also known as an "interconnection" in North America, directly connects a large number of generators delivering AC power with the same relative "frequency", to a large number of consumers. For example, there are four major interconnections in North America (the Western Interconnection, the Eastern Interconnection, the Quebec Interconnection and the Electric Reliability Council of Texas (ERCOT) grid), and one large grid for most of continental Europe.
The same relative "frequency", but almost never the same relative "phase" as ac power interchange is a function of the phase difference between any two nodes in the network, and zero degrees difference means no power is interchanged; any phase difference up to 90 degrees is stable by the "equal area criteria"; any phase difference above 90 degrees is absolutely unstable; the interchange partners are responsible for maintaining frequency as close to the utility frequency as is practical, and the phase differences between any two nodes significantly less than 90 degrees; should 90 degrees be exceeded, a system separation is executed, and remains separated until the trouble has been corrected.
Historically, transmission and distribution lines were owned by the same company, but starting in the 1990s, many countries have liberalized the regulation of the electricity market in ways that have led to the separation of the electricity transmission business from the distribution business.
System.
Most transmission lines are high-voltage three-phase alternating current (AC), although single phase AC is sometimes used in railway electrification systems. High-voltage direct-current (HVDC) technology is used for greater efficiency over very long distances (typically hundreds of miles). HVDC technology is also used in submarine power cables (typically longer than 30 miles (50 km)), and in the interchange of power between grids that are not mutually synchronized. HVDC links are used to stabilize large power distribution networks where sudden new loads, or blackouts, in one part of a network can result in synchronization problems and cascading failures.
Electricity is transmitted at high voltages (115 kV or above) to reduce the energy loss which occurs in long-distance transmission. Power is usually transmitted through overhead power lines. Underground power transmission has a significantly higher installation cost and greater operational limitations, but reduced maintenance costs. Underground transmission is sometimes used in urban areas or environmentally sensitive locations.
A lack of electrical energy storage facilities in transmission systems leads to a key limitation. Electrical energy must be generated at the same rate which it is consumed. A sophisticated control system is required to ensure that power generation very closely matches demand. If the demand for power exceeds supply, the imbalance can cause generation plant(s) and transmission equipment to automatically disconnect and/or shut down to prevent damage. In the worst case, this may lead to a cascading series of shut downs and a major regional blackout. Examples include the US Northeast blackouts of 1965, 1977, 2003, and major blackouts in other US regions in 1996 and 2011. Electric transmission networks are interconnected into regional, national, and even continent wide networks to reduce the risk of such a failure by providing multiple redundant, alternative routes for power to flow should such shut downs occur. Transmission companies determine the maximum reliable capacity of each line (ordinarily less than its physical or thermal limit) to ensure that spare capacity is available in the event of a failure in another part of the network.
Overhead transmission.
High-voltage overhead conductors are not covered by insulation. The conductor material is nearly always an aluminum alloy, made into several strands and possibly reinforced with steel strands. Copper was sometimes used for overhead transmission, but aluminum is lighter, yields only marginally reduced performance and costs much less. Overhead conductors are a commodity supplied by several companies worldwide. Improved conductor material and shapes are regularly used to allow increased capacity and modernize transmission circuits. Conductor sizes range from 12 mm2 (#6 American wire gauge) to 750 mm2 (1,590,000 circular mils area), with varying resistance and current-carrying capacity. Thicker wires would lead to a relatively small increase in capacity due to the skin effect, that causes most of the current to flow close to the surface of the wire. Because of this current limitation, multiple parallel cables (called bundle conductors) are used when higher capacity is needed. Bundle conductors are also used at high voltages to reduce energy loss caused by corona discharge.
Today, transmission-level voltages are usually considered to be 110 kV and above. Lower voltages, such as 66 kV and 33 kV, are usually considered subtransmission voltages, but are occasionally used on long lines with light loads. Voltages less than 33 kV are usually used for distribution. Voltages above 765 kV are considered extra high voltage and require different designs compared to equipment used at lower voltages.
Since overhead transmission wires depend on air for insulation, the design of these lines requires minimum clearances to be observed to maintain safety. Adverse weather conditions, such as high wind and low temperatures, can lead to power outages. Wind speeds as low as can permit conductors to encroach operating clearances, resulting in a flashover and loss of supply.
Oscillatory motion of the physical line can be termed gallop or flutter depending on the frequency and amplitude of oscillation.
Underground transmission.
Electric power can also be transmitted by underground power cables instead of overhead power lines. Underground cables take up less right-of-way than overhead lines, have lower visibility, and are less affected by bad weather. However, costs of insulated cable and excavation are much higher than overhead construction. Faults in buried transmission lines take longer to locate and repair. Underground lines are strictly limited by their thermal capacity, which permits less overload or re-rating than overhead lines. Long underground AC cables have significant capacitance, which may reduce their ability to provide useful power to loads beyond . Long underground DC cables have no such issue and can run for thousands of miles.
History.
In the early days of commercial electric power, transmission of electric power at the same voltage as used by lighting and mechanical loads restricted the distance between generating plant and consumers. In 1882, generation was with direct current (DC), which could not easily be increased in voltage for long-distance transmission. Different classes of loads (for example, lighting, fixed motors, and traction/railway systems) required different voltages, and so used different generators and circuits.
Due to this specialization of lines and because transmission was inefficient for low-voltage high-current circuits, generators needed to be near their loads. It seemed, at the time, that the industry would develop into what is now known as a distributed generation system with large numbers of small generators located near their loads.
The transmission of electric power with alternate current (AC) became possible after Lucien Gaulard and John Dixon Gibbs built what they called the secondary generator, an early transformer provided with 1:1 turn ratio and open magnetic circuit, in 1881.
The first long distance () AC line was built for the 1884 International Exhibition of Turin, Italy. It was powered by a 2kV, 130Hz Siemens & Halske alternator and featured several Gaulard secondary generators with their primary windings connected in series, which fed incandescent lamps. The system proved the feasibility of AC electric power transmission on long distances.
A very first operative AC line was put into service in 1885 in via dei Cerchi, Rome, Italy, for public lighting. It was powered by two Siemens & Halske alternators rated 30 hp (22 kW), 2 kV at 120 Hz and used 200 series-connected Gaulard 2-kV/20-V step-down transformers provided with a closed magnetic circuit, one for each lamp. Few months later it was followed by the first British AC system, which was put into service at the Grosvenor Gallery, London. It also featured Siemens alternators and 2.4-kV/100-V step-down transformers, one per user, with shunt-connected primaries.
In 1886, in Great Barrington, Massachusetts, a 1 kV alternating current (AC) distribution system was installed, featuring both step up and step down transformers and resorting also to European technology. At an AIEE meeting on May 16, 1888, Nikola Tesla delivered a lecture entitled "", describing the equipment which allowed efficient generation and use of polyphase alternating currents. The transformer, and Tesla's polyphase and single-phase induction motors, were essential for a combined AC distribution system for both lighting and machinery. Ownership of the rights to the Tesla patents was a key advantage to the Westinghouse Company in offering a complete alternating current power system for both lighting and power.
Regarded as one of the most influential electrical innovations, the "universal system" used transformers to step-up voltage from generators to high-voltage transmission lines, and then to step-down voltage to local distribution circuits or industrial customers. By a suitable choice of utility frequency, both lighting and motor loads could be served. Rotary converters and later mercury-arc valves and other rectifier equipment allowed DC to be provided where needed. Generating stations and loads using different frequencies could be interconnected using rotary converters. By using common generating plants for every type of load, important economies of scale were achieved, lower overall capital investment was required, load factor on each plant was increased allowing for higher efficiency, a lower cost for the consumer and increased overall use of electric power.
The first transmission of three-phase alternating current using high voltage took place in 1891 during the international electricity exhibition in Frankfurt. A 15 kV transmission line, approximately 175 km long, connected Lauffen on the Neckar and Frankfurt.
Voltages used for electric power transmission increased throughout the 20th century. By 1914, fifty-five transmission systems each operating at more than 70 kV were in service. The highest voltage then used was 150 kV.
By allowing multiple generating plants to be interconnected over a wide area, electricity production cost was reduced. The most efficient available plants could be used to supply the varying loads during the day. Reliability was improved and capital investment cost was reduced, since stand-by generating capacity could be shared over many more customers and a wider geographic area. Remote and low-cost sources of energy, such as hydroelectric power or mine-mouth coal, could be exploited to lower energy production cost.
The rapid industrialization in the 20th century made electrical transmission lines and grids a critical infrastructure item in most industrialized nations. The interconnection of local generation plants and small distribution networks was greatly spurred by the requirements of World War I, with large electrical generating plants built by governments to provide power to munitions factories. Later these generating plants were connected to supply civil loads through long-distance transmission.
Bulk power transmission.
Engineers design transmission networks to transport the energy as efficiently as feasible, while at the same time taking into account economic factors, network safety and redundancy. These networks use components such as power lines, cables, circuit breakers, switches and transformers. The transmission network is usually administered on a regional basis by an entity such as a regional transmission organization or transmission system operator.
Transmission efficiency is greatly improved by devices that increase the voltage, (and thereby proportionately reduce the current) in the line conductors, thus allowing power to be transmitted with acceptable losses. The reduced current flowing through the line reduces the heating losses in the conductors. According to Joule's Law, energy losses are directly proportional to the square of the current. Thus, reducing the current by a factor of two will lower the energy lost to conductor resistance by a factor of four for any given size of conductor.
The optimum size of a conductor for a given voltage and current can be estimated by Kelvin's law for conductor size, which states that the size is at its optimum when the annual cost of energy wasted in the resistance is equal to the annual capital charges of providing the conductor. At times of lower interest rates, Kelvin's law indicates that thicker wires are optimal; while, when metals are expensive, thinner conductors are indicated: however, power lines are designed for long-term use, so Kelvin's law has to be used in conjunction with long-term estimates of the price of copper and aluminum as well as interest rates for capital.
The increase in voltage is achieved in AC circuits by using a "step-up transformer". HVDC systems require relatively costly conversion equipment which may be economically justified for particular projects such as submarine cables and longer distance high capacity point to point transmission. HVDC is necessary for the import and export of energy between grid systems that are not synchronized with each other.
A transmission grid is a network of power stations, transmission lines, and substations. Energy is usually transmitted within a grid with three-phase AC. Single-phase AC is used only for distribution to end users since it is not usable for large polyphase induction motors. In the 19th century, two-phase transmission was used but required either four wires or three wires with unequal currents. Higher order phase systems require more than three wires, but deliver little or no benefit.
The price of electric power station capacity is high, and electric demand is variable, so it is often cheaper to import some portion of the needed power than to generate it locally. Because loads are often regionally correlated (hot weather in the Southwest portion of the US might cause many people to use air conditioners), electric power often comes from distant sources. Because of the economic benefits of load sharing between regions, wide area transmission grids now span countries and even continents. The web of interconnections between power producers and consumers should enable power to flow, even if some links are inoperative.
The unvarying (or slowly varying over many hours) portion of the electric demand is known as the "base load" and is generally served by large facilities (which are more efficient due to economies of scale) with fixed costs for fuel and operation. Such facilities are nuclear, coal-fired or hydroelectric, while other energy sources such as concentrated solar thermal and geothermal power have the potential to provide base load power. Renewable energy sources, such as solar photovoltaics, wind, wave, and tidal, are, due to their intermittency, not considered as supplying "base load" but will still add power to the grid. The remaining or 'peak' power demand, is supplied by peaking power plants, which are typically smaller, faster-responding, and higher cost sources, such as combined cycle or combustion turbine plants fueled by natural gas.
Long-distance transmission of electricity (thousands of kilometers) is cheap and efficient, with costs of US$0.005–0.02/kWh (compared to annual averaged large producer costs of US$0.01–0.025/kWh, retail rates upwards of US$0.10/kWh, and multiples of retail for instantaneous suppliers at unpredicted highest demand moments). Thus distant suppliers can be cheaper than local sources (e.g., New York often buys over 1000 MW of electricity from Canada). Multiple local sources (even if more expensive and infrequently used) can make the transmission grid more fault tolerant to weather and other disasters that can disconnect distant suppliers.
Long-distance transmission allows remote renewable energy resources to be used to displace fossil fuel consumption. Hydro and wind sources cannot be moved closer to populous cities, and solar costs are lowest in remote areas where local power needs are minimal. Connection costs alone can determine whether any particular renewable alternative is economically sensible. Costs can be prohibitive for transmission lines, but various proposals for massive infrastructure investment in high capacity, very long distance super grid transmission networks could be recovered with modest usage fees.
Grid input.
At the power stations, the power is produced at a relatively low voltage between about 2.3 kV and 30 kV, depending on the size of the unit. The generator terminal voltage is then stepped up by the power station transformer to a higher voltage (115 kV to 765 kV AC, varying by the transmission system and by country) for transmission over long distances. In India, for example, the grid voltage is 440kV.
Losses.
Transmitting electricity at high voltage reduces the fraction of energy lost to resistance, which varies depending on the specific conductors, the current flowing, and the length of the transmission line. For example, a 765 kV line carrying 1000 MW of power can have losses of 1.1% to 0.5%. A 345 kV line carrying the same load across the same distance has losses of 4.2%. For a given amount of power, a higher voltage reduces the current and thus the resistive losses in the conductor. For example, raising the voltage by a factor of 10 reduces the current by a corresponding factor of 10 and therefore the "I"2"R" losses by a factor of 100, provided the same sized conductors are used in both cases. Even if the conductor size (cross-sectional area) is reduced 10-fold to match the lower current, the "I"2"R" losses are still reduced 10-fold. Long-distance transmission is typically done with overhead lines at voltages of 115 to 1,200 kV. At extremely high voltages, more than 2,000 kV exists between conductor and ground, corona discharge losses are so large that they can offset the lower resistive losses in the line conductors. Measures to reduce corona losses include conductors having larger diameters; often hollow to save weight, or bundles of two or more conductors.
Factors that affect the resistance, and thus loss, of conductors used in transmission and distribution lines include temperature, spiraling, and the skin effect. The resistance of a conductor increases with its temperature. Temperature changes in electric power lines can have a significant effect on power losses in the line. Spiraling, which refers to the increase in conductor resistance due to the way stranded conductors spiral about the center, also contributes to increases in conductor resistance. The skin effect causes the effective resistance of a conductor to increase at higher alternating current frequencies.
Transmission and distribution losses in the USA were estimated at 6.6% in 1997 and 6.5% in 2007. By using underground DC transmission, these losses can be cut in half. Underground cables can be larger diameter because they do not have the constraint of light weight that overhead conductors have. In general, losses are estimated from the discrepancy between power produced (as reported by power plants) and power sold to the end customers; the difference between what is produced and what is consumed constitute transmission and distribution losses, assuming no theft of utility occurs.
As of 1980, the longest cost-effective distance for direct-current transmission was determined to be . For alternating current it was , though all transmission lines in use today are substantially shorter than this.
In any alternating current transmission line, the inductance and capacitance of the conductors can be significant. Currents that flow solely in 'reaction' to these properties of the circuit, (which together with the resistance define the impedance) constitute reactive power flow, which transmits no 'real' power to the load. These reactive currents, however, are very real and cause extra heating losses in the transmission circuit. The ratio of 'real' power (transmitted to the load) to 'apparent' power (sum of 'real' and 'reactive') is the power factor. As reactive current increases, the reactive power increases and the power factor decreases. For transmission systems with low power factor, losses are higher than for systems with high power factor. Utilities add capacitor banks, reactors and other components (such as phase-shifting transformers; static VAR compensators; and flexible AC transmission systems, FACTS) throughout the system to compensate for the reactive power flow and reduce the losses in power transmission and stabilize system voltages. These measures are collectively called 'reactive support'.
Transposition.
Current flowing through transmission lines induces a magnetic field that surrounds the lines of each phase and affects the inductance of the surrounding conductors of other phases. The mutual inductance of the conductors is partially dependent on the physical orientation of the lines with respect to each other. Three-phase power transmission lines are conventionally strung with phases separated on different vertical levels. The mutual inductance seen by a conductor of the phase in the middle of the other two phases will be different than the inductance seen by the conductors on the top or bottom. Because of this phenomenon, conductors must be periodically transposed along the length of the transmission line so that each phase sees equal time in each relative position to balance out the mutual inductance seen by all three phases. To accomplish this, line position is swapped at specially designed transposition towers at regular intervals along the length of the transmission line in various transposition schemes.
Subtransmission.
Subtransmission is part of an electric power transmission system that runs at relatively lower voltages. It is uneconomical to connect all distribution substations to the high main transmission voltage, because the equipment is larger and more expensive. Typically, only larger substations connect with this high voltage. It is stepped down and sent to smaller substations in towns and neighborhoods. Subtransmission circuits are usually arranged in loops so that a single line failure does not cut off service to a large number of customers for more than a short time. Loops can be "normally closed", where loss of one circuit should result in no interruption, or "normally open" where substations can switch to a backup supply. While subtransmission circuits are usually carried on overhead lines, in urban areas buried cable may be used. The lower-voltage subtransmission lines use less right-of-way and simpler structures; it is much more feasible to put them underground where needed. Higher-voltage lines require more space and are usually above-ground since putting them underground is very expensive.
There is no fixed cutoff between subtransmission and transmission, or subtransmission and distribution. The voltage ranges overlap somewhat. Voltages of 69 kV, 115 kV and 138 kV are often used for subtransmission in North America. As power systems evolved, voltages formerly used for transmission were used for subtransmission, and subtransmission voltages became distribution voltages. Like transmission, subtransmission moves relatively large amounts of power, and like distribution, subtransmission covers an area instead of just point to point.
Transmission grid exit.
At the substations, transformers reduce the voltage to a lower level for distribution to commercial and residential users. This distribution is accomplished with a combination of sub-transmission (33 kV to 132 kV) and distribution (3.3 to 25 kV). Finally, at the point of use, the energy is transformed to low voltage (varying by country and customer requirements—see Mains electricity by country).
Modeling: The Transmission Matrix.
Oftentimes, we are only interested in the terminal characteristics of the transmission line, which are the voltage and current at the sending and receiving ends. The transmission line itself is then modeled as a "black box" and a 2 by 2 transmission matrix is used to model its behavior, as follows:
The line is assumed to be a reciprocal, symmetrical network, meaning that the receiving and sending labels can be switched with no consequence. The transmission matrix T also has the following properties:
The parameters A, B, C, and D differ depending on how the desired model handles the line's resistance (R), inductance (L), capacitance (C), and shunt (parallel) admittance Y. The four main models are the short line approximation, the medium line approximation, the long line approximation (with distributed parameters), and the lossless line. In all models described, a capital letter such as R refers to the total quantity summed over the line and a lowercase letter such as c refers to the per-unit-length quantity.
The lossless line approximation, which is the least accurate model, is often used on short lines when the inductance of the line is much greater than its resistance. For this approximation, the voltage and current are identical at the sending and receiving ends.
The short line approximation is normally used for lines less than 50 miles long. For a short line, only a series impedance Z is considered, while C and Y are ignored. The final result is that A = D = 1 per unit, B = Z ohms, and C = 0.
The medium line approximation is used for lines between 50 and 150 miles long. In this model, the series impedance and the shunt admittance are considered, with half of the shunt admittance being placed at each end of the line. This circuit is often referred to as a "nominal pi" circuit because of the shape that is taken on when admittance is placed on both sides of the circuit diagram. The analysis of the medium line brings one to the following result:
The long line model is used when a higher degree of accuracy is needed or when the line under consideration is more than 150 miles long. Series resistance and shunt admittance are considered as distributed parameters, meaning each differential length of the line has a corresponding differential resistance and shunt admittance. The following result can be applied at any point along the transmission line, where gamma is defined as the propagation constant.
To find the voltage and current at the end of the long line, x should be replaced with L (the line length) in all parameters of the transmission matrix.
High-voltage direct current.
High-voltage direct current (HVDC) is used to transmit large amounts of power over long distances or for interconnections between asynchronous grids. When electrical energy is to be transmitted over very long distances, the power lost in AC transmission becomes appreciable and it is less expensive to use direct current instead of alternating current. For a very long transmission line, these lower losses (and reduced construction cost of a DC line) can offset the additional cost of the required converter stations at each end.
HVDC is also used for submarine cables because AC cannot be supplied over distances of more than about , due to the fact that the cables produce too much reactive power. In these cases special high-voltage cables for DC are used. Submarine HVDC systems are often used to connect the electricity grids of islands, for example, between Great Britain and continental Europe, between Great Britain and Ireland, between Tasmania and the Australian mainland, and between the North and South Islands of New Zealand. Submarine connections up to in length are presently in use.
HVDC links can be used to control problems in the grid with AC electricity flow. The power transmitted by an AC line increases as the phase angle between source end voltage and destination ends increases, but too large a phase angle will allow the systems at either end of the line to fall out of step. Since the power flow in a DC link is controlled independently of the phases of the AC networks at either end of the link, this phase angle limit does not exist, and a DC link is always able to transfer its full rated power. A DC link therefore stabilizes the AC grid at either end, since power flow and phase angle can then be controlled independently.
As an example, to adjust the flow of AC power on a hypothetical line between Seattle and Boston would require adjustment of the relative phase of the two regional electrical grids. This is an everyday occurrence in AC systems, but one that can become disrupted when AC system components fail and place unexpected loads on the remaining working grid system. With an HVDC line instead, such an interconnection would: (1) Convert AC in Seattle into HVDC; (2) Use HVDC for the 3,000 miles of cross-country transmission; and (3) Convert the HVDC to locally synchronized AC in Boston, (and possibly in other cooperating cities along the transmission route). Such a system could be less prone to failure if parts of it were suddenly shut down. One example of a long DC transmission line is the Pacific DC Intertie located in the Western United States.
Capacity.
The amount of power that can be sent over a transmission line is limited. The origins of the limits vary depending on the length of the line. For a short line, the heating of conductors due to line losses sets a thermal limit. If too much current is drawn, conductors may sag too close to the ground, or conductors and equipment may be damaged by overheating. For intermediate-length lines on the order of , the limit is set by the voltage drop in the line. For longer AC lines, system stability sets the limit to the power that can be transferred. Approximately, the power flowing over an AC line is proportional to the cosine of the phase angle of the voltage and current at the receiving and transmitting ends. This angle varies depending on system loading and generation. It is undesirable for the angle to approach 90 degrees, as the power flowing decreases but the resistive losses remain. Very approximately, the allowable product of line length and maximum load is proportional to the square of the system voltage. Series capacitors or phase-shifting transformers are used on long lines to improve stability. High-voltage direct current lines are restricted only by thermal and voltage drop limits, since the phase angle is not material to their operation.
Up to now, it has been almost impossible to foresee the temperature distribution along the cable route, so that the maximum applicable current load was usually set as a compromise between understanding of operation conditions and risk minimization. The availability of industrial distributed temperature sensing (DTS) systems that measure in real time temperatures all along the cable is a first step in monitoring the transmission system capacity. This monitoring solution is based on using passive optical fibers as temperature sensors, either integrated directly inside a high voltage cable or mounted externally on the cable insulation. A solution for overhead lines is also available. In this case the optical fiber is integrated into the core of a phase wire of overhead transmission lines (OPPC). The integrated Dynamic Cable Rating (DCR) or also called Real Time Thermal Rating (RTTR) solution enables not only to continuously monitor the temperature of a high voltage cable circuit in real time, but to safely utilize the existing network capacity to its maximum. Furthermore, it provides the ability to the operator to predict the behavior of the transmission system upon major changes made to its initial operating conditions.
Control.
To ensure safe and predictable operation the components of the transmission system are controlled with generators, switches, circuit breakers and loads. The voltage, power, frequency, load factor, and reliability capabilities of the transmission system are designed to provide cost effective performance for the customers.
Load balancing.
The transmission system provides for base load and peak load capability, with safety and fault tolerance margins. The peak load times vary by region largely due to the industry mix. In very hot and very cold climates home air conditioning and heating loads have an effect on the overall load. They are typically highest in the late afternoon in the hottest part of the year and in mid-mornings and mid-evenings in the coldest part of the year. This makes the power requirements vary by the season and the time of day. Distribution system designs always take the base load and the peak load into consideration.
The transmission system usually does not have a large buffering capability to match the loads with the generation. Thus generation has to be kept matched to the load, to prevent overloading failures of the generation equipment.
Multiple sources and loads can be connected to the transmission system and they must be controlled to provide orderly transfer of power. In centralized power generation, only local control of generation is necessary, and it involves synchronization of the generation units, to prevent large transients and overload conditions.
In distributed power generation the generators are geographically distributed and the process to bring them online and offline must be carefully controlled. The load control signals can either be sent on separate lines or on the power lines themselves. Voltage and frequency can be used as signalling mechanisms to balance the loads.
In voltage signaling, the variation of voltage is used to increase generation. The power added by any system increases as the line voltage decreases. This arrangement is stable in principle. Voltage-based regulation is complex to use in mesh networks, since the individual components and setpoints would need to be reconfigured every time a new generator is added to the mesh.
In frequency signaling, the generating units match the frequency of the power transmission system. In droop speed control, if the frequency decreases, the power is increased. (The drop in line frequency is an indication that the increased load is causing the generators to slow down.)
Wind turbines, vehicle-to-grid and other distributed storage and generation systems can be connected to the power grid, and interact with it to improve system operation.
Failure protection.
Under excess load conditions, the system can be designed to fail gracefully rather than all at once. Brownouts occur when the supply power drops below the demand. Blackouts occur when the supply fails completely.
Rolling blackouts (also called load shedding) are intentionally engineered electrical power outages, used to distribute insufficient power when the demand for electricity exceeds the supply.
Communications.
Operators of long transmission lines require reliable communications for control of the power grid and, often, associated generation and distribution facilities. Fault-sensing protective relays at each end of the line must communicate to monitor the flow of power into and out of the protected line section so that faulted conductors or equipment can be quickly de-energized and the balance of the system restored. Protection of the transmission line from short circuits and other faults is usually so critical that common carrier telecommunications are insufficiently reliable, and in remote areas a common carrier may not be available. Communication systems associated with a transmission project may use:
Rarely, and for short distances, a utility will use pilot-wires strung along the transmission line path. Leased circuits from common carriers are not preferred since availability is not under control of the electric power transmission organization.
Transmission lines can also be used to carry data: this is called power-line carrier, or PLC. PLC signals can be easily received with a radio for the long wave range.
Optical fibers can be included in the stranded conductors of a transmission line, in the overhead shield wires. These cables are known as optical ground wire ("OPGW"). Sometimes a standalone cable is used, all-dielectric self-supporting ("ADSS") cable, attached to the transmission line cross arms.
Some jurisdictions, such as Minnesota, prohibit energy transmission companies from selling surplus communication bandwidth or acting as a telecommunications common carrier. Where the regulatory structure permits, the utility can sell capacity in extra dark fibers to a common carrier, providing another revenue stream.
Electricity market reform.
Some regulators regard electric transmission to be a natural monopoly and there are moves in many countries to separately regulate transmission (see electricity market).
Spain was the first country to establish a regional transmission organization. In that country, transmission operations and market operations are controlled by separate companies. The transmission system operator is Red Eléctrica de España (REE) and the wholesale electricity market operator is Operador del Mercado Ibérico de Energía – Polo Español, S.A. (OMEL) [http://www.omel.es]. Spain's transmission system is interconnected with those of France, Portugal, and Morocco.
In the United States and parts of Canada, electrical transmission companies operate independently of generation and distribution companies.
Cost of electric power transmission.
The cost of high voltage electricity transmission (as opposed to the costs of electric power distribution) is comparatively low, compared to all other costs arising in a consumer's electricity bill. In the UK, transmission costs are about 0.2p/kWh compared to a delivered domestic price of around 10p/kWh.
Research evaluates the level of capital expenditure in the electric power T&D equipment market will be worth $128.9bn in 2011.
Merchant transmission.
Merchant transmission is an arrangement where a third party constructs and operates electric transmission lines through the franchise area of an unrelated utility.
Operating merchant transmission projects in the United States include the Cross Sound Cable from Shoreham, New York to New Haven, Connecticut, Neptune RTS Transmission Line from Sayreville, N.J., to Newbridge, N.Y, and Path 15 in California. Additional projects are in development or have been proposed throughout the United States, including the Lake Erie Connector, an underwater transmission line proposed by ITC Holdings Corp., connecting Ontario to load serving entities in the PJM Interconnection region.
There is only one unregulated or market interconnector in Australia: Basslink between Tasmania and Victoria. Two DC links originally implemented as market interconnectors, Directlink and Murraylink, have been converted to regulated interconnectors. NEMMCO
A major barrier to wider adoption of merchant transmission is the difficulty in identifying who benefits from the facility so that the beneficiaries will pay the toll. Also, it is difficult for a merchant transmission line to compete when the alternative transmission lines are subsidized by other utility businesses.
Health concerns.
Some large studies, including a large United States study, have failed to find any link between living near power lines and developing any sickness or diseases, such as cancer. A 1997 study found that it did not matter how close one was to a power line or a sub-station, there was no increased risk of cancer or illness.
The mainstream scientific evidence suggests that low-power, low-frequency, electromagnetic radiation associated with household currents and high transmission power lines does not constitute a short or long term health hazard. Some studies, however, have found statistical correlations between various diseases and living or working near power lines. No adverse health effects have been substantiated for people not living close to powerlines.
There are established biological effects for acute "high" level exposure to magnetic fields well above 100 µT (1 G). In a residential setting, there is "limited evidence of carcinogenicity in humans and less than sufficient evidence for carcinogenicity in experimental animals", in particular, childhood leukemia, "associated with" average exposure to residential power-frequency magnetic field above 0.3 µT (3 mG) to 0.4 µT (4 mG). These levels exceed average residential power-frequency magnetic fields in homes, which are about 0.07 µT (0.7 mG) in Europe and 0.11 µT (1.1 mG) in North America.
The Earth's natural geomagnetic field strength varies over the surface of the planet between 0.035 mT - 0.07 mT (35 µT - 70 µT or 0.35 G - 0.7 G) while the International Standard for the continuous exposure limit is set at 40 mT (40,000 µT or 400 G) for the general public.
Tree Growth Regulator and Herbicide Control Methods may be used in transmission line right of ways which may have health effects.
United States government policy.
Historically, local governments have exercised authority over the grid and have significant disincentives to encourage actions that would benefit states other than their own. Localities with cheap electricity have a disincentive to encourage making interstate commerce in electricity trading easier, since other regions will be able to compete for local energy and drive up rates. For example, some regulators in Maine do not wish to address congestion problems because the congestion serves to keep Maine rates low. Further, vocal local constituencies can block or slow permitting by pointing to visual impact, environmental, and perceived health concerns. In the US, generation is growing four times faster than transmission, but big transmission upgrades require the coordination of multiple states, a multitude of interlocking permits, and cooperation between a significant portion of the 500 companies that own the grid. From a policy perspective, the control of the grid is balkanized, and even former energy secretary Bill Richardson refers to it as a "third world grid". There have been efforts in the EU and US to confront the problem. The US national security interest in significantly growing transmission capacity drove passage of the 2005 energy act giving the Department of Energy the authority to approve transmission if states refuse to act. However, soon after the Department of Energy used its power to designate two National Interest Electric Transmission Corridors, 14 senators signed a letter stating the DOE was being too aggressive.
Special transmission.
Grids for railways.
In some countries where electric locomotives or electric multiple units run on low frequency AC power, there are separate single phase traction power networks operated by the railways. Prime examples are countries in Europe (including Austria, Germany and Switzerland) which utilize the older AC technology based on 16 2/3 Hz (Norway and Sweden also use this frequency but use conversion from the 50Hz public supply; Sweden has a 16 2/3 Hz traction grid but only for part of the system).
Superconducting cables.
High-temperature superconductors (HTS) promise to revolutionize power distribution by providing lossless transmission of electrical power. The development of superconductors with transition temperatures higher than the boiling point of liquid nitrogen has made the concept of superconducting power lines commercially feasible, at least for high-load applications. It has been estimated that the waste would be halved using this method, since the necessary refrigeration equipment would consume about half the power saved by the elimination of the majority of resistive losses. Some companies such as Consolidated Edison and American Superconductor have already begun commercial production of such systems. In one hypothetical future system called a SuperGrid, the cost of cooling would be eliminated by coupling the transmission line with a liquid hydrogen pipeline.
Superconducting cables are particularly suited to high load density areas such as the business district of large cities, where purchase of an easement for cables would be very costly.
Single wire earth return.
Single-wire earth return (SWER) or single wire ground return is a single-wire transmission line for supplying single-phase electrical power for an electrical grid to remote areas at low cost. It is principally used for rural electrification, but also finds use for larger isolated loads such as water pumps. Single wire earth return is also used for HVDC over submarine power cables.
Wireless power transmission.
Both Nikola Tesla and Hidetsugu Yagi attempted to devise systems for large scale wireless power transmission in the late 1800s and early 1900s, with no commercial success.
In November 2009, LaserMotive won the NASA 2009 Power Beaming Challenge by powering a cable climber 1 km vertically using a ground-based laser transmitter. The system produced up to 1 kW of power at the receiver end. In August 2010, NASA contracted with private companies to pursue the design of laser power beaming systems to power low earth orbit satellites and to launch rockets using laser power beams.
Wireless power transmission has been studied for transmission of power from solar power satellites to the earth. A high power array of microwave or laser transmitters would beam power to a rectenna. Major engineering and economic challenges face any solar power satellite project.
Security of control systems.
The Federal government of the United States admits that the power grid is susceptible to cyber-warfare. The United States Department of Homeland Security works with industry to identify vulnerabilities and to help industry enhance the security of control system networks, the federal government is also working to ensure that security is built in as the U.S. develops the next generation of 'smart grid' networks.
See also.
General:
Electricity market:
Transport:
Technical:
References.
Notes
External links.
Maps

</doc>
<doc id="38826" url="https://en.wikipedia.org/wiki?curid=38826" title="Wenceslaus IV of Bohemia">
Wenceslaus IV of Bohemia

Wenceslaus (also "Wenceslas"; ; , nicknamed "der Faule" ("the Idle"); 26 February 1361 – 16 August 1419) was, by inheritance, King of Bohemia (as "Wenceslaus IV") from 1363 and by election, German King (formally King of the Romans) from 1376. He was the third Bohemian and third German monarch of the Luxembourg dynasty. Wenceslaus was deposed in 1400 as King of the Romans, but continued to rule as Bohemian king until his death.
Biography.
Wenceslaus was born in the Imperial city of Nuremberg, the son of Emperor Charles IV by his third wife Anna von Schweidnitz, a scion of the Silesian Piasts, and baptized at St. Sebaldus Church. He was raised by the Prague Archbishops Arnošt of Pardubice and Jan Očko z Vlašimi. His father had the two-year-old crowned King of Bohemia in 1363 and in 1373 also obtained for him the Electoral Margraviate of Brandenburg. When in 1376 Charles IV asserted Wenceslaus' election as King of the Romans by the prince-electors, two of seven votes, those of Brandenburg and Bohemia, were held by the emperor and his son themselves.
In order to secure the election of his son, Charles IV revoked the privileges of many Imperial Cities that he had earlier granted, and mortgaged them to various nobles. The cities, however, were not powerless, and as executors of the public peace, they had developed into a potent military force. Moreover, as Charles IV had organised the cities into leagues, he had made it possible for them to cooperate in large-scale endeavors. Indeed, on 4 July 1376, two days after Wenceslaus' election, fourteen Swabian cities bound together into the independent Swabian League of Cities to defend their rights against the newly elected King, attacking the lands of Eberhard II, Count of Württemberg. The city league soon attracted other members and until 1389 acted as an autonomous state within the Empire.
Rule.
On Charles's death in 1378, Wenceslaus inherited the Crown of Bohemia and as Emperor-elect assumed the government of the Holy Roman Empire. In the cathedral of Monza there is preserved a series of reliefs depicting the coronations of the kings of Italy with the Iron Crown of Lombardy. The seventh of these depicts Wenceslaus being crowned in the presence of six electors, he himself being the seventh. The depiction is probably not accurate and was likely made solely to reinforce the claims of the cathedral on the custody of the Iron Crown.
In 1387 a quarrel between Frederick, Duke of Bavaria, and the cities of the Swabian League allied with the Archbishop of Salzburg gave the signal for a general war in Swabia, in which the cities, weakened by their isolation, mutual jealousies and internal conflicts, were defeated by the forces of Eberhard II, Count of Württemberg, at Döffingen, near Gafenau, on 24 August 1388. The cities were taken severally and devastated. Most of them quietly acquiesced when King Wenceslaus proclaimed an ambivalent arrangement at Cheb ("Eger") in 1389 that prohibited all leagues between cities, while confirming their political autonomy. This settlement provided a modicum of stability for the next several decades, however the cities dropped out as a basis of the central Imperial authority.
King of Bohemia.
During his long reign, Wenceslaus held a tenuous grip on power at best, as he came into repeated conflicts with the Bohemian nobility led by the House of Rosenberg. On two occasions he was even imprisoned for lengthy spells by rebellious nobles.
But the greatest liability for Wenceslaus proved to be his own family. Charles IV had divided his holdings among his sons and other relatives. Although Wenceslaus upon his father's death retained Bohemia, his younger half-brother Sigismund inherited Brandenburg, while John received the newly established Duchy of Görlitz in Upper Lusatia. The March of Moravia was divided between his cousins Jobst and Procopius, and his uncle Wenceslaus I was made Duke of Luxembourg. Hence the young king was left without the resources his father had enjoyed. In 1386, Sigismund became king of Hungary and became involved in affairs further east.
Wenceslaus also faced serious opposition from the Bohemian nobles and even from his chancellor, the Prague archbishop Jan of Jenštejn. In a conflict surrounding the investiture of the abbot of Kladruby, the torture and murder of the archbishop's vicar-general John of Nepomuk by royal officials in 1393 sparked a noble rebellion. In 1394 Wenceslaus' cousin Jobst of Moravia was named regent, while Wenceslaus was arrested at Králův Dvůr. King Sigismund of Hungary arranged a truce in 1396, and for his efforts he was recognized as heir to Wenceslaus.
In the Papal Schism, Wenceslaus had supported Pope Urban VI. As Bohemian king he sought to protect the religious reformer Jan Hus and his followers against the demands of the Roman Catholic Church for their suppression as heretics. This caused many Germans to withdraw from the University of Prague, and set up their own university at Leipzig. Hus was executed in Konstanz in 1415, and the rest of Wenceslaus's reign in Bohemia featured precursors of the Hussite Wars that would follow his death during the Defenestrations of Prague.
Dethronement.
In view of his troubles in Bohemia, Wenceslaus did not seek a coronation ceremony as Holy Roman Emperor and was long absent from the German lands. Consequently, he faced anger at the "Reichstag" diets of Nuremberg (1397) and Frankfurt (1398). The four Rhenish electors, Count Palatine Rupert III and the Archbishops of Mainz, Cologne and Trier, accused him of failing to maintain the public peace or to resolve the Schism. They demanded that Wenceslaus appear before them to answer to the charges in June 1400. Wenceslaus demurred, in large part because of renewed hostilities in Bohemia. When he failed to appear, the electors meeting at Lahneck Castle declared him deposed on 20 August 1400 on account of "futility, idleness, negligence and ignobility". The next day they chose the Palatine Elector as their king at Rhens, though Wenceslaus refused to acknowledge this successor's decade-long reign.
In 1402 Wenceslaus was again imprisoned and temporarily deposed, this time by his younger brother Sigismund, with the support of the Czech nobility. Lord John of Liechtenstein, with his retinue of knights, successfully freed Wenceslaus from his Vienna prison in autumn of 1403 and accorded him refuge in his Moravian castle. John of Liechtenstein was at the time the Lord of the Mikulov demesne.
Among the charges raised by Ruprecht III as the basis for his predecessor's deposition was the Papal Schism. King Ruprecht called the Council of Pisa in 1409, attended by defectors from both papal parties. They elected Antipope Alexander V, worsening the situation because he was not acknowledged by his two rivals, and from 1409 to 1417 there were three popes.
After the death of Ruprecht in 1410, his succession at first proved difficult, as both Wenceslaus' cousin Jobst of Moravia and Wenceslaus' brother Sigismund of Hungary were elected King of the Romans. Wenceslaus himself had never recognized his deposition and hence still claimed the kingship. Jobst died in 1411, and Wenceslaus agreed to give up the crown, so long as he could keep Bohemia. This settled the issue, and after 1411 Sigismund reigned as king and later also became Holy Roman Emperor.
The bishops and secular leaders, tired of the Great Schism, supported Sigismund when he called the Council of Constance in 1414. The goal of the council was to reform the church in head and members. What made it work was the translation of supreme authority from the popes to the council. In 1417, the council deposed all three popes and elected a new one, maintaining all the while that the council, and not the pope, was the supreme head of the church. By resolving the schism, Sigismund restored the honour of the imperial title and made himself the most influential monarch in the west.
Personal life.
Wenceslaus was married twice, first to Joanna of Bavaria, a scion of the Wittelsbach dynasty, on 29 September 1370. Following her death on 31 December 1386 (allegedly mangled by one of Wenceslaus' beloved deer-hounds), he married her first cousin once removed, Sofia of Bavaria, on 2 May 1389. He had no children by either wife.
Wencelaus was described as a man of great knowledge and is known for the Wenzel Bible, a richly illuminated manuscript he had drawn up between 1390 and 1400. However, his rule remained uncertain, varying between idleness and cruel measures as in the case of John of Nepomuk. Unlike his father, Wenceslaus relied on favouritism, which made him abhorrent to many nobles and led to increasing isolation. Moreover he probably suffered from alcoholism, which was brought to light in 1398 when he was unable to accept an invitation by King Charles VI of France for a reception at Reims due to his drunkenness.
Wenceslaus died in 1419 of a heart attack during a hunt in the woods surrounding his castle Nový Hrad at Kunratice (today a part of Prague), leaving the country in a deep political crisis. His death was followed by almost two decades of conflict called the Hussite Wars, which were centred on greater calls for religious reform by Jan Hus and spurred by popular outrage provoked from his martyrdom.
External links.
58

</doc>
<doc id="38828" url="https://en.wikipedia.org/wiki?curid=38828" title="Michael Bloomberg">
Michael Bloomberg

Michael Rubens Bloomberg, KBE (born February 14, 1942) is an American business magnate, politician, and philanthropist. Bloomberg served as the 108th Mayor of New York City, holding office for three consecutive terms, beginning with his first election in 2001. With a net worth of $43.7 billion, Bloomberg is the 6th-wealthiest person in the United States, and the 8th-wealthiest in the world. Bloomberg is the founder, CEO, and owner of Bloomberg L.P., the global financial data and media company that bears his name and is notable for its Bloomberg Terminal, which is widely used by investment professionals around the world.
Bloomberg began his career at the securities brokerage Salomon Brothers, before forming his own company in 1981 and spending the next twenty years as its Chairman and CEO. Bloomberg also served as Chairman of the Board of Trustees at his alma mater Johns Hopkins University from 1996 to 2002. A Democrat before seeking elective office, Bloomberg switched his party registration in 2001 to run for Mayor as a Republican. Bloomberg defeated opponent Mark Green in a close election held just weeks after the September 11 terrorist attacks. Bloomberg won a second term in 2005, and left the Republican Party two years later. Bloomberg campaigned to change the city's term limits law, and was elected to his third term in 2009 as an Independent candidate on the Republican ballot line.
Bloomberg was frequently mentioned as a possible candidate for the U.S. Presidential elections in 2008, and 2012, as well as for Governor of New York in 2010. Bloomberg declined to seek either office, instead opting to continue serving as the Mayor of New York City. On January 1, 2014, Bill de Blasio succeeded Bloomberg as the Mayor of New York City. After a brief stint as a full-time philanthropist, Bloomberg re-assumed the position of CEO at Bloomberg L.P. the end of 2014. On March 7, 2016, Bloomberg announced that he would not run as a third party candidate in the 2016 Presidential election.
Early life.
Michael Bloomberg was born at St. Elizabeth's Hospital, in the Brighton neighborhood of Boston, on February 14, 1942. Bloomberg's family is Jewish. Bloomberg's father, William Henry Bloomberg (1906–1963), was a bookkeeper for a dairy company and the son of Alexander "Elick" Bloomberg, an immigrant from Russia. His mother, Charlotte (Rubens) Bloomberg (January 2, 1909 – June 19, 2011), was a native of Jersey City, New Jersey. His maternal grandfather, Max Rubens, was an immigrant from present-day Belarus, then also part of Russia.
The family lived in Allston, Massachusetts, until Bloomberg was two years old. They moved to Brookline, Massachusetts, for the next two years, finally settling in Medford, a Boston suburb, where he lived until after he graduated from college. Bloomberg is an Eagle Scout.
Bloomberg attended Johns Hopkins University, where he joined the fraternity Phi Kappa Psi. In 1962, as a sophomore, he constructed the school's mascot, the blue jay. He graduated in 1964 with a Bachelor of Science degree in electrical engineering. In 1966 he graduated from Harvard Business School with a Master of Business Administration.
Business career.
In 1973, Bloomberg became a general partner at Salomon Brothers, a bulge-bracket Wall Street investment bank, where he headed equity trading and, later, systems development. In 1981, Salomon Brothers was bought by Phibro Corporation, and Bloomberg was laid off from the investment bank and given a $10 million severance package. Using this money, Bloomberg went on to set up a company named Innovative Market Systems. His business plan was based on the realization that Wall Street (and the financial community generally) was willing to pay for high-quality business information, delivered as quickly as possible and in as many usable forms possible, via technology (e.g., graphs of highly specific trends). In 1982, Merrill Lynch became the new company's first customer, installing 22 of the company's Market Master terminals and investing $30 million in the company. The company was renamed Bloomberg L.P. in 1987. By 1990, it had installed 8,000 terminals. Over the years, ancillary products including Bloomberg News, Bloomberg Message, and Bloomberg Tradebook were launched.
As of October 2015, the company had more than 325,000 terminal subscribers worldwide. His company also has a radio network which currently has its flagship station as 1130 WBBR AM in New York City. He left the position of CEO to pursue a political career as the mayor of New York City. Bloomberg was replaced as CEO by Lex Fenwick. During Bloomberg's three mayoral terms, the company was led by president Daniel L. Doctoroff, a former deputy mayor under Bloomberg.
After completing his final term as the mayor of New York City, Bloomberg spent his first eight months out of office as a full-time philanthropist. In the fall of 2014, he announced that he would return to Bloomberg L.P. as CEO at the end of 2014, succeeding Doctoroff, who had led the company since retiring from the Bloomberg administration in February 2008. Bloomberg remains the CEO of Bloomberg L.P.
Bloomberg is a member of Kappa Beta Phi.
Bloomberg wrote an autobiography, with help from Bloomberg News Editor-in-Chief Matthew Winkler, called "Bloomberg by Bloomberg".
Wealth.
In September 2013, Forbes reported Bloomberg's wealth as $33 billion and ranked him as the 13th richest person in the world. In March 2012, Forbes reported Bloomberg's wealth at $22 billion, ranking him 20th in the world and 11th in the United States. In March 2009, Forbes reported Bloomberg's wealth at $16 billion, a gain of $4.5 billion over the previous year, enjoying the world's biggest increase in wealth in 2009. At that time, there were only four fortunes in the U.S. that were larger (although the Wal-Mart family fortune is split among four people). He moved from 142nd to 17th in the "Forbes" list of the world's billionaires in only two years (March 2007 – March 2009). As of September 2015, his net worth is $41.1 billion, making him the 6th-richest person in the United States and the 8th-wealthiest in the world.
Mayoralty.
Bloomberg assumed office as the 108th Mayor of New York City on January 1, 2002. He won re-election in 2005 and again in 2009. As mayor, Bloomberg initially struggled to gain high approval levels from the public; however, he subsequently developed and maintained high approval ratings.
Bloomberg's re-election meant the Republicans had won the previous four mayoral elections (although Bloomberg's decision to leave the Republican Party and be declared an independent on June 19, 2007, resulted in the Republican Party's losing the mayor's seat prior to the expiration of his second term). Bloomberg joined Rudy Giuliani and Fiorello La Guardia as re-elected Republican mayors in the mostly Democratic city. (John Lindsay was also elected mayor of New York City twice while a registered Republican; however, Lindsay did not receive the Republican Party nomination during his 1969 campaign for re-election but ran successfully on the Liberal ticket and joined the Democratic Party during his second term.)
Bloomberg said that he wanted public education reform to be the legacy of his first term and addressing poverty to be the legacy of his second. Some have alleged that he made certain decisions regarding the closure of 17 day-care centers across the city for political reasons. According to the National Assessment of Educational Performance, fourth-grade reading scores from 2002 through 2009 rose nationally by 11 points. However, on May 10, 2010, "The New York Times" reported:According to the test New York City eighth graders have shown no significant improvement [in math or reading since they began taking it in 2003, mirroring the largely flat performance of American eighth graders as a whole during that period. In the city, the lack of improvement held true across ethnic groups and also among lower-income students.
Some have seen this approach to the New York education system as largely unsuccessful because of skewed numbers. Under the reformed approach, a school must do better than the previous year to receive funding. Because of this requirement, many successful schools were closed for being "unsuccessful" because of their inability to raise test scores, even though they were the top performing schools, while many unsuccessful schools received the bulk of funding for simply raising their scores slightly.
Bloomberg has chosen to apply a statistical, results-based approach to city management, appointing city commissioners based on their expertise and granting them wide autonomy in their decision-making. Breaking with 190 years of tradition, he implemented what "New York Times" political reporter Adam Nagourney called a "bullpen" open office plan, similar to a Wall Street trading floor, in which dozens of aides and managerial staff are seated together in a large chamber. The design is intended to promote accountability and accessibility.
In efforts to create "cutbacks" in the New York City Spending Bracket, Bloomberg declined to receive a city salary. He accepted a remuneration of $1 annually for his services. He maintains a public listing in the New York City phone directory, and during his term as mayor, he lived not in Gracie Mansion – the official mayoral residence – but instead at his own home on the Upper East Side of Manhattan. He owns additional homes in London, Bermuda and Vail, Colorado.
Bloomberg stated that during his mayoralty, he rode the New York City Subway on a daily basis, particularly in the commute from his 79th Street home to his office at City Hall. An August 2007 story in "The New York Times" asserted that he was often seen chauffeured by two New York Police Department-owned SUVs to an express train station to avoid having to change from the local to the express trains on the IRT Lexington Avenue Line. He also supported the construction of the 7 Subway Extension and the Second Avenue Subway; on December 20, 2013, Bloomberg took a ceremonial ride on a train to the new 34th Street station to celebrate a part of his legacy as mayor.
Elections.
2001 election.
In 2001, the incumbent mayor of New York City, Rudy Giuliani, was ineligible for re-election, as the city limited the mayoralty to two consecutive terms. Several well-known New York City politicians aspired to succeed him. Bloomberg, a lifelong member of the Democratic Party, decided to run for mayor as a member of the Republican Party ticket.
Voting in the primary began on the morning of September 11, 2001. The primary was postponed later that day. In the rescheduled primary, Bloomberg defeated Herman Badillo, a former Congressman, to become the Republican nominee. Meanwhile, the Democratic primary did not produce a first-round winner. After a runoff, the Democratic nomination went to New York City Public Advocate Mark J. Green.
In the general election, Bloomberg received Giuliani's endorsement. He also had a huge spending advantage. Although New York City's campaign finance law restricts the amount of contributions which a candidate can accept, Bloomberg chose not to use public campaign funds and therefore his campaign was not subject to these restrictions. He spent $73 million of his own money on his campaign, outspending Green five to one. One of the major themes of his campaign was that, with the city's economy suffering from the effects of the World Trade Center attacks, it needed a mayor with business experience.
In addition to serving as the Republican nominee, Bloomberg had the ballot line of the controversial Independence Party, in which "Social Therapy" leaders Fred Newman and Lenora Fulani exert strong influence. Some say that endorsement was important, as Bloomberg's votes on that line exceeded his margin of victory over Green. (Under New York's fusion rules, a candidate can run on more than one party's line and combine all the votes received on all lines. Green, the Democrat, also had the ballot line of the Working Families Party. He also created an independent line called Students First whose votes were combined with those on the Independence line). Another factor was the vote in Staten Island, which has traditionally been far friendlier to Republicans than the rest of the city. Bloomberg handily beat Green in that borough, taking 75 percent of the vote there. Overall, Bloomberg won 50 percent to 48 percent.
Bloomberg's election marked the first time in New York City history that two different Republicans had been elected mayor consecutively. New York City has not been won by a Republican in a presidential election since Calvin Coolidge won in 1924. Bloomberg is considered a social liberal, who is pro-choice, in favor of legalizing same-sex marriage and an advocate for stricter gun control laws.
Despite the fact that 68 percent of New York City's registered voters are Democrats, Bloomberg decided the city should host the 2004 Republican National Convention. The Convention drew thousands of protesters, many of them local residents angry over the Iraq war and other issues. The New York Police Department arrested approximately 1,800 protesters, but according to "The New York Times", more than 90 percent of the cases were later dismissed or dropped for lack of evidence.
2005 election.
Bloomberg was re-elected mayor in November 2005 by a margin of 20 percent, the widest margin ever for a Republican mayor of New York City.
Bloomberg spent almost $78 million on his campaign, exceeding the record of $74 million he spent on the previous election. In late 2004 or early 2005, Bloomberg gave the Independence Party of New York $250,000 to fund a phone bank seeking to recruit volunteers for his re-election campaign.
Former Bronx Borough President Fernando Ferrer won the Democratic nomination to oppose Bloomberg in the general election. Thomas Ognibene sought to run against Bloomberg in the Republican Party's primary election. Bloomberg's campaign successfully challenged enough of the signatures Ognibene had submitted to the Board of Elections to prevent Ognibene from appearing on ballots for the Republican primary. Instead, Ognibene ran only on the Conservative Party ticket. Ognibene accused Bloomberg of betraying Republican Party ideals, a feeling echoed by others.
Bloomberg opposed the confirmation of John Roberts as Chief Justice of the United States. Though a Republican at the time, Bloomberg is a staunch supporter of abortion rights and did not believe that Roberts was committed to maintaining "Roe v. Wade".
In addition to receiving Republican support, Bloomberg obtained the endorsements of several prominent Democrats: former Democratic Mayor Ed Koch; former Democratic governor Hugh Carey; former Democratic City Council Speaker Peter Vallone, and his son, Councilman Peter Vallone, Jr.; former Democratic Congressman Floyd Flake (who had previously endorsed Bloomberg in 2001), and Brooklyn Borough President Marty Markowitz.
2009 election.
On October 2, 2008, Bloomberg announced he would seek to extend the city's term limits law and run for a third mayoral term in 2009, arguing a leader of his field was needed following the financial crisis of 2007–08. "Handling this financial crisis while strengthening essential services ... is a challenge I want to take on," Bloomberg said at a news conference. "So should the City Council vote to amend term limits, I plan to ask New Yorkers to look at my record of independent leadership and then decide if I have earned another term." Ronald Lauder, who wrote New York City's term limits in 1993 and spent over 4 million dollars of his own money to limit the maximum years a mayor could serve to 8 years, in exchange, was promised a seat on an influential board by Michael Bloomberg. He agreed to stay out of future legality issues and sided with Bloomberg in running for a third term. Some people and organizations objected and NYPIRG filed a complaint with the City Conflict of Interest Board. On October 23, 2008, the City Council voted 29–22 in favor of extending the term limit to three consecutive four-year terms, thus allowing Bloomberg to run for office again. After two days of public hearings, Bloomberg signed the bill into law on November 3.
Bloomberg's bid for a third term generated some controversy. Civil libertarians such as former New York Civil Liberties Union Director Norman Siegel and New York Civil Rights Coalition Executive Director Michael Meyers joined with local politicians such as New York State Senator Eric Adams to protest the term limits extension.
Bloomberg's opponent was Democratic and Working Families Party nominee Bill Thompson, who had been New York City Comptroller for the past eight years and before that, President of the New York City Board of Education. Bloomberg defeated Thompson by a vote of 51% to 46%.
After the release of Independence Party campaign filings in January 2010, it was reported that Bloomberg had made two $600,000 contributions from his personal account to the Independence Party on October 30 and November 2, 2009. The Independence Party then paid $750,000 of that money to Republican Party political operative John Haggerty Jr.
This prompted an investigation beginning in February 2010 by the office of New York County District Attorney Cyrus Vance, Jr. into possible improprieties. The Independence Party later questioned how Haggerty spent the money, which was to go to poll-watchers. Former New York State Senator Martin Connor contended that because the Bloomberg donations were made to an Independence Party housekeeping account rather than to an account meant for current campaigns, this was a violation of campaign finance laws. Haggerty also spent money from a separate $200,000 donation from Bloomberg on office space.
2013 election endorsements.
On September 13, 2013, Bloomberg announced that he would not endorse any of then current candidates to succeed him. On his radio show, he stated, "I don't want to do anything that complicates it for the next mayor. And that's one of the reasons I've decided I'm just not going to make an endorsement in the race." He added, "I want to make sure that person is ready to succeed, to take what we've done and build on that."
Prior to the announcement in an interview in "New York" magazine, Bloomberg praised the "New York Times" for its endorsement of Christine Quinn and Joe Lhota as their favorite candidates in the Democratic and Republican primaries. Quinn came in third in the Democratic primary and Lhota won the Republican primary.
Earlier in the month, Bloomberg was chastised in the press for his remarks regarding Democratic mayoral candidate Bill de Blasio's campaign methods. Bloomberg said initially in the "New York" magazine interview that he considered de Blasio's campaign "racist" and when asked about his comment, Bloomberg explained what he meant by his remark.
Well, no, no, I mean he's making an appeal using his family to gain support. I think it's pretty obvious to anyone watching what he's been doing. I do not think he himself is racist. It's comparable to me pointing out I'm Jewish in attracting the Jewish vote. You tailor messages to your audiences and address issues you think your audience cares about.
On January 1, 2014, de Blasio became New York City's new mayor, succeeding Bloomberg.
Political stance.
Some of the policies Bloomberg advocates parallel those of either the Democratic or the Republican party platform. He is socially liberal or progressive, supporting abortion rights, same-sex marriage, strict gun control measures, and citizenship for illegal immigrants, for example. On economics, foreign, and domestic issues, Bloomberg tends to be conservative. He opposed a timeline for withdrawal from the Iraq War, and criticized those who favored one. Economically, he supports government involvement in issues such as public welfare, while being strongly in favor of free trade, pro-business, and describing himself as a fiscal conservative because he balanced the city's budget. He is concerned about climate change and has touted his mayoral efforts to reduce greenhouse gasses. Bloomberg has been cited for not allowing many emergency officials who responded to the September 11, 2001, attacks to attend the tenth anniversary observation of that day. He also is at odds with many around the United States for not inviting any clergy to the ceremony marking the anniversary of the 9/11 attacks.
Social issues.
Bloomberg supports abortion rights, stating, "Reproductive choice is a fundamental human right and we can never take it for granted. On this issue, you're either with us or against us." He has criticized pro-choice politicians who support pro-life candidates.
Bloomberg supports governmental funding for embryonic stem cell research, calling the Republican position on the issue "insanity". He also supports same-sex marriage with the rationale that "government shouldn't tell you whom to marry."
Bloomberg supports the strict drug laws of New York City. He has stated that he smoked marijuana in the past, and was quoted in a 2001 interview as saying "You bet I did. I enjoyed it." This led to a reported $500,000 advertising campaign by NORML, featuring his image and the quote. Bloomberg stated in a 2002 interview that he regrets the remark and does not believe that marijuana should be decriminalized.
Crime and punishment.
In April 2006, along with Boston mayor Thomas Menino, Bloomberg co-founded Mayors Against Illegal Guns. A December 2013 press release by the group said the bipartisan coalition included over 1,000 mayors.
As mayor, Bloomberg increased the mandatory minimum sentence for illegal possession of a loaded handgun, saying: "Illegal guns don't belong on our streets and we're sending that message loud and clear. We're determined to see that gun dealers who break the law are held accountable, and that criminals who carry illegal loaded guns serve serious time behind bars." He opposes the death penalty, saying he would "rather lock somebody up and throw away the key and put them in hard labor."
Education.
Bloomberg replaced the school board set up by the state with direct mayoral control over public education. He raised the salaries of teachers by fifteen percent while the test scores of students in the city and the graduation rate rose as well. He is opposed to social promotion, stating that students should be promoted only when they are adequately prepared for the next grade level. He favors after-school programs to help students who are behind. As mayor, Bloomberg strengthened the cell-phone ban in schools.
Environmental issues.
During his second term as the mayor of New York City, Bloomberg unveiled PlaNYC: A Greener, Greater New York on April 22, 2007 to fight global warming, protect the environment and prepare for the projected 1 million additional people expected to be living in the city by the year 2030. Under PlaNYC, in just 6 years New York City reduced citywide greenhouse gas emissions by 19% since 2005 and was on track to achieve a 30% reduction ahead of the PlaNYC 2030 goal. In October 2007 as part of PlaNYC, Bloomberg launched the Million Trees NYC initiative, which aimed to plant and care for one million trees throughout the city in the next decade. In November 2015, New York City planted its one millionth tree, two years ahead of the original 10-year schedule.
In 2008, Bloomberg convened the New York City Panel on Climate Change (NPCC), an effort to prepare the city for climate change. In 2012, "Travel + Leisure" readers voted New York City the "Dirtiest American City," for having the most extant litter. Bloomberg has been involved in motivating other cities to make changes and has spoken about reducing carbon dioxide emissions, using cleaner and more efficient fuels, using congestion pricing in New York City, and encouraging public transportation.
Bloomberg unveiled the Special Initiative for Rebuilding and Resiliency (SIRR) in June 2013, after the city was affected by Hurricane Sandy in October 2012. The $20 billion initiative laid out extensive plans to protect New York City against the impacts of climate change in the future. On September 26, 2013, Bloomberg announced that his administration’s air pollution reduction efforts had resulted in the best air quality in New York City in more than 50 years. The majority of the air quality improvement was attributed to the phasing out of heavy polluting heating oils through New York’s “Clean Heat” program. As a result of the improved air quality, the average life expectancy of New Yorkers had increased three years during Bloomberg's tenure, compared to 1.8 years in the rest of the country.
Immigration.
On issues of domestic and homeland security, Bloomberg has attacked social conservatives on immigration, calling their stance unrealistic: "We're not going to deport 12 million people, so let's stop this fiction. Let's give them permanent status." He supports a federal ID database that uses DNA and fingerprint technology to keep track of all citizens and to verify their legal status. Bloomberg has held that illegal immigrants should be offered legalization and supported the congressional efforts of John McCain and the late Ted Kennedy in their attempt at immigration reform in 2007. Regarding border security, he compared it to the tide, stating, "It's as if we expect border control agents to do what a century of communism could not: defeat the natural market forces of supply and demand... and defeat the natural human desire for freedom and opportunity. You might as well as sit in your beach chair and tell the tide not to come in. As long as America remains a nation dedicated to the proposition that 'all Men are created equal, endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness', people from near and far will continue to seek entry into our country." In 2006, Bloomberg stated on his weekly WABC radio show that illegal immigration does not strain the financial resources of New York City, since many immigrants are hard working and "do not avail themselves of services until their situation is dire".
Health regulations.
In January 2011, city schools began a pilot program which allows girls over 14 years old to be provided with Plan B emergency contraception without parental consent, unless parents opt out in writing. Beginning with five schools, the pilot had been expanded to thirteen schools by September 2012.
In September 2012, the city passed a law limiting the practice of circumcision among orthodox Jews. The legislation requires that at each event, the circumciser receives signed consent forms from the parents, acknowledging that they were notified of health risks associated with cleaning the wound by sucking blood from the male baby's organ. This regulation caused an outcry among the orthodox communities on the infringement of their religious freedom, and the matter was taken to federal court.
During the same month, the NYC Board of Health approved Bloomberg's proposal to ban the sale of many sweetened drinks more than 16 ounces (473 ml.) in volume. The limit would have applied to businesses such as restaurants and movie theaters, but did not apply to grocery stores, including 7-Eleven. Diet varieties of sweetened drinks were unaffected. On March 12, 2013, hours before the ban was scheduled to take effect, State Supreme Court Justice Milton Tingling struck it down, ruling that the Board of Health lacked the jurisdiction to enforce it and that the rule was "arbitrary and capricious". The city appealed the decision. On July 30, the Appellate Division upheld the lower court's ruling, stating the Board of Health "failed to act within the bounds of its lawfully delegated authority" and the ban was a violation of the separation of powers doctrine, which reserves legislative power to the legislature and does not allow the board to "exercise sweeping power to create whatever rule they deem necessary". Bloomberg announced that the city would appeal the decision.
Bloomberg has been criticized for some of his policies which have been described by many as facilitating the creation of a nanny state. Comedian Bill Maher, while on "Jimmy Kimmel Live", said that Bloomberg's soda ban "gives liberals a bad name". Also in response to the soda ban, The Center for Consumer Freedom ran a full-page ad in "The New York Times" featuring an image of Bloomberg's face superimposed on an elderly female body wearing a dress and scarf, with the title "The Nanny", and the tagline "New Yorkers Need a Mayor, Not a Nanny." Others have pointed out the fact that the smoking rate has dropped quickly during Bloomberg's time in office (which has involved the banning of smoking in certain areas).
Criticism of Bloomberg's attempt to ban the sale of large soft drinks was picked up, mostly by Republican and libertarian commentators and politicians, as a line of attack in political campaigns around the United States. In one example, Virginia Attorney General Ken Cuccinelli and Kentucky Senator Rand Paul brought Big Gulps to a joint appearance for Cuccinelli's ultimately unsuccessful 2013 gubernatorial campaign to symbolize Bloomberg's efforts to restrict soft drink sales, criticizing the mayor for wanting "to buy the governor's office down here", a reference to pro-gun control advertisements his political action committee was running in the state. Republican legislators in Wisconsin reacted to the ban by inserting language to prohibit communities from restricting the sale of large soft drinks throughout the state in a 2013 budget bill.
Response to 9/11.
Bloomberg believes that the September 11, 2001 attacks were not intended to be solitary events. When he assumed office, he set up a Counterterrorism Bureau which works along with the NYPD intelligence division to gather information about terrorism affecting New York worldwide. He believes that funding for Homeland Security by the federal government should be distributed by risk, where cities that are considered to have the highest threat for a terrorist attack would get the most money. Bloomberg is also a supporter of the USA PATRIOT Act.
After the April 15, 2013 Boston Marathon bombings, Bloomberg expressed the view that terrorism threats may require a reconsideration of civil liberties, saying "the people who are worried about privacy have a legitimate worry, but we live in a complex world where you're going to have to have a level of security greater than you did back in the olden days, if you will ... our laws and our interpretation of the Constitution, I think, have to change."
Economic issues.
Bloomberg characterizes himself as a fiscal conservative for turning the city's $6 billion deficit into a $3 billion surplus; however, conservative PAC Club for Growth has criticized him because he increased property taxes and spending while doing so.
Bloomberg has expressed a distaste of taxes, stating, "Taxes are not good things, but if you want services, somebody's got to pay for them, so they're a necessary evil." As mayor, he did raise property taxes to fund budget projects; however, in January 2007 he proposed cuts in property taxes by five percent and cuts in sales taxes, including the elimination of taxes on clothing and footwear. Bloomberg pointed to the Wall Street profits and the real estate market as evidence that the city's economy is booming and could handle a tax break.
Bloomberg's self-described fiscal conservatism also led him to eliminate the existing $6-billion deficit when he assumed office. Bloomberg balanced the budget of New York City by raising property taxes and making cuts to city agencies.
Bloomberg is in favor of providing tax breaks to big corporations for the good of the whole community. As mayor, Bloomberg lobbied the CEO of Goldman Sachs to establish its headquarters across from Ground Zero by promising $1.65 billion in tax breaks. Regarding this deal, Bloomberg stated, "This York City is where the best want to live and work. So I told him of Goldman Sachs, 'We can help with minimizing taxes. Minimizing your rent. Improving security. But in the end, this is about people.'"
Bloomberg has had a less cordial relationship with unions as mayor. In 2002, when New York City's transit workers threatened to strike, Bloomberg responded by riding a mountain bike through the city to show how the city could deal with the transit strike by finding alternate means of transportation and not pandering to the unions. Three years later, a clash between Bloomberg and the New York City Transit Authority over wages and union benefits led to a full blown strike that lasted three days. Negotiations led to the end of the strike in December 2005, but controversy exists over Bloomberg's handling of the situation.
Bloomberg is a staunch advocate of free trade and is strongly opposed to protectionism, stating, "The things that we have to worry about is this protectionist movement that has reared its head again in this country..." He worries about the growth of China and fears the lessening gap between the United States and other countries: "The rest of the world is catching up, and, there are people that say, surpassing us. I hope they are wrong. I hope those who think we are still in good shape are right. But nevertheless, the time to address these issues is right now."
Bloomberg has placed a strong emphasis on public health and welfare, adopting many liberal policies. As the mayor he made HIV, diabetes, and hypertension all top priorities. He extended the city's smoking ban to all commercial establishments and implemented a trans fat ban in restaurants. Bloomberg has been a strong supporter of the New York City Health and Hospitals Corporation – the largest urban healthcare agency in the United States – serving over 1.3 million New Yorkers, and has touted its use of information technology and Electronic Health Records to increase efficiency and enhance patient care. He launched a program called Opportunity NYC which is the nation's first-ever conditional cash transfer pilot program designed to help New Yorkers break the cycle of poverty in the city. He instituted a $7.5 billion municipal affordable housing plan, the largest in the nation, that is supposed to provide 500,000 New Yorkers with housing.
Bloomberg has expressed concern about poverty and growing class divisions stating, "This society cannot go forward, the way we have been going forward, where the gap between the rich and the poor keeps growing."
Foreign policy.
As mayor, Bloomberg made trips to Mexico, the United Kingdom, Ireland, and Israel in the first four months of 2007. In late 2007 he conducted an Asia trip that brought him to China, where he called for greater freedom of information to promote innovation. He attended the United Nations Climate Conference in Bali.
Initially, Bloomberg strongly supported the war in Iraq and the rationale for going in. He stated, "Don't forget that the war started not very many blocks from here," alluding to Ground Zero. In regard to the global War on Terrorism including Iraq he said, "It's not only to protect Americans. It's America's responsibility to protect people around the world who want to be free." During the 2004 presidential election campaign, New York City hosted the Republican National Convention at which Bloomberg endorsed President George W. Bush for President of the United States.
His enthusiasm seemed to have lessened somewhat over the course of the war. In August 2005 he said, "I think everybody has very mixed emotions about the war that was started to find weapons of mass destruction and then they were not found." Bloomberg expressed criticism of Democrats in Congress who wanted to set a timetable for withdrawal from Iraq, calling them "irresponsible".
Preservation and development issues.
Bloomberg is a proponent of large-scale development. He has repeatedly come down in favor of projects such as the Atlantic Yards mega-development, the Hudson Yards redevelopment, and the Harlem rezoning proposal. On smaller-scale issues, Bloomberg usually takes the side of development as well. He favors the demolition of Admiral's Row in order to build a supermarket parking lot. However, Bloomberg has occasionally come down on the side of preservation, most notably in vetoing landmark revocation for the Austin Nichols warehouse. This move was widely applauded by architectural historians. The City Council overruled the veto shortly thereafter, however.
Political running.
2008 presidential campaign speculation.
On February 27, 2008, Bloomberg announced that he would not run for president in 2008, and that he would endorse a candidate who takes an independent and non-partisan approach. He had also stated unequivocally, live on "Dick Clark's New Year's Rockin' Eve", December 31, 2007, that he was not going to run for president in 2008. Despite prior public statements by Bloomberg denying plans for a presidential run, many pundits believed Bloomberg would announce a campaign at a later date. On January 7, 2008, he met at the University of Oklahoma with a bipartisan group, including (now former) Nebraska Senator Chuck Hagel and former Georgia Senator Sam Nunn, both of whom had been frequently mentioned as possible running mates – to pressure the major party candidates to promote national unity and reduce partisan gridlock. Speculation that Bloomberg would choose this forum to announce his candidacy proved to be unfounded.
In summer 2006, he met with Al From of the Democratic Leadership Council, a centrist group, to talk about the logistics of a possible run. After a conversation with Bloomberg, Republican Senator Chuck Hagel of Nebraska suggested that he and Bloomberg could run on a shared independent ticket for the presidency.
On "This Week" on June 10, 2007, anchor George Stephanopoulos included panelist Jay Carney, who mentioned a conversation between Bloomberg and top staffers where he heard Bloomberg ask approximately how much a presidential campaign would cost. Carney said that one staffer replied, "Around $500 million." According to a "Washington Post" article, a $500 million budget would allow Bloomberg to circumvent many of the common obstacles faced by third party candidates seeking the White House. On June 19, 2007, Bloomberg left the Republican Party, filing as an independent after a speech criticizing the current political climate in Washington. On August 9, 2007, in an interview with former CBS News anchor Dan Rather that aired on August 21, Bloomberg categorically stated that he was not running for President, that he would not be running, and that there were no circumstances in which he would, saying, "If somebody asks me where I stand, I tell them. And that's not a way to get elected, generally. Nobody's going to elect me president of the United States. What I'd like to do is to be able to influence the dialogue. I'm a citizen."
Despite continued denials, a possible Bloomberg candidacy continued to be the subject of media attention, including a November "Newsweek" cover story. During a private reception in December 2007, Bloomberg conducted a version of bingo in which guests were to guess the meaning of the numbers on a printed card. When Bloomberg asked the significance of 271, one guest answered correctly: the number of electoral votes received by George W. Bush in 2000. In January 2008, CNN reported that a source close to Bloomberg said that the mayor had launched a research effort to assess his chances of winning a potential presidential bid. According to the report, the unidentified source also stated that Bloomberg had set early March as a timetable for making a decision as to whether or not to run. On January 16, 2008, it was reported that Bloomberg's business interests were placed in "a sort of blind trust" because of his possible run for the presidency. His interests were put under the management of Quadrangle Group, co-founded by reported Bloomberg friend Steven Rattner, though Bloomberg would "continue to have control of and access to certain investment decisions".
On January 18, 2008, the Associated Press reported that Bloomberg had a meeting in Austin, Texas, with Clay Mulford, a ballot-access expert and campaign manager for Ross Perot's third party presidential campaigns. Bloomberg denied that the meeting concerned a possible presidential campaign by him, stating "I'm not a candidate – it couldn't be clearer. Which of the words do you not understand?" On February 28, 2008, Bloomberg stated "I am not – and will not be – a candidate for president." He added that he is "hopeful that the current campaigns can rise to the challenge by offering truly independent leadership. The most productive role that I can serve is to push them forward, by using the means at my disposal to promote a real and honest debate.
At the same time that the presidential run was being considered, there was also some speculation that Bloomberg could be a candidate for the vice presidency in 2008. In a blog posting of June 21, 2007, The Politico's Ben Smith asked the question of whether a vice-presidential candidate can self-finance an entire presidential ticket. Many believed that Bloomberg would in fact be legally permitted to self-finance a campaign as the vice-presidential candidate.
Adding more fuel to the speculation that Bloomberg might consider a VP slot were a series of meetings he had in mid-August 2007 with former Georgia Senator Sam Nunn and later with Barack Obama on November 30, 2007. A May 17, 2008, breakfast meeting with John McCain led to speculation that Bloomberg might be on McCain's short list of possible VP candidates.
Rumored gubernatorial campaign.
On November 6, 2007, the "New York Post" detailed efforts by New York State Republicans to recruit Bloomberg to oppose then-incumbent Governor Eliot Spitzer in the State's 2010 election. Early polls indicated Bloomberg would defeat Spitzer in a landslide. (The potential 2010 match-up became moot when Spitzer resigned on March 17, 2008.) A March 20, 2008, poll of New York State voters had the Mayor topping newly ascended Governor David Paterson and former New York City Mayor Rudy Giuliani for the 2010 gubernatorial election. Bloomberg denied plans to run for the governorship in 2010, and did not seek the nomination.
2012 presidential campaign speculation and role.
In March 2010, Bloomberg's top political strategist Kevin Sheekey resigned from his mayoral advisory position and returned to Bloomberg LP, Bloomberg's company. It was speculated that the move would allow Sheekey to begin preliminary efforts for a Bloomberg presidential campaign in the 2012 election. An individual close to Bloomberg said, "the idea of continuing onward is not far from his mind".
In October 2010, The Committee to Draft Michael Bloomberg – which had attempted to recruit Bloomberg to run for the presidency in 2008 – announced it was relaunching its effort to persuade Bloomberg to wage a presidential campaign in 2012. The committee members insisted that they would persist in the effort in spite of Bloomberg's repeated denials of interest in seeking the presidency.
While on the December 12, 2010, episode of "Meet the Press", Bloomberg ruled out a run for the Presidency in 2012, stating: "I'm not going to run for president," further adding "I'm not looking at the possibility of running ... no way, no how." On July 24, 2011, in the midst of Democrats' and Republicans' inability to agree on a budget plan and thus an increase in the federal debt limit, the "Washington Post" published a blog post about groups organizing third party approaches. It focused on Bloomberg as the best hope for a serious third-party presidential candidacy in 2012.
During an appearance on "The Daily Show" in June 2012, London Mayor Boris Johnson told host Jon Stewart that he did not know why Bloomberg had ruled out a bid for the presidency in the upcoming election, declaring that he would be "a great candidate". Bloomberg had privately indicated he could not support Mitt Romney in 2012 because of Romney's positions on social issues such as abortion and gun control. In the immediate aftermath of Hurricane Sandy in November 2012, Bloomberg penned an op-ed officially endorsing Barack Obama for President, citing Obama's policies on climate change.
2016 presidential campaign speculation and role.
On January 23, 2016, it was reported that Bloomberg was again considering a presidential run as an independent candidate in the 2016 election. This was the first time that he had officially confirmed he was considering a run. Backers of Bloomberg reasoned that the Republican and Democratic parties are about to choose presidential candidates that would repel many voters, and Bloomberg could capture many of these dissatisfied voters as a centrist. However, On March 7, Bloomberg announced he would not be running for President.
Philanthropy.
Environmental advocacy.
Bloomberg is a dedicated environmentalist and has advocated policy to fight climate change at least since he became the mayor of New York City. At the national level, Bloomberg has consistently pushed for transitioning the United States’ energy mix from fossil fuels to clean energy. In July 2011, Bloomberg donated $50 million through Bloomberg Philanthropies to Sierra Club’s Beyond Coal campaign, allowing the campaign to expand its efforts to shut down coal-fired power plants from 15 states to 45 states. On April 8, 2015, to build on the success of the Beyond Coal campaign, Bloomberg announced an additional Bloomberg Philanthropies investment of $30 million in the Beyond Coal initiative, matched with another $30 million by other donors, to help secure the retirement of half of America’s fleet of coal plants by 2017.
Bloomberg awarded a $6 million grant through Bloomberg Philanthropies to the Environmental Defense Fund in support of strict regulations on fracking in the 14 states with the heaviest natural gas production. In October 2013, Bloomberg and Bloomberg Philanthropies launched the Risky Business initiative with former Treasury Secretary Hank Paulson and hedge-fund billionaire Tom Steyer. The joint effort worked to convince the business community of the need for more sustainable energy and development policies by quantifying and publicized the economic risks the United States faces from the impacts of climate change. In January 2015, Bloomberg led Bloomberg Philanthropies in a $48 million partnership with the Heising-Simons family to launch the Clean Energy Initiative. The initiative supports state based solutions aimed at ensuring America has a clean, reliable, and affordable energy system.
Since 2010, Bloomberg has taken an increasingly global role on environmental issues. From 2010 to 2013, he served as the chairman of the C40 Cities Climate Leadership Group, a network of the world’s biggest cities working together to reduce carbon emissions. During his tenure, Bloomberg worked with President Bill Clinton to merge C40 with the Clinton Climate Initiative, with the goal of amplifying their efforts in the global fight against climate change worldwide. Today, he serves as the President of the Board of C40 Cities. In January 2014, Bloomberg began a five-year commitment totaling $53 million through Bloomberg Philanthropies to the Vibrant Oceans Initiative. The initiative partners Bloomberg Philanthropies with Oceana, Rare, and Encourage Capital to help reform fisheries and increase sustainable populations worldwide.
On January 31, 2014, United Nations Secretary General Ban Ki-moon appointed Bloomberg as his first Special Envoy for Cities and Climate Change to help the United Nations work with cities to prevent climate change. In September 2014, Bloomberg convened with Ban and global leaders at the UN Climate Summit to announce definite actions to fight climate change in 2015. In late 2014, Bloomberg, Ban Ki-moon, and global city networks ICLEI-Local Governments for Sustainability (ICLEI), C40 Cities Climate Leadership Group (C40) and United Cities and Local Governments (UCLG), with support from UN-Habitat, launched the Compact of Mayors, a global coalition of mayors and city officials pledging to reduce local greenhouse gas emissions, enhance resilience to climate change, and track their progress transparently. To date, over 250 cities representing more than 300 million people worldwide and 4.1% of the total global population, have committed to the Compact of Mayors.
On June 30, 2015, Bloomberg and mayor of Paris Anne Hidalgo jointly announced the creation of the Climate Summit for Local Leaders, which convened on December 4, 2015. The Climate Summit assembled hundreds of city leaders from around the world at Paris City Hall, marking the largest recorded gathering of local leaders on the subject of fighting climate change. The Summit concluded with the presentation of the Paris Declaration, a pledge by leaders from assembled global cities to cut carbon emissions by 3.7 gigatons annually by 2030.
During the 2015 UN Climate Change Conference in Paris, Mark Carney, Governor of the Bank of England and chair of the Financial Stability Board, announced that Bloomberg will lead a new global task force designed to help industry and financial markets understand the growing risks of climate change. 
Other causes.
According to a profile of Bloomberg in "Fast Company", his Bloomberg Philanthropies foundation has five areas of focus: public health, the arts, government innovation, the environment, and education. According to the "Chronicle of Philanthropy", Bloomberg was the third-largest philanthropic donor in America in 2015. Through his Bloomberg Philanthropies Foundation, he has donated and/or pledged $240 million in 2005, $60 million in 2006, $47 million in 2007, $150 million in 2009, $332 million in 2010, $311 million in 2011, and $510M in 2015. 2011 recipients included the Campaign for Tobacco-Free Kids; Centers for Disease Control and Prevention; Johns Hopkins Bloomberg School of Public Health; World Lung Foundation and the World Health Organization. In 2013 it was reported that Bloomberg had donated $109.24 million in 556 grants and 61 countries to campaigns against tobacco. According to "The New York Times", Bloomberg was an "anonymous donor" to the Carnegie Corporation from 2001 to 2010, with gifts ranging from $5 million to $20 million each year. The Carnegie Corporation distributed these contributions to hundreds of New York City organizations, ranging from the Dance Theatre of Harlem to Gilda's Club, a non-profit organization that provides support to people and families living with cancer. He continues to support the arts through his foundation.
In 1996, Bloomberg endowed the William Henry Bloomberg Professorship at Harvard with a $3 million gift in honor of his father, who died in 1963, saying, "throughout his life, he recognized the importance of reaching out to the nonprofit sector to help better the welfare of the entire community." Bloomberg also endowed his hometown synagogue, Temple Shalom, which was renamed for his parents as the William and Charlotte Bloomberg Jewish Community Center of Medford.
Bloomberg reports giving $254 million in 2009 to almost 1,400 nonprofit organizations, saying, "I am a big believer in giving it all away and have always said that the best financial planning ends with bouncing the check to the undertaker." Bloomberg has donated over $1.8 billion to more than 850 charities.
In July 2011, Bloomberg launched a $24 million initiative to fund "Innovation Delivery Teams" in five cities. The teams are one of Bloomberg Philanthropies' key goals: advancing government innovation.
In December 2011, Bloomberg Philanthropies launched a partnership with online ticket search engine SeatGeek to connect artists with new audiences. Called the Discover New York Arts Project, the project includes organizations HERE, New York Theatre Workshop, and the Kaufman Center.
On March 22, 2012, Bloomberg announced his foundation was pledging $220 million over four years in the fight against global tobacco use.
Bloomberg has donated $200 million toward the construction of new buildings at Johns Hopkins Hospital, the teaching hospital and biomedical research facility of Johns Hopkins University School of Medicine, including the Charlotte R. Bloomberg Children's Center. In January 2013, Johns Hopkins University announced that with a recent $350 million gift, Bloomberg's total giving to his undergraduate "alma mater" surpassed $1.1 billion; his first gift to the school, 48 years prior, had been a $5 donation. Five-sevenths of the $350 million gift is allocated to the Bloomberg Distinguished Professorships, endowing 50 Bloomberg Distinguished Professors (BDPs) whose interdisciplinary expertise crosses traditional academic disciplines. 
On March 29, 2016, Bloomberg joined Vice President Joe Biden at Johns Hopkins University to announce the creation of The Bloomberg–Kimmel Institute for Cancer Immunotherapy at Johns Hopkins School of Medicine in East Baltimore. The Institute was launched with a $50 million gift by Bloomberg, a $50 million gift by philanthropist Sidney Kimmel, and $25 million from other donors. It will support cancer therapy research, technology and infrastructure development, and private sector partnerships. The Institute embraces the spirit of Vice President Biden's "cancer moonshot" initiative, which seeks to find a cure for cancer through national coordination of government and private sector resources.
He is the founder of Everytown for Gun Safety (formerly Mayors Against Illegal Guns), a gun control advocacy group.
Personal life.
In 1975, Bloomberg married Susan Brown, a woman from Yorkshire, United Kingdom. They had two daughters: Emma (b. ca. 1979) and Georgina (b. 1983), who were featured on "Born Rich", a documentary film about the children of the extremely wealthy. Bloomberg divorced Brown in 1993, but he has said she remains his "best friend." As of 2010, Bloomberg was living with former New York state banking superintendent Diana Taylor. His daughter Emma is married to Christopher Frissora, son of businessman Mark Frissora.
Licensed as a commercial pilot, Bloomberg pilots an AW109 helicopter, and is near the top of the waiting list for an AW609 tiltrotor aircraft. In his youth he was a licensed amateur radio operator, was proficient in Morse code, and built ham radios.
His younger sister, Marjorie Tiven, has been Commissioner of the New York City Commission for the United Nations, Consular Corps and Protocol, since February 2002.
In 2013, he owned 13 properties in various countries around the world, including a mansion built in the Georgian style. His newest acquisition is a historical property located in London that belonged to writer George Eliot.
Awards and honors.
At the 2007 commencement exercises for Tufts University, Bloomberg delivered the commencement address. He was awarded an honorary degree in Public Service from the university. Likewise, Bloomberg delivered the 2007 commencement address at Bard College, where he was also awarded an honorary degree of Doctor of Humane Letters. In February 2003, he received the "Award for Distinguished Leadership in Global Capital Markets" from the Yale School of Management. Bloomberg was named the 39th most influential person in the world in the 2007 and 2008 Time 100. In October 2010, "Vanity Fair" ranked him #7 in its "Vanity Fair 100: The New Establish 2010."
In May 2008, Bloomberg was awarded an honorary doctorate of laws from the University of Pennsylvania, where he delivered the commencement speech to the class of 2008. Bloomberg also delivered the commencement address to the class of 2008 at Barnard College, located in New York City, after receiving the Barnard Medal of Distinction, the College's highest honor.
In May 2011, Bloomberg was the speaker for Princeton University's 2011 baccalaureate service.
Bloomberg was also awarded a tribute award at the 2007 Gotham Awards, a New York-based celebrator of independent film. On November 19, 2008, Bloomberg received The Hundred Year Association of New York's Gold Medal "in recognition of outstanding contributions to the City of New York". Additionally, he was awarded an honorary doctorate at Fordham University's 2009 commencement ceremonies.
In 2009, Bloomberg received a Healthy Communities Leadership Award from Leadership for Healthy Communities – a Robert Wood Johnson Foundation national program – for his policies and programs that increase access to healthful foods and physical activity options in the city. For instance, to increase access to grocery stores in underserved areas, the Bloomberg administration developed a program called FRESH that offers zoning and financial incentives to developers, grocery store operators and land owners. His administration also created a Healthy Bodega initiative, which provides healthful food samples and promotional support to grocers in lower-income areas to encourage them to carry one-percent milk and fruits and vegetables. Under Bloomberg's leadership, the city also passed a Green Carts bill, which supports mobile produce vendors in lower-income areas; expanded farmers' markets using the city's Health Bucks program which provides coupons to eligible individuals to buy produce at farmers' markets in lower-income areas; and committed $111 million in capital funding for playground improvements. New York also was one of the first cities in the nation to help patrons make more informed decisions about their food choices by requiring fast-food and chain restaurants to label their menus with calorie information.
In 2010, Bloomberg received the U.S. Senator John Heinz Award for Greatest Public Service by an Elected or Appointed Official, an award given out annually by Jefferson Awards.
In 2013, Bloomberg was chosen as the inaugural laureate of the Genesis Prize, a $1 million award to be presented annually for Jewish values. He will invest his US $1M award in a global competition, the Genesis Generation Challenge, to identify young adults' big ideas to better the world.
In 2014, Bloomberg was bestowed the honorary degree of Doctor of Laws from Harvard University in recognition of his public service and leadership in the world of business.
On October 6, 2014, Queen Elizabeth II named Bloomberg an honorary Knight Commander of the Order of the British Empire for his "prodigious entrepreneurial and philanthropic endeavors, and the many ways in which they have benefited the United Kingdom and the U.K.-U.S. special relationship." Since Bloomberg is not a citizen of the United Kingdom, he cannot use the title "Sir", but Bloomberg may, at his own discretion, still use the post-nominal letters "KBE".
In 2015, the Bloomberg Terminal was featured prominently in the "Tools of the Trade" financial technology exhibit in Silicon Valley's Computer History Museum, as well as the Smithsonian National Museum of American History.

</doc>
<doc id="38829" url="https://en.wikipedia.org/wiki?curid=38829" title="Three-phase electric power">
Three-phase electric power

Three-phase electric power is a common method of alternating-current electric power generation, transmission, and distribution. It is a type of polyphase system and is the most common method used by electrical grids worldwide to transfer power. It is also used to power large motors and other heavy loads. A three-phase system is usually more economical than an equivalent single-phase at the same line to ground voltage because it uses less conductor material to transmit electrical power.
The three-phase system was independently invented by Galileo Ferraris, Mikhail Dolivo-Dobrovolsky, Jonas Wenström and Nikola Tesla in the late 1880s.
Principle.
In a symmetric three-phase power supply system, three conductors each carry an alternating current of the same frequency and voltage amplitude relative to a common reference but with a phase difference of one third the period. The common reference is usually connected to ground and often to a current-carrying conductor called the neutral. Due to the phase difference, the voltage on any conductor reaches its peak at one third of a cycle after one of the other conductors and one third of a cycle before the remaining conductor. This phase delay gives constant power transfer to a balanced linear load. It also makes it possible to produce a rotating magnetic field in an electric motor and generate other phase arrangements using transformers (For instance, a two phase system using a Scott-T transformer).
The symmetric three‐phase systems described here are simply referred to as "three‐phase systems" because, although it is possible to design and implement asymmetric three‐phase power systems (i.e., with unequal voltages or phase shifts), they are not used in practice because they lack the most important advantages of symmetric systems.
In a three‐phase system feeding a balanced and linear load, the sum of the instantaneous currents of the three conductors is zero. In other words, the current in each conductor is equal in magnitude to, but with the opposite sign of, the sum of the currents in the other two. The return path for the current in any phase conductor is the other two phase conductors.
Compared to a single-phase AC power supply that uses two conductors (phase and neutral), a three-phase supply with no neutral, the same phase-to-ground voltage and current capacity per phase can transmit three times as much power using just 1.5 times as many wires (i.e., three instead of two). Thus, the ratio of capacity to conductor material is doubled. The same (but not the other properties of three-phase power) can also be attained with a center-grounded single-phase system.
Three-phase systems may also utilize a fourth wire, particularly in low-voltage distribution. This is the neutral wire. The neutral allows three separate single-phase supplies to be provided at a constant voltage and is commonly used for supplying groups of domestic properties which are each single-phase loads. The connections are arranged so that, as far as possible in each group, equal power is drawn from each phase. Further up the distribution system, the currents are usually well balanced. Transformers may be wired in a way that they have a four‐wire secondary but a three‐wire primary while allowing unbalanced loads and the associated secondary‐side neutral currents.
Three-phase supplies have properties that make them very desirable in electric power distribution systems:
Most household loads are single-phase. In North American residences, three-phase power might feed a multiple-unit apartment block, but the household loads are connected only as single phase. In lower-density areas, only a single phase might be used for distribution. Some large European appliances may be powered by three-phase power, such as electric stoves and clothes dryers.
Wiring for the three phases is typically identified by color codes which vary by country. Connection of the phases in the right order is required to ensure the intended direction of rotation of three-phase motors. For example, pumps and fans may not work in reverse. Maintaining the identity of phases is required if there is any possibility two sources can be connected at the same time; a direct interconnection between two different phases is a short-circuit.
Generation and distribution.
At the power station, an electrical generator converts mechanical power into a set of three AC electric currents, one from each coil (or winding) of the generator. The windings are arranged such that the currents vary sinusoidally at the same frequency but with the peaks and troughs of their wave forms offset to provide three complementary currents with a phase separation of one-third cycle (120° or radians). The generator frequency is typically 50 or 60 Hz, varying by country.
At the power station, transformers change the voltage from generators to a level suitable for transmission minimizing losses.
After further voltage conversions in the transmission network, the voltage is finally transformed to the standard utilization before power is supplied to customers.
Most automotive alternators generate three phase AC and rectify it to DC with a diode bridge.
Transformer connections.
A "delta" connected transformer winding is connected between phases of a three-phase system. A "wye" ("star") transformer connects each winding from a phase wire to a common neutral point.
In an "open delta" or "V" system, only two transformers are used. A closed delta system can operate as an open delta if one of the transformers has failed or needs to be removed. In open delta, each transformer must carry current for its respective phases as well as current for the third phase, therefore capacity is reduced to 87%. With one of three transformers missing and the remaining two at 87% efficiency, the capacity is 58% ().
Where a delta-fed system must be grounded for detection of stray current to ground or protection from surge voltages, a grounding transformer (usually a zigzag transformer) may be connected to allow ground fault currents to return from any phase to ground. Another variation is a "corner grounded" delta system, which is a closed delta that is grounded at one of the junctions of transformers.
Three-wire and four-wire circuits.
There are two basic three-phase configurations: delta and wye (star). As shown in the diagram, a delta configuration requires only 3 wires for transmission but a wye (star) configuration may utilise a fourth wire. The fourth wire, if present, is provided as a Neutral and is normally Grounded. The "3-wire" and "4-wire" designations do not count the ground wire used above many transmission lines, which is solely for fault protection and does not carry current under non-fault conditions.
A four-wire system with symmetrical voltages between phase and neutral is obtained when the neutral is connected to the "common star point" of all supply windings. In such a system, all three phases will have the same magnitude of voltage relative to the Neutral. Other non-symmetrical systems have been used.
The four-wire wye system is used when ground referenced voltages or the flexibility of more voltage selections are required. Faults on one phase to ground will cause a protection event (fuse or breaker open) locally and not involve other phases or other connected equipment. An example of application is local distribution in Europe (and elsewhere), where each customer may be only fed from one phase and the neutral (which is common to the three phases). When a group of customers sharing the neutral draw unequal phase currents, the common neutral wire carries the currents resulting from these imbalances. Electrical engineers try to design the system so the loads are balanced as much as possible within premises where 3-phase power is utilized. These same principles apply to the wide scale distribution of power to individual premises. Hence, every effort is made by supply authorities to distribute all three phases over a large number of premises so that, on average, as nearly as possible a balanced load is seen at the point of supply.
For domestic use, some countries such as the UK may supply one phase and neutral at a high current (up to 100A) to one property, while others such as Germany may supply 3 phases and neutral to each customer, but at a lower fuse rating, typically 32 A per phase, and "shuffled" to avoid the effect that more load tends to be put on the first phase.
In North America, a high-leg delta supply is sometimes used, where one winding of a delta connected transformer feeding the load is center-tapped and that center tap is grounded and connected as a Neutral, as shown in the second diagram. This setup produces three different voltages. If the voltage between the center tap (neutral) and each of the two adjacent phases is 120 V (100%), the voltage across any two phases is 240 V (200%), and the neutral to "high leg" voltage is ≈ 208 V (173%).
The reason for providing the delta connected supply is usually to power large motors requiring a rotating field. However, the premises concerned will also require the "normal" North American 120 V supplies, two of which are derived (180 degrees "out of phase") between the "Neutral" and either of the center tapped phase points.
Balanced circuits.
In the perfectly balanced case all three lines share equivalent loads. Examining the circuits we can derive relationships between line voltage and current, and load voltage and current for wye and delta connected loads.
In a balanced system each line will produce equal voltage magnitudes at phase angles equally spaced from each other. With V1 as our reference and V3 lagging V2 lagging V1, using angle notation, we have:
These voltages feed into either a wye or delta connected load.
Wye.
For the wye case, all loads see their respective line voltages, and so:
where "Z"total is the sum of line and load impedances ("Z"total = "Z"LN + "Z"Y), and "θ" is the phase of the total impedance ("Z"total).
The phase angle difference between voltage and current of each phase is not necessarily 0 and is dependent on the type of load impedance, "Z"y. Inductive and capacitive loads will cause current to either lag or lead the voltage. However, the relative phase angle between each pair of lines (1 to 2, 2 to 3,and 3 to 1) will still be −120°.
By applying Kirchhoff's current law (KCL) to the neutral node, the three phase currents sum to the total current in the neutral line. In the balanced case:
Delta.
In the delta circuit, loads are connected across the lines, and so loads see line-to-line voltages:
Further:
where "θ" is the phase of delta impedance ("Z"Δ).
Relative angles are preserved, so "I"31 lags "I"23 lags "I"12 by 120°. Calculating line currents by using KCL at each delta node gives:
and similarly for each other line:
where, again, "θ" is the phase of delta impedance ("Z"Δ).
Single-phase loads.
Single-phase loads may be connected across any two phases, or a load can be connected from phase to neutral. Distributing single-phase loads among the phases of a three-phase system balances the load and makes most economical use of conductors and transformers.
In a symmetrical three-phase four-wire, wye system, the three phase conductors have the same voltage to the system neutral. The voltage between line conductors is square root of 3 times the phase conductor to neutral voltage:
The currents returning from the customers' premises to the supply transformer all share the neutral wire. If the loads are evenly distributed on all three phases, the sum of the returning currents in the neutral wire is approximately zero. Any unbalanced phase loading on the secondary side of the transformer will use the transformer capacity inefficiently.
If the supply neutral is broken, phase-to-neutral voltage is no longer maintained. Phases with higher relative loading will experience reduced voltage, and phases with lower relative loading will experience elevated voltage, up to the phase-to-phase voltage.
A high-leg delta provides phase-to-neutral relationship of , however, LN load is imposed on one phase. A transformer manufacturer's page suggests that LN loading not exceed 5% of transformer capacity.
Since ≈ 1.73, defining as 100% gives . If was set as 100%, then .
Unbalanced loads.
When the currents on the three live wires of a three-phase system are not equal or are not at an exact 120° phase angle, the power loss is greater than for a perfectly balanced system. The method of symmetrical components is used to analyze unbalanced systems.
Non-linear loads.
With linear loads, the neutral only carries the current due to imbalance between the phases. Devices that utilize rectifier-capacitor front-end such as switch-mode power supplies, computers, office equipment and such produce third-order harmonics that are in-phase on all the supply phases. Consequently, such harmonic currents add in the neutral, which can cause the neutral current to exceed the phase current.
Three-phase loads.
An important class of three-phase load is the electric motor. A three-phase induction motor has a simple design, inherently high starting torque and high efficiency. Such motors are applied in industry for many applications. A three-phase motor is more compact and less costly than a single-phase motor of the same voltage class and rating and single-phase AC motors above 10 HP (7.5 kW) are uncommon. Three-phase motors also vibrate less and hence last longer than single-phase motors of the same power used under the same conditions.
Resistance heating loads such as electric boilers or space heating may be connected to three-phase systems. Electric lighting may also be similarly connected.
Line frequency flicker in light can be reduced by evenly spreading three phases across line frequency operated light sources so that illuminated area is provided light from all three phases. The effect of line frequency flicker is detrimental to super slow motion cameras used in sports event broadcasting. Three phase lighting has been applied successfully at the 2008 Beijing Olympics to provide consistent light level for each frame.
Rectifiers may use a three-phase source to produce a six-pulse DC output. The output of such rectifiers is much smoother than rectified single phase and, unlike single-phase, does not drop to zero between pulses. Such rectifiers may be used for battery charging, electrolysis processes such as aluminium production or for operation of DC motors. "Zig-zag" transformers may make the equivalent of six-phase full-wave rectification, twelve pulses per cycle, and this method is occasionally employed to reduce the cost of the filtering components, while improving the quality of the resulting DC.
One example of a three-phase load is the electric arc furnace used in steelmaking and in refining of ores.
In many European countries electric stoves are usually designed for a three-phase feed. However, the individual heating units are often connected between phase and neutral to allow for connection to a single-phase circuit e.g. if within an older domestic property a three-phase feed is not yet available. Other usual three-phase loads in the domestic field are tankless water heating systems and storage heaters. However, since those references appeared homes in Europe and the UK have standardised on a single-phase supply with a nominal 230 V (in practice 240 V in the UK), which is used for all purposes. Most groups of houses are fed from a three-phase supply so that individual premises with above-average demand can be fed with a second or third phase connection, although domestic appliances are invariably designed for a single-phase supply.
Phase converters.
Phase converters are used when three-phase equipment needs to be operated on a single-phase power source. They are used when three-phase power is not available or cost is not justifiable. Such converters may also allow the frequency to be varied (resynthesis) allowing speed control. Some railway locomotives use a single-phase source to drive three-phase motors fed through an electronic drive.
Mechanical.
One method to generate three-phase power from a single-phase source is the rotary phase converter, essentially a three-phase motor with special starting arrangements and power factor correction that produces balanced three-phase voltages. When properly designed, these rotary converters can allow satisfactory operation of a three-phase motor on a single-phase source. In such a device, the energy storage is performed by the inertia (flywheel effect) of the rotating components. An external flywheel is sometimes found on one or both ends of the shaft.
A three-phase generator can be driven by a single-phase motor. This motor-generator combination can provide a frequency changer function as well as phase conversion, but requires two machines with all their expense and losses. The motor-generator method can also form an uninterruptable power supply when used in conjunction with a large flywheel and a battery-powered DC motor for really constant power, a standby generator set gives more frequency drop until standby generator kicks in.
Non-mechanical.
A second method that was popular in the 1940s and 1950s was the "transformer method". At that time, capacitors were more expensive than transformers, so an autotransformer was used to apply more power through fewer capacitors. Separated it from another common method, the static converter, as both methods have no moving parts, which separates them from the rotary converters.
Another method often attempted is with a device referred to as a static phase converter. This method of running three-phase equipment is commonly attempted with motor loads though it only supplies 2/3 power and can cause the motor loads to run hot and in some cases overheat. This method does not work when sensitive circuitry is involved such as CNC devices or in induction and rectifier-type loads.
Variable-frequency drives (also known as solid-state inverters and adjustable speed drives) are used to provide precise speed and torque control of three-phase motors. Some models can be powered by a single-phase supply. VFDs work by converting the supply voltage to DC and then converting the DC to a suitable three-phase source for the motor.
Digital phase converters are designed for fixed-frequency operation from a single-phase source. Similar to a variable-frequency drive, they use a microprocessor to control solid-state power switching components to maintain balanced three-phase voltages.
Color codes.
Conductors of a three-phase system are usually identified by a color code, to allow for balanced loading and to assure the correct phase rotation for motors. Colors used may adhere to International Standard IEC 60446 (now merged into IEC 60445), older standards or to no standard at all and may vary even within a single installation. For example, in the U.S. and Canada, different color codes are used for grounded (earthed) and ungrounded systems.

</doc>
<doc id="38830" url="https://en.wikipedia.org/wiki?curid=38830" title="Rupert, King of Germany">
Rupert, King of Germany

Rupert of the Palatinate (; 5 May 1352 – 18 May 1410), a member of the House of Wittelsbach, was Elector Palatine from 1398 (as Rupert III) and King of Germany "(rex Romanorum)" from 1400 until his death.
Life.
Rupert was born at Amberg in the Upper Palatinate, the son of Elector Palatine Rupert II and Beatrice of Aragon, daughter of King Peter II of Sicily. Rupert's great-granduncle was the Wittelsbach emperor Louis IV. He was raised at the Dominican Liebenau monastery near Worms, where his widowed grandmother Irmengard of Oettingen lived as a nun.
From his early years Rupert took part in the government of the Electoral Palatinate to which he succeeded on his father's death in 1398. He and the three ecclesiastical prince-electors (of Mainz, Cologne and Trier) met at Lahneck Castle in Oberlahnstein on 20 August 1400 and declared the Luxembourg king Wenceslaus deposed. On the next day the same four electors met at Rhens to ballot for Rupert as next German king, thus the majority of the college including the Elector Palatine's own vote. As the Imperial City of Aachen refused to let him enter through its gates, Rupert was crowned by Archbishop Frederick III in Cologne on 6 January 1401.
Lacking a solid power base in the Empire, his rule remained contested by the mighty House of Luxembourg, though Wenceslaus himself did not take any action to regain his royal title. In the Western Schism, Rupert backed Pope Boniface IX who, however, was reluctant to acknowledge his rule in view of the Luxembourg claims. After the king had won some recognition in Southern Germany, he started a campaign to Italy, where he hoped to crush the rule of Gian Galeazzo Visconti over the thriving Duchy of Milan and to be crowned Holy Roman Emperor by the Pope. In the autumn of 1401 he crossed the Alps, but his troops, checked before Brescia, melted away during wintertime and in April 1402 Rupert, too poor to continue the campaign, had to return to Germany.
The news of this failure increased the disorder in Germany, but the king met with some success in his efforts to restore peace. The Luxembourg resistance waned after Wenceslaus was arrested at Prague Castle by his brother Sigismund in March 1402 and the next year his lordship was finally recognized by the Pope. Rupert also gained the support of England by the marriage of his son Louis with Blanche of Lancaster, daughter of King Henry IV on 6 July 1402. In his Palatinate hereditary lands, Rupert turned out to be a capable ruler.
It was nevertheless only the indolence of Wenceslaus that prevented his overthrow. After attempts to enlarge the king's allodium caused conflicts with his former ally, the Archbishop of Mainz forging an alliance with Count Eberhard III of Württemberg, the Zähringen margrave Bernard I of Baden and several Swabian cities in 1405, Rupert was compelled to make certain concessions. The quarrel was complicated by the Papal Schism, but the king was just beginning to make some headway when he died at his castle of Landskrone near Oppenheim on 18 May 1410 and was buried at the Church of the Holy Spirit in Heidelberg.
On his deathbed Rupert had decreed the division of his heritage among his four surviving sons. He was succeeded as Elector Palatine by the eldest brother Louis III, while the second son John received the County Palatine of Neumarkt, the third-born Stephen the County Palatine of Simmern and Zweibrücken, and the youngest son Otto the County Palatine of Mosbach. In the following Imperial election on September 20, Elector Louis III voted for Sigismund of Luxembourg, who however lost to his cousin Margrave Jobst of Moravia.
Family and children.
He was married in Amberg on 27 June 1374 to Elisabeth of Hohenzollern, daughter of Burgrave Frederick V of Nuremberg and Elisabeth of Meissen.
They had the following children:
Legacy.
Rupert's strenuous efforts earned him the surname "Clemens" ("the Gentle"). He also commissioned the Ruprecht building in Heidelberg Castle.

</doc>
<doc id="38832" url="https://en.wikipedia.org/wiki?curid=38832" title="CRC">
CRC

CRC may refer to:

</doc>
<doc id="38833" url="https://en.wikipedia.org/wiki?curid=38833" title="Sheepshank">
Sheepshank

The sheepshank is a type of knot that is used to shorten a rope or take up slack. This knot is not stable. It will fall apart under too much load or too little load.
The knot has several features which allow a rope to be shortened:
Construction methods.
A sheepshank knot may be constructed as follows: ...
An alternative method for quickly constructing a sheepshank is as follows:
The result is a flattened loop which is held at each end by a half hitch. If the sides of the flattened loop are pulled away from each other, the flattened loop ends pull out of the half hitches and the knot falls apart, but if the free ends
are pulled taut then the knot remains secure.
Usage.
Sheepshank knots are typically used for securing loads to trucks or trailers, and in sailing applications.
Disadvantages.
The sheepshank was developed before the use of modern "slippery" synthetic ropes. Constructed from such ropes, under load, it can fail. It is strongly advised that an alternative knot be used.
Variants.
Man-o'war sheepshank.
The man-o'war sheepshank is a sheepshank knot with a Handcuff knot in the middle. This configuration with the half-hitches formed close to the central knot is used in rope rescue and is called a Fireman's chair knot.
Sheepshank with Marlingspike hitches.
This version of the sheepshank is tied by using slipknots instead of half-hitches. It is one of the safest sheepshank variations. 
Kamikaze knot.
The kamikaze knot is a slight variant of the sheepshank. To perform a kamikaze knot, a sheepshank is first constructed. Whilst holding sufficient tension on the sheepshank so it will not slip out, the middle rope is sliced. This allows climbers rappelling down cliff faces to keep most of the rope used for the rappel, by tying the knot at the top, and shaking the rope when they reach the bottom. The shaking disconnects the knot at the top, allowing the longer section of rope to fall, meaning only a small amount of rope is retained by the anchor at the top of the cliff. Thin or slippery rope is unsuitable for such a knot, as it can easily slip, and the knot should not be performed unless desperately needed.
Use.
Although certainly not invented by him this variant of the sheepshank knot appeared in an episode of the TV show "Man Vs Wild". Bear Grylls uses a modification of this knot by cutting one of the lengths of rope in the knot, while rappelling down an edge during the Ireland episode of "Man vs. Wild" in order to retrieve his rope at the bottom by severing the middle leg of the sheepshank knot before his descent. He refers to it as a "Kamikaze" knot.

</doc>
<doc id="38835" url="https://en.wikipedia.org/wiki?curid=38835" title="Clove hitch">
Clove hitch

The clove hitch is a type of knot. Along with the bowline and the sheet bend, it is often considered one of the most important knots and is commonly referred to as a Double Hitch. A clove hitch is two successive half-hitches around an object. It is most effectively used as a crossing knot. It can be used as a binding knot, but is not particularly secure in that role. A clove hitch made around the rope's own standing part is known as either two half-hitches or buntline hitch, depending on whether the turns of the clove hitch progress away from or towards the hitched object.
Usage.
This knot is particularly useful where the length of the running end needs to be adjustable, since feeding in rope from either direction will loosen the knot to be tightened at a new position. With certain types of cord, the clove hitch can slip when loaded. In modern climbing rope, the clove hitch will slip to a point, and then stop slipping. With smaller diameter cords, after being heavily weighted it may become difficult to untie. It is also unreliable when used on a square or rectangular post, rather than round.
The clove hitch is also commonly used in pioneering to start and finish a lashing such as the traditional square lashing, tripod lashing, round lashing, and sheer lashing.

</doc>
<doc id="38838" url="https://en.wikipedia.org/wiki?curid=38838" title="Cyclic redundancy check">
Cyclic redundancy check

A cyclic redundancy check (CRC) is an error-detecting code commonly used in digital networks and storage devices to detect accidental changes to raw data. Blocks of data entering these systems get a short "check value" attached, based on the remainder of a polynomial division of their contents. On retrieval, the calculation is repeated and, in the event the check values do not match, corrective action can be taken against data corruption.
CRCs are so called because the "check" (data verification) value is a "redundancy" (it expands the message without adding information) and the algorithm is based on "cyclic" codes. CRCs are popular because they are simple to implement in binary hardware, easy to analyze mathematically, and particularly good at detecting common errors caused by noise in transmission channels. Because the check value has a fixed length, the function that generates it is occasionally used as a hash function.
The CRC was invented by W. Wesley Peterson in 1961; the 32-bit CRC function of Ethernet and many other standards is the work of several researchers and was published in 1975.
Introduction.
CRCs are based on the theory of cyclic error-correcting codes. The use of systematic cyclic codes, which encode messages by adding a fixed-length check value, for the purpose of error detection in communication networks, was first proposed by W. Wesley Peterson in 1961.
Cyclic codes are not only simple to implement but have the benefit of being particularly well suited for the detection of burst errors, contiguous sequences of erroneous data symbols in messages. This is important because burst errors are common transmission errors in many communication channels, including magnetic and optical storage devices. Typically an "n"-bit CRC applied to a data block of arbitrary length will detect any single error burst not longer than "n" bits and will detect a fraction of all longer error bursts.
Specification of a CRC code requires definition of a so-called generator polynomial. This polynomial becomes the divisor in a polynomial long division, which takes the message as the dividend and in which the quotient is discarded and the remainder becomes the result. The important caveat is that the polynomial coefficients are calculated according to the arithmetic of a finite field, so the addition operation can always be performed bitwise-parallel (there is no carry between digits). The length of the remainder is always less than the length of the generator polynomial, which therefore determines how long the result can be.
In practice, all commonly used CRCs employ the Galois field of two elements, GF(2). The two elements are usually called 0 and 1, comfortably matching computer architecture.
A CRC is called an "n"-bit CRC when its check value is "n" bits long. For a given "n", multiple CRCs are possible, each with a different polynomial. Such a polynomial has highest degree "n", which means it has terms. In other words, the polynomial has a length of ; its encoding requires bits. Note that most polynomial specifications either drop the MSB or LSB, since they are always 1. The CRC and associated polynomial typically have a name of the form CRC-"n"-XXX as in the table below.
The simplest error-detection system, the parity bit, is in fact a trivial 1-bit CRC: it uses the generator polynomial  (two terms), and has the name CRC-1.
Application.
A CRC-enabled device calculates a short, fixed-length binary sequence, known as the "check value" or "CRC", for each block of data to be sent or stored and appends it to the data, forming a "codeword". When a codeword is received or read, the device either compares its check value with one freshly calculated from the data block, or equivalently, performs a CRC on the whole codeword and compares the resulting check value with an expected "residue" constant. If the check values do not match, then the block contains a data error. The device may take corrective action, such as rereading the block or requesting that it be sent again. Otherwise, the data is assumed to be error-free (though, with some small probability, it may contain undetected errors; this is the fundamental nature of error-checking).
Data integrity.
CRCs are specifically designed to protect against common types of errors on communication channels, where they can provide quick and reasonable assurance of the integrity of messages delivered. However, they are not suitable for protecting against intentional alteration of data.
Firstly, as there is no authentication, an attacker can edit a message and recompute the CRC without the substitution being detected. When stored alongside the data, CRCs and cryptographic hash functions by themselves do not protect against "intentional" modification of data. Any application that requires protection against such attacks must use cryptographic authentication mechanisms, such as message authentication codes or digital signatures (which are commonly based on cryptographic hash functions).
Secondly, unlike cryptographic hash functions, CRC is an easily reversible function, which makes it unsuitable for use in digital signatures.
Thirdly, CRC is a linear function with a property that formula_1; as a result, even if the CRC is encrypted with a stream cipher that uses XOR as its combining operation (or mode of block cipher which effectively turns it into a stream cipher, such as OFB or CFB), both the message and the associated CRC can be manipulated without knowledge of the encryption key; this was one of the well-known design flaws of the Wired Equivalent Privacy (WEP) protocol.
Computation.
To compute an "n"-bit binary CRC, line the bits representing the input in a row, and position the ()-bit pattern representing the CRC's divisor (called a "polynomial") underneath the left-hand end of the row.
In this example, we shall encode 14 bits of message with a 3-bit CRC, with a polynomial . The polynomial is written in binary as the coefficients; a 3rd-order polynomial has 4 coefficients (). In this case, the coefficients are 1, 0, 1 and 1. The result of the calculation is 3 bits long.
Start with the message to be encoded:
This is first padded with zeros corresponding to the bit length "n" of the CRC. Here is the first calculation for computing a 3-bit CRC:
The algorithm acts on the bits directly above the divisor in each step. The result for that iteration is the bitwise XOR of the polynomial divisor with the bits above it. The bits not above the divisor are simply copied directly below for that step. The divisor is then shifted one bit to the right, and the process is repeated until the divisor reaches the right-hand end of the input row. Here is the entire calculation:
Since the leftmost divisor bit zeroed every input bit it touched, when this process ends the only bits in the input row that can be nonzero are the n bits at the right-hand end of the row. These "n" bits are the remainder of the division step, and will also be the value of the CRC function (unless the chosen CRC specification calls for some postprocessing).
The validity of a received message can easily be verified by performing the above calculation again, this time with the check value added instead of zeroes. The remainder should equal zero if there are no detectable errors.
Mathematics.
Mathematical analysis of this division-like process reveals how to select a divisor that guarantees good error-detection properties. In this analysis, the digits of the bit strings are taken as the coefficients of a polynomial in some variable "x"—coefficients that are elements of the finite field GF(2), instead of more familiar numbers. The set of binary polynomials is a mathematical ring.
Designing polynomials.
The selection of the generator polynomial is the most important part of implementing the CRC algorithm. The polynomial must be chosen to maximize the error-detecting capabilities while minimizing overall collision probabilities.
The most important attribute of the polynomial is its length (largest degree(exponent) +1 of any one term in the polynomial), because of its direct influence on the length of the computed check value.
The most commonly used polynomial lengths are:
A CRC is called an "n"-bit CRC when its check value is "n"-bits. For a given "n", multiple CRCs are possible, each with a different polynomial. Such a polynomial has highest degree "n", and hence terms (the polynomial has a length of ). The remainder has length "n". The CRC has a name of the form CRC-"n"-XXX.
The design of the CRC polynomial depends on the maximum total length of the block to be protected (data + CRC bits), the desired error protection features, and the type of resources for implementing the CRC, as well as the desired performance. A common misconception is that the "best" CRC polynomials are derived from either irreducible polynomials or irreducible polynomials times the factor , which adds to the code the ability to detect all errors affecting an odd number of bits. In reality, all the factors described above should enter into the selection of the polynomial and may lead to a reducible polynomial. However, choosing a reducible polynomial will result in a certain proportion of missed errors, due to the quotient ring having zero divisors.
The advantage of choosing a primitive polynomial as the generator for a CRC code is that the resulting code has maximal total block length in the sense that all 1-bit errors within that block length have different remainders (also called syndromes) and therefore, since the remainder is a linear function of the block, the code can detect all 2-bit errors within that block length. If formula_2 is the degree of the primitive generator polynomial, then the maximal total block length is formula_3, and the associated code is able to detect any single-bit or double-bit errors. We can improve this situation. If we use the generator polynomial formula_4, where formula_5 is a primitive polynomial of degree formula_6, then the maximal total block length is formula_7, and the code is able to detect single, double, triple and any odd number of errors.
A polynomial formula_8 that admits other factorizations may be chosen then so as to balance the maximal total blocklength with a desired error detection power. The BCH codes are a powerful class of such polynomials. They subsume the two examples above. Regardless of the reducibility properties of a generator polynomial of degree "r", if it includes the "+1" term, the code will be able to detect error patterns that are confined to a window of "r" contiguous bits. These patterns are called "error bursts".
Specification.
The concept of the CRC as an error-detecting code gets complicated when an implementer or standards committee uses it to design a practical system. Here are some of the complications:
These complications mean that there are three common ways to express a polynomial as an integer: the first two, which are mirror images in binary, are the constants found in code; the third is the number found in Koopman's papers. "In each case, one term is omitted." So the polynomial formula_10 may be transcribed as:
In the table below they are shown as:
Standards and common use.
Numerous varieties of cyclic redundancy checks have been incorporated into technical standards. By no means does one algorithm, or one of each degree, suit every purpose; Koopman and Chakravarty recommend selecting a polynomial according to the application requirements and the expected distribution of message lengths. The number of distinct CRCs in use has confused developers, a situation which authors have sought to address. There are three polynomials reported for CRC-12, sixteen conflicting definitions of CRC-16, and six of CRC-32.
The polynomials commonly applied are not the most efficient ones possible. Since 1993, Koopman, Castagnoli and others have surveyed the space of polynomials between 3 and 64 bits in size, finding examples that have much better performance (in terms of Hamming distance for a given message size) than the polynomials of earlier protocols, and publishing the best of these with the aim of improving the error detection capacity of future standards. In particular, iSCSI and SCTP have adopted one of the findings of this research, the CRC-32C (Castagnoli) polynomial.
The design of the 32-bit polynomial most commonly used by standards bodies, CRC-32-IEEE, was the result of a joint effort for the Rome Laboratory and the Air Force Electronic Systems Division by Joseph Hammond, James Brown and Shyan-Shiang Liu of the Georgia Institute of Technology and Kenneth Brayer of the MITRE Corporation. The earliest known appearances of the 32-bit polynomial were in their 1975 publications: Technical Report 2956 by Brayer for MITRE, published in January and released for public dissemination through DTIC in August, and Hammond, Brown and Liu's report for the Rome Laboratory, published in May. Both reports contained contributions from the other team. During December 1975, Brayer and Hammond presented their work in a paper at the IEEE National Telecommunications Conference: the IEEE CRC-32 polynomial is the generating polynomial of a Hamming code and was selected for its error detection performance. Even so, the Castagnoli CRC-32C polynomial used in iSCSI or SCTP matches its performance on messages from 58 bits to 131 kbits, and outperforms it in several size ranges including the two most common sizes of Internet packet. The ITU-T G.hn standard also uses CRC-32C to detect errors in the payload (although it uses CRC-16-CCITT for PHY headers).
The table below lists only the polynomials of the various algorithms in use. Variations of a particular protocol can impose pre-inversion, post-inversion and reversed bit ordering as described above. For example, the CRC32 used in Gzip and Bzip2 use the same polynomial, but Gzip employs reversed bit ordering, while Bzip2 does not.
CRCs in proprietary protocols might be obfuscated by using a non-trivial initial value and a final XOR, but these techniques do not add cryptographic strength to the algorithm and can be reverse engineered using straightforward methods.
See Polynomial representations of cyclic redundancy checks for the algebraic representations of the polynomials for the CRCs below.

</doc>
<doc id="38842" url="https://en.wikipedia.org/wiki?curid=38842" title="Jochem Uytdehaage">
Jochem Uytdehaage

Jochem Simon Uytdehaage (born 9 July 1976) is a Dutch former long track speed skater and two-time Olympic champion. He retired in 2007 at the age of 30, following two consecutive seasons of poor results.
Biography.
Uytdehaage was born on 9 July 1976 in Oog in Al, Utrecht, Netherlands. He was the 2002 European all-round champion. During the 2002 Winter Olympic Games, he won the gold medal in the 5,000 and 10,000 meter events and the silver in the 1,500 meter event. His winning time on the 10,000 meter was 12:58.92, the first time a skater broke the 13-minute barrier on this distance, and this world record stood for three years, until it was broken by Carl Verheijen and Chad Hedrick. His 5,000 meter time of 6:14.66 was also a world record. Uytdehaage led the long track speed skating Adelskalender from 2001 until 13 November 2005, when Chad Hedrick (US) overtook him.
In December 2005, at the Dutch Olympic Trials in Heerenveen, Uytdehaage failed to qualify for the 2006 Winter Olympics in Turin.
Records.
Personal records.
Source: www.isu.org

</doc>
<doc id="38843" url="https://en.wikipedia.org/wiki?curid=38843" title="Renate Groenewold">
Renate Groenewold

Renate Titzia Groenewold (born 8 October 1976) is a former Dutch long track speed skater and road bicycle racer.
Groenewold has won several Dutch Championships. In 1999, 2002 and 2003 she won the Dutch allround championship. On the European Allround Championships she has won various medals. Five times she came in third in the overall ranking. In 2005 she won the silver medal which was her best result at the European Championships. In 2001 she also came in third in the overall ranking on the World Allround Championships, which she won in 2004.
Besides participating in the allround championships Groenewold has participated in the championships for individual distances. Her best results there were winning the team pursuit in 2008 and the 3000 meters in 2009.
In 2002 Groenewold participated at the 2002 Winter Olympics. She won the silver medal in the 3000 m. Motivated by this success Groenewold was looking forward to the 1500 m but to her bitter disappointment she fell in the second turn. At the 2006 Winter Olympics, rookie compatriot Ireen Wüst beat her to the gold on the 3000 m, leaving Groenewold with silver once more.
In 2007, Groenewold joined Team DSB Bank, which was a women's professional cycling team that competed in international and UCI Women's Road World Cup events. In 2010, Groenewold competed again at the 2010 Winter Olympics, in Vancouver. She was listed as one of lesbian athletes at the Games, even though she never publicly came out and even denied she was a lesbian. She retired from speed skating later that year.

</doc>
<doc id="38846" url="https://en.wikipedia.org/wiki?curid=38846" title="Electoral Palatinate">
Electoral Palatinate

The County Palatine of the Rhine (), later the Electorate of the Palatinate () or simply Electoral Palatinate (), was a historical territory of the Holy Roman Empire, originally a palatinate administered by a count palatine. Its rulers served as prince-electors ("Kurfürsten") from "time immemorial", were noted as such in a papal letter of 1261, and were confirmed as electors by the Golden Bull of 1356.
The fragmented territory stretched from the left bank of the Upper Rhine, from the Hunsrück mountain range in what is today the Palatinate region in the German federal state of Rhineland-Palatinate and the adjacent parts of the French region of Alsace (bailiwick of Seltz from 1418 to 1766) to the opposite territory on the east bank of the Rhine in present-day Hesse and Baden-Württemberg up to the Odenwald range and the southern Kraichgau region, containing the capital cities of Heidelberg and Mannheim.
The Counts Palatine of the Rhine held the office of Imperial vicars in the territories under Frankish law (in Franconia, Swabia and the Rhineland) and ranked among the most significant secular Princes of the Holy Roman Empire. Their climax and decline is marked by the rule of Elector Palatine Frederick V, whose coronation as King of Bohemia in 1619 sparked the Thirty Years' War. After the 1648 Peace of Westphalia, the ravaged lands were further afflicted by the "Reunion" campaigns launched by King Louis XIV of France, culminating in the Nine Years' War (1688–97). Ruled in personal union with the Electorate of Bavaria from 1777, the Electoral Palatinate was finally disestablished with the German mediatization in 1803.
History.
The office of a Count palatine at the Frankish court of King Childebert I was already mentioned about 535. Up to the 10th century, the rule of the Merovingian and Carolingian dynasties was centered at the royal palace ("Pfalz") in Aachen, in what was to become the Frankish kingdom of Lotharingia.
Counts Palatine of Lotharingia.
In 985, Herman I, a scion of the Ezzonids, is mentioned as count palatine of Lotharingia. His territories were centered in the Rhineland proper around Cologne and Bonn, but extended south to the Moselle and Nahe Rivers in (Upper) Lorraine. In continual conflicts with the rivalling Archbishops of Cologne, he changed the emphasis of his rule to the southern Eifel region and further to the Upper Rhine, where the Ezzonian dynasty governed several counties on both banks of the river. The southernmost point was near Alzey.
Counts Palatine of the Rhine.
From about 1085/86, after the death of the last Ezzonian count palatine Herman II, the Palatinate lost its military importance in Lotharingia. The territorial authority of his successor Henry of Laach was reduced to the counties along the Upper Rhine, from then on called County Palatine of the Rhine. Various noble dynasties competed to be enfeoffed with the Palatinate by the Holy Roman Emperor, among them the House of Ascania, the House of Salm (Count Otto I of Salm in 1040) and the House of Babenberg (Henry Jasomirgott in 1140/41).
The first hereditary Count Palatine of the Rhine was Conrad, a member of the House of Hohenstaufen and younger half-brother of Emperor Frederick Barbarossa. The territories attached to this hereditary office in 1156 started from those held by the Hohenstaufens in the Donnersberg, Nahegau, Haardt, Bergstraße and Kraichgau regions (other branches of the Hohenstaufens received lands in the Duchy of Swabia, Franche-Comté, and so forth). Much of this was from their imperial ancestors, the Salian emperors, and apart from Conrad's maternal ancestry, the Counts of Saarbrücken. These backgrounds explain the composition of Upper and Rhenish Palatinate in the inheritance centuries onwards. About 1182, Conrad moved his residence from Stahleck Castle near Bacharach up the Rhine River to Heidelberg.
Upon Conrad's death in 1195, the Palatinate passed to the House of Welf through the—secret—marriage of his daughter Agnes with Henry of Brunswick. When Henry's son Henry the Younger died without heirs in 1214, the Hohenstaufen king Frederick II enfeoffed the Wittelsbach duke Louis I of Bavaria. The Bavarian House of Wittelsbach eventually held the Palatinate territories until 1918.
During a later division of territory among the heirs of Duke Louis II, Duke of Upper Bavaria, in 1294, the elder branch of the Wittelsbachs came into possession of both the Rhenish Palatinate and the territories in the Bavarian "Nordgau" (Bavaria north of the Danube river) with the centre around the town of Amberg. As this region was politically connected to the Rhenish Palatinate, the name Upper Palatinate () became common from the early 16th century in contrast to the Lower Palatinate along the Rhine.
With the Treaty of Pavia in 1329, the Wittelsbach emperor Louis IV, a son of Louis II, returned the Palatinate to his nephews Rudolf and Rupert.
Electorate.
In the Golden Bull of 1356, the Palatinate was recognized as one of the secular electorates, and given the hereditary offices of archsteward (, ) of the Empire and imperial vicar ("Reichsverweser") of Franconia, Swabia, the Rhine, and southern Germany. From that time forth, the Count Palatine of the Rhine was usually known as the Elector Palatine (, ).
Due to the practice of dividing territories among different branches of the family, by the early 16th century junior lines of the Palatine Wittelsbachs came to rule in Simmern, Kaiserslautern and Zweibrücken in the Lower Palatinate, and in Neuburg and Sulzbach in the Upper Palatinate. The Elector Palatine, now based in Heidelberg, adopted Lutheranism in the 1530s and Calvinism in the 1550s.
When the senior branch of the family died out in 1559, the Electorate passed to Frederick III of Simmern, a staunch Calvinist, and the Palatinate became one of the major centers of Calvinism in Europe, supporting Calvinist rebellions in both the Netherlands and France.
Thirty Years' War.
In 1619, Frederick V accepted the throne of Bohemia from the Bohemian estates. He was soon defeated by the forces of Emperor Ferdinand II at the Battle of White Mountain in 1620, and Spanish and Bavarian troops soon occupied the Palatinate itself. Called "the Winter King" because his reign in Bohemia only lasted one winter, Frederick was put under the ban of the Empire in 1623. Frederick V's territories and his position as Elector were transferred to the Duke of Bavaria, Maximilian I, of a distantly related branch of the House of Wittelsbach. Although technically Elector Palatine, he was known as the Elector of Bavaria. From 1648 he ruled in Bavaria and the Upper Palatinate alone, but retained all his Electoral dignities and the seniority of the Palatinate Electorate.
By the Peace of Westphalia in 1648, Frederick V's son, Charles Louis was restored to the Lower Palatinate, and given a "new" electoral title, also called "Elector Palatine", but lower in precedence than the other electorates.
Later history.
In 1685, the Simmern line died out, and the Palatinate was inherited by Philip William, Count Palatine of Neuburg (also Duke of Jülich and Berg), a Catholic. During the reign of Johann Wilhelm (1690-1716) the Electoral residence was moved to Düsseldorf, before being moved back to Heidelberg in 1718 and then to Mannheim in 1720. Johann Wilhelm's mistress, Dorothea von Velen, encouraged him to introduce liberal reforms, most notably the abolition of coverture and the declaration of religious toleration.
In 1742, the Palatinate was inherited by Charles Theodore, Duke of Sulzbach. Charles Theodore also inherited the Electorate of Bavaria when its ruling line became extinct in 1777. The title and authority of Elector Palatine were subsumed into the Electorate of Bavaria, Charles Theodore and his heirs retaining only the single vote and precedence of the Bavarian elector. They continued to use the title "Count Palatine of the Rhine" (, ).
Charles Theodore's heir, Maximilian Joseph, Duke of Zweibrücken (on the French border), brought all the Wittelsbach territories under a single rule in 1799. The Palatinate was dissolved in the Wars of the French Revolution. First, its left bank territories were occupied, and then annexed, by France starting in 1795; then, in 1803, its right bank territories were taken by the Margrave of Baden. The Rhenish Palatinate, as a distinct territory, disappeared. In 1806, the Holy Roman Empire was abolished, and all the rights and responsibilities of the electors with it.
After the Empire.
In 1806, Baden was raised to a grand duchy and parts of the former Palatinate including Mannheim became part of the new grand duchy. At the Congress of Vienna in 1814 and 1815, the left-bank Palatinate — enlarged by other territories such as the former Bishopric of Speyer and the free imperial city of Speyer — was returned to the Wittelsbachs and became a formal part of the Kingdom of Bavaria in 1816 in exchange for Tirol, which Bavaria ceded to Austria. After this time, it was this region that was principally known as the Palatinate. The area remained a part of Bavaria until after the Second World War, when it was separated and became a part of the new state of Rhineland-Palatinate, along with former left bank territories of Prussia and Hesse-Darmstadt.
Coat of arms.
In 1156 Conrad of Hohenstaufen, brother of emperor Frederick Barbarossa became count palatinate. The old coat of arms of the House of Hohenstaufen, the single lion, became coat of arms of the palatinate. By marriage, the Palatinate's arms also became quartered with those of Welf and later Wittelsbach. The arms of Bavaria were also used with reference to the elector's holdings in Bavaria. This was extended to quartering of the lion and the Bavarian Arms upon the ascension of Maximilian I to the position of elector of the Palatinate in 1623, used concurrently with the arms shown. The orb represented their position as Arch-Steward of the Holy Roman Empire.

</doc>
<doc id="38847" url="https://en.wikipedia.org/wiki?curid=38847" title="Unpowered aircraft">
Unpowered aircraft

Unpowered aircraft can remain airborne for a significant period of time without onboard propulsion. They can be classified as fixed-wing gliders, lighter-than-air balloons and tethered kites. This requires a trajectory that is not merely a vertical descent such as a parachute. In the case of kites, lift is obtained by tethering to a fixed or moving object, perhaps another kite, to obain a flow of wind over the lifting surfaces. In the case of balloons, lift is obtained through inherent buoyancy and the balloon may or may not be tethered. Free balloon flight has little directional control. Gliding aircraft include sailplanes, hang gliders, and paragliders that have full directional control in free flight.
History.
The first manned aircraft were kites, balloons and gliders. Man-lifting kites were used in ancient China and Japan, often as a punishment for prisoners. Unmanned hot-air balloons and toy "bamboo-copters" are also recorded in Chinese history.
The first manned free flight was in a hot-air balloon built by the brothers Joseph-Michel and Jacques-Etienne Montgolfier in Annonay, France in 1783. The hydrogen balloon appeared at about the same time and proved more practical.
The first practical, controllable glider was designed and built by the British scientist and pioneer George Cayley who many recognise as the first aeronautical engineer. It flew in 1849. 
Tethered balloons and, to a lesser extent, kites were developed for military and meteorological observation, however the use of kites has remained largely recreational. Free-flying ballooning using coal gas (which has about half the lifting power of hydrogen) became a popular sport. Gliders were used mainly for aerodynamic research until their sporting use was developed in the 1920s.
During the two World Wars, tethered barrage balloons were made and deployed in large numbers. Military assault gliders were also developed during WWII, while the rotor kite was used by the German Navy for seaborne observation.
Modern applications include experimental High altitude wind power generation.
Gliders.
Sailplanes, hang gliders and paragliders are all types of glider aircraft.
For a glider to generate lift, it must first gain and then maintain sufficient forward air speed.
Launching a glider gives it the initial forward airspeed to start flying. This is often done by towing the aircraft into the air on a long line, using either a ground-based winch or vehicle, or a powered "tug" aircraft. A small foot-launched glider is launched by running downhill or stepping off a high location.
Forward speed is then maintained by a gradual descent through the surrounding air, with the wings angled slightly down so that their lift also provides a small forward thrust to counter the drag of the wing. 
If the air is rising faster than the aircraft is descending through it, the glider will gain height and additional potential energy. Sources of such rising air include warm thermals and hill ridges. 
In the past, unpowered military gliders have been used for military applications.
Today, the majority of use of all types of glider aircraft is recreational.
Balloons.
Free-flying Balloons drift with the wind. The pilot controls the altitude either by heating the air more or by releasing ballast weight. The wind direction usually changes with altitude, so crude directional control can be obtained by changing altitude. 
A round tethered balloon is unstable in any significant wind. A kite balloon is streamlined to make it stable in strong winds. 
Today, the majority of manned balloon flights are recreational, whereas unmanned and usually free-flying balloons are widely used for meteorological measurement.
Kites.
Kites are aircraft that are tethered to some other object (fixed or mobile) or other means that maintain tension in the kite line; and rely on virtual or real wind blowing over and under them to generate lift and drag. Kytoons are balloon kites that are shaped and tethered to obtain kiting deflections, and can be lighter-than-air, neutrally buoyant, or heavier-than air. Kites have been developed for commercial applications using kite control systems, including the airborne wind energy systems of high altitude wind power.

</doc>
<doc id="38848" url="https://en.wikipedia.org/wiki?curid=38848" title="House of Wittelsbach">
House of Wittelsbach

The Wittelsbach family is a European royal family and a German dynasty from Bavaria.
Members of the family reigned as Dukes, Electors and Kings of Bavaria (1180–1918), Counts Palatine of the Rhine (1214–1803 and 1816–1918), Margraves of Brandenburg (1323–1373), Counts of Holland, Hainaut and Zeeland (1345–1432), Elector-Archbishops of Cologne (1583–1761), Dukes of Jülich and Berg (1614–1794/1806), Kings of Sweden (1441–1448 and 1654–1720) and Dukes of Bremen-Verden (1654–1719).
The family also provided two Holy Roman Emperors (1328–1347/1742–1745), one King of the Romans (1400–1410), two Anti-Kings of Bohemia (1619–20/1742–43), one King of Hungary (1305–1309), one King of Denmark and Norway (1440–1447) and one King of Greece (1832–1862).
The family's head, since 1996, is Franz, Duke of Bavaria.
Origin.
Berthold, Margrave in Bavaria (died 980), was the ancestor of Otto I, Count of Scheyern (died 1072), whose third son Otto II, Count of Scheyern acquired the castle of Wittelsbach (near Aichach). The Counts of Scheyern left Scheyern Castle (constructed around 940) in 1119 for Wittelsbach Castle and established Scheyern Abbey.
Otto I's son Eckhard I, Count of Scheyern was father to the Count palatine of Bavaria Otto IV (died 1156), whose son Otto was invested with the Duchy of Bavaria in 1180 after the fall of Henry the Lion. Duke Otto's son Louis I, Duke of Bavaria acquired also the Electorate of the Palatinate in 1214.
Bavaria and Palatinate within the Holy Roman Empire.
The "Wittelsbach" dynasty ruled the German territories of Bavaria from 1180 to 1918 and the Electorate of the Palatinate from 1214 until 1805; in 1815 the latter territory was partly incorporated as Rhine Palatinate into Bavaria, which Napoleon elevated to a kingdom in 1806.
On Duke Otto II's death in 1253, his sons divided the Wittelsbach possessions between them: Henry became Duke of Lower Bavaria, and Louis II Duke of Upper Bavaria and Count Palatine of the Rhine. When Henry's branch died out in 1340 the Emperor Louis IV, a son of Duke Louis II, reunited the duchy.
The family provided two Holy Roman Emperors: Louis IV (1314–1347) and Charles VII (1742–1745), both members of the Bavarian branch of the family, and one German King with Rupert of the Palatinate (1400–1410), a member of the Palatinate branch.
The House of Wittelsbach split into these two branches in 1329: Under the Treaty of Pavia, Emperor Louis IV granted the Palatinate including the Bavarian Upper Palatinate to his brother Duke Rudolf's descendants, Rudolf II, Rupert I and Rupert II. Rudolf I in this way became the ancestor of the older (Palatinate) line of the Wittelsbach dynasty, which returned to power also in Bavaria in 1777 after the extinction of the younger (Bavarian) line, the descendants of Louis IV.
Bavarian branch.
The Bavarian branch kept the duchy of Bavaria until its extinction in 1777.
The Wittelsbach Emperor Louis IV acquired Brandenburg (1323), Tyrol (1342), Holland, Zeeland and Hainaut (1345) for his House but he had also released the Upper Palatinate for the Palatinate branch of the Wittelsbach in 1329. His six sons succeeded him as Duke of Bavaria and Count of Holland and Hainaut in 1347. The Wittelsbachs lost the Tyrol with the death of duke Meinhard and the following Peace of Schärding - the Tyrol was finally renounced to the Habsburgs in 1369. In 1373 Otto, the last Wittelsbach regent of Brandenburg, released the country to the House of Luxembourg. On Duke Albert's death in 1404, he was succeeded in the Netherlands by his eldest son, William. A younger son, John III, became Bishop of Liège. However, on William's death in 1417, a war of succession broke out between John and William's daughter Jacqueline of Hainaut. This last episode of the Hook and Cod wars finally left the counties in Burgundian hands in 1432.
Emperor Louis IV had reunited Bavaria in 1340 but from 1349 onwards Bavaria was split among the descendants of Louis IV, who created the branches "Bavaria-Landshut", "Bavaria-Straubing", "Bavaria-Ingolstadt" and "Bavaria-Munich". With the Landshut War of Succession Bavaria was reunited in 1505 against the claim of the Palatinate branch under the Bavarian branch "Bavaria-Munich".
From 1549 to 1567 the Wittelsbach owned the County of Kladsko in Bohemia.
Strictly Catholic by upbringing, the Bavarian dukes became leaders of the German Counter-Reformation. From 1583 to 1761, the Bavarian branch of the dynasty provided the Prince-electors and Archbishops of Cologne and many other Bishops of the Holy Roman Empire, namely Liège (1581–1763). Wittelsbach princes served for example as Bishops of Regensburg, Freising, Liège, Münster, Hildesheim, Paderborn and Osnabrück, and as Grand Masters of the Teutonic Order.
In 1623 under Maximilian I the Bavarian dukes were invested with the electoral dignity and the duchy became the Electorate of Bavaria. His grandson Maximilian II Emanuel, Elector of Bavaria served also as Governor of the Habsburg Netherlands (1692–1706) and as Duke of Luxembourg (1712–1714). His son Emperor Charles VII was also king of Bohemia (1741–1743). With the death of Charles' son Maximilian III Joseph, Elector of Bavaria the Bavarian branch died out in 1777.
Palatinate branch.
The Palatinate branch kept the Palatinate until 1918 and succeeded also in Bavaria in 1777. With the Golden Bull of 1356 the Counts Palatine were invested with the electoral dignity, their county became the Electorate of the Palatinate. Princes of the Palatinate branch served as Bishops of the Empire and also as Elector-Archbishops of Mainz and Elector-Archbishops of Trier.
After the death of the Wittelsbach king Rupert of Germany in 1410 the Palatinate lands began to split under numerous branches of the family such as "Neumarkt", "Simmern", "Zweibrücken", "Birkenfeld", "Neuburg" and "Sulzbach". When the senior branch of the Palatinate branch died out in 1559, the Electorate passed to Frederick III of "Simmern", a staunch Calvinist, and the Palatinate became one of the major centers of Calvinism in Europe, supporting Calvinist rebellions in both the Netherlands and France.
The "Neuburg" cadet branch of the Palatinate branch kept also the Duchy of Jülich and Berg from 1614 onwards: When the last duke of Jülich-Cleves-Berg died without direct heirs in 1609, the War of the Jülich succession broke out, ended by the 1614 Treaty of Xanten, which divided the separate duchies between "Palatinate-Neuburg" and the Margraviate of Brandenburg. Jülich and Berg fell to the Wittelsbach Count Palatine Wolfgang William of Neuburg.
In 1619, the Protestant Frederick V, Elector Palatine became King of Bohemia but was defeated by the Catholic Maximilian I, Elector of Bavaria, a member of the Bavarian branch. As a result, the Upper Palatinate had to be ceded to the Bavarian branch in 1623. When the Thirty Years' War concluded with the Treaty of Münster (also called the Peace of Westphalia) in 1648, a new additional electorate was created for the Count Palatine of the Rhine. During their exile Frederick's sons, especially Prince Rupert of the Rhine, gained fame in England.
The house of "Palatinate of Zweibrücken-Kleeburg" as heir to the Swedish throne ruled simultaneously the duchy of Bremen-Verden (1654–1719).
In 1685, the "Simmern" line died out, and the Catholic Philip William, Count Palatine of "Neuburg" inherited the Palatinate (and also Duke of Jülich and Berg). During the reign of Johann Wilhelm (1690–1716) the Electoral residence moved to Düsseldorf in Berg. His brother and successor Charles III Philip, Elector Palatine moved the Palatinate's capital back to Heidelberg in 1718 and then to Mannheim in 1720. To strengthen the union of all lines of the Wittelsbach dynasty Charles Philip organized a wedding on 17 January 1742 when his granddaughters were married to Charles Theodore of Palatinate-Sulzbach and to the Bavarian prince Clement. In the imperial election a few days later Charles III Philip voted for his Bavarian cousin Prince-Elector Charles Albert. After extinction of the "Neuburg" branch in 1742, the Palatinate was inherited by Duke Charles Theodore of the branch "Palatinate-Sulzbach".
After the extinction of the Bavarian branch in 1777, a succession dispute and the brief War of the Bavarian Succession, the Palatinate-Sulzbach branch under Elector Charles Theodore succeeded also in Bavaria.
With the death of Charles Theodore in 1799 all Wittelsbach land in Bavaria and the Palatinate was reunited under Maximilian IV Joseph, a member of the branch "Palatinate-Zweibrücken-Birkenfeld". At the time there were two surviving branches of the Wittelsbach family: "Palatinate-Zweibrücken" (headed by Maximilian Joseph) and "Palatinate-Birkenfeld" (headed by Count Palatine William). Maximilian Joseph inherited Charles Thedore's title of Elector of Bavaria, while William was compensated with the title of Duke "in" Bavaria. The form Duke in Bavaria was selected because in 1506 primogeniture had been established in the House of Wittelsbach resulting in there being only one Reigning Duke of Bavaria at any given time. Maximillian Joseph assumed the title of king as Maximilian I Joseph on January 1, 1806. The new king still served as an Prince-elector until the Kingdom of Bavaria left the Holy Roman Empire (1 August 1806).
Kingdom of Bavaria, 1806–1918.
Under Maximilian's descendants, Bavaria became the third most powerful German state, behind only Prussia and Austria. It was also far-and-away the most powerful secondary state. When the German Empire was formed in 1871, Bavaria became the new empire's second most powerful state after Prussia. The Wittlesbachs reigned as kings of Bavaria until 1918. On 12 November 1918 Ludwig III issued the "Anif declaration" (German: "Anifer Erklärung") at Anif Palace, Austria, in which he released his soldiers and officials from their oath of loyalty to him and ended the 738-year rule of the House of Wittelsbach in Bavaria. The republican movement thereupon declared a republic.
Activities during Nazi regime, 1933–1945.
During the Second World War, the Wittelsbachs were anti-Nazi. The family initially left Germany for Hungary, but were eventually arrested. Family members spent time in several Nazi concentration camps including Oranienburg and Dachau.
Reign outside the Holy Roman Empire.
With Duke Otto III of Lower Bavaria, who was a maternal grandson of Béla IV of Hungary and was elected anti-king of Hungary and Croatia as Bela V (1305–1308) the Wittelsbach dynasty came to power outside the Holy Roman Empire for the first time. Otto had abdicated the Hungarian throne by 1308.
Palatinate branch.
Christopher III of the House of Palatinate-Neumarkt was king of Denmark, Sweden and Norway in 1440/1442–1448, but he left no descendants. The House of Palatinate-Zweibrücken contributed to the monarchy of Sweden again 1654–1720 under Charles X, Charles XI, Charles XII and Ulrika Eleonora. The Wittelsbach princess Sophia of Hanover (1630–1714) was the mother of George I of Great Britain; she died as Heiress Presumptive of Great Britain a few weeks before the case of succession. The line of Jacobite succession is currently within the House of Wittelsbach. Franz, Hereditary Prince of Bavaria is recognised by the Jacobites as "Francis II". The Wittelsbach prince Otto of Bavaria was elected king of newly independent Greece in 1832 and was forced to abdicate in 1862.
Kingdom of Sweden.
Queen Christina of Sweden abdicated her throne on 5 June 1654 in favor of her cousin Charles X Gustavus, a member of the Wittelsbach branch Palatinate-Zweibrücken. It was the second term for the rule of the House of Wittelsbach in Sweden since 1448 when Christopher III of the Palatinate branch was king of Denmark, Sweden and Norway.
Sweden reached its largest territorial extent under the rule of Charles X after the treaty of Roskilde in 1658. Charles' son, Charles XI, rebuilt the economy and refitted the army. His legacy to his son, Charles XII, was one of the finest arsenals in the world, a large standing army and a great fleet. Charles XII was a skilled military leader and tactician. However, although he was also skilled as a politician, he was reluctant in making peace. While Sweden achieved several large scale military successes early on, and won the most battles, the Great Northern War eventually ended in Sweden's defeat and the end of the Swedish Empire. Charles was succeeded to the Swedish throne by his sister, Ulrika Eleonora. Her abdication in 1720 marked the end of the Wittelsbach rule in Sweden.
Kingdom of Greece.
King Otto I of the House of Wittelsbach was made the first modern King of Greece in 1832 under the Convention of London, whereby Greece became a new independent kingdom under the protection of the Great Powers (the United Kingdom, France and the Russian Empire). Throughout his reign, Otto faced political challenges concerning Greece's financial weakness and the role of the government in the affairs of the Church. The politics of Greece of this era was based on affiliations with the three Great Powers, and Otto’s ability to maintain the support of the powers was key to his remaining in power. To remain strong, Otto had to play the interests of each of the Great Powers’ Greek adherents against the others, while not aggravating the Great Powers. When Greece was blockaded by the (British) Royal Navy in 1850 and again in 1853, to stop Greece from attacking the Ottoman Empire during the Crimean War, Otto’s standing amongst Greeks suffered. As a result, there was an assassination attempt on the Queen and finally, in 1862, Otto was deposed while in the countryside.
The law of succession to the throne of Greece was defined by a supplementary article to the convention of 7 May 1832 awarding the Greek Throne to Otto I. It instituted a semi-salic order with an important rule preventing the union of the crown on the same head with any other crown, especially that of Bavaria. Under the terms of the succession law, a Wittelsbach claim to the throne would have passed on Otto's death in 1867 to his younger brother Luitpold, who was regent of Bavaria from 1886 to 1912; and after him to Ludwig who became king Ludwig III of Bavaria in 1913. At this point, tracing the claim becomes impossible as the same branch of the Wittelsbach became heir to both thrones, and a subsequent monarch or pretender should have issued a renunciation to one of the two thrones, which none did. In the end, neither Luitpold nor his son Ludwig actively pursued a claim to the Greek throne inherited from Otto I, and the throne of Bavaria itself disappeared in 1918, leaving the future of the claim to be decided by a further arrangement that never occurred.
Bavarian branch.
Joseph Ferdinand of Bavaria, Prince of Asturias, a son of Maximilian II Emanuel, was the favored choice of England and the Netherlands to succeed as the ruler of Spain, and young Charles II of Spain chose him as his heir. Due to the unexpected death of Joseph Ferdinand in 1699 the Wittelsbach did not come to power in Spain, leaving the Spanish Succession uncertain again.
Major members of the family.
Patrilineal descent.
Duke Franz's patriline is the line from which he is descended father to son. Patrilineal descent is the principle behind membership in royal houses, as it can be traced back through the generations.
Scandinavian kings.
Several other women in the family are known as Elisabeth of Bavaria.
Castles and palaces.
Bavaria.
Some of the most important Bavarian castles and palaces that were built by Wittelsbach rulers, or served as seats of ruling branch lines, are the following:
Palatinate branch.
Some of the most important castles and palaces of the Palatinate Wittelsbach were:
Electorate of Cologne.
From 1597 to 1794, Bonn was the capital of the Electorate of Cologne and residence of the Archbishops and Prince-electors of Cologne, most of them belonging to the Bavarian branch of the House of Wittelsbach (from 1583 to 1761).
Coats of arms.
A full armorial of the Wittelsbach family can be found on the French-language Wikipedia at Armorial of the House of Wittelsbach.

</doc>
<doc id="38849" url="https://en.wikipedia.org/wiki?curid=38849" title="Palatinate (region)">
Palatinate (region)

The Palatinate (, Pfälzer dialect: "Palz"), historically also Rhenish Palatinate (), is a region in Southwestern Germany. It occupies more than a quarter of the German federal state of Rhineland-Palatinate ("Rheinland-Pfalz") covering an area of with about 1.4 million inhabitants. Its demonym is Palatine.
Geography.
In the west, the Palatinate borders on Saarland, historically also comprising the state's Saarpfalz District. In the northwest, the Hunsrück mountain range forms the border with the Rhineland region. The eastern border with Hesse and the Baden region runs along the Upper Rhine River, while the left bank with Mainz and Worms as well as the Selz basin around Alzey belong to the Rhenish Hesse region. In the south, the German-French border separates the Palatinate from Alsace.
One third of the region is covered by the Palatinate Forest ("Pfälzerwald"), including the Palatinate Forest Nature Park popular with hikers. It is Germany's largest contiguous forestal area with about and part of the Franco-German Palatinate Forest-North Vosges Biosphere Reserve.
The western and northern part of the Palatinate is densely forested and mountainous. Its highest mountain is the Donnersberg with a height of , situated in the North Palatine Uplands near Kirchheimbolanden. Most of the major Palatinate towns (Ludwigshafen, Speyer, Landau, Frankenthal, Neustadt) lie in the lower eastern part of the Upper Rhine Plain down to the Rhine River. Here the German Wine Route ("Deutsche Weinstraße") passes through the renowned Palatinate wine region.The Palatinate is one of the greatest wine producer regions in Germany and in the last two decades it became well known for a large number of prizewinning white and red wines of highest quality produced by a number of young, however fully-fledged, winemakers.
Major rivers include the Upper Rhine tributaries Lauter, Queich and Speyerbach, as well as Schwarzbach and Glan in the west.
Subdivision.
The Palatinate is divided into four non-administrative sub-regions, comprising the following rural districts and independent cities:
Climate.
Like most of Europe, the Palatinate is part of the oceanic climate zone influenced by the Atlantic, with an average annual temperature of about 10 degrees Celsius. Wet air streaming from West and Southwest leads to precipitations in the Mittelgebirge ranges, while it warms up on its way further down to the Rhine Valley. Here the clemency of the weather permits the cultivating of almond and fig trees, stone pines, Mediterranean Cypress, palms, and even some banana species. The lower hilly regions are known for its extended chestnut forests, sometimes referred to as "German Tuscany" in tourist advertising.
History.
The former Celtic region was conquered by the Roman Empire under Emperor Augustus about 12 B.C., whereafter it was part of the Germania Superior province. During the decay of the Empire, Alamanni tribes settled here; their territory was conquered by Francia under King Clovis I about 496. From 511 onwards the area belonged to the eastern part of Frankish Austrasia, that—as Rhenish Franconia—became part of East Francia according to the 843 Treaty of Verdun.
Holy Roman Empire.
From the Middle Ages until 1792, the Palatinate was divided into a total of 45 secular and ecclesiastical territories, some of which were very small. The largest and most important of these was the Electorate of the Palatinate ("Kurpfalz"), a number of territories on both sides of the Rhine formerly held by the Counts palatine ("Pfalzgrafen") of Lotharingia. In the late 12th century the Counts palatine had achieved the status of a Prince-elector ("Kurfürst"), i.e. one of the seven nobles with the privilege of electing the Emperor, confirmed by the Golden Bull of 1356. In 1214 the Bavarian House of Wittelsbach was enfeoffed with these estates, which they ruled until 1918, together with the collateral branch of Palatinate-Zweibrücken from 1410, until the re-unification with Bavaria under Elector Charles Theodore in 1777. The major ecclesiastical territory in the region was the Bishopric of Speyer. The Imperial city of Landau to preserve its status joined the Alsacien Décapole in 1521. Nevertheless, it was seized by France after the Thirty Years' War.
Other larger entities of the region were the Duchy of Zweibrücken and the Prince-Bishopric of Speyer. The Prince-Bishopric also had possessions on both sides of the Rhine. For centuries, Electoral Palatinate and Bavaria had had dynastic links through the Wittelsbach family.
French rule.
In 1794, the Left Bank of the Rhine, including the Palatinate, was occupied by French revolutionary troops. As a result of the Treaty of Campo Formio (1797) the First French Republic annexed the region and introduced a new administrative system in 1798 with the establishment of departments. Basically, the area of the Palatinate became the Département of Mont Tonnerre laying the corner stone for today's regional idendity. Minor parts of today's region belonged to the neighbouring departements of Sarre and Bas-Rhin. The French further subdivided the department into cantons, mayoralties and municipalities and introduced their legal system (Napoleonic Code) and the metric system.
Bavarian rule.
Following the defeat of Napoleon at the Battle of Leipzig in 1813 and the capture of the Left Bank of the Rhine by the Allies in January 1814, from 2 February 1814 the region was initially under the provisional authority of the General Government of the Middle Rhine, but, from 16 June that same year, it was placed under the administration of the Imperial-Royal ("k.k.") Austrian and Royal Bavarian Joint Land Administration Commission ("k. k. östreichischen und k. bairischen gemeinschaftliche Landes-Administrations-Kommission").
In the main treaty agreed at the Congress of Vienna in 1815, and dated 9 June 1815, Article 51 stated that ("inter alia") on the Left Bank of the Rhine the former departements of the Sarre and Mont Tonnerre, except where stated in the same treaty, were to go "with full sovereignty" and ownership rights under the overlordship of the Emperor of Austria ("Herrschaft Sr. Maj. des Kaisers von Oesterreich"). The joint Austro-Bavarian administration was initially retained, however.
On 14 April 1816, a treaty was signed between Austria and Bavaria, in which the various territorial changes were agreed. According to Article 2 of the treaty, Emperor Francis I of Austria ceded various regions to King Maximilian I of Bavaria. These included, in addition to various regions east of the Rhine, the following regions west of the Rhine:
The effective date for these changes was stated as 1 May 1816.
In accordance with the prevailing Bavarian administrative structure, the region became one of 8 Bavarian districts (Kreise). As of 1808, Bavaria had embarked on the administrative reorganization of its territory creating districts which, as in France, were named after their main rivers. Thus, the new district along the Rhine was given the name Rheinkreis (Rhine district) with Speyer as its capital. Of the former French administrative structure, the subdivision of the district into arrondissements, cantons, mayoralties and municipalities was basically retained. The Bavarian government also preserved the French legal system (Code Napoléon), giving the Palatinate a distinct legal status within the Bavarian kingdom.
At the next lower level the 3 former French arrondissements were continued as “Kreisdirektion” ("Circle", i.e. district "direction") Frankenthal, Kaiserslautern and Zweibrücken. The Kreisdirektion Landau was a new creation. In 1818, the cantons were mergen into 12 administrative districts called “Landkommissariat”. The names of these were changed into “Bezirksamt” in 1862 and finally into “Landkreis” (rural district) in 1939.
As his first provincial governor, King Maximilian selected the Privy Councillor ("Hofrat") Franz Xaver von Zwack, whose name is responsible for the popular Palatinate nickname for Bavarians, "Zwockel".
In 1832, the Rheinkreis became the focal point of the liberal movements of the time when a big gathering, the Hambach Festival took place near Neustadt an der Weinstraße which is considered a milestone in German history.
In 1835, the romantic-minded King Ludwig I of Bavaria ordered the administrative districts of Bavaria to be named by historical allusions. So the Rheinkreis officially became the Pfalz (Palatinate). It should be noted here, that the historic Electorate of the Palatinate was on both sides of the Rhine with Heidelberg and Mannheim as its capitals on the eastern side, while the new "Palatinate" that was established in 1815/16 was solely on the left bank of the Rhine, and included territories that had never been part of the historic Palatinate (e.g., territories of the former Bishopric of Speyer, the imperial city of Speyer or Kirchheimbolanden, which had formerly belonged to the Weilburg branch of Nassau). In order not to confuse the new Palatinate with the historic one (and with the Upper Palatinate), the name Rhenish Palatinate ("Rheinpfalz") became common and is still used today, but never official. The term Rhenish Bavaria ("Rheinbayern") never gained currency but can be found sometimes in older maps.
The royal family tried to symbolize the unity with Bavaria by erecting a royal palace in Edenkoben and by the restoration of Speyer Cathedral under direct supervision of King Ludwig I himself. The new town of Ludwigshafen was named after the king. On the other hand, the Palatinate's representatives to the common Bavarian Parliament always prided themselves of their origin from a more progressive region and tried to expand the liberalism, which the French had introduced in the Palatinate, to the whole kingdom. The German historian Heiner Haan described the special status of the Palatinate within Bavaria as a relation of "Hauptstaat" (main state, i.e. Bavaria) and "Nebenstaat" (alongside state, i.e. the Palatinate).
In May/June 1849, after the failed revolution of 1848 and as part of the Imperial Constitution campaign a separatist wanted the district to secede from Bavaria and establish a "Palatinate Republic". The uprising was suppressed by Prussian military intervention. The union with Bavaria persisted after it became part of the German Empire in 1871, and even after the Wittelsbach dynasty was deposed and Bavaria became a free state of the Weimar Republic in 1918. 
In 1910, the town of Landau was declared independent from the Bezirksamt.
However, after World War I French troops occupied the Palatinate under the terms of the Treaty of Versailles. In 1920, the western Bezirksämter of Sankt Ingbert and Homburg ("Saarpfalz") were separated from the Bavarian Palatinate and became part of the newly established Saarland, which according to peace treaty was governed by the League of Nations.That same year, 7 more towns were declared independent from the Bezirksämter: Speyer, Ludwigshafen, Frankenthal, Neustadt an der Weinstraße, Kaiserslautern, Pirmasens and Zweibrücken. They have remained independent to this very day.
In 1919 and 1923, during the occupation, there were attempts at separating the Palatinate from Bavaria and the Empire supported by the French. On 1 June 1919, Eberhard Haaß, founder of the “Free Palatine Association” in 1918, proclaimed the “Palatine Republic” but failed to occupy the government building in Speyer. 
On 23 November 1923, Franz Josef Heinz proclaimed the "Government of the Autonomous Palatinate in the Association of the Rhenish Republic" in Speyer after having gained control of the towns of Kaiserslautern, Neustadt and Landau and after capitulation of the Palatine government. In the following days several more towns fell into the hands of his group. The Bavarian government reacted sharply. It organized a squad under the command of Edgar Julius Jung and on 9 January 1924 Heinz was assassinated while dining at the Wittelsbacher Hof in Speyer. On 12 February 1924, other leading members of the separatist movement were killed in a shooting in Pirmasens. By then, a treaty between Bavaria and the inter-allied commission of the Rhineland (the supreme council of the Allied occupation forces) of January 1924 recognised and reassured the Palatinate being a part of Bavaria and spelled the end of the separatist movement.
Under Nazi rule, from 1933 to 1945, the Palatinate officially remained part of Bavaria but else was totally reorganized. Under party rule it was joined with the Saarland to the Gau Westmark with headquarters in Saarbrücken.
Rhineland-Palatinate.
The union with Bavaria was finally dissolved following the reorganisation of German states after World War II during the Allied occupation of Germany. Whereas proper Bavaria was part of the US occupation Zone, the Palatinate was occupied by French Forces. The French reorganised their occupation Zone by founding new states and in 1947, the Palatinate was combined with Rhenish Hesse ("Rheinhessen"), the former parts of the People's State of Hesse left of the Rhine, and the southern part of the Prussian Rhine Province to form the German federal state of Rhineland-Palatinate. The Palatinate formed the administrative district (Regierungsbezirk) Pfalz. 
This reorganization came with smaller lossess of former district territory to the Saarland, especially in the area of Sankt Wendel. As part of the 1969 administrative reform there were again some minor border changes in the north. The Diocese of Speyer and the Evangelical Church of the Palatinate still exist today largely based on the historic boundaries of the Bavarian district "Pfalz".
Initially one of 5 districts in Rhineland-Palatinate, in 1968, the district of Pfalz was merged with the neighbouring district of Rheinhessen to the district of Rheinhessen-Pfalz. On 1 January 2000, all administrative districts of Rheinland-Pfalz were dissolved.
Emigration.
The Pennsylvania Dutch language spoken by the Amish in the United States is derived primarily from the German dialect spoken in the Palatinate, which many Palatine refugees brought to Pennsylvania in the early decades of the 18th century. The only existing Pennsylvania German newspaper, Hiwwe wie Driwwe is published bi-annually in the village Ober-Olm, which is located close to Mainz, the state capital (as a cooperation project with Kutztown University). In the same village, one can find the headquarters of the German-Pennsylvanian Association.
Cuisine.
Arguably the most famous dish in Palatinate is the saumagen, literally "sow's stomach", a dish that consists of a thick, crispy-fried casing (sow stomach) stuffed with a mixture of pork, potatoes, and seasonings. Other traditional meat dishes of the region include bratwurst, Palatinate liverwurst, a blood pudding sausage called "grieweworscht" ("griewe" are speck (bacon) cubes, so lit. "sausage with speck cubes"), "lewwerknepp" or "lewwerknedel" (Leberknödel: liver dumplings), and "fleeschknepp" (Fleischknödel: meat dumplings). Sauerkraut is the typical side dish in all seasons, but especially in winter, as are mashed potatoes and brown gravy. Also eaten are dampfnudels, which can be served with either sweet sauces or side dishes (such as wine, vanilla sauce or canned fruit such as plums, prunes, or pears) or with savory side dishes (such as potato soup, vegetable soup, goulash, or pepper pork).

</doc>
<doc id="38851" url="https://en.wikipedia.org/wiki?curid=38851" title="Finglas">
Finglas

Finglas () is a suburb of the city of Dublin, Ireland. The village forms the core of the civil parish of Finglas in the barony of Castleknock. The suburb mainly lies in the postal district of Dublin 11. A couple of kilometres from Dublin Airport, it is situated at Junction 5 of the M50 and the N2 national primary road leading to Ashbourne and beyond. Nearby city districts include Glasnevin and Ballymun while the village of St. Margaret's is a little to the north.
History.
The name Finglas (), meaning a clear streamlet, is derived from the Finglas River, a stream which flows through the village and joins the Tolka at Finglas Bridge.
Early history.
Finglas was originally the site of an Early Christian abbey, the origin of which has been associated, from early times, with the name of St. Cainnech, or Canice, the patron of Kilkenny, said to have founded it in 560 A.D. The Nethercross from the first abbey can be seen today in the old graveyard. Several primary schools and churches in the area have been named after Canice. According to an ancient legend, the ground on which Finglas stands had been sanctified by St. Patrick, who is said to have uttered from it a prophecy that a great town would arise at the ford of hurdles in the vale beneath. St. Canice is said to have been born at Glengiven near Derry. The Finglas or Finglass family, prominent in law and politics in the sixteenth century, took their name from the district.
Finglas is a civil parish in the barony of Castleknock.
Following the Battle of the Boyne in the 17th century, Finglas was used as a camp for four days by William of Orange en route to Dublin city. While there he issued the Declaration of Finglas, offering a pardon for many of James II's defeated supporters.
20th century onwards.
In 1932, Ireland's first commercial airport was set up at Kildonan in Finglas. It was the site for the first Irish commercial aircraft, a Desoutter Mark II aircraft "EI-AAD", and the first commercial air taxi service, the Iona National Air Taxis and Flying School.
In the 1950s Finglas was developed with extensive housing estates, to re-house many north inner-city Dublin residents. Many of these housing estates particularly in Finglas West were named after prominent Irish republicans from early 20th century Irish history including Barry, Casement, Plunkett, Mellows, McKee, Clune and Clancy.
Finglas today.
Amenities.
In the village centre are a range of shops, including one of the first-established Superquinn stores (since rebranded as SuperValu), banking facilities, pubs and restaurants. To the north are several light industrial estates.
Finglas is home to one of Dublin's four Road Safety Authority Driving Testing Centres, which is located in Jamestown Business Park.
Sports.
The Rugby Union club Unidare RFC and the GAA club Erins Isle are based in the area. Soccer clubs include Tolka Rovers F.C., Valley Park United, Willows FC and Finglas Celtic FC. Beneavin F.C.
Politics.
Finglas is part of the Dublin North–West constituency for elections to Dáil Éireann. For local elections Finglas is split with the west and south in Cabra-Finglas and the east in Ballymun local electoral areas of Dublin City Council.
Education.
There are upwards of 15 primary and national schools in the Finglas area, and approximately 8 secondary schools. Coláiste Íde is in Finglas West and offers third level courses.
Transport.
Finglas is served by a number of Dublin Bus routes. These include the 17A, 9, 40/D, 83/A,140 & 220 (Route 240 which ran for less than a year in 2009 was recently abolished for its under use in the community. Instead Dublin Bus decided to extend some of the 40B journeys to Toberburr where the 240 began its journey). It is also served by the 88n Nitelink service. Two Bus Éireann routes also serve Finglas, passing along the main Finglas Road, including the 103 from Duleek/Kilmoon Cross/Ashbourne to the city centre (Beresford place,O'Connell street) and is extended at peak times to Saint Stephens Green and University College Dublin (UCD)
People.
Finglas has been the home of many public figures such as:

</doc>
<doc id="38853" url="https://en.wikipedia.org/wiki?curid=38853" title="Tantalus">
Tantalus

Tantalus (, "Tántalos") was a Greek mythological figure, most famous for his eternal punishment in Tartarus. He was made to stand in a pool of water beneath a fruit tree with low branches, with the fruit ever eluding his grasp, and the water always receding before he could take a drink. He was the father of Pelops, Niobe and Broteas, and was a son of Zeus and the nymph Plouto. Thus, like other heroes in Greek mythology such as Theseus and the Dioskouroi, Tantalus had both a hidden, divine parent and a mortal one.
Etymology.
Plato in the "Cratylus" (395e) interprets "Tantalos" as ταλάντατος "talantatos" (acc. ταλάντατον in the original), "who has to bear much" from τάλας "talas" "wretched" (now the word "talas" is held to be inherited from Proto-Indo-European). R. S. P. Beekes has rejected an Indo-European interpretation.
Historical background.
There may have been a historical Tantalus – possibly the ruler of an Anatolian city named "Tantalís", "the city of Tantalus", or of a city named "Sipylus". Pausanias reports that there was a port under his name and a sepulchre of him ""by no means obscure"", in the same region.
Tantalus is referred to as "Phrygian", and sometimes even as "King of Phrygia", although his city was located in the western extremity of Anatolia where Lydia was to emerge as a state before the beginning of the first millennium BC, and not in the traditional heartland of Phrygia, situated more inland. References to his son as "Pelops the Lydian" led some scholars to the conclusion that there would be good grounds for believing that he belonged to a primordial house of Lydia.
Other versions name his father as Tmolus, the name of a king of Lydia and, like Sipylus, of another mountain in ancient Lydia. The location of Tantalus' mortal mountain-fathers generally placed him in Lydia; and more seldom in Phrygia or Paphlagonia, all in Asia Minor.
The identity of his wife is variously given: generally as Dione the daughter of Atlas; the Pleiad Taygete, daughter of Atlas; Eurythemista, a daughter of the river-god Xanthus; Euryanassa, daughter of Pactolus, another river-god of Anatolia, like the Xanthus; Clytia, the child of Amphidamantes; and Eupryto. Tantalus, through Pelops, was the progenitor of the House of Atreus, which was named after his grandson Atreus. Tantalus was also the great-grandfather of Agamemnon and Menelaus.
The geographer Strabo, quoting earlier sources, states that the wealth of Tantalus was derived from the mines of Phrygia and Mount Sipylus. Near Mount Sipylus are archaeological features that have been associated with Tantalus and his house since Antiquity. Near Mount Yamanlar in İzmir (ancient Smyrna), where the Lake Karagöl ("Lake Tantalus") associated with the accounts surrounding him is found, is a monument mentioned by Pausanias: the tholos "tomb of Tantalus" (later Christianized as "Saint Charalambos' tomb") and another one in Mount Sipylus, and where a "throne of Pelops", an altar or bench carved in rock and conjecturally associated with his son is found. A more famous monument, a full-faced statue carved in rock mentioned by Pausanias is a statue of Cybele, said by Pausianias to have been carved by Broteas is in fact Hittite.
Further afield, based on a similarity between the names Tantalus and Hantili, it has been suggested that the name Tantalus may have derived from that of these two Hittite kings.
Story of Tantalus.
In mythology, Tantalus became one of the inhabitants of Tartarus, the deepest portion of the Underworld, reserved for the punishment of evildoers; there Odysseus saw him. The association of Tantalus with the underworld is underscored by the names of his mother Plouto ("riches", as in gold and other mineral wealth), and grandmother, Chthonia ("earth").
Tantalus was initially known for having been welcomed to Zeus' table in Olympus, like Ixion. There he is said to have misbehaved and stolen ambrosia and nectar to bring it back to his people, and revealed the secrets of the gods.
Most famously, Tantalus offered up his son, Pelops, as a sacrifice. He cut Pelops up, boiled him, and served him up in a banquet for the gods. The gods became aware of the gruesome nature of the menu, so they did not touch the offering; only Demeter, distraught by the loss of her daughter, Persephone, absentmindedly ate part of the boy's shoulder. Clotho, one of the three Fates, ordered by Zeus, brought the boy to life again (she collected the parts of the body and boiled them in a sacred cauldron), rebuilding his shoulder with one wrought of ivory made by Hephaestus and presented by Demeter. The revived Pelops grew to be an extraordinarily handsome youth. The god Poseidon took him to Mount Olympus to teach him to use chariots. Later, Zeus threw Pelops out of Olympus due to his anger at Tantalus. The Greeks of classical times claimed to be horrified by Tantalus's doings; cannibalism and kin slaying were atrocities and taboo.
Tantalus's punishment for his act, now a proverbial term for temptation without satisfaction (the source of the English word "tantalise"), was to stand in a pool of water beneath a fruit tree with low branches. Whenever he reached for the fruit, the branches raised his intended meal from his grasp. Whenever he bent down to get a drink, the water receded before he could get any. Over his head towers a threatening stone like the one that Sisyphus is punished to roll up a hill. This fate has cursed him with eternal deprivation of nourishment.
In a different story, Tantalus was blamed for indirectly having stolen the dog made of gold created by Hephaestus (god of metals and smithing) for Rhea to watch over infant Zeus. Tantalus's friend Pandareus stole the dog and gave it to Tantalus for safekeeping. When asked later by Pandareus to return the dog, Tantalus denied that he had it, saying he "had neither seen nor heard of a golden dog." According to Robert Graves, this incident is why an enormous stone hangs over Tantalus's head. Others state that it was Tantalus who stole the dog, and gave it to Pandareus for safekeeping.
Tantalus was also the founder of the cursed House of Atreus in which variations on these atrocities continued. Misfortunes also occurred as a result of these acts, making the house the subject of many Greek tragedies. Tantalus's grave-sanctuary stood on Sipylus but honours were paid him at Argos, where local tradition claimed to possess his bones. In Lesbos, there was another hero-shrine in the small settlement of Polion and a mountain named after Tantalos.
Tantalid family tree.
Tantalus, son of Zeus and Plouto the nymph, and his wife Dione, had two sons Broteas and Pelops, and a daughter, Niobe.
Broteas's son was Tantalus II.
Pelops married Hippodameia and had the following children: Pittheus, Alcathous, Dias, Pleisthenes, Atreus, Thyestes, Copreus, Hippalcimus, Astydameia, Nicippe, and Eurydice. 
Atreus had a son named Agamemnon, whose son was Orestes and Thyestes had three sons: Tantalus III, Pleisthenes, and Aegisthus. Orestes became the ruler of all the Peloponessus and had a son named Tisamenus. Aegisthus had a son named Alete.
Niobe had fourteen children.
Other characters with the same name.
in Greek mythology, there are two other characters named Tantalus—minor figures and descendants of the above Tantalus. Broteas is said to have had a son named Tantalus, who ruled over either the city of Pisa in the Peloponnesus or of Lydia in present-day Turkey. This Tantalus was the first husband of Clytemnestra. He was slain by Agamemnon, King of Mycenae, who made Clytemnestra his wife. The third Tantalus was a son of Thyestes, who was murdered by his uncle Atreus, and fed to his unsuspecting father.

</doc>
