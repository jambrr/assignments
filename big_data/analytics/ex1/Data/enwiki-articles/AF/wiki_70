<doc id="36786" url="https://en.wikipedia.org/wiki?curid=36786" title="Little Ice Age">
Little Ice Age

The Little Ice Age (LIA) was a period of cooling that occurred after the Medieval Warm Period (Medieval Climate Optimum). While it was not a true ice age, the term was introduced into the scientific literature by François E. Matthes in 1939. It has been conventionally defined as a period extending from the sixteenth to the nineteenth centuries, or alternatively, from about 1300 to about 1850, although climatologists and historians working with local records no longer expect to agree on either the start or end dates of this period, which varied according to local conditions.
The NASA Earth Observatory notes three particularly cold intervals: one beginning about 1650, another about 1770, and the last in 1850, each separated by intervals of slight warming. The Intergovernmental Panel on Climate Change Third Assessment Report considered the timing and areas affected by the LIA suggested largely independent regional climate changes, rather than a globally synchronous increased glaciation. At most there was modest cooling of the Northern Hemisphere during the period.
Several causes have been proposed: cyclical lows in solar radiation, heightened volcanic activity, changes in the ocean circulation, an inherent variability in global climate, or decreases in the human population.
Areas involved.
The Intergovernmental Panel on Climate Change Third Assessment Report (TAR) of 2001 describes areas affected by the LIA:
The IPCC Fourth Assessment Report (AR4) of 2007 discusses more recent research, giving particular attention to the Medieval Warm Period. It states that "when viewed together, the currently available reconstructions indicate generally greater variability in centennial time scale trends over the last 1 kyr than was apparent in the TAR." Considering confidence limits, "The result is a picture of relatively cool conditions in the seventeenth and early nineteenth centuries and warmth in the eleventh and early fifteenth centuries, but the warmest conditions are apparent in the twentieth century. Given that the confidence levels surrounding all of the reconstructions are wide, virtually all reconstructions are effectively encompassed within the uncertainty previously indicated in the TAR. The major differences between the various proxy reconstructions relate to the magnitude of past cool excursions, principally during the twelfth to fourteenth, seventeenth and nineteenth centuries."
Dating.
There is no consensus regarding the time when the Little Ice Age began, although a series of events preceding the known climatic minima has often been referenced. In the thirteenth century, pack ice began advancing southwards in the North Atlantic, as did glaciers in Greenland. Anecdotal evidence suggests expanding glaciers almost worldwide. Based on radiocarbon dating of roughly 150 samples of dead plant material with roots intact, collected from beneath ice caps on Baffin Island and Iceland, Miller "et al." (2012) state that cold summers and ice growth began abruptly between 1275 and 1300, followed by "a substantial intensification" from 1430 to 1455.
In contrast, a climate reconstruction based on glacial length shows no great variation from 1600 to 1850, though it shows strong retreat thereafter.
For this reason, any of several dates ranging over 400 years may indicate the beginning of the Little Ice Age:
The Little Ice Age ended in the latter half of the nineteenth century or early in the twentieth century.
Northern Hemisphere.
Europe.
The Little Ice Age brought colder winters to parts of Europe and North America. Farms and villages in the Swiss Alps were destroyed by encroaching glaciers during the mid-seventeenth century. Canals and rivers in Great Britain and the Netherlands were frequently frozen deeply enough to support ice skating and winter festivals. The first River Thames frost fair was in 1607 and the last in 1814; changes to the bridges and the addition of an embankment affected the river flow and depth, hence diminishing the possibility of freezes. Freezing of the Golden Horn and the southern section of the Bosphorus took place in 1622. In 1658, a Swedish army marched across the Great Belt to Denmark to attack Copenhagen. The winter of 1794–1795 was particularly harsh: the French invasion army under Pichegru was able to march on the frozen rivers of the Netherlands, while the Dutch fleet was fixed in the ice in Den Helder harbour. 
Sea ice surrounding Iceland extended for miles in every direction, closing harbors to shipping. The population of Iceland fell by half, though this may have been caused by fluorosis after the eruption of the volcano Laki in 1783. Iceland also suffered failures of cereal crops and people moved away from a grain-based diet. The Norse colonies in Greenland starved and vanished by the early fifteenth century, as crops failed and livestock could not be maintained through increasingly harsh winters, though Jared Diamond has suggested they had exceeded the agricultural carrying capacity before then. Greenland was largely cut off by ice from 1410 to the 1720s.
Hubert Lamb said that in many years, "snowfall was much heavier than recorded before or since, and the snow lay on the ground for many months longer than it does today." In Lisbon, Portugal, snowstorms were much more frequent than today; one winter in the seventeenth century produced eight snowstorms. Many springs and summers were cold and wet but with great variability between years and groups of years. Crop practices throughout Europe had to be altered to adapt to the shortened, less reliable growing season, and there were many years of dearth and famine (such as the Great Famine of 1315–1317, although this may have been before the LIA proper). According to Elizabeth Ewan and Janay Nugent, "Famines in France 1693–94, Norway 1695–96 and Sweden 1696–97 claimed roughly 10 percent of the population of each country. In Estonia and Finland in 1696–97, losses have been estimated at a fifth and a third of the national populations, respectively." Viticulture disappeared from some northern regions and storms caused serious flooding and loss of life. Some of these resulted in permanent loss of large areas of land from the Danish, German and Dutch coasts.
The violin maker Antonio Stradivari produced his instruments during the Little Ice Age. The colder climate is proposed to have caused the wood used in his violins to be denser than in warmer periods, contributing to the tone of his instruments. According to the science historian James Burke, the period inspired such novelties in everyday life as the widespread use of buttons and button-holes, knitting of custom-made undergarments to better cover and insulate the body. Fireplace hoods were installed to make more efficient use of fires for indoor heating, and enclosed stoves were developed, in early versions often covered with ceramic tiles.
"The Little Ice Age" by anthropology professor Brian Fagan of the University of California at Santa Barbara tells of the plight of European peasants during the 1300 to 1850 chill: famines, hypothermia, bread riots and the rise of despotic leaders brutalizing an increasingly dispirited peasantry. In the late seventeenth century, writes Fagan, agriculture had dropped off so dramatically that "lpine villagers lived on bread made from ground nutshells mixed with barley and oat flour." Historian Wolfgang Behringer has linked intensive witch-hunting episodes in Europe to agricultural failures during the Little Ice Age.
Depictions of winter in European painting.
William James Burroughs analyses the depiction of winter in paintings, as does Hans Neuberger. Burroughs asserts that this occurred almost entirely from 1565 to 1665 and was associated with the climatic decline from 1550 onwards. Burroughs claims that before this, there were almost no depictions of winter in art, and "hypothesizes that the unusually harsh winter of 1565 inspired great artists to depict highly original images and that the decline in such paintings was a combination of the 'theme' having been fully explored and mild winters interrupting the flow of painting". Wintry scenes, which entail technical difficulties in painting, have been regularly and well handled since the early fifteenth century by artists in illuminated manuscript cycles showing the "Labours of the Months", typically placed on the calendar pages of books of hours. January and February are typically shown as snowy, as in "February" in the famous cycle in the Les Très Riches Heures du duc de Berry, painted 1412–1416 and illustrated below. At this period independent landscape subjects had not developed as a genre in art, so the absence of other winter scenes is not remarkable.
The famous winter landscape paintings by Pieter Brueghel the Elder, such as "The Hunters in the Snow", are all thought to have been painted in 1565. His son Pieter Brueghel the Younger (1564–1638) also painted many snowy landscapes, though according to Burroughs he "slavishly copied his father's designs. The derivative nature of so much of this work makes it difficult to draw any definite conclusions about the influence of the winters between 1570 and 1600...".
Burroughs says that snowy subjects return to Dutch Golden Age painting with works by Hendrick Avercamp from 1609 onwards. There is then a hiatus between 1627 and 1640, before the main period of such subjects from the 1640s to the 1660s, which relates well with climate records for this later period. The subjects are less popular after about 1660, but this does not match any recorded reduction in severity of winters and may just reflect changes in taste or fashion. In the later period between the 1780s and 1810s, snowy subjects again became popular.
Neuberger analysed 12,000 paintings, held in American and European museums and dated between 1400 and 1967, for cloudiness and darkness. His 1970 publication shows an increase in such depictions that corresponds to the LIA, peaking between 1600 and 1649.
Paintings and contemporary records in Scotland demonstrate that curling and ice skating were popular outdoor winter sports, with curling dating back to the sixteenth century and becoming widely popular in the mid-nineteenth century. As an example, an outdoor curling pond constructed in Gourock in the 1860s remained in use for almost a century, but increasing use of indoor facilities, problems of vandalism, and milder winters led to the pond being abandoned in 1963.
North America.
Early European explorers and settlers of North America reported exceptionally severe winters. For example, according to Lamb, Samuel Champlain reported bearing ice along the shores of Lake Superior in June 1608. Both Europeans and indigenous peoples suffered excess mortality in Maine during the winter of 1607–1608, and extreme frost was reported in the Jamestown, Virginia settlement at the same time. Native Americans formed leagues in response to food shortages. The journal of Pierre de Troyes, Chevalier de Troyes, who led an expedition to James Bay in 1686, recorded that the bay was still littered with so much floating ice that he could hide behind it in his canoe on 1 July. In the winter of 1780, New York Harbor froze, allowing people to walk from Manhattan to Staten Island.
The extent of mountain glaciers had been mapped by the late nineteenth century. In the north and the south temperate zones, snowlines (the boundaries separating zones of net accumulation from those of net ablation) were about lower than they were in 1975. In Glacier National Park, the last episode of glacier advance came in the late 18th and early 19th centuries. In Chesapeake Bay, Maryland, large temperature excursions were possibly related to changes in the strength of North Atlantic thermohaline circulation.
Mesoamerica.
An analysis of several proxies undertaken in Mexico's Yucatan Peninsula, linked by its authors to Maya and Aztec chronicles relating periods of cold and drought, supports the existence of the Little Ice Age in the region.
Atlantic Ocean.
In the North Atlantic, sediments accumulated since the end of the last ice age, nearly 12,000 years ago, show regular increases in the amount of coarse sediment grains deposited from icebergs melting in the now open ocean, indicating a series of 1–2 °C (2–4 °F) cooling events recurring every 1,500 years or so. The most recent of these cooling events was the Little Ice Age. These same cooling events are detected in sediments accumulating off Africa, but the cooling events appear to be larger, ranging between 3–8 °C (6–14 °F).
Outside of Europe and North America.
Although the original designation of a Little Ice Age referred to reduced temperature of Europe and North America, there is some evidence of extended periods of cooling outside this region, although it is not clear whether these are related or independent events. Mann states:
"While there is evidence that many other regions outside Europe exhibited periods of cooler conditions, expanded glaciation, and significantly altered climate conditions, the timing and nature of these variations are highly variable from region to region, and the notion of the Little Ice Age as a globally synchronous cold period has all but been dismissed."
China.
In China, warm-weather crops such as oranges were abandoned in Jiangxi Province, where they had been grown for centuries. Also, the two periods of most frequent typhoon strikes in Guangdong coincide with two of the coldest and driest periods in northern and central China (1660–1680, 1850–1880).
Southern Hemisphere.
Scientific works point out cold spells and climate changes in areas of the Southern Hemisphere and their correlation to the Little Ice Age.
Africa.
In Ethiopia and Mauritania, permanent snow was reported on mountain peaks at levels where it does not occur today. Timbuktu, an important city on the trans-Saharan caravan route, was flooded at least 13 times by the Niger River; there are no records of similar flooding before or since.
In Southern Africa, sediment cores retrieved from Lake Malawi show colder conditions between 1570 and 1820, suggesting the Lake Malawi records "further support, and extend, the global expanse of the Little Ice Age." A novel 3,000-year temperature reconstruction method, based on the rate of stalagmite growth in a cold cave in South Africa, further suggests a cold period from 1500 to 1800 "characterizing the South African Little Ice age."
Antarctica.
Kreutz et al. (1997) compared results from studies of West Antarctic ice cores with the Greenland Ice Sheet Project Two (GISP2) and suggested a synchronous global Little Ice Age. An ocean sediment core from the eastern Bransfield Basin in the Antarctic Peninsula shows centennial events that the authors link to the Little Ice Age and Medieval Warm Period. The authors note "other unexplained climatic events comparable in duration and amplitude to the LIA and MWP events also appear."
The Siple Dome (SD) had a climate event with an onset time that is coincident with that of the LIA in the North Atlantic based on a correlation with the GISP2 record. The event is the most dramatic climate event in the SD Holocene glaciochemical record. The Siple Dome ice core also contained its highest rate of melt layers (up to 8%) between 1550 and 1700, most likely because of warm summers. Law Dome ice cores show lower levels of mixing ratios during 1550–1800, results that Etheridge and Steele conjecture are "probably as a result of colder global climate."
Sediment cores in Bransfield Basin, Antarctic Peninsula, have neoglacial indicators by diatom and sea-ice taxa variations during the period of the LIA. The MES stable isotope record suggests that the Ross Sea region experienced 1.6 ± 1.4 °C cooler average temperatures during the LIA in comparison to the last 150 years.
Australia and New Zealand.
Limited evidence describes conditions in Australia. Lake records in Victoria suggest that conditions, at least in the south of the state, were wet and/or unusually cool. In the north, evidence suggests fairly dry conditions, while coral cores from the Great Barrier Reef show similar rainfall as today, but with less variability. A study that analyzed isotopes in Great Barrier Reef corals suggested that increased water vapor transport from southern tropical oceans to the poles contributed to the LIA. Borehole reconstructions from Australia suggest that over the last 500 years, the seventeenth century was the coldest on the continent, but the borehole temperature reconstruction method does not show good agreement between the Northern and Southern Hemispheres.
On the west coast of the Southern Alps of New Zealand, the Franz Josef glacier advanced rapidly during the Little Ice Age, reaching its maximum extent in the early eighteenth century, in one of the few places where a glacier thrust into a rain forest. Based on dating of a yellow-green lichen of the "Rhizocarpon" subgenus, the Mueller Glacier, on the eastern flank of the Southern Alps within Aoraki/Mount Cook National Park, is considered to have been at its maximum extent between 1725 and 1730.
Pacific Islands.
Sea-level data for the Pacific Islands suggest that sea level in the region fell, possibly in two stages, between 1270 and 1475. This was associated with a 1.5 °C fall in temperature (determined from oxygen-isotope analysis) and an observed increase in El Niño frequency. Tropical Pacific coral records indicate the most frequent, intense El Niño-Southern Oscillation activity in the mid-seventeenth century.
South America.
Tree-ring data from Patagonia show cold episodes between 1270 and 1380 and from 1520 to 1670, periods contemporary with LIA events in the Northern Hemisphere. Eight sediment cores taken from Puyehue Lake have been interpreted as showing a humid period from 1470 to 1700, which the authors describe as a regional marker of LIA onset. A 2009 paper details cooler and wetter conditions in southeastern South America between 1550 and 1800, citing evidence obtained via several proxies and models. 18O records from three Andean ice cores show a cool period from 1600–1800 
Although only anecdotal evidence, in 1675 the Spanish explorer Antonio de Vea entered San Rafael Lagoon through Río Témpanos (Spanish for "Ice Floe River") without mentioning any ice floe but stating that the San Rafael Glacier did not reach far into the lagoon. In 1766, another expedition noticed that the glacier reached the lagoon and calved into large icebergs. Hans Steffen visited the area in 1898, noticing that the glacier penetrated far into the lagoon. Such historical records indicate a general cooling in the area between 1675 and 1898: "The recognition of the LIA in northern Patagonia, through the use of documentary sources, provides important, independent evidence for the occurrence of this phenomenon in the region." As of 2001, the border of the glacier had significantly retreated as compared to the borders of 1675.
Possible causes.
Scientists have tentatively identified these possible causes of the Little Ice Age: orbital cycles; decreased solar activity; increased volcanic activity; altered ocean current flows; the inherent variability of global climate; and reforestation following decreases in the human population.
Orbital cycles.
Orbital forcing from cycles in the earth's orbit around the sun has, for the past 2,000 years, caused a long-term northern hemisphere cooling trend that continued through the Middle Ages and the Little Ice Age. The rate of Arctic cooling is roughly 0.02 °C per century. This trend could be extrapolated to continue into the future, possibly leading to a full ice age, but the twentieth-century instrumental temperature record shows a sudden reversal of this trend, with a rise in global temperatures attributed to greenhouse gas emissions.
Solar activity.
There is still a very poor understanding of the correlation between low sunspot activity and cooling temperatures. During the period 1645–1715, in the middle of the Little Ice Age, there was a period of low solar activity known as the Maunder Minimum. The Spörer Minimum has also been identified with a significant cooling period between 1460 and 1550. Other indicators of low solar activity during this period are levels of the isotopes carbon-14 and beryllium-10.
Volcanic activity.
In a 2012 paper, Miller "et al." link the Little Ice Age to an "unusual 50-year-long episode with four large sulfur-rich explosive eruptions, each with global sulfate loading >60 Tg" and notes that "large changes in solar irradiance are not required."
Throughout the Little Ice Age, the world experienced heightened volcanic activity. When a volcano erupts, its ash reaches high into the atmosphere and can spread to cover the whole earth. The ash cloud blocks out some of the incoming solar radiation, leading to worldwide cooling that can last up to two years after an eruption. Also emitted by eruptions is sulfur, in the form of sulfur dioxide gas. When it reaches the stratosphere, it turns into sulfuric acid particles, which reflect the sun's rays, further reducing the amount of radiation reaching Earth's surface.
A recent study found that an especially massive tropical volcanic eruption in 1258, possibly of Mount Rinjani, followed by three smaller eruptions in 1268, 1275, and 1284 did not allow the climate to recover. This may have caused the initial cooling, and the 1452–53 eruption of Kuwae in Vanuatu triggered a second pulse of cooling. The cold summers can be maintained by sea-ice/ocean feedbacks long after volcanic aerosols are removed.
Other volcanoes that erupted during the era and may have contributed to the cooling include Billy Mitchell (ca. 1580), Huaynaputina (1600), Mount Parker (1641), Long Island (Papua New Guinea) (ca. 1660), and Laki (1783). The 1815 eruption of Tambora in Indonesia blanketed the atmosphere with ash; the following year, 1816, came to be known as the Year Without a Summer, when frost and snow were reported in June and July in both New England and Northern Europe.
Ocean circulation.
Another possibility is that there was a slowing of thermohaline circulation. The circulation could have been interrupted by the introduction of a large amount of fresh water into the North Atlantic, possibly caused by a period of warming before the Little Ice Age known as the Medieval Warm Period. There is some concern that a shutdown of thermohaline circulation could happen again as a result of the present warming period.
Decreased human populations.
Some researchers have proposed that human influences on climate began earlier than is normally supposed (see Early anthropocene for more details) and that major population declines in Eurasia and the Americas reduced this impact, leading to a cooling trend. William Ruddiman has proposed that somewhat reduced populations of Europe, East Asia, and the Middle East during and after the Black Death caused a decrease in agricultural activity. He suggests reforestation took place, allowing more carbon dioxide uptake from the atmosphere, which may have been a factor in the cooling noted during the Little Ice Age. Ruddiman further hypothesizes that a reduced population in the Americas after European contact in the early sixteenth century could have had a similar effect. Faust, Gnecco, Mannstein and Stamm (2005) and Nevle (2011) supported depopulation in the Americas as a factor, asserting that humans had cleared considerable amounts of forests to support agriculture in the Americas before the arrival of Europeans brought on a population collapse. A 2008 study of sediment cores and soil samples further suggests that carbon dioxide uptake via reforestation in the Americas could have contributed to the Little Ice Age. The depopulation is linked to a drop in carbon dioxide levels observed at Law Dome, Antarctica.
Increased human populations.
It has been speculated that increased human populations living at high altitudes caused the Little Ice Age through deforestation. The increased albedo due to this deforestation (more reflection of solar rays from snow-covered ground than dark, tree-covered area) could have had a profound effect on global temperatures.
Inherent variability of climate.
Spontaneous fluctuations in global climate might explain past variability. It is very difficult to know what the true level of variability from only internal causes might be since other forcings, as noted above, exist whose magnitude may not be known either. One approach to evaluating internal variability is to use long integrations of coupled ocean-atmosphere global climate models. They have the advantage that the external forcing is known to be zero, but the disadvantage is that they may not fully reflect reality. The variations may result from chaos-driven changes in the oceans, the atmosphere, or interactions between the two. Two studies have concluded that the demonstrated inherent variability is not great enough to account for the Little Ice Age.

</doc>
<doc id="36787" url="https://en.wikipedia.org/wiki?curid=36787" title="Budapest">
Budapest

BudapestSource: </ref> (; ) is the capital and the largest city of Hungary, and one of the largest cities in the European Union. It is the country's principal political, cultural, commercial, industrial, and transportation centre, sometimes described as the primate city of Hungary. According to the census, in 2011 Budapest had 1.74 million inhabitants, down from its 1989 peak of 2.1 million due to suburbanisation. The Budapest Metropolitan Area is home to 3.3 million people. The city covers an area of . Budapest became a single city occupying both banks of the river Danube with the unification of Buda and Óbuda on the west bank, with Pest on the east bank on 17 November 1873.
The history of Budapest began with Aquincum, originally a Celtic settlement that became the Roman capital of Lower Pannonia. Hungarians arrived in the territory in the 9th century. Their first settlement was pillaged by the Mongols in 1241–42. The re-established town became one of the centres of Renaissance humanist culture by the 15th century. Following the Battle of Mohács and nearly 150 years of Ottoman rule, the region entered a new age of prosperity in the 18th and 19th centuries, and Budapest became a global city after its unification in 1873. It also became the second capital of the Austro-Hungarian Empire, a great power that dissolved in 1918, following World War I. Budapest was the focal point of the Hungarian Revolution of 1848, the Hungarian Republic of Councils in 1919, the Battle of Budapest in 1945, and the Revolution of 1956.
Cited as one of the most beautiful cities in Europe, Budapest's extensive World Heritage Site includes the banks of the Danube, the Buda Castle Quarter, Andrássy Avenue, Heroes' Square and the Millennium Underground Railway, the second-oldest metro line in the world. It has around 80 geothermal springs, the world's largest thermal water cave system, second largest synagogue, and third largest Parliament building. The city attracts about 4.4 million tourists a year, making it the 25th most popular city in the world, and the 6th in Europe, according to Euromonitor.
Considered a financial hub in Central Europe, the city ranked third on Mastercard's Emerging Markets Index, and ranked as the most liveable Central or Eastern European city on EIU's quality of life index. It is also ranked as "the world's second best city" by Condé Nast Traveler, and "Europe's 7th most idyllic place to live" by Forbes. It is the highest ranked Central/Eastern European city on Innovation Cities' Top 100 index.
Budapest is home to the headquarters of the European Institute of Innovation and Technology (EIT), the European Police College (CEPOL) and the first foreign office of the China Investment Promotion Agency (CIPA). Eighteen universities are situated in Budapest, including the Central European University, Eötvös Loránd University and the Budapest University of Technology and Economics.
Etymology.
"Budapest" is the combination of the city names Buda and Pest, which were (together with Óbuda) united into a single city in 1873. One of the first documented occurrences of the combined name "Buda-Pest" was in 1831 in the book "Világ" ("World" / "Light"), written by Count István Széchenyi.
The origins of the names "Buda" and "Pest" are obscure. According to chronicles from the Middle Ages, the name "Buda" comes from the name of its founder, Bleda (Buda), brother of the Hunnic ruler Attila. The theory that "Buda" was named after a person is also supported by modern scholars. An alternative explanation suggests that "Buda" derives from the Slavic word вода, "voda" ("water"), a translation of the Latin name Aquincum, which was the main Roman settlement in the region.
There are also several theories about the origin of the name "Pest". One of the theories states that the word "Pest" comes from the Roman times, since there was a fortress ("Contra-Aquincum") in this region that was referred to as "Pession" ("Πέσσιον", iii.7.§ 2) by Ptolemaios. According to another theory, "Pest" originates from the Slavic word for cave (most closely related to Bulgarian and Macedonian: пещера, "peștera"), or oven (, "peșt"), in reference either to a cave where fires burned or to a local limekiln.
History.
Early history.
The first settlement on the territory of Budapest was built by Celts before 1 AD. It was later occupied by the Romans. The Roman settlement – Aquincum – became the main city of Pannonia Inferior in 106 AD. At first it was a military settlement, and gradually the city rose around it, making it the focal point of the city's commercial life. Today this area corresponds to the Óbuda district within Budapest. The Romans constructed roads, amphitheaters, baths and houses with heated floors in this fortified military camp. The Roman city of Aquincum is the best-conserved of the Roman sites in Hungary. The archaeological site was turned into a museum with inside and open-air sections.
Hungarians led by Árpád settled in the territory at the end of the 9th century, and a century later officially founded the Kingdom of Hungary. Research places the probable residence of the Árpáds as an early place of central power near what became Budapest. The Tatar invasion in the 13th century quickly proved that it is difficult to mount a defence on a plain. King Béla IV of Hungary therefore ordered the construction of reinforced stone walls around the towns and set his own royal palace on the top of the protecting hills of Buda. In 1361 it became the capital of Hungary.
The cultural role of Buda was particularly significant during the reign of King Matthias Corvinus. The Italian Renaissance had a great influence on the city. His library, the Bibliotheca Corviniana, was Europe's greatest collection of historical chronicles and philosophic and scientific works in the 15th century, and second only in size to the Vatican Library. After the foundation of the first Hungarian university in Pécs in 1367 (University of Pécs), the second one was established in Óbuda in 1395 (University of Óbuda). The first Hungarian book was printed in Buda in 1473. Buda had about 5,000 inhabitants around 1500.
The Ottomans pillaged Buda in 1526, besieged it in 1529, and finally occupied it in 1541. The Turkish occupation lasted for more than 140 years. The Turks constructed many fine bathing facilities within the city. Some of the baths that the Turks erected during their occupation period are still in use 500 years later (Rudas Baths and Király Baths). Under Ottoman rule many Christians became Muslim. By 1547 the number of Christians was down to about a thousand, and by 1647 it had fallen to only about seventy. The unoccupied western part of the country became part of the Habsburg Empire as Royal Hungary.
In 1686, two years after the unsuccessful siege of Buda, a renewed campaign was started to enter the Hungarian capital. This time, the Holy League's army was twice as large, containing over 74,000 men, including German, Croat, Dutch, Hungarian, English, Spanish, Czech, Italian, French, Burgundian, Danish and Swedish soldiers, along with other Europeans as volunteers, artillerymen, and officers. The Christian forces reconquered Buda, and in the next few years, all of the former Hungarian lands, except areas near Timișoara (Temesvár), were taken from the Turks. In the 1699 Treaty of Karlowitz these territorial changes were officially recognised, and in 1718 the entire Kingdom of Hungary was removed from Ottoman rule.
Contemporary history after Unification.
The 19th century was dominated by the Hungarian struggle for independence and modernisation. The national insurrection against the Habsburgs began in the Hungarian capital in 1848 and was defeated one and a half years later, with the help of the Russian Empire. 1867 was the year of Reconciliation that brought about the birth of Austria-Hungary. This made Budapest the twin capital of a dual monarchy. It was this compromise which opened the second great phase of development in the history of Budapest, lasting until World War I. In 1849 the Chain Bridge linking Buda with Pest was opened as the first permanent bridge across the Danube and in 1873 Buda and Pest were officially merged with the third part, Óbuda (Ancient Buda), thus creating the new metropolis of Budapest. The dynamic Pest grew into the country's administrative, political, economic, trade and cultural hub. Ethnic Hungarians overtook Germans in the second half of the 19th century due to mass migration from the overpopulated rural Transdanubia and Great Hungarian Plain. Between 1851 and 1910 the proportion of Hungarians increased from 35.6% to 85.9%, Hungarian became the dominant language, and German was crowded out. The proportion of Jews peaked in 1900 with 23.6%. Due to the prosperity and the large Jewish community of the city at the start of the 20th century, Budapest was often called the "Jewish Mecca" or "Judapest".
In 1918, Austria-Hungary lost the war and collapsed; Hungary declared itself an independent republic (Republic of Hungary). In 1920 the Treaty of Trianon partitioned the country, and as a result, Hungary lost over two-thirds of its territory, and about two-thirds of its inhabitants, including 3.3 million out of 15 million ethnic Hungarians.
In 1944, about one year before the end of World War II, Budapest was partly destroyed by British and American air raids (first attack 4 April 1944,).
From 24 December 1944 to 13 February 1945, the city was besieged during the Battle of Budapest. Budapest suffered major damage caused by the attacking Soviet and Romanian troops and the defending German and Hungarian troops. More than 38,000 civilians lost their lives during the conflict. All bridges were destroyed by the Germans. The stone lions that have decorated the Chain Bridge since 1852 survived the devastation of the war.
Between 20% and 40% of Greater Budapest's 250,000 Jewish inhabitants died through Nazi and Arrow Cross Party, during the Germany occupation of Hungary, from 1944 to early 1945. 
Swiss diplomat Carl Lutz rescued tens of thousands of Jews by issuing Swiss protection papers and designating numerous buildings, including the now famous Glass House (Üvegház) at Vadász Street 29, to be Swiss protected territory. About 3,000 Hungarian Jews found refuge at the Glass House and in a neighboring building. Swedish diplomat Raoul Wallenberg managed to save the lives of tens of thousands of Jews in Budapest by giving them Swedish protection papers and taking them under his consular protection. Wallenberg was abducted by the Russians on 17 January 1945 and never regained freedom. Some other diplomats also abandoned diplomatic protocol and rescued Jews. There are two monuments for Wallenberg and one for Carl Lutz in Budapest.
Following the liberation of Hungary from Nazi Germany by the Red Army, Soviet military occupation ensued, which ended only in 1991. The Soviets exerted significant influence on Hungarian political affairs. In 1949, Hungary was declared a communist People's Republic (People's Republic of Hungary). The new Communist government considered the buildings like the Buda Castle symbols of the former regime, and during the 1950s the palace was gutted and all the interiors were destroyed (also see Stalin era).
On 23 October 1956 citizens held a large peaceful demonstration in Budapest demanding democratic reform. The demonstrators went to the Budapest radio station and demanded to publish their demands. The regime ordered troops to shoot into the crowd. Hungarian soldiers gave rifles to the demonstrators who were now able to capture the building. This initiated the Hungarian Revolution of 1956. The demonstrators demanded to appoint Imre Nagy to be Prime Minister of Hungary. To their surprise, the central committee of the "Hungarian Working People's Party" did so that same evening. This uprising was an anti-Soviet revolt that lasted from 23 October until 11 November. After Nagy had declared that Hungary was to leave the Warsaw Pact and become neutral, Soviet tanks and troops entered the country to crush the revolt. Fighting continued until mid November, leaving more than 3000 dead. A monument was erected at the fiftieth anniversary of the revolt in 2006, at the edge of the City Park. Its shape is a wedge with a 56 angle degree made in rusted iron that gradually becomes shiny, ending in an intersection to symbolize Hungarian forces that temporarily eradicated the Communist leadership.
From the 1960s to the late 1980s Hungary was often satirically referred to as "the happiest barrack" within the Eastern bloc, and much of the wartime damage to the city was finally repaired. Work on Erzsébet Bridge, the last to be rebuilt, was finished in 1964. In the early 1970s, Budapest Metro's East-West M2 line was first opened, followed by the M3 line in 1976. In 1987, Buda Castle and the banks of the Danube were included in the UNESCO list of World Heritage Sites. Andrássy Avenue (including the Millennium Underground Railway, Hősök tere, and Városliget) was added to the UNESCO list in 2002. In the 1980s, the city's population reached 2.1 million. In recent times a significant decrease in population occurred mainly due to a massive movement to the neighbouring agglomeration in Pest county, i.e., suburbanisation.
In the last decades of the 20th century the political changes of 1989–90 (Fall of the Iron Curtain) concealed changes in civil society and along the streets of Budapest. The monuments of the dictatorship were removed from public places, into Memento Park. In the first 20 years of the new democracy, the development of the city was managed by its mayor, Gábor Demszky.
Geography.
Topography.
Budapest, strategically placed at the centre of the Carpathian Basin, lies on an ancient route linking the hills of Transdanubia with the Great Plain. By road it is south-east of Vienna, south of Warsaw, south-west of Moscow, north of Athens, north-east of Milan, and south-east of Prague.
The area of Budapest lies in Central Hungary, surrounded by settlements of the agglomeration in Pest county. The capital extends in the north-south, east-west direction respectively. The Danube enters the city from the north; later it encircles two islands, Óbuda Island and Margaret Island. The third island Csepel Island is the largest of the Budapest Danube islands, however only its northernmost tip is within city limits. The river that separates the two parts of the city is wide at its narrowest point in Budapest. Pest lies on the flat terrain of the Great Plain while Buda is rather hilly.
The wide Danube was always fordable at this point because of a small number of islands in the middle of the river. The city has marked topographical contrasts: Buda is built on the higher river terraces and hills of the western side, while the considerably larger Pest spreads out on a flat and featureless sand plain on the river’s opposite bank. Pest's terrain rises with a slight eastward gradient, so the easternmost parts of the city lie at the same altitude as Buda's smallest hills, notably Gellért Hill and Castle Hill.
The Buda hills consist mainly of limestone and dolomite, the water created speleothems, the most famous ones being the Pálvölgyi cave (total length 7200 m) and the Szemlőhegyi cave (total length 2200 m). The hills were formed in the Triassic Period. The highest point of the hills and of Budapest is János hill, at above sea level. The lowest point is the line of the Danube which is Above mean sea level|above sea level. Budapest is also rich in green areas. Of the occupied by the city, is green area, park and forest. The forests of Buda hills are environmentally protected.
The city's importance in terms of traffic is very central, because all major European roads and European railway lines lead to Budapest. The Danube was and is still an important water-way and this region in the centre of the Carpathian Basin lies at the cross-roads of trade routes.
Budapest is the only capital city in the world which has thermal springs. Some 125 springs produce 70 million litres of thermal water a day, with temperatures ranging up to 58 Celsius. Some of these waters have medicinal effects due to their medically valuable mineral contents.
Climate.
Budapest has an oceanic climate ("Cfb") using the isotherm of the original Köppen scheme, or a humid continental climate (Köppen "Dfb"), using the isotherm preferred by some climatologists, with relatively cold winters and warm summers.
Winter (November until early March) can be cold and the city receives little sunshine. Snowfall is fairly frequent in most years, and nighttime temperatures of are not uncommon between mid-December and mid-February. The spring months (March and April) see variable conditions, with a rapid increase in the average temperature. The weather in late March and April is often very agreeable during the day and fresh at night. Budapest's long summer – lasting from May until mid-September – is warm or very warm. Budapest has as much summer sunshine as many Mediterranean resorts. Sudden heavy showers also occur, particularly in May and June. The autumn in Budapest (mid-September until late October) is characterised by little rain and long sunny days with moderate temperatures. Temperatures often turn abruptly colder in late October.
Mean annual precipitation in Budapest is around 23.5 inches (600 mm). On average, there are 78 days with precipitation and 1988 hours of sunshine (of a possible 4383) each year.
The city lies on the boundary between Zone 6 and Zone 7 in terms of the hardiness zone.
Architecture.
Budapest has architecturally noteworthy buildings in a wide range of styles and from distinct time periods, from the ancient times as Roman City of Aquincum in Óbuda (District III), which dates to around 89 AD, to the most modern Palace of Arts, the contemporary arts museum and concert hall.
Most buildings in Budapest are relatively low: in the early 2010s there were around 100 buildings higher than . The number of high-rise buildings is kept low by building legislation, which is aimed at preserving the historic cityscape and to meet the requirements of the World Heritage Site. Strong rules apply to the planning, authorisation and construction of high-rise buildings and consequently much of the inner city does not have any. But Budapest is planning to ease rules for the construction of skyscrapers and in the near future would like to build skyscrapers around the city's historic core.
In the chronological order of architectural styles Budapest represents on the entire timeline. Start with the Roman City of Aquincum represents the ancient architecture.
The next determinative style is the Gothic architecture in Budapest. The few remaining ones can be found in the Castle District. Buildings to look for are no. 18, 20 and 22 on Országház Street, which date back to the 14th century and No. 31 Úri Street, which has a Gothic façade that dates back to the 15th century. Another building with Gothic remains is the Inner City Parish Church in Pest, built in the 12th century. The most characteristic Gothic-style buildings are actually Neo-Gothic, like the most well-known Budapest landmarks, the Hungarian Parliament Building and the Matthias Church, where much of the original material was used (originally built in Romanesque style in 1015).
The next chapter of the human architecture is the Renaissance architecture and one of the earliest places to be influenced by the Renaissance style of architecture was Hungary and Budapest. The style appeared following the marriage of King Matthias Corvinus and Beatrice of Naples in 1476. Many Italian artists, craftsmen and masons came to Buda with the new queen. Today, many of the original renaissance buildings disappeared during the varied history of Buda, but Budapest is still rich in renaissance and neo-renaissance buildings, like the famous Hungarian State Opera House, the St. Stephen's Basilica and the Hungarian Academy of Sciences.
During the Turkish occupation (1541–1686), multiple mosques and baths were built in the city. These were great examples of Ottoman architecture, which was influenced by Iranian, and to a larger extent, Byzantine architecture as well as Islamic traditions. Budapest is in fact one of the few places in the world with functioning original Turkish bathhouses dating back to the 16th century, like Rudas Baths or Király Baths. Another little known fact is that Budapest is home to the northernmost holy place of Islam, the Tomb of Gül Baba, tomb of a Turkish dervish. After 1686, the Baroque architecture designated the dominant style of art in catholic countries from the 17th century to the 18th century.
There are many Baroque-style buildings in Budapest and one of the finest examples of original Baroque-style architecture is the Church of St. Anna in Batthyhány square. An interesting part of Budapest is the less touristy Óbuda, the main square of which also has some beautiful historic buildings with original Baroque façades. The Castle District is another place to visit where the best-known landmark Buda Royal Palace and many other buildings were built in the Baroque style.
The Classical architecture and Neoclassical architecture are the next in the timeline. Budapest had not one but two architects that were masters of the Classicist style. Mihály Pollack (1773–1855) and József Hild (1789–1867), built many beautiful Classicist-style buildings in the city. Some of the best examples are the Hungarian National Museum, the Lutheran Church of Budavár (both designed by Pollack) and the seat of the Hungarian president, the Sándor Palace. The most iconic Classicist-style attraction in Budapest, the most widely known Chain Bridge. A bit of maverick in architectural styles the Romanticism. Budapest's two most beautiful Romantic architecture buildings are the Great Synagogue in Dohány Street and the Vigadó Concert Hall on the Danube Promenade, both designed by architect Frigyes Feszl (1821–1884). Another noteworthy structure is the Budapest Western Railway Station, which was designed by August de Serres and built by the Eiffel Company of Paris in 1877.
Art Nouveau came into fashion in Budapest by the exhibitions which were held in and around 1896 and organised in connection with the Hungarian Millennium celebrations. Art Nouveau in Hungary ("Szecesszió" in Hungarian) is a blend of several architectural styles, with a focus on Hungary's specialities. One of the leading Art Nouveau architects, Ödön Lechner (1845–1914), was inspired by Indian and Syrian architecture as well as traditional Hungarian decorative designs. One of his most beautiful buildings in Budapest is the Museum of Applied Arts. Another examples for Art Nouveau in Budapest is the Gresham Palace in front of the Chain Bridge, the Hotel Gellért, the Franz Liszt Academy of Music or Budapest Zoo and Botanical Garden.
In the 21st century, Budapest faces new challenges in its architecture. The pressure towards the high-rise buildings is unequivocal among today's world cities, but preserving Budapest's unique cityscape and its very diverse architecture, along with green areas, is force Budapest to balance between them. The Contemporary architecture has wide margin in the city. Public spaces attract heavy investment by business and government also, so that the city has gained entirely new (or renovated and redesigned) squares, parks and monuments, for example the city central Kossuth Lajos square, Deák Ferenc square and Liberty Square. Budapest's current urban landscape is one of the modern and contemporary architecture. Numerous landmarks are created in the last decade in Budapest, like the National Theatre, Palace of Arts, Rákóczi Bridge, Megyeri Bridge, Budapest Airport Sky Court among others, and millions of square meters of new office buildings and apartments. But there are still large opportunities in real estate development in the city.
Districts.
Most of today's Budapest is the result of a late-nineteenth-century renovation, but the wide boulevards lain then only bordered and bisected much older quarters of activity created by centuries of Budapest's city evolution.
Budapest's vast urban area is often described using a set of district names. These are either informal designations, reflect the names of villages that have been absorbed by sprawl, or are superseded administrative units of former boroughs.
Such names have remained in use through tradition, each referring to a local area with its own distinctive character, but without official boundaries.
Originally Budapest had 10 districts after coming into existence upon the unification of the three cities in 1873. Since 1950, Greater Budapest has been divided into 22 boroughs (and 23 since 1994). At that time there were changes both in the order of districts and in their sizes. The city now consists of 23 districts, 6 in Buda, 16 in Pest and 1 on Csepel Island between them.
The city centre itself in a broader sense comprises the District V, VI, VII, VIII, IX and XIII on the Pest side, and the I, II, XI and XII on the Buda side of the city.
District I is a small area in central Buda, including the historic Buda Castle. District II is in Buda again, in the northwest, and District III stretches along in the northernmost part of Buda. To reach District IV, one must cross the Danube to find it in Pest (the eastern side), also at north. With District V, another circle begins, it is located in the absolute centre of Pest. Districts VI, VII, VIII and IX are the neighbouring areas to the east, going southwards, one after the other.
District X is another, more external circle also in Pest, while one must jump to the Buda side again to find Districts XI and XII, going northwards. No more districts remaining in Buda in this circle, we must turn our steps to Pest again to find Districts XIII, XIV, XV, XVI, XVII, XVIII, XIX and XX (mostly external city parts), almost regularly in a semicircle, going southwards again.
District XXI is the extension of the above route over a branch of the Danube, the northern tip of a long island south from Budapest. District XXII is still on the same route in southwest Buda, and finally District XXIII is again in southernmost Pest, irregular only because it was part of District XX until 1994.
Demographics.
Budapest is the most populous city in Hungary and one of the largest cities in the European Union, with a growing number of inhabitants, estimated at 1,742,000 in 2014, whereby inward migration exceeds outward migration. These trends are also seen throughout the Budapest metropolitan area, which is home to 3.3 million people. This amounts to about 34% of Hungary's population.
In 2014, the city had a population density of 3,314 people per square kilometre (8,580/sq mi), rendering it the most densely populated of all municipalities in Hungary. The population density of District VII (Elisabethtown) is 30,989/km² (80,260/sq mi), which is the highest population density figure in Hungary and one of the highest in the world (for comparison the density in Manhattan is 25,846/km²)."
Budapest is the fourth most "dynamically growing city" by population in Europe, and the Euromonitor predicts a population increase of almost 10% between 2005 and 2030. The European Observation Network for Territorial Development and Cohesion says Budapest's population will increase by 10% to 30% only due to migration by 2050. A constant inflow of migrants in recent years has fuelled population growth in Budapest. Productivity gains and the relatively large economically active share of the population explain why household incomes have increased in Budapest to a greater extent than in other parts of Hungary. Higher incomes in Budapest are reflected in the lower share of expenditure the city’s inhabitants allocate to necessity spending such as food and non-alcoholic drinks.
At the 2011 census, there were 1,729,040 people with 906,782 households living in Budapest. Some 1.6 million persons from the metropolitan area may be within Budapest's boundaries during work hours, and during special events. This fluctuation of people is caused by hundreds of thousands of suburban residents who travel to the city for work, education, health care, and special events.
By ethnicity there were 1,397,851 (80.8%) Hungarians, 19,530 (1.1%) Romani, 18,278 (1.0%) Germans, 6,189 (0.4%) Romanians, 4,692 (0.3%) Chinese and 2,581 (0.1%) Slovaks. 301,943 people (17.5%) did not declare their ethnicity. In Hungary people can declare more than one ethnicity, so the sum of ethnicities is higher than the total population. The city is home to one of the largest Jewish communities in Europe.
According to the same census, 1,600,585 people (92.6%) were born in Hungary, 126,036 people (7.3%) outside Hungary while the birthplace of 2,419 people (0.1%) was unknown.
Although only 1.7% of the population of Hungary in 2009 were foreigners, 43% of them lived in Budapest, making them 4.4% of the city's population (up from 2% in 2001). Nearly two-thirds of foreigners living in Hungary were under 40 years old. The primary motivation for this age group living in Hungary was employment.
According to the 2011 census, 1,712,153 people (99.0%) speak Hungarian, of whom 1,692,815 people (97.9%) speak it as a first language, while 19,338 people (1.1%) speak it as a second language. Other spoken (foreign) languages were: English (536,855 speakers, 31.0%), German (266,249 speakers, 15.4%), French (56,208 speakers, 3.3%) and Russian (54,613 speakers, 3.2%).
Budapest is the home to one of the most populous Christian community in Central Europe, numbered 698,521 people (40.4%) in 2011. According to the 2011 census, there were 501,117 (29.0%) Roman Catholics, 146,756 (8.5%) Calvinists, 30,293 (1.8%) Lutherans, 16,192 (0.9%) Greek Catholics, 7,925 (0.5%) Jews and 3,710 (0.2%) Orthodox in Budapest. 395,964 people (22.9%) were irreligious while 585,475 people (33.9%) did not declare their religion. A Hungarian Central Statistical Office report showed that also, the proportion of Romani in Budapest increased from 2% in 1990 to 4.6% in 2009.
Economy.
Budapest is a significant economic hub, classified as an Alpha- world city in the study by the Globalization and World Cities Research Network and it is the second fastest-developing urban economy in Europe as GDP per capita in the city increased by 2.4 per cent and employment by 4.7 per cent compared to the previous year in 2014.
On national level, Budapest is the primate city of Hungary regarding business and economy, accounting for 39% of the national income, the city has a gross metropolitan product more than $100 billion in 2015, making it one of the largest regional economy in the European Union.
According to the Eurostat GDP per capita in purchasing power parity is 147% of the EU average in Budapest, which means €37.632 ($52.770) per capita.
Budapest is also among the Top100 GDP performing cities in the world, measured by PricewaterhouseCoopers.
The city was named as the 52nd most important business centre in the world in the Worldwide Centres of Commerce Index, ahead of Beijing, Warsaw, Sao Paulo or Shenzhen and ranking 3rd (out of 65 cities) on MasterCard Emerging Markets Index.
The city is 48th on the UBS "The most expensive and richest cities in the world" list, standing before cities such as Prague, Shanghai, Kuala Lumpur or Buenos Aires.
In a global city competitiveness ranking by EIU, Budapest is stands before Tel Aviv, Lisbon, Moscow and Johannesburg among others.
The city is a major centre for banking and finance, real estate, retailing, trade, transportation, tourism, new media as well as traditional media, advertising, legal services, accountancy, insurance, fashion and the arts in Hungary and regionally. Budapest is home not only to almost all national institutions and government agencies, but also to many domestic and international companies, in 2014 there are 395.804 companies registered in the city. Most of these entities are headquartered in the Budapest's Central Business District, in the District V and District XIII. The retail market of the city (and the country) is also concentrated in the downtown, among others through the two largest shopping centre in Central and Eastern Europe, the 186,000sqm WestEnd City Center and the 180,000sqm Arena Plaza.
Budapest has notable innovation capabilities as a technology and start-up hub, many start-ups are headquartered and begin its business in the city, for instance deserve to mention the most well-known Prezi, LogMeIn or Nav N Go. Budapest is the highest ranked Central and Eastern European city on Innovation Cities' Top 100 index. A good indicator of the city's potential for innovation and research also, is that the European Institute of Innovation and Technology chose Budapest for its headquarters, along with the UN, which Regional Representation for Central Europe office is in the city, responsible for UN operations in seven countries.
Moreover, the global aspect of the city's research activity is shown through the establishment of the European Chinese Research Institute in the city. Other important sectors include also, as natural science research, information technology and medical research, non-profit institutions, and universities. The leading business schools and universities in Budapest, the Budapest Business School, the CEU Business School and Corvinus University of Budapest offers a whole range of courses in economics, finance and management in English, French, German and Hungarian. The unemployment rate is far the lowest in Budapest within Hungary, it was 2.7%, besides the many thousands of employed foreign citizens.
Budapest is among the 25 most visited cities in the world, the city welcoming more than 4.4 million international visitors each year, therefore the traditional and the congress tourism industry also deserve a mention, it contributes greatly to the city's economy. The capital being home to many convention centre and thousands of restaurants, bars, coffee houses and party places, besides the full assortment of hotels. In restaurant offerings can be found the highest quality Michelin-starred restaurants, like Onyx, Costes, Tanti or Borkonyha. The city ranked as the most liveable city in Central and Eastern Europe on EIU's quality of life index in 2010.
Finance and corporate location.
Budapest Stock Exchange, key institution of the publicly offered securities in Hungary and Central and Eastern Europe is situated in Budapest's CBD at Liberty Square. BSE also trades other securities such as government bonds and derivatives such as stock options. Large Hungarian multinational corporations headquartered in Budapest are listed on BSE, for instance the Fortune Global 500 firm MOL Group, the OTP Bank, FHB Bank, Gedeon Richter, Magyar Telekom, CIG Pannonia, Zwack Unicum and more.
Nowadays nearly all branches of industry can be found in Budapest, there is no particularly special industry in the city's economy, but the financial centre role of the city is strong, nearly 40 major banks are presented in the city, also those like Bank of China, KDB Bank and Hanwha Bank, which is unique in the region.
Also support the financial industry of Budapest, the firms of international banks and financial service providers, such as Citigroup, Morgan Stanley, GE Capital, Deutsche Bank, Sberbank, ING Group, Allianz, KBC Group, UniCredit and MSCI among others. Another particularly strong industry in the capital city is biotechnology and pharmaceutical industry, these are also traditionally strong in Budapest, through domestic companies, as Egis, Gedeon Richter, Chinoin and through international biotechnology corporations, like Pfizer, Teva, Novartis, Sanofi, who are also has R&D and production division here. Further high-tech industries, such as software development, engineering notable as well, the Nokia, Ericcson, Bosch, Microsoft, IBM employs thousands of engineers in research and development in the city. Game design also highly represented through headquarters of domestic Digital Reality, Black Hole and studio of Crytek or Gameloft. Beyond the above, there are regional headquarters of global firms, such as Alcoa, General Motors, GE, Exxon Mobil, British Petrol, Hudson Legal, British Telecom, Flextronics, Panasonic Corp, Huawei, Knorr-Bremse, Liberty Global, Tata Consultancy, Aegon, WizzAir, TriGránit, MVM Group, Graphisoft, there is a base for Nissan CEE, Volvo, Saab, Ford, including but not limited to.
Politics and government.
As the capital of Hungary, Budapest is the seat of the country's national government. For the executive, the two chief officers each have their own official residences, which also serve as their offices. The President of Hungary resides at the Sándor Palace in the District I (Buda Castle District), while the office of the Hungarian Prime Minister is in the Hungarian Parliament. Government ministries are all located in various parts of the city, most of them are in the District V, Leopoldtown. The National Assembly is seated in the Hungarian Parliament, which also located in the District V. The President of the National Assembly, the third-highest public official in Hungary, is also seated in the largest building in the country, in the Hungarian Parliament.
Hungary's highest courts are located in Budapest. The Curia (supreme court of Hungary), the highest court in the judicial order, which reviews criminal and civil cases, is located in the District V, Leopoldtown. Under the authority of its President it has three departments: criminal, civil and administrative-labour law departments. Each department has various chambers. The Curia guarantees the uniform application of law. The decisions of the Curia on uniform jurisdiction are binding for other courts.
The second most important judicial authority, the National Judicial Council, is also housed in the District V, with the tasks of controlling the financial management of the judicial administration and the courts and giving an opinion on the practice of the president of the National Office for the Judiciary and the Curia deciding about the applications of judges and court leaders, among others.
The Constitutional Court of Hungary is one of the highest level actors independent of the politics in the country. The Constitutional Court serves as the main body for the protection of the Constitution, its tasks being the review of the constitutionality of statutes. The Constitutional Court performs its tasks independently. With its own budget and its judges being elected by Parliament it does not constitute a part of the ordinary judicial system. The constitutional court passes on the constitutionality of laws, and there is no right of appeal on these decisions.
Budapest hosts the main and regional headquarters of many international organizations as well, including United Nations High Commissioner for Refugees, Food and Agriculture Organization of the United Nations, European Institute of Innovation and Technology, European Police Academy, International Centre for Democratic Transition, Institute of International Education, International Labour Organization, International Organization for Migration, International Red Cross, Regional Environmental Center for Central and Eastern Europe, Danube Commission and even others. The city is also home to more than 100 embassies and representative bodies as an international political actor.
"Environmental issues" have a high priority among Budapest's politics. Institutions such as the Regional Environmental Center for Central and Eastern Europe, located in Budapest, are very important assets.
To decrease the use of cars and greenhouse gas emissions, the city has worked to improve public transportation, and nowadays the city has one of the highest mass transit usage in Europe. Budapest has one of the best public transport systems in Europe with an efficient network of buses, trolleys, trams and subway. Budapest has an above-average proportion of people commuting on public transport or walking and cycling for European cities.
Riding on bike paths is one of the best ways to see Budapest – there are currently about of bicycle paths in the city, fitting into the EuroVelo system.
"The crime" in Budapest investigated by different bodies. United Nations Office on Drugs and Crime notes in their 2011 Global Study on Homicide that, according to criminal justice sources, the homicide rate in Hungary, calculated based on UN population estimates, was 1.4 in 2009, compared to Canada's rate of 1.8 that same year.
The homicide rate in Budapest is below the EU capital cities’ average according to WHO also. However, the organised crime is associated with the city, the Institute of Defence in a UN study named Budapest as the "global epicentres" of illegal pornography, money laundering and contraband tobacco, and also the negotiation center for international crime group leaders.
City governance.
Budapest has been a metropolitan municipality with a mayor-council form of government since its consolidation in 1873, but Budapest also holds a special status as a county-level government, and also special within that, as holds a capital-city territory status. In Budapest, the central government is responsible for the urban planning, statutory planning, public transport, housing, waste management, municipal taxes, correctional institutions, libraries, public safety, recreational facilities, among others. The Mayor is responsible for all city services, police and fire protection, enforcement of all city and state laws within the city, and administration of public property and most public agencies. Besides, each of Budapest' twenty-three districts has its own town hall and a directly elected council and the directly elected mayor of district.
István Tarlós, the current Mayor was re-elected mayor for another 5-year term on the 2014 local elections, he received 49.06% of the votes. He is an independent (but supported by Fidesz) who assumed the office first on 3 October 2010. The composition of the 33 seats in the Budapest General Assembly after the 2014 elections is in the table. The mayor and members of General Assembly are elected to five-year terms.
The Budapest General Assembly is a unicameral body consisting of 33 members, which consist of the 23 mayors of the districts, 9 from the electoral lists of political parties, plus Mayor of Budapest (the Mayor is elected directly). Each term for the mayor and assembly members lasts five years. Submitting the budget of Budapest is the responsibility of the Mayor and the deputy-mayor in charge of finance. The latest, 2014 budget was approved with 18 supporting votes from ruling Fidesz and 14 votes against by the opposition lawmakers.
Main sights and tourism.
The neo-Gothic Parliament, the biggest building in Hungary with its length, containing amongst other things the Hungarian Crown Jewels. Saint Stephen's Basilica, where the Holy Right Hand of the founder of Hungary, King Saint Stephen is on display. The Hungarian cuisine and café culture: for example, Gerbeaud Café, and the Százéves, Biarritz, Fortuna, Alabárdos, Arany Szarvas, Kárpátia and the world famous Mátyás Pince Restaurants. There are Roman remains at the Aquincum Museum, and historic furniture at the Nagytétény Castle Museum, just 2 out of 223 museums in Budapest. Another historical museum is the House of Terror, hosted in the building that was the venue of the Nazi Headquarters. The Castle Hill, the River Danube embankments and the whole of Andrássy út have been officially recognized as UNESCO World Heritage Sites.
Castle Hill and the Castle District; there are three churches here, six museums, and a host of interesting buildings, streets and squares. The former Royal Palace is one of the symbols of Hungary – and has been the scene of battles and wars ever since the 13th century. Nowadays it houses two impressive museums and the National Széchenyi Library. The nearby Sándor Palace contains the offices and official residence of the President of Hungary. The seven-hundred-year-old Matthias Church is one of the jewels of Budapest, it is in neo-Gothic style, decorated with coloured shingles and elegant pinnacles. Next to it is an equestrian statue of the first king of Hungary, King Saint Stephen, and behind that is the Fisherman's Bastion, built in 1905 by the architect Frigyes Schulek, the Fishermen's Bastions owes its name to the namesake corporation that during the Middle Ages was responsible of the defence of this part of ramparts, from where opens out a panoramic view of the whole city. Statues of the Turul, the mythical guardian bird of Hungary, can be found in both the Castle District and the Twelfth District.
In Pest, arguably the most important sight is Andrássy út. This Avenue is an elegant long tree-lined street that covers the distance from Deák Ferenc tér to the Heroes Square. On this Avenue overlook many important sites. It is a UNESCO World Heritage Site. As far as Kodály körönd and Oktogon both sides are lined with large shops and flats built close together. Between there and Heroes' Square the houses are detached and altogether grander. Under the whole runs continental Europe's oldest Underground railway, most of whose stations retain their original appearance. Heroes' Square is dominated by the Millenary Monument, with the Tomb of the Unknown Soldier in front. To the sides are the Museum of Fine Arts and the Kunsthalle Budapest, and behind City Park opens out, with Vajdahunyad Castle. One of the jewels of Andrássy út is the Hungarian State Opera House. Statue Park, a theme park with striking statues of the Communist era, is located just outside the main city and is accessible by public transport.
The Dohány Street Synagogue is the largest synagogue in Europe, and the second largest active synagogue in the world. The synagogue is located in the Jewish district taking up several blocks in central Budapest bordered by Király utca, Wesselényi utca, Grand Boulevard and Bajcsy Zsilinszky road. It was built in moorish revival style in 1859 and has a capacity of 3000 people. Adjacent to it is a sculpture reproducing a weeping willow tree in steel to commemorate the Hungarian victims of the Holocaust. The city is also home to the largest medicinal bath in Europe (Széchenyi Medicinal Bath) and the third largest Parliament building in the world, once the largest in the world. Other attractions are the bridges of the capital. Seven bridges provide crossings over the Danube, and from north to south are: the Árpád Bridge (built in 1950 at the north of Margaret Island); the Margaret Bridge (built in 1901, destroyed during the war by an explosion and then rebuilt in 1948); the Chain Bridge (built in 1849, destroyed during the II World War and the rebuilt in 1949); the Elisabeth Bridge (completed in 1903 and dedicated to the murdered Queen Elisabeth, it was destroyed by the Germans during the war and rebuilt in 1964); the Liberty Bridge (opened in 1896 and rebuilt in 1989 in Art Nouveau style); the Petőfi Bridge (completed in 1937, destroyed during the war and rebuilt in 1952); the Rákóczi Bridge (completed in 1995). Most remarkable for their beauty are the Margaret bridge, the Chain bridge and the Liberty bridge.
The world's largest panorama photograph was created in (and of) Budapest in 2010.
Tourists visiting Budapest can receive free maps and information from the nonprofit Budapest Festival and Tourism Center at its info-points. The info centers also offer the Budapest Card which allows free public transit and discounts for several museums, restaurants and other places of interest. Cards are available for 24, 48 or 72-hour durations. The city is also well known for its ruin bars both day and night.
Parks and gardens.
Budapest has many municipal parks and most have playgrounds for children and seasonal activities like skating in the winter and boating in the summer. Access from the city center is quick and easy with the Millennium Underground. Budapest has a complex park system, with various lands operated by the Budapest City Gardening Ltd.
The wealth of greenspace afforded by Budapest's parks is further augmented, a network of open spaces containing forest, streams, and lakes that are set aside as natural areas which lie along not for from inner city, among others the Budapest Zoo and Botanical Garden (established in 1866) in the City Park.
The most notably and popular parks in Budapest are the City Park which were established in 1751 (302 acres) along with Andrássy Avenue, the Margaret Island in the Danube (), the People's Park and the Kopaszi Dam.
The Buda Hills also offer a variety of adventurous outdoor activities, along with some spectacular views. A popular place frequented by locals is Normafa, offering activities for all seasons. With a modest ski run, it is also a winter favorite for skiers and snow boarders if there is enough snowfall.
Islands.
Seven islands can be found on the Danube: Shipyard Island, Margaret Island, Csepel Island, Palotai-sziget (now a peninsula), Népsziget, Háros-sziget, and Molnár-sziget.
Notable islands include:
Spas.
One of the reasons the Romans first colonised the area immediately to the west of the River Danube and established their regional capital at Aquincum (now part of Óbuda, in northern Budapest) is so that they could utilise and enjoy the thermal springs. There are still ruins visible today of the enormous baths that were built during that period. The new baths that were constructed during the Turkish period (1541–1686) served both bathing and medicinal purposes, and some of these are still in use to this day. Budapest gained its reputation as a city of spas in the 1920s, following the first realisation of the economic potential of the thermal waters in drawing in visitors. Indeed, in 1934 Budapest was officially ranked as a "City of Spas". Today, the baths are mostly frequented by the older generation, as, with the exception of the "Magic Bath" and "Cinetrip" water discos, young people tend to prefer the lidos which are open in the summer.
Construction of the Király Baths started in 1565, and most of the present-day building dates from the Turkish period, including most notably the fine cupola-topped pool.
The Rudas Baths are centrally placed – in the narrow strip of land between Gellért Hill and the River Danube – and also an outstanding example of architecture dating from the Turkish period. The central feature is an octagonal pool over which light shines from a diameter cupola, supported by eight pillars.
The Gellért Baths and Hotel were built in 1918, although there had once been Turkish baths on the site, and in the Middle Ages a hospital. In 1927, the Baths were extended to include the wave pool, and the effervescent bath was added in 1934. The well-preserved Art Nouveau interior includes colourful mosaics, marble columns, stained glass windows and statues.
The Lukács Baths are also in Buda and are also Turkish in origin, although they were only revived at the end of the 19th century. This was also when the spa and treatment centre were founded. There is still something of an atmosphere of fin-de-siècle about the place, and all around the inner courtyard there are marble tablets recalling the thanks of patrons who were cured there. Since the 1950s it has been regarded as a centre for intellectuals and artists.
The Széchenyi Baths are one of the largest bathing complexes in all Europe, and the only "old" medicinal baths to be found in the Pest side of the city. The indoor medicinal baths date from 1913 and the outdoor pools from 1927. There is an atmosphere of grandeur about the whole place with the bright, largest pools resembling aspects associated with Roman baths, the smaller bath tubs reminding one of the bathing culture of the Greeks, and the saunas and diving pools borrowed from traditions emanating in northern Europe. The three outdoor pools (one of which is a fun pool) are open all year, including winter. Indoors there are over ten separate pools, and a whole host of medical treatments is also available. The Szécheny Baths are built in modern Renaissance style.
Infrastructure and transportation.
Airport.
Budapest is served by Budapest Ferenc Liszt International Airport (BUD) (named after Franz Liszt, the notable Hungarian composer), one of the busiest airports in Central and Eastern Europe, located east-southeast of the centre of Budapest, in the District XVIII. The airport offers international connections among all major European cities, and also to North America, Africa and the Middle East.
As Hungary's busiest airport, handles nearly all of the country's air passenger traffic. Budapest Liszt Ferenc handled around 250 scheduled flights daily in 2013, and an ever rising number of charters. London, Brussels, Frankfurt, Munich, Paris, and Amsterdam are the busiest international connections respectively, while Toronto, Montreal, Dubai, Doha and Alicante are the most unusual in the region.
Today the airport serves as a base for Ryanair, Wizz Air, Budapest Aircraft Service, CityLine Hungary, Farnair Hungary and Travel Service Hungary among others. The airport is accessible via public transportation from the city centre by the Metro line 3 and then the airport bus No. 200E.
As part of a strategic development plan, €561 million have spent to expanding and modernising the airport infrastructure until December 2012. Most of these improvements are already completed, the postponed ones are the new cargo area and new piers for terminal 2A and 2B, but these development are on standby also, and will start immediately, when the airport traffic will reach the appropriate level.
SkyCourt, the newest, state-of-the-art building between the 2A and 2B terminals with 5 levels. Passenger safety checks were moved here along with new baggage classifiers and the new Malév and SkyTeam business lounges, as well as the first MasterCard lounge in Europe.
Public transportation.
The "Centre for Budapest Transport (BKK)", the transportation authority of Budapest, operates one of the largest public transportation systems in Europe, which covers the city of Budapest and 80 surrounding suburbs.
Budapest's public transport system consists of four metro lines, with Line 1 (Yellow) — constructed 1896, being the second oldest in the world; 5 suburban railway lines; 33 city tram lines; 15 trolleybus lines; 264 bus lines, with 40 routes providing night bus services; 4 city boat services plus the BuBi, the smart bicycle sharing network with bikes monitored by computer and GPS.
On an average weekday, BKK lines transports 3.9 million riders. In 2011, it handled a total of 1.4 billion passengers. In 2014, the 65% of the passenger traffic in Budapest was by public transport and 35% by car. The aim is 80%–20% by 2030 in accordance with the strategy of BKK.
The development of complex Intelligent transportation system in the city is rapidly advancing, the application of smart traffic lights is widespread, they are GPS and computer controlled and give priority to the GPS connected public transport vehicles automatically, as well as the traffic is measured and analyzed on the roads and car drivers informed about the expected travel time and traffic by intelligent displays (EasyWay project). Public transport users are immediately notified of any changes in public transport online, on smartphones and on PIDS displays, as well car drivers can keep track of changes in traffic and road management in real-time online and on smartphones through the "BKK Info". As well all vehicles can be followed online and on smartphones in real-time throughout the city with the "Futár" PIDS system, while the continuous introducing of integrated e-ticket system will help the measurement of passenger numbers on each line and the intelligent control of service frequency.
The development of "Futár", the citywide real-time passenger information system and real-time route planner is finished already and now all of the public transport vehicle is connected via satellite system. The real-time information of trams, buses and trolleybuses are available for both the operators in the control room and for all the passengers in all stops on smartphone and on city street displays.
The implementation of latest generation automated fare collection and e-ticket system with NFC compatibility and reusable contactless smart cards for making electronic payments in online and offline systems in Budapest is started in 2014, the project is implemented and operated by the operator of Hong Kong Octopus card jointly with one of the leading European companies of e-ticket and automated fare collection, Scheidt & Bachmann. The deployment of 300 new digital contactless ticket vending machine will be finished by the end of 2014 in harmonization with the e-ticket system.
The tram lines no. 4 and 6 are the busiest city tram lines in the world, with one of the world's longest trams (54-metre long Siemens Combino) running at 2–3 minute intervals at peak time and 4–5 minutes off-peak. Day services are usually from 4am until 23pm-0.30am. The night service has a reputation for being excellent. Hungarian State Railways operates an extensive network of commuter rail services, their importance in the suburban commuter passenger traffic is significant, but in travel within the city is limited.
The organiser of public transport in Budapest is the municipal corporation "Centre for Budapest Transport" (Budapesti Közlekedési Központ – BKK), that is responsible for planning and organising network and services, planning and developing tariff concepts, attending to public service procurer duties, managing public service contracts, operating controlling and monitoring systems, setting and monitoring service level agreements related to public transport, attending to customer service duties, selling and monitoring tickets and passes, attending to integrated passenger information duties, unified Budapest-centric traffic control within public transport, attending to duties related to river navigation, plus the management of Budapest roads, operating taxi stations, unified control of bicycle traffic development in the capital, preparing parking strategy and developing an operational concept, preparation of road traffic management, developing an optimal traffic management system, organising and co-ordinating road reconstruction and even more, in short, everything which is related to transport in the city.
Roads and railways.
Budapest is the most important Hungarian road terminus, all of the major highways and railways ends within the city limits. The road system in the city is designed in a similar manner to that of Paris, with several ring roads, and avenues radiating out from the center. Ring road M0 around Budapest is nearly completed, with only one section missing on the west side due to local disputes. Currently the beltway is in length, and once finished it will be of highway in length.
The city is a vital traffic hub because all major European roads and European railway lines lead to Budapest. The Danube was and is still today an important water-way and this region in the centre of the Carpathian Basin lies at the cross-roads of trade routes.
Hungarian main line railways are operated by Hungarian State Railways. There are three main railway station in Budapest, the Budapest Eastern railway station, the Budapest Western railway station and Budapest Southern railway station, operating both domestic and international rail services. Budapest is one of the main stops of the Orient Express on its Central and Eastern European route. There is also a suburban rail service in and around Budapest, operated under the name HÉV.
Ports and shipping.
The river Danube flows through Budapest on its way from Germany to the Black Sea. The river is easily navigable and so Budapest historically has a major commercial port at Csepel District and at New Pest District also. The Pest side is also a famous port place with international shipping ports for cargo and for passenger ships. In the summer months, a scheduled hydrofoil service operates on the Danube connecting the city to Vienna.
BKK (through the operator BKV) also provides public transport with boat service within the borders of the city. Four routes, marked D11-14, connect the 2 banks with Margaret Island and Hajógyári-island, from Római fürdő (Buda side, North to Óbudai island) or Árpád Bridge (Pest side) to Rákóczi Bridge, with a total of 15 stops. In addition, several companies provides sightseeing boat trips and also an amphibious vehicle (bus and boat) operates constantly.
Water quality in Budapest harbours improved dramatically in the recent years, treatment facilities processed 100% of generated sewage in 2010. Budapesters regularly kayak, canoe, jet-ski and sail on the Danube, which has continuously become a major recreational site for the city.
Other modes of transport.
Special vehicles in Budapest, besides metros, include suburban rails, trams and boats. There are a couple of less common vehicles in Budapest, like the trolleybus on several lines in Pest, the Castle Hill Funicular between the Chain Bridge and Buda Castle, the cyclecar for rent in Margaret Island, the chairlift, the Budapest Cog-wheel Railway and children's railway. The latter three vehicles runs among Buda hills.
Bridges.
12 road bridge and 2 train bridge connect the two banks of the river Danube (between Pest and Buda) at the city of Budapest. The first permanent bridge was Chain Bridge, nowadays the capital has 2 more historical bridges from the 19th century. Some bridges are combined use because of its tram lines.
Culture and contemporary life.
The culture of Budapest is reflected by Budapest's size and variety. Most Hungarian cultural movements first emerged in the city. Budapest is an important center for music, film, theatre, dance and visual art. Artists have been drawn into the city by opportunity, as the city government funds the arts with adequate financial resources.
Budapest is headquarter of the Hungarian LGBT community.
Museums and galleries.
Budapest is packed with museums and galleries, and there are plenty of temporary exhibitions in the most unlikely of settings, particularly in summer. The city glories in 223 museums and galleries, which presents several memories, not only the Hungarian historical, art and science ones, but also the memories of universal and European culture and science. Here are the greatest examples among them: the Hungarian National Museum, the Hungarian National Gallery, the Museum of Fine Arts (where can see the pictures of Hungarian painters, like Victor Vasarely, Mihály Munkácsy and a great collection about Italian art, Dutch art, Spanish art and British art from before the 19th century and French art, British art, German art, Austrian art after the 19th century), the House of Terror, the Budapest Historical Museum, the Aquincum Museum, the Memento Park, Museum of Applied Arts and the contemporary arts exhibition Palace of Arts Budapest. In Budapest there are currently 837 different monuments, which represent the most of the European artistic style. The classical and unique Hungarian Art Nouveau buildings are prominent.
Libraries.
A lot of libraries have unique collections in Budapest, such as the National Széchenyi Library, which keeps historical relics from the age before the printing of books. The Metropolitan Szabó Ervin Library plays an important role in the general education of the capital's population. Other libraries: The Library of the Hungarian Academy of Sciences, Eötvös University Library, the Parliamentary Library, Library of the Hungarian Central Statistical Office and the National Library of Foreign Literature.
Opera and theatres.
In Budapest there are forty theatres, seven concert halls and an opera house. Outdoor festivals, concerts and lectures enrich the cultural offer of summer, which are often held in historical buildings. The largest theatre facilities are the Budapest Operetta and Musical Theatre, the József Attila Theatre, the Katona József Theatre, the Madách Theatre, the Hungarian State Opera House, the National Theatre, the Vigadó Concert Hall, Radnóti Miklós Theatre, the Comedy Theatre and the Palace of Arts, known as "MUPA". The Budapest Opera Ball is an annual Hungarian society event taking place in the building of the Budapest Opera ("Operaház") on the last Saturday of the carnival season, usually late February.
Performing arts and festivals.
Several annual festivals take place in Budapest, such as Sziget Festival, one of the largest outdoor music festival in Europe, the Budapest Spring Festival presents on concerts at several venues across the city. The Budapest Autumn Festival brings free music, dance, art, and other cultural events to the streets of the city. Budapest Wine Festival and Budapest Pálinka Festival occurs each May and gastronomy festivals focus on culinary pleasures. Budapest Pride (or Budapest Pride Film and Cultural Festival) occurs annually across the city, and usually involves a parade on the Andrássy Avenue. Other festivals include the Budapest Fringe Festival, which brings more than 500 artists in about 50 shows to produce a wide range of interesting works in alternative theatre, dance, music and comedy outside the mainstream. The LOW Festival was a multidisciplinary contemporary cultural festival held in Hungary in the cities Budapest and Pécs from February till March. The name of the festival alludes to the Low Countries, the region encompassing the Netherlands and Flanders. Budapest Jewish Summer Festival, in late August, is also one of the largest in Europe.
There are many symphony orchestras in Budapest with the Budapest Philharmonic Orchestra being preeminent orchestras. It was founded in 1853 by Ferenc Erkel and still presents regular concerts in the Hungarian State Opera House and National Theatre.
The dance tradition of the Carpathian Basin is a unique area of the European dance culture, which is also a special transition between the Balkans and Western Europe regions. The city is home to several authentic Hungarian folk dance ensembles which range from small ensembles to professional troupes. Budapest is one of the few cities in the world where a high school for folk dance learning exists.
Fashion.
Budapest is home to a fashion week twice a year, where the city's fashion designers and houses present their collections and provide a meeting place for the fashion industry representatives. Budapest Fashion Week additionally a place for designers from other countries may present their collections in Budapest. Hungarian models, like Barbara Palvin, Enikő Mihalik, Diána Mészáros, Viktória Vámosi usually appearing at these events along international participants.
Fashion brands like Zara, H&M, Mango, ESPRIT, Douglas AG, Lacoste, Nike and other retail fashion brands are common across the city's shopping malls and on the streets. 
Major luxury fashion brands such as Roberto Cavalli, Dolce & Gabbana, Gucci, Versace, Ferragamo, Moschino, Prada and Hugo Boss, can be found among the city's most prestigious shopping streets, the Fashion Street, Váci Street and Andrássy Avenue in Budapest's main upscale fashion district, the Leopoldtown, District V. Budapest's newest fashion and design mall, the "il Bacio di Stile", opened in 2013 and houses most major fashion houses and brands from around the world including Bottega Veneta, Giorgio Armani, Saint Laurent, Lanvin, Valentino, Oscar de la Renta.
Media.
Budapest is a prominent location for the Hungarian entertainment industry, with many films, television series, books, and other media set there. Budapest is the largest centre for film and television production in Hungary. In 2011, it employed more than 50,000 people and generated 63.9% of revenues of the media industry in the country.
Budapest is the media centre of Hungary, and the location of the main headquarters of Hungarian Television and other numerous local and national TV and radio stations, such as M1, M2, Duna TV, Duna World, RTL Klub, TV2 (Hungary), EuroNews, Comedy Central, MTV Hungary, VIVA Hungary, Viasat 3, Cool TV, Pro4 and politics and news channels such as, Hír TV, ATV, Echo TV, furthermore documentary channels such as, Discovery Channel, Discovery Science, Discovery World, National Geographic Channel, Nat Geo Wild, Spektrum, BBC Entertainment and it is less than a quarter of the channels broadcast from Budapest, for the whole picture see the Television in Hungary.
In 2012, there were 7.2 million internet users in Hungary (72% of the population). and there were 2.3 million subscriptions for mobile broadband,
Cuisine.
In the modern age, Budapest developed its own peculiar cuisine, based on products of the nearby region, as lamb, pork and vegetables special in the region. Modern Hungarian cuisine is a synthesis of ancient Asiatic components mixed with French, Germanic, Italian, and Slavic elements. The food of Hungary can be considered a melting pot of the continent, with a culinary base formed from its own, original Magyar cuisine. Considerable numbers of Saxons, Armenians, Italians, Jews and Serbs settled in the Hungarian basin and in Transylvania, also contributing with different new dishes. Elements of ancient Turkish cuisine were adopted during the Ottoman era, in the form of sweets (for example different nougats, like white nougat called "törökméz", quince ("birsalma"), Turkish delight, Turkish coffee or rice dishes like pilaf, meat and vegetable dishes like the eggplant, used in eggplant salads and appetizers, stuffed peppers and stuffed cabbage called "töltött káposzta". Hungarian cuisine was influenced by Austrian cuisine under the Austro-Hungarian Empire, dishes and methods of food preparation have often been borrowed from Austrian cuisine, and vice versa.
Budapest restaurants reflect diversity, with menus carrying traditional regional cuisine, fusions of various culinary influences, or innovating in the leading edge of new techniques. Budapest' food shops also have a solid reputation for supplying quality specialised culinary products and supplies, reputations that are often built up over generations. These include many shops, such as Café Gerbeaud, one of the greatest and most traditional coffeehouses in Europe, or the Gundel restaurant and gastro shop in the City Park.
Diners can also find the highest quality foods served in several Michelin-starred restaurants, like Onyx, Costes, Borkonyha or Tanti.
In fiction.
The 1906 novel "The Paul Street Boys", the 1937 novel "Journey by Moonlight", the 1957 book "The Bridge at Andau", the 1975 novel "Fateless", the 1977 novel "The End of a Family Story", the 1986 book "Between the Woods and the Water", the 1992 novel "Under the Frog", the 1987 novel "The Door", the 2002 novel "Prague", the 2003 book "Budapeste", the 2004 novel "Ballad of the Whisky Robber", the 2005 novels "Parallel Stories" and "The Historian", the 2012 novel "Budapest Noir" are set, amongst others, partly or entirely in Budapest. Some of the better known feature films set in Budapest are "Kontroll", "The District!", "Ein Lied von Liebe und Tod", "Sunshine", "An American Rhapsody", "As You Desire Me", "The Good Fairy", "Hanna's War", "The Journey", "Ladies in Love", "Mehbooba", "Music Box", "The Shop Around the Corner", "Zoo in Budapest", "Underworld", and "". "The Grand Budapest Hotel" (2014) is a Wes Anderson film. It was filmed in "Germany" and set in the fictional Republic of Zubrowka which is in the alpine mountains of "Hungary".
Sports.
Budapest hosted many global sport event in the past, among others the 1994 IAAF World Cross Country Championships, 1997 World Amateur Boxing Championships, 2000 World Fencing Championships, 2001 World Allround Speed Skating Championships, Bandy World Championship 2004, 2008 World Interuniversity Games, 2008 World Modern Pentathlon Championships, 2010 ITU World Championship Series, 2011 IIHF World Championship, 2013 World Fencing Championships, 2013 World Wrestling Championships, 2014 World Masters Athletics Championships and will in the future, like 2017 World Aquatics Championships, 2017 World Judo Championships, only in the last two decade. Besides these, Budapest was the home of many European-level tournaments, like 2006 European Aquatics Championships, 2010 European Aquatics Championships, 2010 UEFA Futsal Championship, 2013 European Judo Championships, 2013 European Karate Championships and will be the host of 4 matches in the UEFA Euro 2020, which will be held in the 67,889-seat new multi-purpose Puskás Ferenc Stadium, to mention a few.
In 2015 the Assembly of the Hungarian Olympic Committee and the Assembly of Budapest decided to bid for the 2024 Summer Olympics. Budapest has lost several bids to host the games, in 1916, 1920, 1936, 1944, and 1960 to Berlin, Antwerp, London, and Rome, respectively. The Hungarian Parliament also voted to support the bid on 28 January 2016, later Budapest City Council approved list of venues and Budapest became an official candidate for the 2024 Summer Olympic Games.
Numerous Olympic, World, and European Championship winners and medalists reside in the city, which follows from Hungary's 8th place among all the nations of the world in the All-time Olympic Games medal table. 
Hungarians have always been avid sports people: during the history of the Summer Olympic Games, Hungarians have brought home 476 medals, of which 167 are gold. The top events in which Hungarians have excelled are fencing, swimming, water polo, canoeing, wrestling and track & field sports. Beside classic sports, recreational modern sports such as bowling, pool billiard, darts, go-carting, wakeboarding and squash are very popular in Budapest, and extreme sports are also gaining ground. Furthermore, the Budapest Marathon and Budapest Half Marathon also attract many people every year. The city's largest football stadium is named after Ferenc Puskás, recognised as the top scorer of the 20th century and for whom FIFA's Puskás Award (Ballon d'Or) was named.
One of Budapest's most popular sport is football and it has many Hungarian League football club, including in the top level Nemzeti Bajnokság I league, like Ferencvárosi TC (29 Hungarian League titles), MTK Budapest FC (23 titles), Újpest FC (20 titles), Budapest Honvéd FC (13 titles), Vasas SC (6 titles), Csepel SC (4 titles), Budapesti TC (2 titles). In the 2015–16 UEFA Europa League, Hungary's most popular soccer club, Ferencvárosi TC dropped out in the second qualifying round.
The Hungarian Grand Prix in Formula One has been held at the Hungaroring just outside the city, which circuit has FIA Grade 1 license. Since 1986, the race has been a round of the FIA Formula One World Championship. At the 2013 Hungarian Grand Prix, it was confirmed that Hungary will continue to host a Formula 1 race until 2021. The track was completely resurfaced for the first time in early 2016, and it was announced the Grand Prix's deal was extended for a further 5 years, until 2026.
Education.
Budapest is home to over 35 higher education institutions. Under the Bologna Process, many offered qualifications are recognised in countries across Europe. Medicine, dentistry, pharmaceuticals, veterinary programs, and engineering are among the most popular fields for foreigners to undertake in Budapest. Most universities in Budapest offer courses in English, as well as in other languages like German, French, and Dutch, aimed specifically at foreigners. Many students from other European countries spend one or two semesters in Budapest through the Erasmus Programme.
International relations.
Budapest has quite a few sister cities and many partner cities around the world.
Like Budapest, many of them are the most influential and largest cities of their country and region, most of them are the primate city and political, economical, cultural capital of their country.
The Mayor of Budapest says the aim with improving sister city relationships is to allow and encourage a mutual exchange of information and experiences, as well as co-operation, in the areas of city management, education, culture, tourism, media and communication, trade and business development.
Partnerships around the world.
Some of the city's districts are also twinned to small cities or districts of other big cities, for details see the article
List of districts and towns in Budapest.

</doc>
<doc id="36790" url="https://en.wikipedia.org/wiki?curid=36790" title="Artery">
Artery

Arteries () are blood vessels that carry blood away from the heart. While most arteries carry oxygenated blood, there are two exceptions to this, the pulmonary and the umbilical arteries. The effective arterial blood volume is that extracellular fluid which fills the arterial system.
The circulatory system is vital for sustaining life. Its normal functioning is responsible for the delivery of oxygen and nutrients to all cells, as well as the removal of carbon dioxide and waste products, the maintenance of optimum pH, and the circulation of proteins and cells of the immune system. In developed countries, the two leading causes of death, myocardial infarction (heart attack), and stroke, may each directly result from an arterial system that has been slowly and progressively compromised by years of deterioration.
Structure.
The anatomy of arteries can be separated into gross anatomy, at the macroscopic level, and microscopic anatomy, which must be studied with the aid of a microscope. The arterial system of the human body is divided into systemic arteries, carrying blood from the heart to the whole body, and pulmonary arteries, carrying deoxygenated blood from the heart to the lungs.
The outermost layer is known as the "tunica externa" also known as "tunica adventitia" and is composed of connective tissue made up of collagen fibers. Inside this layer is the "tunica media", or "media", which is made up of smooth muscle cells and elastic tissue (also called connective tissue proper). The innermost layer, which is in direct contact with the flow of blood is the "tunica intima", commonly called the "intima". This layer is made up of mainly endothelial cells. The hollow internal cavity in which the blood flows is called the lumen.
Development.
Arterial formation begins, when endothelial cells begin to express arterial specific genes, such as ephrin B2.
Function.
Arteries form part of the circulatory system. They carry blood that is oxygenated after it has been pumped from the heart. Arteries also aid the heart in pumping blood. Arteries carry oxygenated blood away from the heart to the tissues, except for pulmonary arteries, which carry blood to the lungs for oxygenation. (Usually veins carry deoxygenated blood to the heart but the pulmonary veins carry oxygenated blood.) There are two unique arteries. The pulmonary artery carries blood from the heart to the lungs, where it receives oxygen. It is unique because the blood in it is not "oxygenated", as it has not yet passed through the lungs. The other unique artery is the umbilical artery, which carries deoxygenated blood from a fetus to its mother].
Arteries have a higher blood pressure than other parts of the circulatory system. The pressure in arteries varies during the cardiac cycle. It is highest when the heart contracts and lowest when heart relaxes. The variation in pressure produces the pulse, which can be felt in different areas of the body, such as the radial pulse. Arterioles have the greatest collective influence on both local blood flow and on overall blood pressure. They are the primary "adjustable nozzles" in the blood system, across which the greatest pressure drop occurs. The combination of heart output (cardiac output) and systemic vascular resistance, which refers to the collective resistance of all of the body's arterioles, are the principal determinants of arterial blood pressure at any given moment.
Systemic arteries are the arteries (including the peripheral arteries), of the systemic circulation, which is the part of the cardiovascular system that carries oxygenated blood away from the heart, to the body, and returns deoxygenated blood back to the heart. Systemic arteries can be subdivided into two types - muscular and elastic - according to the relative compositions of elastic and muscle tissue in their tunica media as well as their size and the makeup of the internal and external elastic lamina. The larger arteries (>10 mm diameter) are generally elastic and the smaller ones (0.1–10 mm) tend to be muscular. Systemic arteries deliver blood to the arterioles, and then to the capillaries, where nutrients and gases are exchanged.
After travelling from the aorta, blood travels through peripheral arteries into smaller arteries called arterioles, and eventually to capillaries. Arterioles help in regulating blood pressure by the variable contraction of the smooth muscle of their walls, and deliver blood to the capillaries.
=== Aorta 
The aorta is the root systemic artery. It receives blood directly from the left ventricle of the heart via the aortic valve. As the aorta branches, and these arteries branch in turn, they become successively smaller in diameter, down to the arteriole. The arterioles supply capillaries which in turn empty into venules. The very first branches off of the aorta are the coronary arteries, which supply blood to the heart muscle itself. These are followed by the branches off the aortic arch, namely the brachiocephalic artery, the left common carotid and the left subclavian arteries.
Capillaries.
The capillaries are the smallest of the blood vessels and are part of the microcirculation. The capillaries have a width of a single cell in diameter to aid in the fast and easy diffusion of gases, sugars and nutrients to surrounding tissues. Capillaries have no smooth muscle surrounding them and have a diameter less than that of red blood cells; a red blood cell is typically 7 micrometers outside diameter, capillaries typically 5 micrometers inside diameter. The red blood cells must distort in order to pass through the capillaries.
These small diameters of the capillaries provide a relatively large surface area for the exchange of gases and nutrients. Capillaries:
Clinical significance.
Systemic arterial pressures, are generated by the forceful contractions of the heart's left ventricle. High blood pressure is a factor in causing arterial damage. Healthy resting arterial pressures, are relatively low, mean systemic pressures typically being under 100 mmHg, about 1.8 lbf/in², above surrounding atmospheric pressure (about 760 mmHg or 14.7 lbf/in² at sea level). To withstand and adapt to the pressures within, arteries are surrounded by varying thicknesses of smooth muscle which have extensive elastic and inelastic connective tissues. The pulse pressure, i.e. systolic vs. diastolic difference, is determined primarily by the amount of blood ejected by each heart beat, stroke volume, versus the volume and elasticity of the major arteries.
A blood squirt also known as an "arterial gush" is the effect when an artery is cut due to the higher arterial pressures. Blood is spurted out at a rapid, intermittent rate, that conicides with the heartbeat.The amount of blood loss can be copious, can occur very rapidly, and be life-threatening.
Over time, factors such as elevated arterial blood sugar (particularly as seen in diabetes mellitus), lipoprotein, cholesterol, high blood pressure, stress and smoking, are all implicated in damaging both the endothelium and walls of the arteries, resulting in atherosclerosis. Atherosclerosis is a disease marked by the hardening of arteries. This is caused by an atheroma or plaque in the artery wall and is a build-up of cell debris, that contain lipids, (cholesterol and fatty acids), calcium and a variable amount of fibrous connective tissue.
Accidental intra-arterial injection either iatrogenically or through recreational drug use can cause symptoms such as intense pain, paresthesia and necrosis. It usually causes permanent damage to the limb; often amputation is necessary.
History.
Among the ancient Greeks, the arteries were considered to be "air holders" that were responsible for the transport of air to the tissues and were connected to the trachea. This was as a result of finding the arteries of the dead devoid of blood.
In medieval times, it was recognized that arteries carried a fluid, called "spiritual blood" or "vital spirits", considered to be different from the contents of the veins. This theory went back to Galen. In the late medieval period, the trachea, and ligaments were also called "arteries".
William Harvey described and popularized the modern concept of the circulatory system and the roles of arteries and veins in the 17th century.
Alexis Carrel at the beginning of 20th century first described the technique for vascular suturing and anastomosis and successfully performed many organ transplantations in animals; he thus actually opened the way to modern vascular surgery that was before limited to vessels permanent ligatation.
Theodor Kocher the Swiss researcher, reported that atherosclerosis often developed in patients who had undergone a thyroidectomy and suggested that hypothyroidism favors atherosclerosis, which was, in the 1900s at autopsies, seen more frequently in iodine-deficient Austrians compared to Icelanders, which are not deficient in iodine. Turner reported the effectiveness of iodide and dried extracts of thyroid in the prevention of atherosclerosis in laboratory rabbits.

</doc>
<doc id="36791" url="https://en.wikipedia.org/wiki?curid=36791" title="Todd Rundgren">
Todd Rundgren

Todd Harry Rundgren (born June 22, 1948) is an American multi-instrumentalist, songwriter, and record producer. Hailed in the early stages of his career for both his own material and for his production of other artists, supported by the certified gold solo double LP "Something/Anything?" in 1972, his career has produced a diverse and eclectic range of recordings often both as a solo artist and as a member of the band Utopia. Rundgren has often been at the forefront as a promoter of cutting edge recording technologies.
During the 1970s and 1980s, Rundgren engineered and/or produced many notable albums for other acts, including the Band's "Stage Fright" (1970), Badfinger's "Straight Up" (1971), Grand Funk Railroad's "We're an American Band" (1973), the New York Dolls's "New York Dolls" (1973), Hall & Oates's "War Babies" (1974), Meat Loaf's "Bat Out of Hell" (1977), and XTC's "Skylarking" (1986). In the 1980s and 1990s, his interest in video and computers led to his "Time Heals" (1981) being the eighth video played on MTV, and "Change Myself" (1991) was animated by Rundgren on commercially available Amiga computers.
His best-known songs include the 1972 singles "Hello It's Me" and "I Saw the Light", which have heavy rotation on classic rock radio stations, and the 1983 single "Bang the Drum All Day", which is featured in many sports arenas, commercials and movie trailers. Although lesser known, "Couldn't I Just Tell You" has had a major influence on artists in the power pop musical genre.
Early life.
Rundgren was born in Upper Darby, at the western city limits of Philadelphia, Pennsylvania, the son of Ruth (née Fleck; April 29,1922-April 6, 2016) and Harry W. Rundgren (1917–1996). His father was of half Swedish and half Austrian descent. Todd's grandfather Johan Sigfrid Rundgren (1883–1951) was born and raised in Norrtälje, Sweden, and his grandmother Sophie Brandweis Rundgren was born and raised in Austria. Both immigrated to America in the 1900s.
He began his career in Woody's Truck Stop, a Philadelphia-based group in the style of Paul Butterfield Blues Band. However, Rundgren and bassist Carson Van Osten left prior to Woody's Truck Stop releasing its eponymous first album to form the garage rock group Nazz in 1967 with Thom Mooney (drums) and Robert "Stewkey" Antoni (vocals and keyboards). The group gained minor recognition with the Rundgren-penned songs "Open My Eyes" and "Hello It's Me". (He later recorded a solo, uptempo version of "Hello It's Me"; it became one of his signature songs.)
Nazz released three albums during this time – "Nazz" (1968), "Nazz Nazz" (1969), and "Nazz III" (1971). "Open My Eyes" gained belated recognition thanks to its inclusion in "" (1972), the genre-defining anthology of American 1960s garage punk and psychedelia compiled by musician Lenny Kaye. The group's second LP was originally intended as double album (titled "Fungo Bat"), but instead a truncated version was released as "Nazz Nazz" in April 1969. Rundgren and Van Osten left the band shortly after. Under Stewkey's leadership the band continued (with new members) until 1970, and their label released a third LP "Nazz III", on which most of Rundgren's vocals on the unreleased songs from the "Fungo Bat" sessions were replaced by Stewkey's.
Rundgren's distinctive style was inspired by a wide variety of musical influences—British pop-rock & baroque pop (notably Pink Floyd, The Beatles, The Who, The Yardbirds, Cream and The Move), the intricate vocal harmonies of The Beach Boys, classic American rock and roll, Broadway musicals, the operettas of Gilbert & Sullivan and American soul and R&B, but as his music evolved he demonstrated an increasing interest in other genres as well, such as hard rock and the guitar work of Robert Jay Bruner experimental music.
Particularly during the early years of his career, Rundgren's songwriting was heavily influenced by the music of singer-songwriter Laura Nyro:
Rundgren's debut solo album "Runt" (1970) includes the strongly Nyro-influenced "Baby Let's Swing", which was written about her and mentions her by name.
Nazz manager Michael Friedman, who had joined Albert Grossman management brought Rundgren to the firm where he became both a solo artist and producer for many artists in the Grossman stable.
Career.
Production work, 1970–75.
Rundgren's unhappiness with the production on the Nazz recordings prompted him to educate himself in audio engineering and production, and after leaving the Nazz in 1969, he relocated to New York, signed with Albert Grossman and began working as a producer for other groups, as well as recording his own material, which was initially released through the Ampex Records label (a short-lived joint venture between Grossman and the Ampex company). He also apparently considered working as a computer programmer. Subsequently, he became one of the first artists signed to Grossman's Bearsville Records label (distributed through Warner Bros. Records).
After signing with Bearsville, Rundgren worked almost constantly on production projects through the early 1970s and he rapidly became one of the most sought-after and acclaimed producer-engineers of the period. He quickly gained a high reputation for his creative approach, his no-nonsense, "can-do" approach, and for his ability to solve problems, work very rapidly and bring projects to completion on time and on budget – although he did occasionally come into conflict with some of the performers with whom he worked, due to his intense work ethic and his rather sarcastic, aloof manner in the studio. Rundgren's first project for Bearsville was a Philadelphia band called The American Dream, followed by a trip to Nashville to produce Ian and Sylvia Tyson's group Great Speckled Bird, with a backing band featuring guitarist Amos Garrett, pedal steel player Buddy Cage, pianist David Briggs and bassist Norbert Putnam and drummer N. D. Smart, with whom Rundgren worked on several later projects. During this period, Rundgren also made an abortive attempt to record with Janis Joplin and her band for Joplin's next studio album, but the sessions came to nothing and the project was eventually taken over by Paul A. Rothchild; the result was Joplin's swansong LP "Pearl", which Rothchild pieced together from the incomplete session tapes, following the singer's untimely death from a heroin overdose.
Albert Grossman recommended Rundgren to Robbie Robertson of The Band as the engineer for an album Robertson was producing, by singer-songwriter Jesse Winchester, who was at the time living in exile in Canada to avoid the draft. This was followed by a live album for the Paul Butterfield Blues Band. Having impressed Robertson with his work on the Winchester LP, Rundgren was then asked to engineer The Band's third album, "Stage Fright", which was recorded in an often fraught series of sessions at the Woodstock Playhouse. One of these was attended by a budding New York writer called Patti Smith, and their chance meeting led to an enduring friendship. Smith became an ardent champion of Rundgren's early solo work through her reviews in the rock press, and the friendship came full-circle in 1979 when Rundgren produced the final Patti Smith Group album "Wave".
His work for The Band was followed by a second album for Winchester (which was then shelved for two years) and the album "Taking Care of Business" by the James Cotton Blues Band. This project resulted in another fortuitous meeting for Rundgren, introducing him to Cotton's keyboard player Mark "Moogy" Klingman, who in turn introduced Rundgren to keyboard player Ralph Schuckett, and both would work extensively with Todd over the next few years.
Runt and solo career, 1970-1972.
Although he had originally intended to concentrate on production rather than his own music, in 1970 Todd formed the 'band' Runt, consisting of himself, teenagers Hunt Sales on drums, and his brother Tony Sales on bass (the Sales brothers, sons of US comedian Soupy Sales, were in a short lived band called Tony and the Tigers and went on to play with Iggy Pop, David Bowie, and Tin Machine). Rundgren himself wrote, produced, sang and played guitars, keyboards and other instruments. Whether Runt is best described as a band or simply as a pseudonym for Rundgren as a solo artist is unclear—for the album "Runt" (1970) the group appeared to be a "bona fide" trio, but on their second album "" (1971), Hunt Sales plays only on two tracks and is replaced by N. D. Smart on the rest of the album. Furthermore, only Rundgren is pictured on the covers of both albums, and both albums have been subsequently reissued with the same titles and cover art, but bearing the artist credit "Todd Rundgren". Whether a solo project or a band, Runt had a No. 20 hit in the United States with "We Gotta Get You a Woman" in 1970, and two other Runt songs placed in the lower reaches of the Hot 100.
By this time, Rundgren had effectively moved his base to Los Angeles. As he prepared for his second solo album, he was introduced to aspiring L.A. band Halfnelson, led by brothers Ron Mael and Russell Mael and guitarist Earle Mankey. After attending an elaborate, self-staged 'showcase' performance by the group at their L.A. rehearsal space, Rundgren became intrigued by their music and agreed to produce their debut album, originally released as "Halfnelson" and later retitled "Sparks". The brothers later credited Rundgren as being instrumental in launching their career and in 2010 Russell Mael commented that when reviewing the album in 2008 they were still "... really happy with the way it sounded. There's nothing there that really sounds 'of an era' because it didn't exactly sound 'of an era' at the time."
By 1972, the Runt persona/band identity had been abandoned, and Rundgren's next project, the ambitious double LP "Something/Anything?" (1972) was credited simply to Rundgren, who wrote, played, sang, engineered, and produced everything on three of the four sides of the album. "Something/Anything?" featured the Top 20 U.S. hits "I Saw the Light" (#16; not to be confused with the Hank Williams song of the same name), and a remake of the Nazz near-hit "Hello It's Me", which reached No. 5 in the United States and is Rundgren's biggest hit. The former song featured Rundgren on all vocals and instruments. On his ensuing concert tour, his backing band was the Hello People, whose own album he later produced.
Changing style, 1973-1975.
The "Something/Anything?" period marked a significant change in Rundgren's lifestyle. Up until that time he neither drank nor took any drugs:
However, he began to change his views after a visit to Philadelphia to see Randy Reed, his closest friend from his school days. Reed introduced Todd to cannabis, and he credited this with having a big effect on his songwriting for his second solo album, "The Ballad of Todd Rundgren". In the lead-up to his third album, "Something/Anything?", he was experimenting with various mind-altering substances including cannabis, and a range of psychedelics including DMT, psilocybin mushrooms, and peyote – although he says he never (to his knowledge) took LSD. During the recording of "Something/Anything?", he began using the stimulant Ritalin and he later said that it had a marked effect both on the style of his music and on his productivity:
Speaking of the effect on "A Wizard, A True Star" (1973), Rundgren commented:
Though he often revisited the classic popular song format, during the early 1970s Rundgren's music began to incorporate elements of progressive rock. The transitional "A Wizard, a True Star" (1973) marked the beginning of this trend, which came to fruition with his next two solo albums "Todd" (1974) and "Initiation" (1975) and the early recordings under the aegis of his new group project Utopia.
Shortly after he had completed work on "Something/Anything?", Los Angeles was struck by a strong earthquake, and Rundgren was sufficiently unnerved by this to move back to New York. His return east led to a long and fruitful working relationship with Moogy Klingman and the pair collaborated extensively over the next few years. They built a recording facility in Manhattan which they dubbed Secret Sound Studios, and a large proportion of Rundgren's solo and production work was done there, until his relocation to Woodstock in the mid-1970s.
"A Wizard, a True Star" (1973), which was sequenced as a continuous medley, featured a wildly eclectic range of songs set in dazzling arrangements and production, with Rundgren experimenting with the synthesizer and exploiting virtually every studio effect and technique then available. Backing musicians included renowned horn players Michael Brecker and Randy Brecker, guitarist Rick Derringer and several other musicians, who subsequently joined the original incarnation of Utopia. Although it featured predominantly original material (including the anthemic "Just One Victory", which became a concert favorite), the album set a pattern followed on subsequent solo albums, with Rundgren recording cover versions of his favorite songs – in this case, "Never Never Land", from the Broadway musical version of "Peter Pan", and a medley of soul classics, including a unique version of the Capitols' "Cool Jerk" played in the 7/8 time signature. The album was also notable for its extended running time – over 55 minutes in length, compared to around 40–45 minutes for a typical pop-rock LP of the period. This reflected Rundgren's skills as a mastering engineer, since this extended running time took the album close to the practical maximum for an LP. Due to the inherent physical limitations of the vinyl LP medium, on records with running times over 45 minutes there is an unfavorable trade-off between duration and the audio quality and volume. On the album cover, packed with his handwritten notes, he advised listeners to crank up their Victrolas accordingly.
"Todd" (1974) continued in this vein and featured similarly diverse material. Alongside originals such as "A Dream Goes on Forever" and "Heavy Metal Kids", both of which became concert staples, Rundgren also satirized his chosen profession with the song "An Elpees' Worth of Tunes" and revisited his teenage obsession with the music of Gilbert & Sullivan in a rendition of "The Lord Chancellor's Nightmare Song" (from "Iolanthe"). "Izzat Love?" was sampled by Indie artist Neon Indian on their song, "Deadbeat Summer" in 2010.
By contrast, Rundgren's work with Utopia (see below) and his next solo album took him decisively into progressive rock. "Initiation" (1975) addressed cosmic themes, showed a strong interest in spirituality (particularly Far Eastern religion and philosophy), and displayed the musical influence of psychedelic rock, as well as the avant-garde jazz fusion of contemporary acts such as the Mahavishnu Orchestra and Frank Zappa. Once again the original LP issue saw Rundgren pushing the medium to its physical limits, with the side-long suite "A Treatise on Cosmic Fire" clocking in at over 35 minutes.
Touring and equipment.
When touring, Rundgren presented the music in a lavish stage setting that echoed the ambitious space-themed shows of acts like Parliament/Funkadelic and he adopted an outlandish space-rock image on stage, including multi-colored dyed hair.
During 1977 and 1978, Rundgren attempted to tour with a true quadraphonic sound system, however it proved ultimately unworkable – despite successfully delivering high-quality sound in a concert setting – due to the enormous technical requirements involved. Since most concert arenas of the day were ill-equipped to host large towers of sound equipment in the rear of the halls, the speakers often had to be hung from the ceiling rigging. This installation could take up to two days to complete, meaning that it was necessary to send two separate sound systems, each with its own, complete set-up crew, out on the road, so that they could "leapfrog" and allow Rundgren to play dates on consecutive days, which would have otherwise been impossible. The system featured a then-new technology called "signal analysis", which required white and pink noise to be pumped through the speakers, in order to set the active equalizers so as to minimize feedback and distortion. The pink and white noise analysis had to be performed twice: once with the hall empty, and then again with the audience present, which many concertgoers found annoying. Additionally, Rundgren's insistence on personally overseeing the acoustic set-up of the system left him exhausted and unable to continue, and he pulled the plug on the experiment.
During the mid-to-late 1970s, Rundgren regularly played the eye-catching psychedelic Gibson SG (known variously as "Sunny" or "The Fool"), which Eric Clapton had played in Cream. After he had stopped using it ca. 1968, Clapton gave the guitar to George Harrison, who subsequently 'loaned' it to British singer Jackie Lomax. In 1972, after meeting at a recording session, Lomax sold the guitar to Rundgren for $500 with an option to buy it back, which he never took up. Rundgren played it extensively during the early years of Utopia before retiring the instrument for a short time in the mid to late 1970s, which in that time he had the guitar restored having a lacquer finish applied to protect the paint and replaced the talpiece and bridge to stabilize tuning, bringing the guitar back out on tour during the 1980 Deface the Music tour and using it on and off throughout the 1980s until 1993 when he permanently retired the guitar, eventually auctioning it off in 1999; he now uses a reproduction given to him in 1988 by a Japanese fan.
"Faithful", "Hermit of Mink Hollow" and "Back to the Bars", 1976-1979.
The 1976 album "Faithful" saw Rundgren marking his tenth year as a professional musician by return to the pop/rock genre, featuring one side of original songs and one side of covers of significant songs from 1966, including The Yardbirds' "Happening Ten Years Time Ago" (the B-side of that Yardbirds single gave Nazz its name) and a nearly identical recreation of The Beach Boys' "Good Vibrations".
In the latter half of the 1970s, Rundgren moved to Woodstock, where Bearsville Records established a studio under Rundgren's direction. He bought a home nearby and a property adjoining the studio was taken over as accommodation for artists who used the studio. The Woodstock complex became Rundgren's base until his eventual relocation to the Hawaiian island of Kauai in the 1990s. That move was in part prompted by a violent home invasion at Woodstock in the late 1970s, in which Rundgren and girlfriend (who was pregnant at the time) were tied up while the house was ransacked by a group of armed men. According to Rundgren's account, the men appeared to believe that he possessed a large quantity of cocaine (which he never used); although the family was unharmed, the men stole some valuable items including a custom-made Alembic bass guitar. Todd recovered it years later after Alembic staff spotted it for sale on eBay and it was returned to him, but was by then so badly damaged that it could not be restored.
"Faithful" was followed by "Hermit of Mink Hollow" (1978); this included the hit ballad "Can We Still Be Friends" (covered a year later by Robert Palmer), which reached No. 29 in the United States (Palmer's version reached No. 52) and was accompanied by an innovative self-produced music video, and the album became the second most successful of his career (after "Something/Anything?"), reaching No. 36 in the United States. During 1978, Rundgren undertook an American tour playing at smaller venues including The Bottom Line in New York and The Roxy in Los Angeles; this resulted in the double live album "Back to the Bars", which featured a mixture of material from his solo work and Utopia, performed with backing musicians including Utopia, Edgar Winter, Spencer Davis, Daryl Hall and John Oates and Stevie Nicks.
1980-1991.
Subsequent solo releases included the album-long concept work "Healing" (1981) and the new wave-tinged "The Ever Popular Tortured Artist Effect" (1982), which included a cover of The Small Faces' hit "Tin Soldier". The latter album also marked the end of Rundgren's tenure with Bearsville Records. He then signed with Warner Bros. Records, who issued his next album, "A Cappella" (1985), which was recorded using Rundgren's multi-tracked voice, accompanied by arrangements constructed entirely from programmed vocal samples. "Bang the Drum All Day", from "The Ever Popular Tortured Artist Effect" was a minor chart hit, which has become more prominent in subsequent years, having been adopted as an unofficial theme by several professional sports franchises, notably the Green Bay Packers, and becoming popular on radio, where it was often featured on Friday afternoons. "Bang..." was also used prominently in a Carnival Cruise television advertising campaign. It is now considered one of Rundgren's most popular songs. In 1986, Rundgren scored four episodes of the popular children's television show Pee Wee's Playhouse.
"Nearly Human" (1989) and "2nd Wind" (1991) were both recorded live—the former in the studio, the latter in a theater before a live audience, who were instructed to remain silent. Each song on these albums was recorded as a complete single take with no later overdubbing. Both albums marked, in part, a return to his Philly soul roots. "2nd Wind" also included several excerpts from Rundgren's musical "Up Against It", which was adapted from the screenplay (originally titled "Prick Up Your Ears"), that British playwright Joe Orton had originally offered to the Beatles for their never-made follow-up to "Help!". "2nd Wind" was Rundgren's last release through a major label and all his subsequent recordings have been self-released.
After a long absence from touring, Rundgren hit the road with "Nearly Human—2nd Wind" band, which included brass and a trio of slinky backup singers (one of whom, Michele Gray, Rundgren married). He also toured during this period with Ringo Starr's All-Starr band.
1993-present.
The next few years saw Rundgren recording under the pseudonym TR-i ("Todd Rundgren interactive") for two albums. The first of these, 1993's "No World Order", consisted of hundreds of seconds-long snippets of music, that could be combined in various ways to suit the listener. Initially targeted for the Philips CD-i platform, "No World Order" featured interactive controls for tempo, mood, and other parameters, along with pre-programmed mixes by Rundgren himself, Bob Clearmountain, Don Was and Jerry Harrison. The disc was also released for PC and Macintosh and in two versions on standard audio CD, the continuous mix disc "No World Order" and, later, the more song-oriented "No World Order Lite". The music itself was quite a departure from Rundgren's previous work, with a dance/techno feel and much rapping by Rundgren. The follow-up, "The Individualist" (1995), featured interactive video content, that could be viewed or in one case, played; it was a simple video game along with the music, which was more rock-oriented than "No World Order".
Rundgren returned to recording under his own name for "With a Twist..." (1997), an album of bossa-nova covers of his older material. His Patronet work, which trickled out to subscribers over more than a year, was released in 2000 as "One Long Year". In 2004, Rundgren released "Liars", a concept album about "paucity of truth", that features a mixture of his older and newer sounds.
In early 2008, Rundgren launched his official MySpace page. Later that year, he released the rock album "Arena". In concert, he had been performing the album in full and in sequence before its release.
Rundgren released the live compilation album, "For Lack of Honest Work", in 2010. The album was advertised as a collection of bootleg recordings, that were approved by Rundgren himself.
April 2011 saw the release of "Todd Rundgren's Johnson", a collection of Robert Johnson covers, which had been recorded more than a year earlier. On another 2011 release, scheduled for September 13, a further album of covers entitled "(re)Production" sees him performing tracks he had previously produced for other acts, including Grand Funk Railroad's "Walk Like a Man" and XTC's "Dear God".
In April 2013, Rundgren released his 24th solo album, "State".
On April 7, 2015, Todd released his 25th solo album, "Global", with a vinyl release of the album on April 27. He started a US tour to promote the album on April 10 and is planned to continue through June including an appearance on "The Late Show with David Letterman" on April 27.
Utopia.
Rundgren's back-up band for "A Wizard, a True Star" (1973) evolved into the first version of Utopia, a larger prog-rock ensemble, which included multiple keyboards, synthesizers and brass and featured a character completely disguised in a silver suit, "M. Frog Labat" (Jean-Yves Labat de Rossi) on synthesizers, who also put out his own electronics/keyboards-based solo album. This incarnation premiered on "Todd Rundgren's Utopia" (1974), which was book-ended by the 14-minute "Utopia Theme" (recorded live in concert) and the 30-minute suite "The Ikon", which occupied the whole of Side 2 of the album. Like "Wizard", the album also showcased Rundgren's skills as a recording and mastering engineer, clocking in at over 30 minutes per side.
A slightly altered version of this group performed on the eclectic live album "Another Live" (1975). It featured three new extended progressive tracks (which appear only on this LP), a version of "Heavy Metal Kids" (from "Todd") and covers of "Something's Coming" (from "West Side Story") and "Do Ya" by The Move. By the time this album was recorded, the Utopia lineup included keyboard player/trumpeter/vocalist Roger Powell and drummer John "Willie" Wilcox.
In 1976, Siegler left Utopia and was replaced by Kasim Sulton (bass, keyboards, vocals), who had previously played with New York singer-poetess Cherry Vanilla. This formidable ensemble was widely regarded as one of the best live acts of its day—all four members were highly accomplished on their main instrument as well as being able to play multiple other instruments, and all four could sing lead vocals.
After the prog-rock fusion homage, "Ra" (1977), Utopia moved toward a more concise pop-oriented style with "Oops! Wrong Planet" (1977), which included "Love Is the Answer", later a hit for England Dan & John Ford Coley, followed by the more successful "Adventures in Utopia" in 1980, which spawned the hits "Road to Utopia", "Set Me Free" and "Caravan". During that year, Utopia also acted as the backing band for the Rundgren-produced Shaun Cassidy solo album "Wasp".
Other releases include "Deface the Music" (also 1980), an uncanny Beatles homage, that borders on parody; the more politicised "Swing to the Right" (1982), incorporating more new wave elements; their pop-referenced, self-titled album "Utopia" (1982), as well as "Oblivion" (1984), which showed a cynical side of Utopia, sporting a black cover. The album "P.O.V." (1985) includes "Mated", later a staple of Rundgren solo tours. Rundgren eventually disbanded Utopia in the mid-1980s; they released "Trivia" (1986) as their "swan song" effort. However, in 1992, a brief tour of Japan reunited the Rundgren/Powell/Sulton/Wilcox lineup, and "" was released on Rhino Records.
Eventually, the compilation "Oblivion", "P.O.V." and "Some Trivia" was released in 1996, an effort by Rhino Records to re-release selections from the Todd/Utopia discography. In addition, many Utopia concerts from the mid-1970s onwards were taped (e.g. their 1975 London debut, recorded by BBC Radio) and these were widely bootlegged by fans, although some have since gained an official release and can now be obtained as commercial digital downloads from iTunes.
Production, video and other work.
In addition to his own recordings, Rundgren has engineered and/or produced albums for many notable acts. Sparked by his dissatisfaction with the sound quality of the Nazz albums, Rundgren learned how to engineer and master his own records and since 1970, he has overseen production of all his solo recordings and those by Utopia. His earliest outside credits were as producer on a long-unreleased Janis Joplin track (recorded with the Paul Butterfield Blues Band) and as recording engineer for the LP "Stage Fright" by The Band (1970). Other notable production credits include Halfnelson (first incarnation of Sparks), New York Dolls, Badfinger, Grand Funk Railroad, Hall & Oates, Ian and Sylvia (on their "Great Speckled Bird" album), Meat Loaf, Patti Smith, Shaun Cassidy, The Tubes, Tom Robinson Band, XTC, Bad Religion, John Sloman, Cheap Trick, Hello People, Hiroshi Takano, Bourgeois Tagg, Dragon (aka Hunter), 12 Rods, The Pursuit of Happiness, The Psychedelic Furs, Steve Hillage, The American Dream and many others.
The difficult XTC sessions produced the album "Skylarking" (1986), now considered a high point for band and producer despite its acrimonious origin. Rundgren's production of Meat Loaf's "Bat Out of Hell" (1977) (on which he also played lead guitar) helped that album become one of the top selling LPs released in the 1970s. The industry regard for Rundgren's production work has been a lofty one: Jim Steinman, with whom Rundgren worked on "Bat Out of Hell", has said in interviews, that ""Todd Rundgren is a genius and I don't use that word a lot.""
Rundgren has long been on the cutting edge of music and video technologies. His music video for the song "Time Heals" was among the first videos aired on MTV, and a video he produced for RCA, accompanied by Gustav Holst's "The Planets", was used as a demo for their videodisc players. His experience with computer graphics dates back to 1981, when he developed one of the first computer paint programs, dubbed the Utopia Graphics System; it ran on an Apple II with Apple's digitizer tablet. He is also the co-developer of the computer screensaver system Flowfazer.
In the 1990s, Rundgren was an early adopter of the NewTek Video Toaster and made several videos with it. The first, for "Change Myself" from "2nd Wind", was widely distributed as a demo reel for the Toaster; he also used the system for videos from "No World Order" (songs "Fascist Christ" and "Property"). Later, he set up a company to produce 3D animation using the Toaster; this company's first demo, "Theology" (a look at religious architecture through the ages featuring music by former Utopia bandmate Roger Powell) also became a widely circulated item among Toaster users. Most of Rundgren's Toaster work is available on the video compilation "The Desktop Collection."
Rundgren composed music for the 1986 television series "Pee-wee's Playhouse" and "Crime Story" as well as the movies "Undercover" (a/k/a "Under Cover") (1987), and "Dumb and Dumber" (1994), plus background cues for several other television series. He hosted a syndicated radio show called "The Difference" in the early 1990s.
In 1986, he sang a duet with Bonnie Tyler: "Loving You's a Dirty Job but Somebody's Gotta Do It", released (also as a single) on Bonnie's album "Secret Dreams and Forbidden Fire".
As the Internet gained mass acceptance in the mid-1990s Rundgren, along with longtime manager Eric Gardner and Apple digital music exec Kelli Richards, started Patronet, which offered fans (patrons) access to his works-in-progress and new unreleased tracks in exchange for a subscription fee, cutting out record labels. The songs from Rundgren's first Patronet run were later released as the album "One Long Year". Since then, Rundgren has severed his connections with major record labels and continues to offer new music direct to subscribers via his website, although he also continues to record and release CDs through independent labels. (However, as of November 2007, the PatroNet.com website offers the following message: "PatroNet is undergoing a major software revision and is not accepting memberships at this time.")
Rundgren produced the 1999 debut album for the band Splender, entitled "Halfway to the Sky".
In the summer of 2001, Rundgren joined artists such as Alan Parsons, the Who's John Entwistle, Heart's Ann Wilson and Ambrosia's David Pack for the tour "A Walk Down Abbey Road", in which the musicians played their own hits alongside Beatles favorites. They also did a short tour of Japan in the winter of 2001, and another the following year, which included Jack Bruce of Cream, Mark Farner of Grand Funk Railroad, Christopher Cross and Eric Carmen.
In the aftermath of the September 11 attacks Rundgren created the score for the film "A Face to a Name", directed by Douglas Sloan. The film depicted the many photographs of NY's missing, that were displayed on Bellevue Hospital's 'wall of prayers' following the attacks. The film was part of a special screening at the Woodstock Film Festival in 2002.
Rundgren toured the United States and Europe in 2004 with Joe Jackson and the string quartet Ethel, appearing on "Late Night with Conan O'Brien" performing their collaborative cover of the Beatles song "While My Guitar Gently Weeps".
In 2009, Rundgren produced "Cause I Sez So" by the New York Dolls. In October, in one of the last concerts at the famed Wachovia Spectrum, Rundgren and Philadelphia area musicians the Hooters and Hall & Oates headlined a concert titled "Last Call". Tickets were as low as $6.00, the deep discount reflected ticket prices in 1967, when the Spectrum first staged concerts.
The year also included a lecture at DePauw University in Indiana, in which he discussed "Music, Technology and Risk-Taking".
In late-October to early-November 2010, Rundgren was the IU Class of 1963 Wells Scholars Professor at Indiana University. He taught a course with IU Professor Glenn Gass entitled 'The Ballad of Todd Rundgren'.
The New Cars.
In late 2005, the Boston-based band The Cars were planning to re-form despite bassist Benjamin Orr's death and lack of interest on the part of former lead singer Ric Ocasek. Rumors followed that Rundgren had joined Elliot Easton and Greg Hawkes in rehearsals for a possible new Cars lineup. Initial speculation pointed to The New Cars being fleshed out with Clem Burke of Blondie and Art Alexakis of Everclear. Eventually it was revealed that The New Cars were to complete their lineup with veteran bass player and former Rundgren bandmate Kasim Sulton and studio drummer Prairie Prince of The Tubes, who had played on XTC's Rundgren-produced "Skylarking" and who has recorded and toured with Rundgren.
In early 2006, the new lineup played a few private shows for industry professionals, played live on "The Tonight Show with Jay Leno" and made other media appearances before commencing a 2006 summer tour with the re-formed Blondie.
Rundgren has referred to the project as "an opportunity ... for me to pay my bills, play to a larger audience, work with musicians I know and like, and ideally have some fun for a year."
The New Cars' first single, "Not Tonight", was released on March 20, 2006. A live album/greatest hits collection, "The New Cars: It's Alive", was released in June 2006. The album includes classic Cars songs (and two Rundgren hits) recorded live plus three new studio tracks ("Not Tonight", "Warm" and "More").
Tours from 2009–13.
In April 2009, Rundgren discussed his career during an Ubben Lecture at Indiana's DePauw University. In September 2009, Rundgren assembled a very limited-engagement tour with Jesse Gress, Kasim Sulton, Prairie Prince, Greg Hawkes, Bobby Strickland, and Roger Powell (and his wife Michele as costume designer and back-up singer for the concerts finale'), covering his album "A Wizard, A True Star" (1973). The shows included a complete, start-to-finish rendition of the album, with multiple costume changes and theatrical props to accent the songs. The opening band for the shows was Utopia, with Roger Powell, Kasim Sulton and Prairie Prince.
In December 2009, Rundgren once again took the AWATS Live show on the road with four shows in California. Roger Powell returned to his real job in the computer/software industry and was replaced by Ralph Schuckett, who played keyboards on the studio recording of the original album.
The A Wizard a True Star show has had two European dates as well; playing in London, England at the Hammersmith Apollo on February 6, 2010, and the Paradiso in Amsterdam, the Netherlands on February 8, 2010. Rundgren opened the London and Amsterdam shows by showcasing his new project, entitled 'Todd Rundgren's Johnson'; consisting of Rundgren, Jesse Gress (guitar), Prairie Prince (drums) and Kasim Sulton (bass) reworking Robert Johnson songs.
In January 2010, Rundgren gave his first ever concert performance in Australia as a participant in the "Rogue's Gallery" show, produced by Hal Willner for the 2010 Sydney Festival. In October 2010, Rundgren returned for a three-date tour of Australia performing his 'Johnson' project, with concerts at The Basement, Sydney, the Great Southern Blues Festival at Bateman's Bay and the Corner Hotel in Melbourne. The band consisted of Todd, guitarist Jesse Gress, Australian bassplayer Damien Steele Scott and Australian drummer Mick Skelton of Baby Animals.
A Photographic Journal of each American show was created by rock photographer J Bloomrosen.
Rundgren participated in the Hollywood Bowl's "Beatles Celebration" concert held July 9–11, 2010 along with the Hollywood Bowl Orchestra conducted by Thomas Wilkins. Featured guests over the three nights also included Patti Austin, Bettye LaVette, Rob Laufer and Brian Stokes Mitchell. He performed "Being for the Benefit of Mr. Kite", outfitted in an outsized top hat, fake walrus mustache, black waistcoat, white gloves and white spats. He amped up the show's rock quotient with "Everybody's Got Something to Hide Except for Me and My Monkey," and took over the guitar solo in "While My Guitar Gently Weeps", which he preceded with a nod to Ringo Starr's 70th birthday (which had been just two nights earlier). Finally, his performance of "A Day in the Life" concluded his set.
In October 2010, Rundgren was selected as the Class of 1963 Wells Scholars Professor at Indiana University. In that capacity, he taught two weeks of a four-week, one-credit hour honors seminar designed for 22 Wells Scholars (HON-H300: The Ballad of Todd Rundgren). Co-teaching the class was IU Professor of Music Glenn Gass—whose relationship with Rundgren helped make the professorship possible—and IU Distinguished Professor of Sociology Bernice Pescosolido, who was instrumental in helping to plan the course.
In September 2010, Rundgren performed his "Todd" and "Healing" albums live for the first time ever in Akron, OH and followed that up with five more of the album concerts in Muskegon MI, Indianapolis IN, St. Louis MO, Glenside PA, and Morristown NJ. A large LED display and lasers were on display throughout the shows with Rundgren and the band dressed in extravagant costumes. Rundgren brought out his SG Gibson "The Fool" replica guitar and also performed a few songs on the piano. The band consisted of Jesse Gress, Greg Hawkes, Prairie Prince, Bobby Strickland, and Kasim Sulton. Led by Choir Master Dirk Hillyer, local choirs from near each venue joined the band during parts of the "Healing" album set, which added a brand new element to the music for fans, that had only heard it by listening to the album. The shows closed with the song, "Sons of 1984", which included fan participation even after the band left the stage. In March 2011, Rundgren took the "Todd" and "Healing" albums live concerts back on the road for a mini-tour and included stops in Hartford CT, Boston MA, Red Bank NJ, Toledo OH, and Columbus OH.
In January 2011, a reunion of the most of the members of the 1974 Utopia personnel (Rundgren, Klingman, Schuckett, Siegler, and Ellman) was held for two nights in New York City, with proceeds to defray medical treatment for Klingman, who was battling with cancer. Material was drawn from the 1972–1975 catalogs of Rundgren and Todd Rundgren's Utopia. Both shows sold out in just three days, which may have influenced the idea for a full tour, that took place in November 2011 as "Todd Rundgren's Utopia". The original plan for the tour included Moogy Klingman but his health condition worsened during rehearsals and he died before the 12 concert tour was finished.
In September 2011, for the first time ever with a symphony orchestra, Rundgren performed two concerts in the Netherlands (Amsterdam and Groningen) backed by the Dutch Metropole Orchestra. On June 1–2, 2012, he performed in two concerts accompanied by the Rockford Symphony Orchestra at the historic Coronado Performing Arts Center in Rockford, IL. The concerts were Rundgren's first ever symphonic shows in North America.
Rundgren toured with Ringo Starr & His All-Starr Band for the third time and for the first time in 13 years, starting in the summer of 2012, and continuing to 2015.
In November 2012, Rundgren again collaborated with the Dutch Metropole Orchestra. At the Paradiso venue in Amsterdam, he was also backed by three backing vocalist, including Dutch singer Mathilde Santing with whom he sang a duet that night. This concert was released as a bonus cd with his cd State.
In August 2013, Rundgren performed with the Akron Symphony Orchestra and Akron Youth Symphony at the Akron Civic Theatre under the baton of conductor Levi Hammer. This was his first concert with a youth symphony orchestra.
Personal life.
Rundgren has three sons; Rex (born 1980) and Randy (born 1985) with his long-term girlfriend Karen Darvin, and Rebop, with current wife Michele. Rex is a minor league baseball player (Infield position), who, as of 2012, plays for the Tulsa (Oklahoma) Drillers.
From 1972 to 1979, Rundgren had a longterm relationship with model Bebe Buell. During their cohabitation, sometimes they were on-and-off. In 1976, Buell became unexpectedly pregnant from her brief relationship with Steven Tyler. On July 1, 1977, Buell gave birth to future actress/model Liv Tyler. But Buell initially named the daughter "Liv Rundgren" and claimed that Todd Rundgren was the biological father to protect the child from Tyler's drug addiction. Rundgren and Buell ended their romantic relationship shortly after Liv's birth, but Rundgren put his heart and soul into the "white lie". At age eight, Liv was made aware of her real parentage, that she is in fact Steven Tyler's biological daughter.
According to Tyler "...Todd basically decided when I was born that I needed a father so he signed my birth certificate. He knew that there was a chance that I might not be his but…" He paid to put her through private school, and she visited him several times a year.
Tyler maintains a close relationship with Rundgren. "I'm so grateful to him, I have so much love for him. You know, when he holds me it feels like Daddy. And he's very protective and strong."
In 1998, Rundgren married Michele Gray (Michele Rundgren), who had been a dancer with The Tubes, performed with Rundgren as a backup singer on the tour for his album "Nearly Human" which led to a number of appearances on the David Letterman Show as one of "The World's Most Dangerous Backup Singers".
In October 2013, along with his fans, Rundgren founded the Spirit of Harmony Foundation, to provide opportunities for personal development and self-expression through the support of music and music education.

</doc>
<doc id="36795" url="https://en.wikipedia.org/wiki?curid=36795" title="Medieval Warm Period">
Medieval Warm Period

The Medieval Warm Period (MWP), Medieval Climate Optimum, or Medieval Climatic Anomaly was a time of warm climate in the North Atlantic region that may also have been related to other climate events around the world during that time, including China and other areas, lasting from about 950 to 1250. It was followed by a cooler period in the North Atlantic termed the Little Ice Age. Some refer to the event as the Medieval Climatic Anomaly as this term emphasizes that effects other than temperature were important.
Despite uncertainties, especially for the period prior to 1600 for which data are scarce, the warmest period of the last 2,000 years prior to the 20th century very likely occurred between 950 and 1100. Proxy records show peak warmth occurred at different times for different regions, indicating that the Medieval Warm Period was not a time of globally uniform change. Temperatures in some regions matched or exceeded recent temperatures in these regions, but globally the Medieval Warm Period was cooler than recent global temperatures. 
Possible causes of the Medieval Warm Period include increased solar activity, decreased volcanic activity, and changes to ocean circulation.
Initial research.
The Medieval Warm Period (MWP) is generally thought to have occurred from about AD 950–1250, during the European Middle Ages. In 1965 Hubert Lamb, one of the first paleoclimatologists, published research based on data from botany, historical document research and meteorology combined with records indicating prevailing temperature and rainfall in England around 1200 and around 1600. He proposed that "Evidence has been accumulating in many fields of investigation pointing to a notably warm climate in many parts of the world, that lasted a few centuries around A.D. 1000–1200, and was followed by a decline of temperature levels till between 1500 and 1700 the coldest phase since the last ice age occurred."
The warm period became known as the MWP, and the cold period was called the Little Ice Age (LIA). However, this view was questioned by other researchers; the IPCC First Assessment Report of 1990 discussed the "Medieval Warm Period around 1000 AD (which may not have been global) and the Little Ice Age which ended only in the middle to late nineteenth century." The IPCC Third Assessment Report from 2001 summarised research at that time, saying "…current evidence does not support globally synchronous periods of anomalous cold or warmth over this time frame, and the conventional terms of 'Little Ice Age' and 'Medieval Warm Period' appear to have limited utility in describing trends in hemispheric or global mean temperature changes in past centuries". Global temperature records taken from ice cores, tree rings, and lake deposits, have shown that, taken globally, the Earth may have been slightly cooler (by 0.03 degrees Celsius) during the 'Medieval Warm Period' than in the early and mid-20th century.
Palaeoclimatologists developing region-specific climate reconstructions of past centuries conventionally label their coldest interval as "LIA" and their warmest interval as the "MWP". Others follow the convention and when a significant climate event is found in the "LIA" or "MWP" time frames, associate their events to the period. Some "MWP" events are thus wet events or cold events rather than strictly warm events, particularly in central Antarctica where climate patterns opposite to the North Atlantic area have been noticed.
By world region.
Evidence exists across the world, often very sparsely, for changes in climatic conditions over time. Some of the "warm period" events documented below are actually "dry periods" or "wet periods."
Globally.
A 2009 study by Michael Mann "et al." examining spatial patterns of surface temperatures shown in multi-proxy reconstructions finds that the MWP shows "warmth that matches or exceeds that of the past decade in some regions, but which falls well below recent levels globally." Their reconstruction of MWP pattern is characterised by warmth over large part of North Atlantic, Southern Greenland, the Eurasian Arctic, and parts of North America which appears to substantially exceed that of the late 20th century (1961–1990) baseline and is comparable or exceeds that of the past one-to-two decades in some regions. Certain regions such as central Eurasia, northwestern North America, and (with less confidence) parts of the South Atlantic, exhibit anomalous coolness.
North Atlantic.
Lloyd D. Keigwin's 1996 study of radiocarbon-dated box core data from marine sediments in the Sargasso Sea found that the sea surface temperature there was approximately cooler approximately 400 years ago (the Little Ice Age) and 1700 years ago, and approximately 1 °C warmer 1000 years ago (the Medieval Warm Period).
Using sediment samples from Puerto Rico, the Gulf Coast and the Atlantic Coast from Florida to New England, Mann "et al." (2009) found consistent evidence of a peak in North Atlantic tropical cyclone activity during the Medieval Warm Period followed by a subsequent lull in activity.
Through retrieval and isotope analysis of marine cores and examination of mollusc growth patterns from Iceland, Patterson "et al" were able to reconstruct a mollusc growth record at a decadal resolution from the Roman Warm Period through the Medieval Warm Period and into the Little Ice Age.
North America.
The 2009 Mann et al. study found warmth exceeding 1961–1990 levels in Southern Greenland and parts of North America during the Medieval climate anomaly (defined for this purpose as 950 to 1250) with warmth in some regions exceeding temperatures of the 1990–2010 period. Much of the Northern hemisphere showed significant cooling during the Little Ice Age (defined for the purpose as 1400 to 1700) but Labrador and isolated parts of the United States appeared to be approximately as warm as during the 1961–1990 period.
Norse colonization of the Americas has been associated with warmer periods. Popular books say that Vikings took advantage of ice-free seas to colonize areas in Greenland and other outlying lands of the far north but this has been challenged. Around 1000 AD the climate was sufficiently warm for the Vikings to journey to Newfoundland and establish a short-lived European outpost.
From around 985 AD Vikings founded the Eastern Settlement and Western Settlement, both near the southern tip of Greenland. In the colony's early stages they kept cattle, sheep, and goats, with around a quarter of their diet from seafood. After the climate became colder and stormier around 1250 their diet steadily shifted towards ocean sources; by around 1300 seal hunting provided over three quarters of their food. By mid century there was reduced demand for their exports and trade with Europe fell away. The last document from the settlements dates from 1412, and over the following decades the remaining Europeans left in what seems to have been a gradual withdrawal mostly due to economic factors such as increased availability of farms in Scandinavian countries.
In Chesapeake Bay (modern day Maryland and Virginia in the United States), researchers found large temperature excursions (changes from the mean temperature of that time) during the Medieval Warm Period (about 950–1250) and the Little Ice Age (about 1400–1700, with cold periods persisting into the early 20th century), possibly related to changes in the strength of North Atlantic thermohaline circulation. Sediments in Piermont Marsh of the lower Hudson Valley show a dry Medieval Warm period from AD 800–1300.
Prolonged droughts affected many parts of the western United States and especially eastern California and the west of Great Basin. Alaska experienced three time intervals of comparable warmth: AD 1–300, 850–1200, and post-1800. Knowledge of the North American Medieval Warm Period has been useful in dating occupancy periods of certain Native American habitation sites, especially in arid parts of the western U.S. Review of more recent archaeological research shows that as the search for signs of unusual cultural changes during the MWP has broadened, some of these early patterns (for example, violence and health problems) have been found to be more complicated and regionally varied than previously thought while others (for example, settlement disruption, deterioration of long distance trade, and population movements) have been further corroborated.
Other regions.
The climate in equatorial east Africa has alternated between drier than today, and relatively wet. The drier climate took place during the Medieval Warm Period (~AD 1000–1270).
A sediment core from the eastern Bransfield Basin, Antarctic Peninsula, preserves climatic events in the Little Ice Age and Medieval Warm Period. The core shows a distinctly cold period about AD 1000–1100, illustrating that during the "warm" period there were, regionally, periods of both warmth and cold.
Corals in the tropical Pacific Ocean suggest that relatively cool, dry conditions may have persisted early in the millennium, consistent with a La Niña-like configuration of the El Niño-Southern Oscillation patterns. Although there is an extreme scarcity of data from Australia (for both the Medieval Warm Period and Little Ice Age) evidence from wave-built shingle terraces for a permanently full Lake Eyre during the 9th and 10th centuries is consistent with this La Niña-like configuration, though of itself inadequate to show how lake levels varied from year to year or what climatic conditions elsewhere in Australia were like.
The MWP has been noted in Chile in a 1500-year lake bed sediment core, as well as in the Eastern Cordillera of Ecuador.
Adhikari and Kumon (2001), whilst investigating sediments in Lake Nakatsuna in central Japan, finding a warm period from AD 900 to 1200 that corresponded to the Medieval Warm Period and three cool phases, of which two could be related to the Little Ice Age. Another research in northeastern Japan shows that there is one warm/humid interval from AD 750 to 1200, and two cold/dry intervals from AD 1 to 750 and 1200 to present. Ge "et al." studied temperatures in China during the past 2000 years; they found high uncertainty prior to the 16th century but good consistency over the last 500 years, "highlighted by the two cold periods 1620s–1710s and 1800s–1860s, and the warming during the 20th century". They also found that the warming during the 10–14th centuries in some regions might be comparable in magnitude to the warming of the last few decades of the 20th century which was unprecedented within the past 500 years.
A 1979 study from the University of Waikato found that "Temperatures derived from an 18O/16O profile through a stalagmite found in a New Zealand cave (40.67°S, 172.43°E) suggested the Medieval Warm Period to have occurred between AD 1050 and 1400 and to have been 0.75 °C warmer than the Current Warm Period." The MWP has also been evidenced in New Zealand by an 1100-year tree-ring record.
A reconstruction based on ice cores found the Medieval Warm Period could be distinguished in tropical South America from about 1050 to 1300, followed in the 15th century by the Little Ice Age. Peak temperatures did not rise as high as those from the late 20th century, which were unprecedented in the area during the study period going back around 1600 years.

</doc>
<doc id="36796" url="https://en.wikipedia.org/wiki?curid=36796" title="Paclitaxel">
Paclitaxel

Paclitaxel is a drug used to treat ovarian, breast, lung, pancreatic and other cancers. It and docetaxel represent the taxane family of drugs. Paclitaxel's mechanism of action involves interference with the normal breakdown of microtubules during cell division.
Common side effects include: hair loss, muscle and joint pains, and diarrhea, among others. It results in a greater risk of infections that can potentially be serious. Use during pregnancy often results in problems in the infant.
Paclitaxel was discovered beginning in 1962 as a result of a U.S. National Cancer Institute-funded screening program; being isolated from the bark of the Pacific yew, "Taxus brevifolia", thus its name "taxol". Developed commercially by Bristol-Myers Squibb, the generic name has changed to "paclitaxel" with a trademark becoming "Taxol". Other trademarks include Abraxane. Clinicians sometimes use the abbreviation "PTX" for paclitaxel, which is discouraged because it is not a unique identifier.
Paclitaxel is on the World Health Organization's List of Essential Medicines, the most important medication needed in a basic health system. Originally, there was concern over the environmental impact of its initial sourcing from the slow growing Pacific yew. Both the assignment of rights to Bristol-Myers Squibb and the product name were subject to public debate and Congressional hearings.
Medical use.
Paclitaxel is approved in the UK for ovarian, breast and lung, bladder, prostate, melanoma, esophageal, and other types of solid tumor cancers as well as Kaposi's sarcoma.
It is recommended in NICE guidance of June 2001 that it should be used for nonsmall cell lung cancer in patients unsuitable for curative treatment, and in first-line and second-line treatment of ovarian cancer. In September 2001, NICE recommended paclitaxel should be available for the treatment of advanced breast cancer after the failure of anthracyclic chemotherapy, but that its first-line use should be limited to clinical trials. In September 2006, NICE recommended paclitaxel should "not" be used in the adjuvant treatment of early node-positive breast cancer. In 2005, its use in the United States for the treatment of breast, pancreatic, and non-small cell lung cancers was approved by the FDA.
Similar compounds.
Albumin-bound paclitaxel (trade name Abraxane, also called nab-paclitaxel) is an alternative formulation where paclitaxel is bound to albumin nano-particles. Much of the clinical toxicity of paclitaxel is associated with the solvent Cremophor EL in which it is dissolved for delivery.
Abraxis BioScience developed Abraxane, in which paclitaxel is bonded to albumin as an alternative delivery agent to the often toxic solvent delivery method. This was approved by the U.S. Food and Drug Administration in January 2005 for the treatment of breast cancer after failure of combination chemotherapy for metastatic disease or relapse within six months of adjuvant chemotherapy.
Synthetic approaches to paclitaxel production led to the development of docetaxel. Docetaxel has a similar set of clinical uses to paclitaxel and is marketed under the name of Taxotere.
Recently the presence of taxanes including paclitaxel, 10-deacetylbaccatin III, baccatin III, paclitaxel C, and 7-epipaclitaxel in the shells and leaves of hazel plants has been reported. The finding of these compounds in shells, which are considered discarded material and are mass-produced by many food industries, is of interest for the future availability of paclitaxel.
Restenosis.
Paclitaxel is used as an antiproliferative agent for the prevention of restenosis (recurrent narrowing) of coronary and peripheral stents; locally delivered to the wall of the artery, a paclitaxel coating limits the growth of neointima (scar tissue) within stents. Paclitaxel drug eluting coated stents for coronary artery placement are sold under the trade name Taxus by Boston Scientific in the United States. Paclitaxel drug eluting coated stents for femoropopliteal artery placement are sold under the trade name Zilver PTX by Cook Medical, Inc.
Side effects.
Common side effects include nausea and vomiting, loss of appetite, change in taste, thinned or brittle hair, pain in the joints of the arms or legs lasting two to three days, changes in the color of the nails, and tingling in the hands or toes. More serious side effects such as unusual bruising or bleeding, pain/redness/swelling at the injection site, Hand-foot syndrome, change in normal bowel habits for more than two days, fever, chills, cough, sore throat, difficulty swallowing, dizziness, shortness of breath, severe exhaustion, skin rash, facial flushing, female infertility by ovarian damage and chest pain can also occur. A number of these side effects are associated with the excipient used, Cremophor EL, a polyoxyethylated castor oil. Allergies to drugs such as cyclosporine, teniposide and drugs containing polyoxyethylated castor oil may indicate increased risk of adverse reactions to paclitaxel. Dexamethasone is given prior to beginning paclitaxel treatment to mitigate some of the side effects. Leuprolide, a GnRH analog may prevent ovarian damage, according to mice studies.
Mechanism of action.
Paclitaxel is one of several cytoskeletal drugs that target tubulin. Paclitaxel-treated cells have defects in mitotic spindle assembly, chromosome segregation, and cell division. Unlike other tubulin-targeting drugs such as colchicine that inhibit microtubule assembly, paclitaxel stabilizes the microtubule polymer and protects it from disassembly. Chromosomes are thus unable to achieve a metaphase spindle configuration. This blocks the progression of mitosis and prolonged activation of the mitotic checkpoint triggers apoptosis or reversion to the G-phase of the cell cycle without cell division.
The ability of paclitaxel to inhibit spindle function is generally attributed to its suppression of microtubule dynamics, but recent studies have demonstrated that suppression of dynamics occurs at concentrations lower than those needed to block mitosis. At the higher therapeutic concentrations, paclitaxel appears to suppress microtubule detachment from centrosomes, a process normally activated during mitosis. Paclitaxel binds to beta-tubulin subunits of microtubules.
Production.
From 1967 to 1993, almost all paclitaxel produced was derived from bark from the Pacific yew, the harvesting of which kills the tree in the process. The processes used were descendants of the original isolation method of Wall and Wani; by 1987, the NCI had contracted Hauser Chemical Research of Boulder, Colorado, to handle bark on the scale needed for Phase II and III trials. While both the size of the wild population of "Taxus brevifola" and the magnitude of the eventual demand for taxol were uncertain, it was clear for many years that an alternative, sustainable source of supply of the natural product would be needed. Initial attempts to broaden its sourcing used needles from the tree, or material from other related "Taxus" species, including cultivated ones, but these attempts were challenged by the relatively low and often highly variable yields obtained. Early in the 1990s, coincident with increased sensitivity to the ecology of the forests of the Pacific Northwest, paclitaxel was successfully extracted on a clinically useful scale from these sources.
Concurrently, synthetic chemists in the US and France had been interested in taxol, beginning in the late 1970s. As noted, by 1992 extensive efforts were underway to accomplish the total synthesis of paclitaxel, efforts motivated by the desire to generate new chemical understanding rather than to achieve practical commercial production. In contrast, the French group of Pierre Potier at the Centre national de la recherche scientifique (CNRS) addressed the matter of overall process yield, showing that it was feasible to isolate relatively large quantities of the compound 10-deacetylbaccatin from yew, "Taxus baccata", which grew on the CNRS campus and whose needles were available in large quantity. By virtue of its structure, 10-deacetylbaccatin was seen as a viable starting material for a short semisynthesis to produce taxol. By 1988 Poitier and collaborators had published a semisynthetic route from needles of "T. baccata" to taxol.
The view of the NCI, however, was even this route was not practical. The group of Robert A. Holton had also pursued a practical semisynthetic production route; by late 1989, Holton's group had developed a semisynthetic route to paclitaxel with twice the yield of the Potier process. Florida State University, where Holton worked, signed a deal with Bristol-Myers Squibb to license their semisynthesis and future patents. In 1992, Holton patented an improved process with an 80% yield, and BMS took the process in-house and started to manufacture paclitaxel in Ireland from 10-deacetylbaccatin isolated from the needles of the European yew. In early 1993, BMS was able to announce that it would cease reliance on Pacific yew bark by the end of 1995, effectively terminating ecological controversy over its use. This announcement also made good their commitment to develop an alternative supply route, made to the NCI in their CRADA application of 1989.
As of 2013, paclitaxel production for BMS is sourced using a semi-synthetic method from "Taxus baccata" (European yew). Another company which worked with BMS until 2012, Phyton Biotech, Inc uses plant cell fermentation (PCF) technology which eliminates the need for yew tree plantation sourcing. The process uses a specific "Taxus" cell line propagated in aqueous medium in large fermentation tanks with the endophytic fungus "Penicillium raistrickii". Paclitaxel is then extracted directly, purified by chromatography and isolated by crystallization. Compared to the semisynthesis, PCF eliminates the need for many hazardous chemicals and saves a considerable amount of energy.
In 1993, taxol was discovered as a natural product in a newly described endophytic fungus living in the yew tree. It has since been reported in a number of other endophytic fungi, including "Nodulisporium sylviforme", "Alternaria taxi", "Cladosporium cladosporioides MD2", "Metarhizium anisopliae", "Aspergillus candidus MD3", "Mucor rouxianus sp.", "Chaetomella raphigera", "Phyllosticta tabernaemontanae", "Phomopsis", "Pestalotiopsis pauciseta", "Phyllosticta citricarpa", "Podocarpus","Fusarium solani", "Pestalotiopsis terminaliae", "Pestalotiopsis breviseta", "Botryodiplodia theobromae Pat.", "Gliocladium sp.", "Alternaria alternata var. monosporus", "Cladosporium cladosporioides", "Nigrospora sp.", "Pestalotiopsis versicolor", and "Taxomyces andreanae". However, there has been contradictory evidence for its production by endophytes, with other studies finding independent production is unlikely.
Biosynthesis.
The core synthetic route is via a terpenoid pathway, parts of which having been successfully transplanted into production strains of E.coli and yeast.
Synthesis.
By 1992, at least thirty academic research teams globally were working to achieve a total synthesis of this natural product, with the synthesis proceeding from simple natural products and other readily available starting materials. This total synthesis effort was motivated primarily by the desire to generate new chemical understanding, rather than with an expectation of the practical commercial production of paclitaxel. The first laboratories to complete the total synthesis from much less complex starting materials were the research groups of Robert A. Holton, who had the first article to be accepted for publication, and of K. C. Nicolaou who had the first article to appear in print (by a week, on 7 February 1994). Though the Holton submission preceded the Nicolaou by a month (21 December 1993 versus 24 January 1994), the near coincidence of the publications arising from each of these massive, multiyear efforts—11-18 authors appearing on each of the February 1994 publications—has led the ending of the race to be termed a "tie" or a "photo finish", though each group has argued that their synthetic strategy and tactics were superior.
Five additional research groups have reported successful total syntheses of paclitaxel: Wender et al. in 1997, and Kuwajima et al. and Mukaiyama et al. in 1998 with further linear syntheses, and Danishefsky et al. in 1996 and Takahashi et al. in 2006 with further convergent syntheses. All strategies aim to prepare a 10-Deacetylbaccatin-type core containing the ABCD ring system, followed generally by last stage addition of the "tail" to the 13-hydroxyl group.
While the "political climate surrounding taxol and "Taxus brevifolia" in the early 1990s… helped bolster link between total synthesis and the [taxol supply problem", and though total synthesis activities were a requisite to explore the structure-activity relationships of taxol via generation of analogs for testing, the total synthesis efforts were never seen "as a serious commercial route" to provide significant quantities of the natural product for medical testing or therapeutic use.
History.
Paclitaxel was discovered as a part of a U.S. National Cancer Institute screening program, by Monroe E. Wall and Mansukh C. Wani at the Research Triangle Institute, Research Triangle Park, North Carolina, in 1967. These scientists isolated the natural product from the bark of the Pacific yew tree, "Taxus brevifolia", determined its structure and named it "taxol", and arranged for its first biological testing. The compound was then developed commercially by Bristol-Myers Squibb (BMS), who had the generic name assigned as "paclitaxel".
Plant screening program.
In 1955, the National Cancer Institute (NCI) in the United States set up the Cancer Chemotherapy National Service Center (CCNSC) to act as a public screening center for anticancer activity in compounds submitted by external institutions and companies. Although the majority of compounds screened were of synthetic origin, one chemist, Jonathan Hartwell, who was employed there from 1958 onwards, had experience with natural product derived compounds, and began a plant screening operation. After some years of informal arrangements, in July 1960, the NCI commissioned USDA botanists to collect samples from about 1000 plant species per year. On 21 August 1962, one of those botanists, Arthur S. Barclay, collected bark from a single Pacific yew tree, "Taxus brevifolia", in a forest north of the town of Packwood, Washington as part of a four-month trip to collect material from over 200 different species. The material was then processed by a number of specialist CCNSC subcontractors, and one of the "Taxus" samples was found to be cytotoxic in a cellular assay on 22 May 1964.
Accordingly, in late 1964 or early 1965, the fractionation and isolation laboratory run by Monroe E. Wall in Research Triangle Park, North Carolina, began work on fresh "Taxus" samples, isolating the active ingredient in September 1966 and announcing their findings at an April 1967 American Chemical Society meeting in Miami Beach. They named the pure compound taxol in June 1967.
Wall and his colleague Wani published their results, including the chemical structure, in 1971.
The NCI continued to commission work to collect more "Taxus" bark and to isolate increasing quantities of taxol. By 1969, 28 kg of crude extract had been isolated from almost 1,200 kg of bark, although this ultimately yielded only 10g of pure material, but for several years, no use was made of the compound by the NCI. In 1975, it was shown to be active in another "in vitro" system; two years later, a new department head reviewed the data and finally recommended taxol be moved on to the next stage in the discovery process. This required increasing quantities of purified taxol, up to 600 g, and in 1977 a further request for 7,000 lbs of bark was made.
In 1978, two NCI researchers published a report showing taxol was mildly effective in leukaemic mice.
In November 1978, taxol was shown to be effective in xenograft studies.
Meanwhile, taxol began to be well known in the cell biology, as well as the cancer community, with a publication in early 1979 by Susan B. Horwitz, a molecular pharmacologist at Albert Einstein College of Medicine, showing taxol had a previously unknown mechanism of action involving the stabilization of microtubules. Together with formulation problems, this increased interest from researchers meant that, by 1980, the NCI envisaged needing to collect 20,000 lbs of bark.
Animal toxicology studies were complete by June 1982, and in November NCI applied for the IND necessary to begin clinical trials in humans.
Early clinical trials, supply and the transfer to BMS.
Phase I clinical trials began in April 1984, and the decision to start Phase II trials was made a year later. These larger trials needed more bark and collection of a further 12,000 pounds was commissioned, which enabled some phase II trials to begin by the end of 1986. But by then it was recognized that the demand for taxol might be substantial and that more than 60,000 pounds of bark might be needed as a minimum. This unprecedentedly large amount brought ecological concerns about the impact on yew populations into focus for the first time, as local politicians and foresters expressed unease at the program.
The first public report from a phase II trial in May 1988 showed an effect in melanoma patients and a remarkable response rate of 30% in patients with refractory ovarian cancer. At this point, Gordon Cragg of the NCI's Natural Product Branch calculated the synthesis of enough taxol to treat all the ovarian cancer and melanoma cases in the US would require the destruction of 360,000 trees annually. For the first time, serious consideration was given to the problem of supply.
Because of the practical and, in particular, the financial scale of the program needed, the NCI decided to seek association with a pharmaceutical company, and in August 1989, it published a Cooperative Research and Development Agreement (CRADA) offering its current stock and supply from current bark stocks, and proprietary access to the data so far collected, to a company willing to commit to providing the funds to collect further raw material, isolate taxol, and fund a large proportion of clinical trials. In the words of Goodman and Welsh, authors of a substantial scholarly book on taxol, "The NCI was thinking, not of collaboration, ... but of a hand-over of taxol (and its problems)".
Although the offer was widely advertised, only four companies responded to the CRADA, including the American firm Bristol-Myers Squibb (BMS),
which was selected as the partner in December 1989. The choice of BMS later became controversial and was the subject of Congressional hearings in 1991 and 1992. While it seems clear the NCI had little choice but to seek a commercial partner, there was also controversy about the terms of the deal, eventually leading to a report by the General Accounting Office in 2003, which concluded the NIH had failed to ensure value for money. In related CRADAs with the USDA and Department of the Interior, Bristol-Myers Squibb was given exclusive first refusal on all Federal supplies of "Taxus brevifolia".
This exclusive contract lead to some criticism for giving BMS a "cancer monopoly".
Eighteen months after the CRADA, BMS filed a new drug application (NDA), which was given FDA approval at the very end of 1992.
Although there was no patent on the compound, the provisions of the Waxman-Hatch Act gave Bristol-Myers Squibb five years exclusive marketing rights.
In 1990, BMS applied to trademark the name taxol as "Taxol(R)". This was controversially approved in 1992. At the same time, paclitaxel replaced taxol as the generic (INN) name of the compound. Critics, including the journal "Nature", argued the name taxol had been used for more than two decades and in more than 600 scientific articles and suggested the trademark should not have been awarded and the BMS should renounce its rights to it. BMS argued changing the name would cause confusion among oncologists and possibly endanger the health of patients. BMS has continued to defend its rights to the name in the courts.
BMS has also been criticized for misrepresentation by Goodman and Walsh, who quote from a company report saying "It was not until 1971 that ... testing ... enabled the isolation of paclitaxel, initially described as 'compound 17". This quote is, strictly speaking, accurate: the objection seems to be that this misleadingly neglects to explain that it was the scientist doing the isolation who named the compound taxol and it was not referred to in any other way for more than twenty years.
Annual sales peaked in 2000, reaching US$1.6 billion; paclitaxel is now available in generic form.
Nomenclature.
The nomenclature for paclitaxel is structured on a tetracyclic 17-carbon (heptadecane) skeleton. There are a total of 11 stereocenters. The active stereoisomer is (−)-paclitaxel (shown here).
Cost.
The cost to the NHS per patient in early breast cancer, assuming four cycles of treatment, is about £4000 (approx. $6000).
Research.
A recent study suggested that caffeine may inhibit paclitaxel-induced apoptosis in colorectal cancer cells.
Aside from its direct clinical use, paclitaxel is used extensively in biological and biomedical research as a microtubule stabilizer. In general, in vitro assays involving microtubules, such as motility assays, rely on paclitaxel to maintain microtubule integrity in the absence of the various nucleating factors and other stabilizing elements found in the cell. For example, it is used for in vitro tests of drugs that aim to alter the behavior of microtubule motor proteins, or for studies of mutant motor proteins. Moreover, Paclitaxel has been used in vitro to inhibit insulin fibrillation; in a molar ratio of 10:1 (insulin:paclitaxel), it hindered insulin fibrillation near 70%. Iso-thermal titration calorimetry (ITC) findings indicated a spontaneous tendency of paclitaxel to interact with insulin through hydrogen bonds and van der Waal’s forces. Paclitaxel is sometimes used for in vivo studies as well; it can be fed to test organisms, such as fruit flies, or injected into individual cells, to inhibit microtubule disassembly or to increase the number of microtubules in the cell. Paclitaxel induces remyelination in a demyelinating mouse in vivo and inhibits hPAD2 in vitro though its methyl ester side chain. Angiotech Pharmaceuticals Inc. began phase II clinical trials in 1999 as a multiple sclerosis treatment but in 2002, reported that the results showed no statistical significance.
In 2016 "in vitro" multi-drug resistant mouse tumor cells were treated with paclitaxel encased in exosomes. Doses 98% less than common dosing had the same effect. Also, dye-marked exosomes were able to mark tumor cells, potentially aiding in diagnosis.

</doc>
<doc id="36797" url="https://en.wikipedia.org/wiki?curid=36797" title="Occam's razor">
Occam's razor

Occam's razor (also written as Ockham's razor, and "lex parsimoniae" in Latin, which means law of parsimony) is a problem-solving principle attributed to William of Ockham (c. 1287–1347), who was an English Franciscan friar and scholastic philosopher and theologian. The principle can be interpreted as stating "Among competing hypotheses, the one with the fewest assumptions should be selected."
In science, Occam's razor is used as a heuristic technique (discovery tool) to guide scientists in the development of theoretical models, rather than as an arbiter between published models. In the scientific method, Occam's razor is not considered an irrefutable principle of logic or a scientific result; the preference for simplicity in the scientific method is based on the falsifiability criterion. For each accepted explanation of a phenomenon, there may be an extremely large, perhaps even incomprehensible, number of possible and more complex alternatives, because one can always burden failing explanations with ad hoc hypotheses to prevent them from being falsified; therefore, simpler theories are preferable to more complex ones because they are more testable.
History.
The term "Occam's razor" first appeared in 1852 in the works of Sir William Hamilton, 9th Baronet (1788–1856), centuries after William of Ockham's death in 1347. Ockham did not invent this "razor"—its association with him may be due to the frequency and effectiveness with which he used it (Ariew 1976). Ockham stated the principle in various ways, but the most popular version, "Entities must not be multiplied beyond necessity" "(Non sunt multiplicanda entia sine necessitate)" was formulated by the Irish Franciscan philosopher John Punch in his 1639 commentary on the works of Duns Scotus.
Formulations before Ockham.
The oldest and very clear equivalent of Occam's razor is the one of Pythagoras and the Pythagoreans two millennia before Occam, as Proclus very clearly describes. The Pythagoreans have the principle that we have to make the simplest suppositions as Pythagoras ordered them to do when they describe what is necessary to describe: "τῶν μὲν Πυθαγορείων ... παρακέλευσμα ἦν ... δι' ἐλαχίστων καὶ ἁπλουστάτων ὑποθέσεων ἐπειδὴ δὲ καὶ τοῖς κλεινοῖς Πυθαγορείοις" και "δεῖν γὰρ ἐπ' ἐκείνων καὶ αὐτὸν παρακελεύεσθαι τὸν Πυθαγόραν ζητεῖν ἐξ ἐλαχίστων καὶ ἁπλουστάτων ὑποθέσεων δεικνύναι τὰ ζητούμενα·" 
The origins of what has come to be known as Occam's razor are traceable to the works of earlier philosophers such as John Duns Scotus (1265–1308), Robert Grosseteste (1175–1253), Maimonides (Moses ben-Maimon, 1138–1204), and even Aristotle (384–322 BC). Aristotle writes in his "Posterior Analytics", "We may assume the superiority "ceteris paribus" things being equal of the demonstration which derives from fewer postulates or hypotheses." Ptolemy (c. AD 90 – c. AD 168) stated, "We consider it a good principle to explain the phenomena by the simplest hypothesis possible."
Phrases such as "It is vain to do with more what can be done with fewer" and "A plurality is not to be posited without necessity" were commonplace in 13th-century scholastic writing. Robert Grosseteste, in "Commentary on" [Aristotle's] "the Posterior Analytics Books" ("Commentarius in Posteriorum Analyticorum Libros") (c. 1217–1220), declares: "That is better and more valuable which requires fewer, other circumstances being equal... For if one thing were demonstrated from many and another thing from fewer equally known premises, clearly that is better which is from fewer because it makes us know quickly, just as a universal demonstration is better than particular because it produces knowledge from fewer premises. Similarly in natural science, in moral science, and in metaphysics the best is that which needs no premises and the better that which needs the fewer, other circumstances being equal." The "Summa Theologica" of Thomas Aquinas (1225–1274) states that "it is superfluous to suppose that what can be accounted for by a few principles has been produced by many". Aquinas uses this principle to construct an objection to God's existence, an objection that he in turn answers and refutes generally (cf. "quinque viae"), and specifically, through an argument based on causality. Hence, Aquinas acknowledges the principle that today is known as Occam's razor, but prefers causal explanations to other simple explanations (cf. also Correlation does not imply causation).
The Indian Hindu philosopher Madhva (1238–1317) in verse 400 of his "Vishnu-Tattva-Nirnaya" says: ""dvidhAkalpane kalpanAgauravamiti"" ("To make two suppositions when one is enough is to err by way of excessive supposition").
Ockham.
William of Ockham ("circa" 1287–1347) was an English Franciscan friar and theologian, an influential medieval philosopher and a nominalist. His popular fame as a great logician rests chiefly on the maxim attributed to him and known as Ockham's razor. The term "razor" refers to distinguishing between two hypotheses either by "shaving away" unnecessary assumptions or cutting apart two similar conclusions.
While it has been claimed that Ockham's razor is not found in any of his writings, one can cite statements such as "" must never be posited without necessity, which occurs in his theological work on the 'Sentences of Peter Lombard' ("Quaestiones et decisiones in quattuor libros Sententiarum Petri Lombardi" (ed. Lugd., 1495), i, dist. 27, qu. 2, K).
Nevertheless, the precise words sometimes attributed to Ockham, "entia non sunt multiplicanda praeter necessitatem" (entities must not be multiplied beyond necessity), are absent in his extant works; this particular phrasing comes from John Punch, who described the principle as a "common axiom" ("axioma vulgare") of the Scholastics. Ockham's contribution seems to be to restrict the operation of this principle in matters pertaining to miracles and God's power: so, in the Eucharist, a plurality of miracles is possible, simply because it pleases God.
This principle is sometimes phrased as "pluralitas non est ponenda sine necessitate" ("plurality should not be posited without necessity"). In his "Summa Totius Logicae", i. 12, Ockham cites the principle of economy, "Frustra fit per plura quod potest fieri per pauciora" ("It is futile to do with more things that which can be done with fewer"). (Thorburn, 1918, pp. 352–53; Kneale and Kneale, 1962, p. 243.)
Later formulations.
To quote Isaac Newton, "We are to admit no more causes of natural things than such as are both true and sufficient to explain their appearances. Therefore, to the same natural effects we must, as far as possible, assign the same causes."
Bertrand Russell offers a particular version of Occam's razor: "Whenever possible, substitute constructions out of known entities for inferences to unknown entities."
Around 1960, Ray Solomonoff founded the theory of universal inductive inference, the theory of prediction based on observations; for example, predicting the next symbol based upon a given series of symbols. The only assumption is that the environment follows some unknown but computable probability distribution. This theory is a mathematical formalization of Occam's razor.
Another technical approach to Occam's razor is ontological parsimony.
The widespread layman's formulation that "the simplest explanation is usually the correct one" appears to have been derived from Occam's razor.
Justifications.
Beginning in the 20th century, epistemological justifications based on induction, logic, pragmatism, and especially probability theory have become more popular among philosophers.
Aesthetic.
Prior to the 20th century, it was a commonly held belief that nature itself was simple and that simpler hypotheses about nature were thus more likely to be true. This notion was deeply rooted in the aesthetic value that simplicity holds for human thought and the justifications presented for it often drew from theology. Thomas Aquinas made this argument in the 13th century, writing, "If a thing can be done adequately by means of one, it is superfluous to do it by means of several; for we observe that nature does not employ two instruments one suffices."
Empirical.
Occam's razor has gained strong empirical support in helping to converge on better theories (see "Applications" section below for some examples).
In the related concept of overfitting, excessively complex models are affected by statistical noise (a problem also known as the bias-variance trade-off), whereas simpler models may capture the underlying structure better and may thus have better predictive performance. It is, however, often difficult to deduce which part of the data is noise (cf. model selection, test set, minimum description length, Bayesian inference, etc.).
Testing the razor.
The razor's statement that "other things being equal, simpler explanations are generally better than more complex ones" is amenable to empirical testing. Another interpretation of the razor's statement would be that "simpler hypotheses (not conclusions, i.e. explanations) are generally better than the complex ones". The procedure to test the former interpretation would compare the track records of simple and comparatively complex explanations. If one accepts the first interpretation, the validity of Occam's razor as a tool would then have to be rejected if the more complex explanations were more often correct than the less complex ones (while the converse would lend support to its use). If the latter interpretation is accepted, the validity of Occam's razor as a tool could possibly be accepted if the simpler hypotheses led to correct conclusions more often than not.
In the history of competing hypotheses, the simpler hypotheses have led to mathematically rigorous and empirically verifiable theories. In the history of competing explanations, this is not the case—at least not generally. Some increases in complexity are sometimes necessary. So there remains a justified general bias toward the simpler of two competing explanations. To understand why, consider that for each accepted explanation of a phenomenon, there is always an infinite number of possible, more complex, and ultimately incorrect, alternatives. This is so because one can always burden failing explanations with ad hoc hypothesis. Ad hoc hypotheses are justifications that prevent theories from being falsified. Even other empirical criteria, such as consilience, can never truly eliminate such explanations as competition. Each true explanation, then, may have had many alternatives that were simpler and false, but also an infinite number of alternatives that were more complex and false. But if an alternate ad hoc hypothesis were indeed justifiable, its implicit conclusions would be empirically verifiable. On a commonly accepted repeatability principle, these alternate theories have never been observed and continue to escape observation. In addition, one does not say an explanation is true if it has not withstood this principle.
Put another way, any new, and even more complex, theory can still possibly be true. For example, if an individual makes supernatural claims that leprechauns were responsible for breaking a vase, the simpler explanation would be that he is mistaken, but ongoing ad hoc justifications (e.g. "... and that's not me on the film; they tampered with that, too") successfully prevent outright falsification. This endless supply of elaborate competing explanations, called saving hypotheses, cannot be ruled out—except by using Occam's razor. A study of the predictive validity of Occam’s razor found 32 published papers that included 97 comparisons of forecasts from simple and complex forecasting methods. None of the papers provided a balance of evidence that complexity of method improved forecast accuracy. In the 25 papers with quantitative comparisons, complexity increased forecast errors by an average of 27 percent 
Practical considerations and pragmatism.
The common form of the razor, used to distinguish between equally explanatory hypotheses, may be supported by the practical fact that simpler theories are easier to understand.
Some argue that Occam's razor is not an inference-driven model, but a heuristic maxim for choosing "among" other models and instead" underlies" induction.
Alternatively, if one wants to have reasonable discussion one may be practically forced to accept Occam's razor in the same way one is simply forced to accept the laws of thought and inductive reasoning (given the problem of induction). Philosopher Elliott Sober states that not even reason itself can be justified on any reasonable grounds, and that we must start with first principles of some kind (otherwise an infinite regress occurs).
The pragmatist may go on, as David Hume did on the topic of induction, that there is no satisfying alternative to granting this premise. Though one may "claim" that Occam's razor is invalid as a premise that helps regulate theories, putting this doubt into practice would mean doubting whether every step forward will result in locomotion or a nuclear explosion. In other words: "What's the alternative?"
Mathematical.
One justification of Occam's razor is a direct result of basic probability theory. By definition, all assumptions introduce possibilities for error; if an assumption does not improve the accuracy of a theory, its only effect is to increase the probability that the overall theory is wrong.
There have also been other attempts to derive Occam's razor from probability theory, including notable attempts made by Harold Jeffreys and E. T. Jaynes. The probabilistic (Bayesian) basis for Occam's razor is elaborated by David J. C. MacKay in chapter 28 of his book "Information Theory, Inference, and Learning Algorithms", where he emphasises that a prior bias in favour of simpler models is not required.
William H. Jefferys (no relation to Harold Jeffreys) and James O. Berger (1991) generalize and quantify the original formulation's "assumptions" concept as the degree to which a proposition is unnecessarily accommodating to possible observable data. They state, "A hypothesis with fewer adjustable parameters will automatically have an enhanced posterior probability, due to the fact that the predictions it makes are sharp." The model they propose balances the precision of a theory's predictions against their sharpness—preferring theories that sharply make correct predictions over theories that accommodate a wide range of other possible results. This, again, reflects the mathematical relationship between key concepts in Bayesian inference (namely marginal probability, conditional probability, and posterior probability).
Other philosophers.
Karl Popper.
Karl Popper argues that a preference for simple theories need not appeal to practical or aesthetic considerations. Our preference for simplicity may be justified by its falsifiability criterion: we prefer simpler theories to more complex ones "because their empirical content is greater; and because they are better testable" (Popper 1992). The idea here is that a simple theory applies to more cases than a more complex one, and is thus more easily falsifiable. This is again comparing a simple theory to a more complex theory where both explain the data equally well.
Elliott Sober.
The philosopher of science Elliott Sober once argued along the same lines as Popper, tying simplicity with "informativeness": The simplest theory is the more informative, in the sense that it requires less information to a question. He has since rejected this account of simplicity, purportedly because it fails to provide an epistemic justification for simplicity. He now believes that simplicity considerations (and considerations of parsimony in particular) do not count unless they reflect something more fundamental. Philosophers, he suggests, may have made the error of hypostatizing simplicity (i.e., endowed it with a "sui generis" existence), when it has meaning only when embedded in a specific context (Sober 1992). If we fail to justify simplicity considerations on the basis of the context in which we use them, we may have no non-circular justification: "Just as the question 'why be rational?' may have no non-circular answer, the same may be true of the question 'why should simplicity be considered in evaluating the plausibility of hypotheses?'"
Richard Swinburne.
Richard Swinburne argues for simplicity on logical grounds:
According to Swinburne, since our choice of theory cannot be determined by data (see Underdetermination and Quine–Duhem thesis), we must rely on some criterion to determine which theory to use. Since it is absurd to have no logical method for settling on one hypothesis amongst an infinite number of equally data-compliant hypotheses, we should choose the simplest theory: "Either science is irrational the way it judges theories and predictions probable or the principle of simplicity is a fundamental synthetic a priori truth." (Swinburne 1997).
Ludwig Wittgenstein.
From the "Tractatus Logico-Philosophicus":
and on the related concept of "simplicity":
Applications.
Science and the scientific method.
In science, Occam's razor is used as a heuristic to guide scientists in developing theoretical models rather than as an arbiter between published models. In physics, parsimony was an important heuristic in Albert Einstein's formulation of special relativity, in the development and application of the principle of least action by Pierre Louis Maupertuis and Leonhard Euler, and in the development of quantum mechanics by Max Planck, Werner Heisenberg and Louis de Broglie.
In chemistry, Occam's razor is often an important heuristic when developing a model of a reaction mechanism. Although it is useful as a heuristic in developing models of reaction mechanisms, it has been shown to fail as a criterion for selecting among some selected published models. In this context, Einstein himself expressed caution when he formulated Einstein's Constraint: "It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience". An often-quoted version of this constraint (which cannot be verified as posited by Einstein himself) says "Everything should be kept as simple as possible, but no simpler."
In the scientific method, parsimony is an epistemological, metaphysical or heuristic preference, not an irrefutable principle of logic or a scientific result. As a logical principle, Occam's razor would demand that scientists accept the simplest possible theoretical explanation for existing data. However, science has shown repeatedly that future data often support more complex theories than do existing data. Science prefers the simplest explanation that is consistent with the data available at a given time, but the simplest explanation may be ruled out as new data become available. That is, science is open to the possibility that future experiments might support more complex theories than demanded by current data and is more interested in designing experiments to discriminate between competing theories than favoring one theory over another based merely on philosophical principles.
When scientists use the idea of parsimony, it has meaning only in a very specific context of inquiry. Several background assumptions are required for parsimony to connect with plausibility in a particular research problem. The reasonableness of parsimony in one research context may have nothing to do with its reasonableness in another. It is a mistake to think that there is a single global principle that spans diverse subject matter.
It has been suggested that Occam's razor is a widely accepted example of extraevidential consideration, even though it is entirely a metaphysical assumption. There is little empirical evidence that the world is actually simple or that simple accounts are more likely to be true than complex ones.
Most of the time, Occam's razor is a conservative tool, cutting out crazy, complicated constructions and assuring that hypotheses are grounded in the science of the day, thus yielding "normal" science: models of explanation and prediction. There are, however, notable exceptions where Occam's razor turns a conservative scientist into a reluctant revolutionary. For example, Max Planck interpolated between the Wien and Jeans radiation laws and used Occam's razor logic to formulate the quantum hypothesis, even resisting that hypothesis as it became more obvious that it was correct.
Appeals to simplicity were used to argue against the phenomena of meteorites, ball lightning, continental drift, and reverse transcriptase. One can argue for atomic building blocks for matter, because it provides a simpler explanation for the observed reversibility of both mixing and chemical reactions as simple separation and rearrangements of atomic building blocks. At the time, however, the atomic theory was considered more complex because it implied the existence of invisible particles that had not been directly detected. Ernst Mach and the logical positivists rejected John Dalton's atomic theory until the reality of atoms was more evident in Brownian motion, as shown by Albert Einstein.
In the same way, postulating the aether is more complex than transmission of light through a vacuum. At the time, however, all known waves propagated through a physical medium, and it seemed simpler to postulate the existence of a medium than to theorize about wave propagation without a medium. Likewise, Newton's idea of light particles seemed simpler than Christiaan Huygens's idea of waves, so many favored it. In this case, as it turned out, neither the wave—nor the particle—explanation alone suffices, as light behaves like waves and like particles.
Three axioms presupposed by the scientific method are realism (the existence of objective reality), the existence of natural laws, and the constancy of natural law. Rather than depend on provability of these axioms, science depends on the fact that they have not been objectively falsified. Occam's razor and parsimony support, but do not prove, these axioms of science. The general principle of science is that theories (or models) of natural law must be consistent with repeatable experimental observations. This ultimate arbiter (selection criterion) rests upon the axioms mentioned above.
There are examples where Occam's razor would have favored the wrong theory given the available data. Simplicity principles are useful philosophical preferences for choosing a more likely theory from among several possibilities that are all consistent with available data. A single instance of Occam's razor favoring a wrong theory falsifies the razor as a general principle. Michael Lee and others provide cases in which a parsimonious approach does not guarantee a correct conclusion and, if based on incorrect working hypotheses or interpretations of incomplete data, may even strongly support a false conclusion. Lee states, "When parsimony ceases to be a guideline and is instead elevated to an "ex cathedra" pronouncement, parsimony analysis ceases to be science."
If multiple models of natural law make exactly the same testable predictions, they are equivalent and there is no need for parsimony to choose a preferred one. For example, Newtonian, Hamiltonian and Lagrangian classical mechanics are equivalent. Physicists have no interest in using Occam's razor to say the other two are wrong. Likewise, there is no demand for simplicity principles to arbitrate between wave and matrix formulations of quantum mechanics. Science often does not demand arbitration or selection criteria between models that make the same testable predictions.
Biology.
Biologists or philosophers of biology use Occam's razor in either of two contexts both in evolutionary biology: the units of selection controversy and systematics. George C. Williams in his book "Adaptation and Natural Selection" (1966) argues that the best way to explain altruism among animals is based on low-level (i.e., individual) selection as opposed to high-level group selection. Altruism is defined by some evolutionary biologists (e.g., R. Alexander, 1987; W. D. Hamilton, 1964) as behavior that is beneficial to others (or to the group) at a cost to the individual, and many posit individual selection as the mechanism that explains altruism solely in terms of the behaviors of individual organisms acting in their own self-interest (or in the interest of their genes, via kin selection). Williams was arguing against the perspective of others who propose selection at the level of the group as an evolutionary mechanism that selects for altruistic traits (e.g., D. S. Wilson & E. O. Wilson, 2007). The basis for Williams' contention is that of the two, individual selection is the more parsimonious theory. In doing so he is invoking a variant of Occam's razor known as Morgan's Canon: "In no case is an animal activity to be interpreted in terms of higher psychological processes, if it can be fairly interpreted in terms of processes which stand lower in the scale of psychological evolution and development." (Morgan 1903).
However, more recent biological analyses, such as Richard Dawkins' "The Selfish Gene", have contended that Morgan's Canon is not the simplest and most basic explanation. Dawkins argues the way evolution works is that the genes propagated in most copies end up determining the development of that particular species, i.e., natural selection turns out to select specific genes, and this is really the fundamental underlying principle, that automatically gives individual and group selection as emergent features of evolution.
Zoology provides an example. Muskoxen, when threatened by wolves, form a circle with the males on the outside and the females and young on the inside. This is an example of a behavior by the males that seems to be altruistic. The behavior is disadvantageous to them individually but beneficial to the group as a whole and was thus seen by some to support the group selection theory.
However, a much better explanation immediately offers itself once one considers that natural selection works on genes. If the male musk ox runs off leaving his offspring to the wolves, his genes do not propagate. If, however, he fights, his genes may live on in his offspring. Thus, the "stay-and-fight" gene prevails. This is an example of kin selection. An underlying general principle thus offers a much simpler explanation, without retreating to special principles as group selection.
Systematics is the branch of biology that attempts to establish genealogical relationships among organisms. It is also concerned with their classification. There are three primary camps in systematics: cladists, pheneticists, and evolutionary taxonomists. The cladists hold that genealogy alone should determine classification and pheneticists contend that similarity over propinquity of descent is the determining criterion while evolutionary taxonomists say that both genealogy and similarity count in classification.
It is among the cladists that Occam's razor is to be found, although their term for it is "cladistic parsimony". Cladistic parsimony (or maximum parsimony) is a method of phylogenetic inference in the construction of types of phylogenetic trees (more specifically, cladograms). Cladograms are branching, tree-like structures used to represent lines of descent based on one or more evolutionary changes. Cladistic parsimony is used to support the hypotheses that require the fewest evolutionary changes. For some types of tree, it consistently produces the wrong results, regardless of how much data is collected (this is called long branch attraction). For a full treatment of cladistic parsimony, see Elliott Sober's "Reconstructing the Past: Parsimony, Evolution, and Inference" (1988). For a discussion of both uses of Occam's razor in biology, see Sober's article "Let's Razor Ockham's Razor" (1990).
Other methods for inferring evolutionary relationships use parsimony in a more traditional way. Likelihood methods for phylogeny use parsimony as they do for all likelihood tests, with hypotheses requiring few differing parameters (i.e., numbers of different rates of character change or different frequencies of character state transitions) being treated as null hypotheses relative to hypotheses requiring many differing parameters. Thus, complex hypotheses must predict data much better than do simple hypotheses before researchers reject the simple hypotheses. Recent advances employ information theory, a close cousin of likelihood, which uses Occam's razor in the same way.
Francis Crick has commented on potential limitations of Occam's razor in biology. He advances the argument that because biological systems are the products of (an ongoing) natural selection, the mechanisms are not necessarily optimal in an obvious sense. He cautions: "While Ockham's razor is a useful tool in the physical sciences, it can be a very dangerous implement in biology. It is thus very rash to use simplicity and elegance as a guide in biological research."
In biogeography, parsimony is used to infer ancient migrations of species or populations by observing the geographic distribution and relationships of existing organisms. Given the phylogenetic tree, ancestral migrations are inferred to be those that require the minimum amount of total movement.
Medicine.
When discussing Occam's razor in contemporary medicine, doctors and philosophers of medicine speak of diagnostic parsimony. Diagnostic parsimony advocates that when diagnosing a given injury, ailment, illness, or disease a doctor should strive to look for the fewest possible causes that account for all the symptoms. This philosophy is one of several demonstrated in the popular medical adage "when you hear hoofbeats behind you, think horses, not zebras". While diagnostic parsimony might often be beneficial, credence should also be given to the counter-argument modernly known as Hickam's dictum, which succinctly states that, "Patients can have as many diseases as they damn well please." It is often statistically more likely that a patient has several common diseases rather than a single rarer disease that explains myriad symptoms. Also, independently of statistical likelihood, some patients do in fact turn out to have multiple diseases, which by common sense nullifies the approach of insisting to explain any given collection of symptoms with one disease.
These misgivings emerge from simple probability theory—which is already taken into account in many modern variations of the razor—and from the fact that the loss function is much greater in medicine than in most of general science. Because misdiagnosis can result in the loss of a person's health and potentially life, it is considered better to test and pursue all reasonable theories even if there is some theory that appears the most likely.
Diagnostic parsimony and the counterbalance it finds in Hickam's dictum have very important implications in medical practice. Any set of symptoms could be indicative of a range of possible diseases and disease combinations; though at no point is a diagnosis rejected or accepted just on the basis of one disease appearing more likely than another, the continuous flow of hypothesis formulation, testing and modification benefits greatly from estimates regarding which diseases (or sets of diseases) are relatively more likely responsible for a set of symptoms, given the patient's environment, habits, medical history, and so on. For example, if a hypothetical patient's immediately apparent symptoms include fatigue and cirrhosis and they test negative for hepatitis C, their doctor might formulate a working hypothesis that the cirrhosis was caused by their drinking problem, and then seek symptoms and perform tests to formulate and rule out hypotheses as to what has been causing the fatigue; but if the doctor were to further discover that the patient's breath inexplicably smells of garlic and they are suffering from pulmonary edema, they might decide to test for the relatively rare condition of selenium poisoning.
Religion.
In the philosophy of religion, Occam's razor is sometimes applied to the existence of God. William of Ockham himself was a Christian. He believed in God, and in the authority of Scripture; he writes that "nothing ought to be posited without a reason given, unless it is self-evident (literally, known through itself) or known by experience or proved by the authority of Sacred Scripture." Ockham believed that an explanation has no sufficient basis in reality when it does not harmonize with reason, experience, or the Bible. However, unlike many theologians of his time, Ockham did not believe God could be logically proven with arguments. To Ockham, science was a matter of discovery, but theology was a matter of revelation and faith. He states: "only faith gives us access to theological truths. The ways of God are not open to reason, for God has freely chosen to create a world and establish a way of salvation within it apart from any necessary laws that human logic or rationality can uncover."
St. Thomas Aquinas, in the "Summa Theologica", uses a formulation of Occam's razor to construct an objection to the idea that God exists, which he refutes directly with a counterargument:
Further, it is superfluous to suppose that what can be accounted for by a few principles has been produced by many. But it seems that everything we see in the world can be accounted for by other principles, supposing God did not exist. For all natural things can be reduced to one principle which is nature; and all voluntary things can be reduced to one principle which is human reason, or will. Therefore there is no need to suppose God's existence.
In turn, Aquinas answers this with the "quinque viae", and addresses the particular objection above with the following answer:
Since nature works for a determinate end under the direction of a higher agent, whatever is done by nature must needs be traced back to God, as to its first cause. So also whatever is done voluntarily must also be traced back to some higher cause other than human reason or will, since these can change or fail; for all things that are changeable and capable of defect must be traced back to an immovable and self-necessary first principle, as was shown in the body of the Article.
Rather than argue for the necessity of a god, some theists base their belief upon grounds independent of, or prior to, reason, making Occam's razor irrelevant. This was the stance of Søren Kierkegaard, who viewed belief in God as a leap of faith that sometimes directly opposed reason. This is also the doctrine of Gordon Clark's presuppositional apologetics, with the exception that Clark never thought the leap of faith was contrary to reason (see also Fideism).
Various arguments in favor of God establish God as a useful or even necessary assumption. Contrastingly some atheists hold firmly to the belief that assuming the existence of God introduces unnecessary complexity (Schmitt 2005, e.g., the Ultimate Boeing 747 gambit). Taking a nuanced position, philosopher Del Ratzsch suggests that the application of the razor to God may not be so simple, least of all when we are comparing that hypothesis with theories postulating multiple invisible universes.
Another application of the principle is to be found in the work of George Berkeley (1685–1753). Berkeley was an idealist who believed that all of reality could be explained in terms of the mind alone. He invoked Occam's razor against materialism, stating that matter was not required by his metaphysic and was thus eliminable. One potential problem with this belief is that it's possible, given Berkeley's position, to find solipsism itself more in line with the razor than a God-mediated world beyond a single thinker.
Occam's razor may also be recognized in the apocryphal story about an exchange between Pierre-Simon Laplace and Napoleon. It is said that in praising Laplace for one of his recent publications, the emperor asked how it was that the name of God, which featured so frequently in the writings of Lagrange, appeared nowhere in Laplace's. At that, he is said to have replied, "It's because I had no need of that hypothesis." Though some point to this story as illustrating Laplace's atheism, more careful consideration suggests that he may instead have intended merely to illustrate the power of methodological naturalism, or even simply that the fewer logical premises one assumes, the stronger is one's conclusion.
In his article "Sensations and Brain Processes" (1959), J. J. C. Smart invoked Occam's razor with the aim to justify his preference of the mind-brain identity theory over spirit-body dualism. Dualists state that there are two kinds of substances in the universe: physical (including the body) and spiritual, which is non-physical. In contrast, identity theorists state that everything is physical, including consciousness, and that there is nothing nonphysical. Though it is impossible to appreciate the spiritual when limiting oneself to the physical, Smart maintained that identity theory explains all phenomena by assuming only a physical reality. Subsequently, Smart has been severely criticized for his use (or misuse) of Occam's razor and ultimately retracted his advocacy of it in this context. Paul Churchland (1984) states that by itself Occam's razor is inconclusive regarding duality. In a similar way, Dale Jacquette (1994) stated that Occam's razor has been used in attempts to justify eliminativism and reductionism in the philosophy of mind. Eliminativism is the thesis that the ontology of folk psychology including such entities as "pain", "joy", "desire", "fear", etc., are eliminable in favor of an ontology of a completed neuroscience.
Penal ethics.
In penal theory and the philosophy of punishment, parsimony refers specifically to taking care in the distribution of punishment in order to avoid excessive punishment. In the utilitarian approach to the philosophy of punishment, Jeremy Bentham's "parsimony principle" states that any punishment greater than is required to achieve its end is unjust. The concept is related but not identical to the legal concept of proportionality. Parsimony is a key consideration of the modern restorative justice, and is a component of utilitarian approaches to punishment, as well as the prison abolition movement. Bentham believed that true parsimony would require punishment to be individualised to take account of the sensibility of the individual—an individual more sensitive to punishment should be given a proportionately lesser one, since otherwise needless pain would be inflicted. Later utilitarian writers have tended to abandon this idea, in large part due to the impracticality of determining each alleged criminal's relative sensitivity to specific punishments.
Probability theory and statistics.
Marcus Hutter's universal artificial intelligence builds upon Solomonoff's mathematical formalization of the razor to calculate the expected value of an action.
There are various papers in scholarly journals deriving formal versions of Occam's razor from probability theory, applying it in statistical inference, and using it to come up with criteria for penalizing complexity in statistical inference. Papers have suggested a connection between Occam's razor and Kolmogorov complexity.
One of the problems with the original formulation of the razor is that it only applies to models with the same explanatory power (i.e., it only tells us to prefer the simplest of equally good models). A more general form of the razor can be derived from Bayesian model comparison, which is based on Bayes factors and can be used to compare models that don't fit the observations equally well. These methods can sometimes optimally balance the complexity and power of a model. Generally, the exact Occam factor is intractable, but approximations such as Akaike information criterion, Bayesian information criterion, Variational Bayesian methods, false discovery rate, and Laplace's method are used. Many artificial intelligence researchers are now employing such techniques, for instance through work on Occam Learning.
Statistical versions of Occam's razor have a more rigorous formulation than what philosophical discussions produce. In particular, they must have a specific definition of the term "simplicity", and that definition can vary. For example, in the Kolmogorov–Chaitin minimum description length approach, the subject must pick a Turing machine whose operations describe the basic operations "believed" to represent "simplicity" by the subject. However, one could always choose a Turing machine with a simple operation that happened to construct one's entire theory and would hence score highly under the razor. This has led to two opposing camps: one that believes Occam's razor is objective, and one that believes it is subjective.
Objective razor.
The minimum instruction set of a universal Turing machine requires approximately the same length description across different formulations, and is small compared to the Kolmogorov complexity of most practical theories. Marcus Hutter has used this consistency to define a "natural" Turing machine of small size as the proper basis for excluding arbitrarily complex instruction sets in the formulation of razors. Describing the program for the universal program as the "hypothesis", and the representation of the evidence as program data, it has been formally proven under Zermelo–Fraenkel set theory that "the sum of the log universal probability of the model plus the log of the probability of the data given the model should be minimized." Interpreting this as minimising the total length of a two-part message encoding model followed by data given model gives us the minimum message length (MML) principle.
One possible conclusion from mixing the concepts of Kolmogorov complexity and Occam's razor is that an ideal data compressor would also be a scientific explanation/formulation generator. Some attempts have been made to re-derive known laws from considerations of simplicity or compressibility.
According to Jürgen Schmidhuber, the appropriate mathematical theory of Occam's razor already exists, namely, Solomonoff's theory of optimal inductive inference and its extensions. See discussions in David L. Dowe's "Foreword re C. S. Wallace" for the subtle distinctions between the algorithmic probability work of Solomonoff and the MML work of Chris Wallace, and see Dowe's "MML, hybrid Bayesian network graphical models, statistical consistency, invariance and uniqueness" both for such discussions and for (in section 4) discussions of MML and Occam's razor. For a specific example of MML as Occam's razor in the problem of decision tree induction, see Dowe and Needham's "Message Length as an Effective Ockham's Razor in Decision Tree Induction".
Controversial aspects of the razor.
Occam's razor is not an embargo against the positing of any kind of entity, or a recommendation of the simplest theory come what may. Occam's razor is used to adjudicate between theories that have already passed "theoretical scrutiny" tests and are equally well-supported by evidence. Furthermore, it may be used to prioritize empirical testing between two equally plausible but unequally testable hypotheses; thereby minimizing costs and wastes while decreasing chances of falsification of the simpler-to-test hypothesis.
Another contentious aspect of the razor is that a theory can become more complex in terms of its structure (or syntax), while its ontology (or semantics) becomes simpler, or vice versa. Quine, in a discussion on definition, referred to these two perspectives as "economy of practical expression" and "economy in grammar and vocabulary", respectively. The theory of relativity is often given as an example of the proliferation of complex words to describe a simple concept.
Galileo Galilei lampooned the "misuse" of Occam's razor in his "Dialogue". The principle is represented in the dialogue by Simplicio. The telling point that Galileo presented ironically was that if one really wanted to start from a small number of entities, one could always consider the letters of the alphabet as the fundamental entities, since one could construct the whole of human knowledge out of them.
Anti-razors.
Occam's razor has met some opposition from people who have considered it too extreme or rash. Walter Chatton (c. 1290–1343) was a contemporary of William of Ockham (c. 1287–1347) who took exception to Occam's razor and Ockham's use of it. In response he devised his own "anti-razor:" "If three things are not enough to verify an affirmative proposition about things, a fourth must be added, and so on." Although there have been a number of philosophers who have formulated similar anti-razors since Chatton's time, no one anti-razor has perpetuated in as much notability as Chatton's anti-razor, although this could be the case of the Late Renaissance Italian motto of unknown attribution "Se non è vero, è ben trovato" ("Even if it is not true, it is well conceived") when referred to a particularly artful explanation. For further information, see "Ockham's Razor and Chatton's Anti-Razor" (1984) by Armand Maurer.
Anti-razors have also been created by Gottfried Wilhelm Leibniz (1646–1716), Immanuel Kant (1724–1804), and Karl Menger (1902–1985). Leibniz's version took the form of a principle of plenitude, as Arthur Lovejoy has called it: the idea being that God created the most varied and populous of possible worlds. Kant felt a need to moderate the effects of Occam's razor and thus created his own counter-razor: "The variety of beings should not rashly be diminished."
Karl Menger found mathematicians to be too parsimonious with regard to variables, so he formulated his Law Against Miserliness, which took one of two forms: "Entities must not be reduced to the point of inadequacy" and "It is vain to do with fewer what requires more." A less serious but (some might say) even more extremist anti-razor is 'Pataphysics, the "science of imaginary solutions" developed by Alfred Jarry (1873–1907). Perhaps the ultimate in anti-reductionism, "'Pataphysics seeks no less than to view each event in the universe as completely unique, subject to no laws but its own." Variations on this theme were subsequently explored by the Argentine writer Jorge Luis Borges in his story/mock-essay "Tlön, Uqbar, Orbis Tertius". There is also Crabtree's Bludgeon, which cynically states that "o set of mutually inconsistent observations can exist for which some human intellect cannot conceive a coherent explanation, however complicated."

</doc>
<doc id="36806" url="https://en.wikipedia.org/wiki?curid=36806" title="Cotton">
Cotton

Cotton is a soft, fluffy staple fiber that grows in a boll, or protective case, around the seeds of cotton plants of the genus "Gossypium" in the family of "Malvaceae". The fibre is almost pure cellulose. Under natural conditions, the cotton bolls will tend to increase the dispersal of the seeds.
The plant is a shrub native to tropical and subtropical regions around the world, including the Americas, Africa, and India. The greatest diversity of wild cotton species is found in Mexico, followed by Australia and Africa. Cotton was independently domesticated in the Old and New Worlds.
The fiber is most often spun into yarn or thread and used to make a soft, breathable textile. The use of cotton for fabric is known to date to prehistoric times; fragments of cotton fabric dated from 5000 BC have been excavated in Mexico and the Indus Valley Civilization in Ancient India (modern-day Pakistan and some parts of India). Although cultivated since antiquity, it was the invention of the cotton gin that lowered the cost of production that led to its widespread use, and it is the most widely used natural fiber cloth in clothing today.
Current estimates for world production are about 25 million tonnes or 110 million bales annually, accounting for 2.5% of the world's arable land. China is the world's largest producer of cotton, but most of this is used domestically. The United States has been the largest exporter for many years. In the United States, cotton is usually measured in bales, which measure approximately and weigh .
Types.
There are four commercially grown species of cotton, all domesticated in antiquity:
The two New World cotton species account for the vast majority of modern cotton production, but the two Old World species were widely used before the 1900s. While cotton fibers occur naturally in colors of white, brown, pink and green, fears of contaminating the genetics of white cotton have led many cotton-growing locations to ban the growing of colored cotton varieties, which remain a specialty product.
History.
Pakistan and India.
The earliest evidence of cotton use in South Asia has been found at the site of Mehrgarh, Pakistan, where cotton threads have been found preserved in copper beads; these finds have been dated to Neolithic (between 6000 and 5000 BCE). Cotton cultivation in the region is dated to the Indus Valley Civilization, which covered parts of modern eastern Pakistan and northwestern India between 3300 and 1300 BCE The Indus cotton industry was well-developed and some methods used in cotton spinning and fabrication continued to be used until the industrialization of India. Between 2000 and 1000 BC cotton became widespread across much of India. For example, it has been found at the site of Hallus in Karnataka dating from around 1000 BC.
Mexico.
Cotton fabrics discovered in a cave near Tehuacán, Mexico have been dated to around 5800 BCE. The domestication of Gossypium hirsutum in Mexico is dated between 3400 and 2300 BCE.
Peru.
In Peru, cultivation of the indigenous cotton species "Gossypium barbadense" has been dated, from a find in Ancon, to c 4200 BCE, and was the backbone of the development of coastal cultures such as the Norte Chico, Moche, and Nazca. Cotton was grown upriver, made into nets, and traded with fishing villages along the coast for large supplies of fish. The Spanish who came to Mexico and Peru in the early 16th century found the people growing cotton and wearing clothing made of it.
Arabia.
The Greeks and the Arabs were not familiar with cotton until the Wars of Alexander the Great, as his contemporary Megasthenes told Seleucus I Nicator of "there being trees on which wool grows" in "Indica". This may be a reference to "tree cotton", Gossypium arboreum, which is a native of the Indian subcontinent.
According to the "Columbia Encyclopedia":
Iran.
In Iran (Persia), the history of cotton dates back to the Achaemenid era (5th century BC); however, there are few sources about the planting of cotton in pre-Islamic Iran. The planting of cotton was common in Merv, Ray and Pars of Iran. In Persian poets' poems, especially Ferdowsi's Shahname, there are references to cotton ("panbe" in Persian). Marco Polo (13th century) refers to the major products of Persia, including cotton. John Chardin, a French traveler of the 17th century who visited the Safavid Persia, spoke approvingly of the vast cotton farms of Persia.
China.
During the Han dynasty (207 BCE - 220 CE), cotton was grown by non-Chinese peoples in the southern Chinese province of Yunnan.
Egypt.
Though known since antiquity the commercial growing of cotton in Egypt only started in 1820's, following a Frenchman, by the name of M. Jumel, propositioning the then ruler, Mohamed Ali Pasha, that he could earn a substantial income by growing an extra-long staple Maho (Barbadence) cotton, in Lower Egypt, for the French market. Mohamed Ali Pasha accepted the proposition and granted himself the monopoly on the sale and export of cotton in Egypt; and later dictated cotton should be grown in preference to other crops. By the time of the American Civil war annual exports had reached $16 million (120,000 bales), which rose to $56 million by 1864, primarily due to the loss of the Confederate supply on the world market. Exports continued to grow even after the reintroduction of US cotton, produced now by a paid workforce, and Egyptian exports reached 1.2 million bales a year by 1903.
Europe.
During the late medieval period, cotton became known as an imported fiber in northern Europe, without any knowledge of how it was derived, other than that it was a plant. Because Herodotus had written in his "Histories", Book III, 106, that in India trees grew in the wild producing wool, it was assumed that the plant was a tree, rather than a shrub. This aspect is retained in the name for cotton in several Germanic languages, such as German "Baumwolle", which translates as "tree wool" ("Baum" means "tree"; "Wolle" means "wool"). Noting its similarities to wool, people in the region could only imagine that cotton must be produced by plant-borne sheep. John Mandeville, writing in 1350, stated as fact the now-preposterous belief: "There grew there a wonderful tree which bore tiny lambs on the endes of its branches. These branches were so pliable that they bent down to allow the lambs to feed when they are hungrie ." (See Vegetable Lamb of Tartary.) By the end of the 16th century, cotton was cultivated throughout the warmer regions in Asia and the Americas.
India's cotton-processing sector gradually declined during British expansion in India and the establishment of colonial rule during the late 18th and early 19th centuries. This was largely due to aggressive colonialist mercantile policies of the British East India Company, which made cotton processing and manufacturing workshops in India uncompetitive. Indian markets were increasingly forced to supply only raw cotton and, by British-imposed law, to purchase manufactured textiles from Britain.
Industrial Revolution in Britain.
The advent of the Industrial Revolution in Britain provided a great boost to cotton manufacture, as textiles emerged as Britain's leading export. In 1738, Lewis Paul and John Wyatt, of Birmingham, England, patented the roller spinning machine, as well as the flyer-and-bobbin system for drawing cotton to a more even thickness using two sets of rollers that traveled at different speeds. Later, the invention of the James Hargreaves' spinning jenny in 1764, Richard Arkwright's spinning frame in 1769 and Samuel Crompton's spinning mule in 1775 enabled British spinners to produce cotton yarn at much higher rates. From the late 18th century on, the British city of Manchester acquired the nickname ""Cottonopolis"" due to the cotton industry's omnipresence within the city, and Manchester's role as the heart of the global cotton trade.
Production capacity in Britain and the United States was improved by the invention of the cotton gin by the American Eli Whitney in 1793. Before the development of cotton gins, the cotton fibers had to be pulled from the seeds tediously by hand. By the late 1700s a number of crude ginning machines had been developed. However, to produce a bale of cotton required over 600 hours of human labor, making large-scale production uneconomical in the United States, even with the use of humans as slave labor. The gin that Whitney manufactured (the Holmes design) reduced the hours down to just a dozen or so per bale. Although Whitney patented his own design for a cotton gin, he manufactured a prior design from Henry Odgen Holmes, for which Holmes filed a patent in 1796. Improving technology and increasing control of world markets allowed British traders to develop a commercial chain in which raw cotton fibers were (at first) purchased from colonial plantations, processed into cotton cloth in the mills of Lancashire, and then exported on British ships to captive colonial markets in West Africa, India, and China (via Shanghai and Hong Kong).
By the 1840s, India was no longer capable of supplying the vast quantities of cotton fibers needed by mechanized British factories, while shipping bulky, low-price cotton from India to Britain was time-consuming and expensive. This, coupled with the emergence of American cotton as a superior type (due to the longer, stronger fibers of the two domesticated native American species, "Gossypium hirsutum" and "Gossypium barbadense"), encouraged British traders to purchase cotton from plantations in the United States and plantations in the Caribbean. By the mid-19th century, "King Cotton" had become the backbone of the southern American economy. In the United States, cultivating and harvesting cotton became the leading occupation of slaves.
During the American Civil War, American cotton exports slumped due to a Union blockade on Southern ports, and also because of a strategic decision by the Confederate government to cut exports, hoping to force Britain to recognize the Confederacy or enter the war. This prompted the main purchasers of cotton, Britain and France, to turn to Egyptian cotton. British and French traders invested heavily in cotton plantations. The Egyptian government of Viceroy Isma'il took out substantial loans from European bankers and stock exchanges. After the American Civil War ended in 1865, British and French traders abandoned Egyptian cotton and returned to cheap American exports, sending Egypt into a deficit spiral that led to the country declaring bankruptcy in 1876, a key factor behind Egypt's occupation by the British Empire in 1882.
During this time, cotton cultivation in the British Empire, especially Australia and India, greatly increased to replace the lost production of the American South. Through tariffs and other restrictions, the British government discouraged the production of cotton cloth in India; rather, the raw fiber was sent to England for processing. The Indian Mahatma Gandhi described the process:
USA.
In the United States, Southern cotton provided capital for the continuing development of the North. The cotton produced by enslaved African Americans not only helped the South, but also enriched Northern merchants. Much of the Southern cotton was trans-shipped through northern ports.
Cotton remained a key crop in the Southern economy after emancipation and the end of the Civil War in 1865. Across the South, sharecropping evolved, in which landless black and white farmers worked land owned by others in return for a share of the profits. Some farmers rented the land and bore the production costs themselves. Until mechanical cotton pickers were developed, cotton farmers needed additional labor to hand-pick cotton. Picking cotton was a source of income for families across the South. Rural and small town school systems had split vacations so children could work in the fields during "cotton-picking."
It was not until the 1950s that reliable harvesting machinery was introduced (prior to this, cotton-harvesting machinery had been too clumsy to pick cotton without shredding the fibers). During the first half of the 20th century, employment in the cotton industry fell, as machines began to replace laborers and the South's rural labor force dwindled during the World Wars.
Cotton remains a major export of the southern United States, and a majority of the world's annual cotton crop is of the long-staple American variety.
Cultivation.
Successful cultivation of cotton requires a long frost-free period, plenty of sunshine, and a moderate rainfall, usually from . Soils usually need to be fairly heavy, although the level of nutrients does not need to be exceptional. In general, these conditions are met within the seasonally dry tropics and subtropics in the Northern and Southern hemispheres, but a large proportion of the cotton grown today is cultivated in areas with less rainfall that obtain the water from irrigation. Production of the crop for a given year usually starts soon after harvesting the preceding autumn. Cotton is naturally a perennial but is grown as an annual to help control pests. Planting time in spring in the Northern hemisphere varies from the beginning of February to the beginning of June. The area of the United States known as the South Plains is the largest contiguous cotton-growing region in the world. While dryland (non-irrigated) cotton is successfully grown in this region, consistent yields are only produced with heavy reliance on irrigation water drawn from the Ogallala Aquifer.
Since cotton is somewhat salt and drought tolerant, this makes it an attractive crop for arid and semiarid regions. As water resources get tighter around the world, economies that rely on it face difficulties and conflict, as well as potential environmental problems. For example, improper cropping and irrigation practices have led to desertification in areas of Uzbekistan, where cotton is a major export. In the days of the Soviet Union, the Aral Sea was tapped for agricultural irrigation, largely of cotton, and now salination is widespread.
Cotton can also be cultivated to have colors other than the yellowish off-white typical of modern commercial cotton fibers. Naturally colored cotton can come in red, green, and several shades of brown.
Genetic modification.
Genetically modified (GM) cotton was developed to reduce the heavy reliance on pesticides. The bacterium "Bacillus thuringiensis" (Bt) naturally produces a chemical harmful only to a small fraction of insects, most notably the larvae of moths and butterflies, beetles, and flies, and harmless to other forms of life. The gene coding for Bt toxin has been inserted into cotton, causing cotton, called Bt cotton, to produce this natural insecticide in its tissues. In many regions, the main pests in commercial cotton are lepidopteran larvae, which are killed by the Bt protein in the transgenic cotton they eat. This eliminates the need to use large amounts of broad-spectrum insecticides to kill lepidopteran pests (some of which have developed pyrethroid resistance). This spares natural insect predators in the farm ecology and further contributes to noninsecticide pest management.
But Bt cotton is ineffective against many cotton pests, however, such as plant bugs, stink bugs, and aphids; depending on circumstances it may still be desirable to use insecticides against these. A 2006 study done by Cornell researchers, the Center for Chinese Agricultural Policy and the Chinese Academy of Science on Bt cotton farming in China found that after seven years these secondary pests that were normally controlled by pesticide had increased, necessitating the use of pesticides at similar levels to non-Bt cotton and causing less profit for farmers because of the extra expense of GM seeds. However, a 2009 study by the Chinese Academy of Sciences, Stanford University and Rutgers University refuted this. They concluded that the GM cotton effectively controlled bollworm. The secondary pests were mostly miridae (plant bugs) whose increase was related to local temperature and rainfall and only continued to increase in half the villages studied. Moreover, the increase in insecticide use for the control of these secondary insects was far smaller than the reduction in total insecticide use due to Bt cotton adoption. A 2012 Chinese study concluded that Bt cotton halved the use of pesticides and doubled the level of ladybirds, lacewings and spiders. The International Service for the Acquisition of Agri-biotech Applications (ISAAA) said that, worldwide, GM cotton was planted on an area of 25 million hectares in 2011. This was 69% of the worldwide total area planted in cotton.
GM cotton acreage in India grew at a rapid rate, increasing from 50,000 hectares in 2002 to 10.6 million hectares in 2011. The total cotton area in India was 12.1 million hectares in 2011, so GM cotton was grown on 88% of the cotton area. This made India the country with the largest area of GM cotton in the world. A long-term study on the economic impacts of Bt cotton in India, published in the Journal PNAS in 2012, showed that Bt cotton has increased yields, profits, and living standards of smallholder farmers. The U.S. GM cotton crop was 4.0 million hectares in 2011 the second largest area in the world, the Chinese GM cotton crop was third largest by area with 3.9 million hectares and Pakistan had the fourth largest GM cotton crop area of 2.6 million hectares in 2011. The initial introduction of GM cotton proved to be a success in Australia – the yields were equivalent to the non-transgenic varieties and the crop used much less pesticide to produce (85% reduction). The subsequent introduction of a second variety of GM cotton led to increases in GM cotton production until 95% of the Australian cotton crop was GM in 2009 making Australia the country with the fifth largest GM cotton crop in the world. Other GM cotton growing countries in 2011 were Argentina, Myanmar, Burkina Faso, Brazil, Mexico, Colombia, South Africa and Costa Rica.
Cotton has been genetically modified for resistance to glyphosate a broad-spectrum herbicide discovered by Monsanto which also sells some of the Bt cotton seeds to farmers. There are also a number of other cotton seed companies selling GM cotton around the world. About 62% of the GM cotton grown from 1996 to 2011 was insect resistant, 24% stacked product and 14% herbicide resistant.
Cotton has gossypol, a toxin that makes it inedible. However, scientists have silenced the gene that produces the toxin, making it a potential food crop.
Organic production.
Organic cotton is generally understood as cotton from plants not genetically modified and that is certified to be grown without the use of any synthetic agricultural chemicals, such as fertilizers or pesticides. Its production also promotes and enhances biodiversity and biological cycles. In the United States, organic cotton plantations are required to enforce the National Organic Program (NOP). This institution determines the allowed practices for pest control, growing, fertilizing, and handling of organic crops. As of 2007, 265,517 bales of organic cotton were produced in 24 countries, and worldwide production was growing at a rate of more than 50% per year.
Pests and weeds.
The cotton industry relies heavily on chemicals, such as herbicides, fertilizers and insecticides, although a very small number of farmers are moving toward an organic model of production, and organic cotton products are now available for purchase at limited locations. These are popular for baby clothes and diapers. Under most definitions, organic products do not use genetic engineering. All natural cotton products are known to be both sustainable and hypoallergenic.
Historically, in North America, one of the most economically destructive pests in cotton production has been the boll weevil. Due to the US Department of Agriculture's highly successful Boll Weevil Eradication Program (BWEP), this pest has been eliminated from cotton in most of the United States. This program, along with the introduction of genetically engineered Bt cotton (which contains a bacterial gene that codes for a plant-produced protein that is toxic to a number of pests such as cotton bollworm and pink bollworm), has allowed a reduction in the use of synthetic insecticides.
Other significant global pests of cotton include the pink bollworm, "Pectinophora gossypiella"; the chili thrips, "Scirtothrips dorsalis"; the cotton seed bug, "Oxycarenus hyalinipennis"; the tarnish plant bug, "Lygus lineolaris"; and the fall armyworm, "Spodoptera frugiperda", "Xanthomonas citri subsp. malvacearum".
Harvesting.
Most cotton in the United States, Europe and Australia is harvested mechanically, either by a cotton picker, a machine that removes the cotton from the boll without damaging the cotton plant, or by a cotton stripper, which strips the entire boll off the plant. Cotton strippers are used in regions where it is too windy to grow picker varieties of cotton, and usually after application of a chemical defoliant or the natural defoliation that occurs after a freeze. Cotton is a perennial crop in the tropics, and without defoliation or freezing, the plant will continue to grow.
Cotton continues to be picked by hand in developing countries.
Competition from synthetic fibers.
The era of manufactured fibers began with the development of rayon in France in the 1890s. Rayon is derived from a natural cellulose and cannot be considered synthetic, but requires extensive processing in a manufacturing process, and led the less expensive replacement of more naturally derived materials. A succession of new synthetic fibers were introduced by the chemicals industry in the following decades. Acetate in fiber form was developed in 1924. Nylon, the first fiber synthesized entirely from petrochemicals, was introduced as a sewing thread by DuPont in 1936, followed by DuPont's acrylic in 1944. Some garments were created from fabrics based on these fibers, such as women's hosiery from nylon, but it was not until the introduction of polyester into the fiber marketplace in the early 1950s that the market for cotton came under threat. The rapid uptake of polyester garments in the 1960s caused economic hardship in cotton-exporting economies, especially in Central American countries, such as Nicaragua, where cotton production had boomed tenfold between 1950 and 1965 with the advent of cheap chemical pesticides. Cotton production recovered in the 1970s, but crashed to pre-1960 levels in the early 1990s.
Beginning as a self-help program in the mid-1960s, the Cotton Research and Promotion Program (CRPP) was organized by U.S. cotton producers in response to cotton's steady decline in market share. At that time, producers voted to set up a per-bale assessment system to fund the program, with built-in safeguards to protect their investments. With the passage of the Cotton Research and Promotion Act of 1966, the program joined forces and began battling synthetic competitors and re-establishing markets for cotton. Today, the success of this program has made cotton the best-selling fiber in the U.S. and one of the best-selling fibers in the world.
Administered by the Cotton Board and conducted by Cotton Incorporated, the CRPP works to greatly increase the demand for and profitability of cotton through various research and promotion activities. It is funded by U.S. cotton producers and importers.
Uses.
Cotton is used to make a number of textile products. These include terrycloth for highly absorbent bath towels and robes; denim for blue jeans; cambric, popularly used in the manufacture of blue work shirts (from which we get the term "blue-collar"); and corduroy, seersucker, and cotton twill. Socks, underwear, and most T-shirts are made from cotton. Bed sheets often are made from cotton. Cotton also is used to make yarn used in crochet and knitting. Fabric also can be made from recycled or recovered cotton that otherwise would be thrown away during the spinning, weaving, or cutting process. While many fabrics are made completely of cotton, some materials blend cotton with other fibers, including rayon and synthetic fibers such as polyester. It can either be used in knitted or woven fabrics, as it can be blended with elastine to make a stretchier thread for knitted fabrics, and apparel such as stretch jeans.
In addition to the textile industry, cotton is used in fishing nets, coffee filters, tents, explosives manufacture (see nitrocellulose), cotton paper, and in bookbinding. The first Chinese paper was made of cotton fiber. Fire hoses were once made of cotton.
The cottonseed which remains after the cotton is ginned is used to produce cottonseed oil, which, after refining, can be consumed by humans like any other vegetable oil. The cottonseed meal that is left generally is fed to ruminant livestock; the gossypol remaining in the meal is toxic to monogastric animals. Cottonseed hulls can be added to dairy cattle rations for roughage. During the American slavery period, cotton root bark was used in folk remedies as an abortifacient, that is, to induce a miscarriage. Gossypol was one of the many substances found in all parts of the cotton plant and it was described by the scientists as 'poisonous pigment'. It also appears to inhibit the development of sperm or even restrict the mobility of the sperm. Also, it is thought to interfere with the menstrual cycle by restricting the release of certain hormones.
Cotton linters are fine, silky fibers which adhere to the seeds of the cotton plant after ginning. These curly fibers typically are less than long. The term also may apply to the longer textile fiber staple lint as well as the shorter fuzzy fibers from some upland species. Linters are traditionally used in the manufacture of paper and as a raw material in the manufacture of cellulose. In the UK, linters are referred to as "cotton wool". This can also be a refined product ("absorbent cotton" in U.S. usage) which has medical, cosmetic and many other practical uses. The first medical use of cotton wool was by Sampson Gamgee at the Queen's Hospital (later the General Hospital) in Birmingham, England.
Shiny cotton is a processed version of the fiber that can be made into cloth resembling satin for shirts and suits. However, it is hydrophobic (does not absorb water easily), which makes it unfit for use in bath and dish towels (although examples of these made from shiny cotton are seen).
The name Egyptian cotton is broadly associated with quality products, however only a small percentage of "Egyptian cotton" products are actually of superior quality. Most products bearing the name are not made with cotton from Egypt.
Pima cotton is often compared to Egyptian cotton, as both are used in high quality bed sheets and other cotton products. It is considered the next best quality after high quality Egyptian cotton by some authorities. Pima cotton is grown in the American southwest. Not all products bearing the Pima name are made with the finest cotton. The Pima name is now used by cotton-producing nations such as Peru, Australia and Israel.
Cotton lisle is a finely-spun, tightly twisted type of cotton that is noted for being strong and durable. Lisle is composed of two strands that have each been twisted an extra twist per inch than ordinary yarns and combined to create a single thread. The yarn is spun so that it is compact and solid. This cotton is used mainly for underwear, stockings, and gloves. Colors applied to this yarn are noted for being more brilliant than colors applied to softer yarn. This type of thread was first made in the city of Lisle, France (now Lille), hence its name.
International trade.
The largest producers of cotton, currently (2009), are China and India, with annual production of about 34 million bales and 33.4 million bales, respectively; most of this production is consumed by their respective textile industries. The largest exporters of raw cotton are the United States, with sales of $4.9 billion, and Africa, with sales of $2.1 billion. The total international trade is estimated to be $12 billion. Africa's share of the cotton trade has doubled since 1980. Neither area has a significant domestic textile industry, textile manufacturing having moved to developing nations in Eastern and South Asia such as India and China. In Africa, cotton is grown by numerous small holders. Dunavant Enterprises, based in Memphis, Tennessee, is the leading cotton broker in Africa, with hundreds of purchasing agents. It operates cotton gins in Uganda, Mozambique, and Zambia. In Zambia, it often offers loans for seed and expenses to the 180,000 small farmers who grow cotton for it, as well as advice on farming methods. Cargill also purchases cotton in Africa for export.
The 25,000 cotton growers in the United States of America are heavily subsidized at the rate of $2 billion per year although China now provides the highest overall level of cotton sector support. The future of these subsidies is uncertain and has led to anticipatory expansion of cotton brokers' operations in Africa. Dunavant expanded in Africa by buying out local operations. This is only possible in former British colonies and Mozambique; former French colonies continue to maintain tight monopolies, inherited from their former colonialist masters, on cotton purchases at low fixed prices.
Leading producer countries.
The five leading exporters of cotton in 2011 are (1) the United States, (2) India, (3) Brazil, (4) Australia, and (5) Uzbekistan. The largest nonproducing importers are Korea, Taiwan, Russia, and Japan.
In India, the states of Maharashtra (26.63%), Gujarat (17.96%) and Andhra Pradesh (13.75%) and also Madhya Pradesh are the leading cotton producing states, these states have a predominantly tropical wet and dry climate.
In the United States, the state of Texas led in total production as of 2004, while the state of California had the highest yield per acre.
Fair trade.
Cotton is an enormously important commodity throughout the world. However, many farmers in developing countries receive a low price for their produce, or find it difficult to compete with developed countries.
This has led to an international dispute (see United States – Brazil cotton dispute):
On 27 September 2002, Brazil requested consultations with the US regarding prohibited and actionable subsidies provided to US producers, users and/or exporters of upland cotton, as well as legislation, regulations, statutory instruments and amendments thereto providing such subsidies (including export credits), grants, and any other assistance to the US producers, users and exporters of upland cotton.
On 8 September 2004, the Panel Report recommended that the United States "withdraw" export credit guarantees and payments to domestic users and exporters, and "take appropriate steps to remove the adverse effects or withdraw" the mandatory price-contingent subsidy measures.
While Brazil was fighting the US through the WTO's Dispute Settlement Mechanism against a heavily subsidized cotton industry, a group of four least-developed African countries – Benin, Burkina Faso, Chad, and Mali – also known as "Cotton-4" have been the leading protagonist for the reduction of US cotton subsidies through negotiations. The four introduced a "Sectoral Initiative in Favour of Cotton", presented by Burkina Faso's President Blaise Compaoré during the Trade Negotiations Committee on 10 June 2003.
In addition to concerns over subsidies, the cotton industries of some countries are criticized for employing child labor and damaging workers' health by exposure to pesticides used in production. The Environmental Justice Foundation has campaigned against the prevalent use of forced child and adult labor in cotton production in Uzbekistan, the world's third largest cotton exporter. The international production and trade situation has led to "fair trade" cotton clothing and footwear, joining a rapidly growing market for organic clothing, fair fashion or "ethical fashion". The fair trade system was initiated in 2005 with producers from Cameroon, Mali and Senegal.
Trade.
Cotton is bought and sold by investors and price speculators as a tradable commodity on 2 different stock exchanges in the United States of America.
Critical temperatures.
A temperature range of is the optimal range for mold development. At temperatures below , rotting of wet cotton stops. Damaged cotton is sometimes stored at these temperatures to prevent further deterioration.
Fiber properties.
The chemical composition of cotton is as follows:
Cotton genome.
A public genome sequencing effort of cotton was initiated in 2007 by a consortium of public researchers. They agreed on a strategy to sequence the genome of cultivated, tetraploid cotton. "Tetraploid" means that cultivated cotton actually has two separate genomes within its nucleus, referred to as the A and D genomes. The sequencing consortium first agreed to sequence the D-genome relative of cultivated cotton ("G. raimondii", a wild Central American cotton species) because of its small size and limited number of repetitive elements. It is nearly one-third the number of bases of tetraploid cotton (AD), and each chromosome is only present once. The A genome of "G. arboreum" would be sequenced next. Its genome is roughly twice the size of "G. raimondii"'s. Part of the difference in size between the two genomes is the amplification of "retrotransposons" (GORGE). Once both diploid genomes are assembled, then research could begin sequencing the actual genomes of cultivated cotton varieties. This strategy is out of necessity; if one were to sequence the tetraploid genome without model diploid genomes, the euchromatic DNA sequences of the AD genomes would co-assemble and the repetitive elements of AD genomes would assembly independently into A and D sequences respectively. Then there would be no way to untangle the mess of AD sequences without comparing them to their diploid counterparts.
The public sector effort continues with the goal to create a high-quality, draft genome sequence from reads generated by all sources. The public-sector effort has generated Sanger reads of BACs, fosmids, and plasmids as well as 454 reads. These later types of reads will be instrumental in assembling an initial draft of the D genome. In 2010, two companies (Monsanto and Illumina), completed enough Illumina sequencing to cover the D genome of "G. raimondii" about 50x. They announced that they would donate their raw reads to the public. This public relations effort gave them some recognition for sequencing the cotton genome. Once the D genome is assembled from all of this raw material, it will undoubtedly assist in the assembly of the AD genomes of cultivated varieties of cotton, but a lot of hard work remains.

</doc>
<doc id="36807" url="https://en.wikipedia.org/wiki?curid=36807" title="Football Hall of Fame">
Football Hall of Fame

A Football Hall of Fame may refer to:

</doc>
<doc id="36808" url="https://en.wikipedia.org/wiki?curid=36808" title="Heart">
Heart

The heart is a muscular organ in humans and other animals, which pumps blood through the blood vessels of the circulatory system. Blood provides the body with oxygen and nutrients, and also assists in the removal of metabolic wastes. The heart is located in the middle compartment of the mediastinum in the chest.
In humans, other mammals, and birds, the heart is divided into four chambers: upper left and right atria; and lower left and right ventricles. Commonly the right atrium and ventricle are referred together as the "right heart" and their left counterparts as the "left heart". Fish in contrast have two chambers, an atrium and a ventricle, while reptiles have three chambers. In a healthy heart blood flows one way through the heart due to heart valves, which prevent backflow. The heart is enclosed in a protective sac, the pericardium, which also contains a small amount of fluid. The wall of the heart is made up of three layers: epicardium, myocardium, and endocardium.
The heart pumps blood through the body. Blood low in oxygen from the systemic circulation enters the right atrium from the superior and inferior vena cavae and passes to the right ventricle. From here it is pumped into the pulmonary circulation, through the lungs where it receives oxygen and gives off carbon dioxide. Oxygenated blood then returns to the left atrium, passes through the left ventricle and is pumped out through the aorta to the systemic circulation−where the oxygen is used and metabolized to carbon dioxide. In addition the blood carries nutrients from the digestive tract to various organs of the body, while transporting waste to the liver and kidneys. Normally with each heartbeat the right ventricle pumps the same amount of blood into the lungs as the left ventricle pumps to the body. Veins transport blood to the heart and carry deoxygenated blood - except for the pulmonary and portal veins. Arteries transport blood away from the heart, and apart from the pulmonary artery hold oxygenated blood. Their increased distance from the heart cause veins to have lower pressures than arteries. The heart contracts at a resting rate close to 72 beats per minute. Exercise temporarily increases the rate, but lowers resting heart rate in the long term, and is good for heart health.
Cardiovascular diseases (CVD) are the most common cause of death globally as of 2008, accounting for 30% of deaths. Of these more than three quarters follow coronary artery disease and stroke. Risk factors include: smoking, being overweight, little exercise, high cholesterol, high blood pressure, and poorly controlled diabetes, among others. Diagnosis of CVD is often done by listening to the heart-sounds with a stethoscope, ECG or by ultrasound. Specialists who focus on diseases of the heart are called cardiologists, although many specialties of medicine may be involved in treatment.
Structure.
The heart is situated in the middle mediastinum behind the breastbone in the chest, at the level of thoracic vertebrae T5-T8. The largest part of the heart is usually slightly offset to the left side of the chest (though occasionally it may be offset to the right) and is felt to be on the left because the left heart is stronger, since it pumps to all body parts. Because the heart is between the lungs, the left lung is smaller than the right lung and has a cardiac notch in its border to accommodate the heart.
The heart is supplied by the coronary circulation and is enclosed in a double-membraned sac–the pericardium. This attaches to the mediastinum, providing anchorage for the heart. The back surface of the heart lies near to the vertebral column, and the front surface sits deep to the sternum and costal cartilages. Two of the great veins – the venae cavae, and the great arteries, the aorta and pulmonary artery, are attached to the upper part of the heart, called the base, which is located at the level of the third costal cartilage. The lower tip of the heart, the apex, lies to the left of the sternum (8 to 9 cm from the midsternal line) between the junction of the fourth and fifth ribs near their articulation with the costal cartilages. The right side of the heart is deflected forwards, and the left deflected to the back.
The heart is cone-shaped, with its base positioned upwards and tapering down to the apex. A stethoscope can be placed directly over the apex so that the heartbeats can be counted. An adult heart has a mass of 250–350 grams (9–12 oz). The heart is typically the size of a fist: 12 cm (5 in) in length, 8 cm (3.5 in) wide, and 6 cm (2.5 in) in thickness. Well-trained athletes can have much larger hearts due to the effects of exercise on the heart muscle, similar to the response of skeletal muscle.
Heart wall.
The heart wall is made up of three layers: the inner endocardium, middle myocardium and outer epicardium. These are surrounded by a double-membraned sac called the pericardium.
The innermost layer of the heart is called the endocardium. It is made up of a lining of simple squamous epithelium, and covers heart chambers and valves. It is continuous with the endothelium of the veins and arteries of the heart, and is joined to the myocardium with a thin layer of connective tissue. The endocardium, by secreting endothelins, may also play a role in regulating the contraction of the myocardium.
There are two types of cardiac muscle cell: cardiomyocytes which have the ability to contract easily, and modified cardiomyocytes the pacemaker cells of the conducting system. The cardiomyocytes make up the bulk (99%) of cells in the atria and ventricles. These contractile cells are connected by intercalated discs which allow a rapid response to impulses of action potential from the pacemaker cells. The intercalated discs allow the cells to act as a syncytium and enable the contractions that pump blood through the heart and into the major arteries.
The pacemaker cells make up 1% of cells and form the conduction system of the heart. They are generally much smaller than the contractile cells and have few myofibrils which gives them limited contractibility. Their function is similar in many respects to neurons.
The cardiac muscle pattern is elegant and complex, as the muscle cells swirl and spiral around the chambers of the heart. They form a figure 8 pattern around the atria and around the bases of the great vessels. Deeper ventricular muscles also form a figure 8 around the two ventricles and proceed toward the apex. More superficial layers of ventricular muscle wrap around both ventricles. This complex swirling pattern allows the heart to pump blood more effectively than a simple linear pattern would.
As with skeletal muscles the heart can increase in size and efficiency with exercise. Thus endurance athletes such as marathon runners may have a heart that has increased in size by up to 40%.
The pericardium surrounds the heart. It consists of two membranes: an inner serous membrane called the epicardium, and an outer fibrous membrane. These enclose the pericardial cavity which contains the pericardial fluid that lubricates the surface of the heart.
Chambers.
The heart has four chambers, two upper atria, the receiving chambers, and two lower ventricles, the discharging chambers. The atria open into the ventricles via the atrioventricular valves, present in the atrioventricular septum. This distinction is visible also on the surface of the heart as the coronary sulcus. There is an ear-shaped structure in the upper right atrium called the right atrial appendage, or auricle, and another in the upper left atrium, the left atrial appendage. The right atrium and the right ventricle together are sometimes referred to as the "right heart". Similarly, the left atrium and the left ventricle together are sometimes referred to as the "left heart". The ventricles are separated from each other by the interventricular septum, visible on the surface of the heart as the anterior longitudinal sulcus and the posterior interventricular sulcus.
The cardiac skeleton is made of dense connective tissue and this gives structure to the heart. It forms the atrioventricular septum which separates the atria from the ventricles, and the fibrous rings which serve as bases for the four heart valves. The cardiac skeleton also provides an important boundary in the heart's electrical conduction system since collagen cannot conduct electricity. The interatrial septum separates the atria and the interventricular septum separates the ventricles. The interventricular septum is much thicker than the interatrial septum, since the ventricles need to generate greater pressure when they contract.
Valves.
The heart has four valves, which separate its chambers. The valves ensure blood flows in the correct direction through the heart and prevents backflow. Between the right atrium and the right ventricle is the tricuspid valve. This consists of three cusps (flaps or leaflets), made of endocardium reinforced with additional connective tissue. Each of the three valve-cusps is attached to several strands of connective tissue, the chordae tendineae (tendinous cords). They are composed of approximately 80 percent collagenous fibers with the remainder consisting of elastic fibers and endothelium. They connect each of the cusps to a papillary muscle that extends from the walls of the ventricle. These muscles prevent the valve from falling back into the atrium. The three papillary muscles in the right ventricle are called the anterior, posterior, and septal muscles, which correspond to the three positions of the valve cusps.
Between the left atrium and left ventricle is the mitral valve, also known as the bicuspid valve due to its having two cusps, an anterior and a posterior cusp. These cusps are also attached via chordae tendinae to two papillary muscles projecting from the ventricular wall.
The tricuspid and the mitral valves are the atrioventricular valves. During the relaxation phase of the cardiac cycle, the papillary muscles are also relaxed and the tension on the chordae tendineae is slight. However, as the ventricle contracts, so do the papillary muscles. This creates tension on the chordae tendineae, helping to hold the cusps of the atrioventricular valves in place and preventing them from being blown back into the atria.
The semilunar pulmonary valve is located at the base of the pulmonary artery. This has three cusps which are not attached to any papillary muscles. When the ventricle relaxes blood flows back into the ventricle from the artery and this flow of blood fills the pocket-like valve, pressing against the cusps which close to seal the valve. The semilunar aortic valve is at the base of the aorta and also is not attached to papillary muscles. This too has three cusps which close with the pressure of the blood flowing back from the aorta.
Right heart.
The two major systemic veins, the superior and inferior venae cavae, and the collection of veins that make up the coronary sinus which drains the myocardium, empty into the right atrium. The superior vena cava drains blood from above the diaphragm and empties into the upper back part of the right atrium. The inferior vena cava drains the blood from below the diaphragm and empties into the back part of the atrium below the opening for the superior vena cava. Immediately above and to the middle of the opening of the inferior vena cava is the opening of the thin-walled coronary sinus.
In the wall of the right atrium is an oval-shaped depression known as the fossa ovalis, which is a remnant of an opening in the fetal heart known as the foramen ovale. The foramen ovale allowed blood in the fetal heart to pass directly from the right atrium to the left atrium, allowing some blood to bypass the pulmonary circuit. Within seconds after birth, a flap of tissue known as the septum primum that previously acted as a valve closes the foramen ovale and establishes the typical cardiac circulation pattern. Most of the internal surface of the right atrium is smooth, the depression of the fossa ovalis is medial, and the anterior surface has prominent ridges of pectinate muscles, which are also present in the right atrial appendage.
The atria receive venous blood on a nearly continuous basis, preventing venous flow from stopping while the ventricles are contracting. While most ventricular filling occurs while the atria are relaxed, they do demonstrate a contractile phase when they actively pump blood into the ventricles just prior to ventricular contraction. The right atrium is connected to the right ventricle by the tricuspid valve.
When the myocardium of the ventricle contracts, pressure within the ventricular chamber rises. Blood, like any fluid, flows from higher pressure to lower pressure areas, in this case, toward the pulmonary artery and the atrium. To prevent any potential backflow, the papillary muscles also contract, generating tension on the chordae tendineae. This prevents the flaps of the valves from being forced into the atria and regurgitation of the blood back into the atria during ventricular contraction.
The walls of the right ventricle are lined with trabeculae carneae, ridges of cardiac muscle covered by endocardium. In addition to these muscular ridges, a band of cardiac muscle, also covered by endocardium, known as the moderator band reinforces the thin walls of the right ventricle and plays a crucial role in cardiac conduction. It arises from the lower part of the interventricular septum and crosses the interior space of the right ventricle to connect with the inferior papillary muscle.
When the right ventricle contracts, it ejects blood into the pulmonary artery, which branches into the left and right pulmonary arteries that carry it to each lung. The upper surface of the right ventricle begins to taper as it approaches the pulmonary artery. At the base of the pulmonary artery is the pulmonary semilunar valve that prevents backflow from the pulmonary artery.
Left heart.
After gas exchange in the pulmonary capillaries, blood high in oxygen returns to the left atrium via one of the four pulmonary veins. Only the left atrial appendage contains pectinate muscles. Blood flows nearly continuously from the pulmonary veins back into the atrium, which acts as the receiving chamber, and from here through an opening into the left ventricle. Most blood flows passively into the heart while both the atria and ventricles are relaxed, but toward the end of the ventricular relaxation period, the left atrium will contract, pumping blood into the ventricle. This atrial contraction accounts for approximately 20 percent of ventricular filling. The left atrium is connected to the left ventricle by the mitral valve.
Although both sides of the heart will pump the same amount of blood, the muscular layer is much thicker in the left ventricle compared to the right, due to the greater force needed here. Like the right ventricle, the left also has trabeculae carneae, but there is no moderator band. The left ventricle is the major pumping chamber for the systemic circuit; it ejects blood into the aorta through the aortic semilunar valve.
Coronary circulation.
Cardiomyocytes, like all other cells, need to be supplied with oxygen, nutrients and a way of removing metabolic wastes. This is achieved by the coronary circulation. The coronary circulation cycles in peaks and troughs correlating to the heart muscle's relaxation or contraction.
Coronary arteries supply oxygen-rich blood to the heart and the coronary veins remove the deoxygenated blood. There is a left and a right coronary artery supplying the left and right hearts respectively, and the septa. Smaller branches of these arteries anastomose, which in other parts of the body serve to divert blood due to a blockage. In the heart these are very small and cannot form other interconnections with the result that a coronary artery blockage can cause a myocardial infarction and with it, tissue damage.
The great cardiac vein receives the major branches of the posterior, middle, and small cardiac veins and drains into the coronary sinus, a large vein that empties into the right atrium. The anterior cardiac veins drain the front of the right ventricle and drain directly into the right atrium.
Development.
The heart is the first functional organ to develop and starts to beat and pump blood at about three weeks into embryogenesis. This early start is crucial for subsequent embryonic and prenatal development.
The heart derives from splanchnopleuric mesenchyme in the neural plate which forms the cardiogenic region. Two endocardial tubes form here that fuse to form a primitive heart tube known as the tubular heart. Between the third and fourth week, the heart tube lengthens, and begins to fold to form an S-shape within the pericardium. This places the chambers and major vessels into the correct alignment for the developed heart. Further development will include the septa and valves formation and remodelling of the heart chambers. By the end of the fifth week the septa are complete and the heart valves are completed by the ninth week.
The embryonic heart begins beating at around 22 days after conception (5 weeks after the last normal menstrual period, LMP). It starts to beat at a rate near to the mother's which is about 75–80 beats per minute (bpm). The embryonic heart rate then accelerates and reaches a peak rate of 165–185 bpm early in the early 7th week (early 9th week after the LMP). After 9 weeks (start of the fetal stage) it starts to decelerate, slowing to around 145 (±25) bpm at birth. There is no difference in female and male heart rates before birth.
Physiology.
Blood flow.
The heart functions as a pump in the circulatory system to provide a continuous circulation of blood throughout the body. This circulation consists of the systemic circulation to and from the body and the pulmonary circulation to and from the lungs. Blood in the pulmonary circulation exchanges carbon dioxide for oxygen in the lungs through the process of respiration. The systemic circulation then transports oxygen to the body and returns carbon dioxide and relatively deoxygenated blood to the heart for transfer to the lungs.
The right heart collects deoxygenated blood from two large veins, the superior and inferior venae cavae. The blood collects in the right atrium and is pumped through the tricuspid valve into the right ventricle, where it is pumped into the pulmonary artery through the pulmonary valve. Here the blood enters the pulmonary circulation where carbon dioxide can be exchanged for oxygen in the lungs. This happens through the passive process of diffusion.
In the left heart, oxygenated blood is returned to the left atrium via the pulmonary veins. It is then pumped into the left ventricle through the mitral valve and into the aorta through the aortic valve for systemic circulation. The aorta is a large artery that branches into many smaller arteries, arterioles, and ultimately capillaries. In the capillaries, oxygen and nutrients from blood are supplied to body cells for metabolism, and exchanged for carbon dioxide and waste products
Cardiac cycle.
The cardiac cycle refers to a complete heartbeat which includes systole and diastole and the intervening pause. The cycle begins with contraction of the atria and ends with relaxation of the ventricles. Systole is when the ventricles of the heart contract to pump blood to the body. Diastole is when the ventricles relax and fill with blood. The atria and ventricles work in concert, so in systole when the ventricles are contracting, the atria are relaxed and collecting blood. When the ventricles are relaxed in diastole, the atria contract to pump blood to the ventricles. This coordination ensures blood is pumped efficiently to the body.
At the beginning of the cardiac cycle, in early diastole, both the atria and ventricles are relaxed. Since blood moves from areas of high pressure to areas of low pressure, when the chambers are relaxed, blood will flow into the atria (through the coronary sinus and the pulmonary veins). As the atria begin to fill, the pressure will rise so that the blood will move from the atria into the ventricles. In late diastole the atria contract pumping more blood into the ventricles. This causes a rise in pressure in the ventricles, and in ventricular systole blood will be pumped into the pulmonary artery.
When the atrioventricular valves (tricuspid and mitral) are open, during blood flow to the ventricles, the semilunar valves are closed to prevent backflow into the ventricles. When the ventricular pressure is greater than the atrial pressure the tricuspid and mitral valves will shut. When the ventricles contract the pressure forces the semilunar aortic and pulmonary valves open. As the ventricles relax the semilunar valves will close in response to decreased pressure.
Cardiac output.
Cardiac output (CO) is a measurement of the amount of blood pumped by each ventricle (stroke volume) in one minute. This is calculated by multiplying the stroke volume (SV) by the beats per minute of the heart rate (HR). So that: CO = SV x HR.
The average cardiac output, using an average SV of about 70mL, is 5.25 L/min, with a range of 4.0–8.0 L/min. The stroke volume is normally measured using an echocardiogram and can be influenced by the size of the heart, physical and mental condition of the individual, sex, contractility, duration of contraction, preload and afterload.
Preload refers to the filling pressure of the atria at the end of diastole, when they are at their fullest. A main factor is how long it takes the ventricles to fill—if the ventricles contract faster, then there is less time to fill and the preload will be less. Preload can also be affected by a person's hydration status. The force of each contraction of the heart muscle is proportional to the preload, described as the Frank-Starling mechanism. This states that the force of contraction is directly proportional to the initial length of muscle fiber, meaning a ventricle will contract more forcefully, the more it is stretched.
Afterload, or how much pressure the heart must generate to eject blood at systole, is influenced by vascular resistance. It can be influenced by narrowing of the heart valves (stenosis) or contraction or relaxation of the peripheral blood vessels.
The strength of heart muscle contractions controls the stroke volume. This can be influenced positively or negatively by agents termed inotropes. These can be either conditions or drugs. Positive inotropes that cause stronger contractions include high blood calcium and drugs such as Digoxin, which will act to stimulate the sympathetic nerves in the fight-or-flight response. Negative inotropes causing weaker contractions include high blood potassium, hypoxia, acidosis, and drugs such as beta blockers and calcium channel blockers.
Electrical conduction.
The normal rhythmical heart beat, called sinus rhythm, is established by the sinoatrial node, the heart's pacemaker. Here an electrical signal is created that travels through the heart, causing the heart muscle to contract.
The sinoatrial node is found in the upper part of the right atrium near to the junction with the superior vena cava. The electrical signal generated by the sinoatrial node travels through the right atrium in a radial way that is not completely understood. It travels to the left atrium via Bachmann's bundle, such that both left and right atria contract together. The signal then travels to the atrioventricular node. This is found at the bottom of the right atrium in the atrioventricular septum—the boundary between the right atrium and the left ventricle. The septum is part of the cardiac skeleton, tissue within the heart that the electrical signal cannot pass through, which forces the signal to pass through the atrioventricular node only. The signal then travels along the bundle of His to left and right bundle branches through to the ventricles of the heart. In the ventricles the signal is carried by specialized tissue called the Purkinje fibers which then transmit the electric charge to the cardiac muscle.
Sinoatrial node.
The sinoatrial node creates and sustains its own rhythm, the sinus rhythm. Cells in the sinoatrial node do this by creating an action potential. The cardiac action potential is created by the movement of specific electrolytes into and out of the pacemaker cells. The action potential then spreads to nearby cells.
When the sinoatrial cells are resting, they have a negative charge on their membranes. However a rapid influx of sodium ions causes the membrane's charge to become positive. This is called depolarisation and occurs spontaneously. Once the cell has a sufficiently high charge, the sodium channels close and calcium ions then begin to enter the cell, shortly after which potassium begins to leave it. All the ions travel through ion channels in the membrane of the sinoatrial cells. The potassium and calcium only start to move out of and into the cell once it has a sufficiently high charge, and so are called voltage-gated. Shortly after this, the calcium channels close and potassium channels open, allowing potassium to leave the cell. This causes the cell to have a negative resting charge and is called repolarization. When the membrane potential reaches approximately −60 mV, the potassium channels close and the process may begin again.
The ions move from areas where they are concentrated to where they are not. For this reason sodium moves into the cell from outside, and potassium moves from within the cell to outside the cell. Calcium also plays a critical role. Their influx through slow channels means that the sinoatrial cells have a prolonged "plateau" phase when they have a positive charge. A part of this is called the absolute refractory period. Calcium ions also combine with the regulatory protein troponin C in the troponin complex to enable contraction of the cardiac muscle, and separate from the protein to allow relaxation.
Influences.
The normal sinus rhythm of the heart, giving the resting heart rate, is influenced by the autonomic nervous system through sympathetic and parasympathetic nerves. These arise from two paired cardiovascular centres in the medulla oblongata.The vagus nerve of the parasympathetic nervous system acts to decrease the heart rate, and nerves from the sympathetic trunk act to increase the heart rate. These come together in the cardiac plexus near the base of the heart. Without parasympathetic input which normally predominates, the sinoatrial node would generate a heart rate of about 100 bpm.
The nerves from the sympathetic trunk emerge through the T1-T4 thoracic ganglia and travel to both the sinoatrial and atrioventricular nodes, as well as to the atria and ventricles. The ventricles are more richly innervated by sympathetic fibers than parasympathetic fibers. Sympathetic stimulation causes the release of the neurotransmitter norepinephrine (also known as noradrenaline) at the neuromuscular junction of the cardiac nerves. This shortens the repolarization period, thus speeding the rate of depolarization and contraction, which results in an increased heart rate. It opens chemical or ligand-gated sodium and calcium ion channels, allowing an influx of positively charged ions. Norepinephrine binds to the beta–1 receptor. High blood pressure medications are used to block these receptors and so reduce the heart rate.
The cardiovascular centres receive input from a series of receptors including proprioreceptors, baroreceptors, and chemoreceptors, plus stimuli from the limbic system. Through a series of reflexes these help regulate and sustain blood flow. For example, increased physical activity results in increased rates of firing by various proprioreceptors located in muscles, joint capsules, and tendons. With increased rates of firing, the parasympathetic stimulation may decrease or sympathetic stimulation may increase as needed in order to increase blood flow.
Similarly, baroreceptors are stretch receptors located in the aortic sinus, carotid bodies, the venae cavae, and other locations, including pulmonary vessels and the right side of the heart itself. Rates of firing from the baroreceptors represent blood pressure, level of physical activity, and the relative distribution of blood. The cardiac centers monitor baroreceptor firing to maintain cardiac homeostasis, a mechanism called the baroreceptor reflex. With increased pressure and stretch, the rate of baroreceptor firing increases, and the cardiac centers decrease sympathetic stimulation and increase parasympathetic stimulation. As pressure and stretch decrease, the rate of baroreceptor firing decreases, and the cardiac centers increase sympathetic stimulation and decrease parasympathetic stimulation.
There is a similar reflex, called the atrial reflex or Bainbridge reflex, associated with varying rates of blood flow to the atria. Increased venous return stretches the walls of the atria where specialized baroreceptors are located. However, as the atrial baroreceptors increase their rate of firing and as they stretch due to the increased blood pressure, the cardiac center responds by increasing sympathetic stimulation and inhibiting parasympathetic stimulation to increase heart rate. The opposite is also true.
In addition to the autonomic nervous system, other factors can impact on this. These include epinephrine, norepinephrine, and thyroid hormones; levels of various ions including calcium, potassium, and sodium; body temperature; hypoxia; and pH balance. Factors that increase the heart rate can include release of norepinephrine, hypoxemia, low blood pressure and dehydration, a strong emotional response, a higher body temperature, and metabolic and hormonal factors such as a low potassium or sodium level or stimulus from thyroid hormones. Decreased body temperature, relaxation, and metabolic factors can also contribute to a decrease in heart rate.
The resting heart rate of a newborn can be 129 beats per minute (bpm) and this gradually decreases until maturity. The adult resting heart rate ranges from 60 to 100 bpm. Exercise and fitness levels, age and basal metabolic rate can all affect the heart rate. An athlete's heart rate can be lower than 60 bpm. During exercise the rate can be 150 bpm with maximum rates reaching from 200 to 220 bpm.
Heart sounds.
One of the simplest methods of assessing the heart's condition is to listen to it using a stethoscope. In a healthy heart, there are only two audible heart sounds, called S1 and S2. The first heart sound S1, is the sound created by the closing of the atrioventricular valves during ventricular contraction and is normally described as "lub". The second heart sound, S2, is the sound of the semilunar valves closing during ventricular diastole and is described as "dub". Each sound consists of two components, reflecting the slight difference in time as the two valves close. S2 may split into two distinct sounds, either as a result of inspiration or different valvular or cardiac problems. Additional heart sounds may also be present and these give rise to gallop rhythms. A third heart sound, S3 usually indicates an increase in ventricular blood volume. A fourth heart sound S4 is referred to as an atrial gallop and is produced by the sound of blood being forced into a stiff ventricle. The combined presence of S3 and S4 give a quadruple gallop.
Heart murmurs are abnormal heart sounds which can be either pathological or benign. One example of a murmur is Still's murmur, which presents a musical sound in children, has no symptoms and disappears in adolescence.
A different type of sound, a pericardial friction rub can be heard in cases of pericarditis where the inflamed membranes can rub together.
Clinical significance.
Disease.
Cardiovascular diseases, which include diseases of the heart, are the leading cause of death worldwide. The majority of cardiovascular disease is noncommunicable and related to lifestyle and other factors, becoming more prevalent with ageing. Heart disease is a major cause of death, accounting for an average of 30% of all deaths in 2008, globally. This rate varies from a lower 28% to a high 40% in high-income countries. Doctors that specialise in the heart are called cardiologists. Many other medical professionals are involved in treating diseases of the heart, including doctors such as general practitioners, cardiothoracic surgeons and intensivists, and allied health practitioners including physiotherapists and dieticians.
Coronary artery disease is also known as ischemic heart disease, is caused by atherosclerosis – a build-up of plaque along the inner walls of the arteries which narrows them, reducing the blood flow to the heart. A stable plaque may cause chest pain (angina) or breathlessness during exercise or at rest, or no symptoms at all. A ruptured plaque can block a blood vessel and lead to ischaemia of the heart muscle, causing unstable angina or a heart attack. In the worst case this may cause cardiac arrest, a sudden and utter loss of output from the heart. Obesity, high blood pressure, uncontrolled diabetes, smoking and high cholesterol can all increase the risk of developing atherosclerosis and coronary artery disease.
Heart failure is where the heart can't beat enough blood to meet the needs of the body. It is generally a chronic condition, associated with age, that progresses gradually.Each side of the heart can fail independently of the other, resulting in heart failure of the right heart or the left heart. Left heart failure can also lead to right heart failure by increasing strain on the right heart (called cor pulmonale). If the heart is unable to pump sufficient blood, it may accumulate throughout the body, causing breathlessness in the lungs (pulmonary congestion; pulmonary edema), swelling (edema) of the feet or other gravity-dependent areas, decrease exercise tolerance, or cause other clinical signs such as an enlarged liver, cardiac murmurs, or a raised jugular venous pressure. Common causes of heart failure include coronary artery disease, valve disorders and diseases of cardiac muscle.
Cardiomyopathy is a noticeable deterioration of the heart muscle's ability to contract, which can lead to heart failure. The causes of many types cardiomyopathy are poorly understood; some identified causes include alcohol, toxins, systemic disease such as sarcoidosis, and congenital conditions such as HOCM. The types of cardiomyopathy are described according to how they affect heart muscle. Cardiomyopathy can cause the heart to become enlarged (hypertrophic cardiomyopathy), constrict the outflow tracts of the heart (restrictive cardiomyopathy), or cause the heart to dilate and impact on the effiency of its beating (dilated cardiomyopathy). HOCM is often undiagnosed and can cause sudden death in young athletes.
Heart murmurs are abnormal heart sounds which can be either related to disease or benign, and there are several kinds. There are normally two heart sounds, and abnormal heart sounds can either be extra sounds, or "murmurs" related to the flow of blood between the sounds. Murmurs are graded by volume, from 1) the quietest, to 6) the loudest, and evaluated by their relationship to the heart sounds, position in the cardiac cycle, and additional features such as their radiation to other sites, changes with a person's position, the frequency of the sound as determined by the side of the stethoscope by which they are heard, and site at which they are heard loudest.Phonocardiograms can record these sounds, and echocardiograms are generally required for their diagnosis. Murmurs can result from valvular heart diseases due to narrowing (stenosis), or regurgitation of any of the main heart valves, such as aortic stenosis, mitral regurgitation or mitral valve prolapse. They can also result from a number of other disorders, including atrial and ventricular septal defects. Two common and infective causes of heart murmurs, are infective endocarditis and rheumatic fever, particularly in developing countries. Infective endocarditis involves colonisation of a heart valve, and rheumatic fever involves an initial bacterial infection by Group A streptococcus followed by a reaction against heart tissue that resembles the streptococcal antigen.
Abnormalities in the normal sinus rhythm of the heart can prevent the heart from effectively pumping blood, and are generally identified by ECG. These cardiac arrhythmias can cause an abnormal but regular heart rhythm, such as a rapid heart rate (tachycardia, classified as arising from above the ventricles or from the ventricles) or a slow heart rate (bradycardia); or may result in irregular rhythms. Tachycardia is generally defined as a heart rate faster than 100 beats per minute, and bradycardia as a heart rate slower than 60. Asystole is the cessation of heart rhythm. An irregular rhythm is classified as atrial or ventricular fibrillation depending if the electrical activity originates in the atria or the ventricles. Abnormal conduction can cause a delay or unusual order of contraction of the heart muscle. This can be a result of a disease process, such as heart block, or congenital, such as Wolff-Parkinson-White syndrome.
Diseases may also affect the pericardium which surrounds the heart, which when inflammed is called pericarditis. This may result from infective causes (such as glandular fever, cytomegalovirus, coxsackievirus, tuberculosis or Q fever), systemic disorders such as amyloidosis or sarcoidosis, tumours, high uric acid levels, and other causes. This inflammation affects the ability of the heart to pump effectively. When fluid builds up in the pericardium this is called pericardial effusion, which when it causes acute heart failure is called cardiac tamponade. This may be blood from a traumatic injury or fluid from an effusion. This can compress the heart and adversely affect the function of the heart. The fluid can be removed from the pericardial sac using a syringe in a procedure called pericardiocentesis.
The heart can be affected by congenital diseases. These include failure of the developmental foramen ovale to close, present in up to 25% of people; ventricular or atrial septal defects, congenital diseases of the heart valves (e.g. congenital aortic stenosis) or disease relating to blood vessels or blood flow from the heart (such as a patent ductus arteriosus or aortic coarctation).; Harrisons 1458–1465 These may cause symptoms at a variety of ages. If unoxygenated blood travels directly from the right to the left side of the heart, it may be noticed at birth, as it may cause a baby to become blue (cyanotic) such as Tetralogy of Fallot. A heart problem may impact a child's ability to grow. Some causes rectify with time and are regarded as benign. Other causes may be incidentally detected on a cardiac examination. These disorders are often diagnosed on an echocardiogram.
Diagnosis.
Heart disease is diagnosed by the taking of a medical history, a cardiac examination, and further investigations, including blood tests, echocardiograms, ECGs and imaging. Other invasive procedures such as cardiac catheterisation can also play a role.
Examination.
The cardiac examination includes inspection, palpation and listening with a stethoscope (auscultation). It involves assessment of signs that may be visible on a person's hands (such as splinter haemorrhages), joints and other areas. A person's pulse is taken, usually at the radial artery near the wrist, in order to assess for the rhythm and strength of the pulse. The blood pressure is taken, either manually using a sphygmomanometer or an automatic blood pressure reader. Any elevation of the jugular venous pulse is noted. A person's chest is felt for any transmitted vibrations from the heart, and then listened to with a stethoscope, known as auscultation. A normal heart has two hearts sounds - additional heart sounds or heart murmurs may also be able to be heard. Additional tests may be conducted to assess a person's heart murmurs if they are present, and signs of peripheral heart disease such as swollen feet or fluid in the lungs may be assessed.
Electrocardiogram.
Using surface electrodes on the body, it is possible to record the complex electrical activity of the heart. This tracing of the electrical signal is the electrocardiogram (ECG) or (EKG). An ECG is a bedside test and usually requires the placement of nine leads on the body. This produces a "12 lead" ECG (three extra leads are calculated mathematically).
There are five prominent points on the ECG: the P wave (atrial depolarisation), the QRS complex (atrial repolarisation and ventricular depolarisation) and the T wave (ventricular repolarisation). These reflect the summed action potential of cardiac myocytes as they contract. A downward deflection on the ECG implies cells are becoming more negative in charge ("depolarising"), whereas an upward inflection implies cells are becoming more positive ("repolarising"). The ECG is a useful tool in detecting rhythm disturbances and in detecting insufficient blood supply to the heart. Sometimes abnormalities are not immediately visible on the ECG. Testing when exercising can be used to provoke an abnormality, or an ECG can be worn for a longer period such as a 24-hour Holter monitor if a rhythm abnormality is suspected to be present but not present at the time of assessment.
Imaging.
Several imaging methods can be used to assess the anatomy and function of the heart, including angiography, PET, CT, MRI and ultrasound (echocardiography). An echocardiogram is used to measure the heart's function, assess for valve disease, and look for any abnormalities. Echocardiography can be conducted by a probe on the chest ("transthoracic") or by a probe in the esophagus ("transoesophageal"). A typical echocardiography report will include information about the width of the valves noting any stenosis, whether there is any backflow of blood (regurgitation) and information about the blood volumes at the end of systole and diastole, including an ejection fraction, which describes how much blood is ejected from the left and right ventricles after systole. Ejection fraction can then be obtained by dividing the volume ejected by the heart (stroke volume) by the volume of the filled heart (end-diastolic volume). Echocardiograms can also be conducted under circumstances when the body is more stressed, in order to examine for signs of lack of blood supply. This cardiac stress test involves either direct exercise, or where this is not possible, injection of a drug such as dobutamine.
CT scans, chest X-rays and other forms of imaging can help evaluate the heart's size, evaluate for signs of pulmonary oedema, and indicate whether there is fluid around the heart. They are also useful for evaluating the aorta, the major blood vessel which leaves the heart.
Treatment.
A number of medications are used to treat diseases of the heart, or ameliorate symptoms.
For diseases of the heart rate or rhythm, a number of different antiarrhythmic agents are used. These may interfere with electrolyte channels and thus the cardiac action potential (such as calcium channel blockers, sodium channel blockers), interfere with stimulation of the heart by the sympathetic nervous system (beta blockers), or interfere in other ways, such as digoxin. Other examples include atropine for slow rhythms, and amiodarone for irregular rhythms. Such medications are not the only way of treating diseases of heart rate or rhythm. In the context of a new-onset irregular heart rhythm (atrial fibrillation), immediate electrical cardioversion may be attempted. For a slow heartbeat or heart block, a pacemaker or defibrillator may be inserted. The acuity of onset often affects how a rhythm disturbance is managed, as does whether a rhythm causes hemodynamic instability, such as low blood pressure or symptoms. An instigating cause is investigated for, such as a heart attack, medication, or metabolic problem.
For ischaemic heart disease, treatment also includes amelioration of symptoms. This includes GTN, beta blockers and, in the context of an acute event, stronger pain relief such as morphine and other opiates. Many of these drugs have additional protective benefits, by decreasing the sympathetic tone on the heart that occurs with the pain, or by dilating blood vessels (GTN).
Treatment of heart disease includes primary and secondary prevention to prevent the occurrence or worsening of symptoms and atherosclerosis. This includes recommendations to cease smoking, decrease alcohol consumption, increase exercise, and make modifications to their diet to decrease the consumption of fats and sugars. Medications may also be given to help better control concurrent diabetes. Statins or other drugs such as fibrates may also be given to decrease a person's cholesterol levels. Blood pressure medication may also be commenced or modified.
For many diseases of the heart, including atrial fibrillation and valvular disease, and after a heart operation, anticoagulation in the form of aspirin, warfarin, clopidogrel or novel oral anticoagulants is often given simultaneously, because of an increased risk of stroke or, in the context of a clotted heart vessel, rethrombosis.
Surgery.
Surgery, when considered necessary for diseases of the heart, can take place via an open operation or via small guidewires inserted via peripheral arteries ("percutaneous coronary intervention"). Percutaneous coronary intervention is usually used in the context of an acute coronary syndrome, and may be used to insert a stent.
Coronary artery bypass surgery is one such operation. In this operation, one or more arteries surrounding the heart that have becoming narrowed are bypassed. This is done by taking blood vessels harvested from another part of the body. Commonly harvested veins include the saphenous veins or the internal mammary artery. Because this operation involves the heart tissue, a machine is used so that blood can bypass the heart during the operation.
Heart valve repair or valve replacement are options for diseases of the heart valves.
History.
Ancient.
The valves of the heart were discovered by a physician of the Hippocratean school around the 4th century BC, although their function was not fully understood. On dissection, arteries are typically empty of blood because blood pools in the veins after death. It was subsequently assumed they were filled with air and served to transport air around the body.
Philosophers distinguished veins from arteries, but thought the pulse was a property of arteries. Erasistratos observed that arteries cut during life bleed. He ascribed the fact to the phenomenon that air escaping from an artery is replaced with blood which entered by very small vessels between veins and arteries. Thus he apparently postulated capillaries, but with reversed flow of blood.
The Greek physician Galen (2nd century AD) knew blood vessels carried blood and identified venous (dark red) and arterial (brighter and thinner) blood, each with distinct and separate functions. Growth and energy were derived from venous blood created in the liver from chyle, while arterial blood gave vitality by containing pneuma (air) and originated in the heart. Blood flowed from both creating organs to all parts of the body, where it was consumed and there was no return of blood to the heart or liver. The heart did not pump blood around, the heart's motion sucked blood in during diastole and the blood moved by the pulsation of the arteries themselves.
Galen believed the arterial blood was created by venous blood passing from the left ventricle to the right through 'pores' in the interventricular septum, while air passed from the lungs via the pulmonary artery to the left side of the heart. As the arterial blood was created, "sooty" vapors were created and passed to the lungs, also via the pulmonary artery, to be exhaled.
Pre-modern.
The earliest descriptions of the coronary and pulmonary circulation systems can be found in the "Commentary on Anatomy in Avicenna's Canon", published in 1242 by Ibn al-Nafis. In his manuscript, al-Nafis wrote that blood passes through the pulmonary circulation instead of moving from the right to the left ventricle as previously believed by Galen. His work was later translated into Latin by Andrea Alpago.
In Europe, the teachings of Galen continued to dominate the academic community and his doctrines were adopted as the official canon of the Church. Andreas Vesalius questioned some of Galen's beliefs of the heart in "De humani corporis fabrica" (1543), but his magnum opus was interpreted as a challenge to the authorities and he was subjected to a number of attacks. Michael Servetus wrote in "Christianismi Restitutio" (1553) that blood flows from one side of the heart to the other via the lungs.
Modern.
The breakthrough came with the publication of "De Motu Cordis" (1628) by the English physician William Harvey. Harvey's book completely describes the systemic circulation and the mechanical force of the heart, leading to an overhaul of the Galenic doctrines. Otto Frank (1865–1944) was a German physiologist; among his many published works are detailed studies of this important heart relationship. Ernest Starling (1866–1927) was an important English physiologist who also studied the heart. Although they worked largely independently, their combined efforts and similar conclusions have been recognized in the name "Frank–Starling mechanism".
Although Purkinje fibers and the bundle of His were discovered as early as the 19th century, their specific role in the electrical conduction system of the heart remained unknown until Sunao Tawara published his monograph, titled "Das Reizleitungssystem des Säugetierherzens", in 1906. Tawara's discovery of the atrioventricular node prompted Arthur Keith and Martin Flack to look for similar structures in the heart, leading to their discovery of the sinoatrial node several months later. These structures form the anatomical basis of the electrocardiogram, whose inventor, Willem Einthoven, was awarded the Nobel Prize in Medicine or Physiology in 1924.
The first successful heart transplantation was performed in 1967 by the South African surgeon Christiaan Barnard at Groote Schuur Hospital in Cape Town. This marked an important milestone in cardiac surgery, capturing the attention of both the medical profession and the world at large. However, long-term survival rates of patients were initially very low. Louis Washkansky, the first recipient of a donated heart, died 18 days after the operation while other patients did not survive for more than a few weeks. The American surgeon Norman Shumway has been credited for his efforts to improve transplantation techniques, along with pioneers Richard Lower, Vladimir Demikhov and Adrian Kantrowitz. As of March 2000, more than 55,000 heart transplantations have been performed worldwide.
By the middle of the 20th century, heart disease had surpassed infectious disease as the leading cause of death in the United States, and it is currently the leading cause of deaths worldwide. Since 1948, the ongoing Framingham Heart Study has shed light on the effects of various influences on the heart, including diet, exercise, and common medications such as aspirin. Although the introduction of ACE inhibitors and beta blockers has improved the management of chronic heart failure, the disease continues to be an enormous medical and societal burden, with 30 to 40% of patients dying within a year of receiving the diagnosis.
Society and culture.
Symbolism.
As one of the vital organs, the heart was long identified as the center of the entire body, the seat of life, or emotion, or reason, will, intellect, purpose or the mind. The heart is an emblematic symbol in many religions, signifying "truth, consience or moral courage in many religions - the temple or throne of God in Islamic and Judeo-Christian thought; the divine centre, or atman, and the third eye of transcendent wisdom in Hinduism; the diamond of purity and essence of the Buddha; the Taoist centre of understanding."
In the Hebrew Bible, the word for heart, "lev", is used in these meanings, as the seat of emotion, the mind, and referring to the anatomical organ. It is also connected in function and symbolism to the stomach.
An important part of the concept of the soul in Ancient Egyptian religion was thought to be the heart, or "ib". The "ib" or metaphysical heart was believed to be formed from one drop of blood from the child's mother's heart, taken at conception. To ancient Egyptians, the heart was the seat of emotion, thought, will, and intention. This is evidenced by Egyptian expressions which incorporate the word "ib", such as "Awi-ib" for "happy" (literally, "long of heart"), "Xak-ib" for "estranged" (literally, "truncated of heart"). In Egyptian religion, the heart was the key to the afterlife. It was conceived as surviving death in the nether world, where it gave evidence for, or against, its possessor. It was thought that the heart was examined by Anubis and a variety of deities during the "Weighing of the Heart" ceremony. If the heart weighed more than the feather of Maat, which symbolized the ideal standard of behavior. If the scales balanced, it meant the heart's possessor had lived a just life and could enter the afterlife; if the heart was heavier, it would be devoured by the monster Ammit.
The Chinese character for "heart", 心, derives from a comparatively realistic depiction of a heart (indicating the heart chambers) in seal script. The Chinese word "xīn" also takes the metaphorical meanings of "mind", "intention", or "core". In Chinese medicine, the heart is seen as the center of 神 "shén" "spirit, consciousness". The heart is associated with the small intestine, tongue, governs the six organs and five viscera, and belongs to fire in the five elements.
The Sanskrit word for heart is "hṛd" or "hṛdaya", found in the oldest surviving Sanskrit text, the Rigveda. In Sanskrit, it may mean both the anatomical object and "mind" or "soul", representing the seat of emotion. "Hrd" may be a cognate of the word for heart in Greek, Latin, and English.
Many classical philosophers and scientists, including Aristotle, considered the heart the seat of thought, reason, or emotion, often disregarding the brain as contributing to those functions. The identification of the heart as the seat of emotions in particular is due to the Roman physician Galen, who also located the seat of the passions in the liver, and the seat of reason in the brain.
The heart also played a role in the Aztec system of belief. The most common form of human sacrifice practiced by the Aztecs was heart-extraction. The Aztec believed that the heart ("tona") was both the seat of the individual and a fragment of the Sun's heat ("istli"). To this day, the Nahua consider the Sun to be a heart-soul ("tona-tiuh"): "round, hot, pulsating".
In Catholicism, there has been a long tradition of worship of the heart, stemming from worship of the wounds of Jesus Christ which gained prominence from the mid sixteenth century. This tradition influenced the development of the medieval Christian devotion to the Sacred Heart of Jesus and the parallel worship of Immaculate Heart of Mary, made popular by John Eudes.
The expression of a broken heart is a cross-cultural reference to grief for a lost one or to unfulfilled romantic love.
The notion of "Cupid's arrows" is ancient, due to Ovid, but while Ovid describes Cupid as wounding his victims with his arrows, it is not made explicit that it is the "heart" that is wounded. The familiar iconography of Cupid shooting little heart symbols is a Renaissance theme that became tied to Valentine's day.
Food.
Animal hearts are widely consumed as food. As they are almost entirely muscle, they are high in protein. They are often included in dishes with other offal, for example in the pan-Ottoman kokoretsi.
Chicken hearts are considered to be giblets, and are often grilled on skewers: Japanese "hāto yakitori", Brazilian "churrasco de coração", Indonesian chicken heart satay. They can also be pan-fried, as in Jerusalem mixed grill. In Egyptian cuisine, they can be used, finely chopped, as part of stuffing for chicken. Many recipes combined them with other giblets, such as the Mexican "pollo en menudencias" and the Russian "ragu iz kurinyikh potrokhov".
The hearts of beef, pork, and mutton can generally be interchanged in recipes. As heart is a hard-working muscle, it makes for "firm and rather dry" meat, so is generally slow-cooked. Another way of dealing with toughness is to julienne the meat, as in Chinese stir-fried heart.
Beef heart may be grilled or braised. In the Peruvian "anticuchos de corazón", barbecued beef hearts are grilled after being tenderized through long marination in a spice and vinegar mixture. An Australian recipe for "mock goose" is actually braised stuffed beef heart.
Pig heart is stewed, poached, braised, or made into sausage. The Balinese "oret" is a sort of blood sausage made with pig heart and blood. A French recipe for "cœur de porc à l'orange" is made of braised heart with an orange sauce.
Other animals.
The structure of the heart varies among the different animal groups. Cephalopods have two "gill hearts" also known as branchial hearts and one "systemic heart". The vertebrate heart lies in the front (ventral) part of the body cavity, dorsal to the gut. It is always surrounded by a pericardium, which is usually a distinct structure, but may be continuous with the peritoneum in jawless and cartilaginous fish.
The SA node is found in all amniotes but not in more primitive vertebrates. In these animals, the muscles of the heart are relatively continuous and the sinus venosus coordinates the beat which passes in a wave through the remaining chambers. Indeed, since the sinus venosus is incorporated into the right atrium in amniotes, it is likely homologous with the SA node. In teleosts, with their vestigial sinus venosus, the main centre of coordination is, instead, in the atrium. The rate of heartbeat varies enormously between different species, ranging from around 20 beats per minute in codfish to around 600 in hummingbirds and up to 1200 bpm in the ruby-throated hummingbird.
Double circulatory systems.
In the heart of lungfish, the septum extends part-way into the ventricle. This allows for some degree of separation between the de-oxygenated bloodstream destined for the lungs and the oxygenated stream that is delivered to the rest of the body. The absence of such a division in living amphibian species may be partly due to the amount of respiration that occurs through the skin; thus, the blood returned to the heart through the vena cavae is already partially oxygenated. As a result, there may be less need for a finer division between the two bloodstreams than in lungfish or other tetrapods. Nonetheless, in at least some species of amphibian, the spongy nature of the ventricle does seem to maintain more of a separation between the bloodstreams. Also, the original valves of the conus arteriosus have been replaced by a spiral valve that divides it into two parallel parts, thereby helping to keep the two bloodstreams separate.
Adult amphibians and most reptiles have a double circulatory system but the heart is not separated into two pumps. The development of the double system is necessitated by the presence of lungs which deliver oxygenated blood directly to the heart.
In amphibians, the atrium is divided into two chambers by a muscular septum but there is only one ventricle. The sinus venosus, which remains large, connects only to the right atrium and receives blood from the venae cavae, with the pulmonary vein by-passing it to enter the left atrium.
The heart of most reptiles is similar in structure to that of lungfish but the septum is generally much larger. This divides the ventricle into two halves but the septum does not reach the whole length of the heart and there is a considerable gap near the pulmonary artery and aorta openings. In most reptilian species, there appears to be little, if any, mixing between the bloodstreams, so the aorta receives, essentially, only oxygenated blood.
The fully divided heart.
Archosaurs (crocodilians and birds) and mammals show complete separation of the heart into two pumps for a total of four heart chambers; it is thought that the four-chambered heart of archosaurs evolved independently from that of mammals. In crocodilians, there is a small opening, the foramen of Panizza, at the base of the arterial trunks and there is some degree of mixing between the blood in each side of the heart, during a dive underwater; thus, only in birds and mammals are the two streams of blood – those to the pulmonary and systemic circulations – permanently kept entirely separate by a physical barrier.
Fish.
Primitive fish have a four-chambered heart, but the chambers are arranged sequentially so that this primitive heart is quite unlike the four-chambered hearts of mammals and birds. The first chamber is the sinus venosus, which collects deoxygenated blood, from the body, through the hepatic and cardinal veins. From here, blood flows into the atrium and then to the powerful muscular ventricle where the main pumping action will take place. The fourth and final chamber is the conus arteriosus which contains several valves and sends blood to the "ventral aorta". The ventral aorta delivers blood to the gills where it is oxygenated and flows, through the dorsal aorta, into the rest of the body. (In tetrapods, the ventral aorta has divided in two; one half forms the ascending aorta, while the other forms the pulmonary artery).
In the adult fish, the four chambers are not arranged in a straight row but, instead form an S-shape with the latter two chambers lying above the former two. This relatively simpler pattern is found in cartilaginous fish and in the ray-finned fish. In teleosts, the conus arteriosus is very small and can more accurately be described as part of the aorta rather than of the heart proper. The conus arteriosus is not present in any amniotes, presumably having been absorbed into the ventricles over the course of evolution. Similarly, while the sinus venosus is present as a vestigial structure in some reptiles and birds, it is otherwise absorbed into the right atrium and is no longer distinguishable.
Invertebrates.
Arthropods have an open circulatory system, and often some short open-ended arteries.The arthropod heart is typically a muscular tube that runs the length of the body, under the back and from the base of the head. Instead of blood the circulatory fluid is haemolymph which carries the most commonly used respiratory pigment, copper-based haemocyanin as the oxygen transporter; iron-based haemoglobin is used by only a few arthropods. The heart contracts in ripples from the rear to the front of the animal transporting water and nutrients. Pairs of valves run alongside the heart, allowing fluid to enter whilst preventing backflow.
In insects, the circulatory system is not used to transport oxygen and so is much reduced, having no veins or arteries and consisting of a single perforated tube running dorsally which pumps peristaltically. The simpler unsegmented invertebrates have no body cavity, and oxygen and nutrients pass through their bodies by diffusion.

</doc>
<doc id="36811" url="https://en.wikipedia.org/wiki?curid=36811" title="Subset sum problem">
Subset sum problem

In computer science, the subset sum problem is an important problem in complexity theory and cryptography. The problem is this: given a set (or multiset) of integers, is there a non-empty subset whose sum is zero? For example, given the set {−7, −3, −2, 5, 8}, the answer is "yes" because the subset {−3, −2, 5} sums to zero. The problem is NP-complete.
An equivalent problem is this: given a set of integers and an integer "s", does any non-empty subset sum to "s"? Subset sum can also be thought of as a special case of the knapsack problem. One interesting special case of subset sum is the partition problem, in which "s" is half of the sum of all elements in the set.
Complexity.
The complexity of the subset sum problem can be viewed as depending on two parameters, "N", the number of decision variables, and "P", the precision of the problem (stated as the number of binary place values that it takes to state the problem). (Note: here the letters "N" and "P" mean something different from what they mean in the NP class of problems.)
The complexity of the best known algorithms is exponential in the smaller of the two parameters "N" and "P". Thus, the problem is most difficult if "N" and "P" are of the same order. It only becomes easy if either "N" or "P" becomes very small.
If "N" (the number of variables) is small, then an exhaustive search for the solution is practical. If "P" (the number of place values) is a small fixed number, then there are dynamic programming algorithms that can solve it exactly.
Efficient algorithms for both small "N" and small "P" cases are given below.
Exponential time algorithm.
There are several ways to solve subset sum in time exponential in "N". The most naïve algorithm would be to cycle through all subsets of N numbers and, for every one of them, check if the subset sums to the right number. The running time is of order "O"(2"N""N"), since there are 2"N" subsets and, to check each subset, we need to sum at most "N" elements.
A better exponential time algorithm is known which runs in time "O"(2"N"/2). The algorithm splits arbitrarily the "N" elements into two sets of "N"/2 each. For each of these two sets, it stores a list of the sums of all 2"N"/2 possible subsets of its elements. Each of these two lists is then sorted. Using a standard comparison sorting algorithm for this step would take time "O"(2"N"/2"N"). However, given a sorted list of sums for "k" elements, the list can be expanded to two sorted lists with the introduction of a ("k" + 1)st element, and these two sorted lists can be merged in time "O"(2"k"). Thus, each list can be generated in sorted form in time "O"(2"N"/2). Given the two sorted lists, the algorithm can check if an element of the first array and an element of the second array sum up to "s" in time "O"(2"N"/2). To do that, the algorithm passes through the first array in decreasing order (starting at the largest element) and the second array in increasing order (starting at the smallest element). Whenever the sum of the current element in the first array and the current element in the second array is more than "s", the algorithm moves to the next element in the first array. If it is less than "s", the algorithm moves to the next element in the second array. If two elements with sum "s" are found, it stops. Horowitz and Sahni first published this algorithm in a technical report in 1972.
Pseudo-polynomial time dynamic programming solution.
The problem can be solved in pseudo-polynomial time using dynamic programming. Suppose the sequence is 
and we wish to determine if there is a nonempty subset which sums to zero. Define the boolean-valued function "Q"("i", "s") to be the value (true or false) of 
Thus, the solution to the problem "Given a set of integers, is there a non-empty subset whose sum is zero?" is the value of "Q"("N", 0).
Let "A" be the sum of the negative values and "B" the sum of the positive values. Clearly, , if or . So these values do not need to be stored or computed.
Create an array to hold the values "Q"("i", "s") for and 
The array can now be filled in using a simple recursion. Initially, for set
where "==" is a boolean function that returns true if "x"1 is equal to "s", false otherwise.
Then, for "i" = 2, …, "N", set
For each assignment, the values of "Q" on the right side are already known, either because they were stored in the table for the previous value of "i" or because if or Therefore, the total number of arithmetic operations is For example, if all the values are "O"("Nk") for some "k", then the time required is "O"("N""k"+2).
This algorithm is easily modified to return the subset with sum 0 if there is one.
The dynamic programming solution has runtime of formula_1 where formula_2 is the sum we want to find in set of formula_3 numbers. This solution does not count as polynomial time in complexity theory because is not polynomial in the "size" of the problem, which is the number of bits used to represent it. This algorithm is polynomial in the values of "A" and "B", which are exponential in their numbers of bits.
For the case that each "xi" is positive and bounded by a fixed constant "C", Pisinger found a linear time algorithm having time complexity (note that this is for the version of the problem where the target sum is not necessarily zero, otherwise the problem would be trivial). In 2015, Koiliaris and Xu found the formula_4 algorithm for the subset sum problem where formula_2 is the sum we need to find.
Polynomial time approximate algorithm.
An approximate version of the subset sum would be: given a set of "N" numbers "x"1, "x"2, ..., "xN" and a number "s", output
If all numbers are non-negative, the approximate subset sum is solvable in time polynomial in "N" and 1/"c".
The solution for subset sum also provides the solution for the original subset sum problem in the case where the numbers are small (again, for nonnegative numbers). If any sum of the numbers can be specified with at most "P" bits, then solving the problem approximately with is equivalent to solving it exactly. Then, the polynomial time algorithm for approximate subset sum becomes an exact algorithm with running time polynomial in "N" and 2"P" (i.e., exponential in "P").
The algorithm for the approximate subset sum problem is as follows:
The algorithm is polynomial time because the lists "S", "T" and "U" always remain of size polynomial in "N" and 1/"c" and, as long as they are of polynomial size, all operations on them can be done in polynomial time. The size of lists is kept polynomial by the trimming step, in which we only include a number "z" into "S" if it is greater than the previous one by "cs"/"N" and not greater than "s".
This step ensures that each element in "S" is smaller than the next one by at least "cs"/"N" and do not contain elements greater than "s". Any list with that property consists of no more than "N"/"c" elements.
The algorithm is correct because each step introduces an additive error of at most "cs"/"N" and "N" steps together introduce the error of at most "cs".

</doc>
<doc id="36812" url="https://en.wikipedia.org/wiki?curid=36812" title="Pericles">
Pericles

Pericles (; "Periklēs", in Classical Attic; c. 495 – 429 BC) was arguably the most prominent and influential Greek statesman, orator and general of Athens during the Golden Age— specifically the time between the Persian and Peloponnesian wars. He was descended, through his mother, from the powerful and historically influential Alcmaeonid family.
Pericles had such a profound influence on Athenian society that Thucydides, a contemporary historian, acclaimed him as "the first citizen of Athens". Pericles turned the Delian League into an Athenian empire, and led his countrymen during the first two years of the Peloponnesian War. The period during which he led Athens, roughly from 461 to 429 BC, is sometimes known as the "Age of Pericles", though the period thus denoted can include times as early as the Persian Wars, or as late as the next century.
Pericles promoted the arts and literature; it is principally through his efforts that Athens holds the reputation of being the educational and cultural center of the ancient Greek world. He started an ambitious project that generated most of the surviving structures on the Acropolis (including the Parthenon). This project beautified and protected the city, exhibited its glory, and gave work to the people. Pericles also fostered Athenian democracy to such an extent that critics call him a populist.
Early years.
Pericles was born c. 495 BC, in Athens, Greece. He was the son of the politician Xanthippus, who, though ostracized in 485–484 BC, returned to Athens to command the Athenian contingent in the Greek victory at Mycale just five years later. Pericles' mother, Agariste, a member of the powerful and controversial noble family of the Alcmaeonidae, and her familial connections played a crucial role in kickstarting Xanthippus' political career. Agariste was the great-granddaughter of the tyrant of Sicyon, Cleisthenes, and the niece of the Athenian reformer Cleisthenes.
According to Herodotus and Plutarch, Agariste dreamed, a few nights before Pericles' birth, that she had borne a lion. Interestingly, legends say that Philip II of Macedon had a similar dream before the birth of his son, Alexander the Great. One interpretation of the dream treats the lion as a traditional symbol of greatness, but the story may also allude to the unusually large size of Pericles' skull, which became a popular target of contemporary comedians (who called him "Squill-head", after the Squill or Sea-Onion). Although Plutarch claims that this deformity was the reason that Pericles was always depicted wearing a helmet, this is not the case; the helmet was actually the symbol of his official rank as strategos (general).
Pericles belonged to the tribe of Acamantis (). His early years were quiet; the introverted young Pericles avoided public appearances, instead preferring to devote his time to his studies.
His family's nobility and wealth allowed him to fully pursue his inclination toward education. He learned music from the masters of the time (Damon or Pythocleides could have been his teacher) and he is considered to have been the first politician to attribute importance to philosophy. He enjoyed the company of the philosophers Protagoras, Zeno of Elea, and Anaxagoras. Anaxagoras, in particular, became a close friend and influenced him greatly.
Pericles' manner of thought and rhetorical charisma may have been in part products of Anaxagoras' emphasis on emotional calm in the face of trouble and skepticism about divine phenomena. His proverbial calmness and self-control are also often regarded as products of Anaxagoras' influence.
Political career until 431 BC.
Entering politics.
In the spring of 472 BC, Pericles presented "The Persians" of Aeschylus at the Greater Dionysia as a liturgy, demonstrating that he was one of the wealthier men of Athens. Simon Hornblower has argued that Pericles' selection of this play, which presents a nostalgic picture of Themistocles' famous victory at Salamis, shows that the young politician was supporting Themistocles against his political opponent Cimon, whose faction succeeded in having Themistocles ostracized shortly afterwards.
Plutarch says that Pericles stood first among the Athenians for forty years. If this was so, Pericles must have taken up a position of leadership by the early 460s BC- in his early or mid-thirties. Throughout these years he endeavored to protect his privacy and to present himself as a model for his fellow citizens. For example, he would often avoid banquets, trying to be frugal.
In 463 BC, Pericles was the leading prosecutor of Cimon, the leader of the conservative faction who was accused of neglecting Athens' vital interests in Macedon. Although Cimon was acquitted, this confrontation proved that Pericles' major political opponent was vulnerable.
Ostracizing Cimon.
Around 461 BC, the leadership of the democratic party decided it was time to take aim at the Areopagus, a traditional council controlled by the Athenian aristocracy, which had once been the most powerful body in the state. The leader of the party and mentor of Pericles, Ephialtes, proposed a reduction of the Areopagus' powers. The Ecclesia (the Athenian Assembly) adopted Ephialtes' proposal without opposition. This reform signaled the beginning of a new era of "radical democracy".
The democratic party gradually became dominant in Athenian politics, and Pericles seemed willing to follow a populist policy in order to cajole the public. According to Aristotle, Pericles' stance can be explained by the fact that his principal political opponent, Cimon, was both rich and generous, and was able to gain public favor by lavishly handing out portions of his sizable personal fortune. The historian Loren J. Samons II argues, however, that Pericles had enough resources to make a political mark by private means, had he so chosen.
In 461 BC, Pericles achieved the political elimination of this opponent using ostracism. The accusation was that Cimon betrayed his city by aiding Sparta.
After Cimon's ostracism, Pericles continued to promote a populist social policy. He first proposed a decree that permitted the poor to watch theatrical plays without paying, with the state covering the cost of their admission. With other decrees he lowered the property requirement for the archonship in 458–457 BC and bestowed generous wages on all citizens who served as jurymen in the Heliaia (the supreme court of Athens) some time just after 454 BC. His most controversial measure, however, was a law of 451 BC limiting Athenian citizenship to those of Athenian parentage on both sides.
Such measures impelled Pericles' critics to hold him responsible for the gradual degeneration of the Athenian democracy. Constantine Paparrigopoulos, a major modern Greek historian, argues that Pericles sought for the expansion and stabilization of all democratic institutions. Hence, he enacted legislation granting the lower classes access to the political system and the public offices, from which they had previously been barred.
According to Samons, Pericles believed that it was necessary to raise the demos, in which he saw an untapped source of Athenian power and the crucial element of Athenian military dominance. (The fleet, backbone of Athenian power since the days of Themistocles, was manned almost entirely by members of the lower classes.)
Cimon, on the other hand, apparently believed that no further free space for democratic evolution existed. He was certain that democracy had reached its peak and Pericles' reforms were leading to the stalemate of populism. According to Paparrigopoulos, history vindicated Cimon, because Athens, after Pericles' death, sank into the abyss of political turmoil and demagogy. Paparrigopoulos maintains that an unprecedented regression descended upon the city, whose glory perished as a result of Pericles' populist policies.
According to another historian, Justin Daniel King, radical democracy benefited people individually, but harmed the state. On the other hand, Donald Kagan asserts that the democratic measures Pericles put into effect provided the basis for an unassailable political strength. After all, Cimon finally accepted the new democracy and did not oppose the citizenship law, after he returned from exile in 451 BC.
Leading Athens.
Ephialtes' murder in 461 BC paved the way for Pericles to consolidate his authority. Without opposition after the expulsion of Cimon, the unchallengeable leader of the democratic party became the unchallengeable ruler of Athens. He remained in power until his death in 429 BC.
First Peloponnesian War.
Pericles made his first military excursions during the First Peloponnesian War, which was caused in part by Athens' alliance with Megara and Argos and the subsequent reaction of Sparta. In 454 BC he attacked Sicyon and Acarnania. He then unsuccessfully tried to conquer Oeniadea on the Corinthian gulf, before returning to Athens. In 451 BC, Cimon returned from exile and negotiated a five years' truce with Sparta after a proposal of Pericles, an event which indicates a shift in Pericles' political strategy. Pericles may have realized the importance of Cimon's contribution during the ongoing conflicts against the Peloponnesians and the Persians. Anthony J. Podlecki argues, however, that Pericles' alleged change of position was invented by ancient writers to support "a tendentious view of Pericles' shiftiness".
Plutarch states that Cimon struck a power-sharing deal with his opponents, according to which Pericles would carry through the interior affairs and Cimon would be the leader of the Athenian army, campaigning abroad. If it was actually made, this bargain would constitute a concession on Pericles' part that he was not a great strategist. Kagan believes that Cimon adapted himself to the new conditions and promoted a political marriage between Periclean liberals and Cimonian conservatives.
In the mid-450s the Athenians launched an unsuccessful attempt to aid an Egyptian revolt against Persia, which led to a prolonged siege of a Persian fortress in the Nile Delta. The campaign culminated in disaster; the besieging force was defeated and destroyed. In 451–450 BC the Athenians sent troops to Cyprus. Cimon defeated the Persians in the Battle of Salamis-in-Cyprus, but died of disease in 449 BC. Pericles is said to have initiated both expeditions in Egypt and Cyprus, although some researchers, such as Karl Julius Beloch, argue that the dispatch of such a great fleet conforms with the spirit of Cimon's policy.
Complicating the account of this period is the issue of the Peace of Callias, which allegedly ended hostilities between the Greeks and the Persians. The very existence of the treaty is hotly disputed, and its particulars and negotiation are ambiguous. Ernst Badian believes that a peace between Athens and Persia was first ratified in 463 BC (making the Athenian interventions in Egypt and Cyprus violations of the peace), and renegotiated at the conclusion of the campaign in Cyprus, taking force again by 449–448 BC.
John Fine, on the other hand, suggests that the first peace between Athens and Persia was concluded in 450–449 BC, due to Pericles' calculation that ongoing conflict with Persia was undermining Athens' ability to spread its influence in Greece and the Aegean. Kagan believes that Pericles used Callias, a brother-in-law of Cimon, as a symbol of unity and employed him several times to negotiate important agreements.
In the spring of 449 BC, Pericles proposed the Congress Decree, which led to a meeting ("Congress") of all Greek states in order to consider the question of rebuilding the temples destroyed by the Persians. The Congress failed because of Sparta's stance, but Pericles' intentions remain unclear. Some historians think that he wanted to prompt a confederation with the participation of all the Greek cities; others think he wanted to assert Athenian pre-eminence. According to the historian Terry Buckley the objective of the Congress Decree was a new mandate for the Delian League and for the collection of "phoros" (taxes).
During the Second Sacred War Pericles led the Athenian army against Delphi and reinstated Phocis in its sovereign rights on the oracle. In 447 BC Pericles engaged in his most admired excursion, the expulsion of barbarians from the Thracian peninsula of Gallipoli, in order to establish Athenian colonists in the region. At this time, however, Athens was seriously challenged by a number of revolts among its subjects. In 447 BC the oligarchs of Thebes conspired against the democratic faction. The Athenians demanded their immediate surrender, but after the Battle of Coronea, Pericles was forced to concede the loss of Boeotia in order to recover the prisoners taken in that battle. With Boeotia in hostile hands, Phocis and Locris became untenable and quickly fell under the control of hostile oligarchs.
In 446 BC, a more dangerous uprising erupted. Euboea and Megara revolted. Pericles crossed over to Euboea with his troops, but was forced to return when the Spartan army invaded Attica. Through bribery and negotiations, Pericles defused the imminent threat, and the Spartans returned home. When Pericles was later audited for the handling of public money, an expenditure of 10 talents was not sufficiently justified, since the official documents just referred that the money was spent for a "very serious purpose". Nonetheless, the "serious purpose" (namely the bribery) was so obvious to the auditors that they approved the expenditure without official meddling and without even investigating the mystery.
After the Spartan threat had been removed, Pericles crossed back to Euboea to crush the revolt there. He then punished the landowners of Chalcis, who lost their properties. The residents of Histiaea, meanwhile, who had butchered the crew of an Athenian trireme, were uprooted and replaced by 2,000 Athenian settlers. The crisis was brought to an official end by the Thirty Years' Peace (winter of 446–445 BC), in which Athens relinquished most of the possessions and interests on the Greek mainland which it had acquired since 460 BC, and both Athens and Sparta agreed not to attempt to win over the other state's allies.
Final battle with the conservatives.
In 444 BC, the conservative and the democratic factions confronted each other in a fierce struggle. The ambitious new leader of the conservatives, Thucydides (not to be confused with the historian of the same name), accused Pericles of profligacy, criticizing the way he spent the money for the ongoing building plan. Thucydides managed, initially, to incite the passions of the ecclesia in his favor, but, when Pericles, the leader of the democrats, took the floor, he put the conservatives in the shade. Pericles responded resolutely, proposing to reimburse the city for all the expenses from his private property, under the term that he would make the inscriptions of dedication in his own name.
His stance was greeted with applause, and Thucydides suffered an unexpected defeat. In 442 BC, the Athenian public voted to ostracize Thucydides from the city for 10 years and Pericles was once again the unchallenged ruler of the Athenian political arena.
Athens' rule over its alliance.
Pericles wanted to stabilize Athens' dominance over its alliance and to enforce its pre-eminence in Greece. The process by which the Delian League transformed into an Athenian empire is generally considered to have begun well before Pericles' time, as various allies in the league chose to pay tribute to Athens instead of manning ships for the league's fleet, but the transformation was speeded and brought to its conclusion by Pericles.
The final steps in the shift to empire may have been triggered by Athens' defeat in Egypt, which challenged the city's dominance in the Aegean and led to the revolt of several allies, such as Miletus and Erythrae. Either because of a genuine fear for its safety after the defeat in Egypt and the revolts of the allies, or as a pretext to gain control of the League's finances, Athens transferred the treasury of the alliance from Delos to Athens in 454–453 BC.
By 450–449 BC the revolts in Miletus and Erythrae were quelled and Athens restored its rule over its allies. Around 447 BC Clearchus proposed the Coinage Decree, which imposed Athenian silver coinage, weights and measures on all of the allies. According to one of the decree's most stringent provisions, surplus from a minting operation was to go into a special fund, and anyone proposing to use it otherwise was subject to the death penalty.
It was from the alliance's treasury that Pericles drew the funds necessary to enable his ambitious building plan, centered on the "Periclean Acropolis", which included the Propylaea, the Parthenon and the golden statue of Athena, sculpted by Pericles' friend, Phidias. In 449 BC Pericles proposed a decree allowing the use of 9,000 talents to finance the major rebuilding program of Athenian temples. Angelos Vlachos, a Greek Academician, points out the utilization of the alliance's treasury, initiated and executed by Pericles, as one of the largest embezzlements in human history; this misappropriation financed, however, some of the most marvellous artistic creations of the ancient world.
Samian War.
The Samian War was one of the last significant military events before the Peloponnesian War. After Thucydides' ostracism, Pericles was re-elected yearly to the generalship, the only office he ever officially occupied, although his influence was so great as to make him the "de facto" ruler of the state. In 440 BC Samos went to war against Miletus over control of Priene, an ancient city of Ionia on the foot-hills of Mycale. Worsted in the war, the Milesians came to Athens to plead their case against the Samians.
When the Athenians ordered the two sides to stop fighting and submit the case to arbitration in Athens, the Samians refused. In response, Pericles passed a decree dispatching an expedition to Samos, "alleging against its people that, although they were ordered to break off their war against the Milesians, they were not complying".
In a naval battle the Athenians led by Pericles and nine other generals defeated the forces of Samos and imposed on the island an Athenian administration. When the Samians revolted against Athenian rule, Pericles compelled the rebels to capitulate after a tough siege of eight months, which resulted in substantial discontent among the Athenian sailors. Pericles then quelled a revolt in Byzantium and, when he returned to Athens, gave a funeral oration to honor the soldiers who died in the expedition.
Between 438–436 BC Pericles led Athens' fleet in Pontus and established friendly relations with the Greek cities of the region. Pericles focused also on internal projects, such as the fortification of Athens (the building of the "middle wall" about 440 BC), and on the creation of new cleruchies, such as Andros, Naxos and Thurii (444 BC) as well as Amphipolis (437–436 BC).
Personal attacks.
Pericles and his friends were never immune from attack, as preeminence in democratic Athens was not equivalent to absolute rule. Just before the eruption of the Peloponnesian War, Pericles and two of his closest associates, Phidias and his companion, Aspasia, faced a series of personal and judicial attacks.
Phidias, who had been in charge of all building projects, was first accused of embezzling gold meant for the statue of Athena and then of impiety, because, when he wrought the battle of the Amazons on the shield of Athena, he carved out a figure that suggested himself as a bald old man, and also inserted a very fine likeness of Pericles fighting with an Amazon.
Aspasia, who was noted for her ability as a conversationalist and adviser, was accused of corrupting the women of Athens in order to satisfy Pericles' perversions. The accusations against her were probably nothing more than unproven slanders, but the whole experience was very bitter for Pericles. Although Aspasia was acquitted thanks to a rare emotional outburst of Pericles, his friend, Phidias, died in prison and another friend of his, Anaxagoras, was attacked by the ecclesia for his religious beliefs.
Beyond these initial prosecutions, the ecclesia attacked Pericles himself by asking him to justify his ostensible profligacy with, and maladministration of, public money. According to Plutarch, Pericles was so afraid of the oncoming trial that he did not let the Athenians yield to the Lacedaemonians. Beloch also believes that Pericles deliberately brought on the war to protect his political position at home. Thus, at the start of the Peloponnesian War, Athens found itself in the awkward position of entrusting its future to a leader whose pre-eminence had just been seriously shaken for the first time in over a decade.
Peloponnesian War.
The causes of the Peloponnesian War have been much debated, but many ancient historians lay the blame on Pericles and Athens. Plutarch seems to believe that Pericles and the Athenians incited the war, scrambling to implement their belligerent tactics "with a sort of arrogance and a love of strife". Thucydides hints at the same thing, believing the reason for the war was Sparta's fear of Athenian power and growth. However, as he is generally regarded as an admirer of Pericles, Thucydides has been criticized for bias towards Sparta.
Prelude to the war.
Pericles was convinced that the war against Sparta, which could not conceal its envy of Athens' pre-eminence, was inevitable if unfortunate. Therefore, he did not hesitate to send troops to Corcyra to reinforce the Corcyraean fleet, which was fighting against Corinth. In 433 BC the enemy fleets confronted each other at the Battle of Sybota and a year later the Athenians fought Corinthian colonists at the Battle of Potidaea; these two events contributed greatly to Corinth's lasting hatred of Athens. During the same period, Pericles proposed the Megarian Decree, which resembled a modern trade embargo. According to the provisions of the decree, Megarian merchants were excluded from the market of Athens and the ports in its empire. This ban strangled the Megarian economy and strained the fragile peace between Athens and Sparta, which was allied with Megara. According to George Cawkwell, a praelector in ancient history, with this decree Pericles breached the Thirty Years' Peace "but, perhaps, not without the semblance of an excuse". The Athenians' justification was that the Megarians had cultivated the sacred land consecrated to Demeter and had given refuge to runaway slaves, a behavior which the Athenians considered to be impious.
After consultations with its allies, Sparta sent a deputation to Athens demanding certain concessions, such as the immediate expulsion of the Alcmaeonidae family including Pericles and the retraction of the Megarian Decree, threatening war if the demands were not met. The obvious purpose of these proposals was the instigation of a confrontation between Pericles and the people; this event, indeed, would come about a few years later. At that time, the Athenians unhesitatingly followed Pericles' instructions. In the first legendary oration Thucydides puts in his mouth, Pericles advised the Athenians not to yield to their opponents' demands, since they were militarily stronger. Pericles was not prepared to make unilateral concessions, believing that "if Athens conceded on that issue, then Sparta was sure to come up with further demands". Consequently, Pericles asked the Spartans to offer a "quid pro quo". In exchange for retracting the Megarian Decree, the Athenians demanded from Sparta to abandon their practice of periodic expulsion of foreigners from their territory (xenelasia) and to recognize the autonomy of its allied cities, a request implying that Sparta's hegemony was also ruthless. The terms were rejected by the Spartans, and with neither side willing to back down, the two cities prepared for war. According to Athanasios G. Platias and Constantinos Koliopoulos, professors of strategic studies and international politics, "rather than to submit to coercive demands, Pericles chose war". Another consideration that may well have influenced Pericles' stance was the concern that revolts in the empire might spread if Athens showed itself weak.
First year of the war (431 BC).
In 431 BC, while peace already was precarious, Archidamus II, Sparta's king, sent a new delegation to Athens, demanding that the Athenians submit to Sparta's demands. This deputation was not allowed to enter Athens, as Pericles had already passed a resolution according to which no Spartan deputation would be welcomed if the Spartans had previously initiated any hostile military actions. The Spartan army was at this time gathered at Corinth, and, citing this as a hostile action, the Athenians refused to admit their emissaries. With his last attempt at negotiation thus declined, Archidamus invaded Attica, but found no Athenians there; Pericles, aware that Sparta's strategy would be to invade and ravage Athenian territory, had previously arranged to evacuate the entire population of the region to within the walls of Athens.
No definite record exists of how exactly Pericles managed to convince the residents of Attica to agree to move into the crowded urban areas. For most, the move meant abandoning their land and ancestral shrines and completely changing their lifestyle. Therefore, although they agreed to leave, many rural residents were far from happy with Pericles' decision. Pericles also gave his compatriots some advice on their present affairs and reassured them that, if the enemy did not plunder his farms, he would offer his property to the city. This promise was prompted by his concern that Archidamus, who was a friend of his, might pass by his estate without ravaging it, either as a gesture of friendship or as a calculated political move aimed to alienate Pericles from his constituents.
In any case, seeing the pillage of their farms, the Athenians were outraged, and they soon began to indirectly express their discontent towards their leader, who many of them considered to have drawn them into the war. Even when in the face of mounting pressure, Pericles did not give in to the demands for immediate action against the enemy or revise his initial strategy. He also avoided convening the ecclesia, fearing that the populace, outraged by the unopposed ravaging of their farms, might rashly decide to challenge the vaunted Spartan army in the field. As meetings of the assembly were called at the discretion of its rotating presidents, the "prytanies", Pericles had no formal control over their scheduling; rather, the respect in which Pericles was held by the prytanies was apparently sufficient to persuade them to do as he wished. While the Spartan army remained in Attica, Pericles sent a fleet of 100 ships to loot the coasts of the Peloponnese and charged the cavalry to guard the ravaged farms close to the walls of the city. When the enemy retired and the pillaging came to an end, Pericles proposed a decree according to which the authorities of the city should put aside 1,000 talents and 100 ships, in case Athens was attacked by naval forces. According to the most stringent provision of the decree, even proposing a different use of the money or ships would entail the penalty of death. During the autumn of 431 BC, Pericles led the Athenian forces that invaded Megara and a few months later (winter of 431–430 BC) he delivered his monumental and emotional Funeral Oration, honoring the Athenians who died for their city.
Last military operations and death.
In 430 BC, the army of Sparta looted Attica for a second time, but Pericles was not daunted and refused to revise his initial strategy. Unwilling to engage the Spartan army in battle, he again led a naval expedition to plunder the coasts of the Peloponnese, this time taking 100 Athenian ships with him. According to Plutarch, just before the sailing of the ships an eclipse of the sun frightened the crews, but Pericles used the astronomical knowledge he had acquired from Anaxagoras to calm them. In the summer of the same year an epidemic broke out and devastated the Athenians. The exact identity of the disease is uncertain, typhus or typhoid fever are suspected, but this has been the source of much debate. In any case, the city's plight, caused by the epidemic, triggered a new wave of public uproar, and Pericles was forced to defend himself in an emotional final speech, a rendition of which is presented by Thucydides. This is considered to be a monumental oration, revealing Pericles' virtues but also his bitterness towards his compatriots' ingratitude. Temporarily, he managed to tame the people's resentment and to ride out the storm, but his internal enemies' final bid to undermine him came off; they managed to deprive him of the generalship and to fine him at an amount estimated between 15 and 50 talents. Ancient sources mention Cleon, a rising and dynamic protagonist of the Athenian political scene during the war, as the public prosecutor in Pericles' trial.
Nevertheless, within just a year, in 429 BC, the Athenians not only forgave Pericles but also re-elected him as strategos. He was reinstated in command of the Athenian army and led all its military operations during 429 BC, having once again under his control the levers of power. In that year, however, Pericles witnessed the death of both his legitimate sons from his first wife, Paralus and Xanthippus, in the epidemic. His morale undermined, he burst into tears and not even Aspasia's companionship could console him. He himself died of the plague in the autumn of 429 BC.
Just before his death, Pericles' friends were concentrated around his bed, enumerating his virtues during peace and underscoring his nine war trophies. Pericles, though moribund, heard them and interrupted them, pointing out that they forgot to mention his fairest and greatest title to their admiration; "for", said he, "no living Athenian ever put on mourning because of me". Pericles lived during the first two and a half years of the Peloponnesian War and, according to Thucydides, his death was a disaster for Athens, since his successors were inferior to him; they preferred to incite all the bad habits of the rabble and followed an unstable policy, endeavoring to be popular rather than useful. With these bitter comments, Thucydides not only laments the loss of a man he admired, but he also heralds the flickering of Athens' unique glory and grandeur.
Pausanias (c. 150 C.E.) records (I.29) seeing the tomb of Pericles along a road near the Academy.
Personal life.
Pericles, following Athenian custom, was first married to one of his closest relatives, with whom he had two sons, Paralus and Xanthippus, but around 445 BC, Pericles divorced his wife. He offered her to another husband, with the agreement of her male relatives. The name of his first wife is not known; the only information about her is that she was the wife of Hipponicus, before being married to Pericles, and the mother of Callias from this first marriage.
The woman whom he really adored was Aspasia of Miletus. She became Pericles' mistress and they began to live together as if they were married. This relationship aroused many reactions and even Pericles' own son, Xanthippus, who had political ambitions, did not hesitate to slander his father. Nonetheless, these persecutions did not undermine Pericles' morale, although he had to burst into tears in order to protect his beloved Aspasia when she was accused of corrupting Athenian society. His greatest personal tragedy was the death of his sister and of both his legitimate sons, Xanthippus and Paralus, all affected by the epidemic, a calamity he never managed to overcome.
Just before his death, the Athenians allowed a change in the law of 451 BC that made his half-Athenian son with Aspasia, Pericles the Younger, a citizen and legitimate heir, a decision all the more striking in consideration that Pericles himself had proposed the law confining citizenship to those of Athenian parentage on both sides.
Assessments.
Pericles marked a whole era and inspired conflicting judgments about his significant decisions. The fact that he was at the same time a vigorous statesman, general and orator makes more complex the objective assessment of his actions.
Political leadership.
Some contemporary scholars call Pericles a populist, a demagogue and a hawk, while other scholars admire his charismatic leadership. According to Plutarch, after assuming the leadership of Athens, "he was no longer the same man as before, nor alike submissive to the people and ready to yield and give in to the desires of the multitude as a steersman to the breezes". It is told that when his political opponent, Thucydides, was asked by Sparta's king, Archidamus, whether he or Pericles was the better fighter, Thucydides answered without any hesitation that Pericles was better, because even when he was defeated, he managed to convince the audience that he had won. In matters of character, Pericles was above reproach in the eyes of the ancient historians, since "he kept himself untainted by corruption, although he was not altogether indifferent to money-making".
Thucydides, an admirer of Pericles, maintains that Athens was "in name a democracy but, in fact, governed by its first citizen". Through this comment, the historian illustrates what he perceives as Pericles' charisma to lead, convince and, sometimes, to manipulate. Although Thucydides mentions the fining of Pericles, he does not mention the accusations against Pericles but instead focuses on Pericles' integrity. On the other hand, in one of his dialogues, Plato rejects the glorification of Pericles and quote as saying: "as I know, Pericles made the Athenians slothful, garrulous and avaricious, by starting the system of public fees".
Plutarch mentions other criticism of Pericles' leadership: "many others say that the people were first led on by him into allotments of public lands, festival-grants, and distributions of fees for public services, thereby falling into bad habits, and becoming luxurious and wanton under the influence of his public measures, instead of frugal and self-sufficing".
Thucydides argues that Pericles "was not carried away by the people, but he was the one guiding the people". His judgement is not unquestioned; some 20th-century critics, such as Malcolm F. McGregor and John S. Morrison, proposed that he may have been a charismatic public face acting as an advocate on the proposals of advisors, or the people themselves. According to King, by increasing the power of the people, the Athenians left themselves with no authoritative leader. During the Peloponnesian War, Pericles' dependence on popular support to govern was obvious.
Military achievements.
For more than 20 years Pericles led many expeditions, mainly naval ones. Being always cautious, he never undertook of his own accord a battle involving much uncertainty and peril and he did not accede to the "vain impulses of the citizens". He based his military policy on Themistocles' principle that Athens' predominance depends on its superior naval power and believed that the Peloponnesians were near-invincible on land. Pericles also tried to minimize the advantages of Sparta by rebuilding the walls of Athens, which, it has been suggested, radically altered the use of force in Greek international relations.
During the Peloponnesian War, Pericles initiated a defensive "grand strategy" whose aim was the exhaustion of the enemy and the preservation of the "status quo". According to Platias and Koliopoulos, Athens as the strongest party did not have to beat Sparta in military terms and "chose to foil the Spartan plan for victory". The two basic principles of the "Periclean Grand Strategy" were the rejection of appeasement (in accordance with which he urged the Athenians not to revoke the Megarian Decree) and the avoidance of overextension. According to Kagan, Pericles' vehement insistence that there should be no diversionary expeditions may well have resulted from the bitter memory of the Egyptian campaign, which he had allegedly supported. His strategy is said to have been "inherently unpopular", but Pericles managed to persuade the Athenian public to follow it. It is for that reason that Hans Delbrück called him one of the greatest statesmen and military leaders in history. Although his countrymen engaged in several aggressive actions soon after his death, Platias and Koliopoulos argue that the Athenians remained true to the larger Periclean strategy of seeking to preserve, not expand, the empire, and did not depart from it until the Sicilian Expedition. For his part, Ben X. de Wet concludes his strategy would have succeeded had he lived longer.
Critics of Pericles' strategy, however, have been just as numerous as its supporters. A common criticism is that Pericles was always a better politician and orator than strategist. Donald Kagan called the Periclean strategy "a form of wishful thinking that failed", Barry S. Strauss and Josiah Ober have stated that "as strategist he was a failure and deserves a share of the blame for Athens' great defeat", and Victor Davis Hanson believes that Pericles had not worked out a clear strategy for an effective offensive action that could possibly force Thebes or Sparta to stop the war. Kagan criticizes the Periclean strategy on four counts: first that by rejecting minor concessions it brought about war; second, that it was unforeseen by the enemy and hence lacked credibility; third, that it was too feeble to exploit any opportunities; and fourth, that it depended on Pericles for its execution and thus was bound to be abandoned after his death. Kagan estimates Pericles' expenditure on his military strategy in the Peloponnesian War to be about 2,000 talents annually, and based on this figure concludes that he would only have enough money to keep the war going for three years. He asserts that since Pericles must have known about these limitations he probably planned for a much shorter war. Others, such as Donald W. Knight, conclude that the strategy was too defensive and would not succeed.
On the other hand, Platias and Koliopoulos reject these criticisms and state that "the Athenians lost the war only when they dramatically reversed the Periclean grand strategy that explicitly disdained further conquests". Hanson stresses that the Periclean strategy was not innovative, but could lead to a stagnancy in favor of Athens. It is a popular conclusion that those succeeding him lacked his abilities and character.
Oratorical skill.
Modern commentators of Thucydides, with other modern historians and writers, take varying stances on the issue of how much of the speeches of Pericles, as given by this historian, do actually represent Pericles' own words and how much of them is free literary creation or paraphrase by Thucydides. Since Pericles never wrote down or distributed his orations, no historians are able to answer this with certainty; Thucydides recreated three of them from memory and, thereby, it cannot be ascertained that he did not add his own notions and thoughts.
Although Pericles was a main source of his inspiration, some historians have noted that the passionate and idealistic literary style of the speeches Thucydides attributes to Pericles is completely at odds with Thucydides' own cold and analytical writing style. This might, however, be the result of the incorporation of the genre of rhetoric into the genre of historiography. That is to say, Thucydides could simply have used two different writing styles for two different purposes.
Ioannis Kakridis and Arnold Gomme were two scholars who debated the originality of Pericles’ oratory and last speech. Kakridis believes that Thucydides altered Pericles words. Some of his strongest arguments included in the Introduction of the speech, (Thuc.11.35). Kakridis proposes that it is impossible to imagine Pericles deviating away from the expected funeral orator addressing the mourning audience of 430 after the Peloponnesian war. The two groups addressed were the ones who were prepared to believe him when he praised the dead, and the ones who did not. Gomme rejects Kakridis position, defending the fact that "Nobody of men has ever been so conscious of envy and its workings as the Greeks, and that the Greeks and Thucydides in particular had a passion for covering all ground in their generalizations, not always relevantly.".
Kagan states that Pericles adopted "an elevated mode of speech, free from the vulgar and knavish tricks of mob-orators" and, according to Diodorus Siculus, he "excelled all his fellow citizens in skill of oratory". According to Plutarch, he avoided using gimmicks in his speeches, unlike the passionate Demosthenes, and always spoke in a calm and tranquil manner. The biographer points out, however, that the poet Ion reported that Pericles' speaking style was "a presumptuous and somewhat arrogant manner of address, and that into his haughtiness there entered a good deal of disdain and contempt for others".
Gorgias, in Plato's homonymous dialogue, uses Pericles as an example of powerful oratory. In Menexenus, however, Socrates (through Plato) casts aspersions on Pericles' rhetorical fame, claiming ironically that, since Pericles was educated by Aspasia, a trainer of many orators, he would be superior in rhetoric to someone educated by Antiphon. He also attributes authorship of the Funeral Oration to Aspasia and attacks his contemporaries' veneration of Pericles.
Sir Richard C. Jebb concludes that "unique as an Athenian statesman, Pericles must have been in two respects unique also as an Athenian orator; first, because he occupied such a position of personal ascendancy as no man before or after him attained; secondly, because his thoughts and his moral force won him such renown for eloquence as no one else ever got from Athenians".
Ancient Greek writers call Pericles "Olympian" and extol his talents; referring to him "thundering and lightening and exciting Greece" and carrying the weapons of Zeus when orating. According to Quintilian, Pericles would always prepare assiduously for his orations and, before going on the rostrum, he would always pray to the Gods, so as not to utter any improper word.
Legacy.
Pericles' most visible legacy can be found in the literary and artistic works of the Golden Age, most of which survive to this day. The Acropolis, though in ruins, still stands and is a symbol of modern Athens. Paparrigopoulos wrote that these masterpieces are "sufficient to render the name of Greece immortal in our world".
In politics, Victor L. Ehrenberg argues that a basic element of Pericles' legacy is Athenian imperialism, which denies true democracy and freedom to the people of all but the ruling state. The promotion of such an arrogant imperialism is said to have ruined Athens. Pericles and his "expansionary" policies have been at the center of arguments promoting democracy in oppressed countries.
Other analysts maintain an Athenian humanism illustrated in the Golden Age. The freedom of expression is regarded as the lasting legacy deriving from this period. Pericles is lauded as "the ideal type of the perfect statesman in ancient Greece" and his Funeral Oration is nowadays synonymous with the struggle for participatory democracy and civic pride.
External links.
Biographies
Pericles and the Athenian democracy
Further assessments about Pericles and his era

</doc>
<doc id="36816" url="https://en.wikipedia.org/wiki?curid=36816" title="The Three Stooges">
The Three Stooges

The Three Stooges were an American vaudeville and comedy act of the mid–20th century, best known for their numerous Columbia short subject films that are still syndicated on television. Their hallmark was physical farce and slapstick. In films, the Stooges were commonly known by their first names of "Moe, Larry, and Curly", "Moe, Larry, and Shemp," or "Larry, Moe and Curly Joe" (among other lineups, depending on the particular film). There were six active stooges with only three in the act at any given time, five of whom performed in the shorts. Larry and Moe were always present during the film era through the final years of the ensemble's run of more than forty years. 
The act began as part of a mid-1920s vaudeville comedy act, billed as Ted Healy and his Stooges, consisting of Healy, Moe Howard, his brother Shemp Howard, and Larry Fine. The four made one feature film, "Soup to Nuts", before Shemp left to pursue a solo career. He was replaced by his younger brother, Jerome (Curly Howard), in 1932. Two years later, the trio left Healy and signed on to appear in their own short subjects for Columbia, now billed as "The Three Stooges".
Curly suffered a debilitating stroke in May 1946, and Shemp returned, reinstating the original lineup, until his death of a heart attack in November 1955. Film actor Joe Palma was used as a temporary stand-in to complete four Shemp-era shorts under contract (the maneuver thereafter became known as the term of art "Fake Shemp"). Columbia contract player Joe Besser joined as the third Stooge for two years (1956–57), departing in 1958 to nurse his ailing wife. Columbia terminated its shorts division and released its Stooges contractual rights to the Screen Gems production studio. Screen Gems then syndicated the shorts to television, and the Stooges became one of the most popular comedy acts of the early 1960s.
Comic actor Joe DeRita became "Curly Joe" in 1958, replacing Besser for a new series of full-length theatrical films. With intense television exposure, the act regained momentum throughout the 1960s as popular kiddie fare, until Larry Fine's paralyzing stroke in January 1970. Fine died in 1975 after a further series of strokes. Moe tried to revive the Stooges with longtime supporting actor Emil Sitka in Larry's role in 1970, and again in 1975, but this attempt was cut short by Moe's death in May 1975.
History.
Ted Healy and his Stooges (1928–34).
The Three Stooges started in 1928 as part of a raucous vaudeville act called "Ted Healy and His Stooges" (also known as "Ted Healy and His Southern Gentlemen", "Ted Healy and His Three Lost Souls", "Ted Healy and His Racketeers", and "Ted Healy and His Three Stooges".) Moe Howard (born Moses Harry Horwitz) joined Healy's act in 1921, and his brother Shemp Howard (Samuel Horwitz) came aboard in 1923. In 1928, violinist-comedian Larry Fine (Louis Feinberg) and xylophonist-comedian Fred Sanborn also joined the group. In the act, lead comedian Healy would attempt to sing or tell jokes while his noisy assistants would keep "interrupting" him, causing Healy to retaliate with verbal and physical abuse.
In 1930, Ted Healy and His Stooges (including Sanborn) appeared in their first Hollywood feature film, "Soup to Nuts", released by Fox Film Corporation. The film was not a critical success, but the Stooges' performances were singled out as memorable, leading Fox to offer the trio a contract minus Healy. This enraged Healy, who told studio executives that the Stooges were his employees, and the offer was withdrawn. Howard, Fine, and Howard learned of the offer and subsequent withdrawal and left Healy to form their own act, which quickly took off with a tour of the theater circuit. Healy attempted to stop the new act with legal action, claiming that they were using his copyrighted material. There are accounts of Healy threatening to bomb theaters if Howard, Fine, and Howard ever performed there, which worried Shemp so much that he almost left the act; reportedly, only a pay raise kept him on board. 
Healy tried to save his act by hiring replacement stooges, but they were inexperienced and not as well-received as their predecessors. Healy reached a new agreement with his former Stooges in 1932, with Moe now acting as business manager, and they were booked in a production of Jacob J. Shubert's "The Passing Show of 1932". During rehearsals, Healy received a more lucrative offer and found a loophole in his contract allowing him to leave the production. Shemp, fed up with Healy's abrasiveness, decided to quit the act and toured in his own comedy revue for several months, and then landed at Vitaphone Studios in May 1933, appearing in movie comedies produced in Brooklyn, New York, for the next four years.
With Shemp gone, Healy and the two remaining stooges (Moe and Larry) needed a replacement, so Moe suggested his younger brother Jerry Howard. Healy reportedly took one look at Jerry, who had long chestnut red locks and a handlebar mustache, and remarked that he did not look like he was funny. Jerry left the room and returned a few moments later with his head shaved (though his mustache remained for a time), and then quipped "Boy, do I look girly." Healy heard "Curly", and the name stuck. (There are varying accounts as to how the Curly character actually came about.)
In 1933, Metro-Goldwyn-Mayer (MGM) signed Healy and his Stooges to a movie contract. They appeared in feature films and short subjects, either together, individually, or with various combinations of actors. The trio was featured in a series of musical comedy shorts, beginning with "Nertsery Rhymes". The short was one of a few shorts to be made with an early two-strip Technicolor process, including one featuring Curly without Healy or the other Stooges, "Roast Beef and Movies" (1934). The shorts themselves were built around recycled film footage of production numbers cut from MGM musicals, such as "Children of Pleasure", "Lord Byron of Broadway", and the unfinished "March of Time" (all 1930), which had been filmed in early Technicolor. Soon, additional shorts followed (sans the experimental Technicolor), including "Beer and Pretzels" (1933), "Plane Nuts" (1933), "Jail Birds of Paradise" (1934), and "The Big Idea" (1934).
Healy and company also appeared in several MGM feature films as comic relief, such as "Turn Back the Clock" (1933); "Meet the Baron" (1933); "Dancing Lady" (1933) with Joan Crawford, Clark Gable, Fred Astaire and Robert Benchley; "Fugitive Lovers" (1934); and "Hollywood Party" (1934). Healy and the Stooges also appeared together in "Myrt and Marge" for Universal Pictures.
In 1934, the team's contract expired with MGM, and the Stooges parted professional company with Healy. According to Moe Howard's autobiography, the Stooges split with Healy in 1934 once and for all because of Healy's alcoholism and abrasiveness. Their final film with Healy was MGM's "Hollywood Party" in 1934. Both Healy and the Stooges went on to separate successes, with Healy dying under mysterious circumstances in 1937.
Columbia years.
Moe, Larry, and Curly (1934–46).
In 1934, the trio—now officially named "The Three Stooges"—signed on to appear in two-reel comedy short subjects for Columbia Pictures. Moe wrote in his autobiography that they each received $600 per week on a one-year contract with a renewable option; in the Ted Okuda–Edward Watz book "The Columbia Comedy Shorts", the Stooges are said to have received $1,000 among them for their first Columbia effort, "Woman Haters", and then signed a term contract for $7,500 per film (equal to $ today), to be divided among the trio.
Within their first year at Columbia, the Stooges became wildly popular. Realizing this, Columbia Pictures president Harry Cohn used the Stooges as leverage, as the demand for their films was so great that he eventually refused to supply exhibitors with the trio's shorts unless they also agreed to book some of the studio's mediocre B movies. Cohn also saw to it that the Stooges remained ignorant of their popularity. During their 23 years at Columbia, the Stooges were never completely aware of their amazing drawing power at the box office. Their contracts with the studio included an open option that had to be renewed yearly, and Cohn would tell the boys that the short subjects were in decline, which was not a complete fabrication (Cohn's yearly mantra was "the market for comedy shorts is dying out, fellas"). The Stooges thought that their days were numbered and would cruelly sweat it out each year, with Cohn renewing their contract at the eleventh hour. This deception kept the insecure Stooges unaware of their true value, resulting in them having second thoughts about asking for a better contract without a yearly option. Cohn's scare tactics worked for all 23 years that the Stooges were at Columbia; the team never once asked for a salary increasenor were they ever given one. It was not until after they stopped making the shorts in December 1957 that Moe learned of Cohn's underhanded tactics, what a valuable commodity the Stooges had been for the ailing studio, and how many millions more the act could have earned. Columbia offered theater owners an entire program of two-reel comedies (15-25 titles annually) featuring such stars as Buster Keaton, Andy Clyde, Charley Chase, and Hugh Herbert, but the Stooge shorts were the most popular of all.
The Stooges were required to release up to eight short films per year within a 40-week period; for the remaining 12 or so weeks, they were free to pursue other employment, time which was either spent with their families or touring the country to promote their live act. The Stooges appeared in 190 film shorts and five features while at Columbia, outlasting every one of their contemporaries employed in the short film genre. Del Lord directed more than three dozen Stooge films; Jules White directed dozens more, and his brother Jack White directed several under the pseudonym "Preston Black". Silent film star Charley Chase also shared directorial responsibilities with Lord and White.
The Stooge films made between 1935 and 1941 captured the team at the peak, according to film historians Ted Okuda and Edward Watz, authors of "The Columbia Comedy Shorts". Nearly every film produced became a classic in its own right. 1935's "Hoi Polloi" adapted the premise of "Pygmalion", with a stuffy professor making a bet that he can transform the uncultured trio into refined gentlemen; the plotline worked so well that it was reused twice, as "Half-Wits Holiday" and "Pies and Guys". "Three Little Beers" featured the team employed at a brewery who then run amuck on a local golf course to win prize money. 1936's "Disorder in the Court" features the team as star witnesses in a murder trial. 1938's "Violent is the Word for Curly" was a quality Chase-directed short that featured the musical interlude "Swinging the Alphabet". In the 1940 film "A Plumbing We Will Go"one of the team's quintessential comediesthe Stooges are cast as plumbers who nearly destroy a socialite's mansion, causing water to exit every appliance in the home. Other entries of the era are considered among the team's finest work, including "Uncivil Warriors", "A Pain in the Pullman", "False Alarms", "Grips, Grunts and Groans", "The Sitter Downers", "Dizzy Doctors", "Tassels in the Air", "We Want Our Mummy", "Nutty but Nice", "An Ache in Every Stake", and "In the Sweet Pie and Pie".
With the onset of World War II, the Stooges released several entries that poked fun at the rising Axis powers. "You Nazty Spy!" and its sequel "I'll Never Heil Again" burlesqued Hitler and the Nazis at a time when America was still neutral and resolutely isolationist. Moe is cast as "Moe Hailstone", an Adolf Hitler-like character, with Curly playing a Hermann Göring character (replete with medals), and Larry a Joachim von Ribbentrop-type ambassador. The film is revered by Stooge fans as well as the Stooges themselves Moe, Larry, and director Jules White considered "You Nazty Spy!" their best film. These efforts indulged in a deliberately formless, non-sequitur style of verbal humor that was not the Stooges' forte, according to Okuda and Watz.
Other wartime entries have their moments, such as "They Stooge to Conga" (the most violent Stooge short), "Higher Than a Kite", "Back From the Front", "Gents Without Cents", and the controversial "The Yoke's on Me". However, taken in bulk, the wartime films are decidedly substandard. "No Dough Boys" ranks as the best of these farces. The team, made up as Japanese soldiers for a photo shoot, is mistaken for genuine saboteurs by a Nazi ringleader (Vernon Dent). The highlight of the film features the Stooges engaging in nonsensical gymnastics (the real spies are renowned acrobats) for a skeptical group of enemy agents.
The World War II era also brought on rising production costs that resulted in a reduced number of elaborate gags and outdoor sequences, Del Lord's stock in trade; as such, the quality of the teams' films (particularly those directed by Lord) began to slip after 1942. According to Okuda and Watz, entries such as "Loco Boy Makes Good", "What's the Matador?", "Sock-A-Bye Baby", "I Can Hardly Wait", and "A Gem of a Jam" are considered to be less quality work than previous efforts, and in a different class than their earlier films. The 1943 film "Spook Louder", a remake of Mack Sennett's "The Great Pie Mystery", is often cited as their worst film. The story of a phantom pie-thrower (later revealed to be the detective on the case) is repetitious and relying on the same jokes, which many Stooge fans consider to be far less humorous than their past work. "Three Smart Saps", a film considered to be an improvement, features a reworking of a routine from Harold Lloyd's "The Freshman", in which Curly's loosely basted suit begins to come apart at the seams while he is on the dance floor.
The Stooges made occasional guest appearances in feature films, though generally they were restricted to their short subjects. Most of the Stooges' peers had either made the transition from shorts to features films (Laurel and Hardy, The Ritz Brothers) or had been starring their own feature films from the onset (The Marx Brothers, Abbott and Costello). However, Moe believed that the team's firebrand style of humor worked better in short form. In 1935, Columbia proposed to star them in their own full-length feature, but Moe rejected the idea saying, "It's a hard job inventing, rewriting, or stealing gags for our two-reel comedies for Columbia Pictures without having to make a seven-reeler (feature film). We can make short films out of material needed for a starring feature and then we wouldn't know whether it would be funny enough to click."
Film critics and stooge fans alike have cited Curly as the most popular member of the team. His childlike mannerisms and natural comedic charm (he had no previous acting experience) made him a hit with audiences, particularly children and women (the latter usually finding the trio's humor juvenile and uncouth). The fact that Curly had to shave his head for the act led him to feel unappealing to women. To mask his insecurities, he ate and drank to excess and caroused whenever the Stooges made personal appearances, which was approximately seven months out of the year. His weight ballooned in the 1940s, and his blood pressure became dangerously high. His wild lifestyle and constant drinking eventually caught up with him in 1945, and his performances suffered.
Michael Fleming incorrectly stated in his book that, after suffering a stroke, "Moe felt it best Curly take a leave of absence to recover, but Harry Cohn adamantly refused to allow it, forcing Curly to continue the already-taxing work in his ill-health." Actually, their Columbia schedule provided five months off from August 1945 thru January 1946. Rather than rest, the trio committed themselves to making a feature film at Monogram, followed by a two-month-long live appearance gig in New York City with performances seven days a week. Curly also entered a disastrous third marriage in October, leading to a separation in January 1946 and divorce in July 1946. That unhappy union wrecked his already fragile health. Upon their return to Los Angeles in late November 1945, Curly was a shell of his former self. They had two months to rest before reporting back to Columbia in late January 1946, but Curly's condition was irreversible. They had only 24 days work over the next three months, but eight weeks of time off could not help the situation. In those last six shorts (ranging from 1946's "Monkey Businessmen" through 1947's "Half-Wits Holiday"), he was seriously ill, struggling to get through even the most basic scenes.
During the final day of filming "Half-Wits Holiday" on May 6, 1946, he suffered a debilitating stroke on the set, ending his 14-year career and temporarily forcing the Stooges into retirement. They hoped for a full recovery, but Curly never appeared in a film again except for a single cameo appearance in the third film after Shemp returned to the trio, "Hold That Lion!" It was the only film that contained all four of the original Stooges (the three Howard brothers and Larry) on screen simultaneously. According to Jules White, this anomaly came about when Curly visited the set one day, and White had him do this bit for fun. (Curly's cameo appearance was recycled in the 1953 remake "Booty and the Beast".) In 1948, Curly filmed a brief scene for "Malice in the Palace" as the restaurant's cook, but it was not used in the final print of the film. Jules White's copy of the script contained the dialogue for this missing scene. A production still of Curly does exist, appearing on both the film's original one-sheet and lobby card. Larry played the role of the cook in the final print,which was released the following year.
Shemp's return (1947–55).
Moe asked older brother Shemp to take Curly's place, but Shemp was hesitant to rejoin the Stooges as he was enjoying a successful solo career. He realized, however, that not rejoining the Stooges would mean the end of Moe's and Larry's film careers. Shemp wanted assurance that rejoining them would be only temporary, and that he could leave the Stooges once Curly recovered. However, Curly's health continued to deteriorate, and it became clear that he could not return. The Stooges turned to comedian Buddy Hackett as a replacement, but Hackett declined, and Shemp remained a Stooge. Curly remained ill until his death of a cerebral hemorrhage from additional strokes on January 18, 1952.
Shemp appeared with the Stooges in 76 shorts and a low-budget Western comedy feature titled "Gold Raiders" in which the screen time was evenly divided with B-picture cowboy hero George O'Brien. Shemp's return improved the quality of the films, as the last few with Curly had been marred by his sluggish performances. Entries such "Out West", "Squareheads of the Round Table", and "Punchy Cowpunchers" proved that there was life after Curly and that Shemp could easily hold his own. This was due in part to the presence of new director Edward Bernds, who joined the team in 1945 when Curly was failing. Bernds sensed that routines and plotlines that worked well with Curly as the comic focus did not fit Shemp's persona, and allowed the comedian to develop his own Stooge characterization. Jules White, however, persisted in employing the "living cartoon" style of comedy that reigned during the Curly era. White would force either Shemp or Moe to perform similar gags and mannerisms originated by Curly, resulting in what appeared to be lackluster imitation. Most acutely, it created the "Curly vs. Shemp" debate that overshadowed the act upon Curly's departure. The Stooges lost some of their charm and inherent appeal to children after Curly retired, but some excellent films were produced with Shemp, a comedian who often performed best when allowed to improvise on his own.
Unlike the Curly era, the films from the Shemp era contrast sharply, due to the individual directing styles of Bernds and White. From 1947 to 1952, Bernds hit a string of successes, including "Fright Night", "The Hot Scots", "Mummy's Dummies", "Crime on Their Hands", "A Snitch in Time", "Three Arabian Nuts", and "Gents in a Jam". Two of the team's finest efforts were directed by Bernds: "Brideless Groom" and "Who Done It?". White also contributed a few par entries, such as "Hold That Lion!", "Hokus Pokus", "Scrambled Brains", "A Missed Fortune", and "Corny Casanovas".
Another benefit from the Shemp era was that Larry was given more time on screen. Throughout most of the Curly era, Larry was relegated to a background role, being called upon only to break up a potential scuffle between Moe and Curly. By the time that Shemp rejoined the Stooges, Larry was allotted equal footage, even becoming the focus of several films ("Fuelin' Around", "He Cooked His Goose").
The Shemp years also marked a major milestone: the Stooges' first appearance on television. In 1948, they guest starred on Milton Berle's popular "Texaco Star Theater" and Morey Amsterdam's "The Morey Amsterdam Show". By 1949, the team filmed a pilot for ABC-TV for their own weekly television series, titled "Jerks of All Trades". It never sold, but their slapstick humor was in great demand on television programs looking to fill air space. The team went on to appear on "Camel Comedy Caravan" (also known as "The Ed Wynn Show"), "The Kate Smith Hour", "The Colgate Comedy Hour", "The Frank Sinatra Show", and "The Eddie Cantor Comedy Theatre", among others.
In 1952, however, the Stooges lost some key players at Columbia. The studio decided to downsize its short subject division, resulting in producer Hugh McCollum being discharged and director Edward Bernds resigning out of loyalty to McCollum. Bernds had been contemplating his resignation for some time, as he and Jules White were often at odds. Screenwriter Elwood Ullman followed suit, leaving only White to both produce and direct the Stooges' remaining Columbia comedies. Not long after, the quality of the team's output markedly declined with White now assuming complete control over production. DVD Talk critic Stuart Galbraith IV commented that "the Stooges' shorts became increasingly mechanical...and frequently substituted violent sight gags for story and characterization." Production was also significantly faster, with the former four-day filming schedules now tightened to two or three days. In another cost-cutting measure, White would create a "new" Stooge short by borrowing footage from old ones, setting it in a slightly different storyline, and filming a few new scenes often with the same actors in the same costumes. White was initially very subtle when recycling older footage: he would reuse only a single sequence of old film, re-edited so cleverly that it was not easy to detect. The later shorts were cheaper and the recycling more obvious, with as much as 75% of the running time consisting of old footage. White came to rely so much on older material that he could film the "new" shorts in a single day. Plus, any new footage filmed in order to link older material suffered from White's wooden directing style and penchant for telling his actors how to act. Shemp in particular disliked working with White after 1952.
Three years after Curly's death, Shemp died of a sudden heart attack at age 60 on November 22, 1955 during a taxi ride home with a friend after attending a boxing match. Moe was stunned and contemplated disbanding the Stooges. However, Cohn reminded him that the team owed Columbia four additional films with Shemp. Recycled footage, combined with new footage utilizing Columbia supporting player Joe Palma as Shemp's double (filmed from the back), were used to complete the last four films originally planned with Shemp: "Rumpus in the Harem", "Hot Stuff", "Scheming Schemers", and "Commotion on the Ocean".
Joe Besser replaces Shemp (1956–57).
After Shemp's death, Moe and Larry were again in need of a third Stooge. Several comedians were considered (Including Mantan Moreland), but Columbia insisted on a comedian already under contract. They decided on Joe Besser, who appeared in the final 16 Stooge shorts at Columbia. Besser had been starring in his own short-subject comedies for the studio since 1949 and appeared in supporting roles in a variety of movies, making his persona sufficiently well known.
Besser had noted how one side of Larry Fine's face appeared "calloused", so he had a clause in his contract specifically prohibiting him from being hit beyond an infrequent tap (though this restriction was later lifted). Besser was the only Stooge who dared to hit Moe back in retaliation. "I usually played the kind of character who would hit others back", Besser recalled.
Despite Besser's prolific film and stage career, Stooge entries featuring him have often been tagged as the team's weakest. During his tenure, the films were being assailed for being questionable models for youth, and in response began to resemble television sitcoms. Sitcoms, however, were available for free on television, making the short film a throwback to a bygone era. Besser was a talented comic, and was quite popular as "Stinky" on "The Abbott and Costello Show". But his whining mannerisms did not quite blend with the Stooges' brand of humor, though it did create the verbal friction between Moe and Larry which succeeded in making put-down banter. Times had changed, and Besser was not solely to blame for the quality of these final entries; the scripts were rehashes of earlier efforts, the budgets were lower, and Moe's and Larry's advanced ages prohibited them from performing the physical comedy that they once had. Besser had suggested that Moe and Larry comb their hair back to give them a more gentlemanly appearance. Both Moe and Jules White approved of the idea, but used it sparingly in order to match the old footage in films that were remakes.
Despite their poor reputation, the Besser shorts did have their comedic moments. In general, the remakes had the traditional Stooges knockabout look and feel, such as "Pies and Guys" (a scene-for-scene remake of "Half-Wits Holiday", which itself was a reworking of the earlier "Hoi Polloi"), "Guns a Poppin", "Rusty Romeos", and "Triple Crossed." In contrast, "Hoofs and Goofs", "Horsing Around", and "Muscle Up a Little Closer" mostly resembled the sitcoms of the era. "A Merry Mix Up" and "Oil's Well That Ends Well" are also amusing, while the musical "Sweet and Hot" (long detested by fans) deserves some credit for straying from the norm. The space craze also took hold of the American public at the time, resulting in three entries focusing on space travel: "Space Ship Sappy", "Outer Space Jitters", and "Flying Saucer Daffy."
Columbia was the last studio still producing live-action and two-reel short films (other studios were still making animated one-reelers well into the 1960s), and the market for such films had all but dried up. As a result, the studio opted not to renew the Stooges' contract when it expired in December 1957. The final comedy produced was "Flying Saucer Daffy", filmed on December 19–20, 1957. Several days later, the Stooges were unceremoniously fired from Columbia Pictures after 24 years of making low-budget shorts.
No formal "goodbyes" or congratulatory celebrations occurred in recognition of their many years of dedication, service, and the dollars that their comedies had earned for the studio. Moe visited Columbia several weeks after their dismissal to say goodbye to several executives. He was stopped by a guard at the gate, as he did not have the current year's studio pass. Moe was refused entry, later stating that it was a momentary crushing blow to his pride.
The studio had enough completed Stooge films to be released over the next 18 months, though not in the order in which they were produced. The final Stooge release, "Sappy Bull Fighters", did not reach theaters until June 4, 1959. With no active contract in place, Moe and Larry discussed plans for a personal appearance tour. In the meantime, Besser's wife suffered a minor heart attack and he preferred to stay local, leading him to withdraw from the act.
After Besser's departure, Moe and Larry began looking for potential replacements. Larry suggested former Ted Healy stooge Paul "Mousie" Garner, but based on his tryout performance, Moe later remarked that he was "completely unacceptable." Weeks later, Larry came across burlesque performer Joe DeRita, and thought he would be a good fit.
Comeback with Joe DeRita (1958–70).
The early days of television provided movie studios a place to unload a backlog of short films which they thought otherwise unmarketable, and the Stooge films seemed perfect for the burgeoning genre. ABC had even expressed interest as far back as 1949, purchasing exclusive rights to 30 of the trio's shorts and commissioning a pilot for a potential series, "Jerks of All Trades". However, the success of television revivals for such names as Laurel and Hardy, Woody Woodpecker, Popeye, Tom and Jerry, and the "Our Gang" series in the late 1950s led Columbia to cash in again on the Stooges. In January 1958, Columbia's television subsidiary Screen Gems offered a package consisting of 78 Stooge shorts (primarily from the Curly era) which were well received. Almost immediately, an additional 40 shorts hit the market, and by 1959, all 190 Stooge shorts were airing regularly. The films were broadcast Monday through Friday due to the massive quantity of Stooge product available, and this led to heavy exposure aimed squarely at children. Parents who had grown up seeing the same films in the theaters began to watch alongside their children and, before long, Howard, Fine and DeRita were in high demand. After it was discovered that the Curly era shorts were the most popular, Moe suggested that DeRita shave his head to accentuate his slight resemblance to Curly Howard. He adopted first a crew cut and later a completely shaven head, thus becoming "Curly Joe".
This lineup, now frequently referred to as "Larry, Moe and Curly Joe," starred in six full-length feature films from 1959 to 1965: "Have Rocket, Will Travel" (1959), "Snow White and the Three Stooges" (1961), "The Three Stooges Meet Hercules" (1962), "The Three Stooges in Orbit" (1962), "The Three Stooges Go Around the World in a Daze" (1963), and "The Outlaws IS Coming!" (1965). The films were aimed at the kiddie-matinee market, and most were black and white farce outings in the Stooge tradition, with the exception of "Snow White and the Three Stooges", a children's fantasy in Technicolor. They also appeared in an extremely brief cameo as firemen (the role that helped make the original Stooges lineup famous in "Soup to Nuts") in the film "It's a Mad, Mad, Mad, Mad World" in 1963, and in a larger capacity that same year in "4 for Texas" starring Frank Sinatra and Dean Martin. Throughout the early 1960s, the Stooges were one of the most popular and highest-paid live acts in America.
The Stooges also tried their hand at another weekly television series in 1960 titled "The Three Stooges Scrapbook", filmed in color and with a laugh track. The first episode "Home Cooking" featured the boys rehearsing for a new television show. Like "Jerks of All Trades", the pilot did not sell. However, Norman Maurer was able to reuse the footage (reprocessed in black and white) for the first 10 minutes of the "The Three Stooges in Orbit".
The trio also filmed 41 short comedy skits for "The New Three Stooges", which features a series of 156 animated cartoons produced for television. The Stooges appeared in live-action color footage, which preceded and followed each animated adventure in which they voiced their respective characters.
Final years (1970–75).
In late 1969, Howard, Fine and DeRita began production on another half-hour pilot, this time for a syndicated 39-episode TV series titled "Kook's Tour", a combination travelogue-sitcom that had the "retired" Stooges traveling various parts of the world with the episodes filmed on location. On January 9, 1970, during production of the pilot, Larry suffered a paralyzing stroke, ending his acting career along with plans for the television series. The pilot was unfinished and several key shots were missing, but producer Norman Maurer edited the available footage and made the pilot a 52-minute special that was released to the Cartrivision videocassette home video market in 1973. It is the last film in which the Stooges appeared and the last known performance of the team.
Later that year, Moe Howard's grandson Jeffrey Scott wrote a feature film script titled "Make Love, Not War". Moe Howard, Joe DeRita, and Emil Sitka were cast as POWs in a World War II Japanese prison camp, plotting an escape with fellow prisoners. The film would have been a departure from typical Stooge fare, with dark-edged humor and scenes of war violence, but production never advanced beyond the script stage.
In 1974, DeRita invited Howard and Paul "Mousie" Garner to join him in a nightclub act, but Howard's wife refused. He instead recruited vaudeville veteran Frank Mitchell and toured as "The New Three Stooges". Garner had worked with Ted Healy as one of his "replacement stooges" and was considered as Joe Besser's original replacement in 1958. Mitchell had also replaced Shemp as the "third stooge" in a 1929 Broadway play and appeared in two of the Stooges' short subjects in 1953. DeRita later said that the act fared poorly with minimal bookings.
Larry suffered another stroke in mid-December 1974, and four weeks later an even more massive one. After slipping into a coma, he died a week later from a cerebral hemorrhage on January 24, 1975.
Before Larry's death, the Stooges were scheduled to co-star in the R-rated film "Blazing Stewardesses". Originally, Moe and Curly Joe were to appear with Larry, who would participate in a wheel chair. After Larry died in January 1975, long-time Stooge foil Emil Sitka stepped into the middle spot as 'Harry,' Larry's brother. The team was signed and publicity shots were taken, but one week prior to March's filming date, Moe fell ill from lung cancer and the Stooges had to back out; he died on May 4, 1975. Producer Sam Sherman briefly considered having former Stooge Joe Besser appear in place of him, but ultimately decided against it. The surviving Ritz Brothers replaced the Stooges and performed much of their act's schtick, including the precision dance routine, first seen in "Sing, Baby, Sing" (1936) co-starring original Stooge leader Ted Healy.
Joe Besser died of heart failure on March 1, 1988, followed by Joe DeRita of pneumonia on July 3, 1993. Emil Sitka was announced as a Stooge but never performed as such; he died of a stroke on January 16, 1998.
Legacy and perspective.
Over half a century since their last short film was released, the Three Stooges remain popular with audiences. Their films have never left the television airwaves since first appearing in 1958, and they continue to delight old fans while attracting new admirers. They were a hard-working group of working-class comedians who were never the critics' darlings, a durable act who endured several personnel changes in their careers which would have permanently sidelined a less-persistent act. The Stooges would not have lasted as long as they did as a unit without Moe Howard's guiding hand.
The Ted Okuda and Edward Watz book "The Columbia Comedy Shorts" puts the Stooges' legacy in critical perspective:
Beginning in the 1980s, the Stooges finally began to receive critical recognition. The release of nearly all their films on DVD by 2010 has allowed critics of Joe Besser and Joe DeRitaoften the recipients of significant fan backlashto appreciate the unique style of comedy that both men brought to the Stooges. In addition, the DVD market in particular has allowed fans to view the entire Stooge film corpus as distinct periods in their long, distinguished career instead of comparing one Stooge to the other (the Curly vs. Shemp debate continues to this day).
The team appeared in 220 films. In the end, it is the durability of the 190 timeless short films the Stooges made at Columbia Pictures that acts as an enduring tribute to the comedy team. Their continued popularity worldwide has proven to even the most skeptical critics that their films are funny. American television personality Steve Allen went on record in the mid-1980s saying, "though they never achieved widespread critical acclaim, they achieved exactly what they had always intended to do: they made people laugh."
Lineups on film.
Moe Howard
Real Name: Moses Harry Horwitz
Born: 
Died: 
Cause of death: Lung cancer
Stooge years: 1921–1969
Larry Fine
Real Name: Louis Feinberg
Born: 
Died: 
Cause of death: Stroke
Stooge years: 1928–1969
Shemp Howard 
Real Name: Samuel Horwitz
Born: 
Died: 
Cause of death: Heart attack
Stooge years: 1923–1932, 1946–1955
Curly Howard
Real Name: Jerome Lester Horwitz
Born: 
Died: 
Cause of death: Cerebral hemorrhage
Stooge years: 1932–1946
Joe Besser
Born: 
Died: 
Cause of death: Heart failure
Stooge years: 1956–1957
Curly Joe DeRita 
Real Name: Joseph Wardell
Born: 
Died: 
Cause of death: Pneumonia
Stooge years: 1958–1969
Filmography.
The Three Stooges appeared in 220 films throughout their career. Of those 220, 190 short films were made for Columbia Pictures between 1934 and 1959, for which the trio are best known. Their contract was extended each year from 1934 until the final one expired on December 31, 1957. The last 8 of the 16 shorts with Joe Besser were released soon afterward.
C3 Entertainment, Inc..
Throughout their career, Moe acted as both their main creative force and business manager. Comedy III (C3) was formed by Moe, Larry and Joe DeRita in 1959 to manage all business and merchandise transactions for the team. C3 was basically in the background, with Moe's son-in-law Norman Maurer managing the comedy teams' film interests under Normandy Productions, and merchandising affairs under Norman Maurer Productions (NMP). Norman Maurer died of cancer in 1986.
In 1994, the heirs of Larry Fine and Joe DeRita filed a breach-of-contract lawsuit against Moe's family, particularly Joan Howard Maurer and her son Jeffrey, who had inherited the NMP/Normandy business. The lawsuit alleged that the Howards had cheated the DeRita and Fine families out of their share of royalties. Howard was ordered to pay $2.6 million in damages; $1.6 million was for compensatory damages to Jean DeRita, while the remaining $1 million was divided between four of Fine's grandchildren. The Fine and DeRita families were represented by California attorney Bela G. Lugosi. Jr.
The resulting 1994 lawsuit led to the reestablishment of C3 as a three-way interest of Fine/Howard/DeRita. The DeRita heirs received the proxy to the Howard share, giving them majority control on the company's management. Joe DeRita's stepsons, Robert and Earl Benjamin, became the senior management of C3, with Lugosi, Jr. serving as an executive board member for several years. The Benjamins later incorporated the company, and C3 is currently the owner of all Three Stooges trademarks and merchandising. Larry's grandson Eric Lamond is the representative of the Fines' one-third interest in the company.
Since 1995, C3 has authorized and provided the services of veteran actors Jim Skousen, Alan Semok, and Dave Knight (as Moe, Larry, and Curly respectively) for numerous "personal appearances" by the Stooge characters for a variety of merchandising and promotional events. This latter-day trio has also provided voices for the characters in a variety of radio spots, merchandising tie-ins, and most recently for the first new Three Stooges short in 50 years. A CGI animation by Famous Frames Mobile Interactive, a first-wave "new media" company, entitled "The Grate Debate", has Moe, Larry and Curly running for President (with Skousen, Semok, and Knight providing the voices for the Stooges).
Television.
A handful of Three Stooges shorts first aired on television in 1949, on the American Broadcasting Company (ABC) network. It was not until 1958 that Screen Gems packaged 78 shorts for national syndication; the package was gradually enlarged to encompass the entire library of 190 shorts. In 1959, KTTV in Los Angeles purchased the Three Stooges films for air, but by the early 1970s, rival station KTLA began airing the Stooges films, keeping them in the schedule until early 1994. The Family Channel ran the shorts as part of their "Stooge TV" block from February 19, 1996, to January 2, 1998. In the late 1990s, AMC had held the rights to the Three Stooges shorts, originally airing them under a programming block called "Stooges Playhouse". In 1999, it was replaced with a program called "N.Y.U.K. (New Yuk University of Knuckleheads)", which starred actor/comedian Leslie Nielsen. The program would show three random Stooge shorts. Nielsen hosts the program as a college instructor, known as the Professor of Stoogelogy, who teaches to the students lectures on the Three Stooges before the Stooges' shorts air. The block aired several shorts often grouped by a theme, such as similar schtick used in different films. Although the block was discontinued after AMC revamped their format in 2002, the network still ran Stooges shorts occasionally. The AMC run ended when Spike TV picked them up in 2004, airing them in their "Stooges Slap-Happy Hour". By 2007, the network had discontinued the block. Although Spike did air Stooges shorts for a brief period of time after the block was canceled, as of late April 2008, Three Stooges has disappeared from the network's schedule entirely. The Three Stooges returned on December 31, 2009, on AMC, starting with the "Countdown with the Stooges" New Year's Eve marathon. AMC planned to put several episodes on their website in 2010. The "Stooges" shorts were best known in Chicago as a part of a half hour late afternoon show on WGN-TV hosted by Bob Bell as "Andy Starr" in the 1960s.
Since the 1990s Columbia and its television division's successor, Sony Pictures Television, has preferred to license the Stooges shorts to cable networks, precluding the films from being shown on local broadcast TV. Two stations in Chicago and Boston, however, signed long-term syndication contracts with Columbia years ago and have declined to terminate them. Thus, WMEU-CD in Chicago currently airs all 190 Three Stooges shorts on Saturday afternoons from 1–3 pm and Sunday evenings from 9–11 pm. WSBK-TV in Boston airs Stooge shorts and feature films, including an annual New Year's Eve marathon. KTLA in Los Angeles dropped the shorts in 1994, but brought them back in 2007 as part of a special retro-marathon commemorating the station's 60th anniversary. Since that time, the station's original 16mm Stooges film prints have aired occasionally as part of mini-marathons on holidays. Antenna TV, a network broadcasting on the digital subchannels of local broadcast stations (owned by Tribune Broadcasting, who also owns KTLA), began airing the Stooges shorts upon the network's January 1, 2011 launch, which ran in multi-hour blocks on weekends through December 29, 2012; most of the Three Stooges feature films are also broadcast on the network, through Antenna TV's distribution agreement with Sony Pictures Entertainment (whose Columbia Pictures subsidiary released most of the films). While the network stopped airing Stooges shorts regularly from 2013 to 2015, they were occasionally shown as filler if a movie ran short, as well as in holiday marathons. However, the shorts returned to Antenna TV's regular lineup on January 10, 2015.
Some films have been colorized by two separate companies. The first colorized DVD releases, distributed by Sony Pictures Home Entertainment, were prepared by West Wing Studios in 2004. The following year, Legend Films colorized the public domain shorts "Malice in the Palace", "Sing a Song of Six Pants", "Disorder in the Court" and "Brideless Groom". "Disorder in the Court" and "Brideless Groom" also appears on two of West Wing's colorized releases. In any event, the Columbia-produced shorts (aside from the public domain films) are handled by Sony Pictures Entertainment, while the MGM Stooges shorts are owned by Warner Bros. via their Turner Entertainment division. Sony offers 21 of the shorts on their web platform Crackle, along with eleven Minisodes. Meanwhile, the rights to the Stooges' feature films rests with the studios that originally produced them (Columbia/Sony for the Columbia films, and 20th Century Fox for the Fox films).
Home video.
Between 1980 and 1985, Columbia Pictures Home Entertainment and RCA/Columbia Pictures Home Video released a total of thirteen Three Stooges volumes on VHS, Beta and Laserdisc, each containing three shorts. These titles were later reissued on VHS by its successor, Columbia TriStar Home Video, between 1993 and 1996, with a DVD reissue between 2000 and 2004.
"The Three Stooges Collection".
On October 30, 2007, Sony Pictures Home Entertainment released a two-disc DVD set entitled "The Three Stooges Collection, Volume One: 1934–1936". The set contains shorts from the first three years the Stooges worked at Columbia Pictures, marking the first time ever that all 19 shorts were released in their original theatrical order to DVD. Additionally, every short was remastered in high definition, a first for the Stooge films. Previous DVD releases were based on themes (wartime, history, work, etc.), and sold poorly. Fans and critics alike praised Sony for finally giving the Stooges the proper DVD treatment. One critic states "the Three Stooges on DVD has been a real mix'n match hodgepodge of un-restored titles and illogical entries. This new...boxset...seems to be the first concerted effort to categorize their huge body of work chronologically with many shorts seeing the digital light for the first time." Videolibrarian.com critic added "finally, the studio knuckleheads got it right! The way that the Three Stooges have been presented on home video has been a real slap in the face and poke in the eye to fans. They've been anthologized, colorized, and public domain-ed, as their shorts have been released and re-released in varying degrees of quality. Highly recommended." Critic James Plath of DVDtown.com added, "Thank you, Sony, for finally giving these Columbia Pictures icons the kind of DVD retrospective that they deserve. Remastered in High Definition and presented in chronological order, these short films now give fans the chance to appreciate the development of one of the most successful comedy teams in history."
The chronological series proved very successful and wildly popular, and Sony wasted little time preparing the next set for release. "Volume Two: 1937–1939" was released on May 27, 2008, followed by "Volume Three: 1940–1942" three months later on August 26, 2008. Demand exceeded supply, proving to Sony that they had a hit on their hands. In response, "Volume Four: 1943–1945" was released on October 7, 2008, a mere two months after its predecessor. The global economic crisis slowed down the release schedule after Volume Four, and "Volume Five: 1946–1948" was belatedly released on March 17, 2009. "Volume Five" is the first in the series to feature Shemp Howard with the Stooges and the final volume to feature Curly Howard. "Volume Six: 1949–1951" was released June 16, 2009, and "Volume Seven: 1952–1954" was released on November 10, 2009. "Volume Seven" included 3-D glasses for the two shorts: "Spooks!" and "Pardon My Backfire". As of 2013, the 3-D versions of the two shorts in this volume have been removed. "Volume Eight: 1955–1959" was released on June 1, 2010. This was the final volume of the Stooges collection, bringing the series to a close. Instead of two discs, "Volume Eight" includes three discs. It is also the final volume to feature Shemp Howard and the first and only volume to feature Joe Besser. For the first time in history, all 190 "Three Stooges" short subjects became available to the public, uncut and unedited.
A 20-disc DVD boxed set entitled "The Three Stooges: The Ultimate Collection", including all 190 shorts from volumes 1–8 and additional bonus material, was released on June 5, 2012.
Music.
Three feature-length Columbia releases were actually packages of older Columbia shorts. "Columbia Laff Hour" (introduced in 1956) was a random assortment that included the Stooges among other Columbia comedians like Andy Clyde, Hugh Herbert, and Vera Vague; the content and length varied from one theater to the next. "Three Stooges Fun-o-Rama" (introduced in 1959) was an all-Stooges show capitalizing on their TV fame, again with shorts chosen at random for individual theaters. "The Three Stooges Follies" (1974) was similar to "Laff Hour", with a trio of Stooge comedies augmented by Buster Keaton and Vera Vague shorts, a Batman serial chapter, and a Kate Smith musical.
Museum.
Gary Lassin, grandnephew-in-law of Larry Fine, opened the Stoogeum in 2004, in a renovated architect's office in Spring House, Pennsylvania, north of Philadelphia. The museum-quality exhibits fill three stories , including an 85-seat theater. Peter Seely, editor of the book "Stoogeology: Essays on the Three Stooges" said that the Stoogeum has ""more stuff than I even imagined existed"." 2,500 people visit it yearly, many during the annual Three Stooges Fan Club gathering in April.
In other media.
Comic books.
Over the years, several Three Stooges comics were produced.
Music.
Beginning in 1959, the Three Stooges began to appear in a series of novelty records. Their first recording was a 45 rpm single of the title song from "Have Rocket, Will Travel." The trio released additional singles and LPs on the Golden and Coral labels, mixing comedy adventure albums and off-beat renditions of children's songs. Their final recording was the 1966 "Yogi Bear and the Three Stooges Meet the Mad, Mad, Mad Dr. No-No", which incorporated the Three Stooges into the cast of the Yogi Bear cartoons.
Radio.
Sirius XM Radio aired a special about the Stooges hosted by Tom Bergeron on Friday, July 31, 2009, at 2:00PM on the Sirius Howard 101 channel. Bergeron had conducted the interviews at the age of 16 back when he was still in high school in 1971. The television host had the tapes in storage for many years and was convinced on-air during an interview with Howard Stern to bring them in and turn it into a special.
After finding "the lost tapes", Bergeron brought them into Stern's production studio. He stated that the tapes were so old that the tapes with the Larry Fine interviews began to shred as Stern's radio engineers ran them through their cart players. They really had only one shot, but fortunately for Stooges fans the tapes were saved.
"The Lost Stooges Tapes" was hosted by Tom Bergeron, with modern commentary on the almost 40-year-old interviews that he had conducted with Larry Fine and Moe Howard. At the times of these interviews, Moe was still living at home and Larry had suffered a stroke and was living in a Senior Citizen's home.
Sports.
Canadian-American professional wrestler Curly Moe, whose "gimmick" was based on Curly Howard, was a popular fan favorite in International World Class Championship Wrestling during the early-1990s. The promotion billed Curly Moe as the real-life nephew of Curly and Moe Howard which attracted some attention from the media.
Television.
"The New Three Stooges" (1965–66).
In addition to the unsuccessful television series pilots "Jerks of All Trades", "The Three Stooges Scrapbook", and the incomplete "Kook's Tour", the Stooges appeared in an animated series, "The New Three Stooges", which ran from 1965 to 1966. This series featured a mix of forty-one live-action segments which were used as wraparounds to 156 animated Stooges shorts. "The New Three Stooges" became the only regularly scheduled television show in history for the Stooges. Unlike other films shorts that aired on television, like the "Looney Tunes", "Tom and Jerry", and "Popeye", the film shorts of the Stooges never had a regularly scheduled national television program to air in. When Columbia/Screen Gems licensed the film library to television, the shorts aired in any fashion the local stations chose (examples: late-night "filler" material between the end of the late movie and the channel's sign-off time; in "marathon" sessions running shorts back-to-back for one, one-and-a-half, or two hours; etc.) By the 1970s, some local stations showed a Columbia short and a "New Three Stooges" cartoon in the same broadcast.
"The Robonic Stooges" (1977–78).
Another animated series also produced by Hanna-Barbera, titled "The Robonic Stooges", originally seen as a featured segment on "The Skatebirds" (CBS, 1977–1978), featuring Moe, Larry, and Curly (voiced by Paul Winchell, Joe Baker and Frank Welker, respectively) as bionic cartoon superheroes with extendable limbs, similar to the later "Inspector Gadget". "The Robonic Stooges" later aired as a separate half-hour series, retitled "The Three Robonic Stooges" (each half-hour featured two segments of "The Three Robonic Stooges" and one segment of "Woofer And Whimper, Dog Detectives", the latter re-edited from episodes of "Clue Club", an earlier Hanna-Barbera cartoon series).
"The Three Stooges" (TBA).
On June 9, 2015, C3 Entertainment announced it is partnering with London-based production company Cake Entertainment and animation house Titmouse, Inc. to produce a new animated Three Stooges series, consisting of 52 11-minute episodes. Christy Karacas (Co-creator of "Superjail!") directed the pilot episode, with Earl and Robert Benjamin, Chris Prynoski, Tom van Waveren and Edward Galton executive producing. The series will be launched to potential buyers at the market of the Annecy International Animated Film Festival.
Other appearances.
In the October 13, 1967 "Who's Afraid of Mother Goose?" episode of ABC's "World-of-Disney"-like anthology series "Off to See the Wizard", the Three Stooges made a short appearance as "the three men in a tub".
Two episodes of Hanna-Barbera's "The New Scooby-Doo Movies" aired on CBS featuring animated Stooges as guest stars: the premiere, "Ghastly Ghost Town" (September 9, 1972) and "The Ghost of the Red Baron" (November 18, 1972). 
In a 1980 episode of "M*A*S*H", Charles Winchester shows disrespect for three Korean doctors by calling them "Moe, Larry and Curly", and says that they are "highly-respected individuals in the States". After Winchester throws out his back and is unable to relieve the pain through conventional methods (in real life, Winchester would've received an automatic medical discharge from the United States Army), Colonel Potter has the Korean doctors try acupuncture (much to Winchester's dismay), which cures Winchester. After the treatment, one of the doctors tells Winchester "Not bad for Three Stooges, huh?", having caught on to his mistreatment of them.
In the episode "Beware the Creeper" of "The New Batman Adventures", the Joker retreats to his hide-out after a quick fight with Batman. He yells out for his three henchmen "Moe? Larr? Cur?" only to find that they are not there. Shortly after that, Batman comes across these three goons in a pool hall; they have distinctive accents and hairstyles similar to those of Moe, Larry and Curly. These henchmen are briefly seen throughout the rest of the season.
Television film (2000).
In 2000, long-time Stooge fan Mel Gibson executive-produced a TV film ("The Three Stooges") about the lives and careers of the comedians. Playing Moe was Paul Ben-Victor, Evan Handler was Larry, John Kassir was Shemp, and Michael Chiklis was Curly. It was filmed in Australia and was produced for and broadcast on ABC. It was based on Michael Fleming's authorized biography of the Stooges, "The Three Stooges: From Amalgamated Morons to American Icons". Its unflattering portrayal of Ted Healy led Healy's son to give media interviews calling the film inaccurate. Additional errors of fact included the hint that Moe Howard was down on his luck later in life and worked as a gofer at the studio, where he, his brothers and Larry had formerly worked as actors. In reality, Moe was the most careful with his money, which he invested well. He and his wife Helen owned a comfortable house in Toluca Lake, in which they raised their children.
Film.
"The Three Stooges: The Movie".
A film about the Three Stooges, titled "The Three Stooges", started production on March 14, 2011, with 20th Century Fox and was directed by the Farrelly brothers. The film had been in what one critic has dubbed "development hell". The Farrellys, who wanted to make the film since 1996, said that they were not going to do a biopic or remake, but instead new Three Stooges episodes set in the present day. The film is broken up into three continuous episodes that revolves around the Stooges characters.
Casting the title characters proved difficult for the studio. Originally slated were Sean Penn to play Larry, Benicio del Toro to play Moe, and Jim Carrey to play Curly. Both Penn and del Toro left the project but returned while no official confirmation had been made about Jim Carrey. When del Toro was interviewed on MTV News for "The Wolfman", he spoke about playing Moe. He was later asked who was going to play Larry and Curly in the film and commented that he still thought that Sean Penn and Jim Carrey were going to play them, though he added, "Nothing is for sure yet."
A story in "The Hollywood Reporter" stated that Will Sasso would play Curly in the upcoming comedy and that Hank Azaria was the front runner to play Moe. Sasso was ultimately cast as Curly; Sean Hayes of "Will & Grace" was cast as Larry Fine, while Chris Diamantopoulos was cast as Moe. Jane Lynch later joined the cast, playing a nun. The film was released on April 13, 2012, and grossed over $54 million worldwide.
Sequel.
On May 7, 2015, a sequel was announced, with Sean Hayes, Chris Diamantopoulos, and Will Sasso all reprising their roles. Cameron Fay has been hired to write the script.
"The Three Little Stooges".
On February 3, 2016, C3 announced a feature film starring The Three Stooges as 12-year-old children. Production will begin in the Summer in Vancouver, British Columbia. It will be directed by Harris Goldberg.
Video games.
In 1984, Gottlieb released an arcade game featuring the Stooges trying to find three kidnapped brides.
Later in 1987, game developers Cinemaware released a successful Three Stooges computer game, available for Apple IIGS, Amiga, Commodore 64, MS-DOS, and Nintendo Entertainment System (NES). Based on the Stooges earning money by doing odd jobs to prevent the foreclosure of an orphanage, it incorporated audio from the original films and was popular enough to be reissued for the Game Boy Advance in 2002, as well as for PlayStation in 2004.
The Three Stooges also have a slot game adaptation created by Realtime Gaming
VCR game.
A VCR game was released by Pressman Toy Corporation in 1986, which utilized a number of classic Stooges clips.
In foreign languages.
In most other languages, the Three Stooges are known by their English name. In Chinese, however, the trio is known as "Sānge Chòu Píjiàng" (三個臭皮匠) or "Huóbǎo Sānrénzǔ" (活寶三人組). "Sānge Chòu Píjiàng", literally "Three Smelly Shoemakers", which derives from a saying in the "Romance of the Three Kingdoms": "Sāngè chòu píjiàng shèngguò yīgè Zhūgě Liàng" (三個臭皮匠，勝過一個諸葛亮) or "Three smelly shoemakers (are enough to) overcome one Zhuge Liang hero of the story", i.e. three inferior people can overpower a superior person when they combine their strength. "Huóbǎo Sānrénzǔ" translates as "Trio of Buffoons".
In Japanese they are known as "San Baka Taishō" (三ばか大将) meaning "Three Idiot Generals" or "Three "Baka" Generals". The Japanese term "baka" (馬鹿, "fool" or "idiot", lit. "horse deer") is associated with the Chinese idiom "zhǐlù wéimǎ" (指鹿為馬; lit. "point at a deer and call it a horse", in Japanese "shika o sashite uma to nasu" [鹿を指して馬と為す]) meaning "deliberate misrepresentation for ulterior purposes". In Spanish they are known as "Los tres chiflados" or, roughly, "The Three Crackpots". In French and German usage, the name of the trio is partially translated as "Les Trois Stooges" (though the French version of the movie adaptation used a fully translated name, "Les Trois Corniauds") and "Die drei Stooges" respectively. In Thai, the trio is known as 3 สมุนจอมป่วน ("3 Samunčhǭmpūan"; ) or 3 พี่น้องจอมยุ่ง ("Phīnǭngčhǭmyung"; ). In Portuguese, they are known as "Os Três Patetas" in Brazil, and "Os Três Estarolas" in Portugal, "estarola" being a direct translation of "stooge", while "pateta" being more related to "goofy". In Persian the trio are dubbed as "سه نخاله". In Turkish, they are dubbed as "Üç Ahbap Çavuş" ("The Three Cronies").
Awards & Nominations.
In 1993, the Three Stooges won the MTV Lifetime Achievement Award. 

</doc>
<doc id="36819" url="https://en.wikipedia.org/wiki?curid=36819" title="Laetitia Casta">
Laetitia Casta

Laetitia Marie Laure Casta (born 11 May 1978) is a French actress and model. Casta became a "GUESS? Girl" in 1993 and gained further recognition as a Victoria's Secret Angel from 1998 to 2000 and as a spokesperson for cosmetics company L'Oreal. She has appeared on over 100 covers of such popular magazines as "Cosmopolitan", "Vogue", "Rolling Stone", "Elle" and "Glamour", and modeled for designers like Yves Saint Laurent, Jean-Paul Gaultier, Chanel, Ralph Lauren, Tommy Hilfiger, J. Crew, Louis Vuitton, Givenchy, Roberto Cavalli, Lolita Lempicka, and Vivienne Westwood. Casta became an established actress, appearing in the films "Gainsbourg (A Heroic Life)", "Face" and "Blue Bicycle", as well as the play "Ondine" at the theatre Antoine.
Early life.
Casta was born in Pont-Audemer, Normandy, France. Her mother, Line Blin, is from Normandy. Her father, Dominique Casta, is from Corsica. She has an older brother, Jean-Baptiste, and a younger sister, Marie-Ange. She spent her childhood in Normandy and Corsica.
Career.
Casta's modeling career reportedly began when she was discovered by the photographer Frederic Cresseaux, during a family holiday in her father's native Corsica, at age 15. After her unexpected registration by "Jeeby", Casta was elected Miss Lumio 93.
Casta has been the L'Oreal Paris brand ambassador since 1998. She has been featured in Guess? Jeans, Tommy Hilfiger, Miu Miu, Pepe Jeans, Alberta Ferretti and XOXO ad campaigns. Casta has appeared on over 100 magazine covers including Victoria's Secret catalogs, Harper's Bazaar, "ELLE" magazine, and "Vogue" magazine. She walked down the annual Victoria's Secret Fashion Show in 1997, 1998, 1999, and 2000. Casta was one of the company's signature Victoria' Secret Angels from 1998 to 2002. She also appeared in three consecutive Sports Illustrated Swimsuit Issues, "Rolling Stone", and the Pirelli Calendar 1999 by Herb Ritts and 2000 by Annie Leibovitz.
In 1999, Casta was ranked first in a national survey ordered by the French Mayors Association to decide who should be the new model for the bust of "Marianne", an allegorical symbol of the French Republic, which stands inside every French town hall.
Casta became the focus of a controversy when, after being selected to be Marianne, newspapers in Britain and France reported that she had relocated to London where taxes on high earners are lower. Casta's father said she went to London for professional reasons; on a TV show, she also said that she rented a flat in London to be near her boyfriend. The French minister of the interior spoke about Casta on the radio; comparing the advantages of living in France with regard to the drawbacks of London after political opponents used Casta's relocation to London as an opportunity to criticise the government.
She is the face of fragrances Chanel's "Allure", Givenchy's "Forbidden flower", Cacharel's "Promise", Bulgari's "BLV II", Ralph Lauren's "Notorious", and on 15 June 2012 D&G's "Pour Femme" shot in Erice by Mario Testino. The Parisians could follow her Adventures in the Galeries Lafayette by Jean-Paul Goude. For Christmas 2011, Peter Lindbergh shot "True Love", the very thought of Casta at the summit of Manhattan and between the snowy lions of marble of the New York Public Library for Tiffany & Co.
On 10 March 2010, in Paris, she opened the Louis Vuitton Fall/Winter 2010 fashion show. On 27 September 2010, she closed the Roberto Cavalli SS 2011 fashion show in Milan.
For her first movie, Casta has made forays into the blockbuster "Asterix & Obelix Take On Caesar" directed by Claude Zidi, a live-action film of the comic book Asterix; in which Obelix, portrayed by Gerard Depardieu, plays a love interest for Falbala. Casta appeared in "Les Ames Fortes", a dramatic film directed by Raul Ruiz. Her interpretation of Brigitte Bardot in the movie "Gainsbourg (Vie heroique)" revealed the actress who received her first nomination at the Cesar Award. Casta served as a jury member at the 69th Venice International Film Festival in 2012.
Political involvement.
On 6 April 2008, Casta demonstrated in a White March of nonviolent protest to ask for the immediate release of Ingrid Betancourt, presidential candidate kidnapped since 2002 by the FARC.
On 30 April 2002, she attended the demonstration "Vive la République" after the first round election of the 2002 presidential election.
Personal life.
On 19 October 2001, Casta gave birth to her daughter Sahteene, whose father is the photographer Stephane Sednaoui. Casta was engaged to Italian actor Stefano Accorsi. The couple has two children: a son named Orlando, born on 21 September 2006, and a daughter named Athena, born on 29 August 2009.
As of 2015, she is in a relationship with French actor Louis Garrel.

</doc>
<doc id="36821" url="https://en.wikipedia.org/wiki?curid=36821" title="Sutter's Mill">
Sutter's Mill

Sutter's Mill was a sawmill, owned by 19th-century pioneer John Sutter, where gold was found, setting off the California Gold Rush. It was located on the bank of the South Fork American River in Coloma, California.
History.
On January 24, 1848, James Wilson Marshall, a carpenter originally from New Jersey, found flakes of gold in the American River at the base of the Sierra Nevada Mountains near Coloma, California. At the time, Marshall was working to build a water-powered sawmill owned by John Sutter. On February 2, 1848, the Treaty of Guadalupe Hidalgo was signed in Mexico City which transferred the American Southwest to the United States. When the news got out, people from all over the world headed for California, speeding statehood and permanently transforming the territory. During the next seven years, approximately 300,000 people came to California (half by land and half by sea) to seek their fortunes from either mining for gold or selling supplies like food, clothing, burros, lumber, picks, and shovels to the prospectors.
Henry Bigler and Azariah Smith, like other workers at the mill, were veterans of the Mormon Battalion, and wrote about their experience in journals. Bigler recorded the actual date when gold was discovered, January 24, 1848, in his diary. This gold find started the California Gold Rush the next year.
Location.
The site of the mill is located on the South Fork American River. Marshall Gold Discovery State Historic Park is registered as California Historical Landmark #530. The current Sutter's Mill is a replica of the original building. It was built based on Marshall's own drawings and an early day photo of the mill.
In popular culture.
The mill was the namesake and inspiration for a song by singer-songwriter Dan Fogelberg. The mill was also the namesake for a song by the New Riders of the Purple Sage, and for Herb Sutter's blog.
Smithsonian.
The original flake of gold discovered at the mill is currently at the Smithsonian Institution.

</doc>
<doc id="36822" url="https://en.wikipedia.org/wiki?curid=36822" title="Sutter's Fort">
Sutter's Fort

History.
Sutter's Fort was built in 1839 and originally called "New Helvetia" ("New Switzerland") by its builder, John Sutter. The fort was a 19th-century agricultural and trade colony in the Mexican Alta California Province. The fort was the first non-Indigenous community in the California Central Valley. The fort is famous for its association with the Donner Party, the California Gold Rush and the formation of Sacramento. It is notable for its proximity to the end of the California Trail and Siskiyou Trails for which it served as a waystation.
After gold was discovered at Sutter's Mill (also owned by Sutter) in Coloma, the fort was abandoned. The adobe structure has been restored to its original condition and is now administered by California Department of Parks and Recreation. It was designated a National Historic Landmark in 1961.
Description.
The Main Building of the fort is a two story adobe structure built between 1841 and 1843. This building is the only original surviving structure at the reconstructed Sutter's Fort State Historic Park. It was in here on January 28, 1848 that James Marshall met privately with Sutter in order to show Sutter the gold that Marshall had found during the construction of Sutter's sawmill along the American River only four days earlier. Sutter built the original fort with walls thick and 15 to high.
Following word of the Gold Rush, the fort was largely deserted by the 1850s and fell into disrepair.
In 1891, the Native Sons of the Golden West, who sought to safeguard many of the landmarks of California's pioneer days, purchased and rehabilitated Sutter's Fort when the City of Sacramento sought to demolish it. Repair efforts were completed in 1893 and the fort was given by the Native Sons of the Golden West to the State of California. In 1947, the fort was transferred to the authority of California State Parks.
Most of the original neighborhood structures were initially built in the late 1930s as residences, many of which have been converted to commercial uses such as private medical practices. The history of the neighborhood is largely residential. Pioneers took residence at Sutter's Fort around 1841.
Geography and geology.
Sutter's Fort is located on level ground at an elevation of approximately above mean sea datum. The slope elevation decreases northward toward the American River and westward toward the Sacramento River. Slope elevation gradually increases to the south and east, away from the rivers. All surface drainage flows toward the Sacramento River. Groundwater in the vicinity flows south-southwest toward the Sacramento Delta; however, after peak rainfall, because of the swollen Sacramento River, the groundwater flow can actually reverse and flow away from the river.

</doc>
<doc id="36826" url="https://en.wikipedia.org/wiki?curid=36826" title="Dekker's algorithm">
Dekker's algorithm

Dekker's algorithm is the first known correct solution to the mutual exclusion problem in concurrent programming. The solution is attributed to Dutch mathematician Th. J. Dekker by Edsger W. Dijkstra in an unpublished paper on sequential process descriptions and his manuscript on cooperating sequential processes. It allows two threads to share a single-use resource without conflict, using only shared memory for communication.
It avoids the strict alternation of a naïve turn-taking algorithm, and was one of the first mutual exclusion algorithms to be invented.
Overview.
If two processes attempt to enter a critical section at the same time, the algorithm will allow only one process in, based on whose turn it is. If one process is already in the critical section, the other process will busy wait for the first process to exit. This is done by the use of two flags, ] and , which indicate an intention to enter the critical section on the part of processes 0 and 1, respectively, and a variable that indicates who has priority between the two processes.
Dekker's algorithm can be expressed in pseudocode, as follows.
Processes indicate an intention to enter the critical section which is tested by the outer while loop. If the other process has not flagged intent, the critical section can be entered safely irrespective of the current turn. Mutual exclusion will still be guaranteed as neither process can become critical before setting their flag (implying at least one process will enter the while loop). This also guarantees progress as waiting will not occur on a process which has withdrawn intent to become critical. Alternatively, if the other process's variable was set the while loop is entered and the turn variable will establish who is permitted to become critical. Processes without priority will withdraw their intention to enter the critical section until they are given priority again (the inner while loop). Processes with priority will break from the while loop and enter their critical section.
Dekker's algorithm guarantees mutual exclusion, freedom from deadlock, and freedom from starvation. Let us see why the last property holds. Suppose p0 is stuck inside the "while wants_to_enterloop forever. There is freedom from deadlock, so eventually p1 will proceed to its critical section and set turn = 0 (and the value of turn will remain unchanged as long as p0 doesn't progress). Eventually p0 will break out of the inner "while turn ≠ 0" loop (if it was ever stuck on it). After that it will set wants_to_enter[0 to true and settle down to waiting for wants_to_enterto become false (since turn = 0, it will never do the actions in the while loop). The next time p1 tries to enter its critical section, it will be forced to execute the actions in its "while wants_to_enter[0" loop. In particular, it will eventually set wants_to_enterto false and get stuck in the "while turn ≠ 1" loop (since turn remains 0). The next time control passes to p0, it will exit the "while wants_to_enter[1" loop and enter its critical section.
If the algorithm were modified by performing the actions in the "while wants_to_enter" loop without checking if turn = 0, then there is a possibility of starvation. Thus all the steps in the algorithm are necessary.
Note.
One advantage of this algorithm is that it doesn't require special Test-and-set (atomic read/modify/write) instructions and is therefore highly portable between languages and machine architectures. One disadvantage is that it is limited to two processes and makes use of busy waiting instead of process suspension. (The use of busy waiting suggests that processes should spend a minimum of time inside the critical section.)
Modern operating systems provide mutual exclusion primitives that are more general and flexible than Dekker's algorithm. However, in the absence of actual contention between the two processes, the entry and exit from critical section is extremely efficient when Dekker's algorithm is used.
Many modern CPUs execute their instructions in an out-of-order fashion; even memory accesses can be reordered (see memory ordering). This algorithm won't work on SMP machines equipped with these CPUs without the use of memory barriers.
Additionally, many optimizing compilers can perform transformations that will cause this algorithm to fail regardless of the platform. In many languages, it is legal for a compiler to detect that the flag variables "wants_to_enterand "wants_to_enter[1" are never accessed in the loop. It can then remove the writes to those variables from the loop, using a process called Loop-invariant code motion. It would also be possible for many compilers to detect that the "turn" variable is never modified by the inner loop, and perform a similar transformation, resulting in a potential infinite loop. If either of these transformations is performed, the algorithm will fail, regardless of architecture.
To alleviate this problem, volatile variables should be marked as modifiable outside the scope of the currently executing context. For example, in C# or Java, one would annotate these variables as 'volatile'. Note however that the C/C++ "volatile" attribute only guarantees that the compiler generates code with the proper ordering; it does not include the necessary memory barriers to guarantee in-order "execution" of that code. C++11 atomic variables can be used to guarantee the appropriate ordering requirements — by default, operations on atomic variables are sequentially consistent so if the wants_to_enter and turn variables are atomic a naive implementation will "just work". Alternatively, ordering can be guaranteed by the explicit use of separate fences, with the load and store operations using a relaxed ordering.

</doc>
<doc id="36827" url="https://en.wikipedia.org/wiki?curid=36827" title="Mutual exclusion">
Mutual exclusion

In computer science, mutual exclusion refers to the requirement of ensuring that no two concurrent processes are in their critical section at the same time; it is a basic requirement in concurrency control, to prevent race conditions. Here, a critical section refers to a period when the process accesses a shared resource, such as shared memory. The requirement of mutual exclusion was first identified and solved by Edsger W. Dijkstra in his seminal 1965 paper titled "Solution of a problem in concurrent programming control", and is credited as the first topic in the study of concurrent algorithms.
A simple example of why mutual exclusion is important in practice can be visualized using a singly linked list (See Figure 1). In such a linked list, the removal of a node is done by changing the "next" pointer of the preceding node to point to the subsequent node (e.g., if node "i" is being removed then the "next" pointer of node "i" − 1 will be changed to point to node "i" + 1). In an execution where such a linked list is being shared between multiple processes, two processes may attempt to remove two different nodes simultaneously, resulting in the following problem: let nodes "i" and "i" + 1 be the nodes to be removed; furthermore, let neither of them be the head nor the tail; the next pointer of node "i" − 1 will be changed to point to node "i" + 1 and the next pointer of node "i" will be changed to point to node "i" + 2. Although both removal operations complete successfully, node "i" + 1 remains in the list since "i" − 1 was made to point to "i" + 1, skipping node "i" (which was the node that reflected the removal of "i" + 1 by having its next pointer set to "i" + 2). This can be seen in Figure 1. This problem (normally called a race condition) can be avoided by using the requirement of mutual exclusion to ensure that simultaneous updates to the same part of the list cannot occur.
Enforcing mutual exclusion.
There are both software and hardware solutions for enforcing mutual exclusion. Some different solutions are discussed below.
Hardware solutions.
On uniprocessor systems, the simplest solution to achieve mutual exclusion is to disable interrupts during a process's critical section. This will prevent any interrupt service routines from running (effectively preventing a process from being preempted). Although this solution is effective, it leads to many problems. If a critical section is long, then the system clock will drift every time a critical section is executed because the timer interrupt is no longer serviced, so tracking time is impossible during the critical section. Also, if a process halts during its critical section, control will never be returned to another process, effectively halting the entire system. A more elegant method for achieving mutual exclusion is the busy-wait.
Busy-waiting is effective for both uniprocessor and multiprocessor systems. The use of shared memory and an atomic test-and-set instruction provides the mutual exclusion. A process can test-and-set on a location in shared memory, and since the operation is atomic, only one process can set the flag at a time. Any process that is unsuccessful in setting the flag can either go on to do other tasks and try again later, release the processor to another process and try again later, or continue to loop while checking the flag until it is successful in acquiring it. Preemption is still possible, so this method allows the system to continue to function—even if a process halts while holding the lock.
Several other atomic operations can be used to provide mutual exclusion of data structures; most notable of these is compare-and-swap (CAS). CAS can be used to achieve wait-free mutual exclusion for any shared data structure by creating a linked list where each node represents the desired operation to be performed. CAS is then used to change the pointers in the linked list during the insertion of a new node. Only one process can be successful in its CAS; all other processes attempting to add a node at the same time will have to try again. Each process can then keep a local copy of the data structure, and upon traversing the linked list, can perform each operation from the list on its local copy.
Software solutions.
Beside hardware-supported solutions, some software solutions exist that use busy waiting to achieve mutual exclusion. Examples of these include the following:
These algorithms do not work if out-of-order execution is used on the platform that executes them. Programmers have to specify strict ordering on the memory operations within a thread.
It is often preferable to use synchronization facilities provided by an operating system's multithreading library, which will take advantage of hardware solutions if possible but will use software solutions if no hardware solutions exist. For example, when the operating system's lock library is used and a thread tries to acquire an already acquired lock, the operating system could suspend the thread using a context switch and swap it out with another thread that is ready to be run, or could put that processor into a low power state if there is no other thread that can be run. Therefore, most modern mutual exclusion methods attempt to reduce latency and busy-waits by using queuing and context switches. However, if the time that is spent suspending a thread and then restoring it can be proven to be always more than the time that must be waited for a thread to become ready to run after being blocked in a particular situation, then spinlocks are an acceptable solution (for that situation only).
Types of mutual exclusion devices.
The solutions explained above can be used to build the synchronization primitives below:
Many forms of mutual exclusion have side-effects. For example, classic semaphores permit deadlocks, in which one process gets a semaphore, another process gets a second semaphore, and then both wait forever for the other semaphore to be released. Other common side-effects include starvation, in which a process never gets sufficient resources to run to completion; priority inversion, in which a higher priority thread waits for a lower-priority thread; and high latency, in which response to interrupts is not prompt.
Much research is aimed at eliminating the above effects, often with the goal of guaranteeing non-blocking progress. No perfect scheme is known. Blocking system calls used to sleep an entire process. Until such calls became threadsafe, there was no proper mechanism for sleeping a single thread within a process (see polling).

</doc>
<doc id="36832" url="https://en.wikipedia.org/wiki?curid=36832" title="Organisation for the Prohibition of Chemical Weapons">
Organisation for the Prohibition of Chemical Weapons

The Organisation for the Prohibition of Chemical Weapons (OPCW) is an intergovernmental organisation, located in The Hague, Netherlands.
The organisation promotes and verifies the adherence to the Chemical Weapons Convention which prohibits the use of chemical weapons and requires their destruction. The verification consists both of evaluation of declarations by member states and on-site inspections.
The organisation was awarded the 2013 Nobel Peace Prize because it had, with the Chemical Weapons Convention, "defined the use of chemical weapons as a taboo under international law" according to Thorbjørn Jagland, Chairman of the Norwegian Nobel Committee.
Organisational structure.
The activities of the OPCW and its core organisational structure are described in the Chemical Weapons Convention (whose members are all in OPCW). The principal body is the conference of states parties, which normally is convened yearly, and in which all countries participate and have equal voting rights. Countries are generally represented in the Conference by a permanent representative to the organisation, which in most cases is also the ambassador to the Netherlands. The conference decides on all main topics regarding the organisation (for example, taking retaliation measures) and the convention (approving guidelines, imposing retaliating measures against members).
The Executive Council is the executive organ of the organisation and consists of 41 States Parties, which are appointed by the Conference on a 2-year term. The Council amongst others oversees the budget and cooperates with the General Secretariat on all matters related to the convention.
The Technical Secretariat applies most of the activities mandated by the Council and is the body where most of the employees of the organisation work. The main activities of the OPCW are performed by the verification and the inspection division.
All States Parties make contributions to the OPCW budget, based on a modified UN scale of assessments.
Inspections.
Chemical weapons destruction facilities.
At all operational chemical weapons destruction facilities, 24/7 inspections by the OPCW take place on site to verify the success of the destruction as well as the amounts of weapons being destroyed. In light of the hazardous environment in which the inspections take place, they are generally performed by evaluation via CCTV-systems.
Industry inspections.
Inspections are designed to verify compliance of States Parties with the requirements imposed on production and use of scheduled chemicals and to verify that industrial activities of member states have been correctly declared according to the obligation set by the CWC. The intensity and frequency of the inspections is dependent on the type of chemical produced (in descending order: Schedule 1, Schedule 2, Schedule 3 or DOC, see Scheduled Chemicals), but is regardless of the standing of the member state.
For Schedule 1 and 2 facilities, a mass balance is prepared to identify whether all produced chemicals can be accounted for and whether the amounts are consistent with the declarations made by member states. Furthermore, at Schedule 2 and 3 facilities clues are investigated whether, contrary to the declaration and to the rules in the convention, Schedule 1 chemicals are produced. At Schedule 3 and DOC, the main aim is to check the declaration and to verify the absence of Schedule 2 and Schedule 1 production units. The time limit Schedule 2 inspections is 96 hours while Schedule 3 and DOC inspections can take a maximum of 24 hours. There is no time limit on Schedule 1 inspections.
Challenge inspections and investigations of alleged use.
In case of allegation of use of chemical weapons or the prohibited production, a fact finding inspection can be employed according to the convention. None of those activities have taken place, although the OPCW contributed to investigations of alleged use of Chemical Weapons in Syria as part of a United Nations mission. The OPCW only undertakes these inspections on request of another member state, after verification of the presented proof. To avoid misuse, a majority of three quarters can block a challenge inspection request. Furthermore, the OPCW can only be involved after bilateral diplomatic solutions have failed.
Relations with the United Nations.
The organisation is not an agency of the United Nations, but cooperates both on policy and practical issues. On 7 September 2000 the OPCW and the United Nations signed a cooperation agreement outlining how they were to coordinate their activities. The inspectors furthermore travel on United Nations Laissez-Passer in which a sticker is placed explaining their position, and privileges and immunities. The United Nations Regional Groups also operate at the OPCW to govern the rotations on the Executive Council and provide informal discussion platform.
Headquarters.
The OPCW headquarters building was designed by American architect Gerhard Kallmann of Kallmann McKinnell & Wood.
The Hague was chosen as the location for the seat of the organisation after a successful lobby of the Dutch government, competing against Vienna and Geneva. The organisation has its headquarters next to the World Forum Convention Centre (where it holds its yearly Conference of States Parties) and storage/laboratory facilities in Rijswijk. The headquarters were officially opened by Queen Beatrix of the Netherlands on 20 May 1998 and consist of an eight-story building built in a semi-circle. A "permanent memorial to all victims" is present at the back of the building and open to the public.
Membership.
All 192 parties to the Chemical Weapons convention are automatically members of the OPCW. Other states which are eligible to become members are UN member states Israel, which is a signatory state that has not ratified the Chemical Weapons Convention, and Egypt, North Korea and South Sudan, which have neither signed nor acceded to the Chemical Weapons Convention, as well as UN observer state Palestine, which has also neither signed nor acceded to the CWC. Angola was the most recent state to submit its instrument of accession to the treaty.
Leadership.
The Organisation is led by the Director-General, who is directly appointed by the Conference for a maximum of two four-year terms. An overview of Directors-General is shown below.
The first Director-General only served about one year of his second term, after which he was removed from office on grounds of lack of confidence by the member states. Some suspect that Director-General Bustani was forced out by the U.S. government because Bustani wanted international chemical weapons monitors inside Iraq and thus was seen as impeding the U.S. push for war against Iraq. The US gave three main arguments for the removal of Bustani's from his position: "polarising and confrontational conduct", "mismanagement issues" and "advocacy of inappropriate roles for the OPCW". The removal was subsequently determined to be improper by an Administrative Tribunal of the International Labour Organization and consequently Bustani was awarded €50,000 in moral damages, his pay for the remainder of his second term, and his legal costs.
2013 Nobel Peace Prize.
On 11 October, the Norwegian Nobel Committee announced that the OPCW had been awarded the Nobel Peace Prize for "extensive work to eliminate chemical weapons". In the announcement, the OPCW and the Chemical Weapons Convention were praised. The committee further indicated how "Recent events in Syria, where chemical weapons have again been put to use, have underlined the need to enhance the efforts to do away with such weapons.” In the year ending in September, 2014, OPCW had overseen destruction of some 97 percent of Syria's declared chemical weapons.

</doc>
<doc id="36834" url="https://en.wikipedia.org/wiki?curid=36834" title="International Fund for Agricultural Development">
International Fund for Agricultural Development

The International Fund for Agricultural Development (IFAD) (French: "Fonds international de développement agricole"; "FIDA") (Italian: "Fondo Internazionale per lo Sviluppo Agricolo") is a specialized agency of the United Nations dedicated to eradicating rural poverty in developing countries. It was established as an international financial institution in 1977 as one of the major outcomes of the 1974 World Food Conference. Seventy-five percent of the world's poor live in rural areas in developing countries, yet only 4% of official development assistance goes to agriculture.
The strategic policy of IFAD is detailed in Strategic Framework for IFAD 2011–2015: Enabling the Rural Poor to Overcome Poverty. Its headquarters is in Rome, Italy, and is a member of the United Nations Development Group.
The President of the IFAD is Kanayo F. Nwanze from Nigeria, who was elected for a second four-year term in 2013.
Goal.
IFAD's goal is to empower poor rural women and men in developing countries to achieve higher incomes and improved food security.
Objectives.
IFAD seeks to ensure that poor rural people have better access to, and the skills and organization they need to take advantage of:
All of IFAD's decisions – on regional, country and thematic strategies, poverty reduction strategies, policy dialogue and development partners – are made with these principles and objectives in mind. As reflected in the strategic framework, IFAD is committed to achieving the Millennium Development Goals, in particular the target to halve the proportion of hungry and extremely poor people by 2015.
Underlying these objectives is IFAD’s belief that rural poor people must be empowered to lead their own development if poverty is to be eradicated. Poor people must be able to develop and strengthen their own organizations, so they can advance their own interests and dismantle the obstacles that prevent many of them from creating better lives for themselves. They must be able to have a say in the decisions and policies that affect their lives, and they need to strengthen their bargaining power in the marketplace.
Partnerships to eradicate rural poverty.
Through loans and grants, IFAD works with governments to develop and finance programmes and projects that enable rural poor people to overcome poverty themselves.
Since starting operations in 1978, IFAD has invested $12 billion, DM 7.5 billion in 860 projects and programmes that have reached some 370 million poor rural people.
Governments and other financing sources in recipient countries, including project participants, contributed $10.8 billion (€7.5 billion), and multilateral, bilateral and other donors provided approximately another $8.8 billion, €5 billion in cofinancing. This represents a total investment of about $19.6 billion (€15 billion).
IFAD tackles poverty not only as a lender, but also as an advocate for rural poor people. Its multilateral base provides a natural global platform to discuss important policy issues that influence the lives of rural poor people, as well as to draw attention to the centrality of rural development to meeting the Millennium Development Goals.
IFAD is also a partner in Compact2025, a partnership that develops and disseminates evidence-based advice to politicians and other decision-makers aimed at ending hunger and undernutrition in the coming 10 years. IFAD is represented on the Leadership Council of Compact2025 by its president Kanayo F. Nwanze.
Membership.
Membership in IFAD is open to all member states of the United Nations or its specialized agencies or the International Atomic Energy Agency. A state becomes a member of IFAD by ratifying the multilateral treaty known as the Agreement establishing the International Fund for Agricultural Development. The Governing Council is IFAD's highest decision-making authority, with the Member States each represented by a governor and alternate governor. The Council meets annually. The Executive Board, responsible for overseeing the general operations of IFAD and approving loans and grants, is composed of 18 members and 18 alternate members. The President, who serves for a four-year term (renewable once), is IFAD's chief executive officer and chair of the Executive Board. The current, and fifth, President of IFAD is Kanayo F. Nwanze, who was elected for a first four-year term in 2009.
As of February 2015, IFAD has 176 member states. This includes 174 UN members states along with the Cook Islands and Niue. The member states are classified as follows: List A (primarily OECD members); List B (primarily OPEC members); and List C (developing countries). List C is further divided into sub-list C1 (countries in Africa); sub-list C2 (countries in Europe, Asia and the Pacific Islands); and sub-list C3 (countries in Latin America and the Caribbean).
The other UN member states that are not IFAD member states are: Andorra, Australia (which joined in 1977 but subsequently denounced the agreement), Bahrain, Belarus, Brunei, Bulgaria, Czech Republic, Latvia, Liechtenstein, Lithuania, Monaco, Poland, San Marino, Serbia, Singapore, Slovakia, Slovenia, Turkmenistan, and Ukraine.
The observers are the Holy See and European Union.
The Governing Council is IFAD's highest decision-making authority. Each Member State is represented in the Governing Council by a Governors, Alternate Governors and any other designated advisers. The Executive Board is responsible for overseeing the general operations of IFAD and for approving its programme of work. Membership on the Executive Board is determined by the Governing Council and is distributed as follows: List A: eight Members and eight Alternate Members; List B: four Members and four Alternate Members; and List C: six Members and six Alternate Members; two each in the three regional subdivisions of List C Member States.
Food prices and the rural poor.
The prices of basic food commodities increased rapidly during the 2007–08 world food price crisis. In only the first quarter of 2008, wheat and maize prices increased by 130% and 30% respectively over 2007 figures. Rice prices, while rising moderately in 2006 and more so in 2007, rose 10% in February 2008 and an additional 10% in March 2008. The threat to food security in developing countries increased in stride. Coordinated action by the international community was essential.
IFAD’s immediate response was to make available up to $200 million, €175 million from existing loans and grants to provide an urgent boost to agricultural production in the developing world, in the face of high food prices and low food stocks. But IFAD would continue to press for rapid and urgent longer-term investment in agriculture, including access to land, water, technology, financial services and markets, to enable the 450 million smallholder farms in developing countries to grow more food, more productively, and thereby increase their incomes and resilience, and respond to the increasing global demand for food.
Status of rural poverty.
Despite improvements over the past ten years that have lifted more than 350 million rural people out of extreme poverty, global poverty remains a massive and predominantly rural phenomenon with 70% of the developing world’s 1.4 billion extremely poor people living in rural areas. IFAD’s 2011 Rural Poverty Report demonstrated that during the past decade, the overall rate of extreme poverty in rural areas of developing countries has dropped from 48% to 34%, led by dramatic gains in East Asia.The report also points to the persistence of poverty in rural areas of sub-Saharan Africa and South Asia.

</doc>
<doc id="36835" url="https://en.wikipedia.org/wiki?curid=36835" title="Auger electron spectroscopy">
Auger electron spectroscopy

Auger electron spectroscopy (AES; pronounced in French) is a common analytical technique used specifically in the study of surfaces and, more generally, in the area of materials science. Underlying the spectroscopic technique is the Auger effect, as it has come to be called, which is based on the analysis of energetic electrons emitted from an excited atom after a series of internal relaxation events. The Auger effect was discovered independently by both Lise Meitner and Pierre Auger in the 1920s. Though the discovery was made by Meitner and initially reported in the journal "Zeitschrift für Physik" in 1922, Auger is credited with the discovery in most of the scientific community. Until the early 1950s Auger transitions were considered nuisance effects by spectroscopists, not containing much relevant material information, but studied so as to explain anomalies in x-ray spectroscopy data. Since 1953 however, AES has become a practical and straightforward characterization technique for probing chemical and compositional surface environments and has found applications in metallurgy, gas-phase chemistry, and throughout the microelectronics industry.
Electron transitions and the Auger effect.
The Auger effect is an electronic process at the heart of AES resulting from the inter- and intrastate transitions of electrons in an excited atom. When an atom is probed by an external mechanism, such as a photon or a beam of electrons with energies in the range of several eV to 50 keV, a core state electron can be removed leaving behind a hole. As this is an unstable state, the core hole can be filled by an outer shell electron, whereby the electron moving to the lower energy level loses an amount of energy equal to the difference in orbital energies. The transition energy can be coupled to a second outer shell electron, which will be emitted from the atom if the transferred energy is greater than the orbital binding energy. An emitted electron will have a kinetic energy of:
where formula_2, formula_3, formula_4 are respectively the core level, first outer shell, and second outer shell electron binding energies, measured from the vacuum level. The apostrophe (tic) denotes a slight modification to the binding energy of the outer shell electrons due to the ionized nature of the atom; often however, this energy modification is ignored in order to ease calculations. Since orbital energies are unique to an atom of a specific element, analysis of the ejected electrons can yield information about the chemical composition of a surface. Figure 1 illustrates two schematic views of the Auger process.
The types of state-to-state transitions available to electrons during an Auger event are dependent on several factors, ranging from initial excitation energy to relative interaction rates, yet are often dominated by a few characteristic transitions. Because of the interaction between an electron's spin and orbital angular momentum (spin-orbit coupling) and the concomitant energy level splitting for various shells in an atom, there are a variety of transition pathways for filling a core hole. Energy levels are labeled using a number of different schemes such as the j-j coupling method for heavy elements ("Z" ≥ 75), the Russell-Saunders L-S method for lighter elements ("Z" < 20), and a combination of both for intermediate elements. The j-j coupling method, which is historically linked to X-ray notation, is almost always used to denote Auger transitions. Thus for a formula_5 transition, "K" represents the core level hole, formula_6 the relaxing electron's initial state, and formula_7 the emitted electron's initial energy state. Figure 1(b) illustrates this transition with the corresponding spectroscopic notation. The energy level of the core hole will often determine which transition types will be favored. For single energy levels, i.e. "K", transitions can occur from the L levels, giving rise to strong KLL type peaks in an Auger spectrum. Higher level transitions can also occur, but are less probable. For multi-level shells, transitions are available from higher energy orbitals (different "n, ℓ" quantum numbers) or energy levels within the same shell (same "n", different "ℓ" number). The result are transitions of the type LMM and KLL along with faster Coster–Kronig transitions such as LLM. While Coster–Kronig transitions are faster, they are also less energetic and thus harder to locate on an Auger spectrum. As the atomic number Z increases, so too does the number of potential Auger transitions. Fortunately, the strongest electron-electron interactions are between levels that are close together, giving rise to characteristic peaks in an Auger spectrum. KLL and LMM peaks are some of the most commonly identified transitions during surface analysis. Finally, valence band electrons can also fill core holes or be emitted during KVV-type transitions.
Several models, both phenomenological and analytical, have been developed to describe the energetics of Auger transitions. One of the most tractable descriptions, put forth by Jenkins and Chung, estimates the energy of Auger transition ABC as:
formula_9 are the binding energies of the formula_10th level in element of atomic number "Z" and formula_11 are the energies of the same levels in the next element up in the periodic table. While useful in practice, a more rigorous model accounting for effects such as screening and relaxation probabilities between energy levels gives the Auger energy as:
where formula_13 is the energy of interaction between the "B" and "C" level holes in a final atomic state "x" and the "R"'s represent intra- and extra-atomic transition energies accounting for electronic screening. Auger electron energies can be calculated based on measured values of the various formula_14 and compared to peaks in the secondary electron spectrum in order to identify chemical species. This technique has been used to compile several reference databases used for analysis in current AES setups.
Experimental setup and quantification.
Instrumentation.
Surface sensitivity in AES arises from the fact that emitted electrons usually have energies ranging from 50 eV to 3 keV and at these values, electrons have a short mean free path in a solid. The escape depth of electrons is therefore localized to within a few nanometers of the target surface, giving AES an extreme sensitivity to surface species. Because of the low energy of Auger electrons, most AES setups are run under ultra-high vacuum (UHV) conditions. Such measures prevent electron scattering off of residual gas atoms as well as the formation of a thin "gas (adsorbate) layer" on the surface of the specimen, which degrades analytical performance. A typical AES setup is shown schematically in figure 2. In this configuration, focused electrons are incident on a sample and emitted electrons are deflected into a cylindrical mirror analyzer (CMA). In the detection unit, Auger electrons are multiplied and the signal sent to data processing electronics. Collected Auger electrons are plotted as a function of energy against the broad secondary electron background spectrum.
Since the intensity of the Auger peaks may be small compared to the noise level of the background, AES is often run in a derivative mode that serves to highlight the peaks by modulating the electron collection current via a small applied AC voltage. Since this formula_15, the collection current becomes formula_16. Taylor expanding gives:
Using the setup in figure 2, detecting the signal at frequency ω will give a value for formula_18 or formula_19. Plotting in derivative mode also emphasizes Auger fine structure, which appear as small secondary peaks surrounding the primary Auger peak. These secondary peaks, not to be confused with high energy satellites, which are discussed later, arise from the presence of the same element in multiple different chemical states on a surface (i.e. Adsorbate layers) or from relaxation transitions involving valence band electrons of the substrate. Figure 3 illustrates a derivative spectrum from a copper nitride film clearly showing the Auger peaks. The peak in derivative mode is not the true Auger peak, but rather the point of maximum slope of "N(E)", but this concern is usually ignored.
Quantitative analysis.
Semi-quantitative compositional and element analysis of a sample using AES is dependent on measuring the yield of Auger electrons during a probing event. Electron yield, in turn, depends on several critical parameters such as electron-impact cross-section and fluorescence yield. Since the Auger effect is not the only mechanism available for atomic relaxation, there is a competition between radiative and non-radiative decay processes to be the primary de-excitation pathway. The total transition rate, ω, is a sum of the non-radiative (Auger) and radiative (photon emission) processes. The Auger yield, formula_20, is thus related to the fluorescence (x-ray) yield, formula_21, by the relation,
where formula_23 is the X-ray transition probability and formula_24 is the Auger transition probability. Attempts to relate the fluorescence and Auger yields to atomic number have resulted in plots similar to figure 4. A clear transition from electron to photon emission is evident in this chart for increasing atomic number. For heavier elements, x-ray yield becomes greater than Auger yield, indicating an increased difficulty in measuring the Auger peaks for large Z-values. Conversely, AES is sensitive to the lighter elements, and unlike X-ray fluorescence, Auger peaks can be detected for elements as light as lithium ("Z" = 3). Lithium represents the lower limit for AES sensitivity since the Auger effect is a "three state" event necessitating at least three electrons. Neither H nor He can be detected with this technique. For K-level based transitions, Auger effects are dominant for "Z" < 15 while for L- and M-level transitions, AES data can be measured for "Z" ≤ 50. The yield limits effectively prescribe a cutoff for AES sensitivity, but complex techniques can be utilized to identify heavier elements, such as uranium and americium, using the Auger effect.
Another critical quantity that determines yield of Auger electrons at a detector is the electron impact cross-section. Early approximations (in cm2) of the cross-section were based on the work of Worthington and Tomlin,
with "b" acting as a scaling factor between 0.25 and 0.35, and "C" a function of the primary electron beam energy, formula_26. While this value of formula_27 is calculated for an isolated atom, a simple modification can be made to account for matrix effects:
where α is the angle to the surface normal of the incident electron beam; "rm" can be established empirically and encompasses electron interactions with the matrix such as ionization due to backscattered electrons. Thus the total yield can be written as:
Here "Nx" is the number of "x" atoms per volume, λ the electron escape depth, θ the analyzer angle, "T" the transmission of the analyzer, "I(t)" the electron excitation flux at depth "t", dΩ the solid angle, and δt is the thickness of the layer being probed. Encompassed in these terms, especially the Auger yield, which is related to the transition probability, is the quantum mechanical overlap of the initial and final state wave functions. Precise expressions for the transition probability, based on first-order perturbation Hamiltonians, can be found in Thompson and Baker. Often, all of these terms are not known, so most analyses compare measured yields with external standards of known composition. Ratios of the acquired data to standards can eliminate common terms, especially experimental setup characteristics and material parameters, and can be used to determine element composition. Comparison techniques work best for samples of homogeneous binary materials or uniform surface layers, while elemental identification is best obtained from comparison of pure samples.
Uses.
There are a number of electron microscopes that have been specifically designed for use in Auger spectroscopy; these are termed scanning Auger microscopes (SAM) and can produce high resolution, spatially resolved chemical images. SAM images are obtained by stepping a focused electron beam across a sample surface and measuring the intensity of the Auger peak above the background of scattered electrons. The intensity map is correlated to a gray scale on a monitor with whiter areas corresponding to higher element concentration. In addition, sputtering is sometimes used with Auger spectroscopy to perform depth profiling experiments. Sputtering removes thin outer layers of a surface so that AES can be used to determine the underlying composition. Depth profiles are shown as either Auger peak height vs. sputter time or atomic concentration vs. depth. Precise depth milling through sputtering has made profiling an invaluable technique for chemical analysis of nanostructured materials and thin films. AES is also used extensively as an evaluation tool on and off fab lines in the microelectronics industry, while the versatility and sensitivity of the Auger process makes it a standard analytical tool in research labs. Theoretically, Auger spectra can also be utilized to distinguish between protonation states. When a molecule is protonated or deprotonated, the geometry and electronic structure is changed, and AES spectra reflect this. In general, as a molecule becomes more protonated, the ionization potentials increase and the kinetic energy of the emitted outer shell electrons decreases.
Despite the advantages of high spatial resolution and precise chemical sensitivity attributed to AES, there are several factors that can limit the applicability of this technique, especially when evaluating solid specimens. One of the most common limitations encountered with Auger spectroscopy are charging effects in non-conducting samples. Charging results when the number of secondary electrons leaving the sample is different from the number of incident electrons, giving rise to a net positive or negative electric charge at the surface. Both positive and negative surface charges severely alter the yield of electrons emitted from the sample and hence distort the measured Auger peaks. To complicate matters, neutralization methods employed in other surface analysis techniques, such as secondary ion mass spectrometry (SIMS), are not applicable to AES, as these methods usually involve surface bombardment with either electrons or ions (i.e. flood gun). Several processes have been developed to combat the issue of charging, though none of them is ideal and still make quantification of AES data difficult. One such technique involves depositing conductive pads near the analysis area to minimize regional charging. However, this type of approach limits SAM applications as well as the amount of sample material available for probing. A related technique involves thinning or "dimpling" a non-conductive layer with Ar+ ions and then mounting the sample to a conductive backing prior to AES. This method has been debated, with claims that the thinning process leaves elemental artifacts on a surface and/or creates damaged layers that distort bonding and promote chemical mixing in the sample. As a result, the compositional AES data is considered suspect. The most common setup to minimize charging effects includes use of a glancing angle (~10°) electron beam and a carefully tuned bombarding energy (between 1.5 keV and 3 keV). Control of both the angle and energy can subtly alter the number of emitted electrons vis-à-vis the incident electrons and thereby reduce or altogether eliminate sample charging.
In addition to charging effects, AES data can be obscured by the presence of characteristic energy losses in a sample and higher order atomic ionization events. Electrons ejected from a solid will generally undergo multiple scattering events and lose energy in the form of collective electron density oscillations called plasmons. If plasmon losses have energies near that of an Auger peak, the less intense Auger process may become dwarfed by the plasmon peak. As Auger spectra are normally weak and spread over many eV of energy, they are difficult to extract from the background and in the presence of plasmon losses; deconvolution of the two peaks becomes extremely difficult. For such spectra, additional analysis through chemical sensitive surface techniques like x-ray photoelectron spectroscopy (XPS) is often required to disentangle the peaks. Sometimes an Auger spectrum can also exhibit "satellite" peaks at well-defined off-set energies from the parent peak. Origin of the satellites is usually attributed to multiple ionization events in an atom or ionization cascades in which a series of electrons is emitted as relaxation occurs for core holes of multiple levels. The presence of satellites can distort the true Auger peak and/or small peak shift information due to chemical bonding at the surface. Several studies have been undertaken to further quantify satellite peaks.
Despite these sometimes substantial drawbacks, Auger electron spectroscopy is a widely used surface analysis technique that has been successfully applied to many diverse fields ranging from gas phase chemistry to nanostructure characterization. Very new class of high-resolving electrostatic energy analyzers recently developed – the face-field analyzers (FFA) can be used for remote electron spectroscopy of distant surfaces or surfaces with large roughness or even with deep dimples. These instruments are designed as if to be specifically used in combined scanning electron microscopes (SEMs). "FFA" in principle have no perceptible end-fields, which usually distort focusing in most of analysers known, for example, well known CMA.
Sensitivity, quantitative detail, and ease of use have brought AES from an obscure nuisance effect to a functional and practical characterization technique in just over fifty years. With applications both in the research laboratory and industrial settings, AES will continue to be a cornerstone of surface-sensitive electron-based spectroscopies.

</doc>
