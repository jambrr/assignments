<doc id="33426" url="https://en.wikipedia.org/wiki?curid=33426" title="Wave–particle duality">
Wave–particle duality

Wave–particle duality is the concept that every elementary particle or quantic entity may be partly described in terms not only of particles, but also of waves. It expresses the inability of the classical concepts "particle" or "wave" to fully describe the behavior of quantum-scale objects. As Einstein wrote: ""It seems as though we must use sometimes the one theory and sometimes the other, while at times we may use either. We are faced with a new kind of difficulty. We have two contradictory pictures of reality; separately neither of them fully explains the phenomena of light, but together they do"".
Through the work of Max Planck, Albert Einstein, Louis de Broglie, Arthur Compton, Niels Bohr, and many others, current scientific theory holds that "all" particles "also" have a wave nature (and vice versa). This phenomenon has been verified not only for elementary particles, but also for compound particles like atoms and even molecules. For macroscopic particles, because of their extremely short wavelengths, wave properties usually cannot be detected.
Although the use of the wave-particle duality has worked well in physics, the "meaning" or "interpretation" has not been satisfactorily resolved; see Interpretations of quantum mechanics.
Niels Bohr regarded the "duality paradox" as a fundamental or metaphysical fact of nature. A given kind of quantum object will exhibit sometimes wave, sometimes particle, character, in respectively different physical settings. He saw such duality as one aspect of the concept of complementarity. Bohr regarded renunciation of the cause-effect relation, or complementarily, of the space-time picture, as essential to the quantum mechanical account.
Werner Heisenberg considered the question further. He saw the duality as present for all quantic entities, but not quite in the usual quantum mechanical account considered by Bohr. He saw it in what is called second quantization, which generates an entirely new concept of fields which exist in ordinary space-time, causality still being visualizable. Classical field values (e.g. the electric and magnetic field strengths of Maxwell) are replaced by an entirely new kind of field value, as considered in quantum field theory. Turning the reasoning around, ordinary quantum mechanics can be deduced as a specialized consequence of quantum field theory.
Brief history of wave and particle viewpoints.
Aristotle was one of the first to publicly hypothesize about the nature of light, proposing that light is a disturbance in the element aether (that is, it is a wave-like phenomenon). On the other hand, Democritus—the original "atomist"—argued that all things in the universe, including light, are composed of indivisible sub-components (light being some form of solar atom). At the beginning of the 11th Century, the Arabic scientist Alhazen wrote the first comprehensive treatise on optics; describing refraction, reflection, and the operation of a pinhole lens via rays of light traveling from the point of emission to the eye. He asserted that these rays were composed of particles of light. In 1630, René Descartes popularized and accredited the opposing wave description in his treatise on light, showing that the behavior of light could be re-created by modeling wave-like disturbances in a universal medium ("plenum"). Beginning in 1670 and progressing over three decades, Isaac Newton developed and championed his corpuscular hypothesis, arguing that the perfectly straight lines of reflection demonstrated light's particle nature; only particles could travel in such straight lines. He explained refraction by positing that particles of light accelerated laterally upon entering a denser medium. Around the same time, Newton's contemporaries Robert Hooke and Christiaan Huygens—and later Augustin-Jean Fresnel—mathematically refined the wave viewpoint, showing that if light traveled at different speeds in different media (such as water and air), refraction could be easily explained as the medium-dependent propagation of light waves. The resulting Huygens–Fresnel principle was extremely successful at reproducing light's behavior and was subsequently supported by Thomas Young's 1803 discovery of double-slit interference. The wave view did not immediately displace the ray and particle view, but began to dominate scientific thinking about light in the mid 19th century, since it could explain polarization phenomena that the alternatives could not.
James Clerk Maxwell discovered that he could combine four simple equations, which had been previously discovered, along with a slight modification to describe self-propagating waves of oscillating electric and magnetic fields. When the propagation speed of these electromagnetic waves was calculated, the speed of light fell out. It quickly became apparent that visible light, ultraviolet light, and infrared light (phenomena thought previously to be unrelated) were all electromagnetic waves of differing frequency. The wave theory had prevailed—or at least it seemed to.
While the 19th century had seen the success of the wave theory at describing light, it had also witnessed the rise of the atomic theory at describing matter. Antoine Lavoisier deduced the law of conservation of mass and categorized many new chemical elements and compounds; and Joseph Louis Proust advanced chemistry towards the atom by showing that elements combined in definite proportions. This led John Dalton to propose that elements were invisible sub components; Amedeo Avogadro discovered diatomic gases and completed the basic atomic theory, allowing the correct molecular formulae of most known compounds—as well as the correct weights of atoms—to be deduced and categorized in a consistent manner. Dimitri Mendeleev saw an order in recurring chemical properties, and created a table presenting the elements in unprecedented order and symmetry.
Turn of the 20th century and the paradigm shift.
Particles of electricity.
At the close of the 19th century, the reductionism of atomic theory began to advance into the atom itself; determining, through physics, the nature of the atom and the operation of chemical reactions. Electricity, first thought to be a fluid, was now understood to consist of particles called electrons. This was first demonstrated by J. J. Thomson in 1897 when, using a cathode ray tube, he found that an electrical charge would travel across a vacuum (which would possess infinite resistance in classical theory). Since the vacuum offered no medium for an electric fluid to travel, this discovery could only be explained via a particle carrying a negative charge and moving through the vacuum. This "electron" flew in the face of classical electrodynamics, which had successfully treated electricity as a fluid for many years (leading to the invention of batteries, electric motors, dynamos, and arc lamps). More importantly, the intimate relation between electric charge and electromagnetism had been well documented following the discoveries of Michael Faraday and James Clerk Maxwell. Since electromagnetism was "known" to be a wave generated by a changing electric or magnetic "field" (a continuous, wave-like entity itself) an atomic/particle description of electricity and charge was a non sequitur. Furthermore, classical electrodynamics was not the only classical theory rendered incomplete.
Radiation quantization.
In 1901, Max Planck published an analysis that succeeded in reproducing the observed spectrum of light emitted by a glowing object. To accomplish this, Planck had to make an ad hoc mathematical assumption of quantized energy of the oscillators (atoms of the black body) that emit radiation. It was Einstein who later proposed that it is the electromagnetic radiation itself that is quantized, and not the energy of radiating atoms.
Black-body radiation, the emission of electromagnetic energy due to an object's heat, could not be explained from classical arguments alone. The equipartition theorem of classical mechanics, the basis of all classical thermodynamic theories, stated that an object's energy is partitioned equally among the object's vibrational modes. But applying the same reasoning to the electromagnetic emission of such a thermal object was not so successful. It had been long known that thermal objects emit light. Since light was known to be waves of electromagnetism, physicists hoped to describe this emission via classical laws. This became known as the black body problem. Since the equipartition theorem worked so well in describing the vibrational modes of the thermal object itself, it was natural to assume that it would perform equally well in describing the radiative emission of such objects. But a problem quickly arose: if each mode received an equal partition of energy, the short wavelength modes would consume all the energy. This became clear when plotting the Rayleigh–Jeans law which, while correctly predicting the intensity of long wavelength emissions, predicted infinite total energy as the intensity diverges to infinity for short wavelengths. This became known as the ultraviolet catastrophe.
In 1900 when Max Planck hypothesized that the frequency of light emitted by the black body depended on the frequency of the "oscillator" that emitted it, and the energy of these oscillators increased linearly with frequency (according to his constant "h", where E = hν). This was not an unsound proposal considering that macroscopic oscillators operate similarly: when studying five simple harmonic oscillators of equal amplitude but different frequency, the oscillator with the highest frequency possesses the highest energy (though this relationship is not linear like Planck's). By demanding that high-frequency light must be emitted by an oscillator of equal frequency, and further requiring that this oscillator occupy higher energy than one of a lesser frequency, Planck avoided any catastrophe; giving an equal partition to high-frequency oscillators produced successively fewer oscillators and less emitted light. And as in the Maxwell–Boltzmann distribution, the low-frequency, low-energy oscillators were suppressed by the onslaught of thermal jiggling from higher energy oscillators, which necessarily increased their energy and frequency.
The most revolutionary aspect of Planck's treatment of the black body is that it inherently relies on an integer number of oscillators in thermal equilibrium with the electromagnetic field. These oscillators "give" their entire energy to the electromagnetic field, creating a quantum of light, as often as they are "excited" by the electromagnetic field, absorbing a quantum of light and beginning to oscillate at the corresponding frequency. Planck had intentionally created an atomic theory of the black body, but had unintentionally generated an atomic theory of light, where the black body never generates quanta of light at a given frequency with an energy less than hν. However, once realizing that he had quantized the electromagnetic field, he denounced particles of light as a limitation of his approximation, not a property of reality.
Photoelectric effect illuminated.
While Planck had solved the ultraviolet catastrophe by using atoms and a quantized electromagnetic field, most contemporary physicists agreed that Planck's "light quanta" represented only flaws in his model. A more-complete derivation of black body radiation would yield a fully continuous and 'wave-like' electromagnetic field with no quantization. However, in 1905 Albert Einstein took Planck's black body model to produce his solution to another outstanding problem of the day: the photoelectric effect, wherein electrons are emitted from atoms when they absorb energy from light. Since their discovery eight years previously, electrons had been "the" thing to study in physics laboratories worldwide.
In 1902 Philipp Lenard discovered that the energy of these ejected electrons did "not" depend on the intensity of the incoming light, but instead on its "frequency". So if one shines a little low-frequency light upon a metal, a few low energy electrons are ejected. If one now shines a very intense beam of low-frequency light upon the same metal, a whole slew of electrons are ejected; however they possess the same low energy, there are merely "more of them". The more light there is, the more electrons are ejected. Whereas in order to get high energy electrons, one must illuminate the metal with high-frequency light. Like blackbody radiation, this was at odds with a theory invoking continuous transfer of energy between radiation and matter. However, it can still be explained using a fully classical description of light, as long as matter is quantum mechanical in nature.
If one used Planck's energy quanta, and demanded that electromagnetic radiation at a given frequency could only transfer energy to matter in integer multiples of an energy quantum hν, then the photoelectric effect could be explained very simply. Low-frequency light only ejects low-energy electrons because each electron is excited by the absorption of a single photon. Increasing the intensity of the low-frequency light (increasing the number of photons) only increases the number of excited electrons, not their energy, because the energy of each photon remains low. Only by increasing the frequency of the light, and thus increasing the energy of the photons, can one eject electrons with higher energy. Thus, using Planck's constant "h" to determine the energy of the photons based upon their frequency, the energy of ejected electrons should also increase linearly with frequency; the gradient of the line being Planck's constant. These results were not confirmed until 1915, when Robert Andrews Millikan, who had previously determined the charge of the electron, produced experimental results in perfect accord with Einstein's predictions. While the energy of ejected electrons reflected Planck's constant, the existence of photons was not explicitly proven until the discovery of the photon antibunching effect, of which a modern experiment can be performed in undergraduate-level labs. This phenomenon could only be explained via photons, and not through any semi-classical theory (which could alternatively explain the photoelectric effect). When Einstein received his Nobel Prize in 1921, it was not for his more difficult and mathematically laborious special and general relativity, but for the simple, yet totally revolutionary, suggestion of quantized light. Einstein's "light quanta" would not be called photons until 1925, but even in 1905 they represented the quintessential example of wave-particle duality. Electromagnetic radiation propagates following linear wave equations, but can only be emitted or absorbed as discrete elements, thus acting as a wave and a particle simultaneously.
Einstein's explanation of the photoelectric effect.
In 1905, Albert Einstein provided an explanation of the photoelectric effect, a hitherto troubling experiment that the wave theory of light seemed incapable of explaining. He did so by postulating the existence of photons, quanta of light energy with particulate qualities.
In the photoelectric effect, it was observed that shining a light on certain metals would lead to an electric current in a circuit. Presumably, the light was knocking electrons out of the metal, causing current to flow. However, using the case of potassium as an example, it was also observed that while a dim blue light was enough to cause a current, even the strongest, brightest red light available with the technology of the time caused no current at all. According to the classical theory of light and matter, the strength or amplitude of a light wave was in proportion to its brightness: a bright light should have been easily strong enough to create a large current. Yet, oddly, this was not so.
Einstein explained this conundrum by postulating that the electrons can receive energy from electromagnetic field only in discrete portions (quanta that were called photons): an amount of energy "E" that was related to the frequency "f" of the light by
where "h" is Planck's constant (6.626 × 10−34 J seconds). Only photons of a high enough frequency (above a certain "threshold" value) could knock an electron free. For example, photons of blue light had sufficient energy to free an electron from the metal, but photons of red light did not. One photon of light above the threshold frequency could release only one electron; the higher the frequency of a photon, the higher the kinetic energy of the emitted electron, but no amount of light (using technology available at the time) below the threshold frequency could release an electron. To "violate" this law would require extremely high-intensity lasers which had not yet been invented. Intensity-dependent phenomena have now been studied in detail with such lasers.
Einstein was awarded the Nobel Prize in Physics in 1921 for his discovery of the law of the photoelectric effect.
De Broglie's wavelength.
In 1924, Louis-Victor de Broglie formulated the de Broglie hypothesis, claiming that "all" matter, not just light, has a wave-like nature; he related wavelength (denoted as "λ"), and momentum (denoted as "p"):
This is a generalization of Einstein's equation above, since the momentum of a photon is given by "p" = formula_3 and the wavelength (in a vacuum) by "λ" = formula_4, where "c" is the speed of light in vacuum.
De Broglie's formula was confirmed three years later for electrons (which differ from photons in having a rest mass) with the observation of electron diffraction in two independent experiments. At the University of Aberdeen, George Paget Thomson passed a beam of electrons through a thin metal film and observed the predicted interference patterns. At Bell Labs, Clinton Joseph Davisson and Lester Halbert Germer guided their beam through a crystalline grid.
De Broglie was awarded the Nobel Prize for Physics in 1929 for his hypothesis. Thomson and Davisson shared the Nobel Prize for Physics in 1937 for their experimental work.
Heisenberg's uncertainty principle.
In his work on formulating quantum mechanics, Werner Heisenberg postulated his uncertainty principle, which states:
where
Heisenberg originally explained this as a consequence of the process of measuring: Measuring position accurately would disturb momentum and vice versa, offering an example (the "gamma-ray microscope") that depended crucially on the de Broglie hypothesis. It is now thought, however, that this only partly explains the phenomenon, but that the uncertainty also exists in the particle itself, even before the measurement is made.
In fact, the modern explanation of the uncertainty principle, extending the Copenhagen interpretation first put forward by Bohr and Heisenberg, depends even more centrally on the wave nature of a particle: Just as it is nonsensical to discuss the precise location of a wave on a string, particles do not have perfectly precise positions; likewise, just as it is nonsensical to discuss the wavelength of a "pulse" wave traveling down a string, particles do not have perfectly precise momenta (which corresponds to the inverse of wavelength). Moreover, when position is relatively well defined, the wave is pulse-like and has a very ill-defined wavelength (and thus momentum). And conversely, when momentum (and thus wavelength) is relatively well defined, the wave looks long and sinusoidal, and therefore it has a very ill-defined position.
de Broglie–Bohm theory.
De Broglie himself had proposed a pilot wave construct to explain the observed wave-particle duality. In this view, each particle has a well-defined position and momentum, but is guided by a wave function derived from Schrödinger's equation. The pilot wave theory was initially rejected because it generated non-local effects when applied to systems involving more than one particle. Non-locality, however, soon became established as an integral feature of quantum theory (see EPR paradox), and David Bohm extended de Broglie's model to explicitly include it.
In the resulting representation, also called the de Broglie–Bohm theory or Bohmian mechanics, the wave-particle duality vanishes, and explains the wave behaviour as a scattering with wave appearance, because the particle's motion is subject to a guiding equation or quantum potential. ""This idea seems to me so natural and simple, to resolve the wave-particle dilemma in such a clear and ordinary way, that it is a great mystery to me that it was so generally ignored"", J.S.Bell.
The best illustration of the "pilot-wave model" was given by Couder's 2010 "walking droplets" experiments, demonstrating the pilot-wave behaviour in a macroscopic mechanical analog.
Wave behavior of large objects.
Since the demonstrations of wave-like properties in photons and electrons, similar experiments have been conducted with neutrons and protons. Among the most famous experiments are those of Estermann and Otto Stern in 1929.
Authors of similar recent experiments with atoms and molecules, described below, claim that these larger particles also act like waves. A wave is basically a group of particles which moves in a particular form of motion i.e. to and fro, if we break that flow by an object it will convert into radiants.
A dramatic series of experiments emphasizing the action of gravity in relation to wave–particle duality was conducted in the 1970s using the neutron interferometer. Neutrons, one of the components of the atomic nucleus, provide much of the mass of a nucleus and thus of ordinary matter. In the neutron interferometer, they act as quantum-mechanical waves directly subject to the force of gravity. While the results were not surprising since gravity was known to act on everything, including light (see tests of general relativity and the Pound–Rebka falling photon experiment), the self-interference of the quantum mechanical wave of a massive fermion in a gravitational field had never been experimentally confirmed before.
In 1999, the diffraction of C60 fullerenes by researchers from the University of Vienna was reported. Fullerenes are comparatively large and massive objects, having an atomic mass of about 720 u. The de Broglie wavelength is 2.5 pm, whereas the diameter of the molecule is about 1 nm, about 400 times larger. In 2012, these far-field diffraction experiments could be extended to phthalocyanine molecules and their heavier derivatives, which are composed of 58 and 114 atoms respectively. In these experiments the build-up of such interference patterns could be recorded in real time and with single molecule sensitivity.
In 2003, the Vienna group also demonstrated the wave nature of tetraphenylporphyrin—a flat biodye with an extension of about 2 nm and a mass of 614 u. For this demonstration they employed a near-field Talbot Lau interferometer. In the same interferometer they also found interference fringes for C60F48., a fluorinated buckyball with a mass of about 1600 u, composed of 108 atoms. Large molecules are already so complex that they give experimental access to some aspects of the quantum-classical interface, i.e., to certain decoherence mechanisms. In 2011, the interference of molecules as heavy as 6910 u could be demonstrated in a Kapitza–Dirac–Talbot–Lau interferometer. In 2013, the interference of molecules beyond 10,000 u has been demonstrated.
Whether objects heavier than the Planck mass (about the weight of a large bacterium) have a de Broglie wavelength is theoretically unclear and experimentally unreachable; above the Planck mass a particle's Compton wavelength would be smaller than the Planck length and its own Schwarzschild radius, a scale at which current theories of physics may break down or need to be replaced by more general ones.
Recently Couder, Fort, "et al." showed that we can use macroscopic oil droplets on a vibrating surface as a model of wave–particle duality—localized droplet creates periodical waves around and interaction with them leads to quantum-like phenomena: interference in double-slit experiment, unpredictable tunneling (depending in complicated way on practically hidden state of field), orbit quantization (that particle has to 'find a resonance' with field perturbations it creates—after one orbit, its internal phase has to return to the initial state) and Zeeman effect.
Treatment in modern quantum mechanics.
Wave–particle duality is deeply embedded into the foundations of quantum mechanics. In the formalism of the theory, all the information about a particle is encoded in its "wave function", a complex-valued function roughly analogous to the amplitude of a wave at each point in space. This function evolves according to a differential equation (generically called the Schrödinger equation). For particles with mass this equation has solutions that follow the form of the wave equation. Propagation of such waves leads to wave-like phenomena such as interference and diffraction. Particles without mass, like photons, have no solutions of the Schrödinger equation so have another wave.
The particle-like behavior is most evident due to phenomena associated with measurement in quantum mechanics. Upon measuring the location of the particle, the particle will be forced into a more localized state as given by the uncertainty principle. When viewed through this formalism, the measurement of the wave function will randomly "collapse", or rather "decohere", to a sharply peaked function at some location. For particles with mass the likelihood of detecting the particle at any particular location is equal to the squared amplitude of the wave function there. The measurement will return a well-defined position, (subject to uncertainty), a property traditionally associated with particles. It is important to note that a measurement is only a particular type of interaction where some data is recorded and the measured quantity is forced into a particular eigenstate. The act of measurement is therefore not fundamentally different from any other interaction.
Following the development of quantum field theory the ambiguity disappeared. The field permits solutions that follow the wave equation, which are referred to as the wave functions. The term particle is used to label the irreducible representations of the Lorentz group that are permitted by the field. An interaction as in a Feynman diagram is accepted as a calculationally convenient approximation where the outgoing legs are known to be simplifications of the propagation and the internal lines are for some order in an expansion of the field interaction. Since the field is non-local and quantized, the phenomena which previously were thought of as paradoxes are explained. Within the limits of the wave-particle duality the quantum field theory gives the same results.
Visualization.
There are two ways to visualize the wave-particle behaviour: by the "standard model", described below; and by the Broglie–Bohm model, where no duality is perceived.
Below is an illustration of wave–particle duality as it relates to De Broglie's hypothesis and Heisenberg's uncertainty principle (above), in terms of the position and momentum space wavefunctions for one spinless particle with mass in one dimension. These wavefunctions are Fourier transforms of each other.
The more localized the position-space wavefunction, the more likely the particle is to be found with the position coordinates in that region, and correspondingly the momentum-space wavefunction is less localized so the possible momentum components the particle could have are more widespread.
Conversely the more localized the momentum-space wavefunction, the more likely the particle is to be found with those values of momentum components in that region, and correspondingly the less localized the position-space wavefunction, so the position coordinates the particle could occupy are more widespread.
Alternative views.
Wave–particle duality is an ongoing conundrum in modern physics. Most physicists accept wave-particle duality as the best explanation for a broad range of observed phenomena; however, it is not without controversy. Alternative views are also presented here. These views are not generally accepted by mainstream physics, but serve as a basis for valuable discussion within the community.
Both-particle-and-wave view.
The pilot wave model, originally developed by Louis de Broglie and further developed by David Bohm into the hidden variable theory proposes that there is no duality, but rather a system exhibits both particle properties and wave properties simultaneously, and particles are guided, in a deterministic fashion, by the pilot wave (or its "quantum potential") which will direct them to areas of constructive interference in preference to areas of destructive interference. This idea is held by a significant minority within the physics community.
At least one physicist considers the "wave-duality" as not being an incomprehensible mystery. L.E. Ballentine, "Quantum Mechanics, A Modern Development", p. 4, explains:
When first discovered, particle diffraction was a source of great puzzlement. Are "particles" really "waves?" In the early experiments, the diffraction patterns were detected holistically by means of a photographic plate, which could not detect individual particles. As a result, the notion grew that particle and wave properties were mutually incompatible, or complementary, in the sense that different measurement apparatuses would be required to observe them. That idea, however, was only an unfortunate generalization from a technological limitation. Today it is possible to detect the arrival of individual electrons, and to see the diffraction pattern emerge as a statistical pattern made up of many small spots (Tonomura et al., 1989). Evidently, quantum particles are indeed particles, but whose behaviour is very different from classical physics would have us to expect.
It has been claimed that the Afshar experiment (2007) shows that it is possible to simultaneously observe both wave and particle properties of photons. This claim is, however, rejected by other scientists.
Wave-only view.
At least one scientist proposes that the duality can be replaced by a "wave-only" view. In his book "Collective Electrodynamics: Quantum Foundations of Electromagnetism" (2000), Carver Mead purports to analyze the behavior of electrons and photons purely in terms of electron wave functions, and attributes the apparent particle-like behavior to quantization effects and eigenstates. According to reviewer David Haddon:
Mead has cut the Gordian knot of quantum complementarity. He claims that atoms, with their neutrons, protons, and electrons, are not particles at all but pure waves of matter. Mead cites as the gross evidence of the exclusively wave nature of both light and matter the discovery between 1933 and 1996 of ten examples of pure wave phenomena, including the ubiquitous laser of CD players, the self-propagating electrical currents of superconductors, and the Bose–Einstein condensate of atoms.
Albert Einstein, who, in his search for a Unified Field Theory, did not accept wave-particle duality, wrote:
This double nature of radiation (and of material corpuscles)...has been interpreted by quantum-mechanics in an ingenious and amazingly successful fashion. This interpretation...appears to me as only a temporary way out...
The many-worlds interpretation (MWI) is sometimes presented as a waves-only theory, including by its originator, Hugh Everett who referred to MWI as "the wave interpretation".
The "" of R. Horodecki relates the particle to wave. The hypothesis implies that a massive particle is an intrinsically spatially as well as temporally extended wave phenomenon by a nonlinear law.
Particle-only view.
Still in the days of the old quantum theory, a pre-quantum-mechanical version of wave–particle duality was pioneered by William Duane, and developed by others including Alfred Landé. Duane explained diffraction of x-rays by a crystal in terms solely of their particle aspect. The deflection of the trajectory of each diffracted photon was due to quantal translative momentum transfer from the spatially regular structure of the diffracting crystal. Fourier analysis reveals the wave–particle duality as a simply mathematical equivalence, always present, and universal for all quanta. The same reasoning applies for example to diffraction of electrons by a crystal.
Neither-wave-nor-particle view.
It has been argued that there are never exact particles or waves, but only some compromise or intermediate between them. For this reason, in 1928 Arthur Eddington coined the name ""wavicle"" to describe the objects although it is not regularly used today. One consideration
is that zero-dimensional mathematical points cannot be observed. Another is that the formal representation of such points, the Dirac delta function is unphysical, because it cannot be normalized. Parallel arguments apply to pure wave states. Roger Penrose states:
"Such 'position states' are idealized wavefunctions in the opposite sense from the momentum states. Whereas the momentum states are infinitely spread out, the position states are infinitely concentrated. Neither is normalizable [...]."
Relational approach to wave–particle duality.
Relational quantum mechanics is developed which regards the detection event as establishing a relationship between the quantized field and the detector. The inherent ambiguity associated with applying Heisenberg's uncertainty principle and thus wave–particle duality is subsequently avoided.
Applications.
Although it is difficult to draw a line separating wave–particle duality from the rest of quantum mechanics, it is nevertheless possible to list some applications of this basic idea.

</doc>
<doc id="33430" url="https://en.wikipedia.org/wiki?curid=33430" title="Wolfenstein 3D">
Wolfenstein 3D

Wolfenstein 3D is a 3D first-person shooter video game developed by id Software and published by Apogee Software. Originally released on May 5, 1992, for the PC operating system DOS, the game was inspired by the 1980s Muse Software video games "Castle Wolfenstein" and "Beyond Castle Wolfenstein". A promotional version of "Wolfenstein 3D" was released as shareware, which permitted it to be copied widely. The game was later ported to a wide range of computer systems and video game consoles.
The shareware release contains one episode consisting of ten levels. The commercial release consists of three episodes, which include the shareware episode and two subsequent episodes. Later releases included a three-episode mission pack titled "The Nocturnal Missions". The player assumes the role of a World War II Allied spy William "B.J." Blazkowicz, who is trying to escape from Castle Wolfenstein, a Nazi German prison. After the initial escape episode, Blazkowicz carries out a series of crucial missions against the Nazis.
"Wolfenstein 3D" was a critical and commercial success. It is widely regarded as having helped popularize the genre on the PC and having established the basic run-and-gun archetype for many subsequent first-person shooter games.
Gameplay.
Each episode features nine levels (or "maps"), which must be finished sequentially. Levels are completed by reaching an elevator that leads to the next level. The player must fight guards, dogs, and other enemies while maintaining supplies of ammunition and health. If the player's health falls to zero, the player loses one life and all his or her guns and ammunition, except a pistol with eight rounds and a knife. A submachine gun and a rapid-firing chain gun, which all use the same type of ammunition, are also available. The player begins each episode with three lives, and can gain more lives by finding extra-life tokens or by earning 40,000 points. The original version of the game allows the player to save the game at any point, while in most console versions the player must complete each level before saving the game. The players can collect treasures scattered throughout the levels to boost their score. Walls can be searched for secret passages which lead to caches of treasure, ammunition, and/or health refills. Percentages for collecting treasures, eliminating enemies and discovering secrets discovered are displayed at the end of each level. The player can score additional bonus points by earning a 100% kill, secret, or treasure ratio, or completing the level more quickly than average.
Each episode has a different boss, who must be killed in the final mission to complete the episode. Unlike normal enemies, boss enemies are drawn from one angle instead of eight; they are always facing the player, and so cannot be taken by surprise. Bosses are initially stationary and do not become active until they see the player. When most bosses are dead, a replay (called a deathcam) of the boss' death is shown and the episode ends. In other levels there is an exit from the stronghold behind the boss; entering it causes the camera to rotate to face Blazkowicz and show him running out and jumping in elation. Each episode has one secret level that can only be accessed when player uncovers a hidden elevator. The secret level of the third episode is a recreation of a level in "Pac-Man" complete with ghosts, which the player sees from Pac-Man's perspective.
Plot.
The first three episodes of the game are concerned with the protagonist William "B.J." Blazkowicz's efforts to destroy the Nazi regime. Blazkowicz is an American spy of Polish descent. In the first episode, "Escape from Castle Wolfenstein", he has been captured while trying to find the plans for Operation Eisenfaust (Iron Fist) and has been imprisoned in Castle Wolfenstein by the SS. Initially armed with a knife and a Luger P08 obtained by overpowering the guard in his cell, Blazkowicz tries to escape from the prison. He takes on the guards and eventually finds himself face-to-face with Hans Grosse, the head prison guard. In the second episode, "Operation: Eisenfaust", Blazkowicz finds that the operation is real and that the Nazis are creating an army of undead mutants in Castle Hollehammer. He enters the castle and confronts the mad scientist and creator of the mutants Dr. Schabbs, whose defeat signals the end of this biological war. "Die, Führer, Die!" is chronologically the final episode. Fighting Nazi soldiers and attacking the bunker under the Reichstag, Blazkowicz finds himself up against Adolf Hitler, who is equipped with a robotic suit and four chain guns.
"The Nocturnal Missions" form a prequel storyline, dealing with German plans for chemical warfare (Giftkrieg, literally "poison warfare"). Like the original episodes, each episode contains ten levels. "A Dark Secret" deals with the initial pursuit of the scientist responsible for developing the weaponry. Blazkowicz must enter the weapons research facility and hunt down another mad scientist, Dr. Otto Giftmacher (Poisonmaker). "Trail of the Madman" takes place in Castle Erlangen. Blazkowicz's goal is to find the maps and plans of the chemical war, which are guarded by Gretel Grosse, Hans' sister. The story ends in "Confrontation", which is set in Castle Offenbach. The final battle between Blazkowicz and General Fettgesicht (Fatface), the leader of the chemical war initiative, is fought.
Despite the game's historical setting and the presence of Hitler as an episode boss, the game bears no resemblance to any actual Nazi plans or structures. Many of the level designs are highly fanciful; at least three levels heavily feature swastika-shaped room layouts and maps; one level (episode 6, map 3) is built entirely of a tessellation of swastikas.
Development.
According to David Kushner, John Carmack's technical achievements with the Catacomb 3-D game engine were a strong starting point for the game concept. The game's development began in late 1991 after id Software decided to rework "Castle Wolfenstein" heavily. Before its development, John Romero added to one level of "Commander Keen 5" pipes whose shape resembled a swastika, which was a sign that the team were planning to rewrite the game "Castle Wolfenstein". The team were allowed to use the "Wolfenstein" title because Muse Software had allowed the name's trademark registration to lapse. Id Software pitched the game's concept to Scott Miller, founder of Apogee Software, who promised the id team to deliver a shareware title. Carmack bought a NeXT machine to aid development.
According to Kushner, the early concept of the game included some innovative stealth concepts, including dragging dead bodies, swapping uniforms with fallen guards and silent attacks as in the earlier "Wolfenstein" games, which emphasized stealth rather than action. These ideas were dropped because they slowed the game down and complicated the controls. Secret walls, which were sections of wall that players could push to reveal a hidden area, were also discussed during development. Designers Tom Hall and John Romero wanted this feature included because they thought secrets were integral to a good game. Carmack initially resisted the idea, but was able to implement push walls to his satisfaction late in development.
"Wolfenstein 3D" was originally designed to use the same 16-color EGA graphics palette as earlier 3D titles such as "Hovertank 3D" and "Catacomb 3-D". At Scott Miller's suggestion, the team implemented the 256-color VGA graphics palette. Adrian Carmack drew each sprite frame by hand using a computer. "Wolfenstein 3D" for the PC supports PC speaker, AdLib, Disney Sound Source and Sound Blaster sound effects and Adlib and Sound Blaster for music. This was id Software's first use of digitally sampled sound effects, which were composed by Bobby Prince.
Engine technology.
The game uses ray casting to render the walls in pseudo-3D. This method emits one ray for each column of pixels, checks to see whether it intersects a wall and draws textures on the screen accordingly, creating a one-dimensional depth buffer against which to clip the scaled sprites that represent enemies, power-ups and props. Before "Wolfenstein 3D", id Software had used the technology in 1991 to create "Hovertank 3D" and "Catacomb 3-D" for Softdisk. Other games using the Wolfenstein 3D game engine or derivatives of it include ', ', "Operation Body Count", "Super 3D Noah's Ark", and "Rise of the Triad".
Id Software's John Carmack said the game's engine was inspired by a technology demonstration of Looking Glass Studios' and Origin Systems' first-person role-playing video game, "" (1991). Carmack said that he could make a quicker renderer. Whereas the Wolfenstein engine lacks many features present in the Underworld engine, such as ceiling or floor height changes, sloped floors, textured floors and ceilings, and lighting, it ran well on relatively weak PC hardware. The engine uses a vertical scanline scaling algorithm, which unlike later engines and hardware rasterizers, does not calculate the texture coordinate for the pixel at runtime. Instead, a fixed set of several hundred rendering functions is generated during game startup or viewport size change, where all memory offsets are fixed. To keep the number of these procedures small, heightwhich can be easily seen when player is close to the wall but not viewing it at a right angleis quantized.
Release.
Id Software planned to release one shareware episode and allow gamers to buy the full trilogy, following the shareware model used profitably to market "Commander Keen: Invasion of the Vorticons". After learning that it took a day to make one level, Scott Miller persuaded the id team to produce another trilogy. This led to the production of "The Nocturnal Missions".
Promotion.
The game's level episode 2, map 8 (E2M8) features a large, hidden "pushwall" maze consisting of 181 nearly identical rooms. Depending on the path taken, the player can find treasure, an extra life, a surprise encounter with the Hans Grosse boss or a sign reading "Call Apogee Say Aardwolf". This was part of a planned contest in which the first person to find the sign and carry out its instructions would win a prize. While no prize was ever decided, preliminary discussion suggested the prize may have been registered copies of all Apogee games for life. However, because level editors and cheat programs for the game were released within days of the full version of "Wolfenstein 3D", many players easily found the sign. Additionally, a cheat code that allowed the player to view all of the in-game sprites, including the "Aardwolf" sign was soon discovered and published. As a result, the planned contest was abandoned before it was officially announced or the prize decided upon. The maze and the sign were left in the game as Easter eggs; a text file included with the registered version explained its backstory. The sign was removed in a 1997 commercial re-release by Activision and replaced it with graphics depicting a pile of bones. After completing an episode, the player is given a three-letter code in addition to a total score and time. This was part of a high-score contest that was abandoned for similar reasons to the "Aardwolf" one; the code would have been used to verify that a player gained that score without use of cheat codes.
Ports.
"Wolfenstein 3D" has been commercially ported and sold on over a dozen platforms, ranging from early releases on platforms such as the Super Nintendo Entertainment System (SNES) (1993) to newer releases on mobile platforms such as the iPad (2010). Other ports include Mac OS (August 3, 1994), Atari Jaguar (1994), Acorn Archimedes (1994), 3DO (1995), Apple IIGS (1998), and the PC-98 (1998). Later releases include the Game Boy Advance (April 2002), Steam, Xbox Live Arcade and the PlayStation Network (2009), and the iPhone and iPod Touch (2009). These ports' sound, graphics and levels may differ from the original but the core gameplay and aesthetic are retained. The source code for the Acorn Archimedes version was released by author Eddie Edwards in 1999.
Outside of commercial sale, enthusiasts of the game have created ports or reworked versions for other platforms, such as Symbian, the TI-83 series, Maemo, the PlayStation Portable, Wii, Dreamcast, the Dingoo A320, Atari STE, Amiga, Sega Mega Drive/Genesis and the Falcon030. The fan community has also developed numerous add-ons and enhancements for the game.
Reception.
Sales and reviews.
By the end of 1993, sales of "Wolfenstein 3D" had reached over 100,000 units, vastly exceeding the shareware game sales record set by the developer's earlier "Commander Keen" series and providing id with a higher profit margin than sales of the retail counterpart, "Spear of Destiny". "Wolfenstein 3D" was well received by reviewers upon its release. "Computer Gaming World" praised the "sparse gorgeous ... frighteningly realistic ... extremely violent" graphics and sound, warning "those sensitive to such things to stay home". The magazine concluded that "Wolfenstein 3D", like "Ultima Underworld" was "the first game technologically capable of creating a sufficient element of disbelief-suspension to emotionally immerse the player in a threatening environment" stating "I can't remember a game ... evoking such intense psychological responses from its players". The game twice received 5 out of 5 stars in "Dragon" in 1993.
The four reviewers of "Electronic Gaming Monthly" gave the Super NES version a 7 out of 10. They dismissed the censoring in this version as inconsequential and assessed it as a good conversion which retains the good music, huge levels, and overall fun of the PC game. They gave the Jaguar version a 7.25 out of 10, commenting that the graphics and audio are superior to other versions of the game, though they criticized that the faster movement of the player character makes the game less fun to play. Writing for "GamePro", The King Fisher gave the Jaguar version a rave review, saying "Wolfenstein 3D" "set a new standard for PC gaming" and that the Jaguar version was the best to date, including the PC version. They elaborated that the graphics are detailed with minimal pixelation, the digitized voices are clear, and "The fast, intense action is slowed only by the Jaguar's cumbersome control pad."
Major Mike of "GamePro" commended the 3DO version's complete absence of pixelation, fast scaling, "rousing" music, and high quality sound effects, but criticized that the controls are overly sensitive. He remarked that while "Wolfenstein 3D" had become aged next to games like "Doom", it "still packs a punch as a first-person shooter." "Maximum", on the other hand, felt that the game was so aged compared to recent releases like "" and the PlayStation version of "Doom" that a new port was pointless. While acknowledging that the 3DO version is better than the PC version and equal to the Jaguar version, they found the game itself "somewhat tiresome and very, very repetitive" and scored it 2 out of 5 stars.
More recently, Colin Williamson of Allgame awarded "Wolfenstein 3D" 4½ out of 5 stars and Marc Golding of HonestGamers gave it 7 out of 10. Both modern reviews praised the game's moody soundtrack, evocative sound design and tense gameplay. Golding said players may struggle to remain interested in the game because its sixty levels are similar to each other. A 2009 review by Daemon Hatfield of IGN gave the PlayStation 3 version of the game a score of 8 out of 10, calling it "required playing for any first-person shooter fan" that "remains fun after all these years". He also said that "it's definitely dated and flawed, but this is a game you play for its nostalgic value".
Awards and accolades.
"Wolfenstein 3D" won the 1993 "Best Action/Arcade Game" award at the Shareware Industry Awards, and a Codie award from the Software Publishing Association for Best Action/Arcade Game. It was the first shareware game to win a Codie, and id (with six employees) the smallest company to receive the award. "Wolfenstein 3D" was nominated for an award at the 1993 Game Developers Conference, and "Computer Gaming World" named it the magazine's Action Game of the Year in 1993. It was included on "Computer Gaming World"'s list of the 150 Best Games of All Time" in 1996, on IGN's list of the Top 100 Games of All Time in 2003 and 2007, and on G4's list of Top 100 Video Games of All Time in 2012.
Hitler.
The game's version of the Nazi leader Adolf Hitler was proclaimed the 15th greatest boss in video game history by "The Phoenix" in 2006; the encounter with Hitler was also recognized as an exceptional boss fight by 1UP.com in 2009, and ranked as the 50th hardest boss battle in video game history by "Complex" in 2013. In 2011, PlayStation Universe featured killing Hitler in "Wolfenstein 3D" in the first article of a retrospective series "Unforgettable Gaming Moments". GamesRadar put 'Mecha-Hitler' in their 2013 list of the best villains in video game history at number 23, calling it "one of the most nonsensically funny boss encounters in gaming."
Controversy.
Because of "Wolfenstein 3D"s use of Nazi symbols, including the swastika and the Nazi Party's anthem "Horst-Wessel-Lied" as theme music, the game was withdrawn from sale in Germany despite its portrayal of Nazis as the enemy. The use of Nazi symbols is a federal offense in Germany in most contexts, as outlined in German law. The Atari Jaguar version was confiscated following a verdict by the Amtsgericht Berlin Tiergarten on December 7, 1994 (Az. 351 Gs 5509/94).
Because of concerns from Nintendo of America and "Bundesprüfstelle für jugendgefährdende Medien", the SNES version of the game was heavily edited. All swastikas and Nazi references were removed. Hitler, a boss character in the game, had his mustache removed and was renamed "Staatmeister". Blood was replaced with sweat to make the game seem less violent; on SNES copies distributed in Germany, the enemy blood was green. Attack dogs were replaced by giant mutant rats. The employees at id Software said in "The Official DOOM Player Guide" about the reaction to "Wolfenstein" that it was ironic that it was morally acceptable to shoot people but not dogs. The opening music was also changed.
Legacy.
"Wolfenstein 3D" has been called the "grandfather of 3D shooters", specifically first-person shooters, because it established the fast-paced action and technical prowess commonly expected in the genre and increased the genre's popularity. It has also been acknowledged that it confirmed shareware distribution as a serious and profitable business strategy. The release of id Software's hit game "Doom" in 1993 was an additional impetus for a wave of similar games, most of which were distributed using the same shareware strategy as "Wolfenstein 3D".
According to Ronald Strickland, "Wolfenstein 3D" introduced a fresh formula that blended together disparate elements from computer and arcade game genres to the PC game market. It combined the fast pace and quick reflexes of arcade action games that pit the player against multiple enemies that come in increasing waves of speed and complexity, with the first-person perspective of some early role-playing video games such as "Wizardry", which tried to provide players with an immersive experience. While prior computer shooter games were most often scrolling shooters, "Wolfenstein 3D" helped move the market towards first-person shooters.
Although id Software had not designed "Wolfenstein 3D" to be editable or modified by players, users developed character and level editors to create original alterations to the game's content. These efforts influenced id Software to design later titles like "Doom" and "Quake" to be easily modifiable for the end user. The game's source code was published by id Software on July 21, 1995, while the artwork data, music and software tools of the game remain under copyright. Bethesda Softworks, whose parent company bought id Software in 2009, celebrated the 20th anniversary of "Wolfenstein 3D"s release by making available a free-to-play, browser-based version of the game on its website on May 9, 2012. The first level of "Wolfenstein 3D" is included as an easter egg and playable in ' however the level maintains the gameplay mechanics and player/weapon design of "The New Order". The whole first episode is playable as an easter egg in the game '. In each chapter of the game, a level of "Wolfenstein 3D" is playable by finding secret areas in a chapter.
Sequels and spin-offs.
"Wolfenstein 3D" was followed by several games based on its protagonist and settings:

</doc>
<doc id="33431" url="https://en.wikipedia.org/wiki?curid=33431" title="Whidbey Island">
Whidbey Island

Whidbey Island (historical spellings Whidby, Whitbey, or Whitby) is the largest of the islands composing Island County, Washington, in the United States. (The other large island is Camano Island, east of Whidbey.) Whidbey is about north of Seattle, and lies between the Olympic Peninsula and the I-5 corridor of western Washington. The island forms the northern boundary of Puget Sound. It is home to Naval Air Station Whidbey Island.
Whidbey Island is home to 58,211 residents (according to the 2000 census). An estimated 29,000 of Whidbey Island residents live in rural locations.
Whidbey Island is approximately long (from the extreme north to extreme south), and wide, with a total land area of , making it the 40th largest island in the United States. It is ranked as the fourth longest and fourth largest island in the contiguous United States, behind Padre Island, Texas (the world's longest barrier island); Long Island (a fact disputed by residents); and Isle Royale, Michigan. In the state of Washington, it is the largest island, followed by Orcas Island.
History.
Whidbey Island was once inhabited by members of the Lower Skagit, Swinomish, Suquamish, Snohomish and other Native American tribes. The first known European sighting of Whidbey Island was during the 1790 Spanish expedition of Manuel Quimper and Gonzalo López de Haro on the "Princesa Real". The island was fully explored in 1792 by Captain George Vancouver. In May of that year, Royal Navy officers and members of Vancouver's expedition, Joseph Whidbey and Peter Puget, began to map and explore the areas of what would later be named Puget Sound. After Whidbey circumnavigated the island in June 1792, Vancouver named the island in his honor.
The first known overnight stay on Whidbey Island by a non-native American was made on May 26, 1840 by a Catholic missionary during travel across Puget Sound.
Lieutenant Charles Wilkes, commander of the United States Exploring Expedition of 1838–1842, sailed the USS "Vincennes" into Penn Cove in 1841. There he found the largest Native settlement on Puget Sound and noted that a Catholic mission had been started with a fenced garden. Wilkes named the lower cove Holmes Harbor, after his assistant surgeon, Silas Holmes.
In 1850, Colonel Isaac N. Ebey became the first permanent white settler on Whidbey Island, claiming a square mile (2.6 km²) of prairie with a southern shoreline on Admiralty Inlet. Even though he was farming potatoes and wheat on his land, he was also the postmaster for Port Townsend, Washington and rowed a boat daily across the inlet in order to work at the post office there. On August 11, 1857, Colonel Ebey was murdered and beheaded by Haida who traveled from the Queen Charlotte Islands when he was 39 years old. Ebey was slain in proxy-retaliation for the killing of a Haida chief at Port Gamble. Fort Ebey, named for the Colonel, was established in 1942 on the west side of the central part of the island, just northwest of Coupeville.
Admiralty Head Lighthouse is located in this area, on the grounds of Fort Casey State Park. The area around Coupeville is the federally protected Ebey's Landing National Historical Reserve, named in honor of Isaac Ebey.
In 1984, the island was the site of a violent encounter between law enforcement and white nationalist and organized crime leader Robert Jay Mathews. A large shootout occurred between Mathews and FBI agents in which Mathews was killed in a house fire. Mathews' followers have since gathered on the island at the location where he was killed by FBI agents on the anniversary of his death to commemorate it.
Government.
Whidbey Island, along with Camano Island, Ben Ure Island and six uninhabited islands, comprises Island County, Washington. The county seat is located in the town of Coupeville on Whidbey Island.
Population centers of Whidbey Island include the City of Oak Harbor, the Town of Coupeville, the City of Langley, the Village of Freeland, the Community of Greenbank, the Village of Clinton and the Community of Bayview. Only Oak Harbor, Coupeville and Langley are incorporated, the others (with the exception of Greenbank and Bayview) are all Census-designated places, and all but Bayview have their own post offices and ZIP codes.
Economy.
Whidbey Island is divided economically into two different regions: the northern end of the island (encompassing Oak Harbor and Whidbey Island Naval Air Station), and the remainder of the island (encompassing Coupeville, Greenbank, Freeland, Langley, Clinton and the smaller communities in-between).
The economy of the northern end of Whidbey Island is strongly influenced by the presence of Whidbey Island Naval Air Station near Oak Harbor (N.A.S. Whidbey). N.A.S. Whidbey is Oak Harbor’s largest employer; thus, Oak Harbor has a predominantly service-based economy and several national chain stores have been attracted to the Oak Harbor area.
The economy of Whidbey Island south of Oak Harbor relies heavily on tourism, small-scale agriculture, and the arts.
Tourism is especially important for both Whidbey and Camano Islands. On Whidbey, tourists find a wide range of amenities in the towns of Oak Harbor, Coupeville, Freeland and Langley. Coupeville's Penn Cove Mussel Farm exports large quantities of its highly renowned Penn Cove Mussels. This aquaculture facility, along with a number of small farms, reflects the rural agricultural nature of most of central Whidbey Island. Many of these small farms host farm stands onsite, where customers may buy produce, flowers, meat, eggs and other locally raised products directly from the farmers.
Often referred to as Puget Sound's Largest Artist's Colony, Whidbey is home to numerous working artists, writers, and performers. These include many well-known painters, sculptors, glass artists, wood workers, metal workers, mixed media artists, photographers, authors, poets, actors, and musicians.
In addition to being a haven for artists, the southern end of Whidbey Island also serves as a minor bedroom community for the nearby cities of Everett, where the Boeing Everett Factory is located, and Seattle. Commuters to and from those areas use the Washington State Ferries system's run between Clinton and Mukilteo.
Geography.
Whidbey Island is often claimed to be the longest island in the continental United States (or another similar claim), but according to the Seattle Times it cannot be correctly considered so. Whidbey Island has four lakes that are part of its interior hydrology: Cranberry Lake (inside Deception Pass State Park), Deer Lake (inside Deer Lake Park), Goss Lake and Lone Lake (both near the town of Langley).
Parks and reserve areas.
Whidbey Island contains Ebey's Landing National Historical Reserve, the first national historic reserve in the US created by the National Park Service to preserve the rural history and culture of the island and to protect the area's rare and sensitive plants.
Washington State Parks located on the island include Deception Pass State Park (the most visited state park in Washington), Joseph Whidbey State Park, Fort Ebey State Park, Fort Casey State Park, Possession Point State Park, and South Whidbey Island State Park. There is also a series of county operated parks throughout the Island.
Earth Sanctuary is a nature reserve, sculpture garden and retreat center on Whidbey Island. The ponds and bog fen complex have been designated as a “habitat of local importance” by the Whidbey Audubon Society and Island County Critical Areas program.
Festivals.
Whidbey Island hosts many festivals and celebrations throughout the year.
Climate.
Whidbey Island lies partially in the rain shadow of the Olympic Mountain Range to the west, and has a variety of climate zones. This can be observed by rainfall amounts – wettest in the south with average rainfall of , driest in the central district of Coupeville with average rainfall of , and turning moister again farther north with average rainfall of . Microclimates abound, determined by proximity to water, elevation and prevailing winds.
Ecology.
Flora.
Vegetation varies greatly from one end of the island to the other. Vegetation in the south is more similar to that of mainland Washington. The principal trees are Douglas fir, red alder, bigleaf maple, western red cedar, and western hemlock. Compared to the rest of western Washington state, vine maple is notably absent, except where they have been planted. Other under-story plants include the evergreen huckleberry, lower longleaf Oregon grape, elderberry, salal, oceanspray, and varieties of nettle. Non-native introduced plants such as foxglove, ivy and holly are also evident.
Farther up the island, however, the shorter Oregon-Grape and the blue Evergreen Huckleberry is seen less, while tall Oregon-grape and Red Huckleberry predominate. The native Pacific rhododendron is much more visible. Amongst the deciduous varieties, Garry oak (from which Oak Harbor takes its name) are seen more frequently in the northern portion of the island and Pacific madrone is also notably present. In the conifer classification, grand fir is found more in the northern part of Whidbey Island along with Sitka spruce and shore pine. There are three open prairie areas on Whidbey Island – Smith Prairie, Crockett Prairie and Ebey Prairie. Interestingly, some patches of prickly pear cactus are found along the slopes near Partridge Point.
Fauna.
Gray whales migrate between Whidbey and Camano Islands during March and April and can be seen from both ship and shore. Orca also make use of the waters surrounding Whidbey Island.
Clams and Oysters are abundant locally and may be harvested from some public beaches. The Washington State Department of Health provides an online guide to assist in identifying shellfish varieties as well as providing guidance about where to find specific varieties.
Education.
Public school districts.
Whidbey Island is served by three public school districts.
Oak Harbor School District operates in Oak Harbor. Within the district, there is one high school, one alternative high school, two middle schools, and five elementary schools. Within the Washington Interscholastic Activities Association, Oak Harbor High is listed as a 3-A school.
Coupeville School District operates in Coupeville, Washington and Greenbank, Washington. Within the district, there is one high school, one middle school, and one elementary school. Within the Washington Interscholastic Activities Association, Coupeville High is listed as a 1-A school.
South Whidbey School District serves the southern end of the island, including Freeland, Clinton, Bayview, and Langley. Within the district, there is one high school (grades 9–12), one alternative school (grades K–12), one middle school (grades 6–8), and one elementary school (grades K–5). Within the Washington Interscholastic Activities Association, South Whidbey High is listed as a 1-A school.
Colleges.
Skagit Valley College has a campus located in Oak Harbor, and a limited service campus in South Whidbey.
Seattle Pacific University owns Camp Casey, a retreat center near Coupeville, which was once the barracks for the adjacent Fort Casey.
Infrastructure.
Transportation.
Travel on the island involves use of an extensive county road system, or city infrastructure depending on location, all of which act as feeders to the two state highways State Route 525 and State Route 20.
Whidbey Island's State Routes 525/20 is the only nationally designated Scenic Byway on an island. It is appropriately named the "Whidbey Island Scenic Isle Way."
Public transportation is provided by Island Transit, which provides a zero-fare bus service paid for by a 6/10th of 1% sales tax within the county. There are currently 10 bus routes serving Whidbey Island. No service is available on Saturdays, and buses do not run on Sunday or major holidays.
Two public airports provide service to Whidbey Island. Whidbey Air Park is located southwest of Langley with a long runway. Wes Lupien Airport is located southwest of Oak Harbor with a long runway. In addition, there are approximately half dozen private dirt strips on the island. Kenmore Air Express restarted scheduled airline service to Whidbey Island in 2006, serving the Oak Harbor airport. This service was discontinued January 1, 2009.
The United States Navy operates two airports on Whidbey Island. The largest is a two-runway airport located at Whidbey Island Naval Air Station north of Oak Harbor. In addition, the Navy also operates a flight training facility named Coupeville Outlying Landing Field (Coupeville OLF) located just southeast of Coupeville. The Navy named USS Whidbey Island (LSD-41) in honor of the island.
Health systems.
Whidbey General Hospital is the regional, county-run hospital. Located in Coupeville, the hospital has extension clinics in both Clinton and Oak Harbor. The Naval Air Station in Oak Harbor has a limited service hospital for military personnel, veteran retirees and their dependents only.
Communities.
North to south:

</doc>
<doc id="33432" url="https://en.wikipedia.org/wiki?curid=33432" title="Writers of the Future">
Writers of the Future

Writers of the Future (WOTF) is a science fiction and fantasy story contest that was established by L. Ron Hubbard in the early 1980s. A sister contest, Illustrators of the Future, presents awards for science fiction art. Hubbard characterized the contest as a way of "giving back" to the field that had defined his professional writing life. The contest has no entry fee and is the highest-paying contest for amateur science-fiction and fantasy writers. Notable past winners of WOTF include Stephen Baxter, Karen Joy Fowler, James Alan Gardner, Nina Kiriki Hoffman, Jay Lake, Michael H. Payne, Patrick Rothfuss, Robert Reed, Dean Wesley Smith, Sean Williams, Dave Wolverton, Nancy Farmer, and David Zindell. 
The winning stories are published in the yearly anthology "L. Ron Hubbard Presents Writers of Future". The contest enjoys a favorable reputation in the science fiction community, although its connection with the Church of Scientology has caused some controversy.
Contest rules and procedures.
Writers of the Future.
The Writers of the Future (WOTF) contest may be entered quarterly, and is open to authors who have no, or few, professional publications. The contest rules state that entrants cannot have had published "a novel or short novel, or more than one novelette, or more than three short stories, in any medium. Professional publication is deemed to be payment, and at least 5,000 copies, or 5,000 hits." Thus, works that are less than 3,000 words and for which payment was less 6c/word, do not count as "professional" publications. Stories of up to 17,000 words in length can be submitted to the contest. Poems, screenplays, non-fiction, etc., are not eligible.
Manuscripts are judged with the authors' names deleted, and are separated out in quarterfinal and semifinal award rounds by the Coordinating Judge (previously K. D. Wentworth, currently Dave Wolverton, and originally Algis Budrys). Eight finalists are sent to a panel of professional sf writers, who determine the top three awards. Prizes are $1000 (first place), $750 (second) and $500 (third). The process is then repeated the next quarter. At the end of the contest year, the four quarterly first place stories compete for a separate annual grand prize, the "Gold Award," which includes an additional $5000. The first, second and third-place winners and often a selection of the other finalist stories are published annually, for which the writers receive additional compensation for publication rights. Thus, a grand prize-winning author can make over $6000 for a single story - more than many writers receive for a first novel. 
Some finalist stories not considered among the top three (in effect, the fourth or fifth placers) may be included in the annual anthology. These are called "published finalists." The writers are compensated for publication rights, but are not considered winners and receive no prize money, but are eligible to re-enter the contest. Often writers will repeatedly enter the contest, quarter after quarter, until they either win or become ineligible due to publications elsewhere.
Illustrators of the Future.
An artists' contest, the Illustrators of the Future (IOTF), was added in 1988. Like the WOTF contest, the Illustrators contest is open to amateurs. The Rules state: "The Contest is open to those who have not previously published more than three black-and-white story illustrations, or more than one process-color painting, in media distributed nationally to the general public, such as magazines or books sold at newsstands, or books sold in stores merchandising to the general public. The submitted entry shall not have been previously published in professional media as exampled above."
Entrants submit a portfolio of three pieces of artwork, which are circulated among the judges. Up to three winners are selected every quarter, each given a prize of $500. Unlike the Writers, the Illustrators are not ranked. After the completion of the contest year, each of the twelve Illustration winners is assigned one of the stories from among the twelve Writer winners, and given a month to return the finished illustration. A single grand prize, also called the Gold Award, is accompanied by a prize of $5000 - judging is based only on the final illustration, not the initial portfolio. While the art is judged according to standard artistic considerations (composition, draftsmanship, consistency of lighting, sense of wonder, facial expressions, etc.), a key consideration during the final judging is whether or not the art would make the viewer want to read the accompanying story. The art is also included in the annual anthology, and illustrators are additionally compensated.
Awards and workshop.
No official tallies are given for the number of entrants in either contest, but it is believed that thousands enter the Writers contest every quarter, while only hundreds enter the Illustration contest. Thus, the Illustration judges are sometimes often unable to find three deserving winners, and only pick one or two. (This is not a problem for the Writing judges.) Should the Illustration winners number less than twelve in a year, each illustrator is - as usual - assigned a single story to illustrate for purposes of determining who wins the Gold Award. Returning the assigned illustration quickly does not directly correlate to winning the Gold Award, but those artists who do so are allowed the opportunity to illustrate additional stories. 
All winners and published finalists are invited to attend the annual week-long writers' and artists' workshops and Awards gala at the invitation and expense of the contest administration. Tuxedoes and gowns are worn by the judges, administrators, and winners for the Awards gala (but members of the general public are casually attired), and various Hollywood actors are generally in attendance, in addition to prominent science fiction authors and artists. These include the present judges in addition to a famous and generally elderly writer given a Lifetime Achievement Award. While it is not required to attend the week-long festivities and seminars, it is thought by some that those in the running for the Gold Award may advance their cause by displaying professionalism and hard work at that time; judges for the contest, however, refute this, as the judging is done blindly in advance of the week-long pre-awards event and most judges don't arrive on site until the last day of the workshop.
Prominent judges and winners.
Many noted writers and artists have judged WotF awards, or have won them themselves.
Notable writing judges have included: Algis Budrys, Gregory Benford, Kevin J. Anderson, Orson Scott Card, Jack Williamson, Nina Kiriki Hoffman, Brian Herbert, K. D. Wentworth, Tim Powers, Robert J. Sawyer, Frederik Pohl, Jerry Pournelle, Andre Norton, Larry Niven, and Anne McCaffrey.
Prominent art judges have included: Bob Eggleton, Frank Kelly Freas, Frank Frazetta, Will Eisner, Edd Cartier, Stephen Youll, Stephen Hickman, Echo Chernik, and Leo and Diane Dillon.
Judges receive only token payment for their efforts ($25 per story adjudicated).
Winners and published finalists in the contest have included the writers 
Stephen Baxter, 
Karen Joy Fowler,
Carl Frederick,
James Alan Gardner, 
Jim C. Hines,
Jay Lake, 
David D. Levine,
Syne Mitchell,
Nnedi Okorafor,
Michael H. Payne,
Brian Plante,
Robert Reed, 
Bruce Holland Rogers, 
Patrick Rothfuss,
Dean Wesley Smith,
Catriona Sparks,
Sean Tinsley,
Mary Turzillo,
Sean Williams, 
Dave Wolverton, 
David Zindell,
and the artists
Shaun Tan and Frank Wu.
Connections to Scientology.
The original sponsor of the contest was Bridge Publications, Inc., the publishing arm of the Church of Scientology. Prior to the 2004 contest, the sponsorship moved to Author Services Inc. under the trade name Galaxy Press, which was spun off from Bridge to publish Hubbard's fiction and the contest anthologies.
The contest has also been characterized as a promotional vehicle for Hubbard himself, who returned to science fiction writing with "Battlefield Earth" at about the same time as he began the contest. On the covers of the annual WOTF anthologies, Hubbard's name appears "above the title", and in at least as prominent a font. The prominence of Hubbard's name and the lavish funding of the contest awards, publicity and ceremonies have led some to speculate that the contest is part of a campaign by the Church of Scientology to promote Hubbard's status in the science fiction and literary communities.
Entering or winning the contest does not require or imply endorsement or membership in the Church of Scientology, and the contest itself has been endorsed by a wide range of well-known speculative fiction writers (see Judges and Winners above) who have no relationship to Scientology.
According to Director of the Writers and Illustrators Contests Joni Labaqui, the funds to underwrite the contest—including the cash prizes, the gala awards ceremony and the weeklong pre-awards festivities—come from the Hubbard estate. The Hubbard estate is separate from the Church of Scientology and earns royalties from sales of Hubbard's books, including his fiction. Labaqui also reports that staff of Author Services Inc. is entirely made up of Scientologists.
However, records with the United States Patent and Trademark Office show that the rights to the Writers of the Future name were transferred from the L. Ron Hubbard estate ("Family Trust-B") to the Church of Spiritual Technology in 1989, and under the 1993 IRS closing agreement with the Church of Scientology, the L. Ron Hubbard estate became part of the Church of Spiritual Technology, a "Scientology-related entity".

</doc>
<doc id="33433" url="https://en.wikipedia.org/wiki?curid=33433" title="Wilfrid Laurier">
Wilfrid Laurier

Sir Henri Charles Wilfrid Laurier (20 November 1841 – 17 February 1919), known as Wilfrid Laurier (; ; lor-yay), was the seventh Prime Minister of Canada, in office from 11 July 1896, to 6 October 1911.
Canada's first francophone prime minister, Laurier is often considered one of the country's greatest statesmen. He is well known for his policies of conciliation, expanding Confederation, and compromise between French and English Canada. His vision for Canada was a land of individual liberty and decentralized federalism. He also argued for an English-French partnership in Canada. "I have had before me as a pillar of fire," he said, "a policy of true Canadianism, of moderation, of reconciliation." He passionately defended individual liberty, "Canada is free and freedom is its nationality," and "Nothing will prevent me from continuing my task of preserving at all cost our civil liberty." Laurier was also well-regarded for his efforts to establish Canada as an autonomous country within the British Empire, and he supported the continuation of the Empire if it was based on "absolute liberty political and commercial". A 2011 "Maclean's" historical ranking of the Prime Ministers placed Laurier first.
Laurier holds a number of records: he holds the record for the most "consecutive" federal elections won (4), and his 15-year tenure remains the longest unbroken term of office among Prime Ministers. In addition, his nearly 45 years (1874–1919) of service in the House of Commons is a record for that house. At 31 years, 8 months, Laurier was the longest-serving leader of a major Canadian political party, surpassing William Lyon Mackenzie King by over two years. Finally, he is the fourth-longest serving Prime Minister of Canada, behind King, John A. Macdonald, and Pierre Trudeau. Laurier's portrait is displayed on the Canadian five-dollar bill.
Early life.
The second child of Carolus Laurier and Marcelle Martineau, Wilfrid Laurier was born in Saint-Lin, Canada East (modern day Saint-Lin-Laurentides, Quebec), on 20 November 1841. Laurier was among the seventh generation of his family in Canada. He was a sixth-generation Canadian. His ancestor François Cottineau, dit Champlaurier, came to Canada from Saint-Claud, France. He grew up in a family where politics was a staple of talk and debate. His father, an educated man having liberal ideas, enjoyed a certain degree of prestige about town. In addition to being a farmer and surveyor, he also occupied such sought-after positions as mayor, justice of the peace, militia lieutenant and school board member. At the age of 11, Wilfrid left home to study in New Glasgow, a neighbouring village largely inhabited by immigrants from Scotland. Over the next two years, he familiarized himself with the mentality, language and culture of British people. Laurier attended the Collège de L'Assomption and graduated in law from McGill University.
He was elected to the Legislative Assembly of Quebec from Drummond-Arthabaska in the 1871 Quebec general election, but resigned on 19 January 1874, to enter federal politics in the riding of Quebec East. He was first elected to the Canadian House of Commons in the 1874 election, serving briefly in the Cabinet of Prime Minister Alexander Mackenzie as Minister of Inland Revenue.
Leadership.
Chosen as leader of the federal Liberal Party in 1887, he gradually built up his party's strength through his personal following both in Quebec and elsewhere in Canada. He led the Liberal Party to victory in the 1896 election, and contested five other federal elections; he remained Prime Minister until the defeat of the Liberal Party by the Conservative Party in the 1911 election.
Quebec stronghold.
By 1909, Laurier had been able to build the Liberal Party a base in Quebec, which had remained a Conservative stronghold for decades due to the province's social conservatism and to the influence of the Roman Catholic Church, which distrusted the Liberals' anti-clericalism. The growing alienation of French-Canadians from the Conservative Party due to its links with anti-French, anti-Catholic Orangemen in English Canada aided the Liberal Party. These factors, combined with the collapse of the Conservative Party of Quebec, gave Laurier an opportunity to build a stronghold in French Canada and among Catholics across Canada.
Catholic priests in Quebec repeatedly warned their parishioners not to vote for Liberals. Their slogan was ""le ciel est bleu, l'enfer est rouge"" (heaven is blue/Conservative, hell is red/Liberal).
Prime Minister (1896–1911).
Laurier led Canada during a period of rapid growth, industrialization and immigration. His long career straddles a period of major political and economic change. As Prime Minister he was instrumental in ushering Canada into the 20th century and in gaining greater autonomy from Britain for his country. A list of his Ministers is available at the Parliamentary website, and is known as the 8th Canadian Ministry.
One of Laurier's first acts as Prime Minister was to implement a solution to the Manitoba Schools Question, which had helped to bring down the Conservative government of Charles Tupper earlier in 1896. The Manitoba legislature had passed a law eliminating public funding for Catholic schooling (thereby going against the federal constitutional Manitoba Act, 1870, which guaranteed Catholic and Protestant religious education rights). The Catholic minority asked the federal Government for support, and eventually the Conservatives proposed remedial legislation to override Manitoba's legislation. Laurier opposed the remedial legislation on the basis of provincial rights, and succeeded in blocking its passage by Parliament. Once elected, Laurier proposed a compromise stating that Catholics in Manitoba could have a Catholic education if there were enough students to warrant it, on a school-by-school basis. This was seen by many as the best possible solution in the circumstances, making both the French and English equally satisfied. Laurier called his effort to lessen the tinder in this issue "sunny ways" ().
In 1899, the United Kingdom expected military support from Canada, as part of the British Empire, in the Second Boer War. Laurier was caught between demands for support for military action from English Canada, and a strong opposition from French Canada which saw the Boer War as an "English" war and to some degree appreciated the similar places that Boers and French Canadians held in the British Empire. Henri Bourassa was an especially vocal opponent. Laurier eventually decided to send a volunteer force, rather than the militia expected by Britain, but Bourassa continued to oppose any form of military involvement.
In 1905, Laurier oversaw Saskatchewan and Alberta's entry into Confederation, the last two provinces to be created out of the Northwest Territories. This followed the enactment of the "Yukon Territory Act" by the Laurier Government in 1898, separating the Yukon from the Northwest Territories.
Laurier presided over the Quebec Bridge disaster, in which 75 workers were killed, on 29 August 1907.
On 29 July 1910, while in Saskatoon to attend the opening of the University of Saskatchewan, he bought a newspaper from a young John Diefenbaker, a future Conservative Prime Minister. The young Diefenbaker, recognizing the Prime Minister, shared his ideas for the country and amused him. He inquired about the young man's business and expressed the hope that he would be a great man someday. The boy ended the conversation by saying, "Well, Mr. Prime Minister, I can't waste any more time on you. I must get back to work."
Naval Bill.
The naval competition between the United Kingdom and the German Empire escalated in the early years of the 20th century. The British asked Canada for more money and resources for ship construction, precipitating a heated political division in Canada. The British supporters wished to send as much as possible, whereas those against wished to send nothing.
Aiming for compromise, Laurier advanced the Naval Service Bill of 1910 which created the Naval Service of Canada. The navy would initially consist of five cruisers and six destroyers; in times of crisis, it could be made subordinate to the British Royal Navy. The idea was lauded at the 1911 Imperial Conference in London, but it proved unpopular across the political spectrum in Canada, especially in Quebec as ex-Liberal Henri Bourassa organized an anti-Laurier force.
Reciprocity and defeat.
In 1911, another controversy arose regarding Laurier's support of trade reciprocity with the United States. His long serving Minister of Finance, William Stevens Fielding, reached an agreement allowing for free trade of natural products. This had the strong support of agricultural interests, but it alienated many businessmen who formed a significant part of the Liberals' support base. The Conservatives denounced the deal and played on long standing fears that reciprocity could eventually lead to the American annexation of Canada.
Contending with an unruly House of Commons, including vocal disapproval from Liberal MP Clifford Sifton, Laurier called an election to settle the issue of reciprocity. The Conservatives were victorious and Robert Laird Borden succeeded Laurier as Prime Minister.
Opposition and war.
Laurier led the opposition during World War I. He led the filibuster to the Conservatives' own Naval Bill which would have sent contributions directly to the British Navy; the bill was later blocked by the Liberal-controlled Senate. He was an influential opponent of conscription, which led to the Conscription Crisis of 1917 and the formation of a Union government, which Laurier refused to join for fear of having Quebec fall in the hands of nationalist Henri Bourassa. However, many Liberals, particularly in English Canada, joined Borden as Liberal-Unionists and the "Laurier Liberals" were reduced to a mostly French-Canadian rump as a result of the 1917 election.
However, Laurier's last policies and efforts had not been in vain. As a result of Laurier's opposition of conscription in 1917, Quebec and its French-Canadian voters voted overwhelmingly to support the Liberal party starting in 1917. Despite one notable exception in 1958, the Liberal party continued to dominate federal politics in Quebec until 1984. His protege and successor as party leader William Lyon Mackenzie King led the Liberals to a landslide victory over the Conservatives in the 1921 election.
Family.
Wilfrid Laurier married Zoé Lafontaine in Montreal on 13 May 1868. She was the daughter of G.N.R. Lafontaine and his first wife, Zoé Tessier known as Zoé Lavigne. Laurier's wife Zoé was born in Montreal and educated there at the School of the Bon Pasteur, and at the Convent of the Sisters of the Sacred Heart, St. Vincent de Paul. The couple lived at Arthabaskaville until they moved to Ottawa in 1896. She served as one of the vice presidents on the formation of the National Council of Women and was honorary vice president of the Victorian Order of Nurses. The couple had no children.
Beginning in 1878 and for some twenty years while married to Zoé, Laurier had an "ambiguous relationship" with a married woman, Émilie Barthe, with whom he fell in love. Where Zoé loved plants, animals and home life, she was not an intellectual; Émilie was, and relished literature and politics like Wilfrid, whose heart she won. Rumour had it he fathered a son, Armand Lavergne, with her, yet Zoé remained with him until his death.
Death.
Laurier died of a stroke on 17 February 1919, while still in office as Leader of the Opposition. Though he had lost a bitter election two years earlier, he was loved nationwide for his "warm smile, his sense of style, and his "sunny ways"." Some 50,000 people jammed the streets of Ottawa as his funeral procession marched to his final resting place at Notre Dame Cemetery. His remains would eventually be placed in a stone sarcophagus, adorned by sculptures of nine mourning female figures, representing each of the provinces in the union. His wife, Zoé Laurier, died in 1921 and was placed in the same tomb.
National Historic Sites.
Laurier is commemorated by three National Historic Sites.
Sir Wilfrid Laurier National Historic Site is in his birthplace, Saint-Lin-Laurentides, a town north of Montreal. Its establishment reflected an early desire to not only mark his birthplace (a plaque in 1925 and a monument in 1927), but to create a shrine to Laurier in the 1930s. Despite early doubts and later confirmation that the house designated as the birthplace was neither Laurier's nor on its original site, its development, and the building of a museum, satisfied the goal of honoring the man and reflecting his early life.
His handsome brick residence in Ottawa is known as Laurier House National Historic Site, at the corner of what is now Laurier Avenue and Chapel Street. In their will, the Lauriers left the house to Prime Minister Mackenzie King, who in turn donated it to Canada upon his death. Both sites are administered by Parks Canada as part of the national park system.
The 1876 Italianate residence of the Lauriers during his years as a lawyer and Member of Parliament, in Victoriaville, Quebec, is designated Wilfrid Laurier House National Historic Site, owned privately and operated as the Laurier Museum.
In November 2011, Wilfrid Laurier University located in Waterloo, Ontario, unveiled a statue depicting a young, passionate Wilfrid Laurier sitting on a bench, thinking deeply about the future.
Recognition.
Laurier had titular honours including:
Many sites and landmarks were named to honor Wilfrid Laurier. They include:
Supreme Court appointments.
Laurier chose the following jurists to be appointed as justices of the Supreme Court of Canada by the Governor General:

</doc>
<doc id="33436" url="https://en.wikipedia.org/wiki?curid=33436" title="William Lyon Mackenzie King">
William Lyon Mackenzie King

William Lyon Mackenzie King (December 17, 1874 – July 22, 1950), also commonly known as Mackenzie King, was the dominant Canadian political leader from the 1920s through the 1940s. He served as the tenth Prime Minister of Canada in 1921–1926, 1926–1930, and 1935–1948. He is best known for his leadership of Canada throughout the Second World War (1939–1945) when he mobilized Canadian money, supplies and volunteers to support Britain while boosting the economy and maintaining home front morale. A Liberal with 22 years in office, he was the longest-serving prime minister in Canadian history. Trained in law and social work, he was keenly interested in the human condition (as a boy, his motto was "Help those that cannot help themselves"), and played a major role in laying the foundations of the Canadian welfare state.
King acceded to the leadership of the Liberal Party in 1919. Taking the helm of a party bitterly torn apart during the First World War, he reconciled factions, unifying the Liberal Party and leading it to victory in 1921. His party was out of office during the harshest days of the Great Depression in Canada, 1930–35; he returned when the economy was on an upswing. He personally handled complex relations with the Prairie Provinces, while his top aides Ernest Lapointe and Louis St. Laurent skillfully met the demands of French Canadians. During the Second World War, he carefully avoided the battles over conscription, patriotism and ethnicity that had divided Canada so deeply in the First World War. Though few major policy innovations took place during his premiership, he was able to synthesize and pass a number of measures that had reached a level of broad national support. Scholars attribute King's long tenure as party leader to his wide range of skills that were appropriate to Canada's needs. He understood the workings of capital and labour. Keenly sensitive to the nuances of public policy; he was a workaholic with a shrewd and penetrating intelligence and a profound understanding of the complexities of Canadian society. A modernizing technocrat who regarded managerial mediation as essential to an industrial society, he wanted his Liberal Party to represent liberal corporatism to create social harmony. King worked to bring compromise and harmony to many competing and feuding elements, using politics and government action as his instrument. He led his party for 29 years, and established Canada's international reputation as a middle power fully committed to world order.
King's biographers agree on the personal characteristics that made him distinctive. He lacked the charisma of such contemporaries as Franklin Roosevelt, Winston Churchill, or Charles de Gaulle. He lacked a commanding presence or oratorical skill; his best writing was academic, and did not resonate with the electorate. Cold and tactless in human relations, he had allies but very few close personal friends. He never married and lacked a hostess whose charm could substitute for his chill. He kept secret his beliefs in spiritualism and use of mediums to stay in contact with departed associates and particularly with his mother, and allowed his intense spirituality to distort his understanding of Adolf Hitler throughout the late 1930s.
A survey of scholars in 1997 by "Maclean's" magazine ranked King first among all Canada's prime ministers, ahead of Sir John A. Macdonald and Sir Wilfrid Laurier. As historian J. L. Granatstein notes, "the scholars expressed little admiration for King the man but offered unbounded admiration for his political skills and attention to Canadian unity." On the other hand, Stewart in 2007 found that even Liberal activists have but a dim memory of him.
Early life, family, and religion.
King was born in Berlin, Ontario (now known as Kitchener), to John King and Isabella Grace Mackenzie. His maternal grandfather was William Lyon Mackenzie, first mayor of Toronto and leader of the Upper Canada Rebellion in 1837. His father was a lawyer, and later a professor at Osgoode Hall Law School. King had three siblings. He attended Berlin Central School (now Suddaby Public School) and Berlin High School (now Kitchener-Waterloo Collegiate and Vocational School). Tutors were hired to teach him more politics, science, math, English and French.
His father was a lawyer with a struggling practice in a small city, and never enjoyed financial security. His parents lived a life of shabby gentility, employing servants and tutors they could scarcely afford, although their financial situation improved somewhat following a move to Toronto around 1890, where Mackenzie lived with them for several years in a duplex located in a then-respectable neighborhood, Beverley Street, while studying at the University of Toronto.
King became a lifelong practising Presbyterian with a dedication to applying Christian virtues to social issues in the style of the Social Gospel. He never favoured socialism.
University.
King earned five university degrees. He obtained three degrees from the University of Toronto: B.A. 1895, LL.B. 1896 and M.A. 1897; he earned his LL.B. in 1896 from Osgoode Hall Law School. While studying in Toronto he met a wide circle of friends, many of whom became prominent. He was an early member and officer of the Kappa Alpha Society, which included a number of these individuals (two future Ontario Supreme Court Justices and the future Chairman of the University itself). It encouraged debate on political ideas. He also met Arthur Meighen, a future political rival; the two men did not get on especially well from the start.
King was especially concerned with issues of social welfare and was influenced by the settlement house movement pioneered by Toynbee Hall in London, England. He played a central role in fomenting a students' strike at the university in 1895. He was in close touch, behind the scenes, with Vice-Chancellor William Mulock, for whom the strike provided a chance to embarrass his rivals Chancellor Edward Blake and President James Loudon. King failed to gain his immediate objective, a teaching position at the University, but earned political credit with Mulock, the man who would invite him to Ottawa and make him a deputy minister only five years later. While studying at the University of Toronto, King also contributed to the campus newspaper "The Varsity".
After studying at the University of Chicago and working with Jane Addams at her settlement house, Hull House, King proceeded to Harvard University. He earned an M.A. in political economy from Harvard in 1898. In 1909, Harvard granted him a PhD for a dissertation on "Oriental Immigration to Canada". It was a report he had written while he was Deputy-Minister of Labour in 1908. In it he argued against the immigration of Asians, saying:
He is the only Canadian Prime Minister to have earned a PhD.
Civil servant, Minister of Labour.
King was appointed in 1900 as Deputy Minister at the head of the Canadian government's new department of Labour, and became active in policy domains from Japanese immigration to railways, notably the Industrial Disputes Investigations Act (1907) which sought to avert labour strikes by prior conciliation.
In 1901, King's roommate and best friend, Henry Albert Harper, died heroically during a skating party when a young woman fell through the ice of the partly frozen Ottawa River. Harper dove into the water to try to save her, and perished in the attempt. King led the effort to raise a memorial to Harper, which resulted in the erection of the Sir Galahad statue on Parliament Hill in 1905. In 1906, King published a memoir of Harper, entitled "The Secret of Heroism".
He was first elected to Parliament as a Liberal in a 1908 by-election, and was re-elected by acclamation in a 1909 by-election following his appointment as the first-ever Minister of Labour.
King's term as Minister of Labour was marked by two significant achievements. He led the passage of the Industrial Disputes Investigation Act and the Combines Investigation Act, which he had shaped during his civil and parliamentary service. The legislation significantly improved the financial situation for millions of Canadian workers. He lost his seat in the 1911 general election, which saw the Conservatives defeat his Liberals.
Industrial consultant.
After his defeat, King went on the lecture circuit on behalf of the Liberal Party. In June 1914 John D. Rockefeller Jr. hired him as a Director of the Rockefeller Foundation in New York City, heading their new Department of Industrial Research. It paid $12,000 per year, compared to the meager $2,500 per year the Liberal Party was paying. He worked for the Foundation until 1918, forming a close working association and friendship with Rockefeller, advising him through the turbulent period of the 1914 strike and Ludlow massacre at a family-owned coal company in Colorado, which subsequently set the stage for a new era in labor management in America. King became one of the earliest expert practitioners in the emerging field of industrial relations.
King was not a pacifist, but he showed little enthusiasm for the Great War; he faced criticism for not serving in Canada's military and instead working for the Rockefellers. But he was nearly 40 years old when the war began, and was not in good physical condition. He never gave up his Ottawa home, and travelled to the United States on an as-needed basis, performing valuable service by helping to keep war-related industries running smoothly.
In 1918 King, assisted by his friend F.A. McGregor, published the far-sighted book "Industry and Humanity: A Study in the Principles Underlying Industrial Reconstruction", a dense, abstract work he wrote in response to the Ludlow massacre. It went over the heads of most readers, but revealed the practical idealism behind King's political thinking. He emphasized that capital and labour were natural allies, not foes, and that the community at large (represented by the government) should be the third and decisive party in industrial disputes. He expressed derision for syndicates and trades unions, chastising them for aiming at the "destruction by force of existing organization, and the transfer of industrial capital from the present possessors" to themselves.
Quitting the Rockefeller Foundation in February 1918, King became an independent consultant on labour issues for the next two years, earning $1,000 per week from leading American corporations. Even so, he kept his official residence in Ottawa, hoping for a call to duty.
Wartime politics.
In 1917, Canada was in crisis; King supported Liberal leader Sir Wilfrid Laurier in his opposition to conscription, which was violently opposed in the province of Quebec. The Liberal party became deeply split, with most Anglophones joining in the pro-conscription Union government, a coalition controlled by the Conservatives under Prime Minister Sir Robert Borden. King returned to Canada to run in the 1917 election, which focused almost entirely on the conscription issue. Unable to overcome a landslide against Laurier, King lost in the constituency of North York, which his grandfather had once represented.
Liberal party leader.
King was Laurier's chosen successor as leader of the Liberal Party, but it was deeply divided by Quebec's total opposition to conscription and the agrarian revolt in Ontario and the Prairies. Levin argues that when King returned to politics in 1919, he was a rusty outsider with a weak base facing a nation bitterly split by language, regionalism and class. He outmaneuvered more senior competitors by embracing Laurier's legacy, championing labour interests, calling for welfare reform, and offering solid opposition to the Conservative enemy. When Laurier died in 1919, King was elected leader in the first Liberal leadership convention, defeating his four rivals on the fourth ballot. He won thanks to the support of the Quebec bloc, organized by his long-time lieutenant in Quebec, Ernest Lapointe (1876–1941). King could not speak French and had minimal interest in Quebec, but in election after election for the next 20 years (save for 1930), Lapointe produced the critical seats to give the Liberals control of the Commons. He was almost co-Prime Minister with King until his death in 1941.
Idealizes the Prairies.
Once he became the Liberal leader in 1919 he paid closer attention to the Prairies, a fast-developing region. With a highly romanticized view he envisioned the pioneers as morally sound, hardworking individuals who lived close to nature and to God. The reform ferment in the region meshed with his self-image as a social reformer and fighter for the "people" against the "interests". Viewing a glorious sunrise in Alberta in 1920, he wrote in his diary, "I thought of the New Day, the New Social Order. It seems like Heaven's prophecy of the dawn of a new era, revealed to me." Pragmatism played a role as well, since his party depended for its survival on the votes of Progressive party members of parliament who represented farmers in Ontario and the Prairies. He convinced many Progressives to return to the Liberal fold.
Prime Minister: first Parliament.
In the 1921 election, his party defeated Arthur Meighen and the Conservatives, and he became Prime Minister. King's Liberals originally had a bare majority position, however, since they had won 118 out of 235 seats, exactly the minimum for a majority. The Conservatives won 49, the newly formed Progressive Party won 58 (but declined to form the official Opposition), and the remaining ten seats went to fringe parties and Independents; most of these ten supported the Progressives.
As Prime Minister of Canada, King was appointed to the Privy Council of the United Kingdom on 20 June 1922 and was sworn at Buckingham Palace on 11 October 1923, during the 1923 Imperial Conference.
Balancing act.
During his first term of office, from 1921 to 1926, King pursued a conservative domestic policy with the object of lowering wartime taxes and, especially, wartime ethnic and labour tensions. "The War is over," he argued, "and for a long time to come it is going to take all that the energies of man can do to bridge the chasm and heal the wounds which the War has made in our social life." He sought a Canadian voice independent of London in foreign affairs. In September 1922 the British Prime Minister, David Lloyd George, appealed repeatedly to King for Canadian support in the Chanak crisis, in which a war threatened between Britain and Turkey. King coldly replied that the Canadian Parliament would decide what policy to follow, making clear it would not be bound by London's suggestions; the crisis soon dissipated, but the episode led to the downfall of Lloyd George.
Despite prolonged negotiations, King was unable to attract the Progressives into his government, but once Parliament opened, he relied on their support to defeat non-confidence motions from the Conservatives. King was opposed in some policies by the Progressives, who opposed the high tariffs of the National Policy. King faced a delicate balancing act of reducing tariffs enough to please the Prairie-based Progressives, but not too much to alienate his vital support in industrial Ontario and Quebec, who perceived tariffs were necessary to compete with American imports. King and Conservative leader Arthur Meighen sparred bitterly in Commons debates, and the decades-long rivalry between the two was among the nastiest in the history of Canadian politics. Despite their university-days acquaintance, their personalities and working methods contrasted enormously in almost every respect.
As King's term wore on, the Progressives gradually weakened. Their effective and passionate leader, Thomas Crerar, resigned to return to his grain business, and was replaced by the more placid Robert Forke. Socialist reformer J. S. Woodsworth gradually gained influence and power, and King was able to reach an accommodation with him on policy matters.
City planning.
King had a long-standing concern with city planning and the development of the national capital, since he had been trained in the settlement house movement and envisioned town planning and garden cities as a component of his broader program of social reform. He drew on four broad traditions in early North American planning: social planning, the Parks Movement, the City Scientific, and the City Beautiful. King's greatest impact was as the political champion for the planning and development of Ottawa, Canada's national capital. His plans, much of which were completed in the two decades after his death, was part of a century of federal planning that repositioned Ottawa as a national space in the City Beautiful style. Confederation Square, for example, was initially planned to be a civic plaza to balance the nearby federal presence of Parliament Hill. The Great War monument was not installed until the 1939 royal visit, and King intended that the replanning of the capital would be the World War II memorial. However, the symbolic meaning of the World War II monument gradually expanded to become the place of remembrance for all Canadian war sacrifices.
Prime Minister: second and third Parliaments.
Corruption scandals.
King called an election in 1925, in which the Conservatives won the most seats, but not a majority in the House of Commons. King held onto power with the support of the Progressives. A corruption scandal discovered late in his first term involved misdeeds around the expansion of the Beauharnois Canal in Quebec; this led to extensive inquiries and eventually a Royal Commission, which exposed the Beauharnois Scandal. The resulting press coverage damaged King's party in the election. Early in his second term, another corruption scandal, this time in the Department of Customs, was revealed, which led to more support for the Conservatives and Progressives, and the possibility that King would be forced to resign, if he lost sufficient support in the Commons. King had no personal connection to this scandal, although one of his own appointees was at the heart of it. Opposition leader Meighen unleashed his fierce invective towards King, stating he was hanging onto power "like a lobster with lockjaw."`
King–Byng Affair.
In 1926 King advised the Governor General, Lord Byng, to dissolve Parliament and call another election, but Byng refused, the only time in Canadian history that the Governor General has exercised such a power. Instead Byng called upon the Conservative Party leader, Arthur Meighen, to form a government. Meighen attempted to do so, but was unable to obtain a majority in the Commons and he, too, advised dissolution, which this time was accepted. The episode marks a constitutional crisis that was resolved by a tradition of non-interference in Canadian political affairs on the part of the British government.
Wins election.
In the ensuing Canadian federal election, 1926, King appealed for public support of the constitutional principle that the Governor General must accept the advice of his ministers, though this principle was at most only customary. The Liberals argued that the Governor General had interfered in politics and shown favour to one party over another. King and his party won the election with a plurality of seats in the Commons: 116 seats to the Conservatives' 91 in a 245-member House.
Extending Canadian autonomy.
The constitutional crisis of 1926 provoked a consideration of the constitutional relations between the self-governing dominions and the British government. During the next five years the position of the Governor General of a Dominion was clarified; he ceased to be a representative of the British government and became a representative of The Crown. The independent position of the Dominions in the British Empire (later the Commonwealth) and in the international community was put on a firm foundation by the Balfour Declaration of 1926, subsequently codified in the Statute of Westminster (1931).
King expanded the Department of External Affairs, founded in 1909, to further promote Canadian autonomy from Britain. The new department took some time to develop, but over time it significantly increased the reach and projection of Canadian diplomacy. Prior to this, Canada had relied on British diplomats who owed their first loyalty to London. King recruited many high-calibre people for the new venture, including future prime minister Lester Pearson and influential career administrators Norman Robertson and Hume Wrong. This project was a key element of his overall strategy, setting Canada on a course independent of Britain, of former colonizer France, as well as of the neighbouring powerful United States.
Extends provincial powers.
In domestic affairs King strengthened the Liberal policy of increasing the powers of the provincial governments by transferring to the governments of Manitoba, Alberta, and Saskatchewan the ownership of the crown lands within those provinces, as well as the subsoil rights; these in particular would become increasingly important, as petroleum and other natural resources proved very abundant. In collaboration with the provincial governments, he inaugurated a system of old-age pensions based on need. In February 1930, he appointed Cairine Wilson as the first female senator in Canadian history.
Defeat in 1930.
His government was in power during the beginning of the Great Depression, but was slow to respond to the mounting crisis. He felt that the crisis was a temporary swing of the business cycle and that the economy would soon recover without government intervention. Critics said he was out of touch. Just prior to the election, King carelessly remarked that he "would not give a five-cent piece" to Tory provincial governments for unemployment relief. The opposition made this remark a catch-phrase; the main issue was the deterioration in the economy and whether the prime minister was out of touch with the hardships of ordinary people. The Liberals lost the election of 1930 to the Conservative Party, led by Richard Bedford Bennett. The popular vote was very close between the two parties, with the Liberals actually earning more votes than in 1926, but the Conservatives had a geographical advantage that turned into enough seats to give a majority.
Opposition leader.
After his loss, King stayed on as Opposition Leader, where it was his policy to refrain from offering advice or alternative policies. Indeed, his policy preferences were not much different from Bennett's, and he let the Conservative government have its way. Though he gave the impression of sympathy with progressive and liberal causes, he had no enthusiasm for the New Deal of American President Franklin D. Roosevelt (which Bennett eventually tried to emulate, after floundering without solutions for several years), and he never advocated massive government action to alleviate depression in Canada. Upon his return to office in October 1935, however, King seemed to demonstrate a commitment (like Franklin Roosevelt) to the underprivileged, speaking of a new era where "poverty and adversity, want and misery are the enemies which Liberalism will seek to banish from the land". Over the next fourteen years, a wide range of reforms similar to those association with the New Deal were realized during Mackenzie King's last period in office as Prime Minister. In 1939, compulsory contributions for pensions for low-income widows and orphans were introduced (although these only covered the regularly employed) while depressed farmers were subsidized from that same year onwards. In 1944, family allowances were introduced, and from 1948 the federal government subsidized medical services in the provinces.
The various provinces were assisted by the Federal Unemployment and Agricultural Assistance Act of 1938 and the Youth Training Act of 1939 to create training programs for young persons, while an amendment to the Criminal Code (which received Royal assent in May 1939) provided against refusal to hire, or dismissal, "solely because of a person’s membership in a lawful trade-union or association." In 1937, the age for blind persons to qualify for old-age pensions was reduced to 40 in 1937, and later to 21 in 1947. The Federal Home Improvement Plan of 1937 provided subsidized rates of interest on rehabilitation loans to 66,900 homes, while the National Housing Act of 1938 made provision for the building of low-rent housing. Another Housing Act was later passed in 1944 with the intention of providing federally guaranteed loans or mortgages to individuals who wished to repair or construct dwellings through their own initiative. The Vocational Training Co-ordination Act of 1942 provided an impetus to the provinces to set up facilities for postsecondary vocational training, and in 1948 the Industrial Relations and Disputes Investigation Act was passed, which safeguarded the rights of workers to join unions while requiring employers to recognize unions chosen by their employees.
Prime Minister: fourth Parliament.
In the 1935 election the Liberals used the slogan "King or Chaos" to win a landslide victory. Promising a much-desired trade treaty with the U.S., the King government passed the 1935 Reciprocal Trade Agreement. It marked the turning point in Canadian-American economic relations, reversing the disastrous trade war of 1930–31, lowering tariffs, and yielding a dramatic increase in trade. More subtly, it revealed to the prime minister and 
President Roosevelt that they could work together well.
The worst of the Depression had passed by 1935, and King implemented relief programs such as the National Housing Act and National Employment Commission. His government also made the Canadian Broadcasting Corporation a crown corporation in 1936, created Trans-Canada Airlines (the precursor to Air Canada) in 1937, and formed the National Film Board of Canada in 1939. In 1938, he transformed the Bank of Canada from a private entity to a crown corporation.
After 1936 the prime minister lost patience when western Canadians preferred radical alternatives such as the CCF (Co-operative Commonwealth Federation) and Social Credit to his middle-of-the-road liberalism. Indeed, he came close to writing off the region with his comment that the prairie dust bowl was "part of the U.S. desert area. I doubt if it will be of any real use again." Instead he paid more attention to the industrial regions and the needs of Ontario and Quebec, particularly with respect to the proposed St. Lawrence Seaway project with the United States. As for the unemployed, he was hostile to federal relief, and only reluctantly accepted a Keynesian solution that involved federal deficit spending, tax cuts and subsidies to the housing market.
Germany and Hitler.
In March 1936, in response to the German remilitarization of the Rhineland, King had the Canadian High Commissioner in London inform the British government that if Britain went to war with Germany over the Rhineland issue that Canada would remain neutral. In June 1937, during an Imperial Conference of all the Dominion Prime Ministers in London, King informed British Prime Minister Neville Chamberlain that Canada would only go to war if Britain were directly attacked, and that if Britain were to become involved in a continental war then Chamberlain was not to expect Canadian support.
In 1937, King visited Germany and met with Adolf Hitler. Possessing a religious yearning for direct insight into the hidden mysteries of life and the universe, and strongly influenced by the operas of Richard Wagner (who was also Hitler's favourite composer), King decided Hitler was akin to mythical Wagnerian heroes within whom good and evil were struggling. He thought that good would eventually triumph and Hitler would redeem his people and lead them to a harmonious, uplifting future. These spiritual attitudes not only guided Canada's relations with Hitler but gave the prime minister the comforting sense of a higher mission, that of helping to lead Hitler to peace. King commented in his journal that "he is really one who truly loves his fellow-men, and his country, and would make any sacrifice for their good". He forecast that "the world will yet come to see a very great man–mystic in Hitler. [...] I cannot abide in Nazism -– the regimentation -– cruelty -– oppression of Jews -– attitude towards religion, etc., but Hitler, him –- the peasant -– will rank some day with Joan of Arc among the deliverers of his people."
In late 1938, during the great crisis in Europe over Czechoslovakia that culminated in the Munich Agreement, Canadians were divided. Francophones insisted on neutrality, as did some top advisers like Oscar D. Skelton. Imperialists stood behind Britain and were willing to fight Germany. King, who served as his own secretary of state for external affairs (foreign minister), said privately that if he had to choose he would not be neutral, but he made no public statement. All of Canada was relieved that the British appeasement at Munich, while sacrificing the rights of Czechoslovakia, seemed to bring peace.
Ethnic policies.
While Minister of Labour, King was appointed to investigate the causes of and claims for compensation resulting from the 1907 Asiatic Exclusion League riots in Vancouver's Chinatown and Japantown. One of the claims for damages came from Chinese opium manufacturers, which led King to investigate narcotics use in Vancouver. King became alarmed upon hearing that white women were also opium users, not just Chinese men, and he then initiated the process that led to the first legislation outlawing narcotics in Canada.
Under King's administration, the Canadian government, responding to strong public opinion, especially in Quebec, refused to expand immigration opportunities for Jewish refugees from Europe. In June 1939 Canada, along with Cuba and the United States, refused to allow entry for the 900 Jewish refugees aboard the passenger ship .
Prime Minister: fifth Parliament, Second World War.
Parliamentary Declaration of War.
King realized the likelihood of World War II and began mobilizing on August 25, 1939, with full mobilization on September 1, 1939, the day Germany invaded Poland. In 1914, Canada was at the war by virtue of King George V's declaration. In 1939, the Prime Minister asserted Canada's autonomy and convened the House of Commons on September 7, nearly a month ahead of schedule, to discuss the government's intention to enter the war, which was approved two days later. On September 10, Prime Minister King, through his High Commissioner in London, issued a request to King George VI, asking him, in his capacity as King of Canada, to declare war against Germany.
Mobilization.
King linked Canada more and more closely to the United States, signing an agreement with Roosevelt at Ogdensburg, New York in August 1940 that provided for the close cooperation of Canadian and American forces, despite the fact that the U.S. remained officially neutral until the bombing of Pearl Harbor on December 7, 1941. During the war the Americans took virtual control of the Yukon and the then-British colony of Newfoundland in building the Alaska Highway and major airbases.
King—and Canada—were largely ignored by Winston Churchill, despite Canada's major role in supplying food, raw materials, munitions and money to the hard-pressed British economy, training airmen for the Commonwealth, guarding the western half of the North Atlantic Ocean against German U-boats, and providing combat troops for the invasions of Italy, France and Germany in 1943–45. King proved highly successful in mobilizing the economy for war, with impressive results in industrial and agricultural output. The depression ended, prosperity returned, and Canada's economy expanded significantly. On the political side, King rejected any notion of a government of national unity. He held the Canadian federal election, 1940 as normally scheduled, despite the ongoing World War, unlike Britain, which formed a government of national unity and did not hold a wartime election.
To re-arm Canada he built the Royal Canadian Air Force as a viable military power, while at the same time keeping it separate from Britain's Royal Air Force. He was instrumental in obtaining the British Commonwealth Air Training Plan Agreement, which was signed in Ottawa in December 1939, binding Canada, Britain, New Zealand and Australia to a program that eventually trained half the airmen from those four nations in the Second World War.
Expansion of scientific research.
King's government greatly expanded the role of the National Research Council of Canada during the war, moving into full-scale research in nuclear physics and commercial use of nuclear power in the following years. King, with C.D. Howe acting as point man, moved the nuclear group from Montreal to Chalk River, Ontario in 1944, with the establishment of Chalk River Nuclear Laboratories and the residential town of Deep River, Ontario. Canada became a world leader in this field, with the NRX reactor becoming operational in 1947; at the time, NRX was the only operational nuclear reactor outside the United States.
The NRC also contributed to wartime scientific development in other ways during this period.
Conscription Crisis.
King's promise not to impose conscription contributed to the defeat of Maurice Duplessis's Union Nationale Quebec provincial government in 1939 and Liberals' re-election in the 1940 election. But after the fall of France in 1940, Canada introduced conscription for home service. Still, only volunteers were to be sent overseas. King wanted to avoid a repeat of the Conscription Crisis of 1917. By 1942, the military was pressing King hard to send conscripts to Europe. In 1942, King held a national plebiscite on the issue, asking the nation to relieve him of the commitment he had made during the election campaign. In the House of Commons on June 10, 1942, he said that his policy was "not necessarily conscription but conscription if necessary".
French Canadians voted against conscription, with over 70% opposed, but an overwhelming majority – over 80% – of English Canadians supported it. French and English conscripts were sent to fight in the Aleutian Islands in 1943 – technically North American soil and therefore not "overseas" – but the mix of Canadian volunteers and draftees found that the Japanese troops had fled before their arrival. Otherwise, King continued with a campaign to recruit volunteers, hoping to address the problem with the shortage of troops caused by heavy losses in the Dieppe Raid in 1942, in Italy in 1943, and after the Battle of Normandy in 1944. In November 1944, the Government decided it was necessary to send conscripts to Europe for the war. This led to a brief political crisis (see Conscription Crisis of 1944) and a mutiny by conscripts posted in British Columbia, but the war ended a few months later. Over 15,000 conscripts went to Europe, though only a few hundred saw combat.
Internment of Japanese-Canadians.
After the start of war with Japan in December 1941 the government oversaw the Japanese-Canadian internment on Canada's west coast, which sent 22,000 British Columbia residents of Japanese descent to relocation camps far from the coast. The reason was intense public demand for removal and fears of espionage or sabotage. King and his Cabinet ignored reports from the Royal Canadian Mounted Police and Canadian military that most of the Japanese were law-abiding and not a threat. Major General Ken Stuart told Ottawa, "I cannot see that the Japanese Canadians constitute the slightest menace to national security." King's political direction on this issue closely followed postulates from his 1909 doctoral thesis at Harvard.
Canadian autonomy.
Throughout his tenure, King led Canada from a colony with responsible government to an autonomous nation within the British Commonwealth. During the Chanak Crisis of 1922, King refused to support the British without first consulting Parliament, while the Conservative leader, Arthur Meighen, supported Britain. The British were disappointed with King's response, but the crisis was soon resolved, as King had anticipated. After the King-Byng Affair, King went to the Imperial Conference of 1926 and argued for greater autonomy of the Dominions. This resulted in the Balfour Declaration 1926, which announced the equal status of all members of the British Commonwealth (as it was known then), including Britain. This eventually led to the Statute of Westminster 1931. The Canadian city of Hamilton hosted the first Empire Games in 1930; this competition later became known as the Commonwealth Games, and is held every four years.
In the lead-up to World War II in 1939, King affirmed Canadian autonomy by saying that the Canadian Parliament would make the final decision on the issue of going to war. He reassured the pro-British Canadians that Parliament would surely decide that Canada would be at Britain's side if Great Britain was drawn into a major war. At the same time, he reassured those who were suspicious of British influence in Canada by promising that Canada would not participate in British colonial wars. His Quebec lieutenant, Ernest Lapointe, promised French-Canadians that the government would not introduce conscription; individual participation would be voluntary. In 1939, in a country which had seemed deeply divided, these promises made it possible for Parliament to agree almost unanimously to declare war.
King played two roles. On the one hand, he told English Canadians that Canada would no doubt enter war if Britain did. On the other hand, he and his Quebec lieutenant Ernest Lapointe told French Canadians that Canada would only go to war if it was in the country's best interests. With the dual messages, King slowly led Canada toward war without causing strife between Canada's two main linguistic communities. As his final step in asserting Canada's autonomy, King ensured that the Canadian Parliament made its own declaration of war one week after Britain.
During the war, Canada rapidly expanded its diplomatic missions abroad. However British Prime Minister Winston Churchill made all the major military and diplomatic decisions for Canada and the other dominions, with minimal consultation. While Canada hosted two major Allied conferences in Quebec in 1943 and 1944, neither Mackenzie King nor his senior generals and admirals were invited to take part in any of the discussions.
King's government introduced the Canadian Citizenship Act in 1946, which officially created the notion of "Canadian citizens". Prior to this, Canadians were considered British subjects living in Canada. On January 3, 1947, King received Canadian citizenship certificate number 0001.
Prime Minister: sixth Parliament, post-war Canada.
With the War winding down, King held the Canadian federal election, 1945, and won the election, with a minority, but formed a functioning coalition to continue governing. The main opposition party Conservatives were weak for most of the two decades after R.B. Bennett lost the 1935 election, and King had virtually unchallenged power for much of his later years; this expanded still further during the War. He promoted American-born engineer C.D. Howe into positions of great power and influence during the War, but was hit hard by the 1940 air-crash death of key minister and protege Norman McLeod Rogers. After this setback, and the 1941 death of his Quebec lieutenant Ernest Lapointe, King sought out the reluctant Louis St. Laurent, a leading Quebec lawyer, to take over Lapointe's role, and eventually persuaded St. Laurent to serve in government.
King helped found the United Nations in 1945 and attended the opening meetings in San Francisco. However, he became pessimistic about the organization's future possibilities. After the war, King quickly dismantled wartime controls. Unlike World War I, press censorship ended with the hostilities. He began an ambitious program of social programs and laid the groundwork for Newfoundland and Labrador's entry into Canada; however, this did not take place until 1949, the year after King retired.
King moved Canada into the deepening Cold War in alliance with the U.S. and Britain. He dealt with the espionage revelations of Soviet cipher clerk Igor Gouzenko, who defected in Ottawa in September 1945, by quickly appointing a Royal Commission to investigate Gouzenko's allegations of a Canadian Communist spy-ring transmitting top-secret documents to the Soviet Union. External Affairs minister Louis St. Laurent dealt decisively with this crisis, the first of its type in Canada's history. St. Laurent's leadership deepened King's respect, and helped make St. Laurent the next Canadian Prime Minister three years later.
Retirement and death.
On January 20, 1948, King called on the Liberal Party to hold its first national convention since 1919 to choose a new leader. The August convention chose Louis St. Laurent as the new leader of the Liberal Party. Three months later, King retired after 22 years as prime minister. King also had the most terms (six) as Prime Minister. Sir John A. Macdonald was second-in-line, with 19 years, as the longest-serving Prime Minister in Canadian history (1867–1873, 1878–1891). King was not charismatic and did not have a large personal following. Only eight Canadians in 100 picked him when the Canadian Gallup (CIPO) poll asked in September 1946, "What person living in any part of the world today do you admire?" Nevertheless, his Liberal Party was easily re-elected in the election of 1945.
King died on July 22, 1950, at Kingsmere from pneumonia, with his retirement plans to write his memoirs unfulfilled. He is buried in Mount Pleasant Cemetery, Toronto.
Personal life.
Christopher Moore says, "King had made 'Parliament will decide' his maxim, and he trotted it out whenever he wished to avoid a decision."
King kept a very candid diary from 1893 until his death in 1950. One biographer called these diaries "the most important single political document in twentieth-century Canadian history," for they explain motivations of the Canadian war efforts and describe other events in detail.
King's occult interests were kept secret during his years in office, and only became publicized after his death when his diaries were opened. Readers were amazed. King communed with spirits, using seances with paid mediums. Thereby he communicated with Leonardo da Vinci, Sir Wilfrid Laurier, his dead mother, his grandfather William Lyon Mackenzie, and several of his dead dogs, as well as the spirit of the late President Roosevelt. Some historians argue that he sought personal reassurance from the spirit world, more than political advice. After his death, one of his mediums said that she had not realized that he was a politician. King did inquire whether his party would win the 1935 election, one of the few times politics came up during his seances. However Allan Levine argues that sometimes he did pay attention to the political implications of his seances:
Historians have seen in his spiritualism and occult activities a penchant for forging unities from antitheses, thus having latent political import. Historian Charles Perry Stacey, in his 1976 book "A Very Double Life" examined King's secret life in detail, argued that King did not allow his beliefs to influence his decisions on political matters. Stacey wrote that King entirely gave up his interests in the occult and spiritualism during World War II.
King never married, but had several close women friends, including Joan Patteson, a married woman with whom he spent some of his leisure time; sometimes she served as hostess at his dinner parties. He did not have a wife who could be the hostess all the time and handle the many social obligations that he tried to downplay. Editor Charles Bowman reports that, "He felt the lack of a wife, particularly when social duties called for a hostess."
Some historians have interpreted passages in his diaries as suggesting that King regularly had sexual relations with prostitutes. Others, also basing their claims on passages of his diaries, have suggested that King was in love with Lord Tweedsmuir, whom he had chosen for appointment as Governor General in 1935.
Legacy.
King was the only Canadian Prime Minister to be in office during the reigns of three Canadian Monarchs.
King was ranked #1, or greatest Canadian Prime Minister, by a survey of Canadian historians.
He was named a Person of National Historic Significance in 1968.
His most famous quotes include:
Honours.
<br>
<br>
Memorials.
King's likeness appears on the Canadian fifty-dollar note.
King left no published political memoirs, although his private diaries were extensively detailed. His main published work remains his 1918 book "Industry and Humanity".
Following the publication of King's diaries in the 1970s, several fictional works about him were published by Canadian writers. These included Elizabeth Gourlay's novel "Isabel", Allan Stratton's play "Rexy" and Heather Robertson's trilogy "Willie: A Romance" (1983), "Lily: A Rhapsody in Red" (1986), and "Igor: A Novel of Intrigue" (1989).
In 1998, there was controversy over King's exclusion from a memorial to the Quebec Conference, which was attended by King, Roosevelt, and Churchill. The monument was commissioned by the sovereigntist Parti Québécois government of Quebec, which justified the decision on their interpretation that King was acting merely as a host for the meeting between Roosevelt and Churchill. Canadian federalists, however, accused the government of Quebec of trying to advance their own political agenda.
OC Transpo has a Transitway station named Mackenzie King due to its location on the Mackenzie King Bridge. It is located adjacent to the Rideau Centre in downtown Ottawa.
The bridge across the Rideau Canal in downtown Ottawa, built following World War II, is named in his honour to recognize his contributions to the land planning of the city of Ottawa.
Part of his country retreat, now called Mackenzie King Estate, at Kingsmere in the Gatineau Park, near Ottawa, is open to the public. The house King died in, called "The Farm", is the official residence of the Speaker of the Canadian House of Commons, and is not part of the park.
The Woodside National Historic Site in Kitchener, Ontario was King's boyhood home. The estate has over 4.65 hectares of garden and parkland for exploring and relaxing, and the house has been restored to reflect life during King's era. There is a MacKenzie King Public School in the Heritage Park neighbourhood in Kitchener. Kitchener was known as Berlin until 1916.
King was mentioned in the book "Alligator Pie" by Dennis Lee as the subject of a nonsensical children's poem, which reads "William Lyon Mackenzie King / He sat in the middle and played with string / He loved his mother like anything / William Lyon Mackenzie King."
A character who appeared twice in the popular 1990s Canadian TV series Due South was named "Mackenzie King" in obvious reference.
Supreme Court appointments.
King chose the following jurists to be appointed as justices of the Supreme Court of Canada by the Governor General:

</doc>
<doc id="33446" url="https://en.wikipedia.org/wiki?curid=33446" title="Waterloo (1970 film)">
Waterloo (1970 film)

Waterloo () is a 1970 Soviet-Italian film directed by Sergei Bondarchuk and produced by Dino De Laurentiis. It depicts the story of the preliminary events and the Battle of Waterloo, and is famous for its lavish battle scenes.
It stars Rod Steiger as Napoleon Bonaparte and Christopher Plummer as the Duke of Wellington with a cameo by Orson Welles as Louis XVIII of France. Other stars include Jack Hawkins as General Thomas Picton, Virginia McKenna as the Duchess of Richmond and Dan O'Herlihy as Marshal Ney.
The film includes some 15,000 Soviet foot soldiers and 2,000 cavalrymen as extras—it was said that, during its making, director Sergei Bondarchuk was in command of the seventh largest army in the world. Fifty circus stunt riders were used to perform the dangerous horse falls. 
Plot.
In 1814 French Emperor Napoleon Bonaparte, facing certain defeat at the hands of Britain, Austria, Prussia and Russia (the Sixth coalition), abdicates at the demand of his marshals. He is banished to Elba with 1,000 men, but escapes and returns to France. Ney, now serving the monarchy of Louis XVIII of France, is tasked with recapturing him, but he and his army defect to Napoleon. King Louis flees, Napoleon triumphantly enters Paris, and the European powers declare war.
The Prussian von Muffling interrupts the Duchess of Richmond's ball to warn the Duke of Wellington that Napoleon has invaded Belgium to defeat the Allied forces before they can unite. Realising that Napoleon has got between himself and the Prussians, Wellington decides to halt the French at Waterloo.
The French fight the British to a draw at Quatre-Bras, but defeat the Prussians at Ligny. Field Marshal Blücher rejects the advice of his Chief of Staff, General Gneisenau to retreat and instead moves north to Wavre to keep contact with Wellington. Napoleon, enraged that Ney has let Wellington withdraw to ground of his choosing, directs 30,000 men under Marshal Grouchy to pursue Blücher and keep the Prussians from rejoining the British, while he leads his remaining force against Wellington.
The battle of Waterloo, delayed to let the ground dry after the previous night's storm, starts shortly after 11:30 am with cannon fire from the French. Napoleon launches a diversionary infantry attack on Wellington's right flank, the Chateau of Hougoumont, but Wellington refuses to divert forces. Napoleon then attacks the allied left with d'Erlon's infantry corps. General Picton successfully halts the attack but is killed. Ponsonby's cavalry brigade, the renowned Royal Scots Greys, pursue the French, but go too far across the battlefield and become isolated from the rest of the Allied force, and are thus cut to pieces by Napoleon's lancers. Ponsonby himself is killed.
Napoleon realises that troops spotted emerging from the woods to the east are Prussians (Blücher's army), not French (Grouchy's force), but keeps this from his army. He then suffers stomach pain and withdraws temporarily, leaving Marshal Ney in command. Ney misinterprets a reorganisation of the Allied line as a retreat and leads a cavalry charge, which is repelled with heavy losses by allied infantry squares.
Napoleon returns and rebukes his marshals for letting Ney attack without infantry support. However he hopes that Wellington's line has been worn down. The British farmhouse of La Haye Sainte falls, and Napoleon sends the Imperial Guard for the decisive blow. As they advance they are repulsed by Maitland's Guards Division, who were lying unseen in the grass on the reverse of the slope. The repulse of the Guard devastates French morale, and the arrival of the Prussians makes matters certain. After refusing to surrender, the Imperial Guard squares are annihilated with close range artillery.
After the battle, Wellington wanders among the piles of dead, lamenting the cost of victory. At the same time Napoleon, who had declared that he would die with his men, is dragged by his marshals from the field and later departs in a carriage for Paris.
Production.
Columbia Pictures published a 28-page, full-colour pictorial guide when it released "Waterloo" in 1970. According to the guidebook, Italian producer Dino De Laurentiis had difficulty finding financial backers for the massive undertaking until he finally began talks with the Russians in the late 1960s and reached agreement with the Mosfilm organization. Final costs were over £12 million (UK) (equivalent to about US $38.3 million in 1970), making "Waterloo", for its time, one of the most expensive movies ever made. Had the movie been filmed in the West, costs might have been as much as three times this. Mosfilm contributed more than £4 million of the costs, nearly 16,000 soldiers of the Soviet Army, a full brigade of Soviet cavalry, and a host of engineers and labourers to prepare the battlefield in the rolling farmland outside Uzhhorod, Ukraine (then part of the Soviet Union).
To recreate the battlefield authentically, the Russians bulldozed away two hills, laid five miles of roads, transplanted 5,000 trees, sowed fields of rye, barley and wildflowers and reconstructed four historic buildings. To create the mud, more than six miles of underground irrigation piping was specially laid. Most of the battle scenes were filmed using five Panavision cameras simultaneously—from ground level, from 100 foot towers, from a helicopter, and from an overhead railway built right across the location.
Actual filming was accomplished over 28 weeks, which included 16 days of delay (principally due to bad weather). Many of the battle scenes were filmed in the summer of 1969 in often sweltering heat. In addition to the battlefield in Ukraine, filming also took place on location in Caserta, Italy, while interior scenes were filmed on the large De Laurentiis Studios lot in Rome. A massive quantity of period props were built by E. Rancati and hundreds of pairs of footwear were supplied by Pompei.
Months before the cameras started filming, the 16,000 Soviet Army soldiers began training to learn 1815 drill and battle formations, as well as the use of sabres, bayonets and handling cannon. A selected 2,000 additional men were also taught to load and fire muskets. This army lived in a large encampment next to the battlefield. Each day after breakfast, they marched to a large wardrobe building, donned their French, British or Prussian uniforms and fifteen minutes later were in position. The soldiers were commanded by officers who took orders from director Sergei Bondarchuk by walkie-talkie. To assist in the direction of this huge, multi-national undertaking, the Russian director had four interpreters permanently at his side: one each for English, Italian, French and Serbo-Croatian.
Historical inaccuracies.
While the film portrayed the events of the "Hundred Days" quite faithfully, including some allusions to and scenes from the Battle of Ligny and of Quatre Bras, there were a few mistakes, presumably made for artistic purposes, and some characters act as ciphers for others. In the opening scene, where the marshals are attempting to persuade Napoleon to abdicate, Marshal Soult is present: in 1814, Soult was commanding the defence of Toulouse against Wellington's Army.
At the Duchess of Richmond's ball (which itself was held in something more like a barn than the magnificent ballroom depicted 
), there is an entirely fictional romantic sub-plot with Lord Hay and one of the Duchess' daughters.
As Wellington awaits Napoleon's assault at Waterloo, his men start singing "Boney was a Warrior." This song is a sea chanty written no earlier than the 1820s, and so could not have been sung in 1815. 
Unlike the Prussians in the movie, arriving at the right flank of the French force, General Bülow's 4th corps attacked at the rear-right of the French lines at the village of Plancenoit. Napoleon sent first his reserve corps (under General Lobau) and then the Second Foot Grenadiers, the second-most-senior corps of his Imperial Guard, to engage and delay these Prussians while maintaining his front line; these clashes in and around the village of Plancenoit were crucial to the battle; around 7:30 PM, another Prussian corps under Marshal Blücher arrived on the battlefield to link with the British army on the grounds of the inn "La Belle Alliance", sealing the fate of the French force.
William Ponsonby, before leading the British cavalry charge, tells the Earl of Uxbridge that Ponsonby's father had been killed in battle by lancers, not least because he had been riding an inferior horse: in fact his father had been a politician who died of natural causes back in England, and he is simply foretelling his own fate in the battle.
The Duke of Gordon is depicted as leading his Gordon Highlanders into battle, and is described by the Duchess of Richmond as "uncle": in fact, he is a conflate character, representing the contributions of several members of the House of Gordon. The Duke at the time, the founder and colonel of the regiment, was the Duchess of Richmond's "father", and he saw no active service overseas during the Napoleonic Wars; his son and the Duchess's brother, the Marquis of Huntly (later the 5th Duke) was a distinguished general, but held no command in the campaign, although anecdotal evidence suggests that he arrived during the aftermath of the battle; the senior representative of the family at the battle was in fact the Duchess's own twenty-three-year-old son, the Earl of March, who would eventually become the 5th Duke's heir in 1836, and who served as a major and an aide de camp to the Duke of Wellington; another branch of the family was represented by another ADC, Colonel Sir Alexander Gordon, aged twenty-eight or twenty-nine, the brother of the Earl of Aberdeen; in reality, both were young men similar in age and duty to Lord Hay. The field commander of the Gordon regiment during the campaign, Lieutenant Colonel, John Cameron of Fassiefern, had been killed at the battle of Quatre Bras on 16 June. The acting commander of the regiment during the battle appears to have been Major Donald MacDonald of Dalchosnie.
Reception.
The film was the fifth most popular "reserve ticket" movie at the British box office in 1971. However it failed to recoup its cost. This, in part, led director Stanley Kubrick to abandon a film he was preparing on Napoleon. Post release saw the film gain popularity and receive numerous positive reviews for its battle depiction. The film is rumoured to have originally been 4 hours long as shown in the Soviet Union. Several historical characters listed in the credits do not actually appear in the film, they are said to have been in scenes cut before release. In this 'extended version', the chronology of Waterloo is said to have been much more detailed as well as more in depth coverage of the Battle of Ligny. 
The film won two BAFTA awards in 1971 (Best art direction and best costume design) and was nominated for a third (best cinematography.) The film was also novelized by Frederick E. Smith, with the content based on the screenplay.

</doc>
<doc id="33447" url="https://en.wikipedia.org/wiki?curid=33447" title="Wrestling weight classes">
Wrestling weight classes

In many styles of wrestling, opponents are matched based on weight.
Olympic and International weight classes.
Currently, men's freestyle and Greco-Roman as well as female wrestling have the following weights on the international level:
International youth weight classes.
For men's freestyle and Greco-Roman.
Currently, men's freestyle and Greco-Roman wrestling is divided into three youth age categories internationally: schoolboys, cadets, and juniors.
Schoolboys (young men ages 13–14; or age 12 with a medical certificate and parental authorization) competing in freestyle and Greco-Roman do so in one of the following 10 weight classes:
Cadets (young men ages 15–16; or age 14 with a medical certificate and parental authorization) competing in freestyle and Greco-Roman do so in one of the following 10 weight classes:
Juniors (young men ages 18 to 20; or age 17 with a medical certificate and parental authorization) competing in freestyle and Greco-Roman do so in one of the following eight weight classes:
For men, there is also a special category for some freestyle and Greco-Roman competitions, "Veterans", for men ages 35 and older, that presumably wrestle in the same weight classes as seniors.
For women's freestyle.
Women currently compete in freestyle wrestling in one of four age categories on an international level: schoolgirls, cadets, juniors, and seniors.
Schoolgirls (young women ages 14–15; or age 13 with a medical certificate and parental authorization) competing in freestyle wrestling do so in one of the following 10 weight classes:
Cadets (young women ages 16–17; or age 15 with a medical certificate and parental authorization) competing in freestyle wrestling do so in one of the following 10 weight classes:
Juniors (young women ages 18 to 20; or age 17 with a medical certificate and parental authorization) competing in freestyle wrestling do so in one of the following eight weight classes:
Different nations may have different weight classes and different age categories for their levels of men's and women's freestyle and men's Greco-Roman competition.
Collegiate (scholastic) weight classes.
Elementary school.
Elementary school students competing in wrestling have multiple ways weight classes are determined.
Middle school.
Wrestling weight classes for Middle (junior high) school in the United States vary from state to state and are not regulated by the NFHS. Students may compete in scholastic wrestling in one of the following weight classes:
Some states use these weight classes for middle school:
Also in some states:
High school.
High school students in the United States competing in scholastic wrestling do so in one of the following 14 weight classes set by the National Federation of State High School Associations (NFHS)
The AAU has their own weight classes for their tournaments.
These weights are only for their Freshman/Sophomore State Tournament.
Other states have additional or modified weight classes such as:
The state of Michigan has different weight classes than the standard classes listed above. The classes include:
Rankings for these classes in Michigan can be found on Michigan Grappler. 
The state of Pennsylvania has different weight classes than the standard classes listed above. The classes include:
106
112
120
126
132
138
145
152
160
170
182
195
220
HWT (285)
College.
College and university students in the United States competing in collegiate wrestling do so in one of the following 10 weight classes set by the National Collegiate Athletic Association (NCAA):
Also:
The National Collegiate Wrestling Association has also approved the following eight weight classes for its women's division:

</doc>
<doc id="33449" url="https://en.wikipedia.org/wiki?curid=33449" title="William Empson">
William Empson

Sir William Empson (, 27 September 1906 – 15 April 1984) was an English literary critic and poet, widely influential for his practice of closely reading literary works, a practice fundamental to New Criticism. His best-known work is his first, "Seven Types of Ambiguity", published in 1930.
Jonathan Bate has written that the three greatest English literary critics of the 18th, 19th and 20th centuries are Johnson, Hazlitt and Empson, "not least because they are the funniest".
Education.
Empson was the son of Arthur Reginald Empson of Yokefleet Hall, Yorkshire. His mother was Laura, daughter of Richard Mickelthwait, JP, of Ardsley House, Yorkshire. He was a first cousin of the twins David and Richard Atcherley.
Empson first discovered his great skill and interest in mathematics at his preparatory school. He won an entrance scholarship to Winchester College, where he excelled as a student and received what he later described as "a ripping education" in spite of the rather rough and abusive milieu of the school: a longstanding tradition of physical force, especially among the students, figured prominently in life at such schools.
In 1925 Empson won a scholarship to Magdalene College, Cambridge, where he read Mathematics, gaining a First for his Part I but a disappointing 2.i for his Part II. He then went on to pursue a second degree in English, and at the end of the first year he was offered a Bye-Fellowship. His supervisor in Mathematics, the father of the mathematician and philosopher Frank P. Ramsey, expressed regret at Empson's decision to pursue English rather than Mathematics, since it was a discipline for which Empson showed great talent.
I. A. Richards, the director of studies in English, recalled the genesis of Empson's first major work, "Seven Types of Ambiguity", composed when Empson was not yet 22 and published when he was 24:
At about his third visit he brought up the games of interpretation which Laura Riding and Robert Graves had been playing "A Survey of Modernist Poetry", 1927 with the unpunctuated form of 'The expense of spirit in a waste of shame.' Taking the sonnet as a conjuror takes his hat, he produced an endless swarm of lively rabbits from it and ended by 'You could do that with any poetry, couldn't you?' This was a Godsend to a Director of Studies, so I said, 'You'd better go off and do it, hadn't you?'
But disaster struck when a servant found condoms among Empson's possessions and claimed to have caught him "in flagrante delicto" with a woman. As a result, not only did he have his scholarship revoked, but his name was struck from the college records, he lost his prospects of a fellowship and he was banished from the city.
Career.
After his banishment from Cambridge Empson supported himself for a brief period as a freelance critic and journalist, living in Bloomsbury until 1930, when he signed a three-year contract to teach in Japan after his tutor Richards had failed to find him a post teaching in China. He returned to England in the mid-1930s only to depart again after receiving a three-year contract to teach at Peking University. Upon his arrival he discovered that, because of the Japanese invasion of China, he no longer had a post. He joined the exodus of the university's staff, with little more than a typewriter and a suitcase, and ended up in Kunming, with Lianda (Southwest Associated University), the school created there by students and professors who were refugees from the war in the North. He arrived back in England in January 1939.
He worked for a year on the daily Digest of foreign broadcasts and in 1941 met George Orwell, at that time the Indian Editor of the BBC Eastern Service, on a six-week course at what was called the Liars' School of the BBC. They remained friends, but Empson recalled one clash: "At that time the Government had put into action a scheme for keeping up the birth-rate during the war by making it in various ways convenient to have babies, for mothers going out to work; government nurseries were available after the first month, I think, and there were extra eggs and other goodies on the rations. My wife and I took advantage of this plan to have two children. I was saying to George one evening after dinner what a pleasure it was to cooperate with so enlightened a plan when, to my horror, I saw the familiar look of settled loathing come over his face. Rich swine boasting over our privileges, that was what we had become ...".
Just after the war Empson returned to China. He taught at Peking University, befriending a young David Hawkes, who later became a noted sinologist and chair of Chinese at Oxford University. Then, in the late 1940s and early 1950s, he taught a summer course for the intensive study of literature at the Kenyon School of English at Kenyon College in Ohio. According to "Newsweek", "The roster of instructors was enough to pop the eyes of any major in English." In addition to Empson the faculty included Robert Penn Warren, John Crowe Ransom, Robert Lowell, Delmore Schwartz, Jacques Barzun, Eric Bentley, Cleanth Brooks, Alfred Kazin, Arthur Mizener, Allen Tate and Yvor Winters.
In 1953 Empson was Professor of Rhetoric at Gresham College, London, for a year. He then became head of the English Department at the University of Sheffield until his retirement in 1972. He was knighted in 1979, the same year his old college, Magdalene, awarded him an honorary fellowship some 50 years after his expulsion.
Professor Sir William Empson died in 1984.
Critical focus.
Empson's critical work focuses largely on early and pre-modern works in the English literary canon. He was a significant scholar of Milton (see below), Shakespeare ("Essays on Shakespeare") and Elizabethan drama ("Essays on Renaissance Literature", Volume 2: "The Drama"). He published a monograph, "Faustus and the Censor", on the subject of censorship and the authoritative version of Marlowe's "Doctor Faustus". He was also an important scholar of the metaphysical poets John Donne ("Essays on Renaissance Literature", Volume 1: "Donne and the New Philosophy") and Andrew Marvell.
Occasionally Empson brought his critical genius to bear on modern writers; "Using Biography", for instance, contains papers on Henry Fielding's "Tom Jones" as well as the poems of W. B. Yeats and T. S. Eliot, and Joyce's "Ulysses".
Literary criticism.
Empson was styled a "critic of genius" by Frank Kermode, who qualified his praise by identifying willfully perverse readings of certain authors. Harold Bloom has stated that Empson is among a handful of critics who matter most to him because of their force and eccentricity. Empson's bluntness led to controversy both during his life and after his death, and a reputation in part also as a "licensed buffoon" (Empson's own phrase).
Style, method and influence.
Empson is today best known for his literary criticism, and in particular his analysis of the use of language in poetical works: his own poems are arguably undervalued, although they were admired by and influenced English poets in the 1950s. The philosopher Ludwig Wittgenstein was an acquaintance at Cambridge, but Empson consistently denied any previous or direct influence on his work. Empson's best-known work is the book "Seven Types of Ambiguity", which, together with "Some Versions of Pastoral" and "The Structure of Complex Words", mines the astonishing riches of linguistic ambiguity in English poetic literature. Empson's studies unearth layer upon layer of irony, suggestion and argumentation in various literary works, applying a technique of textual criticism so influential that often Empson's contributions to certain domains of literary scholarship remain significant, though they may no longer be recognized as his. The universal recognition of the difficulty and complexity (indeed, ambiguity) of Shakespeare's "Sonnet 94" ("They that have power ..."), for instance, is traceable to Empson's analysis in "Some Versions of Pastoral". Empson's study of "Sonnet 94" goes some way towards explaining the high esteem in which the sonnet is now held (often being reckoned as among the finest sonnets), as well as the technique of criticism and interpretation that has thus reckoned it.
Empson's technique of teasing a rich variety of interpretations from poetic literature does not, however, exhaustively characterize his critical practice. He was also very interested in the human or experiential reality to be discovered in great works of literature, as is manifest, for instance, in his discussion of the fortunes of the notion of proletarian literature in "Some Versions of Pastoral". His commitment to unravelling or articulating the experiential truth or reality in literature permitted him unusual avenues to explore sociopolitical ideas in literature in a vein very different from contemporary Marxist critics or scholars of New Historicism. Thus, for instance, Empson remarks in the first few pages of "Some Versions of Pastoral" that:
Gray's "Elegy" is an odd case of poetry with latent political ideas:
What this means, as the context makes clear, is that eighteenth century England had no scholarship system or "carrière ouverte aux talents". This is stated as pathetic, but the reader is put into a mood in which one would not try to alter it. ... By comparing the social arrangement to Nature he makes it seem inevitable, which it was not, and gives it a dignity which was undeserved. ... The tone of melancholy claims that the poet understands the considerations opposed to aristocracy, though he judges against them; the truism of the reflections in the churchyard, the universality and impersonality this gives to the style, claim as if by comparison that we ought to accept the injustice of society as we do the inevitability of death.
Empson goes on to deliver his political verdict with a psychological suggestion:
Many people, without being communists, have been irritated by the complacence in the massive calm of the poem, and this seems partly because they feel there is a cheat in the implied politics; the "bourgeois" themselves do not like literature to have too much "bourgeois ideology".
Empson also made remarks reminiscent of Dr Samuel Johnson in their pained insistence:
And yet what is said is one of the permanent truths; it is only in degree that any improvement of society could prevent wastage of human powers; the waste even in a fortunate life, the isolation even of a life rich in intimacy, cannot but be felt deeply, and is the central feeling of tragedy. And anything of value must accept this because it must not prostitute itself; its strength is to be prepared to waste itself, if it does not get its opportunity. A statement of this is certainly non-political because it is true in any society, and yet nearly all the great poetic statements of it are in a way "bourgeois", like this one; they suggest to readers, though they do not say, that for the poor man things cannot be improved even in degree.
Despite the complexity of Empson's critical methods and attitude, his work, in particular "Seven Types of Ambiguity", had a significant impact on the New Criticism, a school of criticism that directed particular attention to close reading of texts, among whose adherents may be numbered F. R. Leavis (whose critical approach was, however, already well developed before Empson appeared on the scene - he had been teaching at Cambridge since 1925), although Empson could scarcely be described as an adherent or exponent of such a school or, indeed, of any critical school at all. Indeed, Empson consistently ridiculed, both outrightly in words and implicitly in practice, the doctrine of the intentional fallacy formulated by William K. Wimsatt, an influential New Critic. Indeed, Empson's distaste for New Criticism could manifest itself in a distinctively dismissive and brusque wit, as when he described New Criticism (which he ironically labelled "the new rigour") as a "campaign to make poetry as dull as possible" ("Essays on Renaissance Literature", Volume 1: "Donne and the New Philosophy", p. 122). Similarly, both the title and the content of one of Empson's volumes of critical papers, "Using Biography", show a patent and polemical disregard for the teachings of New Critics as much as for those of Roland Barthes and postmodern literary theories predicated upon, if not merely influenced by, the notion of the Death of the Author, despite the fact that some scholars regard Empson as a progenitor of certain of these currents of criticism, which vexed Empson. As Frank Kermode stated:
Now and again somebody like Christopher Norris may, in a pious moment, attempt to "recuperate" a particularly brilliant old-style reputation by claiming its owner as a New New Critic "avant la lettre" - Empson in this case, now to be thought of as having, in his "great theoretical summa," "The Structure of Complex Words", anticipated deconstruction. The grumpy old man repudiated this notion with his habitual scorn, calling the work of Derrida (or, as he preferred to call him, "Nerrida") "very disgusting"(Kermode, "Pleasure, Change, and the Canon")
"Milton's God".
Empson's "Milton's God" is often described as a sustained attack on Christianity and a defence of Milton's attempt to 'justify the ways of God to man' in "Paradise Lost". Empson argues that precisely the inconsistencies and complexities adduced by critics as evidence of the poem's badness in fact function in quite the opposite manner. What the poem brings out is the difficulty faced by anyone in encountering and submitting to the will of God and, indeed, the great clash between the authority of such a deity and the determinate desires and needs of human beings:
the poem is not good in spite of but especially because of its moral confusions, which ought to be clear in your mind when you are feeling its power. I think it horrible and wonderful; I regard it as like Aztec or Benin sculpture, or to come nearer home the novels of Kafka, and am rather suspicious of any critic who claims not to feel anything so obvious.
Empson claims that it is precisely Milton's great sensitivity and faithfulness to the Scriptures, in spite of their apparent madness, that generates such a controversial picture of God. Empson reckons that it requires a mind of astonishing integrity to, in the words of Blake, be of the Devil's party without knowing it:
Empson portrays "Paradise Lost" as the product of a poet of astonishingly powerful and imaginative sensibilities and great intellect who had invested much of himself in the poem.
Despite its lack of influence, certain critics view "Milton's God" as by far the best sustained work of criticism on the poem by a 20th-century critic. Harold Bloom includes it as one of the few critical works worthy of canonical status in his "The Western Canon" (where it is also the only critical work concerned solely with a single piece of literature).
Verse.
Empson's poems are clever, learned, dry, aethereal and technically virtuosic, not wholly dissimilar to his critical work. His high regard for the metaphysical poet John Donne is to be seen in many places within his work, tempered with his appreciation of Buddhist thinking, an occasional tendency to satire and a larger awareness of intellectual trends. He wrote very few poems and stopped publishing poems almost entirely after 1940. His "Complete Poems" by John Haffenden, his biographer is 512 pages long, with over 300 pages of notes. In reviewing this work Frank Kermode commended Empson as a "most noteworthy poet" and chose it as International Book of the Year for "The Times Literary Supplement".
Quotations.
From "Proletarian Literature" in "Some Versions of Pastoral":
From "They That Have Power" in "Some Versions of Pastoral":
From "Milton and Bentley" in "Some Versions of Pastoral":
Surely Bentley was right to be surprised at finding Faunus haunting the bower ["Paradise Lost" ll. 705 - 707], a ghost crying in the cold of Paradise, and the lusts of Pan sacred even in comparison to Eden. There is a Vergilian quality in the lines, haunting indeed, a pathos not mentioned because it is the whole of the story. I suppose that in Satan determining to destroy the innocent happiness of Eden, for the highest political motives, without hatred, not without tears, we may find some echo of the Elizabethan fulness of life that Milton as a poet abandoned, and as a Puritan helped to destroy.
On Celine's "Journey to the End of the Night" from "Some Versions of Pastoral":
"Voyage au Bout de la Nuit"...is not to be placed quickly either as pastoral or proletarian; it is partly the 'underdog' theme and partly social criticism. The two main characters have no voice or trust in their society and no sympathy with those who have; it is this, not cowardice or poverty or low class, which the war drives home to them, and from then on they have a straightforward inferiority complex; the theme becomes their struggle with it as private individuals. ... Life may be black and mad in the second half but Bardamu is not, and he gets to the real end of the night as critic and spectator. This change is masked by unity of style and by a humility which will not allow that one can claim to be sane while living as part of such a world, but it is in the second half that we get Bardamu speaking as Celine in criticism of it. What is attacked may perhaps be summed up as the death-wishes generated by the herds of a machine society, and he is not speaking as 'spokesman of the proletariat' or with any sympathy for a communist one. ...before claiming the book as proletarian literature "you have to separate off the author (in the phrase that Radek used) as a man ripe for fascism".
From "The Variants for the Byzantium Poems" in "Using Biography":
From ""Ulysses": Joyce's Intentions" in "Using Biography":

</doc>
<doc id="33454" url="https://en.wikipedia.org/wiki?curid=33454" title="Web">
Web

Web or Webs may refer to:

</doc>
<doc id="33455" url="https://en.wikipedia.org/wiki?curid=33455" title="Web server">
Web server

A web server is an information technology that processes requests via HTTP, the basic network protocol used to distribute information on the World Wide Web. The term can refer either to the entire computer system, an appliance, or specifically to the software that accepts and supervises the HTTP requests.
Overview.
The primary function of a web server is to store, process and deliver web pages to clients. The communication between client and server takes place using the Hypertext Transfer Protocol (HTTP). Pages delivered are most frequently HTML documents, which may include images, style sheets and scripts in addition to text content. 
A user agent, commonly a web browser or web crawler, initiates communication by making a request for a specific resource using HTTP and the server responds with the content of that resource or an error message if unable to do so. The resource is typically a real file on the server's secondary storage, but this is not necessarily the case and depends on how the web server is implemented.
While the primary function is to serve content, a full implementation of HTTP also includes ways of receiving content from clients. This feature is used for submitting web forms, including uploading of files.
Many generic web servers also support server-side scripting using Active Server Pages (ASP), PHP, or other scripting languages. This means that the behaviour of the web server can be scripted in separate files, while the actual server software remains unchanged. Usually, this function is used to generate HTML documents dynamically ("on-the-fly") as opposed to returning static documents. The former is primarily used for retrieving and/or modifying information from databases. The latter is typically much faster and more easily cached but cannot deliver dynamic content.
Web servers are not only used for serving the World Wide Web. They can also be found embedded in devices such as printers, routers, webcams and serving only a local network. The web server may then be used as a part of a system for monitoring and/or administering the device in question. This usually means that no additional software has to be installed on the client computer, since only a web browser is required (which now is included with most operating systems).
History.
In 1989 Tim Berners-Lee proposed a new project to his employer CERN, with the goal of easing the exchange of information between scientists by using a hypertext system. The project resulted in Berners-Lee writing two programs in 1990:
Between 1991 and 1994, the simplicity and effectiveness of early technologies used to surf and exchange data through the World Wide Web helped to port them to many different operating systems and spread their use among scientific organizations and universities, and then to industry.
In 1994 Tim Berners-Lee decided to constitute the World Wide Web Consortium (W3C) to regulate the further development of the many technologies involved (HTTP, HTML, etc.) through a standardization process.
Path translation.
Web servers are able to map the path component of a Uniform Resource Locator (URL) into:
For a "static request" the URL path specified by the client is relative to the web server's root directory.
Consider the following URL as it would be requested by a client:
The client's user agent will translate it into a connection to www.example.com with the following HTTP 1.1 request:
The web server on www.example.com will append the given path to the path of its root directory. On an Apache server, this is commonly /home/www (On Unix machines, usually /var/www). The result is the local file system resource:
The web server then reads the file, if it exists, and sends a response to the client's web browser. The response will describe the content of the file and contain the file itself or an error message will return saying that the file does not exist or is unavailable.
Kernel-mode and user-mode web servers.
A web server can be either incorporated into the OS kernel, or in user space (like other regular applications).
Web servers that run in user-mode have to ask the system for permission to use more memory or more CPU resources. Not only do these requests to the kernel take time, but they are not always satisfied because the system reserves resources for its own usage and has the responsibility to share hardware resources with all the other running applications. Executing in user mode can also mean useless buffer copies which are another handicap for user-mode web servers.
Load limits.
A web server (program) has defined load limits, because it can handle only a limited number of concurrent client connections (usually between 2 and 80,000, by default between 500 and 1,000) per IP address (and TCP port) and it can serve only a certain maximum number of "" (RPS, also known as queries per second or QPS) depending on:
When a web server is near to or over its limit, it becomes unresponsive.
Causes of overload.
At any time web servers can be overloaded due to:
Symptoms of overload.
The symptoms of an overloaded web server are:
Anti-overload techniques.
To partially overcome above average load limits and to prevent overload, most popular web sites use common techniques like:
Market share.
Below are the latest statistics of the market share of the top web servers on the Internet by Netcraft
February 2016 Web Server Survey.
Apache, IIS and Nginx are the most used web servers on the Internet.

</doc>
<doc id="33456" url="https://en.wikipedia.org/wiki?curid=33456" title="Well-order">
Well-order

In mathematics, a well-order (or well-ordering or well-order relation) on a set "S" is a total order on "S" with the property that every non-empty subset of "S" has a least element in this ordering. The set "S" together with the well-order relation is then called a well-ordered set. In some academic articles and textbooks these terms are instead written as wellorder, wellordered, and wellordering or well order, well ordered, and well ordering.
Every non-empty well-ordered set has a least element. Every element "s" of a well-ordered set, except a possible greatest element, has a unique successor (next element), namely the least element of the subset of all elements greater than "s". There may be elements besides the least element which have no predecessor (see "Natural numbers" below for an example). In a well-ordered set "S", every subset "T" which has an upper bound has a least upper bound, namely the least element of the subset of all upper bounds of "T" in "S".
If ≤ is a non-strict well ordering, then < is a strict well ordering. A relation is a strict well ordering if and only if it is a well-founded strict total order. The distinction between strict and non-strict well orders is often ignored since they are easily interconvertible.
Every well-ordered set is uniquely order isomorphic to a unique ordinal number, called the order type of the well-ordered set. The well-ordering theorem, which is equivalent to the axiom of choice, states that every set can be well ordered. If a set is well ordered (or even if it merely admits a well-founded relation), the proof technique of transfinite induction can be used to prove that a given statement is true for all elements of the set.
The observation that the natural numbers are well ordered by the usual less-than relation is commonly called the well-ordering principle (for natural numbers).
Ordinal numbers.
Every well-ordered set is uniquely order isomorphic to a unique ordinal number, called the order type of the well-ordered set. The position of each element within the ordered set is also given by an ordinal number. In the case of a finite set, the basic operation of counting, to find the ordinal number of a particular object, or to find the object with a particular ordinal number, corresponds to assigning ordinal numbers one by one to the objects. The size (number of elements, cardinal number) of a finite set is equal to the order type. Counting in the everyday sense typically starts from one, so it assigns to each object the size of the initial segment with that object as last element. Note that these numbers are one more than the formal ordinal numbers according to the isomorphic order, because these are equal to the number of earlier objects (which corresponds to counting from zero). Thus for finite "n", the expression ""n"-th element" of a well-ordered set requires context to know whether this counts from zero or one. In a notation "β-th element" where β can also be an infinite ordinal, it will typically count from zero.
For an infinite set the order type determines the cardinality, but not conversely: well-ordered sets of a particular cardinality can have many different order types. For a countably infinite set, the set of possible order types is even uncountable.
Examples and counterexamples.
Natural numbers.
The standard ordering ≤ of the natural numbers is a well ordering and has the additional property that every non-zero natural number has a unique predecessor.
Another well ordering of the natural numbers is given by defining that all even numbers are less than all odd numbers, and the usual ordering applies within the evens and the odds:
This is a well-ordered set of order type ω + ω. Every element has a successor (there is no largest element). Two elements lack a predecessor: 0 and 1.
Integers.
Unlike the standard ordering ≤ of the natural numbers, the standard ordering ≤ of the integers is not a well ordering, since, for example, the set of negative integers does not contain a least element.
The following relation "R" is an example of well ordering of the integers: "x R y" if and only if one of the following conditions holds:
This relation "R" can be visualized as follows: 
"R" is isomorphic to the ordinal number ω + ω.
Another relation for well ordering the integers is the following definition: "x" ≤z "y" iff (|"x"| < |"y"| or (|"x"| = |"y"| and "x" ≤ "y")). This well order can be visualized as follows: 
This has the order type ω.
Reals.
The standard ordering ≤ of any real interval is not a well ordering, since, for example, the open interval (0, 1) ⊆ [0,1] does not contain a least element. From the ZFC axioms of set theory (including the axiom of choice) one can show that there is a well order of the reals. Also Wacław Sierpiński proved that ZF + GCH (the generalized continuum hypothesis) imply the axiom of choice and hence a well order of the reals. Nonetheless, it is possible to show that the ZFC+GCH axioms alone are not sufficient to prove the existence of a definable (by a formula) well order of the reals. However it is consistent with ZFC that a definable well ordering of the reals exists—for example, it is consistent with ZFC that V=L, and it follows from ZFC+V=L that a particular formula well orders the reals, or indeed any set.
An uncountable subset of the real numbers with the standard ordering ≤ cannot be a well order: Suppose "X" is a subset of R well ordered by ≤. For each "x" in "X", let "s"("x") be the successor of "x" in ≤ ordering on "X" (unless "x" is the last element of "X"). Let "A" = { ("x", "s"("x")) | "x" ∈ "X" } whose elements are nonempty and disjoint intervals. Each such interval contains at least one rational number, so there is an injective function from "A" to Q. There is an injection from "X" to "A" (except possibly for a last element of "X" which could be mapped to zero later). And it is well known that there is an injection from "Q" to the natural numbers (which could be chosen to avoid hitting zero). Thus there is an injection from "X" to the natural numbers which means that "X" is countable. On the other hand, a countably infinite subset of the reals may or may not be a well order with the standard "≤".
Examples of well orders:
Equivalent formulations.
If a set is totally ordered, then the following are equivalent to each other:
Order topology.
Every well-ordered set can be made into a topological space by endowing it with the order topology.
With respect to this topology there can be two kinds of elements:
For subsets we can distinguish:
A subset is cofinal in the whole set if and only if it is unbounded in the whole set or it has a maximum which is also maximum of the whole set.
A well-ordered set as topological space is a first-countable space if and only if it has order type less than or equal to ω1 (omega-one), that is, if and only if the set is countable or has the smallest uncountable order type.

</doc>
<doc id="33458" url="https://en.wikipedia.org/wiki?curid=33458" title="Well-ordering theorem">
Well-ordering theorem

In mathematics, the well-ordering theorem states that every set can be well-ordered. A set X is "well-ordered" by a strict total order if every non-empty subset of X has a least element under the ordering. This is also known as Zermelo's theorem and is equivalent to the Axiom of Choice. Ernst Zermelo introduced the Axiom of Choice as an "unobjectionable logical principle" to prove the well-ordering theorem. This is important because it makes every set susceptible to the powerful technique of transfinite induction. The well-ordering theorem has consequences that may seem paradoxical, such as the Banach–Tarski paradox.
History.
Georg Cantor considered the well-ordering theorem to be a "fundamental principle of thought." Most mathematicians however find it difficult to visualize a well-ordering of, for example, the set R of real numbers. In 1904, Gyula Kőnig claimed to have proven that such a well-ordering cannot exist. A few weeks later, Felix Hausdorff found a mistake in the proof. It turned out, though, that the well-ordering theorem is equivalent to the axiom of choice, in the sense that either one together with the Zermelo–Fraenkel axioms is sufficient to prove the other, in first order logic (the same applies to Zorn's Lemma). In second order logic, however, the well-ordering theorem is strictly stronger than the axiom of choice: from the well-ordering theorem one may deduce the axiom of choice, but from the axiom of choice one cannot deduce the well-ordering theorem.
Statement and proof.
For every set "X", there exists a well-ordering with domain "X".
The well-ordering theorem follows from Zorn's Lemma. Take the set "A" of all well-orderings of subsets of "X": an element of "A" is an ordered pair ("a","b") where "a" is a subset of "X" and "b" is a well-ordering of "a". "A" can be partially ordered by continuation. That means, define "E" ≤ "F" if "E" is an initial segment of "F" and the ordering of the members in "E" is the same as their ordering in "F". If "E" is a chain in "A", then the union of the sets in "E" can be ordered in a way that makes it a continuation of any set in "E"; this ordering is a well-ordering, and therefore, an upper bound of "E" in "A". We may therefore apply Zorn's Lemma to conclude that "A" has a maximal element, say ("M","R"). The set "M" must be equal to "X", for if "X" has an element "x" not in "M", then the set "M"∪{"x"} has a well-ordering that restricts to "R" on "M", and for which "x" is larger than all elements of "M". This well ordered set is a continuation of ("M","R"), contradicting its maximality, therefore "M" = "X". Now "R" is a well-ordering of "X".
The Axiom of Choice can be proven from the well-ordering theorem as follows. To make a choice function for a collection of non-empty sets, "E", take the union of the sets in "E" and call it "X". There exists a well-ordering of "X"; let "R" be such an ordering. The function that to each set "S" of "E" associates the smallest element of "S", as ordered by (the restriction to "S" of) "R", is a choice function for the collection "E". An essential point of this proof is that it involves only a single arbitrary choice, that of "R"; applying the well-ordering theorem to each member "S" of "E" separately would not work, since the theorem only asserts the existence of a well-ordering, and choosing for each "S" a well-ordering would not be easier than choosing an element.

</doc>
<doc id="33496" url="https://en.wikipedia.org/wiki?curid=33496" title="Weapon">
Weapon

A weapon, arm, or armament is any device used with intent to inflict damage or harm to living beings, structures, or systems. Weapons are used to increase the efficacy and efficiency of activities such as crime, law enforcement, self-defense and warfare. In a broader context, weapons may be construed to include anything used to gain a strategic, material or mental advantage over an adversary.
While just about any ordinary objects such as sticks, stones, cars, or pencils can be used as weapons, many are expressly designed for the purpose – ranging from simple implements such as clubs, swords and guns, to complicated modern intercontinental ballistic missiles, biological and cyber weapons.
History.
Prehistoric.
The use of objects as weapons has been observed among chimpanzees, leading to speculation that early hominids first began to use weapons as early as five million years ago. However, this can not be confirmed using physical evidence because wooden clubs, spears, and unshaped stones would not have left an unambiguous record. The earliest unambiguous weapons to be found are the Schöninger Speere: eight wooden throwing spears dated as being more than 300,000 years old. At the site of Nataruk in Turkana, Kenya, numerous human skeletons dating to 10,000 years ago have major traumatic injuries to the head, neck, ribs, knees and hands, including obsidian projectiles still embedded in the bones, that would have been caused by arrows and clubs in the context of conflict between two hunter-gatherer groups.
Ancient and classical.
Ancient weapons were evolutionary improvements of late neolithic implements, but then significant improvements in materials and crafting techniques created a series of revolutions in military technology:
The development of metal tools, beginning with copper during the Copper Age (about 3,300 BC) and followed shortly by bronze led to the Bronze Age sword and similar weapons.
The first defensive structures and fortifications appeared in the Bronze Age, indicating an increased need for security. Weapons designed to breach fortifications followed soon after, for example the battering ram was in use by 2500 BC.
Although early Iron Age swords were not superior to their bronze predecessors, once iron-working developed, around 1200 BC in Sub-Saharan Africa, iron began to be used widely in weapon production.
Domestication of the horse and widespread use of spoked wheels by ca. 2000 BC, led to the light, horse-drawn chariot. The mobility provided by chariots were important during this era. Spoke-wheeled chariot usage peaked around 1300 BC and then declined, ceasing to be militarily relevant by the 4th century BC.
Cavalry developed once horses were bred to support the weight of a man. The horse extended the range and increased the speed of attacks.
Ships built as weapons or warships such as the trireme were in use by the 7th century BC. These ships were eventually replaced by larger ships by the 4th century BC.
Middle Ages.
European warfare during the middle ages was dominated by elite groups of knights supported by massed infantry (both in combat and ranged roles). They were involved in mobile combat and sieges which involved various siege weapons and tactics. Knights on horseback developed tactics for charging with lances providing an impact on the enemy formations and then drawing more practical weapons (such as swords) once they entered into the melee. Whereas infantry, in the age before structured formations, relied on cheap, sturdy weapons such as spears and billhooks in close combat and bows from a distance. As armies became more professional, their equipment was standardized and infantry transitioned to pikes. Pikes are normally seven to eight feet in length, in conjunction with smaller side-arms (short sword).
In Eastern and Middle Eastern warfare, similar tactics were developed independent of European influences.
The introduction of gunpowder from the Far East at the end of this period revolutionized warfare. Formations of musketeers, protected by pikemen came to dominate open battles, and the cannon replaced the trebuchet as the dominant siege weapon.
Early modern.
The European Renaissance marked the beginning of the implementation of firearms in western warfare. Guns and rockets were introduced to the battlefield.
Firearms are qualitatively different from earlier weapons because they release energy from combustible propellants such as gunpowder, rather than from a counter-weight or spring. This energy is released very rapidly and can be replicated without much effort by the user. Therefore even early firearms such as the arquebus were much more powerful than human-powered weapons. Firearms became increasingly important and effective during the 16th century to 19th century, with progressive improvements in ignition mechanisms followed by revolutionary changes in ammunition handling and propellant. During the U.S. Civil War various technologies including the machine gun and ironclad warship emerged that would be recognizable and useful military weapons today, particularly in limited conflicts. In the 19th century warship propulsion changed from sail power to fossil fuel-powered steam engines.
The age of edged weapons ended abruptly just before World War I with rifled artillery. Howitzers were able to destroy masonry fortresses and other fortifications. This single invention caused a Revolution in Military Affairs (RMA) and established tactics and doctrine that are still in use today. "See Technology during World War I for a detailed discussion."
An important feature of industrial age warfare was technological escalation – innovations were rapidly matched through replication or countered by yet another innovation. The technological escalation during World War I (WW I) was profound, producing armed aircraft and tanks.
This continued in the inter-war period (between WW I and WW II) with continuous evolution of all weapon systems by all major industrial powers. Many modern military weapons, particularly ground-based ones, are relatively minor improvements of weapon systems developed during World War II. "See military technology during World War II for a detailed discussion."
Modern.
Since the mid-18th century North American French-Indian war through the beginning of the 20th century, human-powered weapons were reduced from the primary weaponry of the battlefield yielding to gunpowder-based weaponry. Sometimes referred to as the "Age of Rifles", this period was characterized by the development of firearms for infantry and cannons for support, as well as the beginnings of mechanized weapons such as the machine gun, the tank and the wide introduction of aircraft into warfare, including naval warfare with the introduction of the aircraft carriers.
World War I marked the entry of fully industrialized warfare as well as weapons of mass destruction ("e.g.", chemical and biological weapons), and weapons were developed quickly to meet wartime needs. Above all, it promised to the military commanders the independence from the horse and the resurgence in maneuver warfare through extensive use of motor vehicles. The changes that these military technologies underwent before and during the Second World War were evolutionary, but defined the development for the rest of the century.
World War II however, perhaps marked the most frantic period of weapons development in the history of humanity. Massive numbers of new designs and concepts were fielded, and all existing technologies were improved between 1939 and 1945. The most powerful weapon invented during this period was the atomic bomb, however many more weapons influenced the world in different ways.
Nuclear age and beyond.
Since the realization of Mutually Assured Destruction (MAD), the nuclear option of all-out war is no longer considered a survivable scenario. During the Cold War in the years following World War II, both the United States and the Soviet Union engaged in a nuclear arms race. Each country and their allies continually attempted to out-develop each other in the field of nuclear armaments. Once the joint technological capabilities reached the point of being able to ensure the destruction of the entire planet (see nuclear holocaust) then a new tactic had to be developed. With this realization, armaments development funding shifted back to primarily sponsoring the development of conventional arms technologies for support of limited wars rather than nuclear war.
Legislation.
The production, possession, trade and use of many weapons are controlled. This may be at a local or central government level, or international treaty.
Examples of such controls include:
Lifecycle problems.
The end of a weapon's lifecycle has been determined differently in different cultures, and throughout history. Likewise, the disposal methods of used or no longer used weapons have varied.
The US military used ocean dumping for unused weapons and bombs, including ordinary bombs, UXO, landmines and chemical weapons from at least 1919 until 1970. Weapons dumped in the Gulf of Mexico have washed up on the Florida coast. The oil drilling activity at the seafloor off the Texas-Louisiana coast increases chances of encountering these weapons.
Fishermen have brought weapons disposed of at the Massachusetts Bay Disposal Site to various towns in Massachusetts.

</doc>
<doc id="33498" url="https://en.wikipedia.org/wiki?curid=33498" title="Wire">
Wire

A wire is a single, usually cylindrical, flexible strand or rod of metal. Wires are used to bear mechanical loads or electricity and telecommunications signals. Wire is commonly formed by drawing the metal through a hole in a die or draw plate. Wire gauges come in various standard sizes, as expressed in terms of a gauge number. The term "wire" is also used more loosely to refer to a bundle of such strands, as in "multistranded wire", which is more correctly termed a wire rope in mechanics, or a cable in electricity.
Wire comes in solid core, stranded, or braided forms. Although usually circular in cross-section, wire can be made in square, hexagonal, flattened rectangular, or other cross-sections, either for decorative purposes, or for technical purposes such as high-efficiency voice coils in loudspeakers. Edge-wound coil springs, such as the Slinky toy, are made of special flattened wire. 
History.
In antiquity, jewelry often contains, in the form of chains and applied decoration, large amounts of wire that is accurately made and which must have been produced by some efficient, if not technically advanced, means. In some cases, strips cut from metal sheet were made into wire by pulling them through perforations in stone beads. This causes the strips to fold round on themselves to form thin tubes. This strip drawing technique was in use in Egypt by the 2nd Dynasty. From the middle of the 2nd millennium BCE most of the gold wires in jewellery are characterised by seam lines that follow a spiral path along the wire. Such twisted strips can be converted into solid round wires by rolling them between flat surfaces or the strip wire drawing method. The strip twist wire manufacturing method was superseded by drawing in the ancient Old World sometime between about the 8th and 10th centuries AD. There is some evidence for the use of drawing further East prior to this period.
Square and hexagonal wires were possibly made using a swaging technique. In this method a metal rod was struck between grooved metal blocks, or between a grooved punch and a grooved metal anvil. Swaging is of great antiquity, possibly dating to the beginning of the 2nd millennium BCE in Egypt and in the Bronze and Iron Ages in Europe for torcs and fibulae. Twisted square-section wires are a very common filigree decoration in early Etruscan jewelry.
In about the middle of the 2nd millennium BCE, a new category of decorative tube was introduced which imitated a line of granules. True beaded wire, produced by mechanically distorting a round-section wire, appeared in the Eastern Mediterranean and Italy in the seventh century BCE, perhaps disseminated by the Phoenicians. Beaded wire continued to be used in jewellery into modern times, although it largely fell out of favour in about the tenth century CE when two drawn round wires, twisted together to form what are termed 'ropes', provided a simpler-to-make alternative. A forerunner to beaded wire may be the notched strips and wires which first occur from around 2000 BCE in Anatolia.
Wire was drawn in England from the medieval period. The wire was used to make wool cards and pins, manufactured goods whose import was prohibited by Edward IV in 1463. The first wire mill in Great Britain was established at Tintern in about 1568 by the founders of the Company of Mineral and Battery Works, who had a monopoly on this. Apart from their second wire mill at nearby Whitebrook, there were no other wire mills before the second half of the 17th century. Despite the existence of mills, the drawing of wire down to fine sizes continued to be done manually.
Wire is usually drawn of cylindrical form; but it may be made of any desired section by varying the outline of the holes in the draw-plate through which it is passed in the process of manufacture. The draw-plate or die is a piece of hard cast-iron or hard steel, or for fine work it may be a diamond or a ruby. The object of utilising precious stones is to enable the dies to be used for a considerable period without losing their size, and so producing wire of incorrect diameter. Diamond dies must be rebored when they have lost their original diameter of hole, but metal dies are brought down to size again by hammering up the hole and then drifting it out to correct diameter with a punch.
Uses.
Wire has many uses. It forms the raw material of many important manufacturers, such as the wire netting industry, engineered springs, wire-cloth making and wire rope spinning, in which it occupies a place analogous to a textile fiber. Wire-cloth of all degrees of strength and fineness of mesh is used for sifting and screening machinery, for draining paper pulp, for window screens, and for many other purposes. Vast quantities of aluminium, copper, nickel and steel wire are employed for telephone and data cables, and as conductors in electric power transmission, and heating. It is in no less demand for fencing, and much is consumed in the construction of suspension bridges, and cages, etc. In the manufacture of stringed musical instruments and scientific instruments, wire is again largely used. Carbon and stainless spring steel wire have significant applications in engineered springs for critical automotive or industrial manufactured parts/components. Pin and hairpin making; the needle and fish-hook industries; nail, peg, and rivet making; and carding machinery consume large amounts of wire as feedstock.
Not all metals and metallic alloys possess the physical properties necessary to make useful wire. The metals must in the first place be ductile and strong in tension, the quality on which the utility of wire principally depends. The principal metals suitable for wire, possessing almost equal ductility, are platinum, silver, iron, copper, aluminium, and gold; and it is only from these and certain of their alloys with other metals, principally brass and bronze, that wire is prepared.
By careful treatment, extremely thin wire can be produced. Special purpose wire is however made from other metals (e.g. tungsten wire for light bulb and vacuum tube filaments, because of its high melting temperature). Copper wires are also plated with other metals, such as tin, nickel, and silver to handle different temperatures, provide lubrication, provide easier stripping of rubber insulation from copper.
Production.
Wire is often reduced to the desired diameter and properties by repeated drawing through progressively smaller dies, or traditionally holes in draw plates. After a number of passes the wire may be annealed to facilitate more drawing or, if it is a finished product, to maximise ductility and conductivity.
Finishing, jacketing, and insulating.
Electrical wires are usually covered with insulating materials, such as plastic, rubber-like polymers, or varnish. Insulating and jacketing of wires and cables is nowadays done by passing them through an extruder. Formerly, materials used for insulation included treated cloth or paper and various oil-based products. Since the mid-1960s, plastic and polymers exhibiting properties similar to rubber have predominated.
Two or more wires may be wrapped concentrically, separated by insulation, to form coaxial cable. The wire or cable may be further protected with substances like paraffin, some kind of preservative compound, bitumen, lead, aluminum sheathing, or steel taping. Stranding or covering machines wind material onto wire which passes through quickly. Some of the smallest machines for cotton covering have a large drum, which grips the wire and moves it through toothed gears; the wire passes through the centre of disks mounted above a long bed, and the disks carry each a number of bobbins varying from six to twelve or more in different machines. A supply of covering material is wound on each bobbin, and the end is led on to the wire, which occupies a central position relatively to the bobbins; the latter being revolved at a suitable speed bodily with their disks, the cotton is consequently served on to the wire, winding in spiral fashion so as to overlap. If a large number of strands are required the disks are duplicated, so that as many as sixty spools may be carried, the second set of strands being laid over the first.
For heavier cables that are used for electric light and power as well as submarine cables, the machines are somewhat different in construction. The wire is still carried through a hollow shaft, but the bobbins or spools of covering material are set with their spindles at right angles to the axis of the wire, and they lie in a circular cage which rotates on rollers below. The various strands coming from the spools at various parts of the circumference of the cage all lead to a disk at the end of the hollow shaft. This disk has perforations through which each of the strands pass, thence being immediately wrapped on the cable, which slides through a bearing at this point. Toothed gears having certain definite ratios are used to cause the winding drum for the cable and the cage for the spools to rotate at suitable relative speeds which do not vary. The cages are multiplied for stranding with a large number of tapes or strands, so that a machine may have six bobbins on one cage and twelve on the other.
Forms of wire.
Solid wire.
Solid wire, also called solid-core or single-strand wire, consists of one piece of metal wire. Solid wire is useful for wiring breadboards. Solid wire is cheaper to manufacture than stranded wire and is used where there is little need for flexibility in the wire. Solid wire also provides mechanical ruggedness; and, because it has relatively less surface area which is exposed to attack by corrosives, protection against the environment.
Stranded wire.
Stranded wire is composed of a number of small wires bundled or wrapped together to form a larger conductor. Stranded wire is more flexible than solid wire of the same total cross-sectional area. Stranded wire tends to be a better conductor than solid wire because the individual wires collectively comprise a greater surface area. Stranded wire is used when higher resistance to metal fatigue is required. Such situations include connections between circuit boards in multi-printed-circuit-board devices, where the rigidity of solid wire would produce too much stress as a result of movement during assembly or servicing; A.C. line cords for appliances; musical instrument cables; computer mouse cables; welding electrode cables; control cables connecting moving machine parts; mining machine cables; trailing machine cables; and numerous others.
At high frequencies, current travels near the surface of the wire because of the "skin effect", resulting in increased power loss in the wire. Stranded wire might seem to reduce this effect, since the total surface area of the strands is greater than the surface area of the equivalent solid wire, but ordinary stranded wire does not reduce the skin effect because all the strands are short-circuited together and behave as a single conductor. A stranded wire will have higher resistance than a solid wire of the same diameter because the cross-section of the stranded wire is not all copper; there are unavoidable gaps between the strands (this is the circle packing problem for circles within a circle). A stranded wire with the same cross-section of conductor as a solid wire is said to have the same equivalent gauge and is always a larger diameter.
However, for many high-frequency applications, "proximity effect" is more severe than skin effect, and in some limited cases, simple stranded wire can reduce proximity effect. For better performance at high frequencies, litz wire, which has the individual strands insulated and twisted in special patterns, may be used.
Braided wire.
A braided wire is composed of a number of small strands of wire braided together. Similar to stranded wires, braided wires are better conductors than solid wires. Braided wires do not break easily when flexed. Braided wires are often suitable as an electromagnetic shield in noise-reduction cables.
Number of strands.
The more individual wire strands in a wire bundle, the more flexible, kink-resistant, break-resistant, and stronger the wire becomes. However, more strands increases manufacturing complexity and cost.
For geometrical reasons, the lowest number of strands usually seen is 7: one in the middle, with 6 surrounding it in close contact. The next level up is 19, which is another layer of 12 strands on top of the 7. After that the number varies, but 37 and 49 are common, then in the 70 to 100 range (the number is no longer exact). Even larger numbers than that are typically found only in very large cables.
For application where the wire moves, 19 is the lowest that should be used (7 should only be used in applications where the wire is placed and then does not move), and 49 is much better. For applications with constant repeated movement, such as assembly robots and headphone wires, 70 to 100 is mandatory.
For applications that need even more flexibility, even more strands are used (welding cables are the usual example, but also any application that needs to move wire in tight areas). One example is a 2/0 wire made from 5,292 strands of #36 gauge wire. The strands are organized by first creating a bundle of 7 strands. Then 7 of these bundles are put together into super bundles. Finally 108 super bundles are used to make the final cable. Each group of wires is wound in a helix so that when the wire is flexed, the part of a bundle that is stretched moves around the helix to a part that is compressed to allow the wire to have less stress.

</doc>
<doc id="33501" url="https://en.wikipedia.org/wiki?curid=33501" title="White dwarf">
White dwarf

A white dwarf, also called a degenerate dwarf, is a stellar remnant composed mostly of electron-degenerate matter. A white dwarf is very dense: its mass is comparable to that of the Sun, while its volume is comparable to that of Earth. A white dwarf's faint luminosity comes from the emission of stored thermal energy; no fusion takes place in a white dwarf wherein mass is converted to energy. The nearest known white dwarf is Sirius B, at 8.6 light years, the smaller component of the Sirius binary star. There are currently thought to be eight white dwarfs among the hundred star systems nearest the Sun. The unusual faintness of white dwarfs was first recognized in 1910. The name "white dwarf" was coined by Willem Luyten in 1922. The universe has not been alive long enough to experience a white dwarf releasing all of its energy as it will take close to a trillion years.
White dwarfs are thought to be the final evolutionary state of stars whose mass is not high enough to become a neutron star, including our Sun and over 97% of the other stars in the Milky Way., §1. After the hydrogen–fusing period of a main-sequence star of low or medium mass ends, such a star will expand to a red giant during which it fuses helium to carbon and oxygen in its core by the triple-alpha process. If a red giant has insufficient mass to generate the core temperatures required to fuse carbon, around 1 billion K, an inert mass of carbon and oxygen will build up at its center. After a star sheds its outer layers and forms a planetary nebula, it will leave behind this core, which is the remnant white dwarf. Usually, therefore, white dwarfs are composed of carbon and oxygen. If the mass of the progenitor is between 8 and 10.5 solar masses (), the core temperature is sufficient to fuse carbon but not neon, in which case an oxygen–neon–magnesium white dwarf may form. Stars of very low mass will not be able to fuse helium, hence, a helium white dwarf may form by mass loss in binary systems.
The material in a white dwarf no longer undergoes fusion reactions, so the star has no source of energy. As a result, it cannot support itself by the heat generated by fusion against gravitational collapse, but is supported only by electron degeneracy pressure, causing it to be extremely dense. The physics of degeneracy yields a maximum mass for a non-rotating white dwarf, the Chandrasekhar limit—approximately 1.4 —beyond which it cannot be supported by electron degeneracy pressure. A carbon-oxygen white dwarf that approaches this mass limit, typically by mass transfer from a companion star, may explode as a type Ia supernova via a process known as carbon detonation. (SN 1006 is thought to be a famous example.)
A white dwarf is very hot when it forms, but because it has no source of energy, it will gradually radiate its energy and cool. This means that its radiation, which initially has a high color temperature, will lessen and redden with time. Over a very long time, a white dwarf will cool to temperatures at which it will no longer emit significant heat or light, and it will become a cold "black dwarf". The length of time it takes for a white dwarf to reach this state is calculated to be longer than the current age of the universe (approximately 13.8 billion years), and it is thought that no black dwarfs yet exist. The oldest white dwarfs still radiate at temperatures of a few thousand kelvin.
Discovery.
The first white dwarf discovered was in the triple star system of 40 Eridani, which contains the relatively bright main sequence star 40 Eridani A, orbited at a distance by the closer binary system of the white dwarf 40 Eridani B and the main sequence red dwarf 40 Eridani C. The pair 40 Eridani B/C was discovered by William Herschel on 31 January 1783;, p. 73 it was again observed by Friedrich Georg Wilhelm Struve in 1825 and by Otto Wilhelm von Struve in 1851. In 1910, Henry Norris Russell, Edward Charles Pickering and Williamina Fleming discovered that, despite being a dim star, 40 Eridani B was of spectral type A, or white. In 1939, Russell looked back on the discovery:, p. 1
I was visiting my friend and generous benefactor, Prof. Edward C. Pickering. With characteristic kindness, he had volunteered to have the spectra observed for all the stars—including comparison stars—which had been observed in the observations for stellar parallax which Hinks and I made at Cambridge, and I discussed. This piece of apparently routine work proved very fruitful—it led to the discovery that all the stars of very faint absolute magnitude were of spectral class M. In conversation on this subject (as I recall it), I asked Pickering about certain other faint stars, not on my list, mentioning in particular 40 Eridani B. Characteristically, he sent a note to the Observatory office and before long the answer came (I think from Mrs Fleming) that the spectrum of this star was A. I knew enough about it, even in these paleozoic days, to realize at once that there was an extreme inconsistency between what we would then have called "possible" values of the surface brightness and density. I must have shown that I was not only puzzled but crestfallen, at this exception to what looked like a very pretty rule of stellar characteristics; but Pickering smiled upon me, and said: "It is just these exceptions that lead to an advance in our knowledge", and so the white dwarfs entered the realm of study!
The spectral type of 40 Eridani B was officially described in 1914 by Walter Adams.
The white dwarf companion of Sirius, Sirius B, was next to be discovered. During the nineteenth century, positional measurements of some stars became precise enough to measure small changes in their location. Friedrich Bessel used position measurements to determine that the stars Sirius (α Canis Majoris) and Procyon (α Canis Minoris) were changing their positions periodically. In 1844 he predicted that both stars had unseen companions:
If we were to regard "Sirius" and "Procyon" as double stars, the change of their motions would not surprise us; we should acknowledge them as necessary, and have only to investigate their amount by observation. But light is no real property of mass. The existence of numberless visible stars can prove nothing against the existence of numberless invisible ones.
Bessel roughly estimated the period of the companion of Sirius to be about half a century; C. A. F. Peters computed an orbit for it in 1851. It was not until 31 January 1862 that Alvan Graham Clark observed a previously unseen star close to Sirius, later identified as the predicted companion. Walter Adams announced in 1915 that he had found the spectrum of Sirius B to be similar to that of Sirius.
In 1917, Adriaan van Maanen discovered Van Maanen's Star, an isolated white dwarf. These three white dwarfs, the first discovered, are the so-called "classical white dwarfs"., p. 2 Eventually, many faint white stars were found which had high proper motion, indicating that they could be suspected to be low-luminosity stars close to the Earth, and hence white dwarfs. Willem Luyten appears to have been the first to use the term "white dwarf" when he examined this class of stars in 1922; the term was later popularized by Arthur Stanley Eddington. Despite these suspicions, the first non-classical white dwarf was not definitely identified until the 1930s. 18 white dwarfs had been discovered by 1939., p. 3 Luyten and others continued to search for white dwarfs in the 1940s. By 1950, over a hundred were known, and by 1999, over 2,000 were known. Since then the Sloan Digital Sky Survey has found over 9,000 white dwarfs, mostly new.
Composition and structure.
Although white dwarfs are known with estimated masses as low as 0.17 and as high as 1.33 , the mass distribution is strongly peaked at 0.6 , and the majority lie between 0.5 to 0.7 . The estimated radii of observed white dwarfs are typically 0.8–2 % the radius of the Sun; this is comparable to the Earth's radius of approximately 0.9% solar radius. A white dwarf, then, packs mass comparable to the Sun's into a volume that is typically a million times smaller than the Sun's; the average density of matter in a white dwarf must therefore be, very roughly, 1,000,000 times greater than the average density of the Sun, or approximately 106 g/cm3, or 1 tonne per cubic centimetre. A typical white dwarf has a density of between 10 7 and 1011 kg per cubic meter. White dwarfs are composed of one of the densest forms of matter known, surpassed only by other compact stars such as neutron stars, black holes and, hypothetically, quark stars.
White dwarfs were found to be extremely dense soon after their discovery. If a star is in a binary system, as is the case for Sirius B or 40 Eridani B, it is possible to estimate its mass from observations of the binary orbit. This was done for Sirius B by 1910, yielding a mass estimate of 0.94 . (A more modern estimate is 1.00 .) Since hotter bodies radiate more energy than colder ones, a star's surface brightness can be estimated from its effective surface temperature, and that from its spectrum. If the star's distance is known, its absolute (overall) luminosity can also be estimated. From the absolute luminosity and distance, the star's surface area and its radius can be calculated. Reasoning of this sort led to the realization, puzzling to astronomers at the time, that Sirius B and 40 Eridani B must be very dense. When Ernst Öpik estimated the density of a number of visual binary stars in 1916, he found that 40 Eridani B had a density of over 25,000 times the Sun's, which was so high that he called it "impossible". As Arthur Stanley Eddington put it later in 1927:, p. 50
We learn about the stars by receiving and interpreting the messages which their light brings to us. The message of the Companion of Sirius when it was decoded ran: "I am composed of material 3,000 times denser than anything you have ever come across; a ton of my material would be a little nugget that you could put in a matchbox." What reply can one make to such a message? The reply which most of us made in 1914 was—"Shut up. Don't talk nonsense."
As Eddington pointed out in 1924, densities of this order implied that, according to the theory of general relativity, the light from Sirius B should be gravitationally redshifted. This was confirmed when Adams measured this redshift in 1925.
Such densities are possible because white dwarf material is not composed of atoms joined by chemical bonds, but rather consists of a plasma of unbound nuclei and electrons. There is therefore no obstacle to placing nuclei closer than normally allowed by electron orbitals limited by normal matter. Eddington wondered what would happen when this plasma cooled and the energy to keep the atoms ionized was no longer sufficient. This paradox was resolved by R. H. Fowler in 1926 by an application of the newly devised quantum mechanics. Since electrons obey the Pauli exclusion principle, no two electrons can occupy the same state, and they must obey Fermi–Dirac statistics, also introduced in 1926 to determine the statistical distribution of particles which satisfy the Pauli exclusion principle. At zero temperature, therefore, electrons can not all occupy the lowest-energy, or "ground", state; some of them would have to occupy higher-energy states, forming a band of lowest-available energy states, the "Fermi sea". This state of the electrons, called "degenerate", meant that a white dwarf could cool to zero temperature and still possess high energy.
Compression of a white dwarf will increase the number of electrons in a given volume. Applying the Pauli exclusion principle, this will increase the kinetic energy of the electrons, thereby increasing the pressure. This "electron degeneracy pressure" supports a white dwarf against gravitational collapse. The pressure depends only on density and not on temperature. Degenerate matter is relatively compressible; this means that the density of a high-mass white dwarf is much greater than that of a low-mass white dwarf and that the radius of a white dwarf decreases as its mass increases.
The existence of a limiting mass that no white dwarf can exceed (beyond which it becomes a neutron star) is another consequence of being supported by electron degeneracy pressure. These masses were first published in 1929 by Wilhelm Anderson and in 1930 by Edmund C. Stoner. The modern value of the limit was first published in 1931 by Subrahmanyan Chandrasekhar in his paper "The Maximum Mass of Ideal White Dwarfs". For a non-rotating white dwarf, it is equal to approximately , where is the average molecular weight per electron of the star., eq. (63) As the carbon-12 and oxygen-16 which predominantly compose a carbon-oxygen white dwarf both have atomic number equal to half their atomic weight, one should take equal to 2 for such a star, leading to the commonly quoted value of 1.4 . (Near the beginning of the 20th century, there was reason to believe that stars were composed chiefly of heavy elements, p. 955 so, in his 1931 paper, Chandrasekhar set the average molecular weight per electron, , equal to 2.5, giving a limit of 0.91 .) Together with William Alfred Fowler, Chandrasekhar received the Nobel prize for this and other work in 1983. The limiting mass is now called the "Chandrasekhar limit".
If a white dwarf were to exceed the Chandrasekhar limit, and nuclear reactions did not take place, the pressure exerted by electrons would no longer be able to balance the force of gravity, and it would collapse into a denser object called a neutron star. Carbon-oxygen white dwarfs accreting mass from a neighboring star undergo a runaway nuclear fusion reaction, which leads to a Type Ia supernova explosion in which the white dwarf may be destroyed, before it reaches the limiting mass.
New research indicates that many white dwarfs—at least in certain types of galaxies—may not approach that limit by way of accretion. It has been postulated that at least some of the white dwarfs that become supernovae attain the necessary mass by colliding with one another. It may be that in elliptical galaxies such collisions are the major source of supernovae. This hypothesis is based on the fact that the X-rays produced by those galaxies are 30 to 50 times less than what is expected to be produced by type Ia supernovas of that galaxy as matter accretes on the white dwarf from its encircling companion. It has been concluded that no more than 5 percent of the supernovae in such galaxies could be created by the process of accretion onto white dwarfs. The significance of this finding is that there could be two types of supernovae, which could mean that the Chandrasekhar limit might not always apply in determining when a white dwarf goes supernova, given that two colliding white dwarfs could have a range of masses. This in turn would confuse efforts to use exploding white dwarfs as standard candles in determining distances.
White dwarfs have low luminosity and therefore occupy a strip at the bottom of the Hertzsprung–Russell diagram, a graph of stellar luminosity versus color (or temperature). They should not be confused with low-luminosity objects at the low-mass end of the main sequence, such as the hydrogen-fusing red dwarfs, whose cores are supported in part by thermal pressure, or the even lower-temperature brown dwarfs.
Mass–radius relationship and mass limit.
The relationship between the mass and radii of white dwarfs can be derived using an energy minimization argument . The energy of the white dwarf can be approximated by taking it to be the sum of its gravitational potential energy and kinetic energy. The gravitational potential energy of a unit mass piece of white dwarf, , will be on the order of , where is the gravitational constant, "M" is the mass of the white dwarf, and is its radius.
The kinetic energy of the unit mass, , will primarily come from the motion of electrons, so it will be approximately , where is the average electron momentum, is the electron mass, and is the number of electrons per unit mass. Since the electrons are degenerate, we can estimate to be on the order of the uncertainty in momentum, , given by the uncertainty principle, which says that is on the order of the reduced Planck constant, "ħ". will be on the order of the average distance between electrons, which will be approximately , i.e., the reciprocal of the cube root of the number density, , of electrons per unit volume. Since there are electrons in the white dwarf, where is the star's mass and its volume is on the order of , will be on the order of .
Solving for the kinetic energy per unit mass, "E"k, we find that
The white dwarf will be at equilibrium when its total energy, , is minimized. At this point, the kinetic and gravitational potential energies should be comparable, so we may derive a rough mass-radius relationship by equating their magnitudes:
Solving this for the radius, , gives
Dropping , which depends only on the composition of the white dwarf, and the universal constants leaves us with a relationship between mass and radius:
"i.e.", the radius of a white dwarf is inversely proportional to the cube root of its mass.
Since this analysis uses the non-relativistic formula for the kinetic energy, it is non-relativistic. If we wish to analyze the situation where the electron velocity in a white dwarf is close to the speed of light, , we should replace by the extreme relativistic approximation for the kinetic energy. With this substitution, we find
If we equate this to the magnitude of , we find that drops out and the mass, , is forced to be
To interpret this result, observe that as we add mass to a white dwarf, its radius will decrease, so, by the uncertainty principle, the momentum, and hence the velocity, of its electrons will increase. As this velocity approaches , the extreme relativistic analysis becomes more exact, meaning that the mass  of the white dwarf must approach a limiting mass of . Therefore, no white dwarf can be heavier than the limiting mass , or 1.4 .
For a more accurate computation of the mass-radius relationship and limiting mass of a white dwarf, one must compute the equation of state which describes the relationship between density and pressure in the white dwarf material. If the density and pressure are both set equal to functions of the radius from the center of the star, the system of equations consisting of the hydrostatic equation together with the equation of state can then be solved to find the structure of the white dwarf at equilibrium. In the non-relativistic case, we will still find that the radius is inversely proportional to the cube root of the mass., eq. (80) Relativistic corrections will alter the result so that the radius becomes zero at a finite value of the mass. This is the limiting value of the mass—called the "Chandrasekhar limit"—at which the white dwarf can no longer be supported by electron degeneracy pressure. The graph on the right shows the result of such a computation. It shows how radius varies with mass for non-relativistic (blue curve) and relativistic (green curve) models of a white dwarf. Both models treat the white dwarf as a cold Fermi gas in hydrostatic equilibrium. The average molecular weight per electron, , has been set equal to 2. Radius is measured in standard solar radii and mass in standard solar masses.
These computations all assume that the white dwarf is non-rotating. If the white dwarf is rotating, the equation of hydrostatic equilibrium must be modified to take into account the centrifugal pseudo-force arising from working in a rotating frame. For a uniformly rotating white dwarf, the limiting mass increases only slightly. If the star is allowed to rotate nonuniformly, and viscosity is neglected, then, as was pointed out by Fred Hoyle in 1947, there is no limit to the mass for which it is possible for a model white dwarf to be in static equilibrium. Not all of these model stars will be dynamically stable.
Radiation and cooling.
The degenerate matter that makes up the bulk of a white dwarf has a very low opacity, because any absorption of a photon requires that an electron must transition to a higher empty state, which may not be possible as the energy of the photon may not be a match for the possible quantum states available to that electron, hence radiative heat transfer within a white dwarf is low; it does, however, have a high thermal conductivity. As a result, the interior of the white dwarf maintains a uniform temperature, approximately 107 K. An outer shell of non-degenerate matter cools from approximately 107 K to 104 K. This matter radiates roughly as a black body. A white dwarf remains visible for a long time, as its tenuous outer atmosphere of normal matter begins to radiate at about 107 K, upon formation, while its greater interior mass is at 107  K but cannot radiate through its normal matter shell.
The visible radiation emitted by white dwarfs varies over a wide color range, from the blue-white color of an O-type main sequence star to the red of an M-type red dwarf. White dwarf effective surface temperatures extend from over 150,000 K to barely under 4,000 K. In accordance with the Stefan–Boltzmann law, luminosity increases with increasing surface temperature; this surface temperature range corresponds to a luminosity from over 100 times the Sun's to under 1/10,000 that of the Sun's. Hot white dwarfs, with surface temperatures in excess of 30,000 K, have been observed to be sources of soft (i.e., lower-energy) X-rays. This enables the composition and structure of their atmospheres to be studied by soft X-ray and extreme ultraviolet observations.
As was explained by Leon Mestel in 1952, unless the white dwarf accretes matter from a companion star or other source, its radiation comes from its stored heat, which is not replenished., §2.1. White dwarfs have an extremely small surface area to radiate this heat from, so they cool gradually, remaining hot for a long time. As a white dwarf cools, its surface temperature decreases, the radiation which it emits reddens, and its luminosity decreases. Since the white dwarf has no energy sink other than radiation, it follows that its cooling slows with time. The rate of cooling has been estimated for a carbon white dwarf of 0.59 with a hydrogen atmosphere. After initially taking approximately 1.5 billion years to cool to a surface temperature of 7,140 K, cooling approximately 500 more kelvins to 6,590 K takes around 0.3 billion years, but the next two steps of around 500 kelvins (to 6,030 K and 5,550 K) take first 0.4 and then 1.1 billion years., Table 2.
Most observed white dwarfs have relatively high surface temperatures, between 8,000 K and 40,000 K. A white dwarf, though, spends more of its lifetime at cooler temperatures than at hotter temperatures, so we should expect that there are more cool white dwarfs than hot white dwarfs. Once we adjust for the selection effect that hotter, more luminous white dwarfs are easier to observe, we do find that decreasing the temperature range examined results in finding more white dwarfs. This trend stops when we reach extremely cool white dwarfs; few white dwarfs are observed with surface temperatures below 4,000 K, and one of the coolest so far observed, WD 0346+246, has a surface temperature of approximately 3,900 K. The reason for this is that the Universe's age is finite, there has not been enough time for white dwarfs to cool below this temperature. The white dwarf luminosity function can therefore be used to find the time when stars started to form in a region; an estimate for the age of our Galactic disk found in this way is 8 billion years. A white dwarf will eventually, in many trillion years, cool and become a non-radiating "black dwarf" in approximate thermal equilibrium with its surroundings and with the cosmic background radiation. No black dwarfs are thought to exist yet.
Although white dwarf material is initially plasma—a fluid composed of nuclei and electrons—it was theoretically predicted in the 1960s that at a late stage of cooling, it should crystallize, starting at its center. The crystal structure is thought to be a body-centered cubic lattice. In 1995 it was suggested that asteroseismological observations of pulsating white dwarfs yielded a potential test of the crystallization theory, and in 2004, observations were made that suggested approximately 90% of the mass of BPM 37093 had crystallized. Other work gives a crystallized mass fraction of between 32% and 82%. As a white dwarf core undergoes crystallization into a solid phase, latent heat is released which provides a source of thermal energy that delays its cooling.
Low-mass helium white dwarfs (with a mass < 0.20 , often referred to as "extremely low-mass white dwarfs, ELM WDs") are formed in binary systems. As a result of their hydrogen-rich envelopes, residual hydrogen burning via the CNO cycle may keep these white dwarfs hot on a long timescale. In addition, they remain in a bloated proto-white dwarf stage for up to 2 Gyr before they reach the cooling track.
Atmosphere and spectra.
Although most white dwarfs are thought to be composed of carbon and oxygen, spectroscopy typically shows that their emitted light comes from an atmosphere which is observed to be either hydrogen or helium dominated. The dominant element is usually at least 1,000 times more abundant than all other elements. As explained by Schatzman in the 1940s, the high surface gravity is thought to cause this purity by gravitationally separating the atmosphere so that heavy elements are below and the lighter above., §5–6 This atmosphere, the only part of the white dwarf visible to us, is thought to be the top of an envelope which is a residue of the star's envelope in the AGB phase and may also contain material accreted from the interstellar medium. The envelope is believed to consist of a helium-rich layer with mass no more than 1/100 of the star's total mass, which, if the atmosphere is hydrogen-dominated, is overlain by a hydrogen-rich layer with mass approximately 1/10,000 of the stars total mass., §4–5.
Although thin, these outer layers determine the thermal evolution of the white dwarf. The degenerate electrons in the bulk of a white dwarf conduct heat well. Most of a white dwarf's mass is therefore at almost the same temperature (isothermal), and it is also hot: a white dwarf with surface temperature between 8,000 K and 16,000 K will have a core temperature between approximately 5,000,000 K and 20,000,000 K. The white dwarf is kept from cooling very quickly only by its outer layers' opacity to radiation.
The first attempt to classify white dwarf spectra appears to have been by G. P. Kuiper in 1941, and various classification schemes have been proposed and used since then. The system currently in use was introduced by Edward M. Sion, Jesse L. Greenstein and their coauthors in 1983 and has been subsequently revised several times. It classifies a spectrum by a symbol which consists of an initial D, a letter describing the primary feature of the spectrum followed by an optional sequence of letters describing secondary features of the spectrum (as shown in the table to the right), and a temperature index number, computed by dividing 50,400 K by the effective temperature. For example:
The symbols ? and : may also be used if the correct classification is uncertain.
White dwarfs whose primary spectral classification is DA have hydrogen-dominated atmospheres. They make up the majority (approximately 80%) of all observed white dwarfs. The next class in number is of DBs (approximately 16%). The hot (above 15,000 K) DQ class (roughly 0.1%) have carbon-dominated atmospheres. Those classified as DB, DC, DO, DZ, and cool DQ have helium-dominated atmospheres. Assuming that carbon and metals are not present, which spectral classification is seen depends on the effective temperature. Between approximately 100,000 K to 45,000 K, the spectrum will be classified DO, dominated by singly ionized helium. From 30,000 K to 12,000 K, the spectrum will be DB, showing neutral helium lines, and below about 12,000 K, the spectrum will be featureless and classified DC.,§ 2.4.
Molecular hydrogen (H2) has been detected in spectra of the atmospheres of some white dwarfs.
Metal-Rich White Dwarfs.
Around 25-33% of white dwarfs have metal lines in their spectra, which is unusual because any heavy elements in a white dwarf should sink into the star's interior in just a small fraction of the star's lifetime. The prevailing explanation for metal-rich white dwarfs is that they have recently accreted rocky planetesimals. The bulk composition of the accreted object can be measured from the strengths of the metal lines. For example, a 2015 study of the white dwarf Ton 345 concluded that its metal abundances were consistent with those of a differentiated, rocky planet whose mantle had been eroded by the host star's wind during its asymptotic giant branch phase.
Magnetic field.
Magnetic fields in white dwarfs with a strength at the surface of ~1 million gauss (100 teslas) were predicted by P. M. S. Blackett in 1947 as a consequence of a physical law he had proposed which stated that an uncharged, rotating body should generate a magnetic field proportional to its angular momentum. This putative law, sometimes called the "Blackett effect", was never generally accepted, and by the 1950s even Blackett felt it had been refuted., pp. 39–43 In the 1960s, it was proposed that white dwarfs might have magnetic fields due to conservation of total surface magnetic flux that existed in its progenitor star phase. A surface magnetic field of ~100 gauss (0.01 T) in the progenitor star would thus become a surface magnetic field of ~100·1002 = 1 million gauss (100 T) once the star's radius had shrunk by a factor of 100., §8;, p. 484 The first magnetic white dwarf to be observed was GJ 742, which was detected to have a magnetic field in 1970 by its emission of circularly polarized light. It is thought to have a surface field of approximately 300 million gauss (30 kT)., §8 Since then magnetic fields have been discovered in well over 100 white dwarfs, ranging from to 109 gauss (0.2 T to 100 kT). Only a small number of white dwarfs have been examined for fields, and it has been estimated that at least 10% of white dwarfs have fields in excess of 1 million gauss (100 T).
Chemical bonds.
The magnetic fields in a white dwarf may allow for the existence of a new type of chemical bond, perpendicular paramagnetic bonding, in addition to ionic and covalent bonds, resulting in what has been initially described as "magnetized matter" in research published in 2012.
Variability.
Early calculations suggested that there might be white dwarfs whose luminosity varied with a period of around 10 seconds, but searches in the 1960s failed to observe this., § 7.1.1; The first variable white dwarf found was HL Tau 76; in 1965 and 1966, and was observed to vary with a period of approximately 12.5 minutes. The reason for this period being longer than predicted is that the variability of HL Tau 76, like that of the other pulsating variable white dwarfs known, arises from non-radial gravity wave pulsations., § 7. Known types of pulsating white dwarf include the "DAV", or "ZZ Ceti", stars, including HL Tau 76, with hydrogen-dominated atmospheres and the spectral type DA;, pp. 891, 895 "DBV", or "V777 Her", stars, with helium-dominated atmospheres and the spectral type DB;, p. 3525 and "GW Vir stars" (sometimes subdivided into "DOV" and "PNNV" stars), with atmospheres dominated by helium, carbon, and oxygen. GW Vir stars are not, strictly speaking, white dwarfs, but are stars which are in a position on the Hertzsprung-Russell diagram between the asymptotic giant branch and the white dwarf region. They may be called "pre-white dwarfs". These variables all exhibit small (1%–30%) variations in light output, arising from a superposition of vibrational modes with periods of hundreds to thousands of seconds. Observation of these variations gives asteroseismological evidence about the interiors of white dwarfs.
Formation.
White dwarfs are thought to represent the end point of stellar evolution for main-sequence stars with masses from about 0.07 to 10 . The composition of the white dwarf produced will depend on the initial mass of the star.
Stars with very low mass.
If the mass of a main-sequence star is lower than approximately half a solar mass, it will never become hot enough to fuse helium in its core. It is thought that, over a lifespan that considerably exceeds the age of the Universe (~13.8 billion years), such a star will eventually burn all its hydrogen and end its evolution as a helium white dwarf composed chiefly of helium-4 nuclei. Due to the very long time this process takes, it is not thought to be the origin of the observed helium white dwarfs. Rather, they are thought to be the product of mass loss in binary systems or mass loss due to a large planetary companion.
Stars with low to medium mass.
If the mass of a main-sequence star is between 0.5 to 8 , its core will become sufficiently hot to fuse helium into carbon and oxygen via the triple-alpha process, but it will never become sufficiently hot to fuse carbon into neon. Near the end of the period in which it undergoes fusion reactions, such a star will have a carbon-oxygen core which does not undergo fusion reactions, surrounded by an inner helium-burning shell and an outer hydrogen-burning shell. On the Hertzsprung-Russell diagram, it will be found on the asymptotic giant branch. It will then expel most of its outer material, creating a planetary nebula, until only the carbon-oxygen core is left. This process is responsible for the carbon-oxygen white dwarfs which form the vast majority of observed white dwarfs.
Stars with medium to high mass.
If a star is massive enough, its core will eventually become sufficiently hot to fuse carbon to neon, and then to fuse neon to iron. Such a star will not become a white dwarf, because the mass of its central, non-fusing core, initially supported by electron degeneracy pressure, will eventually exceed the largest possible mass supportable by degeneracy pressure. At this point the core of the star will collapse and it will explode in a core-collapse supernova which will leave behind a remnant neutron star, black hole, or possibly a more exotic form of compact star. Some main-sequence stars, of perhaps 8 to 10 , although sufficiently massive to fuse carbon to neon and magnesium, may be insufficiently massive to fuse neon. Such a star may leave a remnant white dwarf composed chiefly of oxygen, neon, and magnesium, provided that its core does not collapse, and provided that fusion does not proceed so violently as to blow apart the star in a supernova Although a few white dwarfs have been identified which may be of this type, most evidence for the existence of such comes from the novae called "ONeMg" or "neon" novae. The spectra of these novae exhibit abundances of neon, magnesium, and other intermediate-mass elements which appear to be only explicable by the accretion of material onto an oxygen-neon-magnesium white dwarf.
Type Ia supernovae.
Type Ia supernovae, that involve one or two previous white dwarfs, have been proposed to be a channel for transformation of this type of stellar remnant. In this scenario, the carbon detonation produced in a Type Ia supernova is too weak to destroy the white dwarf, expelling just a small part of its mass as ejecta, but produces an asymmetric explosion that kicks the star to high speeds of a Hypervelocity star. The matter processed in the failed detonation is re-accreted by the white dwarf with the heaviest elements such as iron falling to its core where it accumulates.
These "iron-core" white dwarfs would be smaller than their carbon-oxygen kind of similar mass and would cool and crystallize faster than those.
Fate.
A white dwarf is stable once formed and will continue to cool almost indefinitely, eventually to become a black dwarf. Assuming that the Universe continues to expand, it is thought that in 1019 to 1020 years, the galaxies will evaporate as their stars escape into intergalactic space., §IIIA. White dwarfs should generally survive galactic dispersion, although an occasional collision between white dwarfs may produce a new fusing star or a super-Chandrasekhar mass white dwarf which will explode in a Type Ia supernova., §IIIC, IV. The subsequent lifetime of white dwarfs is thought to be on the order of the lifetime of the proton, known to be at least 1032 years. Some simple grand unified theories predict a proton lifetime of no more than 1049 years. If these theories are not valid, the proton may decay by more complicated nuclear processes, or by quantum gravitational processes involving a virtual black hole; in these cases, the lifetime is estimated to be no more than 10200 years. If protons do decay, the mass of a white dwarf will decrease very slowly with time as its nuclei decay, until it loses enough mass to become a nondegenerate lump of matter, and finally disappears completely., §IV.
A white dwarf can also be cannibalized or evaporated by a companion star, causing the white dwarf to lose so much mass that it becomes a planetary mass object. The resultant object, orbiting the former companion, now host star, could be a helium planet or diamond planet.
Debris disks and planets.
A white dwarf's stellar and planetary system is inherited from its progenitor star and may interact with the white dwarf in various ways. Infrared spectroscopic observations made by NASA's Spitzer Space Telescope of the central star of the Helix Nebula suggest the presence of a dust cloud, which may be caused by cometary collisions. It is possible that infalling material from this may cause X-ray emission from the central star. Similarly, observations made in 2004 indicated the presence of a dust cloud around the young white dwarf G29-38 (estimated to have formed from its AGB progenitor about 500 million years ago), which may have been created by tidal disruption of a comet passing close to the white dwarf. Some estimations based on the metal content of the atmospheres of the white dwarfs consider that at least a 15% of them may be orbited by planets and/or asteroids, or at least their debris. Another suggested idea is that white dwarfs could be orbited by the stripped cores of rocky planets, that would have survived the red giant phase of their star but losing their outer layers and, given those planetary remnants would likely be made of metals, to attempt to detect them looking for the signatures of their interaction with the white dwarf's magnetic field.
There is a planet in the white dwarf–pulsar binary system PSR B1620-26.
There are two circumbinary planets around the white dwarf–red dwarf binary NN Serpentis.
The metal-rich white dwarf WD 1145+017 is the first white dwarf observed with a disintegrating minor planet which transits the star. The disintegration of the planetesimal generates a debris cloud which passes in front of the star every 4.5 hours, causing a 5-minute-long fade in the star's optical brightness. The depth of the transit is highly variable.
Habitability.
It has been proposed that white dwarfs with surface temperatures of less than 10,000 Kelvin could harbor a habitable zone at a distance between ~0.005 to 0.02 AU that would last upwards of 3 billion years. The goal is to search for transits of hypothetical Earth-like planets that could have migrated inward and/or formed there. As a white dwarf has a size similar to that of a planet, these kinds of transits would produce strong eclipses. Newer research casts some doubts on this idea, given that the close orbits of those hypothetical planets around their parent stars would subject them to strong tidal forces that could render them unhabitable by triggering a greenhouse effect. Another suggested constraint to this idea is the origin of those planets. Leaving aside in-situ formation on an accretion disk surrounding the white dwarf, there are two ways a planet could end in a close orbit around stars of this kind: by surviving being engulfed by the star during its red giant phase, and then spiraling towards its core, or inward migration after the white dwarf has formed. The former case is implausible for low-mass bodies, as they are unlikely to survive being absorbed by their stars. In the latter case, the planets would have to expel so much orbital energy as heat, through tidal interactions with the white dwarf, that they would likely end as uninhabitable embers.
Binary stars and novae.
If a white dwarf is in a binary star system and is accreting matter from its companion, a variety of phenomena may occur, including novae and Type Ia supernovae. It may also be a super-soft x-ray source if it is able to take material from its companion fast enough to sustain fusion on its surface. A close binary system of two white dwarfs can radiate energy in the form of gravitational waves, causing their mutual orbit to steadily shrink until the stars merge.
Type Ia supernovae.
The mass of an isolated, nonrotating white dwarf cannot exceed the Chandrasekhar limit of ~1.4 . (This limit may increase if the white dwarf is rotating rapidly and nonuniformly.) White dwarfs in binary systems can accrete material from a companion star, increasing both their mass and their density. As their mass approaches the Chandrasekhar limit, this could theoretically lead to either the explosive ignition of fusion in the white dwarf or its collapse into a neutron star.
Accretion provides the currently favored mechanism called the "single-degenerate model" for Type Ia supernovae. In this model, a carbon–oxygen white dwarf accretes mass and compresses its core by pulling mass from a companion star., p. 14. It is believed that compressional heating of the core leads to ignition of carbon fusion as the mass approaches the Chandrasekhar limit. Because the white dwarf is supported against gravity by quantum degeneracy pressure instead of by thermal pressure, adding heat to the star's interior increases its temperature but not its pressure, so the white dwarf does not expand and cool in response. Rather, the increased temperature accelerates the rate of the fusion reaction, in a runaway process that feeds on itself. The thermonuclear flame consumes much of the white dwarf in a few seconds, causing a Type Ia supernova explosion that obliterates the star. In another possible mechanism for Type Ia supernovae, the "double-degenerate model", two carbon-oxygen white dwarfs in a binary system merge, creating an object with mass greater than the Chandrasekhar limit in which carbon fusion is then ignited., p. 14.
Observations have failed to note signs of accretion leading up to Type Ia supernovae, and this is now thought to be because the star is first loaded up to above the Chandrasekhar limit while also being spun up to a very high rate by the same process. Once the accretion stops the star gradually slows until the spin is no longer enough to prevent the explosion.
Cataclysmic variables.
Before accretion of material pushes a white dwarf close to the Chandrasekhar limit, accreted hydrogen-rich material on the surface may ignite in a less destructive type of thermonuclear explosion powered by hydrogen fusion. These surface explosions can be repeated as long as the white dwarf's core remains intact. This weaker kind of repetitive cataclysmic phenomenon is called a (classical) nova. Astronomers have also observed dwarf novae, which have smaller, more frequent luminosity peaks than the classical novae. These are thought to be caused by the release of gravitational potential energy when part of the accretion disc collapses onto the star, rather than through a release of energy due to fusion. In general, binary systems with a white dwarf accreting matter from a stellar companion are called cataclysmic variables. As well as novae and dwarf novae, several other classes of these variables are known, including polars and intermediate polars, both of which feature highly magnetic white dwarfs. Both fusion- and accretion-powered cataclysmic variables have been observed to be X-ray sources.

</doc>
<doc id="33507" url="https://en.wikipedia.org/wiki?curid=33507" title="Wabash College">
Wabash College

Wabash College is a small, private, liberal arts college for men, located in Crawfordsville, Indiana, United States. Founded in 1832 by several Dartmouth College graduates and Midwestern leaders, Wabash is ranked in the top tier of national liberal arts colleges by "U.S. News & World Report". The trustees have consistently rejected calls to institute coeducation, leaving Wabash one of the country's three remaining male-only liberal arts colleges.
History.
The college was initially named "The Wabash Teachers Seminary and Manual Labor College", a name shortened to its current form by 1851. Many of the founders were Presbyterian ministers, yet nevertheless believed that Wabash should be independent and non-sectarian. Patterning it after the liberal arts colleges of New England, they resolved "that the institution be at first a classical and English high school, rising into a college as soon as the wants of the country demand."
Elihu Baldwin, the first president of the college, served from 1835 until 1840. He came from a church in New York City and accepted the presidency even though he knew that Wabash was at that time threatened with bankruptcy. After his death, he was succeeded by Charles White, a graduate of Dartmouth College and the brother-in-law of Edmund O. Hovey, a professor at the college.
Joseph F. Tuttle, who became president of Wabash College in 1862 and served for 30 years, worked with his administrators to improve town-gown relations in Crawfordsville. Gronert described him "an eloquent preacher, a sound administrator and an astute handler of public relations." He is the namesake of Tuttle Grade School in Crawfordsville (1906) and Tuttle Junior High School, now Tuttle Middle School (1960).
Gregory D. Hess became the 16th President of Wabash College July 1, 2013. Prior to coming to Wabash, Dr. Hess had been Dean of the Faculty and Vice President of Academic Affairs at Claremont McKenna College at Claremont, California.
During World War II, Wabash College was one of 131 colleges and universities offered students a path to a Navy commission as part of the V-12 Navy College Training Program.
In the early 1900s, the College closed its "Preparatory School", which prepared incoming students from less-rigorous rural high schools that lacked the courses required for entrance to the College.
In 1996, Wabash became the first college in America to stage Tony Kushner's "Angels in America".
Academics.
Curriculum.
Wabash College's curriculum is divided into three: Division I, Division II, and Division III representing the natural sciences, humanities and arts, and social sciences respectively. Wabash offers 22 major programs and several additional minors.
Comprehensive Exams.
Seniors at Wabash College take a comprehensive exam in their major subject. Over three days, there are two days of written exams and one day of oral exams. The two days of written exams differ by major, but the oral exams are relatively uniform. A senior meets with three professors, one from his major, another from his minor and a third professor who represents the rest of his academic career, and can be from any discipline. Over the course of an hour a senior answers questions from the professors which can relate to anything during his studies at Wabash. A senior must pass the examinations in order to be eligible for a degree.
Student life.
Student culture and traditions.
Rhyneship was a freshman orientation program that took first semester freshmen, "rhynes" and acculturated them to Wabash. While some aspects of rhyneship were less visible, the most visible was the wearing of the "rhynie pot", a green hat with a red bill. When approaching a member of the faculty or Senior Council, the freshman would dip his pot as a sign of respect. This tradition is carried on by the pledges of the Phi Delta Theta Fraternity. Rhyneship is continued through the Sphinx Club, a secret society made up of campus leaders, which aims to unite the campus, honor traditions, and create an atmosphere of support and prestige. Sphinx Club members don white "pots" to distinguish themselves on campus.
Student government.
The student government, referred to collectively as the Student Body of Wabash College, comprises executive and legislative branches. The executive authority of the student body is vested in a president and vice president, who chair the Senior Council and Student Senate, respectively. They are "ex officio", non-voting members of the body that they do not chair. The president has broad powers of appointment over all Senate standing committees. The vice-president possesses a tie-breaking vote in the Student Senate.
The Student Senate of Wabash College is the legislative authority, consisting of senators from each residence hall and fraternity, four representatives from each of the three underclasses, and the chairmen of the Senate's standing committees. The body of approximately 32 voting members manages an annual budget of over $400,000, allocating funds and setting guidelines for recognized associations. The Senate also serves as a general student forum.
The Senior Council of Wabash College is a special quasi-legislative body comprising the presidents of certain student organizations and self-selected at-large councilmen. The Senior Council is responsible for representing student concerns to the faculty and administration, as well as fostering campus unity and maintaining proper regard for college traditions.
The Inter-Fraternity Council (IFC) is a body composed of representatives of each of the college's fraternities. It helps to organize recruitment activities, all-campus entertainment, and honors the chapters with the best Grade Point Average and Intramural Athletics record.
Student organizations.
Student organizations at Wabash receive funding and recognition from the Student Senate. This funding in turn comes from a student activities fee, which every attendee of the college must pay each semester. The student paper of Wabash College is "The Bachelor" and has been publishing since the early 1900s.
Fraternities.
The first fraternity appeared at Wabash in 1846 and has been on campus continuously since. It was quickly followed by others. Many of the traditions of the college were begun and are maintained by the fraternities, both individually and collectively. On average, 50-60% of students belong to one of the campus's nine national fraternities. Unlike most other colleges and universities, Wabash fraternity members — including pledges — live in the fraternity houses by default. While most Wabash fraternities allow juniors and seniors to live outside the house, most Greek students live in their respective house all four years. This has led to the odd circumstance of a college with fewer than 1,000 students dotted with Greek houses of a size appropriate to campuses ten times Wabash's size. The fraternity chapters range in size from about 40 to 70 members each.
The college and the fraternity system have created a somewhat symbiotic relationship that differs from most other colleges and universities. The college believes that the system largely accomplishes the task of quickly involving new students in the life of the college while also providing leadership opportunities for a larger number of students. All fraternity houses on campus, except one, are owned by the college. In 2009 the college and the fraternity's alumni associations completed a 10-year effort to rebuild or renovate the chapter houses. At the same time, the college realized that fraternity life is not right for each student. The re-building project also renovated most of the campus dormitories.
Endowment.
As of March 31, 2014, the value of Wabash's endowment was approximately $345 million, which places Wabash among the richest colleges in the nation in per-student endowment. The endowment was created primarily over the past 70 years using major campaigns and estate planning with alumni. Major donors include the pharmaceutical industrialist Eli Lilly, the company his grandfather founded, his heirs, and the Lilly Endowment. The school's library is named after him as are a number of premier scholarships. During the most recent capital campaign, "Challenge of Excellence", between fall 2010 and 1 October 2012, the college raised $68.1 million, exceeding the original goal of $60 million.
Athletics.
The basketball team at Wabash was formerly coached by legendary Malcolm "Mac" Petty, who retired after 35 seasons at Wabash. Wabash won the 1981–82 NCAA Division III title (the school's only national title) with a 24–4 record. Wabash won the first national intercollegiate championship basketball tournament ever held in 1922.
Football at Wabash dates back to 1884, when student-coach Edwin R. Taber assembled a team and defeated Butler University by a score of 4–0 in the first intercollegiate football game in the history of the state of Indiana. The current head football coach is Erik Raeburn.
In the summer of 2010, Wabash reconstructed Mud Hollow and Byron P. Hollett Stadium to provide the football, soccer, baseball and intramural teams with better athletic facilities.
Monon Bell Classic.
In 1999, "GQ" listed the Monon Bell game as reason number three on its "50 Reasons Why College Football is Better Than Pro Football" list.
Summer programs.
Wabash has a summer program for high school students: OLAB (Opportunities to Learn about Business). OLAB is a co-ed program going into its 39th year at Wabash. OLAB is a one-week hands-on introduction to business and the market economy for young women and men entering their senior year in high school. In 2010, 44 students from 11 states and Korea participated in the OLAB program.
The Innovation, Business & Entrepreneurship initiative also hosts a Summer Business Immersion program. The seven-week LABB program is an intensive summer immersion into all aspects of business and entrepreneurship. Students from all majors get a crash course in financial literacy, strategic planning, marketing, decision making, leadership, human resources and negotiations through case study analysis, lectures and site visits. Students research and write multiple business plans, which are presented to panels of expert judges. Students also work on a consulting project in the community to solve a real-world problem. Students are paid a $3,200 stipend. This is a full-time 40-hour-per-week internship.
National rankings.
Wabash has long been ranked in the top tier of national liberal arts colleges in the annual U.S. News & World Report.
According to the Princeton Review's Annual Rankings of "The Best 379 Colleges", Wabash was ranked nationally in the following categories over the last two years:
Wabash College is also listed in Loren Pope's "Colleges That Change Lives".

</doc>
<doc id="33509" url="https://en.wikipedia.org/wiki?curid=33509" title="Walking">
Walking

Walking (also known as ambulation) is one of the main gaits of locomotion among legged animals, and is typically slower than running and other gaits. Walking is defined by an 'inverted pendulum' gait in which the body vaults over the stiff limb or limbs with each step. This applies regardless of the number of limbs - even arthropods, with six, eight or more limbs, walk.
In the United Kingdom and Ireland, the term walking includes activities such as walking in a park and trekking in the Alps. However, in Canada and the United States the term for a long, vigorous walk is hiking, while the word walking covers shorter walks, especially in an urban setting.
Difference from running.
The word "walk" is descended from the Old English "wealcan" "to roll". In humans and other bipeds, walking is generally distinguished from running in that only one foot at a time leaves contact with the ground and there is a period of double-support. In contrast, running begins when both feet are off the ground with each step. This distinction has the status of a formal requirement in competitive walking events. For quadrupedal species, there are numerous gaits which may be termed walking or running, and distinctions based upon the presence or absence of a suspended phase or the number of feet in contact any time do not yield mechanically correct classification. The most effective method to distinguish walking from running is to measure the height of a person's centre of mass using motion capture or a force plate at midstance. During walking, the centre of mass reaches a maximum height at midstance, while during running, it is then at a minimum. This distinction, however, only holds true for locomotion over level or approximately level ground. For walking up grades above 9%, this distinction no longer holds for some individuals. Definitions based on the percentage of the stride during which a foot is in contact with the ground (averaged across all feet) of greater than 50% contact corresponds well with identification of 'inverted pendulum' mechanics and are indicative of walking for animals with any number of limbs, although this definition is incomplete. Running humans and animals may have contact periods greater than 50% of a gait cycle when rounding corners, running uphill or carrying loads.
Speed is another factor that distinguishes walking from running. Although walking speeds can vary greatly depending on many factors such as height, weight, age, terrain, surface, load, culture, effort, and fitness, the average human walking speed is about 5.0 kilometres per hour (km/h), or about 3.1 miles per hour (mph). Specific studies have found pedestrian walking speeds ranging from to for older individuals and from to for younger individuals; a brisk walking speed can be around . Champion racewalkers can average more than over a distance of . An average human child achieves independent walking ability at around 11 months old.
Health benefits of walking.
Regular, brisk exercise of any kind can improve confidence, stamina, energy, weight control and life expectancy and reduce stress. It can also reduce the risk of coronary heart disease, strokes, diabetes, high blood pressure, bowel cancer and osteoporosis. Scientific studies have also shown that walking, besides its physical benefits, is also beneficial for the mind, improving memory skills, learning ability, concentration and abstract reasoning, as well as ameliorating spirits. Sustained walking sessions for a minimum period of thirty to sixty minutes a day, five days a week, with the correct walking posture, reduce health risks and have various overall health benefits, such as reducing the chances of cancer, type 2 diabetes, heart disease, anxiety and depression. Life expectancy is also increased even for individuals suffering from obesity or high blood pressure. Walking also improves bone health, especially strengthening the hip bone, and lowering the harmful low-density lipoprotein (LDL) cholesterol, and raising the useful high-density lipoprotein (HDL) cholesterol. Studies have found that walking may also help prevent dementia and Alzheimer's.
The Centers for Disease Control and Prevention's fact sheet on the "Relationship of Walking to Mortality Among U.S. Adults with Diabetes" states that those with diabetes who walked for 2 or more hours a week lowered their mortality rate from all causes by 39 per cent. "Walking lengthened the life of people with diabetes regardless of age, sex, race, body mass index, length of time since diagnosis, and presence of complications or functional limitations." It has been suggested that there is a relationship between the speed of walking and health, and that the best results are obtained with a speed of more than 2.5 mph (4 km/h).
Governments now recognize the benefits of walking for mental and physical health and are actively encouraging it. This growing emphasis on walking has arisen because people walk less nowadays than previously. In the UK; a Department of Transport report found that between 1995/97 and 2005 the average number of walk trips per person fell by 16%, from 292 to 245 per year. Many professionals in local authorities and the NHS are employed to halt this decline by ensuring that the built environment allows people to walk and that there are walking opportunities available to them. Professionals working to encourage walking come mainly from six sectors: health, transport, environment, schools, sport and recreation, and urban design.
One programme to encourage walking is "The Walking the Way to Health Initiative", organized by the British walkers association The Ramblers, which is the largest volunteer led walking scheme in the United Kingdom. Volunteers are trained to lead free Health Walks from community venues such as libraries and doctors' surgeries. The scheme has trained over 35,000 volunteers and have over 500 schemes operating across the UK, with thousands of people walking every week. A new organization called "Walk England" launched a web site in June 2008 to provide these professionals with evidence, advice and examples of success stories of how to encourage communities to walk more. The site has a social networking aspect to allow professionals and the public to ask questions, post news and events and communicate with others in their area about walking, as well as a "walk now" option to find out what walks are available in each region. Similar organizations exist in other countries and recently a "Walking Summit" was held in the USA. This "assembl[ed thought-leaders and influencers from business, urban planning and real estate, with physicians and public health officials," and others, to discuss how to make American cities and communities places where "people can and want to walk".
Origins.
It is theorized that "walking" among tetrapods originated underwater with air-breathing fish that could "walk" underwater, giving rise to the plethora of land-dwelling life that walk on four or two limbs. While terrestrial tetrapods are theorised to have a single origin, arthropods and their relatives are thought to have independently evolved walking several times, specifically in insects, myriapods, chelicerates, tardigrades, onychophorans, and crustaceans.
Judging from footprints discovered on a former shore in Kenya, it is thought possible that ancestors of modern humans were walking in ways very similar to the present activity as many as 1.5 million years ago.
Biomechanics.
Human walking is accomplished with a strategy called the double pendulum. During forward motion, the leg that leaves the ground swings forward from the hip. This sweep is the first pendulum. Then the leg strikes the ground with the heel and rolls through to the toe in a motion described as an inverted pendulum. The motion of the two legs is coordinated so that one foot or the other is always in contact with the ground. The process of walking recovers approximately sixty per cent of the energy used due to pendulum dynamics and ground reaction force.
Walking differs from a running gait in a number of ways. The most obvious is that during walking one leg always stays on the ground while the other is swinging. In running there is typically a ballistic phase where the runner is airborne with both feet in the air (for bipedals).
Another difference concerns the movement of the centre of mass of the body. In walking the body "vaults" over the leg on the ground, raising the centre of mass to its highest point as the leg passes the vertical, and dropping it to the lowest as the legs are spread apart. Essentially kinetic energy of forward motion is constantly being traded for a rise in potential energy. This is reversed in running where the centre of mass is at its lowest as the leg is vertical. This is because the impact of landing from the ballistic phase is absorbed by bending the leg and consequently storing energy in muscles and tendons. In running there is a conversion between kinetic, potential, and elastic energy.
There is an absolute limit on an individual's speed of walking (without special techniques such as those employed in speed walking) due to the upwards acceleration of the centre of mass during a stride - if it's greater than the acceleration due to gravity the person will become airborne as they vault over the leg on the ground. Typically however, animals switch to a run at a lower speed than this due to energy efficiencies.
A leisure activity.
Many people enjoy walking as a recreation in the mainly urban modern world, and it is one of the best forms of exercise. For some, walking is a way to enjoy nature and the outdoors; and for others the physical, sporting and endurance aspect is more important.
There are a variety of different kinds of walking, including bushwalking, racewalking, beach walking, hillwalking, volksmarching, Nordic walking, trekking and hiking. Some people prefer to walk indoors on a treadmill, or in a gym, and fitness walkers and others may use a pedometer to count their steps. Hiking is the usual word used in Canada, the USA and South Africa for long vigorous walks; similar walks are called tramps in New Zealand, or hill walking or just walking in Australia, the UK and the Irish Republic. Australians also bushwalk. In English-speaking parts of North America the term walking is used for short walks, especially in towns and cities. Snow shoeing is walking in snow; a slightly different gait is required compared with regular walking.
In terms of tourism the possibilities range from guided walking tours in cities, to organized trekking holidays in the Himalayas. In the UK the term walking tour also refers to a multi-day walk or hike undertaken by a group or individual. Well-organized systems of trails exist in many other European counties, as well as Canada, USA, New Zealand, and Nepal. Systems of lengthy waymarked walking trails now stretch across Europe from Norway to Turkey, Portugal to Cyprus. Many also walk the traditional pilgrim routes, of which the most famous is El Camino de Santiago, The Way of St. James.
Numerous walking festivals and other walking events take place each year in many countries. The world's largest multi-day walking event is the International Four Days Marches Nijmegen in the Netherlands. The "Vierdaagse" (Dutch for "Four day Event") is an annual walk that has taken place since 1909; it has been based at Nijmegen since 1916. Depending on age group and category, walkers have to walk 30, 40 or 50 kilometers each day for four days. Originally a military event with a few civilians, it now is a mainly civilian event. Numbers have risen in recent years, with over 40,000 now taking part, including about 5,000 military personnel. Due to crowds on the route, since 2004 the organizers have limited the number of participants. In the USA there is the annual Labor Day walk on Mackinac Bridge, Michigan, which draws over 60,000 participants; it is the largest single-day walking event; while the Chesapeake Bay Bridge Walk in Maryland draws over 50,000 participants each year. There are also various walks organised as charity events, with walkers sponsored for a specific cause. Thes walks range in length from two miles (3 km) or five km to 50 miles (80 km). The MS Challenge Walk is a 80 km or 50 mile walk which raises money to fight multiple sclerosis, while walkers in the Oxfam Trailwalker cover 100 km or 60 miles.
In Britain, The Ramblers, a registered charity, is the largest organisation that looks after the interests of walkers, with some 139,000 members. Its "Get Walking Keep Walking" project provides free route guides, led walks, as well as information for people new to walking. The Long Distance Walkers Association in the UK is for the more energetic walker, and organizes lengthy challenge hikes of 20 or even 50 miles (30 to 80 km) or more in a day. The LDWA's annual "Hundred" event, entailing walking 100 miles or 160 km in 48 hours, takes place each British Spring Bank Holiday weekend.
Walkability.
There has been a recent focus among urban planners in some communities to create pedestrian-friendly areas and roads, allowing commuting, shopping and recreation to be done on foot. The concept of walkability has arisen as a measure of the degree to which an area is friendly to walking. Some communities are at least partially car-free, making them particularly supportive of walking and other modes of transportation. In the United States, the active living network is an example of a concerted effort to develop communities more friendly to walking and other physical activities.
An example of such efforts to make urban development more pedestrian friendly is the pedestrian village. This is a compact, pedestrian-oriented neighborhood or town, with a mixed-use village center, that follows the tenets of New Pedestrianism. Shared-use lanes for pedestrians and those using bicycles, Segways, wheelchairs, and other small rolling conveyances that do not use internal combustion engines. Generally, these lanes are in front of the houses and businesses, and streets for motor vehicles are always at the rear. Some pedestrian villages might be nearly car-free with cars either hidden below the buildings or on the periphery of the village. Venice, Italy is essentially a pedestrian village with canals. The canal district in Venice, California, on the other hand, combines the front lane/rear street approach with canals and walkways, or just walkways.
Walking is also considered to be a clear example of a sustainable mode of transport, especially suited for urban use and/or relatively shorter distances. Non-motorised transport modes such as walking, but also cycling, small-wheeled transport (skates, skateboards, push scooters and hand carts) or wheelchair travel are often key elements of successfully encouraging clean urban transport. A large variety of case studies and good practices (from European cities and some worldwide examples) that promote and stimulate walking as a means of transportation in cities can be found at Eltis, Europe's portal for local transport.
The development of specific rights of way with appropriate infrastructure can promote increased participation and enjoyment of walking. Examples of types of investment include pedestrian malls, and foreshoreways such as oceanways and also river walks.
The first purpose-built pedestrian street in Europe is the Lijnbaan in Rotterdam, opened in 1953. The first pedestrianised shopping centre in the United Kingdom was in Stevenage in 1959. A large number of European towns and cities have made part of their centres car-free since the early 1960s. These are often accompanied by car parks on the edge of the pedestrianised zone, and, in the larger cases, park and ride schemes. Central Copenhagen is one of the largest and oldest: It was converted from car traffic into pedestrian zone in 1962.
In robotics.
The first successful attempts at walking robots tended to have six legs. The number of legs was reduced as microprocessor technology advanced, and there are now a number of robots that can walk on two legs. One, for example, is ASIMO. Although robots have taken great strides in advancement, they still don't walk nearly as well as human beings as they often need to keep their knees bent permanently in order to improve stability.
In 2009, Japanese roboticist Tomotaka Takahashi developed a robot that can jump three inches off the ground. The robot, named Ropid, is capable of getting up, walking, running, and jumping.
Animals.
Horses.
The walk is a four-beat gait that averages about . When walking, a horse's legs follow this sequence: left hind leg, left front leg, right hind leg, right front leg, in a regular 1-2-3-4 beat. At the walk, the horse will always have one foot raised and the other three feet on the ground, save for a brief moment when weight is being transferred from one foot to another. A horse moves its head and neck in a slight up and down motion that helps maintain balance.
Ideally, the advancing rear hoof oversteps the spot where the previously advancing front hoof touched the ground. The more the rear hoof oversteps, the smoother and more comfortable the walk becomes. Individual horses and different breeds vary in the smoothness of their walk. However, a rider will almost always feel some degree of gentle side-to-side motion in the horse's hips as each hind leg reaches forward.
The fastest "walks" with a four-beat footfall pattern are actually the lateral forms of ambling gaits such as the running walk, singlefoot, and similar rapid but smooth intermediate speed gaits. If a horse begins to speed up and lose a regular four-beat cadence to its gait, the horse is no longer walking, but is beginning to either trot or pace.
Elephants.
Elephants can move both forwards and backwards, but cannot trot, jump, or gallop. They use only two gaits when moving on land, the walk and a faster gait similar to running. In walking, the legs act as pendulums, with the hips and shoulders rising and falling while the foot is planted on the ground. With no "aerial phase", the fast gait does not meet all the criteria of running, although the elephant uses its legs much like other running animals, with the hips and shoulders falling and then rising while the feet are on the ground. Fast-moving elephants appear to 'run' with their front legs, but 'walk' with their hind legs and can reach a top speed of . At this speed, most other quadrupeds are well into a gallop, even accounting for leg length.
Walking fish.
Walking fish, sometimes called ambulatory fish, is a general term that refers to fish that are able to travel over land for extended periods of time. The term may also be used for some other cases of nonstandard fish locomotion, e.g., when describing fish "walking" along the sea floor, as the handfish or frogfish.

</doc>
<doc id="33511" url="https://en.wikipedia.org/wiki?curid=33511" title="Wikification">
Wikification

Wikification may refer to:

</doc>
<doc id="33514" url="https://en.wikipedia.org/wiki?curid=33514" title="War of the Polish Succession">
War of the Polish Succession

The War of the Polish Succession (1733–1738) was a major European war sparked by a Polish civil war over the succession to Augustus II, which the other European powers widened in pursuit of their own national interests. France and Spain, the two Bourbon powers, attempted to check the power of the Austrian Habsburgs in western Europe, as did the Kingdom of Prussia; whilst Saxony and Russia mobilized to support the eventual Polish victor. The slight amount of fighting in Poland resulted in the accession of Augustus III, who in addition to Russia and Saxony, was politically supported by the Habsburgs.
The war's major military campaigns occurred outside Poland. The Bourbons, supported by Charles Emmanuel III of Sardinia, moved against isolated Habsburg territories. In the Rhineland France successfully took the Duchy of Lorraine, and in Italy Spain regained control over the kingdoms of Naples and Sicily (lost in the War of the Spanish Succession), while territorial gains in northern Italy were limited despite bloody campaigning. Great Britain's unwillingness to support Habsburg Austria demonstrated major cracks in the Anglo-Austrian Alliance and may have contributed to Austria's military failures.
Although a preliminary peace was reached in 1735, the war was formally ended with the Treaty of Vienna (1738) in which Augustus III was confirmed as king of Poland and his opponent Stanisław I (who had received virtually no foreign military support) was awarded the Duchy of Lorraine. Francis Stephen, the duke of Lorraine, was given the Grand Duchy of Tuscany in compensation for the loss of Lorraine. The Duchy of Parma went to Austria whereas Charles of Parma took the crowns of Naples and Sicily, resulting in territorial gains for the Bourbons. Poland also gave up claims to Livonia and direct control over the Duchy of Courland and Semigallia, which, although remaining a Polish fief, was not integrated into Poland proper, and came under strong Russian influence.
Background.
After Sigismund II Augustus (d. 1572), each King of Poland was elected by the "Szlachta" (the Polish nobility) in the Sejm (Parliament). As a result, the kings had little formal power. But the Sejm was often paralyzed by the "Liberum Veto", the right of any member of the Sejm to block its decisions. Poland's neighbors often influenced the Sejm, and by the early 18th century the democratic system was in decline.
Elector Augustus the Strong of Saxony had become king in 1697, with the backing of Austria and Russia. In 1705, during the Great Northern War, Charles XII of Sweden deposed Augustus and installed Stanisław I as king. After Charles' defeat by Russia at Poltava in 1709, Stanisław fled to France, and Augustus was restored. In 1725, his daughter Maria married King Louis XV of France.
Augustus tried to make the Polish crown hereditary in his family, but failed. So when he died in 1733, Stanisław hoped to regain the throne. He was backed by his son-in-law Louis XV, who wanted to counter Russian and Austrian power by renewing France's traditional alliance with Poland. 
In 1732 Empress Anna of Russia, Holy Roman Emperor Charles VI and King Frederick William I of Prussia, irritated with Augustus but unwilling to allow Stanisław to become king, secretly signed Löwenwolde's Treaty, in which they agreed to back Infante Manuel of Portugal for the Polish throne.
France's prime minister, Cardinal Fleury, saw the Polish struggle as a chance to strike at the Austrian monarchy in the west without seeming to be the aggressor. While he cared little for who should become King of Poland, the cause of the King's father-in-law was a sympathetic one. He also hoped to use the war to humble Austria, and perhaps secure the long-desired Duchy of Lorraine from Duke Francis Stephen, who was unofficially betrothed to Emperor Charles's daughter and heir Maria Theresa. Their marriage would bring Austrian power dangerously close to France. Fleury's diplomatic moves brought into the war additional powers with no interest in Polish affairs and politics, most notably Spain and King Charles Emmanuel III of Sardinia, who was also Duke of Savoy.
Death of Augustus II.
Augustus II died on February 1, 1733. Throughout the spring and summer of 1733, France began building up forces along its northern and eastern frontiers, while the emperor massed troops on Polish borders, reducing garrisons in the Duchy of Milan for the purpose. While the aging Prince Eugene of Savoy had recommended to the emperor a more warlike posture against potential actions by France in the Rhine valley and northern Italy, only minimal steps were taken to improve imperial defenses on the Rhine.
The Marquis de Monti, France's ambassador in Warsaw, convinced the rival Potocki and Czartoryski families to unite behind Stanisław. Teodor Potocki, Primate of Poland and interrex following the death of Augustus, called a convocation sejm in March 1733. Delegates to this sejm passed a resolution forbidding the candidacy of foreigners; this would explicitly exclude both Emmanuel of Portugal and Augustus II's son, Frederick August II, the Elector of Saxony.
Frederick August negotiated agreements with Austria and Russia in July 1733. In exchange for Russian support, he agreed to give up any remaining Polish claims to Livonia, and promised to Anna of Russia her choice of successor to the Duchy of Courland, a Polish fief (of which she had been duchess prior to her ascension to the Russian throne) which would have otherwise come under direct Polish rule on the death of the current duke, Ferdinand Kettler, who had no heirs. To the Austrian emperor he promised recognition of the Pragmatic Sanction of 1713, a document designed to guarantee inheritance of the Austrian throne to Maria Theresa, Charles' oldest child.
In August, Polish nobles gathered for the election sejm. On August 11, 30,000 Russian troops under Field Marshal Peter Lascy entered Poland in a bid to influence the sejm's decision. On September 4, France openly declared its support for Leszczyński, who was elected king by a sejm of 12,000 delegates on September 12. A group of nobles, led by Lithuanian magnates including Duke Michael Wiśniowiecki (the former Lithuanian grand chancellor nominated by Augustus II), crossed the Vistula River to Praga and the protection of Russian troops. This group, numbering about 3,000, elected Frederick August II King of Poland as Augustus III on October 5. Despite the fact that this group was a minority, Russia and Austria, intent on maintaining their influence within Poland, recognised Augustus as king.
On October 10, France declared war on Austria and Saxony. Louis XV was later joined by his uncle, King Philip V of Spain, who hoped to secure territories in Italy for his sons by his second marriage to Elizabeth Farnese. Specifically, he hoped to secure Mantua for the elder son, Don Carlos, who was already Duke of Parma and had the expectation of the Grand Duchy of Tuscany, and the Kingdoms of Naples and Sicily for the younger son, Don Felipe. The two Bourbon monarchs were also joined by Charles Emmanuel of Savoy, who hoped to secure gains from the Austrian Duchies of Milan and Mantua.
Austrian isolation.
When hostilities finally broke out, the Austrians had hoped for aid from the maritime powers, Great Britain and the Dutch Republic. They were disappointed in this, since both the Dutch and the British chose to pursue a policy of neutrality. The British Prime Minister Sir Robert Walpole justified Britain's non-intervention by insisting that the Anglo-Austrian Alliance agreed at the 1731 Treaty of Vienna was a purely defensive agreement, while Austria was in this instance the aggressor. This position was attacked by English Austrophiles who wanted to aid the Austrians against France, but Walpole's dominant position ensured that Britain stayed out of the conflict. The French, not wishing to provoke Britain, carefully chose not to campaign in the Austrian Netherlands and avoided campaigning in parts of the Holy Roman Empire that might draw either power into the conflict.
On Austria's southern border, France in November 1733 negotiated the secret Treaty of Turin with Charles Emmanuel and prepared for military operations in northern Italy. It concluded the (also secret) Treaty of the Escorial with Spain, which included promises of French assistance in the Spanish conquest of Naples and Sicily. France also made diplomatic overtures to Sweden and the Ottoman Empire in a fruitless attempt to draw them into the conflict in support of Stanisław.
The Austrians were thus left largely without effective external allies on their southern and western frontiers. Their Russian and Saxon allies were occupied with the Polish campaign, and the Emperor distrusted Frederick William I of Prussia, who was willing to provide some aid. Divisions within the empire also had an impact on the raising of troops in 1733, as Charles-Albert of Bavaria, who harbored ambitions to become the next Holy Roman Emperor, signed a secret agreement with France in November 1733, and tried, with limited success, to dissuade other rulers within the empire from the Wittelsbach family from providing troops to the emperor under their treaty obligations. While Britain itself did not provide support, the Electorate of Hanover, where George II also ruled as an Imperial Elector, proved willing to help.
War.
Poland.
The Russians, led by the famous commander Peter Lacy, quickly captured the capital city of Warsaw and installed Augustus as potential heir, forcing Stanisław to flee to Danzig (present-day Gdańsk), where he was besieged for some time by a Russian-Saxon army that came under the overall command of Field Marshal Burkhard Christoph von Münnich. Danzig capitulated in June 1734, and Stanisław was forced to flee once more, this time first to the city of Königsberg and eventually to France. This ended major military activity in Poland itself, although it continued to be occupied by foreign troops as Augustus dealt with partisan supporters of Stanisław I. A group of nobles and aristocrats supporting Stanisław formed the Confederation of Dzików in late 1734, and under their commander, Adam Tarło, tried to fight the Russian and Saxon troops, but their efforts were ineffective. In what became known as the Pacification Sejm, held in June–July of 1736, Augustus was confirmed as king of Poland and Grand Duke of Lithuania.
Rhineland.
Following France's October 10 declaration of war, it began military operations three days later, invading the Duchy of Lorraine and besieging the imperial fortress at Kehl, across the Rhine River from Strasbourg, gaining control of both objectives in a few weeks. Unable to attack Austria directly, and unwilling to invade the intervening German states for fear of drawing Great Britain and the Dutch into the conflict, France consolidated its position in Lorraine, and withdrew its troops across the Rhine for the winter.
The emperor mobilized his active forces in response to the French attacks, and began the process of calling up troops from the states of the empire, establishing a defensive line at Ettlingen, near Karlsruhe. In the spring of 1734 French maneuvers successfully flanked this line, and Prince Eugene of Savoy was forced to withdraw these forces to the imperial encampment at Heilbronn. This cleared the way for the French army under the Duke of Berwick to besiege the imperial fort at Philippsburg, which fell after a siege of two months in July 1734. Eugene, who was accompanied by Crown Prince Frederick of Prussia, made some attempts to relieve the siege, but never made any decisive attacks against the besieging army owing to its size and relatively poor quality of the troops under his command. Berwick was killed by a shell at Philippsburg.
French armies continued to advance along the Rhine, reaching as far as Mainz, but the growing imperial army, which came to include troops from Russia that had assisted with the capture of Danzig, was able to prevent France from establishing a siege there, and Eugene went on the offensive. A force of 30,000 under Friedrich Heinrich von Seckendorff crossed the Rhine and began pushing the French back toward Trier, defeating them at Clausen in October 1735, in one of the last battles before preliminary peace terms were reached.
Italy.
French and Savoyard troops numbering over 50,000, under the command of Charles Emmanuel, entered Milanese territory as early as October 24, against minimal resistance, as the Austrian forces in the duchy numbered only about 12,000. By November 3, the city of Milan itself had surrendered, although the Austrian governor, Count Wirich Philipp von Daun, still held the fortress. France's great general, the Duke de Villars, joined Charles Emmanuel in Milan on November 11. While Villars wanted to move immediately against Mantua to secure the Alpine passes against Austrian reinforcements, Charles Emmanuel, mistrustful of his French allies and their dealings with Spain, sought to secure Milan. The army spent the next three months eliminating Austrian opposition from the remaining fortified towns in the duchy. Villars attempted to interest Don Carlos of Parma in joining the expedition against Mantua, but Carlos was focused on the campaign into Naples. Villars began to move against Mantua, but Charles Emmanuel resisted, and the army made little progress. In early May, an Austrian army of 40,000 under Count Claude Florimond de Mercy crossed the Alps and threatened to close in on the French army's rear by a flanking maneuver. Villars responded by retreating from Mantua and attempted without success to interrupt the Austrian army's crossing of the Po River. Villars, frustrated by Charles Emmanuel's delaying tactics, quit the army on May 27. He fell ill on the way back to France and died in Turin on June 17.
Mercy's forces made repeated attempts to cross the Parma River in June, but it was not until late in that month that they were able to cross the river and approach the city of Parma, where the allied forces, now under the command of French marshals de Broglie and Coigny, were entrenched. In a bloody battle near the village of Crocetta on June 29, the Austrians were beaten back, Mercy was killed, and Frederick of Württemberg, his second, was wounded. Charles Emmanuel returned the next day to retake command, and resumed his delaying tactics by failing to immediately pursue the retreating Austrians. The Austrians retreated to the Po, where they were reinforced by additional troops and placed under the command of Field Marshal Königsegg. After two months of inaction, during which the armies faced each other across the Secchia River, Königsegg on September 15 took advantage of lax security and executed a raid on Coigny's headquarters at Quistello, very nearly capturing Coigny and taking among other prizes Charles Emmanuel's china. Two days later the French withdrew to a position near Guastalla in response to Austrian maneuvers, but one detachment of nearly 3,000 men was surrounded and captured by the advancing Austrians. On September 19, Königsegg attacked the allied position at Guastalla, and in another bloody encounter, was beaten back, losing among others Frederick of Württemberg. Königsegg retreated across the Po, adopting a defensive position between the Po and the Oglio while Charles Emmanuel again did not capitalize on his victory. When he finally withdrew most of the allied army to Cremona, the Austrians advanced on the north bank of the Po as far as the Adda before both armies entered winter quarters in December 1734.
In southern Italy, the Austrians, choosing a strategy of defending a large number of fortresses, were soundly defeated. Don Carlos assembled an army composed primarily of Spaniards, but also including some troops from France and Savoy. Moving south through the Papal States, his army flanked the frontline Austrian defense at Mignano, forcing them to retreat into the fortress at Capua. He was then practically welcomed into Naples by the city fathers, as the Austrian viceroy had fled toward Bari, and the fortresses held by the Austrians in the city were quickly captured. While maintaining a blockade of the largest Austrian holdings at Capua and Gaeta, a large portion of the allied army gave chase to the remaining Austrian forces. These finally attempted a stand in late May, and were defeated at Bitonto. Capua and Gaeta were then properly besieged while Austrian fortresses in Sicily were quickly subdued. Gaeta surrendered in August, and Capua held out until November when its commander, Otto Ferdinand von Abensberg und Traun, finally negotiated surrender terms when he ran out of ammunition. The Jacobite pretender to the thrones of United Kingdom and France, Charles Edward Stuart, who was under 14 then, also participated in the French and Spanish siege of Gaeta, making his first exposure to battle.
The armies in northern Italy suffered significantly over the winter, with significant losses to disease and desertion. For the 1735 campaign the allied forces in northern Italy came under the command of the Duke de Noailles, elevated to Marshal after his successful contributions to the Rhine campaign. They were also joined by Spanish forces in May, now available after the successes in the south. In response to this threat, Königsegg retreated into the Bishopric of Trent, but leaving the fortress city of Mantua well-defended. At this point divisions between the allies became clear, as Spain laid claim to Mantua, and also refused to guarantee Milan to Charles Emmanuel. In response, Charles Emmanuel refused to allow his siege equipment to be used against Mantua. As a result, the Franco-Spanish army was unable to do more than blockade the city. When Charles Emmanuel withdrew his forces from the area, the allies were forced to retreat, and the beleaguered Austrians capitalized, eventually recovering most of Milan against little opposition in November.
Peace settlement.
As early as February 1734 the British and Dutch had offered to mediate peace talks between the various parties of the conflict. By early 1735, proposals were being circulated. As 1735 progressed with the Austrians being in no real position to continue the fight, and the French concerned by the possible arrival of Russian reinforcements on the Rhine (which did eventually occur), negotiations continued through the summer of 1735.
A preliminary peace was finally concluded in October of 1735 and ratified in the Treaty of Vienna in November 1738. Augustus was officially confirmed as king of Poland, Stanisław was compensated with Lorraine (which would pass on his death, through his daughter, to the French), while the former Duke of Lorraine, Francis Stephen, was made heir to the Grand Duchy of Tuscany.
Charles of Parma gave up Parma, which came under direct Austrian rule, but he was richly compensated by being confirmed instead as king of Naples and Sicily. Charles Emmanuel III of Sardinia received territories in the western part of the Duchy of Milan west of the Ticino, including Novara and Tortona.
Although fighting stopped after the preliminary peace in 1735, the final peace settlement had to wait until the death of the last Medici Grand Duke of Tuscany, Gian Gastone in 1737, to allow the territorial exchanges provided for by the peace settlement to go into effect.
The French (and their allies), hoping for détente and good relations with the Austrians, now also recognized the Pragmatic Sanction that would allow Emperor Charles's daughter Maria Theresa to succeed him. This proved a hollow guarantee, however, as the French decided to intervene to partition the Habsburg Monarchy after all following the death of Charles in 1740. The acquisition of Lorraine for the former Polish king, however, proved of lasting benefit to France, as it passed under direct French rule with Stanisław's death in 1766.
Stanisław signed the act of abdication in 1736, while Augustus III pronounced a general amnesty. Michał Serwacy Wiśniowiecki was lavishly rewarded: the king made him the Grand Hetman and commander-in-chief of the Grand Duchy of Lithuania.

</doc>
<doc id="33516" url="https://en.wikipedia.org/wiki?curid=33516" title="Wave">
Wave

In physics, a wave is an oscillation accompanied by a transfer of energy that travels through medium (space or mass). Frequency refers to the addition of time. Wave motion transfers energy from one point to another, which displace particles of the transmission medium—that is, with little or no associated mass transport. Waves consist, instead, of oscillations or vibrations (of a physical quantity), around almost fixed locations.
There are two main types of waves. Mechanical waves propagate through a medium, and the substance of this medium is deformed. The deformation reverses itself owing to restoring forces resulting from its deformation. For example, sound waves propagate via air molecules colliding with their neighbors. When air molecules collide, they also bounce away from each other (a restoring force). This keeps the molecules from continuing to travel in the direction of the wave.
The second main type of wave, electromagnetic waves, do not require a medium. Instead, they consist of periodic oscillations of electrical and magnetic fields originally generated by charged particles, and can therefore travel through a vacuum. These types of waves vary in wavelength, and include radio waves, microwaves, infrared radiation, visible light, ultraviolet radiation, X-rays, and gamma rays.
Waves are described by a wave equation which sets out how the disturbance proceeds over time. The mathematical form of this equation varies depending on the type of wave. Further, the behavior of particles in quantum mechanics are described by waves. In addition, gravitational waves also travel through space, which are a result of a vibration or movement in gravitational fields.
A wave can be transverse or longitudinal. Transverse waves occur when a disturbance creates oscillations that are perpendicular to the propagation of energy transfer. Longitudinal waves occur when the oscillations are parallel to the direction of energy propagation. While mechanical waves can be both transverse and longitudinal, all electromagnetic waves are transverse in free space.
General features.
A single, all-encompassing definition for the term "wave" is not straightforward. A vibration can be defined as a "back-and-forth" motion around a reference value. However, a vibration is not necessarily a wave. An attempt to define the necessary and sufficient characteristics that qualify a phenomenon to be called a "wave" results in a fuzzy border line.
The term "wave" is often intuitively understood as referring to a transport of spatial disturbances that are generally not accompanied by a motion of the medium occupying this space as a whole. In a wave, the energy of a vibration is moving away from the source in the form of a disturbance within the surrounding medium . However, this motion is problematic for a standing wave (for example, a wave on a string), where energy is moving in both directions equally, or for electromagnetic (e.g., light) waves in a vacuum, where the concept of medium does not apply and interaction with a target is the key to wave detection and practical applications. There are water waves on the ocean surface; gamma waves and light waves emitted by the Sun; microwaves used in microwave ovens and in radar equipment; radio waves broadcast by radio stations; and sound waves generated by radio receivers, telephone handsets and living creatures (as voices), to mention only a few wave phenomena.
It may appear that the description of waves is closely related to their physical origin for each specific instance of a wave process. For example, acoustics is distinguished from optics in that sound waves are related to a mechanical rather than an electromagnetic wave transfer caused by vibration. Concepts such as mass, momentum, inertia, or elasticity, become therefore crucial in describing acoustic (as distinct from optic) wave processes. This difference in origin introduces certain wave characteristics particular to the properties of the medium involved. For example, in the case of air: vortices, radiation pressure, shock waves etc.; in the case of solids: Rayleigh waves, dispersion; and so on.
Other properties, however, although usually described in terms of origin, may be generalized to all waves. For such reasons, wave theory represents a particular branch of physics that is concerned with the properties of wave processes independently of their physical origin. For example, based on the mechanical origin of acoustic waves, a moving disturbance in space–time can exist if and only if the medium involved is neither infinitely stiff nor infinitely pliable. If all the parts making up a medium were rigidly "bound", then they would all vibrate as one, with no delay in the transmission of the vibration and therefore no wave motion. On the other hand, if all the parts were independent, then there would not be any transmission of the vibration and again, no wave motion. Although the above statements are meaningless in the case of waves that do not require a medium, they reveal a characteristic that is relevant to all waves regardless of origin: within a wave, the phase of a vibration (that is, its position within the vibration cycle) is different for adjacent points in space because the vibration reaches these points at different times.
Mathematical description of one-dimensional waves.
Wave equation.
Consider a traveling transverse wave (which may be a pulse) on a string (the medium). Consider the string to have a single spatial dimension. Consider this wave as traveling
This wave can then be described by the two-dimensional functions
or, more generally, by d'Alembert's formula:
representing two component waveforms formula_8 and formula_10 traveling through the medium in opposite directions. A generalized representation of this wave can be obtained as the partial differential equation
General solutions are based upon Duhamel's principle.
Wave forms.
The form or shape of "F" in d'Alembert's formula involves the argument "x − vt". Constant values of this argument correspond to constant values of "F", and these constant values occur if "x" increases at the same rate that "vt" increases. That is, the wave shaped like the function "F" will move in the positive "x"-direction at velocity "v" (and "G" will propagate at the same speed in the negative "x"-direction).
In the case of a periodic function "F" with period "λ", that is, "F"("x + λ" − "vt") = "F"("x " − "vt"), the periodicity of "F" in space means that a snapshot of the wave at a given time "t" finds the wave varying periodically in space with period "λ" (the wavelength of the wave). In a similar fashion, this periodicity of "F" implies a periodicity in time as well: "F"("x" − "v(t + T)") = "F"("x " − "vt") provided "vT" = "λ", so an observation of the wave at a fixed location "x" finds the wave undulating periodically in time with period "T = λ"/"v".
Amplitude and modulation.
The amplitude of a wave may be constant (in which case the wave is a "c.w." or "continuous wave"), or may be "modulated" so as to vary with time and/or position. The outline of the variation in amplitude is called the "envelope" of the wave. Mathematically, the modulated wave can be written in the form:
where formula_16 is the amplitude envelope of the wave, formula_17 is the "wavenumber" and formula_18 is the "phase". If the group velocity formula_19 (see below) is wavelength-independent, this equation can be simplified as:
showing that the envelope moves with the group velocity and retains its shape. Otherwise, in cases where the group velocity varies with wavelength, the pulse shape changes in a manner often described using an "envelope equation".
Phase velocity and group velocity.
There are two velocities that are associated with waves, the phase velocity and the group velocity. To understand them, one must consider several types of waveform. For simplification, examination is restricted to one dimension.
The most basic wave (a form of plane wave) may be expressed in the form:
which can be related to the usual sine and cosine forms using Euler's formula. Rewriting the argument, formula_22, makes clear that this expression describes a vibration of wavelength formula_23 traveling in the "x"-direction with a constant "phase velocity" formula_24.
The other type of wave to be considered is one with localized structure described by an envelope, which may be expressed mathematically as, for example:
where now "A(k"1")" (the integral is the inverse Fourier transform of A(k1)) is a function exhibiting a sharp peak in a region of wave vectors Δ"k" surrounding the point "k"1 = "k". In exponential form:
with "A"o the magnitude of "A". For example, a common choice for "A"o is a Gaussian wave packet:
where σ determines the spread of "k"1-values about "k", and "N" is the amplitude of the wave.
The exponential function inside the integral for ψ oscillates rapidly with its argument, say φ("k"1), and where it varies rapidly, the exponentials cancel each other out, interfere destructively, contributing little to ψ. However, an exception occurs at the location where the argument φ of the exponential varies slowly. (This observation is the basis for the method of stationary phase for evaluation of such integrals.) The condition for φ to vary slowly is that its rate of change with "k"1 be small; this rate of variation is:
where the evaluation is made at "k"1 = "k" because "A(k"1")" is centered there. This result shows that the position "x" where the phase changes slowly, the position where ψ is appreciable, moves with time at a speed called the "group velocity":
The group velocity therefore depends upon the dispersion relation connecting ω and "k". For example, in quantum mechanics the energy of a particle represented as a wave packet is "E" = ħω = (ħ"k")2/(2"m"). Consequently, for that wave situation, the group velocity is
showing that the velocity of a localized particle in quantum mechanics is its group velocity. Because the group velocity varies with "k", the shape of the wave packet broadens with time, and the particle becomes less localized. In other words, the velocity of the constituent waves of the wave packet travel at a rate that varies with their wavelength, so some move faster than others, and they cannot maintain the same interference pattern as the wave propagates.
Sinusoidal waves.
Mathematically, the most basic wave is the (spatially) one-dimensional sine wave (or "harmonic wave" or "sinusoid") with an amplitude formula_4 described by the equation:
where
The units of the amplitude depend on the type of wave. Transverse mechanical waves (e.g., a wave on a string) have an amplitude expressed as a distance (e.g., meters), longitudinal mechanical waves (e.g., sound waves) use units of pressure (e.g., pascals), and electromagnetic waves (a form of transverse vacuum wave) express the amplitude in terms of its electric field (e.g., volts/meter).
The wavelength formula_39 is the distance between two sequential crests or troughs (or other equivalent points), generally is measured in meters. A wavenumber formula_17, the spatial frequency of the wave in radians per unit distance (typically per meter), can be associated with the wavelength by the relation
The period formula_42 is the time for one complete cycle of an oscillation of a wave. The frequency formula_43 is the number of periods per unit time (per second) and is typically measured in hertz. These are related by:
In other words, the frequency and period of a wave are reciprocals.
The angular frequency formula_37 represents the frequency in radians per second. It is related to the frequency or period by
The wavelength formula_39 of a sinusoidal waveform traveling at constant speed formula_5 is given by:
where formula_5 is called the phase speed (magnitude of the phase velocity) of the wave and formula_43 is the wave's frequency.
Wavelength can be a useful concept even if the wave is not periodic in space. For example, in an ocean wave approaching shore, the incoming wave undulates with a varying "local" wavelength that depends in part on the depth of the sea floor compared to the wave height. The analysis of the wave can be based upon comparison of the local wavelength with the local water depth.
Although arbitrary wave shapes will propagate unchanged in lossless linear time-invariant systems, in the presence of dispersion the sine wave is the unique shape that will propagate unchanged but for phase and amplitude, making it easy to analyze. Due to the Kramers–Kronig relations, a linear medium with dispersion also exhibits loss, so the sine wave propagating in a dispersive medium is attenuated in certain frequency ranges that depend upon the medium.
The sine function is periodic, so the sine wave or sinusoid has a wavelength in space and a period in time.
The sinusoid is defined for all times and distances, whereas in physical situations we usually deal with waves that exist for a limited span in space and duration in time. Fortunately, an arbitrary wave shape can be decomposed into an infinite set of sinusoidal waves by the use of Fourier analysis. As a result, the simple case of a single sinusoidal wave can be applied to more general cases. In particular, many media are linear, or nearly so, so the calculation of arbitrary wave behavior can be found by adding up responses to individual sinusoidal waves using the superposition principle to find the solution for a general waveform. When a medium is nonlinear, the response to complex waves cannot be determined from a sine-wave decomposition.
Standing waves.
A standing wave, also known as a "stationary wave", is a wave that remains in a constant position. This phenomenon can occur because the medium is moving in the opposite direction to the wave, or it can arise in a stationary medium as a result of interference between two waves traveling in opposite directions.
The "sum" of two counter-propagating waves (of equal amplitude and frequency) creates a "standing wave". Standing waves commonly arise when a boundary blocks further propagation of the wave, thus causing wave reflection, and therefore introducing a counter-propagating wave. For example, when a violin string is displaced, transverse waves propagate out to where the string is held in place at the bridge and the nut, where the waves are reflected back. At the bridge and nut, the two opposed waves are in antiphase and cancel each other, producing a node. Halfway between two nodes there is an antinode, where the two counter-propagating waves "enhance" each other maximally. There is no net propagation of energy over time.
Physical properties.
Waves exhibit common behaviors under a number of standard situations, e. g.
Transmission and media.
Waves normally move in a straight line (i.e. rectilinearly) through a "transmission medium". Such media can be classified into one or more of the following categories:
Absorption.
Absorption of waves mean, if a kind of wave strikes a matter, it will be absorbed by the matter. When a wave with that same natural frequency impinges upon an atom, then the electrons of that atom will be set into vibrational motion. If a wave of a given frequency strikes a material with electrons having the same vibrational frequencies, then those electrons will absorb the energy of the wave and transform it into vibrational motion.
Reflection.
When a wave strikes a reflective surface, it changes direction, such that the angle made by the incident wave and line normal to the surface equals the angle made by the reflected wave and the same normal line.
Interference.
Waves that encounter each other combine through superposition to create a new wave called an interference pattern. Important interference patterns occur for waves that are in phase.
Refraction.
Refraction is the phenomenon of a wave changing its speed. Mathematically, this means that the size of the phase velocity changes. Typically, refraction occurs when a wave passes from one medium into another. The amount by which a wave is refracted by a material is given by the refractive index of the material. The directions of incidence and refraction are related to the refractive indices of the two materials by Snell's law.
Diffraction.
A wave exhibits diffraction when it encounters an obstacle that bends the wave or when it spreads after emerging from an opening. Diffraction effects are more pronounced when the size of the obstacle or opening is comparable to the wavelength of the wave.
Polarization.
The phenomenon of polarization arises when wave motion can occur simultaneously in two orthogonal directions. Transverse waves can be polarized, for instance. When polarization is used as a descriptor without qualification, it usually refers to the special, simple case of linear polarization. A transverse wave is linearly polarized if it oscillates in only one direction or plane. In the case of linear polarization. it is often useful to add the relative orientation of that plane, perpendicular to the direction of travel, in which the oscillation occurs, such as "horizontal" for instance, if the plane of polarization is parallel to the ground. Electromagnetic waves propagating in free space, for instance, are transverse; they can be polarized by the use of a polarizing filter.
Longitudinal waves, such as sound waves, do not exhibit polarization. For these waves there is only one direction of oscillation, that is, along the direction of travel.
Dispersion.
A wave undergoes dispersion when either the phase velocity or the group velocity depends on the wave frequency.
Dispersion is most easily seen by letting white light pass through a prism, the result of which is to produce the spectrum of colours of the rainbow. Isaac Newton performed experiments with light and prisms, presenting his findings in the "Opticks" (1704) that white light consists of several colours and that these colours cannot be decomposed any further.
Mechanical waves.
Waves on strings.
The speed of a transverse wave traveling along a vibrating string (" v ") is directly proportional to the square root of the tension of the string (" T ") over the linear mass density (" μ "):
where the linear density "μ" is the mass per unit length of the string.
Acoustic waves.
Acoustic or sound waves travel at speed given by
or the square root of the adiabatic bulk modulus divided by the ambient fluid density (see speed of sound).
Electromagnetic waves.
An electromagnetic wave consists of two waves that are oscillations of the electric and magnetic fields. An electromagnetic wave travels in a direction that is at right angles to the oscillation direction of both fields. In the 19th century, James Clerk Maxwell showed that, in vacuum, the electric and magnetic fields satisfy the wave equation both with speed equal to that of the speed of light. From this emerged the idea that light is an electromagnetic wave. Electromagnetic waves can have different frequencies (and thus wavelengths), giving rise to various types of radiation such as radio waves, microwaves, infrared, visible light, ultraviolet, X-rays, and Gamma rays.
Quantum mechanical waves.
Schrödinger equation.
The Schrödinger equation describes the wave-like behavior of particles in quantum mechanics. Solutions of this equation are wave functions which can be used to describe the probability density of a particle.
Dirac equation.
The Dirac equation is a relativistic wave equation detailing electromagnetic interactions. Dirac waves accounted for the fine details of the hydrogen spectrum in a completely rigorous way. The wave equation also implied the existence of a new form of matter, antimatter, previously unsuspected and unobserved and which was experimentally confirmed. In the context of quantum field theory, the Dirac equation is reinterpreted to describe quantum fields corresponding to spin-½ particles.
de Broglie waves.
Louis de Broglie postulated that all particles with momentum have a wavelength
where "h" is Planck's constant, and "p" is the magnitude of the momentum of the particle. This hypothesis was at the basis of quantum mechanics. Nowadays, this wavelength is called the de Broglie wavelength. For example, the electrons in a CRT display have a de Broglie wavelength of about 10−13 m.'"
A wave representing such a particle traveling in the "k"-direction is expressed by the wave function as follows:
where the wavelength is determined by the wave vector k as:
and the momentum by:
However, a wave like this with definite wavelength is not localized in space, and so cannot represent a particle localized in space. To localize a particle, de Broglie proposed a superposition of different wavelengths ranging around a central value in a wave packet, a waveform often used in quantum mechanics to describe the wave function of a particle. In a wave packet, the wavelength of the particle is not precise, and the local wavelength deviates on either side of the main wavelength value.
In representing the wave function of a localized particle, the wave packet is often taken to have a Gaussian shape and is called a "Gaussian wave packet". Gaussian wave packets also are used to analyze water waves.
For example, a Gaussian wavefunction ψ might take the form:
at some initial time "t" = 0, where the central wavelength is related to the central wave vector "k"0 as λ0 = 2π / "k"0. It is well known from the theory of Fourier analysis, or from the Heisenberg uncertainty principle (in the case of quantum mechanics) that a narrow range of wavelengths is necessary to produce a localized wave packet, and the more localized the envelope, the larger the spread in required wavelengths. The Fourier transform of a Gaussian is itself a Gaussian. Given the Gaussian:
the Fourier transform is:
The Gaussian in space therefore is made up of waves:
that is, a number of waves of wavelengths λ such that "k"λ = 2 π.
The parameter σ decides the spatial spread of the Gaussian along the "x"-axis, while the Fourier transform shows a spread in wave vector "k" determined by 1/σ. That is, the smaller the extent in space, the larger the extent in "k", and hence in λ = 2π/"k".
Gravity waves.
Gravity waves are waves generated in a fluid medium or at the interface between two media when the force of gravity or buoyancy tries to restore equilibrium. A ripple on a pond is one example.
Gravitational waves.
Gravitational waves also travel through space. The first observation of gravitational waves was announced on 11 February 2016.
Gravitational waves are disturbances in the curvature of spacetime, predicted by Einstein's theory of general relativity.
WKB method.
In a nonuniform medium, in which the wavenumber "k" can depend on the location as well as the frequency, the phase term "kx" is typically replaced by the integral of "k"("x")"dx", according to the WKB method. Such nonuniform traveling waves are common in many physical problems, including the mechanics of the cochlea and waves on hanging ropes.

</doc>
<doc id="33519" url="https://en.wikipedia.org/wiki?curid=33519" title="Weak">
Weak

Weak may refer to:

</doc>
<doc id="33521" url="https://en.wikipedia.org/wiki?curid=33521" title="William McKinley">
William McKinley

William McKinley (January 29, 1843 – September 14, 1901) was the 25th President of the United States, serving from March 4, 1897, until his assassination in September 1901, six months into his second term. McKinley led the nation to victory in the Spanish–American War, raised protective tariffs to promote American industry, and maintained the nation on the gold standard in a rejection of inflationary proposals.
McKinley was the last president to have served in the American Civil War, beginning as a private in the Union Army and ending as a brevet major. After the war, he settled in Canton, Ohio, where he practiced law and married Ida Saxton. In 1876, he was elected to Congress, where he became the Republican Party's expert on the protective tariff, which he promised would bring prosperity. His 1890 McKinley Tariff was highly controversial; which together with a Democratic redistricting aimed at gerrymandering him out of office, led to his defeat in the Democratic landslide of 1890. He was elected Ohio's governor in 1891 and 1893, steering a moderate course between capital and labor interests. With the aid of his close adviser Mark Hanna, he secured the Republican nomination for president in 1896, amid a deep economic depression. He defeated his Democratic rival, William Jennings Bryan, after a front-porch campaign in which he advocated "sound money" (the gold standard unless altered by international agreement) and promised that high tariffs would restore prosperity.
Rapid economic growth marked McKinley's presidency. He promoted the 1897 Dingley Tariff to protect manufacturers and factory workers from foreign competition, and in 1900, he secured the passage of the Gold Standard Act. McKinley hoped to persuade Spain to grant independence to rebellious Cuba without conflict, but when negotiation failed, he led the nation in the Spanish–American War of 1898; the U.S. victory was quick and decisive. As part of the peace settlement, Spain turned over to the United States its main overseas colonies of Puerto Rico, Guam, and the Philippines; Cuba was promised independence, but at that time remained under the control of the U.S. Army. The United States annexed the independent Republic of Hawaii in 1898 and it became a U.S. territory.
Historians regard McKinley's 1896 victory as a realigning election, in which the political stalemate of the post-Civil War era gave way to the Republican-dominated Fourth Party System, which began with the Progressive Era. McKinley defeated Bryan again in the 1900 presidential election, in a campaign focused on imperialism, protectionism, and free silver. However, his legacy was quickly cut short when he was shot on September 6, 1901 by Leon Czolgosz, a second-generation Polish-American with anarchist leanings; McKinley died eight days later, and was succeeded by Vice President Theodore Roosevelt. As an innovator of American interventionism and pro-business sentiment, McKinley's presidency is generally considered above average, though his universally positive public perception was soon overshadowed by Roosevelt.
Early life and family.
William McKinley, Jr. was born in 1843 in Niles, Ohio, the seventh child of William and Nancy (née Allison) McKinley. The McKinleys were of English and Scots-Irish descent and had settled in western Pennsylvania in the 18th century. There, the elder McKinley was born in Pine Township, Mercer County.
The family moved to Ohio when the senior McKinley was a boy, settling in New Lisbon (now Lisbon). He met Nancy Allison there, and married her later. The Allison family was of mostly English descent and among Pennsylvania's earliest settlers. The family trade on both sides was iron-making, and McKinley senior operated foundries throughout Ohio, in New Lisbon, Niles, Poland, and finally Canton. The McKinley household was, like many from Ohio's Western Reserve, steeped in Whiggish and abolitionist sentiment, the latter based on the family's staunch Methodist beliefs. William followed in the Methodist tradition, becoming active in the local Methodist church at the age of sixteen.
He was a lifelong pious Methodist. In 1852, the family moved from Niles to Poland, Ohio so that their children could attend the better school there. Graduating in 1859, he enrolled the following year at Allegheny College in Meadville, Pennsylvania. He remained at Allegheny for only one year, returning home in 1860 after becoming ill and depressed. He also spent time at Mount Union College in Alliance, Ohio, where he joined Sigma Alpha Epsilon. He did not graduate from either university. Although his health recovered, family finances declined and McKinley was unable to return to Allegheny, first working as a postal clerk and later taking a job teaching at a school near Poland, Ohio.
Civil War.
Western Virginia and Antietam.
When the Southern states seceded from the Union and the American Civil War began, thousands of men in Ohio volunteered for service. Among them were McKinley and his cousin William McKinley Osbourne, who enlisted as privates in the newly formed Poland Guards in June 1861. The men left for Columbus where they were consolidated with other small units to form the 23rd Ohio Infantry. The men were unhappy to learn that, unlike Ohio's earlier volunteer regiments, they would not be permitted to elect their officers; they would be designated by Ohio's governor, William Dennison. Dennison appointed Colonel William Rosecrans as the commander of the regiment, and the men began training on the outskirts of Columbus. McKinley quickly took to the soldier's life and wrote a series of letters to his hometown newspaper extolling the army and the Union cause. Delays in issuance of uniforms and weapons again brought the men into conflict with their officers, but Major Rutherford B. Hayes convinced them to accept what the government had issued them; his style in dealing with the men impressed McKinley, beginning an association and friendship that would last until Hayes' death in 1893.
After a month of training, McKinley and the 23rd Ohio, now led by Colonel Eliakim P. Scammon, set out for western Virginia (today part of West Virginia) in July 1861 as a part of the Kanawha Division. McKinley initially thought Scammon was a martinet, but when the regiment finally saw battle, he came to appreciate the value of their relentless drilling. Their first contact with the enemy came in September when they drove back Confederate troops at Carnifex Ferry in present-day West Virginia. Three days after the battle, McKinley was assigned to duty in the brigade quartermaster office, where he worked both to supply his regiment, and as a clerk. In November, the regiment established winter quarters near Fayetteville (today in West Virginia). McKinley spent the winter substituting for a commissary sergeant who was ill, and in April 1862 he was promoted to that rank. The regiment resumed its advance that spring with Hayes in command (Scammon by then led the brigade) and fought several minor engagements against the rebel forces.
That September, McKinley's regiment was called east to reinforce General John Pope's Army of Virginia at the Second Battle of Bull Run. Delayed in passing through Washington, D.C., the 23rd Ohio did not arrive in time for the battle, but joined the Army of the Potomac as it hurried north to cut off Robert E. Lee's Army of Northern Virginia as it advanced into Maryland. The 23rd was the first regiment to encounter the Confederates at the Battle of South Mountain on September 14. After severe losses, Union forces drove back the Confederates and continued to Sharpsburg, Maryland, where they engaged Lee's army at the Battle of Antietam, one of the bloodiest battles of the war. The 23rd was also in the thick of the fighting at Antietam, and McKinley himself came under heavy fire when bringing rations to the men on the line. McKinley's regiment again suffered many casualties, but the Army of the Potomac was victorious and the Confederates retreated into Virginia. The regiment was then detached from the Army of the Potomac and returned by train to western Virginia.
Shenandoah Valley and promotion.
While the regiment went into winter quarters near Charleston, Virginia (present-day West Virginia), McKinley was ordered back to Ohio with some other sergeants to recruit fresh troops. When they arrived in Columbus, Governor David Tod surprised McKinley with a commission as second lieutenant in recognition of his service at Antietam. McKinley and his comrades saw little action until July 1863, when the division skirmished with John Hunt Morgan's cavalry at the Battle of Buffington Island. Early in 1864, the Army command structure in West Virginia was reorganized, and the division was assigned to George Crook's Army of West Virginia. They soon resumed the offensive, marching into southwestern Virginia to destroy salt and lead mines used by the enemy. On May 9, the army engaged Confederate troops at Cloyd's Mountain, where the men charged the enemy entrenchments and drove the rebels from the field. McKinley later said the combat there was "as desperate as any witnessed during the war." Following the rout, the Union forces destroyed Confederate supplies and skirmished with the enemy again successfully.
McKinley and his regiment moved to the Shenandoah Valley as the armies broke from winter quarters to resume hostilities. Crook's corps was attached to Major General David Hunter's Army of the Shenandoah and soon back in contact with Confederate forces, capturing Lexington, Virginia, on June 11. They continued south toward Lynchburg, tearing up railroad track as they advanced. Hunter believed the troops at Lynchburg were too powerful, however, and the brigade returned to West Virginia. Before the army could make another attempt, Confederate General Jubal Early's raid into Maryland forced their recall to the north. Early's army surprised them at Kernstown on July 24, where McKinley came under heavy fire and the army was defeated. Retreating into Maryland, the army was reorganized again: Major General Philip Sheridan replaced Hunter, and McKinley, who had been promoted to captain after the battle, was transferred to General Crook's staff. By August, Early was retreating south in the valley, with Sheridan's army in pursuit. They fended off a Confederate assault at Berryville, where McKinley had a horse shot out from under him, and advanced to Opequon Creek, where they broke the enemy lines and pursued them farther south. They followed up the victory with another at Fisher's Hill on September 22, and were engaged once more at Cedar Creek on October 19. After initially falling back from the Confederate advance, McKinley helped to rally the troops and turn the tide of the battle.
After Cedar Creek, the army stayed in the vicinity through election day, when McKinley cast his first presidential ballot, for the incumbent Republican, Abraham Lincoln. The next day, they moved north up the valley into winter quarters near Kernstown. In February 1865, Crook was captured by Confederate raiders. Crook's capture added to the confusion as the army was reorganized for the spring campaign, and McKinley found himself serving on the staffs of four different generals over the next fifteen days — Crook, John D. Stevenson, Samuel S. Carroll, and Winfield S. Hancock. Finally assigned to Carroll's staff again, McKinley acted as the general's first and only adjutant. Lee and his army surrendered to General Ulysses S. Grant a few days later, effectively ending the war. McKinley found time to join a Freemason lodge (later renamed after him) in Winchester, Virginia, before he and Carroll were transferred to Hancock's First Veterans Corps in Washington. Just before the war's end, McKinley received his final promotion, a brevet commission as major. In July, the Veterans Corps was mustered out of service, and McKinley and Carroll were relieved of their duties. Carroll and Hancock encouraged McKinley to apply for a place in the peacetime army, but he declined and returned to Ohio the following month.
Legal career and marriage.
After the war ended in 1865, McKinley decided on a career in the law and began studying in the office of an attorney in Poland, Ohio. The following year, he continued his studies by attending Albany Law School in New York. After studying there for less than a year, McKinley returned home and was admitted to the bar in Warren, Ohio, in March 1867. That same year, he moved to Canton, the county seat of Stark County, and set up a small office. He soon formed a partnership with George W. Belden, an experienced lawyer and former judge. His practice was successful enough for him to buy a block of buildings on Main Street in Canton, which provided him with a small but consistent rental income for decades to come. When his Army friend Rutherford B. Hayes was nominated for governor in 1867, McKinley made speeches on his behalf in Stark County, his first foray into politics. The county was closely divided between Democrats and Republicans, but Hayes carried it that year in his statewide victory. In 1869, McKinley ran for the office of prosecuting attorney of Stark County, an office usually then held by Democrats, and was unexpectedly elected. When McKinley ran for re-election in 1871, the Democrats nominated William A. Lynch, a prominent local lawyer, and McKinley was defeated by 143 votes.
As McKinley's professional career progressed, so too did his social life blossom as he wooed Ida Saxton, the daughter of a prominent Canton family. They were married on January 25, 1871, in the newly built First Presbyterian Church of Canton, although Ida soon joined her husband's Methodist church. Their first child, Katherine, was born on Christmas Day 1871. A second daughter, Ida, followed in 1873, but died the same year. McKinley's wife descended into a deep depression at her baby's death and her health, never robust, grew worse. Two years later, in 1875, Katherine died of typhoid fever. Ida never recovered from her daughters' deaths; the McKinleys had no more children. Ida McKinley developed epilepsy around the same time and thereafter disliked her husband's leaving her side. He remained a devoted husband and tended to his wife's medical and emotional needs for the rest of his life.
Ida insisted that McKinley continue his increasingly successful career in law and politics. He attended the state Republican convention that nominated Hayes for a third term as governor in 1875, and campaigned again for his old friend in the election that fall. The next year, McKinley undertook a high-profile case defending a group of coal miners arrested for rioting after a clash with strikebreakers. Lynch, McKinley's opponent in the 1871 election, and his partner, William R. Day, were the opposing counsel, and the mine owners included Mark Hanna, a Cleveland businessman. Taking the case "pro bono," he was successful in getting all but one of the miners acquitted. The case raised McKinley's standing among laborers, a crucial part of the Stark County electorate, and also introduced him to Hanna, who would become his strongest backer in years to come.
McKinley's good standing with labor became useful that year as he campaigned for the Republican nomination for Ohio's 17th congressional district. Delegates to the county conventions thought he could attract blue-collar voters, and in August 1876, McKinley was nominated. By that time, Hayes had been nominated for president, and McKinley campaigned for him while running his own congressional campaign. Both were successful. McKinley, campaigning mostly on his support for a protective tariff, defeated the Democratic nominee, Levi L. Lamborn, by 3,300 votes, while Hayes won a hotly disputed election to reach the presidency. McKinley's victory came at a personal cost: his income as a congressman would be half of what he earned as a lawyer.
Rising politician 1877–1895.
Spokesman for protection.
"Under free trade the trader is the master and the producer the slave. Protection is but the law of nature, the law of self-preservation, of self-development, of securing the highest and best destiny of the race of man. is said that protection is immoral... Why, if protection builds up and elevates 63,000,000 U.S. population of people, the influence of those 63,000,000 of people elevates the rest of the world. We cannot take a step in the pathway of progress without benefiting mankind everywhere. Well, they say, 'Buy where you can buy the cheapest'... Of course, that applies to labor as to everything else. Let me give you a maxim that is a thousand times better than that, and it is the protection maxim: 'Buy where you can pay the easiest.' And that spot of earth is where labor wins its highest rewards."
McKinley first took his congressional seat in October 1877, when President Hayes summoned Congress into special session. With the Republicans in the minority, McKinley was given unimportant committee assignments, which he undertook conscientiously. McKinley's friendship with Hayes did McKinley little good on Capitol Hill; the President was not well-regarded by many leaders there. The young congressman broke with Hayes on the question of the currency, but it did not affect their friendship. The United States had effectively been placed on the gold standard by the Coinage Act of 1873; when silver prices dropped significantly, many sought to make silver again a legal tender, equally with gold. Such a course would be inflationary, but advocates argued that the economic benefits of the increased money supply would be worth the inflation; opponents warned that "free silver" would not bring the promised benefits and would harm the United States in international trade. McKinley voted for the Bland-Allison Act of 1878, which mandated large government purchases of silver for striking into money, and also joined the large majorities in each house that overrode Hayes' veto of the legislation. In so doing, McKinley voted against the position of the House Republican leader, his fellow Ohioan and friend, James Garfield.
From his first term in Congress, McKinley was a strong advocate of protective tariffs. The primary purposes of such imposts was not to raise revenue, but to allow American manufacturing to develop by giving it a price advantage in the domestic market over foreign competitors. McKinley biographer Margaret Leech noted that Canton had become prosperous as a center for the manufacture of farm equipment because of protection, and that this may have helped form his political views. McKinley introduced and supported bills that raised protective tariffs, and opposed those that lowered them or imposed tariffs simply to raise revenue. Garfield's election as president in 1880 created a vacancy on the House Ways and Means Committee; McKinley was selected to fill it, placing him on the most powerful committee after only two terms.
McKinley increasingly became a significant figure in national politics. In 1880, he served a brief term as Ohio's representative on the Republican National Committee. In 1884, he was elected a delegate to that year's Republican convention, where he served as chair of the Committee on Resolutions and won plaudits for his handling of the convention when called upon to preside. By 1886, McKinley, Senator John Sherman, and Governor Joseph B. Foraker were considered the leaders of the Republican party in Ohio. Sherman, who had helped to found the Republican Party, ran three times for the Republican nomination for president in the 1880s, each time failing, while Foraker began a meteoric rise in Ohio politics early in the decade. Hanna, once he entered public affairs as a political manager and generous contributor, supported Sherman's ambitions, as well as those of Foraker. The latter relationship broke off at the 1888 Republican National Convention, where McKinley, Foraker, and Hanna were all delegates supporting Sherman. Convinced Sherman could not win, Foraker threw his support to the unsuccessful Republican 1884 presidential nominee, Maine Senator James G. Blaine. When Blaine stated he was not a candidate, Foraker returned to Sherman, but the nomination went to former Indiana senator Benjamin Harrison, who was elected president. In the bitterness that followed the convention, Hanna abandoned Foraker, and for the rest of McKinley's life, the Ohio Republican Party was divided into two factions, one aligned with McKinley, Sherman, and Hanna and the other with Foraker. Hanna came to admire McKinley and became a friend and close adviser to him. Although Hanna remained active in business and in promoting other Republicans, in the years after 1888, he spent an increasing amount of time boosting McKinley's political career.
In 1889, with the Republicans in the majority, McKinley sought election as Speaker of the House. He failed to gain the post, which went to Thomas B. Reed of Maine; however, Speaker Reed appointed McKinley chairman of the Ways and Means Committee. The Ohioan guided the McKinley Tariff of 1890 through Congress; although McKinley's work was altered through the influence of special interests in the Senate, it imposed a number of protective tariffs on foreign goods.
Gerrymandering and defeat for re-election.
Recognizing McKinley's potential, the Democrats, whenever they controlled the Ohio legislature, sought to gerrymander or redistrict him out of office. In 1878, McKinley faced election in a redrawn 17th district; he won anyway, causing Hayes to exult, "Oh, the good luck of McKinley! He was gerrymandered out and then beat the gerrymander! We enjoyed it as much as he did." After the 1882 election, McKinley was unseated on an election contest by a near party-line House vote. Out of office, he was briefly depressed by the setback, but soon vowed to run again. The Democrats again redistricted Stark County for the 1884 election; McKinley was returned to Congress anyway.
For 1890, the Democrats gerrymandered McKinley one final time, placing Stark County in the same district as one of the strongest pro-Democrat counties, Holmes, populated by solidly Democratic Pennsylvania Dutch. The new boundaries seemed good, based on past results, for a Democratic majority of 2000 to 3000. The Republicans could not reverse the gerrymander as legislative elections would not be held until 1891, but they could throw all their energies into the district, as the McKinley Tariff was a main theme of the Democratic campaign nationwide, and there was considerable attention paid to McKinley's race. The Republican Party sent its leading orators to Canton, including Blaine (then Secretary of State), Speaker Reed and President Harrison. The Democrats countered with their best spokesmen on tariff issues. McKinley tirelessly stumped his new district, reaching out to its 40,000 voters to explain that his tariff
Democrats ran a strong candidate in former lieutenant governor John G. Warwick. To drive their point home, they hired young partisans to pretend to be peddlers, who went door to door offering 25-cent tinware to housewives for 50 cents, explaining the rise in prices was due to the McKinley Tariff. In the end, McKinley lost by 300 votes, but the Republicans won a statewide majority and claimed a moral victory.
Governor of Ohio.
Even before McKinley completed his term in Congress, he met with a delegation of Ohioans urging him to run for governor. Governor James E. Campbell, a Democrat, who had defeated Foraker in 1889, was to seek re-election in 1891. The Ohio Republican party remained divided, but McKinley quietly arranged for Foraker to nominate him at the 1891 state Republican convention, which chose McKinley by acclamation. The former congressman spent much of the second half of 1891 campaigning against Campbell, beginning in his birthplace of Niles. Hanna, however, was little seen in the campaign; he spent much of his time raising funds for the election of legislators pledged to vote for Sherman in the 1892 senatorial election. McKinley won the 1891 election by some 20,000 votes; the following January, Sherman, with considerable assistance from Hanna, turned back a challenge by Foraker to win the legislature's vote for another term in the Senate.
Ohio's governor had relatively little power—for example, he could recommend legislation, but not veto it—but with Ohio a key swing state, its governor was a major figure in national politics. Although McKinley believed that the health of the nation depended on that of business, he was evenhanded in dealing with labor. He procured legislation that set up an arbitration board to settle work disputes and obtained passage of a law that fined employers who fired workers for belonging to a union.
President Harrison had proven unpopular; there were divisions even within the Republican party as the year 1892 began and Harrison began his re-election drive. Although no declared candidate opposed Harrison, many Republicans were ready to dump the President from the ticket if an alternative emerged. Among the possible candidates spoken of were McKinley, Reed, and the aging Blaine. Fearing that the Ohio governor would emerge as a candidate, Harrison's managers arranged for McKinley to be permanent chairman of the convention in Minneapolis, requiring him to play a public, neutral role. Hanna established an unofficial McKinley headquarters near the convention hall, though no active effort was made to convert delegates to McKinley's cause. McKinley objected to delegate votes being cast for him; nevertheless he finished third, behind the renominated Harrison, and behind Blaine, who had sent word he did not want to be considered. Although McKinley campaigned loyally for the Republican ticket, Harrison was defeated by former President Cleveland in the November election. In the wake of Cleveland's victory, McKinley was seen by some as the likely Republican candidate in 1896.
Soon after Cleveland's return to office, hard times struck the nation with the Panic of 1893. A businessman in Youngstown, Robert Walker, had lent money to McKinley in their younger days; in gratitude, McKinley had often guaranteed Walker's borrowings for his business. The governor had never kept track of what he was signing; he believed Walker a sound businessman. In fact, Walker had deceived McKinley, telling him that new notes were actually renewals of matured ones. Walker was ruined by the recession; McKinley was called upon for repayment in February 1893. The total owed was over $100,000 and a despairing McKinley initially proposed to resign as governor and earn the money as an attorney. Instead, McKinley's wealthy supporters, including Hanna and Chicago publisher H. H. Kohlsaat, became trustees of a fund from which the notes would be paid. Both William and Ida McKinley placed their property in the hands of the fund's trustees (who included Hanna and Kohlsaat), and the supporters raised and contributed a substantial sum of money. All of the couple's property was returned to them by the end of 1893, and when McKinley, who had promised eventual repayment, asked for the list of contributors, it was refused him. Many people who had suffered in the hard times sympathized with McKinley, whose popularity grew. He was easily re-elected in November 1893, receiving the largest percentage of the vote of any Ohio governor since the Civil War.
McKinley campaigned widely for Republicans in the 1894 midterm congressional elections; many party candidates in districts where he spoke were successful. His political efforts in Ohio were rewarded with the election in November 1895 of a Republican successor as governor, Asa Bushnell, and a Republican legislature that elected Foraker to the Senate. McKinley supported Foraker for Senate and Bushnell (who was of Foraker's faction) for governor; in return, the new senator-elect agreed to back McKinley's presidential ambitions. With party peace in Ohio assured, McKinley turned to the national arena.
Election of 1896.
Obtaining the nomination.
It is unclear when William McKinley began to seriously prepare a run for president. As Phillips notes, "no documents, no diaries, no confidential letters to Mark Hanna (or anyone else) contain his secret hopes or veiled stratagems." From the beginning, McKinley's preparations had the participation of Hanna, whose biographer William T. Horner noted, "what is certainly true is that in 1888 the two men began to develop a close working relationship that helped put McKinley in the White House." Sherman did not run for president again after 1888, and so Hanna could support McKinley's ambitions for that office wholeheartedly.
Backed by Hanna's money and organizational skills, McKinley quietly built support for a presidential bid through 1895 and early 1896. When other contenders such as Speaker Reed and Iowa Senator William B. Allison sent agents outside their states to organize Republicans in support of their candidacies, they found that Hanna's agents had preceded them. According to historian Stanley Jones in his study of the 1896 election,
Hanna, on McKinley's behalf, met with the eastern Republican political bosses, such as Senators Thomas Platt of New York and Matthew Quay of Pennsylvania, who were willing to guarantee McKinley's nomination in exchange for promises regarding patronage and offices. McKinley, however, was determined to obtain the nomination without making deals, and Hanna accepted that decision. Many of their early efforts were focused on the South; Hanna obtained a vacation home in southern Georgia where McKinley visited and met with Republican politicians from the region. McKinley needed 453½ delegate votes to gain the nomination; he gained nearly half that number from the South and border states. Platt lamented in his memoirs, " had the South practically solid before some of us awakened."
The bosses still hoped to deny McKinley a first-ballot majority at the convention by boosting support for local favorite son candidates such as Quay, New York Governor (and former vice president) Levi P. Morton, and Illinois Senator Shelby Cullom. Delegate-rich Illinois proved a crucial battleground, as McKinley supporters, such as Chicago businessman (and future vice president) Charles G. Dawes, sought to elect delegates pledged to vote for McKinley at the national convention in St. Louis. Cullom proved unable to stand against McKinley despite the support of local Republican machines; at the state convention at the end of April, McKinley completed a near-sweep of Illinois' delegates. Former president Harrison had been deemed a possible contender if he entered the race; when Harrison made it known he would not seek a third nomination, the McKinley organization took control of Indiana with a speed Harrison privately found unseemly. Morton operatives who journeyed to Indiana sent word back that they had found the state alive for McKinley. Wyoming Senator Francis Warren wrote, "The politicians are making a hard fight against him, but if the masses could speak, McKinley is the choice of at least 75% of the entire of Republican voters in the Union".
By the time the national convention began in St. Louis on June 16, 1896, McKinley had an ample majority of delegates. The former governor, who remained in Canton, followed events at the convention closely by telephone, and was able to hear part of Foraker's speech nominating him over the line. When Ohio was reached in the roll call of states, its votes gave McKinley the nomination, which he celebrated by hugging his wife and mother as his friends fled the house, anticipating the first of many crowds that gathered at the Republican candidate's home. Thousands of partisans came from Canton and surrounding towns that evening to hear McKinley speak from his front porch. The convention nominated Republican National Committee vice chairman Garret Hobart of New Jersey for vice president, a choice actually made, by most accounts, by Hanna. Hobart, a wealthy lawyer, businessman, and former state legislator, was not widely known, but as Hanna biographer Herbert Croly pointed out, "if he did little to strengthen the ticket he did nothing to weaken it".
General election campaign.
Before the Republican convention, McKinley had been a "straddle bug" on the currency question, favoring moderate positions on silver such as accomplishing bimetallism by international agreement. In the final days before the convention, McKinley decided, after hearing from politicians and businessmen, that the platform should endorse the gold standard, though it should allow for bimetallism by international agreement. Adoption of the platform caused some western delegates, led by Colorado Senator Henry M. Teller, to walk out of the convention. However, compared with the Democrats, Republican divisions on the issue were small, especially as McKinley promised future concessions to silver advocates.
The bad economic times had continued, and strengthened the hand of forces for free silver. The issue bitterly divided the Democratic Party; President Cleveland firmly supported the gold standard, but an increasing number of rural Democrats wanted silver, especially in the South and West. The silverites took control of the 1896 Democratic National Convention and chose William Jennings Bryan for president; he had electrified the delegates with his Cross of Gold speech. Bryan's financial radicalism shocked bankers—they thought his inflationary program would bankrupt the railroads and ruin the economy. Hanna approached them for support for his strategy to win the election, and they gave $3.5 million for speakers and over 200 million pamphlets advocating the Republican position on the money and tariff questions.
Bryan's campaign had at most an estimated $500,000. With his eloquence and youthful energy his major assets in the race, Bryan decided on a whistle-stop political tour by train on an unprecedented scale. Hanna urged McKinley to match Bryan's tour with one of his own; the candidate declined on the grounds that the Democrat was a better stump speaker: "I might just as well set up a trapeze on my front lawn and compete with some professional athlete as go out speaking against Bryan. I have to "think" when I speak." Instead of going to the people, McKinley would remain at home in Canton and allow the people to come to him; according to historian R. Hal Williams in his book on the 1896 election, "it was, as it turned out, a brilliant strategy. McKinley's 'Front Porch Campaign' became a legend in American political history."
McKinley made himself available to the public every day except Sunday, receiving delegations from the front porch of his home. The railroads subsidized the visitors with low excursion rates—the pro-silver Cleveland "Plain Dealer" disgustedly stated that going to Canton had been made "cheaper than staying at home". Delegations marched through the streets from the railroad station to McKinley's home on North Market Street. Once there, they crowded close to the front porch—from which they surreptitiously whittled souvenirs—as their spokesman addressed McKinley. The candidate then responded, speaking on campaign issues in a speech molded to suit the interest of the delegation. The speeches were carefully scripted to avoid extemporaneous remarks; even the spokesman's remarks were approved by McKinley or a representative. This was done as the candidate feared an offhand comment by another that might rebound on him.
Most Democratic newspapers refused to support Bryan, the major exception being the New York "Journal", controlled by William Randolph Hearst, whose fortune was based on silver mines. In biased reporting and through the sharp cartoons of Homer Davenport, Hanna was viciously characterized as a plutocrat, trampling on labor. McKinley was drawn as a child, easily controlled by big business. Even today, these depictions still color the images of Hanna and McKinley: one as a heartless businessman, the other as a creature of Hanna and others of his ilk.
The Democrats had pamphlets too, though not as many. Jones analyzed how voters responded to the education campaigns of the two parties:
The battleground proved to be the Midwest — the South and most of the West were conceded to Bryan — and the Democrat spent much of his time in those crucial states. The Northeast was considered most likely safe for McKinley after the early-voting states of Maine and Vermont supported him in September. By then, it was clear that public support for silver had receded, and McKinley began to emphasize the tariff issue. By the end of September, the Republicans had discontinued printing material on the silver issue, and were entirely concentrating on the tariff question. On November 3, 1896, the voters had their say in most of the nation. McKinley won the entire Northeast and Midwest; he won 51% of the vote and an ample majority in the Electoral College. Bryan had concentrated entirely on the silver issue, and had not appealed to urban workers. Voters in cities supported McKinley; the only city outside the South of more than 100,000 population carried by Bryan was Denver, Colorado.
The 1896 presidential election is often seen as a realigning election, in which McKinley's view of a stronger central government building American industry through protective tariffs and a dollar based on gold triumphed. The voting patterns established then displaced the near-deadlock the major parties had seen since the Civil War; the Republican dominance begun then would continue until 1932, another realigning election with the ascent of Franklin Roosevelt. Phillips argues that, with the possible exception of Iowa Senator Allison, McKinley was the only Republican who could have defeated Bryan—he theorized that eastern candidates such as Morton or Reed would have done badly against the Illinois-born Bryan in the crucial Midwest. According to the biographer, though Bryan was popular among rural voters, "McKinley appealed to a very different industrialized, urbanized America."
Presidency (1897–1901).
Inauguration and appointments.
McKinley was sworn in as president on March 4, 1897, as his wife and mother looked on. The new President gave a lengthy inaugural address; he urged tariff reform, and stated that the currency issue would have to await tariff legislation. He warned against foreign interventions, "We want no wars of conquest. We must avoid the temptation of territorial aggression."
McKinley's most controversial Cabinet appointment was that of John Sherman as Secretary of State. Sherman was not McKinley's first choice for the position; he initially offered it to Senator Allison. One consideration in Senator Sherman's appointment was to provide a place in the Senate for Hanna (who had turned down a Cabinet position as Postmaster General). As Sherman had served as Secretary of the Treasury under Hayes, only the State position, the leading Cabinet post, was likely to entice him from the Senate. Sherman's mental faculties were decaying even in 1896; this was widely spoken of in political circles, but McKinley did not believe the rumors. Nevertheless, McKinley sent his cousin, William McKinley Osborne, to have dinner with the 73-year-old senator; he reported back that Sherman seemed as lucid as ever. McKinley wrote once the appointment was announced, "the stories regarding Senator Sherman's 'mental decay' are without foundation ... When I saw him last I was convinced both of his perfect health, physically and mentally, and that the prospects of life were remarkably good."
After some difficulties, Ohio Governor Bushnell appointed Hanna to the Senate. Once in Cabinet office, Sherman's mental incapacity became increasingly apparent. He was often bypassed by his first assistant, McKinley's Canton crony Judge William Day, and by the second secretary, Alvey A. Adee. Day, an Ohio lawyer unfamiliar with diplomacy, was often reticent in meetings; Adee was somewhat deaf. One diplomat characterized the arrangement, "the head of the department knew nothing, the first assistant said nothing, and the second assistant heard nothing".
Maine Congressman Nelson Dingley Jr. was McKinley's choice for Secretary of the Treasury; he declined it, preferring to remain as chairman of the Ways and Means Committee. Charles Dawes, who had been Hanna's lieutenant in Chicago during the campaign, was considered for the Treasury post but by some accounts Dawes considered himself too young. Dawes eventually became Comptroller of the Currency; he recorded in his published diary that he had strongly urged McKinley to appoint as secretary the successful candidate, Lyman J. Gage, president of the First National Bank of Chicago and a Gold Democrat. The Navy Department was offered to former Massachusetts Congressman John Davis Long, an old friend from the House, on January 30, 1897. Although McKinley was initially inclined to allow Long to choose his own assistant, there was considerable pressure on the President-elect to appoint Theodore Roosevelt, head of the New York City Police Commission and a former state assemblyman. McKinley was reluctant, stating to one Roosevelt booster, "I want peace and I am told that your friend Theodore is always getting into rows with everybody." Nevertheless, he made the appointment.
In addition to Sherman, McKinley made one other ill-advised Cabinet appointment, that of Secretary of War, which fell to Russell A. Alger, former general and Michigan governor. Competent enough in peacetime, Alger proved inadequate once the conflict with Spain began. With the War Department plagued by scandal, Alger resigned at McKinley's request in mid-1899. Vice President Hobart, as was customary at the time, was not invited to Cabinet meetings. However, he proved a valuable adviser both for McKinley and for his Cabinet members. The wealthy Vice President leased a residence close to the White House; the two families visited each other without formality, and the Vice President's wife, Jennie Tuttle Hobart, sometimes substituted as Executive Mansion hostess when Ida McKinley was unwell. For most of McKinley's administration, George B. Cortelyou served as his personal secretary. Cortelyou, who served in three Cabinet positions under Theodore Roosevelt, became a combination press secretary and chief of staff to McKinley.
War with Spain.
For decades, rebels in Cuba had waged an intermittent campaign for freedom from Spanish colonial rule. By 1895, the conflict had expanded to a war for Cuban independence. As war engulfed the island, Spanish reprisals against the rebels grew ever harsher. These included the removal of Cubans to internment camps near Spanish military bases, a strategy designed to make it hard for the rebels to receive support in the countryside. American opinion favored the rebels, and McKinley shared in their outrage against Spanish policies. As many of his countrymen called for war to liberate Cuba, McKinley favored a peaceful approach, hoping that through negotiation, Spain might be convinced to grant Cuba independence, or at least to allow the Cubans some measure of autonomy. The United States and Spain began negotiations on the subject in 1897, but it became clear that Spain would never concede Cuban independence, while the rebels (and their American supporters) would never settle for anything less.
In January 1898, Spain promised some concessions to the rebels, but when American consul Fitzhugh Lee reported riots in Havana, McKinley agreed to send the battleship USS "Maine" there to protect American lives and property. On February 15, the "Maine" exploded and sank with 266 men killed. Public opinion and the newspapers demanded war, but McKinley insisted that a court of inquiry first determine whether the explosion was accidental. Negotiations with Spain continued as the court considered the evidence, but on March 20, the court ruled that the "Maine" was blown up by an underwater mine. As pressure for war mounted in Congress, McKinley continued to negotiate for Cuban independence. Spain refused McKinley's proposals, and on April 11, McKinley turned the matter over to Congress. He did not ask for war, but Congress declared war anyway on April 20, with the addition of the Teller Amendment, which disavowed any intention of annexing Cuba.
The expansion of the telegraph and the development of the telephone gave McKinley a greater control over the day-to-day management of the war than previous presidents had enjoyed, and he used the new technologies to direct the army's and navy's movements as far as he was able. McKinley found Alger inadequate as Secretary of War, and did not get along with the Army's commanding general, Nelson A. Miles. Bypassing them, he looked for strategic advice first from Miles's predecessor, General John Schofield, and later from Adjutant General Henry Clarke Corbin. The war led to a change in McKinley's cabinet, as the President accepted Sherman's resignation as Secretary of State; Day agreed to serve as Secretary until the war's end.
Within a fortnight, the navy had its first victory when the Asiatic Squadron, led by Commodore George Dewey, engaged the Spanish navy at the Battle of Manila Bay in the Philippines, destroying the enemy force without the loss of a single American vessel. Dewey's overwhelming victory expanded the scope of the war from one centered in the Caribbean to one that would determine the fate of all of Spain's Pacific colonies. The next month, he increased the number of troops sent to the Philippines and granted the force's commander, Major General Wesley Merritt, the power to set up legal systems and raise taxes—necessities for a long occupation. By the time the troops arrived in the Philippines at the end of June 1898, McKinley had decided that Spain would be required to surrender the archipelago to the United States. He professed to be open to all views on the subject; however, he believed that as the war progressed, the public would come to demand retention of the islands as a prize of war.
Meanwhile, in the Caribbean theater, a large force of regulars and volunteers gathered near Tampa, Florida, for an invasion of Cuba. The army faced difficulties in supplying the rapidly expanding force even before they departed for Cuba, but by June, Corbin had made progress in resolving the problems. After lengthy delays, the army, led by Major General William Rufus Shafter, sailed from Florida on June 20, landing near Santiago de Cuba two days later. Following a skirmish at Las Guasimas on June 24, Shafter's army engaged the Spanish forces on July 2 in the Battle of San Juan Hill. In an intense day-long battle, the American force was victorious, although both sides suffered heavy casualties. The next day, the Spanish Caribbean squadron, which had been sheltering in Santiago's harbor, broke for the open sea but was intercepted and destroyed by Rear Admiral William T. Sampson's North Atlantic Squadron in the largest naval battle of the war. Shafter laid siege to the city of Santiago, which surrendered on July 17, placing Cuba under effective American control. McKinley and Miles also ordered an invasion of Puerto Rico, which met little resistance when it landed in July. The distance from Spain and the destruction of the Spanish navy made resupply impossible, and the Spanish government began to look for a way to end the war.
Peace and territorial gain.
On July 22, the Spanish authorized Jules Cambon, the French Ambassador to the United States, to represent Spain in negotiating peace. The Spanish initially wished to restrict the discussion to Cuba, but were quickly forced to recognize that their other possessions would be claimed as spoils of war. McKinley's cabinet agreed with him that Spain must leave Cuba and Puerto Rico, but they disagreed on the Philippines, with some wishing to annex the entire archipelago and some wishing only to retain a naval base in the area. Although public sentiment seemed to favor annexation of the Philippines, several prominent political leaders – including Bryan, ex-President Grover Cleveland, and the newly formed American Anti-Imperialist League – made their opposition known.
McKinley proposed to open negotiations with Spain on the basis of Cuban liberation and Puerto Rican annexation, with the final status of the Philippines subject to further discussion. He stood firmly in that demand even as the military situation on Cuba began to deteriorate when the American army was struck with yellow fever. Spain ultimately agreed to a ceasefire on those terms on August 12, and treaty negotiations began in Paris in September 1898. The talks continued until December 18, when the Treaty of Paris was signed. The United States acquired Puerto Rico and the Philippines as well as the island of Guam, and Spain relinquished its claims to Cuba; in exchange, the United States agreed to pay Spain $20 million. McKinley had difficulty convincing the Senate to approve the treaty by the requisite two-thirds vote, but his lobbying, and that of Vice President Hobart, eventually saw success, as the Senate voted in favor on February 6, 1899, 57 to 27.
During the war, McKinley also pursued the annexation of the Republic of Hawaii. The new republic, dominated by American interests, had seized power from the royal government in 1893. The lame-duck Harrison administration had submitted a treaty of annexation to the Senate; Cleveland, once he returned to office, had sent a special commission to the islands. After receiving the report, Cleveland withdrew the treaty, stating that the revolution did not reflect the will of Hawaiian citizens. Nevertheless, many Americans favored annexation, and the cause gained momentum as the United States became embroiled in war with Spain. McKinley came to office as a supporter of annexation, and lobbied Congress to adopt his opinion, believing that to do nothing would invite a royalist counter-revolution or a Japanese takeover. Foreseeing difficulty in getting two-thirds of the Senate to approve a treaty of annexation, McKinley instead supported the effort of Democratic Representative Francis G. Newlands of Nevada to accomplish the result by joint resolution of both houses of Congress. The resulting Newlands Resolution passed both houses by wide margins, and McKinley signed it into law on July 8, 1898. McKinley biographer H. Wayne Morgan notes, "McKinley was the guiding spirit behind the annexation of Hawaii, showing ... a firmness in pursuing it"; the President told Cortelyou, "We need Hawaii just as much and a good deal more than we did California. It is manifest destiny." Wake Island, an uninhabited atoll between Hawaii and Guam, was claimed for the United States on July 12, 1898.
Expanding influence overseas.
In acquiring Pacific possessions for the United States, McKinley expanded the nation's ability to compete for trade in China. Even before peace negotiations began with Spain, McKinley asked Congress to set up a commission to examine trade opportunities in the region and espoused an "Open Door Policy", in which all nations would freely trade with China and none would seek to violate that nation's territorial integrity. When John Hay replaced Day as Secretary of State at the end of the war, he circulated notes to that effect to the European powers. Great Britain favored the idea, but Russia opposed it; France, Germany, Italy and Japan agreed in principle, but only if all the other nations signed on.
Trade with China became imperiled shortly thereafter as the Boxer Rebellion menaced foreigners and their property in China. Americans and other westerners in Peking were besieged and, in cooperation with other western powers, McKinley ordered 5000 troops to the city in June 1900 in the China Relief Expedition. The westerners were rescued the next month, but several Congressional Democrats objected to McKinley dispatching troops without consulting the legislature. McKinley's actions set a precedent that led to most of his successors exerting similar independent control over the military. After the rebellion ended, the United States reaffirmed its commitment to the Open Door policy, which became the basis of American policy toward China.
Closer to home, McKinley and Hay engaged in negotiations with Britain over the possible construction of a canal across Central America. The Clayton–Bulwer Treaty, which the two nations signed in 1850, prohibited either from establishing exclusive control over a canal there. The war had exposed the difficulty of maintaining a two-ocean navy without a connection closer than Cape Horn. Now, with American business and military interests even more involved in Asia, a canal seemed more essential than ever, and McKinley pressed for a renegotiation of the treaty. Hay and the British ambassador, Julian Pauncefote, agreed that the United States could control a future canal, provided that it was open to all shipping and not fortified. McKinley was satisfied with the terms, but the Senate rejected them, demanding that the United States be allowed to fortify the canal. Hay was embarrassed by the rebuff and offered his resignation, but McKinley refused it and ordered him to continue negotiations to achieve the Senate's demands. He was successful, and a new treaty was drafted and approved, but not before McKinley's assassination in 1901.
Tariffs and bimetallism.
Two of the great issues of the day, tariff reform and free silver, became intertwined in 1897. Ways and Means chairman Dingley introduced a new tariff bill (later called the Dingley Act) to revise the Wilson–Gorman Tariff Act of 1894. McKinley supported the bill, which increased tariffs on wool, sugar, and luxury goods, but the proposed new rates alarmed the French, who exported many luxury items to the United States. The Dingley Act passed the House easily, but was delayed in the Senate as they assessed the French objections. French representatives offered to cooperate with the United States in developing an international agreement on bimetallism if the new tariff rates were reduced; this pleased silverite Republicans in the Senate, whose votes were necessary for passage. The Senate amended the bill to allow limited reciprocity (giving France some possibility of relief), but did not reduce the rates on luxury goods. McKinley signed the bill into law and agreed to begin negotiations on an international bimetallism standard.
American negotiators soon concluded a reciprocity treaty with France, and the two nations approached Britain to gauge British enthusiasm for bimetallism. The Prime Minister, Lord Salisbury, and his government showed some interest in the idea and told the American envoy, Edward O. Wolcott, that he would be amenable to reopening the mints in India to silver coinage if the Viceroy's Executive Council there agreed. News of a possible departure from the gold standard stirred up immediate opposition from its partisans, and misgivings by the Indian administration led Britain to reject the proposal. With the international effort a failure, McKinley turned away from silver coinage and embraced the gold standard. Even without the agreement, agitation for free silver eased as prosperity began to return to the United States and gold from recent strikes in the Yukon and Australia increased the monetary supply even without silver coinage. In the absence of international agreement, McKinley favored legislation to formally affirm the gold standard, but was initially deterred by the silver strength in the Senate. By 1900, with another campaign ahead and good economic conditions, McKinley urged Congress to pass such a law, and was able to sign the Gold Standard Act on March 14, 1900, using a gold pen to do so.
Civil rights.
In the wake of McKinley's election in 1896, African Americans were hopeful of progress towards equality. McKinley had spoken out against lynching while governor, and most African Americans who could vote supported him in 1896. McKinley's priority, however, was in ending sectionalism, and they were disappointed by his policies and appointments. Although McKinley made some appointments of African Americans to low-level government posts, and received some praise for that, the appointments were less than they had received under previous Republican administrations. Blanche K. Bruce, an African American who during Reconstruction had served as senator from Mississippi, received the post of register at the Treasury Department; this post was traditionally given to an African American by Republican presidents. McKinley appointed several black postmasters; however, when whites protested the appointment of Justin W. Lyons as postmaster of Augusta, Georgia, McKinley asked Lyons to withdraw (he was subsequently given the post of Treasury register after Bruce's death in 1898). The President did appoint George B. Jackson, a former slave, to the post of customs collector in Presidio, Texas. However, African Americans in northern states felt that their contributions to McKinley's victory were overlooked; few were appointed to office.
The administration's response to racial violence was minimal, causing him to lose black support. When black postmasters at Hogansville, Georgia in 1897, and at Lake City, South Carolina the following year, were assaulted, McKinley issued no statement of condemnation. Although black leaders criticized McKinley for inaction, supporters responded by saying there was little the president could do to intervene. Critics replied by saying that he could at least publicly condemn such events, as Harrison had done.
According to historian Clarance A. Bacote, "Before the Spanish–American War, the Negroes, in spite of some mistakes, regarded McKinley as the best friend they ever had." African Americans saw the onset of war in 1898 as an opportunity to display their patriotism; and black soldiers fought bravely at El Caney and San Juan Hill. African Americans in the peacetime Army had formed elite units; nevertheless they were harassed by whites as they traveled from the West to Tampa for embarkation to the war. Under pressure from black leaders, McKinley required the War Department to commission black officers above the rank of lieutenant. The heroism of the black troops did not still racial tensions in the South, as the second half of 1898 saw several outbreaks of racial violence; 11 African Americans were killed in riots in Wilmington, North Carolina. McKinley toured the South in late 1898, hoping for sectional reconciliation. In addition to visiting Tuskegee Institute and black educator Booker T. Washington, he addressed the Georgia legislature, wearing a badge of gray, and visited Confederate memorials. In his tour of the South, McKinley did not mention the racial tensions or violence. Although the President received a rapturous reception from Southern whites, many African Americans, excluded from official welcoming committees, felt alienated by the President's words and actions.
According to Gould and later biographer Phillips, given the political climate in the South, with white legislatures passing segregationist laws such as that upheld in "Plessy v. Ferguson", there was little McKinley could have done to improve race relations, and he did better than later presidents Theodore Roosevelt, who doubted racial equality, and Woodrow Wilson, who supported segregation. However, Gould concluded, "McKinley lacked the vision to transcend the biases of his day and to point toward a better future for all Americans".
Judicial appointments.
After the retirement of Justice Stephen Johnson Field, McKinley appointed Attorney General Joseph McKenna to the Supreme Court of the United States in December 1897. The appointment aroused some controversy as McKenna's critics in the Senate said he was too closely associated with railroad interests and lacked the qualifications of a Supreme Court justice. Despite the objections, McKenna's nomination was approved unanimously. McKenna responded to the criticism of his legal education by taking some courses at Columbia Law School for several months before taking his seat. Along with his Supreme Court appointment, McKinley appointed six judges to the United States Courts of Appeals, and 28 judges to the United States district courts.
1900 election.
Republicans were generally successful in state and local elections around the country in 1899, and McKinley was optimistic about his chances at re-election in 1900. McKinley's popularity in his first term assured him of renomination for a second. The only question about the Republican ticket concerned the vice presidential nomination; McKinley needed a new running mate as Hobart had died in late 1899. McKinley initially favored Elihu Root, who had succeeded Alger as Secretary of War, but McKinley decided that Root was doing too good a job at the War Department to move him. He considered other prominent candidates, including Allison and Cornelius N. Bliss, but none were as popular as the Republican party's rising star, Theodore Roosevelt. After a stint as Assistant Secretary of the Navy, Roosevelt had resigned and raised a cavalry regiment; they fought bravely in Cuba, and Roosevelt returned home covered in glory. Elected governor of New York on a reform platform in 1898, Roosevelt had his eye on the presidency. Many supporters recommended him to McKinley for the second spot on the ticket, and Roosevelt believed it would be an excellent stepping stone to the presidency in 1904. McKinley remained uncommitted in public, but Hanna was firmly opposed to the New York governor. The Ohio senator considered the New Yorker overly impulsive; his stance was undermined by the efforts of political boss and New York Senator Thomas Platt, who, disliking Roosevelt's reform agenda, sought to sideline the governor by making him vice president.
When the Republican convention began in Philadelphia that June, no vice presidential candidate had overwhelming support, but Roosevelt had the broadest range of support from around the country. McKinley affirmed that the choice belonged to the convention, not to him. On June 21, McKinley was unanimously renominated and, with Hanna's reluctant acquiescence, Roosevelt was nominated for vice president on the first ballot. The Democratic convention convened the next month in Kansas City and nominated William Jennings Bryan, setting up a rematch of the 1896 contest.
The candidates were the same, but the issues of the campaign had shifted: free silver was still a question that animated many voters, but the Republicans focused on victory in war and prosperity at home as issues they believed favored their party. Democrats knew the war had been popular, even if the imperialism issue was less sure, so they focused on the issue of trusts and corporate power, painting McKinley as the servant of capital and big business. As in 1896, Bryan embarked on a speaking tour around the country while McKinley stayed at home, this time making only one speech, to accept his nomination. Roosevelt emerged as the campaign's primary speaker and Hanna helped the cause working to settle a coal miners strike in Pennsylvania. Bryan's campaigning failed to excite the voters as it had in 1896, and McKinley never doubted that he would be re-elected. On November 6, 1900, he was proven correct, winning the largest victory for any Republican since 1872. Bryan carried only four states outside the solid South, and McKinley even won Bryan's home state of Nebraska.
Second term.
Soon after his second inauguration on March 4, 1901, William and Ida McKinley undertook a six-week tour of the nation. Traveling mostly by rail, the McKinleys were to travel through the South to the Southwest, and then up the Pacific coast and east again, to conclude with a visit on June 13, 1901, to the Pan-American Exposition in Buffalo, New York. However, the First Lady fell ill in California, causing her husband to limit his public events and cancel a series of speeches he had planned to give urging trade reciprocity. He also postponed the visit to the fair until September, planning a month in Washington and two in Canton before the Buffalo visit.
Assassination and death throes.
Although McKinley enjoyed meeting the public, Cortelyou was concerned with his security due to recent assassinations by anarchists in Europe, such as the assassination of King Umberto I of Italy the previous year, and twice tried to remove a public reception from the President's rescheduled visit to the Exposition. McKinley refused, and Cortelyou arranged for additional security for the trip. On September 5, the President delivered his address at the fairgrounds, before a crowd of some 50,000 people. In his final speech, McKinley urged reciprocity treaties with other nations to assure American manufacturers access to foreign markets. He intended the speech as a keynote to his plans for a second term.
One man in the crowd, Leon Czolgosz, hoped to assassinate McKinley. He had managed to get close to the presidential podium, but did not fire, uncertain of hitting his target. Czolgosz, since hearing a speech by anarchist Emma Goldman in Cleveland, had decided to do something heroic (in his own mind) for the cause. After his failure to get close enough on the fifth, Czolgosz waited the next day at the Temple of Music on the Exposition grounds, where the President was to meet the public. Czolgosz concealed his gun in a handkerchief, and, when he reached the head of the line, shot McKinley twice in the abdomen.
McKinley urged his aides to break the news gently to Ida, and to call off the mob that had set on Czolgosz—a request that may have saved his assassin's life. McKinley was taken to the Exposition aid station, where the doctor was unable to locate the second bullet. Although a primitive X-ray machine was being exhibited on the Exposition grounds, it was not used. McKinley was taken to the Milburn House.
In the days after the shooting McKinley appeared to improve. Doctors issued increasingly optimistic bulletins. Members of the Cabinet, who had rushed to Buffalo on hearing the news, dispersed; Vice President Roosevelt departed on a camping trip to the Adirondacks. Leech wrote, 
Unknown to the doctors, the gangrene that would kill him was growing on the walls of his stomach, slowly poisoning his blood. On the morning of September 13, McKinley took a turn for the worse. Relatives and friends gathered around the death bed.
At 2:15 a.m. on September 14, President McKinley died. Theodore Roosevelt had rushed back and took the oath of office as president in Buffalo. Czolgosz, put on trial for murder nine days after McKinley's death, was found guilty, sentenced to death on September 26, and executed by electric chair on October 29, 1901.
Funeral, memorials, and legacy.
Funeral and resting place.
According to Gould, "The nation experienced a wave of genuine grief at the news of McKinley's passing." The stock market, faced with sudden uncertainty, suffered a steep decline—almost unnoticed in the mourning. The nation focused its attention on the casket that made its way by train, first to Washington, where it first lay in the East Room of the Executive Mansion, and then in state in the Capitol, and then was taken to Canton. A hundred thousand people passed by the open casket in the Capitol Rotunda, many having waited hours in the rain; in Canton, an equal number did the same at the Stark County Courthouse on September 18. The following day, a funeral service was held at the First Methodist Church; the casket was then sealed and taken to the McKinley house, where relatives paid their final respects. It was then transported to the receiving vault at West Lawn Cemetery in Canton, to await the construction of the memorial to McKinley already being planned.
There was a widespread expectation that Ida McKinley would not long survive her husband; one family friend stated, as William McKinley lay dying, that they should be prepared for a double funeral. This did not occur; the former first lady accompanied her husband on the funeral train. Leech noted "the circuitous journey was a cruel ordeal for the woman who huddled in a compartment of the funeral train, praying that the Lord would take her with her Dearest Love". She was thought too weak to attend the services in Washington or Canton, although she listened at the door to the service for her husband in her house on North Market Street. She remained in Canton for the remainder of her life, setting up a shrine in her house, and often visiting the receiving vault, until her death at age 59 on May 26, 1907. She died only months before the completion of the large marble monument to her husband in Canton, which was dedicated by President Roosevelt on September 30, 1907. William and Ida McKinley are interred there with their daughters, atop a hillside overlooking the city of Canton.
Other memorials.
In addition to the Canton site there are many memorials to McKinley. There is a monument at his birthplace in Niles; 20 Ohio schools bear his name. There are several schools in the United States named McKinley School. Nearly a million dollars was pledged by contributors or allocated from public funds for the construction of McKinley memorials in the year after his death. Phillips suggests the significant number of major memorials to McKinley in Ohio reflected the expectation among Ohioans in the years after McKinley's death that he would be ranked among the great presidents. Statues to him may be found in more than a dozen states; his name has been bestowed on streets, civic organizations, and libraries. McKinley's name is also used in the large inner-city Honolulu, Hawaii high school, President William McKinley High School.
Denali, in central Alaska, was named Mount McKinley in support of the then newly minted Republican nominee for President until The Alaska Board of Geographic Names changed the name of the mountain to Denali in 1975, which is how it was called by locals. The mountain's name was changed to Denali on the federal level by the Department of the Interior as a part of a visit to Alaska by President Barack Obama in August 2015; its summit, at , is the highest point in North America. Similarly, until its name was changed to Denali National Park on December 2, 1980, under congressional legislation signed by President Jimmy Carter, the park in which it is located was known as Mount McKinley National Park.
Legacy and historical image.
McKinley's biographer, H. Wayne Morgan remarks that McKinley died the most beloved president in history. However, the young, enthusiastic Roosevelt quickly captured public attention after his predecessor's death. The new president made little effort to secure the trade reciprocity McKinley had intended to negotiate with other nations. Controversy and public interest surrounded Roosevelt throughout the seven and a half years of his presidency as memories of McKinley faded; by 1920, according to Gould, McKinley's administration was deemed no more than "a mediocre prelude to the vigor and energy of Theodore Roosevelt's". Beginning in the 1950s, McKinley received more favorable evaluations; nevertheless, in surveys ranking American presidents, he has generally been placed near the middle, often trailing contemporaries such as Hayes and Cleveland. Morgan suggests that this relatively low ranking is due to a perception among historians that while many decisions during McKinley's presidency profoundly affected the nation's future, he more followed public opinion than led it, and that McKinley's standing has suffered from altered public expectations of the presidency.
There has been broad agreement among historians that McKinley's election was at the time of a transition between two political eras, dubbed the Third and Fourth Party Systems. Kenneth F. Warren emphasizes the national commitment to a pro-business, industrial, and modernizing program, represented by McKinley. Historian Daniel P. Klinghard argued that McKinley's personal control of the 1896 campaign gave him the opportunity to reshape the presidency—rather than simply follow the party platform—by representing himself as the voice of the people. However, more recently, as Republican political official Karl Rove exalted McKinley as the agent of sweeping political realignment in the 2000s, some scholars, such as David Mayhew, questioned whether the 1896 election truly represented a realignment, thereby placing in issue whether McKinley deserves credit for it. Historian Michael J. Korzi argued in 2005 that while it is tempting to see McKinley as the key figure in the transition from congressional domination of government to the modern, powerful president, this change was an incremental process through the late 19th and early 20th centuries.
Phillips writes that McKinley's low rating is undeserved, and that he should be ranked just after the great presidents such as Washington and Lincoln. He pointed to McKinley's success at building an electoral coalition that kept the Republicans mostly in power for a generation. Phillips believes that part of McKinley's legacy is the men he included in his administration, who dominated the Republican Party for a quarter century after his death. These officials included Cortelyou, who served in three Cabinet positions under Roosevelt, and Dawes, who became vice president under Coolidge. Other McKinley appointees who later became major figures include Day, who Roosevelt elevated to the Supreme Court where he remained nearly twenty years, and William Howard Taft, whom McKinley had made Governor-General of the Philippines and who succeeded Roosevelt as president.
A controversial aspect of McKinley's presidency is territorial expansion and the question of imperialism—with the exception of the Philippines, granted independence in 1946, the United States retains the territories taken under McKinley. The territorial expansion of 1898 is often seen by historians as the beginning of American empire. Morgan sees that historical discussion as a subset of the debate over the rise of America as a world power; he expects the debate over McKinley's actions to continue indefinitely without resolution, and notes that however one judges McKinley's actions in American expansion, one of his motivations was to change the lives of Filipinos and Cubans for the better.
Morgan alludes to the rise of interest in McKinley as part of the debate over the more assertive American foreign policy of recent decades:
Bibliography.
Books
Articles
Online

</doc>
<doc id="33522" url="https://en.wikipedia.org/wiki?curid=33522" title="William Howard Taft">
William Howard Taft

William Howard Taft (September 15, 1857 – March 8, 1930) served as the 27th President of the United States (1909–1913) and as the 10th Chief Justice of the United States Supreme Court (1921–1930), the only person to have held both offices. Taft was elected president in 1908, the chosen successor of Theodore Roosevelt, but was defeated for re-election by Woodrow Wilson in 1912 after Roosevelt split the Republican vote by running as a third-party candidate. In 1921, President Warren G. Harding appointed Taft chief justice, a position in which he served until a few weeks before his death.
Taft was born in Cincinnati in 1857, the son of Alphonso Taft, a prominent lawyer and judge. William Taft attended Yale, and after becoming a lawyer was appointed a judge while still in his twenties. He continued a rapid rise, being named Solicitor General and as a judge of the Sixth Circuit Court of Appeals. President William McKinley appointed Taft civilian governor of the Philippines. In 1904, Roosevelt made him Secretary of War and he became Roosevelt's hand-picked successor. Taft declined repeated offers of appointment to the Supreme Court, believing his political work more important.
With Roosevelt's help, Taft had little opposition for the Republican nomination for president in 1908, and easily defeated William Jennings Bryan for the presidency that November. In the White House, he focused on the Far East more than European affairs, and repeatedly intervened to prop up or remove Latin American governments. Taft sought reductions to the tariff, then a major source of governmental income, but the resulting bill was heavily influenced by special interests. His administration was filled with conflict between the conservative wing of the Republican Party, with which Taft often sympathized, and the progressive wing, to which Roosevelt moved more and more. Controversies over conservation and over antitrust cases filed by the Taft administration served to further separate the two men. Roosevelt challenged Taft for renomination in 1912. Taft used his control of the party machinery to gain a bare majority of delegates, and Roosevelt bolted the party. The split left Taft with little chance of re-election, and in Wilson's victory won only Utah and Vermont.
After leaving office, Taft returned to Yale as a professor, continuing his political activity and working against war through the League to Enforce Peace. In 1921, President Harding appointed Taft chief justice, an office he had long sought. Chief Justice Taft was a conservative on business issues, but under him, there were advances in individual rights. In poor health, he resigned in February 1930. After his death the next month, he was buried at Arlington National Cemetery, the first president and first Supreme Court justice to be interred there. Taft is generally listed near the middle in historians' rankings of U.S. presidents.
Early life and education.
William Howard Taft was born September 15, 1857, in Cincinnati, Ohio, the son of Alphonso Taft and his second wife, Louise Torrey. The Taft family was not wealthy, living in a modest home in the suburb of Mount Auburn. Alphonso served as a judge, ambassador and in the cabinet, as War Secretary and Attorney General under Grant. Alphonso's first wife, Elisa Phelps, died in 1852, he married Louise a year and a half later, on December 26, 1853.
William Taft was not seen as brilliant as a child, but was a hard worker; the demanding parents pushed their five boys toward success, tolerating nothing less. He attended Woodward High School in Cincinnati. At Yale College, which he entered in 1874, the heavyset, jovial Taft was popular. One classmate described him succeeding through hard work rather than being the smartest, with sterling integrity. In 1878, Taft graduated, second in his class out of 121. He attended Cincinnati Law School, and graduated with a Bachelor of Laws in 1880. While in law school, he worked on "The Cincinnati Commercial" newspaper, edited by Murat Halstead. Taft was assigned to cover the local courts, and also spent time reading law in his father's office; both activities gave him practical knowledge of the law that was taught in no class. Shortly before graduating from law school, Taft went to the state capital of Columbus to take the bar examination and easily passed.
Rise in government (1880—1908).
Ohio lawyer and judge.
After admission to the Ohio bar, Taft devoted himself to his job at the "Commercial" full-time. Halstead was willing to take him on permanently at an increase in salary if he would give up the law, but Taft declined. In October 1880, Taft was appointed assistant prosecutor for Hamilton County (where Cincinnati is located), and took office the following January. Taft served for a year as assistant prosecutor, trying his share of routine cases. He resigned in January 1882 after President Chester A. Arthur appointed him Collector of Internal Revenue for Ohio's First District, an area centered on Cincinnati. Taft refused to dismiss competent employees who were politically out of favor, and resigned effective in March 1883, writing to Arthur that he wished to begin private practice in Cincinnati. In 1884, Taft campaigned for the Republican candidate for president, Maine Senator James G. Blaine, who lost to New York Governor Grover Cleveland.
In 1887, Taft, then aged 29, was appointed to a vacancy on the Superior Court of Cincinnati by Governor Joseph B. Foraker. The appointment was good for just over a year, after which he would have to face the voters, and in April 1888, he sought election for the first of three times in his lifetime, the other two being for the presidency. He was elected to a full five-year term. Some two dozen of Taft's opinions as a state judge survive, the most significant being "Moores & Co. v. Bricklayers' Union No. 1" (1889) if only because it was used against him when he ran for president in 1908. The case involved bricklayers who refused to work for any firm that dealt with a company called Parker Brothers, with which they were in dispute. Taft ruled that the union's action amounted to a secondary boycott, which was illegal.
It is not clear when Taft met Helen Herron (often called Nellie), but it was no later than 1880, when she mentioned in her diary receiving an invitation to a party from him. By 1884, they were meeting regularly, and in 1885, after an initial rejection, she agreed to marry him. The wedding took place at the Herron home on June 19, 1886. William Taft remained devoted to his wife throughout their almost 44 years of marriage. Nellie Taft pushed her husband much as his parents had, and could be very frank with her criticisms. The couple had three children, of which the eldest, Robert, became a U.S. senator.
Solicitor General.
There was a seat vacant on the U.S. Supreme Court in 1889, and Governor Foraker suggested President Harrison appoint Taft to fill it. Taft was 32 and his professional goal was always a seat on the high court. He actively sought the appointment, writing to Foraker to urge the governor to press his case, while stating to others it was unlikely he would get it. Instead, in 1890, Harrison appointed him Solicitor General of the United States. When Taft arrived in Washington in February 1890, the office had been vacant two months, with the work piling up. He worked to eliminate the backlog, while simultaneously educating himself on federal law and procedure he had not needed as an Ohio state judge.
New York Senator William M. Evarts, a former Secretary of State, had been a classmate of Alphonso Taft at Yale. Evarts called to see his friend's son as soon as Taft took office, and William and Nellie Taft were launched into Washington society. Nellie Taft was ambitious for herself and her husband, and was annoyed when the people he socialized with most were mainly Supreme Court justices, rather than the arbiters of Washington society such as Theodore Roosevelt, John Hay, Henry Cabot Lodge and their wives.
Although Taft was successful as Solicitor General, winning 15 of the 18 cases he argued before the Supreme Court, he was glad when in March 1891, Congress created a new judgeship for each of the United States Courts of Appeal and Harrison appointed him to the Sixth Circuit, based in Cincinnati. In March 1892, Taft resigned as Solicitor General to resume his judicial career.
Federal judge.
Taft's federal judgeship was a lifetime appointment, and one from which promotion to the Supreme Court might come. Taft's older half-brother Charles, successful in business, supplemented Taft's government salary, allowing William and Nellie Taft and their family to live in comfort. Taft's duties involved hearing trials in the circuit, which included Ohio, Michigan, Kentucky, and Tennessee, and participating with Supreme Court Justice John Marshall Harlan, the circuit justice, and judges of the Sixth Circuit in hearing appeals. Taft spent eight years of his life, from 1892 to 1900, in personal and professional contentment.
According to historian Louis L. Gould, "while Taft shared the fears about social unrest that dominated the middle classes during the 1890s, he was not as conservative as his critics believed. He supported the right of labor to organize and strike, and he ruled against employers in several negligence cases." Among these was "Voight v. Baltimore & Ohio Southwestern Railway Co." Taft's decision for a worker injured in a railway accident violated the contemporary doctrine of liberty of contract, and he was reversed by the Supreme Court. On the other hand, Taft's opinion in "United States v. Addyston Pipe and Steel Co." was upheld unanimously by the high court. Taft's opinion, in which he held that a pipe manufacturers' association had violated the Sherman Antitrust Act, was described by Henry Pringle, his biographer, as having "definitely and specifically revived" that legislation.
In 1896, Taft became dean and Professor of Property at his "alma mater", the Cincinnati Law School, a post that required him to prepare and give two hour-long lectures each week. He was devoted to his law school, and was deeply committed to legal education, introducing the case system to the curriculum. As a federal judge, Taft could not involve himself with politics, but followed it closely, remaining a Republican supporter. He watched with some disbelief as the campaign of Ohio Governor William McKinley developed in 1894 and 1895, writing "I cannot find anybody in Washington who wants him". By March 1896, Taft realized that McKinley would likely be nominated, and was lukewarm in his support. He landed solidly in McKinley's camp after former Nebraska representative William Jennings Bryan in July stampeded the 1896 Democratic National Convention with his Cross of Gold speech. Bryan, both in that address and in his campaign, strongly advocated free silver, a policy that Taft saw as economic radicalism. Taft feared that people would hoard gold in anticipation of a Bryan victory, but he could do nothing but worry. McKinley was elected, but when a place on the Supreme Court opened in 1898, the only one under McKinley, the president named Joseph McKenna.
Philippine years.
In January 1900, Taft was called to Washington to meet with McKinley. Taft hoped a Supreme Court appointment was in the works, but instead McKinley wanted to place Taft on the commission to organize a civilian government in the Philippines. The appointment would require Taft's resignation from the bench; the president assured him that if he fulfilled this task, McKinley would appoint him to the next vacancy on the high court. Taft accepted on condition he was made head of the commission, with responsibility for success or failure; McKinley agreed, and Taft sailed for the islands in April 1900.
Many Filipinos had responded to the American takeover with a fierce resistance, seeking independence for the islands, but U.S. forces, led by military governor General Arthur MacArthur had the upper hand by 1900. MacArthur felt the commission was a nuisance, and their mission a quixotic attempt to impose self-government on a people unready for it. The general was forced to co-operate with Taft, as McKinley had given the commission control over the islands' military budget. The commission took executive power in the Philippines on September 1, 1900; on July 4, 1901, Taft became civilian governor. MacArthur, until then the military governor, was relieved by General Adna Chaffee, who was designated only as commander of American forces.
Taft sought to make the Filipinos partners in a venture that would lead to their self-government; he saw independence as something far off. Many Americans in the Philippines viewed the locals as racial inferiors, but Taft wrote soon before his arrival, "we propose to banish this idea from their minds". Taft did not impose segregation at official events, and treated the Filipinos as social equals. Nellie Taft recalled that "neither politics nor race should influence our hospitality in any way".
McKinley died by assassination in September 1901, and was succeeded by Theodore Roosevelt. Taft and Roosevelt had first become friends around 1890 while Taft was Solicitor General and Roosevelt a member of the Civil Service Commission. Taft had, after McKinley's election, urged the appointment of Roosevelt as Assistant Secretary of the Navy, and watched as Roosevelt became a war hero, Governor of New York, and Vice President of the United States. They met again when Taft went to Washington in January 1902 to recuperate after two operations caused by an infection. There, Taft testified before the Senate Committee on the Philippines. Taft wanted to have Filipino farmers to have a stake in the new government through land ownership, but much of the arable land was held by Catholic religious orders, priests who were mostly Spanish, and were often resented by the Filipinos. Roosevelt had Taft go to Rome to negotiate with Pope Leo XIII, to purchase the lands and to arrange the withdrawal of the Spanish priests, with Americans replacing them and training locals as clergy. Taft did not succeed in resolving these issues on his visit to Rome, but an agreement on both points was made in 1903.
In late 1902, Taft had heard from Roosevelt that a seat on the Supreme Court would soon fall vacant on the resignation of Justice George Shiras, and Roosevelt desired that Taft fill it. Although this was Taft's professional goal, he refused as he felt his work as governor was not yet done. One reason for Roosevelt's action was his desire to neutralize a potential rival for the presidency: Taft's success in the Philippines had not gone unnoticed in the American press. The following year, Roosevelt asked Taft to become Secretary of War. As the War Department was responsible for the Philippines, Taft would remain responsible for the islands, and Root was willing to postpone his departure until 1904, allowing Taft time to wrap up his work in Manila. After consulting with his family, Taft agreed, and sailed for the United States in December 1903.
Secretary of War.
When Taft took office as Secretary of War in January 1904, he was not called upon to spend much time administering the army, which the president was content to do himself—Roosevelt wanted him as a troubleshooter in difficult situations, as a legal adviser, and to be able to give campaign speeches as he sought election in his own right. Taft strongly defended Roosevelt's record in his addresses, and wrote of the president's successful but strenuous efforts to gain election, "I would not run for president if you guaranteed the office. It is awful to be afraid of one's shadow."
Between 1905 and 1907, Taft came to terms with the likelihood he would be the next Republican nominee for president, though he did not plan to actively campaign for it. When Justice Henry B. Brown resigned in 1905, Taft would not accept the seat although Roosevelt offered it, a position Taft held to when another seat opened in 1906. Edith Roosevelt, the First Lady, disliked the growing closeness between the two men, feeling they were too much alike, and that the president did not gain much from the advice of someone who rarely contradicted him.
Alternatively, Taft wanted to be chief justice, and kept a close eye on the health of the aging incumbent, Melville Fuller, who turned 75 in 1908. Taft believed Fuller likely to live many years. Roosevelt had indicated he was likely to appoint Taft if the opportunity came to fill the court's center seat, but some considered Attorney General Philander Knox a better candidate. In any event, Fuller remained chief justice throughout Roosevelt's presidency.
Through the 1903 Panamanian Revolution and the Hay-Bunau-Varilla Treaty, the United States had secured rights to build a canal in the Isthmus of Panama. Legislation authorizing construction did not specify which government department would be responsible, and Roosevelt designated the Department of War. Taft journeyed to Panama in 1904, viewing the canal site and meeting with Panamanian officials. The Isthmian Canal Commission had trouble keeping a chief engineer, and when in February 1907 John D. Stevens submitted his resignation, Taft recommended an army engineer, George W. Goethals. Under Goethals, the project moved ahead smoothly.
Another colony lost by Spain in 1898 was Cuba, but as freedom for Cuba had been a major purpose of the war, it was not annexed by the U.S., but was, after a period of occupation, given independence in 1902. Election fraud and corruption followed, as did factional conflict. In September 1906, President Tomás Estrada Palma asked for U.S. intervention. Taft traveled to Cuba with a small American force, and on September 29, 1906, under the terms of the Cuban–American Treaty of Relations of 1903, declared himself Provisional Governor of Cuba, a post he held for two weeks before being succeeded by Charles Edward Magoon. In his time in Cuba, Taft worked to persuade Cubans that the U.S. intended stability, not occupation.
Taft remained involved in Philippine affairs. During Roosevelt's election campaign in 1904, he urged that Philippine agricultural products be admitted to the U.S. without duty. This caused growers of U.S. sugar and tobacco to complain to Roosevelt, who remonstrated with his Secretary of War. Taft expressed unwillingness to change his position, and threatened to resign; Roosevelt hastily dropped the matter. Taft returned to the islands in 1905, leading a delegation of congressmen, and again in 1907, to open the first Philippine Assembly.
On both of his Philippine trips as Secretary of War, Taft went to Japan, and met with officials there. The meeting in July 1905 came a month before the conference which would end the Russo-Japanese War with the Treaty of Portsmouth. Taft met with Japanese Prime Minister Katsura Tarō. After that meeting, the two signed a memorandum, with Japan indicating it had no desire to invade the Philippines, and the U.S. that it did not object to Japanese control of Korea. During Taft's second visit, in September 1907, Tadasu Hayashi, the foreign minister, informally agreed to issue fewer passports to them.
Presidential election of 1908.
Gaining the nomination.
Roosevelt had served almost three and a half years of McKinley's term. On the night of his own election in 1904, Roosevelt publicly declared he would not run for re-election in 1908, a pledge he quickly regretted. But he felt bound by his word. Roosevelt believed Taft was his logical successor, although the War Secretary was initially reluctant to run. Roosevelt used his control of the party machinery to aid his heir apparent. On pain of loss of their jobs, political appointees were required to support Taft or remain silent.
A number of Republican politicians, such as Treasury Secretary George Cortelyou tested the waters for a run, but chose to stay out. New York Governor Charles Evans Hughes ran, but when he made a major policy speech, Roosevelt the same day sent a special message to Congress warning in strong terms against corporate corruption. The resulting coverage of the presidential message relegated Hughes to the back pages. Roosevelt reluctantly deterred repeated attempts to draft him for another term.
Assistant Postmaster General Frank H. Hitchcock resigned from his office in February 1908 to lead the Taft effort. In April, Taft made a speaking tour, traveling as far west as Omaha before being recalled to go to Panama and straighten out another contested election. At the 1908 Republican National Convention in Chicago in June, there was no serious opposition to him, and he gained a first-ballot victory. Yet, Taft did not have things his own way: he had hoped his running mate would be a midwestern progressive like Iowa Senator Jonathan Dolliver, but instead the convention named Congressman James S. Sherman of New York, a conservative. Taft resigned as Secretary of War on June 30 to devote his full-time to the campaign.
General election campaign.
Taft's opponent in the general election was Bryan, the Democratic nominee for the third time in four presidential elections. As many of Roosevelt's reforms stemmed from proposals by Bryan, the Democrat argued that he was the heir to Roosevelt's mantle and that Taft was not. Corporate contributions to federal political campaigns had been outlawed by the 1907 Tillman Act, and Bryan proposed that contributions by officers and directors of corporations be similarly banned, or at least disclosed when made. Taft was only willing to see the contributions disclosed after the election, and tried to ensure that officers and directors of corporations litigating with the government were not among his contributors.
Taft began the campaign on the wrong foot, fueling the arguments of those who said he was not his own man by traveling to Roosevelt's home at Sagamore Hill for advice on his acceptance speech, saying that he needed "the President's judgment and criticism". He for the most part supported Roosevelt's policies. The candidate argued that labor had a right to organize, but not to boycott. Moneyed interests, that is, capital, must also obey the law. Bryan wanted the railroads to be owned by the government, but Taft preferred that they remain in the private sector, with their maximum rates set by the Interstate Commerce Commission, subject to judicial review. Taft attributed blame for the recent recession, the Panic of 1907, to stock speculation and other abuses, and felt some reform of the currency (the U.S. was on the gold standard) was needed to allow flexibility in the government's response to poor economic times. Specific legislation on trusts was needed to supplement the Sherman Antitrust Act. The constitution should be amended to allow for an income tax, thus overruling decisions of the Supreme Court striking such a tax down. Roosevelt's expansive use of executive power had been controversial; Taft proposed to continue his policies, but place them on more solid legal underpinnings through the passage of legislation.
Taft upset some progressives by choosing Hitchcock as Chairman of the Republican National Committee (RNC), placing him in charge of the presidential campaign. Hitchcock was quick to bring in men closely allied with big business. Taft took an August vacation in Hot Springs, Virginia, where he irritated political advisors by spending more time on golf than strategy. After seeing a newspaper photo of Taft taking a large swing at a golf ball, Roosevelt warned him against candid shots.
Roosevelt, frustrated by his own relative inaction, showered Taft with advice, fearing that the electorate would not appreciate Taft's qualities, and that Bryan would win. Roosevelt's supporters spread rumors that the president was in effect running Taft's campaign. This annoyed Nellie Taft, who never trusted the Roosevelts. Nevertheless, Roosevelt supported the Republican nominee with such enthusiasm that humorists suggested "TAFT" stood for "Take advice from Theodore".
Bryan urged a system of bank guarantees, so that depositors could be repaid if banks failed, but Taft opposed this, offering a postal savings system instead. The issue of prohibition of alcohol entered the campaign when in mid-September, Carrie Nation called on Taft and demanded to know his views. Taft and Roosevelt had agreed the party platform would take no position on the matter, and Nation left indignant, to allege that Taft was irreligious and against temperance. Taft, at Roosevelt's advice, ignored the issue.
In the end, Taft won by a comfortable margin. Taft defeated Bryan by 321 electoral votes to 162; however, he garnered just 51.6 percent of the popular vote. Nellie Taft said regarding the campaign, "There was nothing to criticize, except his not knowing or caring about the way the game of politics is played." Longtime White House usher Ike Hoover recalled that Taft came often to see Roosevelt during the campaign, but seldom between the election and Inauguration Day, March 4, 1909.
Presidency (1909–1913).
Inauguration and appointments.
William Howard Taft was sworn in as president on March 4, 1909. Due to a winter storm that coated Washington with ice, Taft was inaugurated within the Senate Chamber rather outside the Capitol as is customary. The new president stated in his inaugural address that he had been honored to have been "one of the advisers of my distinguished predecessor" and to have had a part "in the reforms he has initiated. I should be untrue to myself, to my promises, and to the declarations of the party platform on which I was elected if I did not make the maintenance and enforcement of those reforms a most important feature of my administration". He pledged to make those reforms long-lasting, ensuring that honest businessmen did not suffer uncertainty through change of policy. He spoke of the need for reduction of the 1897 Dingley Tariff, for antitrust reform, and for continued advancement of the Philippines toward full self-government. Roosevelt left office with regret that his tenure in the position he enjoyed so much was over, and to keep out of Taft's way arranged for a year-long hunting trip to Africa.
Soon after the Republican convention, Taft and Roosevelt had discussed which cabinet officers would stay on. Taft kept only Agriculture Secretary James Wilson and Postmaster General George von Lengerke Meyer (who was shifted to the Navy Department). Others appointed to the Taft cabinet included Philander Knox, the new Secretary of State, and Franklin MacVeagh as Treasury Secretary.
Taft did not enjoy the easy relationship with the press that Roosevelt had, choosing not to offer himself for interviews or photo opportunities as often as his predecessor had. His administration marked a change in style from the charismatic leadership of Roosevelt to Taft's quieter passion for the rule of law.
Foreign policy.
Organization and principles.
Taft made it a priority to restructure the State Department, noting, "it is organized on the basis of the needs of the government in 1800 instead of 1900." The Department was for the first time organized into geographical divisions, including desks for the Far East, Latin America and Western Europe. The department's first in-service training program was established, and appointees spent a month in Washington before going to their posts. Taft and Secretary of State Knox had a strong relationship, and the president listened to his counsel on matters foreign and domestic. According to Coletta, however, Knox was not a good diplomat, and had poor relations with the Senate, press, and many foreign leaders, especially those from Latin America.
There was broad agreement between Taft and Knox on major foreign policy goals. The U.S. would not interfere in European affairs. The U.S. would use force if necessary to enforce the Monroe Doctrine in the Americas. The defense of the Panama Canal, which was under construction throughout Taft's term (it opened in 1914), guided U.S. policy in the Caribbean and in Central America. Previous administration had tried to defend American business interests overseas, but Taft went a step further and used the web of American diplomats and consuls abroad to promote trade. Such ties, Taft hoped, would promote world peace. Taft promoted arbitration treaties with Great Britain and France, but the Senate was not willing to yield to arbitrators its constitutional prerogative to approve treaties.
Tariffs and reciprocity.
At the time of Taft's presidency, protectionism through the use of tariffs was a fundamental position of the Republican Party. The Dingley Tariff had been enacted to protect American industry from foreign competition. The 1908 party platform had supported unspecified revisions to the Dingley Act, and Taft interpreted this to mean reductions. Taft called a special session of Congress to convene on March 15, 1909 to deal with the tariff question.
Sereno E. Payne, chairman of the House Ways and Means Committee, had held hearings in late 1908, and sponsored the resulting draft legislation. On balance, the bill reduced tariffs slightly, but when it passed the House in April 1909 and reached the Senate, the chairman of the Senate Finance Committee, Rhode Island Senator Nelson W. Aldrich, attached many amendments raising rates. This outraged progressives such as Wisconsin's Robert M. La Follette, who urged Taft to say that the bill was not in accord with the party platform. Taft refused, angering them. Taft insisted that most imports from the Philippines be free of duty, and according to Anderson, showed effective leadership on a subject he was knowledgeable on and really cared about.
When opponents sought to modify the tariff bill to allow for an income tax, Taft opposed it on the ground that the Supreme Court would likely strike it down as unconstitutional, as it had before. Instead, they proposed a constitutional amendment, which passed both houses in early July, was sent to the states, and by 1913 was ratified as the Sixteenth Amendment. In the conference committee, Taft won some victories, such as limiting the tax on lumber. The conference report passed both houses, and Taft signed it on August 6, 1909. The Payne-Aldrich tariff was immediately controversial. According to Coletta, "Taft had lost the initiative, and the wounds inflicted in the acrid tariff debate never healed".
In Taft's annual message sent to Congress in December 1910, he urged a free trade accord for Canada. Britain at that time still handled Canada's foreign relations, and Taft found the British and Canadian governments willing. Many in Canada opposed an accord, fearing the U.S. would dump it when convenient as it had the 1854 Elgin-Marcy Treaty in 1866, and American farm and fisheries interests were also opposed. After January 1911 talks with Canadian officials, Taft had the agreement, which was not a treaty, introduced into Congress and it passed in late July. The Canadian Parliament, led by Prime Minister Sir Wilfrid Laurier, had deadlocked over the issue. Canadians turned Laurier out of office in the September 1911 election. No cross-border agreement was concluded, and the debate deepened divisions in the Republican Party.
Latin America.
Taft and his Secretary of State, Philander Knox, instituted a policy of Dollar Diplomacy towards Latin America, believing U.S. investment would benefit all involved, while keeping European influence away from areas subject to the Monroe Doctrine. Although exports rose sharply during Taft's administration, the policy was unpopular among Latin American states that did not wish to become financial protectorates of the United States, as well as in the U.S. Senate, many of whose members believed the U.S. should not interfere abroad. No foreign affairs controversy tested Taft's statesmanship and commitment to peace more than the collapse of the Mexican regime and subsequent turmoil of the Mexican Revolution.
When Taft entered office, Mexico was increasingly restless under the grip of longtime dictator Porfirio Díaz and many Mexicans backed his opponent, Francisco Madero. There were a number of incidents in which Mexican rebels crossed the U.S. border to obtain horses and weapons; Taft sought to prevent this by ordering the army to the border areas for maneuvers. Taft told his military aide, Archibald Butt, that "I am going to sit on the lid and it will take a great deal to pry me off". He showed his support for Díaz by meeting with him at El Paso, Texas, and Ciudad Juárez, Mexico, the first meeting between a U.S. and a Mexican president and also the first time an American president visited Mexico. The day of the summit, Frederick Russell Burnham and a Texas Ranger captured and disarmed an assassin holding a palm pistol only a few feet of the two presidents. Before the election in Mexico, Díaz jailed opposition candidate Madero, whose supporters took up arms resulting in both the ouster of Díaz and a revolution that would continue for another ten years. In the U.S.'s Arizona Territory, two citizens were killed and almost a dozen injured, some as a result of gunfire across the border. Taft would not be goaded into fighting and so instructed the territorial governor.
Nicaragua's president, José Zelaya, wanted to revoke commercial concessions granted to American companies, and American diplomats quietly favored rebel forces under Juan Estrada. Nicaragua was in debt to foreign powers, and the U.S. was unwilling that an alternate canal route fall into the hands of Europeans. Zelaya's elected successor, José Madriz, could not put down the rebellion as U.S. forces interfered, and in August 1910, the Estrada forces took Managua, the capital. The U.S. had Nicaragua accept a loan, and sent officials to ensure it was repaid from government revenues. The country remained unstable, and after another coup in 1911 and more disturbances in 1912, Taft sent troops; though most were soon withdrawn, some remained as late as 1933.
Treaties among Panama, Colombia, and the United States to resolve disputes arising from the Panamanian Revolution of 1903 had been signed by the lame-duck Roosevelt administration in early 1909, and were approved by the Senate and also ratified by Panama. Colombia, however, declined to ratify the treaties, and after the 1912 elections, Knox offered $10 million to the Colombians (later raised to $25 million). The Colombians felt the amount inadequate, and requested arbitration; the matter was not settled under the Taft administration.
Far East.
Due to his years in the Philippines, Taft was keenly interested as president in Far Eastern affairs. Taft considered relations with Europe relatively unimportant, but because of the potential for trade and investment, Taft ranked the post of minister to China as most important in the Foreign Service. Knox did not agree, and declined a suggestion that he go to Peking to view the facts on the ground. Taft replaced Roosevelt's minister there, William W. Rockhill, as uninterested in the China trade, with William J. Calhoun, whom McKinley and Roosevelt had sent on several foreign missions. Knox did not listen to Calhoun on policy, and there were often conflicts. Taft and Knox tried to extend John Hay's Open Door Policy to Manchuria; this was not successful.
In 1898, an American company had gained a concession for a railroad between Hankow and Szechuan, but the Chinese revoked the agreement in 1904 after the company (which was indemnified for the revocation) breached the agreement by selling a majority stake outside the United States. The Chinese imperial government got the money for the indemnity from the British Hong Kong government, on condition British subjects would be favored if foreign capital was needed to build the railroad line, and in 1909, a British-led consortium began negotiations. This came to Knox's attention in May of that year, and he demanded that U.S. banks be allowed to participate. Taft appealed personally to the Prince Regent, Prince Chun, and was successful in gaining U.S. participation, though agreements were not signed until May 1911. However, the Chinese decree authorizing the agreement also required the nationalization of local railroad companies in the affected provinces. Inadequate compensation was paid to the shareholders, and these grievances were among those which touched off the Chinese Revolution of 1911.
After the revolution broke out, the revolt's leaders chose Sun Yat Sen as provisional president of what became the Republic of China, overthrowing the Manchu Dynasty, Taft was reluctant to recognize the new government, although American public opinion was in favor of it. The U.S. House of Representatives in February 1912 passed a resolution supporting a Chinese republic, but Taft and Knox felt recognition should come as a concerted action by Western powers. Taft in his final annual message to Congress in December 1912 indicated that he was moving towards recognition once the republic was fully established, but by then he had been defeated for re-election and he did not follow through.
Taft continued the policy against immigration from China and Japan as under Roosevelt. A revised treaty of friendship and navigation entered into by the U.S. and Japan in 1911 granted broad reciprocal rights to Japanese in America and Americans in Japan, but were premised on the continuation of the Gentlemen's Agreement. There was objection on the West Coast when the treaty was submitted to the Senate, but Taft informed politicians that there was no change in immigration policy.
Europe.
Taft was opposed to the traditional practice of rewarding wealthy supporters with key ambassadorial posts, preferring that diplomats not live in a lavish lifestyle and selecting men who, as Taft put it, would recognize an American when they saw one. High on his list for dismissal was the ambassador to France, Henry White, whom Taft knew and disliked from his visits to Europe. White's ouster caused other career State Department employees to fear that their jobs might be lost to politics. Taft also wanted to replace the Roosevelt-appointed ambassador in London, Whitelaw Reid, but Reid, owner of the "New-York Tribune", had backed Taft during the campaign, and both William and Nellie Taft enjoyed his gossipy reports. Reid remained in place until his 1912 death.
Taft was a supporter of settling international disputes by arbitration, and he negotiated treaties with Great Britain and with France providing that differences be arbitrated. These were signed in August 1911. Neither Taft nor Knox (a former senator) consulted with members of the Senate during the negotiating process. By then many Republicans were opposed to Taft and the president felt that lobbying too hard for the treaties might cause their defeat. He made some speeches supporting the treaties in October, but the Senate added amendments Taft could not accept, killing the agreements.
Although no general arbitration treaty was entered into, Taft's administration settled several disputes with Great Britain by peaceful means, often involving arbitration. These included a settlement of the boundary between Maine and New Brunswick, a long-running dispute over seal hunting in the Bering Sea that also involved Japan, and a similar disagreement regarding fishing off Newfoundland. The sealing convention remained in force until abrogated by Japan in 1940.
Domestic policies and politics.
Antitrust.
Taft continued and expanded Roosevelt's efforts to break up business combinations through lawsuits brought under the Sherman Antitrust Act, bringing 70 cases in four years (Roosevelt had brought 40 in seven years). Suits brought against the Standard Oil Company and the American Tobacco Company, initiated under Roosevelt, were decided in favor of the government by the Supreme Court in 1911. In June 1911, the Democrat-controlled House of Representatives began hearings into United States Steel (U.S. Steel). That company had been expanded under Roosevelt, who had supported its acquisition of the Tennessee Coal, Iron, and Railroad Company as a means of preventing the deepening of the Panic of 1907, a decision the former president defended when testifying at the hearings. Taft, as Secretary of War, had praised the acquisitions. Historian Louis L. Gould suggested that Roosevelt was likely deceived into believing that U.S. Steel did not want to purchase the Tennessee company, but it was in fact a bargain. For Roosevelt, questioning the matter went to his personal honesty.
In October 1911, Taft's Justice Department brought suit against U.S. Steel, demanding that over a hundred of its subsidiaries be granted corporate independence, and naming as defendants many prominent business executives and financiers. The pleadings in the case had not been reviewed by Taft, and alleged that Roosevelt "had fostered monopoly, and had been duped by clever industrialists". Roosevelt was offended by the references to him and his administration in the pleadings, and felt that Taft could not evade command responsibility by saying he did not know of them.
Taft sent a special message to Congress on the need for a revamped antitrust statute when it convened its regular session in December 1911, but it took no action. Another antitrust case that had political repercussions for Taft was that brought against the International Harvester Company, the large manufacturer of farm equipment, in early 1912. As Roosevelt's administration had investigated International Harvester, but had taken no action (a decision Taft had supported), the suit became caught up in Roosevelt's challenge for the Republican presidential nomination. Supporters of Taft alleged that Roosevelt had acted improperly; the former president blasted Taft for waiting three and a half years, and until he was under challenge, to reverse a decision he had supported.
Ballinger-Pinchot affair.
Roosevelt was an ardent conservationist, assisted in this by like-minded appointees, including Interior Secretary James R. Garfield and Chief Forester Gifford Pinchot. Taft agreed with the need for conservation, but felt it should be accomplished by legislation rather than executive order. He did not retain Garfield, an Ohioan, as secretary, choosing instead a westerner, former Seattle mayor Richard A. Ballinger. Roosevelt was surprised at the replacement, believing that Taft had promised to keep Garfield, and this change was one of the events that caused Roosevelt to realize that Taft would choose different policies.
Roosevelt had withdrawn much land from the public domain, including some in Alaska thought rich in coal. In 1902, Clarence Cunningham, an Idaho entrepreneur, had found coal deposits in Alaska, and made mining claims, and the government investigated their legality. This dragged on for the remainder of the Roosevelt administration, including during the year (1907–1908) when Ballinger served as head of the General Land Office. A special agent for the Land Office, Louis Glavis, investigated the Cunningham claims, and when Secretary Ballinger in 1909 approved them, Glavis broke governmental protocol by going outside the Interior Department to seek help from Pinchot.
In September 1909, Glavis made his allegations public in a magazine article, disclosing that Ballinger had acted as an attorney for Cunningham between his two periods of government service. This violated conflict of interest rules forbidding a former government official from advocacy on a matter he had been responsible for. On September 13, 1909 Taft dismissed Glavis from government service, relying on a report from Attorney General George W. Wickersham dated two days previously. Pinchot was determined to dramatize the issue by forcing his own dismissal, which Taft tried to avoid, fearing that it might cause a break with Roosevelt (still overseas). Taft asked Root (by then a senator) to look into the matter, and Root urged the firing of Pinchot.
Taft had ordered government officials not to comment on the fracas. In January 1910, Pinchot forced the issue by sending a letter to Iowa Senator Dolliver alleging that but for the actions of the Forestry Service, Taft would have approved a fraudulent claim on public lands. According to Pringle, this "was an utterly improper appeal from an executive subordinate to the legislative branch of the government and an unhappy president prepared to separate Pinchot from public office". Pinchot was dismissed, much to his delight, and he sailed for Europe to lay his case before Roosevelt. A congressional investigation followed, which cleared Ballinger by majority vote, but the administration was embarrassed when Glavis' attorney, Louis D. Brandeis, proved that the Wickersham report had been backdated, which Taft belatedly admitted. The Ballinger-Pinchot affair caused progressives and Roosevelt loyalists to feel that Taft had turned his back on Roosevelt's agenda.
Civil rights.
Taft announced in his inaugural address that he would not appoint African Americans to federal jobs, such as postmaster, where this would cause racial friction. This differed from Roosevelt, who would not remove or replace black officeholders with whom local whites would not deal. Termed Taft's "Southern Policy", this stance effectively invited white protests against black appointees. Taft followed through, removing most black office holders in the South, and made few appointments from that race in the North.
At the time Taft was inaugurated, the way forward for African Americans was debated by their leaders. Booker T. Washington felt that most blacks should be trained for industrial work, with only a few seeking higher education; W.E.B. DuBois took a more militant stand for equality. Taft tended towards Washington's approach. According to Coletta, Taft let the African-American "be 'kept in his place' ... He thus failed to see or follow the humanitarian mission historically associated with the Republican party, with the result that Negroes both North and South began to drift toward the Democratic party."
A supporter of free immigration, Taft vetoed a bill passed by Congress and supported by labor unions that would have restricted unskilled laborers by imposing a literacy test.
Judicial appointments.
Taft made six appointments to the Supreme Court, the most of any president except George Washington and Franklin D. Roosevelt. The death of Justice Rufus Peckham in October 1909 gave Taft his first opportunity. He chose an old friend and colleague from the Sixth Circuit, Horace H. Lurton of Georgia; he had in vain urged Theodore Roosevelt to appoint Lurton to the high court. Attorney General Wickersham objected that Lurton, a former Confederate soldier and a Democrat, was aged 65. Taft named Lurton anyway on December 13, 1909, and the Senate confirmed him by voice vote a week later. Lurton is still the oldest man to be made an associate justice. Lurie suggested that Taft, already beset by the tariff and conservation controversies, desired to perform an official act which gave him pleasure, especially since he thought Lurton deserved it.
Justice David Brewer's death on March 28, 1910 gave Taft a second opportunity to fill a seat on the high court; he chose New York Governor Charles Evans Hughes. Taft told Hughes that should the chief justiceship fall vacant during his term, Hughes would be his likely choice for the center seat. The Senate quickly confirmed Hughes, but then Chief Justice Fuller died on July 4, 1910. Taft took five months to replace Fuller, and when he did, it was with Justice Edward D. White, who became the first associate justice to be promoted to chief justice. According to Lurie, Taft, who still had hopes of being chief justice, may have been more willing to appoint an older man than he (White) than a younger one (Hughes), who might outlive him, as indeed Hughes did. To fill White's seat as associate justice, Taft appointed Willis Van Devanter of Wyoming, a federal appeals judge. By the time Taft nominated White and Van Devanter in December 1910, he had another seat to fill due to William Moody's retirement because of illness; he named a Louisiana Democrat, Joseph R. Lamar, whom he had met while playing golf, and had subsequently learned had a good reputation as a judge.
With the death of Justice Harlan in October 1911, Taft got to fill a sixth seat on the Supreme Court. After Secretary Knox declined appointment, Taft named Chancellor of New Jersey Mahlon Pitney, the last person appointed to the Supreme Court who did not attend law school. Pitney had a stronger anti-labor record than Taft's other appointments, and was the only one to meet opposition, winning confirmation by a Senate vote of 50—26.
Taft appointed 13 judges to the federal courts of appeal and 38 to the United States district courts. Taft also appointed judges to various specialized courts, including the first five appointees each to the United States Commerce Court and the United States Court of Customs Appeals. The Commerce Court, created in 1910, stemmed from a Taft proposal for a specialized court to hear appeals from the Interstate Commerce Commission. There was considerable opposition to its establishment, which only grew when one of its judges, Robert W. Archbald, was in 1912 impeached for corruption and removed by the Senate the following January. Taft vetoed a bill to abolish the court, but the respite was short-lived as Wilson signed similar legislation in October 1913.
1912 presidential campaign and election.
Moving apart from Roosevelt.
During Roosevelt's fifteen months beyond the Atlantic, from March 1909 to June 1910, neither man wrote much to the other. Taft biographer Lurie suggested that each expected the other to make the first move to re-establish their relationship on a new footing. Upon Roosevelt's triumphant return in June 1910, Taft invited him to stay at the White House. The former president declined, and in private letters to friends expressed dissatisfaction at Taft's performance. Nevertheless, he wrote that he expected Taft to be renominated by the Republicans in 1912, and did not speak of himself as a candidate.
Taft and Roosevelt met twice in 1910; the meetings, though outwardly cordial, did not display their former closeness. Roosevelt gave a series of speeches in the West in the late summer and early fall of 1910. Roosevelt not only attacked the Supreme Court's 1905 decision in "Lochner v. New York", he accused the federal courts of undermining democracy, and called for them to be deprived of the power to rule legislation unconstitutional. This attack horrified Taft, who privately agreed that "Lochner" had been wrongly decided. Roosevelt called for "elimination of corporate expenditures for political purposes, physical valuation of railroad properties, regulation of industrial combinations, establishment of an export tariff commission, a graduated income tax" as well as "workmen's compensation laws, state and national legislation to regulate the of women and children, and complete publicity of campaign expenditure". According to John Murphy in his journal article on the breach between the two presidents, "As Roosevelt began to move to the left, Taft veered to the right."
During the 1910 midterm election campaign, Roosevelt involved himself in New York politics, while Taft with donations and influence tried to secure the election of the Republican gubernatorial candidate in Ohio, former lieutenant governor Warren G. Harding. The Republicans suffered losses in the 1910 elections as the Democrats took control of the House and slashed the Republican majority in the Senate. In New Jersey, Democrat Woodrow Wilson was elected governor, and Harding lost his race in Ohio.
After the election, Roosevelt continued to promote progressive ideals, a New Nationalism, much to Taft's dismay. Roosevelt attacked his successor's administration, arguing that its guiding principles were not that of the party of Lincoln, but those of the Gilded Age. The feud continued on and off through 1911, a year in which there were few elections of significance. Wisconsin Senator La Follette announced a presidential run as a Republican, and was backed by a convention of progressives. Roosevelt began to move into a position for a run in late 1911, writing that the tradition that presidents not run for a third term only applied to consecutive terms.
Roosevelt was receiving many letters from supporters urging him to run, and Republican office-holders were organizing on his behalf. Balked on many policies by an unwilling Congress and courts in his full term in the White House, he saw manifestations of public support he believed would sweep him to the White House with a mandate for progressive policies that would brook no opposition. In February, Roosevelt announced he would accept the Republican nomination if it was offered to him. Taft felt that if he lost in November, it would be a repudiation of the party, but if he lost renomination, it would be a rejection of himself. He was reluctant to oppose Roosevelt, who helped make him president, but having become president, he was determined to be president, and that meant not standing aside to allow Roosevelt to gain another term.
Primaries and convention.
As Roosevelt became more radical in his progressivism, Taft was hardened in his resolve to achieve re-nomination, as he was convinced that the progressives threatened the very foundation of the government. One blow to Taft was the loss of Archibald Butt, one of the last links between the previous and present presidents, as Butt had formerly served Roosevelt. Ambivalent between his loyalties, Butt went to Europe on vacation in early 1912. He sailed for home in April on the "Titanic" and died in its sinking, a death Taft found hard to accept as his body was not recovered.
Roosevelt dominated the primaries, winning 278 of the 362 delegates to the Republican National Convention in Chicago decided in that manner. Taft had control of the party machinery, and it came as no surprise that he gained the bulk of the delegates decided at district or state conventions. Taft did not have a majority, but was likely to have one once southern delegations committed to him. Roosevelt challenged the election of these delegates, but the RNC overruled most objections. Roosevelt's sole remaining chance was with a friendly convention chairman, who might make rulings on the seating of delegates that favored his side. Taft followed custom and remained in Washington, but Roosevelt went to Chicago to run his campaign and told his supporters in a speech, "we stand at Armageddon, and we battle for the Lord".
Taft had won over Root, who agreed to run for temporary chairman of the convention, and the delegates elected Root over Roosevelt's candidate. The Roosevelt forces moved to substitute the delegates they supported for the ones they argued should not be seated. Root made a crucial ruling, that although the contested delegates could not vote on their own seating, they could vote on the other contested delegates, a ruling that assured Taft's nomination, as the motion offered by the Roosevelt forces failed, 567—507. As it became clear Roosevelt would bolt the party if not nominated, some Republicans sought a compromise candidate to avert the electoral disaster to come; they were unsuccessful. Taft's name was placed in nomination by Warren Harding, whose attempts to praise Taft and unify the party were met with angry interruptions from progressives. Taft was nominated on the first ballot, though most Roosevelt delegates refused to vote.
Campaign and defeat.
Alleging Taft had stolen the nomination, Roosevelt and his followers formed the Progressive Party. Taft knew he would almost certainly be defeated, but concluded that through Roosevelt's loss at Chicago the party had been preserved as "the defender of conservative government and conservative institutions." Governor Woodrow Wilson was the Democratic nominee. Seeing Roosevelt as the greater electoral threat, Wilson spent little time attacking Taft, arguing that Roosevelt had been lukewarm in opposing the trusts during his presidency, and that Wilson was the true reformer.
Reverting to the pre-Roosevelt custom that presidents seeking re-election did not campaign, Taft spoke publicly only once, making his nomination acceptance speech on August 1. He had difficulty in financing the campaign, as many industrialists had concluded he could not win, and would support Wilson to block Roosevelt. The president issued a confident statement in September after the Republicans narrowly won Vermont's state elections in a three-way fight, but had no illusions he would win his race. He had hoped to send his cabinet officers out on the campaign trail, but found them reluctant to go. Senator Root agreed to give a single speech for him.
Vice President Sherman had been renominated at Chicago; seriously ill during the campaign, he died six days before the election, and was replaced on the ticket by the president of Columbia University, Nicholas Murray Butler. But few electors chose Taft and Butler, who won only Utah and Vermont, for a total of eight electoral votes. Roosevelt won 88, and Wilson 435. Wilson won though he had only a plurality of the popular vote and less of it than Taft and Roosevelt combined. Taft had hoped to better Roosevelt in the popular vote, but finished with just under 3.5 million, over 600,000 less than the former president. Taft was not on the ballot in California, due to the actions of local Progressives, nor in South Dakota.
Return to Yale (1913–1921).
With no pension or other compensation to expect from the government after leaving the White House, Taft contemplated a return to the practice of law, from which he had long been absent. Given that Taft had appointed many federal judges, including a majority of the Supreme Court, this would raise questions of conflict of interest at every federal court appearance and he was saved from this by an offer for him to become Kent Professor of Law and Legal History at Yale Law School. He accepted, and after a month's vacation in Georgia, arrived in New Haven on April 1, 1913 to a rapturous reception. As it was too late in the semester for him to give an academic course, he instead prepared eight lectures on "Questions of Modern Government", which he delivered in May. He earned money with paid speeches and with articles for magazines, and would end his eight years out of office having increased his savings. While at Yale, he wrote the treatise, "Our Chief Magistrate and His Powers" (1916).
Taft had been made president of the Lincoln Memorial Commission while still in office; when Democrats proposed removing him for one of their party, he quipped that unlike losing the presidency, such a removal would hurt. The architect, Henry Bacon, wanted to use Colorado-Yule marble, while southern Democrats urged using Georgia marble. Taft lobbied for the western stone, and the matter was submitted to the Commission of Fine Arts, which supported Taft and Bacon. The project went forward; Taft would dedicate the Lincoln Memorial as chief justice in 1922. In 1913, Taft was elected to a one-year term as president of the American Bar Association (ABA), a trade group of lawyers. He removed opponents, such as Louis Brandeis and University of Pennsylvania Law School dean William Draper Lewis (a supporter of the Progressive Party) from committees.
Taft maintained a cordial relationship with Wilson. The former president privately criticized his successor on a number of issues, but made his views known publicly only on Philippine policy. Taft was appalled when, after Justice Lamar's death in January 1916, Wilson nominated Brandeis, whom the former president had never forgiven for his role in the Ballinger-Pinchot affair. When hearings led to nothing discreditable about Brandeis, Taft intervened with a letter signed by himself and other former ABA presidents, stating that Brandeis was not fit to serve on the Supreme Court. Nevertheless, the Democratic-controlled Senate confirmed Brandeis. Taft and Roosevelt remained embittered; they met only once in the first three years of the Wilson presidency, at a funeral at Yale. They spoke only for a moment, politely but formally.
As president of the League to Enforce Peace, Taft hoped to prevent war through an international association of nations. With World War I raging in Europe, Taft sent Wilson a note of support for his foreign policy in 1915. President Wilson accepted Taft's invitation to address the league, and spoke in May 1916 of a postwar international organization that could prevent a repetition. Taft supported the effort to get Justice Hughes to resign from the bench and accept the Republican presidential nomination. Once this was done, Hughes tried to get Roosevelt and Taft to reconcile, as a united effort was needed to defeat Wilson. This occurred on October 3 in New York, but Roosevelt allowed only a handshake, and no words were exchanged. This was one of many difficulties for the Republicans in the campaign, and Wilson narrowly won re-election.
When Wilson asked Congress to declare war on Germany in April 1917, Taft was an enthusiastic supporter. Taft was chairman of the American Red Cross' executive committee, occupying much of the former president's time. He took leave from Yale to be co-chairman of the National War Labor Board, tasked with assuring industrial peace. In February 1918, the new RNC chairman, Will Hays, approached Taft seeking his reconciliation with Roosevelt. In May, Taft was in Chicago at the Blackstone Hotel, and when he heard that Roosevelt and his party were dining there, walked in on them. The two men embraced to the applause of the room, but the renewed relationship did not progress past outward friendliness before Roosevelt's death in January 1919. Taft later wrote, "Had he died in a hostile state of mind toward me, I would have mourned the fact all my life. I loved him always and cherish his memory."
When Wilson proposed establishment of a League of Nations, with the League's charter part of the Treaty of Versailles, Taft expressed public support. He was out of step with his party, whose senators were not inclined to confirm the treaty. Taft's subsequent flip-flop on the issue of whether reservations to the treaty were necessary angered both sides, destroying any remaining influence he had with the Wilson administration, and causing some Republicans to call him a Wilson supporter and a traitor to his party. The Senate refused to ratify the Versailles pact.
Chief Justice (1921–1930).
Appointment.
During the 1920 election campaign, Taft supported the Republican ticket, Harding (by then a senator) and Massachusetts Governor Calvin Coolidge, who were elected. Taft was among those asked to come to the president-elect's home in Marion, Ohio to advise him on appointments, and the two men conferred there on December 24, 1920. By Taft's later account, after some conversation, Harding casually asked if Taft would accept appointment to the Supreme Court, for if Taft would, Harding would put him there. Taft had a condition for Harding: that having been president, and having appointed two of the present associate justices and opposed Brandeis, he could only accept the chief justiceship. Harding made no response, and Taft in a thank-you note reiterated the condition and stated that Chief Justice White had often told him he was keeping the position for Taft until a Republican held the White House. In January 1921, Taft heard through intermediaries that Harding planned to appoint him, if given the chance.
White by then was in failing health, but made no move to resign when Harding was sworn in on March 4, 1921. Taft called on the chief justice on March 26, and found White ill, but still carrying on his work and not talking of retiring. White did not retire, dying in office on May 19, 1921. Taft issued a tribute to the man he had appointed to the center seat, and waited and worried if he would be White's successor. Despite widespread speculation Taft would be the pick, Harding made no quick announcement. Taft was lobbying for himself behind the scenes, especially with the Ohio politicians who formed Harding's inner circle.
It later emerged that Harding had also promised former Utah senator George Sutherland a seat on the Supreme Court, and was waiting in the expectation that another place would become vacant. Harding was also considering a proposal by Justice William R. Day to crown his career by being chief justice for six months before retiring. Taft felt, when he learned of this plan, that a short-term appointment would not serve the office well, and that once confirmed by the Senate, the memory of Day would grow dim. After Harding rejected Day's plan, Attorney General Harry Daugherty, who supported Taft's candidacy, urged him to fill the vacancy, and he named Taft on June 30, 1921. The Senate confirmed Taft the same day, 61–4, without any committee hearings and after a brief debate in executive session. Taft drew the objections of three progressive Republicans and one southern Democrat. When he was sworn in on July 11, he became the first and to date only person to serve both as president and chief justice.
Jurisprudence.
Commerce Clause.
The Supreme Court, under Taft, posted a conservative record in Commerce Clause jurisprudence. This had the practical effect of making it difficult for the federal government to regulate industry, but the Taft Court also scuttled many state laws. The few liberals on the court—Brandeis, Holmes, and (from 1925) Harlan Fiske Stone—sometimes protested, believing orderly progress essential, but often joined in the majority opinion.
The White Court had, in 1918, struck down an attempt by Congress to regulate child labor in "Hammer v. Dagenhart". Congress thereafter attempted to end child labor by imposing a tax on certain corporations making use of it. That law was overturned by the Supreme Court in 1922 in "Bailey v. Drexel Furniture Co.", with Taft writing the court's opinion for an 8—1 majority. He held that the tax was not intended to raise revenue, but rather was an attempt to regulate matters reserved to the states under the Tenth Amendment, and that allowing such taxation would eliminate the power of the states. One case in which Taft and his court upheld federal regulation was "Stafford v. Wallace". Taft ruled for a 7–1 majority that the processing of animals in stockyards was so closely tied to interstate commerce as to bring it within the ambit of Congress's power to regulate.
A case in which the Taft Court struck down regulation that generated a dissent from the chief justice was "Adkins v. Children's Hospital". Congress had decreed a minimum wage for women in the District of Columbia. A 5–3 majority of the Supreme Court struck it down. Justice Sutherland wrote for the majority that the recently ratified Nineteenth Amendment, guaranteeing women the vote, meant that the sexes were equal when it came to bargaining power over working conditions; Taft, in dissent, deemed this unrealistic. Taft's dissent in "Adkins" was rare both because he authored few dissents, and because it was one of the few times he took an expansive view of the police power of the government.
Powers of government.
Taft in 1922 ruled for a unanimous court in "Balzac v. Porto Rico". One of the Insular Cases, "Balzac" involved a Puerto Rico newspaper publisher who was prosecuted for libel but denied a jury trial, a Sixth Amendment protection under the constitution. Taft held that as Puerto Rico was not a territory designated for statehood, only such constitutional protections as Congress decreed would apply to its residents.
In 1926, Taft wrote for a 6–3 majority in "Myers v. United States" that Congress could not require the president to get Senate approval before removing an appointee. Taft noted that there is no restriction of the president's power to remove officials in the constitution. Although "Myers" involved the removal of a postmaster, Taft in his opinion found invalid the repealed Tenure of Office Act, for violation of which his presidential predecessor, Andrew Johnson, had been impeached, though acquitted by the Senate. Taft valued "Myers" as his most important opinion.
The following year, the court decided "McGrain v. Daugherty". A congressional committee investigating possible complicity of former Attorney General Daugherty in the Teapot Dome scandal subpoenaed records from his brother, Mally, who refused to provide them, alleging Congress had no power to obtain documents from him. Van Devanter ruled for a unanimous court against him, finding that Congress had the authority to conduct investigations as an auxiliary to its legislative function.
Individual rights.
In 1925, the Taft Court laid the groundwork for the incorporation of many of the guarantees of the Bill of Rights to be applied against the states through the Fourteenth Amendment. In "Gitlow v. New York", the court by a 6–2 vote with Taft in the majority, upheld Gitlow's conviction on criminal anarchy charges for advocating the overthrow of the government; his defense was freedom of speech. Justice Edward T. Sanford wrote the court's opinion, and both majority and minority (Holmes, joined by Brandeis) assumed that the First Amendment's Free Speech and Free Press clauses were protected against infringement by the states.
"Pierce v. Society of Sisters" was a 1925 decision by the Taft Court striking down an Oregon law banning private schools. In a decision written by Justice James C. McReynolds, a unanimous court held that Oregon could regulate private schools, but could not eliminate them. The outcome supported the right of parents to control the education of their children, but also, since the lead plaintiff (the society) ran Catholic schools, struck a blow for religious freedom.
"United States v. Lanza" was one of a series of cases involving Prohibition. Lanza committed acts allegedly in violation of both state and federal law, and was first convicted in Washington state court, then prosecuted in federal district court. He alleged the second prosecution in violation of the Double Jeopardy Clause of the Fifth Amendment. Taft, for a unanimous court, allowed the second prosecution, holding that the state and federal governments were dual sovereigns, each empowered to prosecute the conduct in question.
Administration and political influence.
Taft exercised the power of his position to influence the decisions of his colleagues, urging unanimity and discouraging dissents. Alpheus Mason, in his article on Chief Justice Taft for the "American Bar Association Journal", contrasted Taft's expansive view of the role of the chief justice with the narrow view of presidential power he took while in that office. Taft saw nothing wrong with making his views on possible appointments to the court known to the White House, and was annoyed to be criticized in the press. He was initially a firm supporter of President Coolidge after Harding's death in 1923, but became disillusioned with Coolidge's appointments to office and to the bench; he had similar misgivings about Coolidge's successor, Herbert Hoover. Taft advised the Republican presidents in office while he was chief justice to avoid "offside" appointments like Brandeis and Holmes. Nevertheless, by 1923, Taft was writing of his liking for Brandeis, whom he deemed a hard worker, and Holmes walked to work with him until age and infirmity required an automobile.
Believing that the chief justice should be responsible for the federal courts, Taft felt that he should have an administrative staff to assist him, and the chief justice should be empowered to temporarily reassign judges. He also believed the federal courts had been ill-run. Many of the lower courts had lengthy backlogs, as did the Supreme Court. Immediately on taking office, Taft made it a priority to confer with Attorney General Daugherty as to new legislation, and made his case before congressional hearings, in legal periodicals and in speeches across the country. When Congress convened in December 1921, a bill was introduced for 24 new judges, to empower the chief justice to move judges temporarily to eliminate the delays, and to have him chair a body consisting of the senior appellate judge of each circuit. Congress objected to some aspects, requiring Taft to get the agreement of the senior judge of each involved circuit before assigning a judge, but it in September 1922 passed the bill, and the Judicial Conference of Senior Circuit Judges held its first meeting that December.
The Supreme Court's docket was congested, swelled by war litigation and laws that allowed a party defeated in the circuit court of appeals to have the case decided by the Supreme Court if a constitutional question was involved. Taft believed an appeal should be usually be settled by the circuit court, with only cases of major import decided by the justices. He and other Supreme Court members proposed legislation to make most of the court's docket discretionary, with a case getting full consideration by the justices only if they granted a writ of certiorari. To Taft's frustration, Congress took three years to consider the matter. Taft and other members of the court lobbied for the bill in Congress, and the Judges' Bill became law in February 1925. By late the following year, Taft was able to show that the backlog was shrinking.
When Taft became chief justice, the court did not have its own building and met in the Capitol. Its offices were cluttered and overcrowded, but Fuller and White had been opposed to proposals to move the court to its own building. In 1925, Taft began a fight to get the court a building, and two years later Congress appropriated money to purchase the land, on the south side of the Capitol. Cass Gilbert had prepared plans for the building, and was hired by the government as architect. Taft had hoped to live to see the court move into the new building, but it did not do so until 1935, after Taft's death.
Declining health and death.
Taft is remembered as the heaviest president; he was tall and his weight peaked at toward the end of his presidency, though this later decreased, and he weighed by 1929 just . By the time Taft became chief justice, his health was starting to decline, and he carefully planned a fitness regimen, walking from his home to the Capitol each day. When he walked after work as well, he would usually go by way of Connecticut Avenue; the crossing over Rock Creek he would often take was, after his death, named the Taft Bridge.
At Hoover's inauguration on March 4, 1929, Taft recited part of the oath incorrectly, later writing, "my memory is not always accurate and one sometimes becomes a little uncertain", misquoting again in that letter, but differently. His health gradually declined over the near-decade of his chief justiceship, and he wrote in 1929, "I am older and slower and less acute and more confused. However, as long as things continue as they are, and I am able to answer to my place, I must stay on the court in order to prevent the Bolsheviki from getting control".
Taft insisted on going to Cincinnati to attend the funeral of his brother Charles, who died on December 31, 1929; the strain did not improve his own health. When the court reconvened on January 6, 1930, Taft had not returned to Washington, and two opinions were delivered by Van Devanter that Taft had drafted but had been unable to complete because of his illness. Taft went to Asheville, North Carolina for a rest, but by the end of January, he could barely speak and was suffering from hallucinations. Taft was afraid that Stone would be made chief justice; he did not resign until he had secured assurances from Hoover that Hughes would be the choice. Returning to Washington after his resignation on February 3, Taft had barely enough strength to sign a reply to a letter of tribute from the eight associate justices. He died at his home in Washington on March 8, 1930.
Three days following his death, on March 11, he became the first president and first member of the Supreme Court to be buried at Arlington National Cemetery. James Earle Fraser sculpted his grave marker out of Stony Creek granite.
Legacy and historical view.
Lurie argued that Taft did not receive the public credit for his policies that he should have. Few trusts had been broken up under Roosevelt (although the lawsuits received much publicity). Taft, more quietly than his predecessor, filed many more cases than did Roosevelt, and rejected his predecessor's contention that there was such a thing as a "good" trust. This lack of flair marred Taft's presidency; according to Lurie, Taft "was boring—honest, likable, but boring". Mason called Taft's years in the White House "undistinguished". Coletta deemed Taft to have had a solid record of bills passed by Congress, but felt he could have accomplished more with political skill. Anderson noted that Taft's prepresidential federal service was entirely in appointed posts, and that he had never run for an important executive or legislative position, which would have allowed him to develop the skills to manipulate public opinion, "the presidency is no place for on-the-job training". According to Coletta, "in troubled times in which the people demanded progressive change, he saw the existing order as good."
Inevitably linked with Roosevelt, Taft generally falls in the shadow of the flamboyant Rough Rider, who chose him to be president, and who took it away. Yet, a portrait of Taft as a victim of betrayal by his best friend is incomplete: as Coletta put it, "Was he a poor politician because he was victimized or because he lacked the foresight and imagination to notice the storm brewing in the political sky until it broke and swamped him?" Adept at using the levers of power in a way his successor could not, Roosevelt generally got what was politically possible out of a situation. Taft was generally slow to act, and when he did, his actions often generated enemies, as in the Ballinger-Pinchot affair. Roosevelt was able to secure positive coverage in the newspapers; Taft had a judge's reticence in talking to journalists, and, with no comment from the White House, hostile journalists would supply the want with a quote from a Taft opponent. And it was Roosevelt who engraved in public memory the image of Taft as a Buchanan-like figure, with a narrow view of the presidency which made him unwilling to act for the public good. Anderson pointed out that Roosevelt's "Autobiography" (which placed this view in enduring form) was published after both men had left the presidency (in 1913), was intended in part to justify Roosevelt's splitting of the Republican Party, and contains not a single positive reference to the man Roosevelt had admired and hand-picked as his successor. While Roosevelt was biased, he was not alone: every major newspaper reporter of that time who left reminiscences of Taft's presidency was critical of him. Taft replied to his predecessor's criticism with his constitutional treatise on the powers of the presidency.
Taft was convinced he would be vindicated by history. After he left office, he was estimated to be about in the middle of U.S. presidents by greatness, and subsequent rankings by historians have by and large sustained that verdict. Coletta noted that this places Taft in good company, with James Madison, John Quincy Adams and McKinley. Lurie catalogued progressive innovations that took place under Taft, and opined that historians have overlooked them because Taft was not an effective political writer or speaker. According to Gould, "the clichés about Taft's weight, his maladroitness in the White House, and his conservatism of thought and doctrine have an element of truth, but they fail to do justice to a shrewd commentator on the political scene, a man of consummate ambition, and a resourceful practitioner of the internal politics of his party." Anderson deemed Taft's success in becoming both president and chief justice "an astounding feat of inside judicial and Republican party politics, played out over years, the likes of which we are not likely to see again in American history".
Taft has been rated among the best of the chief justices; later Supreme Court justice Antonin Scalia noted that this was "not so much on the basis of his opinions, perhaps because many of them ran counter to the ultimate sweep of history". A successor as chief justice, Earl Warren, concurred: "In Taft's case, the symbol, the tag, the label usually attached to him is 'conservative.' It is certainly not of itself a term of opprobrium even when bandied by the critics, but its use is too often confused with 'reactionary.' " Most commentators agree that as chief justice, Taft's most significant contribution was his advocacy for reform of the high court, urging and ultimately gaining improvement in the court's procedures and facilities. Mason cited enactment of the Judges' Bill of 1925 as Taft's major achievement on the court. According to Anderson, Taft as chief justice "was as aggressive in the pursuit of his agenda in the judicial realm as Theodore Roosevelt was in the presidential".
The house in Cincinnati where Taft was born and lived as a boy is now the William Howard Taft National Historic Site. Taft's son Robert was a significant political figure, becoming Senate Majority Leader and three times a major contender for the Republican nomination for president. A conservative, each time he was defeated by a candidate backed by the more liberal Eastern Establishment wing of the party.
Lurie concluded his account of William Taft's career,

</doc>
