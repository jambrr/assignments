<doc id="60355" url="https://en.wikipedia.org/wiki?curid=60355" title="Amherst College">
Amherst College

Amherst College ( ) is a private liberal arts college located in Amherst, Massachusetts, United States. Founded in 1821 as an attempt to relocate Williams College by its president, Zephaniah Swift Moore, Amherst is the third oldest institution of higher education in Massachusetts. The institution was named after the town, which in turn had been named after Lord Jeffery Amherst. Amherst was established as a men's college and became coeducational in 1975.
Amherst is an exclusively undergraduate four-year institution and enrolled 1,795 students in the fall of 2015. Students choose courses from 38 major programs in an open curriculum. Students are not required to study a core curriculum or fulfill any distribution requirements and may even design their own unique interdisciplinary major. Freshmen may take advanced courses, and seniors may take introductory ones. For the class of 2020, Amherst received 8,397 applications and accepted 1,149 yielding a 13.7% acceptance rate. Amherst was ranked as the second best liberal arts college in the country by "U.S. News & World Report", and ninth out of all U.S. colleges and universities by "Forbes" in their 2015 rankings. Amherst competes in the New England Small College Athletic Conference. 
Amherst has historically had close relationships and rivalries with Williams College and Wesleyan University which form the Little Three colleges. The college is a member of the Five Colleges consortium, which allows its students to attend classes at four other Pioneer Valley institutions. These include Mount Holyoke College, Smith College, Hampshire College, and the University of Massachusetts Amherst.
The college has graduated Nobel, Crafoord Prize and Lasker Award laureates, MacArthur Fellowship and Pulitzer Prize winners, National Medal of Science and National Book Award recipients, and Academy, Tony, Grammy Award and Emmy Award winners; a U.S. President, the current Sovereign Prince of Monaco, two prime ministers of Greece, as well as Uhuru Kenyatta, the fourth president of Kenya, a Chief Justice of the United States, three Speakers of the U.S. House of Representatives, a U.S. Poet Laureate, the legal architect of "Brown v Board of Education", and Charles R. Drew, the inventor of the blood bank.
History.
Founding and 19th century.
Founded in 1821, Amherst College developed out of the secondary school Amherst Academy. The college was originally suggested as an alternative to Williams College, which was struggling to stay open. Although Williams remained open, Amherst was formed and diverged from its Williams roots into an individual institution.
In 1812, funds were raised in Amherst for a secondary school, Amherst Academy; it opened December 1814. The institution was named after the town, which in turn had been named after Jeffery, Lord Amherst, a veteran from the Seven Years' War and later commanding general of the British forces in North America. On November 18, 1817, a project was adopted at the Academy to raise funds for the free instruction of "indigent young men of promising talents and hopeful piety, who shall manifest a desire to obtain a liberal education with a sole view to the Christian ministry." This required a substantial investment from benefactors.
During the fundraising for the project, it became clear that without larger designs, it would be impossible to raise sufficient funds. This led the committee overseeing the project to conclude that a new institution should be created. On August 18, 1818, the Amherst Academy board of trustees accepted this conclusion and began building a new college.
Establishment.
Moore, then President of Williams College, however, still believed that Williamstown was an unsuitable location for a college, and with the advent of Amherst College was elected its first president on May 8, 1821. At its opening, Amherst had forty-seven students. Fifteen of these had followed Moore from Williams College. Those fifteen represented about one-third of the whole number at Amherst, and about one-fifth of the whole number in the three classes to which they belonged in Williams College. President Moore died on June 29, 1823, and was replaced with a Williams College trustee, Heman Humphrey. Williams alumni are fond of an apocryphal story ascribing the removal of books from the Williams College library to Amherst College, but there is no contemporaneous evidence to verify the story. In 1995, Williams president Harry C. Payne declared the story false, but many still nurture the legend.
Amherst grew quickly, and for two years in the mid-1830s it was the second largest college in the United States, second only to Yale. In 1835, Amherst attempted to create a course of study parallel to the classical liberal arts education. This parallel course focused less on Greek and Latin, instead focusing on English, French, Spanish, chemistry, economics, etc. The parallel course did not take hold, however, until the next century.
Amherst was founded as a non-sectarian institution "for the classical education of indigent young men of piety and talents for the Christian ministry." (Tyler, "A History of Amherst College") One of the hallmarks of the new college was its Charity Fund, an early form of financial aid that paid the tuition of poorer students. Although officially non-denominational, the initial Amherst was widely seen as a religiously conservative institution with a strong connection to Calvinism, and as a result, there was considerable debate in the Massachusetts government over whether the new college should receive an official charter from the state, and a charter was not granted until February 21, 1825. As a result of the official charter being granted four years after the official founding of the college, the Amherst seal lists a date of 1825. A tradition of religious conservatism persisted at Amherst until the mid-nineteenth century; students who consumed alcohol or played cards were subject to expulsion, and there were a number of religious revivals at Amherst where mobs of righteous students would herd less religious students into the chapel and berate them for lack of piety. Towards the end of the nineteenth century, however, the college began a transition towards secularism, culminating in the demolishing of the college church in 1949.
Development and academic reform.
Academic hoods in the United States are traditionally lined with the official colors of the school, in theory so watchers can tell where the hood wearer earned his or her degree. Amherst's hoods are purple (Williams' official color) with a white stripe or chevron, said to signify that Amherst was born of Williams. Amherst records one of the first uses of Latin honors of any American college, dating back to 1881. The college was an all-male school until the late 1960s, when a few female students from nearby schools in the Five-College Consortium attended on an experimental basis. In October 1974, the faculty voted in favor of coeducation and in November 1974 the board of trustees voted to admit female students starting in the 1975-1976 school year. In 1975, nine women who were already attending classes as part of an inter-college exchange program were admitted as transfer students. In June 1976, they became the first female graduates of the college.
The college established the Black Studies Department in 1969. In 1973, it launched the nation's first undergraduate neuroscience program. In 1983, it established a Department of Asian Languages and Literatures, which was later to become the Department of Asian Languages and Civilizations. 
In 1984, on-campus fraternities were abolished. The former fraternity buildings, which were owned by the college, were converted into residence halls.
The Department of Women's and Gender Studies was established in 1987 and the Department of Law, Jurisprudence, and Social Thought in 1993.
Rankings.
Since the inception of the "U.S. News & World Report" rankings, Amherst College has been ranked ten times as the first overall amongst 266 liberal arts colleges in the United States, and in 2016 ranked second, behind Williams. In 2015, "Forbes" ranked Amherst College as the ninth best college or university in the United States.
"Kiplinger's Personal Finance" places Amherst 11th in its 2016 ranking of best value liberal arts colleges in the United States.
Amherst College ranked second overall in 2012, according to the National Collegiate Scouting Association's annual report, which ranks colleges based on student-athlete graduation rates, academic strength, and athletic prowess.
Amherst ranked as having the second-highest graduation rate of any institution in the United States, second only to Harvard according to a 2009 American Enterprise Institute Study.
Amherst ranked 18th in the 2015 "Washington Monthly" rankings, which focus on key research outputs, the quality level and total dollar amount of scientific (natural and social sciences) grants won, the number of graduates going on to earn Ph.D. degrees, and certain types of public service.
According to "The Princeton Review", Amherst ranks in the top 20 among all colleges and universities in the nation for "Students Satisfied With Financial Aid," "School Runs Like Butter," and "Top 10 Best Value Private Schools."
Amherst also participates in the University and College Accountability Network (U-CAN) developed by the National Association of Independent Colleges and Universities (NAICU). Amherst’s sustainability efforts earned it an overall grade of “A-” on the College Sustainability Report Card 2010 published by the Sustainable Endowments Institute.
Admissions.
Amherst has been dubbed a "most selective" liberal arts colleges in the United States; the Carnegie Foundation classifies Amherst as one of the "more selective" institutions whose first-year students’ test scores places these institutions in roughly the top fifth of baccalaureate institutions. For the class first enrolled in Fall 2015, Amherst received 8,568 applications and accepted 1,210 for a 14% acceptance rate. Of the 477 enrolling, 53% were women. In terms of class rank, 86% of enrolled freshmen were in the top 10% of their high school classes; 96% ranked in the top quarter. The middle 50% range of SAT scores of enrolled freshmen was 680-780 for critical reading, 680-780 for math, and 680-770 for writing; the middle 50% range of the ACT Composite score was 31-34.
Amherst's comprehensive tuition, room, and board fee for the 2012–13 academic year is $55,510. Once miscellaneous expenses are factored in the total cost to attend for the 2012–13 academic year amounts to $60,809–$63,259.
Despite its high cost of attendance, Amherst College meets the full demonstrated need of every admitted student. Sixty percent of current students receive scholarship aid, and the average financial aid package award amounts to $41,150; the average net price of attendance is $13,809 per year. College expenditures exceed $85,000 per student each year.
In July 2007, Amherst announced that grants would replace loans in all financial aid packages beginning in the 2008-09 academic year. Amherst had already been the first school to eliminate loans for low-income students, and with this announcement it joined Princeton University, Cornell University and Davidson College, then the only colleges to completely eliminate loans from need-based financial aid packages. Increased rates of admission of highly qualified lower income students has resulted in greater equality of opportunity at Amherst than is usual at elite American colleges.
In the 2008-2009 academic year, Amherst College also extended its need-blind admission policy to international applicants.
Academics.
Amherst College offers 36 fields of study (with 850 courses) in the sciences, arts, humanities, mathematics and computer sciences, social sciences, foreign languages, classics, and several interdisciplinary fields (including premedical studies) and provides an unusually open curriculum. Students are not required to study a core curriculum or fulfill any distribution requirements and may even design their own unique interdisciplinary major. Freshmen may take advanced courses, and seniors may take introductory ones.
Thirty-five percent of Amherst students in the class of 2007 were double majors. Amherst College has been the first college to have undergraduate departments in the interdisciplinary fields of American Studies; Law, Jurisprudence and Social Thought; and Neuroscience and has helped to pioneer other interdisciplinary programs, including Asian Languages and Civilizations.
The Amherst library is named for long-time faculty member, poet Robert Frost. Amherst College has been recognized for its commitment to quality teaching, with professor-student interaction, so much so that Harvard and Columbia University looked to Amherst in 2007 when they were in the throes of reviewing their teaching program. The student-faculty ratio is 8:1 and 90% of classes have fewer than 30 students.
Notable faculty members include, among others, modern literature and poetry critic William H. Pritchard, Beowulf translator Howell Chickering, Jewish and Latino studies scholar Ilan Stavans, novelist and legal scholar Lawrence Douglas, physicist Arthur Zajonc, Pulitzer Prize-winning Nikita Khrushchev biographer William Taubman, African art specialist Rowland Abiodun, Natural Law expert Hadley Arkes, Mathematician Daniel Velleman, Biblical scholar Susan Niditch, law and society expert Austin Sarat, and Pulitzer Prize-winning composer Lewis Spratlan, professor emeritus of the music faculty.
Academic freedom debate.
The writings of Amherst College political science Professor Hadley Arkes about homosexuality led to a dispute in 2013 over whether a college seeking to create a diverse, respectful academic community should speak out when a faculty member disparages community members or should instead remain silent as a way to protect academic freedom. The issue arose when a group of alumni petitioned the college trustees and President Biddy Martin to “dissociate the institution” from Arkes’s “divisive and destructive” views, focusing particularly on his May 2013 comparison of homosexuality to bestiality, pedophilia and necrophilia. The alumni said, “Amherst College cannot credibly maintain its professed commitment to be an inclusive community as long as it chooses to remain silent while a sitting professor disparages members of its community in media of worldwide circulation and accessibility.”
Martin disagreed, citing past debates over the college’s position on Vietnam War and apartheid in South Africa—issues on which the college initially remained silent but eventually took a public position. In such times, she said, colleges should “avoid taking institutional positions on controversial political matters, except in extraordinary circumstances” and should simultaneously both “protect their communities from discrimination and disrespect” and “cherish a diversity of viewpoints.”
Five College Consortium.
Amherst is a member of the Five Colleges consortium, which allows its students to attend classes at four other Pioneer Valley institutions. These include Mount Holyoke College, Smith College, Hampshire College, and the University of Massachusetts Amherst. In addition to the 850 courses available on campus, Amherst students have an additional 5,300 classes to consider through the Consortium (without paying additional tuition) and access to 8 million library volumes. The Five Colleges are geographically close to one another and are linked by buses that run between the campuses.
The Five Colleges share resources and develop common academic programs. Museums10 is a consortium of local art, history and science museums. The Five College Dance Department is one of the largest in the nation. The joint Astronomy department shares use of the Five College Radio Astronomy Observatory, which contributed to work that won the 1993 Nobel Prize in Physics.
The Five College Coastal and Marine Sciences Program offers an interdisciplinary curriculum to undergraduates in the Five Colleges.
Sustainability.
Amherst College is reducing its energy consumption through a computerized monitoring system for lighting and the use of an efficient cogeneration facility. The cogeneration facility features a gas turbine that generates electricity in addition to steam for heating the campus. Amherst also operates a composting program, in which a portion of the food waste from dining halls is sent to a farmer in Vermont.
Athletics.
Amherst claims its athletics program as the oldest in the nation, pointing to its compulsory physical fitness regimen put in place in 1860 (the mandate that all students participate in sports or pursue physical education has been discontinued). One-third of the student body participates in sports at the intercollegiate level, and eighty percent participate in intramural and club sports teams.
The school participates in the NCAA's Division III, the Eastern College Athletic Conference, and the New England Small College Athletic Conference, which includes Bates, Bowdoin, Colby, Connecticut College, Hamilton, Middlebury, Trinity, Tufts, Wesleyan, and Williams College.
Amherst is also one of the "Little Three," along with Williams and Wesleyan. A Little Three champion is informally recognized by most teams based on the head-to-head records of the three schools, but three-way competitions are held in some of the sports.
Amherst has placed in the top ten of the NACDA Director's Cup in the NCAA Division III in seven of the last ten years, including fourth in 2007 and 2008 and third in 2009. On May 3, 2009, Williams College and Amherst alumni played a game of vintage baseball at Wahconah Park according to 1859 rules to commemorate the 150th anniversary of the first college baseball game played on July 2, 1859, between the two schools.
Amherst fields several club athletic teams, including rugby union, water polo, ultimate, equestrian, mountain biking, crew, fencing, sailing and skiing. Intramural sports include soccer, tennis, golf, basketball, volleyball and softball.
The sport of Ultimate was started and named at Amherst College in the mid-1960s by Jared Kass '69.
Student life.
Students.
Amherst's resources, faculty, and academic life allow the college to enroll students with a range of talents, interests, and commitments. Students represent all fifty states, the District of Columbia, Puerto Rico, and fifty countries. Ninety-seven percent of students live on campus. Ninety-seven percent of Amherst freshmen return for their sophomore year; ninety-six percent graduate, among the highest retention and graduation rates in the country. There are more than 140 student groups at Amherst. Students pursue their interests through student-led organizations funded by the student government, including a variety of cultural and religious groups, publications, fine and performing arts and political advocacy and service groups. Groups include a medieval sword-fighting club, a knitting club, and a club devoted to random acts of kindness, among others. Community service groups and opportunities (locally—through the Center for Community Engagement, nationally, and internationally) have been a priority at Amherst and for former President Anthony Marx, who helped start a secondary school for black students in apartheid South Africa.
One of the longstanding traditions at the college involves the Sabrina Statue. Even year and odd year classes battle for possession of the historic statue, often engaging in elaborate pranks in the process.
Controversies.
Sexual assault.
Concerns over issues of sexual respect on the campus (sparked in part by controversy over a fraternity's misogynist T-shirt design) and allegations of inappropriate handling of a case of sexual assault in an essay by Angie Epifano published in "The Amherst Student" led President Biddy Martin to begin a community-wide review of the sexual misconduct and disciplinary policies at the College. In January 2013, a college committee published a report noting Amherst's rate of sexual assault as similar to other colleges and universities and making recommendations to address the problem.
After a complaint was filed by Epifano and an anonymous former student in November 2013, the US Department of Education opened an investigation into the college's handling of sexual violence and potential violations of Title IX. In May 2014, the Department of Education announced a list of 55 colleges and universities (including Amherst) currently under investigation.
From 2009 to 2011, Amherst reported 35 instances of "forcible sex offenses," a term that encompasses rape, attempted rape, and lesser forms of sexual contact.
Discrimination lawsuit.
In December 2015, a lawsuit against Amherst College was filed alleging that "teaching assistants [...] were encouraged to sleep with and socialize with students to boost enrollment in the Spanish department."
Mascot.
The original unofficial mascot of Amherst College, Lord Jeffrey Amherst, concerned many members of the Amherst school and community who sought to remove the school from the passive condoning of the wrongs committed by Lord Jeffrey Amherst. In May 2014, after a wild moose found its way onto the Amherst College campus and into the backyard of the house of the college president, students organized a Facebook campaign to change the mascot of the school to a moose. The page grew rapidly in popularity, receiving over 900 "likes" in under two weeks, and inspiring both a Twitter and Tumblr account for the newly proposed mascot. On May 25, at the Commencement ceremony for the class of 2014, the moose mascot was mentioned by Biddy Martin in her address, and the Dining Hall served Moose Tracks ice cream in front of an ice sculpture of a moose. Nearly a year later, in February 2015, discussion of a mascot change continued when the editorial board of the Amherst Student, the college's official student-run newspaper, came out in favor of "the moose-scot". In November 2015 the student body and the faculty overwhelmingly voted to vacate the mascot; the decision to drop the mascot was made official on January 26, 2016 after student anti-racism protests on campus.
Alumni.
Although a relatively small college, Amherst has many accomplished alumni, including Nobel, Crafoord Prize and Lasker Award laureates, MacArthur Fellowship and Pulitzer Prize winners, National Medal of Science and National Book Award recipients, and Academy, Tony, Grammy Award and Emmy Award winners; a U.S. President, the current Sovereign Prince of Monaco, two prime ministers of Greece, as well as Uhuru Kenyatta, the fourth president of Kenya, a Chief Justice of the United States, three Speakers of the U.S. House of Representatives, a U.S. Poet Laureate, the legal architect of "Brown v Board of Education", and the inventor of the blood bank; leaders in science, religion, politics, the Peace Corps, medicine, law, education, communications, and business; and acclaimed actors, architects, artists, astronauts, engineers, human rights activists, inventors, musicians, philanthropists, and writers.
There are approximately 20,000 living alumni, of which about 60% make a gift to Amherst each year—one of the highest alumni participation rates of any college in the country.

</doc>
<doc id="60356" url="https://en.wikipedia.org/wiki?curid=60356" title="Albany, California">
Albany, California

Albany (formerly Ocean View) is a city in Alameda County, California, United States. The population was 18,539 at the 2010 census.
History.
In 1908, a group of local women protested the dumping of Berkeley garbage in their community. Armed with two shotguns and a twenty-two-caliber rifle, they confronted the drivers of the wagons near what is now the corner of San Pablo Avenue and Buchanan Street. The women told the drivers of the horse-drawn garbage wagons to go home, which they did quickly and without complaint. Shortly thereafter, the residents of the town voted to incorporate as the City of Ocean View. In 1909, voters changed the name of the city, primarily to distinguish the city from the adjacent section of Berkeley which had previously been named Ocean View. On a vote of 38 to 6 the city was renamed in honor of Albany, New York, the birthplace of the city's first mayor, Frank Roberts.
Geography.
According to the United States Census Bureau, the city has a total area of , of which is land and (67.28%) is water.
The principal shopping street in Albany is Solano Avenue, which cuts across the city from west to east. Another important street is San Pablo Avenue, which travels from north to south.
Albany is located on the eastern shore of San Francisco Bay, bordering the city of Berkeley to the south and east, and the Contra Costa County cities of El Cerrito and Richmond to the north. Albany's northern and southern borders are defined by two creeks, Codornices Creek on the south and Cerrito Creek on the north. Cerrito Creek takes its name from "El Cerrito de San Antonio", now known as Albany Hill. The hill's unusual location near the bay shore makes it a prominent landmark in the East Bay. The rest of the city is relatively flat by Bay Area standards, except for a small area near the base of the Berkeley Hills.
Albany's waterfront has undergone significant man-made changes; the most prominent landform is now the Albany Bulb, a former garbage landfill jutting out into San Francisco Bay. The bulb was the site of a small art colony and shanty town until it was cleared to turn the area into part of the new Eastshore State Park.
University Village, a housing unit of the University of California Berkeley, is located in Albany.
Demographics.
The 2010 United States Census reported that Albany had a population of 18,539. , Albany had a population of 18,969. The population density was 3,392.1 people per square mile (1,309.7/km2). The racial makeup of Albany was 10,128 (54.6%) White, 645 (3.5%) African American, 88 (0.5%) Native American, 5,790 (31.2%) Asian, 37 (0.2%) Pacific Islander, 607 (3.3%) from other races, and 1,244 (6.7%) from two or more races. Hispanic or Latino of any race were 1,891 persons (10.2%).
The Census reported that 18,454 people (99.5% of the population) lived in households, 74 (0.4%) lived in non-institutionalized group quarters, and 11 (0.1%) were institutionalized.
There were 7,401 households, out of which 2,909 (39.3%) had children under the age of 18 living in them, 3,801 (51.4%) were opposite-sex married couples living together, 883 (11.9%) had a female householder with no husband present, 295 (4.0%) had a male householder with no wife present. There were 341 (4.6%) unmarried opposite-sex partnerships, and 123 (1.7%) same-sex married couples or partnerships. 1,862 households (25.2%) were made up of individuals and 593 (8.0%) had someone living alone who was 65 years of age or older. The average household size was 2.49. There were 4,979 families (67.3% of all households); the average family size was 3.00.
The population was spread out with 4,630 people (25.0%) under the age of 18, 1,006 people (5.4%) aged 18 to 24, 6,154 people (33.2%) aged 25 to 44, 4,902 people (26.4%) aged 45 to 64, and 1,847 people (10.0%) who were 65 years of age or older. The median age was 37.0 years. For every 100 females there were 90.8 males. For every 100 females age 18 and over, there were 86.9 males.
There were 7,889 housing units at an average density of 1,443.5 per square mile (557.3/km2), of which 3,574 (48.3%) were owner-occupied, and 3,827 (51.7%) were occupied by renters. The homeowner vacancy rate was 1.0%; the rental vacancy rate was 6.2%. 9,070 people (48.9% of the population) lived in owner-occupied housing units and 9,384 people (50.6%) lived in rental housing units.
Economy.
The major retail and business areas in Albany are Solano Avenue, which is a pedestrian-oriented street lined with mainly small shops, restaurants, and services; San Pablo Avenue, which is more automobile-oriented; and an area near the Eastshore Freeway, to which the city is trying to attract big-box stores and offices, and currently houses a two-story Target store.
Albany is the site of Golden Gate Fields, the only horse racing track in the Bay Area.
Real estate prices have been rising steeply in recent years until the 2008 financial crisis and recession. The median price of a single family home and condo in Census 2000, June 2007, November 2009, July 2011, August 2013 and August 2014 were $334,800, $687,500, $610,000, $590,000, $625,750 and $820,050 respectively.
Top employers.
According to Albany's 2013 Comprehensive Annual Financial Report, the top employers in the city are:
Education.
Public schools in Albany are operated by the Albany Unified School District, a special-purpose district whose borders match the city's. The school district operates three elementary schools (Marin, Ocean View and Cornell School), one middle school (Albany Middle School), one traditional high school (Albany High School), and one continuation high school, in addition to an adult school. Albany High School is known as one of the best public schools of the San Francisco Bay Area for its academic excellence. The high school had a graduation rate of 92.1%, according to the 2009–10 School Accountability Report Card for the prior academic year.
There are two private high schools in Albany: Tilden Preparatory School (formerly School for Independent Learners) on Solano Avenue and St. Mary's College High School, whose campus straddles the border with Berkeley, CA.
The University of California, Berkeley owns a large student housing complex in Albany, University Village, which is primarily used for family housing.
Arts, culture, and recreation.
The Solano Avenue Stroll, an annual street festival held on Solano Avenue in Albany and Berkeley, attracts more than 250,000 visitors on the second Sunday of September. The event was started in 1975 by "The Iris" store owner and Solano Avenue Association founder Ira Klein as a "thank you party" from Solano Avenue business owners to customers. The Library of Congress designated the Solano Stroll as a "National Local Legacy" in 2001.
Albany provides both the locale and the title for one of the best-known poems in language poetry, by former long-time Albany resident, poet Ron Silliman.
Albany also has a large little league, which draws children from around the area. The Albany Little League has gone to state tournaments with their junior and Majors levels. In 2008, Albany won its first championship in the Little League.
Albany is home to Golden Gate Fields, the only commercial racetrack in the Bay Area, as well as the Eastshore State Park which skirts the San Francisco Bay, and the Albany Bulb.
Albany has a strong school music program. High school music groups, both instrumental and choral, have performed at the CMEA, Reno Jazz, and other festivals. The Albany High School Jazz Band was also accepted at the Essentially Ellington festival at the Lincoln Center in 2010. Albany was one of 15 schools accepted into the festival.
Albany Strollers & Rollers is a volunteer group dedicated to service and advocacy for bicycling and walking.
Friends of Five Creeks is an all-volunteer group working hands-on for clean water and healthy watersheds.

</doc>
<doc id="60357" url="https://en.wikipedia.org/wiki?curid=60357" title="Evans Hall">
Evans Hall

Evans Hall is a common name for buildings on college and university campuses. Colleges which have an Evans Hall include:

</doc>
<doc id="60358" url="https://en.wikipedia.org/wiki?curid=60358" title="Internal rate of return">
Internal rate of return

The internal rate of return (IRR) or economic rate of return (ERR) is a method of calculating rate of return. The term "internal" refers to the fact that its calculation does not incorporate environmental factors (e.g., the interest rate or inflation). 
It is also called the discounted cash flow rate of return (DCFROR). 
In the context of savings and loans, the IRR is also called the effective interest rate. 
Definition.
The internal rate of return on an investment or project is the "annualized effective compounded return rate" or rate of return that makes the net present value of all cash flows (both positive and negative) from a particular investment equal to zero. It can also be defined as the discount rate at which the present value of all future cash flow is equal to the initial investment or, in other words, the rate at which an investment breaks even.
Equivalently, the IRR of an investment is the discount rate at which the net present value of costs (negative cash flows) of the investment equals the net present value of the benefits (positive cash flows) of the investment.
Uses of IRR.
IRR is used in capital budgeting to measure and compare the profitability of investments. 
IRR calculations are commonly used to evaluate the desirability of investments or projects. The higher a project's IRR, the more desirable it is to undertake the project. Assuming all projects require the same amount of up-front investment, the project with the highest IRR would be considered the best and undertaken first.
A firm (or individual) should, in theory, undertake all projects or investments available with IRRs that exceed the cost of capital. Investment may be limited by availability of funds to the firm and/or by the firm's capacity or ability to manage numerous projects.
Because the internal rate of return is a rate quantity, it is an indicator of the efficiency, quality, or yield of an investment. This is in contrast with the net present value, which is an indicator of the value or magnitude of an investment.
An investment is considered acceptable if its internal rate of return is greater than an established minimum acceptable rate of return or cost of capital. In a scenario where an investment is considered by a firm that has shareholders, this minimum rate is the cost of capital of the investment (which may be determined by the risk-adjusted cost of capital of alternative investments). This ensures that the investment is supported by equity holders since, in general, an investment whose IRR exceeds its cost of capital adds value for the company (i.e., it is economically profitable).
One of the uses of IRR is by corporations that wish to compare capital projects. For example, a corporation will evaluate an investment in a new plant versus an extension of an existing plant based on the IRR of each project. In such a case, each new capital project must produce an IRR that is higher than the company's cost of capital. Once this hurdle is surpassed, the project with the highest IRR would be the wiser investment, all other things being equal (including risk).
IRR is also useful for corporations in evaluating stock buyback programs. Clearly, if a company allocates a substantial amount to a stock buyback, the analysis must show that the company's own stock is a better investment (has a higher IRR) than any other use of the funds for other capital projects, or than any acquisition candidate at current market prices.
IRR is also suitable for private equity, from the limited partners' perspective, as a measure of the general partner's performance as investment manager. This is because it is the general partner who controls the cash flows, including the limited partners' draw-downs of committed capital.
Calculation.
Given a collection of pairs (time, cash flow) involved in a project, the internal rate of return follows from the net present value as a function of the rate of return. A rate of return for which this function is zero is an internal rate of return.
Given the (period, cash flow) pairs (formula_1, formula_2) where formula_1 is a positive integer, the total number of periods formula_4, and the formula_5, (net present value); the IRR is given by formula_6 in:
The period formula_1 is usually given in years, but the calculation may be made simpler if formula_6 is calculated using the period in which the majority of the problem is defined (e.g., using months if most of the cash flows occur at monthly intervals) and converted to a yearly period thereafter.
Any fixed time can be used in place of the present (e.g., the end of one interval of an annuity); the value obtained is zero if and only if the NPV is zero.
In the case that the cash flows are random variables, such as in the case of a life annuity, the expected values are put into the above formula.
Often, the value of formula_6 cannot be found analytically. In this case, numerical methods or graphical methods must be used.
Example.
If an investment may be given by the sequence of cash flows
then the IRR formula_6 is given by
In this case, the answer is 5.96% (in the calculation, that is, r = .0596).
Numerical solution.
Since the above is a manifestation of the general problem of finding the roots of the equation formula_13, there are many numerical methods that can be used to estimate formula_6. For example, using the secant method, formula_6 is given by
where formula_17 is considered the formula_1th approximation of the IRR.
This formula_6 can be found to an arbitrary degree of accuracy. An accuracy of 0.00001% is provided by Microsoft Excel.
The convergence behaviour of by the following:
Having formula_27 when formula_28 or formula_29 when formula_30 may speed up convergence of formula_17 to formula_6.
Numerical solution for single outflow and multiple inflows.
Of particular interest is the case where the stream of payments consists of a single outflow, followed by multiple inflows occurring at equal periods. In the above notation, this corresponds to:
In this case the NPV of the payment stream is a convex, strictly decreasing function of interest rate. There is always a single unique solution for IRR.
Given two estimates formula_34 and formula_35 for IRR, the secant method equation (see above) with formula_36 always produces an improved estimate formula_37. This is sometimes referred to as the Hit and Trial (or Trial and Error) method. More accurate interpolation formulas can also be obtained: for instance the secant formula with correction
(which is most accurate when formula_39) has been shown to be almost 10 times more accurate than the secant formula for a wide range of interest rates and initial guesses. For example, using the stream of payments {−4000, 1200, 1410, 1875, 1050} and initial guesses formula_40 and formula_41 the secant formula with correction gives an IRR estimate of 14.2% (0.7% error) as compared to IRR = 13.2% (7% error) from the secant method. Other improved formulas may be found in
If applied iteratively, either the secant method or the improved formula always converges to the correct solution.
Both the secant method and the improved formula rely on initial guesses for IRR. The following initial guesses may be used:
where
Here, formula_46 refers to the NPV of the inflows only (that is, set formula_47 and compute NPV).
Problems with using internal rate of return.
As an investment decision tool, the calculated IRR should "not" be used to rate mutually exclusive projects, but only to decide whether a single project is worth investing in. cases where one project has a higher initial investment than a second mutually exclusive project, the first project may have a lower IRR (expected return), but a higher NPV (increase in shareholders' wealth) and should thus be accepted over the second project (assuming no capital constraints).
IRR should not be used to compare projects of different duration. For example, the net present value added by a project with longer duration but lower IRR could be greater than that of a project of similar size, in terms of total net cash flows, but with shorter duration and higher IRR.
Modified Internal Rate of Return (MIRR) considers cost of capital, and is intended to provide a better indication of a project's probable return.
In the case of positive cash flows followed by negative ones and then by positive ones (for example, + + − − − +) the IRR may have multiple values. In this case a discount rate may be used for the borrowing cash flow and the IRR calculated for the investment cash flow. This applies for example when a customer makes a deposit before a specific machine is built.
In a series of cash flows like (−10, 21, −11), one initially invests money, so a high rate of return is best, but then receives more than one possesses, so then one owes money, so now a low rate of return is best. In this case it is not even clear whether a high or a low IRR is better. There may even be multiple IRRs for a single project, like in the example 0% as well as 10%. Examples of this type of project are strip mines and nuclear power plants, where there is usually a large cash outflow at the end of the project.
In general, the IRR can be calculated by solving a polynomial equation. Sturm's theorem can be used to determine if that equation has a unique real solution. In general the IRR equation cannot be solved analytically but only iteratively.
When a project has multiple IRRs it may be more convenient to compute the IRR of the project with the benefits reinvested. Accordingly, MIRR is used, which has an assumed reinvestment rate, usually equal to the project's cost of capital.
It has been shown that with multiple internal rates of return, the IRR approach can still be interpreted in a way that is consistent with the present value approach provided that the underlying investment stream is correctly identified as net investment or net borrowing.
See also for a way of identifying the relevant value of the IRR from a set of multiple IRR solutions.
Despite a strong academic preference for NPV, surveys indicate that executives prefer IRR over NPV. Apparently, managers find it easier to compare investments of different sizes in terms of percentage rates of return than by dollars of NPV. However, NPV remains the "more accurate" reflection of value to the business. IRR, as a measure of investment efficiency may give better insights in capital constrained situations. However, when comparing mutually exclusive projects, NPV is the appropriate measure.
Mathematics.
Mathematically, the value of the investment is assumed to undergo exponential growth or decay according to some rate of return (any value greater than −100%), with discontinuities for cash flows, and the IRR of a series of cash flows is defined as any rate of return that results in a net present value of zero (or equivalently, a rate of return that results in the correct value of zero after the last cash flow).
Thus, internal rate(s) of return follow from the net present value as a function of the rate of return. This function is continuous. Towards a rate of return of −100% the net present value approaches infinity with the sign of the last cash flow, and towards a rate of return of positive infinity the net present value approaches the first cash flow (the one at the present). Therefore, if the first and last cash flow have a different sign there exists an internal rate of return. Examples of time series without an IRR:
In the case of a series of exclusively negative cash flows followed by a series of exclusively positive ones, the resulting function of the rate of return is continuous and monotonically decreasing from positive infinity (when the rate of return approaches -100%) to the value of the first cash flow (when the rate of return approaches infinity), so there is a unique rate of return for which it is zero. Hence, the IRR is also unique (and equal). Although the NPV-function itself is not necessarily monotonically decreasing on its whole domain, it "is" at the IRR.
Similarly, in the case of a series of exclusively positive cash flows followed by a series of exclusively negative ones the IRR is also unique.
Finally, by Descartes' rule of signs, the number of internal rates of return can never be more than the number of changes in sign of cash flow.
The reinvestment misconception.
It is often stated that IRR assumes reinvestment of all cash flows until the very end of the project. This is a misconception. There is no hidden reinvestment assumption associated with the calculation of IRR. IRR is simply the solution to the equation in the example shown above. The cash flows are static. The NPV is set at zero. There is only one unknown variable in the equation, namely r.
This misconception likely stems from the modified internal rate of return (MIRR) concept, which allows for inclusion of a second, subsequent investment. If the reinvestment rate is set at IRR, the MIRR equals the IRR. This is hardly a surprise - compounding cash flows (with the IRR) and then discounting them using the same discount factor (the IRR) is obviously a zero-sum game.
Sources stating that there is such a hidden assumption include those cited below. Sources arguing that there is no IRR reinvestment assumption include
The internal rate of return in personal finance.
The IRR can be used to measure the money-weighted performance of financial investments such as an
individual investor's brokerage account. For this scenario, an 
equivalent, 
more intuitive definition of the IRR is, "The IRR is the annual interest rate of the fixed rate account (like a somewhat idealized savings account)
which, when subjected to the same deposits and withdrawals as the actual investment, has the same ending balance as the actual investment." 
This fixed rate account is also called the "replicating fixed rate account" for the investment. There are examples where 
the replicating fixed rate account encounters negative balances despite the fact that the actual investment did not. 
In those cases, the IRR calculation assumes that the same interest rate that is paid on positive balances is charged on 
negative balances. It has been shown that this way of charging interest is the root cause of the IRR's multiple solutions 
problem. If the model is modified so that, as is the case in real life, an externally supplied cost of borrowing 
(possibly varying over time) is charged on negative balances, the multiple solutions issue 
disappears. The resulting rate is 
called the "fixed rate equivalent" ("FREQ").
Unannualized internal rate of return.
In the context of investment performance measurement, there is sometimes ambiguity in terminology between the periodic rate of return, such as the internal rate of return as defined above, and a holding period return. The term "internal rate of return" or "IRR" or "Since Inception Internal Rate of Return (SI-IRR)" is in some contexts used to refer to the unannualized return over the period, particularly for periods of less than a year.

</doc>
<doc id="60359" url="https://en.wikipedia.org/wiki?curid=60359" title="Benthos">
Benthos

Benthos is the community of organisms that live on, in, or near the seabed, also known as the benthic zone. This community lives in or near marine sedimentary environments, from tidal pools along the foreshore, out to the continental shelf, and then down to the abyssal depths.
Many organisms adapted to deep-water pressure cannot survive in the upper parts of the water column. The pressure difference can be very significant (approximately one atmosphere for each 10 metres of water depth).
Because light is absorbed before it can reach deep ocean-water, the energy source for deep benthic ecosystems is often organic matter from higher up in the water column that drifts down to the depths. This dead and decaying matter sustains the benthic food chain; most organisms in the benthic zone are scavengers or detritivores.
The term "benthos" comes from the Greek noun "depth of the sea". "Benthos" is also used in freshwater biology to refer to organisms at the bottom of freshwater bodies of water, such as lakes, rivers, and streams.
Food sources.
The main food sources for the benthos are algae and organic runoff from land. The depth of water, temperature and salinity, and type of local substrate all affect what benthos is present. In coastal waters and other places where light reaches the bottom, benthic photosynthesizing diatoms can proliferate. Filter feeders, such as sponges and bivalves, dominate hard, sandy bottoms. Deposit feeders, such as polychaetes, populate softer bottoms. Fish, such as dragonets, as well as sea stars, snails, cephalopods, and crustaceans are important predators and scavengers.
Benthic organisms, such as sea stars, oysters, clams, sea cucumbers, brittle stars and sea anemones, play an important role as a food source for fish, such as the California sheephead, and humans.
By size.
Macrobenthos.
They are easily visible to the naked eye with the lower range of body size at 0.5 mm but usually larger than 3 mm. In the coastal water ecosystem, they include several species of organisms from different taxa including Porifera, Annelids, Coelenterates, Mollusks, Crustaceans, Arthropods etc.
By type.
Zoobenthos.
Zoobenthos comprises the animals belonging to the benthos.
Phytobenthos.
Phytobenthos comprises the plants belonging to the benthos, mainly benthic diatoms and macroalgae (seaweed).
By location.
Endobenthos.
Endobenthos lives buried, or burrowing in the sediment, often in the oxygenated top layer, e.g., a sea pen or a sand dollar.
Epibenthos.
Epibenthos lives on top of the sediments, e.g., like a sea cucumber or a sea snail crawling about.
Hyperbenthos.
Hyperbenthos lives just above the sediment, e.g., a rock cod.
See also.
Contrast the terms plankton (the organisms that float or drift within the water), nekton (the organisms that swim (powerfully) in the water), and neuston (the organisms that float on the water).

</doc>
<doc id="60360" url="https://en.wikipedia.org/wiki?curid=60360" title="Anapsid">
Anapsid

An anapsid is an amniote whose skull does not have openings near the temples. Traditionally, the Anapsida are the most primitive subclass of reptiles, the ancestral stock from which Synapsida and Diapsida evolved, making anapsids paraphyletic. It is however doubtful that all anapsids lack temporal fenestra as a primitive trait, and that all the groups traditionally seen as anapsids truly lacked fenestra.
Anapsids and the turtles.
While "anapsid reptiles" or "anapsida" were traditionally spoken of as if they were a monophyletic group, it has been suggested that several groups of reptiles that had anapsid skulls may be only distantly related. Scientists still debate the exact relationship between the basal (original) reptiles that first appeared in the late Carboniferous, the various Permian reptiles that had anapsid skulls, and the Testudines (turtles, tortoises, and terrapins). However, it was later suggested that the anapsid-like turtle skull may be due to reversion rather than to anapsid descent. The majority of modern paleontologists believe that the Testudines are descended from diapsid reptiles that lost their temporal fenestrae. More recent morphological phylogenetic studies with this in mind placed turtles firmly within diapsids, some place turtles as a sister group to extant archosaurs or, more commonly within Lepidosauromorpha.
Phylogenetic position of turtles.
All molecular studies have strongly upheld the placement of turtles within diapsids; some place turtles within Archosauria, or, more commonly, as a sister group to extant archosaurs. However, one of the most recent molecular studies, published on 23 February 2012, suggests that turtles are lepidosauromorph diapsids, most closely related to the lepidosaurs (lizards, snakes, and tuataras).
Reanalysis of prior phylogenies suggests that they classified turtles as anapsids both because they assumed this classification (most of them were studying what sort of anapsid turtles are) and because they did not sample fossil and extant taxa broadly enough for constructing the cladogram. "Testudines" were suggested to have diverged from other diapsids between 200 and 279 million years ago, though the debate is far from settled. Most of the other reptiles with anapsid skulls, including the millerettids, nycteroleterids, and pareiasaurs, became extinct in the late Permian period by the Permian-Triassic extinction event. But the procolophonids managed to survive into the Triassic.
Despite the molecular studies, there is evidence that contradicts their classification as diapsids. Firstly, all known diapsids are uricotelic, meaning they excrete uric acid as nitrogenous waste, and there is no known case of a diapsid re-evolving ureotelism, or the excretion of urea, even when they return to semi-aquatic lifestyles. Crocolilians, for example, are still uricotelic, although they are also partly ammonotelic, meaning they excrete some of their waste as ammonia. Ureotelism appears to be the ancestral condition among primitive amniotes, and it is retained by mammals, which likely inherited ureotelism from their synapsid and therapsid ancestors. Ureotelism therefore would suggest that turtles were more likely anapsids than diapsids. The only known uricotelic chelonian is the desert tortoise, which likely evolved it recently as adaptation to desert habitats recently. Some desert mammals are also uricotelic, but since practically all known mammals are ureotelic, the uricotelic mammals may have converged on the desert tortoise. Therefore turtles would have to be the only known case of a uricotelic reptile reverting to ureotelism. Secondly, the oldest known turtle, Odontochelys, displays no evidence of any skull openings. That means turtles would have to lose their skull openings without a trace before Odontochelys appeared. That also means there is absolutely no evidence to support the assumption that any turtle has ever had any skull openings at all. Physiological and fossil evidence therefore would make it rather unlikely that turtles were diapsids.
Anapsida in modern taxonomy.
Anapsida is still sporadically recognized as a valid group, but this is not favoured by current workers. Anapsids in the traditional meaning of the word are not a clade, but rather a paraphyletic group composed of all the early reptiles retaining the primitive skull morphology, grouped together by the absence of temporal openings. Gauthier, Kluge and Rowe (1988) attempted to redefine Anapsida so it would be monophyletic, defining it as the clade containing "extant turtles and all other extinct taxa that are more closely related to them than they are to other reptiles".
This definition explicitly includes turtles in Anapsida; because the phylogenetic placement of turtles within Amniota is very uncertain, it is unclear what taxa, other than turtles themselves, would be included in such defined Anapsida, and whether its content would be similar to the Anapsida of tradition. Indeed, Gauthier, Kluge and Rowe (1988) themselves included only turtles and Captorhinidae in their Anapsida, while excluding the majority of anapsids in the traditional sense of the word from it.
Temporal openings in traditional anapsids.
Tsuji and Müller (2009) noted that the name Anapsida implies a morphology (lack of temporal openings) that is in fact absent in the skeletons of a number of taxa traditionally included in the group. A temporal opening in the skull roof behind each eye, similar to that present in the skulls of synapsids, has been discovered in the skulls of a number of members of Parareptilia (the clade containing most of reptiles traditionally referred to as anapsids), including lanthanosuchoids, millerettids, bolosaurids, some nycteroleterids, some procolophonoids and at least some mesosaurs. The presence of temporal openings in the skulls of these taxa makes it uncertain whether the ancestral reptiles had an anapsid-like skull as traditionally assumed or a synapsid-like skull instead.

</doc>
<doc id="60361" url="https://en.wikipedia.org/wiki?curid=60361" title="Illyria">
Illyria

In classical antiquity, Illyria ( or , , see also "Illyricum)" was a region in the western part of the Balkan Peninsula inhabited by the Illyrians.
The prehistory of Illyria and the Illyrians is known from archaeological evidence. The Romans conquered the region in 168 BC in the aftermath of the Illyrian Wars.
The Roman term "Illyris" (distinct from "Illyria") was sometimes used to define an area north of the Aous valley, most notably Illyris proper.
Mythology.
In Greek mythology, the name of Illyria is aetiologically traced to Illyrius, the son of Cadmus and Harmonia, who eventually ruled Illyria and became the eponymous ancestor of the Illyrians. A later version of the myth identifies Polyphemus and Galatea as parents of Celtus, Galas and Illyrius. The second myth could stem perhaps from the similarities to Celts and Gauls.
Kingdoms.
The earliest recorded Illyrian kingdom was that of the Enchele in the 8th century BC. The era in which we observe other Illyrian kingdoms begins approximately at 400 BC and ends at 167 BC. The Autariatae under Pleurias (337 BC) were considered to have been a kingdom. The Kingdom of the Ardiaei began at 230 BC and ended at 167 BC. The most notable Illyrian kingdoms and dynasties were those of Bardyllis of the Dardani and of Agron of the Ardiaei who created the last and best-known Illyrian kingdom. Agron ruled over the Ardiaei and had extended his rule to other tribes as well. As for the Dardanians, they always had separate domains from the rest of the Illyrians.
The Illyrian kingdoms were composed of small areas within the region of Illyria. Only the Romans ruled the entire region. The internal organization of the south Illyrian kingdoms points to imitation of their neighbouring Greek kingdoms and influence from the Greek and Hellenistic world in the growth of their urban centres. Polybius gives as an image of society within an Illyrian kingdom as peasant infantry fought under aristocrats which he calls in Greek "Polydynastae" (Greek: Πολυδυνάστες) where each one controlled a town within the kingdom. The monarchy was established on hereditary lines and Illyrian rulers used marriages as a means of alliance with other powers. Pliny (23–79 AD) writes that the people that formed the nucleus of the Illyrian kingdom were 'Illyrians proper' or Illyrii Proprie Dicti. They were the Taulantii, the Pleraei, the Endirudini, Sasaei, Grabaei and the Labeatae. These later joined to form the Docleatae.
Roman and Byzantine rule.
The Romans defeated Gentius, the last king of Illyria, at Scodra (in present-day Albania) in 168 BC and captured him, bringing him to Rome in 165 BC. Four client-republics were set up, which were in fact ruled by Rome. Later, the region was directly governed by Rome and organized as a province, with Scodra as its capital.
The Roman province of "Illyricum" replaced the formerly independent kingdom of Illyria. It stretched from the Drilon river in modern Albania to Istria (Croatia) in the west and to the Sava river (Bosnia & Herzegovina) in the north. Salona (near modern Split in Croatia) functioned as its capital.
After crushing a revolt of Pannonians and Daesitiates, Roman administrators dissolved the province of Illyricum and divided its lands between the new provinces of Pannonia in the north and Dalmatia in the south. Although this division occurred in 10 AD, the term "Illyria" remained in use in Late Latin and throughout the medieval period. After the division of the Roman Empire, the bishops of Thessalonica appointed papal vicars for Illyricum. The first of these vicars is said to have been Bishop Acholius or Ascholius (died 383 or 384), the friend of St. Basil. In the 5th century, the bishops of Illyria withdrew from communion with Rome, without attaching themselves to Constantinople, and remained for a time independent, but in 515, forty Illyrian bishops renewed their loyalty to Rome by declaring allegiance to Pope Hormisdas. The patriarchs of Constantinople succeeded in bringing Illyria under their jurisdiction in the 8th century.
Legacy.
The name "Illyria" only disappears from the historical record after the Ottoman invasion of the Balkans in the 15th century, and re-emerges in the 17th century, acquiring a new significance in the Ottoman–Habsburg Wars, as Leopold I designated as the "Illyrian nation" the South Slavs on Hungarian territory.
The name "Illyria" was revived by Napoleon for the Illyrian Provinces that were incorporated into the French Empire from 1809 to 1813, and the Kingdom of Illyria (1816–1849) was part of Austria until 1849, after which time it was not used in the reorganised Austro-Hungarian Empire.
In popular culture.
William Shakespeare chose a fictionalised Illyria as the setting for his play "Twelfth Night". (In the modernised film spoof "She's the Man", this function is served by "Illyria High School" in California.) A fictional "kingdom of Illyria" is postulated alongside historical late medieval states of the region in the Fojnica Armorial (17th century). An extensive history of Illyria by Charles du Fresne, sieur du Cange, was published by Joseph Keglevich in 1746.
The land of Illyria is the setting for Jean-Paul Sartre's "Les Mains Sales" and in Lloyd Alexander's "The Illyrian Adventure".
John Hawkes 1970 novel "The Blood Oranges" is set in a fictionalised Illyria reminiscent of Shakespeare's.
In Christopher Paolini's Inheritance Cycle, Illyria is the former name of an Elven city north of Lake Tudosten. It was later renamed Urû'baen when captured by Galbatorix and the Forsworn.

</doc>
<doc id="60364" url="https://en.wikipedia.org/wiki?curid=60364" title="Mostly Harmless">
Mostly Harmless

Mostly Harmless is a novel by Douglas Adams and the fifth book in the "Hitchhiker's Guide to the Galaxy" series. It is described on the cover of the first editions as "The fifth book in the increasingly inaccurately named Hitchhikers Trilogy". It was the last Hitchhiker's book written by Adams.
Title.
The title derives from a joke early in the series, when Arthur Dent discovers that the entry for Earth in "The Hitchhiker's Guide to the Galaxy" consists, in its entirety, of the word "Harmless". His friend Ford Prefect, a contributor to the "Guide", assures him that the next edition will contain the article on Earth that Ford has spent the last 15 years researching—somewhat cut due to space restrictions, but still an improvement. The revised article, he eventually admits, will simply read ""Mostly" harmless". It later turns out that Ford had written a long essay on how to have fun on Earth, but the editors in the guide's main office building edited everything out. Later in the series, Ford is surprised to discover that all of his contribution had been edited back into the Guide, prompting his reunion with Arthur on the alternative Earth in "So Long, and Thanks for All the Fish".
Plot summary.
Arthur Dent plans to sightsee across the Galaxy with his girlfriend Fenchurch, but she disappears during a hyperspace jump, a result of being from an unstable sector of the Galaxy. Depressed, Arthur continues to travel the galaxy using his biological donations to DNA banks to fund his travels, and knowing that he cannot die until he visits Stavromula Beta, as told to him by the insane Agrajag who had been repeatedly killed in various ways by Arthur before being reincarnated. During one trip, he ends up stranded on the homely planet Lamuella, and decides to stay to become a sandwich maker for the local population.
Meanwhile, Ford Prefect has returned to the offices of the Hitchhiker's Guide, and is annoyed to find out the original publishing company, Megadodo Publications, has been taken over by InfiniDim Enterprises, which are run by the Vogons. Fearing for his life, he escapes the building, along the way stealing the yet-unpublished, seemingly sentient Hitchhiker's Guide Mk. II. He goes into hiding after sending the Guide to himself, care of Arthur, for safekeeping.
On Lamuella, Arthur is surprised by the appearance of Trillian with a teenage daughter, Random Dent. Trillian explains that she wanted a child, and could use the only human DNA she could find, thus claiming that Arthur is Random's father. She leaves Random with Arthur to allow her to better pursue her career as an intergalactic reporter. Random is frustrated with Arthur and life on Lamuella; when Ford's package to Arthur arrives, she takes it and discovers the Guide. The Guide helps her to escape the planet on Ford's ship after Ford arrives on the planet looking for Arthur. Discovering Random, the Guide, and Ford's ship missing, the two manage to find a way to leave Lamuella and head for Earth, where they suspect Random is also heading to find Trillian. Ford expresses concern on the Guide's manipulation of events.
Reporter Tricia McMillan is an alternate version of Trillian living on Earth who never took Zaphod Beeblebrox's offer to travel in space. She is approached by an extraterrestrial species, the Grebulons, who have created a base of operations on the planet Rupert , a recently discovered tenth planet in the Solar System. However, due to damage to their ship in arriving, they have lost most of their computer core and their memories, with the only salvageable instructions being to observe something interesting with Earth. They ask Tricia's help to adapt astrology charts for Rupert in exchange for allowing her to interview them. Tricia conducts the interview, but the resulting footage looks fake. She is called away from editing the footage to report on a spaceship landing in the middle of London.
As Tricia arrives, Random is leaving the ship. Random yells at Tricia, believing Tricia to be her mother. Arthur, Ford, and Trillian arrive and help Tricia to calm Random. They remove her from the chaos surrounding the spacecraft and take her to a bar. Trillian tries to warn the group that the Grebulons, having become bored of their mission, are about to destroy the Earth. Random disrupts the discussion by producing a laser gun she took from her ship. Arthur, still believing he cannot die, tries to calm Random's nerves, but a distraction causes her to flinch. She fires the weapon, sending the bar into a panic. Arthur tends to a man hit by the blast, and learns he is another reincarnation of Agrajag. He also discovers that the bar is named "Stavro Mueller - Beta". Arthur makes out Ford laughing wildly at this turn of events. Arthur, despite the panic beginning around him, experiences a ″tremendous feeling of peace″.
The Grebulons, having determined that removing Earth from the astrological charts will improve their horoscopes, destroy it. It is revealed that the Vogons designed the Guide Mk. II with the ability to see the potential outcome of any event, enabling it to ensure that every version of the Earth in all realities is destroyed. With its mission complete, the Guide collapses into nothingness.
Adaptations.
Radio.
Dirk Maggs adapted the book as the "Quintessential Phase" of the radio series, and it was broadcast in June 2005. The radio version has an entirely new, upbeat ending, appended to the existing story.
In the alternate ending, after the destruction of Earth, the description of the Babel fish from the earlier series is replayed with an additional section, which states that dolphins and Babel fish are acquainted, and that the dolphins' ability to travel through possibility space (first mentioned in "The Hitchhiker's Guide to the Galaxy" and elaborated on in "So Long, and Thanks for All the Fish") is shared by the Babel fish as well. During the ending, Ford explains that the dolphins got taught this skill from the Babel fish in exchange for knowing a good place to have parties. All the major characters are carrying Babel fish in their ears, which rescue them at the moment of Earth's destruction by transporting them to the Restaurant at the End of the Universe. The characters are reunited with Marvin, and it is revealed that beyond the Restaurant (and beyond the car park in which Marvin works) lies an endless series of blue lagoons — the final destination of the dolphins. The series ends with Arthur asking Fenchurch, "Will you come flying with me?", and her reply, "Always."
The version released on CD contains an even longer set of alternate endings, including one set after the events of the twelfth radio episode (with Arthur Dent and Lintilla), and on an alternate Earth where Arthur Dent and Fenchurch engage in a stand-off against Mr Prosser, together.
Audiobook.
There have been four unabridged audiobook recordings of the novel. In 1992, Adams himself recorded an edition, later re-released by New Millennium Audio in the United States and available from BBC Audiobooks in the United Kingdom. In 2006, actor Martin Freeman, who had played Arthur Dent in the 2005 movie, recorded a new edition of the audiobook. This is the only book in the five novel series not to have also had a prior, abridged edition read by Stephen Moore.
In addition, the National Library Service for the Blind and Physically Handicapped released a version of the book, narrated by George Guidall-Shapiro, on 4-track cassette tape in 1993. They released the book again as part of a larger work called "The Ultimate Hitchhiker's Guide to the Galaxy" (with forward by Neil Gaiman, and including other books in the series), narrated by David Cutler; available on cassette as RC 62183, and in encrypted DAISY downloadable form as DB 62183. The NLS books can be found using their book search engine, by entering the book numbers or titles.
Academia and popular culture.
Joshua D. Angrist and Joern-Steffen Pischke named their applied econometrics toolkit book "Mostly Harmless Econometrics" in the spirit of Douglas Adams' "The Hitchhiker's Guide to the Galaxy" and "Mostly Harmless".

</doc>
<doc id="60367" url="https://en.wikipedia.org/wiki?curid=60367" title="Front 242">
Front 242

Front 242 is a Belgian electronic music group that came into prominence during the 1980s. Pioneering the style they called electronic body music, they were a profound influence on the electronic and industrial music genres.
History.
Formation.
Front 242 were formed in 1981 in Aarschot, near Leuven, Belgium, by Daniel Bressanutti and Dirk Bergen, who wanted to create music and graphic design using emerging electronic tools. The first single, "Principles", was released in 1981. The "front" part of the name comes from the idea of an organized popular uprising. Patrick Codenys and Jean-Luc De Meyer had separately formed a group called Under Viewer at around the same time, and the two duos joined together in 1982. Bressanutti, Codenys and De Meyer took turns on vocals at first, until they settled on De Meyer as the lead vocalist (early recordings with Bressanutti on vocals were subsequently released in 2004). De Meyer came to write most of the lyrics and Valerie Jane Steele also wrote several tracks including "Don't Crash".
Their next single, "U-Men", was released in 1982, followed by the band's first album "Geography" that same year. In 1983, Dirk Bergen left the band to pursue graphic design, and Richard Jonckheere, referred to as Richard 23, joined as vocalist.
Rising popularity.
Front 242 became a popular musical group in Belgium. Their next album, "No Comment", released in 1984, was the first to introduce the term electronic body music in association with their sound. Front 242 signed with the Wax Trax! label in 1984, and started their first tour in the United States with Ministry. This tour led to the creation of Revolting Cocks by Richard 23, Luc Van Acker, Alain Jourgensen of Ministry and others.
In 1987, Front 242 signed with Wax Trax! Records in the U.S. and Red Rhino in Europe, and released "Backcatalogue" and "Official Version".
In 1988, "Front by Front" was released, and in December of that same year, "Headhunter" (with a video by Anton Corbijn), became the band's first club hit, reaching #13 on the US "Billboard" Dance/Club Play Songs chart.
1990s.
"Tyranny (For You)", released in 1991, became the band's highest charting album, reaching #95 on the "Billboard" 200. "Tyranny (For You)" was the first album they released under contract with a major corporate label, Sony/Epic, after the widespread popularity of "Front by Front". Sony/Epic also acquired the rights to the band's back catalog from Wax Trax! and issued re-released versions of the albums with new cover art and bonus tracks taken from singles and EPs.
A broader public was exposed to Front 242's music in 1992 in the film "Single White Female", starring Bridget Fonda and Jennifer Jason Leigh. In the film, obsessed roommate Leigh ties Fonda to a chair but leaves her with the television remote control. In order to attract attention, Fonda tunes in to a music video channel and turns up the volume. The video playing at the time is Front 242's "Rhythm Of Time", from the album "Tyranny (For You)". Also in 1992, the television commercials for the film "K2" were set to the Front 242 song "Moldavia", from the same album.
In 1992, Bressanutti returned to combining graphic arts with music, taking his lithographs on tour to three U.S. galleries. Bressanutti also composed a solo half-hour atmospheric recording called "Art and Strategy" (or The Art Corporation) to play during viewings of the lithographs, and released it in a limited edition of 1,000 CDs.
Front 242's style shifted abruptly with each of their next two albums, released in rapid succession in 1993 on Epic's sub-label RRE (originally planned as a double-CD): "06:21:03:11 UP EVIL" and "05:22:09:12 OFF" (the numbers correspond to letters, spelling "FUCK UP EVIL" and "EVIL OFF"). The band describes the two albums as "based on the duality of good and evil." However, strains were emerging, with the band members apparently having different artistic views. Despite these tensions, they performed on the main stage of the 1993 Lollapalooza tour.
Neither of these albums had significant input from Richard 23, and "05:22:09:12 OFF" only included their lead vocalist, Jean-Luc De Meyer, on a remixed track originally from "Up Evil". On the other hand, a variety of new contributors were listed as members of Front 242 on these albums: Jean-Marc Pauly and Pierre Pauly (of the Belgian electronic group Parade Ground) on "Up Evil", and 99 Kowalski and Eran Westwood on "Off".
99 Kowalski is the stage name of Kristin Kowalski, making a tradition out of Richard 23's idea of number-as-name. Kowalski and Westwood were originally members of a New York City band called Spill who Bressanutti and Codenys had brought to Belgium to produce their debut album. After the recording sessions fell apart, they contributed to Front 242 on the "Off" release.
After the release of "06:21:03:11 Up Evil" and "05:22:09:12 Off", there was no new material from Front 242 under any lineup. Instead, the band released a stream of live recordings and remixes. However, this period also saw a proliferation of side projects, an inordinate number of which involved De Meyer.
Earlier, Richard 23 played in the Revolting Cocks, and De Meyer had a side project doing vocals for Bigod 20 for their single, "The Bog" in 1990. In 1995, De Meyer met Marc Heal of Cubanate at a Front Line Assembly concert, and the two of them collaborated along with Ged Denton and Jonathan Sharp, to record as Cyber-Tec Project for the new (and short-lived) Cyber-Tec record label.
After the departure of Sharp and the demise of the Cyber-Tec label, the remaining group continued working under the name C-Tec. De Meyer also took over as vocalist for Birmingham 6 for their 1996 album "Error of Judgment". 1996 also saw the debut album "Elemental" from Cobalt 60, which De Meyer formed with Dominique Lallement and Frederic Sebastien of Reims, France, members of Kriegbereit. This was the start of a number of releases from Cobalt 60, which also did the soundtrack for the video game "". Meanwhile, Richard 23 recorded with the groups Holy Gang, and later, LaTchak.
The four core members of Front 242 regrouped in 1998 to compose radically reworked versions of many of their songs, which they then performed on their first tour in five years, appropriately called the Re:Boot tour. They acknowledged the influence of The Prodigy and their "Fat of the Land" album in crafting the new, more techno style of Re:Boot.
The new tour material was the subject of Front 242's new recording contract in the U.S. with Metropolis Records. Front 242 also indicated at this time that they were recording new material. However, they had little activity after 1998, making occasional appearances in Europe and Mexico, while Codenys recorded under the name Gaiden with Steve Stoll in 2001.
2000s.
2002 saw the beginning of a wave of new material from Bresanutti and Codenys, and then from Front 242. In August 2002 a DVD/CD two-disc set called "Speed Tribe" was released by Dance.com. The DVD was a collaboration with experimental documentary filmmakers Rod Chong and Sharon Matarazzo, who filmed the 2001 24 Hour Le Mans. In the video, the racecars, clouds, rain and spectators form an impressionistic visual backdrop for the music.
Several months later, the first release from Male or Female, also known as Morf, a new project for Bresanutti and Codenys along with vocalist Elko Blijweert. In 2002 and 2003, Morf released an album, an E.P., a double album, and a DVD/CD two-disc combo, on the Belgian record label Alfa Matrix, and went on tour through the U.S.
Then, 2002 and 2003 also saw the release of the new material from Front 242 in a decade: the E.P. "Still and Raw" and the album "Pulse", released on XIIIBis Records in Europe and Metropolis in the U.S. These represented another iteration of Front 242's explicitly stated goal of reinventing itself. The style of the two new releases is more mellow than some of their past work, using more "glitchy" and "bleepy" sounds. As well, it uses the manipulated voice as a musical instrument. The new releases have a much more emotional style from De Meyer, which was presaged in his later recordings with C-Tec and particularly Cobalt 60 on its album "Twelve".
Front 242 promised a new U.S. tour to perform new material from these releases. They have made occasional appearances in Latin America and Europe, even being rejoined by Dirk Bergen for a reunion concert in Aarschot (De Klinker club) in 2004 under the original lineup of Bresanutti, Bergen, Codenys and De Meyer. This performance was kept secret until two days before the show but when the scene magazine Side-Line and the band's label Alfa Matrix launched the news, tickets were quickly sold out.
The band has now also set itself to re-release its entire back catalogue both as a normal CD and as a limited edition consisting of a 2-CD set holding previously unreleased material. For this the band is working together with the Belgian label Alfa Matrix that already took care of releasing the albums of the Front 242 side-project Male Or Female. The first re-release is their debut album "Geography", this time newly remastered personally by Bresanutti to surprisingly powerful effect and including 3 extra tracks (two hidden ones) on the normal CD format.
Meanwhile, their enthusiasm for side projects has continued, as Patrick Codenys started appearing with a new group called Red Sniper, Bresanutti started recording with a new group called Troissoeur, and Codenys and Richard 23 formed a quasi-DJ project called Coder23 which toured in late 2004 and early 2005 as the opening act for VNV Nation. De Meyer contributed vocals on two studio tracks for the Glis album "Nemesis" in 2005. The lyrical content of the two songs ("The Irreparable" and "La Béatrice") were based on the poems of Charles Baudelaire.
Front 242 toured through twenty venues in North America in November 2005, their first tour as a full band since 2000. The band performed at the Roskilde Festival in 2006. The band's sold out two-day performance at the Ancienne Belgique in Brussels has been recorded for a future release via Alfa Matrix.
In December 2006, Front 242 announced from their MySpace page that they were writing music for a video game called "Cipher Complex" and provided a link to a teaser trailer with a short sample of one of their scores.
In 2007, De Meyer announced a new project: 32CRASH via the Alfa Matrix label. The band is preparing for an album release in October 2007 after the release of the EP "Humanity".
In August 2008, Front 242 played live at the Infest Festival in Bradford, England.
In October 2008, Front 242 performed for the first time in Finland, at the Alternative Party 2008 media arts festival.
Moments.
On June 1, 2008, the Alfa Matrix label announced that Front 242 would make an ultimate statement towards abusive audio compression by releasing the free two-track download, "First Moment". By June 15 the same year, the tracks were made available for free on Alfa Matrix's site in medium and high bit-rate MP3s, WAV, FLAC, and M4A formats. Contrary to what fans and some media speculated, the two-track download was not new studio material. Instead, "First Moments" consisted of two previously unreleased live tracks, "U-Men" and "Im Rhythmus Bleiben", in rather stunning sound quality. It is rumored that over 20,000 people downloaded the tracks within hours of being made available. The label later confirmed that over 25,000 people downloaded the free tracks.
On June 4, 2008, Alfa Matrix announced the release of "Moments..." The album was a live recording encompassing the best of Front 242's compositions. The album was shipped in several formats including limited CD box sets, vinyl in different colors including 300-copy limited editions, and as a one-disc CD release.

</doc>
<doc id="60368" url="https://en.wikipedia.org/wiki?curid=60368" title="Jean-Luc Godard">
Jean-Luc Godard

Jean-Luc Godard (; born 3 December 1930) is a French-Swiss film director, screenwriter and film critic. He is often identified with the 1960s French film movement "La Nouvelle Vague", or "New Wave".
Like his New Wave contemporaries, Godard criticized mainstream French cinema's "Tradition of Quality", which "emphasized craft over innovation, privileged established directors over new directors, and preferred the great works of the past to experimentation." To challenge this tradition, he and like-minded critics started to make their own films. Many of Godard's films challenge the conventions of traditional Hollywood in addition to French cinema. He is often considered the most radical French filmmaker of the 1960s and 1970s; his approach in film conventions, politics and philosophies made him arguably the most influential director of the French New Wave. Along with showing knowledge of film history through homages and references, several of his films expressed his political views; he was an avid reader of existential and Marxist philosophy.
Since the New Wave, his politics have been much less radical and his recent films are about representation and human conflict from a humanist, and a Marxist perspective.
In a 2002 "Sight & Sound" poll, Godard ranked third in the critics' top-ten directors of all time (which was put together by assembling the directors of the individual films for which the critics voted). He is said to have "created one of the largest bodies of critical analysis of any filmmaker since the mid-twentieth century." He and his work have been central to narrative theory and have "challenged both commercial narrative cinema norms and film criticism's vocabulary." In 2010, Godard was awarded an Academy Honorary Award, but did not attend the award ceremony.
Godard's films have inspired many directors including Martin Scorsese, Quentin Tarantino, Steven Soderbergh, D. A. Pennebaker, Robert Altman, Jim Jarmusch, Wong Kar-wai, Wim Wenders, Bernardo Bertolucci, and Pier Paolo Pasolini.
Early life.
Jean-Luc Godard was born on 3 December 1930 in the 7th arrondissement of Paris, the son of Odile (née Monod) and Paul Godard, a Swiss physician. His wealthy parents came from Protestant families of Franco–Swiss descent, and his mother was the daughter of Julien Monod, a founder of the Banque Paribas. She was the great-granddaughter of theologian Adolphe Monod. Relatives on his mother's side include also composer Jacques-Louis Monod, naturalist Théodore Monod and pastor Frédéric Monod. Four years after Jean-Luc's birth, his father moved the family to Switzerland. At the outbreak of the Second World War, Godard was in France and returned to Switzerland with difficulty. He spent most of the war in Switzerland, although his family made clandestine trips to his grandfather's estate on the French side of Lake Geneva. Godard attended school in Nyon, Switzerland.
Not a frequent cinema-goer, he attributed his introduction to cinema to a reading of Malraux's essay "Outline of a Psychology of Cinema", and his reading of "La Revue du cinéma", which was relaunched in 1946. In 1946, he went to study at the Lycée Buffon in Paris and, through family connections, mixed with members of its cultural elite. He lodged with the writer Jean Schlumberger. Having failed his baccalaureate exam in 1948 he returned to Switzerland. He studied in Lausanne and lived with his parents, whose marriage was breaking up. He spent time in Geneva also with a group that included another film fanatic, Roland Tolmatchoff, and the extreme rightist philosopher Jean Parvulesco. His older sister Rachel encouraged him to paint, which he did, in an abstract style. After time spent at a boarding school in Thonon to prepare for the retest, which he passed, he returned to Paris in 1949. He registered for a certificate in anthropology at the University of Paris (Sorbonne), but did not attend class. He got involved with the young group of film critics at the ciné-clubs that started the New Wave. Godard originally held only French citizenship, then in 1953, he became a citizen of Gland, canton of Vaud, Switzerland, possibly through simplified naturalisation through his Swiss father.
Early career (1950–59).
Film criticism.
In Paris, in the Latin Quarter just prior to 1950, "ciné-clubs" (film societies) were gaining prominence. Godard began attending these clubs—the Cinémathèque, the CCQL, Work and Culture ciné Club, and others, became his regular haunts. The Cinémathèque had been founded by Henri Langlois and Georges Franju in 1936; Work and Culture was a workers' education group for which André Bazin had organized wartime film screenings and discussions and which had become a model for the film clubs that had risen throughout France after the Liberation; Ciné-Club du Quartier Latin (CCQL), founded 1947-48, was animated and intellectually led by Maurice Schérer. At these clubs he met fellow film enthusiasts including Jacques Rivette, Claude Chabrol, and François Truffaut. Godard was part of a generation for whom cinema took on a special importance. He has said: "In the 1950s cinema was as important as bread—but it isn't the case any more. We thought cinema would assert itself as an instrument of knowledge, a microscope... a telescope... At the Cinémathèque I discovered a world which nobody had spoken to me about. They'd told us about Goethe, but not Dreyer. ... We watched silent films in the era of talkies. We dreamed about film. We were like Christians in the catacombs."
His foray into films began in the field of criticism. Along with Maurice Schérer (writing under the to-be-famous pseudonym Éric Rohmer) and Rivette, he founded the short-lived film journal "Gazette du cinéma", which saw publication of five issues in 1950. When Bazin co-founded the influential critical magazine "Cahiers du cinéma" in 1951, Godard was the first of the younger critics from the CCQL/Cinémathèque group to be published—the January 1952 issue featured his review of an American melodrama directed by Rudolph Maté, "No Sad Songs for Me". His "Defence and Illustration of Classical Découpage" published in September 1952, in which he attacks an earlier article by Bazin and defends the use of the shot-reverse shot technique, is one of his earliest important contributions to cinema. Praising Otto Preminger and "the greatest American artist—Howard Hawks", Godard raises their harsh melodramas above the more "formalistic and overtly artful films of Welles, De Sica and Wyler which Bazin endorsed". At this point Godard's activities did not include making films—rather he watched films, and wrote about them, and helped others make films, notably Rohmer, with whom he worked on "Présentation ou Charlotte et son steak".
Filmmaking.
Having left Paris in the autumn of 1952, Godard returned to Switzerland and went to live with his mother in Lausanne. He became friendly with his mother's lover, Jean-Pierre Laubscher, who was a labourer on the Grande Dixence Dam. Through Laubscher he secured work himself as a construction worker at the Plaz Fleuri work site at the dam. He saw the possibility of making a documentary film about the dam and when his initial contract ended, in order to prolong his time at the dam, moved to the post of telephone switchboard operator. It was whilst on duty, in April 1954, that he put through a call to Laubscher that relayed the fact that Odile Monod, his mother, had died in a scooter accident. Thanks to Swiss friends who lent him a 35mm movie camera, he was able to shoot on 35mm film. He rewrote the commentary that Laubscher had written, and gave his film a rhyming title "Opération béton" (Operation concrete). The company that administered the dam bought the film and used it for publicity purposes.
As he continued to work for "Cahiers", he made "Une femme coquette" (1955), in Geneva, a ten-minute short; and in January 1956 he returned to Paris. A plan for a feature film of Goethe's "Elective Affinities" proved too ambitious and came to nothing. Truffaut enlisted his help to work on an idea he had for a film based on the true-crime story of a petty criminal, Michel Portail, who had shot a motorcycle policeman and whose girlfriend had turned him in to the police. But Truffaut failed to interest any producers. Another project with Truffaut, a comedy about a country girl arriving in Paris, was also abandoned. He worked with Rohmer on a planned series of short films centering on the lives of two young women, Charlotte and Véronique; and in the autumn of 1957, Pierre Braunberger produced the first film in the series, "All the Boys Are Named Patrick", directed by Godard from Rohmer's script. "Une histoire d'eau" (1958) was created largely out of unused footage shot by Truffaut. In 1958, Godard, with a cast that included Jean-Paul Belmondo and Anne Colette, made his last short before gaining international prominence as a filmmaker, "Charlotte et son Jules", an homage to Jean Cocteau. The film was shot in Godard's hotel room on the rue de Rennes and apparently reflected something of the 'romantic austerity' of Godard's own life at this time. His Swiss friend Roland Tolmatchoff noted; "In Paris he had a big Bogart poster on the wall and nothing else." In December 1958, Godard reported from the Festival of Short Films in Tours and praised the work of, and became friends with, Jacques Demy, Jacques Rozier, and Agnès Varda—he already knew Alain Resnais whose entry he also praised—but Godard now wanted to make a feature film. He travelled to the 1959 Cannes Film Festival and asked Truffaut to let him use the story on which they had collaborated in 1956, about the car thief Michel Portail. He sought money from the producer Georges de Beauregard whom he had met previously whilst working briefly in the publicity department of Twentieth Century Fox's Paris office, and who was also at the Festival. Beauregard could offer his expertise, but was in debt from two productions based on Pierre Loti stories and so finance came rather from a film distributor, René Pignières.
Cinematic period (1960–68).
Godard's most celebrated period as a director spans roughly from his first feature, "Breathless" (1960), through to "Week End" (1967). His work during this period focused on relatively conventional films that often refer to different aspects of film history. Although Godard's work during this time is considered groundbreaking in its own right, the period stands in contrast to that which immediately followed it, during which Godard ideologically denounced much of cinema's history as "bourgeois" and therefore without merit.
Films.
Godard's "Breathless" ("À bout de souffle", 1960), starring Jean-Paul Belmondo and Jean Seberg distinctly expressed the French New Wave's style, and incorporated quotations from several elements of popular culture—specifically American film noir. The film employed various techniques such as the innovative use of jump cuts (which were traditionally considered amateurish), character asides, and breaking the eyeline match in continuity editing. Truffaut co-wrote "Breathless" with Godard.
Godard viewed film-making as an extension of criticism and was more interested in redefining film structure and style than actually being understood by the public. Often his movies were more about the presentation of a story than anything else. The stories in his films were very simple yet unfocused and constantly digressing from the main story line.
From the beginning of his career, Godard included more film references into his movies than did any of his New Wave colleagues. In "Breathless", his citations include a movie poster showing Humphrey Bogart—from "The Harder They Fall", his last film(whose expression the lead actor Jean-Paul Belmondo tries reverently to imitate)—visual quotations from films of Ingmar Bergman, Samuel Fuller, Fritz Lang, and others; and an onscreen dedication to Monogram Pictures,an American B-movie studio. Quotations from, and references to literature include William Faulkner, Dylan Thomas, Louis Aragon, Rilke, Françoise Sagan, Maurice Sachs. The film also contains citations in images or on the soundtrack—Mozart, Picasso, J. S. Bach, Paul Klee, and Auguste Renoir. "This first-person cinema invoked not the director's experience but his presence". If, in Rohmer's words, "life was the cinema", then a film filled with movie references was supremely autobiographical.
Godard wanted to hire the American actress Jean Seberg, who was living in Paris with her husband François Moreuil, an attorney, to play the American woman. Seberg had become famous in 1956 when Otto Preminger had chosen her to play Joan of Arc in his "Saint Joan", and had then cast her in his acidulous 1958 adaptation of "Bonjour Tristesse". Her performance in this film had not been generally regarded as a success—the "New York Times" critic called her a "misplaced amateur"—but Truffaut and Godard disagreed. In the role of Michel Poiccard, Godard cast Belmondo, an actor he had already called, writing in "Arts" in 1958, "the Michel Simon and the Jules Berry of tomorrow." The cameraman was Raoul Coutard, the producer Beauregard's choice. Godard wanted "Breathless" to be shot like a documentary, with a lightweight handheld camera and a minimum of added lighting and Coutard had had experience as a documentary cameraman while working for the French army's information service in Indochina during the French-Indochina War. Tracking shots were filmed by Coutard from a wheelchair pushed by Godard. Though he had prepared a traditional screenplay, he dispensed with it and Godard wrote the dialogue day by day as the production went ahead. The film's importance was recognized immediately and in January 1960, Godard won the Jean Vigo Prize, awarded " to encourage an auteur of the future". One reviewer mentioned Alexandre Astruc's prophecy of the age of the "caméra-stylo", the camera that a new generation would use with the efficacy with which a writer uses his pen—"here is in fact the first work authentically written with a "caméra-stylo".
The following year Godard made "Le Petit Soldat" (The Little Soldier), filmed on location in Geneva, and dealing with the Algerian War of Independence. The film begins on 13 May 1958, the date of the attempted putsch in Algeria, and ends later the same month. In the film, Bruno Forestier a photojournalist who has links with a right wing paramilitary group working for the French government, is ordered to murder a professor accused of aiding the Algerian resistance. He is in love with Veronica Dreyer, a young woman who has worked with the Algerian fighters. He is captured by Algerian militants and tortured. His organisation captures and tortures her. The 'little soldier' was played by Michel Subor and Veronica Dreyer by Anna Karina—the first collaboration between Godard and the Danish-born—of Russian extraction—actress. Unlike Seberg, Karina had virtually no experience as an actress and Godard used her awkwardness as an element of her performance. He wrote the dialogue every day and, since it was filmed without direct sound and was dubbed, called dialogue to the actors. Forestier was a character close to Godard himself, an image-maker and intellectual, 'more or less my spokesman, but not totally' Godard told an interviewer. The film, due to its political nature, implied that France was involved in a dirty war, engaging in torture, and was banned by the French government until January 1963. Godard and Karina were a couple by the end of the shoot. She appeared again, along with Belmondo, in Godard's first color film, "A Woman Is a Woman" (1961), which was intended as a homage to the American musical. Adjustments that Godard made to the original version of the story gave it autobiographical resonances, 'specifically in regard to his relationship with Anna Karina'. The film revealed 'the confinement within the four walls of domestic life', and 'the emotional and artistic fault lines that threatened their relationship'.
Godard's next film, "Vivre sa vie" (My Life to Live) (1962), was one of his most popular among critics. Karina starred as Nana, an errant mother and aspiring actress whose financially strained circumstances lead her to the life of a streetwalker. It is an episodic account of her rationalizations to prove she is free, even though she is tethered at the end of her pimp's short leash. In one touching scene in a cafe, she spreads her arms out and announces she is free to raise or lower them as she wishes.
"Les Carabiniers" (1963) was about the horror of war and its inherent injustice. It was the influence and suggestion of Roberto Rossellini that led Godard to make this film which follows two peasants who join the army of a king, only to find futility in the whole thing as the king reveals the deception of war-administrating leaders.
His most commercially successful film was "Le Mépris" ("Contempt") (1963), starring Michel Piccoli and one of France's biggest female stars, Brigitte Bardot. A coproduction between Italy and France, "Contempt" became known as a pinnacle in cinematic modernism with its profound reflexivity. The film follows Paul (Piccoli), a screenwriter who is commissioned by the arrogant American movie producer Prokosch (Jack Palance) to rewrite the script for an adaptation of Homer's "Odyssey", which the Austrian director Fritz Lang has been filming. Lang's 'high culture' interpretation of the story is lost on Prokosch, whose character is a firm indictment of the commercial motion picture hierarchy. Another prominent theme is the inability to reconcile love and labor, which is illustrated by Paul's crumbling marriage to Camille (Bardot) during the course of shooting.
In 1964, Godard and Karina formed a production company, Anouchka Films. He directed "Bande à part" ("Band of Outsiders"), another collaboration between the two and described by Godard as ""Alice in Wonderland" meets Franz Kafka." It follows two young men, looking to score on a heist, who both fall in love with Karina, and quotes from several gangster film conventions.
"Une femme mariée" (A Married Woman) (1964) followed "Band of Outsiders". It was a slow, deliberate, toned-down black-and-white picture without a real story. The film was shot in four weeks and was "an explicitly and stringently modernist film". It showed Godard's "engagement with the most advanced thinking of the day, as expressed in the work of Claude Lévi-Strauss and Roland Barthes" and its fragmentation and abstraction reflected also "his loss of faith in the familiar Hollywood styles." Godard made the film while he acquired funding for "Pierrot le fou" (1965).
In 1965, Godard directed "Alphaville", a futuristic blend of science fiction, film noir, and satire. Eddie Constantine starred as Lemmy Caution, a detective who is sent into a city controlled by a giant computer named Alpha 60. His mission is to make contact with Professor von Braun (Howard Vernon), a famous scientist who has fallen mysteriously silent, and is believed to be suppressed by the computer. "Pierrot le fou" (1965) featured a complex storyline, distinctive personalities, and a violent ending. Gilles Jacob, an author, critic, and president of the Cannes Film Festival, called it both a "retrospective" and recapitulation in the way it played on so many of Godard's earlier characters and themes. With an extensive cast and variety of locations, the film was expensive enough to warrant significant problems with funding. Shot in color, it departed from Godard's minimalist works (typified by "Breathless", "Vivre sa vie", and "Une femme mariée"). He solicited the participation of Jean-Paul Belmondo, by then a famous actor, in order to guarantee the necessary amount of capital.
"Masculin, féminin" (1966), based on two Guy de Maupassant stories, "La Femme de Paul" and "Le Signe", was a study of contemporary French youth and their involvement with cultural politics. An intertitle refers to the characters as "The children of Marx and Coca-Cola." Although Godard's cinema is sometimes thought to depict a wholly masculine point of view, Phillip John Usher has demonstrated how the film, by the way it connects images and disparate events, seems to blur gender lines.
Godard followed with "Made in U.S.A" (1966), whose source material was Richard Stark's "The Jugger"; and "Two or Three Things I Know About Her" (1967), in which Marina Vlady portrays a woman leading a double life as housewife and prostitute. A Classic New Wave crime thiller, "Made in the U.S.A" is inspired by American Noir films. Anna Karina stars as the anti-hero searching for her murdered lover; the film includes a cameo by Marianne Faithfull.
"La Chinoise" (1967) saw Godard at his most politically forthright so far. The film focused on a group of students and engaged with the ideas coming out of the student activist groups in contemporary France. Released just before the May 1968 events, the film is thought by some to foreshadow the student rebellions that took place.
That same year, Godard made a more colorful and political film, "Week End". It follows a Parisian couple as they leave on a weekend trip across the French countryside to collect an inheritance. What ensues is a confrontation with the tragic flaws of the over-consuming bourgeoisie. The film contains some of the most written-about scenes in cinema's history. One of them, an eight-minute tracking shot of the couple stuck in an unremitting traffic jam as they leave the city, is cited as a new technique Godard used to deconstruct bourgeois trends. Startlingly, a few shots contain extra footage from, as it were, before the beginning of the take (while the actors are preparing) and after the end of the take (while the actors are coming out of character). "Week End"'s enigmatic and audacious end title sequence, which reads "End of Cinema", appropriately marked an end to the narrative and cinematic period in Godard's filmmaking career.
Politics.
Politics are never far from the surface in Godard's films. One of his earliest features, "Le Petit Soldat", dealt with the Algerian War of Independence, and was notable for its attempt to present the complexity of the dispute rather than pursue any specific ideological agenda. Along these lines, "Les Carabiniers" presents a fictional war that is initially romanticized in the way its characters approach their service, but becomes a stiff anti-war metonym. In addition to the international conflicts Godard sought an artistic response to, he was also very concerned with the social problems in France. The earliest and best example of this is Karina's potent portrayal of a prostitute in "Vivre sa vie".
In 1960s Paris, the political milieu was not overwhelmed by one specific movement. There was, however, a distinct post-war climate shaped by various international conflicts such as the colonialism in North Africa and Southeast Asia. Godard's Marxist disposition did not become abundantly explicit until "La Chinoise" and "Week End", but is evident in several films—namely "Pierrot" and "Une femme mariée".
Godard has been accused by some of harboring anti-Semitic views: in 2010, in the lead-up to the presentation of Godard's honorary Oscar, a prominent article in the New York Times by Michael Cieply drew attention to the idea, which had been circulating through press in previous weeks, that Godard might be an anti-Semite, and thus undeserving of the accolade. Cieply makes reference to Richard Brody's book, "Everything is Cinema: The Working Life of Jean-Luc Godard", and alluded to a previous, longer article published by the Jewish Journal as lying near the origin of the debate. The article also draws upon Brody's book, for example in the following quotation, which Godard made on television in 1981: "Moses is my principal enemy...Moses, when he received the commandments, he saw images and translated them. Then he brought the texts, he didn't show what he had seen. That's why the Jewish people are accursed." Immediately after Cieply's article was published, Brody made a clear point of criticizing the "extremely selective and narrow use" of passages in his book, and noted that Godard's work has approached the Holocaust with "the greatest moral seriousness". Indeed, his documentaries feature images from the Holocaust in a context suggesting he considers Nazism and the Holocaust as the nadir of human history. Godard's views become more complex regarding the State of Israel. In 1970, Godard traveled to the Middle East to make a pro-Palestinian film he didn't complete and whose footage eventually became part of the 1976 film "Ici et ailleurs". In this film, Godard seems to view the Palestinian cause as one of many worldwide Leftist revolutionary movements. Elsewhere, Godard has explicitly identified himself as an anti-Zionist but has denied the accusations of anti-Semitism.
Vietnam War.
Godard produced several pieces that directly address the Vietnam War. Furthermore, there are two scenes in "Pierrot le fou" that tackle the issue. The first is a scene that takes place in the initial car ride between Ferdinand (Belmondo) and Marianne (Karina). Over the car radio, the two hear the message "garrison massacred by the Viet Cong who lost 115 men". Marianne responds with an extended musing on the way the radio dehumanizes the Northern Vietnamese combatants.
In the same film, the lovers accost a group of American sailors along the course of their liberating crime spree. Their immediate reaction, expressed by Marianne, is "Damn Americans!", an obvious outlet of the frustration so many French communists felt towards American hegemony. Ferdinand then reconsiders, "That's OK, we’ll change our politics. We can put on a play. Maybe they’ll give us some dollars." Marianne is puzzled, but Ferdinand suggests that something the Americans would like would be the Vietnam War. The ensuing sequence is a makeshift play where Marianne dresses up as a stereotypical Vietnamese woman and Ferdinand as an American sailor. The scene ends on a brief shot revealing a chalk message left on the floor by the pair, "Long live Mao!" ("Vive Mao!").
Notably, he also participated in "Loin du Vietnam" (1967). An anti-war project, it consists of seven sketches directed by Godard (who used stock footage from "La Chinoise"), Claude Lelouch, Joris Ivens, William Klein, Chris Marker, Alain Resnais and Agnès Varda.
Bertolt Brecht.
Godard's engagement with German poet and playwright Bertolt Brecht stems primarily from his attempt to transpose Brecht's theory of epic theatre and its prospect of alienating the viewer ("Verfremdungseffekt") through a radical separation of the elements of the medium (in Brecht's case theater, but in Godard's, film). Brecht's influence is keenly felt through much of Godard's work, particularly before 1980, when Godard used filmic expression for specific political ends.
For example, "Breathless"' elliptical editing, which denies the viewer a fluid narrative typical of mainstream cinema, forces the viewers to take on more critical roles, connecting the pieces themselves and coming away with more investment in the work's content. Godard also employs other devices, including asynchronous sound and alarming title frames, with perhaps his favorite being the character aside. In many of his most political pieces, specifically "Week End", "Pierrot le fou", and "La Chinoise", characters address the audience with thoughts, feelings, and instructions.
Marxism.
A Marxist reading is possible with most if not all of Godard's early work. Godard's direct interaction with Marxism does not become explicitly apparent, however, until "Week End", where the name "Karl Marx" is cited in conjunction with figures such as Jesus Christ. A constant refrain throughout Godard's cinematic period is that of the bourgeoisie's consumerism, the commodification of daily life and activity, and man's alienation—all central features of Marx's critique of capitalism.
In an essay on Godard, philosopher and aesthetics scholar Jacques Rancière states, "When in "Pierrot le fou", 1965, a film without a clear political message, Belmondo played on the word 'scandal' and the 'freedom' that the Scandal girdle supposedly offered women, the context of a Marxist critique of commodification, of pop art derision at consumerism, and of a feminist denunciation of women's false 'liberation', was enough to foster a dialectical reading of the joke and the whole story." The way Godard treated politics in his cinematic period was in the context of a joke, a piece of art, or a relationship, presented to be used as tools of reference, romanticizing the Marxist rhetoric, rather than being solely tools of education.
"Une femme mariée" is also structured around Marx's concept of "commodity fetishism". Godard once said that it is "a film in which individuals are considered as things, in which chases in a taxi alternate with ethological interviews, in which the spectacle of life is intermingled with its analysis". He was very conscious of the way he wished to portray the human being. His efforts are overtly characteristic of Marx, who in his "Economic and Philosophical Manuscripts of 1844" gives one of his most nuanced elaborations, analyzing how the worker is alienated from his product, the object of his productive activity. Georges Sadoul, in his short rumination on the film, describes it as a "sociological study of the alienation of the modern woman".
Revolutionary period (1968–79).
The period that spans from May 1968 indistinctly into the 1970s has been subject to an even larger volume of varying labeling. They include everything from his "militant" period, to his "radical" period, along with terms as specific as "Maoist" and vague as "political". The period saw Godard align himself with a specific revolution and employ a consistent revolutionary rhetoric.
Films.
Amid the upheavals of the late 1960s, Godard became interested in Maoist ideology. He formed the socialist-idealist Dziga-Vertov cinema group with Jean-Pierre Gorin and produced a number of shorts outlining his politics. In that period he travelled extensively and shot a number of films, most of which remained unfinished or were refused showings. His films became intensely politicized and experimental, a phase that lasted until 1980.
In 1978 Godard was commissioned by the Mozambican government to make a short film. During this time his experience with Kodak film led him to criticize the stock film as "inherently racist" since it did not reflect the variety, nuance or complexity in dark brown or dark skin. This was because Kodak Shirley cards were only made for Caucasian subjects, a problem that was not rectified until 1995.
According to Elliott Gould, he and Godard met to discuss the possibility of Godard's directing Jules Feiffer's 1971 surrealist play "Little Murders". During this meeting, Godard said his two favorite American writers were Feiffer and Charles M. Schulz. Godard soon declined the opportunity to direct; the job later went to Alan Arkin.
Jean-Pierre Gorin.
After the events of May 1968, when the city of Paris saw total upheaval in response to the "authoritarian de Gaulle", and Godard's professional objective was reconsidered, he began to collaborate with like-minded individuals in the filmmaking arena. The most notable of these collaborations was with a young Maoist student, Jean-Pierre Gorin, who displayed a passion for cinema that grabbed Godard's attention.
Between 1968 and 1973, Godard and Gorin collaborated to make a total of five films with strong Maoist messages. The most prominent film from the collaboration was "Tout va bien", which starred Jane Fonda and Yves Montand, at the time very big stars. Jean-Pierre Gorin now teaches the study of film at the University of California, San Diego.
The Dziga Vertov group.
The small group of Maoists that Godard had brought together, which included Gorin, adopted the name Dziga Vertov Group. Godard had a specific interest in Vertov, a Soviet filmmaker—whose adopted name is derived from the verb to spin or rotate and is best remembered for "Man with the Movie Camera" (1929) and a contemporary of both the great Soviet montage theorists, most notably Sergei Eisenstein, and Russian constructivist and avant-garde artists such as Alexander Rodchenko and Vladimir Tatlin. Part of Godard's political shift after May 1968 was toward a proactive participation in the class struggle.
Sonimage.
In 1972, Godard and Swiss filmmaker Anne-Marie Miéville started the alternative video production and distribution company Sonimage, based in Grenoble. Under Sonimage, Godard produced both "Numéro Deux" (1975) and "Sauve qui peut (la vie)" (1980). In 1976, Godard and Miéville, his wife, collaborated on a series of innovative video works for European broadcast television called "Six fois deux/Sur et sous la communication" (1976) and "France/tour/détour/deux/enfants" (1978).
1980–present.
Godard's return to somewhat more traditional fiction was marked with "Sauve qui peut (la vie)" (1980), the first of a series of more mainstream films marked by autobiographical currents: for example "Passion" (1982), "Lettre à Freddy Buache" (1982), "Prénom Carmen" (1984), and "Grandeur et décadence d'un petit commerce de cinéma" (1986). There was, though, another flurry of controversy with "Je vous salue, Marie" (1985), which was condemned by the Catholic Church for alleged heresy, and also with "King Lear" (1987), an extraordinary but much-excoriated essay on William Shakespeare and language. Also completed in 1987 was a segment in the film ARIA which was based loosely from the plot of Armide; it is set in a gym and uses several arias by Jean-Baptiste Lully from his famous Armide.
His later films have been marked by great formal beauty and frequently a sense of requiem—"Nouvelle Vague" (New Wave, 1990), the autobiographical "JLG/JLG, autoportrait de décembre" ("JLG/JLG: Self-Portrait in December", 1995), and "For Ever Mozart" (1996). "Allemagne année 90 neuf zéro" ("Germany Year 90 Nine Zero", 1991) was a quasi-sequel to "Alphaville" but done with an elegiac tone and focus on the inevitable decay of age. Between 1988 and 1998 he produced perhaps the most important work of his career in the multi-part series "Histoire(s) du cinéma", a monumental project which combined all the innovations of his video work with a passionate engagement in the issues of twentieth-century history and the history of film itself.
In 2001, "In Praise of Love" ("Éloge de l'amour") was released. The film is notable for its use of both film and video—the first half captured in 35-mm black and white, the latter half shot in color on DV—and subsequently transferred to film for editing. The blending of film and video recalls the statement from "Sauve Qui Peut", in which the tension between film and video evokes the struggle between Cain and Abel. The film is also noted for containing themes of aging, love, separation, and rediscovery as it follows the young artist Edgar in his contemplation of a new work on the four stages of love.
In "Notre musique" (2004), Godard turned his focus to war, specifically, the war in Sarajevo, but with attention to all war, including the American Civil War, the war between the US and Native Americans, and the Israeli–Palestinian conflict. The film is structured into three Dantean kingdoms: Hell, Purgatory and Paradise. Godard's fascination with paradox is a constant in the film. It opens with a long, ponderous montage of war images that occasionally lapses into the comic; Paradise is shown as a lush wooded beach patrolled by US Marines.
Godard's film, "Film Socialisme", premiered in the Un Certain Regard section at the 2010 Cannes Film Festival. It was released theatrically in France in May 2010.
Godard was rumored to be considering directing a film adaptation of Daniel Mendelsohn's "", an award-winning book about the Holocaust. In 2013, Godard released the short "Les trois désastres" ("The Three Disasters") as part of the omnibus film "3X3D" with filmmakers Peter Greenaway and Edgar Pera. "3X3D" premiered at the 2013 Cannes Film Festival.
His 2014 film "Goodbye to Language", shot in 3-D, revolves around a couple who cannot communicate with each other until their pet dog acts as an interpreter for them. The film was selected to compete for the Palme d'Or in the main competition section at the 2014 Cannes Film Festival, where it won the Jury Prize.
In 2015 J. Hoberman reported that Godard is working on a new film.
Filmography.
Feature Films
Collaboration with ECM Records.
Godard shares a friendship with Manfred Eicher, founder and head of the innovative German music label ECM Records. The label has released the soundtracks of "Nouvelle Vague" (ECM NewSeries 1600-01) and "Histoire(s) du cinéma" (ECM NewSeries 1706) by Godard. This collaboration expanded over the years and led on the one hand into the contribution of several stills from Godard’s movies for album covers. On the other hand, Eicher took over the musical direction of many of Godard’s films like "Allemagne 90 neuf zéro", "Hélas Pour Moi", "JLG" or "For Ever Mozart". Additionally Godard has released a collection of short films on the label with Anne-Marie Miéville called "Four Short Films" (ECM 5001).
Album covers with Godard's contribution include:

</doc>
<doc id="60372" url="https://en.wikipedia.org/wiki?curid=60372" title="Calamine (mineral)">
Calamine (mineral)

Calamine is a historic name for an ore of zinc. The name "calamine" was derived from "lapis calaminaris", a Latin corruption of Greek "cadmia (καδμία)", the old name for zinc ores in general. The name of the Belgian town of Kelmis, "La Calamine" in French, which was home to a zinc mine, comes from that. In the 18th and 19th centuries large ore mines could be found near the German village of Breinigerberg.
During the early 19th century it was discovered that what had been thought to be one ore was actually two distinct minerals:
Although chemically and crystallographically quite distinct, the two minerals exhibit similar massive or botryoidal external form and are not readily distinguished without detailed chemical or physical analysis. The first person to separate the minerals was the British chemist and mineralogist James Smithson in 1803. In the mining industry the term calamine has been historically used to refer to both minerals indiscriminately.
In mineralogy calamine is no longer considered a valid term. It has been replaced by smithsonite and hemimorphite in order to distinguish it from the pinkish mixture of zinc oxide (ZnO) and iron(III) oxide (Fe2O3) used in calamine lotion.
Until the 18th century, "calamine" was essential for the production of brass since metallic zinc does not exist in nature and no technique was known to produce it. Brass produced using calamine is called calamine brass.

</doc>
<doc id="60373" url="https://en.wikipedia.org/wiki?curid=60373" title="8-bit clean">
8-bit clean

8-bit clean describes a computer system that correctly handles 8-bit character encodings, such as the ISO 8859 series and the UTF-8 encoding of Unicode.
History.
Up to the early 1990s, many programs and data transmission channels assumed that all characters would be represented as numbers between 0 and 127 (7 bits). On computers and data links using 8-bit bytes this left the top bit of each byte free for use as a parity, flag bit, or meta data control bit. 7-bit systems and data links are unable to handle more complex character codes which are commonplace in non-English-speaking countries with larger alphabets.
Binary files cannot be transmitted through 7-bit data channels directly. To work around this, binary-to-text encodings have been devised which use only 7-bit ASCII characters. Some of these encodings are uuencoding, Ascii85, SREC, BinHex, kermit and MIME's Base64. EBCDIC-based systems cannot handle all characters used in UUencoded data. However, the base64 encoding does not have this problem.
SMTP and NNTP 8-bit cleanness.
Historically, various media were used to transfer messages, some of them only supporting 7-bit data, so an 8-bit message had high chances to be garbled during transmission in the 20th century. But some implementations really did not care about formal discouraging of 8-bit data and allowed high bit set bytes to pass through.
Many early communications protocol standards, such as RFC 780, RFC 788, RFC 821 for SMTP, RFC 977 for NNTP, RFC 1056, RFC 2821, RFC 5321, were designed to work over such "7-bit" communication links. They specifically mention the use of ASCII character set "transmitted as a 8-bit byte with the high-order bit cleared to zero" and some of these
explicitly restrict "all" data to 7-bit characters.
For the first few decades of email networks (1971 to the early 1990s),
most email messages were plain text in the 7-bit US-ASCII character set.
According to RFC 1428, the original RFC 821 definition of SMTP limits Internet Mail to
lines (1000 characters or less) of 7-bit US-ASCII characters.
Later the format of email messages was re-defined
in order to support
messages that are not entirely US-ASCII text
(text messages in character sets
other than US-ASCII,
and non-text messages,
such as audio and images).
The Internet community generally adds features by "extension", allowing communication in both directions between upgraded machines and not-yet-upgraded machines, rather than declaring formerly standards-compliant legacy software to be "broken" and insisting that all software world-wide be upgraded to the latest standard.
In the mid-1990s, people objected to "just send 8 bits (to RFC 821 SMTP servers)",
perhaps because of a perception that "just send 8 bits"
is an implicit declaration that ISO 8859-1 become the new "standard encoding", forcing everyone in the world to use the same character set.
Instead, the recommended way to take advantage of 8-bit-clean links between machines is to use the ESMTP (RFC 1869) 8BITMIME extension.

</doc>
<doc id="60378" url="https://en.wikipedia.org/wiki?curid=60378" title="IBM 709/90 9PAC">
IBM 709/90 9PAC

9PAC is a common abbreviation for 709 PACkage. It was a report generator developed in 1959 for the IBM 709 and used on its successor, the IBM 7090. It was developed by SHARE, an early IBM users' group, and based on the File Maintenance and Report Generator System developed by General Electric for the IBM 702, led by Harry Tellier.
Charles Bachman worked on its design in 1957, and although his company's order for the 709 was cancelled, he later included some of its general concepts into the more generalized idea of navigational databases.
Engineers at companies such as Union Carbide, Northwest Power Company, Philips Petroleum, Dow Chemical, and Chrysler cooperated on the project.

</doc>
<doc id="60379" url="https://en.wikipedia.org/wiki?curid=60379" title="Aioli">
Aioli

Aioli or aïoli ( or ; Provençal or "aiòli" ;
Aioli is, like mayonnaise, an emulsion or suspension of small globules of oil and oil-soluble compounds in water and water-soluble compounds. In Spain, purists consider that the absence of egg is what distinguishes aioli from mayonnaise, however this is not the case in France and other countries where egg and egg yolk can be used as an emulsifier and is generally used in making aioli today. Using only garlic as an emulsifier requires it to be thoroughly crushed and for oil to be add drop by drop so that the aioli is not "cut" by excess oil.
Since the late 1980s, it has become fashionable to call all flavored mayonnaises "aioli", with flavorings such as saffron, chili. However, purists insist that "flavored mayonnaise can contain garlic, but true aïoli contains no seasoning "but" garlic".
Word.
The word is a compound of the words for garlic and for oil. 
The English spelling comes from the French "aïoli", which itself comes from Occitan. The spelling in Occitan may be "alhòli", following the classical norm, or "aiòli", following the Mistralian norm. In Catalan, it is spelled "allioli" () or "alioli" (). In southeastern Spain, it is called "ajoaceite" or "ajiaceite", whereas in the rest of Spain, the Catalan term is more common.
Basic recipe.
Garlic is crushed in a mortar and pestle and emulsified with egg yolks, salt, and olive oil. Today, aioli is often made in a food processor or blender, but traditionalists object that this does not give the same result.
Serving.
In Spain, "allioli" is often served with arròs a banda from Alicante, with grilled lamb, grilled vegetables and arròs negre, and comes in other varieties such as allioli de codony (allioli with boiled quince, not the preserve) or allioli with boiled pear. Other commonly used vegetables are beets, fennel, celery, zucchini, cauliflower, chick peas, and raw tomato.
In Occitan cuisine, "aioli" is typically served with seafood, fish soup, and croutons, in a dish called "merluça amb alhòli".
In Malta, arjoli or ajjoli is commonly made with the addition of either crushed galletti or tomato.
In the Occitan Valleys of Italy it is served with potatoes boiled with salt and bay laurel.
In Provence, "aioli" or, more formally, "le grand aïoli", "aioli garni", or "aïoli monstre" is a dish consisting of various boiled vegetables (usually carrots, potatoes, artichokes, and green beans), poached fish (normally soaked salt cod), snails, canned tuna, other seafood, and boiled eggs, all served with "aioli". This dish is often served during the festivities on the feast days of the patron saint of Provençal villages and towns. It is traditional to serve it with snails for Christmas Eve and with cod on Ash Wednesday. Aïoli is so strongly associated with Provence that when the poet Frédéric Mistral started a regionalist, Provençal-language, newspaper in 1891, he called it "L'Aiòli".
Aillade.
Aillade is the name used in southern France for two different garlic-based condiments. In Provence, it is a garlic-flavored vinaigrette, while in areas such as Languedoc-Roussillon, it is the name given to aioli.

</doc>
<doc id="60383" url="https://en.wikipedia.org/wiki?curid=60383" title="A-0 System">
A-0 System

The A-0 system ("Arithmetic Language version 0"), written by Grace Hopper in 1951 and 1952 for the UNIVAC I, was the first compiler ever developed for an electronic computer. The A-0 functioned more as a loader or linker than the modern notion of a compiler. A program was specified as a sequence of subroutines and arguments. The subroutines were identified by a numeric code and the arguments to the subroutines were written directly after each subroutine code. The A-0 system converted the specification into machine code that could be fed into the computer a second time to execute the said program. 
The A-0 system was followed by the A-1, A-2, A-3 (released as ARITH-MATIC), AT-3 (released as MATH-MATIC) and B-0 (released as FLOW-MATIC).
The A-2 system was developed at the UNIVAC division of Remington Rand in 1953 and released to customers by the end of that year. Customers were provided the source code for A-2 and invited to send their improvements back to UNIVAC. Thus A-2 was an early, and perhaps the first, example of free and open-source software. 

</doc>
<doc id="60384" url="https://en.wikipedia.org/wiki?curid=60384" title="A0">
A0

A0, A-0, A0, or a0 may refer to:

</doc>
<doc id="60385" url="https://en.wikipedia.org/wiki?curid=60385" title="AO">
AO

AO, aO, Ao, or ao may refer to:

</doc>
<doc id="60389" url="https://en.wikipedia.org/wiki?curid=60389" title="Orange Book">
Orange Book

Orange Book may refer to:

</doc>
<doc id="60392" url="https://en.wikipedia.org/wiki?curid=60392" title="Sind Province (1936–55)">
Sind Province (1936–55)

Sindh was a province of British India from 1936 to 1947 and Pakistan from 1947 to 1955. Under the British, it encompassed the current territorial limits excluding the princely state of Khairpur with the capital at Karachi. After Pakistan's creation, the province lost the city of Karachi, as it became the capital of the newly created country.
Location.
The province was bordered by Karachi (within The Federal Capital Territory after 1948) and the princely states of Las Bela and Kalat on the west. To the north were the provinces of Baluchistan and West Punjab. The province bordered the princely state of Bahawalpur on the northeast and it enclosed on three sides the princely state of Khairpur. The nation of India's states of Rajasthan and Gujarat bordered to the east and south. On the southwest lay the Arabian Sea, with the Sind's coastline consisting entirely of river deltas, including the Indus River Delta up to Sind's border with the city of Karachi, now the capital of modern Sindh.
History.
Sindh was first settled by the Indus Valley Civilization and Mohenjo-daro, as early as 7000 BC. It had Greek influence during its history after the expansion of the Macedonian Empire, and developed trade with surrounding regions. Several Sunni Muslim and Rajput kingdoms were set up there, beginning with the Rai Dynasty and ending with the Arghun dynasty. The Mughal Empire conquered Sindh under the rule of Akbar in 1509. Soon after the coming of European companies, namely the British East Indian Company, the Mughal hold on the area loosened, and Sindh became part of the Bombay Presidency in 1843. Soon, it became the Sind Province.
1936–1947.
After conquest by the British in 1843 Sindh had been part of the Bombay Presidency, however on 1 April 1936 Sindh Division was separated from the Bombay Presidency and made into a province of British India.
1947–1955.
The independence and passage of the resolution joining Pakistan in the Sindh Assembly, Sindh becoming part of Pakistan in 1947. The province was merged into the province of West Pakistan in 1955 under the One Unit policy announced by Prime Minister Chaudhry Mohammad Ali.
Demographics.
By the time of independence in 1947 Sindh had had a Muslim majority for centuries but there were significant minorities of Hindus throughout the province. In 1947 due to communal tensions and the influx of two million Muslim refugees from India many Hindus were forced to flee to India.
The refugees from India were mostly Urdu speakers, and although the official language of Sindh was Sindhi, many schools in big cities of Sindh and switched to Urdu schools.
Government.
The offices of Governor of Sindh and Chief Minister of Sindh were established in 1936 when Sindh became a province. This system continued until 1955 when Sindh was dissolved.

</doc>
<doc id="60393" url="https://en.wikipedia.org/wiki?curid=60393" title="ARITH-MATIC">
ARITH-MATIC

ARITH-MATIC is an extension of Grace Hopper's A-2 programming language, developed around 1955. ARITH-MATIC was originally known as A-3, but was renamed by the marketing department of Remington Rand UNIVAC.

</doc>
<doc id="60394" url="https://en.wikipedia.org/wiki?curid=60394" title="A3D">
A3D

A3D (Aureal 3-Dimensional) was a technology developed by Aureal Semiconductor for use in their Vortex line of PC sound chips to deliver three-dimensional sound through headphones, two or even four speakers. The technology used head-related transfer functions (HRTF), which the human ear interprets as spatial cues indicating the location of a particular sound source. Many modern sound cards and PC games incorporated A3D via license from Aureal. Due to Aureal's acquisition (see below) the A3D technology is now part of the intellectual property of Creative Labs.
A3D differs from various forms of discrete positional audio in that it only requires two speakers, while surround sound typically requires more than four. The particular advantage of A3D is for dynamic or interactive environments such as simulations, games, video conference, and remote learning. A3D is not as effective for static productions such as movies which typically employ surround sound.
A3D uses a subset of the actual in-game 3D world data to accurately model the location of both direct (A3Dspace) and reflected (A3Dverb) sound streams (A3D 2.0 can perform up to 60 first-order reflections). EAX 1.0, the competing technology at the time promoted by Creative Labs, simulated the environment with an adjustable reverb—it didn't calculate any actual reflections off the 3D surfaces.
Creative Labs sued Aureal for patent infringement in March 1998 [http://web.archive.org/web/19990829025202/www.aureal.com/cgi-bin/pub/display.pl?template=press_aur_detail.htm&serial=76], and Aureal countersued for patent infringement and deceptive trade practices. Aureal won the lawsuit brought by Creative in December 1999. However, the cost of the legal battle caused Aureal's investors to cease funding operations, forcing Aureal into bankruptcy. Creative then acquired Aureal's assets in September 2000 through the bankruptcy court with the specific provision that Creative Labs would be released from all claims of past infringement by Creative Labs upon Aureal's A3D technology. Creative Labs has not chosen to support the A3D API.

</doc>
<doc id="60399" url="https://en.wikipedia.org/wiki?curid=60399" title="AAP">
AAP

Aap or AAP may refer to:

</doc>
<doc id="60400" url="https://en.wikipedia.org/wiki?curid=60400" title="Association of American Publishers">
Association of American Publishers

The Association of American Publishers (AAP) is the national trade association of the American book publishing industry. AAP has more than 300 members, including most of the major commercial publishers in the United States, as well as smaller and non-profit publishers, university presses and scholarly societies. Former U.S. congresswoman Patricia Schroeder served as the association's CEO from 1997 until 2009, taking over the role from two time US Ambassador and Assistant Secretary of State Nicholas A. Veliotes. On May 1, 2009 former U.S. congressman Tom Allen took over as president and CEO.
Activities.
AAP members publish hardcover and paperback books in every field, educational materials for the elementary, secondary, postsecondary, and professional markets, scholarly journals, computer software, and electronic products and services.
The association's core programs deal with intellectual property; new technology and digital issues of concern to publishers; the freedom to read, censorship and libel; the freedom to publish; funding for education and libraries; postal rates and regulations; tax and trade policy; and international copyright enforcement.
Controversy.
AAP was criticized after it contracted Eric Dezenhall's crisis management firm to promote its position regarding the open access movement. Schroeder told the "Washington Post" the association hired Dezenhall when members realized they needed help. "We thought we were angels for a long time and we didn't need PR firms."

</doc>
<doc id="60401" url="https://en.wikipedia.org/wiki?curid=60401" title="AAP DTD">
AAP DTD

In computing, AAP DTD is a Document Type Definition for a standard SGML document type for scientific documents, defined by the Association of American Publishers.
The AAP DTD has been succeeded by ISO 12083.

</doc>
<doc id="60408" url="https://en.wikipedia.org/wiki?curid=60408" title="IBM Notes">
IBM Notes

IBM Notes (formerly Lotus Notes; see branding, below) and IBM Domino (formerly Lotus Domino) are the client and server, respectively, of a collaborative client-server software platform sold by IBM.
IBM Notes provides business collaboration functions, such as email, calendars, to-do lists, contacts management, teamrooms, discussion forums, file sharing, microblogging, instant messaging, blogs, and user directories. IBM Notes can also be used with other IBM Domino applications and databases. IBM Notes 9 Social Edition removed integration with the office software package IBM Lotus Symphony, which had been integrated with the IBM Lotus Notes client in versions 8.x.
Lotus Development Corporation originally developed "Lotus Notes" in 1989. IBM bought the Lotus corporation in 1995 and it became known as the Lotus Development division of IBM. it forms part of the IBM Software and Systems Group under the name "IBM Collaboration Solutions".
IBM Notes is a desktop workflow application, commonly used in corporate environments for email but can also be used to access databases such as document libraries and custom applications.
Design.
IBM Notes is a client-server cross-platform application runtime environment that provides an interface to the IBM Notes and Domino software. IBM Notes can be used as an email client without an IBM Domino server, for example, as an IMAP client.
IBM Notes and Domino provide email, calendars, instant messaging (with additional IBM software voice- and video-conferencing and web-collaboration), discussions/forums, blogs, and an inbuilt personnel/user directory. In addition to these standard applications, an organization may use the IBM Domino Designer development environment and other tools to develop additional integrated applications such as request approval / workflow and document management.
The IBM Notes and Domino product consists of several components:
IBM Notes and Domino compete with products from other companies such as Microsoft, Google, Zimbra and others. Because of the application development abilities, IBM Notes and Domino is often compared to products like Microsoft Sharepoint. The database in IBM Notes and Domino can be replicated between servers and between server and client, thereby allowing clients offline capabilities.
IBM Domino, a business application as well as a messaging server, is only compatible with IBM Notes. IBM Notes (and since IBM Domino 9, the Notes Browser Plugin) may be used to access any IBM Domino application, such as discussion forums, document libraries, and numerous other applications. IBM Notes resembles a web-browser in that it may run any compatible application that the user has permission for.
IBM Notes provides applications that can be used to:
The standard storage mechanism in IBM Domino is a NoSQL document-database format, the "Notes Storage Facility" (.nsf). The .nsf file will normally contain both an application design and its associated data. IBM Notes can also access relational databases, either through an additional server called Lotus Enterprise Integration for Domino, through ODBC calls or through the use of XPages.
As IBM Notes and Domino is an application runtime environment, email and calendars operate as applications within IBM Notes, which IBM provides with the product. A Domino application-developer can change or completely replace that application. IBM has released the base templates as open source as well.
Programmers can develop applications for IBM Notes in a variety of development languages including:
The client supports a formula language as well as JavaScript. Software developers can build applications to run either within the IBM Notes application runtime environment or through a web server for use in a web browser, although the interface would need to be developed separately unless XPages is used.
Use.
IBM Notes can be used for email, as a calendar, PIM, instant messaging, Web browsing, and other applications. Notes can access both local- and server-based applications and data.
IBM Notes can function as an IMAP and POP email client with non-Domino mail servers. The system can retrieve recipient addresses from any LDAP server, including Active Directory, and includes a web browser, although it can be configured by a Domino Developer to launch a different web browser instead.
Features include group calendars and schedules, SMTP/MIME-based email, NNTP-based news support, and automatic HTML conversion of all documents by the Domino HTTP task.
IBM Notes can be used with IBM Sametime instant-messaging to allow to see other users online and chat with one or more of them at the same time. Beginning with Release 6.5, this function has been freely available. Presence awareness is available in email and other IBM Domino applications for users in organizations that use both IBM Notes and IBM Sametime.
Since version 7, Notes has provided a Web services interface. Domino can be a Web server for HTML files; authentication of access to Domino databases or HTML files uses the IBM Domino user directory and external systems such as Microsoft Active Directory.
A design client, IBM Domino Designer, can allow the development of database applications consisting of forms (which allow users to create documents) and views (which display selected document fields in columns).
In addition to its role as a groupware system (email, calendaring, shared documents and discussions), IBM Notes and Domino can also construct "workflow"-type applications, particularly those which require approval processes and routing of data.
Since Release 5, server clustering has had the ability to provide geographic redundancy for servers.
Notes System Diagnostic (NSD) gathers information about the running of a Notes workstation or of a Domino server.
On March 13, 2013, IBM released IBM Notes 9.0 Social Edition as the latest release.
Overview.
Client/server.
IBM Notes and Domino is a NoSQL client/server database environment. The server software is called IBM Domino and the client software is IBM Notes. IBM Domino software can run on Windows, Unix, Linux, AIX, and IBM mid-range systems such as the IBM System i (previously known as AS/400), and can scale to tens of thousands of users per server. There are different supported versions of the IBM Domino server that are supported on the various levels of server operating systems. Usually the latest server operating system is only officially supported by a version of IBM Domino that is released at about the same time as that OS.
IBM Domino has security capabilities on a variety of levels. The authorizations can be granular, down to the field level in specific records all the way up to 10 different parameters that can be set up at a database level, with intermediate options in between. Users can also assign access for other users to their personal calendar and email on a more generic reader, editor, edit with delete and manage my calendar levels. All of the security in IBM Notes and Domino is independent of the server OS or Active Directory. Optionally, the IBM Notes client can be configured to have the user use their Active Directory identity.
Data replication.
The first release of IBM Notes included a generalized replication facility. The generalized nature of this feature set it apart from predecessors like Usenet and continues to differentiate IBM Notes from many other systems that now offer some form of synchronization or replication. The replication facility in IBM Notes and Domino is not limited to email, calendar, and contacts. It is available for any data in any application that uses Notes Storage Facility (.nsf) files. No special programming, tagging, or other configuration is required to enable replication.
IBM Domino servers and Notes clients identify NSF files by their Replica IDs, and keep replicate files synchronized by bi-directionally exchanging data, metadata, and application logic and design. There are options available to define what meta-data replicate, or specifically exclude certain meta data from replicating. Replication between two servers, or between a client and a server, can occur over a network or a point-to-point modem connection. Replication between servers may occur at intervals according to a defined schedule, in near-real-time when triggered by data changes in server clusters, or when triggered by an administrator or program.
Creation of a local replica of an NSF file on the hard disk of an IBM Notes client enables the user to fully use IBM Notes and Domino databases while working off-line. The client synchronizes any changes when client and server next connect. Local replicas are also sometimes maintained for use while connected to the network in order to reduce network latency. Replication between an IBM Notes client and Domino server can run automatically according to a schedule, or manually in response to a user or programmatic request. Since Notes 6, local replicas maintain all security features programmed into the applications. Earlier releases of Notes did not always do so. Early releases also did not offer a way to encrypt NSF files, raising concerns that local replicas might expose too much confidential data on laptops or insecure home office computers, but more recent releases offer encryption, and as of the default setting for newly created local replicas.
Security.
IBM Notes was the first widely adopted software product to use public key cryptography for client–server and server–server authentication and for encryption of data. Until US laws regulating encryption were changed in 2000, IBM and Lotus were prohibited from exporting versions of Notes that supported symmetric encryption keys that were longer than 40 bits. In 1997, Lotus negotiated an agreement with the NSA that allowed export of a version that supported stronger keys with 64 bits, but 26 of the bits were encrypted with a special key and included in the message to provide a "workload reduction factor" for the NSA. This strengthened the protection for users of Notes outside the US against private-sector industrial espionage, but not against spying by the US government. This implementation was widely announced, but with some justification many people did consider it to be a backdoor. Some governments objected to being put at a disadvantage to the NSA, and as a result Lotus continued to support the 40-bit version for export to those countries.
Under current US export laws, IBM Notes supports only one version of the Notes PKI with 128-bit symmetric keys, 1024-bit public keys, and no workload reduction factor. The Domino server includes security tools support S/MIME, SSL 3.0 with industry standard key sizes for HTTP and other Internet protocols, X.509 client certificates, and an integrated certificate authority.
IBM Notes and Domino also uses a code-signature framework that controls the security context, runtime, and rights of custom code developed and introduced into the environment. Notes 5 introduced execution control lists (ECLs) at the client level. Notes and Domino 6 allowed ECLs to be managed centrally by server administrators through the implementation of Policies. Since release 4.5, the code signatures listed in properly configured ECLs prevent code from being executed by external sources, to avoid virus propagation through Notes/Domino environments. Administrators can centrally control whether each mailbox user can add exceptions to, and thus override, the ECL.
Database security.
Every database has an access control list (ACL) that specifies the level of access a user or a server can have to that database. A user's access level determines what tasks he or she can perform in the database. A server's access level determines what information the server can replicate. The names of access levels are the same for users and servers. Only a user with Manager access can create or modify the ACL. To set an ACL, the Manager selects the access level, user type, and access level privileges for each user or group in a database. Default entries in the ACL can be set when the Manager creates the database. The manager can also assign roles if the database designer determines this level of access refinement is needed by the application; for instance, when users within the same group must be provided different levels of access.
Programming.
IBM Notes and Domino is a cross-platform, distributed document-oriented NoSQL database and messaging framework and rapid application development environment that includes pre-built applications like email, calendar, etc. This sets it apart from its major commercial competitors, such as Microsoft Exchange or Novell GroupWise, which are purpose-built applications for mail and calendaring that offer APIs for extensibility.
IBM Domino databases are built using the IBM Domino Designer client, available only for Microsoft Windows; standard user clients are available for Windows, Linux, and OS X. A key feature of IBM Notes is that many replicas of the same database can exist at the same time on different servers and clients, across dissimilar platforms; the same storage architecture is used for both client and server replicas. Originally, replication in Notes happened at document (i.e., record) level. With release of Notes 4 in 1996, replication was changed so that it now occurs at field level.
A database is a Notes Storage Facility (.nsf) file, containing basic units of storage known as a "note". Every note has a UniqueID that is shared by all its replicas. Every replica also has a UniqueID that uniquely identifies it within any cluster of servers, a domain of servers, or even across domains belonging to many organizations that are all hosting replicas of the same database. Each note also stores its creation and modification dates, and one or more Items.
There are several classes of notes, including design notes and document notes. Design notes are created and modified with the Domino Designer client, and represent programmable elements, such as the GUI layout of forms for displaying and editing data, or formulas and scripts for manipulating data. Document notes represent user data, and are created and modified with the Lotus Notes client, via a web browser, via mail routing and delivery, or via programmed code.
Document notes can have parent-child relationships, but IBM Notes should not be considered a hierarchical database in the classic sense of information management systems. Notes databases are also not relational, although there is a SQL driver that can be used with Notes, and it does have some features that can be used to develop applications that mimic relational features. IBM Notes does not support atomic transactions, and its file locking is rudimentary. IBM Notes is a document-oriented database (document-based, schema-less, loosely structured) with support for rich content and powerful indexing facilities. This structure closely mimics paper-based work flows that IBM Notes is typically used to automate.
Items represent the content of a note. Every item has a name, a type, and may have some flags set. A note can have more than one item with the same name. Item types include Number, Number List, Text, Text List, Date-Time, Date-Time List, and Rich Text. Flags are used for managing attributes associated with the item, such as read or write security. Items in design notes represent the programmed elements of a database. For example, the layout of an entry form is stored in the rich text Body item within a form design note. This means that the design of the database can replicate to users' desktops just like the data itself, making it extremely easy to deploy updated applications.
Items in document notes represent user-entered or computed data. An item named "Form" in a document note can be used to bind a document to a form design note, which directs the IBM Notes client to merge the content of the document note items with the GUI information and code represented in the given form design note for display and editing purposes. However, other methods can be used to override this binding of a document to a form note. The resulting loose binding of documents to design information is one of the cornerstones of the power of IBM Notes. Traditional database developers used to working with rigidly enforced schemas, on the other hand, may consider the power of this feature to be a double-edged sword.
IBM Notes applications development uses several programming languages. Formula and LotusScript are the two original ones. LotusScript is similar to, and may even be considered a specialized implementation of, Visual Basic, but with the addition of many native classes that model the IBM Notes environment, whereas Formula is similar to Lotus 1-2-3 formula language but is unique to Notes.
Java was integrated into IBM Notes beginning with Release 4.5. With Release 5, Java support was greatly enhanced and expanded, and JavaScript was added. While LotusScript remains a primary tool in developing applications for the Lotus Notes client, Java and JavaScript are the primary tools for server-based processing, developing applications for browser access, and allowing browsers to emulate the functionality of the IBM Notes client. With XPages, the IBM Notes client can now natively process Java and JavaScript code, although applications development usually requires at least some code specific to only IBM Notes or only a browser.
As of version 6, Lotus established an XML programming interface in addition to the options already available. The Domino XML Language (DXL) provides XML representations of all data and design resources in the Notes model, allowing any XML processing tool to create and modify IBM Notes and Domino data.
Since Release 8.5, XPages were also integrated into IBM Notes.
External to the IBM Notes application, IBM provides toolkits in C, C++, and Java to connect to the IBM Domino database and perform a wide variety of tasks. The C toolkit is the most mature, and the C++ toolkit is an objectized version of the C toolkit, lacking many functions the C toolkit provides. The Java toolkit is the least mature of the three and can be used for basic application needs.
Database.
IBM Notes includes a database management system but IBM Notes files are different from relational or object databases because they are document-centric. Document-oriented databases such as IBM Notes allow multiple values in items (fields), do not require a schema, come with built-in document-level access control, and store rich text data. IBM Domino 7 to 8.5.x supports the use of IBM DB2 database as an alternative store for IBM Notes databases. This NSFDB2 feature, however, is now in maintenance mode with no further development planned. An IBM Notes database can be mapped to a relational database using tools like DECS, , JDBCSql for Domino or NotesSQL.
It could be argued that IBM Notes and Domino is a multi-value database system like PICK, or that it is an object system like Zope, but it is in fact unique. Whereas the temptation for relational database programmers is to normalize databases, Notes databases must be denormalized. RDBMS developers often find it difficult to conceptualize the difference. It may be useful to think of an IBM Notes document (a 'note') as analogous to an XML document natively stored in a database (although with limitations on the data types and structures available).
Since Lotus Notes 8.5, IBM started to change the term Database to Application, because of the reason that these files are not really object databases as mentioned above.
The benefits of this data structure are:
Configuration.
The IBM Domino server or the IBM Notes client store their configuration in their own databases / application files (*.nsf). No relevant configuration settings are saved in the Windows Registry if the operating system is Windows. Some other configuration options (primary the start configuration) is stored in the notes.ini (there are currently over 2000 known options available).
Use as an email client.
IBM Notes is commonly deployed as an end-user email client in larger organizations, with IBM claiming a cumulative 145 million licenses sold to date. (IBM does not release the number of licenses on current maintenance, nor does it track number of licenses in current use.) 
When an organization employs an IBM Domino server, it usually also deploys the supplied IBM Notes client for accessing the IBM Notes application for email and calendaring but also to use document management and workflow applications. As IBM Notes is a runtime environment, and the email and calendaring functions in IBM Notes are simply an application provided by IBM, the administrators are free to develop alternate email and calendaring applications. It is also possible to alter, amend or extend the IBM supplied email and calendaring application.
The IBM Domino server also supports POP3 and IMAP mail clients, and through an extension product (Domino Access for Microsoft Outlook) supports native access for Microsoft Outlook clients (now with limited support).
IBM also provides IBM iNotes (in Notes 6.5 renamed to "Domino Web Access" but in version 8.0 reverted to iNotes), to allow the use of email and calendaring features through web browsers on Windows, Mac and Linux, such as Internet Explorer and Firefox. There are several spam filtering programs available (including IBM Lotus Protector), and a rules engine allowing user-defined mail processing to be performed by the server.
Comparison with other email clients.
IBM Notes was designed as a collaborative application platform where email was just one of numerous applications that ran in the Notes client software. The Notes client was also designed to run on multiple platforms including Windows, OS/2, Mac, SCO Open Desktop UNIX, and Linux. These two factors have resulted in the user interface containing some differences from applications that only run on Windows. Furthermore, these differences have often remained in the product to retain backward compatibility with earlier releases, instead of conforming to updated Windows UI standards. The following are some of these differences.
Lotus Notes 7 and older versions had more differences, which were removed from subsequent releases:
Lotus Notes 8.0 (released in 2007) became the first version to employ a dedicated user-experience team, resulting in a greatly improved IBM Notes client experience in the primary and new notes user interface. This new interface runs in the open source Eclipse Framework, which is a project started by IBM, opening up more application development opportunities through the use of Eclipse plug-ins. The new interface provides many new user interface features and the ability to include user-selected applications/applets in small panes in the interface. Lotus Notes 8.0 also included a new email interface / design to match the new Lotus Notes 8.0 eclipse based interface. Eclipse is a Java framework and allows IBM to port Notes to other platforms rapidly. An issue with Eclipse and therefore Notes 8.0 is the applications start-up and user-interaction speed. Lotus Notes 8.5 sped up the application and the increase in general specification of PCs means this is less of an issue. IBM Notes 9 continued the evolution of the user interface to more closely align with modern application interfaces found in many commercial packaged or web-based software. Currently, the software still does not have an auto-correct option - or even ability - to reverse accidental use of caps lock.
Domino is now running on the Eclipse platform and offers many new development environments and tools such as XPages.
For lower spec PCs, a new version of the old interface is still provided albeit as it is the old interface many of the new features are not available and the email user interface reverts to the Notes 7.x style.
This new and improved user experience builds on Notes 6.5 (released in 2003), which upgraded the email client, previously regarded by many as the product's Achilles heel. Features added at that time included:
Reception.
Publications such as "The Guardian" in 2006 have criticized earlier versions of Lotus Notes for having an "unintuitive interface" and cite widespread dissatisfaction with the usability of the client software. "The Guardian" indicated that Notes has not necessarily suffered as a result of this dissatisfaction due to the fact that "the people who choose [enterprise software tend not to be the ones who use it."
Earlier versions of Lotus Notes have also been criticized for violating an important usability best practice that suggests a consistent UI is often better than custom alternative. Software written for a particular operating system should follow that particular OS's user interface style guide. Not following those style guides can confuse users. A notable example is F5 keyboard shortcut, which is used to refresh window contents in Microsoft Windows. Pressing F5 in Lotus Notes before release 8.0 caused it to lock screen. Since this was a major point of criticism this was changed in release 8.0. Old versions did not support proportional scrollbars (which give the user an idea of how long the document is, relative to the portion being viewed). Proportional scroll bars were only introduced in Notes 8.
Older versions of Lotus Notes also suffered from similar user interaction choices, many of which were also corrected in subsequent releases. One example that was corrected in Release 8.5: In earlier versions the out-of-office agent needed to be manually enabled when leaving and disabled when coming back, even if start and end date have been set. As of Release 8.5 the out-of-office notification now automatically shuts off without a need for a manual disable.
Unlike some other e-mail client software programs, IBM Notes developers made a choice to not allow individual users to determine whether a return receipt is sent when they open an e-mail; rather, that option is configured at the server level. IBM developers believe "Allowing individual cancellation of return receipt violates the intent of a return receipt function within an organization". So, depending on system settings, users will have no choice in return receipts going back to spammers or other senders of unwanted e-mail. This has led tech sites to publish ways to get around this feature of Notes. For IBM Notes 9.0 and IBM iNotes 9.0, the IBM Domino server's .INI file can now contain an entry to control return receipt in a manner that's more aligned with community expectations (IBM Notes 9 Product Documentation).
When Lotus Notes crashes, some processes may continue running and prevent the application from being restarted until they are killed.
Related software.
Related IBM Lotus products.
Over the 20-year history of IBM Notes, Lotus Development Corporation and later IBM have developed many other software products that are based on or integrated with IBM Notes. The most prominent of these is the IBM Lotus Domino server software, which was originally known as the Lotus Notes Server and gained a separate name with the release of version 4.5. The server platform also became the foundation for products such as IBM Lotus Quickr for Domino, for document management, and IBM Sametime for instant messaging, audio and video communication, and web conferencing, and with Release 8.5, IBM Connections.
In early releases of IBM Notes, there was considerable emphasis on client-side integration with the IBM Lotus SmartSuite environment. With Microsoft's increasing predominance in office productivity software, the desktop integration focus switched for a time to Microsoft Office. With the release of version 8.0 in 2007, based on the Eclipse framework, IBM again added integration with its own office-productivity suite, the OpenOffice.org-derived IBM Lotus Symphony. IBM Lotus Expeditor is a framework for developing Eclipse-based applications.
Other IBM products and technologies have also been built to integrate with IBM Notes. For mobile-device synchronization, this previously included the client-side IBM Lotus Easysync Pro product (no longer in development) and IBM Lotus Notes Traveler, a newer no-charge server-side add-on for mail, calendar and contact sync. A recent addition to IBM's portfolio are two IBM Lotus Protector products for mail security and encryption, which have been built to integrate with Lotus Notes.
Related software from other vendors.
With a long market history and large installed base, IBM Notes and Domino have spawned a large third-party software ecosystem. Such products can be divided into four broad, and somewhat overlapping classes:
History.
IBM Notes has a history spanning more than 20 years. Its chief inspiration was "PLATO Notes", created by David R. Woolley at the University of Illinois in 1973. In today's terminology, PLATO Notes was a message board, and it was part of the foundation for an online community which thrived for more than 20 years on the PLATO system. Ray Ozzie worked with PLATO while attending the University of Illinois in the 1970s. When PC network technology began to emerge, Ozzie made a deal with Mitch Kapor, the founder of Lotus Development Corporation, that resulted in the formation of Iris Associates in 1984 to develop products that would combine the capabilities of PCs with the collaborative tools pioneered in PLATO. The agreement put control of product development under Ozzie and Iris, and sales and marketing under Lotus. In 1994, after the release and marketplace success of Notes R3, Lotus purchased Iris. In 1995 IBM purchased Lotus.
In 2008, IBM released XPages technology, based on JavaServer Faces. This allows IBM Notes applications to be displayed to browser clients and in the Notes client with no change of the code. Previously, IBM Domino applications could be accessed through browsers, but required web specific modifications to get full functionality in browsers. XPages also give the application new capabilities that are not possible with the classic IBM Notes client. The IBM Domino 9 Social Edition included the IBM Notes Browser Plugin, allowing most IBM Domino applications to display unmodified through a web browser without requiring the IBM Notes rich desktop client.
Branding.
When Lotus Notes was initially released, the name "Notes" referred to both the client and server components. Prior to release 4.5, the term "Lotus Notes" referred to both the client and server applications. In 1996, Lotus released an HTTP server add-on for the Notes 4 server called "Domino". This add-on allowed Notes documents to be rendered as web pages in real time. Later that year, the Domino web server was integrated into release 4.5 of the core Notes server and the entire server program was re-branded, taking on the name "Domino". Only the client program officially retained the "Lotus Notes" name.
In November 2012, IBM announced it would be dropping the Lotus brand and moving forward with the IBM brand only to identify products, including Notes and Domino. On March 13, 2013, IBM announced the availability of IBM Notes 9 Social Edition, the replacement name and latest version for the updated client software. As of March 21, 2013 IBM Notes was in release 9.0, with the official name IBM Notes 9 Social Edition.
Release history.
IBM donated parts of the IBM Notes and Domino code to OpenOffice.org on September 12, 2007 and since 2008 has been regularly donating code to OpenNTF.org.
Future.
Since the IBM acquisition of Lotus in 1995, some industry analysts and mainstream business press writers, along with IBM competitors, have made repeated predictions of the decline or impending demise of IBM Notes and Domino. One noted example of this was an article published in "Forbes" magazine entitled "The decline and fall of Lotus", published in April 1998. Since then, IBM claims that the installed base of Lotus Notes has increased from an estimated 42 million seats in September 1998 to approximately 145 million cumulative licenses sold through 2008. (IBM does not publish the number of licenses on current maintenance. Additionally, IBM Notes and Domino users who no longer pay maintenance are permitted to keep using the software—they are simply not permitted to install subsequent releases.)
Speculation about the decline of IBM Notes was fueled by lingering market confusion emanating from IBM placing marketing emphasis on Websphere and IBM Workplace in 2003 and 2004. IBM Workplace, however, has been discontinued, thus this source of confusion about the future of IBM Notes and Domino has been rendered moot. While the future of any product in the technology sector cannot be predicted, IBM has made announcements that indicate that it continues to invest heavily in research and development on the IBM Notes and Domino product line. Public roadmaps have shown a commitment by IBM to continue research and development of IBM Notes and Domino through 2016.
In 2005, some analysts concluded that IBM Notes and Domino was losing market share to Microsoft Exchange. There is no general agreement, however, about methods of accurately calculating share in the messaging and collaboration market. Figures based on seat count may be skewed by the presence of unused seats that are counted as a result of "bundled CALs", and figures based on customer count may be skewed by difference in typical customer organization sizes. IBM has asserted that growth shown in the revenue figures for the IBM Collaboration Solutions (formerly "Lotus") brand, as published in their audited annual financial report, purportedly show the continuing strength of the IBM Notes and Domino product line in the market. According to these figures, the IBM Notes and Domino product line has sustained double-digit growth since late 2004 and continuing through 2006, including 30% year-to-year growth in Q4 of 2006.
IBM contributed some of the code it had developed for the integration of the OpenOffice.org suite into Notes 8 to the project. IBM also packaged its version of OpenOffice.org for free distribution as IBM Lotus Symphony.
IBM Lotus Notes and Lotus Domino 8.0.1 shipped in February 2008, and 8.0.2 came in the summer.
Lotus Notes and Lotus Domino 8.5, which includes a MacOS client, support for Ubuntu in addition to Red Hat Linux and SUSE Linux distributions, as well as an Eclipse-based Domino Designer, shipped in December 2008. Version 8.5 also offers a new Ajax-enabled web programming paradigm called XPages. Since then, additional refreshes have been released including Lotus Notes 8.5.1, Lotus Notes 8.5.2, and Lotus Notes 8.5.3.
IBM Notes and Domino 9 Social Edition shipped on March 21, 2013. Improvements include significantly updated user interface, near-parity of IBM Notes and IBM iNotes functionality, the IBM Notes Browser Plugin, new XPages controls added to IBM Domino, refreshed IBM Domino Designer user interface, added support for To Dos on Android mobile devices, and additional server functionality as detailed in the Announcement Letter.

</doc>
<doc id="60411" url="https://en.wikipedia.org/wiki?curid=60411" title="Steller's sea cow">
Steller's sea cow

The Steller's sea cow ("Hydrodamalis gigas") is an extinct herbivorous marine mammal. It was the largest member of the order Sirenia, which includes its closest living relative, the dugong ("Dugong dugon"), and the manatees ("Trichechus" spp.). It reached up to in length, making it among the largest mammals other than whales to have existed in the holocene epoch. Although the sea cow had formerly been abundant throughout the North Pacific, by 1741, when it was first described by Georg Wilhelm Steller, chief naturalist on an expedition led by explorer Vitus Bering, its range had been limited to a single, isolated population surrounding the uninhabited Commander Islands. Within 27 years of discovery by Europeans, the slow-moving and easily captured Steller's sea cow was hunted to extinction.
Description.
The sea cow grew to at least in length as an adult, much larger than the manatee or dugong; however, concerning their weight, Steller's work contains two contradictory estimates: 4 and 24.3 metric tons. The true value is estimated to lie between these figures, at around 8 to 10 t. It looked somewhat like a large seal, but had two stout forelimbs and whale-like flukes.
According to Steller, it "is not the sea cow of Aristotle, for it never comes upon dry land to feed", but it can use its fore limbs for a number of tasks: swimming, walking on the shallows of the shore, supporting himself on the rocks, digging for algae and seagrasses, fighting, and embracing each other.
"It is covered with a thick hide, more like unto the bark of an ancient oak than unto the skin of an animal; the manatee’s hide is black, mangy, wrinkled, rough, hard, and tough; it is void of hairs, and almost impervious to an ax or to the point of a hook."
Its head is small and short compared to the huge body. The upper lip is so large, so broad, and extends so far beyond the mandible, that the mouth appears to be located underneath the skull. The mouth is rather small, toothless, and equipped with double lips, both above and below. When it closes its mouth, the space between the lips is filled up with a dense array of very thick white bristles, long. These bristles take the place of teeth and are used to pull out seaweed and hold food. Mastication is performed by two white bones or solid tooth masses.
Behavior.
It was completely tame, according to Steller. It fed on a variety of kelp. Wherever sea cows had been feeding, heaps of stalks and roots of kelp were washed ashore. The sea cow was also a slow swimmer and apparently was unable to submerge.
Habitat.
The number of sea cows was small and limited in range when Steller first described them; although he had said they were numerous and found in herds, zoologist Leonhard Hess Stejneger later estimated that at discovery there had been fewer than 1,500 remaining, and thus had been in immediate danger of extinction from overhunting. There is evidence that sea cows also inhabited the Near Islands during historic times. Oral tradition on Attu stated that sea cows were still hunted there after their extinction on the Commander Islands.
Fossils indicate Steller's sea cow was formerly widespread along the North Pacific coast, reaching south to Japan and California in the US. Given the rapidity with which its last population was eliminated, aboriginal hunting likely caused its extinction over the rest of its original range (aboriginal peoples apparently never inhabited the Commander Islands).
Population and extinction.
The species was quickly wiped out by the sailors, seal hunters, and fur traders who followed Bering's route past the islands to Alaska, who hunted it both for food and for skins, which were used to make boats. It was also hunted for its valuable subcutaneous fat, which was not only used for food (usually as a butter substitute), but also for oil lamps because it did not give off any smoke or odour and could be kept for a long time in warm weather without spoiling. By 1768, 27 years after it had been discovered by Europeans, Steller's sea cow was extinct.
It has been argued that the sea cow's decline may have also been an indirect response to the harvest of sea otters by aboriginal people from the inland areas. With the otters reduced, the population of sea urchins would have increased and reduced availability of kelp, the sea cow's primary source of food. Thus, aboriginal hunting of both species may have contributed to the sea cow's disappearance from continental shorelines. In historic times, though, aboriginal hunting had depleted sea otter populations only in localized areas. The sea cow would have been easy prey for aboriginal hunters, who would likely have exterminated accessible populations with or without simultaneous otter hunting. In any event, the sea cow was limited to coastal areas off islands without a human population by the time Bering arrived, and was already endangered. It has been demonstrated that the extinction of these remaining endangered populations of sea cow could have been effected solely by the hunting of the sea cow for meat by fur-trading mariners of the time, and no other factors (such as overpopulation of sea urchins) needed to have contributed.
Portrayals in media.
"Tales of a Sea Cow" is a 2012 film by Icelandic-French artist Etienne de France "documenting" a fictional 2006 re-discovery by scientists of a population of Steller's sea cows off the coast of Greenland via sound recordings or their calls. This film has been exhibited in public institutions such as art museums and universities in Europe. Art critic Annick Buread found the film a "tongue in cheek and joyous but unsettling fable".

</doc>
<doc id="60413" url="https://en.wikipedia.org/wiki?curid=60413" title="Susa">
Susa

Susa (; "Shush"; ; Hebrew "Shushān"; Greek: Σοῦσα ; "Shush"; Old Persian "Çūšā") was an ancient city of the Proto-Elamite, Elamite, First Persian Empire, Seleucid, and Parthian empires of Iran, and one of the most important cities of the Ancient Near East. It is located in the lower Zagros Mountains about east of the Tigris River, between the Karkheh and Dez Rivers.
The modern Iranian town of Shush is located at the site of ancient Susa. Shush is the administrative capital of the Shush County of Iran's Khuzestan province. It had a population of 64,960 in 2005.
Name.
In Elamite, the name of the city was written variously "Ŝuŝan", "Ŝuŝun", etc. The origin of the word "Susa" is from the local city deity "Inshushinak".
Literary traditions.
Susa was one of the most important cities of the Ancient Near East. In historic literature, Susa appears in the very earliest Sumerian records: for example, it is described as one of the places obedient to Inanna, patron deity of Uruk, in "Enmerkar and the Lord of Aratta".
Biblical texts.
Susa is also mentioned in the Ketuvim of the Hebrew Bible by the name Shushan, mainly in Esther, but also once each in Nehemiah and Daniel. Both Daniel and Nehemiah lived in Susa during the Babylonian captivity of the 6th century BCE. Esther became queen there, married to King Ahasueurus, and saved the Jews from genocide. A tomb presumed to be that of Daniel is located in the area, known as "Shush-Daniel". However, the current structure is actually a much later construction dated to the late nineteenth century, around 1871. Susa is further mentioned in the "Book of Jubilees" (8:21 & 9:2) as one of the places within the inheritance of Shem and his eldest son Elam; and in 8:1, "Susan" is also named as the son (or daughter, in some translations) of Elam.
Greek texts.
Greek mythology attributed the founding of Susa to king Memnon of Aethiopia, a character from Homer's Trojan War epic, the "Iliad".
Excavation history.
The site was examined in 1836 by Henry Rawlinson and then by A. H. Layard.
In 1851, some modest excavation was done by William Loftus, who identified it as Susa.
In 1885 and 1886 Marcel-Auguste Dieulafoy and Jane Dieulafoy began the first French excavations.
Jacques de Morgan conducted major excavations from 1897 until 1911. These efforts continued under Roland De Mecquenem until 1914, at the beginning of World War I. French work at Susa resumed after the war, led by De Mecquenem, continuing until World War II in 1940. Archaeological results from the later period were very thinly published and attempts are underway to remedy this situation.
Roman Ghirshman took over direction of the French efforts in 1946, after the end of the war. He continued there until 1967. Ghirshman concentrated on excavating a single part of the site, the hectare sized Ville Royale, taking it all the way down to bare earth. The pottery found at the various levels enabled a stratigraphy to be developed for Susa.
During the 1970s, excavations resumed under Jean Perrot.
Early settlement.
Archeologists have dated the first traces of an inhabited Neolithic village to c 7000 BCE. Evidence of a painted-pottery civilization has been dated to c 5000 BCE. Painted ceramic vessels from Susa in the earliest first style are a late, regional version of the Mesopotamian Ubaid ceramic tradition that spread across the Near East during the fifth millennium B.C.
In urban history, Susa is one of the oldest-known settlements of the region. Based on C14 dating, the foundation of a settlement there occurred as early as 4395 BCE (a calibrated radio-carbon date). At this stage, the city was already very large for the time, about 15 hectares.
The founding of Susa corresponded with the abandonment of nearby villages. Potts suggests that the city may have been founded to try to reestablish the previously destroyed settlement at Chogha Mish. Previously, Chogha Mish was also a very large settlement, and it featured a similar massive platform that was later built at Susa.
Another important settlement in the area is Chogha Bonut, that was discovered in 1976.
Susa I period.
Shortly after Susa was first settled over 6000 years ago, its inhabitants erected a temple on a monumental platform that rose over the flat surrounding landscape. The exceptional nature of the site is still recognizable today in the artistry of the ceramic vessels that were placed as offerings in a thousand or more graves near the base of the temple platform.
Susa's earliest settlement is known as "Susa I" period (c. 4200-3900 BCE). Two settlements named by archeologists "Acropolis" (7 ha) and "Apadana" (6.3 ha), would later merge to form Susa proper (18 ha). The "Apadana" was enclosed by 6m thick walls of rammed earth (this particular place is named Apadana because it also contains a late Achaemenid structure of this type).
Nearly two thousand pots of "Susa I" style were recovered from the cemetery most of them now in the Louvre. The vessels found are eloquent testimony to the artistic and technical achievements of their makers, and they hold clues about the organization of the society that commissioned them.
Susa I style was very much a product of the past and of influences from contemporary ceramic industries in the mountains of western Iran. The recurrence in close association of vessels of three types—a drinking goblet or beaker, a serving dish, and a small jar—implies the consumption of three types of food, apparently thought to be as necessary for life in the afterworld as it is in this one. Ceramics of these shapes, which were painted, constitute a large proportion of the vessels from the cemetery. Others are coarse cooking-type jars and bowls with simple bands painted on them and were probably the grave goods of the sites of humbler citizens as well as adolescents and, perhaps, children. The pottery is carefully made by hand. Although a slow wheel may have been employed, the asymmetry of the vessels and the irregularity of the drawing of encircling lines and bands indicate that most of the work was done freehand.
Copper metallurgy is also attested during this period, which was contemporary with metalwork at some highland Iranian sites such as Tepe Sialk.
Susa II and Uruk influence.
Susa came within the Uruk cultural sphere during the Uruk period. An imitation of the entire state apparatus of Uruk, proto-writing, cylinder seals with Sumerian motifs, and monumental architecture, is found at Susa. According to some scholars, Susa may have been a colony of Uruk.
There's some dispute about the comparative periodization of Susa and Uruk at this time, as well as about the extent of Uruk influence in Susa. Recent research indicates that Early Uruk period corresponds to Susa II period.
D. T. Potts, argue that the influence from the highland Iranian Khuzestan area in Susa was more significant at the early period, and also continued later on. Thus, Susa combined the influence of two cultures, from the highland area and from the alluvial plains. Also, Potts stresses the fact that the writing and numerical systems of Uruk were not simply borrowed in Susa wholesale. Rather, only partial and selective borrowing took place, that was adapted to Susa's needs. Despite the fact that Uruk was far larger than Susa at the time, Susa was not its colony, but still maintained some independence for a long time, according to Potts.
Some scholars believe that Susa was part of the greater Uruk culture. Holly Pittman, an art historian at the University of Pennsylvania in Philadelphia says, “they are participating entirely in an Uruk way of life. They are not culturally distinct; the material culture of Susa is a regional variation of that on the Mesopotamian plain”. Gilbert Stein, director of the University of Chicago’s Oriental Institute, says that "An expansion once thought to have lasted less than 200 years now apparently went on for 700 years. It is hard to think of any colonial system lasting that long. The spread of Uruk material is not evidence of Uruk domination; it could be local choice”. 
Susa III period.
Susa III (3100–2700 BCE) is also known as the 'Proto-Elamite' period. At this time, Banesh period pottery is predominant. This is also when the Proto-Elamite tablets first appear in the record. Subsequently, Susa became the centre of Elam civilization.
Ambiguous reference to Elam (Cuneiform; NIM) appear also in this period in Sumerian records. Susa enters history during the Early Dynastic period of Sumer. A battle between Kish and Susa is recorded in 2700 BCE.
Elamites.
In the Sumerian period, Susa was the capital of a state called Susiana (Šušan), which occupied approximately the same territory of modern Khūzestān Province centered on the Karun River. Control of Susiana shifted between Elam, Sumer, and Akkad. Susiana is sometimes mistaken as synonymous with Elam but, according to F. Vallat, it was a distinct cultural and political entity.
Susiana was incorporated by Sargon the Great into his Akkadian Empire in approximately 2330 BCE.
Kutik-Inshushinak.
Susa was the capital of an Akkadian province until ca. 2100 BCE, when its governor, Kutik-Inshushinak, rebelled and made it an independent state and a literary center. Also, he was the last from the Awan dynasty according to the Susa kinglist. He unified the neighbouring territories and became the king of Elam. He encouraged the use of the Linear Elamite script, that remains undeciphered.
The city was subsequently conquered by the neo-Sumerian Ur-III dynasty and held until Ur finally collapsed at the hands of the Elamites under Kindattu in ca. 2004 BCE. At this time, Susa became an Elamite capital under the Epartid dynasty.
Middle Elamite period.
Around 1500 BCE, the Middle Elamite period began with the rise of the Anshanite dynasties. Their rule was characterized by an "Elamisation" of Susa, and the kings took the title "king of Anshan and Susa". While, previously, the Akkadian language was frequently used in inscriptions, the succeeding kings, such as the Igihalkid dynasty of c. 1400 BCE, tried to use Elamite. Thus, Elamite language and culture grew in importance in Susiana.
This was also the period when the Elamite pantheon was being imposed in Susiana. This policy reached its height with the construction of the political and religious complex at Chogha Zanbil, south-east of Susa.
In ca. 1175 BCE, the Elamites under Shutruk-Nahhunte plundered the original stele bearing the "Code of Hammurabi," the world's first known written laws, and took it to Susa. Archeologists found it in 1901. Nebuchadnezzar I of the Babylonian empire plundered Susa around fifty years later.
Neo-Assyrians.
In 647 BCE, Neo-Assyrian king Assurbanipal leveled the city during a war in which the people of Susa participated on the other side. A tablet unearthed in 1854 by Austen Henry Layard in Nineveh reveals Ashurbanipal as an "avenger", seeking retribution for the humiliations that the Elamites had inflicted on the Mesopotamians over the centuries:
"Susa, the great holy city, abode of their gods, seat of their mysteries, I conquered. I entered its palaces, I opened their treasuries where silver and gold, goods and wealth were amassed. . . .I destroyed the ziggurat of Susa. I smashed its shining copper horns. I reduced the temples of Elam to naught; their gods and goddesses I scattered to the winds. The tombs of their ancient and recent kings I devastated, I exposed to the sun, and I carried away their bones toward the land of Ashur. I devastated the provinces of Elam and, on their lands, I sowed salt."
Assyrian rule of Susa began in 647 BCE and lasted till Median capture of Susa in 617 BCE.
After Persian conquest.
Achaemenid period.
Susa underwent a major political and ethnocultural transition when it became part of the Persian Achaemenid empire between 540 and 539 BCE when it was captured by Cyrus the Great during his conquest of Elam (Susiana), of which Susa was the capital. The Nabonidus Chronicle records that, prior to the battle(s), Nabonidus had ordered cult statues from outlying Babylonian cities to be brought into the capital, suggesting that the conflict over Susa had begun possibly in the winter of 540 BCE.
It is probable that Cyrus negotiated with the Babylonian generals to obtain a compromise on their part and therefore avoid an armed confrontation. Nabonidus was staying in the city at the time and soon fled to the capital, Babylon, which he had not visited in years.
Cyrus' conquest of Susa and the rest of Babylonia commenced a fundamental shift, bringing Susa under Persian control for the first time.
Under Cyrus' son Cambyses II, Susa became a center of political power as one of 4 capitals of the Achaemenid Persian empire, while reducing the significance of Pasargadae as the capital of Persis. Following Cambyses' brief rule, Darius the Great began a major building program in Susa and Persepolis. During this time he describes his new capital in the DSf inscription:
"This palace which I built at Susa, from afar its ornamentation was brought. Downward the earth was dug, until I reached rock in the earth. When the excavation had been made, then rubble was packed down, some 40 cubits in depth, another part 20 cubits in depth. On that rubble the palace was constructed." Susa continued as a winter capital and residence for Achaemenid kings succeeding Darius the Great, Xerxes I, and their successors.
The city forms the setting of "The Persians" (472 BCE), an Athenian tragedy by the ancient Greek playwright Aeschylus that is the oldest surviving play in the history of theatre.
Events mentioned in the Old Testament book of Esther are said to have occurred in Susa during the Sassanid or Achaemenid period.
Macedonian, Parthian and Sassanid periods.
Susa lost much of its importance when Alexander of Macedon conquered it in 331 BCE and incorporated the first Persian Empire. The Susa weddings was arranged by Alexander in 324 BC in Susa, where mass weddings took place between the Persians and the Macedonians.
Approximately one century after Alexander, Susa fell to the Seleucid Empire. After Seleucia, it was the biggest city in under Seleucid control at the time. Susa used Charax Spasinou as its port. It retained a considerable amount of independence and retained its Greek city state organization well into the ensuing Parthian period and seems to have gained independence under a dynasty whose kings bore the name of Kamnaskires in the 1st century CE.
When the Parthian Empire gained its independence from the Seleucid Empire, and took control of much of its eastern provinces, Susa was made one of the two capitals (along with Ctesiphon) of the new state.
Susa became a frequent place of refuge for Parthian and later, the Persian Sassanid kings, as the Romans sacked Ctesiphon five different times between 116 and 297 AD (Susa was briefly captured only by Roman emperor Trajan in 116 AD and never again would the Roman Empire advance so far to the east). Typically, the Parthian rulers wintered in Susa, and spent the summer in Ctesiphon.
Post-Islamic period and degradation.
Susa was destroyed at least three times in its history. The first was in 647 BCE, by Ashurbanipal. The second destruction took place in 638 CE, when the Muslim armies first conquered Persia. In 1218, the city was razed by invading Mongols. The city further degraded in the 15th century when the majority of its population moved to Dezful and it remains as a small settlement today.
Susa had a significant Christian population during the first millennium, and was a diocese of the Church of the East between the 5th and 13th centuries, in the metropolitan province of Beth Huzaye (Elam).

</doc>
<doc id="60417" url="https://en.wikipedia.org/wiki?curid=60417" title="Battle of Maldon">
Battle of Maldon

The Battle of Maldon took place three weeks before Whitsun on 10 (possibly 11) August 991 AD near Maldon beside the River Blackwater in Essex, England, during the reign of Aethelred the Unready. Earl Byrhtnoth and his thegns led the English against a Viking invasion. The battle ended in an Anglo-Saxon defeat. After the battle Archbishop Sigeric of Canterbury and the aldermen of the south-western provinces advised King Aethelred to buy off the Vikings rather than continue the armed struggle. The result was a payment of 10,000 Roman pounds (3,300 kg) of silver, the first example of Danegeld in England.
An account of the battle, embellished with many speeches attributed to the warriors and with other details, is related in an Old English poem which is usually named The Battle of Maldon. A modern embroidery created for the millennium celebration in 1991 and, in part, depicting the battle, can be seen at the Maeldune Centre in Maldon.
One manuscript of the "Anglo-Saxon Chronicle" said a Norwegian, Olaf Tryggvason, led the Viking forces, estimated to have been between 2,000 and 4,000 fighting men. A source from the 12th century, "Liber Eliensis", written by the monks at Ely, suggests that Byrhtnoth had only a few men to command: "he was neither shaken by the small number of his men, nor fearful of the multitude of the enemy". Not all sources indicate such a disparity in numbers.
The poem "The Battle of Maldon".
'The Battle of Maldon' is the name conventionally given to a surviving 325-line fragment of Old English poetry. Linguistic study has led to the conjecture that initially the complete poem was transmitted orally, then in a lost manuscript in the East Saxon dialect and now survives as a fragment in the West Saxon form, possibly that of a scribe active at the Monastery of Worcester late in the 11th century. It is fortuitous that this was attached at an early date to a very notable manuscript, Asser's "Life of King Alfred", which undoubtedly assisted in its survival. The manuscript, by now detached, was burned in the Cotton library fire at Ashburnham House in 1731. The keeper of the collection, John Elphinstone (or his assistant, David Casley), had transcribed the 325 lines of the poem in 1724, but the front and back pages were already missing from the manuscript (possibly around 50 lines each): an earlier catalogue described it as "fragmentum capite et calce mutilatum" ("mutilated at head and heel"). As a result, vital clues about the purpose of the poem and perhaps its date have been lost.
At the time of battle, English royal policy of responding to Viking incursions was split. Some favoured paying off the Viking invaders with land and wealth, while others favoured fighting to the last man. The poem suggests that Byrhtnoth held this latter attitude, hence his moving speeches of patriotism.
The Vikings sailed up the Blackwater (then called the Panta), and Byrhtnoth called out his levy. The poem begins with him ordering his men to stand and to hold weapons. His men, except for his household guard, were peasants and householders from the area. He ordered them to "send steed away and stride forwards": they arrived on horses but fought on foot. The Vikings sailed up to a small island in the river. At low tide, the river leaves a land bridge from this island to the shore; the description seems to have matched the Northey Island causeway at that time. This would place the site of the battle about two miles southeast of Maldon. Olaf addressed the Saxons, promising to sail away if he was paid with gold and armour from the lord. Byrhtnoth replied, "We will pay you with spear tips and sword blades."
Olaf's forces could not make headway against the troops guarding the small land bridge, and he asked Byrhtnoth to allow his warriors onto the shore. Byrhtnoth, "for his ofermōde" (line 89b), let all the Vikings cross to the mainland. Battle was joined, but an Englishman called Godrīc fled riding Byrhtnoth's horse. Godrīc's brothers Godwine and Godwīg followed him. Then many English fled, recognizing the horse and thinking that its rider was Byrhtnoth fleeing. To add insult to injury, it is stated that Godric had often been given horses by Byrhtnoth, a detail that, especially during the time period, would have had Godric marked as a coward and a traitor, something that could have easily been described as worse than death. The Vikings overcame the Saxons after losing many men, killing Byrhtnoth. After the battle Byrhtnoth's body was found with its head missing, but his gold-hilted sword was still with his body.
There is some discussion about the meaning of ""ofermōd"." Although literally meaning "over-heart" or "having too much heart", it could mean either "pride" or "excess of courage" (cf. Swedish "övermod" or German "Übermut", which mean both "hubris" and "recklessness"). One argument is that the poem was written to celebrate Byrhtnoth's actions and goad others into heroic action, and Byrhtnoth's action stands proudly in a long tradition of heroic literature. Another viewpoint, most notably held by J.R.R. Tolkien, is that the poem is an elegy on a terrible loss and that the monastic author pinpoints the cause of the defeat in the commander's sin of pride, a viewpoint bolstered by the fact that "ofermōd" is, in every other attested instance, used to describe Satan's pride. There is a memorial window, representing Byrhtnoth's dying prayer, in St Mary's church at Maldon.
It is believed by many scholars that the poem, while based upon actual events and people, was created to be less of a historical account and more of a means of enshrining and lifting up the memories of the men who fought and lost their lives on the battlefield protecting their homeland, especially in the case of the English commander of the battle, Byrhtnoth. He (Byrhtnoth) seems to embody many of the virtues that are uplifted in the Anglo-Saxon world, and is compared often by many scholars to the character Beowulf.
Norse invaders and Norse raiders differed in purpose. The forces engaged by the Anglo-Saxon were raiding, or (in Old Norse) ""í víking"", to gather loot, rather than to occupy land for settlement. Therefore, if Byrhtnoth's forces had kept the Vikings off by guarding the causeway or by paying them off, Olaf would likely have sailed farther up the river or along the coast, and raided elsewhere. As a man with troops and weapons, it might be that Byrhtnoth had to allow the Vikings ashore to protect others. The poem may, therefore, represent the work of what has been termed the "monastic party" in Ethelred's court, which advocated a military response, rather than tribute, to all Norse attacks.
Other sources.
The death of Byrhtnoth, an ealdorman of Essex, was recorded in four versions of the "Anglo-Saxon Chronicle". Its Cotton Tiberius manuscript says for the year 991:-
"The Life of Oswald", written in Ramsey, England around the same time as the battle, portrays Byrhtnoth as a nearly supernatural, prophetic figure.
In 1170, the "Book of Ely" retold and embroidered the story and made the battle two fights, with the second being a fortnight long against overwhelming odds. These texts show, to some degree, the growth of a local hero cultus.
Manuscript sources.
In the Cotton library, the "Battle of Maldon" text had been in Otho A xii. The Elphinstone transcription is in the British Library.

</doc>
<doc id="60422" url="https://en.wikipedia.org/wiki?curid=60422" title="Battle of Badon">
Battle of Badon

The Battle of Badon (Latin: "Bellum in monte Badonis" or "Mons Badonicus", , all literally meaning "Battle of Mount Badon" or "Battle of Badon Hill") was a battle thought to have occurred between Britons and an Anglo-Saxons in the late 5th or early 6th century. It was credited as a major victory for the Britons, stopping the encroachment of the Anglo-Saxon kingdoms for a period. It is chiefly known today for the supposed involvement of King Arthur, a tradition that first clearly appeared in the 9th-century "Historia Brittonum". Because of the limited number of sources, there is no certainty about the date, location, or details of the fighting.
Historical accounts.
Siege of Mount Badon.
The earliest mention of the Battle of Badon is Gildas' "De Excidio Britanniae" ("The Ruin of Britain"), written in the early-mid 6th century AD. In it, the Saxons are said to have "dipped red and savage tongue in the western ocean" before Ambrosius Aurelianus organized a British resistance with the survivors of the initial Saxon onslaught. Gildas describes the period that followed Ambrosius' initial success:
... From that time, the citizens were sometimes victorious, sometimes the enemy, in order that the Lord, according to His wont, might try in this nation the Israel of to-day, whether it loves Him or not. This continued up to the year of the siege of Badon Hill ("obsessionis Badonici montis"), and of almost the last great slaughter inflicted upon the rascally crew. And this commences, a fact I know, as the forty-fourth year, with one month now elapsed; it is also the year of my birth.
"The Ruin of Britain" is unclear as to whether Ambrosius is still leading the Britons at this point, but describes the battle as such an "unexpected recovery of the " that it caused kings, nobles, priests, and commoners to "live orderly according to their several vocations" before the long peace degenerated into civil wars and the iniquity of Maelgwn Gwynedd. Passages of "The Ruin of Britain" that address Maelgwn directly are sometimes employed to date the work from accounts of the king's death by plague in the 540s, but such arguments ignore the obvious apostrophe employed in the passages and the possible years of composition involved in the final collected sermon.
The battle is next mentioned in an 8th-century text of the Venerable Bede's "Ecclesiastical History of the English People". It describes the "siege of Mount Badon, when they made no small slaughter of those invaders," as occurring 44 years after the arrival of the Saxons. Since Bede places that arrival during or just after the joint reign of Marcian and Valentinian in AD 449456, he must have considered Badon to have taken place between 493 and 500. Bede then puts off discussion of the battle "But more of this hereafter" only to seemingly never return to it. Bede does later include an extended account of Saint Germanus's victory over the Saxons and Picts in a mountain valley, which he credits with curbing the threat of invasion for a generation. However, as the victory is described as having been accomplished bloodlessly, it was presumably a different occasion from Badon. (Accepted at face value, St. Germanus's involvement would also place the battle around 430, although Bede's chronology shows no knowledge of this.)
Battle of Badon.
The earliest surviving text mentioning Arthur at the battle is the early 9th century "Historia Brittonum", in which the "soldier" (Latin "miles") Arthur is identified as the leader of the victorious British force at Badon:
"The twelfth battle was on Mount Badon in which there fell in one day 960 men from one charge by Arthur; and no one struck them down except Arthur himself".
The Battle of Badon is next mentioned in the "Annales Cambriae" ("Annals of Wales"), assumed to have been written during the mid- to late-10th century. The entry states: 
"The Battle of Badon, in which Arthur carried the Cross of our Lord Jesus Christ for three days and three nights upon his shoulders shield] and the Britons were the victors".
That Arthur had gone unmentioned in the source closest to his own time, Gildas, was noticed at least as early as the 12th-century "vita", which claims that Gildas had praised Arthur extensively but then excised him completely after Arthur killed the saint's brother, Huail. Modern writers have suggested the details of the battle were so well known that Gildas could have expected his audience to be familiar with them.
Geoffrey of Monmouth's c. 1136 "History of the Kings of Britain" was massively popular and survives in many copies from soon after its composition. Going into (and fabricating) much greater detail, Geoffrey closely identifies Badon with Bath, including having Merlin foretell that Badon's baths would lose their hot water and turn poisonous. He employs aspects of other accounts, mixing them: the battle begins as a Saxon siege and then becomes a normal engagement once Arthur's men arrive; Arthur bears the image of the Virgin both on his shield and shoulder. Arthur charges, but kills a mere 470, ten more than the number of Britons ambushed by Hengist near Salisbury. Elements of the Welsh legends are also added: in addition to the shield (named "Pridwen"), Arthur gains his sword "Caliburnus" and his spear "Ron". Geoffrey also makes the defense of the city from the Saxon sneak attack a holy cause, having St. Dubricius offer absolution of all sins for those who fall in battle.
Scholarship.
Separate sources dating the concession of Thanet to Hengist to AD 447 would place "The Ruin of Britain" and Bede's account of the battle around the year 491. The "Anglo-Saxon Chronicle" is completely silent about this battle but does seem to document a gap of almost 70 years between two major Anglo-Saxon leaders ("bretwaldas") in the fifth and sixth centuries.
If Rhygyfarch's celebrated "Life of David" is credited, its account of St. David's ten years of education under St. Pol suggests David could not have been born later than 514. Since the same account has Gildas preaching to Ste. Non while she was pregnant with David, it is improbable that Gildas's birth and therefore the battle could have occurred later than 498.
McCarthy and Ó Cróinín propose Gildas's 44 years and one month is not a reference to the simple chronology but a position within the 84-year Easter cycle used for computus at the time by the Celtic Church. The tables in question in January 438, which would place their revised date of the battle in February 482.
Hirst, Ashe and Wood argue for the site of Liddington Castle on the hill above Badbury (Old English: "Baddan byrig") in Wiltshire. This site commands The Ridgeway track connecting the Thames valley with the Avon and Severn beyond.
Aftermath.
The early sources' account that the Saxons were thrown back around this time seems to be borne out by archaeological evidence. Studies of cemeteries (at this point, the Anglo-Saxons remained pagan while the Britons were Christianized) suggest the border shifted some time around 500. Afterwards, the pagans held the present areas of Kent, Sussex, Norfolk and Suffolk, and the area around the Humber. The Britons seem to have controlled salients to the north and west of London and south of Verulamium in addition to everything west of a line running from Christchurch at the mouth of the Wiltshire Avon north to the Trent, then along the Trent to the Humber, then north along the Derwent to the North Sea. The salients could then be supplied along Watling Street, dividing the invaders into pockets south of the Weald in east Kent and around the Wash.
Second Badon.
The A Text of the "Annales Cambriae" includes the entry: "The first celebration of Easter among the Saxons. The second battle of Badon. Morgan dies." The date for this action is given by Phillimore as 665, but the Saxons' first Easter is placed by the B Text in its entry 634 years after the birth of Christ and neither Second Badon nor Morcant are mentioned.
Local lore.
Apart from the professional scholarship, various communities around Wales and England carry on local traditions that their area was the site of the battle: these include Bathampton Down; Badbury Hillfort at the Kingston Lacy House in Dorset; and Bowden Hill in Linlithgow.

</doc>
<doc id="60424" url="https://en.wikipedia.org/wiki?curid=60424" title="Hallucigenia">
Hallucigenia

Hallucigenia is a genus of Cambrian animals known from articulated fossils in Burgess Shale-type deposits in Canada and China, and from isolated spines around the world. Its quirky name reflects its unusual appearance and eccentric history of study; when it was erected as a genus, the animal was reconstructed upside down and back to front. "Hallucigenia" is now recognized as a "lobopodian worm". It is considered by some to represent an early ancestor of the living velvet worms, although other researchers favour a relationship closer to arthropods.
Description.
"Hallucigenia" is a 0.5—3.5 cm long tubular organism with seven or eight pairs of slender legs, each terminating with a pair of claws. Above each leg is a rigid conical spine. The 'head' and 'tail' end of the organism are difficult to identify; one end extends some distance beyond the legs and often droops down as if to reach the floor. Although some specimens display traces of a gut, the internal anatomy has not been formally described.
Recent research suggests that the extended element is an elongated head with two simple eyes, a mouth with radial teeth, and pharyngeal teeth within the front of the gut.
"Hallucigenia"'s spines are made up of one to four nested elements. Their surface is covered in an ornament of minute triangular 'scales'.
History of study.
"Hallucigenia" was originally described by Walcott as a species of the polychaete worm "Canadia". In his 1977 redescription of the organism, Simon Conway Morris recognized the animal as something quite distinct, establishing the new genus. No specimen was available that showed both rows of legs, and as such Conway Morris reconstructed the animal walking on its spines, with its single row of legs interpreted as tentacles on the animal's back. A dark stain at one end of the animal was interpreted as a featureless head. Only the forward tentacles could easily reach to the 'head', meaning that a mouth on the head would have to be fed by passing food along the line of tentacles. Conway Morris suggested that a hollow tube within each of the tentacles might be a "mouth". This raised questions, such as how it would walk on the stiff legs, but it was accepted as the best available interpretation.
An alternative interpretation considered "Hallucigenia" to be an appendage of a larger, unknown animal. There had been precedent for this, as the species "Anomalocaris" had been originally identified as three separate creatures before being identified as a single huge (for its time) creature. Given the uncertainty of its taxonomy, "Hallucigenia" was tentatively placed within the phylum Lobopodia, a catch-all clade containing numerous odd "worms with legs".
In 1991, Lars Ramskold and Hou Xianguang, working with additional specimens of a "hallucigenid", "Microdictyon", from the lower Cambrian Maotianshan shales of China, reinterpreted "Hallucigenia" as an Onychophoran (velvet worm). They inverted it, interpreting the tentacles, which they believe to be paired, as walking structures and the spines as protective. Further preparation of fossil specimens showed that the 'second legs' were buried at an angle to the plane along which the rock had split, and could be revealed by removing the overlying sediment. Ramskold and Hou also believe that the blob-like 'head' is actually a stain that appears in many specimens, not a preserved portion of the anatomy. This stain may be an artefact of decomposition.
Affinity.
"Hallucigenia" is unquestionably a panarthropod, and has long been interpreted as a stem-group onychophoran – a position that has now found support from phylogenetic analysis. A key character demonstrating this affinity is the cone-in-cone construction of "Hallucigenia" claws, a feature shared only with modern onychophorans. "Hallucigenia" also exhibits certain characters inherited from the ancestral ecdysozoan, but lost in the modern onychophorans – in particular its distinctive foregut armature.
Diversity.
In 2002, Desmond Collins informally suggested that new "Hallucigenia" fossils from the Burgess Shale showed male and female forms, one with "a rigid trunk, robust neck and a globular head" and the other thinner, and with a small head.
Further species are represented from the Chengjiang.
Distribution.
"Hallucigenia" was first described from the Burgess Shale in southwestern British Columbia, Canada. "Hallucigenia" also forms a minor component of Chinese lagerstätten. Isolated hallucigeniid spines, however, are widely distributed in a range of Cambrian deposits, preserved both as carbonaceous and mineralized fossils.

</doc>
<doc id="60426" url="https://en.wikipedia.org/wiki?curid=60426" title="Symbiogenesis">
Symbiogenesis

Symbiogenesis, or endosymbiotic theory, is an evolutionary theory that explains the origin of eukaryotic cells from prokaryotes. It states that several key organelles of eukaryotes originated as a symbiosis between separate single-celled organisms. According to this theory, mitochondria, plastids (for example chloroplasts), and possibly other organelles representing formerly free-living bacteria (prokaryotes) were taken inside another cell as an endosymbiont around 1.5 billion years ago. Molecular and biochemical evidence suggest that mitochondria developed from proteobacteria (in particular, Rickettsiales, the SAR11 clade, or close relatives) and chloroplasts from cyanobacteria (in particular, nitrogen-fixing filamentous cyanobacteria).
History.
The theory of symbiogenesis (Greek: σύν "syn" "together", βίωσις "biosis" "living", and γένεσις "genesis" "origin or birth") was first articulated by the Russian botanist Konstantin Mereschowsky in 1910, although he described the fundamental elements of the theory in a paper five years earlier. Mereschkowski was familiar with work by botanist Andreas Schimper, who had observed in 1883 that the division of chloroplasts in green plants closely resembled that of free-living cyanobacteria, and who had himself tentatively proposed (in a footnote) that green plants had arisen from a symbiotic union of two organisms. In 1918 the French scientist Paul Portier published "Les Symbiotes" in which he claimed that the mitochondria originated from a symbiosis process. Ivan Wallin extended the idea of an endosymbiotic origin to mitochondria in the 1920s. A Russian botanist Boris Kozo-Polyansky was the first to explain the theory in terms of Darwinian evolution. In his 1924 book "Symbiogenesis: A New Principle of Evolution" he wrote, "The theory of symbiogenesis is a theory of selection relying on the phenomenon of symbiosis." These theories were initially dismissed or ignored. More detailed electron microscopic comparisons between cyanobacteria and chloroplasts (for example studies by Hans Ris published in 1961), combined with the discovery that plastids and mitochondria contain their own DNA (which by that stage was recognized to be the hereditary material of organisms) led to a resurrection of the idea in the 1960s.
The theory was advanced and substantiated with microbiological evidence by Lynn Margulis in a 1967 paper, "On the origin of mitosing cells." In her 1981 work "Symbiosis in Cell Evolution" she argued that eukaryotic cells originated as communities of interacting entities, including endosymbiotic spirochaetes that developed into eukaryotic flagella and cilia. This last idea has not received much acceptance, because flagella lack DNA and do not show ultrastructural similarities to bacteria or archaea (see also: Evolution of flagella and Prokaryotic cytoskeleton). According to Margulis and Dorion Sagan, "Life did not take over the globe by combat, but by networking" (i.e., by cooperation). The possibility that peroxisomes may have an endosymbiotic origin has also been considered, although they lack DNA. Christian de Duve proposed that they may have been the first endosymbionts, allowing cells to withstand growing amounts of free molecular oxygen in the Earth's atmosphere. However, it now appears that they may be formed "de novo", contradicting the idea that they have a symbiotic origin.
It is thought that over millennia these endosymbionts transferred some of their own DNA to the host cell's nucleus (called "endosymbiotic gene transfer") during the evolutionary transition from a symbiotic community to an instituted eukaryotic cell. The endosymbiotic theory is considered to be a type of saltational evolution.
From endosymbionts to organelles.
According to Keeling and Archibald, the usual way to distinguish organelles from endosymbionts is by their reduced genome sizes. As an endosymbiont evolves into an organelle, most of their genes are transferred to the host cell genome. The host cell and organelle need to develop a transport mechanism that enables transfer back of the protein products needed by the organelle but now manufactured by the cell. Cyanobacteria and α-proteobacteria are the most closely related free-living organisms to plastids and mitochondria respectively. Both cyanobacteria and α-proteobacteria maintain a large (>6Mb) genome encoding thousands of proteins. Plastids and mitochondria exhibit a dramatic reduction in genome size when compared to their bacterial relatives. Chloroplast genomes in photosynthetic organisms are normally 120-200kb encoding 20-200 proteins and mitochondrial genomes in humans are approximately 16kb and encode 37 genes, 13 of which are proteins. Using the example of the freshwater amoeboid, however, "Paulinella chromatophora", which contains chromatophores found to be evolved from cyanobacteria, these authors argue that this is not the only possible criterion; another is that the host cell has assumed control of the regulation of the former endosymbiont's division, thereby synchronizing it with the cell's own division. Nowack and her colleagues performed gene sequencing on the chromatophore (1.02 Mb) and found that only 867 proteins were encoded by these photosynthetic cells. Comparisons with their closest free living cyanobacteria of the genus "Synechococcus" (having a genome size 3 Mb, with 3300 genes) revealed that chromatophores underwent a drastic genome shrinkage. Chromatophores contained genes that were accountable for photosynthesis but were deficient in genes that could carry out other biosynthetic functions; this observation suggests that these endosymbiotic cells are highly dependent on their hosts for their survival and growth mechanisms. Thus, these chromatophores were found to be non-functional for organelle-specific purposes when compared to mitochondria and plastids. This distinction could have promoted the early evolution of photosynthetic organelles.
The loss of genetic autonomy, that is, the loss of many genes from endosymbionts, occurred very early in evolutionary time. Taking into account the entire original endosymbiont genome, there are three main possible fates for genes over evolutionary time. The first fate involves the loss of functionally redundant genes, in which genes that are already represented in the nucleus are eventually lost.The second fate involves the transfer of genes to the nucleus. The loss of autonomy and integration of the endosymbiont with its host can be primarily attributed to nuclear gene transfer. As organelle genomes have been greatly reduced over evolutionary time, nuclear genomes have expanded and become more complex. As a result, many plastid and mitochondrial processes are driven by nuclear encoded gene products. In addition, many nuclear genes originating from endosymbionts have acquired novel functions unrelated to their organelles.
The mechanisms of gene transfer are not fully known, however, multiple hypotheses exist to explain this phenomenon. The cDNA hypothesis involves the use of mRNAs to transport genes from organelles to the nucleus where they are converted to cDNA and incorporated into the genome. The cDNA hypothesis is based on studies of the genomes of flowering plants. Protein coding RNAs in mitochondria are spliced and edited using organelle-specific splice and editing sites. Nuclear copies of some mitochondrial genes, however, do not contain organelle-specific splice sites, suggesting a processed mRNA intermediate. The cDNA hypothesis has since been revised as edited mitochondrial cDNAs are unlikely to recombine with the nuclear genome and are more likely to recombine with their native mitochondrial genome. If the edited mitochondrial sequence recombines with the mitochondrial genome, mitochondrial splice sites would no longer exist in the mitochondrial genome. Any subsequent nuclear gene transfer would therefore also lack mitochondrial splice sites.
The bulk flow hypothesis is the alternative to the cDNA hypothesis, stating that escaped DNA, rather than mRNA, is the mechanism of gene transfer. According to this hypothesis, disturbances to organelles, including autophagy (normal cell destruction), gametogenesis (the formation of gametes), and cell stress, release DNA which is imported into the nucleus and incorporated into the nuclear DNA using non-homologous end joining (repair of double stranded breaks). For example, in the initial stages of endosymbiosis, due to a lack of major gene transfer, the host cell had little to no control over the endosymbiont. The endosymbiont underwent cell division independently of the host cell, resulting in many "copies" of the endosymbiont within the host cell. Some of the endosymbionts lysed (bursted) and high levels of DNA were incorporated into the nucleus. A similar mechanism is thought to occur in tobacco plants, who show a high rate of gene transfer and whose cells contain multiple chloroplasts. In addition, the bulk flow hypothesis is also supported by the presence of non-random clusters of organelle genes, suggesting the simultaneous movement of multiple genes.
Organellar genomes.
Plastomes and mitogenomes.
The third and final possible fate of endosymbiont genes is that they remain in the organelles. Plastids and mitochondria, although they have lost much of their genomes, retain genes encoding rRNAs, tRNAs, proteins involved in redox reactions and proteins required for transcription, translation and replication. There are many hypotheses to explain why the organelles retain a small portion of their genome, however no one hypothesis will apply to all organisms and the topic is still quite controversial. The hydrophobicity hypothesis states that highly hydrophobic (water hating) proteins (such as the membrane bound proteins involved in redox reactions) are not easily transported through the cytosol and therefore these proteins must be encoded in their respective organelles. The code disparity hypothesis states that the limit on transfer is due to differing genetic codes and RNA editing between the organelle and the nucleus. The redox control hypothesis states that genes encoding redox reaction proteins are retained in order to effectively couple the need for repair and the synthesis of these proteins. For example, if one of the photosystems is lost from the plastid, the intermediate electron carriers may lose or gain too many electrons, signalling the need for repair of a photosystem. The time delay involved in signalling the nucleus and transporting a cytosolic protein to the organelle results in the production of damaging reactive oxygen species. The final hypothesis states that the assembly of membrane proteins, particularly those involved in redox reactions, require coordinated synthesis and assembly of subunits, however translation and protein transport coordination is more difficult to control in the cytoplasm.
Non-photosynthetic plastid genomes.
The majority of the genes in the mitochondria and plastid are related to the expression (transcription, translation and replication) of genes encoding proteins involved in either photosynthesis (in plastids) or cellular respiration (in mitochondria). One might predict, that the loss of photosynthesis or cellular respiration would allow for the complete loss of the plastid genome or the mitochondrial genome respectively. While there are numerous examples of mitochondrial descendants (mitosomes and hydrogenosomes) that have lost their entire organellar genome, non-photosynthetic plastids tend to retain a small genome. There are two main hypotheses to explain this occurrence:
The essential tRNA hypothesis: There have been no documented functional plastid to nucleus gene transfers of genes encoding RNA products (tRNAs and rRNAs). As a result, plastids must make their own functional RNAs or import nuclear counterparts. The genes encoding tRNA-Glu and tRNA-fmet, however, appear to be indispensable. The plastid is responsible for haem biosynthesis, which requires plastid encoded tRNA-Glu (from the gene trnE) as a precursor molecule. Like other genes encoding RNAs, trnE cannot be transferred to the nucleus. In addition, it is unlikely trnE could be replaced by a cytosolic tRNA-Glu as trnE is highly conserved; single base changes in trnE have resulted in the loss of haem synthesis. The gene for tRNA-formylmethionine (tRNA-fmet) is also encoded in the plastid genome and is required for translation initiation in both plastids and mitochondria. A plastid is required to continue expressing the gene for tRNA-fmet so long as the mitochondrion is translating proteins.
The limited window hypothesis: This hypothesis offers a more general explanation for the retention of genes in non-photosynthetic plastids. According to the bulk flow hypothesis, genes are transferred to the nucleus following the disturbance of organelles. Disturbance was common in the early stages of endosymbiosis, however, once the host cell gained control of organelle division, eukaryotes could evolve to have only one plastid per cell. Having only one plastid severely limits gene transfer as the lysis of the single plastid would likely result in cell death. Consistent with this hypothesis, organisms with multiple plastids show an 80-fold increase in plastid to nucleus gene transfer compared to organisms with single plastids.
Evidence.
Evidence that mitochondria and plastids arose from bacteria is as follows:
Secondary endosymbiosis.
Primary endosymbiosis involves the engulfment of a bacterium by another free living organism. Secondary endosymbiosis occurs when the product of primary endosymbiosis is itself engulfed and retained by another free living eukaryote. Secondary endosymbiosis has occurred several times and has given rise to extremely diverse groups of algae and other eukaryotes. Some organisms can take opportunistic advantage of a similar process, where they engulf an alga and use the products of its photosynthesis, but once the prey item dies (or is lost) the host returns to a free living state. Obligate secondary endosymbionts become dependent on their organelles and are unable to survive in their absence (for a review see McFadden 2001). RedToL, the Red Algal Tree of Life Initiative funded by the National Science Foundation highlights the role red algae or Rhodophyta played in the evolution of our planet through secondary endosymbiosis.
One possible secondary endosymbiosis in process has been observed by Okamoto & Inouye (2005). The heterotrophic protist "Hatena" behaves like a predator until it ingests a green alga, which loses its flagella and cytoskeleton, while "Hatena", now a host, switches to photosynthetic nutrition, gains the ability to move towards light and loses its feeding apparatus.
The process of secondary endosymbiosis left its evolutionary signature within the unique topography of plastid membranes. Secondary plastids are surrounded by three (in euglenophytes and some dinoflagellates) or four membranes (in haptophytes, heterokonts, cryptophytes, and chlorarachniophytes). The two additional membranes are thought to correspond to the plasma membrane of the engulfed alga and the phagosomal membrane of the host cell. The endosymbiotic acquisition of a eukaryote cell is represented in the cryptophytes; where the remnant nucleus of the red algal symbiont (the nucleomorph) is present between the two inner and two outer plastid membranes.
Despite the diversity of organisms containing plastids, the morphology, biochemistry, genomic organisation, and molecular phylogeny of plastid RNAs and proteins suggest a single origin of all extant plastids – although this theory is still debated.
Some species including "Pediculus humanus" have multiple chromosomes in the mitochondrion. This and the phylogenetics of the genes encoded within the mitochondrion suggest that mitochondria have multiple ancestors, that these were acquired by endosymbiosis on several occasions rather than just once, and that there have been extensive mergers and rearrangements of genes on the several original mitochondrial chromosomes.

</doc>
<doc id="60429" url="https://en.wikipedia.org/wiki?curid=60429" title="Archie search engine">
Archie search engine

Archie is a tool for indexing FTP archives, allowing people to find specific files. It is considered to be the first Internet search engine. The original implementation was written in 1990 by Alan Emtage, then a postgraduate student at McGill University in Montreal, and Bill Heelan, who studied at Concordia University in Montreal and worked at McGill University at the same time.
History and name.
The archie service began as a project for students and volunteer staff at the McGill University School of Computer Science in 1987, when Peter Deutsch (systems manager for the School), Emtage, and Heelan were asked to connect the School of Computer Science to the Internet. The earliest versions of Archie, written by Alan Emtage, simply contacted a list of FTP archives on a regular basis (contacting each roughly once a month, so as not to waste too many resources of the remote servers) and requested a listing. These listings were stored in local files to be searched using the Unix grep command.
Bill Heelan and Peter Deutsch wrote a script allowing people to log in and search collected information using the Telnet protocol at the host "archie.mcgill.ca" [132.206.2.3]. Later, more efficient front- and back-ends were developed, and the system spread from a local tool, to a network-wide resource, and a popular service available from multiple sites around the Internet. The collected data would be exchanged between the neighbouring Archie servers. The servers could be accessed in multiple ways: using a local client (such as "archie" or "xarchie"); telnetting to a server directly; sending queries by electronic mail; and later via a World Wide Web interface. At the zenith of its fame the Archie search engine accounted for 50% of Montreal Internet traffic.
In 1992, Emtage along with Peter Deutsch and some financial help of McGill University formed Bunyip Information Systems the world's first company expressly founded for and dedicated to providing Internet information services with a licensed commercial version of the Archie search engine used by millions of people worldwide. Bill Heelan followed them into Bunyip soon after, where he together with Bibi Ali and Sandro Mazzucato was a part of so-called Archie Group. The group significantly updated the archie database and indexed web-pages. Work on the search engine was ceased in the late 1990s.
The name derives from the word "archive" without the v. Alan Emtage has said that contrary to popular belief, there was no association with the Archie Comics and that he despised them. Despite this, other early Internet search technologies such as Jughead and Veronica were named after characters from the comics. Anarchie, one of the earliest graphical ftp clients was named for its ability to perform Archie searches.
A legacy Archie server is still maintained active for historic purposes in Poland at University of Warsaw's Interdisciplinary Centre for Mathematical and Computational Modelling.

</doc>
<doc id="60430" url="https://en.wikipedia.org/wiki?curid=60430" title="Archie Comics">
Archie Comics

Archie Comic Publications, Inc. (or shortly known as Archie) is an American comic book publisher headquartered in Pelham, New York. The company is known for its many titles featuring the fictional teenagers Archie Andrews, Betty Cooper, Veronica Lodge, Reggie Mantle, and Jughead Jones. The characters were created by publisher/editor John L. Goldwater, written by Vic Bloom, and drawn by Bob Montana. They were based in part on people met by Goldwater "in the Midwest" during his travels throughout the United States while looking for jobs and places to stay.
Archie's first appearance in "Pep Comics" #22 on December 22, 1941, was drawn by Montana and written by Vic Bloom. With the creation of Archie, publisher Goldwater hoped to appeal to fans of the Andy Hardy movies starring Mickey Rooney. "Archie Comics" is also the title of the company's longest-running publication, the first issue appearing with a cover date of Winter 1942. Starting with issue #114, the title was shortened to simply "Archie".
History.
MLJ Magazines.
1939–1946: Early years.
Maurice Coyne, Louis Silberkleit, and John L. Goldwater formed MLJ Magazines and started publishing in November 1939. The company name was derived from the initials of the partners' first names.
Coyne served as MLJ's bookkeeper and CFO. Coyne and Silberkleit had been partners in Columbia Publishing, a pulp company that published its last pulp in the late 1950s. Silberkleit had a college degree from St. John's University, was a licensed and registered pharmacist, and had a law degree from New York Law School. His efforts were focused on the business, printing, separating, distribution and financial ends of the company. John Goldwater served as editor-in-chief. Goldwater was one of the founders of the Comics Magazine Association of America, and served as its president for 25 years. The Comics Magazine Association of America is best known to comic fans for its Comics Code Authority. He was also a national commissioner of the Anti-Defamation League.
MLJ's first comic book published in November 1939 was "Blue Ribbon Comics" with the first half full color and the last half in red and white tints. In January 1940, "Pep Comics" debuted with the Shield, the first USA patriotic comic book hero, created by writer and managing editor Harry Shorten and artist Irv Novick. "Top Notch Comics" was launched in December 1941. Until March 1944, the cover feature of Pep was the Shield when Archie took over the cover. The Shield was a forerunner for Joe Simon's and Jack Kirby's Captain America, being published 14 months earlier.
Archie Comics.
1946–1990s.
The Andy Hardy movies were an inspiration for Goldwater to have a comic book about a relatable normal person. Teenaged Archibald "Chick" Andrews debuted with Betty Cooper in "Pep Comics" #22 (Dec. 1941), in a story by writer Vic Bloom and artist Bob Montana. Archie soon became MLJ Magazine's headliner, which led to the company changing its name to Archie Comic Publications. Siberkleit and Coyne discontinued Columbia Publications. In the late 1950s, Archie Publishing launched its "Archie Adventure Series" line with a new version of the Shield and two new characters.
The February 1962 issue of Harvey Kurtzman's "Help!" magazine featured his parody of the Archie characters in its "Goodman Beaver" story, "Goodman Goes Playboy", which was illustrated by frequent collaborator Will Elder. A parody of the sybaritic "Playboy" lifestyle, the article featured various characters drinking, living out of wedlock, stealing cars, becoming pregnant, attending an orgy, and selling their soul to Satan. "Help!" publisher Jim Warren received a letter on December 6, 1961, accusing "Help!" of copyright infringement and demanding removal of the offending issue from newsstands. Warren couldn't recall the magazine, but agreed to settle out of court rather than risk an expensive lawsuit. Warren paid Archie Comics $1000, and ran a note of apology in a subsequent issue of "Help!". The story was reprinted in the book collection "Executive Comic Book" in 1962, with the artwork modified by Elder to obscure the appearance of the Archie characters. Archie Comics found their appearance still too close to its copyrighted properties, and threatened another lawsuit. Kurtzman and Elder settled out of court by handing over the copyright to the story. Archie Comics held onto the copyright and refused to allow the story to be republished. A request from Denis Kitchen in 1983 to include the story in his "Goodman Beaver" reprint collection was turned down. After "The Comics Journal" co-owner Gary Groth discovered that Archie Comics had let the copyright on "Goodman Goes Playboy" expire, he had the story reprinted in "The Comics Journal" #262 (September 2004), and made it available as a PDF on the magazine's website.
In the mid-1960s, during the period fans and historians call the Silver Age of Comic Books, Archie switched its superheroes to a new imprint, "Mighty Comics Group", with the MLJ heroes done in the campy humor of the Batman TV show. This imprint ended in 1967.
In the early 1970s, Archie Enterprises Inc. went public. Just over 10 years later, Louis Silberkleit's son Michael and John Goldwater's son Richard returned Archie Comic Publications to private ownership. Michael Silberkleit served as chairman and co-publisher, while Richard Goldwater served as president and co-publisher. Coyne retired in the 1970s as CFO.
Archie launched a short-lived fantasy and horror imprint, Red Circle Comics, in the 1970s. The company revived that imprint in the 1980s for its brief line of superheroes comics. Later in the 1980s, Archie planned to publish superheroes again with the Spectrum Comics imprint, featuring a number of high-profile talents, but cancelled this attempt before publishing a single issue.
Having licensed Archie's MLJ Superheroes in 1991, DC Comics launched its imprint Impact Comics with these heroes.
2000s.
On April 4, 2003, Dad's Garage Theatre Company in Atlanta was scheduled to debut a new play by Roberto Aguirre-Sacasa, "Archie's Weird Fantasy", which depicted Riverdale's most famous resident coming out of the closet and moving to New York. The day before the play was scheduled to open, Archie Comics issued a cease and desist order, threatening litigation if the play proceeded as written. Dad's Garage artistic director Sean Daniels said, "The play was to depict Archie and his pals from Riverdale growing up, coming out and facing censorship. Archie Comics thought if Archie was portrayed as being gay, that would dilute and tarnish his image." It opened a few days later as "Weird Comic Book Fantasy" with the character names changed.
Bill Yoshida learned comic book lettering from Ben Oda and was hired in 1965 by Archie Comics, where he averaged 75 pages a week for 40 years for an approximate total of 156,000 pages.
Archie Comics sued music duo The Veronicas for trademark infringement in 2005 over the band's name, which Archie Comics alleges was taken from the comic book character. Archie Comics and Sire Records (The Veronicas' record company) reached a settlement involving co-promotion.
In 2008, Archie Publications once again licensed DC Comics its MLJ Super heroes for a DC Universe integrated line, Red Circle.
2010–present.
Following Richard Goldwater's death in 2007 and Michael Silberkleit's in 2008, Silberkleit's widow Nancy and Goldwater's half brother Jonathan became co-CEOs in 2009. Nancy Silberkleit, a former elementary-school art teacher, was given responsibility for scholastic and theater projects, and Jon Goldwater, a former rock/pop music manager, was responsible for all the other company elements. The company sued Silberkleit in July 2011, and Goldwater filed another lawsuit against her in January 2012, alleging she was making bad business decisions and alienating staff; she in turn sued him for defamation. As of February 2012, New York Supreme Court Justice Shirley Kornreich, in Manhattan, fined Silberkleit $500 for violating the court's autumn order to temporarily barring her from the company's headquarters, and said the court might appoint a temporary receiver to protect the company's assets.
Beginning in 2010, the company partnered with Random House Publisher Services for its bookstore distribution which included trade paperbacks, children’s book formats and additional book formats. Archie Comics only published 11 book titles that year but after the new partnership those numbers grew to 33 in 2012, and 40 in 2013. The company's sales also increased by 410% for books and 1,000% for e-books since 2010. In February 2010, Archie Comics partnered with A Squared Entertainment and POW! Entertainment to create Stan Lee Comics, a print and digital line. Beginning in July 2010, the first issue of "Life with Archie: The Married Life", a series featuring two storylines exploring possible futures where Archie married either Betty or Veronica that also dealt with adult issues such as death, marriage woes, financial problems and gun control, was released. Kevin Keller, the first openly gay character in Archie Comics, first appeared in "Veronica" #202 in September. The issue sold out prompting Archie Comics to issue their first ever re-print. In June 2011, Keller was featured in his own four-part miniseries. After the success of the character and his self-titled mini-series, Kevin Keller was given his own comic book beginning in early 2012 that was published bi-monthly. 
In March 2011, a copy of "Archie Comics" #1, first published in 1942, was sold at auction for $167,300, a record for a non-superhero comic book. In April 2011, Archie Comics became the first mainstream publisher to make its entire line available digitally on the same day as the print release accomplishing this five months before DC Comics and eleven months before Marvel Comics. At the New York Comic Con in October 2011, Archie Comics announced that their superheroes would return as an all-digital line under the Red Circle imprint, a subscription model with back-issue archive access. The imprint started in 2012 with a new "New Crusaders" series.
In October 2013, Archie Comics launched their first horror title "Afterlife with Archie", depicting Archie and his gang dealing with a zombie apocalypse which begins in their hometown of Riverdale. "Afterlife with Archie" was also their first title to be sold only in comic shops and carry a rating of "TEEN+". The success of the series led to another horror series, "Chilling Adventures of Sabrina", which debuted in October 2014.
On April 9, 2014, Archie Comics announced that Archie Andrews would die in the July 2014 issue of "Life with Archie: The Married Life" which would also be the second-to-last issue of the series. Archie Comics CEO Jon Goldwater verified that in both parallel futures covered by the "Life with Archie" series, Archie's final fate is the same. On July 2014, it was revealed that Archie would be killed saving Kevin Keller from an assassination attempt from a stalker's bullet.
In July 2014, Archie Comics announced that the Red Circle imprint would be relaunched as Dark Circle Comics in early 2015 with the past continuity removed. It was also announced that the ongoing titles would follow a self-contained five-issue arc while taking a brief hiatus to allow for the publication of trade collections. Dark Circle Comics officially debuted with the release of the first issue of "The Black Hood" in February 2015. It was followed by "The Fox" in April, "The Shield" in October, and "The Hangman" in November.
In March 2015, after a suspending of publication of its two horror books, Archie Comics announced that they would return under a new imprint, Archie Horror, with "Chilling Adventures of Sabrina" #2 and "Afterlife with Archie" #8 being released in April and May.
In December 2014, Archie Comics announced that "Archie" would being getting relaunched for the first time since 1942 with a new first issue being released in 2015. On May 11, 2015, Archie Comics launched a $350,000 Kickstarter campaign to help them get three more planned series set in the '"New Riverdale" out to the public sooner. These included a new "Jughead" series, "Life with Kevin" focusing on Kevin Keller, and a new "Betty and Veronica" series. Five days later, Archie Comics cancelled their Kickstarter after negative critical response. They stated that the three titles will still be published although on a delayed timeline. The first title in their "New Riverdale" universe, "Archie" was released in July and came in at #7 for comic book sales for the month. The next title, "Jughead", was released in October. In April 2015, Archie Comics announced "Betty and Veronica" set for release in July 2015. Also announced was "Life with Kevin", a digital-first mini-series set to debut in June 2015.
Characters.
Archie and Riverdale.
"Archie" is set in the small town of Riverdale. While the state or even the general location of the town is unspecified, John L. Goldwater attended Horace Mann School in the Riverdale section of The Bronx, New York City. In the early years of Archie, Riverdale was located in Massachusetts, with Mr. Lodge being a senator for that state, but this is no longer considered canon. Drawings of Riverdale High School appeared to follow the general design of the original high school, now City Hall, in Haverhill, Massachusetts. "The Thinker" statue still sits outside the front entrance, just like it did in the comic strip.
The "New York Times" postulated that "the cartoonist Bob Montana inked the original likenesses of Archie and his pals and plopped them in an idyllic Midwestern community named Riverdale because Mr. Goldwater, a New Yorker, had fond memories of time spent in Hiawatha, Kansas."
For the comics' 60th anniversary in 2002, several geographical and historical hints to the location of Riverdale were printed in every digest issue. At the end of the year, it was revealed that the hints point to Riverdale being located in the "Missouri area," but that officially Riverdale has no location. It is essentially located wherever the reader wants it to be. Indeed, the geography of Riverdale is far too inconsistent for it to be any one specific location (see below).
Superheroes.
Initially, MLJ started out publishing humor and adventure strips in anthology comic books as was the standard, but quickly added superheroes in their first title's second issue, "Blue Ribbon Comics" #2, with Bob Phantom. In January 1940, "Pep Comics" debuted featuring the Shield, America's first patriotic comic book hero, by writer and managing editor Harry Shorten and artist Irv Novick. MLJ's Golden Age heroes also included the Black Hood, who also appeared in pulp magazines and a radio show; and The Wizard, who shared a title with the Shield.
Later revivals of the MLJ superheroes occurred under a number of imprints: Archie Adventure Series, Mighty Comics, Red Circle Comics and one aborted attempt, Spectrum Comics. Archies Publications then licensed them out to DC Comics in the 1990s for Impact Comics universe imprint then again in 2008 for a DC Universe integrated Red Circle line.
Archie's Silver Age relaunch of its superheroes under the Archie Adventure Series imprint and then the Mighty Comics imprint began with a new version of the Shield and two new characters the Jaguar and the Fly. In the mid-1960s with the Silver Age of Comics, Archie switched the heroes to a new imprint, "Mighty Comics Group", with the revival of all the MLJ heroes done as Marvel parodies with "the campy humor of the Batman TV show." This imprint shift soon brought the company its first super hero team book similar to Marvel's Avengers with the Mighty Crusaders. This imprint ended in 1967.
With the conversion of Archie's Red Circle Comics from horror to superheroes in the 1980s, the Mighty Crusaders, Black Hood, the Comet, the Fly and two version of the Shields had their own titles.
Archie planned to publish superheroes again in the late 1980s with an imprint called Spectrum Comics, featuring a number of high-profile talents, including Steve Englehart, Jim Valentino, Marv Wolfman, Michael Bair, Kelley Jones, and Rob Liefeld. Planned Spectrum titles included "The Fly", "The Fox", "Hangman", "Jaguar", "Mister Justice", and "The Shield". Ultimately, Archie cancelled Spectrum Comics before publishing a single issue.
In 2012, Archie Comics relaunched its superhero imprint, Red Circle Comics, as an all-digital line under a subscription model with back issues archive access starting with New Crusader.
In 2015, Archie Comics rebranded its superhero imprint under the new title, Dark Circle Comics. It was launched in February with The Black Hood followed by the launch of "The Fox" in April with "The Shield" and "The Hangman" to follow in September and November.
Titles.
Titles in publication as of 2016.
New Riverdale
Archie Action
Archie Horror
Dark Circle Comics
The Archie Library
"New look" series.
In 2007, Archie Comics launched a "new look" series of stories, featuring Archie characters drawn in an updated, less cartoony style similar to the characters' first appearance. There are a total of seven storylines and each one was published as a four part storyline in a digest series. Also each "new look" story was based on a Riverdale High novel, a series of twelve novels that were published in the 1990s. The only Riverdale High novels that were not adapted into one of these stories are "The Trouble With Candy", "Rich Girls Don't Have to Worry", "Is That Arabella?", "Goodbye Millions", and "Tour Troubles" due to the "new look" series ending in 2010.
Spire Christian Comics.
Spire Christian Comics were a line of comic books not published by Archie Comics, but by Fleming H. Revell, which eventually became Barbour & Company. Through Al Hartley, one of Spire's illustrators who also worked for Archie Comics at the time, Revell obtained license to feature the Archie characters in several of its titles, including "Archie's Sonshine," "Archie's Roller Coaster," "Archie's Family Album," and "Archie's Parables." These comics used Archie and his friends to tell stories with strong Christian themes and morals, sometimes incorporating Bible scripture. In at least one instance, the regular characters meet a Christ-like figure on the beach, and listen as he gently preaches Christian values. Spire Christian Comics were produced from 1972 through to the 1980s.
Honors and awards.
The United States Postal Service included Archie in a set of five 44-cent commemorative postage stamps on the theme "Sunday Funnies", issued July 16, 2010. The Archie stamp featured Veronica, Archie, and Betty sharing a chocolate milkshake. The other stamps depicted characters from the comic strips "Beetle Bailey", "Calvin and Hobbes", "Garfield", and "Dennis the Menace".
Archie characters in other media.
Television.
Animation.
In 1968, CBS began airing episodes of "The Archie Show", a cartoon series produced by Filmation. Although it only lasted for a single season, it aired in reruns for the next decade, and was followed by several spin-off programs, which used segments from this original Archie show and new material. In 1970, Sabrina, the Teenage Witch got her own animated series, also produced by Filmation. In 1970, another Archie property received the Saturday morning cartoon treatment: "Josie and the Pussycats". Unlike Archie and Sabrina, Josie's show was produced by Hanna-Barbera Productions, the company behind such animated hits as "The Flintstones", "The Jetsons", and "Scooby-Doo, Where Are You?". The show was followed by a spin-off, "Josie and the Pussycats in Outer Space," in 1972. "The Archie Show", "Sabrina, the Teenage Witch", "Josie and the Pussycats", and several of the spin-off shows including "Josie and the Pussycats in Outer Space" are currently available on DVD in complete series boxed sets.
In 1987, DIC Entertainment produced an NBC Saturday morning cartoon, "The New Archies". This children's television cartoon re-imagined the teenage students of Riverdale High School as pre-teens in junior high. Fourteen episodes of the show were produced, which aired during the show's only season in 1987 and were repeated in 1989. A short-lived Archie Comics series was produced bearing the same title and set in the same universe as the animated series. Reruns of the series ran on The Family Channel's Saturday morning lineup from 1991 to 1993, and on Toon Disney from 1998 to 2002. The cast was basically the same, but Dilton Doiley was replaced as the "intellectual" character by an African American named Eugene. Eugene's girlfriend Amani was another addition to the cast. Archie also gained a dog named Red.
In 1999, another animated program featuring Archie and his friends was produced by DIC Entertainment. "Archie's Weird Mysteries" featured core Archie characters solving mysteries occurring in their hometown of Riverdale. The show ran on the PAX network for a single 40-episode season, and continues to air sporadically in reruns on various other networks. The complete series was released on DVD in 2012. As a companion to the Archie series, DIC also produced "Sabrina: the Animated Series", "Sabrina's Secret Life" and ""; the cartoons featured Sabrina and her aunts at a younger age than they were in the comic books. Tie-in comic book titles were produced for all of these series.
In 2012, it was announced that MoonScoop would produce a new Sabrina the Teenage Witch series titled "". It ran for a single 26-episode season on Hub Network from October 2013 until June 2014.
In 2013, MoonScoop announced that it will also produce a new Archie animated series titled "It's Archie" which will feature Archie and friends in junior high. The first season was set to feature 52 11-minute episodes. However, since its announcement no other information about the series has been released.
Live action.
1970 Special and "Archie: To Riverdale and Back Again".
In the early 1970s, a live-action special of Archie and the Archie characters was aired on U.S. television. In 1990, NBC aired "" (titled "Archie: Return to Riverdale" on video), a TV movie featuring Christopher Rich as a 30-something Archie Andrews who returns to his hometown for a high school reunion, and reunites with Betty, Veronica, and several other original comic book characters.
"Sabrina, the Teenage Witch".
In 1996, cable network Showtime aired "Sabrina, the Teenage Witch", a live-action TV movie starring Melissa Joan Hart as Sabrina. The film served as the pilot for a TV series, also starring Hart, which began airing in the fall of 1996 on ABC. The sitcom was relatively faithful to the comic book series, and enjoyed a lengthy run until 2003. It is now available in its entirety on DVD, as is the original TV movie.
"Riverdale".
By October 2014, Greg Berlanti was developing a drama series for Fox titled "Riverdale" with Berlanti and Sarah Schechter as executive producers through Berlanti Productions, and Roberto Aguirre-Sacasa writing the series. It will feature Archie, Betty, Veronica, Jughead, Reggie, Kevin and Josie & the Pussycats. In July 2015, the pilot was moved to The CW. In addition to the series offering a bold, subversive take on the gang, Aguirre-Sacasa has described "Riverdale" as "Archie meets "Twin Peaks"".
The pilot was ordered by the network in January 2016 with filming set to begin in the spring. In February 2016, Deadline reported that K.J. Apa, Lili Reinhart, Cole Sprouse, Camila Mendes, Ashleigh Murray, Madelaine Petsch and Luke Perry had been cast as Archie Andrews, Betty Cooper, Jughead Jones, Veronica Lodge, Josie McCoy, Cheryl Blossom and Fred Andrews and in March 2016, Ross Butler, Cody Kearsley, Daniel Yang and Casey Cott were cast as Reggie Mantle, Moose Mason, Dilton Doiley and Kevin Keller.
Film.
In 2001, Universal Studios and Metro-Goldwyn-Mayer released "Josie and the Pussycats", based on the comic of the same name.
In 2003, Miramax announced that they were working on a Betty and Veronica movie, but the project was cancelled.
In 2013, Warner Bros. closed a deal for a live-action movie based on the Archie Comics books with Roy Lee and Dan Lin producing, Jon Goldwater, Krishnan Menon and Jon Silk executive producing, Roberto Aguirre-Sacasa writing and Jason Moore has signed on to direct. The film is described as a "high school comedy based on the original line of Archie Comics set in present-day Riverdale". In an interview with Comic Book Resources, Aguirre-Sacasa has hinted about doing an "Afterlife with Archie" film.
Broadway.
In 2015, Archie Comics announced that they would be bringing Archie, Betty, Veronica, Jughead and the rest of the Riverdale gang to Broadway with an all-new musical. Adam McKay is set to write the book for the show while Funny Or Die will serve as a presenting partner. CEO Jon Goldwater and CCO Roberto Aguirre-Sacasa will oversee production. Triptyk Studios packaged the partnership and Tara Smith, B. Swibel and Adam Westbrook will oversee development of the musical for the company. At this time no creative team for the musical has been announced.
Painting.
In 2014, the Tripoli Gallery in Southampton, New York, displayed a collected of oil paintings by Gordon Stevenson, also known as Baron Von Fancy, featuring Archie Comic characters in adult-oriented scenes.
Official site.
According to Archie publisher Michael Silberkleit, the official "Archie" website receives 40 million hits a month. There have been many "Archie" licensing deals and products, including "Archie" tattoos from Topps Chewing Gum in 1968.
On the blogs on ArchieComics.com, there also is a story starter page where the beginning of an Archie-related story is listed, and replaced once a week. Fans may write a story about the starter and post it on the blog for all to read. In a couple of weeks, if the fan wins because their story is the best, they are rewarded with either a comic subscription or a comic collector set. They may go on to win the grand prize and get their story published in an Archie comic book.

</doc>
<doc id="60433" url="https://en.wikipedia.org/wiki?curid=60433" title="Nuclear bunker buster">
Nuclear bunker buster

A nuclear bunker buster, also known as an earth-penetrating weapon (EPW), is the nuclear equivalent of the conventional bunker buster. The non-nuclear component of the weapon is designed to penetrate soil, rock, or concrete to deliver a nuclear warhead to an underground target. These weapons would be used to destroy hardened, underground military bunkers or other below-ground facilities. An underground explosion releases a larger fraction of its energy into the ground, compared to a surface burst or air burst explosion at or above the surface, and so can destroy an underground target using a lower explosive yield. This in turn could lead to a reduced amount of radioactive fallout. However, it is unlikely that the explosion would be completely contained underground. As a result, significant amounts of rock and soil would be rendered radioactive and lofted as dust or vapor into the atmosphere, generating significant fallout.
Base principle.
While conventional bunker busters utilize several methods to penetrate concrete structures, these are for the purpose of destroying the structure directly, and are generally limited in how much of a bunker (or system of bunkers) they can destroy by depth and their relatively low explosive force (versus nuclear weapons).
The primary difference between conventional and nuclear bunker busters is that, while the conventional version is meant for one target, the nuclear version can destroy an entire underground bunker system.
The main principles in modern bunker design are largely centered around survivability in nuclear war. As a result of this both American and Soviet sites reached a state of "super hardening", involving defenses against the effects of a nuclear weapon such as spring- or counterweight-mounted (in the case of the R-36) control capsules and thick concrete walls (three to four feet for the Minuteman ICBM launch control capsule) heavily reinforced with rebar. These systems were designed to survive a near miss of 20 megatons.
A nuclear bunker buster negates most of the countermeasures involved in the protection of underground bunkers by penetrating the defenses prior to detonating. A relatively low yield may be able to produce seismic forces beyond those of an air burst or even ground burst of a weapon with twice its yield. Additionally, the weapon has the ability to impart more severe horizontal shock waves than many bunker systems are designed to combat by detonating at or near the bunker's depth, rather than above it.
Methods of operation.
Penetration by explosive force.
Concrete structure design has not changed significantly in the last 60 years. The majority of protected concrete structures in the U.S. military are derived from standards set forth in "Fundamentals of Protective Design", published in 1946 (US Army Corps of Engineers). Various augmentations, such as glass, fibers, and rebar, have made concrete less vulnerable, but far from impenetrable.
When explosive force is applied to concrete, three major fracture regions are usually formed: the initial crater, a crushed aggregate surrounding the crater, and "scabbing" on the surface opposite the crater. Scabbing, also known as spalling, is the violent separation of a mass of material from the opposite face of a plate or slab subjected to an impact or impulsive loading, without necessarily requiring that the barrier itself be penetrated.
While soil is a less dense material, it also doesn't transmit shock waves as well as concrete. So while a penetrator may actually travel further through soil, its effect may be lessened due to its inability to transmit shock to the target.
Hardened penetrator.
Further thinking on the subject envisions a hardened penetrator using kinetic energy to defeat the target's defenses and subsequently deliver a nuclear explosive to the buried target.
The primary difficulty facing the designers of such a penetrator is the tremendous heat applied to the penetrator unit when striking the shielding (surface) at hundreds of meters per second. This has partially been solved by using metals such as tungsten (the element with the highest melting point), and altering the shape of the projectile (such as an ogive).
Altering the shape of the projectile to incorporate an ogive shape has yielded substantial improvement in penetration ability. Rocket sled testing at Eglin Air Force Base has demonstrated penetrations of 100 to in concrete when traveling at . The reason for this is liquefaction of the concrete in the target, which tends to flow over the projectile. Variation in the speed of the penetrator can either cause it to be vaporized on impact (in the case of traveling too fast), or to not penetrate far enough (in the case of traveling too slow). An approximation for the penetration depth is obtained with an impact depth formula derived by Sir Isaac Newton.
Combination penetrator-explosive munitions.
Another school of thought on nuclear bunker busters is using a light penetrator to travel 15 to 30 meters through shielding, and detonate a nuclear charge there. Such an explosion would generate powerful shock waves, which would be transmitted very effectively through the solid material comprising the shielding (see "scabbing" above).
Policy and criticism of fallout.
The main criticisms of nuclear bunker busters regard fallout and nuclear proliferation. The purpose of an earth-penetrating nuclear bunker buster is to reduce the required yield needed to ensure the destruction of the target by coupling the explosion to the ground, yielding a shock wave similar to an earthquake. For example, the United States retired the B-53 warhead, with a yield of nine megatons, because the B-61 Mod 11 could attack similar targets with much lower yield (400 kilotons), due to the latter's superior ground penetration. By burying itself into the ground before detonation, a much higher proportion of the explosion energy is transferred to seismic shock when compared to the surface burst produced from the B-53's laydown delivery. Moreover, the globally dispersed fallout of an underground B-61 Mod 11 would likely be less than that of a surface burst B-53. Supporters note that this is one of the reasons nuclear bunker busters should be developed. Critics claim that developing new nuclear weapons sends a proliferating message to non-nuclear powers, undermining non-proliferation efforts.
Critics also worry that the existence of lower-yield nuclear weapons for relatively limited tactical purposes will lower the threshold for their actual use, thus blurring the sharp line between conventional weapons intended for use and weapons of mass destruction intended only for hypothetical deterrence and increasing the risk of escalation to higher-yield nuclear weapons.
Local fallout from any nuclear detonation is increased with proximity to the ground. While a megaton-class yield surface burst will inevitably throw up many tons of (newly) radioactive debris, which falls back to the earth as fallout, critics contend that despite their relatively minuscule explosive yield, nuclear bunker busters create more local fallout per kiloton yield. Also, because of the subsurface detonation, radioactive debris may contaminate the local groundwater.
The Union of Concerned Scientists advocacy group points out that, at the Nevada Test Site, the depth required to contain fallout from an average-yield nuclear test was over 100 meters, depending upon the weapon's yield. They contend that it is improbable that penetrators could be made to burrow so deeply. With yields between 0.3 and 340 kilotons, they argue, it is unlikely the blast would be completely contained.
Another criticism is that bunkers can be built at greater depth to make them more difficult to reach. The target's vulnerability is then limited to openings like the ventilation system, which are susceptible to conventional explosives. Proponents of nuclear bunker busters respond that deeper bunkers entail higher costs, limiting the potential enemies who can withstand nuclear bunker busters.
Critics further state that the testing of new nuclear weapons would be prohibited by the proposed Comprehensive Test Ban Treaty. Although Congress refused to ratify the CTBT in 1999, and therefore this treaty has no legal force in the US, the US has adhered to the spirit of the treaty by maintaining a moratorium on nuclear testing since 1992.
Propenents, however, contend that lower explosive yield devices and subsurface bursts would produce little to no climatic effects in the event of a nuclear war, in contrast to multi-megaton air and surface bursts, that is, if the nuclear winter hypothesis proves accurate. Lower fuzing heights, which would result from partially buried warheads, would limit or completely obstruct the range of the burning thermal rays of a nuclear detonation, therefore limiting the target, and surroundings, to a fire hazard by reducing the range of thermal radiation with fuzing for subsurface bursts. Professors Altfeld and Cimbala have suggested that belief in the possibility of nuclear winter has actually made nuclear war more likely, contrary to the views of Carl Sagan and others, because it has inspired the development of more accurate, and lower explosive yield, nuclear weapons.
Targets and the development of bunker busters.
As early as 1944, the Wallis Tallboy bomb and subsequent Grand Slam weapons were designed to penetrate deeply fortified structures through sheer explosive power. These were not designed to directly penetrate defences, though they could do this (for example, the Valentin submarine pens had ferrous concrete roofs thick which were penetrated by two Grand Slams on 27 March 1945), but rather to penetrate under the target and explode leaving a camouflet (cavern) which would undermine foundations of structures above, causing it to collapse, thus negating any possible hardening. The destruction of targets such as the V3 battery at Mimoyecques was the first operational use of the Tallboy. One bored through a hillside and exploded in the Saumur rail tunnel about below, completely blocking it, and showing that these weapons could destroy any hardened or deeply excavated installation. Modern targeting techniques allied with multiple strikes could perform a similar task.
Development continued, with weapons such as the nuclear B61, and conventional thermobaric weapons and GBU-28. One of the more effective housings, the GBU-28 used its large mass () and casing (constructed from barrels of surplus 203 mm howitzers) to penetrate of concrete, and more than of earth. The B61 Mod 11, which first entered military service after the Cold war had ended, in January 1997, was specifically developed to allow for bunker penetration, and is speculated to have the ability to destroy hardened targets a few hundred feet beneath the earth.
While penetrations of were sufficient for some shallow targets, both the Soviet Union and the United States were creating bunkers buried under huge volumes of soil or reinforced concrete in order to withstand the multi-megaton thermonuclear weapons developed in the 1950s and 1960s. Bunker penetration weapons were initially designed within this Cold War context. One likely Soviet Union/Russian target, Mount Yamantau, was regarded in the 1990s by Maryland Republican congressman, Roscoe Bartlett, as capable of surviving "half a dozen"(6) repeated nuclear strikes of an unspecified yield, one after the other in a "direct hole".
The Russian continuity of government facility at Kosvinsky Mountain, finished in early 1996, was designed to resist US earth-penetrating warheads and serves a similar role as the American Cheyenne Mountain Complex. The timing of the Kosvinsky completion date is regarded as one explanation for US interest in a new nuclear bunker buster and the declaration of the deployment of the B-61 mod 11 in 1997, Kosvinksy is protected by about 1000 feet of granite.
The weapon was revisited after the Cold War during the 2001 U.S. invasion of Afghanistan, and again during the 2003 invasion of Iraq. During the campaign in Tora Bora in particular, the United States believed that "vast underground complexes," deeply buried, were protecting opposing forces. Such complexes were not found. While a nuclear penetrator (the "Robust Nuclear Earth Penetrator", or "RNEP") was never built, the U.S. DOE was allotted budget to develop it, and tests were conducted by the U.S. Air Force Research Laboratory. The RNEP was to use the 1.2 megaton B83 physics package.
The Bush administration removed its request for funding of the weapon in October 2005. Additionally, then U.S. Senator Pete Domenici announced funding for the nuclear bunker-buster has been dropped from the U.S. Department of Energy's 2006 budget at the department's request.
While the project for the RNEP seems to be in fact canceled, Jane's Information Group speculated in 2005 that work might continue under another name.
A more recent development (c. 2012) is the GBU-57 Massive Ordnance Penetrator, a 30000-pound conventional gravity bomb. The USAF's B-2 Spirit bombers can each carry two such weapons.
Russian spy interest.
In 2010 it was revealed that members of the Illegals Program, a group of Russian sleeper agents in the US, were gathering online information about bunker busters and made contacts with a former intelligence official and with a scientist involved in developing the weapons.

</doc>
<doc id="60445" url="https://en.wikipedia.org/wiki?curid=60445" title="Apple Attachment Unit Interface">
Apple Attachment Unit Interface

Apple Attachment Unit Interface (AAUI) is a mechanical re-design by Apple of the standard Attachment Unit Interface (AUI) used to connect Ethernet transceivers to computer equipment. AUI was popular in the era before the dominance of 10BASE-T networking that started in the early 1990s; AAUI was an attempt to make the connector much smaller and more user friendly.
FriendlyNet.
AAUI was part of a system of Ethernet peripherals that tried to make connecting to Ethernet much easier. At the time, Ethernet systems usually were 10BASE2, also known as thinnet. Apple's system was called FriendlyNet. A FriendlyNet 10BASE2 system did not use BNC T-connectors or separate 50 Ω terminators. Instead of a single BNC connector that was inserted into a T-connector placed inline in the cable, the AAUI transceiver had two BNC connectors, one on each side to which the cables were attached. The transceiver would automatically terminate the network if a cable was not attached to one of the sides. Additionally, Apple 10BASE2 cables would terminate the network if no device was attached to them. Thus the number of mistakes that could be made hooking up a thinnet network was reduced considerably. Since any of these mistakes would disable the network in an area this was a significant improvement.
FriendlyNet equipment was quite expensive and even third party AAUI transceivers were rather expensive. Because of this, Apple's computers, which were billed as having built-in Ethernet, were actually rather expensive to connect to Ethernet, perhaps adding as much as 10% to the total price of the computer system. Additionally, AAUI held no advantage for any system other than 10BASE2 and thus as 10BASE-T became ubiquitous it became impossible to justify the cost of an external transceiver at all. Apple eventually abandoned the system and sold off the name.
Macintosh Quadra, Centris, PowerBook 500, Duo Dock II (for PowerBook Duo) and early Power Macintoshes had an AAUI port, which requires an external transceiver. By the time AAUI was nearing the end of its life, an AAUI transceiver could cost as much or more than the cost of a low-cost Ethernet card on the PC - a disproportionate amount as network cards for PCs did not become commodity items until the spread of broadband internet in the early 21st century. Later models included both an AAUI and modular connector port for directly connecting 10BASE-T; either could be used, but not both at the same time. AAUI connectors were also present on some Processor Direct Slot Ethernet adapter cards used in Macintosh LC and Performa machines. AAUI had disappeared by the late 1990s, when all new Apple machines starting with the beige Power Macintosh G3 series included only 10BASE-T.
Third party vendors.
Many third parties also created AAUI transceivers. Most made simplifications to the connectors and cables, presumably to reduce costs. Most third parties, as well as any non-Apple equipment would use standard 10BASE2 cabling, including T-connectors and manual termination. Additionally, Apple's 10BASE2 cables were not really feasible for all uses since they only came in fixed lengths and the ends were not detachable, making it very difficult to wire them through walls. Unfortunately, when mixing and matching Apple and non-Apple 10BASE2 devices, there were many seemingly natural configurations of cables and connectors which would cause the network to become unreliable or unusable in the area, reducing the value of the complex and proprietary Apple 10BASE2 wiring system.
Connector and signals.
AUI used a full-sized 15-pin D connector (model DA-15) that used a sliding clip for mechanical connections in place of thumbscrews. AAUI replaced these with a small 14-position, 0.050-inch-spaced ribbon contact connector. The connector may have been changed to avoid confusion with the monitor port on early Macintoshes, which also used a 15-pin D connector. The connector was locked into position using two clips or hooks on the sides of the connector outside of the D shell (where screws often are on D subs) which automatically clicked on when plugged in, and could be removed simply by pulling back on a sliding sheath over the body of the connector, disengaging the hooks. 3rd party AAUI devices often omitted this sheath, requiring the user to directly squeeze small tabs on the sides of the plug housing to detach the hooks.
AAUI signals have the same description, function, and electrical requirements as the Attachment Unit Interface (AUI) signals of the same name, as detailed in IEEE 802.3-1990 CSMA/CD Standard, section 7, with the exception that most hosts provide only 5 volt power rather than the 12 volts required for most AUI transceivers. An adapter containing a power supply to provide the required 12 volts was available from Apple to permit connection of standard AUI transceivers to an AAUI port - this facilitated direct connection to 10BASE-F (fibre optic) and 10BASE5 (ThickNet) Ethernet networks, for which AAUI transceivers were not available.

</doc>
<doc id="60446" url="https://en.wikipedia.org/wiki?curid=60446" title="Abbreviated Test Language for All Systems">
Abbreviated Test Language for All Systems

Abbreviated Test Language for All Systems (ATLAS) is a MILSPEC language for automatic testing of avionics equipment. It is a high-level computer language and can be used on any computer whose supporting software can translate it into the appropriate low-level instructions.
History.
The ATLAS language was initially developed by an international committee made up of representatives from the airline industries, military services, avionics manufacturers, and Automatic Test Equipment manufacturers. The goal of the committee was to design a standard English-like language that could be easily understood and used by both avionics and test equipment engineers. The result was the ATLAS language specification, published by Aeronautical Radio, Inc.
The ATLAS language is oriented toward the Unit Under Test and is independent of the test equipment used. This allows interchangeability of test procedures developed by different organizations, and thus reduces costly duplication of test programming effort.
The first ATLAS specification developed by the international committee was published in 1968. The basic document has been revised several times.
The ATLAS programming language incorporates an online compiler (OLC), Test executive (TEX or Test Exec), and file manager and media exchange (FMX) packages. Test executive is the mode ATLAS is run in on test stations while testing electronic equipment.
Structure.
A standard ATLAS program structure consists of two elements: preamble structure and procedural structure. The ATLAS programming language makes extensive use of variables and statement syntax. An ATLAS statement consists of a flag field, statement number field (STATNO), verb field, field separator, variable field, and statement terminator. Each and every ATLAS statement is terminated with the currency symbol ($).
ATLAS statement structure.
A standard ATLAS statement:
Sample ATLAS Statements:
Sample ATLAS statements to apply a voltage to a pin (stimulus) and verify the presence and characteristics of a voltage at a pin:
Applications.
ATLAS is used in the Air Force primarily on test stations for testing the avionic components of the F-15 Eagle, F-16 Fighting Falcon, C-5 Galaxy, C-17 Globemaster III, and B-1 Lancer. 
The U. S. Navy uses or has used ATLAS-based programs for testing avionics systems of the P-3C Orion, UH-1Y Venom, AH-1Z Viper, SH-60 Seahawk, E-2C Hawkeye, F-14 Tomcat, F/A-18 Hornet, S-3 Viking, A-6 Intruder, EA-6B Prowler, AV8B Harrier, and V-22 Osprey.
The US Navy and Marine Corps used a version called Super Atlas for its 484 HTS test benches going back at least to 2000.
AN-USM-247 VAST Versatile Avionics Shop Test was used by the US Navy onboard aircraft carrier and shore stations. It supported F-14, S3, E-2, A-7, A-6 et al. VAST is considered by many to be the grandfather of modern avionics test equipment.
In the years that followed the cold war, ATLAS found uses on many Dual Use Aircraft, for the US, NATO, as well as Commercial, Business, Regional, and General Aviation Aircraft. ATLAS Test Program Sets (TPS) allow porting an older code base to new hardware, providing some insurance from hardware obsolescence. Although a standard, many adaptations, customizations, and flavors exist that impede full transportability. As most ATLAS toolsets are custom, on custom hardware, with a custom SW load for the platform it is not as prone to some types of issues that plague other languages that are more prevalent in industry—the down side is that training on this is not available to the general public, and also requires an extensive investment in personnel. It generally can be configured to run "stand-alone", or "stand-alone - monitored only" which can help limit many of the tampering, and other concerns with commercial software such as Apple, Microsoft, Linux, and other commercial/free software. Other Languages such as BASIC, C/C++, PYTHON, and PERL are also used on commercial and military programs for testing of systems—ATLAS typically requires another computer system to either optically scan test results, or read a tape, disk, or locked memory stick/data key from a test station and then perform statistical analysis on test results for a variety of uses.
ATLAS can be quite challenging to implement on newer more complex systems as, these can also involve many sub-contractors, and equipment vendors. However, the cost of re-writing a large base of existing TPS's can be a daunting task as well.
No open source versions of ATLAS currently exist, although that could make a good project for a university.
Subsets.
ATLAS-AISR
ATLAS-AN/USM-410 (RCA EQUATE)
ATLAS-ARINC-616
ATLAS-ARINC-626 (SMART)
ATLAS-ARINC-626-3
ATLAS-B1-B
ATLAS-B2
ATLAS-CASS
ATLAS-CRATE
ATLAS-ESTS
ATLAS-F2/1989
ATLAS-F15-ADTS
ATLAS-HTS
ATLAS-IEEE-416-1984
ATLAS-MATE
ATLAS-RADCOM-1991 (AN/USM-467)
ATLAS-RTCASS
ATLAS-TETS (Marines)
C/ATLAS-IEEE-716-1982, 1985, 1989, 1995
C/ATLAS-ATSE-IFTE-1993, 1996
Implementations.
TYX (now Astronics) created a COTS ATLAS compiler, Integrated Development Environment (IDE), and run-time system that ran on the original IBM PC and was updated for all flavors of Windows called Professional ATLAS Work Station (PAWS).
Lexico made converters that would take ATLAS code and convert to run under HP BASIC. These were popular with McDonnell Douglas, Boeing, Honeywell, etc.
Grumman made an ATLAS compiler for their IFTE V3 and V5 test stations.
General Dynamics made a compiler for their F-16 test station.
RCA developed a compiler for their EQUATE testers.

</doc>
<doc id="60450" url="https://en.wikipedia.org/wiki?curid=60450" title="ABC ALGOL">
ABC ALGOL

ABC ALGOL is an extension of the Algol 60 programming language with arbitrary data structures and user-defined operators, targeted for symbolic mathematics. Despite its advances, it was never used as widely as Algol proper.

</doc>
<doc id="60455" url="https://en.wikipedia.org/wiki?curid=60455" title="Line-of-sight propagation">
Line-of-sight propagation

Line-of-sight propagation is a characteristic of electromagnetic radiation or acoustic wave propagation. Electromagnetic transmission includes light emissions traveling in a straight line. The rays or waves may be diffracted, refracted, reflected, or absorbed by atmosphere and obstructions with material and generally cannot travel over the horizon or behind obstacles.
At low frequency (below approximately 3 MHz), radio signals travel as ground waves, which follow the Earth's curvature due to diffraction with the layers of the atmosphere. This enables AM radio signals in low-noise environments to be received well after the transmitting antenna has dropped below the horizon. Additionally, frequencies between approximately 1 and 30 MHz can be reflected by the F1/F2 Layer, thus giving radio transmissions in this range a potentially global reach (see shortwave radio), again along multiple deflected straight lines. The effects of multiple diffraction or reflection lead to macroscopically "quasi-curved paths".
However, at higher frequencies and in lower levels of the atmosphere, neither of these effects are significant. Thus, any obstruction between the transmitting antenna (transmitter) and the receiving antenna (receiver) will block the signal, just like the light that the eye may sense. Therefore, since the ability to visually see a transmitting antenna (disregarding the limitations of the eye's resolution) roughly corresponds to the ability to receive a radio signal from it, the propagation characteristic of VHF and higher radio frequency (>30 MHz) paths is called "line-of-sight". The farthest possible point of propagation is referred to as the "radio horizon".
In practice, the propagation characteristics of these radio waves vary substantially depending on the exact frequency and the strength of the transmitted signal (a function of both the transmitter and the antenna characteristics). Broadcast FM radio, at comparatively low frequencies of around 100 MHz, are less affected by the presence of buildings and forests.
Radio horizon.
The "radio horizon" is the locus of points at which direct rays from an antenna are tangential to the surface of the Earth. If the Earth was a perfect sphere and there was no atmosphere, the radio horizon would be a circle. 
The radio horizon of the transmitting and receiving antennas can be added together to increase the effective communication range. Antenna heights above will cover the entire hemisphere and not increase the radio horizon.
Radio wave propagation is affected by atmospheric conditions, ionospheric absorption, and the presence of obstructions, for example mountains or trees. 
Simple formulas that include the effect of the atmosphere give the range as:
The simple formulas give a best-case approximation of the maximum propagation distance, but are not sufficient to estimate the quality of service at any location.
Earth bulge and atmosphere effect.
"Earth bulge" is a term used in telecommunications. It refers to the circular segment of earth profile that blocks off long distance communications. Since the geometric line of sight passes at varying heights over the Earth, the propagating radio wave encounters slightly different propagation conditions over the path. The usual effect of the declining pressure of the atmosphere with height is to bend radio waves down towards the surface of the Earth, effectively increasing the Earth's radius, and the distance to the radio horizon, by a factor of around 4/3. This "k-factor" can change from its average value depending on weather.
Geometric distance to horizon.
Assuming a perfect sphere with no terrain irregularity, the distance to the horizon from a high altitude transmitter (i.e., line of sight) can readily be calculated.
Let R be the radius of the Earth and h be the altitude of a telecommunication station. The line of sight distance d of this station is given by the Pythagorean theorem;
Since the altitude of the station is much less than the radius of the Earth,
If the height is given in metres, and distance in kilometres,
If the height is given in feet, and the distance in miles,
The actual service range.
The above analysis does not consider the effect of atmosphere on the propagation path of RF signals. In fact, RF signals don’t propagate in straight lines. Because of the refractive effects of atmospheric layers, the propagation paths are somewhat curved. Thus, the maximum service range of the station is not equal to the line of sight (geometric) distance. Usually, a factor k is used in the equation above
k > 1 means geometrically reduced bulge and a longer service range. On the other hand, k < 1 means a shorter service range.
Under normal weather conditions, k is usually chosen to be 4/3. That means that the maximum service range increases by 15%.
for h in meters and d in kilometres; or
for h in feet and d in miles.
But in stormy weather, k may decrease to cause fading in transmission. (In extreme cases, k can be less than 1.) That is equivalent to a hypothetical decrease in Earth radius and an increase of Earth bulge.
Example.
In normal weather conditions, the service range of a station at an altitude of 1500 m. with respect to receivers at sea level can be found as,
Line-of-sight propagation as a prerequisite for radio distance measurements.
The travel time of radio waves between transmitters and receivers can be measured disregarding the type of propagation. But, generally, travel time only then represents the distance between the transmitter and receiver when line of sight propagation is the basis for the measurement. This also applies to radar, Real Time Locating and lidar.
This rules: Travel time measurements for determining the distance between pairs of transmitters and receivers generally require line of sight propagation for proper results. Whereas the desire to have just any type of propagation to enable communication may suffice, this does never coincide with the requirement to have strictly line of sight at least temporarily as the means to obtain properly measured distances. However, the travel time measurement may always be biased by multi-path propagation, including line of sight propagation as well as non line of sight propagation in any random share. A qualified system for measuring the distance between transmitters and receivers must take this phenomenon into account. Thus filtering signals traveling along various paths makes the approach either operationally sound or just tediously irritating.
Impairments to line-of-sight propagation.
Low-powered microwave transmitters can be foiled by tree branches, or even heavy rain or snow.
If a direct visual fix cannot be taken, it is important to take into account the curvature of the Earth when calculating line-of-sight from maps.
The presence of objects not in the direct visual line of sight can interfere with radio transmission. This is caused by diffraction effects: for the best propagation, a volume known as the first Fresnel zone should be kept free of obstructions. 
Reflected radiation from the ground plane also acts to cancel out the direct signal. This effect, combined with the free-space r−2 propagation loss to a r−4 propagation loss. This effect can be reduced by raising either or both antennas further from the ground: the reduction in loss achieved is known as "height gain".
Mobile telephones.
Although the frequencies used by mobile phones (cell phones) are in the line-of-sight range, they still function in cities. This is made possible by a combination of the following effects:
The combination of all these effects makes the mobile phone propagation environment highly complex, with multipath effects and extensive Rayleigh fading. For mobile phone services, these problems are tackled using:
Other conditions may physically disrupt the connection without prior notice:

</doc>
<doc id="60459" url="https://en.wikipedia.org/wiki?curid=60459" title="Abductive reasoning">
Abductive reasoning

Abductive reasoning (also called abduction, abductive inference or retroduction) is a form of logical inference which goes from an observation to a theory which accounts for the observation, ideally seeking to find the simplest and most likely explanation. In abductive reasoning, unlike in deductive reasoning, the premises do not guarantee the conclusion. One can understand abductive reasoning as "inference to the best explanation".
The fields of law, computer science, and artificial intelligence research renewed interest in the subject of abduction. Diagnostic expert systems frequently employ abduction.
History.
The American philosopher Charles Sanders Peirce (1839–1914) first introduced the term as "guessing". Peirce said that to "abduce" a hypothetical explanation formula_1 from an observed circumstance formula_2 is to surmise that formula_1 may be true because then formula_2 would be a matter of course. Thus, to abduce formula_1 from formula_2 involves determining that formula_1 is sufficient, but not necessary, for formula_2.
For example, suppose we observe that "the lawn is wet". If "it rained last night", then it would be unsurprising that "the lawn is wet". Therefore, by abductive reasoning, the possibility that "it rained last night" is reasonable (but note that Peirce did not remain convinced that a single logical form covers all abduction); however, some other process may have also resulted in a wet lawn, e.g. dew or lawn sprinklers. Moreover, abducing that "it rained last night" from the observation of a wet lawn can lead to false conclusion(s).
Peirce argues that good abductive reasoning from "P" to "Q" involves not simply a determination that "Q" is sufficient for "P", but also that "Q" is among the most economical explanations for "P". Simplification and economy both call for that "leap" of abduction.
Formalizations of abduction.
Logic-based abduction.
In logic, explanation is done from a logical theory formula_30 representing a domain and a set of observations formula_31. Abduction is the process of deriving a set of explanations of formula_31 according to formula_30 and picking out one of those explanations. For formula_34 to be an explanation of formula_31 according to formula_30, it should satisfy two conditions:
In formal logic, formula_31 and formula_34 are assumed to be sets of literals. The two conditions for formula_34 being an explanation of formula_31 according to theory formula_30 are formalized as:
Among the possible explanations formula_34 satisfying these two conditions, some other condition of minimality is usually imposed to avoid irrelevant facts (not contributing to the entailment of formula_31) being included in the explanations. Abduction is then the process that picks out some member of formula_34. Criteria for picking out a member representing "the best" explanation include the simplicity, the prior probability, or the explanatory power of the explanation.
A proof theoretical abduction method for first order classical logic based on the sequent calculus and a dual one, based on semantic tableaux (analytic tableaux) have been proposed (Cialdea Mayer & Pirri 1993). The methods are sound and complete and work for full first order logic, without requiring any preliminary reduction of formulae into normal forms. These methods have also been extended to modal logic.
Abductive logic programming is a computational framework that extends normal logic programming with abduction. It separates the theory formula_30 into two components, one of which is a normal logic program, used to generate formula_34 by means of backward reasoning, the other of which is a set of integrity constraints, used to filter the set of candidate explanations.
Set-cover abduction.
A different formalization of abduction is based on inverting the function that calculates the visible effects of the hypotheses. Formally, we are given a set of hypotheses formula_54 and a set of manifestations formula_55; they are related by the domain knowledge, represented by a function formula_56 that takes as an argument a set of hypotheses and gives as a result the corresponding set of manifestations. In other words, for every subset of the hypotheses formula_57, their effects are known to be formula_58.
Abduction is performed by finding a set formula_57 such that formula_60. In other words, abduction is performed by finding a set of hypotheses formula_61 such that their effects formula_58 include all observations formula_55.
A common assumption is that the effects of the hypotheses are independent, that is, for every formula_57, it holds that formula_65. If this condition is met, abduction can be seen as a form of set covering.
Abductive validation.
Abductive validation is the process of validating a given hypothesis through abductive reasoning. This can also be called reasoning through successive approximation. Under this principle, an explanation is valid if it is the best possible explanation of a set of known data. The best possible explanation is often defined in terms of simplicity and elegance (see Occam's razor). Abductive validation is common practice in hypothesis formation in science; moreover, Peirce claims that it is a ubiquitous aspect of thought:
Looking out my window this lovely spring morning, I see an azalea in full bloom. No, no! I don't see that; though that is the only way I can describe what I see. That is a proposition, a sentence, a fact; but what I perceive is not proposition, sentence, fact, but only an image, which I make intelligible in part by means of a statement of fact. This statement is abstract; but what I see is concrete. I perform an abduction when I so much as express in a sentence anything I see. The truth is that the whole fabric of our knowledge is one matted felt of pure hypothesis confirmed and refined by induction. Not the smallest advance can be made in knowledge beyond the stage of vacant staring, without making an abduction at every step.
It was Peirce's own maxim that "Facts cannot be explained by a hypothesis more extraordinary than these facts themselves; and of various hypotheses the least extraordinary must be adopted." After obtaining results from an inference procedure, we may be left with multiple assumptions, some of which may be contradictory. Abductive validation is a method for identifying the assumptions that will lead to your goal.
Probabilistic abduction.
Probabilistic abductive reasoning is a form of abductive validation, and is used extensively in areas where conclusions about possible hypotheses need to be derived, such as for making diagnoses from medical tests. For example, a pharmaceutical company that develops a test for a particular infectious disease will typically determine the reliability of the test by hiring a group of infected and a group of non-infected people to undergo the test. Assume the statements formula_66: "Positive test", formula_67: "Negative test", formula_68: "Infected", and formula_69: "Not infected". The result of these trials will then determine the reliability of the test in terms of its sensitivity formula_70 and false positive rate formula_71. The interpretations of the conditionals are: formula_70: "The probability of positive test given infection", and formula_71: "The probability of positive test in the absence of infection". The problem with applying these conditionals in a practical setting is that they are expressed in the opposite direction to what the practitioner needs. The conditionals needed for making the diagnosis are: formula_74: "The probability of infection given positive test", and formula_75: "The probability of infection given negative test". The probability of infection could then have been conditionally deduced as formula_76, where "formula_77" denotes conditional deduction. Unfortunately the required conditionals are usually not directly available to the medical practitioner, but they can be obtained if the base rate of the infection in the population is known.
The required conditionals can be correctly derived by inverting the available conditionals using Bayes rule. The inverted conditionals are obtained as follows:
formula_78
The term formula_79 on the right hand side of the equation expresses the base rate of
the infection in the population. Similarly, the term formula_80 expresses the default likelihood of
positive test on a random person in the population. In the expressions below
formula_81 and formula_82 denote the base rates of formula_68 and its complement formula_69 respectively, so that e.g. formula_85. The full expression for the required
conditionals formula_74 and formula_75 are then
formula_88
The full expression for the conditionally abduced probability of infection in a tested person, expressed as formula_89, given the outcome of the test, the base rate of the infection, as well as the test's sensitivity and false positive rate, is then given by
formula_90.
This further simplifies to
formula_91.
Probabilistic abduction can thus be described as a method for inverting conditionals in order to apply probabilistic deduction.
A medical test result is typically considered positive or negative, so
when applying the above equation it can be assumed that
either formula_92 (positive) or formula_93 (negative). In
case the patient tests positive, the above equation can be
simplified to formula_94 which
will give the correct likelihood that the patient actually is infected.
The Base rate fallacy in medicine, or the Prosecutor's fallacy in legal reasoning, consists of making the erroneous assumption that formula_95. While this reasoning error often can produce a relatively good approximation of the correct hypothesis probability value, it can lead to a completely wrong result and wrong conclusion in case the base rate is very low and the reliability of the test is not perfect. An extreme example of the base rate fallacy is to conclude that a male person is pregnant just because he tests positive in a pregnancy test. Obviously, the base rate of male pregnancy is zero, and assuming that the test is not perfect, it would be correct to conclude that the male person is not pregnant or the person is not biologically male.
The expression for probabilistic abduction can be generalised to multinomial cases, i.e., with a state space formula_96 of multiple formula_97 and a state space formula_98 of multiple states formula_99.
Subjective logic abduction.
Subjective logic generalises probabilistic logic by including parameters for uncertainty in the input arguments. Abduction in subjective logic is thus similar to probabilistic abduction described above. The input arguments in subjective logic are composite functions called subjective opinions which can be binomial when the opinion applies to a single proposition or multinomial when it applies to a set of propositions. A multinomial opinion thus applies to a frame formula_100 (i.e. a state space of exhaustive and mutually disjoint propositions formula_101), and is denoted by the composite
function formula_102, where formula_103 is a vector of belief masses over the propositions of formula_100, formula_105 is the uncertainty mass, and formula_106 is a vector of base rate values over the propositions of formula_100. These components satisfy formula_108 and formula_109 as well as formula_110.
Assume the frames formula_96 and formula_98, the sets of conditional opinions formula_113 and formula_114, the opinion formula_115 on formula_96, and the base rate function formula_117 on formula_98. Based on these parameters, subjective logic provides a method for deriving the set of inverted conditionals formula_119 and formula_120. Using these inverted conditionals, subjective logic also provides a method for deduction. Abduction in subjective logic consists of inverting the conditionals and then applying deduction.
The symbolic notation for conditional abduction is "formula_121", and the operator itself is denoted as formula_122. The expression for subjective logic abduction is then:
formula_123.
The advantage of using subjective logic abduction compared to probabilistic abduction is that uncertainty about the probability values of the input arguments can be explicitly expressed and taken into account during the analysis. It is thus possible to perform abductive analysis in the presence of missing or incomplete input evidence, which normally results in degrees of uncertainty in the output conclusions.
History.
The philosopher Charles Sanders Peirce (; 1839–1914) introduced abduction into modern logic. Over the years he called such inference "hypothesis", "abduction", "presumption", and "retroduction". He considered it a topic in logic as a normative field in philosophy, not in purely formal or mathematical logic, and eventually as a topic also in economics of research.
As two stages of the development, extension, etc., of a hypothesis in scientific inquiry, abduction and also induction are often collapsed into one overarching concept — the hypothesis. That is why, in the scientific method pioneered by Galileo and Bacon, the abductive stage of hypothesis formation is conceptualized simply as induction. Thus, in the twentieth century this collapse was reinforced by Karl Popper's explication of the hypothetico-deductive model, where the hypothesis is considered to be just "a guess" (in the spirit of Peirce). However, when the formation of a hypothesis is considered the result of a process it becomes clear that this "guess" has already been tried and made more robust in thought as a necessary stage of its acquiring the status of hypothesis. Indeed, many abductions are rejected or heavily modified by subsequent abductions before they ever reach this stage.
Before 1900, Peirce treated abduction as the use of a known rule to explain an observation, e.g., it is a known rule that if it rains the grass is wet; so, to explain the fact that the grass is wet; one infers that it has rained. This remains the common use of the term "abduction" in the social sciences and in artificial intelligence.
Peirce consistently characterized it as the kind of inference that originates a hypothesis by concluding in an explanation, though an unassured one, for some very curious or surprising (anomalous) observation stated in a premise. As early as 1865 he wrote that all conceptions of cause and force are reached through hypothetical inference; in the 1900s he wrote that all explanatory content of theories is reached through abduction. In other respects Peirce revised his view of abduction over the years.
In later years his view came to be:
Writing in 1910, Peirce admits that "in almost everything I printed before the beginning of this century I more or less mixed up hypothesis and induction" and he traces the confusion of these two types of reasoning to logicians' too "narrow and formalistic a conception of inference, as necessarily having formulated judgments from its premises."
He started out in the 1860s treating hypothetical inference in a number of ways which he eventually peeled away as inessential or, in some cases, mistaken:
1867.
In 1867, Peirce's "The Natural Classification of Arguments", hypothetical inference always deals with a cluster of characters (call them "P′, P′′, P′′′," etc.) known to occur at least whenever a certain character ("M") occurs. Note that categorical syllogisms have elements traditionally called middles, predicates, and subjects. For example: All "men" are "mortal" [predicate; "Socrates" is a "man" [middle; ergo "Socrates" is "mortal" [predicate". Below, 'M' stands for a middle; 'P' for a predicate; 'S' for a subject. Note also that Peirce held that all deduction can be put into the form of the categorical syllogism Barbara (AAA-1).
1878.
In 1878, in "Deduction, Induction, and Hypothesis", there is no longer a need for multiple characters or predicates in order for an inference to be hypothetical, although it is still helpful. Moreover, Peirce no longer poses hypothetical inference as concluding in a "probable" hypothesis. In the forms themselves, it is understood but not explicit that induction involves random selection and that hypothetical inference involves response to a "very curious circumstance". The forms instead emphasize the modes of inference as rearrangements of one another's propositions (without the bracketed hints shown below).
1883.
Peirce long treated abduction in terms of induction from characters or traits (weighed, not counted like objects), explicitly so in his influential 1883 "A Theory of Probable Inference", in which he returns to involving probability in the hypothetical conclusion. Like "Deduction, Induction, and Hypothesis" in 1878, it was widely read (see the historical books on statistics by Stephen Stigler), unlike his later amendments of his conception of abduction. Today abduction remains most commonly understood as induction from characters and extension of a known rule to cover unexplained circumstances.
Sherlock Holmes uses this method of reasoning in the stories of Arthur Conan Doyle, although Holmes refers to it as deductive reasoning.
1902 and after.
In 1902 Peirce wrote that he now regarded the syllogistical forms and the doctrine of extension and comprehension (i.e., objects and characters as referenced by terms), as being less fundamental than he had earlier thought. In 1903 he offered the following form for abduction: 
The hypothesis is framed, but not asserted, in a premise, then asserted as rationally suspectable in the conclusion. Thus, as in the earlier categorical syllogistic form, the conclusion is formulated from some premise(s). But all the same the hypothesis consists more clearly than ever in a new or outside idea beyond what is known or observed. Induction in a sense goes beyond observations already reported in the premises, but it merely amplifies ideas already known to represent occurrences, or tests an idea supplied by hypothesis; either way it requires previous abductions in order to get such ideas in the first place. Induction seeks facts to test a hypothesis; abduction seeks a hypothesis to account for facts.
Note that the hypothesis ("A") could be of a rule. It need not even be a rule strictly necessitating the surprising observation ("C"), which needs to follow only as a "matter of course"; or the "course" itself could amount to some known rule, merely alluded to, and also not necessarily a rule of strict necessity. In the same year, Peirce wrote that reaching a hypothesis may involve placing a surprising observation under either a newly hypothesized rule or a hypothesized combination of a known rule with a peculiar state of facts, so that the phenomenon would be not surprising but instead either necessarily implied or at least likely.
Peirce did not remain quite convinced about any such form as the categorical syllogistic form or the 1903 form. In 1911, he wrote, "I do not, at present, feel quite convinced that any logical form can be assigned that will cover all 'Retroductions'. For what I mean by a Retroduction is simply a conjecture which arises in the mind."
Pragmatism.
In 1901 Peirce wrote, "There would be no logic in imposing rules, and saying that they ought to be followed, until it is made out that the purpose of hypothesis requires them." In 1903 Peirce called pragmatism "the logic of abduction" and said that the pragmatic maxim gives the necessary and sufficient logical rule to abduction in general. The pragmatic maxim is: "Consider what effects, that might conceivably have practical bearings, we conceive the object of our conception to have. Then, our conception of these effects is the whole of our conception of the object." It is a method for fruitful clarification of conceptions by equating the meaning of a conception with the conceivable practical implications of its object's conceived effects. Peirce held that that is precisely tailored to abduction's purpose in inquiry, the forming of an idea that could conceivably shape informed conduct. In various writings in the 1900s he said that the conduct of abduction (or retroduction) is governed by considerations of economy, belonging in particular to the economics of research. He regarded economics as a normative science whose analytic portion might be part of logical methodeutic (that is, theory of inquiry).
Three levels of logic about abduction.
Peirce came over the years to divide (philosophical) logic into three departments: 
Peirce had, from the start, seen the modes of inference as being coordinated together in scientific inquiry and, by the 1900s, held that hypothetical inference in particular is inadequately treated at the level of critique of arguments. To increase the assurance of a hypothetical conclusion, one needs to deduce implications about evidence to be found, predictions which induction can test through observation so as to evaluate the hypothesis. That is Peirce's outline of the scientific method of inquiry, as covered in his inquiry methodology, which includes pragmatism or, as he later called it, pragmaticism, the clarification of ideas in terms of their conceivable implications regarding informed practice.
Classification of signs.
As early as 1866, Peirce held that:
1. Hypothesis (abductive inference) is inference through an "icon" (also called a "likeness"). <br>
2. Induction is inference through an "index" (a sign by factual connection); a sample is an index of the totality from which it is drawn. <br>
3. Deduction is inference through a "symbol" (a sign by interpretive habit irrespective of resemblance or connection to its object).
In 1902, Peirce wrote that, in abduction: "It is recognized that the phenomena are "like", i.e. constitute an Icon of, a replica of a general conception, or Symbol."
Critique of arguments.
At the critical level Peirce examined the forms of abductive arguments (as discussed above), and came to hold that the hypothesis should economize explanation for plausibility in terms of the feasible and natural. In 1908 Peirce described this plausibility in some detail. It involves not likeliness based on observations (which is instead the inductive evaluation of a hypothesis), but instead optimal simplicity in the sense of the "facile and natural", as by Galileo's natural light of reason and as distinct from "logical simplicity" (Peirce does not dismiss logical simplicity entirely but sees it in a subordinate role; taken to its logical extreme it would favor adding no explanation to the observation at all). Even a well-prepared mind guesses oftener wrong than right, but our guesses succeed better than random luck at reaching the truth or at least advancing the inquiry, and that indicates to Peirce that they are based in instinctive attunement to nature, an affinity between the mind's processes and the processes of the real, which would account for why appealingly "natural" guesses are the ones that oftenest (or least seldom) succeed; to which Peirce added the argument that such guesses are to be preferred since, without "a natural bent like nature's", people would have no hope of understanding nature. In 1910 Peirce made a three-way distinction between probability, verisimilitude, and plausibility, and defined plausibility with a normative "ought": "By plausibility, I mean the degree to which a theory ought to recommend itself to our belief independently of any kind of evidence other than our instinct urging us to regard it favorably." For Peirce, plausibility does not depend on observed frequencies or probabilities, or on verisimilitude, or even on testability, which is not a question of the critique of the hypothetical inference "as" an inference, but rather a question of the hypothesis's relation to the inquiry process.
The phrase "inference to the best explanation" (not used by Peirce but often applied to hypothetical inference) is not always understood as referring to the most simple and natural. However, in other senses of "best", such as "standing up best to tests", it is hard to know which is the best explanation to form, since one has not tested it yet. Still, for Peirce, any justification of an abductive inference as good is not completed upon its formation as an argument (unlike with induction and deduction) and instead depends also on its methodological role and promise (such as its testability) in advancing inquiry.
Methodology of inquiry.
At the methodeutical level Peirce held that a hypothesis is judged and selected for testing because it offers, via its trial, to expedite and economize the inquiry process itself toward new truths, first of all by being testable and also by further economies, in terms of cost, value, and relationships among guesses (hypotheses). Here, considerations such as probability, absent from the treatment of abduction at the critical level, come into play. For examples:
Other writers.
Norwood Russell Hanson, a philosopher of science, wanted to grasp a logic explaining how scientific discoveries take place. He used Peirce's notion of abduction for this.
Further development of the concept can be found in Peter Lipton's "Inference to the Best Explanation" (Lipton, 1991).
Applications.
Applications in artificial intelligence include fault diagnosis, belief revision, and automated planning. The most direct application of abduction is that of automatically detecting faults in systems: given a theory relating faults with their effects and a set of observed effects, abduction can be used to derive sets of faults that are likely to be the cause of the problem.
In medicine, abduction can be seen as a component of clinical evaluation and judgment.
Abduction can also be used to model automated planning. Given a logical theory relating action occurrences with their effects (for example, a formula of the event calculus), the problem of finding a plan for reaching a state can be modeled as the problem of abducting a set of literals implying that the final state is the goal state.
In intelligence analysis, Analysis of Competing Hypotheses and Bayesian networks, probabilistic abductive reasoning is used extensively. Similarly in medical diagnosis and legal reasoning, the same methods are being used, although there have been many examples of errors, especially caused by the base rate fallacy and the prosecutor's fallacy.
Belief revision, the process of adapting beliefs in view of new information, is another field in which abduction has been applied. The main problem of belief revision is that the new information may be inconsistent with the corpus of beliefs, while the result of the incorporation cannot be inconsistent. This process can be done by the use of abduction: once an explanation for the observation has been found, integrating it does not generate inconsistency. This use of abduction is not straightforward, as adding propositional formulae to other propositional formulae can only make inconsistencies worse. Instead, abduction is done at the level of the ordering of preference of the possible worlds. Preference models use fuzzy logic or utility models.
In the philosophy of science, abduction has been the key inference method to support scientific realism, and much of the debate about scientific realism is focused on whether abduction is an acceptable method of inference.
In historical linguistics, abduction during language acquisition is often taken to be an essential part of processes of language change such as reanalysis and analogy.
In anthropology, Alfred Gell in his influential book "Art and Agency" defined abduction (after Eco) as "a case of synthetic inference 'where we find some very curious circumstances, which would be explained by the supposition that it was a case of some general rule, and thereupon adopt that supposition". Gell criticizes existing 'anthropological' studies of art, for being too preoccupied with aesthetic value and not preoccupied enough with the central anthropological concern of uncovering 'social relationships,' specifically the social contexts in which artworks are produced, circulated, and received. Abduction is used as the mechanism for getting from art to agency. That is, abduction can explain how works of art inspire a "sensus communis:" the commonly-held views shared by members that characterize a given society. The question Gell asks in the book is, 'how does it initially 'speak' to people?' He answers by saying that "No reasonable person could suppose that art-like relations between people and things do not involve at least some form of semiosis." However, he rejects any intimation that semiosis can be thought of as a language because then he would have to admit to some pre-established existence of the "sensus communis" that he wants to claim only emerges afterwards out of art. Abduction is the answer to this conundrum because the tentative nature of the abduction concept (Peirce likened it to guessing) means that not only can it operate outside of any pre-existing framework, but moreover, it can actually intimate the existence of a framework. As Gell reasons in his analysis, the physical existence of the artwork prompts the viewer to perform an abduction that imbues the artwork with intentionality. A statue of a goddess, for example, in some senses actually becomes the goddess in the mind of the beholder; and represents not only the form of the deity but also her intentions (which are adduced from the feeling of her very presence). Therefore, through abduction, Gell claims that art can have the kind of agency that plants the seeds that grow into cultural myths. The power of agency is the power to motivate actions and inspire ultimately the shared understanding that characterizes any given society.

</doc>
<doc id="60467" url="https://en.wikipedia.org/wiki?curid=60467" title="Abnormal end">
Abnormal end

An AbEnd (also "ab"normal "end" or abend) is an abnormal termination of software, or a program crash.
This usage derives from an error message from the IBM OS/360, IBM zOS operating systems. Usually capitalized, but may appear as "abend". It is jocularly claimed to be derived from the German word "Abend" meaning "evening". Folklore stories from IBM also refer to the IBM language JCL being developed during the abortion debate in the United States. In a very early form of being politically correct, IBM revised any JCL that referred to ABORT to ABEND.
The most common were ABEND 0C7 (Data exception) and ABEND 0CB (Division by zero)
Errors or crashes on the Novell NetWare network operating system are usually called ABENDs. Communities of NetWare administrators have sprung up around the Internet, such as abend.org.

</doc>
<doc id="60470" url="https://en.wikipedia.org/wiki?curid=60470" title="ABI">
ABI

ABI or Abi may refer to:

</doc>
<doc id="60471" url="https://en.wikipedia.org/wiki?curid=60471" title="Application binary interface">
Application binary interface

In computer software, an application binary interface (ABI) is the interface between two program modules, one of which is often a library or operating system, at the level of machine code. An ABI determines such details as how functions are called and in which binary format information should be passed from one program component to the next, or to the operating system in the case of a system call.
Adhering to ABIs (which may or may not be officially standardized) is usually the job of the compiler, OS or library writer, but application programmers may have to deal with ABIs directly when writing programs in a mix of programming languages, using foreign function call interfaces between them.
ABIs differ from application programming interfaces (APIs), which similarly define interfaces between program components, but at the source code level.
Description.
ABIs cover details such as:
A complete ABI, such as the Intel Binary Compatibility Standard (iBCS), allows a program from one operating system supporting that ABI to run without modifications on any other such system, provided that necessary shared libraries are present, and similar prerequisites are fulfilled.
Other ABIs standardize details such as the C++ name mangling, exception propagation, and calling convention between compilers on the same platform, but do not require cross-platform compatibility.
Embedded-application binary interface.
An embedded-application binary interface (EABI) specifies standard conventions for file formats, data types, register usage, stack frame organization, and function parameter passing of an embedded software program.
Compilers that support the EABI create object code that is compatible with code generated by other such compilers, allowing developers to link libraries generated with one compiler with object code generated with another compiler. Developers writing their own assembly language code may also use the EABI to interface with assembly generated by a compliant compiler.
The main differences between an EABI and an ABI for general-purpose operating systems are that privileged instructions are allowed in application code, dynamic linking is not required (sometimes it is completely disallowed), and a more compact stack frame organization is used to save memory. The choice of EABI can affect performance.
Widely used EABIs include PowerPC, ARM EABI2 and MIPS EABI.

</doc>
<doc id="60474" url="https://en.wikipedia.org/wiki?curid=60474" title="Asynchronous Balanced Mode">
Asynchronous Balanced Mode

Asynchronous Balanced Mode (ABM) is a communication mode of HDLC and derivative protocols, supporting peer-oriented point-to-point communications between two nodes, where either node can initiate transmission.
For systems that work in the ABM (Asynchronous Balanced Mode), there is no master/slave relationship. Each station may initialize, supervise, recover from errors, and send frames at any time. The DTE (Data Terminal Equipment) and DCE (Data circuit-terminating equipment) are treated as equals. The initiator for Asynchronous Balanced Mode sends an SABM.

</doc>
<doc id="60476" url="https://en.wikipedia.org/wiki?curid=60476" title="Augmented Backus–Naur Form">
Augmented Backus–Naur Form

In computer science, Augmented Backus–Naur Form (ABNF) is a metalanguage based on Backus–Naur Form (BNF), but consisting of its own syntax and derivation rules. The motive principle for ABNF is to describe a formal system of a language to be used as a bidirectional communications protocol. It is defined by "Internet Standard 68" ("STD 68", type case sic), which is RFC 5234, and it often serves as the definition language for IETF communication protocols.
RFC 5234 supersedes RFC 4234 (which superseded RFC 2234 and RFC 733). RFC 7405 updates it, adding a syntax for specifying case-sensitive string literals.
Introduction.
An ABNF specification is a set of derivation rules, written as
where rule is a case-insensitive nonterminal, the definition consists of sequences of symbols that define the rule, a comment for documentation, and ending with a carriage return and line feed.
Rule names are case insensitive: codice_1, codice_2, codice_3, and codice_4 all refer to the same rule. Rule names consist of a letter followed by letters, numbers, and hyphens.
Angle brackets (“codice_5”, “codice_6”) are not required around rule names (as they are in BNF). However they may be used to delimit a rule name when used in prose to discern a rule name.
Terminal values.
Terminals are specified by one or more numeric characters.
Numeric characters may be specified as the percent sign “codice_7”, followed by the base (b = binary, d = decimal, and x = hexadecimal), followed by the value, or concatenation of values (indicated by “codice_8”). For example, a carriage return is specified by codice_9 in decimal or codice_10 in hexadecimal. A carriage return followed by a line feed may be specified with concatenation as codice_11.
Literal text is specified through the use of a string enclosed in quotation marks (codice_12). These strings are case-insensitive and the character set used is (US-)ASCII. Therefore, the string “abc” will match “abc”, “Abc”, “aBc”, “abC”, “ABc”, “AbC”, “aBC”, and “ABC”. RFC 7405 added a syntax for case-sensitive strings: codice_13 will only match "aBc". Prior to that, a case-sensitive string could only be specified by listing the individual characters: to match “aBc” the definition would be codice_14. A string can also be explicitly specified as case-insensitive with a codice_15 prefix.
Operators.
White space.
White space is used to separate elements of a definition; for space to be recognized as a delimiter it must be explicitly included. The explicit reference for a single whitepace character is WSP (linear white space), or LWSP for zero or more whitespace characters with newlines permitted. The LWSP definition in RFC5234 controversial because at least one whitespace character is needed to form a delimiter two fields.
Definitions are left-aligned. When multiple lines are required (for readability) continuation lines are indented by whitespace.
Comment.
codice_16
A semicolon (“codice_17”) starts a comment that continues to the end of the line.
Concatenation.
codice_18
A rule may be defined by listing a sequence of rule names.
To match the string “aba” the following rules could be used:
Alternative.
codice_22
A rule may be defined by a list of alternative rules separated by a solidus ("codice_23").
To accept the rule "fu" or the rule "bar" the following rule could be constructed:
Incremental alternatives.
codice_25
Additional alternatives may be added to a rule through the use of “codice_26” between the rule name and the definition.
The rule
is equivalent to 
Value range.
codice_31
A range of numeric values may be specified through the use of a hyphen (“codice_32”).
The rule
is equivalent to
Sequence group.
codice_35
Elements may be placed in parentheses to group rules in a definition.
To match “elem fubar snafu” or “elem tarfu snafu” the following rule could be constructed:
To match “elem fubar” or “tarfu snafu” the following rules could be constructed:
Variable repetition.
codice_39
To indicate repetition of an element the form codice_40 is used. The optional codice_41 gives the minimum number of elements to be included with the default of 0. The optional codice_41 gives the maximum number of elements to be included with the default of infinity.
Use codice_40 for zero or more elements, codice_44 for zero or one element, codice_45 for one or more elements, and codice_46 for two or three elements, cf. regular expressions codice_47, codice_48, codice_49 and codice_50.
Specific repetition.
codice_51
To indicate an explicit number of elements the form codice_52 is used and is equivalent to codice_40.
Use codice_54 to get two numeric digits and codice_55 to get three numeric digits. (DIGIT is defined below under 'Core rules'. Also see "zip-code" in the example below.)
Optional sequence.
codice_41
To indicate an optional element the following constructions are equivalent:
Operator precedence.
The following operators have the given precedence from tightest binding to loosest binding:
Use of the alternative operator with concatenation may be confusing and it is recommended that grouping be used to make explicit concatenation groups.
Core rules.
The core rules are defined in the ABNF standard.
Example.
The postal address example given in the Backus–Naur Form (BNF) page may be specified as follows:
Pitfalls.
RFC 5234 adds a warning in conjunction to the definition of LWSP as follows: 

</doc>
<doc id="60478" url="https://en.wikipedia.org/wiki?curid=60478" title="Abort (computing)">
Abort (computing)

In a computer or data transmission system, to abort means to , usually in a controlled manner, a processing activity because it is impossible or undesirable for the activity to proceed. Such an action may be accompanied by information on the aborted process.
In addition to being a verb, abort also has two noun senses. In the most general case, the event of aborting can be referred to as an abort. Sometimes the event of aborting can be given a special name, as in the case of an abort involving a Unix kernel where it is known as a kernel panic. Specifically in the context of data transmission, an abort is a function invoked by a sending station to cause the recipient to discard or ignore all bit sequences transmitted by the sender since the preceding flag sequence.
In the C programming language, codice_1 is a standard library function that terminates the current application and returns an error code.

</doc>
<doc id="60481" url="https://en.wikipedia.org/wiki?curid=60481" title="Alternating bit protocol">
Alternating bit protocol

Alternating bit protocol (ABP) is a simple network protocol operating at the data link layer that retransmits lost or corrupted messages. It can be seen as a special case of the Sliding window protocol where a simple timer restricts the order of messages to ensure receivers send messages in turn while using a window of 1 bit.
Messages are sent from transmitter A to receiver B. Assume that the channel from A to B is initialized and that there are no messages in transit. Each message from A to B contains a data part and a one-bit sequence number, i.e., a value that is 0 or 1. B has two acknowledge characters that it can send to A: ACK0 and ACK1.
When A sends a message, it resends it continuously, with the same sequence number, until it receives an acknowledgment from B that contains the same sequence number. When that happens, A complements (flips) the sequence number and starts transmitting the next message.
When B receives a message that is not corrupted and has sequence number 0, it starts sending ACK0 and keeps doing so until it receives a valid message with number 1. Then it starts sending ACK1, etc.
This means that A may still receive ACK0 when it is already transmitting messages with sequence number one. (And vice versa.) It treats such messages as negative-acknowledge characters (NAKs). The simplest behaviour is to ignore them all and continue transmitting.
The protocol may be initialized by sending bogus messages and acks with sequence number 1. The first message with sequence number 0 is a real message.

</doc>
<doc id="60483" url="https://en.wikipedia.org/wiki?curid=60483" title="ABR">
ABR

Abr or ABR may refer to:
Technology:
Transport:
Other uses:

</doc>
<doc id="60486" url="https://en.wikipedia.org/wiki?curid=60486" title="Automatic baud rate detection">
Automatic baud rate detection

Automatic baud rate detection (ABR, autobaud) refers to the process by which a receiving device (such as a modem) determines the speed, code level, and stop bits of incoming data by examining the first character, usually a preselected sign-on character (syncword). ABR allows the receiving device to accept data from a variety of transmitting devices operating at different speeds without needing to establish data rates in advance. 

</doc>
<doc id="60487" url="https://en.wikipedia.org/wiki?curid=60487" title="Abscissa">
Abscissa

Etymology.
Though the word "abscissa" (Latin; "linea abscissa", "a line cut off") has been used at least since "De Practica Geometrie" published in 1220 by Fibonacci (Leonardo of Pisa), its use in its modern sense may be due to Venetian mathematician Stefano degli Angeli in his work "Miscellaneum Hyperbolicum, et Parabolicum" of 1659.
In his 1892 work "Vorlesungen über Geschichte der Mathematik, Volume 2," (""Lectures on history of mathematics"") German historian of mathematics Moritz Cantor writes
In parametric equations.
In a somewhat obsolete variant usage, the abscissa of a point may also refer to any number that describes the point's location along some path, e.g. the parameter of a parametric equation. Used in this way, the abscissa can be thought of as a coordinate-geometry analog to the independent variable in a mathematical model or experiment (with any ordinates filling a role analogous to dependent variables).

</doc>
<doc id="60490" url="https://en.wikipedia.org/wiki?curid=60490" title="Abstract interpretation">
Abstract interpretation

In computer science, abstract interpretation is a theory of sound approximation of the semantics of computer programs, based on monotonic functions over ordered sets, especially lattices. It can be viewed as a partial execution of a computer program which gains information about its semantics (e.g., control-flow, data-flow) without performing all the calculations.
Its main concrete application is formal static analysis, the automatic extraction of information about the possible executions of computer programs; such analyses have two main usages:
Abstract interpretation was formalized by the French computer scientists Patrick Cousot and Radhia Cousot in the late 1970s.
Intuition.
This section illustrates abstract interpretation by means of real-world, non-computing examples.
Consider the people in a conference room. Assume a unique identifier for each person in the room, like a social security number in the United States. To prove that someone is not present, all one needs to do is see if their social security number is not on the list. Since two different people cannot have the same number, it is possible to prove or disprove the presence of a participant simply by looking up his or her number.
However it is possible that only the names of attendees were registered. If the name of a person is not found in the list, we may safely conclude that that person was not present; but if it is, we cannot conclude definitely without further inquiries, due to the possibility of homonyms (for example, two people named John Smith). Note that this imprecise information will still be adequate for most purposes, because homonyms are rare in practice. However, in all rigor, we cannot say for sure that somebody was present in the room; all we can say is that he or she was "possibly" here. If the person we are looking up is a criminal, we will issue an "alarm"; but there is of course the possibility of issuing a "false alarm". Similar phenomena will occur in the analysis of programs.
If we are only interested in some specific information, say, "was there a person of age "n" in the room?", keeping a list of all names and dates of births is unnecessary. We may safely and without loss of precision restrict ourselves to keeping a list of the participants' ages. If this is already too much to handle, we might keep only the age of the youngest, "m" and oldest person, "M". If the question is about an age strictly lower than "m" or strictly higher than "M", then we may safely respond that no such participant was present. Otherwise, we may only be able to say that we do not know.
In the case of computing, concrete, precise information is in general not computable within finite time and memory (see Rice's theorem and the halting problem). Abstraction is used to allow for generalized answers to questions (for example, answering "maybe" to a yes/no question, meaning "yes or no" - when we (an algorithm of abstract interpretation) cannot compute the precise answer with certainty); this simplifies the problems, making them amenable to automatic solutions. One crucial requirement is to add enough vagueness so as to make problems manageable while still retaining enough precision for answering the important questions (such as "may the program crash?").
Abstract interpretation of computer programs.
Given a programming or specification language, abstract interpretation consists of giving several semantics linked by relations of abstraction. A semantics is a mathematical characterization of a possible behavior of the program. The most precise semantics, describing very closely the actual execution of the program, are called the concrete semantics. For instance, the concrete semantics of an imperative programming language may associate to each program the set of execution traces it may produce – an execution trace being a sequence of possible consecutive states of the execution of the program; a state typically consists of the value of the program counter and the memory locations (globals, stack and heap). More abstract semantics are then derived; for instance, one may consider only the set of reachable states in the executions (which amounts to considering the last states in finite traces).
The goal of static analysis is to derive a computable semantic interpretation at some point. For instance, one may choose to represent the state of a program manipulating integer variables by forgetting the actual values of the variables and only keeping their signs (+, − or 0). For some elementary operations, such as multiplication, such an abstraction does not lose any precision: to get the sign of a product, it is sufficient to know the sign of the operands. For some other operations, the abstraction may lose precision: for instance, it is impossible to know the sign of a sum whose operands are respectively positive and negative.
Sometimes a loss of precision is necessary to make the semantics decidable (see Rice's theorem, halting problem). In general, there is a compromise to be made between the precision of the analysis and its decidability (computability), or tractability (complexity).
In practice the abstractions that are defined are tailored to both the program properties one desires to analyze, and to the set of target programs. The first large scale automated analysis of computer programs with abstract interpretation can be attributed to an accident that resulted in the destruction of the first flight of the Ariane 5 rocket in 1996.
Formalization.
Let "L" be an ordered set, called a concrete set and let "L"′ be another ordered set, called an abstract set. These two sets are related to each other by defining total functions that map elements from one to the other.
A function α is called an abstraction function if it maps an element "x" in the concrete set "L" to an element α("x") in the abstract set "L"′. That is, element α("x") in "L"′ is the abstraction of "x" in "L".
A function γ is called a concretization function if it maps an element "x"′ in the abstract set "L"′ to an element γ("x"′) in the concrete set "L". That is, element γ("x"′) in "L" is a concretization of "x"′ in "L"′.
Let "L"1, "L"2, "L"′1 and "L"′2 be ordered sets. The concrete semantics "f" is a monotonic function from "L"1 to "L"2. A function "f"′ from "L"′1 to "L"′2 is said to be a valid abstraction of "f" if for all "x"′ in "L"′1, ("f" ∘ γ)("x"′) ≤ (γ ∘ "f"′)("x"′).
Program semantics are generally described using fixed points in the presence of loops or recursive procedures. Let us suppose that "L" is a complete lattice and let "f" be a monotonic function from "L" into "L". Then, any "x"′ such that "f"("x"′) ≤ "x"′ is an abstraction of the least fixed-point of "f", which exists, according to the Knaster–Tarski theorem.
The difficulty is now to obtain such an "x"′. If "L"′ is of finite height, or at least verifies the ascending chain condition (all ascending sequences are ultimately stationary), then such an "x"′ may be obtained as the stationary limit of the ascending sequence "x"′"n" defined by induction as follows: "x"′0=⊥ (the least element of "L"′) and "x"′"n"+1="f"′("x"′"n").
In other cases, it is still possible to obtain such an "x"′ through a widening operator ∇: for all "x" and "y", "x" ∇ "y" should be greater or equal than both "x" and "y", and for any sequence "y"′"n", the sequence defined by "x"′0=⊥ and "x"′"n"+1="x"′"n" ∇ "y"′"n" is ultimately stationary. We can then take "y"′"n"="f"′("x"′"n").
In some cases, it is possible to define abstractions using Galois connections (α, γ) where α is from "L" to "L"′ and γ is from "L"′ to "L". This supposes the existence of best abstractions, which is not necessarily the case. For instance, if we abstract sets of couples ("x", "y") of real numbers by enclosing convex polyhedra, there is no optimal abstraction to the disc defined by "x"2+"y"2 ≤ 1.
Examples of abstract domains.
One can assign to each variable "x" available at a given program point an interval ["L""x", "H""x"]. A state assigning the value "v"("x") to variable "x" will be a concretization of these intervals if for all "x", "v"("x") is in ["L""x", "H""x"]. From the intervals ["L""x", "H""x"] and ["L""y", "H""y"] for variables "x" and "y", one can easily obtain intervals for "x"+"y" (["L""x"+"L""y", "H""x"+"H""y"]) and for "x"−"y" (["L""x"−"H""y", "H""x"−"L""y"]); note that these are "exact" abstractions, since the set of possible outcomes for, say, "x"+"y", is precisely the interval (["L""x"+"L""y", "H""x"+"H""y"]). More complex formulas can be derived for multiplication, division, etc., yielding so-called interval arithmetics.
Let us now consider the following very simple program:
With reasonable arithmetic types, the result for z should be zero. But if we do interval arithmetic starting from x in 1, one gets z in [−1, +1]. While each of the operations taken individually was exactly abstracted, their composition isn't.
The problem is evident: we did not keep track of the equality relationship between x and y; actually, this domain of intervals does not take into account any relationships between variables, and is thus a non-relational domain. Non-relational domains tend to be fast and simple to implement, but imprecise.
Some examples of relational numerical abstract domains are:
and combinations thereof (cf. right picture).
When one chooses an abstract domain, one typically has to strike a balance between keeping fine-grained relationships, and high computational costs.
Tools.
Sound tools.
Sound tools guarantee that the verification they perform are correct and exhaustive. They can never yield false negatives, but by undecidability may produce false alarms (or false positive) signaling a potential error with no instance during any execution (because the static analysis is not precise enough to eliminate the potential error).
Unsound tools.
Unsound tools do not guarantee that the verification they perform are correct and exhaustive. They can yield false alarms/positive as well as false negative, not signaling an error that occur for at least one program execution, because the static analysis they perform is incorrect (i.e., they fail to consider some possible executions). As a consequence, they can falsely claim that an unsafe program is safe.

</doc>
<doc id="60491" url="https://en.wikipedia.org/wiki?curid=60491" title="Abstraction (software engineering)">
Abstraction (software engineering)

In software engineering and computer science, abstraction is a technique for managing complexity of computer systems. It works by establishing a level of complexity on which a person interacts with the system, suppressing the more complex details below the current level. The programmer works with an idealized interface (usually well defined) and can add additional levels of functionality that would otherwise be too complex to handle. For example, a programmer writing code that involves numerical operations may not be interested in the way numbers are represented in the underlying hardware (e.g. whether they're "16 bit" or "32 bit integers"), and where those details have been suppressed it can be said that they were "abstracted away", leaving simply "numbers" with which the programmer can work.
In addition, a task of sending an email message across continents would be extremely complex if you start with a piece of optic cable and basic hardware components. By using layers of complexity that have been created to abstract away the physical cables, network layout and presenting the programmer with a virtual data channel, this task is manageable.
Abstraction can apply to control or to data: Control abstraction is the abstraction of actions while data abstraction is that of data structures.
One can view the notion of an object as a way to combine abstractions of data and code.
The same abstract definition can be used as a common interface for a family of objects with different implementations and behaviors but which share the same meaning. The inheritance mechanism in object-oriented programming can be used to define an abstract class as the common interface.
The recommendation that programmers use abstractions whenever suitable in order to avoid duplication (usually of code) is known as the abstraction principle. The requirement that a programming language provide suitable abstractions is also called the abstraction principle.
Rationale.
Computing mostly operates independently of the concrete world: The hardware implements a model of computation that is interchangeable with others. The software is structured in architectures to enable humans to create the enormous systems by concentrating on a few issues at a time. These architectures are made of specific choices of abstractions. Greenspun's Tenth Rule is an aphorism on how such an architecture is both inevitable and complex.
A central form of abstraction in computing is language abstraction: new artificial languages are developed to express specific aspects of a system. "Modeling languages" help in planning. "Computer languages" can be processed with a computer. An example of this abstraction process is the generational development of programming languages from the machine language to the assembly language and the high-level language. Each stage can be used as a stepping stone for the next stage. The language abstraction continues for example in scripting languages and domain-specific programming languages.
Within a programming language, some features let the programmer create new abstractions. These include subroutines, modules, polymorphism, and software components. Some other abstractions such as software design patterns and architectural styles remain invisible to a programming language and operate only in the design of a system.
Some abstractions try to limit the breadth of concepts a programmer needs by completely hiding the abstractions that in turn are built on. The software engineer and writer Joel Spolsky has criticised these efforts by claiming that all abstractions are "leaky" — that they can never completely hide the details below; however this does not negate the usefulness of abstraction. Some abstractions are designed to interoperate with others, for example a programming language may contain a foreign function interface for making calls to the lower-level language.
Data abstraction is the separation between the specification of data object and its implementation.
Language features.
Programming languages.
Different programming languages provide different types of abstraction, depending on the intended applications for the language. For example:
Specification methods.
Analysts have developed various methods to formally specify software systems. Some known methods include:
Specification languages.
Specification languages generally rely on abstractions of one kind or another, since specifications are typically defined earlier in a project, (and at a more abstract level) than an eventual implementation. The UML specification language, for example, allows the definition of "abstract" classes, which remain abstract during the architecture and specification phase of the project.
Control abstraction.
Programming languages offer control abstraction as one of the main purposes of their use. Computer machines understand operations at the very low level such as moving some bits from one location of the memory to another location and producing the sum of two sequences of bits. Programming languages allow this to be done in the higher level. For example, consider this statement written in a Pascal-like fashion:
To a human, this seems a fairly simple and obvious calculation (""one plus two is three, times five is fifteen""). However, the low-level steps necessary to carry out this evaluation, and return the value "15", and then assign that value to the variable "a", are actually quite subtle and complex. The values need to be converted to binary representation (often a much more complicated task than one would think) and the calculations decomposed (by the compiler or interpreter) into assembly instructions (again, which are much less intuitive to the programmer: operations such as shifting a binary register left, or adding the binary complement of the contents of one register to another, are simply not how humans think about the abstract arithmetical operations of addition or multiplication). Finally, assigning the resulting value of "15" to the variable labeled "a", so that "a" can be used later, involves additional 'behind-the-scenes' steps of looking up a variable's label and the resultant location in physical or virtual memory, storing the binary representation of "15" to that memory location, etc.
Without control abstraction, a programmer would need to specify "all" the register/binary-level steps each time they simply wanted to add or multiply a couple of numbers and assign the result to a variable. Such duplication of effort has two serious negative consequences:
Structured programming.
Structured programming involves the splitting of complex program tasks into smaller pieces with clear flow-control and interfaces between components, with reduction of the complexity potential for side-effects.
In a simple program, this may aim to ensure that loops have single or obvious exit points and (where possible) to have single exit points from functions and procedures.
In a larger system, it may involve breaking down complex tasks into many different modules. Consider a system which handles payroll on ships and at shore offices:
These layers produce the effect of isolating the implementation details of one component and its assorted internal methods from the others. Object-oriented programming embraces and extends this concept.
Data abstraction.
Data abstraction enforces a clear separation between the "abstract" properties of a data type and the "concrete" details of its implementation. The abstract properties are those that are visible to client code that makes use of the data type—the "interface" to the data type—while the concrete implementation is kept entirely private, and indeed can change, for example to incorporate efficiency improvements over time. The idea is that such changes are not supposed to have any impact on client code, since they involve no difference in the abstract behaviour.
For example, one could define an abstract data type called "lookup table" which uniquely associates "keys" with "values", and in which values may be retrieved by specifying their corresponding keys. Such a lookup table may be implemented in various ways: as a hash table, a binary search tree, or even a simple linear list of (key:value) pairs. As far as client code is concerned, the abstract properties of the type are the same in each case.
Of course, this all relies on getting the details of the interface right in the first place, since any changes there can have major impacts on client code. As one way to look at this: the interface forms a "contract" on agreed behaviour between the data type and client code; anything not spelled out in the contract is subject to change without notice.
Languages that implement data abstraction include Ada and Modula-2. Object-oriented languages are commonly claimed to offer data abstraction; however, their inheritance concept tends to put information in the interface that more properly belongs in the implementation; thus, changes to such information ends up impacting client code, leading directly to the Fragile binary interface problem.
Abstraction in object oriented programming.
In object-oriented programming theory, abstraction involves the facility to define objects that represent abstract "actors" that can perform work, report on and change their state, and "communicate" with other objects in the system. The term encapsulation refers to the hiding of state details, but extending the concept of "data type" from earlier programming languages to associate "behavior" most strongly with the data, and standardizing the way that different data types interact, is the beginning of abstraction. When abstraction proceeds into the operations defined, enabling objects of different types to be substituted, it is called polymorphism. When it proceeds in the opposite direction, inside the types or classes, structuring them to simplify a complex set of relationships, it is called delegation or inheritance.
Various object-oriented programming languages offer similar facilities for abstraction, all to support a general strategy of polymorphism in object-oriented programming, which includes the substitution of one type for another in the same or similar role. Although not as generally supported, a configuration or image or package may predetermine a great many of these bindings at compile-time, link-time, or loadtime. This would leave only a minimum of such bindings to change at run-time.
Common Lisp Object System or Self, for example, feature less of a class-instance distinction and more use of delegation for polymorphism. Individual objects and functions are abstracted more flexibly to better fit with a shared functional heritage from Lisp.
C++ exemplifies another extreme: it relies heavily on templates and overloading and other static bindings at compile-time, which in turn has certain flexibility problems.
Although these examples offer alternate strategies for achieving the same abstraction, they do not fundamentally alter the need to support abstract nouns in code - all programming relies on an ability to abstract verbs as functions, nouns as data structures, and either as processes.
Consider for example a sample Java fragment to represent some common farm "animals" to a level of abstraction suitable to model simple aspects of their hunger and feeding. It defines an codice_5 class to represent both the state of the animal and its functions:
With the above definition, one could create objects of type Animal and call their methods like this:
In the above example, the class "codice_5" is an abstraction used in place of an actual animal, "codice_7" is a further abstraction (in this case a generalisation) of "codice_5".
If one requires a more differentiated hierarchy of animals — to differentiate, say, those who provide milk from those who provide nothing except meat at the end of their lives — that is an intermediary level of abstraction, probably DairyAnimal (cows, goats) who would eat foods suitable to giving good milk, and MeatAnimal (pigs, steers) who would eat foods to give the best meat-quality.
Such an abstraction could remove the need for the application coder to specify the type of food, so s/he could concentrate instead on the feeding schedule. The two classes could be related using inheritance or stand alone, and the programmer could define varying degrees of polymorphism between the two types. These facilities tend to vary drastically between languages, but in general each can achieve anything that is possible with any of the others. A great many operation overloads, data type by data type, can have the same effect at compile-time as any degree of inheritance or other means to achieve polymorphism. The class notation is simply a coder's convenience.
Object-oriented design.
Decisions regarding what to abstract and what to keep under the control of the coder become the major concern of object-oriented design and domain analysis—actually determining the relevant relationships in the real world is the concern of object-oriented analysis or legacy analysis.
In general, to determine appropriate abstraction, one must make many small decisions about scope (domain analysis), determine what other systems one must cooperate with (legacy analysis), then perform a detailed object-oriented analysis which is expressed within project time and budget constraints as an object-oriented design. In our simple example, the domain is the barnyard, the live pigs and cows and their eating habits are the legacy constraints, the detailed analysis is that coders must have the flexibility to feed the animals what is available and thus there is no reason to code the type of food into the class itself, and the design is a single simple Animal class of which pigs and cows are instances with the same functions. A decision to differentiate DairyAnimal would change the detailed analysis but the domain and legacy analysis would be unchanged—thus it is entirely under the control of the programmer, and we refer to abstraction in object-oriented programming as distinct from abstraction in domain or legacy analysis.
Considerations.
When discussing formal semantics of programming languages, formal methods or abstract interpretation, abstraction refers to the act of considering a less detailed, but safe, definition of the observed program behaviors. For instance, one may observe only the final result of program executions instead of considering all the intermediate steps of executions. Abstraction is defined to a concrete (more precise) model of execution.
Abstraction may be exact or faithful with respect to a property if one can answer a question about the property equally well on the concrete or abstract model. For instance, if we wish to know what the result of the evaluation of a mathematical expression involving only integers +, -, ×, is worth modulo "n", we need only perform all operations modulo "n" (a familiar form of this abstraction is casting out nines).
Abstractions, however, though not necessarily exact, should be sound. That is, it should be possible to get sound answers from them—even though the abstraction may simply yield a result of undecidability. For instance, we may abstract the students in a class by their minimal and maximal ages; if one asks whether a certain person belongs to that class, one may simply compare that person's age with the minimal and maximal ages; if his age lies outside the range, one may safely answer that the person does not belong to the class; if it does not, one may only answer "I don't know".
The level of abstraction included in a programming language can influence its overall usability. The Cognitive dimensions framework includes the concept of "abstraction gradient" in a formalism. This framework allows the designer of a programming language to study the trade-offs between abstraction and other characteristics of the design, and how changes in abstraction influence the language usability.
Abstractions can prove useful when dealing with computer programs, because non-trivial properties of computer programs are essentially undecidable (see Rice's theorem). As a consequence, automatic methods for deriving information on the behavior of computer programs either have to drop termination (on some occasions, they may fail, crash or never yield out a result), soundness (they may provide false information), or precision (they may answer "I don't know" to some questions).
Abstraction is the core concept of abstract interpretation. Model checking generally takes place on abstract versions of the studied systems.
Levels of abstraction.
Computer science commonly presents "levels" (or, less commonly, "layers") of abstraction, wherein each level represents a different model of the same information and processes, but uses a system of expression involving a unique set of objects and compositions that apply only to a particular domain.
Each relatively abstract, "higher" level builds on a relatively concrete, "lower" level, which tends to provide an increasingly "granular" representation. For example, gates build on electronic circuits, binary on gates, machine language on binary, programming language on machine language, applications and operating systems on programming languages. Each level is embodied, but not determined, by the level beneath it, making it a language of description that is somewhat self-contained.
Database systems.
Since many users of database systems lack in-depth familiarity with computer data-structures, database developers often hide complexity through the following levels:
Physical level: The lowest level of abstraction describes "how" a system actually stores data. The physical level describes complex low-level data structures in detail.
Logical level: The next higher level of abstraction describes "what" data the database stores, and what relationships exist among those data. The logical level thus describes an entire database in terms of a small number of relatively simple structures. Although implementation of the simple structures at the logical level may involve complex physical level structures, the user of the logical level does not need to be aware of this complexity. This referred to as physical data independence. Database administrators, who must decide what information to keep in a database, use the logical level of abstraction.
View level: The highest level of abstraction describes only part of the entire database. Even though the logical level uses simpler structures, complexity remains because of the variety of information stored in a large database. Many users of a database system do not need all this information; instead, they need to access only a part of the database. The view level of abstraction exists to simplify their interaction with the system. The system may provide many views for the same database.
Layered architecture.
The ability to provide a design of different levels of abstraction can
Systems design and business process design can both use this. Some design processes specifically generate designs that contain various levels of abstraction.
Layered architecture partitions the concerns of the application into stacked groups (layers).
It is a technique used in designing computer software, hardware, and communications in which system or network components are isolated in layers so that changes can be made in one layer without affecting the others.

</doc>
<doc id="60492" url="https://en.wikipedia.org/wiki?curid=60492" title="Abstract machine">
Abstract machine

An abstract machine, also called an abstract computer, is a theoretical model of a computer hardware or software system used in automata theory. Abstraction of computing processes is used in both the computer science and computer engineering disciplines and usually assumes a discrete time paradigm.
Information.
In the theory of computation, abstract machines are often used in thought experiments regarding computability or to analyze the complexity of algorithms ("see" computational complexity theory). A typical abstract machine consists of a definition in terms of input, output, and the set of allowable operations used to turn the former into the latter. The best-known example is the Turing machine.
Abstract data types can be specified in terms of their operational semantics on an abstract machine. For example, a stack can be specified in terms of operations on an abstract machine with an array of memory.
More complex definitions create abstract machines with full instruction sets, registers and models of memory. One popular model more similar to real modern machines is the RAM model, which allows random access to indexed memory locations. As the performance difference between different levels of cache memory grows, cache-sensitive models such as the external-memory model and cache-oblivious model are growing in importance.
An abstract machine can also refer to a microprocessor design which has yet to be (or is not intended to be) implemented as hardware. An abstract machine implemented as a software simulation, or for which an interpreter exists, is called a virtual machine.
Through the use of abstract machines it is possible to compute the amount of resources (time, memory, etc.) necessary to perform a particular operation without having to construct an actual system to do it.

</doc>
<doc id="60496" url="https://en.wikipedia.org/wiki?curid=60496" title="194 BC">
194 BC

__NOTOC__
Year 194 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Africanus and Longus (or, less frequently, year 560 "Ab urbe condita"). The denomination 194 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Korea.
</onlyinclude>

</doc>
<doc id="60497" url="https://en.wikipedia.org/wiki?curid=60497" title="200 BC">
200 BC

__NOTOC__
Year 200 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Maximus and Cotta (or, less frequently, year 554 "Ab urbe condita"). The denomination 200 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Astronomy.
</onlyinclude>

</doc>
<doc id="60498" url="https://en.wikipedia.org/wiki?curid=60498" title="201 BC">
201 BC

__NOTOC__
Year 201 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Lentulus and Paetus (or, less frequently, year 553 "Ab urbe condita"). The denomination 201 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="60499" url="https://en.wikipedia.org/wiki?curid=60499" title="204 BC">
204 BC

__NOTOC__
Year 204 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Cethegus and Tuditanus (or, less frequently, year 550 "Ab urbe condita"). The denomination 204 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Seleucid Empire.
</onlyinclude>

</doc>
<doc id="60500" url="https://en.wikipedia.org/wiki?curid=60500" title="203 BC">
203 BC

__NOTOC__
Year 203 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Caepio and Geminus (or, less frequently, year 551 "Ab urbe condita"). The denomination 203 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Carthage.
</onlyinclude>

</doc>
<doc id="60501" url="https://en.wikipedia.org/wiki?curid=60501" title="199 BC">
199 BC

__NOTOC__
Year 199 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Lentulus and Tappulus (or, less frequently, year 555 "Ab urbe condita"). The denomination 199 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Roman Republic.
</onlyinclude>

</doc>
<doc id="60503" url="https://en.wikipedia.org/wiki?curid=60503" title="206 BC">
206 BC

__NOTOC__
Year 206 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Philo and Metellus (or, less frequently, year 548 "Ab urbe condita"). The denomination 206 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="60504" url="https://en.wikipedia.org/wiki?curid=60504" title="205 BC">
205 BC

__NOTOC__
Year 205 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Africanus and Dives (or, less frequently, year 549 "Ab urbe condita"). The denomination 205 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Egypt.
</onlyinclude>

</doc>
<doc id="60505" url="https://en.wikipedia.org/wiki?curid=60505" title="207 BC">
207 BC

__NOTOC__
Year 207 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Nero and Salinator (or, less frequently, year 547 "Ab urbe condita"). The denomination 207 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="60506" url="https://en.wikipedia.org/wiki?curid=60506" title="208 BC">
208 BC

__NOTOC__
Year 208 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Marcellus and Crispinus (or, less frequently, year 546 "Ab urbe condita"). The denomination 208 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="60507" url="https://en.wikipedia.org/wiki?curid=60507" title="209 BC">
209 BC

__NOTOC__
Year 209 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Verrucosus and Flaccus (or, less frequently, year 545 "Ab urbe condita"). The denomination 209 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Central Asia.
</onlyinclude>

</doc>
<doc id="60508" url="https://en.wikipedia.org/wiki?curid=60508" title="Pinball">
Pinball

Pinball is a type of arcade game, usually coin-operated, in which points are scored by a player manipulating one or more steel balls on a play field inside a glass-covered cabinet called a pinball machine. The primary objective of the game is to score as many points as possible. Many modern pinball machines include a story line where the player must complete certain objectives in a certain fashion to complete the story, usually earning high scores for different methods of completing the game. Points are earned when the ball strikes different targets on the play field. A drain is situated at the bottom of the play field, partially protected by player-controlled plastic bats called flippers. A game ends after all the balls fall into the drain. Secondary objectives are to maximize the time spent playing (by earning "extra balls" and keeping the ball in play as long as possible) and to earn bonus games (known as "replays").
History.
Pre-modern: Development of outdoor and tabletop ball games.
The origins of pinball are intertwined with the history of many other games. Games played outdoors by rolling balls or stones on a grass course, such as bocce or bowls, eventually evolved into various local ground billiards games played by hitting the balls with sticks and propelling them at targets, often around obstacles. Croquet, golf and paille-maille eventually derived from ground billiards variants.
The evolving and specializing outdoor games finally led to indoor versions that could be played on a table, such as billiards, or on the floor of a pub, like bowling and shuffleboard. The tabletop versions of these games became the ancestors of modern pinball.
Late 1700s: Spring launcher invented.
In France, during the long 1643–1715 reign of Louis XIV, billiard tables were narrowed, with wooden pins or skittles at one end of the table, and players would shoot balls with a stick or cue from the other end, in a game inspired as much by bowling as billiards. Pins took too long to reset when knocked down, so they were eventually fixed to the table, and holes in the bed of the table became the targets. Players could ricochet balls off the pins to achieve the harder scorable holes. A standardized version of the game eventually became known as bagatelle.
Somewhere between the 1750s and 1770s, the bagatelle variant "" 'Japanese billiards' was invented (in Western Europe, despite the name), which used thin metal pins and replaced the cue at the player's end of the table with a coiled spring and a plunger. The player shot balls up the inclined playfield toward the scoring targets using this plunger, a device that remains in use in pinball to this day, and the game was also directly ancestral to pachinko.
1869: Spring launchers become mainstream.
In 1869, British inventor Montague Redgrave settled in the US and manufactured bagatelle tables in Cincinnati, Ohio. In 1871 Redgrave was granted US Patent #115,357 for his "Improvements in Bagatelle", another name for the spring launcher that was first introduced in "". The game also shrank in size to fit atop a bar or counter. The balls became marbles and the wickets became small metal pins. Redgrave's popularization of the spring launcher and innovations in game design are acknowledged as the birth of pinball in its modern form.
1931: Coin operation introduced.
By the 1930s, manufacturers were producing coin-operated versions of bagatelles, now known as "marble games" or "pin games". The table was under glass and used M. Redgrave's plunger device to propel the ball into the upper playfield. In 1931 David Gottlieb's "Baffle Ball" became the first hit of the coin-operated era. Selling for $17.50, the game dispensed five to seven balls for a penny. The game resonated with people wanting cheap entertainment in the Great Depression-era economy. Most drugstores and taverns in the US operated pinball machines, with many locations quickly recovering the cost of the game. Baffle Ball sold over 50,000 units and established Gottlieb as the first major manufacturer of pinball machines.
In 1932, Gottlieb distributor Ray Moloney found it hard to obtain more Baffle Ball units to sell. In his frustration he founded Lion Manufacturing to produce a game of his own design, "Ballyhoo", named after a popular magazine of the day. The game became a smash hit. Its larger playfield and ten pockets made it more challenging than "Baffle Ball", selling 50,000 units in 7 months. Moloney eventually changed the name of his company to Bally to reflect the success of this game. These early machines were relatively small, mechanically simple and designed to sit on a counter or bar top.
1933: Electrification and active bumpers introduced.
The 1930s saw major advances in pinball design with the introduction of electrification. A company called Pacific Amusements in Los Angeles, USA produced a game called "Contact" in 1933. "Contact" had an electrically powered solenoid to propel the ball out of a bonus hole in the middle of the playfield. Another solenoid rang a bell to reward the player. The designer of "Contact", Harry Williams, would eventually form his own company, Williams Manufacturing, in 1944. Other manufacturers quickly followed suit with similar features. Electric lights soon became a standard feature of all subsequent pinball games, designed to attract players.
By the end of 1932, there were approximately 150 companies manufacturing pinball machines, most of them in Chicago. Chicago has been the center of pinball manufacturing ever since. Competition among the companies was strong, and by 1934 there were 14 companies remaining.
During WWII, all of the major manufacturers of coin-operated games turned to the manufacture of equipment for the war effort. Some companies, like Williams, bought old games from operators and refurbished them, adding new artwork with a patriotic theme. At the end of the war, a generation of Americans looked for amusement in bars and malt shops, and pinball saw another golden age. Improvements such as the tilt mechanism and free games (known as replays) appeared.
1947: Flippers introduced.
Gottlieb's "Humpty Dumpty", introduced in 1947, was the first game to add player-controlled flippers to keep the ball in play longer, adding a skill factor to the game. The low power flippers required three pairs around the playfield to get the ball to the top.
"Triple Action" was the first game to feature just two flippers at the bottom of the playfield. Unlike in modern machines, the flippers faced outwards. These more powerful flippers were facilitated by the addition of a DC power supply. These innovations were some of many by designer Steve Kordek.
The first game to feature the familiar dual-inward-facing-flipper design was "Spot Bowler", made by Gottlieb in 1950.
The post-war era was dominated by Gottlieb. Game designer Wayne Neyens, along with artist Leroy Parker, produced games that collectors consider some of the best classic pinball machines.
1970s: Solid-state electronics and digital displays introduced.
The introduction of microprocessors brought pinball into the realm of electronic gaming. The electromechanical relays and scoring reels that drove games in the 1950s and 1960s were replaced in the 1970s with circuit boards and digital displays. The first solid-state pinball is believed to be Mirco Games' "The Spirit of '76" (1976), though the first mainstream solid-state game was Williams' "Hot Tip" (1977). This new technology led to a boom for Williams and Bally, who attracted more players with games featuring more complex rules, digital sound effects, and speech.
The video game boom of the 1980s signaled the end of the boom for pinball. Arcades replaced rows of pinball machines with video games like 1978's "Space Invaders", 1979's "Asteroids", 1980's "Pac-Man", and 1981's "Galaga". These earned significantly greater profits than the pinball machines of the day, while simultaneously requiring less maintenance. Bally, Williams, and Gottlieb continued to make pinball machines, while they also manufactured video games in much higher numbers. Many of the larger companies were acquired by, or merged with, other companies. Chicago Coin was purchased by the Stern family, who brought the company into the digital era as Stern Enterprises, which closed its doors in the mid-1980s. Bally exited the pinball business in 1988 and sold their assets to Williams, who subsequently used the Bally trademark from then on for about half of their pinball releases.
While the video game craze of the late 1970s and early 1980s dealt a severe blow to pinball revenue, it did spark the creative talents within the industry. All companies involved tried to take advantage of the new solid state technology to improve player appeal of pinball and win back former players from video games. Some of this creativity resulted in landmark designs and features still present today. Some of these include speech, such as Williams' "Gorgar"; ramps for the ball to travel around, such as Williams' "Space Shuttle"; "multiball", used on Williams' "Firepower"; multi-level games like Gottlieb's "Black Hole" and Williams' "Black Knight"; and blinking chase lights, as used on Bally's "Xenon". Although these novel features did not win back players as the manufacturers had hoped, they changed players' perception of pinball for coming decades.
1980s and beyond: Pinball in the digital age.
After the collapse of the coin-operated video game industry, pinball saw another comeback in the 1990s. Some new manufacturers entered the field such as Capcom Pinball and Alvin G. and Company, founded by Alvin Gottlieb, son of David Gottlieb. Gary Stern, the son of Williams co-founder Sam Stern, founded Data East Pinball with funding from Data East Japan.
The games from Williams now dominated the industry, with complicated mechanical devices and more elaborate display and sound systems attracting new players to the game. Licensing popular movies and icons of the day became a staple for pinball, with Bally/Williams' "The Addams Family" hitting an all-time modern sales record of 20,270 machines. Two years later, Williams commemorated this benchmark with a limited edition of 1,000 "Addams Family Gold" pinball machines, featuring gold-colored trim and updated software with new game features. Other notable popular licenses included ' and '. Expanding markets in Europe and Asia helped fuel the revival of interest. Pat Lawlor was a designer, working for Williams until their exit from the industry in 1999. About a year later, Lawlor returned to the industry, starting his own company. working in conjunction with Stern Pinball to produce new games.
The end of the 1990s saw another downturn in the industry, with Gottlieb, Capcom, and Alvin G. closing by the end of 1996. Data East's pinball division was acquired by Sega and became Sega Pinball in 1996. By 1997, there were two companies left: Sega Pinball and Williams. In 1999, Sega sold their pinball division to Gary Stern (President of Sega Pinball at the time) who called his company Stern Pinball. By this time, Williams games rarely sold more than 4,000 units. In 1999, Williams attempted to revive sales with the Pinball 2000 line of games, merging a video display into the pinball playfield. The reception was initially good with "Revenge From Mars" selling well over 6,000 machines, but short of the 10,000-plus production runs for releases just six years earlier. The next Pinball 2000 game, "Star Wars Episode I", sold only a little over 3,500 machines. Williams exited the pinball business to focus on making gaming equipment for casinos, which was more profitable. They licensed the rights to reproduce Bally/Williams parts to Illinois Pinball and the rights to reproduce full-sized machines to The Pinball Factory. Stern Pinball remained the only manufacturer of original pinball machines until 2013, when Jersey Jack Pinball started shipping "The Wizard of Oz". Most members of the design teams for Stern Pinball are former employees of Williams.
In November 2005 The Pinball Factory (TPF) in Melbourne, Australia, announced that they would be producing a new "Crocodile Hunter"-themed pinball machine under the Bally label. With the death of Steve Irwin, it was announced that the future of this game was uncertain. In 2006 TPF announced that they would be reproducing two popular 90's era Williams machines, "Medieval Madness" and "Cactus Canyon". TPF however was unable to make good on its promises to produce new machines, and in October 2010 transferred its Williams Electronics Games licenses as well as its pinball spare parts manufacturing and distribution business to Planetary Pinball Supply Inc, a California distributor of pinball replacement parts.[http://www.planetarypinball.com/mm5/merchant.mvc?Store_Code=PP&Screen=PRESS]
In 2006, Illinois pinball company PinBall Manufacturing Inc. produced 178 reproductions of Capcom's "Big Bang Bar" for the European and US markets.
In 2010, MarsaPlay in Spain manufactured a remake of Inder's original "Canasta" titled "New Canasta", which was the first game to include an LCD screen in the backbox.
In 2013, Jersey Jack Pinball released "The Wizard of Oz" pinball machine. It is the first pinball machine manufactured in the USA with a LCD as backbox, the first widebody pinball machine since 1994 and the first new US pinball machine not made by Stern Pinball since 2001.
In 2015, the new British pinball manufacturer Heighway Pinball released the racing themed pinball machine "Full Throttle". The game has its LCD screen for scores, info & animations located in the playfield surface at player’s eye view.
Pinball and gambling.
Pinball machines, like many other mechanical games, were sometimes used as gambling devices. Some pinball machines, such as Bally's "bingos", featured a grid on the backglass scoring area with spaces corresponding to targets or holes on the playfield. Free games could be won if the player was able to get the balls to land in a winning pattern; however, doing this was nearly random, and a common use for such machines was for gambling. Other machines allowed a player to win and accumulate large numbers of "free games" which could then be cashed out for money with the location owner. Later, this type of feature was discontinued in an effort to legitimize the machines, and to avoid legal problems in areas where awarding free games was considered illegal, some games, called Add-A-Ball, did away with the free game feature, instead giving players extra balls to play (between 5 and 25 in most cases). These extra balls were indicated via lighted graphics in the backglass or by a ball count wheel, but in some areas that was disallowed, and some games were shipped with a sticker to cover the counters.
Pinball was banned beginning in the early 1940s until 1976 in New York City. New York mayor Fiorello La Guardia was responsible for the ban, believing that it robbed school children of their hard earned nickels and dimes. La Guardia spearheaded major raids throughout the city, collecting thousands of machines. The mayor participated with police in destroying machines with sledgehammers before dumping the remnants into the city's rivers.
The ban ended when Roger Sharpe (a star witness for the AMOA – Amusement and Music Operators Association) testified in April 1976 before a committee in a Manhattan courtroom that pinball games had become games of skill and were not games of chance, that is, gambling. He began to play one of two games set up in the courtroom, and – in a move he compares to Babe Ruth's home run in the 1932 World Series – called out precisely what he was going to shoot for, and then proceeded to do so. Astonished committee members reportedly voted to remove the ban, which was followed in other cities. (Sharpe reportedly acknowledges his courtroom shot was by sheer luck.)
Like New York, Los Angeles banned pinball machines in 1939. The ban was overturned by the Supreme Court of California in 1974 because (1) if pinball machines were games of chance, the ordinance was preempted by state law governing games of chance in general, and (2) if they were games of skill, the ordinance was unconstitutional as a denial of the equal protection of the laws. Although it was rarely enforced, Chicago's ban on pinball lasted three decades and ended in 1973. Philadelphia and Salt Lake City also had similar bans. Regardless of these events, some towns in America still have such bans on their books 50 years later, and several countries still ban the games and their rewards. More recent games are clearly labeled "FOR AMUSEMENT ONLY" in an attempt to emphasize their legitimate, legal nature.
Pachinko.
Another close but distinct relative of pinball is pachinko, a gambling game played in Japan. Although they share a common ancestry, the games are very different, in that pachinko involves shooting many small balls repeatedly into a nearly vertical playfield, while pinball is about the manipulation of the small number of balls currently in play on a near-horizontal playfield.
Machine layout.
The key attribute of a successful pinball game is an interesting and challenging layout of scoring opportunities on the playfield. Many types of targets and features have been developed over the years.
Playfield.
The "playfield" is a planar surface inclined upward from three to seven degrees (current convention is six and a half degrees), away from the player, and includes multiple targets and scoring objectives. Some operators intentionally extend (to raise) threaded levelers on the rear legs and/or shorten or remove the levelers on the front legs to create additional incline in the playfield, making the ball move faster and harder to play. It is important that the playfield be level left-to-right; a quick visual test compares the top of the back cabinet against a brick or block wall behind it, or to roll a marble down the center of the playfield glass. If it clearly rolls off to one side, a player may be inclined to stuff folded paper beneath the legs on the lower side to level the playfield. Additionally, leg levelers that are all extended fully make the game easier to nudge; when collapsed low, the entire game is more stable, and nudging becomes harder. A game that is fun to play makes more money for the owner; a game that is faulty does not get repeat customers.
The ball is put into play by use of the "plunger", a spring-loaded rod that strikes the ball as it rests in an entry lane, or as in some newer games, by a button that signals the game logic to fire a solenoid that strikes the ball. With both devices the result is the same: The ball is propelled upwards onto the playfield. Once a ball is in play, it tends to move downward towards the player, although the ball can move in any direction, sometimes unpredictably, due to contact with objects on the playfield or by the player's own actions. To return the ball to the upper part of the playfield, the player makes use of one or more "flippers". Manipulation of the ball may also be accomplished by nudging (physically pushing the cabinet). However, excessive nudging is generally penalized by the loss of the current player's turn (known as "tilting") or ending of the entire game when the nudging is particularly violent (known as "slam tilting"). This penalty was instituted because nudging the machine too much may damage it. Many games also have a slam tilt in the bottom of the lower cabinet to end the game if the cabinet is raised and dropped to the floor in an attempt to falsely trigger the coin counting switch.
Plunger.
The "plunger" is a spring-loaded rod with a small handle, used to propel the ball into the playfield. The player can control the amount of force used for launching by pulling the plunger a certain distance (thus changing the spring compression). This is often used for a "skill shot," in which a player attempts to launch a ball so that it exactly hits a specified target. Once the ball is in motion in the main area of the playfield, the plunger is not used again until another ball must be brought onto the playfield. In modern machines, an electronically controlled launcher is sometimes substituted for the plunger.
The button that replaces the plunger may be modified to look like the trigger of a gun.
Flippers.
The "flippers" are one or more small mechanically or electromechanically controlled levers, roughly 3 to 7 cm in length, used for redirecting the ball up the playfield. They are the main control that the player has over the ball. Careful timing and positional control allows the player to intentionally direct the ball in a range of directions with various levels of velocity. With the flippers, the player attempts to move the ball to hit various types of scoring targets, and to keep the ball from disappearing off the bottom of the playfield. The very first pinball games appeared in the early 1930s and did not have flippers; after launch the ball simply proceeded down the playfield, directed by static nails (or "pins") to one of several scoring areas. (These pins gave the game its name.) In 1947, the first mechanical flippers appeared on Gottlieb's Humpty Dumpty and by the early 1950s, the familiar two-flipper configuration, with the flippers at the bottom of the playfield above the center drain, had become standard. Some machines also added a third or fourth flipper midway up the playfield.
The new flipper ushered in the "golden age" of pinball, where the fierce competition between the various pinball manufacturers led to constant innovation in the field. Various types of stationary and moving targets were added, spinning scoring reels replaced games featuring static scores lit from behind. Multiplayer scores were added soon after, and then bells and other noise-makers, all of which began to make pinball less a game and more of an experience. The flippers have loaned pinball its common name in many languages, where the game is known mainly as "flipper".
Bumpers.
"Bumpers" are round knobs that, when hit, will actively push the ball away. There is also an earlier variety of bumper (known as a "dead bumper" or "passive bumper") that doesn't propel the ball away; most bumpers on machines built since the 1960s are active bumpers, variously called "pop bumpers," "thumper bumpers," "jet bumpers," or "turbo bumpers." Most recent games include a set of pop bumpers, usually three, sometimes more or fewer depending on the designer's goals. Bumpers predate flippers, and active bumpers added a great deal of spice to older games.
Pop bumpers are operated by a switch connected to a ring surrounding the bottom circumference of the bumper that is suspended several millimeters above the playfield surface. When the ball rolls over this ring and forces one side of it down, a switch is closed that activates the bumper's solenoid. This pulls down a tapered ring surrounding the central post of the bumper that pushes downward and outward on the ball, propelling it away.
Kickers and slingshots.
"Kickers" and "slingshots" are rubber pads which propel the ball away upon impact, like bumpers, but are usually a horizontal side of a wall. Every recent pinball machine includes slingshots to the upper left and upper right of the lowest set of flippers; older games used more experimental arrangements. They operate similarly to pop bumpers, with a switch on each side of a solenoid-operated lever arm in a typical arrangement. The switches are closed by ball contact with the rubber on the face of the kicker and this activates the solenoid.
Early pinball machines typically had full solenoid current passing through trigger switches for all types of solenoids, from kickers to pop bumpers to the flippers themselves. This caused arcing across switch contacts and rapid contact fouling and failure. As electronics were gradually implemented in pinball design, solenoids began to be switched by power transistors under software control to lower switch voltage and current, vastly extend switch service lifetime, and add flexibility to game design.
As an example, some later machines had flippers that could be operated independently of the flipper button by the machine's software. The upper-left flipper during "Thing Flips" on "The Addams Family" pinball machine triggers automatically a brief moment after the ball passes an optical sensor just above the flipper.
The smaller, lower-powered solenoids were first to be transistorized, followed later by the higher-current solenoids as the price, performance, and reliability of power transistors improved over the years.
Holes and saucers.
Originally holes and saucers worked by using tubes behind the playing field, with a pin at the top to hold the ball for later drops. Another version of the tube uses two spinning wheels to transfer the ball from hole to hole. Newer versions use an electronic track with a carriage or an electromagnet to pull the ball between holes.
Ramps.
Ramps are inclined planes with a gentle enough slope that the ball may travel along it. The player attempts to direct the ball with enough force to make it to the top of the ramp and down the other side. If the player succeeds, a "ramp shot" has been made. Ramps frequently end in such a way that the ball goes to a flipper so one can make several ramp shots in a row. Often, the number of ramp shots scored in a game is tallied, and reaching certain numbers may lead to various game features. At other times, the ramps will go to smaller "mini-playfields" (small playfields, usually raised above the main game surface, with special goals or scoring).
Common features.
There are other idiosyncratic features on many pinball playfields. Pinball games have become increasingly complex and multiple play modes, multi-level playfields, and even progression through a rudimentary "plot" have become common features on recent games. Pinball scoring objectives can be quite complex and require a series of targets to be hit in a particular order. Recent pinball games are distinguished by increasingly complex rule sets that require a measure of strategy and planning by the player for maximum scoring. Players seeking highest scores would be well-advised to study the placard (usually found in the lower-left corner of the playfield) to learn each game's specific patterns required for these advanced features and scoring.
Common features in modern pinball games include the following:
Unique features.
In the 1990s, game designers often put hidden, recurring images or references in their games, which became known as Easter eggs. For example, Williams' designers hid cows in the video displays of the games, and Pat Lawlor would place a red button in the artwork of games he developed. The methods used to find the hidden items usually involved pressing the flipper buttons in a certain order or during specific events.
Designers also included hidden messages or in-jokes; one example of this is the phrase "DOHO" sometimes seen quickly displayed on the dot matrix displays, a reference to Dorris Ho, the wife of then-Williams display artist Scott "Matrix" Slomiany. DOHO was popularly thought to be an acronym for Documented Occurrence of a Hidden Object until its true meaning was revealed in a "PinGame Journal" article on the subject. The game "" went so far as to embed a hidden "Breakout"-like game, available only after a complex sequence of events had been accomplished during the game.
Backglass.
The "backglass" is a vertical graphic panel mounted on the front of the backbox, which is the upright box at the top back of the machine. The backglass contains the name of the machine, eye-catching graphics, (usually) the score displays (lights, mechanical wheels, digital displays, or a dot matrix display depending on the era), and sometimes a mechanical device tied to game play, for example, elevator doors that opened on an image or a woman swatting a cat with a broom such as on Williams' 1989 "Bad Cats". For older games, the backglass image is screen printed in layers on the reverse side of a piece of glass; in more recent games, the image is imprinted into a translucent piece of plastic-like material called a translite which is mounted behind a piece of glass and which is easily removable. The earliest games did not have backglasses or backboxes and were little more than playfields in boxes. Games are generally built around a particular theme, such as a sport or character and the backglass art reflects this theme to attract the attention of players. Recent machines are typically "tied-in" to other enterprises such as a popular film series, toy, or brand name. The entire machine is designed to be as eye-catching as possible to attract players and their money; every possible space is filled with colorful graphics, blinking lights, and themed objects, and the backglass is usually the first artwork the players see from a distance. Since the artistic value of the backglass may be quite impressive, it is not uncommon for enthusiasts to use a deep frame around a backglass (lighted from behind) and hang it as art after the remainder of the game is discarded.
Scoring points.
Contact with or manipulation of scoring elements (such as targets or ramps) scores points for the player. Electrical switches embedded in the scoring elements detect contact and relay this information to the scoring mechanism. Older pinball machines used an electromechanical system for scoring wherein a pulse from a switch would cause a complex mechanism composed of relays to ratchet up the score. In later games these tasks have been taken over by semiconductor chips and displays are made on electronic segmented or dot-matrix displays (DMD). The first DMD on a pinball machine was used by "Checkpoint" and features also video mode minigames. MarsaPlay in Spain manufactured a remake of Inder's original "Canasta" titled "New Canasta", with an LCD screen in the backbox in 2010. " The Wizard of Oz" is the first US pinball machine that used a LCD in the back box. It is not only used for scoring and mini-games but also to display full color videos. Other display innovations on pinball machines include pinball video game hybrids like "Baby Pac-Man" in 1982 and "Granny and the Gators" in 1984 and the use of a small color video monitor for scoring and minigames in the backbox of the pinball machine "Dakar" from manufacturer Mr. Game in 1988 and CGA color monitors in Pinball 2000 in 1999 that utilizes a Pepper's Ghost technique to reflect the monitor in the head of the as well as modifications by the use of ColorDMD that is used to replace the standard mono color DMDs.
Pinball scoring can be peculiar and varies greatly from machine to machine. During the 1930s and the 1940s, lights mounted behind the painted backglasses were used for scoring purposes, making the scoring somewhat arbitrary. (Frequently the lights represented scores in the hundreds of thousands.) Then later, during the 1950s and 1960s when the scoring mechanism was limited to mechanical wheels, high scores were frequently only in the hundreds "or" thousands. (Although, in an effort to keep with the traditional high scores attained with the painted backglass games, the first pinball machines to use mechanical wheels for scoring, such as "Army Navy", allowed the score to reach into the millions by adding a number of permanent zeros to the end of the score.) The average score changed again in the 1970s with the advent of electronic displays. Average scores soon began to commonly increase back into tens or hundreds of thousands. Since then, there has been a trend of scoring inflation, with modern machines often requiring scores of over a billion points to win a free game. At the peak of this trend, two machines, "Johnny Mnemonic" and "Attack from Mars", have been played into the trillions. Another recent curiosity is the 1997 Bally game "NBA Fastbreak" which, true to its theme, awards points in terms of a real basketball score: Each successful shot can give from one to three points. Getting a hundred points by the end of a game is considered respectable, which makes it one of the "lowest" scoring pinball machines of all time. The inflated scores are the source of one of the Spanish-language names of pinball machines, "máquina del millón" ("million machine").
Special scores.
Pinball designers also entice players with the chance to win an extra game or "replay". Ways to get a replay might include the following:
When an extra game is won, the machine typically makes a single loud bang, most often with a solenoid that strikes a piece of metal, or the side of the cabinet, with a rod, known as a "knocker", or less commonly with loudspeakers. "Knocking" is the act of winning an extra game when the knocker makes the loud and distinctive noise.
Playing techniques.
The primary skill of pinball involves application of the proper timing and technique to the operation of the flippers, nudging the playfield when appropriate without tilting, and choosing targets for scores or features. A skilled player can quickly "learn the angles" and gain a high level of control of ball motion, even on a machine they have never played. Skilled players can often play on a machine for long periods of time on a single coin. By earning extra balls, a single game can be stretched out for a long period, and if the player is playing well he or she can earn replays known as "specials."
A placard is usually placed in a lower corner of the playfield. It may simply show pricing information, but should also show critical details about special scoring techniques. This information is vital to achieving higher scores; it typically describes a series of events that must take place (e.g., shoot right ramp and left drop targets to light 'extra ball' rollover). Learning these details makes the game more fun and challenging. With practice — and a machine in good operating condition — a player can often achieve specific targets and higher scores and trigger exciting events.
Nudging.
Skillful players can influence the movement of the ball by nudging or bumping the pinball machine, a technique known as "nudging." There are tilt mechanisms which guard against excessive manipulation of this sort. The mechanisms generally include:
When any of these sensors is activated, the game registers a "tilt" and locks out, disabling solenoids for the flippers and other playfield systems so that the ball can do nothing other than roll down the playfield directly to the drain. A tilt will usually result in loss of bonus points earned by the player during that ball. Older games would immediately end the ball in play on a tilt. Modern games give tilt warnings before sacrificing the ball in play. The number of tilt warnings can be adjusted by the operator of the machine. Until recently most games also had a "slam tilt" switch which guarded against kicking or slamming the coin mechanism, or for overly aggressive behavior with the machine, which could give a false indication that a coin had been inserted, thereby giving a free game or credit. This feature was recently taken out by default in new Stern S.A.M System games, but can be added as an option. A slam tilt will typically end the current game for all players.
Trapping.
Skilled players can also hold a ball in place with the flipper, giving them more control over where they want to place the ball when they shoot it forward. This is known as "trapping." This technique involves catching the ball in the corner between the base of the flipper and the wall to its side, just as the ball falls towards the flipper; the flipper is then released, which allows the ball to roll slowly downward against the flipper. The player then chooses the moment to hit the flipper again, timing the shot as the ball slides slowly against the flipper. Multi-ball games, in particular, reward trapping techniques. Usually this is done by trapping one or more balls out of play with one flipper, then using the other flipper to score points with the remaining ball or balls.
Once a player has successfully trapped a ball, they may then attempt to "juggle" the ball to the other flipper. This is done by tapping the flipper button quickly enough so that the trapped ball is knocked back at an angle of less than 90 degrees into the bottom of the nearest slingshot. The ball will then often bounce across the playfield to the other flipper, where the ball may then be hit (or trapped) by the opposite flipper.
Occasionally a pinball machine will have a pin or post placed directly between the two bottom flippers. When this feature is present, the advanced player may then attempt to perform a "chill maneuver" when the ball is heading directly toward the pin by opting "not" to hit a flipper. If successful, this will cause the ball to bounce up and back into play. A related move, the "dead flipper pass," is performed by "not" flipping when a ball is heading toward a flipper. If done properly, the ball will bounce off the "dead" flipper, across to the other flipper, where it may be trapped and controlled.
Competitions.
Two Pinball World Championships were held in the Washington, DC area in 1972 and 1973 under the auspices of the World Pinball Association which also published a newsletter carrying results of regional tournaments.
In 1974, students at Jersey City State College wanted to make pinball playing a varsity school sport, like football was, so they started a Pinball Club Team to compete against clubs at other schools. They asked two other schools to participate. St. Peter's College took up the challenge, while the other school did not.
Many pinball leagues have formed, with varying levels of competitiveness, formality and structure. These leagues exist everywhere from the Free State Pinball Association (FSPA) in the Washington, DC area to the Tokyo Pinball Organization (TPO)] in Japan. In the late 1990s, game manufacturers added messages to some games encouraging players to join a local league, providing website addresses for prospective league players to investigate.
Competitive pinball has become increasingly popular in recent years, with the relaunch of both the Professional and Amateur Pinball Association (PAPA) and the International Flipper Pinball Association (IFPA).
Two different systems for ranking pinball players exist. The World Pinball Player Rankings (WPPR) was created by the IFPA. The WPPR formula takes into account the quantity and quality of the players in the field, and awards points based on that calculation for the nearly 200 IFPA endorsed events worldwide. PAPA manages a ranking system known as the PAPA Advanced Rating System (PARS), which uses the Glicko Rating System to mathematically analyze the results of more than 100,000 competitive matches. Since 2008 the IFPA has held a World Championship tournament, inviting the top-ranked WPPR players to compete; the current title holder is Daniele Celestino Acciari of Italy.
PAPA also designates the winner of the A Division in the annual PAPA World Pinball Championships as the World Pinball Champion; the current holder of this title is Keith Elwin from the USA. Current Junior (16 and under) and Senior (50 and over) World Champions are Joshua Henderson and Paul McGlone, respectively.
Manufacturing process.
The first part of a pinball machine's construction involves the wiring for the game's electronic system. A color-coded wiring arrangement is wrapped around pins and connectors on a circuit board. Technicians then follow through using a meticulous set of instructions to ensure that the almost-half mile of wire is engineered properly. During this time the playing field is set onto foam strips and a bed of nails. The nails are then pressed in the playing board as the bed raises and compresses them against the header. Afterward anchors come and are hammered into place. The anchors help secure a metal railing that keeps the balls from exiting the playing field.
After the main construction is processed, it then comes down to fitting a few lampposts, some plastic bumpers, and flashing lights. All of the wiring is permanently fastened and speakers are bolted into the cabinet. Along with this comes the most crucial tool, the spring power plunger, which is set into place.
Finally, a few other toys and gimmicks are added, such as toy villains and other small themed characters. Once everything is tested and seems to be running alright, the playfield is set on top of the lower box. The lower box on computerized games is essentially empty. On older electromechanical games, the entire floor of the lower box was used to mount custom relays and special scoring switches, making older games much heavier. To protect the top of the playfield, a tempered glass window is installed, secured by a metal bar that is locked into place. The expensive, unique, painted vertical backglass is fragile. The backglass covers the custom microprocessor boards on newer games, or electromechanical scoring wheels on older games. On older games, a broken backglass might be impossible to replace, ruining the game's appeal.
Solenoids.
Flipper solenoids contain two coil windings in one package; a short, heavy gage 'power' winding to give the flipper its initial thrust up, and a long, light gage 'hold' winding that uses lower power (and creates far less heat) and essentially just holds the flipper up allowing the player to capture the ball in the inlane for more precise aiming. As the flipper nears the end of its upward travel, a switch under the flipper disconnects the power-winding and leaves only the second sustain winding to hold the flipper up in place. If this switch fails 'open' the flipper will be too weak to be usable, since only the weak winding is available. If it fails 'closed' the coil will overheat and destroy itself, since both windings will hold the flipper at the top of its stroke.
Solenoids also control pop-bumpers, kickbacks, drop target resets, and many other features on the machine. These solenoid coils contain a single coil winding. The plunger size and wire gage & length are matched to the strength required for each coil to do its work, so some types are repeated throughout the game, some are not.
All solenoids and coils used on microprocessor games include a special reverse-biased diode to eliminate a high-voltage pulse of reverse EMF (electromotive force). Without this diode, when the solenoid is de-energized, the magnetic field that was built up in the coil collapses and generates a brief, high-voltage pulse backward into the wiring, capable of destroying the solid-state components used to control the solenoid. Proper wiring polarity must be retained during coil replacement or this diode will act as a dead short, immediately destroying electronic switches. Older electromechanical game solenoids do not require this diode, since they were controlled with mechanical switches.
All but very old games use low DC voltages to power the solenoids and electronics (or relays). Some microprocessor games use high voltages (potentially hazardous) for the score displays. Very early games used low-voltage AC power for solenoids, requiring fewer components, but AC is less efficient for powering solenoids, causing heavier wiring and slower performance. For locations that suffer from low AC wall outlet voltage, additional taps may be provided on the AC transformer in electromechanical games to permit raising the game's DC voltage levels, thus strengthening the solenoids. Microprocessor games have electronic power supplies that automatically compensate for inaccurate AC supply voltages.
Historically, pinball machines have employed a central fixed I/O board connected to the primary CPU controlled by a custom microcontroller platform running an in-house operating system. For a variety of reasons that include thermal flow, reliability, vibration reduction and serviceability, I/O electronics have been located in the upper backbox of the game, requiring significant custom wiring harnesses to connect the central I/O board to the playfield devices.
A typical pinball machine I/O mix includes 16 to 24 outputs for driving solenoids, motors, electromagnets and other mechanical devices in the game. These devices can draw up to 500 W momentarily and operate at voltages up to 50 Vdc. There is also individually controlled lighting that consists of 64 to 96 individually addressable lights. Recently developed games have switched from incandescent bulbs to LEDs. And there is general illumination lighting that comprises two or more higher-power light strings connected and controlled in parallel for providing broad illumination to the playfield and backbox artwork. Additionally, 12 to 24 high-impulse lighting outputs, traditionally incandescent but now LED, provide flash effects within the game. Traditionally, these were often controlled by solenoid-level drivers.
A game typically includes 64 to 96 TTL-level inputs from a variety of sensors such as mechanical leaf switches, optical sensors and electromagnetic sensors. Occasionally extra signal conditioning is necessary to adapt custom sensors, such as eddy sensors, to the system TTL inputs.
Recently, some pinball manufacturers have replaced some of the discrete control wiring with standard communication buses. In one case, the pinball control system might include a custom embedded network node bus, a custom embedded Linux-based software stack, and a 48-V embedded power distribution system.
Computer pinball simulation.
Simulating a pinball machine has also been a popular theme of video games, most famously when Bill Budge wrote "Pinball Construction Set" for the Apple II in 1983. While there had been earlier pinball video games, such as "Video Pinball" for the Atari 2600, "Pinball Construction Set" was the first program that allowed the user to create his own simulated pinball machine and then play it. Another early pinball video game is "David's Midnight Magic".
Most early simulations were top-down 2D. As processor and graphics capabilities have improved, more accurate ball physics and 3D pinball simulations have become possible. Tilting has also been simulated, which can be activated using one or more keys (sometimes the space bar) for "moving" the machine. Flipper button computer peripherals were also released, allowing pinball fans to add an accurate feel to their game play instead of using the keyboard or mouse. Modern pinball video games are often based around established franchises such as "Metroid Prime Pinball", "Super Mario Ball" and "Sonic the Hedgehog Spinball".
Popular pinball games of the 1990s include "Pinball Dreams", "Pro Pinball" and "3D Pinball: Space Cadet" that was included in Windows Me and Windows XP. More recent examples include "Pinball FX" and "Pinball FX 2".
There have been pinball programs released for all major home video game and computer systems, tablet computers and smart phones. Pinball video game engines and editors for creation and recreation of pinball machines include for instance "Visual Pinball", "Future Pinball" and "Unit3D Pinball".
A BBC News article described virtual pinball games e.g. "Zen Pinball" and "The Pinball Arcade" as a way to preserve pinball culture and bring it to new audiences. Another example of preserving historic pinball machines is "Zaccaria Pinball" that consists of digital recreations of classic Zaccaria pinball machines.
Custom pinball machines.
Some hobbyists and small companies modify existing pinball machines or create their own custom pinball machines. Some want, for example, a game with a specific subject or theme that cannot be bought in this form or was never built at all. Some custom games are built by using the programmable P-ROC controller board. Modifications include the use of ColorDMD that is used to replace the standard mono color dot-matrix displays or the addition of features, e.g. figures or other toys.
A few notable examples of custom pinball machines include a Ghostbusters theme machine, a Matrix style game, Bill Paxton Pinball, Sonic, StarFox, and Predator machines.
Data East was one of few regular pinball company that manufactured custom pinball games (e.g. for Aaron Spelling, Michael Jordan and the movie "Richie Rich"), though these were basically mods of existing or soon to be released pinball machines (e.g. "Lethal Weapon 3" or "The Who's Tommy Pinball Wizard").
In popular culture.
Pinball games have frequently been featured in popular culture, often as a symbol of rebellion or toughness. Perhaps the most famous instance is the rock opera album "Tommy" (1969) by The Who, which centers on the title character, a "deaf, dumb, and blind kid", who becomes a "Pinball Wizard" and who later uses pinball as a symbol and tool for his messianic mission. (The album was subsequently made into a movie and stage musical.) "Wizard" has since moved into popular usage as a term for an expert pinball player. Things came full circle in 1975 when Bally created the "Wizard!" pinball game featuring Ann-Margret and The Who's Roger Daltrey on the backglass. In the movie version, Tommy plays a Gottlieb "Kings and Queens" machine, while The Champ plays a Gottlieb "Buckaroo" machine. In 1976, Bally released "Capt.Fantastic", which had an image of Elton John on the backglass, playing pinball in a similar costume as used in the movie "Tommy". Data East produced "The Who's Tommy Pinball Wizard" in 1994, based on the rock musical "The Who's Tommy". This game is notable in its use of The Who's iconic songs, including "Pinball Wizard", sung by original Broadway cast members.
In the late 1970s the children's television series "Sesame Street" began airing a series of short animated segments, called the "Pinball Number Count". Each segment was different, and involved the ball rolling in different themed areas of a pinball machine depending on which number (from 1-12) was being featured. The animations were directed by Jeff Hale and featured music by Walt Kraemer and vocal work by the Pointer Sisters.
In "Pinball, 1973", a novel by Haruki Murakami, the protagonist is obsessed with pinball. One of the plot lines follows his attempts to find a pinball machine he used to play.
In 1975–76 there was a brief TV game show based on pinball called "The Magnificent Marble Machine".
"Tilt" is a 1979 drama film starring Brooke Shields as the protagonist, Tilt, a young pinball wizard.

</doc>
<doc id="60509" url="https://en.wikipedia.org/wiki?curid=60509" title="195 BC">
195 BC

__NOTOC__
Year 195 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Flaccus and Cato (or, less frequently, year 559 "Ab urbe condita"). The denomination 195 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Korea.
</onlyinclude>

</doc>
<doc id="60510" url="https://en.wikipedia.org/wiki?curid=60510" title="198 BC">
198 BC

__NOTOC__
Year 198 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Catus and Flamininus (or, less frequently, year 556 "Ab urbe condita"). The denomination 198 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="60511" url="https://en.wikipedia.org/wiki?curid=60511" title="Parrot virtual machine">
Parrot virtual machine

Parrot is a register-based process virtual machine designed to run dynamic languages efficiently. It is possible to compile Parrot assembly language and PIR (an intermediate language) to Parrot bytecode and execute it. Parrot is free and open source software.
Parrot was started by the Perl community and is developed with help from the open source and free software communities. As a result, it is focused on license compatibility with Perl (Artistic License 2.0), platform compatibility across a broad array of systems, processor architecture compatibility across most modern processors, speed of execution, small size (around 700k depending on platform), and the flexibility to handle the varying demands made by Perl 6 and other modern dynamic languages. 
Version 1.0, with a stable API for development, was released on March 17, 2009.
The current version is release 7.9.0 "Sangihe hanging parrot"
History.
The name "Parrot" came from an April Fool's joke which announced a hypothetical language, named "Parrot", that would unify Python and Perl. The name was later adopted by this project (initially a part of the Perl 6 development effort) which aims to support Perl 6, Python, and other programming languages. Several languages are being ported to run on the Parrot virtual machine.
The Parrot Foundation was created in 2008 to hold the copyright and trademarks of the Parrot project, to help drive development of language implementations and the core codebase, to provide a base for growing the Parrot community, and to reach out to other language communities.
Languages.
The goal of the Parrot virtual machine is to host client languages and allow inter-operation between them. Several hurdles exist in accomplishing this goal, in particular the difficulty of mapping high-level concepts, data, and data structures between languages.
Static and dynamic languages.
The differing properties of statically and dynamically typed languages have motivated the design of Parrot. Current popular virtual machines such as the Java virtual machine and the Common Language Runtime, for the .NET platform, have been designed for statically typed languages, while the languages targeted by Parrot are dynamically typed.
Virtual machines such as the Java virtual machine and the current Perl 5 virtual machine are also stack based. Parrot developers see Parrot's inclusion of registers as an advantage, as it therefore more closely resembles a hardware design, allowing the vast literature on compiler optimization to be used in generating bytecode for the Parrot virtual machine that could run at speeds closer to machine code. Other register-based virtual machines have inspired parts of Parrot's design, including LLVM, the Lua VM and Inferno's Dis.
Functional concepts.
Parrot has rich support for several features of functional programming including closures and continuations, both of which can be particularly difficult to implement correctly and portably, especially in conjunction with exception handling and threading. The biggest advantage is the dynamic extendability of objects with methods, which allows for "polymorphic containers" (PMCs) and associated opcodes. Implementing solutions to these problems at the virtual machine level prevents repeated efforts to solve these problems in the individual client languages.
Compiler tools.
Parrot provides a suite of compiler-writing tools which includes the Parser Grammar Engine (PGE), a hybrid parser-generator that can express a recursive descent parser as well as an operator-precedence parser, allowing free transition between the two in a single grammar. The PGE feeds into the Tree Grammar Engine (TGE) which further transforms the parse-tree generated by PGE for optimization and ultimately for code generation.
Existing client languages.
Many languages already have compiler front-ends designed for Parrot; however, many of them are still only partially functional. As of July 2013, actively maintained languages are:
Inactive languages, as of July 2013, are the following:
Internals.
There are three forms of program code for Parrot:
Examples.
Registers.
Parrot is register-based like most hardware CPUs, and unlike most virtual machines, which are stack-based. Parrot provides four types of registers:
Parrot provides an arbitrary number of registers; this number is fixed at compile time per subroutine.
Arithmetic operations.
In PASM
In PIR
Development.
Until late 2005, Dan Sugalski was the lead designer and chief architect of Parrot. Chip Salzenberg, a longtime Perl, Linux kernel, and C++ hacker, took over until mid-2006, when he became the lead developer. Allison Randal, the lead developer of Punie and chief architect of Parrot's compiler tools, was the chief architect until mid-October 2010 when she stepped down and chose Christoph Otto as the new chief architect.
Development discussions take place primarily on the #parrot channel on irc.perl.org. In addition, there are weekly moderated meetings for Parrot and language developers hosted in #parrotsketch on the same network. Much discussion also occurs on the parrot-dev mailing list, hosted by parrot.org.
Design discussions exist in the form of Parrot Design Documents, or PDDs, in the Parrot repository. The chief architect or another designated designer produces these documents to explain the philosophy of a feature as well as its interface and design notes. Parrot hackers turn these documents into executable tests, and then existing features.
The Parrot team releases a new stable version of the software on the third Tuesday of every month. Core committers take turns producing releases in a revolving schedule, where no single committer is responsible for multiple releases in a row. This practice has improved the project's velocity and stability.

</doc>
<doc id="60512" url="https://en.wikipedia.org/wiki?curid=60512" title="197 BC">
197 BC

__NOTOC__
Year 197 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Cethegus and Rufus (or, less frequently, year 557 "Ab urbe condita"). The denomination 197 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Hispania.
</onlyinclude>

</doc>
<doc id="60513" url="https://en.wikipedia.org/wiki?curid=60513" title="196 BC">
196 BC

__NOTOC__
Year 196 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Purpureo and Marcellus (or, less frequently, year 558 "Ab urbe condita"). The denomination 196 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Seleucid Empire.
</onlyinclude>

</doc>
<doc id="60514" url="https://en.wikipedia.org/wiki?curid=60514" title="193 BC">
193 BC

__NOTOC__
Year 193 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Merula and Thermus (or, less frequently, year 561 "Ab urbe condita"). The denomination 193 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming a year.
Events.
<onlyinclude>
By place.
Egypt.
</onlyinclude>

</doc>
<doc id="60515" url="https://en.wikipedia.org/wiki?curid=60515" title="192 BC">
192 BC

__NOTOC__
Year 192 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Flamininus and Ahenobarbus (or, less frequently, year 562 "Ab urbe condita"). The denomination 192 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Greece.
</onlyinclude>

</doc>
<doc id="60516" url="https://en.wikipedia.org/wiki?curid=60516" title="191 BC">
191 BC

__NOTOC__
Year 191 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Nasica and Glabrio (or, less frequently, year 563 "Ab urbe condita"). The denomination 191 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="60518" url="https://en.wikipedia.org/wiki?curid=60518" title="190 BC">
190 BC

__NOTOC__
Year 190 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Asiaticus and Laelius (or, less frequently, year 564 "Ab urbe condita"). The denomination 190 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Art.
</onlyinclude>

</doc>
