<doc id="58008" url="https://en.wikipedia.org/wiki?curid=58008" title="Bachem Ba 349">
Bachem Ba 349

The Bachem Ba 349 Natter () was a World War II German point-defence rocket-powered interceptor, which was to be used in a very similar way to a manned surface-to-air missile. After a vertical take-off, which eliminated the need for airfields, most of the flight to the Allied bombers was to be controlled by an autopilot. The primary role of the relatively untrained pilot was to aim the aircraft at its target bomber and fire its armament of rockets. The pilot and the fuselage containing the rocket-motor would then land using separate parachutes, while the nose section was disposable. The only manned vertical take-off flight on 1 March 1945 ended in the death of the test pilot, Lothar Sieber.
Development.
In 1943 "Luftwaffe" air superiority was being challenged by the Allies over the "Reich" and radical innovations were required to overcome the crisis. Surface-to-air missiles appeared to be a promising approach to counter the Allied strategic bombing offensive; a variety of projects were started, but invariably problems with the guidance and homing systems prevented any of these from attaining operational status. Providing the missile with a pilot, who could operate a weapon during the brief terminal approach phase, offered a solution. Submissions for a simple target defence interceptor were requested by the "Luftwaffe" in early 1944 under the umbrella of the "Emergency Fighter Program". A number of simple designs were proposed, including the Heinkel P.1077 "Julia", in which the pilot lay prone (on his stomach), to reduce the frontal area. The "Julia" was the front-runner for the contract. The initial plan was to launch the aircraft vertically, but this concept was later changed to a conventional horizontal take-off from a tricycle-wheeled trolley, similar to that used by the first eight prototypes of the Arado Ar 234 jet reconnaissance bomber.
Bachem's proposal.
Erich Bachem's BP-20 ("Natter") was a development from a design he had worked on at Fieseler, the Fi 166 concept, but considerably more radical than the other submissions. It was built using glued and nailed wooden parts with an armour-plated bulkhead and bulletproof glass windshield at the front of the cockpit. The initial plan was to power the machine with a Walter HWK 109-509A-2 rocket motor; however, only the 109-509A-1, as used in the Me 163, was available. It had a sea level thrust variable between at "idle" to at full power, with the "Natter's" intended quartet of Schmidding SG34 solid fuel rocket boosters used in its vertical launch to provide an additional thrust for 10 seconds before they burned out and were jettisoned. The experimental prototypes slid up a -tall vertical steel launch tower for a maximum sliding length of in three guideways, one for each wing tip and one for the lower tip of the ventral tail fin. By the time the aircraft left the tower it was hoped that it would have achieved sufficient speed to allow its aerodynamic surfaces to provide stable flight.
Under operational conditions, once the Natter had left the launcher, it would be guided to the proximity of the Allied bombers by an autopilot with the possibility of an added beam guidance similar to that used in some V-2 rocket launches. Only then would the pilot take control, aim and fire the armament, which was originally proposed to be a salvo of 19 R4M rockets. Later, 28 R4Ms or a number of Henschel Hs 297 "Föhn" rockets were suggested, with either variety of unguided rocket fired from the Natter's nose-mount cellular launch tubes contained in its nose. The Natter was intended to fly up and over the bombers, by which time its Walter motor would probably be out of propellant. Following its one-time attack with its rockets, the pilot would dive his Natter, now effectively a glider, to an altitude of around , flatten out, release the nose of the aircraft and a small braking parachute from the rear fuselage. The fuselage would decelerate and the pilot would be ejected forwards by his own inertia and land by means of a personal parachute.
In an early proposal in August 1944, the Natter design had a concrete nose; it was suggested that the machine might ram a bomber, but this proposal was subsequently withdrawn in later Project Natter outlines. Bachem stated clearly in the initial proposal that the Natter was not a suicide weapon and much effort went into designing safety features for the pilot. However, owing to the potential dangers for the pilot inherent in the operation of this precarious aircraft, the Natter is sometimes listed as a suicide craft. The design had one decisive advantage over its competitors – it eliminated the necessity to land an unpowered gliding machine at an airbase, which, as the history of the Me 163 rocket aircraft had clearly demonstrated, made an aircraft extremely vulnerable to attack by Allied fighters.
Modifications.
Bachem's design caught the eye of Heinrich Himmler. The "Reichsführer-SS" granted Bachem an interview and fully supported the project. In the middle of September 1944 the Technical Office of the "Waffen-SS" made an order for Bachem to develop and manufacture the Natter at his Waldsee factory. In December 1944 the project came largely under the control of the SS and Hans Kammler. This decision is said to have been the only time the SS significantly interfered with aircraft design and air fighting strategy. Early-on in the project, the "Reichsluftfahrtministerium" ("RLM") undertook an engineering assessment of the Natter, which it reported on 28 October 1944. Various stringent economies were imposed on an already frugal design.
The Natter had no landing gear, which saved weight, expense and construction time. Consequently one of the most unusual features of the machine was the escape of the pilot and recovery of the machine. The proposed sequence of these events was as follows: After the attack, the Natter might dive to a lower altitude and flatten out into level flight. The pilot would then proceed with a well-practised escape sequence. He would open the cockpit canopy latch; the canopy flicking backwards on its hinge in the airstream; he would undo his seat belt and remove his feet from the rudder pedal stirrups. By squeezing a lever mounted on the control column, he would release a lock at the base of the column, which would allow him to tilt the column forwards where it could engage in and undo a safety latch for the nose release mechanism. He would then lean a little further forward and pull a lever hinged near the floor at the front of the cockpit. This action frees the nose section, which self-jettisoned as a result of the reduced aerodynamic pressure at the front of the fuselage. As the nose section separates, it was intended to briefly pull on two cables that release a small ribbon parachute stored on the starboard side of the rear fuselage. The parachute subsequently opens and decelerates the Natter. The pilot would be ejected from the cockpit by his own inertia and as soon as he was clear of the fuselage, he would open his personal parachute and descend to the ground.
Although it was originally planned to recover the Walter liquid propulsion unit, which was probably the most expensive single component of the machine, using two salvage parachutes, associated problems were still not fully resolved prior to the war's end.
Professor Wilhelm Fucks reportedly calculated the Natter's aerodynamics at the "Technische Hochschule", Aachen using a large analog computer. Wind tunnel testing on a wooden model, scaled to 40% of full size, was performed at the "Deutsche Versuchsanstalt für Luftfahrt" (DVL), the Institute for Aerodynamics at Berlin-Adlershof in September 1944 at speeds up to 504 km/h. Results from these tests were reported in January 1945 to the Bachem-Werk. Further model tests were carried out at the "Luftfahrtforschungsanstalt Hermann Göring" (LFA) facility in Völkenrode-Braunschweig, at speeds close to Mach 1. In March the Bachem-Werk simply received a statement that satisfactory flying qualities should be expected with speeds up to 1,100 km/h.
Testing.
Construction of the first experimental prototype "Natter, Versuchsmuster 1", was completed on 4 October 1944. V1 was subsequently referred to as "Baumuster1" ("BM1") and later still the "B" was dropped and the machine became known as the M1. Most subsequent prototypes were known by 'M' codes, as the later prototypes of the Heinkel He 162 were. Manned glider flights began on 3 November 1944. The first glider M1 was towed to around 3,000 m by a Heinkel He 111 bomber with a cable ("Tragschlepp" mode) at Neuburg an der Donau. The pilot was Erich Klöckner, who made all four documented "Tragschlepp" flights. After carrying out the test programme of the M1, he bailed out and the machine crashed into the ground. Unfortunately it was found that the towing cable, and in the case of the M3, the undercarriage interfered with the flight characteristics of the gliders and consequently the results were difficult to interpret. To clear any lingering doubts about the Natter in the glider mode, Hans Zübert made a daring free flight in the M8 on the 14 February, and showed that the Natter was indeed a very good flying machine.
The vertical take-off (VTO) trials were conducted on high ground called the Ochsenkopf at the "Truppenübungsplatz" (military training area) Heuberg near Stetten am kalten Markt, Würtemberg. The first successful unmanned vertical take-off from the experimental launch tower occurred on 22 December 1944. The test machine, the M16, was powered only by the Schmidding solid boosters, as were all the early VTO trials. Up to and including 1 March 1945, 16 prototypes had been used, eight in glider trials and eight in VTO trials.
Manned VTO test flight.
By January 1945 Bachem was under pressure from the authorities in Berlin to carry out a manned VTO flight by the end of February. On 25 February, M22 was in the experimental launch tower. It was as complete an operational machine as possible with the Walter HWK 109-509 A1 motor installed for the first time. A dummy pilot was in the cockpit. Lift-off from the tower was perfect. The engineers and ground crew watched spellbound as the M22 ascended under the combined power of the four Schmidding boosters and the Walter motor, an estimated total thrust of . The nose separated as programmed and the dummy pilot descended "safely" under its personal parachute. The remainder of the fuselage came down under its two large salvage parachutes, but when it hit the ground the Walter liquid-propellant rocket motor's residual hypergolic propellants ("T-Stoff" oxidizer and "C-Stoff" fuel) exploded and the machine was destroyed.
Despite Bachem's concerns that the test programme had been significantly cut short, a young volunteer "Luftwaffe" test pilot, Lothar Sieber, climbed into the cockpit of the fully fuelled M23 on 1 March. The aircraft was equipped with an FM transmitter for the purpose of transmitting flight data from various monitoring sensors in the machine.
A hard wire intercom appears to have been provided between Sieber and the engineers in the launch bunker using a system similar to that used in the manned glider flights. Around 1100 am, the M23 was ready for take-off. Low stratus clouds lay over the Ocksenkopf. The Walter liquid-fueled rocket motor built up to full thrust and Sieber pushed the button to ignite the four solid boosters. With a roar, the M23 rose out of a cloud of steam and rocket smoke straight up, displaying its camouflage paintwork. At an altitude of about , the Natter suddenly pitched backwards into an inverted curve. Initially it climbed at about 30° to the vertical. At about the cockpit canopy was seen to fly off. The Natter continued to climb at high speed at an angle of 15° from the horizontal and disappeared into the clouds. The Walter motor stalled about 15 seconds after take-off. It is estimated the Natter reached , at which point it nose-dived and hit the ground with great force about 32 seconds later, some kilometres from the launch site. Unknown at the time, one of the Schmidding boosters failed to jettison and its remains were dug up at the crash site in 1998.
Bachem surmised Sieber had involuntarily pulled back on the control column under the effect of the 3 G acceleration. Examination of the canopy, which fell near the launch site, showed the tip of the latch was bent, suggesting it may not have been in the fully closed position at launch. The pilot's headrest had been attached to the underside of the canopy and as the canopy flew off the pilot's head would have snapped back suddenly about , hitting the solid wooden rear upper cockpit bulkhead, and either knocking Sieber unconscious or breaking his neck.
This tragedy reinforced Bachem's long held belief that the take-off and flight in the vicinity of the target bombers should be fully automated. The canopy latch was strengthened and the headrest was attached to the backboard of the cockpit. Before the introduction of the autopilot in the test programme, the control column would have a temporary locking device on it, which would allow the machine to ascend vertically to at least and then be removed by the pilot. The Walter motor probably ceased operation because the Natter was virtually upside-down and air may have entered the intake pipes in the propellant tanks, starving the motor. Sieber had become the first man to take off vertically from the ground under pure rocket power, some 16 years before Yuri Gagarin's "Vostok 1" pioneering, peacetime orbital flight.
Production.
Much debate has surrounded the number of Natters built at the Bachem-Werk and their disposition. According to Bachem, 36 "Natters" were produced at the Bachem-Werk in Waldsee by the end of the war. Up to April 1945, 17 aircraft had been used in unmanned trials comprising five gliders, all slung under an He 111 in the "Mistelschlepp" configuration prior to launch, and 12 VTO examples. Five aircraft were prepared for manned trials, four gliders and one VTO version. The M3 was flown twice, and then rebuilt at which time it was given the new code BM3a but was never flown. The total number of launches to early April 1945 was 22, as was the total number of Natters constructed up to that time. Bachem reported further that there were 14 more finished or almost finished aircraft in April 1945. Four of these were prototype A1 operational Natters built for test launching from a wooden pole launcher, which had been designed for field deployment. This new launcher was also constructed on the Heuberg, not far from the experimental steel tower. There is documentary evidence for two pole launches in April but not three as claimed by Bachem in his post-war presentation. The documentation for this third flight may have been destroyed by the SS at war's end. Ten A1 operational Natters, called "K-Maschinen", were constructed for the "Krokus-Einsatz" ("Operation Crocus").
The fate of these 14 A1 Natters was as follows:
Three were fired from the pole launcher according to Bachem, four were burnt at Waldsee, two were burnt at "Lager" Schlatt, Oetztal, Austria, four were captured by US troops at Sankt Leonhard im Pitztal, Austria and one, which had been sent as a sample model to a new factory in Thuringia, was captured by the Red Army. Consequently, the total of 36 test and operational aircraft constructed at the Bachem-Werk can be accounted for. However, Natter carcasses were used for a variety of ground-based purposes; for example, as a static booster rocket, armament and strength testing and pilot seat position tests. Some fuselages were reused after flight testing; for example, the M5, 6 and 7.
Of the four Natters captured at Sankt Leonhard im Pitztal, two went to the United States. Only one original Natter built in Germany in the Second World War survives in storage at the Paul E. Garber Preservation, Restoration, and Storage Facility in Suitland, Maryland, under the auspices of the Smithsonian Institution. The fate of the other Natter brought to the US is unknown. There is no documentary evidence that a Natter was ever flown from Muroc Field. The tail section of one of the Natters at Sankt Leonhard im Pitztal was broken off while it still rested on its trailer. The remaining machine was possibly destroyed when the CIOS Field Team left the area. Despite being promised one of these Natters, there is no evidence that a machine ever reached UK shores.
Stability.
In early February 1945 the positions of the centre of gravity for the A1 operational machine during its flight profile were giving the RLM and the SS cause for concern. They wanted these figures to be decided upon for the upcoming construction of the A1 aircraft for "Krokus-Einsatz" (Operation Crocus), the field deployment of the Natter. The position of the centre of gravity is expressed as a percentage of the chord (distance between the leading and trailing edges) of the main wing. Thus 0% is the leading edge and 100% is the trailing edge. In the manned glider trials the centre of gravity had been varied between 20 and 34%. At a meeting of engineers held on 8 February, the variations in the centre of gravity expected in the A1 "Krokus" machine were discussed. At take-off with the weight of the four solid boosters, the centre of gravity would be brought back to 65%, but after releasing these rockets it would move forwards to 22%. The free flight by Zübert on 14 February had showed unequivocally that the little Natter had excellent flying characteristics as a glider. The centre of gravity problem was solved initially by the addition of one-metre-square auxiliary tailfins that were released simultaneously with the jettisoning of the boosters. The "Krokus" aircraft had vanes that would direct the Walter rocket exhaust gases so as to assist vehicle stabilisation at low speed similar to those used in the V-2 rocket.
Legacy.
French forces had captured Waldsee by 25 April 1945 and presumably took control of the Bachem-Werk. Shortly before the French troops arrived, a group of Bachem-Werk personnel set out for Austria with five A1 Natters on trailers. At Bad Wörishofen, the group waited for another squad retreating from Nabern unter Teck with one completed Natter. Both groups then set out for the Austrian Alps. One group with two Natters ended up at the junction of the river Inn and one of its tributaries, the Ötztaler Ache, at Camp Schlatt. The other group went to St. Leonhard im Pitztal with four aircraft. US troops captured the first group at Camp Schlatt around 4 May and the second group on the following day.
At some time during the project, the Bachem-Werk was ordered to give complete details of the BP-20 Natter to the Japanese, but there was doubt over whether they had received them. They were, however, known to have a general knowledge of the Natter and showed considerable interest in the project.
"Operation Krokus" launch pads at Hasenholz wood.
An operational launch site for the first Ba 349A-1 operational Natters under the code name Operation "Krokus" was being established in a small wooded area called Hasenholz, south of the Stuttgart to Munich autobahn and to the east of Nabern unter Teck. Around the end of February and the beginning of March the Todt Organisation was in action, constructing each set of the trios of concrete foundations (or "footings") for the launch towers. These three launch pads and their towers were arranged at the corners of an equilateral triangle, 120 m per side. The specific locations are said to be , and . In the centre of each of the three concrete footings is a square hole approximately 50 centimeters deep, which once served as the foundation for the launch tower. Beside each hole is a pipe, cut off at ground level, which was probably once a cable pit. These three concrete pads were noticed by a surveyor in the autumn of 1945, but not rediscovered until 1999. In March 1945 eight pilots, who were experienced, mostly highly decorated and volunteers for the first operational flights, started training at the Lager Heuberg. This training continued until the first half of April at which time they moved to the Hasenholz operational area. The first three manned and fully armed A1 "Krokus" examples were scheduled to be launched from 20 April, which was Hitler's birthday. But on that day the US 10th Armored Division drove its tanks into Kirchheim unter Teck to the northwest of Hasenholz wood. The next day it crossed the autobahn and headed straight for the Natter operational area. The Natter group subsequently retreated to Waldsee.
Survivor and reproductions.
Only one original A1 Natter survives; it is stored in the Paul E. Garber Preservation, Restoration, and Storage Facility in Suitland, Maryland, USA. It is in a poor state of repair and is no longer accessible to the general public. The evidence supports the proposition that this machine was captured at St. Leonhard im Pitztal, Austria in May 1945 by US troops. The Natter displayed at the Deutsches Museum is said to have been reconstructed partly from sub-assemblies that survived the end of the war. This machine is of the experimental type as launched from the steel tower and is painted to look like an M17. There are several static reproductions of Natters around the world, for example at the Planes of Fame Air Museum, Chino, California and Fantasy of Flight, Polk City, Florida, US.

</doc>
<doc id="58009" url="https://en.wikipedia.org/wiki?curid=58009" title="Good Friday">
Good Friday

Good Friday is a Christian religious holiday commemorating the crucifixion of Jesus Christ and his death at Calvary. The holiday is observed during Holy Week as part of the Paschal Triduum on the Friday preceding Easter Sunday, and may coincide with the Jewish observance of Passover. It is also known as Holy Friday, Great Friday, Black Friday, or Easter Friday, though the last term properly refers to the Friday in Easter week.
Good Friday is a widely instituted legal holiday in many national governments around the world, including in most Western countries (especially among Anglican and Catholic nations) as well as in 12 U.S. states. Some countries, such as Germany, have laws prohibiting certain acts, such as dancing and horse racing, that are seen as profaning the solemn nature of the day.
Etymology.
The etymology of the term "good" in the context of Good Friday is contested. Some sources claim "good" to simply mean "pious" or "holy", while others contend that it is a corruption of "God Friday". The "Oxford English Dictionary" supports the first etymology, giving "of a day or season observed as holy by the church" as an archaic sense of "good" ("good", adj. 8c), and providing examples of "good tide" meaning "Christmas" or "Shrove Tuesday", and "Good Wednesday" meaning the Wednesday in Holy Week.
In German-speaking countries, Good Friday is generally referred to as "Karfreitag" ("Kar" from Old High German "kara"‚ "bewail", "grieve"‚ "mourn", Freitag for "Friday"): Mourning Friday. The "Kar" prefix is an ancestor of the English word "care" in the sense of cares and woes; it meant mourning. The day is also known as "Stiller Freitag" ("Silent Friday") and "Hoher Freitag" ("High Friday, Holy Friday").
Biblical accounts.
According to the accounts in the Gospels, the Temple Guards, guided by Jesus' disciple Judas Iscariot, arrested Jesus in the Garden of Gethsemane. Judas received money (30 pieces of silver) () for betraying Jesus and told the guards that whomever he kisses is the one they are to arrest. Following his arrest, Jesus was taken to the house of Annas, the father-in-law of the high priest, Caiaphas. There he was interrogated with little result and sent bound to Caiaphas the high priest where the Sanhedrin had assembled ().
Conflicting testimony against Jesus was brought forth by many witnesses, to which Jesus answered nothing. Finally the high priest adjured Jesus to respond under solemn oath, saying "I adjure you, by the Living God, to tell us, are you the Anointed One, the Son of God?" Jesus testified ambiguously, "You have said it, and in time you will see the Son of Man seated at the right hand of the Almighty, coming on the clouds of Heaven." The high priest condemned Jesus for blasphemy, and the Sanhedrin concurred with a sentence of death (). Peter, waiting in the courtyard, also denied Jesus three times to bystanders while the interrogations were proceeding just as Jesus had predicted.
In the morning, the whole assembly brought Jesus to the Roman governor Pontius Pilate under charges of subverting the nation, opposing taxes to Caesar, and making himself a king (). Pilate authorized the Jewish leaders to judge Jesus according to their own law and execute sentencing; however, the Jewish leaders replied that they were not allowed by the Romans to carry out a sentence of death ().
Pilate questioned Jesus and told the assembly that there was no basis for sentencing. Upon learning that Jesus was from Galilee, Pilate referred the case to the ruler of Galilee, King Herod, who was in Jerusalem for the Passover Feast. Herod questioned Jesus but received no answer; Herod sent Jesus back to Pilate. Pilate told the assembly that neither he nor Herod found guilt in Jesus; Pilate resolved to have Jesus whipped and released (). Under the guidance of the chief priests, the crowd asked for Barabbas, who had been imprisoned for committing murder during an insurrection. Pilate asked what they would have him do with Jesus, and they demanded, "Crucify him" (). Pilate's wife had seen Jesus in a dream earlier that day, and she forewarned Pilate to "have nothing to do with this righteous man" (). Pilate had Jesus flogged and then brought him out to the crowd to release him. The chief priests informed Pilate of a new charge, demanding Jesus be sentenced to death "because he claimed to be God's son." This possibility filled Pilate with fear, and he brought Jesus back inside the palace and demanded to know from where he came ().
Coming before the crowd one last time, Pilate declared Jesus innocent and washed his own hands in water to show he has no part in this condemnation. Nevertheless, Pilate handed Jesus over to be crucified in order to forestall a riot () and ultimately to keep his job. The sentence written was "Jesus of Nazareth, King of the Jews." Jesus carried his cross to the site of execution (assisted by Simon of Cyrene), called the "place of the Skull", or "Golgotha" in Hebrew and in Latin "Calvary". There he was crucified along with two criminals ().
Jesus agonized on the cross for six hours. During his last three hours on the cross, from noon to 3 pm, darkness fell over the whole land. Jesus spoke from the cross, saying "My God, my God, why have you forsaken me?"
With a loud cry, Jesus gave up his spirit. There was an earthquake, tombs broke open, and the curtain in the Temple was torn from top to bottom. This tear, according to Christian tradition, signified a removal of restriction of the common Jews from the Temple's "Holiest of Holies", and that God's people now could, themselves, communicate directly with their advocate before God, Jesus the Christ, rather than needing the Temple's High Priest as an intercessor. The centurion on guard at the site of crucifixion declared, "Truly this was God's Son!" ()
Joseph of Arimathea, a member of the Sanhedrin and secret follower of Jesus, who had not consented to his condemnation, went to Pilate to request the body of Jesus (). Another secret follower of Jesus and member of the Sanhedrin named Nicodemus brought about a hundred-pound weight mixture of spices and helped wrap the body of Jesus (). Pilate asked confirmation from the centurion of whether Jesus was dead (). A soldier pierced the side of Jesus with a lance causing blood and water to flow out (), and the centurion informed Pilate that Jesus was dead ().
Joseph of Arimathea took Jesus' body, wrapped it in a clean linen shroud, and placed it in his own new tomb that had been carved in the rock () in a garden near the site of crucifixion. Nicodemus () also brought 75 pounds of myrrh and aloes, and placed them in the linen with the body, in keeping with Jewish burial customs (). They rolled a large rock over the entrance of the tomb (). Then they returned home and rested, because Shabbat had begun at sunset (). Matt. 28:1 "After the Sabbath, at dawn on the first day of the week, Mary Magdalene and the other Mary went to look at the tomb". i.e. "After the Sabbath, at dawn on the first day of the week...". "He is not here; he has risen, just as he said...".(Matt. 28:6) On the third day, which is now known as Easter Sunday (or Pascha), Jesus rose from the dead.
In Eastern and Oriental Orthodox Christianity.
Byzantine Christians (Eastern Christians who follow the Rite of Constantinople: Orthodox Christians and Greek-Catholics) call this day "Great and Holy Friday", or simply "Great Friday".
Because the sacrifice of Jesus through his crucifixion is commemorated on this day, the Divine Liturgy (the sacrifice of bread and wine) is never celebrated on Great Friday, except when this day coincides with the Great Feast of the Annunciation, which falls on the fixed date of 25 March (for those churches which follow the traditional Julian Calendar, 25 March currently falls on 7 April of the modern Gregorian Calendar). Also on Great Friday, the clergy no longer wear the purple or red that is customary throughout Great Lent, but instead don black vestments. There is no "stripping of the altar" on Holy and Great Thursday as in the West; instead, all of the church hangings are changed to black, and will remain so until the Divine Liturgy on Great Saturday.
The faithful revisit the events of the day through public reading of specific Psalms and the Gospels, and singing hymns about Christ's death. Rich visual imagery and symbolism as well as stirring hymnody are remarkable elements of these observances. In the Orthodox understanding, the events of Holy Week are not simply an annual commemoration of past events, but the faithful actually participate in the death and resurrection of Jesus.
Each hour of this day is the new suffering and the new effort of the expiatory suffering of the Savior. And the echo of this suffering is already heard in every word of our worship service – unique and incomparable both in the power of tenderness and feeling and in the depth of the boundless compassion for the suffering of the Savior. The Holy Church opens before the eyes of believers a full picture of the redeeming suffering of the Lord beginning with the bloody sweat in the Garden of Gethsemane up to the crucifixion on Golgotha. Taking us back through the past centuries in thought, the Holy Church brings us to the foot of the cross of Christ erected on Golgotha, and makes us present among the quivering spectators of all the torture of the Savior.
Great and Holy Friday is observed as a strict fast, and adult Byzantine Christians are expected to abstain from all food and drink the entire day to the extent that their health permits. "On this Holy day neither a meal is offered nor do we eat on this day of the crucifixion. If someone is unable or has become very old is unable to fast, he may be given bread and water after sunset. In this way we come to the holy commandment of the Holy Apostles not to eat on Great Friday."
Matins of Holy and Great Friday.
The Byzantine Christian observance of Holy and Great Friday, which is formally known as The Order of Holy and Saving Passion of our Lord Jesus Christ, begins on Thursday night with the Matins of the Twelve Passion Gospels. Scattered throughout this Matins service are twelve readings from all four of the Gospels which recount the events of the Passion from the Last Supper through the Crucifixion and burial of Jesus. Some churches have a candelabrum with twelve candles on it, and after each Gospel reading one of the candles is extinguished.
The first of these twelve readings is the longest Gospel reading of the liturgical year, and is a concatenation from all four Gospels. Just before the sixth Gospel reading, which recounts Jesus being nailed to the cross, a large cross is carried out of the sanctuary by the priest, accompanied by incense and candles, and is placed in the center of the nave (where the congregation gathers)"Sēmeron Kremātai Epí Xýlou":
Today He who hung the earth upon the waters is hung upon the Cross "(three times)".<br>He who is King of the angels is arrayed in a crown of thorns.<br>He who wraps the Heavens in clouds is wrapped in the purple of mockery. <br>He who in Jordan set Adam free receives blows upon His face.<br>The Bridegroom of the Church is transfixed with nails. <br>The Son of the Virgin is pierced with a spear.<br>We venerate Thy Passion, O Christ "(three times)".<br>Show us also Thy glorious Resurrection.
The readings are:
During the service, all come forward to kiss the feet of Christ on the cross. After the Canon, a brief, moving hymn, "The Wise Thief" is chanted by singers who stand at the foot of the cross in the center of the nave. The service does not end with the First Hour, as usual, but with a special dismissal by the priest:
May Christ our true God, Who for the salvation of the world endured spitting, and scourging, and buffeting, and the Cross, and death, through the intercessions of His most pure Mother, of our holy and God-bearing fathers, and of all the saints, have mercy on us and save us, for He is good and the Lover of mankind.
Royal Hours.
The next day, in the forenoon on Friday, all gather again to pray the Royal Hours, a special expanded celebration of the Little Hours (including the First Hour, Third Hour, Sixth Hour, Ninth Hour and Typica) with the addition of scripture readings (Old Testament, Epistle and Gospel) and hymns about the Crucifixion at each of the Hours (some of the material from the previous night is repeated). This is somewhat more festive in character, and derives its name of "Royal" from both the fact that the Hours are served with more solemnity than normal, commemorating Christ the King who humbled himself for the salvation of mankind, and also from the fact that this service was in the past attended by the Emperor and his court.
Vespers of Holy and Great Friday.
In the afternoon, around 3 pm, all gather for the Vespers of the Taking-Down from the Cross, commemorating the Deposition from the Cross. The Gospel reading is a concatenation taken from all four of the Gospels. During the service, the body of Christ (the "soma") is removed from the cross, as the words in the Gospel reading mention Joseph of Arimathea, wrapped in a linen shroud, and taken to the altar in the sanctuary. Near the end of the service an "epitaphios" or "winding sheet" (a cloth embroidered with the image of Christ prepared for burial) is carried in procession to a low table in the nave which represents the Tomb of Christ; it is often decorated with an abundance of flowers. The epitaphios itself represents the body of Jesus wrapped in a burial shroud, and is a roughly full-size cloth icon of the body of Christ. Then the priest may deliver a homily and everyone comes forward to venerate the epitaphios. In the Slavic practice, at the end of Vespers, Compline is immediately served, featuring a special "Canon of the Crucifixion of our Lord and the Lamentation of the Most Holy Theotokos" by Symeon the Logothete.
Matins of Holy and Great Saturday.
On Friday night, the Matins of Holy and Great Saturday, a unique service known as The Lamentation at the Tomb ("Epitáphios Thrēnos") is celebrated. This service is also sometimes called "Jerusalem Matins". Much of the service takes place around the tomb of Christ in the center of the nave.
A unique feature of the service is the chanting of the Lamentations or Praises ("Enkōmia"), which consist of verses chanted by the clergy interspersed between the verses of Psalm 119 (which is, by far, the longest psalm in the Bible). The "Enkōmia" are the best-loved hymns of Byzantine hymnography, both their poetry and their music being uniquely suited to each other and to the spirit of the day. They consist of 185 tercet antiphons arranged in three parts ("stáseis" or "stops"), which are interjected with the verses of Psalm 119, and nine short "doxastiká" ("Gloriae") and "Theotókia" (invocations to the Virgin Mary). The three "stáseis" are each set to its own music, and are commonly known by their initial antiphons: , "Life in a grave", , "Worthy it is", and , "All the generations". Musically they can be classified as strophic, with 75, 62, and 48 tercet stanzas each, respectively. The climax of the "Enkōmia" comes during the third "stásis", with the antiphon ""Ō glyký mou Éar"", a lamentation of the Virgin for her dead Child ("O, my sweet spring, my sweetest child, where has your beauty gone?"). The author(s) and date of the "Enkōmia" are unknown. Their High Attic linguistic style suggests a dating around the 6th century, possibly before the time of St. Romanos the Melodist.
At the end of the Great Doxology, while the Trisagion is sung, the epitaphios is taken in procession around the outside the church, and is then returned to the tomb. Some churches observe the practice of holding the epitaphios at the door, above waist level, so the faithful most bow down under it as they come back into the church, symbolizing their entering into the death and resurrection of Christ. The epitaphios will lay in the tomb until the Paschal Service early Sunday morning. In some churches, the epitaphios is never left alone, but is accompanied 24 hours a day by a reader chanting from the Psalter.
The Troparion (hymn of the day) of Good Friday is:
<poem>
The noble Joseph, when he had taken down Thy most pure Body from the tree, wrapped it in fine linen, and anointed it with spices, and placed it in a new tomb.
Glory to the Father, and to the Son, and to the Holy Spirit, both now and ever, and unto ages of ages. Amen.
The angel came to the myrrh-bearing women at the tomb and said:
Myrrh is fitting for the dead, but Christ has shown Himself a stranger to corruption.
</poem>
In the Roman Catholic Church.
Day of Fasting.
The Catholic Church treats Good Friday as a fast day, which in the Latin Church is understood as having only one full meal (but smaller than a regular meal) and two collations (a smaller repast, two of which together do not equal one full meal) and on which the faithful abstain from eating meat. This is why many places have the typical 'Fish Friday'. In countries where Good Friday is not a day of rest from work, the afternoon liturgical service is usually put off until a few hours after the recommended time of 3 pm.
Services on the day.
The Roman Rite has no celebration of Mass between the Lord's Supper on Holy Thursday evening and the Easter Vigil unless a special exemption is granted for rare solemn or grave occasions by the Vatican or the local bishop. The only sacraments celebrated during this time are Baptism (for those in danger of death), Penance, and Anointing of the Sick. While there is no celebration of the Eucharist, it is distributed to the faithful only in the Service of the Passion of the Lord, but can also be taken at any hour to the sick who are unable to attend this service. During this period crosses, candlesticks, and altar cloths are removed from the altar which remains completely bare. Though these things are gradually added to the altar as part of the ceremony. It is also customary to empty the holy water fonts in preparation of the blessing of the water at the Easter Vigil. Traditionally, no bells are rung on Good Friday or Holy Saturday until the Easter Vigil.
The Celebration of the Passion of the Lord takes place in the afternoon, ideally at three o'clock, but for pastoral reasons a later hour may be chosen. The vestments used are red (more commonly) or black (more traditionally).
Before 1970, vestments were black except for the Communion part of the rite when violet was used. Before 1955 black was used throughout. If a bishop or abbot celebrates, he wears a plain mitre ("mitra simplex").
Liturgy.
The Good Friday liturgy consists of three parts: the Liturgy of the Word, the Veneration of the Cross, and Holy Communion.
Stations of the Cross.
In addition to the prescribed liturgical service, the Stations of the Cross are often prayed either in the church or outside, and a prayer service may be held from midday to 3.00 pm, known as the Three Hours' Agony. In countries such as Malta, Italy, Philippines, Puerto Rico and Spain, processions with statues representing the Passion of Christ are held.
In Rome, since the papacy of Saint John Paul II, the heights of the Temple of Venus and Roma and their position opposite the main entrance to the Colosseum have been used to good effect as a public address platform. This may be seen in the photograph below where a red canopy has been erected to shelter the Pope as well as an illuminated cross, on the occasion of the Way of the Cross ceremony. The Pope, either personally or through a representative, leads the faithful through meditations on the stations of the cross while a cross is carried from there to the Colosseum.
In Polish churches, a tableau of Christ's Tomb is unveiled in the sanctuary. Many of the faithful spend long hours into the night grieving at the Tomb, where it is customary to kiss the wounds on the Lord's body. A life-size figure of Jesus lying in his tomb is widely visited by the faithful, especially on Holy Saturday. The tableaux may include flowers, candles, figures of angels standing watch, and the three crosses atop Mt Calvary, and much more. Each parish strives to come up with the most artistically and religiously evocative arrangement in which the Blessed Sacrament, draped in a filmy veil, is prominently displayed.
Acts of Reparation to Jesus Christ.
The Roman Catholic tradition includes specific prayers and devotions as "acts of reparation" for the sufferings and insults that Jesus suffered during his Passion on Good Friday. These "Acts of Reparation to Jesus Christ" do not involve a petition for a living or deceased beneficiary, but aim to "repair the sins" against Jesus. Some such prayers are provided in the Raccolta Catholic prayer book (approved by a Decree of 1854, and published by the Holy See in 1898) which also includes prayers as Acts of Reparation to the Virgin Mary.
In his encyclical "Miserentissimus Redemptor" on reparations, Pope Pius XI called Acts of Reparation to Jesus Christ a duty for Catholics and referred to them as ""some sort of compensation to be rendered for the injury"" with respect to the sufferings of Jesus.
Pope John Paul II referred to Acts of Reparation as the ""unceasing effort to stand beside the endless crosses on which the Son of God continues to be crucified"".
Anglican Communion.
The 1662 Book of Common Prayer did not specify a particular rite to be observed on Good Friday but local custom came to mandate an assortment of services, including the Seven Last Words from the Cross and a three-hour service consisting of Matins, Ante-communion (using the Reserved Sacrament in high church parishes) and Evensong. In recent times revised editions of the Prayer Book and Common Worship have re-introduced pre-Reformation forms of observance of Good Friday corresponding to those in today's Roman Catholic Church, with special nods to the rites that had been observed in the Church of England prior to the Henrican, Edwardian and Elizabethan reforms, including Creeping to the Cross.
Lutheran Church.
In Lutheran tradition from the 16th to the 20th century, Good Friday was the most important religious holiday, and abstention from all worldly works was expected. During that time, Lutheranism had no restrictions on the celebration of the Eucharist on Good Friday; on the contrary, it was a prime day on which to receive the Eucharist, and services were often accentuated by special music such as the "St Matthew Passion" by Johann Sebastian Bach.
More recently, Lutheran liturgical practice has recaptured Good Friday as part of the larger sweep of the great Three Days: Maundy Thursday, Good Friday, and the Vigil of Easter. The Three Days remain one liturgy which celebrates the death and resurrection of Jesus. As part of the liturgy of the Three Days, Lutherans generally fast from the Eucharist on Good Friday. Rather, it is celebrated in remembrance of the Last Supper on Maundy Thursday and at the Vigil of Easter. One practice among Lutheran churches is to celebrate a tenebrae service on Good Friday, typically conducted in candlelight and consisting of a collection of passion accounts from the four gospels. While being called "Tenebrae" it holds little resemblance to the now-suppressed Catholic monastic rite of the same name. The Good Friday liturgy appointed in "Evangelical Lutheran Worship", the worship book of the Evangelical Lutheran Church in America, specifies a liturgy similar to the revised Roman Catholic liturgy. A rite for adoration of the crucified Christ includes the optional singing of the Solemn Reproaches in an updated and revised translation which eliminates some of the anti-Jewish overtones in previous versions. Influenced by the ecumenical liturgical renewal movement and in an attempt to recover patterns of worship from the early church, many Lutheran congregations are moving away from long preaching services centered on a dramatic and sentimentalized remembrance of the "Seven Last Words," sayings of Jesus assembled from the four gospels, toward a more devotional practice that places an emphasis on the triumph of the cross, and a singular biblical account of the Passion narrative from the Gospel of John.
Other Protestant traditions.
Many other Protestant communities hold special services on this day as well. Moravians hold a Lovefeast on Good Friday as they receive Holy Communion on Maundy Thursday. The Methodist Church commemorates Good Friday with a service of worship, often based on the Seven Last Words from the Cross. It is not uncommon for some communities to hold interdenominational services on Good Friday.
Some Baptist, Pentecostal, many Sabbatarian and non-denominational churches oppose the observance of Good Friday, regarding it as a papist tradition, and instead observe the Crucifixion on Wednesday to coincide with the Jewish sacrifice of the Passover Lamb (which Christians believe is an Old Testament pointer to Jesus Christ). A Wednesday Crucifixion of Jesus allows for him to be in the tomb ("heart of the earth") for three days and three nights as he told the Pharisees he would be (Matthew 12:40), rather than two nights and a day if he had died on a Friday. Preparation Day (14 Nisan on the Hebrew calendar) – which is the day before Passover (15 Nisan), instead of the Friday morning found in the Synoptic Gospels.
Associated customs.
In many countries with a strong Christian tradition such as Australia, Bermuda, Brazil, Canada, the countries of the Caribbean, Chile, Colombia, Costa Rica, Ecuador, Finland, Germany, Malta, Mexico, New Zealand, Peru, the Philippines, Singapore, Spain, Sweden, the United Kingdom, and Venezuela, the day is observed as a public or federal holiday. In the United States, 12 states observe Good Friday as state holiday: Connecticut, Texas, Delaware, Hawaii, Indiana, Tennessee, Florida, Kentucky, Louisiana, New Jersey, North Carolina and North Dakota. Germany and some other countries have laws prohibiting certain acts, such as dancing and horse racing, that are seen as profaning the solemn nature of the day.
Australia.
Good Friday is a holiday under state and territory laws in all states and territories in Australia. Generally speaking, shops in all Australian states (but not in the two territories of Northern Territory and the ACT) are required to remain closed for the duration of Good Friday, although there are certain shops which are permitted to open and other shops can apply for exemptions. All schools and universities close on Good Friday in Australia, and Good Friday falls within the school holidays in most years in all states and territories except the Northern Territory, although many states now commence their school holidays in early April regardless of Easter. In 2016, for example, when Good Friday falls on March 25, only Queensland and Victoria have school holidays which coincide with Good Friday. The vast majority of businesses are closed on Good Friday, although many recreational businesses, such as the Sydney Royal Easter Show, open on Good Friday as among non-religious families Good Friday is a popular day to indulge in such activities.
Canada.
In Canada, Good Friday is a federal statutory holiday. In the province of Quebec "employers can choose to give the day off either on Good Friday or Easter Monday."
Cuba.
In an online article posted on Catholic News Agency by Alejandro Bermúdez on 31 March 2012, Cuban President Raúl Castro, with the Communist Party and his advisers, decreed that Good Friday that year would be a holiday. This was Castro's response to a request made personally to him by Pope Benedict XVI during the latter's Apostolic Visitation to the island and León, Mexico that month. The move followed the pattern of small advances in Cuba's relations with the Vatican, mirroring Pope John Paul II's success in getting Fidel Castro to declare Christmas Day a holiday. Both Good Friday and Christmas are now annual holidays in Cuba.
Ireland.
In the Republic of Ireland, Good Friday is not an official public holiday, but most non-retail businesses close for the day. As a predominantly observant Catholic country, religious ceremonies are well attended. It is illegal to sell alcoholic beverages on Good Friday, with some exceptions, so pubs and off-licences generally close. Critics of the ban include the catering and tourism sector, but public surveys indicate substantial support. In Northern Ireland, a similar ban operates until 5pm on Good Friday.
Malta.
The Holy Week commemorations reach their peak on Good Friday as the Roman Catholic Church celebrates the passion of Jesus. Solemn celebrations take place in all churches together with processions in different villages around Malta and Gozo. During the celebration, the narrative of the passion is read in some localities, while the Adoration of the Cross follows. Good Friday processions take place in Birgu, Bormla, Għaxaq, Luqa, Mosta, Naxxar, Paola, Qormi, Rabat, Senglea, Valletta, Żebbuġ (Città Rohan) and Żejtun. Processions in Gozo will be in Nadur, Victoria (St. George and Cathedral), Xagħra and Żebbuġ, Gozo.
The Philippines.
In predominantly Roman Catholic Philippines, the day is commemorated with street processions, the Way of the Cross, the chanting of the "Pasyón", and performances of the "Senákulo" or Passion play. Some devotees engage in self-flagellation and even have themselves crucified as expressions of penance despite health issues and strong disapproval from the Church.
Church bells are not rung and Masses are celebrated, while television and radio have shorter hours, broadcasting mostly religious content. Malls and shops are generally closed, as are restaurants as it is the second of three public holidays within the week.
After three o'clock in the afternoon (the time at which Jesus is traditionally believed to have died), the faithful venerate the cross in the local church and follow the procession of the Burial of Jesus. The image of the dead Christ is then laid in state to be venerated, and sometimes treated in accordance with local burial customs.
In Cebu and many parts of the Visayan Islands, people usually eat "binignit" and "biko" as a form of fasting.
United Kingdom.
In the UK, Good Friday is an official public holiday (a.k.a. Bank Holiday). All schools are closed and most businesses treat it as a holiday for staff; however, many retail stores now remain open. Government services in Northern Ireland operate as normal on Good Friday substituting the holiday for Easter Tuesday.
There has traditionally been no horse racing on Good Friday in the UK. However, in 2008, betting shops and stores opened for the first time on this day and in 2014 Lingfield Park and Musselburgh staged the UK's first Good Friday race meetings. The BBC has for many years introduced its 7 am News broadcast on Radio 4 on Good Friday with a verse from Isaac Watts' hymn "When I Survey the Wondrous Cross".
United States.
In the United States, Good Friday is not a government holiday at the federal level; however, individual states, counties and municipalities may observe the holiday. Good Friday is a state holiday in Connecticut, Delaware, Florida, Hawaii, Indiana, Kentucky (half day), Louisiana, New Jersey, North Carolina, North Dakota, Tennessee and Texas. State and local government offices and courts are closed, as well as some banks and postal offices in these states, and in those counties and municipalities where Good Friday is observed as a holiday. Good Friday is also a holiday in the U.S. territories of Guam, U.S. Virgin Islands and Puerto Rico.
The stock markets are closed on Good Friday but the foreign exchange and bond trading markets open for a partial business day. Most retail stores remain open, while some of them may close early. Public schools and universities are often closed on Good Friday, either as a holiday of its own, or part of spring break. The postal service operates, and banks regulated by the federal government do not close for Good Friday. In some governmental contexts Good Friday has been referred to by a generic name such as "spring holiday".
Calculating the date.
Good Friday is the Friday before Easter, which is calculated differently in Eastern Christianity and Western Christianity (see Computus for details). Easter falls on the first Sunday following the Paschal Full Moon, the full moon on or after 21 March, taken to be the date of the vernal equinox. The Western calculation uses the Gregorian calendar, while the Eastern calculation uses the Julian calendar, whose 21 March now corresponds to the Gregorian calendar's 3 April. The calculations for identifying the date of the full moon also differ. See Computus.
In Eastern Christianity, Easter can fall between 22 March and 25 April on Julian Calendar (thus between 4 April and 8 May in terms of the Gregorian calendar, during the period 1900 and 2099), so Good Friday can fall between 20 March and 23 April, inclusive (or between 2 April and 6 May in terms of the Gregorian calendar).
Cultural references.
Good Friday assumes a particular importance in the plot of Richard Wagner's music drama "Parsifal", which contains an orchestral interlude known as the "Good Friday Music".

</doc>
<doc id="58010" url="https://en.wikipedia.org/wiki?curid=58010" title="Pascha">
Pascha

Pascha may refer to:

</doc>
<doc id="58014" url="https://en.wikipedia.org/wiki?curid=58014" title="Basque">
Basque

Basque may refer to:
In geography:
In other uses:

</doc>
<doc id="58015" url="https://en.wikipedia.org/wiki?curid=58015" title="Mohave people">
Mohave people

Mohave or Mojave (Mojave: 'Aha Makhav) are a Native American people indigenous to the Colorado River in the Mojave Desert. The Fort Mojave Indian Reservation includes territory within the borders of California, Arizona, and Nevada. The Colorado River Indian Reservation includes parts of California and Arizona and is shared by members of the Chemehuevi, Hopi, and Navajo peoples.
The original Colorado River and Fort Mojave reservations were established in 1865 and 1870, respectively. Both reservations include substantial senior water rights in the Colorado River; water is drawn for use in irrigated farming. 
The four combined tribes sharing the Colorado River Indian Reservation function today as one geo-political unit known as the federally recognized Colorado River Indian Tribes; each tribe also continues to maintain and observe its individual traditions, distinct religions, and culturally unique identities.
The Colorado River Indian Tribes headquarters, library and museum are in Parker, Arizona, about 40 miles (64 km) north of I-10. The National Indian Days Celebration is held annually in Parker, from Thursday through Sunday during the last week of September. The All-Indian Rodeo is also celebrated annually, on the first weekend in December. RV facilities are available along the Colorado River.
Culture.
In the 1930s, George Devereux, a Hungarian-French anthropologist, did fieldwork and lived among the Mohave for an extended period of study. He published extensively about their culture and incorporated psychoanalytic thinking in his interpretation of their culture.
Language.
The Mojave language belongs to the River Yuman branch of the Yuman language family. In 1994 approximately 75 people in total on the Colorado River and Fort Mojave reservations spoke the language, according to lingusit Leanne Hinton. The tribe has published language materials, and there are new efforts to teach the language to their children.
Religion.
The Mohave creator is "Matevilya," who gave the people their names and their commandments. His son is "Mastamho," who gave them the River and taught them how to plant. Historically this was an agrarian culture; they planted in the fertile floodplain of the untamed river, following the age-old customs of the Aha macave. They have traditionally used Datura in a religious sacrament. A Mohave who is coming of age must consume the plant in a rite of passage, in order to enter a new state of consciousness.
History.
Much of early Mojave history remains unrecorded in writing, since the Mojave language was not written in precolonial times. They depended on oral communication to transmit their history and culture from one generation to the next. The disruption of disease, outside cultures and encroachment on their territory disrupted their social organization. Together with having to adapt to a majority culture of another language, this resulted in interrupting the Mojave transmission of their stories and songs to the following generations.
The tribal name has been spelled in Spanish and English transliteration in more than 50 variations, such as "Hamock avi", "Amacava," "A-mac-ha ves", "A-moc-ha-ve", "Jamajabs", and "Hamakhav". This has led to misinterpretations of the tribal name, also partly traced to a translation error in Frederick W. Hodge's 1917 "Handbook of the American Indians North of Mexico" (1917). This incorrectly defined the name Mohave as being derived from "hamock," (three), and "avi," (mountain). According to this source, the name refers to the mountain peaks known as The Needles in English, located near the Colorado River. (The city of Needles, California is located a few miles north from here). But, the Mojave call these peaks "Huqueamp avi," which means "where the battle took place," referring to the battle in which the God-son, Mastamho, slew the sea serpent.
Ancestral lands.
The Mojave held lands along the river that stretched from Black Canyon, where the tall pillars of First House of Mutavilya loomed above the river, past Avi kwame or Spirit Mountain, the center of spiritual things, to the Quechan Valley, where the lands of other tribes began. As related to contemporary landmarks, their lands began in the north at Hoover Dam and ended about one hundred miles below Parker Dam on the Colorado River, or "aha kwahwat" in Mojave.
19th–20th centuries.
In mid-April 1859, United States troops of the Expedition of the Colorado, led by Lieutenant Colonel William Hoffman, moved upriver into Mojave country with the well-publicized objective of establishing a military post. It was intended to protect east-west European-American emigrants from attack by the Mojave. By that time, white immigrants and settlers had begun to encroach on Mojave lands. In competition for scarce resources in the desert, they sometimes got into violent conflict with the indigenous people, who were trying to protect their territory. Hoffman sent couriers among the tribes, warning that the post would be gained by force if they or their allies chose to resist. Instead, the army occupied the site without armed conflict.
The Mojave warriors withdrew as Hoffman's formidable armada approached, and the expedition posted camp near the future Fort Mojave. Hoffman ordered the Mojave men to assemble at the armed stockade adjacent to his headquarters; two days later, on April 23, 1859, clan chiefs came as ordered to hear Hoffman's terms of peace. Hoffman gave them the choice of submission or extermination. They chose peace. At that time, the Mojave had a traditional culture that had existed for centuries, unchanged by the few parties of white men who had traveled through their country. Among a Mojave population estimated to be about 4,000 in total, they had 22 clans identified by totems.
During most of the period of military occupation, the Mojave were technically under the jurisdiction of the Office of Indian Affairs of the Department of the Interior. Legally they belonged on the Colorado River Reservation after it was established in 1865. But when many Mojave refused to leave their ancestral homes in the Mojave Valley, the War Department declined to try to force them onto the reservation. The US Indian Agent could not supervise them at a distance. As long as Fort Mojave was garrisoned by the War Department, the Mojave in that area were relatively free to follow their tribal ways. In the midsummer of 1890, the War Department withdrew its troops, after the end of the period of migration and Indian Wars. 
The post was transferred to the Department of the Interior and its Office of Indian Affairs. Beginning in August 1890, Indian Affairs began an intensive program of assimilation; federal policy was based on the belief that this was the only way the peoples could survive. The US Indian agent forced the Mohave and other native children living on reservations into a boarding school to learn to speak, write, and read English. Fort Mojave was converted into an boarding school for Fort Mojave and other "non-reservation" Indians. Until 1931, forty-one years later, all Fort Mojave boys and girls between the ages of six and eighteen were compelled to live at this school or to attend an advanced Indian boarding school remote from Fort Mojave.
In this period, the federal government was trying to assimilate Indians to European-American culture by breaking up tribal culture and governments. The schools taught American culture, customs and English, and insisted that Indian children follow the patterns of the majority culture. At the school the students were required to cut their hair and use European-American hairstyles, clothing, habits of eating, sleeping, toiletry, manners, industry, and language. They were forbidden to use their own language and customs. These were punished when observed. Five lashes of the whip was the penalty for the first offense of speaking in their native tongue. Such corporal punishment of children scandalized the Mojave, who did not discipline their children this way.
The administrators of the reservations' school systems assigned English names to the children. They were registered with the Department of the Interior as members of two tribes, the Mojave Tribe on the Colorado River Reservation and the Fort Mojave Indian Tribe on the Fort Mojave Indian Reservation. These divisions did not reflect the traditional Mojave clan and kinship system. By the late 1960s, 18 of the traditional clans survived.
Population.
Estimates for the pre-contact populations of most native groups in California have varied substantially. The Franciscan missionary-explorer Francisco Garcés estimated the Mohave population in 1776 as approximately 3,000 Mojave Indians (Garcés 1900(2):450). Alfred L. Kroeber (1925:883) also put the 1770 population of the Mohave at 3,000.
A.L. Kroeber estimated the population of the Mohave in 1910 as 1,050. Lorraine M. Sherer's research revealed that by 1963, the population of Fort Mojave was 438 and that of the Colorado River Reservation approximately 550.

</doc>
<doc id="58017" url="https://en.wikipedia.org/wiki?curid=58017" title="Microwave oven">
Microwave oven

A microwave oven, commonly referred to as a microwave, is a kitchen appliance that heats and cooks food by exposing it to microwave radiation in the electromagnetic spectrum. This induces polar molecules in the food to rotate and produce thermal energy in a process known as dielectric heating. Microwave ovens heat foods quickly and efficiently because excitation is fairly uniform in the outer of a homogenous (high water content) food item; food is more evenly heated throughout (except in heterogeneous, dense objects) than generally occurs in other cooking techniques.
Percy Spencer is generally credited with inventing the modern microwave oven after World War II from radar technology developed during the war. Named the "Radarange", it was first sold in 1946. Raytheon later licensed its patents for a home-use microwave oven that was first introduced by Tappan in 1955, but these units were still too large and expensive for general home use. The countertop microwave oven was first introduced in 1967 by the Amana Corporation, and their use has spread into commercial and residential kitchens around the world.
Microwave ovens are popular for reheating previously cooked foods and cooking a variety of foods. They are also useful for rapid heating of otherwise slowly prepared cooking items, such as hot butter, fats, and chocolate. Unlike conventional ovens, microwave ovens usually do not directly brown or caramelize food, since they rarely attain the necessary temperatures to produce Maillard reactions. Exceptions occur in rare cases where the oven is used to heat frying-oil and other very oily items (such as bacon), which attain far higher temperatures than that of boiling water. Microwave ovens have a limited role in professional cooking, because the boiling-range temperatures produced in especially hydrous foods impede flavors produced by the higher temperatures of frying, browning, or baking. However, additional heat sources can be added to microwave ovens, or into combination microwave ovens, to produce these other heating effects, and microwave heating may cut the overall time needed to prepare such dishes. Some modern microwave ovens are part of over-the-range units with built-in extractor hoods.
History.
Early developments.
The exploitation of high-frequency radio waves for heating substances was made possible by the development of vacuum tube radio transmitters around 1920. By 1930 the application of short waves to heat human tissue had developed into the medical therapy of diathermy. At the 1933 Chicago World's Fair, Westinghouse demonstrated the cooking of foods between two metal plates attached to a 10 kW, 60 MHz shortwave transmitter. The Westinghouse team, led by I. F. Mouromtseff, found that foods like steaks and potatoes could be cooked in minutes.
The 1937 United States patent application by Bell Laboratories states and also in Canada:
However, lower-frequency dielectric heating, as described in the aforementioned patent, is (like induction heating) an electromagnetic heating effect, the result of the so-called near-field effects that exist in an electromagnetic cavity that is small compared with the wavelength of the electromagnetic field. This patent proposed radio frequency heating, at 10 to 20 megahertz (wavelength 15 to 30 meters). Heating from microwaves that have a wavelength that is small relative to the cavity (as in a modern microwave oven) is due to "far-field" effects that are due to classical electromagnetic radiation that describes freely propagating light and microwaves suitably far from their source. Nevertheless, the primary heating effect of all types of electromagnetic fields at both radio and microwave frequencies occurs via the dielectric heating effect, as polarized molecules are affected by a rapidly alternating electric field.
Cavity magnetron.
The invention of the cavity magnetron made possible the production of electromagnetic waves of a small enough wavelength (microwaves). The magnetron was originally a crucial component in the development of short wavelength radar during World War II. In 1937–1940, a multi-cavity magnetron was built by the British physicist Sir John Turton Randall, FRSE, together with a team of British coworkers, for the British and American military radar installations in World War II. A more high-powered microwave generator that worked at shorter wavelengths was needed, and in 1940, at the University of Birmingham, John Randall and Harry Boot produced a working prototype.
Sir Henry Tizard travelled to the U.S. in late September 1940 to offer the magnetron in exchange for their financial and industrial help (see Tizard Mission). An early 6 kW version, built in England by the General Electric Company Research Laboratories, Wembley, London, was given to the U.S. government in September 1940. Contracts were awarded to Raytheon and other companies for mass production of the magnetron.
Discovery.
In 1945 the specific heating effect of a high-power microwave beam was accidentally discovered by Percy Spencer, an American self-taught engineer from Howland, Maine. Employed by Raytheon at the time, he noticed that microwaves from an active radar set he was working on started to melt a candy bar he had in his pocket. The first food deliberately cooked with Spencer's microwave was popcorn, and the second was an egg, which exploded in the face of one of the experimenters. To verify his finding, Spencer created a high density electromagnetic field by feeding microwave power from a magnetron into a metal box from which it had no way to escape. When food was placed in the box with the microwave energy, the temperature of the food rose rapidly.
On October 8, 1945, Raytheon filed a United States patent application for Spencer's microwave cooking process, and an oven that heated food using microwave energy from a magnetron was soon placed in a Boston restaurant for testing. The first time the public was able to use a microwave oven was in January 1947, when the Speedy Weeny vending machine was placed in Grand Central Terminal to dispense "sizzling delicious" hot dogs. Among those on the development team was robotics pioneer George Devol, who had spent the last part of the war developing radar countermeasures.
Commercial availability.
In 1947, Raytheon built the "Radarange", the first commercially available microwave oven. It was almost tall, weighed and cost about US$5,000 ($ in today's dollars) each. It consumed 3 kilowatts, about three times as much as today's microwave ovens, and was water-cooled. An early Radarange was installed (and remains) in the galley of the nuclear-powered passenger/cargo ship NS "Savannah". An early commercial model introduced in 1954 consumed 1.6 kilowatts and sold for US$2,000 to US$3,000 ($ to $ in today's dollars). Raytheon licensed its technology to the Tappan Stove company of Mansfield, Ohio in 1952. They tried to market a large 220 volt wall unit as a home microwave oven in 1955 for a price of US$1,295 ($ in today's dollars), but it did not sell well. In 1965, Raytheon acquired Amana. In 1967, they introduced the first popular home model, the countertop Radarange, at a price of US$495 ($ in today's dollars).
In the 1960s, Litton bought Studebaker's Franklin Manufacturing assets, which had been manufacturing magnetrons and building and selling microwave ovens similar to the Radarange. Litton then developed a new configuration of the microwave: the short, wide shape that is now common. The magnetron feed was also unique. This resulted in an oven that could survive a no-load condition: an empty microwave oven where there is nothing to absorb the microwaves. The new oven was shown at a trade show in Chicago, and helped begin a rapid growth of the market for home microwave ovens. Sales volume of 40,000 units for the U.S. industry in 1970 grew to one million by 1975. Market penetration was faster in Japan, due to a re-engineered magnetron allowing for less expensive units.
Several other companies joined in the market, and for a time most systems were built by defense contractors, who were most familiar with the magnetron. Litton was particularly well known in the restaurant business.
Residential use.
By the late 1970s, technological advances led to rapidly falling prices. Often called "electronic ovens" in the 1960s, the name "microwave oven" later gained currency, and they are now informally called "microwaves".
Formerly found only in large industrial applications, microwave ovens increasingly became a standard fixture of residential kitchens in developed countries. By 1986, roughly 25% of households in the U.S. owned a microwave oven, up from only about 1% in 1971; the U.S. Bureau of Labor Statistics reported that over 90% of American households owned a microwave oven in 1997. In Australia, a 2008 market research study found that 95% of kitchens contained a microwave oven and that 83% of them were used daily. In Canada, fewer than 5% of households had a microwave oven in 1979, but more than 88% of households owned one by 1998. In France, 40% of households owned a microwave oven in 1994, but that number had increased to 65% by 2004.
Adoption has been slower in less-developed countries, as households with disposable income concentrate on more important household appliances like refrigerators and ovens. In India in 2013, for example, only about 5% of households owned a microwave, well behind refrigerators at 31% ownership. Microwave ovens are gaining popularity, however. In Russia, the number of households with a microwave grew from almost 24% in 2002 to almost 40% in 2008. Almost twice as many households in South Africa owned microwaves in 2008 (38.7%) than in 2002 (19.8%). Microwave ownership in Vietnam was at 16% of households in 2008—versus 30% ownership of refrigerators—but this rate was up significantly from 6.7% microwave ownership in 2002—and 14% for refrigerators.
Principles.
A microwave oven heats food by passing microwave radiation through it. Microwaves are a form of non-ionizing electromagnetic radiation with a frequency higher than ordinary radio waves but lower than infrared light. Microwave ovens use frequencies in one of the ISM (industrial, scientific, medical) bands, which are reserved for this use, so they do not interfere with other vital radio services. Consumer ovens usually use 2.45 gigahertz (GHz)—a wavelength of —while large industrial/commercial ovens often use 915 megahertz (MHz)—. Water, fat, and other substances in the food absorb energy from the microwaves in a process called dielectric heating. Many molecules (such as those of water) are electric dipoles, meaning that they have a partial positive charge at one end and a partial negative charge at the other, and therefore rotate as they try to align themselves with the alternating electric field of the microwaves. Rotating molecules hit other molecules and put them into motion, thus dispersing energy. This energy, when dispersed as molecular vibration in solids and liquids (i.e. as both potential energy and kinetic energy of atoms), is heat. Sometimes, microwave heating is explained as a resonance of water molecules, but this is incorrect; such resonances occur only at above 1 terahertz (THz). Rather it is the lag in response of the polar water molecule to the impending electromagnetic wave. This type of dieletric loss mechanism is referred to as dipole interaction.
Microwave heating is more efficient on liquid water than on frozen water, where the movement of molecules is more restricted. Dielectric heating of liquid water is also temperature-dependent: At 0 °C, dielectric loss is greatest at a field frequency of about 10 GHz, and for higher water temperatures at higher field frequencies.
Compared to liquid water, microwave heating is less efficient on fats and sugars (which have a smaller molecular dipole moment). Sugars and triglycerides (fats and oils) absorb microwaves due to the dipole moments of their hydroxyl groups or ester groups. However, due to the lower specific heat capacity of fats and oils and their higher vaporization temperature, they often attain much higher temperatures inside microwave ovens. This can induce temperatures in oil or very fatty foods like bacon far above the boiling point of water, and high enough to induce some browning reactions, much in the manner of conventional broiling (UK: grilling), braising, or deep fat frying. Foods high in water content and with little oil rarely exceed the boiling temperature of water.
Microwave heating can cause localized thermal runaways in some materials with low thermal conductivity which also have dielectric constants that increase with temperature. An example is glass, which can exhibit thermal runaway in a microwave to the point of melting if preheated. Additionally, microwaves can melt certain types of rocks, producing small quantities of synthetic lava. Some ceramics can also be melted, and may even become clear upon cooling. Thermal runaway is more typical of electrically conductive liquids such as salty water.
A common misconception is that microwave ovens cook food "from the inside out", meaning from the center of the entire mass of food outwards. This idea arises from heating behavior seen if an absorbent layer of water lies beneath a less absorbent drier layer at the surface of a food; in this case, the deposition of heat energy inside a food can exceed that on its surface. This can also occur if the inner layer has a lower heat capacity than the outer layer causing it to reach a higher temperature, or even if the inner layer is more thermally conductive than the outer layer making it feel hotter despite having a lower temperature. In most cases, however, with uniformly structured or reasonably homogenous food item, microwaves are absorbed in the outer layers of the item at a similar level to that of the inner layers. Depending on water content, the depth of initial heat deposition may be several centimetres or more with microwave ovens, in contrast to broiling/grilling (infrared) or convection heating—methods which deposit heat thinly at the food surface. Penetration depth of microwaves is dependent on food composition and the frequency, with lower microwave frequencies (longer wavelengths) penetrating further.
Heating efficiency.
A microwave oven converts only part of its electrical input into microwave energy. An average consumer microwave oven consumes 1100 W of electricity in producing 700 W of microwave power, an efficiency of 64%. Such wasted heat, along with heat from the product being microwaved, is exhausted as warm air through cooling vents. The other 400 W are dissipated as heat, mostly in the magnetron tube. Additional power is used to operate the lamps, AC power transformer, magnetron cooling fan, food turntable motor and the control circuits, although the power consumed by the electronic control circuits of a modern microwave oven is negligible (< 1% of the input power) during cooking.
For cooking or reheating small amounts of food, the microwave oven may use less energy than a cook stove. Although microwave ovens are touted as the most efficient appliance, the energy savings are largely due to the reduced heat mass of the food's container. The amount of energy used to heat food is generally small compared to total energy usage in typical residences in the United States.
Design.
A microwave oven consists of:
Modern microwave ovens use either an analog dial-type timer or a digital control panel for operation. Control panels feature an LED, liquid crystal or vacuum fluorescent display, numeric buttons for entering the cook time, a power level selection feature and other possible functions such as a defrost setting and pre-programmed settings for different food types, such as meat, fish, poultry, vegetables, frozen vegetables, frozen dinners, and popcorn. In most ovens, the magnetron is driven by a linear transformer which can only feasibly be switched completely on or off. As such, the choice of power level does not affect the intensity of the microwave radiation; instead, the magnetron is cycled on and off every few seconds. Newer models have inverter power supplies that use pulse width modulation to provide effectively continuous heating at reduced power, so that foods are heated more evenly at a given power level and can be heated more quickly without being damaged by uneven heating.
The microwave frequencies used in microwave ovens are chosen based on regulatory and cost constraints. The first is that they should be in one of the industrial, scientific, and medical (ISM) frequency bands set aside for non-communication purposes. For household purposes, 2.45 GHz has the advantage over 915 MHz in that 915 MHz is only an ISM band in the ITU Region 2 while 2.45 GHz is available worldwide. Three additional ISM bands exist in the microwave frequencies, but are not used for microwave cooking. Two of them are centered on 5.8 GHz and 24.125 GHz, but are not used for microwave cooking because of the very high cost of power generation at these frequencies. The third, centered on 433.92 MHz, is a narrow band that would require expensive equipment to generate sufficient power without creating interference outside the band, and is only available in some countries.
The cooking chamber is similar to a Faraday cage (but there is no continuous metal-to-metal contact around the rim of the door), and prevents the waves from coming out of the oven. The oven door usually has a window for easy viewing, with a layer of conductive mesh some distance from the outer panel to maintain the shielding. Because the size of the perforations in the mesh is much less than the microwaves' wavelength (12.2 cm for the usual 2.45 GHz), most of the microwave radiation cannot pass through the door, while visible light (with its much shorter wavelength) can.
Variants and accessories.
A quantitative, model-based understanding of heat exchange in infrared and combined infrared-microwave heating of food inside an oven is developed. A variant of the conventional microwave is the convection microwave. A convection microwave oven is a combination of a standard microwave and a convection oven. It allows food to be cooked quickly, yet come out browned or crisped, as from a convection oven. Convection microwaves are more expensive than conventional microwave ovens. Some convection microwaves—those with exposed heating elements—can produce smoke and burning odors as food spatter from earlier microwave-only use is burned off the heating elements.
In 2000, some manufacturers began offering high power quartz halogen bulbs to their convection microwave models, marketing them under names such as "Speedcook", "Advantium" , "Lightwave" and "Optimawave" to emphasize their ability to cook food rapidly and with good browning. The bulbs heat the food's surface with infrared (IR) radiation, browning surfaces as in a conventional oven. The food browns while also being heated by the microwave radiation and heated through conduction through contact with heated air. The IR energy which is delivered to the outer surface of food by the lamps is sufficient to initiate browning caramelization in foods primarily made up of carbohydrates and Maillard reactions in foods primarily made up of protein. These reactions in food produce a texture and taste similar to that typically expected of conventional oven cooking rather than the bland boiled and steamed taste that microwave-only cooking tends to create.
In order to aid browning, sometimes an accessory browning tray is used, usually composed of glass or porcelain. It makes food crisp by oxidizing the top layer until it turns brown. Ordinary plastic cookware is unsuitable for this purpose because it could melt.
Frozen dinners, pies, and microwave popcorn bags often contain a susceptor made from thin aluminium film in the packaging or included on a small paper tray. The metal film absorbs microwave energy efficiently and consequently becomes extremely hot and radiates in the infrared, concentrating the heating of oil for popcorn or even browning surfaces of frozen foods. Heating packages or trays containing susceptors are designed for single use and are discarded as waste.
Microwave-safe plastics.
Some current plastic containers and food wraps are specifically designed to resist radiation from microwaves. Products may use the term "microwave safe", may carry a microwave symbol (three lines of waves, one above the other) or simply provide instructions for proper microwave use. Any of these is an indication that a product is suitable for microwaving when used in accordance with the directions provided.
Benefits and safety features.
Commercial microwave ovens all use a timer in their standard operating mode; when the timer runs out, the oven turns itself off.
Microwave ovens heat food without getting hot themselves. Taking a pot off a stove, unless it is an induction cooktop, leaves a potentially dangerous heating element or trivet that will stay hot for some time. Likewise, when taking a casserole out of a conventional oven, one's arms are exposed to the very hot walls of the oven. A microwave oven does not pose this problem.
Food and cookware taken out of a microwave oven are rarely much hotter than . Cookware used in a microwave oven is often much cooler than the food because the cookware is transparent to microwaves; the microwaves heat the food directly and the cookware is indirectly heated by the food. Food and cookware from a conventional oven, on the other hand, are the same temperature as the rest of the oven; a typical cooking temperature is . That means that conventional stoves and ovens can cause more serious burns.
The lower temperature of cooking (the boiling point of water) is a significant safety benefit compared to baking in the oven or frying, because it eliminates the formation of tars and char, which are carcinogenic. Microwave radiation also penetrates deeper than direct heat, so that the food is heated by its own internal water content. In contrast, direct heat can fry the surface while the inside is still cold. Pre-heating the food in a microwave oven before putting it into the grill or pan reduces the time needed to heat up the food and reduces the formation of carcinogenic char. Unlike frying and baking, microwaving does not produce acrylamide in potatoes, however unlike deep-frying, it is of only limited effectiveness in reducing glycoalkaloid (i.e. solanine) levels. Acrylamide has been found in other microwaved products like popcorn.
Heating characteristics.
Microwave ovens are frequently used for reheating leftover food, and bacterial contamination may not be repressed if the safe temperature is not reached, resulting in foodborne illness, as with all inadequate reheating methods.
Uneven heating in microwaved food can be partly due to the uneven distribution of microwave energy inside the oven, and partly due to the different rates of energy absorption in different parts of the food. The first problem is reduced by a stirrer, a type of fan that reflects microwave energy to different parts of the oven as it rotates, or by a turntable or carousel that turns the food; turntables, however, may still leave spots, such as the center of the oven, which receive uneven energy distribution. The location of dead spots and hot spots in a microwave can be mapped out by placing a damp piece of thermal paper in the oven. When the water saturated paper is subjected to the microwave radiation it becomes hot enough to cause the dye to be released which will provide a visual representation of the microwaves. If multiple layers of paper are constructed in the oven with a sufficient distance between them a three-dimensional map can be created. Many store receipts are printed on thermal paper which allows this to be easily done at home.
The second problem is due to food composition and geometry, and must be addressed by the cook, by arranging the food so that it absorbs energy evenly, and periodically testing and shielding any parts of the food that overheat. In some materials with low thermal conductivity, where dielectric constant increases with temperature, microwave heating can cause localized thermal runaway. Under certain conditions, glass can exhibit thermal runaway in a microwave to the point of melting.
Due to this phenomenon, microwave ovens set at too-high power levels may even start to cook the edges of frozen food while the inside of the food remains frozen. Another case of uneven heating can be observed in baked goods containing berries. In these items, the berries absorb more energy than the drier surrounding bread and cannot dissipate the heat due to the low thermal conductivity of the bread. Often this results in overheating the berries relative to the rest of the food. "Defrost" oven settings use low power levels designed to allow time for heat to be conducted within frozen foods from areas that absorb heat more readily to those which heat more slowly. In turntable-equipped ovens, more even heating will take place by placing food off-centre on the turntable tray instead of exactly in the centre.
Microwave heating can be deliberately uneven by design. Some microwavable packages (notably pies) may include materials that contain ceramic or aluminium flakes, which are designed to absorb microwaves and heat up, thereby converting microwaves to less penetrating infrared, which aids in baking or crust preparation by depositing more energy shallowly in these areas. Such ceramic patches affixed to cardboard are positioned next to the food, and are typically smokey blue or gray in colour, usually making them easily identifiable; the cardboard sleeves included with Hot Pockets, which have a silver surface on the inside, are a good example of such packaging. Microwavable cardboard packaging may also contain overhead ceramic patches which function in the same way. The technical term for such a microwave-absorbing patch is a susceptor.
Effects on food and nutrients.
Comparative cooking method studies generally find that, if properly used, microwave cooking does not affect the nutrient content of foods to a larger extent than conventional heating, and that there is a tendency towards greater retention of many micronutrients with microwaving, probably due to the reduced preparation time. Microwaving human milk at high temperatures is contraindicated, due to a marked decrease in activity of anti-infective factors.
Any form of cooking will destroy some nutrients in food, but the key variables are how much water is used in the cooking, how long the food is cooked, and at what temperature. Nutrients are primarily lost by leaching into cooking water, which tends to make microwave cooking healthier, given the shorter cooking times it requires. Like other heating methods, microwaving converts vitamin B12 from an active to inactive form. The amount inactivated depends on the temperature reached, as well as the cooking time. Boiled food reaches a maximum of (the boiling point of water), whereas microwaved food can get locally hotter than this, leading to faster breakdown of vitamin B12. The higher rate of loss is partially offset by the shorter cooking times required. A single study indicated that microwaving broccoli loses 74% or more of phenolic compounds (97% of flavonoids), while boiling loses 66% of flavonoids, and high-pressure boiling loses 47%, though the study has been contradicted by other studies. To minimize phenolic losses in potatoes, microwaving should be done at 500W.
Spinach retains nearly all its folate when cooked in a microwave; in comparison, it loses about 77% when boiled, leaching out nutrients. Bacon cooked by microwave has significantly lower levels of carcinogenic nitrosamines than conventionally cooked bacon. Steamed vegetables tend to maintain more nutrients when microwaved than when cooked on a stovetop. Microwave blanching is 3-4 times more effective than boiled water blanching in the retaining of the water-soluble vitamins folic acid, thiamin and riboflavin, with the exception of ascorbic acid, of which 28.8% is lost (vs. 16% with boiled water blanching).
Use in cleaning kitchen sponges.
Studies have investigated the use of the microwave to clean non-metallic domestic sponges which have been thoroughly wetted. A 2006 study found that microwaving wet sponges for two minutes (at 1000 watt power) removed 99% of coliforms, E. coli and MS2 phages, and Bacillus cereus spores were killed at 4 minutes of microwaving.
Hazards.
High temperatures.
Homogeneous liquids can superheat when heated in a microwave oven in a container with a smooth surface. That is, the liquid reaches a temperature slightly above its normal boiling point without bubbles of vapour forming inside the liquid. The boiling process can start explosively when the liquid is disturbed, such as when the user takes hold of the container to remove it from the oven or while adding solid ingredients such as powdered creamer or sugar. This can result in spontaneous boiling (nucleation) which may be violent enough to eject the boiling liquid from the container and cause severe scalding.
Closed containers, such as eggs, can explode when heated in a microwave oven due to the increased pressure from steam. Insulating plastic foams of all types generally contain closed air pockets, and are generally not recommended for use in a microwave, as the air pockets explode and the foam (which can be toxic if consumed) may melt. Not all plastics are microwave-safe, and some plastics absorb microwaves to the point that they may become dangerously hot.
Products that are heated for too long can catch fire. Though this is inherent to any form of cooking, the rapid cooking and unattended nature of the use of microwave ovens results in additional hazard.
Metal objects.
Any metal or conductive object placed into the microwave will act as an antenna to some degree, resulting in an electric current. This causes the object to act as a heating element. This effect varies with the object's shape and composition, and is sometimes utilized for cooking.
Any object containing pointed metal can create an electric arc (sparks) when microwaved. This includes cutlery, crumpled aluminium foil (though some foil used in microwaves are safe, see below), twist-ties containing metal wire, the metal wire carry-handles in paper Chinese take-out food containers, or almost any metal formed into a poorly conductive foil or thin wire; or into a pointed shape. Forks are a good example: the tines of the fork respond to the electric field by producing high concentrations of electric charge at the tips. This has the effect of exceeding the dielectric breakdown of air, about 3 megavolts per meter (3×106 V/m). The air forms a conductive plasma, which is visible as a spark. The plasma and the tines may then form a conductive loop, which may be a more effective antenna, resulting in a longer lived spark. When dielectric breakdown occurs in air, some ozone and nitrogen oxides are formed, both of which are unhealthy in large quantities.
It is possible for metal objects to be microwave-oven compatible, although experimentation by users is not encouraged. Microwaving an individual smooth metal object without pointed ends, for example, a spoon or shallow metal pan, usually does not produce sparking. Thick metal wire racks can be part of the interior design in microwave ovens (see illustration). In a similar way, the interior wall plates with perforating holes which allow light and air into the oven, and allow interior-viewing through the oven door, are all made of conductive metal formed in a safe shape.
The effect of microwaving thin metal films can be seen clearly on a Compact Disc or DVD (particularly the factory pressed type). The microwaves induce electric currents in the metal film, which heats up, melting the plastic in the disc and leaving a visible pattern of concentric and radial scars. Similarly, porcelain with thin metal films can also be destroyed or damaged by microwaving. Aluminium foil is thick enough to be used in microwave ovens as a shield against heating parts of food items, if the foil is not badly warped. When wrinkled, aluminium foil is generally unsafe in microwaves, as manipulation of the foil causes sharp bends and gaps that invite sparking. The USDA recommends that aluminium foil used as a partial food shield in microwave cooking cover no more than one quarter of a food object, and be carefully smoothed to eliminate sparking hazards.
Another hazard is the resonance of the magnetron tube itself. If the microwave is run without an object to absorb the radiation, a standing wave will form. The energy is reflected back and forth between the tube and the cooking chamber. This may cause the tube to overload and burn out. For the same reason, dehydrated food, or food wrapped in metal which does not arc, is problematic for overload reasons, without necessarily being a fire hazard.
Certain foods such as grapes, if properly arranged, can produce an electric arc. Prolonged arcing from food carries similar risks to arcing from other sources as noted above.
Some other objects that may conduct sparks are plastic/holographic print thermoses (such as Starbuck's novelty cups) or cups with metal lining. If any bit of the metal is exposed, all the outer shell will burst off the object or melt.
The high electrical fields generated inside a microwave often can be illustrated by placing a radiometer or neon glow-bulb inside the cooking chamber, creating glowing plasma inside the low-pressure bulb of the device.
Direct microwave exposure.
Direct microwave exposure is not generally possible, as microwaves emitted by the source in a microwave oven are confined in the oven by the material out of which the oven is constructed. Furthermore, ovens are equipped with redundant safety interlocks, which remove power from the magnetron if the door is opened. This safety mechanism is required by United States federal regulations. Tests have shown confinement of the microwaves in commercially available ovens to be so nearly universal as to make routine testing unnecessary. According to the United States Food and Drug Administration's Center for Devices and Radiological Health, a U.S. Federal Standard limits the amount of microwaves that can leak from an oven throughout its lifetime to 5 milliwatts of microwave radiation per square centimeter at approximately (2 in) from the surface of the oven. This is far below the exposure level currently considered to be harmful to human health.
The radiation produced by a microwave oven is non-ionizing. It therefore does not have the cancer risks associated with ionizing radiation such as X-rays and high-energy particles. Long-term rodent studies to assess cancer risk have so far failed to identify any carcinogenicity from microwave radiation even with chronic exposure levels (i.e. large fraction of life span) far larger than humans are likely to encounter from any leaking ovens. However, with the oven door open, the radiation may cause damage by heating. Every microwave oven sold has a protective interlock so that it cannot be run when the door is open or improperly latched.
Microwaves generated in microwave ovens cease to exist once the electrical power is turned off. They do not remain in the food when the power is turned off, any more than light from an electric lamp remains in the walls and furnishings of a room when the lamp is turned off. They do not make the food or the oven radioactive. There is some evidence that nutritional content of some foods may be altered differently by cooking in a microwave oven, compared to conventional cooking, but there is no indication of detrimental health issues associated with microwaved food.
There are, however, a few cases where people have been exposed to direct microwave radiation, either from appliance malfunction or deliberate action. The general effect of this exposure will be physical burns to the body, as human tissue, particularly the outer fat and muscle layers, has similar composition to some foods that are typically cooked in microwave ovens and so experiences similar dielectric heating effects when exposed to microwave electromagnetic radiation.
Chemical exposure.
Some magnetrons have ceramic insulators with beryllium oxide (beryllia) added. The beryllium in such oxides is a serious chemical hazard if crushed and ingested (for example, by inhaling dust). In addition, beryllia is listed as a confirmed human carcinogen by the IARC; therefore, broken ceramic insulators or magnetrons should not be handled. This is obviously a danger only if the microwave oven becomes physically damaged, such as if the insulator cracks, or when the magnetron is opened and handled directly, and as such should not be a concern during normal usage.

</doc>
<doc id="58018" url="https://en.wikipedia.org/wiki?curid=58018" title="Tora! Tora! Tora!">
Tora! Tora! Tora!

Tora! Tora! Tora! () is a 1970 Japanese-American war film that dramatizes the Japanese attack on Pearl Harbor in 1941. The film was directed by Richard Fleischer, Toshio Masuda and Kinji Fukasaku and stars an ensemble cast, including Martin Balsam, Joseph Cotten, Sō Yamamura, E. G. Marshall, James Whitmore and Jason Robards.
The title is the Japanese codeword used to indicate that complete surprise had been achieved. "Tora" (虎, ) literally means "tiger", but in this case was an acronym for "totsugeki raigeki"　(突撃雷撃, "lightning attack").
Plot.
In August 1939, the newly appointed Commander-in-Chief of the Combined Fleet Admiral Isoroku Yamamoto (Sō Yamamura) and his predecessor, Zengo Yoshida (Junya Usami), discuss America's embargo that starves Japan of raw materials. While both agree that a war with the United States would be a complete disaster, army hotheads and politicians push through an alliance with Germany and Italy in September 1940 and start planning for war. With the U.S. Pacific fleet at Pearl Harbor, Yamamoto orders the planning of a preventive strike, believing Japan's only hope is to annihilate the American Pacific fleet at the outset of hostilities.
When planning the attack, the Japanese commanders modify their torpedoes to dive to only 35 ft, negating Pearl Harbor's shallow waters, which the Americans feel is a natural defense against torpedoes. In a major intelligence victory, American intelligence in Washington manages to break the Japanese "Purple Code", allowing the United States to intercept secret Japanese radio transmissions. Monitoring the transmissions are U.S. Army Col. Bratton (E. G. Marshall) and U.S. Navy Lt. Commander Kramer (Wesley Addy).
Japanese commanders call on the famous Air Staff Officer Minoru Genda (Tatsuya Mihashi) to mastermind the attack. Genda's Japanese Naval Academy classmate, Mitsuo Fuchida (Takahiro Tamura), is chosen to be the leader of the attack. At Pearl Harbor, although hampered by a late-arriving critical intelligence report about the attack fleet, Admiral Kimmel (Martin Balsam) and General Short (Jason Robards) do their best to enhance defenses. Short orders his aircraft to be concentrated in the middle of their airfields to prevent sabotage, though leaving them vulnerable to an air raid. Kimmel calls for more B-17 bombers to patrol offshore to provide early warning of any enemy vessels or airplanes, and increases patrols off the harbor entrance.
Diplomatic tensions increase between the U.S. and Japan as the Japanese ambassador continues negotiations to avoid war. Army General Hideki Tojo (Asao Uchida) is adamantly opposed to any last minute attempts at peace. The Japanese commence a series of 14 radio messages from Tokyo to the Japanese embassy in Washington that will conclude with a declaration of war. The final message will be received precisely at 1:00 pm on December 7, 1941 after which the Japanese embassy is to destroy the code machines, an ominous point. Attempts to convey this message to American commanders fail because it is Sunday and they have the day off. Finally, Chief of Naval Operations Harold R. Stark (Edward Andrews) is informed of the increased threat, but decides not to inform Hawaii until after calling the President, although it is not clear if he takes any action at all.
Finally, at 11:30 am, Colonel Bratton convinces the Army Chief of Staff, General George Marshall (Keith Andes), that a greater threat exists, and Marshall orders that Pearl Harbor be notified of an impending attack. An American destroyer, , spots a Japanese midget submarine trying to slip through the defensive net and enter Pearl Harbor, sinks it, and notifies the base. Although the receiving officer, Lieutenant Kaminsky (Neville Brand), takes the report of an attempted foreign incursion seriously, Captain John Earle (Richard Anderson) at Pearl Harbor demands confirmation before calling an alert. Admiral Kimmel later learns of this and is furious he was not told of this foreign action immediately. Meanwhile, the two privates posted at the remote radar station spot the incoming Japanese aircraft and inform the Hickham Field Information Center, but the Army Air Forces Lieutenant on duty, Kermit Tyler (Jerry Cox), dismisses the report, assuming it is a group of American B-17 Flying Fortresses inbound from the mainland.
The Japanese intend to break off negotiations at 1:00 pm, 30 minutes before the attack. However, the typist for the Japanese ambassador is slow, and cannot translate and transcribe the 14th message quickly enough to meet the deadline. A final attempt to warn Pearl Harbor is stymied by poor atmospherics that prevent radio transmission, and bungling when a warning sent by telegram is not marked urgent; it will be received by Pearl Harbor after the attack. 
The incoming Japanese fighter pilots receive no anti-aircraft fire as they approach the base, encountering only a civilian biplane on their way in. As a result, strike commander Fuchida, riding in a Nakajima B5N "Kate," radios in the code phrase marking that complete surprise has been achieved: "Tora! Tora! Tora!"
Once the attack begins, the Americans are not even aware that the planes overhead are not American until the first bomb drops. The resultant hasty response is desperate and only partially effective. General Short's anti-sabotage precautions prove a disastrous mistake that allows the Japanese aerial forces to destroy the U.S. aircraft on the ground with ease, thereby preventing an effective aerial counter-attack; most of the aircraft on the major airfields are destroyed either as they attempted to take off or while they were still parked. Two American fighter pilots (portrayals of Second Lieutenants Ken Taylor and George Welch) race to remote Haleiwa Field and manage to take off in their P-40s to engage the attacking aircraft, as the Japanese have not hit the satellite airfields.
The damage to the naval base is catastrophic, with sailors fighting as long as they can before abandoning sinking ships and jumping into the water with oil burning on the surface, while sailors and Marines on Ford Island fight back as best they can with the few machine guns available. When the attacks are over, with the Pearl Harbor naval base in flames, Admiral Kimmel finally receives the Pentagon's telegram warning of impending danger. In Washington, the Secretary of State, Cordell Hull (George Macready), is stunned on learning of the attack and urgently requests confirmation of it before receiving the Japanese ambassador, who is waiting outside his office. The distraught Japanese ambassador (Shōgo Shimada), helpless to explain the late ultimatum and the unprovoked sneak attack, is bluntly rebuffed by Hull with the words, "In all my fifty years of public service, I have never seen a document so crowded with infamous falsehoods and distortions, on a scale so huge, that I never imagined until today that any government on this planet was capable of uttering them."
The Japanese fleet commander, Vice-Admiral Chuichi Nagumo (Eijiro Tono), refuses to launch a third air strike out of fear of exposing his six carriers to the increased risk of detection and destruction by the still-unaccounted for U.S. carriers, especially as the element of surprise is gone. On his flagship, Admiral Yamamoto laments the fact that the Americans did not receive the declaration of war until after the attack began, noting that nothing would infuriate the Americans more. He says: "I fear all we have done is to awaken a sleeping giant and fill him with a terrible resolve."
Cast.
The film was deliberately cast with actors who were not true box-office stars, in order to place the emphasis on the story rather than the actors who were in it. The original cast list had included many Japanese amateurs.
Cast in credits order:
Production.
Veteran 20th Century Fox executive Darryl F. Zanuck, who had earlier produced "The Longest Day" (1962), wanted to create an epic that depicted what "really happened on December 7, 1941", with a "revisionist's approach". He believed that the commanders in Hawaii, General Short and Admiral Kimmel, though scapegoated for decades, provided adequate defensive measures for the apparent threats, including relocation of the fighter aircraft at Pearl Harbor to the middle of the base, in response to fears of sabotage from local Japanese. Despite a breakthrough in intelligence, they had received limited warning of the increasing risk of aerial attack. Recognizing that a balanced and objective recounting was necessary, Zanuck developed an American-Japanese co-production, allowing for "a point of view from both nations." He was helped out by his son, Richard D. Zanuck, who was chief executive at Fox during this time.
Production on "Tora! Tora! Tora!" took three years to plan and prepare for the eight months of principal photography. The film was created in two separate productions, one based in the United States, directed by Richard Fleischer, and one based in Japan. The Japanese side was initially to be directed by Akira Kurosawa, who worked on script development and pre-production for two years. But after two weeks of shooting, he was replaced by Toshio Masuda and Kinji Fukasaku, who directed the Japanese sections.
Richard Fleischer said of Akira Kurosawa's role in the project:
Larry Forrester and frequent Kurosawa collaborators Hideo Oguni and Ryuzo Kikushima wrote the screenplay, based on books written by Ladislas Farago and Gordon Prange of the University of Maryland, who served as a technical consultant. Numerous technical advisors on both sides, some of whom had participated in the battle and/or planning, were crucial in maintaining the accuracy of the film. Minoru Genda, the man who largely planned and led the attack on Pearl Harbor was an uncredited technical advisor for the film.
Four cinematographers were involved in the main photography: Charles F. Wheeler, Sinsaku Himeda, Masamichi Satoh and Osami Furuya. They were jointly nominated for the Academy Award for Best Cinematography. A number of well-known cameramen also worked on the second units without credit, including Thomas Del Ruth and Rexford Metz. The second unit doing miniature photography was directed by Ray Kellogg, while the second unit doing aerial sequences was directed by Robert Enrietto.
Noted composer Jerry Goldsmith composed the film score and Robert McCall painted several scenes for various posters of the film.
The carrier entering Pearl Harbor towards the end of the film was in fact the Iwo Jima-class amphibious assault ship , returning to port. The "Japanese" aircraft carrier was the anti-submarine carrier . The Japanese A6M Zero fighters, and somewhat longer "Kate" torpedo bombers or "Val" dive bombers were heavily modified RCAF Harvard (T-6 Texan) and BT-13 Valiant pilot training aircraft. The large fleet of Japanese aircraft was created by Lynn Garrison, a well-known aerial action coordinator, who produced a number of conversions. Garrison and Jack Canary coordinated the actual engineering work at facilities in the Los Angeles area. These aircraft still make appearances at air shows.
In preparation for filming, was berthed at North Island in San Diego to load all the aircraft, maintenance, and film crew prior to sailing to Hawaii. The night before filming the "Japanese" take-off scenes she sailed to a spot a few miles west of San Diego and at dawn the film crew filmed the launches of all the aircraft. Since these "Japanese" aircraft were not actual carrier based aircraft they did not have arresting gear with which to land back on the carrier, and continued on to land at North Island Naval Air Station. sailed back to North Island and re-loaded the aircraft. She then sailed to Hawaii and the aircraft were off-loaded and used to film the attack scenes in and around Pearl Harbor. Aircraft Specialties of Mesa, Arizona performed maintenance on the aircraft while in Hawaii.
A Boeing B-17 Flying Fortress's actual crash landing during filming, a result of a jammed landing gear, was filmed and used in the final cut. The film crew received word that one of the B-17s could not lower their starboard landing gear so they quickly set up to film the "single gear" landing. The aircraft stayed aloft to use up as much fuel as possible, which gave the film crew some time to prepare, prior to landing. After viewing the "single gear" landing footage they decided to include it in the movie. In the sequence depicting the crash, only the final crash was actual footage. For the scenes leading up to the crash they manually retracted the starboard landing gear on a functioning B-17 and filmed the scenes of its final approach. After touching down on one wheel the pilot simply applied power and took off again. In the movie, all the approach footage was of this aircraft, and then, right at the moment of touchdown, they switch to the actual crash footage. The difference in production values between the actual footage and the final approach footage is quite clear. The B-17 that actually landed with one gear up sustained only minor damage to the starboard wing and propellers and was repaired and returned to service. A total of five Boeing B-17s were obtained for filming. Other U.S. aircraft used are the Consolidated PBY Catalina and, especially, the Curtiss P-40 Warhawk (two flyable examples were used). Predominately, P-40 fighter aircraft are used to depict the U.S. defenders with a full-scale P-40 used as a template for fiberglass replicas (some with working engines and props) that were strafed and blown up during filming. Fleischer also said a scene involving a P-40 model crashing into the middle of a line of P-40s was unintended, as it was supposed to crash at the end of the line. The stuntmen involved in the scene were actually running for their lives.
With over 30 aircraft in the air, the flying scenes were complex to shoot, and can be compared to the 1969 film "Battle of Britain" where large formations of period specific aircraft were filmed in staged aerial battles. The 2001 film "Pearl Harbor" would use some of the same modified aircraft.
Historical accuracy.
Parts of the film showing the takeoff of the Japanese aircraft utilize an , , which was commissioned in 1943 and modernized after the war to have an angled flightdeck. The ship was leased by the film producers, who needed an aircraft carrier for the film; "Yorktown" was scheduled to be decommissioned shortly afterwards. It was used largely in the takeoff sequence of the Japanese attack aircraft. The sequence shows interchanging shots of models of the Japanese aircraft carriers and the "Yorktown". It does not look like any of the Japanese carriers involved in the attack, due to its large bridge island and its angled landing deck. The Japanese carriers had small bridge islands, and angled flight decks were not developed until after the war. In addition, during the scene in which Admiral Halsey is watching bombing practice an aircraft carrier with the hull number 14 is shown. Admiral Halsey was on the , not the "Essex"-class carrier , which would not be commissioned until 1944. This is understandable, however, as both the "Enterprise" and all six of the Japanese carriers from the attack had been scrapped and sunk, respectively. "Enterprise" was scrapped in 1959, and four of the six, including "Akagi", were sunk not six months after the attack at the Battle of Midway.
In "Tora! Tora! Tora!", an error involves the model of the Japanese carrier "Akagi". In the film, "Akagi's" bridge island is positioned on the starboard side of the ship, which is typical on most aircraft carriers. However, the aircraft carrier "Akagi" was an exception; its bridge island was on the port side of the ship. Despite this, the bridge section appeared accurately as a mirrored version of "Akagi's" real port-side bridge. Secondly, all the Japanese aircraft in the footage bear the markings of "Akagi"s aircraft (a single vertical red stripe following the red sun symbol of Japan), even though five other aircraft carriers participated, each having its own markings. In addition, the markings do not display the aircraft's identification numbers as was the case in the actual battle. The white surround on the roundel on the Japanese aircraft was only used from 1942 onwards. Prior to this the roundel was red only.
The was an old "4-piper" destroyer commissioned in 1918; the ship used in the movie, , which portrays the "Ward" looked far different from the original destroyer. In addition, in the movie she fired two shots from her #1 turret. In reality, the "Ward" fired the first shot from the #1 4" un-turreted gunmount and the second shot from the #3 wing mount.
A stern section of the was built that was also used to portray the and other U.S. battleships. The lattice mast (or cage mast) section of the "Tennessee-class"/"Maryland-class" battleship was built beside the set of the USS "Nevada" stern section, but not built upon a set of a deck, but on the ground as the footage in the movie only showed the cage mast tower. The large scale model of the stern shows the two aft gun turrets with three gun barrels in each; in reality, "Nevada" had two heightened fore and aft turrets with two barrels each while the lower two turrets fore and aft had three barrels each. Another model of "Nevada", used in the film to portray the whole ship, displays the turrets accurately. It should be noted that the reason for this anomaly is because the aft section model was used in the film to portray both USS "Nevada" "and" USS "Arizona". The ships looked remarkably similar except that "Arizona" had four triple turrets and a slightly different stern section. Footage and photographs not used in the film show the cage mast as being built on the ground. The USS "Nevada"/USS "Arizona" stern section was shown exploding to represent the explosion that destroyed the "Arizona", although in reality the explosion took place in #2 magazine, forward, and "Arizona's" stern section remains essentially intact to this day.
The film has a Japanese Zero fighter being damaged over a naval base and then deliberately crashing into a naval base hangar. This is actually a composite of three incidents at Pearl Harbor attack: in the first wave, a Japanese Zero crashed into Fort Kamehameha's ordnance building; in the second wave, a Japanese Zero did deliberately crash into a hillside after U.S. Navy CPO John William Finn at Naval Air Station at Kāneʻohe Bay had shot and damaged the aircraft; also during the second wave, a Japanese aircraft that was damaged crashed into the seaplane tender USS "Curtiss".
During a number of shots of the attack squadrons traversing across Oahu, a small cross can be seen on one of the mountainsides. The cross was actually erected after the attack as a memorial to the victims of the attack.
Reception.
At the time of its initial movie release, "Tora! Tora! Tora!" was thought to be a box office flop in North America, although its domestic box office of $29,548,291 made it the ninth highest-grossing film of 1970. It was a major hit in Japan and over the years, home media releases provided a larger overall profit.
Roger Ebert felt that "Tora! Tora! Tora!" was "one of the deadest, dullest blockbusters ever made" and suffered from not having "some characters to identify with." In addition, he criticized the film for poor acting and special effects in his 1970 review. Vincent Canby, reviewer for "The New York Times", was similarly unimpressed, noting the film was "nothing less than a $25-million irrelevancy." "Variety" also found the film to be boring; however, the magazine praised the film's action sequences and production values. James Berardinelli, however, said it was "rare for a feature film to attain the trifecta of entertaining, informing, and educating." Charles Champlin in his review for the "Los Angeles Times" on September 23, 1970, considered the movie's chief virtues as a "spectacular", and the careful recreation of an historical event.
Despite the initial negative reviews, the film was critically acclaimed for its vivid action scenes, and found favor with aviation and history aficionados. However, even the team of Jack Hardwick and Ed Schnepf who have been involved in research on aviation films, had relegated "Tora! Tora! Tora!" to the "also-ran" status, due to its slow-moving plotline. The film holds a 59% "Fresh" rating on the review aggregate website Rotten Tomatoes, based on 27 critical reviews. In 1994, a survey at the USS Arizona Memorial in Honolulu determined that for Americans the film was the most common source of popular knowledge about the Pearl Harbor attack.
Several later films and TV series relating to World War II in the Pacific have used footage from "Tora! Tora! Tora!". These productions include the films "Midway" (1976; in the "Tora! Tora! Tora!" DVD commentary, Fleischer is angry that Universal used the footage), "All This and World War II" (film 1976), "Pearl" (TV mini-series 1978), "From Here to Eternity" (TV mini-series 1979), "The Final Countdown" (1980), and "Australia" (2008) as well as the "Magnum, P. I." television series episode titled "Lest We Forget" (first airdate February 12, 1981).
Honors.
"Tora! Tora! Tora!" was nominated for five Academy Awards, winning one for Visual Effects.

</doc>
<doc id="58019" url="https://en.wikipedia.org/wiki?curid=58019" title="Harvard architecture">
Harvard architecture

The Harvard architecture is a computer architecture with physically separate storage and signal pathways for instructions and data. The term originated from the Harvard Mark I relay-based computer, which stored instructions on punched tape (24 bits wide) and data in electro-mechanical counters. These early machines had data storage entirely contained within the central processing unit, and provided no access to the instruction storage as data. Programs needed to be loaded by an operator; the processor could not initialize itself.
Today, most processors implement such separate signal pathways for performance reasons, but actually implement a modified Harvard architecture, so they can support tasks like loading a program from disk storage as data and then executing it.
Memory details.
In a Harvard architecture, there is no need to make the two memories share characteristics. In particular, the word width, timing, implementation technology, and memory address structure can differ. In some systems, instructions can be stored in read-only memory while data memory generally requires read-write memory. In some systems, there is much more instruction memory than data memory so instruction addresses are wider than data addresses.
Contrast with von Neumann architectures.
Under pure von Neumann architecture the CPU can be either reading an instruction or reading/writing data from/to the memory. Both cannot occur at the same time since the instructions and data use the same bus system. In a computer using the Harvard architecture, the CPU can both read an instruction and perform a data memory access at the same time, even without a cache. A Harvard architecture computer can thus be faster for a given circuit complexity because instruction fetches and data access do not contend for a single memory pathway.
Also, a Harvard architecture machine has distinct code and data address spaces: instruction address zero is not the same as data address zero. Instruction address zero might identify a twenty-four bit value, while data address zero might indicate an eight-bit byte that is not part of that twenty-four bit value.
Contrast with modified Harvard architecture.
A modified Harvard architecture machine is very much like a Harvard architecture machine, but it relaxes the strict separation between instruction and data while still letting the CPU concurrently access two (or more) memory buses. The most common modification includes separate instruction and data caches backed by a common address space. While the CPU executes from cache, it acts as a pure Harvard machine. When accessing backing memory, it acts like a von Neumann machine (where code can be moved around like data, which is a powerful technique). This modification is widespread in modern processors, such as the ARM architecture and x86 processors. It is sometimes loosely called a Harvard architecture, overlooking the fact that it is actually "modified".
Another modification provides a pathway between the instruction memory (such as ROM or flash memory) and the CPU to allow words from the instruction memory to be treated as read-only data. This technique is used in some microcontrollers, including the Atmel AVR. This allows constant data, such as text strings or function tables, to be accessed without first having to be copied into data memory, preserving scarce (and power-hungry) data memory for read/write variables. Special machine language instructions are provided to read data from the instruction memory. (This is distinct from instructions which themselves embed constant data, although for individual constants the two mechanisms can substitute for each other.)
Speed.
In recent years, the speed of the CPU has grown many times in comparison to the access speed of the main memory. Care needs to be taken to reduce the number of times main memory is accessed in order to maintain performance. If, for instance, every instruction run in the CPU requires an access to memory, the computer gains nothing for increased CPU speed—a problem referred to as being memory bound.
It is possible to make extremely fast memory, but this is only practical for small amounts of memory for cost, power and signal routing reasons. The solution is to provide a small amount of very fast memory known as a CPU cache which holds recently accessed data. As long as the data that the CPU needs are in the cache, the performance is much higher than it is when the cache has to get the data from the main memory.
Internal vs. external design.
Modern high performance CPU chip designs incorporate aspects of both Harvard and von Neumann architecture. In particular, the "split cache" version of the modified Harvard architecture is very common. CPU cache memory is divided into an instruction cache and a data cache. Harvard architecture is used as the CPU accesses the cache. In the case of a cache miss, however, the data is retrieved from the main memory, which is not formally divided into separate instruction and data sections, although it may well have separate memory controllers used for concurrent access to RAM, ROM and (NOR) flash memory.
Thus, while a von Neumann architecture is visible in some contexts, such as when data and code come through the same memory controller, the hardware implementation gains the efficiencies of the Harvard architecture for cache accesses and at least some main memory accesses.
In addition, CPUs often have write buffers which let CPUs proceed after writes to non-cached regions. The von Neumann nature of memory is then visible when instructions are written as data by the CPU and software must ensure that the caches (data and instruction) and write buffer are synchronized before trying to execute those just-written instructions.
Modern uses of the Harvard architecture.
The principal advantage of the pure Harvard architecture—simultaneous access to more than one memory system—has been reduced by modified Harvard processors using modern CPU cache systems. Relatively pure Harvard architecture machines are used mostly in applications where trade-offs, like the cost and power savings from omitting caches, outweigh the programming penalties from featuring distinct code and data address spaces.
Even in these cases, it is common to employ special instructions in order to access program memory as though it were data for read-only tables, or for reprogramming; those processors are modified Harvard architecture processors.

</doc>
<doc id="58023" url="https://en.wikipedia.org/wiki?curid=58023" title="Lewis–Clark State College">
Lewis–Clark State College

Lewis–Clark State College is a public undergraduate college in the northwest United States, located in Lewiston, Idaho. Founded in 1893, it has an annual enrollment of approximately 3,500 students. The college offers over 83 degrees and is well known for its criminal justice, education, nursing, and technical programs.
History.
In 1893, Idaho Governor William J. McConnell signed an act on January 27 authorizing the establishment of the Lewiston State Normal School in Lewiston. There was a catch, however: "Provided the mayor and common council of that city on or before May 1, 1893, donate ten acres, within the city limits and known as part of the city park, and authorizing the said mayor and council to convey to the trustees of said normal school the said tract of land," etc.
The first Trustees on the school's Board were James W. Reid (who had done the most to shepherd the authorization bill through the legislature), Norman B. Willey (who had just stepped down as Idaho governor), Benjamin Wilson (a previous gubernatorial candidate), J. Morris Howe, and C. W. Schaff. Reid was elected President of the Board, a position he held until his death in 1902.
Lewiston residents lost no time in obtaining the required space for the school. However, the legislature acted slowly in providing construction funds, and then construction lagged. George E. Knepper had been hired as first President of the Normal School. Frustrated by the delays in getting his building, Knepper leased space in downtown Lewiston and opened for classes on January 6, 1896. The building itself was not ready until May. Over the next several years, more structures were added to the campus, including dormitories and a gymnasium.
In keeping with the Normal school philosophy, Lewiston Normal focused on practical, hands-on training for new teachers. That meant they provided a great deal of “manual training” – what we would call vocational education. Also, to insure that teachers truly knew how to handle a classroom, the School ran an on-campus training school. In it, real teachers taught real pupils, but student teachers also learned-by-doing under the supervision of experienced teacher-critics.
Until the 1920s one-room schools served well over half of Idaho’s primary students. In most, only the teacher knew anything at all about running a school. Thus, in Keith Petersen’s words, “teachers assumed responsibility for shaping a district's entire educational policy.”
World War I certainly impacted the nation’s normal schools, but not as much as it did conventional institutions. Generally, male students were in the majority at regular colleges, many of which experienced brutal enrollment losses. Normal schools attracted a predominantly female student body, so the declines were much smaller – about 15% at Lewiston Normal.
The school experienced a painful crisis on December 5, 1917, when the Administration Building suffered severe damage in a fire,
Supporters also fought an ongoing battle just to keep the school open; some legislators still wanted to close the Normals to save money. The advent of World War II squelched that notion. Not only did the school continue to turn out desperately needed teachers, it also expanded its nurse-training program, and produced large numbers of fliers in its Navy Air School. In 1943, the Board of Education raised the school to full four-year status. Now with the ability to grant a B.Ed., school leaders took it upon themselves to use the name Northern Idaho College of Education (NICE), and the legislature approved the name change in 1947.
The school got another temporary reprieve from the cost-cutters when a deluge of veterans funded by the G.I. Bill hit the campus after the war. However, that wave passed, and in 1951 budget hawks succeeded in closing the school, as well as its counterpart, SICE in Albion in southern Idaho. The state’s other colleges had assured legislators that they could supply all the teachers needed. That promise proved disastrously wrong: In just three years, the state found itself issuing nearly 40% more provisional teaching certificates than it had in 1951.
Under that pressure, the legislature re-opened the school as Lewis–Clark Normal School in 1955 as a two-year school under the administration of the University of Idaho, thirty miles (50 km) north in Moscow. The first dean of LCSN was appointed for the third year in 1957, and enrollment was 319 in the fall of 1961. The arrangement with UI proved difficult and it ended abruptly in 1963 when the affiliation seemed like it might damage the university’s academic accreditation.
The ongoing need for teachers, a developing shortage of nurses, and a new push for vocational education from the federal government combined to rescue the school from oblivion. The state legislature voted to elevate it to four-year status in 1963 but did not approve funding until two years later. Enrollment of the now-independent, four-year school grew, by from 465 in 1964 to 1,033 in the fall of 1968. It continued to grow and in July 1971 the name was officially changed to Lewis–Clark State College. It was the very last Normal school in the country to make the change.
Students and faculty.
Over 3,500 students from over 30 different states and 20 different countries are enrolled at LCSC. Women outnumber men in the student body by five to three.
School reputation.
Lewis-Clark Normal School became a state college in 1966 and gained its current name in 1971. Lewis–Clark State College has been ranked as one of the top public colleges in the West in the Comprehensive-Bachelor’s Degree categories – including No. 1 in 2002, 2005, & 2007 – by U.S. News & World Report in its annual rankings of colleges and universities.
Athletics.
Lewis–Clark State competes in inercollegiate athletics in the National Association of Intercollegiate Athletics (NAIA), primarily in the Frontier Conference. The school colors are navy blue, white, & red with a team nickname of the Warriors. Men's sports include baseball, basketball, cross country golf, tennis, and track & field. Women's sports teams are nicknamed "Lady Warriors" and include basketball, cross country, golf, tennis, track & field, and volleyball.
"Warriors" was adopted in the 1950s; earlier nicknames include "Pioneers" in the 1930s, and "Loggers" in the late 1940s and early 1950s.
Baseball.
Since 1984, the Lewis–Clark State baseball team has won a record 17 NAIA national championships. All championships won before 2010 were under head coach Ed Cheff, who retired after 34 years in 2010. LCSC has hosted the NAIA World Series at Harris Field since 2000; it also hosted from 1984–1991.

</doc>
<doc id="58031" url="https://en.wikipedia.org/wiki?curid=58031" title="Bourgeoisie">
Bourgeoisie

The bourgeoisie (Eng.: ; ) is a polysemous French term because it can mean:
The "bourgeoisie", in its original sense, is intimately linked to the existence of cities recognized as such by their urban charters (e.g. municipal charter, town privileges, German town law) so there was no bourgeoisie "outside the walls of the city" beyond which the people were "peasants" submitted to the stately courts and manorialism (except for the traveling "Fair bourgeoisie" living outside urban territories, who retained their city rights and domicile).
In Marxist philosophy the bourgeoisie is the social class that came to own the means of production during modern industrialization and whose societal concerns are the value of property and the preservation of capital, to ensure the perpetuation of their economic supremacy in society. Joseph Schumpeter saw the creation of new bourgeoisie as the driving force behind the capitalist engine, particularly entrepreneurs who took risks to bring innovation to industries and the economy through the process of creative destruction.
Etymology.
The Modern French word "bourgeois" derived from the Old French "burgeis" (walled city), which derived from "bourg" (market town), from the Old Frankish "burg" (town); in other European languages, the etymologic derivations are the Middle English "burgeis", the Middle Dutch "burgher", the German "Bürger", the Modern English "burgess", and the Polish "burżuazja", which occasionally is synonymous with the intelligentsia. 
In English, "bourgeoisie" (a French citizen-class) identified a social class oriented to economic materialism and hedonism, and to upholding the extreme political and economic interests of the capitalist ruling class. In the 18th century, before the French Revolution (1789–99), in the French feudal order, the masculine and feminine terms "bourgeois" and "bourgeoise" identified the rich men and women who were members of the urban and rural Third Estate – the common people of the French realm, who violently deposed the absolute monarchy of the Bourbon King Louis XVI (r. 1774–91), his clergy, and his aristocrats. Hence, since the 19th century, the term "bourgeoisie" usually is politically and sociologically synonymous with the ruling upper class of a capitalist society.
Historically, the medieval French word "bourgeois" denoted the inhabitants of the "bourgs" (walled market-towns), the craftsmen, artisans, merchants, and others, who constituted "the bourgeoisie", they were the socio-economic class between the peasants and the landlords, between the workers and the owners of the means of production. As the economic managers of the (raw) materials, the goods, and the services, and thus the capital (money) produced by the feudal economy, the term "bourgeoisie" evolved to also denote the middle class – the businessmen and businesswomen who accumulated, administered, and controlled the capital that made possible the development of the bourgs into cities.
Contemporarily, the terms "bourgeoisie" and "bourgeois" (noun) identify the ruling class in capitalist societies, as a social stratum; while "bourgeois" (adjective / noun modifier) describes the "Weltanschauung" (worldview) of men and women whose way of thinking is socially and culturally determined by their economic materialism and philistinism, a social identity famously mocked in Molière's comedy "Le Bourgeois gentilhomme" (1670), which satirises buying the trappings of a noble-birth identity as the means of climbing the social ladder. The eighteenth century saw a partial rehabilitation of bourgeois values in genres such as the "drame bourgeois" (bourgeois drama) and "bourgeois tragedy".
History.
Origins and rise.
In the 11th century, the bourgeoisie emerged as a historical and political phenomenon when the "bourgs" of Central and Western Europe developed into cities dedicated to commerce. The organised economic concentration that made possible such urban expansion derived from the protective self-organisation into guilds, which became necessary when individual businessmen (craftsmen, artisans, merchants, "et alii") conflicted with their rent-seeking feudal landlords who demanded greater-than-agreed rents. 
In the event, by the end of the Middle Ages (ca. AD 1500), under régimes of the early national monarchies of Western Europe, the bourgeoisie acted in self-interest, and politically supported the king or the queen against the legal and financial disorder caused by the greed of the feudal lords. In the late-16th and early 17th centuries, the bourgeoisies of England and the Netherlands had become the financial – thus political – forces that deposed the feudal order; economic power had vanquished military power in the realm of politics.
From progress to reaction.
During the 17th and 18th centuries, the bourgeoisie were the politically progressive social class who supported the principles of constitutional government and of natural right, against the Law of Privilege and the claims of rule by divine right that the nobles and prelates had autonomously exercised during the feudal order. 
The motivations for the English Civil War (1642–51), the American War of Independence (1775–83), and French Revolution (1789–99) partly derived from the desire of the bourgeoisie to rid themselves of the feudal trammels and royal encroachments upon their personal liberty, commercial rights, and the ownership of property. In the 19th century, the bourgeoisie propounded liberalism, and gained political rights, religious rights, and civil liberties for themselves and the lower social classes; thus was the bourgeoisie then a progressive philosophic and political force in modern Western societies.
By the middle of the 19th century, subsequent to the Industrial Revolution (1750–1850), the great expansion of the bourgeoisie social class caused its self-stratification – by business activity and by economic function – into the "haute bourgeoisie" (bankers and industrialists) and the "petite bourgeoisie" (tradesmen and white-collar workers). Moreover, by the end of the 19th century, the capitalists (the original bourgeoisie) had ascended to the upper class, whilst the developments of technology and technical occupations allowed the ascension of working-class men and women to the lower strata of the bourgeoisie; yet the social progress was incidental.
Denotations.
Marxist theory.
According to Karl Marx, the bourgeois during Middle Ages usually was a self-employed businessman – such as a merchant, banker, or entrepreneur – whose economic role in society was being the financial intermediary to the feudal landlord and the peasant who worked the fief, the land of the lord. Yet, by the 18th century, the time of the Industrial Revolution (1750–1850) and of industrial capitalism, the bourgeoisie had become the economic ruling class who owned the means of production (capital and land), and who controlled the means of coercion (armed forces and legal system, police forces and prison system). 
In such a society, the bourgeoisie's ownership of the means of production enabled their employment and exploitation of the wage-earning working class (urban and rural), people whose sole economic means is labour; and the bourgeois control of the means of coercion suppressed the sociopolitical challenges of the lower classes, and so preserved the economic status quo; workers remained workers, and employers remained employers.
In the 19th century, Marx distinguished two types of bourgeois capitalist: (i) the functional capitalist, the business administrator of the means of production; and (ii) the rentier capitalist whose livelihood derives either from the rent of property or from the interest-income produced by finance capital, or both. In the course of economic relations, the working class and the bourgeoisie continually engage in class struggle, wherein the capitalists exploit the workers, whilst the workers resist their economic exploitation, which occurs because the worker owns no means of production, and, to earn a living, he or she seeks employment from the bourgeois capitalist; the worker produces goods and services that are property of the employer, who sells them for a price.
Besides describing the social class who own the means of production, the Marxist usage of the term "bourgeois" also describes the consumerist style of life derived from the ownership of capital and real property. Marx acknowledged the bourgeois industriousness that created wealth, yet criticised the moral hypocrisy of the bourgeoisie when they ignored the alleged origins of their wealth – the exploitation of the proletariat, the urban and rural workers. Further sense denotations of "bourgeois" describe ideological concepts such as "bourgeois freedom", which is thought to be opposed to substantive forms of freedom; "bourgeois independence"; "bourgeois personal individuality"; the "bourgeois family"; et cetera, all derived from owning capital and property. (See: "The Communist Manifesto", 1848.)
"Nomenklatura".
In the 20th century, some communist states, particularly the Soviet Union, developed a category of people called a "nomenklatura", the bureaucrats who administered the country's government, industry, agriculture, education, system of state capitalism, et cetera.
France and French-speaking countries.
In English, the term "bourgeoisie" is often used to denote the middle classes. In fact, the French term encompasses both the upper and middle classes, a misunderstanding which has occurred in other languages as well. The bourgeoisie in France and many French-speaking countries consists of four evolving social layers: "la petite bourgeoisie", "la moyenne bourgeoisie", "la grande bourgeoisie", and "la haute bourgeoisie".
"La Petite Bourgeoisie".
The "petite bourgeoisie" consists of people who have experienced a brief ascension in social mobility for one or two generations. It usually starts with a trade or craft, and by the second and third generation, a family may rise another level. The "petite bourgeois" would belong to the British lower middle class and would be American middle income. They are distinguished mainly by their mentality, and would differentiate themselves from the "proletariat" or working class. This class would include artisans, small traders, shopkeepers, and small farm owners. They are not employed, but may not be able to afford employees themselves.
"La Moyenne Bourgeoisie".
People who belong to the "moyenne bourgeoisie" or middle bourgeoisie, have solid incomes and assets, but without the aura of those who have become established at a higher level. They tend to belong to a family that has been bourgeois for three or more generations. Some members of this class may have relatives from similar backgrounds, or may even have aristocratic connections. The "moyenne bourgeoisie" would be the equivalent of the British and American upper-middle classes.
"La Grande Bourgeoisie".
The "grande bourgeoisie" are families that have been bourgeois since the 19th century, or for at least four or five generations. Members of these families tend to marry with the aristocracy or make other advantageous marriages. This bourgeoisie family has acquired an established historical and cultural heritage over the decades. The names of these families are generally known in the city where they reside, and their ancestors have often contributed to the region's history. These families are respected and revered. They belong to the upper class, and in the British class system would be considered part of the gentry. In the French-speaking countries they are sometimes referred "la petite haute bourgeoisie".
"La Haute Bourgeoisie".
The "haute bourgeoisie" is a social rank in the bourgeoisie that can only be acquired through time. In France, it is composed of bourgeois families that have existed since the French Revolution. They hold only honourable professions and have experienced many illustrious marriages in their family's history. They have rich cultural and historical heritages, and their financial means are more than secure. 
These families exude an aura of nobility, which prevents them from certain marriages or occupations. They only differ from nobility in that due to circumstances, the lack of opportunity, and/or political regime, they have not been ennobled. These people nevertheless live a lavish lifestyle, enjoying the company of the great artists of the time. In France, the families of the "haute bourgeoisie" are also referred to as "les 200 familles", a term which was coined in the first half of the 20th century. Michel Pinçon and Monique Pinçon-Charlot have studied the lifestyle of the French bourgeoisie, and how they boldly guard their world from the "nouveau riche", or newly rich.
In the French language, the term "bourgeoisie" almost designates a caste by itself, even though social mobility into this socio-economic group is possible. Nevertheless, the "bourgeoisie" is differentiated from "la classe moyenne", or the middle class, which consists mostly of white-collar employees, by holding a profession referred to as a "profession libérale", which "la classe moyenne", in its definition does not hold. Yet, in English the definition of a white-collar job encompasses the "profession libérale".
Modern history.
Because of their ascribed cultural excellence as a social class, the Italian fascist régime (1922–45) of Prime Minister Benito Mussolini regarded the bourgeoisie as an obstacle to Modernism in aid to transforming Italian society. Nonetheless, despite such intellectual and social hostility, the Fascist State ideologically exploited the Italian bourgeoisie and their materialistic, middle-class spirit, for the more efficient cultural manipulation of the upper (aristocratic) and the lower (working) classes of Italy. 
In 1938, Prime Minister Mussolini gave a speech wherein he established a clear ideological distinction between capitalism (the social function of the bourgeoisie) and the bourgeoisie (as a social class), whom he dehumanised by reducing them into high-level abstractions: a moral category and a state of mind. Culturally and philosophically, Mussolini isolated the bourgeoisie from Italian society by portraying them as social parasites upon the fascist Italian state and "The People"; as a social class who drained the human potential of Italian society, in general, and of the working class, in particular; as exploiters who victimised the Italian nation with an approach to life characterised by hedonism and materialism. Nevertheless, despite the slogan "The Fascist Man Disdains the ″Comfortable″ Life", which epitomised the anti-bourgeois principle, in its final years of power, for mutual benefit and profit, the Mussolini fascist régime transcended ideology to merge the political and financial interests of Prime Minister Benito Mussolini with the political and financial interests of the bourgeoisie, the Catholic social circles who constituted the ruling class of Italy.
Philosophically, as a materialist creature, the bourgeois man was irreligious; thus, to establish an existential distinction between the supernatural faith of the Roman Catholic Church and the materialist faith of temporal religion; in "The Autarchy of Culture: Intellectuals and Fascism in the 1930s", the priest Giuseppe Marino said that:
Culturally, the bourgeois man is unmanly, effeminate, and infantile; describing his philistinism in "Bonifica antiborghese" (1939), Roberto Paravese said that the:
The economic security, financial freedom, and social mobility of the bourgeoisie threatened the philosophic integrity of Italian fascism, the ideological monolith that was the régime of Prime Minister Benito Mussolini. Any assumption of legitimate political power (government and rule) by the bourgeoisie represented a fascist loss of totalitarian state power for social control through political unity—one people, one nation, one leader. Sociologically, to the fascist man, to become a bourgeois was a character flaw inherent to the masculine mystique; therefore, the ideology of Italian fascism scornfully defined the bourgeois man as "spiritually castrated".
Bourgeois culture.
Cultural hegemony.
Karl Marx said that the culture of a society is dominated by the mores of the ruling-class, wherein their superimposed value system is abided by each social class (the upper, the middle, the lower) regardless of the socio-economic results it yields to them. In that sense, contemporary societies are bourgeois to the degree that they practice the mores of the small-business "shop culture" of early modern France; which the writer Émile Zola (1840–1902) naturalistically presented, analysed, and ridiculed in the twenty-two-novel series (1871–1893) about "Les Rougon-Macquart" family; the thematic thrust is the necessity for social progress, by subordinating the economic sphere to the social sphere of life.
Conspicuous consumption.
The critical analyses of the bourgeois mentality by the German intellectual Walter Benjamin (1892–1940) indicated that the shop culture of the petite bourgeoisie established the sitting room as the centre of personal and family life; as such, the English bourgeois culture is a sitting-room culture of prestige through conspicuous consumption. The material culture of the bourgeoisie concentrated on mass-produced luxury goods of high quality; between generations, the only variance was the materials with which the goods were manufactured. 
In the early part of the 19th century, the bourgeois house contained a home that first was stocked and decorated with hand-painted porcelain, machine-printed cotton fabrics, machine-printed wallpaper, and Sheffield steel (crucible and stainless). The utility of these things was inherent to their practical functions. By the latter part of the 19th century, the bourgeois house contained a home that had been remodelled by conspicuous consumption. Here, the goods were bought to display wealth (discretionary income), rather than for their practical utility. The bourgeoisie had transposed the wares of the shop window to the sitting room, where the clutter of display signalled bourgeois success. (See: "Culture and Anarchy", 1869.)
Two spatial constructs manifest the bourgeois mentality: (i) the shop-window display, and (ii) the sitting room. In English, the term "sitting-room culture" is synonymous for "bourgeois mentality", a philistine cultural perspective from the Victorian Era (1837–1901), especially characterised by the repression of emotion and of sexual desire; and by the construction of a regulated social-space where "propriety" is the key personality trait desired in men and women. 
Nonetheless, from such a psychologically constricted worldview, regarding the rearing of children, contemporary sociologists claim to have identified "progressive" middle-class values, such as respect for non-conformity, self-direction, autonomy, gender equality and the encouragement of innovation; as in the Victorian Era, the transposition to the US of the bourgeois system of social values has been identified as a requisite for employment success in the professions.
Representations.
Beyond the intellectual realms of political economy, history, and political science that discuss, describe, and analyse the "bourgeoisie" as a social class, the colloquial usage of the sociological terms "bourgeois" and "bourgeoise" describe the social stereotypes of the old money and of the "nouveau riche", who is a politically timid conformist satisfied with a wealthy, consumerist style of life characterised by conspicuous consumption and the continual striving for prestige. This being the case, the cultures of the world describe the philistinism of the middle-class personality, produced by the excessively rich life of the bourgeoisie, is examined and analysed in comedic and dramatic plays, novels, and films. (See: Authenticity.)
Theatre.
"Le Bourgeois gentilhomme" (The Would-be Gentleman, 1670) by Molière (Jean-Baptiste Poquelin), is a comedy-ballet that satirises Monsieur Jourdain, the prototypical nouveau riche man who buys his way up the social-class scale, to realise his aspirations of becoming a gentleman, to which end he studies dancing, fencing, and philosophy, the trappings and accomplishments of a gentleman, to be able to pose as a man of noble birth, someone who, in 17th-century France, was a man to the manner born; Jourdain's self-transformation also requires managing the private life of his daughter, so that her marriage can also assist his social ascent.
Literature.
"Buddenbrooks" (1901), by Thomas Mann (1875–1955), chronicles the moral, intellectual, and physical decay of a rich family through its declines, material and spiritual, in the course of four generations, beginning with the patriarch Johann Buddenbrook Sr. and his son, Johann Buddenbrook Jr., who are typically successful German businessmen; each is a reasonable man of solid character. 
Yet, in the children of Buddenbrook Jr., the materially comfortable style of life provided by the dedication to solid, middle-class values elicits decadence: The fickle daughter, Toni, lacks and does not seek a purpose in life; son Christian is honestly decadent, and lives the life of a ne’er-do-well; and the businessman son, Thomas, who assumes command of the Buddenbrook family fortune, occasionally falters from middle-class solidity by being interested in art and philosophy, the impractical life of the mind, which, to the bourgeoisie, is the epitome of social, moral, and material decadence.
"Babbitt" (1922), by Sinclair Lewis (1885–1951), satirises the American bourgeois George Follansbee Babbitt, a middle-aged realtor, booster, and joiner in the Midwestern city of Zenith, who – despite being unimaginative, self-important, and hopelessly conformist and middle-class – is aware that there must be more to life than money and the consumption of the best things that money can buy. Nevertheless, he fears being excluded from the mainstream of society more than he does living for himself, by being true to himself – his heart-felt flirtations with independence (dabbling in liberal politics and a love affair with a pretty widow) come to naught because he is existentially afraid.
Yet, George F. Babbitt sublimates his desire for self-respect, and encourages his son to rebel against the conformity that results from bourgeois prosperity, by recommending that he be true to himself:
Films.
The comedy films by the Spanish film director Luis Buñuel (1900–83) examine the mental and moral effects of the bourgeois mentality, its culture, and the stylish way of life it provides for its practitioners.

</doc>
<doc id="58032" url="https://en.wikipedia.org/wiki?curid=58032" title="Control Data Corporation">
Control Data Corporation

Control Data Corporation (CDC) was a supercomputer firm. CDC was one of the nine major United States computer companies through most of the 1960s; the others were IBM, Burroughs Corporation, DEC, NCR, General Electric, Honeywell, RCA, and UNIVAC. CDC was well-known and highly regarded throughout the industry at the time. For most of the 1960s, Seymour Cray worked at CDC and developed a series of machines that were the fastest computers in the world by far, until Cray left the company to found Cray Research (CRI) in the 1970s. After several years of losses in the early 1980s, in 1988 CDC started to leave the computer manufacturing business and sell the related parts of the company, a process that was completed in 1992 with the creation of Control Data Systems, Inc. The remaining businesses of CDC currently operate as Ceridian.
Background and origins: World War II–1957.
During World War II the U.S. Navy had built up a team of engineers to build codebreaking machinery for both Japanese and German electro-mechanical ciphers. A number of these were produced by a team dedicated to the task working in the Washington, D.C., area. With the post-war wind-down of military spending, the Navy grew increasingly worried that this team would break up and scatter into various companies, and it started looking for ways to covertly keep the team together.
Eventually they found their solution; the owner of a Chase Aircraft affiliate in St. Paul, Minnesota, John Parker, was about to lose all his contracts with the end of the war. The Navy never told Parker exactly what the team did, since it would have taken too long to get top secret clearance. Instead they simply said the team was important, and they would be very happy if he hired them all. Parker was obviously wary, but after several meetings with increasingly high-ranking Naval officers it became apparent that whatever it was, they were serious, and he eventually agreed to give this team a home in his military glider factory.
The result was Engineering Research Associates (ERA), a contract engineering company that worked on a number of seemingly unrelated projects in the early 1950s. One of these was one of the first commercial stored program computers, the 36-bit ERA 1103. The machine was built for the Navy, which intended to use it in their non-secret code-breaking centers. In the early 1950s a minor political debate broke out in Congress about the Navy essentially "owning" ERA, and the ensuing debates and legal wrangling left the company drained of both capital and spirit. In 1952, Parker sold ERA to Remington Rand.
Although Rand kept the ERA team together and developing new products, it was most interested in ERA's magnetic drum memory systems. Rand soon merged with Sperry Corporation to become Sperry Rand. In the process of merging the companies, the ERA division was folded into Sperry's UNIVAC division. At first this did not cause too many changes at ERA, since the company was used primarily to provide engineering talent to support a variety of projects. However, one major project was moved from UNIVAC to ERA, the UNIVAC II project, which led to lengthy delays and upsets to nearly everyone involved.
Since the Sperry "big company" mentality encroached on the decision-making powers of the ERA founders, they left Sperry to form the Control Data Corp. in 1957, setting up shop in an old warehouse across the river from Sperry's St. Paul laboratory, in Minneapolis at 501 Park Avenue. Of the members forming CDC, William Norris was the unanimous choice to become the chief executive officer of the new company. Seymour Cray soon became the chief designer, though at the time of CDC's formation he was still in the process of completing a prototype for the Naval Tactical Data System (NTDS), and he did not leave Sperry to join CDC until it was complete.
Early designs and Cray's big plan.
CDC started business by selling subsystems, mostly drum memory systems, to other companies. Cray joined the next year, and he immediately built a small transistor-based 6-bit machine known as the "CDC Little Character" to test his ideas on large-system design and transistor-based machines. "Little Character" was a great success.
In 1959, CDC released a 48-bit transistorized version of their 1103 re-design as the CDC 1604, with the first machine delivered to the U.S. Navy in 1960 at the Naval Postgraduate School in Monterey, California. Legend has it that the 1604 designation was chosen by adding CDC's first street address (501 Park Avenue) to Cray's former project, the ERA-Univac 1103.
A 12-bit cut-down version was also released as the CDC 160A in 1960, often considered among the first minicomputers. The 160A was particularly notable as it was built as a standard office desk, which was unusual packaging for that era. New versions of the basic 1604 architecture were rebuilt into the CDC 3000 series, which sold through the early and mid-1960s.
Cray immediately turned to the design of a machine that would be the fastest (or in the terminology of the day, largest) machine in the world, setting the goal at 50 times the speed of the 1604. This required radical changes in design, and as the project "dragged on" — it had gone on for about four years by then — the management got increasingly upset and it demanded greater oversight. Cray in turn demanded (in 1962) to have his own remote lab, saying that otherwise, he would quit. Norris agreed, and Cray and his team moved to Cray's home town, Chippewa Falls, Wisconsin. Not even Bill Norris, the founder and president of CDC, could visit Cray's laboratory without an invitation.
Peripherals business.
In the early 1960s, the corporation moved to Ford Parkway in the Highland Park neighborhood of St. Paul where Norris lived. Through this period, Norris became increasingly worried that CDC had to develop a "critical mass" in order to compete with IBM. In order to do this, he started an aggressive program of buying up various companies to round out CDC's peripheral lineup. In general, they tried to offer a product to compete with any of IBM's, but running 10% faster and costing 10% less. This was not always easy to achieve.
One of its first peripherals was a tape transport, which led to some internal wrangling as the Peripherals Equipment Division attempted to find a reasonable way to charge other divisions of the company for supplying the devices. If the division simply "gave" them away at cost as part of a system purchase, they would never have a real budget of their own. Instead, a plan was established in which it would share profits with the divisions selling its peripherals, a plan eventually used throughout the company.
The tape transport was followed by the "405 Card Reader" and the "415 Card Punch", followed by a series of tape drives and drum printers, all of which were designed in-house. The printer business was initially supported by Holley Carburetor in the Rochester, Michigan suburb outside of Detroit. They later formalized this by creating a jointly held company, Holley Computer Products. Holley later sold its stake back to CDC, the remainder becoming the Rochester Division.
Train printers and band printers in Rochester were developed in a joint venture with NCR and ICL, with CDC holding controlling interest. This joint venture was known as Computer Peripherals, Inc. (CPI). In the early 80s, it was merged with dot matrix computer manufacturer Centronics.
Norris was particularly interested in breaking out of the punched card–based workflow, where IBM held a stranglehold. He eventually decided to buy Rabinow Engineering, one of the pioneers of optical character recognition (OCR) systems. The idea was to bypass the entire punched card stage by having the operators simply type onto normal paper pages with an OCR-friendly typewriter font, and then submit those pages to the computer. Since a typewritten page contains much more information than a punched card (which has essentially one line of text from a page), this would offer savings all around. Unfortunately, this seemingly simple task turned out to be much harder than anyone expected, and while CDC became a major player in the early days of OCR systems, OCR has remained a niche product to this day. Rabinow's plant in Rockville, MD was closed in 1976, and CDC left the business.
With the continued delays on the OCR project, it became clear that punched cards were not going to go away any time soon, and CDC had to address this as quickly as possible. Although the 405 remained in production, it was an expensive machine to build. So another purchase was made, Bridge Engineering, which offered a line of lower-cost as well as higher-speed card punches. All card-handling products were moved to what became the Valley Forge Division after Bridge moved to a new factory, with the tape transports to follow. Later on, the Valley Forge and Rochester divisions were spun off to form a new joint company with National Cash Register (later NCR Corporation), Computer Peripherals Inc (CPI), in order to share development and production costs across the two companies. ICL later joined the effort. Eventually the Rochester Division was sold to Centronics in 1982.
Another side-effect of Norris's attempts to diversify was the creation of a number of service bureaus that ran jobs on behalf of smaller companies that could not afford to buy computers. This was never very profitable, and in 1965, several managers suggested that the unprofitable centers be closed in a cost-cutting measure. Nevertheless, Norris was so convinced of the idea that he refused to accept this, and ordered an across-the-board "belt tightening" instead.
CDC 6600: defining supercomputing.
Meanwhile, at the new Chippewa Falls lab, Seymour Cray, Jim Thornton, and Dean Roush put together a team of 34 engineers, which continued work on the new computer design. One of the ways they hoped to improve the CDC 1604 was to use better transistors, and Cray used the new silicon transistors using the planar process, developed by Fairchild Semiconductor. These were much faster than the germanium transistors in the 1604, without the drawbacks of the older mesa silicon transistors. The speed of light restriction forced a more compact design with refrigeration designed by Dean Roush. In 1964, the resulting computer was released onto the market as the CDC 6600, out-performing everything on the market by roughly ten times. When it sold over 100 units at $8 million each it was considered a supercomputer.
The 6600 had a 100ns, transistor-based CPU (Central Processing Unit) with multiple asynchronous functional units, using 10 logical, external I/O processors to off-load many common tasks and core memory. That way, the CPU could devote all of its time and circuitry to processing actual data, while the other controllers dealt with the mundane tasks like punching cards and running disk drives. Using late-model compilers, the machine attained a standard mathematical operations rate of 500 kilo-FLOPS, but the handcrafted computer assembler managed to deliver approximately 1 mega-FLOPS. A simpler, albeit much slower and less expensive version, implemented using a more traditional serial processor design rather than the 6600's parallel functional units, was released as the CDC 6400, and a two-processor version of the 6400 was called the CDC 6500.
A FORTRAN compiler, known as MNF (Minnesota FORTRAN), was developed by Lawrence A. Liddiard and E. James Mundstock at the University of Minnesota for the 6600.
After the delivery of the 6600 IBM took notice of this new company. In 1965 IBM started an effort to build a machine that would be faster than the 6600, the ACS-1. Two hundred people were gathered together on the U.S. West Coast to work on the project, away from corporate prodding, in an attempt to mirror Cray's off-site lab. The project produced interesting computer architecture and technology, but it was not compatible with IBM's hugely successful System/360 line of computers. The engineers were directed to make it 360-compatible, but that compromised its performance. The ACS was canceled in 1969, without ever being produced for customers. Many of the engineers left the company, leading to a brain-drain in IBM's high-performance departments.
In the meantime, IBM announced a new System/360 model, the Model 92, which would be just as fast as CDC's 6600. Although this machine did not exist, sales of the 6600 dropped drastically while people waited for the release of the mythical Model 92. Norris did not take this tactic, dubbed as fear, uncertainty and doubt (FUD), lying down, and in an extensive antitrust lawsuit launched against IBM a year later, he eventually won a settlement valued at $80 million. As part of the settlement, he picked up IBM's subsidiary, Service Bureau Corporation (SBC), which ran computer processing for other corporations on its own computers. SBC fitted nicely into CDC's existing service bureau offerings.
During the designing of the 6600, CDC had set up "Project SPIN" to supply the system with a high speed hard disk memory system. At the time it was unclear if disks would replace magnetic memory drums, or whether fixed or removable disks would become the more prevalent. SPIN explored all of these approaches, and eventually delivered a 28" diameter fixed disk and a smaller multi-platter 14" removable disk-pack system. Over time, the hard disk business pioneered in SPIN became a major product line.
CDC 7600 and 8600.
In the same month it won its lawsuit against IBM, CDC announced its new computer, the CDC 7600 (previously referred to as the 6800 within CDC). This machine's hardware clock speed was almost four times that of the 6600 (36 MHz vs. 10 MHz), with a 27.5 ns clock cycle, and it offered considerably more than four times the total throughput.
Much of this speed increase was due to extensive use of pipelining, a technique that allows different parts of the CPU to work simultaneously on different parts of successive instructions of the process at the same time. This works in the same way that an automotive assembly line can produce one vehicle every 90 seconds, and thus easily 300 vehicles per 8 hour shift by doing a partial assembly of each vehicle simultaneously every 90 seconds. Any one vehicle will still take several hours to be completely assembled. In computers, pipelining uses separate circuits to work on different parts of different instructions at the same time, in a fashion similar to the many stations on an assembly line. Any one instruction completes processing no faster, but the program as a whole moves through the computer more quickly.
The 7600 did not sell well because it was introduced during the 1969 downturn in the U.S. national economy. Its complexity had led to poor reliability. The machine was not totally compatible with the 6000-series and required a completely different operating system, which like most new OSs, was primitive. The 7600 project paid for itself, but damaged CDC's reputation. The 7600 memory had a split primary- and secondary-memory which required user management but was more than fast enough to make it the fastest uniprocessor from 1969 to 1976. A few dozen 7600s were the computers of choice at supercomputer centers around the world.
Cray then turned to the design of the CDC 8600. This design included four 7600-like processors in a single, smaller case. The smaller size and shorter signal paths allowed the 8600 to run at much higher clock speeds which, together with faster memory, provided most of the performance gains. The 8600, however, belonged to the "old school" in terms of its physical construction, and it used individual components soldered to circuit boards. The design was so compact that cooling the CPU modules proved effectively impossible, and access for maintenance difficult. An abundance of hot-running solder joints ensured that the machines did not work reliably; Cray recognized that a re-design was needed.
The STAR and the Cyber.
In addition to the redesign of the 8600, CDC had another project called the CDC STAR-100 under way, led by Cray's former collaborator on the 6600/7600, Jim Thornton. Unlike the 8600's "four computers in one box" solution to the speed problem, the STAR was a new design using a unit that we know today as the vector processor. By highly pipelining mathematical instructions with purpose-built instructions and hardware, mathematical processing is dramatically improved in a machine that was otherwise slower than a 7600. Although the particular set of problems it would be best at solving was limited compared to the general-purpose 7600, it was for solving exactly these problems that customers would buy CDC machines.
Since these two projects competed for limited funds during the late 1960s, Norris felt that the company could not support simultaneous development of the STAR and a complete redesign of the 8600. Therefore, Cray left CDC to form the Cray Research company in 1972. Norris remained, however, a staunch supporter of Cray, and invested money into Cray's new company. In 1974 CDC released the STAR, designated as the Cyber 203. It turned out to have "real world" performance that was considerably worse than expected. STAR's chief designer, Jim Thornton, then left CDC to form the Network Systems Corporation.
A variety of systems based on the basic 6600/7600 architecture were repackaged in different price/performance categories of the CDC Cyber, which became CDC's main product line in the 1970s. An updated version of the STAR architecture, the Cyber 205, had considerably better performance than the original. By this time, however, Cray's own designs, like the Cray-1, were using the same basic design techniques as the STAR, but were computing much faster.
Sales of the STAR were weak, but Control Data Corp. produced a successor system, the Cyber 200/205, that gave Cray Research some competition. CDC also embarked on a number of special projects for its clients, who produced an even smaller number of black project computers. The CDC Advanced Flexible Processor (AFP), also known as CYBER PLUS, was one such machine.
Another design direction was the "Cyber 80" project, which was aimed at release in 1980. This machine could run old 6600-style programs, and also had a completely new 64-bit architecture. The concept behind Cyber 80 was that current 6000-series users would migrate to these machines with relative ease. The design and debugging of these machines went on past 1980, and the machines were eventually released under other names.
CDC was also attempting to diversify its revenue from hardware into services and this included its promotion of the PLATO computer-aided learning system, which ran on Cyber hardware and incorporated many early computer interface innovations including bit-mapped touchscreen terminals.
Magnetic Peripherals Inc..
Meanwhile, several very large Japanese manufacturing firms were entering the market. The supercomputer market was too small to support more than a handful of companies, so CDC started looking for other markets. One of these was the high-performance hard disk drive market, which was becoming more lucrative as personal computers (PCs) began to include them in the mid-1980s.
Magnetic Peripherals Inc., originally a joint venture with Honeywell and Honeywell Bull, became a major player in the hard disk drive market. It was the worldwide leader in 14 inch disk drive technology in the OEM marketplace in the 1970s and early 1980s especially with its SMD (Storage Module Device) and CMD (Cartridge Module Drive), with its plant at Brynmawr in the South Wales valleys running 24/7 production. The Magnetic Peripherals division in Brynmawr had produced 1 million disks and 3 million magnetic tapes by October 1979. CDC was an early developer of the eight-inch drive technology with products from its MPI Oklahoma City Operation. Its CDC Wren series drives were particularly popular with "high end" users, although it was behind the capacity growth and performance curves of numerous startups such as Micropolis, Atasi, Maxtor, and Quantum. CDC also co-developed the now universal Advanced Technology Attachment (ATA) interface with Compaq and Western Digital, which was aimed at lowering the cost of adding low-performance drives.
CDC founded a separate division called "Rigidyne" in Simi Valley, California, to develop 3.5-inch drives using technology from the Wren series. These were marketed by CDC as the "Swift" series, and were among the first high-performance 3.5-inch drives on the market at their introduction in 1987.
in September 1988 CDC merged Rigidyn and MPI into the umbrella subsidiary of Imprimis Technology. The next year Seagate Technology purchased Imprimis for $250 million in cash, 10.7 million in Seagate stock and a $50 million promissory note.
ETA Systems, wind-down and sale of assets.
CDC decided to fight for the high-performance niche, but Norris considered that the company had become moribund and unable to quickly design competitive machines. In 1983 he set up a spinoff company, ETA Systems, whose design goal was a machine processing data at 10 GFLOPs, about 40 times the speed of the Cray-1. The design never fully matured, and it was unable to reach its goals. Nevertheless, the product was one of the fastest computers on the market, and 7 liquid nitrogen-cooled and 27 smaller air cooled versions of the computers were sold during the next few years. They used the new CMOS chips, which produced much less heat. The effort ended after half-hearted attempts to sell ETA Systems. In 1989, most of the employees of ETA Systems were laid off, and the remaining ones were folded into CDC.
Despite having valuable technology, CDC still suffered huge losses in 1985 and 1986 while attempting to reorganize. As a result, in 1987 it sold its PathLab Laboratory Information System to 3M. While CDC was still making computers, it was decided that hardware manufacturing was no longer as profitable as it used to be, and so in 1988 it was decided to leave the industry, bit by bit. The first division to go was Imprimis. After that CDC sold other assets such as VTC (a chip maker that specialized in mass-storage circuitry and was closely linked with MPI), and non-computer-related assets like Ticketron. Finally, in 1992, the computer hardware and service businesses were spun out as Control Data Systems, Inc. (CDS). In 1999, CDS was bought out by Syntegra, a subsidiary of the BT Group, and merged into BT's Global Services organization.
CDC's Energy Management Division was one of its most successful business units, providing control systems solutions that managed as much as 25% of all electricity on the planet. In 1988 or 1989, this division was renamed Empros and was later sold to Siemens as CDC broke apart.
Finally, after the CDS spinout, all that was left of CDC was its services business, and it became known as the Ceridian Corporation. Ceridian continues as a successful outsourced IT company focusing on human resources. In 1997 General Dynamics acquired the Computing Devices International Division of Ceridian. Computing Devices, headquartered in Bloomington, Minnesota, was a defense electronics and systems integration business, originally Control Data's Government Systems Division.
Commercial Credit Corporation.
In 1968, Commercial Credit Corporation was the target of a hostile takeover by Loews Inc. Loews had acquired nearly 10% of CCC, which it intended to break up on acquisition. To avoid the takeover, CCC forged a deal with CDC lending them the money to purchase control in CCC instead, and "That is how a computer company came to own a fleet of fishing boats in the Chesapeake Bay."
By the 1980s, Control Data entered an unstable period, which resulted in the company liquidating many of their assets. In 1986, Sandy Weill convinced the Control Data management to spin off their Commercial Credit subsidiary to prevent the company's potential liquidation. Over a period of years, Weill used Commercial Credit to build an empire that became Citigroup. In 1999, Commercial Credit was renamed CitiFinancial, and in 2011, the full-service network of US CitiFinancial branches were renamed OneMain Financial.

</doc>
<doc id="58034" url="https://en.wikipedia.org/wiki?curid=58034" title="Chemehuevi">
Chemehuevi

The Chemehuevi are an indigenous people of the Great Basin. They are the southernmost branch of Paiute. Today, Chemehuevi people are enrolled in the following federally recognized tribes:
Some Chemehuevi are also part of the Soboba Band of Luiseno Indians, which members are mostly "Sovovatum" or "Soboba band" members of Cahuilla and Luiseño people.
Name.
"Chemehuevi" has multiple interpretations. It is considered to either be a Mojave term meaning "those who play with fish;" or a Quechan word meaning "nose-in-the-air-like-a-roadrunner." The Chemehuevi call themselves "Nüwüwü" ("The People", singular "Nüwü") or "Tantáwats", meaning "Southern Men."
Language.
The language, Chemehuevi, is a Colorado River Numic language, in the Numic language branch of the Uto-Aztecan language family. First transcribed by John P. Harrington and Carobeth Laird in the early 20th Century, it was studied in the 1970s by linguist Margaret L. Press. whose field notes and extensive sound recordings remain available. The language is now near extinction; during the filming of Ironbound Films' 2008 American documentary film "The Linguists", linguists Greg Anderson and K. David Harrison interviewed and recorded one of the last 3 remaining speakers.
In 2015, the Siwavaats Junior College in Havasu Lake, California has been established to teach children the language. A Chemehuevi dictionary with 2,500 words is expected to become available in 2016.
History and traditional culture.
The Chemehuevi were originally a desert tribe among the Nüwü or Paiute-Shoshone nations. Post-contact, they lived primarily in the eastern Mojave Desert and later the Chemehuevi Valley along the Colorado River in California. They were a nomadic people living in small groups given the sparse resources available in the desert environment. Carobeth Laird indicates their traditional territory spanned the High Desert from the Colorado River on the east to the Tehachapi Mountains on the west and from the Las Vegas area and Death Valley on the north to the San Bernardino and San Gabriel Mountains in the south. They are most closely identified as among the Great Basin Indians. Among others they are cousins of the Kawaiisu.
The most comprehensive collection of Chemehuevi history, culture and mythology was gathered by Carobeth Laird (1895–1983) and her second husband, George Laird, one of the last Chemehuevi to have been raised in the traditional culture. Carobeth Laird, a linguist and ethnographer, wrote a comprehensive account of the culture and language as George Laird remembered it, and published their collaborative efforts in her 1976 "The Chemehuevis", the first and, to date, only ethnography of the Chemehuevi traditional culture.
Describing the Chemehuevi as she knew them, and presenting the texture of traditional life amongst the people, Carobeth Laird writes:
The Chemehuevi character is made up of polarities which are complementary rather than contradictory. They are loquacious yet capable of silence; gregarious yet so close to the earth that single families or even men alone might live and travel for long periods away from other human beings; proud, yet capable of a gentle self-ridicule. They are conservative to a degree, yet insatiably curious and ready to inquire into and even to adopt new ways: to visit all tribes, whether friends or enemies; to speak strange tongues, sing strange songs, and marry strange wives.
Population.
Estimates for the pre-contact populations of most native groups in California have varied substantially. Alfred L. Kroeber estimated the combined 1770 population of the Chemehuevi, Koso (Western Shoshone), and Kawaiisu as 1,500, and the combined population of the Chemehuevi, Koso (Western Shoshone), and Kawaiisu in 1910 as 500. An Indian agent reported the Chemehuevi population in 1875 to be 350. Kroeber estimated U.S. Census data put the Chemehuevi population in 1910 as 355. population as of 2016 is in the 1000s

</doc>
<doc id="58035" url="https://en.wikipedia.org/wiki?curid=58035" title="Hopi">
Hopi

The Hopi are a Native American tribe, who primarily live on the Hopi Reservation in northeastern Arizona. As of 2010, there were 18,327 Hopi in the United States, according to the 2010 census. The Hopi language is one of the 30 of the Uto-Aztecan language family. The majority of Hopi people are enrolled in the Hopi Tribe of Arizona but some are enrolled in the Colorado River Indian Tribes.
When first encountered by the Spanish in the 16th century, the Hopi and the surrounding cultures were referred to as Pueblo people, because they lived in villages ("pueblos" in the Spanish language). The Hopi are descended from the Ancient Pueblo Peoples (Hopi: "Hisatsinom" or ) who constructed large apartment-house complexes in northeastern Arizona, northwestern New Mexico, and southwestern Colorado. They lived along the Mogollon Rim, especially from the 12th–14th century, when they abandoned their large villages.
The name "Hopi" is a shortened form of their autonym, "Hopituh Shi-nu-mu" ("The Peaceful People" or "Peaceful Little Ones"). The "Hopi Dictionary" gives the primary meaning of the word "Hopi" as: "behaving one, one who is mannered, civilized, peaceable, polite, who adheres to the Hopi way." In the past, Hopi sometimes used the term "Hopi" and its cognates to refer to the Pueblo peoples in general, in contrast to other, more warlike tribes.
"Hopi" is a concept deeply rooted in the culture's religion, spirituality, and its view of morality and ethics. To be Hopi is to strive toward this concept, which involves a state of total reverence and respect for all things, to be at peace with these things, and to live in accordance with the instructions of "Maasaw", the Creator or Caretaker of Earth. The Hopi observe their traditional ceremonies for the benefit of the entire world.
Traditionally, Hopi are organized into matrilineal clans. When a man marries, the children from the relationship are members of his wife's clan. These clan organizations extend across all villages. Children are named by the women of the father's clan. On the twentieth day of a baby's life, the women of the paternal clan gather, each woman bringing a name and a gift for the child. In some cases where many relatives would attend, a child could be given over forty names, for example. The child's parents generally decide the name to be used from these names. Current practice is to either use a non-Hopi or English name or the parent's chosen Hopi name. A person may also change the name upon initiation into one of the religious societies, such as the Kachina society, or with a major life event.
The Hopi have always viewed their land as sacred. Agriculture is a very important part of their culture, and their villages are spread out across the northern part of Arizona. The Hopi and the Navajo did not have a conception of land being bounded and divided. They lived on the land that their ancestors did. On December 16, 1882 President Arthur passed an executive order creating a reservation for the Hopi. It was much smaller than the Navajo reservation, which was the largest in the country.
On October 24, 1936 the Hopi people ratified a Constitution. That Constitution created a unicameral government where all powers are vested in a Tribal Council. While there is an executive branch (tribal chairman and vice chairman) and judicial branch, their powers are limited under the Hopi Constitution. The traditional powers and authority of the Hopi Villages was preserved in the 1936 Constitution.
Today, the Hopi Reservation is entirely surrounded by the much larger Navajo Reservation. The two nations used to share the "Navajo–Hopi Joint Use Area", but this was a source of conflict. The partition of this area, commonly known as Big Mountain, by Acts of Congress in 1974 and 1996, has also resulted in long-term controversy.
Hopi History.
The Hopi are one of many Native American cultures in the Southwestern United States. When first encountered by the Spanish in the 16th century, these cultures were referred to as Pueblo people because they lived in villages ("pueblos" in the Spanish language). The Hopi are descended from the Ancient Pueblo Peoples (Hopi: "Hisatsinom" or ) who constructed large apartment-house complexes in northeastern Arizona, northwestern New Mexico, and southwestern Colorado. They lived along the Mogollon Rim, especially from the 12th–14th century, when they abandoned their large villages. No researchers have been able to determine the reason, although it is likely that a drying of water sources would have forced the people away.
Oraibi.
Old Oraibi is one of four original Hopi villages, and one of the oldest continuously inhabited villages within the territory of the United States. In the 1540s the village was recorded as having 1,500–3,000 residents.
Early European contact, 1540–1680.
The first recorded European contact with the Hopi was by the Spanish in A.D 1540. Spanish General Francisco Vásquez de Coronado went to North America to explore the land. While at the Zuni villages, he learned of the Hopi tribe. Coronado dispatched Pedro de Tovar and other members of their party to find the Hopi villages. The Spanish wrote that the first Hopi village they visited was "Awatovi". They noted that there were about 16,000 Hopi and Zuni people. A few years later, the Spanish explorer García López de Cárdenas investigated the Rio Grande and met the Hopi. They warmly entertained Cardenas and his men and directed him on his journey.
In 1582–1583 the Hopi were visited by Antonio de Espejo’s expedition. He noted that there were five Hopi villages and around 12,000 Hopi people. During these early years, the Spanish explored and colonized the southwestern region of the New World, but never sent many forces or settlers to the Hopi country. Their visits to the Hopi were random and spread out over many years. Many times the visits were from military explorations.
The Spanish colonized near the Rio Grande and, because the Hopi did not live near rivers that gave access to the Río Grande, the Spanish never left any troops on their land. The Spanish were accompanied by missionaries, Catholic friars. Beginning in 1629, with the arrival of 30 friars in Hopi country, the Franciscan Period started. The Franciscans had missionaries assigned and built a church at Awatovi. The Hopi originally were against conversion to Catholicism. After an incident where Father Porras purportedly restored the sight of a blind youth by placing a cross over his eyes, the Hopi at Awatovi believed in Christianity. Most Hopi in the other villages continued to resist conversion, wanting to maintain their own ways.
Pueblo Revolt of 1680.
Spanish Roman Catholic priests were only marginally successful in converting the Hopi and persecuted them in a draconian manner for adhering to Hopi religious practices. The Spanish occupiers in effect enslaved the Hopi populace, compelling them to endure forced labor and hand over goods and crops. Spanish oppression and attempts to convert the Hopi caused the Hopi over time to become increasingly intolerant towards their occupiers. The only significant conversions were at the pueblo of Awatovi. Eventually in the year 1680 the Rio Grande Pueblo Indians put forward the suggestion to revolt and garnered Hopi support.
The Hopi and Pueblo Revolt was the first time that diverse Pueblo groups had worked in unison to drive out the Spanish colonists. In the Hopi revolt against the Spanish, local Catholic Church missions were attacked, friars and priests were all put to death, and the churches and mission buildings were dismantled stone by stone. It took two decades for the Spanish to reassert their control over the Rio Grande Pueblos but thereafter Spanish influence in the more distant Hopi area was more limited. By 1700, the Spanish friars had begun rebuilding a smaller church at Awatovi. During the winter of 1700–01, selected teams of men from the other Hopi villages sacked Awatovi at the request of the village chief, killed all the men of the village, and removed the women and children to other Hopi villages, then completely destroyed the village and burned it to the ground. Thereafter, despite intermittent attempts in the course of the 18th century, the Spanish failed subsequently to ever re-establish a presence in Hopi country.
Hopi-U.S relations, 1849–1946.
In 1849, James S. Calhoun was appointed official Indian agent of Indian Affairs for the Southwest Territory of the U.S. He had headquarters in Santa Fe and was responsible for all of the Indian residents of the area. The first formal meeting between the Hopi and the U.S government occurred in 1850 when seven Hopi leaders made the trip to Santa Fe to meet with Calhoun. They wanted the government to provide protection against the Navajo, an Apachean-language tribe, but distinct from other Apache. At this time, the Hopi leader was "Nakwaiyamtewa".
The US established Fort Defiance in 1851 in Arizona, and placed troops in Navajo country to deal with their threats to the Hopi. General James J. Carleton, with the assistance of Kit Carson, was assigned to travel through the area. They "captured" the Navajo natives and forced them to the fort. As a result of the Long Walk of the Navajo, the Hopi enjoyed a short period of peace.
In 1847, Mormons settled in Utah and tried to convert the Indians to Mormonism. Jacob Hamblin, a Mormon missionary, first made a trip into Hopi country in 1858. He was on good terms with the Hopi Indians, and in 1875 an LDS Church was built on Hopi land.
Education.
In 1875, the English trader Thomas Keam escorted Hopi leaders to meet President Chester A. Arthur in Washington D.C. "Loololma," village chief of "Oraibi" at the time, was very impressed with Washington. As he concluded that education allowed the whites to live that way, he returned wanting a formal school to be built for the Hopi children. In 1886, twenty of the Hopi leaders signed a petition sent to the Commissioner of Indian Affairs requesting that a school be built on their land. In 1887, a federal boarding school was established at Keams Canyon for the Hopi children.
The Oraibi people did not support the school and refused to send their children away from their villages. The Keams Canyon School was organized to teach the Hopi youth the ways of European-American civilization: forcing them to use English and give up their traditional ways. The children were forced to abandon their tribal identity and completely take on the European-American culture. They received haircuts, new clothes, took on Anglo names, and learned English. The boys learned farming and carpentry skills, while the girls were taught ironing, sewing and "civilized" dining. The school also reinforced European-American religions. The American Baptist Home Mission Society provided the students with services every morning and religious teachings during the week. In 1890, the Commissioner of Indian Affairs arrived in Hopi country with other government officials to review the progress of the new school. Seeing that few students were enrolled, they returned with federal troops who threatened to arrest the Hopi parents if they refused to send their children to school. The Commissioner took children to fill the school.
Hopi land.
Agriculture is a very important part of Hopi culture, and their villages are spread out across the northern part of Arizona. The Hopi and the Navajo did not have a conception of land being bounded and divided. They lived on the land that their ancestors did. On December 16, 1882 President Arthur passed an executive order creating a reservation for the Hopi. It was much smaller than the Navajo reservation, which was the largest in the country.
The Hopi reservation was originally a rectangle 55 by , in the middle of the Navajo Reservation, with their village lands taking about half of the land. The reservation prevented encroachment by white settlers, but it did not protect the Hopis against the Navajos.
The Hopi and the Navajo continued to fight over land, and they had different models of sustainability, as the Navajo were sheepherders. Eventually the Hopi went before the Senate Committee of Interior and Insular Affairs to ask them to help provide a solution to the dispute. The tribes argued over around of land in northern Arizona. In 1887 the U.S government passed the Dawes Allotment Act. The purpose was to divide up communal tribal land into individual allotments by household, to encourage a model of European-American style subsistence farming on individually owned family plots of or less. The Department of Interior would declare remaining land "surplus" to the tribe's needs and make it available for purchase by U.S citizens. For the Hopi, the Act would destroy their ability to farm, which was their main means of income. The Bureau of Indian Affairs did not set up land allotments in the Southwest.
Oraibi split.
The chief of the Oraibi, Lololoma enthusiastically supported Hopi education, but the people were divided on this issue. Most of the village was conservative and refused to allow their children to attend school. The Indians were referred to as the "hostiles" because they opposed the American government and its attempts to force assimilation. The rest of the Oraibi were called the "friendlies" because of their acceptance of the white people. The "hostiles" refused to let their children attend school. In 1893, the Oraibi Day School was opened in the Oraibi village. Although the school was within the village, the traditional parents still refused to allow their children to attend.
In 1894, a group of Hopi parents announced that they were against the ideas of Washington and did not want their children to be exposed to the culture of the white American people. The government sent in troops to arrest the 19 parents and sent them to Alcatraz Prison, where they stayed for a year. Another Oraibi leader, "Lomahongyoma", competed with "Lololoma" for village leadership. In 1906 the village split after a conflict between Hostiles and Friendlies. The conservative Hostiles left and formed a new village, known as "Hotevilla".
Hopi recognition.
At dawn of the 20th century, the US government established day schools, missionaries, farming assistants and physicians on every Indian reservation. This policy required that every reservation set up its own Indian-police and Tribal courts, and appoint a chief or leader who would represent their tribe within the U.S government. In 1910 in the Census for Indians, the Hopi Tribe had a total of 2,000 members, which was the highest in 20 years. The Navajo at this time had 22,500 members and have consistently increased in population. During the early years of this century, only about 3% of Hopis lived off the reservation. In 1924 Congress officially declared Native Americans to be U.S citizens.
Under the Indian Reorganization Act of 1934, the Hopi established a constitution to create their own tribal government, and in 1936 elected a Tribal Council. The Preamble to the Hopi constitution states that they are a self-governing tribe, focused on working together for peace and agreements between villages in order to preserve the "good things of Hopi life." The Constitution consists of thirteen different "Articles," all with a different topic of interest. The articles cover the topics of territory, membership, and organization of their government with a legislative, executive and judicial branch. The rest of the articles discuss the twelve villages recognized by the tribe, lands, elections, Bill of Rights and more.
Hopi-Navajo land disputes.
From the 1940s to the 1970s, the Navajo kept moving their villages closer and closer to Hopi land, causing the Hopi to raise the land issue with the U.S government. This resulted in the establishment of "District 6" which placed a boundary around the Hopi villages on the first, second, and third mesas, thinning the reservation to . In 1962 the courts issued the "Opinion, Findings of Fact and Conclusions of Law and Judgment," which stated that the U.S government did not grant the Navajo any type of permission to reside on the Hopi Reservation that was declared in 1882; and that the remaining Hopi land was to be shared with the Navajo.
Between 1961–1964, the Hopi tribal council signed leases with the U.S government that allowed for companies to explore and drill for oil, gas and minerals within Hopi country. This drilling brought over 3 million dollars to the Hopi Tribe. In 1974, The Navajo-Hopi Land Settlement Act was passed. It created the Navajo-Hopi Indian Relocation Commission, which forced the relocation of any Hopi or Navajo living on the other’s land. In 1992, the Hopi Reservation was increased to .
Today's Hopi Reservation is bisected by Arizona State Route 264, which is an expansive scenic paved road that links together the numerous Hopi villages.
The Modern Tribal Government is Created.
On October 24, 1936 the Hopi people ratified a Constitution. That Constitution created a unicameral government where all powers are vested in a Tribal Council. While there is an executive branch (tribal chairman and vice chairman) and judicial branch, their powers are limited under the Hopi Constitution. The traditional powers and authority of the Hopi Villages was preserved in the 1936 Constitution.
The Hopi Tribal Government Today.
The Hopi tribe is federally recognized and headquartered in Kykotsmovi, Arizona.
Tribal Officers:
The current tribal officers are:
Chairman: Herman G. Honanie,
Vice Chairman: Alfred Lomahquahu, Jr.,
Tribal Secretary: Vernita Selestewa,
Treasurer: Vacant,
Sergeant-at-Arms: Alfonso Sakeva
The Tribal Council
Representatives to the council are selected either by a community election or by an appointment from the village kikmongwi, or leader. Each representative serves a two-year term. Tribal Representation on the Tribal Council as of 2014 is as follows:
Village of Upper Moenkopi:
Daniel Honahni,
Danny Humetewa, Sr.,
Leroy Sumatzkuku,
Michael Elmer
Village of Bakabi:
Davis F. Pecusa,
Leroy G. Kewanimptewa, Jr.,
Lamar Keevama
Village of Kykotsmovi:
Alban Mooya, Jr.,
Caleb H. Johnson,
Nada Talayumptewa,
Norman Honanie
Village of Sipaulovi:
George Mase,
Rosa Honanie
Village of Mishongnovi:
Annette F. Talayumptewa,
Arthur Batala,
Marilyn Tewa,
Mervin Yoyetewa
Currently, the villages of Mishongnovi, Shungopavi, Oraibi, Hotevilla, Lower Moenkopi and First Mesa Consolidated Villages (Walpi, Shitchumovi and Tewa) do not have a representative on council. The Hopi Villages select Council representatives, and may decline to send any representative. The declination has been approved by the Hopi Courts.
Tribal Courts
The Hopi Tribal Government operates a Trial Court and Appellate Court in Keams Canyon. These courts operate under an amended Tribal Code, which was amended August 28, 2012.
Economic development.
The Hopi tribe earns most of its income from natural resources. On the Navajo reservation, a significant amount of coal is mined yearly from which the Hopi Tribe shares mineral royalty income. Peabody Western Coal Company is one of the largest coal operations on Hopi land, with long-time permits for continued mining.
The tribe's 2010 operating budget was $21.8 million, and projected mining revenues for 2010 was $12.8 million.
The Hopi Economic Development Corporation is the tribal enterprise tasked with creating diverse, viable economic opportunities. The HEDC oversees the Hopi Cultural Center and Walpi Housing Management. Other HEDC businesses include the Hopi Three Canyon Ranches, between Flagstaff and Winslow; and the 26 Bar Ranch in Eagar; Hopi Travel Plaza in Holbrook; three commercial properties in Flagstaff; and the Kokopelli Inn in Sedona.
Tourism is a source of income, and the tribe's opening of the 100-room Moenkopi Legacy Inn and Suites in Moenkopi, Arizona, near Tuba City, Arizona, is the second hotel on the reservation. It provides non-Hopi a venue for entertainment, lectures, and educational demonstrations, as well as tours and lodging. The project is expected to support 400 jobs. The tribe operates the Tuvvi Travel Center and Tuvvi Café in Moenkopi.
The Hopi people have repeatedly voted against gambling casinos as an economic opportunity.
Culture.
The name "Hopi" is a shortened form of their autonym, "Hopituh Shi-nu-mu" ("The Peaceful People" or "Peaceful Little Ones"). The "Hopi Dictionary" gives the primary meaning of the word "Hopi" as: "behaving one, one who is mannered, civilized, peaceable, polite, who adheres to the Hopi way." In the past, Hopi sometimes used the term "Hopi" and its cognates to refer to the Pueblo peoples in general, in contrast to other, more warlike tribes.
"Hopi" is a concept deeply rooted in the culture's religion, spirituality, and its view of morality and ethics. To be Hopi is to strive toward this concept, which involves a state of total reverence and respect for all things, to be at peace with these things, and to live in accordance with the instructions of "Maasaw", the Creator or Caretaker of Earth. The Hopi observe their traditional ceremonies for the benefit of the entire world.
Traditionally, Hopi are organized into matrilineal clans. When a man marries, the children from the relationship are members of his wife's clan. These clan organizations extend across all villages. Children are named by the women of the father's clan. On the twentieth day of a baby's life, the women of the paternal clan gather, each woman bringing a name and a gift for the child. In some cases where many relatives would attend, a child could be given over forty names, for example. The child's parents generally decide the name to be used from these names. Current practice is to either use a non-Hopi or English name or the parent's chosen Hopi name. A person may also change the name upon initiation into one of the religious societies, such as the Kachina society, or with a major life event.
The Hopi practice a complete cycle of traditional ceremonies although not all villages retain or had the complete ceremonial cycle. These ceremonies take place according to the lunar calendar and are observed in each of the Hopi villages. Like other Native American groups, the Hopi have been influenced by Christianity and the missionary work of several Christian denominations. Few have converted enough to Christianity to drop their traditional religious practices.
Traditionally the Hopi are highly skilled micro or subsistence farmers. The Hopi also are part of the wider cash economy; a significant number of Hopi have mainstream jobs; others earn a living by creating high-quality Hopi art, notably the carving of Kachina dolls, the expert crafting of earthenware ceramics, and the design and production of fine jewelry, especially sterling silver.
The Hopi collect and dry a native perennial plant called Thelesperma megapotamicum, known by the common name Hopi tea, and use it to make an herbal tea, as a medicinal remedy and as a yellow dye.
Albinism.
The Hopi have a high rate of albinism - about 1 in 200 individuals.
External links.
Hopi movie "Techqua Ikachi" part 1 https://www.youtube.com/watch?v=vGdbpu1_STM
Hopi movie "Techqua Ikachi" part 2 https://www.youtube.com/watch?v=XSSHnbjfBl4

</doc>
<doc id="58036" url="https://en.wikipedia.org/wiki?curid=58036" title="Lancaster County, Nebraska">
Lancaster County, Nebraska

Lancaster County is a county located in the U.S. state of Nebraska. As of the 2010 census, the population was 285,407, making it the second-most populous county in Nebraska. Its county seat is Lincoln, the state capital. The county was created in 1859, and the original county seat was the village of Lancaster.
Lancaster County is part of the Lincoln, NE Metropolitan Statistical Area.
In the Nebraska license plate system, Lancaster County was represented by the prefix 2 (it had the second-largest number of vehicles registered in the state when the license plate system was established in 1922). In 2002, the state discontinued the 1922 system in Lancaster, Douglas and Sarpy counties.
Geography.
According to the U.S. Census Bureau, the county has a total area of , of which is land and (1.0%) is water.
Climate.
In 2004, Lancaster County was named a StormReady county by the National Weather Service.
Demographics.
As of the census of 2000, there were 250,291 people, 99,187 households, and 60,702 families residing in the county. The population density was 298 people per square mile (115/km²). There were 104,217 housing units at an average density of 124 per square mile (48/km²). The racial makeup of the county was 90.07% White, 2.82% Black or African American, 0.64% Native American, 2.86% Asian American, 0.06% Pacific Islander, 1.69% from other races, and 1.87% from two or more races. 3.37% of the population were Hispanic or Latino of any race. 39.1% were of German, 7.9% English and 7.8% Irish ancestry according to Census 2000.
There were 99,187 households out of which 30.30% had children under the age of 18 living with them, 48.80% were married couples living together, 9.10% had a female householder with no husband present, and 38.80% were non-families. 29.10% of all households were made up of individuals and 8.30% had someone living alone who was 65 years of age or older. The average household size was 2.40 and the average family size was 3.00.
In the county the population was spread out with 23.50% under the age of 18, 15.40% from 18 to 24, 30.40% from 25 to 44, 20.30% from 45 to 64, and 10.40% who were 65 years of age or older. The median age was 32 years. For every 100 females there were 99.80 males. For every 100 females age 18 and over, there were 98.50 males.
The median income for a household in the county was $41,850, and the median income for a family was $53,676. Males had a median income of $34,720 versus $25,614 for females. The per capita income for the county was $21,265. About 5.50% of families and 9.50% of the population were below the poverty line, including 9.90% of those under age 18 and 6.10% of those age 65 or over.
Communities.
Census divisions.
Lancaster County is divided into the following census divisions, called precincts, except for the City of Lincoln.

</doc>
<doc id="58038" url="https://en.wikipedia.org/wiki?curid=58038" title="Oliver Goldsmith">
Oliver Goldsmith

Oliver Goldsmith (10 November 1728 – 4 April 1774) was an Anglo-Irish novelist, playwright and poet, who is best known for his novel "The Vicar of Wakefield" (1766), his pastoral poem "The Deserted Village" (1770), and his plays "The Good-Natur'd Man" (1768) and "She Stoops to Conquer" (1771, first performed in 1773). He is thought to have written the classic children's tale "The History of Little Goody Two-Shoes" (1765).
Biography.
Goldsmith's birth date and year are not known with certainty. According to the Library of Congress authority file, he told a biographer that he was born on 10 November 1728.
The location of his birthplace is also uncertain. He was born either in the townland of Pallas, near Ballymahon, County Longford, Ireland, where his father was the Anglican curate of the parish of Forgney, or at the residence of his maternal grandparents, at the Smith Hill House in the diocese of Elphin, County Roscommon where his grandfather Oliver Jones was a clergyman and master of the Elphin diocesan school, and where Oliver studied. When Goldsmith was two years old, his father was appointed the rector of the parish of "Kilkenny West" in County Westmeath. The family moved to the parsonage at Lissoy, between Athlone and Ballymahon, and continued to live there until his father's death in 1747.
In 1744 Goldsmith went up to Trinity College, Dublin. His tutor was Theaker Wilder. Neglecting his studies in theology and law, he fell to the bottom of his class. In 1747, along with four other undergraduates, he was expelled for a riot in which they attempted to storm the Marshalsea Prison. He was graduated in 1749 as a Bachelor of Arts, but without the discipline or distinction that might have gained him entry to a profession in the church or the law; his education seemed to have given him mainly a taste for fine clothes, playing cards, singing Irish airs and playing the flute. He lived for a short time with his mother, tried various professions without success, studied medicine desultorily at the University of Edinburgh from 1752 to 1755, and set out on a walking tour of Flanders, France, Switzerland and Northern Italy, living by his wits (busking with his flute).
He settled in London in 1756, where he briefly held various jobs, including an apothecary's assistant and an usher of a school. Perennially in debt and addicted to gambling, Goldsmith produced a massive output as a hack writer for the publishers of London, but his few painstaking works earned him the company of Samuel Johnson, with whom he was a founding member of "The Club". There, through fellow Club member Edmund Burke, he made the acquaintance of Sir George Savile, who would later arrange a job for him at Thornhill Grammar School. The combination of his literary work and his dissolute lifestyle led Horace Walpole to give him the epithet "inspired idiot". During this period he used the pseudonym "James Willington" (the name of a fellow student at Trinity) to publish his 1758 translation of the autobiography of the Huguenot Jean Marteilhe.
Goldsmith was described by contemporaries as prone to envy, a congenial but impetuous and disorganised personality who once planned to emigrate to America but failed because he missed his ship. At some point around this time he worked at Thornhill Grammar School, later basing Squire Thornhill (in the Vicar of Wakefield) on his benefactor Sir George Savile and certainly spending time with eminent scientist Rev. John Mitchell, who he probably knew from London. Mitchell, sorely missed good company, which Goldsmith naturally provided in spades.Thomas De Quincey wrote of him 'All the motion of Goldsmith's nature moved in the direction of the true, the natural, the sweet, the gentle'.
His premature death in 1774 may have been partly due to his own misdiagnosis of his kidney infection. Goldsmith was buried in Temple Church in London. The inscription reads; "HERE LIES/OLIVER GOLDSMITH". There is a monument to him in the centre of Ballymahon, also in Westminster Abbey with an epitaph written by Samuel Johnson.
Works.
"See The Vicar of Wakefield, The Good-Natur'd Man, The Traveller, and She Stoops to Conquer."
"The Citizen of the World".
In 1760 Goldsmith began to publish a series of letters in the "Public Ledger" under the title "The Citizen of the World". Purportedly written by a Chinese traveller in England by the name of Lien Chi, they used this fictional outsider's perspective to comment ironically and at times moralistically on British society and manners. It was inspired by the earlier essay series "Persian Letters" by Charles de Secondat, Baron de Montesquieu.
"The Hermit".
Goldsmith wrote this romantic ballad of precisely 160 lines in 1765. The hero and heroine are Edwin, a youth without wealth or power, and Angelina, the daughter of a lord "beside the Tyne." Angelina spurns many wooers, but refuses to make plain her love for young Edwin. "Quite dejected with my scorn," Edwin disappears and becomes a hermit. One day, Angelina turns up at his cell in boy's clothes and, not recognising him, tells him her story. Edwin then reveals his true identity, and the lovers never part again. The poem is notable for its interesting portrayal of a hermit, who is fond of the natural world and his wilderness solitude but maintains a gentle, sympathetic demeanor toward other people. In keeping with eremitical tradition, however, Edwin the Hermit claims to "spurn the sex." This poem appears under the title of "A Ballad" sung by the character of Mr. Burchell in Chapter 8 of Goldsmith's novel, "The Vicar of Wakefield."
"The Deserted Village".
In the 1760s Goldsmith witnessed the demolition of an ancient village and destruction of its farms to clear land to become a wealthy man's garden. His poem "The Deserted Village", published in 1770, expresses a fear that the destruction of villages and the conversion of land from productive agriculture to ornamental landscape gardens would ruin the peasantry.
Memorials concerning Oliver Goldsmith.
Goldsmith lived in Kingsbury, now in North-West London between 1771 and 1774 and Oliver Goldsmith Primary School and Goldsmith Lane there are named after him.
The Oliver Goldsmith Summer School is held every June Bank Holiday at Ballymahon with poetry and creative readings being held at Goldsmith's birthplace in nearby Pallas, Forgney.
In the play "Marx in Soho" by Howard Zinn, Marx makes a reference to Goldsmiths' poem, "The Deserted Village".
A statue of him by JH Foley stands at the Front Arch of Trinity College, Dublin (see image).
A statue of him stands in a limestone cell at the ruin of his birthplace in Pallas, Forgney, Ballymahon, County Longford. The statue is a copy of the Foley statue that stands outside Trinity college Dublin and is the focus point of the annual Oliver Goldsmith Summer School.
His name has been given to a new lecture theatre and student accommodation on the Trinity College campus: Goldsmith Hall.
Somerset Maugham used the last line from "An Elegy on the Death of a Mad Dog" in his novel "The Painted Veil" (1925). The character Walter Fane's last words are "The dog it was that died".
Auburn, Alabama, and Auburn University were named for the first line in Goldsmith's poem: ""Sweet Auburn, loveliest village of the plain."" Auburn is still referred to as the 'loveliest village on the plain.'
There is a statue in Ballymahon County Longford outside the town library by Irish Sculptor Éamonn O' Doherty (1939 - 2011)which was unveiled in 1999.
London Underground locomotive number 16 (used on the Metropolitan line of the London Underground until 1962) was named "Oliver Goldsmith".
Longford based band Goldsmith are named after the famous writer.
Athlone Institute of Technology library is named the Goldsmith Library
In popular culture.
Two characters in the 1951 comedy "The Lavender Hill Mob" quote the same line from Goldsmith's poem "The Traveller" – a subtle joke, because the film's plot involves the recasting of stolen gold.
During the opening credits of the SKY One adaptation of Sir Terry Pratchett's Christmas story "The Hogfather", a portrait of Goldsmith is shown as part of a hall of memorials to those "exhumed" by the "Ankh-Morpork Assassins' Guild".

</doc>
<doc id="58039" url="https://en.wikipedia.org/wiki?curid=58039" title="Stuckism">
Stuckism

Stuckism is an international art movement founded in 1999 by Billy Childish and Charles Thomson to promote figurative painting as opposed to conceptual art. By July 2012 the initial group of 13 British artists had expanded to 233 groups in 52 countries.
Childish and Thomson have issued several manifestos. The first one was "The Stuckists", consisting of 20 points starting with "Stuckism is a quest for authenticity". "Remodernism", the other well-known manifesto of the movement, is a criticism of postmodernism; it aims to get back to the true spirit of modernism, to produce art with spiritual value regardless of style, subject matter or medium. In another manifesto they define themselves as "anti-anti-art" which is against anti-art and for art.
After exhibiting in small galleries in Shoreditch, London, the Stuckists' first show in a major public museum was held in 2004 at the Walker Art Gallery, as part of the Liverpool Biennial. The group has demonstrated annually at Tate Britain against the Turner Prize since 2000, sometimes dressed in clown costumes. They have also come out in opposition to the Charles Saatchi-patronised Young British Artists.
Although painting is the dominant artistic form of Stuckism, artists using other media such as photography, sculpture, film and collage have also joined, and share the Stuckist opposition to conceptualism and ego-art.
Name, founding and origin.
[[Image:MedwayPoets.jpg|thumb|Sexton Ming, Tracey Emin, Charles Thomson, Billy Childish and musician Russell Wilkinson
at the Rochester Adult Education Centre to record The Medway Poets LP, 11 December 1987.]]
The name "Stuckism" was coined in January 1999 by Charles Thomson in response to a poem read to him several times by Billy Childish. In it, Childish recites that his former girlfriend, Tracey Emin had said he was "stuck! stuck! stuck!" with his art, poetry and music. Later that month, Thomson approached Childish with a view to co-founding an art group called Stuckism, which Childish agreed to, on the basis that Thomson would do the work for the group, as Childish already had a full schedule.
There were eleven other founding members: Philip Absolon, Frances Castle, Sheila Clark, Eamon Everall, Ella Guru, Wolf Howard, Bill Lewis, Sanchia Lewis, Joe Machine, Sexton Ming, and Charles Williams. The membership has evolved since its founding through creative collaborations: the group was originally promoted as working in paint, but members have since worked in various other media, including poetry, fiction, performance, photography, film and music.
In 1979, Thomson, Childish, Bill Lewis and Ming were members of The Medway Poets performance group, to which Absolon and Sanchia Lewis had earlier contributed. Peter Waite's Rochester Pottery staged a series of solo painting shows. In 1982, TVS broadcast a documentary on the poets. That year, Emin, then a fashion student, and Childish started a relationship; her writing was edited by Bill Lewis, printed by Thomson and published by Childish. Group members published dozens of works. The poetry group dispersed after two years, reconvening in 1987 to record "The Medway Poets" LP. Clark, Howard and Machine became involved over the following years. Thomson got to know Williams, who was a local art student and whose girlfriend was a friend of Emin; Thomson also met Everall. During the foundation of the group, Ming brought in his girlfriend, Guru, who in turn invited Castle.
Manifestos.
In August 1999, Childish and Thomson wrote "The Stuckists manifesto" which stress the value of painting as a medium, its use for communication, and the expression of emotion and experience – as opposed to what Stuckists see as the superficial novelty, nihilism and irony of conceptual art and postmodernism. The most contentious statement in the manifesto is: "Artists who don't paint aren't artists".
The second and third manifestos, "An Open Letter to Sir Nicholas Serota" and "Remodernism" respectively, were sent to the director of the Tate, Nicholas Serota. He sent a brief reply: "Thank you for your open letter dated 6 March. You will not be surprised to learn that I have no comment to make on your letter, or your manifesto 'Remodernism'."
In the "Remodernism" manifesto, the Stuckists declared that they aimed to replace postmodernism with remodernism, a period of renewed spiritual (as opposed to religious) values in art, culture and society. Other manifestos have included "Handy Hints", "Anti-anti-art", "The Cappuccino writer and the Idiocy of Contemporary Writing", "The Turner Prize", "The Decreptitude of the Critic" and "Stuckist critique of Damien Hirst".
In "Anti-anti-art", the Stuckists outlined their opposition to what is known as "anti-art". Stuckists claim that conceptual art is justified by the work of Marcel Duchamp, but that Duchamp's work is "anti-art by intent and effect". The Stuckists feel that "Duchamp's work was a protest against the stale, unthinking artistic establishment of his day", while "the great (but wholly unintentional) irony of postmodernism is that it is a direct equivalent of the conformist, unoriginal establishment that Duchamp attacked in the first place".
Manifestos have been written by other Stuckists, including the Students for Stuckism group. An "Underage Stuckists" group was founded in 2006 with a manifesto for teenagers written by two 16-year-olds, Liv Soul and Rebekah Maybury, on MySpace.
Growth in UK.
In July 1999, the Stuckists were first mentioned in the media, in an article in "The Evening Standard" and soon gained other coverage, helped by press interest in Tracey Emin, who had been nominated for the Turner Prize.
The first Stuckist show was "Stuck! Stuck! Stuck!" in September 1999 in Joe Crompton's in Shoreditch Gallery 108 (now defunct), followed by "The Resignation of Sir Nicholas Serota". In 2000 they staged "The Real Turner Prize Show" at the same time as the Tate Gallery's Turner Prize exhibition.
A "Students for Stuckism" group was founded in 2000 by students from Camberwell College of Arts, who staged their own exhibition. S.P. Howarth was expelled from the painting degree course at Camberwell college for his paintings, and had the first solo exhibit at the Stuckism International Gallery in 2002, named "I Don't Want a Painting Degree if it Means Not Painting".
Thomson stood as a Stuckist candidate for the 2001 British General Election, in the constituency of Islington South & Finsbury, against Chris Smith, the then Secretary of State for Culture. He picked up 108 votes (0.4%). Childish left the group at this time because he objected to Thomson's leadership.
From 2002 to 2005 Thomson ran the Stuckism International Centre and Gallery in Shoreditch, London. In 2003, under the title "A Dead Shark Isn't Art", the gallery exhibited a shark which had first been put on public display in 1989 (two years before Damien Hirst's) by Eddie Saunders in his Shoreditch shop, JD Electrical Supplies. It was suggested that Hirst may have seen this and copied it.
In 2003 they reported Charles Saatchi to the UK Office of Fair Trading, complaining that he had an effective monopoly on art. The complaint was not upheld. In 2003, an allied group, Stuckism Photography, was founded by Larry Dunstan and Andy Bullock. In 2005 the Stuckists offered a donation of 175 paintings from the Walker show to the Tate, but it was rejected by the Tate's trustees.
In August 2005 Thomson alerted the press to the fact that the Tate had purchased a work by Chris Ofili, "The Upper Room", for £705,000 while the artist was a serving Tate trustee. Fraser Kee Scott, owner of A Gallery, demonstrated with the Stuckists outside the Tate Gallery against the gallery's purchase of "The Upper Room". Scott said in "The Daily Telegraph" that the Tate Gallery's chairman, Paul Myners, was hypocritical for refusing to divulge the price paid. Ofili had asked other artists to donate work to the gallery. In July 2006 the Charity Commission censured the gallery for acting outside its legal powers. Sir Nicholas Serota stated that the Stuckists had "acted in the public interest".
In October 2006, the Stuckists staged their first exhibition, "Go West", in a commercial West End gallery, Spectrum London, signalling their entry as "major players" in the art world.
An international symposium on Stuckism took place in October 2006 at the Liverpool John Moores University during the Liverpool Biennial. The programme was led by Naive John, founder of the Liverpool Stuckists. There was an accompanying exhibition in the 68 Hope Gallery at Liverpool School of Art and Design (John Moores University Gallery).
By 2006 there were 63 Stuckist groups in the UK. Members include Naive John, Mark D, Elsa Dax, Paul Harvey, Jane Kelly, Udaiyan, Peter McArdle, Peter Murphy, Rachel Jordan, Guy Denning and Abby Jackson. John Bourne opened Stuckism Wales at his home, a permanent exhibition of (mainly Welsh) paintings. Mandy McCartin is a regular guest artist.
In 2010, Paul Harvey's painting of Charles Saatchi was banned from the window display of the Artspace Gallery in Maddox Street, London, on the grounds that it was "too controversial for the area". It was the centrepiece of the show, "Stuckist Clowns Doing Their Dirty Work", the first exhibition of the Stuckists in Mayfair, and depicted Saatchi with a sheep at his feet and a halo made from a cheese wrapper. The Saatchi Gallery said that Saatchi "would not have any problem" with the painting's display. The gallery announced they were shutting down the show. Harvey said, "I did it to make Saatchi look friendly and human. It's a ludicrous decision".
The Stuckists considered legal action, and protested with emails to the gallery. Subsequently, the painting was reinstated and the show continued.
Demonstrations.
The Stuckists gained significant media coverage for eight years of protests (2000-2006 and 2008) outside Tate Britain against the Turner Prize, sometimes dressed as clowns. In 2001 they demonstrated in Trafalgar Square at the unveiling of Rachel Whiteread's "Monument". In 2002, they carried a coffin marked "The Death of Conceptual Art" to the White Cube Gallery. In 2004 outside the launch of "The Triumph of Painting" at the Saatchi Gallery they wore tall hats with Charles Saatchi's face emblazoned and carried placards claiming that Saatchi had copied their ideas.
Events outside Britain have included "The Clown Trial of President Bush" held in New Haven in 2003 to protest against the Iraq War. Michael Dickinson has exhibited political and satirical collages in Turkey for which he was arrested, and charged, but acquitted of any crime—an outcome which was seen to have positive implications for Turkey's relationship with the European Union.
The Stuckists Punk Victorian.
"The Stuckists Punk Victorian" was the first national gallery exhibition of Stuckist art. It was held at the Walker Art Gallery and Lady Lever Art Gallery and was part of the 2004 Liverpool Biennial. It consisted of over 250 paintings by 37 artists, mostly from the UK but also with a representation of international Stuckist artists from the US, Germany and Australia. There was an accompanying exhibition of Stuckist photographers. A book, "The Stuckists Punk Victorian", was published to accompany the exhibition. "Daily Mail" journalist Jane Kelly exhibited a painting of Myra Hindley in the show, which may have been the cause of her dismissal from her job.
A Gallery.
In July 2007, the Stuckists held an exhibition at A Gallery, "I Won't Have Sex with You as long as We're Married", titled after words apparently said to Thomson by his ex-wife, Stella Vine on their wedding night. The show coincided with the opening of Vine's major show at Modern Art Oxford and was prompted by Thomson's anger that the material promoting her show did not mention her time with the Stuckists. Tate chairman Paul Myners visited both shows.
Sir Nicholas Serota Makes an Acquisitions Decision.
Charles Thomson's painting, "Sir Nicholas Serota Makes an Acquisitions Decision", as Charlotte Cripps of The Independent wrote is one of the best known paintings to come out of the Stuckist movement, and as Jane Morris wrote in "The Guardian" it's a likely "signature piece" for the movement, standing for its opposition to conceptual art. Painted in 2000, the piece has been exhibited in laterStuckist shows, and featured on placards in Stuckist demonstrations against the Turner Prize. It depicts Sir Nicholas Serota, Director of the Tate Gallery and the usual chairman of the Turner Prize jury, and satirises Young British Artist Tracey Emin's installation, "My Bed", consisting of her bed and objects, including knickers, which she exhibited in 1999 as a Turner Prize nominee.
International movement.
In 2000 Regan Tamanui started the first Stuckist group outside Britain in Melbourne, Australia, and it was decided that other artists should be free to start their own groups also, named after their locality. Stuckism has since grown into an international art movement of 233 groups in 52 countries, as of July 2012.
Africa.
Mafa Bamba founded "The Abidgan Stuckists" in 2001 in Ivory Coast and Kari Seid founded "The Cape Town Stuckists" in 2008 in South Africa.
America.
In 2000, Susan Constanse founded the first US group "The Pittsburgh Stuckists" in Pittsburgh—the second group to be founded outside the UK. This was announced in the "In Pittsburgh Weekly", 1 November 2000: "The new word in art is Stuckism. A Stuckist paints their life, mind and soul with no pretensions and no excuses." By 2011 there are 44 US Stuckist groups. There have been Stuckist shows and demonstrations in the US, and American Stuckists have also exhibited in international Stuckist shows abroad. US Stuckists include Jeffrey Scott Holland, Tony Juliano, Frank Kozik and Terry Marks. There are also 4 Stuckist groups in Canada including "The White Rock Stuckists" in British Columbia founded by David Wilson.
Asia.
Asim Butt founded the first Pakistani Stuckist group, "The Karachi Stuckists", in 2005. At the end of 2009 he was thinking of expanding "The Karachi Stuckists" with new members, but on 15 January 2010 he committed suicide. In 2011 Sheherbano Husain restarted the group.
"The Tehran Stuckists" is an Iranian Stuckist, Remodernist and anti-anti-art group of painters founded in 2007 in Tehran, which is a major protagonist of Asian Stuckism. In April 2010 they curated the first Stuckist exhibition in Iran, "Tehran Stuckists: Searching for the Unlimited Potentials of Figurative Painting", at Iran Artists Forum, Mirmiran Gallery. Their second exhibition, "International Stuckists: Painters Out of Order", including paintings by Stuckists from Iran, Britain, USA, Spain, South Africa, Pakistan and Turkey was held at Day Gallery in November 2013. Although one of the main aspects of Stuckism movement is that "the Stuckist allows him/herself uncensored expression", but "The Tehran Stuckists"' exhibitions in Iran are censored and they are not allowed to exhibit some of their artworks in Iranian galleries. The group has also participated in Stuckist exhibitions in Britain, Lithuania and Spain.
Other Asian Stuckists are Shelley Li (China), Smeetha Boumik (India), Joko Apridinoto (Indonesia), Elio Yuri Figini (Japan) and Fady Chamaa (Lebanon).
Europe.
Despite Stuckists in UK, "The Prague Stuckists", founded in 2005 in Czech by Robert Janás, is a flourishing Stuckist group. Other Stuckist artists in Europe include Peter Klint (Germany), Michael Dickinson (Turkey), Odysseus Yakoumakis (Greece), Artista Eli (Spain), Kloot Per W (Belgium), Jaroslav Valecka (Czech), Marketa Koreckova (Czech), Jan Macko (Slovakia) and Pavel Lefterov (Bulgaria).
Oceania.
In October 2000, Regan Tamanui founded "The Melbourne Stuckists" in Melbourne, the fourth Stuckist group to be started and the first one outside the UK. On 27 October 2000, he staged the "Real Turner Prize Show" at the Dead End Gallery in his home, concurrent with three shows with the same title in England (London, Falmouth and Dartington) and one in Germany in protest against the Tate Gallery's Turner Prize. Other Australian Stuckists include Godfrey Blow, who exhibited in "The Stuckists Punk Victorian". In 2005 Mike Mayhew also founded "The Christchurch Stuckists" in New Zealand.
Ex Stuckists.
Co-founder, Billy Childish left the group in 2001, but has stated that he remains committed to its principles. Sexton Ming left to concentrate on a solo career with the Aquarium Gallery. Wolf Howard left in 2006, but has exhibited with the group since. Jesse Richards who ran the Stuckism Centre USA in New Haven, left the group in 2006 to focus on Remodernist film.
In June 2000, Stella Vine went to a talk given by Childish and Thomson on Stuckism and Remodernism in London. At the end of May 2001, she exhibited some of her paintings publicly for the first time in the "Vote Stuckist" show in Brixton, and formed The Westminster Stuckists group. On 4 June, she took part in a Stuckist demonstration in Trafalgar Square. By 10 July, she renamed her group The Unstuckists. In mid-August, Thomson and Vine were married. A work by her was shown in the Stuckist show in Paris, which ended in mid-November, by which time she had rejected the Stuckists, and the marriage had ended.
In February 2004, Charles Saatchi bought a painting of Diana, Princess of Wales by Vine and was credited with "discovering" her. Thomson said it was the Stuckists and not Saatchi who had discovered her. At the end of March 2004, Thomson made a formal complaint about Saatchi to the Office of Fair Trading, claiming that Saatchi's leading position was monopolistic "to the detriment of smaller competitors", citing Vine as an example of this. On 15 April, the OFT closed the file on the case on the basis that Saatchi was not "in a dominant position in any relevant market."
Responses.
In 1999, two performance artists, Yuan Chai and Jian Jun Xi, jumped on Tracey Emin's installation "My Bed", a work consisting of the artist's own unmade bed, at the Tate Gallery's Turner Prize, in an unauthorised art intervention. Chai had written, among other things, the words "Anti Stuckism" on his bare back. Fiachra Gibbons of "The Guardian" wrote (in 1999) that the event "will go down in art history as the defining moment of the new and previously unheard of Anti-Stuckist Movement." Writing in "The Guardian" ten years later, Jonathan Jones described the Stuckists as "enemies of art", and what they say as "cheap slogans" and "hysterical rants".
The artist Max Podstolski wrote that the art world needed a new manifesto, as confrontational as that of Futurism or Dadaism, "written with a heart-felt passion capable of inspiring and rallying art world outsiders, dissenters, rebels, the neglected and disaffected", and suggests that "Well now we've got it, in the form of Stuckism".
New York art gallery owner Edward Winkleman wrote in 2006 that he had never heard of the Stuckists, so he "looked them up on Wikipedia", and stated he was "turned off by their anti-conceptual stance, not to mention the inanity of their statement about painting, but I'm more than a bit interested in the democratization their movement represents." Thomson responded to Winkleman directly.
Also in 2006, Colin Gleadell, writing in "The Telegraph", noted that the Stuckist's first exhibition in central London had brought "multiple sales" for leading artists of the movement, and that this raised the question of how good they were at painting. He observed that "Whatever the critics may say, buyers from the UK, the US and Japan have already taken a punt. Six of Thomson's paintings have sold for between £4,000 and £5,000 each. Joe Machine, a former jailbird who paints for therapeutic reasons, has also sold six paintings for the same price."
The BBC arts correspondent Lawrence Pollard wrote in 2009 that the way was paved for "cultural agitators" like the Stuckists, as well as the Vorticists, Surrealists and others, by the Futurist Manifesto of 20 February 1909.
Gallery.
Some UK artists.

</doc>
<doc id="58041" url="https://en.wikipedia.org/wiki?curid=58041" title="Bromeliaceae">
Bromeliaceae

The Bromeliaceae (the bromeliads) are a family of monocot flowering plants of around 3,170 species native mainly to the tropical Americas, with a few species found in the American subtropics and one in tropical west Africa, "Pitcairnia feliciana".
They are among the basal families within the Poales and are unique because they are the only family within the order that has septal nectaries and inferior ovaries. These inferior ovaries characterize the Bromelioideae, a subfamily of the Bromeliaceae. The family includes both epiphytes, such as Spanish moss ("Tillandsia usneoides"), and terrestrial species, such as the pineapple ("Ananas comosus"). Many bromeliads are able to store water in a structure formed by their tightly-overlapping leaf bases. However, the family is diverse enough to include the tank bromeliads, grey-leaved epiphyte "Tillandsia" species that gather water only from leaf structures called trichomes, and a large number of desert-dwelling succulents.
The largest bromeliad is "Puya raimondii", which reaches 3–4 m tall in vegetative growth with a flower spike 9–10 m tall, and the smallest is Spanish moss.
Description.
Bromeliads are plants that are adapted to various climates. Foliage takes different shapes, from needle-thin to broad and flat, symmetrical to irregular, spiky to soft. The foliage, which usually grows in a rosette, is widely patterned and colored. Leaf colors range from maroon, through shades of green, to gold. Varieties may have leaves with red, yellow, white and cream variations. Others may be spotted with purple, red, or cream, while others have different colors on the tops and bottoms of the leaves.
The inflorescences produced by bromeliads are also regarded as considerably more diverse than any other plant family. Some flower spikes may reach 10 meters tall, while others only measure 2–3 mm across. Upright stalks may be branched or simple with spikes retaining their color from two weeks up to 12 months, depending on species. In some species, the flower remains unseen, growing deep in the base of the plants.
Root systems vary according to plant type. Terrestrial bromeliad species have complex root systems that gather water and nutrients, while epiphytic bromeliads only grow hard, wiry roots to attach themselves to trees and rocks.
Some bromeliads are faintly scented, while others are heavily perfumed. Blooms from the species "Tillandsia cyanea" have a fragrance resembling that of clove spice.
One study found 175,000 bromeliads per hectare (2.5 acres) in one forest; that many bromeliads can sequester 50,000 liters (more than 13,000 gallons) of water.
A wide variety of organisms takes advantage of the pools of water trapped by bromeliads. A study of 209 plants from the Ecuadorian lowlands identified 11,219 animals, representing more than 300 distinct species, many of which are found only on bromeliads. Examples include some species of ostracods, small salamanders about in length, and tree frogs. Jamaican bromeliads are home to "Metopaulias depressus", a reddish-brown crab across, which has evolved social behavior to protect its young from predation by "Diceratobasis macrogaster", a species of damselfly whose larvae live in bromeliads. Some bromeliads even form homes for other species of bromeliads.
Distribution.
Plants in the Bromeliaceae are widely represented in their natural climates across the Americas. One species can be found in Africa. They can be found at altitudes from sea level to 4200 meters, from rainforests to deserts. Approximately half the species are epiphytes, some are lithophytes, and some are terrestrial. Accordingly, these plants can be found in the Andean highlands, from northern Chile to Colombia, in the Sechura Desert of coastal Peru, in the cloud forests of Central and South America, in southern United States from southern Virginia to Florida to Texas, and in far southern Arizona.
Ecology.
Bromeliads often serve as phytotelmata, accumulating water between their leaves. The aquatic habitat created as a result is host to a diverse array of invertebrates, especially aquatic insect larvae. These bromeliad invertebrates benefit their hosts by increasing nitrogen uptake into the plant.
Evolution.
Bromeliads are among the more recent plant groups to have emerged. The greatest number of primitive species resides in the Andean highlands of South America, where they originated in the tepuis of the Guyana Shield. The most basal genus, "Brocchinia", is endemic to these tepuis, and is placed as the sister group to the remaining genera in the family. The west African species "Pitcairnia feliciana" is the only bromeliad not endemic to the Americas, and is thought to have reached Africa via long-distance dispersal about 12 million years ago.
Adaptations.
Bromeliads are able to live in a vast array of environmental conditions due to their many adaptations. Trichomes, in the form of scales or hairs, allow bromeliads to capture water in cloud forests and help to reflect sunlight in desert environments. Some bromeliads have also developed an adaptation known as the tank habit, which involves them forming a tightly bound structure with their leaves that helps to capture water and nutrients in the absence of a well-developed root system. Bromeliads also use crassulacean acid metabolism (CAM) photosynthesis to create sugars. This adaptation allows bromeliads in hot or dry climates to open their stomates at night rather than during the day, which reduces water loss.
Classification.
The family Bromeliaceae is currently placed in the order Poales. 
Subfamilies.
The family Bromeliaceae is organized into eight subfamilies:
Bromeliaceae were originally split into three subfamilies: Bromelioideae, Tillandsioideae, and Pitcairnioideae based on morphological characters. However, molecular evidence has revealed that while Bromelioideae and Tillandsioideae are monophyletic, Pitcairnioideae is, in fact, paraphyletic and should be split into six subfamilies: Brocchinioideae, Lindamanioideae, Hechtioideae, Navioideae, Pitcairnioideae, and Puyoideae.
Brocchinioideae is defined as the most basal branch of Bromeliaceae based on both morphological and molecular evidence, namely genes in chloroplast DNA.
Lindmanioideae is the next most basal branch distinguished from the other subfamilies by convolute sepals and chloroplast DNA.
Hechtioideae is also defined based on analyses of chloroplast DNA; similar morphological adaptations to arid environments also found in other groups are attributed to convergent evolution.
Navioideae is split from Pitcairnioideae based on its cochlear sepals and chloroplast DNA.
Puyoideae has been re-classified multiple times and its monophyly remains controversial according to analyses of chloroplast DNA.
Cultivation and uses.
Humans have been using bromeliads for thousands of years. The Incas, Aztecs, Maya and others used them for food, protection, fiber and ceremony, just as they are still used today. European interest began when Spanish conquistadors returned with pineapple, which became so popular as an exotic food that the image of the pineapple was adapted into European art and sculpture. In 1776, the species "Guzmania lingulata" was introduced to Europe, causing a sensation among gardeners unfamiliar with such a plant. In 1828, "Aechmea fasciata" was brought to Europe, followed by "Vriesea splendens" in 1840. These transplants were so successful, they are still among the most widely grown bromeliad varieties.
In the 19th century, breeders in Belgium, France and the Netherlands started hybridizing plants for wholesale trade. Many exotic varieties were produced until World War I, which halted breeding programs and led to the loss of some species. The plants experienced a resurgence of popularity after World War II. Since then, Dutch, Belgian and North American nurseries have greatly expanded bromeliad production.
Only one bromeliad, the pineapple ("Ananas comosus"), is a commercially important food crop. Bromelain, a common ingredient in meat tenderizer, is extracted from pineapple stems. Many other bromeliads are popular ornamental plants, grown as both garden and houseplants.
Collectors.
Édouard André was a French collector/explorer whose many discoveries of bromeliads in the Cordilleras of South America would be influential on horticulturists to follow. He served as a source of inspiration to 20th-century collectors, in particular Mulford B. Foster and Lyman Smith of the United States and Werner Rauh of Germany and Michelle Sullivan of Australia.

</doc>
<doc id="58043" url="https://en.wikipedia.org/wiki?curid=58043" title="Chinese sovereign">
Chinese sovereign

Chinese sovereign is the ruler of a particular period in ancient China. Several titles and naming schemes have been used throughout history.
Imperial titles.
Emperor.
The characters "Huang" (皇 huáng "god-king") and "Di" (帝 dì "sage king") had been used separately and never consecutively (see Three August Ones and Five Emperors). The character was reserved for mythological rulers until the first emperor of Qin (Qin Shi Huang), who created a new title "Huangdi" (皇帝 in pinyin: huáng dì) for himself in 221 BCE, which is commonly translated as "Emperor" in English. This title continued in use until the fall of the Qing dynasty in 1911.
From the Han Dynasty, the title "Huangdi" could also be abbreviated to "huang" or "di". The former nobility titles "Qing" (卿), "Daifu" (大夫) and "Shi" (仕) became synonyms for court officials.
The power of the emperor varied between emperors and dynasties, with some emperors being absolute rulers and others being figureheads with actual power lying in the hands of court factions, eunuchs, the bureaucracy or noble families. In principle, the title of emperor was transmitted from father to son via primogeniture, as endorsed by Confucianism. However, there are many exceptions to this rule. For example, because the Emperor usually had many concubines, the first born of the queen (i.e. the wife) is usually the heir apparent. However, Emperors could elevate another more favoured child or the child of a favourite concubine to the status of Crown Prince. Disputes over succession occurred regularly and have led to a number of civil wars. In the Qing dynasty, primogeniture was abandoned altogether, with the designated heir kept secret until after the Emperor's death.
Of the San Huang Wu Di, the three first of them were called 皇 (huang, "god-king") and the five last were called 帝 (di, "sage-king"), which can translate as either emperor, demigod human, or a superhuman. This title may have been used in the Shang and Xia dynasties, though oracle bones were found from the Shang Dynasty showing the title 王 (wáng, "king").
King.
The king (王, "wáng") was the Chinese head of state during the Zhou Dynasty. Its use during the Xia and Shang is uncertain but possible: the character has been found upon oracle bones. It was abolished under the Qin and, after that, the same term was used for (and translated as) royal princes. The title was commonly given to members of the Emperor's family and could be inherited. A poem from about 2,500 years ago said "普天之下,莫非王土.率土之賓,莫非王臣" which roughly translates as "Under the sky, nothing isn't the king's land; the people who lead the lands, no one isn't the king's subjects."
Son of Heaven.
The Son of Heaven was a title of the Emperor based on the Mandate of Heaven. The Son of Heaven is a universal emperor who rules tianxia comprising "all under heaven". The title was not interpreted literally. The monarch is a mortal chosen by Heaven, not its actual descendant. The title comes from the Mandate of Heaven, created by the monarchs of the Zhou dynasty to justify deposing the Shang dynasty. They declared that Heaven had revoked the mandate from the Shang and given it to the Zhou in retaliation for their corruption and misrule. Heaven bestowed the mandate to whoever was best fit to rule. The title held the emperor responsible for the prosperity and security of his people through the threat of losing the mandate.
Unlike the Japanese emperor for example, Chinese political theory allowed for a change of dynasty as imperial families could be replaced. This is based on the concept of "Mandate of Heaven". The theory behind this was that the Chinese emperor acted as the "Son of Heaven". As the only legitimate ruler, his authority extended to "All under heaven" and had neighbors only in a geographical sense. He holds a mandate to which he had a valid claim to rule over (or to lead) everyone else in the world as long as he served the people well. If the ruler became immoral, then rebellion is justified and heaven would take away that mandate and give it to another. This single most important concept legitimized the dynastic cycle or the change of dynasties regardless of social or ethnic background. This principle made it possible for dynasties founded by non-noble families such as Han Dynasty and Ming Dynasty or non-ethnic Han dynasties such as the Mongol-led Yuan Dynasty and Manchu-led Qing Dynasty. It was moral integrity and benevolent leadership that determined the holder of the "Mandate of Heaven." Every dynasty that self-consciously adopted this administrative practice powerfully reinforced this Sinocentric concept throughout the history of imperial China. Historians noted that this was one of the key reasons why imperial China in many ways had the most efficient system of government in ancient times.
Finally, it was generally not possible for a woman to succeed to the throne and in the history of China there has only been one reigning Empress, Wu Zetian (624–705 CE) who usurped power under the Tang dynasty.
How to read the titles of a Chinese sovereign.
All sovereigns are denoted by a string of Chinese characters. 
Examples:
The first character(s) are the name of the dynasty or kingdom.
e.g. Hàn, Táng, Wèi and Hòu Hàn.
Then come the characters of how the sovereign is commonly called, in most cases the posthumous names or the temple names.
e.g. Gāo Zǔ, Tài Zōng, Wǔ Dì, Guāng Wǔ Dì.
Then follow the characters of their family and given names.
e.g. "Liú Bāng", "Lǐ Shì Mín", "Cáo Cāo", "Liú Zhī Yuǎn" and "Liú Xiù".
In contemporary historical texts, the string including the name of dynasty and temple or posthumous names is sufficient enough as a clear reference to a particular sovereign.
e.g. Hàn Gāo Zǔ
Note that Wèi Wǔ Dì "Cáo Cāo" was never a sovereign in his own right but his son was. Thus his imperial style of Wǔ Dì was added only after his son had ascended to the throne. Such cases were common in Chinese history, i.e., the first emperor of a new dynasty often accorded posthumous imperial titles to his father or sometimes even further paternal ancestors.
Tang Dynasty naming conventions.
All sovereigns starting from the Tang Dynasty are contemporarily referred to using the temple names. They also had posthumous names that were less used, except in traditional historical texts. The situation was reversed before Tang as posthumous names were contemporarily used. 
e.g. The posthumous name of Táng Tài Zōng "Lǐ Shì Mín" was Wén Dì (文帝)
If sovereigns since Tang were referenced using posthumous names, they were the last ones of their sovereignties or their reigns were short and unpopular.
e.g. Táng Āi Dì "Lǐ Zhù" (唐哀帝 "李柷"), also known as Táng Zhāo Xuān Dì (唐昭宣帝), was last emperor of the Tang Dynasty reigning from 904 to 907.
Hàn Guāng Wǔ Dì is equivalent to Dōng Hàn Guāng Wǔ Dì since he was the founder of the Eastern (dōng) Han Dynasty. All dōng (east)-xī (west), nán (south)-běi (north), qián (former)-hòu (later) conventions were invented only by past or present historiographers for denoting a new era of a dynasty. They were never used during that era.
Self-made titles.
Xiang Yu styled himself, Xīchǔ Bàwáng (“西楚霸王,” lit. Hegemon-King of Western Chu).
Foreign titles taken by Chinese rulers.
Emperor Taizong of Tang was crowned Tian Kehan 天可汗, or "heavenly Khagan", after defeating the Gokturks, (Tujue).
Common naming conventions.
Here is a quick guide of the most common style of reference (but not a thorough explanation) in contemporary use. Using an emperor's different titles or styles is nevertheless considered correct but not as common.

</doc>
<doc id="58045" url="https://en.wikipedia.org/wiki?curid=58045" title="LL parser">
LL parser

In computer science, an LL parser is a top-down parser for a subset of context-free languages. It parses the input from Left to right, performing Leftmost derivation of the sentence.
An LL parser is called an LL("k") parser if it uses "k" tokens of lookahead when parsing a sentence. If such a parser exists for a certain grammar and it can parse sentences of this grammar without backtracking then it is called an LL("k") grammar. LL("k") grammars can generate more languages the higher the number "k" of lookahead tokens. A corollary of this is that not all context-free languages can be recognized by an LL(k) parser. An LL parser is called an LL("*") parser (an LL-regular parser) if it is not restricted to a finite "k" tokens of lookahead, but can make parsing decisions by recognizing whether the following tokens belong to a regular language (for example by means of a Deterministic Finite Automaton).
LL grammars, particularly LL(1) grammars, are of great practical interest, as parsers for these grammars are easy to construct, and many computer languages are designed to be LL(1) for this reason. LL parsers are table-based parsers, similar to LR parsers. LL grammars can also be parsed by recursive descent parsers.
Overview.
For a given context-free grammar, the parser attempts to find the leftmost derivation.
Given an example grammar formula_1:
the leftmost derivation for formula_5 is:
Generally, there are multiple possibilities when selecting a rule to expand given (leftmost) non-terminal. In the previous example of the leftmost derivation, in step 2:
We can choose from two rules:
To be effective, the parser must be able to make this choice deterministically when possible, without backtracking. For some grammars, it can do this by peeking on the unread input (without reading). In our example, if the parser knows that the next unread symbol is formula_8 , the only correct rule that can be used is 2.
Generally, formula_9 parser can look ahead at formula_10 symbols. However, given a grammar, the problem of determining if there exists a formula_9 parser for some formula_10 that recognizes it is undecidable. For each formula_10, there is a language that cannot be recognized by formula_9 parser, but can be by formula_15.
We can use the above analysis to give the following formal definition:
Let formula_1 be a context-free grammar and formula_17. We say that formula_1 is formula_9, if and only if for any two leftmost derivations:
Following condition holds: Prefix of the string formula_22 of length formula_10 equals the prefix of the formula_24 of length formula_10 implies formula_26.
In this definition, formula_27 is the starting and formula_28 any non-terminal. The already derived input formula_29, and yet unread formula_22 and formula_31 are strings of terminals. The Greek letters formula_32, formula_33 and formula_34 represent any string of both terminals and non-terminals (possibly empty). The prefix length corresponds to the lookahead buffer size, and the definition says that this buffer is enough to distinguish between any two derivations of different words.
Parser.
The formula_9 parser is a deterministic pushdown automaton with the ability to peek on the next formula_10 input symbols without reading. This capability can be emulated by storing the lookahead buffer contents in the finite state space, since both buffer and input alphabet are finite in size. As a result, this does not make the automaton more powerful, but is a convenient abstraction.
The stack alphabet formula_37, where:
The parser stack initially contains the starting symbol above the EOI: formula_41. During operation, the parser repeatedly replaces the symbol formula_42 on top of the stack:
If the last symbol to be removed from the stack is the EOI, the parsing is successful; the automaton accepts via an empty stack.
The states and the transition function are not explicitly given; they are specified (generated) using a more convenient "parse table" instead. The table provides the following mapping:
If the parser cannot perform a valid transition, the input is rejected (empty cells). To make the table more compact, only the non-terminal rows are commonly displayed, since the action is the same for terminals.
Concrete example.
Set up.
To explain an LL(1) parser's workings we will consider the following small LL(1) grammar:
and parse the following input:
We construct a parsing table for this grammar by expanding all the terminals by column and all nonterminals by row. Later, the expressions are numbered by the position where the columns and rows cross. For example, the terminal '(' and non-terminal 'S' match for expression number 2. The table is as follows:
Parsing procedure.
In each step, the parser reads the next-available symbol from the input stream, and the top-most symbol from the stack. If the input symbol and the stack-top symbol match, the parser discards them both, leaving only the unmatched symbols in the input stream and on the stack.
Thus, in its first step, the parser reads the input symbol '(' and the stack-top symbol 'S'. The parsing table instruction comes from the column headed by the input symbol '(' and the row headed by the stack-top symbol 'S'; this cell contains '2', which instructs the parser to apply rule (2). The parser has to rewrite 'S' to '( S + F )' on the stack by removing 'S' from stack and pushing '(', 'S', '+', 'F', ')' onto the stack and this writes the rule number 2 to the output. The stack then becomes:
Since the '(' from the input stream did not match the top-most symbol, 'S', from the stack, it was not removed, and remains the next-available input symbol for the following step.
In the second step, the parser removes the '(' from its input stream and from its stack, since they now match. The stack now becomes:
Now the parser has an 'a' on its input stream and an 'S' as its stack top. The parsing table instructs it to apply rule (1) from the grammar and write the rule number 1 to the output stream. The stack becomes:
The parser now has an 'a' on its input stream and an 'F' as its stack top. The parsing table instructs it to apply rule (3) from the grammar and write the rule number 3 to the output stream. The stack becomes:
In the next two steps the parser reads the 'a' and '+' from the input stream and, since they match the next two items on the stack, also removes them from the stack. This results in:
In the next three steps the parser will replace 'F' on the stack by 'a', write the rule number 3 to the output stream and remove the 'a' and ')' from both the stack and the input stream. The parser thus ends with '$' on both its stack and its input stream.
In this case the parser will report that it has accepted the input string and write the following list of rule numbers to the output stream:
This is indeed a list of rules for a leftmost derivation of the input string, which is:
Parser implementation in C++.
Below follows a C++ implementation of a table-based LL parser for the example language:
Remarks.
As can be seen from the example, the parser performs three types of steps depending on whether the top of the stack is a nonterminal, a terminal or the special symbol $:
These steps are repeated until the parser stops, and then it will have either completely parsed the input and written a leftmost derivation to the output stream or it will have reported an error.
Constructing an LL(1) parsing table.
In order to fill the parsing table, we have to establish what grammar rule the parser should choose if it sees a nonterminal "A" on the top of its stack and a symbol "a" on its input stream. 
It is easy to see that such a rule should be of the form "A" → "w" and that the language corresponding to "w" should have at least one string starting with "a". 
For this purpose we define the "First-set" of "w", written here as Fi("w"), as the set of terminals that can be found at the start of some string in "w", plus ε if the empty string also belongs to "w". 
Given a grammar with the rules "A"1 → "w"1, ..., "A""n" → "w""n", we can compute the Fi("w""i") and Fi("A""i") for every rule as follows:
Unfortunately, the First-sets are not sufficient to compute the parsing table. 
This is because a right-hand side "w" of a rule might ultimately be rewritten to the empty string. 
So the parser should also use the rule "A" → "w" if ε is in Fi("w") and it sees on the input stream a symbol that could follow "A". Therefore, we also need the "Follow-set" of "A", written as Fo("A") here, which is defined as the set of terminals "a" such that there is a string of symbols "αAaβ" that can be derived from the start symbol. We use $ as a special terminal indicating end of input stream and "S" as start symbol.
Computing the Follow-sets for the nonterminals in a grammar can be done as follows:
Now we can define exactly which rules will be contained where in the parsing table. 
If "T"["A", "a"] denotes the entry in the table for nonterminal "A" and terminal "a", then
If the table contains at most one rule in every one of its cells, then the parser will always know which rule it has to use and can therefore parse strings without backtracking. 
It is in precisely this case that the grammar is called an "LL(1) grammar".
Constructing an LL("k") parsing table.
Until the mid-1990s, it was widely believed that LL("k") parsing (for "k" > 1) was impractical, since the parser table would have exponential size in "k" in the worst case. This perception changed gradually after the release of the Purdue Compiler Construction Tool Set around 1992, when it was demonstrated that many programming languages can be parsed efficiently by an LL("k") parser without triggering the worst-case behavior of the parser. Moreover, in certain cases LL parsing is feasible even with unlimited lookahead. By contrast, traditional parser generators like yacc use LALR(1) parser tables to construct a restricted LR parser with a fixed one-token lookahead.
Conflicts.
As described in the introduction, LL(1) parsers recognize languages that have LL(1) grammars, which are a special case of context-free grammars (CFGs); LL(1) parsers cannot recognize all context-free languages. The LL(1) languages are a proper subset of the LR(1) languages which in turn are a proper subset of all context-free languages. In order for a CFG to be an LL(1) grammar, certain conflicts must not arise, which we describe in this section.
Terminology.
Let A be a non-terminal. FIRST(A) is (defined to be) the set of terminals that can appear in the first position of any string derived from A. FOLLOW(A) is the union over FIRST(B) where B is any non-terminal that immediately follows A in the right hand side of a production rule.
LL(1) Conflicts.
There are 2 main types of LL(1) conflicts:
FIRST/FIRST Conflict.
The FIRST sets of two different grammar rules for the same non-terminal intersect.
An example of an LL(1) FIRST/FIRST conflict:
FIRST(E) = {'b', ε} and FIRST(E 'a') = {'b', 'a'}, so when the table is drawn, there is conflict under terminal 'b' of production rule S.
Special Case: Left Recursion.
Left recursion will cause a FIRST/FIRST conflict with all alternatives.
FIRST/FOLLOW Conflict.
The FIRST and FOLLOW set of a grammar rule overlap. With an empty string (ε) in the FIRST set it is unknown which alternative to select.
An example of an LL(1) conflict:
The FIRST set of A now is {'a', ε} and the FOLLOW set {'a'}.
Solutions to LL(1) Conflicts.
Left Factoring.
For a general method, see removing left recursion.
A common left-factor is "factored out".
becomes
Can be applied when two alternatives start with the same symbol like a FIRST/FIRST conflict.
Another example (more complex) using above FIRST/FIRST conflict example:
becomes (merging into a single non-terminal)
then through left-factoring, becomes
Substitution.
Substituting a rule into another rule to remove indirect or FIRST/FOLLOW conflicts.
Note that this may cause a FIRST/FIRST conflict.
Left recursion removal.
A simple example for left recursion removal:
The following production rule has left recursion on E
This rule is nothing but list of Ts separated by '+'. In a regular expression form T ('+' T)*.
So the rule could be rewritten as 
Now there is no left recursion and no conflicts on either of the rules.
However, not all CFGs have an equivalent LL(k)-grammar, e.g.:
It can be shown that there does not exist any LL(k)-grammar accepting the language generated by this grammar.

</doc>
<doc id="58046" url="https://en.wikipedia.org/wiki?curid=58046" title="Figure-eight knot">
Figure-eight knot

The figure-eight knot or figure-of-eight knot is a type of stopper knot. It is very important in both sailing and rock climbing as a method of stopping ropes from running out of retaining devices. Like the overhand knot, which will jam under strain, often requiring the rope to be cut, the figure-of-eight will also jam, but is usually more easily undone than the overhand knot.
Different types of figure-eight knots.
Figure-eight loop.
The figure-eight loop is used like an overhand loop knot. This type of knot can be used in prusik climbing when used in conjunction with a climbing harness, a climbing rope, and locking carabiner designed for climbing, to ascend or descend with minimal equipment and effort.
Figure-eight bend.
The figure-eight bend knot is used to "splice" together two ropes, not necessarily of equal diameter. This knot is tied starting with a loose figure-eight knot on one rope (the larger-diameter one if unequal), and threading of the other rope's running end through the first figure eight, starting at the first figure-eight's running end and paralleling the path of the first rope through the figure eight until the second's ropes running end lies parallel against first's standing end. The result is two figure-eight knots, each partly inside the other and tightening its hold on the other when they are pulled in opposite directions. This can be a permanent or temporary splice. While it precludes the ropes' slipping relative to each other, it is a typical knot in having less strength than the straight ropes.
In heraldry, this knot is known as Savoy knot.
Offset figure-eight bend.
The offset figure-eight bend is a poor knot that has been implicated in the deaths of several rock climbers.
Stein knot.
The stein knot (aka stone knot) is a variation of the figure-eight knot. It is used to secure a rope that is already passed around a post or through a ring. It is quick and easy to tie and untie. It is a device rigging rather than a true knot.
In canyoneering, it is used to isolate rope strands to allow one person to rappel while another is getting on the rappel, or allow rappellers the option of using a single or a double rope.
It is also used to make baskets.

</doc>
<doc id="58055" url="https://en.wikipedia.org/wiki?curid=58055" title="Bering Sea">
Bering Sea

The Bering Sea is a marginal sea of the Pacific Ocean. It comprises a deep water basin, which then rises through a narrow slope into the shallower water above the continental shelves.
The Bering Sea is separated from the Gulf of Alaska by the Alaska Peninsula. It covers over and is bordered on the east and northeast by Alaska, on the west by Russian Far East and Kamchatka Peninsula, on the south by the Alaska Peninsula and the Aleutian Islands and on the far north by the Bering Strait, which connects the Bering Sea to the Arctic Ocean's Chukchi Sea. Bristol Bay is the portion of the Bering Sea which separates the Alaska Peninsula from mainland Alaska. The Bering Sea is named for Vitus Bering, a Danish navigator in Russian service, who in 1728 was the first European to systematically explore it, sailing from the Pacific Ocean northward to the Arctic Ocean.
The Bering Sea ecosystem includes resources within the jurisdiction of the United States and Russia, as well as international waters in the middle of the sea (known as the "Donut Hole"). The interaction between currents, sea ice, and weather makes for a vigorous and productive ecosystem.
History.
Most scientists believe that during the most recent ice age, sea level was low enough to allow humans and other animals to migrate on foot from Asia to North America across what is now the Bering Strait. This is commonly referred to as the "Bering land bridge" and is believed by some—though not all— to be the first point of entry of humans into the Americas.
There is a small portion of the Kula Plate in the Bering Sea. The Kula Plate is an ancient tectonic plate that used to subduct under Alaska during the Triassic period.
Geography.
Extent.
The International Hydrographic Organization defines the limits of the Bering Sea as follows:
Islands.
Islands of the Bering Sea include:
Regions.
Regions of the Bering Sea include:
The Bering Sea contains 16 submarine canyons including the largest submarine canyon in the world, Zhemchug Canyon.
Ecosystem.
The Bering Sea shelf break is the dominant driver of primary productivity in the Bering Sea. This zone, where the shallower continental shelf drops off into the North Aleutians Basin is also known as the “Greenbelt”. Nutrient upwelling from the cold waters of the Aleutian basin flowing up the slope and mixing with shallower waters of the shelf provide for constant production of phytoplankton.
The second driver of productivity in the Bering Sea is seasonal sea ice that, in part, triggers the spring phytoplankton bloom. Seasonal melting of sea ice causes an influx of lower salinity water into the middle and other shelf areas, causing stratification and hydrographic effects which influence productivity. In addition to the hydrographic and productivity influence of melting sea ice, the ice itself also provides an attachment substrate for the growth of algae as well as interstitial ice algae.
Some evidence suggests that great changes to the Bering Sea ecosystem have already occurred. Warm water conditions in the summer of 1997 resulted in a massive bloom of low energy coccolithophorid phytoplankton (Stockwell et al. 2001). A long record of carbon isotopes, which is reflective of primary production trends of the Bering Sea, exists from historical samples of bowhead whale baleen. Trends in carbon isotope ratios in whale baleen samples suggest that a 30–40% decline in average seasonal primary productivity has occurred over the last 50 years. The implication is that the carrying capacity of the Bering Sea is much lower now than it has been in the past.
Biodiversity.
The sea supports many endangered whale species including bowhead whale, blue whale, fin whale, sei whale, humpback whale, sperm whale and the rarest in the world, the North Pacific right whale. Other marine mammals include walrus, Steller sea lion, northern fur seal, beluga, orca and polar bear.
The Bering Sea is very important to the seabirds of the world. Over 30 species of seabirds and approximately 20 million individuals breed in the Bering Sea region. Seabird species include tufted puffins, the endangered short-tailed albatross, spectacled eider, and red-legged kittiwakes. Many of these species are unique to the area, which provides highly productive foraging habitat, particularly along the shelf edge and in other nutrient-rich upwelling regions, such as the Pribilof, Zhemchug, and Pervenets canyons. The Bering Sea is also home to colonies of crested auklets, with upwards of a million individuals.
Two Bering Sea species, the Steller's sea cow ("Hydrodamalis gigas") and spectacled cormorant ("Phalacrocorax perspicillatus"), are extinct because of overexploitation by man. In addition, a small subspecies of Canada goose, the Bering Canada goose ("Branta canadensis asiatica") is extinct due to overhunting and introduction of rats to their breeding islands.
The Bering Sea supports many species of fish. Some species of fish support large and valuable commercial fisheries. Commercial fish species include 6 species of Pacific salmon, Alaska pollock, red king crab, "Chionoecetes", Pacific cod, Pacific halibut, yellowfin sole, Pacific ocean perch and sablefish.
Fish biodiversity is high, and at least 419 species of fish have been reported from the Bering Sea.
Fisheries.
The Bering Sea is world-renowned for its enormously productive and profitable fisheries, such as king crab, opilio and tanner crabs, Bristol Bay salmon, pollock and other groundfish. These fisheries rely on the productivity of the Bering Sea via a complicated and little understood food web. The continued existence of these fisheries requires an intact, healthy, and productive ecosystem.
Commercial fishing is big business in the Bering Sea, which is relied upon by the largest seafood companies in the world to produce fish and shellfish. On the U.S. side, commercial fisheries catch approximately $1 billion worth of seafood annually, while Russian Bering Sea fisheries are worth approximately $600 million annually.
The Bering Sea also serves as the central location of the Alaskan king crab and opilio crab seasons, which are chronicled on the Discovery Channel television program "Deadliest Catch". Landings from Alaskan waters represents half the U.S. catch of fish and shellfish.
Change.
Because of the changes going on in the Arctic, future evolution of the Bering Sea climate/ecosystem is uncertain. Between 1979 and 2012 the region experienced small growth in sea ice extent, standing in contrast to the substantial loss of summer sea ice in the Arctic Ocean to the north.
In media.
The movie Harbinger Down, which was released on August 7, 2015, was about a group of grad students have booked passage on the crabbing boat Harbinger to study the effects of global warming on a pod of beluga whales in the Bering Sea.
One of the central characters in the 1949 movie Down to the Sea in Ships has the given name "Bering" due to having been born in a ship crossing the Bering Sea.

</doc>
<doc id="58062" url="https://en.wikipedia.org/wiki?curid=58062" title="Marion County, Florida">
Marion County, Florida

Marion County is a county located in the U.S. state of Florida. As of the 2010 census, the population was 331,298. Its county seat is Ocala.
Marion County comprises the Ocala, FL Metropolitan Statistical Area.
History.
Marion County was created in 1844 from portions of Alachua, Mosquito (Orange), and Hillsborough counties. Until 1853, Marion County included most of what are now Lake and Sumter counties. In 1849, Putnam County was created and took the northeast portion of Marion. Levy County’s creation took some of the western portion of Marion in 1877. The county is named after General Francis Marion of South Carolina, a guerilla fighter and hero of the American Revolutionary War. A large share of the early settlers being natives of South Carolina likely caused the name to be selected. The Act creating the county of Marion of the Territory of Florida was signed on March 14, 1844, by the territorial governor, R. K. Call. Many of the early settlers of Marion County were from South Carolina. The county motto is "Kingdom of the Sun." Farms in the county are known for breeding champion race horses such as Affirmed and Needles.
Geography.
According to the U.S. Census Bureau, the county has a total area of , of which is land and (4.7%) is water.
Marion County is generally composed of rolling hills, some high and some low. The majority of its trees consist of live oaks, pine, and palm trees. Marion County is considered the southernmost county in North Central Florida, and the northernmost county in Central Florida.
It is about a two-hour drive from many of Florida's major cities, Orlando is 75 minutes to the southeast while Daytona Beach is about 90 minutes to the east. Tampa is about 75 minutes to the southwest. Jacksonville is roughly a two-hour drive northeast. Miami is about five hours to the southeast. Fort Lauderdale is about a four-hour drive from Marion County.
Marion County also has three large lakes at its opposite borders. Orange Lake is in the far northern part of Marion County, near the border with Alachua County. Lake Kerr is in the northeastern part of the county, near the town of Salt Springs, which is near the border with Putnam County. Lake Weir, the largest of the three, is in the far southern region near the border with Lake County. Part of Lake George is in Marion County also.
Marion County is inland, centered between the Atlantic Ocean to the east and the Gulf of Mexico to the west. Because of this, Marion County is not affected as much by hurricanes as the more coastal counties to its east and west are. It has however been impacted been major hurricanes within the historical record including ones that would produce tremendous damage if they were to happen again. The second greatest threat from tropical cyclones, both financial and in terms of life, is the threat created by fresh water flooding. Major winds above 100mph are possible from hurricanes in Marion County, anywhere in the county, but have not been recorded in modern times. However, tornadoes are a major threat to this region of the state. Although Marion County is not near either of Florida's coasts, it is situated slightly to the west. Therefore, it takes a little less than an hour to get to the Gulf of Mexico while it takes about half an hour longer to get to the Atlantic Ocean.
Demographics.
As of the census of 2000, there were 258,916 people, 106,755 households, and 74,621 families residing in the county. The population density was 164 people per square mile (63/km²). There were 122,663 housing units at an average density of 78 per square mile (30/km²). The racial makeup of the county was 84.16% White, 11.55% Black or African American, 0.45% Native American, 0.70% Asian, 0.02% Pacific Islander, 1.69% from other races, and 1.44% from two or more races. 6.03% of the population were Hispanic or Latino of any race.
According to the 2000 Census the largest European ancestry groups in Marion County were English (18.7%), German (16.7%) and Irish (14.0%).
There were 106,755 households out of which 24.70% had children under the age of 18 living with them, 55.60% were married couples living together, 10.70% had a female householder with no husband present, and 30.10% were non-families. 25.00% of all households were made up of individuals and 13.00% had someone living alone who was 65 years of age or older. The average household size was 2.36 and the average family size was 2.79.
In the county the population was spread out with 21.40% under the age of 18, 6.40% from 18 to 24, 23.80% from 25 to 44, 23.90% from 45 to 64, and 24.50% who were 65 years of age or older. The median age was 44 years. For every 100 females there were 93.30 males. For every 100 females age 18 and over, there were 89.90 males.
The median income for a household in the county was $31,944, and the median income for a family was $37,473. Males had a median income of $28,836 versus $21,855 for females. The per capita income for the county was $17,848. About 9.20% of families and 13.10% of the population were below the poverty line, including 20.20% of those under age 18 and 7.40% of those age 65 or over.
Government and infrastructure.
The Florida Department of Corrections operates facilities in unincorporated areas in the county, including the Lowell Correctional Institution and the Lowell Annex. The annex houses Florida's female death row.
Education.
County public education is supervised under the Marion County School District.
High schools.
Marion County Public Schools Homepage
Libraries.
The Marion County Public Library System has 8 branches. The library system also has two bookmobiles that have routes throughout the county on weekdays.
Headquarters – Ocala<br>
2720 E. Silver Springs Blvd. 
<br>Ocala, FL 34470
Belleview<br>
13145 SE Highway 484
<br>Belleview, FL 34420
Dunnellon<br>
20351 Robinson Road
<br>Dunnellon, FL 34431
Forest<br>
905 S. Highway 314A
<br>Ocklawaha, FL 32179
Freedom<br>
5870 SW 95th St.
<br>Ocala, FL 34476
Ft. McCoy<br>
14660 NE Highway 315
<br>Ft. McCoy, FL 32134
Marion Oaks<br>
294 Marion Oaks Lane
<br>Ocala, FL 34473
Reddick<br>
15150 NW Gainesville Road
<br>Reddick, FL 32686
Transportation.
Public surface transportation.
Local bus service is provided by SunTran.

</doc>
<doc id="58064" url="https://en.wikipedia.org/wiki?curid=58064" title="Mast">
Mast

Mast or MAST may refer to:

</doc>
<doc id="58067" url="https://en.wikipedia.org/wiki?curid=58067" title="W. C. Handy">
W. C. Handy

William Christopher Handy (November 16, 1873 – March 28, 1958) was an American blues composer and musician. He was widely known as the "Father of the Blues".
Handy remains among the most influential of American songwriters. Though he was one of many musicians who played the distinctively American form of music known as the blues, he is credited with giving it its contemporary form. While Handy was not the first to publish music in the blues form, he took the blues from a regional music style (Delta blues) with a limited audience to one of the dominant national forces in American music.
Handy was an educated musician who used folk material in his compositions. He was scrupulous in documenting the sources of his works, which frequently combined stylistic influences from several performers.
Early life.
Handy was born in Florence, Alabama, to parents Elizabeth Brewer, and Charles Barnard Handy. His father was the pastor of a small church in Guntersville, a small town in northeast central Alabama. Handy wrote in his 1941 autobiography, "Father of the Blues," that he was born in the log cabin built by his grandfather William Wise Handy, who became an African Methodist Episcopal (AME) minister after emancipation. The log cabin of Handy's birth has been saved and preserved near downtown Florence.
Growing up he apprenticed in carpentry, shoemaking and plastering.
Handy was a deeply religious man, whose influences in his musical style were found in the church music he sang and played as a youth, and in the natural world. He later cited the sounds of nature, such as "whippoorwills, bats and hoot owls and their outlandish noises", the sounds of Cypress Creek washing on the fringes of the woodland, and "the music of every songbird and all the symphonies of their unpremeditated art" as inspiration.
Handy's father believed that musical instruments were tools of the devil. Without his parents' permission, Handy bought his first guitar, which he had seen in a local shop window and secretly saved for by picking berries and nuts and making lye soap. Upon seeing the guitar, his father asked him, "What possessed you to bring a sinful thing like that into our Christian home?" Ordering Handy to "Take it back where it came from", his father quickly enrolled him in organ lessons. Handy's days as an organ student were short-lived, and he moved on to learn the cornet. Handy joined a local band as a teenager, but he kept this fact a secret from his parents. He purchased a cornet from a fellow band member and spent every free minute practicing it.
Musical development.
He worked on a "shovel brigade" at the McNabb furnace, and described the music made by the workers as they beat shovels, altering the tone while thrusting and withdrawing the metal part against the iron buggies to pass the time while waiting for the overfilled furnace to digest its ore. "With a dozen men participating, the effect was sometimes remarkable...It was better to us than the music of a martial drum corps, and our rhythms were far more complicated." He wrote, "Southern Negroes sang about everything...They accompany themselves on anything from which they can extract a musical sound or rhythmical effect..." He would later reflect that, "In this way, and from these materials, they set the mood for what we now call blues".
In September 1892, Handy travelled to Birmingham, Alabama, to take a teaching exam, which he passed easily, and gained a teaching job in the city. Learning that it paid poorly, he quit the position and found industrial work at a pipe works plant in nearby Bessemer.
During his off-time, he organized a small string orchestra and taught musicians how to read notes. Later, Handy organized the Lauzetta Quartet. When the group read about the upcoming World's Fair in Chicago, they decided to attend. To pay their way, group members performed at odd jobs along the way. They arrived in Chicago only to learn that the World's Fair had been postponed for a year. Next they headed to St. Louis, Missouri but found working conditions very bad.
After the quartet disbanded, Handy went to Evansville, Indiana. He played cornet in the Chicago World's Fair in 1893. In Evansville, Handy joined a successful band that performed throughout the neighboring cities and states. His musical endeavors were varied: he sang first tenor in a minstrel show, worked as a band director, choral director, cornetist and trumpeter.
At the age of 23, Handy became band master of Mahara's Colored Minstrels. In their three-year tour, they traveled to Chicago, throughout Texas and Oklahoma, through Tennessee, Georgia and Florida, and on to Cuba. Handy earned a salary of $6 per week. Returning from Cuba, the band traveled north through Alabama, and stopped to perform in Huntsville. Weary of life on the road, he and his wife Elizabeth decided to stay with relatives in his nearby hometown of Florence.
Marriage and family.
In 1896 while performing at a barbecue in Henderson, Kentucky, Handy met Elizabeth Price. They married shortly afterward on July 19, 1896. She had Lucille, the first of their six children, on June 29, 1900, after they had settled in Florence, Alabama, his hometown.
Teaching music.
Around that time, William Hooper Councill, President of Alabama Agricultural and Mechanical College for Negroes (AAMC) (today named Alabama Agricultural and Mechanical University) in Normal, Alabama, recruited Handy to teach music at the college. Handy became a faculty member in September 1900 and taught through much of 1902.
His enthusiasm for the distinctive style of uniquely American music, then often considered inferior to European classical music, was part of his development. He was disheartened to discover that the college emphasized teaching European music considered to be "classical". Handy felt he was underpaid and could make more money touring with a minstrel group.
Studying the blues.
In 1902 Handy traveled throughout Mississippi, where he listened to the various black popular musical styles. The state was mostly rural, and music was part of the culture, especially of the Mississippi Delta cotton plantation areas. Musicians usually played the guitar, banjo, and to a much lesser extent, the piano. Handy's remarkable memory enabled him to recall and transcribe the music heard in his travels.
After a dispute with AAMC President Councill, Handy resigned his teaching position to rejoin the Mahara Minstrels and tour the Midwest and Pacific Northwest. In 1903 he became the director of a black band organized by the Knights of Pythias, located in Clarksdale, Mississippi. Handy and his family lived there for six years. In 1903 while waiting for a train in Tutwiler in the Mississippi Delta, Handy had the following experience: 
A lean loose-jointed Negro had commenced plunking a guitar beside me while I slept... As he played, he pressed a knife on the strings of the guitar in a manner popularized by Hawaiian guitarists who used steel bars...The singer repeated the line three times, accompanying himself on the guitar with the weirdest music I had ever heard.
About 1905 while playing a dance in Cleveland, Mississippi, Handy was given a note asking for "our native music". He played an old-time Southern melody, but was asked if a local colored band could play a few numbers. Three young men with a battered guitar, mandolin, and a worn-out bass took the stage.
They struck up one of those over and over strains that seem to have no beginning and certainly no ending at all. The strumming attained a disturbing monotony, but on and on it went, a kind of stuff associated with cane rows and levee camps. Thump-thump-thump went their feet on the floor. It was not really annoying or unpleasant. Perhaps "haunting" is the better word.
Handy noted square dancing by Mississippi blacks with "one of their own calling the figures, and crooning all of his calls in the key of G." He remembered this when deciding on the key for "St Louis Blues".
It was the memory of that old gent who called figures for the Kentucky breakdown—the one who everlastingly pitched his tones in the key of G and moaned the calls like a presiding elder preaching at a revival meeting. Ah, there was my key – I'd do the song in G.
In describing "blind singers and footloose bards" around Clarksdale, Handy wrote, "urrounded by crowds of country folks, they would pour their hearts out in song ... They earned their living by selling their own songs – "ballets," as they called them—and I'm ready to say in their behalf that seldom did their creations lack imagination."
Transition: popularity, fame and business.
In 1909 Handy and his band moved to Memphis, Tennessee, where they started playing at clubs on Beale Street. The genesis of his "Memphis Blues" was as a campaign tune written for Edward Crump, a successful Memphis mayoral candidate in 1909 (and future "boss"). Handy later rewrote the tune and changed its name from "Mr. Crump" to "Memphis Blues." 
The 1912 publication of his "Memphis Blues" sheet music introduced his style of 12-bar blues; it was credited as the inspiration for the foxtrot dance step by Vernon and Irene Castle, a New York–based dance team. Some consider it to be the first blues song. Handy sold the rights to the song for US$100. By 1914, when Handy was 40, he had established his musical style, his popularity increased significantly, and he composed prolifically.
Handy wrote about using folk songs: 
The primitive southern Negro, as he sang, was sure to bear down on the third and seventh tone of the scale, slurring between major and minor. Whether in the cotton field of the Delta or on the Levee up St. Louis way, it was always the same. Till then, however, I had never heard this slur used by a more sophisticated Negro, or by any white man. I tried to convey this effect... by introducing flat thirds and sevenths (now called blue notes) into my song, although its prevailing key was major..., and I carried this device into my melody as well... This was a distinct departure, but as it turned out, it touched the spot.
The three-line structure I employed in my lyric was suggested by a song I heard Phil Jones sing in Evansville ... While I took the three-line stanza as a model for my lyric, I found its repetition too monotonous ... Consequently I adopted the style of making a statement, repeating the statement in the second line, and then telling in the third line why the statement was made.
Regarding the "three-chord basic harmonic structure" of the blues, Handy wrote the "(tonic, subdominant, dominant seventh) was that already used by Negro roustabouts, honky-tonk piano players, wanderers and others of the underprivileged but undaunted class from Missouri to the Gulf, and had become a common medium through which any such individual might express his personal feeling in a sort of musical soliloquy." He noted,
In the folk blues the singer fills up occasional gaps with words like 'Oh, lawdy' or 'Oh, baby' and the like. This meant that in writing a melody to be sung in the blues manner one would have to provide gaps or waits.
Writing about the first time "St Louis Blues" was played (1914), Handy said, 
The one-step and other dances had been done to the tempo of Memphis Blues... When St Louis Blues was written the tango was in vogue. I tricked the dancers by arranging a tango introduction, breaking abruptly into a low-down blues. My eyes swept the floor anxiously, then suddenly I saw lightning strike. The dancers seemed electrified. Something within them came suddenly to life. An instinct that wanted so much to live, to fling its arms to spread joy, took them by the heels.
His published musical works were groundbreaking because of his ethnicity, and he was among the first blacks to achieve economic success because of publishing. In 1912, Handy met Harry H. Pace at the Solvent Savings Bank in Memphis. Pace was valedictorian of his graduating class at Atlanta University and student of W. E. B. Du Bois. By the time of their meeting, Pace had already demonstrated a strong understanding of business. He earned his reputation by recreating failing businesses. Handy liked him, and Pace later became manager of Pace and Handy Sheet Music. 
While in New York City, Handy wrote: 
I was under the impression that these Negro musicians would jump at the chance to patronize one of their own publishers. They didn't... The Negro musicians simply played the hits of the day...They followed the parade. Many white bands and orchestra leaders, on the other hand, were on the alert for novelties. They were therefore the ones most ready to introduce our numbers. [But,] Negro vaudeville artists...wanted songs that would not conflict with white acts on the bill. The result was that these performers became our most effective pluggers.
In 1917, he and his publishing business moved to New York City, where he had offices in the Gaiety Theatre office building in Times Square. By the end of that year, his most successful songs: "Memphis Blues", "Beale Street Blues", and "Saint Louis Blues", had been published. That year the Original Dixieland Jazz Band, a white New Orleans jazz ensemble, had recorded the first jazz record, introducing the style to a wide segment of the American public. Handy initially had little fondness for this new "jazz", but bands dove into his repertoire with enthusiasm, making many of them jazz standards.
Handy encouraged performers such as Al Bernard, "a young white man" with a "soft Southern accent" who "could sing all my Blues". Handy sent Bernard to Thomas Edison to be recorded, which resulted in "an impressive series of successes for the young artist, successes in which we proudly shared." Handy also published the original "Shake Rattle and Roll" and "Saxophone Blues", both written by Bernard. "Two young white ladies from Selma, Alabama (Madelyn Sheppard and Annelu Burns) contributed the songs "Pickaninny Rose" and "O Saroo", with the music published by Handy's company. These numbers, plus our blues, gave us a reputation as publishers of Negro music."
Expecting to make only "another hundred or so" on a third recording of his "Yellow Dog Blues" (originally titled "Yellow Dog Rag"
), Handy signed a deal with the Victor company. The Joe Smith recording of this song in 1919 became the best-selling recording of Handy's music to date.
Handy tried to interest black women singers in his music, but initially was unsuccessful. In 1920 Perry Bradford persuaded Mamie Smith to record two of his non-blues songs, published by Handy, accompanied by a white band: "That Thing Called Love" and "You Can't Keep a Good Man Down". When Bradford's "Crazy Blues" became a hit as recorded by Smith, African-American blues singers became increasingly popular. Handy found his business began to decrease because of the competition.
In 1920 Pace amicably dissolved his long-standing partnership with Handy, with whom he also collaborated as lyricist. As Handy wrote: "To add to my woes, my partner withdrew from the business. He disagreed with some of my business methods, but no harsh words were involved. He simply chose this time to sever connection with our firm in order that he might organize Pace Phonograph Company, issuing Black Swan Records and making a serious bid for the Negro market. . . . With Pace went a large number of our employees. . . . Still more confusion and anguish grew out of the fact that people did not generally know that I had no stake in the Black Swan Record Company."
Although Handy's partnership with Pace was dissolved, he continued to operate the publishing company as a family-owned business. He published works of other black composers as well as his own, which included more than 150 sacred compositions and folk song arrangements and about 60 blues compositions. In the 1920s, he founded the Handy Record Company in New York City. Bessie Smith's January 14, 1925, Columbia Records recording of "Saint Louis Blues" with Louis Armstrong is considered by many to be one of the finest recordings of the 1920s. So successful was Handy's "Saint Louis Blues" that in 1929, he and director Murphy collaborated on a RCA motion picture project of the same name, which was to be shown before the main attraction. Handy suggested blues singer Bessie Smith have the starring role, since she had gained widespread popularity with that tune. The picture was shot in June and was shown in movie houses throughout the United States from 1929 to 1932.
In 1926 Handy authored and edited a work entitled "Blues: An Anthology—Complete Words and Music of 53 Great Songs". It is probably the first work that attempted to record, analyze and describe the blues as an integral part of the U.S. South and the history of the United States. To celebrate the books release and to honor Handy, Small's Paradise in Harlem hosted a party "Handy Night" on Tuesday October 5, which contained the best of jazz and blues selections provided by the entertainers Adelaide Hall, Lottie Gee, Maude White and Chic Collins.
The genre of the blues was a hallmark of American society and culture in the 1920s and 1930s. So great was its influence, and so much was it recognized as Handy's hallmark, that author F. Scott Fitzgerald wrote in his novel "The Great Gatsby" that "All night the saxophones wailed the hopeless comment of the "Beale Street Blues" while a hundred pairs of golden and silver slippers shuffled the shining dust. At the gray tea hour there were always rooms that throbbed incessantly with this low, sweet fever, while fresh faces drifted here and there like rose petals blown by the sad horns around the floor."
Later life.
Following publication of his autobiography, Handy published a book on African-American musicians entitled "Unsung Americans Sing" (1944). He wrote a total of five books:
During this time, he lived on Strivers' Row in Harlem. He became blind following an accidental fall from a subway platform in 1943. After the death of his first wife, he remarried in 1954, when he was 80. His new bride was his secretary, the former Irma Louise Logan, whom he frequently said had become his eyes.
In 1955, Handy suffered a stroke, following which he began to use a wheelchair. More than eight hundred attended his 84th birthday party at the Waldorf-Astoria Hotel.
Death.
On March 28, 1958 he died of bronchial pneumonia at Sydenham Hospital in New York City. Over 25,000 people attended his funeral in Harlem's Abyssinian Baptist Church. Over 150,000 people gathered in the streets near the church to pay their respects. He was buried in Woodlawn Cemetery in The Bronx, New York City.
Compositions.
Handy's songs do not always follow the classic 12-bar pattern, often having 8- or 16-bar bridges between 12-bar verses.

</doc>
<doc id="58070" url="https://en.wikipedia.org/wiki?curid=58070" title="House of Este">
House of Este

The House of Este ( , originally House of Welf-Este) is a European princely dynasty. It is one of the most ancient noble dynasties in Europe.
The elder branch of the House of Este included the dukes of Brunswick and Lüneburg (1208–1918) and produced Britain's Hanoverian monarchs and one Emperor of Russia (Ivan VI).
The younger branch of the House of Este included rulers of Ferrara (1240–1597), and Modena and Reggio (1288–1796).
Origins.
Edward Gibbon said the family originated from the Roman Attii family, which migrated from Rome to Este to defend Italy against the Ostrogoths. However, there is little evidence to support this hypothesis. The names of the early members of the family indicate that a Frankish origin is much more likely. The first known member of the house was Margrave Adalbert of Mainz, known only as father of Oberto I, Count palatine of Italy, who died around 975. Oberto's grandson, Albert Azzo II, Margrave of Milan (996–1097) built a castle at Este, near Padua, and named himself after it. He had three sons from two marriages, two of whom became the ancestors of the two branches of the family:
The two surviving branches, with Duke Henry the Lion of Saxony and Bavaria on the German side, concluded an agreement in 1154 which allocated the family's Italian possessions to the younger line, the Fulc-Este, who in the course of time acquired Ferrara, Modena and Reggio. Este itself was taken over in 1275 by Padua and in 1405, (together with Padua) by Venice.
Elder branch, Guelph, Electors of Hanover.
The elder branch of the House of Este, the House of Welf, historically rendered "Guelf" or "Guelph" in English, produced dukes of Bavaria (1070–1139, 1156–1180), dukes of Saxony (1138–1139, 1142–1180), a German King (1198–1218), and the dukes of Brunswick and Lüneburg (1208–1918), later styled the ""Electors of Hanover"" when two branches of the family recombined in 1705.
After the peace ending the Napoleonic wars reshaped Europe ushering in the Modern era, the Electorate of Hanover (duchy of Brunswick and Lüneburg held in personal union by the king of Great Britain, George III) was dissolved by treaty, its lands were enlarged, and the state promoted to a kingdom. The new kingdom existed from 1815 to 1866, but upon accession of Queen Victoria (who could not inherit Hanover under the Salic law) in 1837, it passed to her uncle and thus ceased to be in personal union with the British Crown.
The House of Este hence gave Great Britain and the United Kingdom the "Hanoverian monarchs" (1714–1901).
Younger branch, the Margraves of Este.
"All later generations of the Italian branch are descendants of Fulco d'Este." From 1171 on, his descendants were titled Margraves of Este.
Obizzo I (d. 1193), the first margrave, battled against Emperor Frederick I Barbarossa. His nephew Azzo d'Este VI (1170–1212) became podestà of Mantua and Verona. In 1146, with the last of the Adelardi, Ferrara passed as the dowry of his niece "the Marchesella", to Azzo VI d'Este. Azzo VII "Novello" was nominated podestà for his lifetime in 1242.
The lordship of Ferrara was made hereditary by Obizzo II (d. 1293) who was proclaimed Lord of Ferrara in 1264, Lord of Modena 1288 and Lord of Reggio 1289. Ferrara was a papal fief and the Este family were given the position of hereditary papal vicars in 1332.
Ferrara became a significant center of culture under Niccolò d'Este III (1384–1441), who received several popes with great magnificence, especially Eugene IV.He held a Council here in 1438, later known as the Council of Florence.
His successors were Leonello (1407–1450) and Borso (1413–1471), who was elevated to Duke of Modena and Reggio by Emperor Frederick III in 1452. In return, he received these duchies as imperial fiefs. In 1471, he received the duchy of Ferrara as papal fief from Pope Paul II, for which occasion splendid frescoes were executed at Palazzo Schifanoia.
Under Ercole (1431–1505), one of the most significant patrons of the arts in late 15th and early 16th century Italy, Ferrara grew into a cultural center, renowned especially for music; Josquin des Prez worked for Duke Ercole, Jacob Obrecht came to Ferrara twice, and Antoine Brumel served as principal musician from 1505. Ercole's daughter Beatrice (1475–1497) married Ludovico Sforza, Duke of Milan, while his daughter Isabella (1474–1539) married Francesco Gonzaga, Marquess of Mantua.
Ercole I's successor was his son Alfonso I (1476–1534), third husband of Lucrezia Borgia, daughter of Pope Alexander VI, sister to Cesare Borgia and the patron of Ariosto.
Alfonso and Lucrezia Borgia's son Ercole d'Este II (1508–1559) married Renée of France, daughter of Louis XII of France. His son Alfonso II first married Lucrezia, daughter of grand-duke Cosimo I of Tuscany. Later, after becoming a widower, he married Barbara, the sister of Maximilian II, Holy Roman Emperor (1527–1576). His third wife, Margherita Gonzaga, was daughter of the duke of Mantua.
Though he raised the glory of Ferrara to its highest point, and was the patron of Torquato Tasso and Giovanni Battista Guarini, favoring the arts and sciences, as the princes of his house had always done, the legitimate line ended in 1597 with him. Emperor Rudolph II recognized as heir, his first cousin Cesare d'Este (1533–1628), member of a cadet branch born out of wedlock, who continued to rule in the imperial duchies and carried on the family name. Ferrara, on the other hand, was annexed by force of arms in 1598 by Pope Clement VIII, on grounds of the heir's illegitimacy, and incorporated into the Papal States.
The last duke, Ercole III, was deposed in 1796 by the French. His two duchies became the Cispadane Republic which one year later was merged into the Cisalpine Republic and then into the Napoleonic Kingdom of Italy. Ercole was compensated in 1801 with the small principality of Breisgau in southwestern Germany, whose previous rulers, the Habsburgs, ceded it to him in anticipation of its eventual return to the Habsburgs, since Ercole's daughter Maria Beatrice Ricciarda d'Este was married to a cadet Habsburg, Archduke Ferdinand of Austria-Este. Ercole died in 1803 and Breisgau passed to his daughter and her husband, who then (1806) lost it during the Napoleonic reorganization of the western territories of the defunct Holy Roman Empire to the enlarged and elevated Grand Duchy of Baden.
Austria-Este and the House of Habsburg.
In 1814, when French rule in Italy ended (but after the death of Duke Ercole), Modena was returned to his daughter Mary Beatrice and her son, Archduke Francis of Austria-Este. The family thus ruled the duchy of Modena and Reggio again from 1814 to 1859, using the names Asburgo-Este (Habsburg-Este) and Austria-Este. In 1859, the duchy lost its independence to the new united Italy, and Francis V, Duke of Modena, was deposed.
The family of Austria-Este became extinct in the male line with the death of Francis V in 1875. His blood-heiress was his niece, Archduchess Maria Theresia of Austria-Este (d. 1919); she and her husband, Prince Louis of Bavaria, later became Queen and King of Bavaria. The present head of this branch of the family is Franz, Duke of Bavaria.
However, Francis V had decided to retain the Este name in the Habsburg family and willed his inheritance to the line of Archduke Charles Louis, younger brother of Emperor Francis Joseph, on condition that the heir use the name Austria-Este. The first "adoptee" was Archduke Franz Ferdinand of Austria (b. 1863, not descended from Maria Beatrice Ricciarda d'Este), who took the name Austria-Este and in 1896 became the heir presumptive of the Habsburg Empire, but was murdered on 28 June 1914 in Sarajevo. 
Since his own children were born in morganatic marriage (Sophie, Duchess of Hohenberg), the Habsburgs designated his soon-to-be born great-nephew Robert (b. 8 February 1915), second son of the future emperor Charles, as the next "adopted Austria-Este." Through his mother Zita of Bourbon-Parma (a great-granddaughter of Maria Teresa of Savoy, Duchess of Lucca and Parma, who was a daughter of Maria Teresa of Austria-Este, Queen of Sardinia, who in turn was a daughter of Maria Beatrice Ricciarda d'Este and Archduke Ferdinand of Austria-Este, Duchess and Duke of Breisgau and Modena), Robert was a descendant of Ercole III d'Este, and the blood of last Este dukes thus joined again with the name Austria-Este.
Today, the bearer of this tradition is the eldest son of Archduke Robert of Austria-Este (1915–1996), Lorenz Otto Charles of Austria-Este (b. 1955), who is married to Princess Astrid of Belgium, the only daughter of King Albert II. In 1995, Lorenz received the additional title of Prince of Belgium.
Since 1991 the couple's children are titled :
The eldest of their children is Prince Amedeo of Belgium, Archduke of Austria-Este (b. 1986).

</doc>
<doc id="58072" url="https://en.wikipedia.org/wiki?curid=58072" title="John Mathieson (computer scientist)">
John Mathieson (computer scientist)

John Mathieson is a Computer Science graduate who initially worked for Sinclair Research before going on to found Flare with fellow ex-Sinclair colleagues Martin Brennan and Ben Cheese.
After working at Flare on the "Flare 1" and its development into the Konix Multisystem, he went on to work for Atari developing the Atari Jaguar with Martin Brennan. John moved to California and worked on the Atari Jaguar II which never saw the light of day.
He led the development of the ill-fated NUON media processor at VM Labs. He moved to work for NVIDIA at the end of 2001. As Director of Mobile Systems Architecture at NVIDIA Corp. he led the system architecture team for three generations of the Tegra applications processor.

</doc>
<doc id="58074" url="https://en.wikipedia.org/wiki?curid=58074" title="Battle of Cape St Vincent (1797)">
Battle of Cape St Vincent (1797)

The Battle of Cape St Vincent (14 February 1797) was one of the opening battles of the Anglo-Spanish War (1796–1808), as part of the French Revolutionary Wars, where a British fleet under Admiral Sir John Jervis defeated a larger Spanish fleet under Admiral Don José de Córdoba y Ramos near Cape St. Vincent, Portugal.
Origins.
After the signing of the Treaty of San Ildefonso in 1796 allying Spanish and French forces against Great Britain, the British navy blockaded Spain in 1797, impairing communications with its American colonies.
The Spanish declaration of war on Britain and Portugal in October 1796 made the British position in the Mediterranean untenable. The combined Franco-Spanish fleet of 38 ships of the line heavily outnumbered the British Mediterranean Fleet of 15 ships of the line, forcing the British to evacuate their positions in first Corsica and then Elba.
Early in 1797, the Spanish fleet of 27 ships of the line, which were supposed to join the French fleet at Brest lay at Cartagena, on the Mediterranean Sea, with the intention of sailing to Cádiz as an escort of a 57 merchant convoy, carrying mainly mercury—necessary for gold and silver production—which would eventually enter that Spanish harbour along with warships "Neptuno", "Terrible" and "Bahama", prior to running into the British force.
Don José de Córdoba and the Spanish fleet left Cartagena on 1 February and might have reached Cádiz safely but for a fierce Levanter, the easterly wind, blowing between Gibraltar and Cádiz, which pushed the Spanish fleet further out into the Atlantic than intended. As the winds died down, the fleet began working its way back to Cádiz.
In the meantime, the British Mediterranean Fleet, under Admiral Sir John Jervis, had sailed from the Tagus with 10 ships of the line to try to intercept the Spanish fleet. On 6 February, Jervis was joined off Cape St. Vincent by a reinforcement of five ships of the line from the Channel Fleet under Rear-Admiral William Parker.
On 11 February, the British frigate HMS "Minerve", under the command of Commodore Horatio Nelson, passed through the Spanish fleet unseen thanks to heavy fog. Nelson reached the British fleet of 15 ships off Spain on 13 February, and passed the location of the Spanish fleet to Jervis, commanding the fleet from his flagship "Victory". Unaware of the size of his opponent's fleet—in the fog, Nelson had not been able to count them—Jervis's squadron immediately sailed to intercept.
Unaware of the British presence, the Spanish continued toward Cádiz. Early on the 14th, Jervis learnt that the Spanish fleet was 35 miles to windward.
Battle.
Early morning.
Captain Thomas Troubridge in "Culloden" was in the lead. At 6:30 a.m., "Culloden" signalled that she could see 5 enemy sail to the south east, and then with "Blenheim" and "Prince George" turned toward the Spanish ships. Jervis had no idea of the size of the fleet he was up against. As they loomed up out of the fog, a signal lieutenant in "Barfleur" described them as "thumpers, looming like Beachy Head in a fog."
As dawn broke, Jervis's ships were in position to engage the Spanish. On the quarter-deck of "Victory", Jervis, Captain Robert Calder and Captain Benjamin Hallowell counted the ships. It was at this point Jervis discovered that he was outnumbered nearly two-to-one:
"There are eight sail of the line, Sir John"
"Very well, sir"
"There are twenty sail of the line, Sir John"
"Very well, sir"
"There are twenty five sail of the line, Sir John"
"Very well, sir"
"There are twenty seven sail of the line, Sir John"
"Enough, sir, no more of that; the die is cast, and if there are fifty sail I will go through them"
Seeing that it would be difficult to disengage, Jervis decided to continue because the situation would only get worse were the Spanish fleet to join up with the French. Meanwhile, the Canadian Captain Hallowell became so excited that he thumped the Admiral on the back, "That's right Sir John, and, by God, we'll give them a damn good licking!"
As the light grew, it became obvious that the Spanish ships were formed in two loose columns, one of about 18 ships to windward and the other, of about 9 ships, somewhat closer to the British. At about 10:30 a.m., the Spanish ships in the weather column were seen to wear ship and turn to port. This gave the impression that they might form a line and pass along the weather column of the British fleet, exposing the smaller British column to the fire of the larger Spanish division.
At 11:00 a.m., Jervis gave his order:
Form in a line of battle ahead and astern of Victory as most convenient.
When this order was completed the British fleet had formed a single line of battle, sailing in a southerly direction on a course to pass between the two Spanish columns.
At 11:12 a.m., Jervis made his next signal:
Engage the enemy
and then at 11:30 a.m.,
Admiral intends to pass through enemy lines
The Battle of Cape St. Vincent had begun.
11:30 a.m..
To the British advantage, the Spanish fleet was formed into two groups and was unprepared for battle, while the British were already in line. Jervis ordered the British fleet to pass between the two groups, minimising the fire they could put into him, while letting him fire in both directions
12:30 p.m..
"Culloden" tacked to reverse her course and take after the Spanish column. "Blenheim" and then "Prince George" did the same in succession. The Spanish lee division now put about to the port tack with the intention of breaking the British line at the point where the ships were tacking in succession. "Orion" came round but "Colossus" was in the course of going about when her foreyard and foretop yard were shot away. She was forced to wear ship instead of tack and the leading Spanish vessel came close enough to threaten her with a broadside. Saumarez in "Orion" saw the danger to his friends and backed his sails to give covering fire.
As "Victory" came to the tacking point, another attempt was made to break the British line. "Victory", however, was too fast and the leading Spaniard, a 3-decker, had to tack close to "Victory" and received a raking broadside as she did so. "We gave them their Valentine in style," later wrote a gunner in "Goliath".
As the last ship in the British line passed the Spanish, the British line had formed a U shape with "Culloden" in the lead and on the reverse course but chasing the rear of the Spanish. At this point the Spanish lee division bore up to make an effort to join their compatriots to windward. Had they managed to do this, the battle would have ended indecisively and with the Spanish fleet running for Cádiz. The British ships would have been left harrying their sterns in much the manner of the Armada, 1588.
1:05 p.m..
At 1:05 p.m., Jervis hoisted a signal:
Take suitable stations for mutual support and engage the enemy as coming up in succession
Nelson had returned to his own ship "Captain" (a seventy-four) and was now towards the rear of the British line, much closer to the larger group. He came to the conclusion that the manoeuvre could not be completed so as to allow the British to catch them. Unless the movements of the Spanish ships could be thwarted, everything so far gained would be lost. Interpreting Jervis' signal loosely, and disobeying previous orders, Nelson gave orders to Captain Ralph Miller to wear ship and to take "Captain" out of line while engaging the smaller group.
As soon as the seventy-four was around, Nelson directed her to pass between "Diadem" and "Excellent" and ran across the bows of the Spanish ships forming the central group of the weather division. This group included the "Santísima Trinidad", the largest ship afloat at the time and mounting 130 guns, the "San José", 112, "Salvador del Mundo", 112, "San Nicolás", 84, "San Ysidro" 74 and the "Mexicano" 112.
Nelson's decision to wear ship was significant. As a junior commander, he was subject to the orders of his Commander in Chief (Admiral Jervis); in taking this action he was acting against the "form line ahead and astern of "Victory"" order and using his own wide interpretation of "take suitable stations" in the later signal. Had the action failed, he would have been subject to court-martial for disobeying orders in the face of the enemy, with subsequent loss of command and disgrace.
At about 1:30 p.m., "Culloden" was gradually overhauling the Spanish rear and began a renewed but not very close engagement of the same group of ships. Jervis signalled his rearmost ship, "Excellent" to come to the wind on the larboard tack and following this order, Collingwood brought his ship round to a position ahead of "Culloden". After a few more minutes, "Blenheim" and "Prince George" came up behind and the group of British ships prevented the Spanish from grouping together.
The "Captain" was now under fire from as many as six Spanish ships, of which three were 112-gun three-deckers and a fourth Córdoba’s 130-gun flagship "Santísima Trinidad". At about 2:00 p.m., "Culloden" had stretched so far ahead as to cover the "Captain" from the heavy fire poured into her by the Spanish four-decker and her companions, as they hauled up and brought their broadsides to bear. Of the respite thus afforded to her, the "Captain" took immediate advantage, replenishing her lockers with shot and splicing and repairing her running rigging.
At about 2:30, "Excellent" having been directed by signal to bear up, edged away and at 2:35, arriving abreast of the disabled Spanish three-decker "Salvator del Mundo", engaged the latter on her weather bow for a few minutes; then passing on to the next Spanish ship in succession, the "San Ysidro", whose three topmasts had already been shot away. This ship Captain Collingwood engaged closely until 2:50 when, after a gallant defence in her crippled state, the "San Ysidro" hauled down the Spanish flag.
Moments later, "Excellent" and "Diadem" commenced an attack on the "Salvator del Mundo", with "Excellent" stationing herself on the weather bow and "Diadem" on the lee quarter of the Spanish three-decker. Observing that the "Victory" was about to pass close astern, the "Salvator del Mundo", which had more or less been disabled, judiciously hauled down her flag as soon as some of Victory's bow guns came to bear.
3:00 p.m..
By about 3:00, "Excellent" was already in close action with "San Nicolás" which, with foretop mast shot away, had been in action against "Captain". "Excellent" fired broadsides into "San Nicolás" and then made sail to clear ahead. To avoid "Excellent", "San Nicolás" luffed up and ran foul of "San José", which had suffered the loss of mizzen mast and other damage. "Captain" was by now almost uncontrollable with her wheel shot away. At this point, her foretop mast fell over the side leaving her in a completely unmanageable state and with little option but to board the Spanish vessels. "Captain" opened fire on the Spanish vessels with her larboard (port) side broadside and then put the helm over and hooked her larboard cat-head with the starboard quarter of "San Nicolás".
At 3:20, with a cry of "Westminster Abbey or Glorious Victory!", Nelson ordered his boarders to cross the first Spanish ship onto the second. He later wrote,
The soldiers of the 69th, with an alacrity which will ever do them credit, and Lieutenant Pearson of the same regiment, were almost the foremost on this service – the first man who jumped into the enemy's mizen chains was Commander Berry, late my First Lieutenant (Captain Miller was in the very act of going also, but I directed him to remain); he was supported from our sprit sail yard, which hooked in the mizen rigging. A soldier of the 69th Regiment having broken the upper quarter-gallery window, I jumped in myself, and was followed by others as fast as possible. I found the cabin doors fastened, and some Spanish officers fired their pistols: but having broke open the doors the soldiers fired, and the Spanish Brigadier fell, as retreating to the quarter-deck. I pushed immediately onwards for the quarter-deck, where I found Commander Berry in possession of the poop, and the Spanish ensign hauling down. I passed with my people, and Lieutenant Pearson, on the larboard gangway, to the forecastle, where I met two or three Spanish officers, prisoners to my seamen: they delivered me their swords. A fire of pistols, or muskets, opening from the stern gallery of the San Josef, I directed the soldiers to fire into her stern; and calling to Captain Miller, ordered him to send more men into the San Nicolas; and directed my people to board the first-rate, which was done in an instant, Commander Berry assisting me into the main chains. At this moment a Spanish officer looked over the quarter deck rail, and said they surrendered. From this most welcome intelligence, it was not long before I was on the quarter deck, where the captain, with a bow, presented me his sword, and said the admiral was dying of his wounds. I asked him on his honour if the ship was surrendered. He declared she was: on which i gave him my hand, and desired him to call on his officers and ship's company and tell them of it: which he did – and on the quarter deck of a Spanish first-rate, extravagant as the story may seem, did I receive the swords of vanquished Spaniards: which as I received, I gave to William Fearney, one of my bargemen, who put them, with the greatest sang-froid, under his arm.
Both Spanish vessels were successfully captured. This manoeuvre was so unusual and so widely admired in the Royal Navy that using one enemy ship to cross to another became known facetiously as ""Nelson's patent bridge for boarding enemy vessels.""
By the time "Santísima Trinidad" had struck her colours to surrender, "Pelayo" and "San Pablo", separated from de Córdoba's group during action, having been dispatched by the commander the day before, sailed in and bore down on "Diadem" and "Excellent". "Pelayo"´s captain Cayetano Valdés warned "Santísima Trinidad" to fly her flag again under threat she would be deemed an enemy ship and raked. The Spanish four-decker raised her flag. She was saved from being captured by the British.
By 4:00, the Spanish ship "Santísima Trinidad" was relieved by two of her escorts and made away from the scene. Admiral Moreno's squad put together the survivors of Córdoba's group and turned to assist the harassed Spanish sails. Jervis signalled his fleet to cover the prizes and disabled vessels and at 4:15 the frigates were directed to take the prizes in tow. At 4:39 the fleet was ordered to take station in line astern of "Victory". The battle was by now almost over with only some remaining skirmishing between "Britannia", "Orion" and the departing Spanish covering "Santísima Trinidad" (which was to later serve as the Spanish flagship at the Battle of Trafalgar).
End of the battle.
Nelson remained on board the captured Spanish ships while they were made secure – and was cheered by the British ships as they passed. He returned to the "Captain" to thank Captain Miller and presented him with the sword of the captain of the "San Nicolás".
At 5:00, Nelson shifted his pennant from the disabled "Captain" to "Irresistible". The Battle of Cape St. Vincent had cost the lives of 73 men of the Royal Navy and wounded a further 227 (this figure only includes serious injuries). Casualties amongst the Spanish ships were far higher – aboard "San Nicolás" alone 144 were killed. Then, still black with smoke and with his uniform in shreds, Nelson went on board "Victory" where he was received on the quarter-deck by Admiral Jervis – "the Admiral embraced me, said he could not sufficiently thank me, and used every kind expression which could not fail to make me happy."
It was a great and welcome victory for the Royal Navy – 15 British ships had defeated a Spanish fleet of 27, and the Spanish ships had a greater number of guns and men. But, Admiral Jervis had trained a highly disciplined force and this was pitted against an inexperienced Spanish navy under Don José Córdoba. The Spanish men fought fiercely but without direction. After the "San José" was captured it was found that some of her guns still had their tampions in the muzzles. The confusion amongst the Spanish fleet was so great that they were unable to use their guns without causing more damage to their own ships than to the British.
Aftermath.
Jervis had given orders to destroy the four prizes had the action restarted. Several days later, the frigate (32) spotted the damaged "Santísima Trinidad" making her way back to Spain. The captain, Orozco, now commissioned by de Cordoba, had flown his flag in frigate "Diana". "Terpsichore" engaged but kept always out of range from the stern guns of the ship anytime "Santísima Trinidad" bore down on the English frigate. "Terpsichore" nonetheless was hit twice with those cannons in a sudden move, resulting in damage in her rigging, masts and sails as well as some impacts on her hull. Captain Richard Bowen then ordered to keep the pursuit but from a longer distance until the frigate vanished away.
In the battle as a whole, the British casualties were 73 killed, 227 badly wounded, and about 100 lightly wounded. The Spanish casualties were about 1,000 men killed or wounded. While the British fleet lay at Lagos Bay, in Portugal, the Spanish prisoners received from the four prizes, numbering about 3000, were landed.
Jervis was made Baron Jervis of Meaford and Earl St Vincent. Nelson was knighted as a member of the Order of the Bath. Nelson's promotion to Rear-Admiral was not a reward for his services, but simply a happy coincidence: promotion to flag rank in the Navy of the time was based on seniority on the Captain's list and not on achievement. The now Earl St Vincent was granted a pension for life of £3,000 per year. The City of London presented him with the Freedom of the City in a gold box valued at 100 guineas and awarded both him and Nelson a ceremonial sword. The presentation box and sword are both currently held at the National Maritime Museum, Greenwich. The two swords awarded Jervis and Nelson were the first of their kind to be issued by the City of London. St Vincent was awarded the thanks of both Houses of Parliament and given a gold medal by the King. The "London Gazette" published an advertisement in 1798 regarding the prize money that was due to the officers and men who had fought at the battle. The sum quoted was £140,000 of which, as admiral, Jervis was entitled to a sizable share. In 1847 the Admiralty authorized the issuance of the Naval General Service Medal with clasp "St. Vincent" to all surviving claimants from the battle.
Cordóba was dismissed from the Spanish navy and forbidden from appearing at court.
Jervis resumed his blockade of the Spanish fleet in Cadiz. The continuation of the blockade for most of the following three years, largely curtailed the operations of the Spanish fleet until the Peace of Amiens in 1802.
The containment of the Spanish threat, and the further reinforcement of his command, enabled Jervis to send a squadron under Nelson back into the Mediterranean the following year. That squadron, including Saumarez’s "Orion", Troubridge’s "Culloden", and the "Goliath", now under Foley, re-established British command of the Mediterranean at the Battle of the Nile.
Order of battle.
British fleet.
Admiral Sir John Jervis was on his flagship "Victory". The British ships are listed in order from van to rear. Many of the British wounded later died.

</doc>
<doc id="58075" url="https://en.wikipedia.org/wiki?curid=58075" title="Hervé Villechaize">
Hervé Villechaize

Hervé Jean-Pierre Villechaize (23 April 1943 – 4 September 1993) was a French actor of English and Filipino descent who achieved worldwide recognition for various roles including that of the evil henchman Nick Nack in the James Bond film, "The Man with the Golden Gun" (1974), as well as Mr. Roarke's assistant, Tattoo, in the television series "Fantasy Island" (1978–1984). On "Fantasy Island", he was well known for delivering the line "Ze plane! Ze plane!"
Early life.
Villechaize suffered from proportionate dwarfism, likely due to an endocrine disorder, despite his surgeon father's attempts to cure the disease in several institutions. In later years, he insisted on being called a "midget" rather than a "little person".
Villechaize was born in Nazi-occupied Paris to English-born Evelyn (Recchionni) and raised there by her and his father André Villechaize. Villechaize was bullied at school for his condition and found solace in painting. He also had a brief modeling career. A gifted artist, in 1959, at the age of 16, he entered the École des Beaux-Arts to study art. In 1961, he became the youngest artist to ever have his work displayed in the Museum of Paris. In 1964 he left France for the USA. He settled in a Bohemian section in New York, taught himself English by watching television and continued his career as an artist, painter and photographer. He began acting in Off Broadway productions, including "The Young Master Dante" by Werner Liepolt and a play by Sam Shepard, and also did some photo shoot modeling for "National Lampoon", before moving on to film.
Career.
His first movie appearance was in "Chappaqua" in 1966. The second film was Edward Summer's "Item 72-D: The Adventures of Spa and Fon" filmed in 1969. This was followed by several films including Christopher Speeth's and Werner Liepolt's "Malatesta's Carnival of Blood;" "Crazy Joe;" Oliver Stone's first film, "Seizure"; "The Gang That Couldn't Shoot Straight"; and 1980's "Forbidden Zone". He was asked to play a part in the film "Dune", which had originally begun pre-production in 1971; however, the project was cancelled.
His big break was getting cast in "The Man with the Golden Gun" in 1974, by which time he had become so poor he was living out of his car in Los Angeles. Prior to being signed up by Bond producer Albert R. Broccoli, he made ends meet by working as a rat catcher's assistant near his South Central home. From what his co-actor Christopher Lee saw, "The Man with the Golden Gun" filming was possibly the happiest time of Hervé's life: Lee likened it to honey in the sandwich between an insecure past and an uncertain future. In addition to being an actor, Villechaize became an active member of a movement in 1970s and 1980s California to deal with child abuse and neglect, often going to crime scenes himself to help comfort abuse victims. Villechaize's former co-workers recalled that despite his stature, he would often confront and chastise spousal and child abusers when he arrived at crime scenes. In the 1970s, on "Sesame Street", Villechaize performed Oscar the Grouch as a pair of legs peeping out from a trash can, for scenes which required the Grouch to be mobile. These appearances began in the second season and included the 1978 Hawaii episodes.
Though popular with the public, Villechaize proved a difficult actor on "Fantasy Island", where he continually propositioned women and quarreled with the producers. He was eventually fired after demanding a salary on par with that of co-star Ricardo Montalbán. The show's popularity waned after this move, and it was soon cancelled.
He starred in the 1980 movie "Forbidden Zone", and appeared in "", and episodes of "Diff'rent Strokes" and "Taxi". He later played the role of the character Rumpelstiltskin in the Shelly Duvall's "Faerie Tale Theatre" episode "Rumpelstiltskin". 
In the eighties, he became popular in Spain due to his impersonations of Prime Minister Felipe González in the TV show "Viaje con nosotros" (""Travel with us""), with showman Javier Gurruchaga.
He made his final appearance in a cameo as himself in an episode of "The Ben Stiller Show".
Personal life and death.
In the early morning hours of 4 September 1993, Villechaize is believed to have first fired a shot through the sliding glass patio door in order to awaken his longtime girlfriend, Kathy Self, before shooting himself at his North Hollywood home. Self found Villechaize in his backyard, and he was pronounced dead at a North Hollywood facility. Villechaize left a suicide note saying he was despondent over longtime health problems. Villechaize was suffering from chronic pain due to having normal-sized internal organs putting increasing pressure on his small body. According to Self, Villechaize often slept in a kneeling position so he could breathe more easily.
Ten years earlier, Haywood Nelson, star of "What's Happening!!", had interviewed him about his many suicide attempts for a program entitled "That Teen Show", which included messages directed at depressed and suicide-prone teenagers. Villechaize said then that he had learned to love life.
At the time of his suicide, Cartoon Network was in negotiations for him to co-star in "Space Ghost Coast to Coast", which was in pre-production at the time. Villechaize would have voiced Space Ghost's sidekick on the show.
His ashes were sprinkled into the Pacific Ocean off Point Fermin in San Pedro, Los Angeles, California. 
In a March 2012 "New York Times" interview, Peter Dinklage revealed that he and Sacha Gervasi had spent several years writing a script about Villechaize. Gervasi, a director and journalist, conducted a lengthy interview with Villechaize just prior to the latter's suicide; according to Dinklage, "fter he killed himself, Sacha realized Hervé's interview was a suicide note". The film, to be entitled "My Dinner with Hervé", is based on the last few days of Villechaize's life, and is meant to star Dinklage in the title role if produced.

</doc>
<doc id="58079" url="https://en.wikipedia.org/wiki?curid=58079" title="Five Dynasties and Ten Kingdoms period">
Five Dynasties and Ten Kingdoms period

The Five Dynasties and Ten Kingdoms period, also called Five Dynasties, was an era of political upheaval in 10th-century imperial China. During this period, five states quickly succeeded one another in the Chinese Central Plain, while more than a dozen concurrent states were established elsewhere, mainly in south China. 
Traditionally, the era started with the fall of the Tang dynasty in 907 AD and ended with the founding of the Song dynasty in 960. However, many states were "de facto" independent long before 907, and the last of the Five Dynasties and Ten Kingdoms states, Northern Han, was not vanquished until 979. 
The states.
The Five Dynasties were:
The Ten Kingdoms were:
Only ten are traditionally listed, hence the era's name, "Ten Kingdoms"; some historians, such as Bo Yang, count eleven, including Yan and Qi but not the Northern Han, viewing it as simply a continuation of Later Han. This era also led to the founding of the Liao dynasty in the north.
Other regimes during this period were Yan, Qi, Zhao, Yiwu Jiedushi, Dingnan Jiedushi, Wuping Jiedushi, Qingyuan Jiedushi, Yin, Ganzhou, Shazhou, and Liangzhou.
Background.
Towards the end of the Tang, the imperial government granted increased powers to the jiedushi, the regional military governors. The Huang Chao Rebellion weakened the imperial government, and by the early 10th century the jiedushi commanded "de facto" independence from its authority. Thus ensued the Five Dynasties and Ten Kingdoms period.
The following were important jiedushi:
North China
South China
Northern China.
Later Liang.
During the Liang Dynasty, the warlord Zhu Wen held the most power in northern China. Although he was originally a member of Huang Chao's rebel army, he took on a crucial role in suppressing the Huang Chao Rebellion. For this function, he was awarded the Xuanwu Jiedushi title. Within a few years, he had consolidated his power by destroying neighbours and forcing the move of the imperial capital to Luoyang, which was within his region of influence. In 904, he executed Emperor Zhaozong of Tang and made his 13-year-old son a subordinate ruler. Three years later, he induced the boy emperor to abdicate in his favour. He then proclaimed himself emperor, thus beginning the Later Liang.
Later Tang.
During the Tang Dynasty, rival warlords declared independence in their governing provinces—not all of whom recognized the emperor's authority. Li Cunxu and Liu Shouguang (劉守光) fiercely fought the regime forces to conquer northern China; Li Cunxu succeeded. He defeated Liu Shouguang (who had proclaimed a Yan Empire in 911) in 915, and declared himself emperor in 923; within a few months, he brought down the Later Liang regime. Thus began the Later Tang—the first in a long line of conquest dynasties. After reuniting much of northern China, Cunxu conquered Former Shu in 925, a regime that had been set up in Sichuan.
Later Jin.
The Later Tang had a few years of relative calm, followed by unrest. In 934, Sichuan again asserted independence. In 936, Shi Jingtang, a Shatuo jiedushi from Taiyuan, was aided by the Liao dynasty in a rebellion against the dynasty. In return for their aid, Shi Jingtang promised annual tribute and the Sixteen Prefectures (modern northern Hebei and Beijing) to the Khitans. The rebellion succeeded; Shi Jingtang became emperor in this same year.
Not long after the founding of the Later Jin, the Khitans regarded the emperor as a proxy ruler for China proper. In 943, the Khitans declared war and within three years seized the capital, Kaifeng, marking the end of Later Jin. But while they had conquered vast regions of China, the Khitans were unable or unwilling to control those regions and retreated from them early in the next year.
Later Han.
To fill the power vacuum, the jiedushi Liu Zhiyuan entered the imperial capital in 947 and proclaimed the advent of the Later Han, establishing a third successive Shatuo reign. This was the shortest of the five dynasties. Following a coup in 951, General Guo Wei, a Han Chinese, was enthroned, thus beginning the Later Zhou. However, Liu Chong, a member of the Later Han imperial family, established a rival Northern Han regime in Taiyuan and requested Khitan aid to defeat the Later Zhou.
Later Zhou.
After the death of Guo Wei in 951, his adopted son Chai Rong succeeded the throne and began a policy of expansion and reunification. In 954, his army defeated combined Khitan and Northern Han forces, ending their ambition of toppling the Later Zhou. Between 956 and 958, forces of Later Zhou conquered much of Southern Tang, the most powerful regime in southern China, which ceded all the territory north of the Yangtze in defeat. In 959, Chai Rong attacked the Liao in an attempt to recover territories ceded during the Later Jin. After many victories, he succumbed to illness.
In 960, the general Zhao Kuangyin staged a coup and took the throne for himself, founding the Northern Song Dynasty. This is the official end of the Five Dynasties and Ten Kingdoms period. During the next two decades, Zhao Kuangyin and his successor Zhao Kuangyi defeated the other remaining regimes in China proper, conquering Northern Han in 979, and reunifying China completely in 982.
Northern Han.
Though considered one of the ten kingdoms, the Northern Han was based in the traditional Shatuo stronghold of Shanxi. It was created after the last of three dynasties created by Shatuo Turks fell to the Han-governed Later Zhou in 951. With the protection of the powerful Liao, the Northern Han maintained nominal independence until the Song Dynasty wrested it from the Khitan in 979.
Southern China: The Ten Kingdoms.
Unlike the dynasties of northern China, which succeeded one other in rapid succession, the regimes of South China were generally concurrent, each controlling a specific geographical area. These were known as "The Ten Kingdoms".
Wu.
The Kingdom of Wu (902–937) was established in modern-day Jiangsu, Anhui, and Jiangxi. It was founded by Yang Xingmi, who became a Tang Dynasty military governor in 892. The capital was initially at Guangling (present-day Yangzhou) and later moved to Jinling (present-day Nanjing). The kingdom fell in 937 when it was taken from within by the founder of the Southern Tang.
Wuyue.
The Kingdom of Wuyue was the longest-lived (907–978) and among the most powerful of the southern states. Wuyue was known for its learning and culture. It was founded by Qian Liu, who set up his capital at Xifu (modern-day Hangzhou). It was based mostly in modern Zhejiang province but also held parts of southern Jiangsu. Qian Liu was named the Prince of Yue by the Tang emperor in 902; the Prince of Wu was added in 904. After the fall of the Tang Dynasty in 907, he declared himself king of Wuyue. Wuyue survived until the eighteenth year of the Song dynasty, when Qian Shu surrendered to the expanding dynasty.
Min.
The Kingdom of Min (909–945) was founded by Wang Shenzhi, who named himself the Prince of Min with its capital at Changle (present-day Fuzhou). One of Shenzhi’s sons proclaimed the independent state of Yin in the northeast of Min territory. The Southern Tang took that territory after the Min asked for help. Despite declaring loyalty to the neighboring Wuyue, the Southern Tang finished its conquest of Min in 945.
Southern Han.
The Southern Han (917–971) was founded in Guangzhou (also known as Canton) by Liu Yan. His brother, Liu Yin, was named regional governor by the Tang court. The kingdom included Guangdong, Guangxi, Hanoi, and Hainan.
Chu.
The Chu (927–951) was founded by Ma Yin with the capital at Changsha. The kingdom held Hunan and northeastern Guangxi. Ma was named regional military governor by the Tang court in 896, and named himself the Prince of Chu with the fall of the Tang in 907. This status as the Prince of Chu was confirmed by the Later Tang in 927. The Southern Tang absorbed the state in 951 and moved the royal family to its capital in Nanjing, although Southern Tang rule of the region was temporary, as the next year former Chu military officers under the leadership of Liu Yan seized the territory. In the waning years of the Five Dynasties and Ten Kingdoms period, the region was ruled by Zhou Xingfeng.
Northern Han.
The Northern Han was founded by Liu Min (劉旻), formerly known as Liu Chong (劉崇), and lasted from 951 to 979.
It has the capital at Taiyuan.
Jingnan (also known as Nanping).
The smallest of the southern states, Jingnan (924–963), was founded by Gao Jichang. It was based in Jiangling and held two other districts southwest of present-day Wuhan in Hubei. Gao was in the service of the Later Liang (the successor of the Tang in North China). Gao’s successors claimed the title of King of Nanping after the fall of the Later Liang in 924. It was a small and weak kingdom, and thus tried to maintain good relations with each of the Five Dynasties. The kingdom fell to advancing armies of the Song in 963.
Former Shu.
Former Shu (907–25) was founded after the fall of the Tang Dynasty by Wang Jian, who held his court in Chengdu. The kingdom held most of present-day Sichuan, western Hubei, and parts of southern Gansu and Shaanxi. Wang was named military governor of western Sichuan by the Tang court in 891. The kingdom fell when his son surrendered in the face of an advance by the Later Tang in 925.
Later Shu.
The Later Shu (935–965) is essentially a resurrection of the previous Shu state that had fallen a decade earlier to the Later Tang. Because the Later Tang was in decline, Meng Zhixiang found the opportunity to reassert Shu’s independence. Like the Former Shu, the capital was at Chengdu and it basically controlled the same territory as its predecessor. The kingdom was ruled well until forced to succumb to Song armies in 965.
Southern Tang.
The Southern Tang (937–975) was the successor state of Wu as Li Bian (Emperor Liezu) took the state over from within in 937. Expanding from the original domains of Wu, it eventually took over Yin, Min, and Chu, holding present-day southern Anhui, southern Jiangsu, much of Jiangxi, Hunan, and eastern Hubei at its height. The kingdom became nominally subordinate to the expanding Song in 961 and was invaded outright in 975, when it was formally absorbed into Song China.
Transitions between kingdoms.
Although more stable than northern China as a whole, southern China was also torn apart by warfare. Wu quarrelled with its neighbours, a trend that continued as Wu was replaced with Southern Tang. In the 940s Min and Chu underwent internal crises which Southern Tang handily took advantage of, destroying Min in 945 and Chu in 951. Remnants of Min and Chu, however, survived in the form of Qingyuan Jiedushi and Wuping Jiedushi for many years after. With this, Southern Tang became the undisputedly most powerful regime in southern China. However, it was unable to defeat incursions by the Later Zhou between 956 and 958, and ceded all of its land north of the Yangtze River.
The Song dynasty, established in 960, was determined to reunify China. Jingnan and Wuping Jiedushi were swept away in 963, Later Shu in 965, Southern Han in 971, and Southern Tang in 975. Finally, Wuyue and Qingyuan Jiedushi gave up their land to Northern Song in 978, bringing all of southern China under the control of the central government.
In common with other periods of fragmentation, the Five Dynasties and Ten Kingdoms period resulted in a division between northern and southern China. The greater stability of the Ten Kingdoms, especially the longevity of Wu Yue and Southern Han, would contribute to the development of distinct regional identities within China.

</doc>
<doc id="58084" url="https://en.wikipedia.org/wiki?curid=58084" title="Vladimir Atlasov">
Vladimir Atlasov

Vladimir Vasilyevich Atlasov or Otlasov ( or Отла́сов) (born in Veliky Ustyug between 1661 and 1664—died in 1711) was a Siberian Cossack who was the first Russian to organize systematic exploration of the Kamchatka Peninsula. Atlasov Island, an uninhabited volcanic island off the southern tip of Kamchatka, is named after him.
He is first heard of around 1682 collecting Yasak on the Aldan River and one of the Uda Rivers. In 1695 the voyevoda of Yakutsk appointed him prikazshchik of Anadyrsk. The Russians here had heard reports of a 'Kamchatka River' to the south and were already collecting yasak on the headwaters of the rivers that flow south toward Kamchatka. At least one of them had followed the Penzhina River to the Sea of Okhotsk. In 1696 he sent Luka Morozko south to explore. Morozko got as far south as the Tegil River on the west side of the peninsula and returned with some 'mysterious writings', apparently from a wrecked Japanese ship. In 1697 Atlasov set off south with 65 serving-men and 60 Yukaghirs. Travelling on reindeer, they reached the mouth of the Penzhina River. He went down the west coast for two weeks and then crossed to the east coast. (Lantzeff has this as February 1697 on the Olyutorsky Gulf, but the Russian wiki has him leaving in the spring of 1697 and the Olyutorsky Gulf is rather far to the northeast). He left Morzoko to explore the east side and returned to the west side, but Morozko had to be recalled to deal with a Yukaghir mutiny (at the Palana River). Going south to the Tegil River, he heard reports of the Kamchatka River and recrossed the Central Range to the Kamchatka where he met the Itelmens for the first time. He made an alliance with one clan and went downriver and burned a village of their enemies. Returning, he learned that some Koryaks had stolen his reindeer. He chased them, killed about 150 and retrieved his reindeer. Continuing down the west side he reached the Icha River where he rescued or captured a Japanese sailor who had been shipwrecked. Further south he reached the Golygina River area, from which he was able to see Atlasov Island. Here he met the first Ainu and managed to kill fifty of them. Returning north to the Icha, he sent a party of men over the mountains to build an ostrog at Verkhnekamchatsk on the upper Kamchatka. Here he decided to return to Anadyrsk, either under pressure of his men or because he was running short of gunpowder and lead.
He reached Anadyrsk in July 1699 and wrote a report. He was in Yakutsk in June 1700 and in February 1701 he reached Moscow where he presented his report. He was promoted to Golova and sent back to administer Kamchatka. On the Angara River in 1701 he met and plundered a merchant's boat loaded with Chinese goods. For this he and his men were thrown in jail. Kamchatka became increasingly disorderly and in 1707 Atlasov was released and sent to Kamchatka to restore order. On the journey his methods were so rough that most of his men sent a letter of protest to Yakutsk. He pacified the natives to some degree, but in December 1707 his own cossacks revolted and imprisoned him. He escaped (from Verkhnekamchatsk) and went downriver to Nizhnekamchatsk, but the local commander refused to step aside and give him command. What he did for the next four years is uncertain. In January 1711 he was murdered in his sleep by another band of mutineers.

</doc>
<doc id="58088" url="https://en.wikipedia.org/wiki?curid=58088" title="Sakhalin">
Sakhalin

Sakhalin (, ) is a large Russian island in the North Pacific Ocean, lying between 45°50' and 54°24' N. It is Russia's largest island, and is administered as part of Sakhalin Oblast. Sakhalin, which is about one fifth the size of Japan, is just off the east coast of Russia, and just north of Japan.
The indigenous peoples of the island are the Ainu, Oroks and Nivkhs. Sakhalin has been claimed by both Russia and Japan over the course of the 19th and 20th centuries. This has led to bitter disputes between the two countries over control of the island. Russia seized the island from the Japanese near the end of World War II. Most Ainu moved to Hokkaido when the Japanese were displaced from the island in 1949.
Etymology.
The island is known in Russian as Сахалин ("Sakhalin"). In Chinese, it is known as Kuye (). In Japanese, it is known as or, borrowing the Russian appellation, as . The spelling Saghalien may be found in historical texts.
The European names derive from misinterpretation of a Manchu name "sahaliyan ula angga hada" ("peak/craggy rock at the mouth of the Amur River"). "Sahaliyan", the word that has been borrowed in the form of "Sakhalin", means "black" in Manchu and is the proper Manchu name of the Amur River ( "sahaliyan ula", literally "Black River"; see Sikhote-Alin). Its Japanese name, , supposedly comes from Ainu "kamuy kar put ya mosir" (, shortened to "Karput" ), which means "the island a god has created at the estuary (of the Amur River)." The name was used by the Japanese during their possession of its southern part (1905–1945).
History.
Early history.
Sakhalin was inhabited in the Neolithic Stone Age. Flint implements such as those found in Siberia have been found at Dui and Kusunai in great numbers, as well as polished stone hatchets similar to European examples, primitive pottery with decorations like those of the Olonets, and stone weights used with fishing nets. A later population familiar with bronze left traces in earthen walls and kitchen-middens on Aniva Bay.
Among the indigenous people of Sakhalin are the Ainu in the southern half, the Oroks in the central region, and the Nivkhs in the north. Chinese chronicled the Xianbei and Hezhe tribes, who had a way of life based on fishing.
The Mongol Empire made some efforts to subjugate the native people of Sakhalin starting in about 1264 CE. According to Yuanshi, the official history of the Yuan dynasty, the Mongols militarily subdued the "Guwei" (骨嵬, "Gǔwéi"), and by 1308, all inhabitants of Sakhalin had submitted to the Yuan. The Nivkhs and the Oroks were subjugated earlier, whereas the Ainu people submitted to the Mongols later. Following their subjugation, "Gǔwéi" elders made tributary visits to Yuan posts located at Wuleihe, Nanghar, and Boluohe until the end of the Mongol Yuan dynasty in China (1368). In the early Ming dynasty (1368–1644), the tributary relationship was re-established. By the middle of the 15th century, following the introduction of Chinese political and commercial institutions in the Amur region, the Sakhalin Ainu were making frequent tributary visits to Chinese-controlled outposts. Chinese of the Ming dynasty knew the island as Kuyi (苦夷 "Kǔyí") or Kuwu (), and later as Kuye (), as it is known today. There is some evidence that the Ming eunuch Admiral Yishiha reached Sakhalin in 1413 during one of his expeditions to the lower Amur, and granted Ming titles to a local chieftain. Under the Ming dynasty, commerce in Northeast Asia and Sakhalin was placed under the "system for subjugated peoples", or "ximin tizhi". This suggests that the island was at least nominally under the administration of the Nurgan Regional Military Commission, which was established by Yishiha near today's village of Tyr on the Siberian mainland in 1411, and continued operating until the mid-1430s. A Ming boundary stone still exists on the island.
European and Japanese exploration.
According to Wei Yuan's work "Military history of the Qing dynasty" (), the Later Jin sent 400 troops to Sakhalin in 1616 in response to Japanese activity in the area, but later withdrew, judging there to be no major threat to their control of the island.
In an early colonization attempt, a Japanese settlement was established at Ootomari on Sakhalin's southern end in 1679. Cartographers of the Matsumae clan created a map of the island and called it "Kita-Ezo" (Northern Ezo, Ezo being the old name for the islands north of Honshu). The 1689 Nerchinsk Treaty between Russia and China, which defined the Stanovoy Mountains as their mutual border, made no explicit mention of the island; however, the Qing dynasty (1644–1912) did consider the island to be part of its territory, and enacted policies of a pattern similar to the previous Ming dynasty, which drew Sakhalin further into the "system for subjugated peoples". Local people were forced to pay tribute at Qing posts, and Qing officials sometimes granted titles to local elders, entrusting them with the task of "keeping the peace". By the mid-18th century, Qing officials had registered 56 surname groups; of these, Qing sources note that six clans and 148 households were those of Ainu and Nivkh who came under the Qing administrative umbrella. However, since the Chinese government did not have a military presence on the island, Japanese attempts at colonization continued.
The first European known to visit Sakhalin was Martin Gerritz de Vries, who mapped Cape Patience and Cape Aniva on the island's east coast in 1643. The Dutch captain, however, was unaware that it was an island, and 17th century maps usually showed these points (and often Hokkaido as well) as being part of the mainland.
As part of a nationwide Sino-French cartographic program, the Jesuits Jean-Baptiste Régis, Pierre Jartoux, and Xavier Ehrenbert Fridelli joined a Chinese team visiting the lower Amur (known to them under its Manchu name, Saghalien Ula, i.e. the "Black River"), in 1709, and learned of the existence of the nearby offshore island from the "Ke tcheng" natives of the lower Amur. The Jesuits were told that the islanders were believed to be good at reindeer husbandry. They reported that the mainlanders used a variety of names to refer to the island, but "Saghalien anga bata" (i.e. "the Island the mouth of the Black River") was the most common, while the name "Huye" (presumably, "Kuye", 庫頁), which they had heard in Beijing, was completely unknown to the locals.
The Jesuits did not have a chance to visit the island personally, and the geographical information provided by the "Ke tcheng" people and Manchus who had been to the island was insufficient to allow them to identify it as the land visited by de Vries in 1643. As a result, many 17th century maps showed a rather strangely shaped Sakhalin, which included only the northern half of the island (with Cape Patience), while Cape Aniva, discovered by de Vries, and the "Black Cape" (Cape Crillon) were thought to be part of the mainland.
It was not until the 1787 expedition of Jean-François de La Pérouse that the island began to resemble something of its true shape on European maps. Though unable to pass through its northern "bottleneck" due to contrary winds, La Perouse charted most of the Strait of Tartary, and islanders he encountered near today's Strait of Nevelskoy told him that the island was called "Tchoka" (or at least that is how he recorded the name in French), and it was used on some maps thereafter.
The Russian explorer Adam Johann von Krusenstern visited Sakhalin in 1805, but regarded it as a peninsula.
Alarmed by the visits of European powers, Japan proclaimed its sovereignty over the whole island in 1807. Most Japanese sources claim Mamiya Rinzō as the true discoverer of the Strait of Tartary, in 1809.
Russo-Japanese rivalry.
On the basis of its belief that it was an extension of Hokkaido, both geographically and culturally, Japan again proclaimed sovereignty over the whole island (as well as the Kuril Islands chain) in 1845, in the face of competing claims from Russia. In 1849, however, the Russian navigator Gennady Nevelskoy recorded the existence and navigability of the strait later given his name, and — in defiance of the Qing and Japanese claims — Russian settlers began establishing coal mines, administration facilities, schools, and churches on the island.
In 1855, Russia and Japan signed the Treaty of Shimoda, which declared that nationals of both countries could inhabit the island: Russians in the north, and Japanese in the south, without a clearly defined boundary between. Russia also agreed to dismantle its military base at Ootomari. Following the Opium War, Russia forced China to sign the Treaty of Aigun (1858) and the Convention of Peking (1860), under which China lost to Russia all claims to territories north of Heilongjiang (Amur) and east of Ussuri, including Sakhalin.
In 1857 the Russians established a "katorga" labor camp (penal colony) on Sakhalin. Japan proclaimed its sovereignty over Sakhalin (which they called Karafuto) yet again in 1865, and the government built a stele announcing the claim at the northern extremity of the island.
The island remained under shared sovereignty until the signing of the 1875 Treaty of Saint Petersburg, in which Japan surrendered its claims in Sakhalin to Russia in exchange for the Kuril Islands.
Whaling.
Between 1848 and 1902, American whaleships hunted whales off Sakhalin. They cruised for bowhead and gray whales to the north and right whales to the east and south. On 24 June 1855, the ship "Jefferson" (396 tons), of New London, was wrecked on Cape Elizabeth, the northern point of the island, during a fog. All hands were saved as well as 300 barrels of whale oil.
Division.
Japanese forces invaded and occupied Sakhalin in the closing stages of the Russo-Japanese War. Per the Treaty of Portsmouth of 1905, the southern part of the island below the 50th parallel north reverted to Japan, while Russia retained the northern three-fifths. In 1920, during the Siberian Intervention, Japan again occupied the northern part of the island, returning it to the Soviet Union in 1925.
South Sakhalin was administrated by Japan as Karafuto Prefecture (), with the capital at Toyohara (today's Yuzhno-Sakhalinsk). A large number of migrants were brought in from Korea.
The northern, Russian, half of the island formed Sakhalin Oblast, with the capital at Aleksandrovsk-Sakhalinsky.
Second World War.
In August 1945, after repudiating the Soviet–Japanese Neutrality Pact, the Soviet Union invaded southern Sakhalin. The Soviet attack started on August 11, 1945, a few days before the surrender of Japan. The Soviet 56th Rifle Corps, part of the 16th Army, consisting of the 79th Rifle Division, the 2nd Rifle Brigade, the 5th Rifle Brigade and the 214 Armored Brigade, attacked the Japanese 88th Infantry Division. Although the Soviet Red Army outnumbered the Japanese by three to one, they advanced only slowly due to strong Japanese resistance. It was not until the 113th Rifle Brigade and the 365th Independent Naval Infantry Rifle Battalion from Sovetskaya Gavan landed on Tōro, a seashore village of western Karafuto on August 16 that the Soviets broke the Japanese defense line. Japanese resistance grew weaker after this landing. Actual fighting continued until August 21. From August 22 to August 23, most remaining Japanese units agreed to a ceasefire. The Soviets completed the conquest of Karafuto on August 25, 1945 by occupying the capital of Toyohara.
Of the approximately 400,000 people - mostly Japanese and Korean - who lived on South Sakhalin in 1944, about 100,000 were evacuated to Japan during the last days of the war. The remaining 300,000 stayed behind, some for several more years. While the vast majority of Sakhalin Japanese and Koreans were gradually repatriated between 1946 and 1950, tens of thousands of Sakhalin Koreans (and a number of their Japanese spouses) remained in the Soviet Union.
No final peace treaty has been signed and the status of four neighboring islands remains disputed. Japan renounced its claims of sovereignty over southern Sakhalin and the Kuril Islands in the Treaty of San Francisco (1951), but maintains that the four offshore islands of Hokkaido currently administered by Russia were not subject to this renunciation. Japan has granted mutual exchange visas for Japanese and Ainu families divided by the change in status. Recently, economic and political cooperation has gradually improved between the two nations despite disagreements.
Recent history.
On 1 September 1983, the Korean Air Flight 007, a South Korean civilian airliner, flew over Sakhalin and was shot down by the Soviet Union, just west of Sakhalin Island, near the smaller Moneron Island; the Soviet Union claimed it was a spy plane. All 269 passengers and crew died, including a U.S. Congressman, Larry McDonald.
On 28 May 1995, a magnitude 7.6 earthquake occurred, killing 2,000 people in the town of Neftegorsk.
Geography.
Sakhalin is separated from the mainland by the narrow and shallow Strait of Tartary, which often freezes in winter in its narrower part, and from Hokkaido, (Japan) by the Soya Strait or La Pérouse Strait. Sakhalin is the largest island in Russia, being long, and wide, with an area of .
Its orography and geological structure are imperfectly known. One theory is that Sakhalin arose from the Sakhalin island arc. Nearly two-thirds of Sakhalin is mountainous. Two parallel ranges of mountains traverse it from north to south, reaching . The Western Sakhalin Mountains peak in Mount Ichara, , while the Eastern Sakhalin Mountains's highest peak, Mount Lopatin , is also the island's highest mountain. Tym-Poronaiskaya Valley separates the two ranges. Susuanaisky and Tonino-Anivsky ranges traverse the island in the south, while the swampy Northern-Sakhalin plain occupies most of its north.
Crystalline rocks crop out at several capes; Cretaceous limestones, containing an abundant and specific fauna of gigantic ammonites, occur at Dui on the west coast; and Tertiary conglomerates, sandstones, marls and clays, folded by subsequent upheavals, are found in many parts of the island. The clays, which contain layers of good coal and an abundant fossil vegetation, show that during the Miocene period, Sakhalin formed part of a continent which comprised north Asia, Alaska and Japan, and enjoyed a comparatively warm climate. The Pliocene deposits contain a mollusc fauna more Arctic than that which exists at the present time, indicating that the connection between the Pacific and Arctic Oceans was probably broader than it is now.
Main rivers: The Tym, long and navigable by rafts and light boats for , flows north and north-east with numerous rapids and shallows, and enters the Sea of Okhotsk. The Poronai River flows south-south-east to the Gulf of Patience or Shichiro Bay, on the south-east coast. Three other small streams enter the wide semicircular Gulf of Aniva or Higashifushimi Bay at the southern extremity of the island.
The northernmost point of Sakhalin is Cape of Elisabeth on the Schmidt Peninsula, while Cape Crillon is the southernmost point of the island.
Sakhalin has two smaller islands associated with it, Moneron Island and Ush Island. Moneron, the only land mass in the Tatar strait, long and wide, is about west from the nearest coast of Sakhalin and from the port city of Nevelsk. Ush Island is an island off of the northern coast of Sakhalin.
Demographics.
At the beginning of the 20th century, some 32,000 Russians (of whom over 22,000 were convicts) inhabited Sakhalin along with several thousand native inhabitants. By 2002 the island's population had grown to 546,695, 83% of whom were ethnic Russians, followed by about 30,000 Koreans (5.5%). Smaller minorities were Ukrainians, Tatars, Yakuts and Evenks. The native inhabitants consist of some 2,000 Nivkhs and 750 Oroks. The Nivkhs in the north support themselves by fishing and hunting. In 2008 there were 6,416 births and 7,572 deaths.
The administrative center of the oblast, Yuzhno-Sakhalinsk, a city of about 175,000, has a large Korean minority, typically referred to as Sakhalin Koreans, who were forcibly brought by the Japanese during World War II to work in the coal mines. Most of the population lives in the southern half of the island, centered mainly around Yuzhno-Sakhalinsk and two ports, Kholmsk and Korsakov (population about 40,000 each).
The 400,000 Japanese inhabitants of Sakhalin (including all indigenous Ainu) were deported following the conquest of the southern portion of the island by the Soviet Union in 1945 at the end of World War II.
Climate.
The Sea of Okhotsk ensures Sakhalin has a cold and humid climate, ranging from humid continental (Köppen "Dfb") in the south to subarctic ("Dfc") in the centre and north. The maritime influence makes summers much cooler than in similar-latitude inland cities such as Harbin or Irkutsk, but makes the winters much more snowy and a few degrees warmer than in interior East Asian cities at the same latitude. Summers are foggy with little sunshine.
Precipitation is heavy, owing to the strong onshore winds in summer and the high frequency of North Pacific storms affecting the island in the autumn. It ranges from around on the northwest coast to over in southern mountainous regions. In contrast to interior east Asia with its pronounced summer maximum, onshore winds ensure Sakhalin has year-round precipitation with a peak in the autumn.
Flora and fauna.
The whole of the island is covered with dense forests, mostly coniferous. The Yezo (or Yeddo) spruce ("Picea jezoensis"), the Sakhalin fir ("Abies sachalinensis") and the Dahurian larch ("Larix gmelinii") are the chief trees; on the upper parts of the mountains are the Siberian dwarf pine ("Pinus pumila") and the Kurile bamboo ("Sasa kurilensis"). Birches, both Siberian silver birch ("Betula platyphylla") and Erman's birch ("B. ermanii"), poplar, elm, bird cherry ("Prunus padus"), Japanese yew ("Taxus cuspidata") and several willows are mixed with the conifers; while farther south the maple, rowan and oak, as also the Japanese "Panax ricinifolium", the Amur cork tree ("Phellodendron amurense"), the Spindle ("Euonymus macropterus") and the vine ("Vitis thunbergii") make their appearance. The underwoods abound in berry-bearing plants (e.g. cloudberry, cranberry, crowberry, red whortleberry), red-berried elder ("Sambucus racemosa"), wild raspberry and Spiraea.
Bears, foxes, otters and sables are numerous, as are reindeer in the north, and musk deer, hares, squirrels, rats and mice everywhere. The bird fauna is mostly the common east Siberian, but there are some endemic or near-endemic breeding species, notably the endangered Nordmann's greenshank ("Tringa guttifer") and the Sakhalin leaf warbler ("Phylloscopus borealoides"). The rivers swarm with fish, especially species of salmon ("Oncorhynchus"). Numerous whales visit the sea coast, including the critically endangered Western Pacific gray whale, for which the coast of Sakhalin is the only known feeding ground. Other endangered whale species known to occur in this area are the North Pacific right whale, the bowhead whale and the beluga whale.
Transport.
Sea.
Transport, especially by sea, is an important segment of the economy. Nearly all the cargo arriving for Sakhalin (and the Kuril Islands) is delivered by cargo boats, or by ferries, in railway wagons, through the SSC train ferry from the mainland port of Vanino to Kholmsk. The ports of Korsakov and Kholmsk are the largest and handle all kinds of goods, while coal and timber shipments often go through other ports. In 1999, a ferry service was opened between the ports of Korsakov and Wakkanai, Japan, and operated through the autumn of 2015, when service was suspended.
Sakhalin's main shipping company is Sakhalin Shipping Company, headquartered in Kholmsk on the island's west coast.
Rail.
About 30% of all inland transport volume is carried by the island's railways, most of which are organized as the Sakhalin Railway (Сахалинская железная дорога), which is one of the 17 territorial divisions of the Russian Railways.
The Sakhalin Railway network extends from Nogliki in the north to Korsakov in the south. Sakhalin's railway has a connection with the rest of Russia via a ferry operating between Vanino and Kholmsk.
, the railways are only now being converted from the Japanese gauge to the Russian gauge. The original Japanese D51 steam locomotives were used by the Soviet Railways until 1979.
Besides the main network run by the Russian Railways, until December 2006 the local oil company (Sakhalinmorneftegaz) operated a corporate narrow-gauge line extending for from Nogliki further north to Okha (Узкоколейная железная дорога Оха — Ноглики). During the last years of its service, it gradually deteriorated; the service was terminated in December 2006, and the line was dismantled in 2007–2008.
Air.
Sakhalin is connected by regular flights to Moscow, Khabarovsk, Vladivostok and other cities of Russia. Yuzhno-Sakhalinsk Airport has regularly scheduled international flights to Hakodate, Japan, and Seoul and Busan, South Korea. There are also charter flights to the Japanese cities of Tokyo, Niigata, and Sapporo and to the Chinese cities of Shanghai, Dalian and Harbin. The island was formerly served by Alaska Airlines from Anchorage, Petropavlovsk and Magadan.
Fixed links.
The idea of building a fixed link between Sakhalin and the Russian mainland was first mooted in the 1930s. In the 1940s, an abortive attempt was made to link the island via a long undersea tunnel. The workers supposedly made it almost to the half-way point before the project was abandoned under Nikita Khrushchev. In 2000, the Russian government revived the idea, adding a suggestion that a 40-km-long bridge could be constructed between Sakhalin and the Japanese island of Hokkaidō, providing Japan with a direct connection to the Euro-Asian railway network. It was claimed that construction work could begin as early as 2001. The idea was received skeptically by the Japanese government and appears to have been shelved, probably permanently, after the cost was estimated at as much as US$50 billion.
In November 2008, Russian president Dmitry Medvedev announced government support for the construction of the Sakhalin Tunnel, along with the required re-gauging of the island's railways to Russian standard gauge, at an estimated cost of 300–330 billion roubles.
In July 2013, Russian Far East development minister Viktor Ishayev proposed a rail bridge to link Sakhalin with the Russian mainland. He also again suggested a bridge between Sakhalin and Hokkaidō, which could potentially create a continuous rail corridor between Europe and Japan.
Economy.
Sakhalin is a classic "primary sector of the economy" relying on oil and gas exports, coal mining, forestry, and fishing. Limited quantities of rye, wheat, oats, barley and vegetables are grown, although the growing season averages less than 100 days.
Following the collapse of the Soviet Union and economic liberalization, Sakhalin has experienced an oil boom with extensive petroleum exploration and mining by most large oil multinational corporations. The oil and natural gas reserves contain an estimated 14 billion barrels (2.2 km3) of oil and 96 trillion cubic feet (2,700 km3) of gas and are being developed under production-sharing agreement contracts involving international oil companies like ExxonMobil and Shell.
In 1996, two large consortia signed contracts to explore for oil and gas off the northeast coast of the island, Sakhalin-I and Sakhalin-II. The two consortia were estimated to spend a combined US$21 billion on the two projects which almost doubled to $37 billion as of September 2006, triggering Russian governmental opposition. The cost will include an estimated US$1 billion to upgrade the island's infrastructure: roads, bridges, waste management sites, airports, railways, communications systems, and ports. In addition, Sakhalin-III-through-VI are in various early stages of development.
The Sakhalin I project, managed by Exxon Neftegas Limited (ENL), completed a production-sharing agreement (PSA) between the Sakhalin I consortium, the Russian Federation, and the Sakhalin government. Russia is in the process of building a pipeline across the Tatar Strait from Sakhalin Island to De-Kastri terminal on the Russian mainland. From De-Kastri, the resource will be loaded onto tankers for transport to East Asian markets, namely Japan, South Korea and China.
The second consortium, Sakhalin Energy Investment Company Ltd (Sakhalin Energy), is managing the Sakhalin II project. It completed the first ever production-sharing agreement (PSA) with the Russian Federation. Sakhalin Energy will build two 800-km pipelines running from the northeast of the island to Prigorodnoye (Prigorodnoe) in Aniva Bay at the southern end. The consortium will also build, at Prigorodnoye, the first ever liquefied natural gas (LNG) plant to be built in Russia. The oil and gas are also bound for East Asian markets.
Sakhalin II has come under fire from environmental groups, namely Sakhalin Environment Watch, for dumping dredging material in Aniva Bay. The groups were also worried about the offshore pipelines interfering with the migration of whales off the island. The consortium has (as of January 2006) re-routed the pipeline to avoid the whale migration. After a doubling in the projected cost, the Russian government threatened to halt the project for environmental reasons. There have been suggestions that the Russian government is using the environmental issues as a pretext for obtaining a greater share of revenues from the project and/or forcing involvement by the state-controlled Gazprom. The cost overruns (at least partly due to Shell's response to environmental concerns), are reducing the share of profits flowing to the Russian treasury.
In 2000, the oil and gas industry accounted for 57.5% of Sakhalin's industrial output. By 2006, it is expected to account for 80% of the island's industrial output. Sakhalin's economy is growing rapidly thanks to its oil and gas industry. By 2005, the island had become the largest recipient of foreign investment in Russia, followed by Moscow. Unemployment in 2002 was only 2%.
As of 18 April 2007, Gazprom has taken a 50% plus one share interest in Sakhalin II by purchasing 50% of Shell, Mitsui and Mitsubishi's shares.

</doc>
<doc id="58089" url="https://en.wikipedia.org/wiki?curid=58089" title="ITV (TV network)">
ITV (TV network)

ITV is a commercial TV network in the United Kingdom. Launched in 1955 as Independent Television under the auspices of the Independent Television Authority (ITA, then after the Sound Broadcasting Act 1972, Independent Broadcasting Authority, now Ofcom) to provide competition to the BBC, it is also the oldest commercial network in the UK. Since the passing of the Broadcasting Act 1990 its legal name has been Channel 3, to distinguish it from the other analogue channels at the time, namely BBC 1, BBC 2 and Channel 4. In part, the number 3 was assigned as television sets would usually be tuned so that the regional ITV station would be on the third button, with the other stations being allocated to the number within their name.
ITV is a network of television channels that operate regional television services as well as sharing programmes between each other to be displayed on the entire network. In recent years, several of these companies have merged so currently the fifteen franchises are in the hands of two companies.
The ITV network is to be distinguished from ITV plc, the company that resulted from the merger of Granada plc and Carlton Communications in 2004 and which holds the Channel 3 broadcasting licences in England, Wales, southern Scotland, the Isle of Man, the Channel Islands and Northern Ireland. With the exception of Northern Ireland, the ITV brand is the brand used by ITV plc for the Channel 3 service in these areas. In Northern Ireland, ITV plc uses the brand name UTV. STV Group plc, uses the STV brand for its two franchises of central and northern Scotland.
History.
The origins of ITV lie in the passing of the Television Act 1954, designed to break the monopoly on television held by the BBC Television Service. The act created the Independent Television Authority (ITA, then IBA after the Sound Broadcasting Act) to heavily regulate the industry and to award franchises. The first six franchises were awarded in 1954 for London, the Midlands and the North of England, with separate franchises for Weekdays and Weekends. The first ITV network to launch was London's Associated-Rediffusion on 22 September 1955, with the Midlands and North services launching in February 1956 and May 1956 respectively. Following these launches, the ITA awarded more franchises until the whole country was covered by fourteen regional stations, all launched by 1962.
The network has been modified several times through franchise reviews that have taken place in 1963, 1967, 1974, 1980 and 1991, during which broadcast regions have changed and service operators have been replaced. Only one service operator has ever been declared bankrupt, WWN in 1963, with all other operators leaving the network as a result of a franchise review. Separate weekend franchises were removed, with the exception of London, in 1964 and over the years more services were added including a teletext service and a national breakfast franchise, operating between 6:00 am and 9:25 am, in 1983. The Broadcasting Act 1990 changed the nature of ITV; the then regulator the IBA was replaced with a light-touch regulator the ITC, companies now able to purchase other ITV regional companies and franchises were now being awarded based upon a highest-bidder auction, with few safeguards in place. This heavily criticised part of the review saw four operators replaced and the operators facing different annual payments to the treasury: Central Television, for example, paid only £2000, despite holding a lucrative and large region, because they were unopposed, while Yorkshire television paid £37.7 million for a region of the same size and status due to heavy competition.
Following the 1993 changes, ITV as a network began to consolidate with several companies doing so to save money by ceasing the duplication of services present when they were all separate companies. By 2004, ITV was owned by five companies of which two, Carlton and Granada had become major players by owning between the two all the franchises in England, Wales, the Scottish borders and the Isle of Man. That same year, the two merged to form ITV plc with the only subsequent acquisition being the takeover of Channel Television, the Channel Islands franchise, in 2011.
Organisation (other networks).
The ITV Network is not owned or operated by one company, but rather by a series of licensees that provide a regional service while also broadcasting programmes across the network. Since 2016 the fifteen licences are held by two companies, with the majority held by ITV Broadcasting Limited, part of ITV plc.
The network is regulated by the media regulator Ofcom who is responsible for awarding the broadcast licences. The last major review of the Channel 3 franchises was in 1991, with all operators' licences having been renewed between 1999 and 2002 and again from 2014 without a further contest. While this has been the longest period that the ITV Network has gone without a major review of its licence holders, Ofcom announced (following consultation) that it would split the Wales and West licence from 1 January 2014, creating a national licence for Wales and joining the newly separated West region to Westcountry Television, to form a new licence for the enlarged South West of England region.
All companies holding a licence were part of the non-profit body ITV Network Limited, which commissioned and scheduled network programming, with compliance previously handled by ITV plc and Channel Television. However, due to amalgamation of several of these companies since the creation of ITV Network Limited (and given Channel Television is now owned by ITV plc), it has been replaced by an affiliation system. Approved by Ofcom, this results in ITV plc commissioning and funding the network schedule, with STV and UTV paying a fee to broadcast it. All licensees have the right to opt out of network programming (except for the national news bulletins), however many do not due to pressures from the parent company or because of limited resources. Prior to the affiliate system being introduced, STV would frequently (and sometimes controversially) opt out of several popular network programmes – such as the original run of the first series of "Downton Abbey" – citing the need to provide more Scottish content to its viewers.
As a public service broadcaster, the ITV network is obliged to broadcast programming of public importance, including news, current affairs, children's and religious programming as well as party election broadcasts on behalf of the major political parties and political events, such as the Budget. The network also needs to produce accessible output containing subtitles, signing and audio description. In exchange for this programming, the ITV network is available on all platforms free to air and can be found at the top of the EPG of all providers.
Since the launch of the platform in 1998, all of the ITV licensees have received gifted capacity on the digital terrestrial television platform. At present, the companies are able to broadcast additional channels and all choose to broadcast the ITV plc owned ITV2, ITV3, ITV4 and CITV in their region. UTV and STV (formerly Scottish Television and Grampian Television) previously broadcast their own services – UTV2 in Northern Ireland and S2 in central and northern Scotland – until 2002, when they adopted the ITV plc channels. The broadcasters all make use of the Digital 3&4 multiplex, shared with Channel 4. ITV Encore launched on June 2014 and ITVBe launched in October 2014.
ITV plc.
ITV plc owns thirteen of the fifteen franchises and broadcasts to England, Wales, southern Scotland, the Isle of Man, the Channel Islands and Northern Ireland through its subsidiary companies ITV Broadcasting Limited, Channel Television Limited and UTV Limited The company also owns the breakfast contractor that broadcasts across the network between 6:00 and 9:25am each morning using the "Good Morning Britain" (previously "Daybreak") and "Lorraine" names. The company broadcasts a centralised service under the ITV brand. In Northern Ireland, ITV uses the UTV brand name. ITV also owns UTV Ireland, UTV's sister channel in the Republic of Ireland.
The group also owns ITV Studios, the production arm of the company and formed from an amalgamation of all the production departments of the regional licenses they own. The company produces a large proportion of ITV's networked programming (around 47%, but previously as high as 66% according to some reports), with the rest coming primarily from independent suppliers (Under the Broadcasting Act 1990, at least 25% of ITV's total output must be from independent companies). ITV plc hope to increase the amount of in-house programming to as close to the 75% limit as possible.
The group has recently cut the number of regional news programmes offered from 17 in 2007 to 9 by 2009, resulting several regions being merged to form one programme, including the Border Television and Tyne Tees Television regions, the Westcountry Television and West regions and the removal of sub regional programming, with some regions only represented by pre-recorded segments.
STV Group.
STV Group plc owns two franchises, covering central and northern Scotland, through subsidiary companies STV Central and STV North, broadcasting a central service under the STV brand.
The company has had several disputes with ITV plc in recent years over network programming. STV aims to broadcast more Scottish programmes at peak times and so removed several key ITV plc programmes from their schedule in July 2009 including "The Bill", "Midsomer Murders" and "Lewis". Despite STV's explanation of expense, ITV plc were angered by the decision, as a recent schedule change had made "The Bill" central to their programming, and broadcast the programmes on ITV3 as well to ensure Scottish viewers could see the programmes. On 23 September ITV was reported to be in the process of suing STV for £20 million, as ITV plc felt dropping the shows constituted a breach of network agreements; STV subsequently counter-sued ITV plc for £35 million.
The dispute was ended in 2011 with STV agreeing to pay ITV plc £18 million. The signing of the new affiliation deal has resulted in STV paying a flat fee for all networked programming, and so to drop any programmes is unlikely due to the large costs involved.
Current licensees.
There are fourteen regional licences and one national licence for the breakfast service. Other licences exist to provide specific programming services, such as Teletext and national news, but are not listed here. All licences listed here were renewed until the end of 2014. Licences in England and Wales were held by the individual regional ITV plc owned companies prior to November 2008.
Programming.
For over 60 years of ITV, the homegrown programmes have become the best loved and remembered as well as being extremely successful. Before the 1990s, nearly all of the content for the channel was produced by the fifteen franchise licensees: the regional companies.
However, in the last decade, and following legislation in the Broadcasting Act 1990 imposing a 25% quota for commissioning of independent productions, the number of programmes from independent production companies not connected to the traditional ITV Network, has increased rapidly. Notable examples include Talkback Thames (one half of which, Thames Television, was itself a former ITV franchisee), producers of "The Bill" and co-producers of "The X Factor", and 2waytraffic (previously Celador), producers of "Who Wants to Be a Millionaire?".
From the late 1990s, ITV's long-standing commitment to strong current affairs and documentary programming began to diminish with the ending of productions such as "World in Action" (Granada Television), "This Week" (Rediffusion London/Thames Television), "First Tuesday" (Yorkshire Television), "Network First", "Survival" (Anglia Television), and "Weekend World" (LWT) and their replacement with populist shows such as "Tonight". "News at Ten" was also axed in 1999, although it was reinstated in 2008. In December 2009, the final edition of ITV's long-running arts programme, "The South Bank Show" was broadcast.
Increasingly ITV's primetime schedules are dominated by its soap operas, such as the flagship "Coronation Street" and "Emmerdale". At the start of the 21st century, Independent Television faced criticism for including a large amount of "reality TV" programmes in the schedule, such as "Celebrity Fit Club", "Celebrity Wrestling" and "Love Island". In its defence, ITV does continue to show its major strengths in the fields of sports coverage and drama productions, and it continues to schedule national news in primetime.
ITV's strong daytime line-up helped by programmes such as "This Morning", "Loose Women", "Dickinson's Real Deal" and game shows "Tipping Point" and "The Chase" are very popular, achieving the highest audience share during the daytime slot.
National and international news.
Since the network started, Independent Television News Limited (ITN) has held the contract to produce news for the ITV Network, with 30-minute national news bulletins broadcast at 1:30 pm, 6:30 pm, and 10:00 pm. These bulletins were broadcast under the ITN brand between 1955 and 1999, when a new network identity reinforced the ITV brand, resulting in the new bulletins being broadcast under the ITV News brand.
ITN has long been respected in the news industry as a source of reliable information and news, and as a result the service has won many awards for their programmes, the latest being in May 2011 when News at Ten was named best news programme by the Royal Television Society and BAFTA.
Breakfast.
Between 6 am to 9.25 am on Monday to Friday, ITV broadcast 2 breakfast programmes called Good Morning Britain and Lorraine. Good Morning Britain keeps viewers up to date with all the latest news, sport, features and weather, whilst Lorraine predominantly focuses on celebrity interviews, recipes, fashion and showbiz.
Regional news.
The regional ITV companies are required to provide local news as part of their franchise agreement, with the main local bulletin at 6pm and regional bulletins located after each national news programme. In addition to this, traditionally ITV companies would provide other regional programming based on current affairs, entertainment or drama. However, apart from a monthly political programme, most non-news regional programming in the English regions was dropped by ITV plc in 2009, although it continues in Wales and the Channel Islands, as well as on STV and UTV & from 2014 ITV Border Scotland. On 14 January 2013, ITV plc regional news programmes titles were discontinued in favour of more generic branding, i.e. "North East Tonight" became "ITV News Tyne Tees".
Weather.
The ITV National Weather forecast was first broadcast in 1989, using data supplied by the Met Office, and was presented by a number of weather forecasters. The forecasts are sponsored in which the sponsors message, as of December 2012 Seven Seas or STV Health Centre, would appear prior to the forecast. The forecasts are made immediately after the main national news bulletins.
Prior to the creation of the national forecast, regional forecast provided by each regional companies were shown in each region only. The regional forecasts today are incorporated into the main regional news bulletins, and in the ITV plc regions includes a Pollen Count.
Sport.
ITV covers many popular sports. The channel emphasises coverage of football, with the channel holding the UK terrestrial rights to the UEFA Champions League and with the channel sharing coverage of international football events such as the World Cup with the BBC. On 30 March 2007 The Football Association confirmed that it had agreed a new four-year £425m television deal for ITV and Setanta Sports to show FA Cup and England home international matches (the Scottish regional broadcaster STV replaces these games with regular programming). The deal with the FA represented a 42% increase on the existing deal with BBC Sport and BSkyB.
In May 2009, ITV acquired the rights to broadcast live cricket from the Indian Premier League. The network also covers motorsport, rugby, and other sports.
Children's programming.
The network broadcasts children's programming under the CITV (Children's ITV) strand. Children's programming was originally provided during weekday afternoons and weekend mornings, however following the launch of the CITV Channel in 2006, all children's programming, with the exception of the weekend ITV Breakfast slot, were relocated from the ITV line-up to the CITV channel in 2007, a move which was challenged by Ofcom in April 2007.
Teletext provider.
The Public Teletext Licence allows the holder to broadcast a text-based information service around the clock on Channel 3 (as well as Channel 4 and S4C) frequencies. Teletext on ITV was provided by ORACLE from 1974 until 1993 and from 1993 to 2010 by Teletext Ltd., whose news, sport and TV listings pages rivalled the BBC's offering, Ceefax on terrestrial and BBC Red Button on digital. Teletext Ltd. also provided digital teletext for the Channel 3 services, as well as the text output for both Channel 4 and S4C under the same licence and Channel 5. However, the licence was revoked by Ofcom on 29 January 2010 for failing to provide news and local non-news information on ITV and there is currently no teletext licence holder for ITV.
Schools programming.
Schools programming on the network began in 1957 in some regions and expanded as more regions began broadcasting. It is a contractual obligation for the ITV company to broadcast schools programming, and this was initially broadcast as part of the normal scheduling. The programmes were moved into a segment for broadcast during the day in the 1960s, under the banner "Independent Television for Schools and Colleges" and from 1987 were broadcast on Channel 4 in the "ITV Schools on Channel 4" segment. In 1993, this segment became "Channel 4 Schools" and later in 2000 "4Learning". These strands of programming consisted of schools programming from all the ITV companies or from independent sources. The schools strand itself is now defunct, with no particular branding segment used.
Availability outside the UK.
ITV (as UTV) is widely available in the Republic of Ireland on cable and MMDS, as well as being received directly in areas bordering Northern Ireland, or in coastal areas from Wales (as ITV Wales). It is also available on cable and IPTV in Switzerland and Liechtenstein. Since 27 March 2013, it has been offered by British Forces Broadcasting Service (BFBS) to members of HM Forces and their families around the world, replacing the BFBS3 TV channel, which already carried a selection of ITV programmes.
Criticism.
Since the launch of ITV, there have been concerns from politicians and the press that ITV faced a conflict concerning programme audiences and advertisers. As advertisers are reluctant to buy advertising space around low viewing programmes, there is a pressure on ITV to broadcast more popular programmes in peak times. This has become more profound in recent years following a relaxation in regulation and significantly more competition in the advertising market following the huge increase in commercial channels. In recent years, programmes have started to dominate from the reality television genre including the celebrity and talent show subgenres. This has led to accusations of ITV 'dumbing down' their programmes and appealing to the 'lowest common denominator', accusations that are at odds with the network's status as a public service broadcaster. ITV was also heavily criticised for scaling back its regional programmes, including regional news.

</doc>
<doc id="58090" url="https://en.wikipedia.org/wiki?curid=58090" title="Jean-François de Galaup, comte de Lapérouse">
Jean-François de Galaup, comte de Lapérouse

Jean François de Galaup, comte de Lapérouse (; variant spelling of his name comte "de La Pérouse"; 23 August 1741 – 1788?) was a French Naval officer and explorer whose expedition vanished in Oceania.
Early career.
Jean-François de Galaup was born near Albi, France. "Lapérouse" was the name of a family property that he added to his name. He studied in a Jesuit college and entered the naval college in Brest when he was fifteen. In 1757 he was posted to the "Célèbre" and participated in a supply expedition to the fort of Louisbourg in New France. Lapérouse also took part in a second supply expedition in 1758 to Louisbourg, but as this was in the early years of the Seven Years' War, the fort was under siege and the expedition was forced to make a circuitous route around Newfoundland to avoid British patrols.
In 1759 Lapérouse was wounded in the Battle of Quiberon Bay, where he was serving aboard the "Formidable". He was captured and briefly imprisoned before being paroled back to France; he was formally exchanged in December 1760. He participated in a 1762 attempt by the French to gain control of Newfoundland, escaping with the fleet when the British arrived in force to drive them out.
Following the Franco-American alliance, Lapérouse fought against the Royal Navy off the American coast, and victoriously led the frigate "Astree" in the Naval battle of Louisbourg, 21 July 1781. He was promoted to the rank of commodore when he defeated the English frigate "Ariel" in the West Indies. He then escorted a convoy to the West Indies in December 1781, participated in the attack on St. Kitts in February 1782 and then fought in the defeat at the Battle of the Saintes against the squadron of Admiral Rodney. In August 1782 he made his name by capturing two English forts (Prince of Wales Fort and York Fort) on the coast of Hudson Bay, but allowed the survivors, including Governor Samuel Hearne of Prince of Wales Fort, to sail off to England in exchange for a promise to release French prisoners held in England. The next year his family finally consented to his marriage to Louise-Eléonore Broudou, a young creole of modest origins whom he had met on Ile de France (present-day Mauritius) eight years earlier.
Scientific expedition - around the world.
Objectives.
Lapérouse was appointed in 1785 by Louis XVI and his Minister of the Marine, the Marquis de Castries, to lead an expedition around the world. Many countries were initiating voyages of scientific exploration.
Louis XVI and his court had been stimulated by a proposal from the Dutch-born merchant adventurer William Bolts, who had earlier tried unsuccessfully to interest Louis’s brother-in-law, the Holy Roman Emperor Joseph II (brother of Queen Marie Antoinette), in a similar voyage. The French court adopted the concept (though not its author, Bolts), leading to the dispatch of the Lapérouse expedition. Charles Pierre Claret de Fleurieu, Director of Ports and Arsenals, stated in the draft memorandum on the expedition that he submitted to the King: "the utility which may result from a voyage of discovery ... has made me receptive to the views put to me by Mr. Bolts relative to this enterprise". But Fleurieu explained to the King: "I am not proposing at all, however, the plan for this voyage as it was conceived by Mr. Bolts".
The expedition's aims were to complete the Pacific discoveries of James Cook (whom Lapérouse greatly admired), correct and complete maps of the area, establish trade contacts, open new maritime routes and enrich French science and scientific collections. His ships were the "Astrolabe" (under Fleuriot de Langle) and the "Boussole", both 500 tons. They were storeships reclassified as frigates for the occasion. Their objectives were geographic, scientific, ethnological, economic (looking for opportunities for whaling or fur trading), and political (the eventual establishment of French bases or colonial cooperation with their Spanish allies in the Philippines). They were to explore both the north and south Pacific, including the coasts of the Far East and of Australia, and send back reports through existing European outposts in the Pacific.
Preparations.
As early as March 1785, Lapérouse proposed that Paul Monneron, who had been chosen as the expedition's chief engineer, go to London to find out about the anti-scurvy measures recommended by Cook and the exchange items used by Cook in his dealings with native peoples, and to buy scientific instruments of English manufacture.
The best-known figure from Cook's missions, Joseph Banks, intervened at the Royal Society to obtain for Monneron two inclining compasses that had belonged to Cook. Furnished with a list produced by Charles Pierre Claret de Fleurieu, Monneron also bought scientific instruments from some of the largest English firms, particularly Ramsden. He even surpassed Fleurieu's directives by acquiring two sextants of a new type.
Crew.
Lapérouse was well liked by his men. Among his 114-man crew there were ten scientists: Joseph Lepaute Dagelet (1751–1788), an astronomer and mathematician; Robert de Lamanon, a geologist; La Martinière, a botanist; a physicist; three naturalists; and three illustrators, Gaspard Duché de Vancy and an uncle and nephew named Prévost. Another of the scientists was Jean-André Mongez. Even both chaplains were scientifically schooled.
One of the men who applied for the voyage was a 16-year-old Corsican named Napoléon Bonaparte. Bonaparte, a second lieutenant from Paris's military academy at the time, made the preliminary list but he was ultimately not chosen for the voyage list and remained behind in France. At the time Bonaparte was interested in serving in the navy rather than army because of his proficiency in mathematics and artillery, both valued skills on warships.
Copying the work methods of Cook's scientists, the scientists on this voyage would base their calculations of longitude on precision watches and the distance between the moon and the sun followed by theodolite triangulations or bearings taken from the ship, the same as those taken by Cook to produce his maps of the Pacific islands. As regards geography, Lapérouse decisively showed the rigour and safety of the methods proven by Cook. From his voyage, the resolution of the problem of longitude was evident and mapping attained a scientific precision. Impeded (as Cook had been) by the continual mists enveloping the northwestern coast of America, he did not succeed any better in producing complete maps, though he managed to fill in some of the gaps.
Chile and Hawaii.
Lapérouse and his 220 men left Brest on 1 August 1785, rounded Cape Horn, investigated the Spanish colonial government in the Captaincy General of Chile. He arrived on 9 April 1786 at Easter Island 
He then sailed to the Sandwich Islands, the present-day Hawaiian Islands, where he became the first European to set foot on the island of Maui.
Alaska.
Lapérouse sailed on to Alaska, where he landed near Mount St. Elias in late June 1786 and explored the environs. On 13 July 1786 a barge and two longboats, carrying 21 men, were lost in the heavy currents of the bay called "Port des Français" by Lapérouse, but now known as Lituya Bay. The men visited with the Tlingit tribe. (This encounter was dramatized briefly in episode 13 of Carl Sagan's "".) Next, he headed south, exploring the northwest coast, including the outer islands of present-day British Columbia 
California.
Lapérouse sailed during 10–30 August all the way south to the Spanish Las Californias Province, present-day California. He reportedly observed the only historical eruption of Mount Shasta on 7 September 1786, although this account is disputed. He stopped at the Presidio of San Francisco long enough to create an outline map of the Bay Area, "Plan du Port du St. Francois," which was reproduced as Map 33 in L. Aubert's 1797 "Atlas du Voyage de la Perouse." He arrived in Monterey Bay and at the Presidio of Monterey on 14 September 1786. He examined the Spanish settlements, ranchos, and missions. He made critical notes on the missionary treatment of the California indigenous peoples with the Indian Reductions at the Franciscan run missions. France and Spain were on friendly terms at this time. Lapérouse was the first non-Spanish visitor to California since Drake in 1579 , and the first to come to California after the founding of Spanish missions and presidios.
East Asia.
Lapérouse again crossed the Pacific Ocean in 100 days, arriving at Macau, where he sold the furs acquired in Alaska, dividing the profits among his men. The next year, on 9 April 1787, after a visit to Manila, he set out for the northeast Asian coasts. He saw the island of Quelpart, present-day Cheju in South Korea, which had been visited by Europeans only once before when a group of Dutchmen shipwrecked there in 1635. He visited the Asian mainland coasts of Korea.
Japan and Russia.
Lapérouse then sailed northward to Northeast Asia and "Oku-Yeso" Island, present day Sakhalin Island, Russia. The Ainu people, "Oku-Yeso" Island residents, drew him a map showing: their second domain of Yezo Island, present day Hokkaidō Island, Japan; and the coasts of Tartary, Russia on mainland Asia. Lapérouse wanted to sail north through the narrow Strait of Tartary between "Oku-Yeso" Island and mainland Asia but failed. Instead he turned south, and then sailed west through La Pérouse Strait, between "Oku-Yeso" Island (Sakhalin) and (Hokkaidō), where he met more Ainu in their third domain of the Kuril Islands, and explored.
Lapérouse then sailed north and reached Petropavlovsk on the Russian Kamchatka peninsula on 7 September 1787. Here they rested from their trip, and enjoyed the hospitality of the Russians and Kamchatkans. In letters received from Paris, Lapérouse was ordered to investigate the settlement the British were establishing in New South Wales, Australia. Barthélemy de Lesseps, the French vice consul at Kronstadt, Russia, who had joined the expedition as an interpreter, disembarked in Petropavlovsk to bring the expedition's ships' logs, charts, and letters to France, which he reached after a year-long, epic journey across Siberia and Russia.
South Pacific.
Lapérouse next stopped in the Navigator Islands (Samoa), on 6 December 1787. Just before he left, the Samoans attacked a group of his men, killing twelve of them, among whom were Lamanon and de Langle, commander of the "Astrolabe". Twenty men were wounded. The expedition drifted to Tonga, for resupply and help, and later recognized the "île Plistard" and Norfolk Island.
Australia.
The expedition continued to Australia, arriving off Botany Bay on 24 January 1788, just as Captain Arthur Phillip was attempting to move the colony from there to Sydney Cove in Port Jackson. The First Fleet was unable to leave until 26 January because of a tremendous gale, which also prevented Lapérouse's ships from entering Botany Bay.
The British received him courteously, and each captain, through their officers, offered the other any assistance and needed supplies. Lapérouse was 6 weeks in the colony and this was his last recorded landfall. The French established an observatory, held Catholic masses, made geological observations, and established a garden. Their chaplain from L'Astrolabe was buried there and is celebrated annually on the anniversary of his death. Although Phillip and Lapérouse did not meet, there were 11 visits recorded between the French and English. Over the past 200 years commanders from the French Navy have regularly paid their respects at the Lapérouse Monument. Lapérouse Day, Bastille Day and the foundation of the Lapérouse Monument by Hyacinthe de Bougainville are celebrated every year.
Lapérouse took the opportunity to send his journals, some charts and also some letters back to Europe with a British naval ship from the First Fleet—the "Alexander". He also obtained wood and fresh water and, on 10 March, left for New Caledonia, Santa Cruz, the Solomons, the Louisiades, and the western and southern coasts of Australia.
Lapérouse wrote that he expected to be back in France by June 1789. The documents that he dispatched with the "Alexander" from the in-progress expedition were returned to Paris, where they were published after his presumed death. However, neither he nor any of his men were seen again.
Epilogue.
HMS "Pandora".
Reportedly HMS "Pandora" missed a chance to rescue the survivors in May 1791. See the discussion below in The saga.
Rescue mission of D'Entrecasteaux.
On 25 September 1791 Rear Admiral Bruni d'Entrecasteaux departed Brest in search of Lapérouse. His expedition followed Lapérouse's proposed path through the islands northwest of Australia while at the same time making scientific and geographic discoveries. The expedition consisted of two ships, "Recherche" and "Esperance".
In May 1793, he arrived at the island of Vanikoro, which is part of the Santa Cruz group of islands (now part of the Solomon Islands). D'Entrecasteaux thought he saw smoke signals from several elevated areas on the island, but was unable to investigate due to the dangerous reefs surrounding the island and had to leave. He died two months later. The botanist Jacques Labillardière, attached to the expedition, eventually returned to France and published his account, "Relation du Voyage à la Recherche de la Pérouse", in 1800.
During the French Revolution, Franco-British relations deteriorated and unfounded rumours spread in France blaming the British for the tragedy which had occurred in the vicinity of the new colony. Before the mystery was solved the revolutionary French government had published the records of the voyage as far as Kamchatka: "Voyage De La Pérouse Autour du Monde", 1–4 (Paris, 1797). These volumes are still used for cartographic and scientific information about the Pacific. Three English translations were published during 1798–99.
Discovery of the expedition.
1826 expedition.
It was not until 1826 that an Irish sea captain, Peter Dillon, found enough evidence to piece together the events of the tragedy. In Tikopia (one of the islands of Santa Cruz), he bought some swords that he had reason to believe had belonged to Lapérouse or his officers. He made enquiries, and found that they came from nearby Vanikoro, where two big ships had broken up years earlier. Dillon managed to obtain a ship in Bengal, and sailed for the coral atoll of Vanikoro where he found cannonballs, anchors and other evidence of the remains of ships in water between coral reefs.
He brought several of these artifacts back to Europe, as did Dumont d'Urville in 1828. De Lesseps, the only member of the original expedition still alive at the time, identified them as all belonging to the "Astrolabe". From the information Dillon received from the people on Vanikoro, a rough reconstruction could be made of the disaster that struck Lapérouse. Dillon's reconstruction was later confirmed by the discovery, and subsequent examination in 1964, of what was believed to be the shipwreck of the "Boussole".
2005 expedition.
In May 2005, the shipwreck examined in 1964 was formally identified as that of the "Boussole". The 2005 expedition had embarked aboard the "Jacques Cartier", a French naval vessel. The ship supported a multi-discipline scientific team assembled to investigate the "Mystery of Lapérouse". The mission was called "Opération Vanikoro - Sur les traces des épaves de Lapérouse 2005".
2008 expedition.
A further similar mission was mounted in 2008.
The 2008 expedition showed the commitment of France, in conjunction with the New Caledonian 'Association Salomon', to seek further answers about Lapérouse's mysterious fate. It received the patronage of the President of France as well as the support and co-operation of the French Ministry of Defense, the Ministry of Higher Education and Research, and the Ministry of Culture and Communication.
Preparation for this, the eighth expedition sent to Vanikoro, took 24 months. It brought together more technological resources than previously and involved two ships, 52 crew members and almost 30 scientists and researchers. On 16 September 2008, two French Navy boats set out for Vanikoro from Nouméa (New Caledonia) and arrived on 15 October, thus recreating a section of the final voyage of discovery undertaken more than 200 years earlier by Lapérouse.
The saga.
Both ships had been wrecked on Vanikoro's reefs, the "Boussole" first. The "Astrolabe" was unloaded and taken apart. A group of men, probably the survivors of the "Boussole", was massacred by the local inhabitants. According to the islanders, some surviving sailors built a two-masted craft from the wreckage of the "Astrolabe" and left in a westward direction about nine months later; but what happened to them is unknown. Also, two men, one a "chief" and the other his servant, had remained behind, but had left Vanikoro a few years before Dillon arrived.
Sven Wahlroos, in his 1989 book, "Mutiny and Romance in the South Seas", suggests that there was a narrowly missed chance to rescue one or more of the survivors in 1791.
In November 1790, Captain Edward Edwards—in command of HMS "Pandora"—had sailed from England with orders to comb the Pacific for the mutineers of HMS "Bounty". In March of the following year, the "Pandora" arrived at Tahiti and picked up 14 "Bounty" men who had stayed on that island. Although some of the 14 had not joined the mutiny, all were imprisoned and shackled in a cramped "cage" built on the deck, which the men grimly nicknamed "Pandora's Box". The "Pandora" then left Tahiti in search of the "Bounty" and the leader of the mutiny, Fletcher Christian.
Captain Edwards' search for the remaining mutineers ultimately proved fruitless. However, when passing Vanikoro on 13 August 1791, smoke signals were observed rising from the island. Edwards, single-minded in his search for the "Bounty" and convinced that mutineers fearful of discovery would not be advertising their whereabouts, ignored the smoke signals and sailed on.
Wahlroos argues that the smoke signals were almost certainly a distress message sent by survivors of the Lapérouse expedition, which later evidence indicated were still alive on Vanikoro at that time—three years after the "Boussole" and "Astrolabe" had foundered. Wahlroos is "virtually certain" that Captain Edwards, whom he characterizes as one of England's most "ruthless," "inhuman," "callous" and "incompetent" naval captains, missed his chance to become "one of the heroes of maritime history" by solving the mystery of the lost Lapérouse expedition.
Legacy.
Places later named in honour of Lapérouse include:
Several ships have also been named after him:
Lapérouse in literature and film.
The fate of Lapérouse, his ships and his men is the subject of a chapter from "Twenty Thousand Leagues Under the Sea" by Jules Verne. Lapérouse was also mentioned in an episode ("The Quest") of the series "Northern Exposure" where the character Joel (Rob Morrow) finds an old chart of the French explorer that will lead to a legendary "jewelled city of the North" (New York).
The novel "Landfalls" by Naomi J. Williams explores the Lapérouse expedition in depth.

</doc>
<doc id="58092" url="https://en.wikipedia.org/wiki?curid=58092" title="Hokkaido">
Hokkaido

History.
Hokkaido was settled by the Ainu, Nivkh, and Orok peoples many years ago. The "Nihon Shoki", finished in 720 AD, is often said to be the first mention of Hokkaido in recorded history. According to the text, Abe no Hirafu led a large navy and army to northern areas from 658 to 660 and came into contact with the Mishihase and Emishi. One of the places Hirafu went to was called , which is often believed to be present-day Hokkaido. However, many theories exist in relation to the details of this event, including the location of Watarishima and the common belief that the Emishi in Watarishima were the ancestors of the present-day Ainu people.
During the Nara and Heian periods (710–1185), people in Hokkaido conducted trade with Dewa Province, an outpost of the Japanese central government. From the Middle Ages, the people in Hokkaido began to be called Ezo. Hokkaido, formerly known as Ezochi or . The Ezo mainly relied upon hunting and fishing and obtained rice and iron through trade with the Japanese.
During the Muromachi period (1336–1573), the Japanese created a settlement at the south of the Oshima Peninsula. As more people moved to the settlement to avoid battles, disputes arose between the Japanese and the Ainu. The disputes eventually developed into a war. Takeda Nobuhiro killed the Ainu leader, Koshamain, and defeated the opposition in 1457. Nobuhiro's descendants became the rulers of the Matsumae-han, which was granted exclusive trading rights with the Ainu in the Azuchi-Momoyama and Edo periods (1568–1868). The Matsumae family's economy relied upon trade with the Ainu. They held authority over the south of Ezochi until the end of the Edo period in 1868.
The Matsumae clan rule over the Ainu must be understood in the context of the expansion of the Japanese feudal state. Medieval military leaders in northern Honshū (ex. Northern Fujiwara, Akita clan) maintained only tenuous political and cultural ties to the imperial court and its proxies, the Kamakura Shogunate and Ashikaga Shogunate. Feudal strongmen sometimes located themselves within medieval institutional order, taking shogunal titles, while in other times they assumed titles that seemed to give them a non-Japanese identity. In fact many of the feudal strongmen were descended from Emishi military leaders who had been assimilated into Japanese society. The Matsumae clan were of Yamato descent like other ethnic Japanese people, whereas the Emishi of northern Honshu where a distinctive group related to the Ainu. The Emishi were conquered and integrated into the Japanese state dating back as far as the 8th century, and as result began to lose their distinctive culture and ethnicity as they became minorities. By the time the Matsumae clan ruled over the Ainu most of the Emishi were ethnically mixed and physically closer to Japanese than they were to Ainu. This dovetails nicely with the "transformation" theory that native Jōmon peoples changed gradually with the infusion of Yayoi immigrants into the Tōhoku rather than the "replacement" theory which posits that one population (Jōmon) was replaced by another (Yayoi).
There were numerous revolts by the Ainu against feudal rule. The last large-scale resistance was Shakushain's Revolt in 1669–1672. In 1789, a smaller movement, the Menashi-Kunashir Rebellion, was also crushed. After that rebellion the terms "Japanese" and "Ainu" referred to clearly distinguished groups, and the Matsumae were unequivocally Japanese. In 1799–1821 and 1855–1858 the Edo Shogunate took direct control over Hokkaido in response to a perceived threat from Russia.
Leading up to the Meiji Restoration, the Tokugawa Shogunate realized there was a need to prepare northern defenses against a possible Russian invasion and took over control of most of Ezochi. The Shogunate made the plight of the Ainu slightly easier, but did not change the overall form of rule.
Hokkaido was known as Ezochi until the Meiji Restoration. Shortly after the Boshin War in 1868, a group of Tokugawa loyalists led by Enomoto Takeaki temporarily occupied the island (the polity is commonly but mistakenly known as the Republic of Ezo), but the rebellion was crushed in May 1869. Ezochi was subsequently put under control of , Hakodate Prefectural Government. When establishing the , the Meiji Government introduced a new name. After 1869, the northern Japanese island was known as Hokkaido; and regional subdivisions were established, including the provinces of Oshima, Shiribeshi, Iburi, Ishikari, Teshio, Kitami, Hidaka, Tokachi, Kushiro, Nemuro and Chishima.
The primary purpose of the development commission was to secure Hokkaido before the Russians extended their control of the Far East beyond Vladivostok. Kuroda Kiyotaka was put in charge of the venture. His first step was to journey to the United States and recruit Horace Capron, President Grant's Commissioner of Agriculture. From 1871 to 1873 Capron bent his efforts to expounding Western agriculture and mining with mixed results. Capron, frustrated with obstacles to his efforts returned home in 1875. In 1876, William S. Clark arrived to found an agricultural college in Sapporo. Although he only remained a year, Clark left lasting impression on Hokkaido, inspiring the Japanese with his teachings on agriculture as well as Christianity. His parting words, ""Boys, be ambitious!"" can be found on public buildings in Hokkaido to this day. The population of Hokkaido boomed from 58,000 to 240,000 during that decade.
In 1882, the Development Commission was abolished, and Hokkaido was separated into three prefectures -- , , and . In 1886, the three prefectures were abolished, and Hokkaido was put under the . Hokkaido became equal with other prefectures in 1947, when the revised Local Autonomy Law became effective. The Japanese central government established the as an agency of the Prime Minister's Office in 1949 to maintain its executive power in Hokkaido. The Agency was absorbed by the Ministry of Land, Infrastructure and Transport in 2001. and the of the Ministry still have a strong influence on public construction projects in Hokkaido.
In mid-July 1945 shipping, cities and military facilities in Hokkaido were attacked by the United States Navy's Task Force 38. On 14 and 15 July aircraft operating from the task force's aircraft carriers sank and damaged a large number of ships in ports along Hokkaido's southern coastline as well as in northern Honshu. In addition, on 15 July a force of three battleships and two light cruisers bombarded the city of Muroran.
Naming of Hokkaido.
When establishing the , the Meiji Government decided to change the name of Ezochi. Matsuura Takeshirō submitted six proposals, including names such as and , to the government. The government eventually decided to use the name Hokkaidō, but decided to write it as , as a compromise between and because of the similarity with names such as . According to Matsuura, the name was thought up because the Ainu called the region "Kai". Historically, many peoples who had interactions with the ancestors of the Ainu called them and their islands "Kuyi", "Kuye", "Qoy", or some similar name, which may have some connection to the early modern form "Kai". The "Kai" element also strongly resembles the Sino-Japanese reading of the characters (Sino-Japanese , Japanese "kun'yomi" ), which have been used for over a thousand years in China and Japan as the standard orthographic form to be used when referring to Ainu and related peoples; it is possible that Matsuura's "Kai" was actually an alteration, influenced by the Sino-Japanese reading of "Ka-i", of the Nivkh exonym for the Ainu, namely "Qoy" or .
There is no known established Ainu language word for the island of Hokkaido. However, the Ainu people did have a name for all of their domain, which included Hokkaido along with the Kuril Islands, Sakhalin, and parts of northern Honshu, which was "Aynu Mosir" (), a name taken by the modern Ainu to refer to their traditional homeland. "Ainu Mosir" literally translates as "The Land Where People (the Ainu) Live", and it was traditionally used to be contrasted with "Kamuy Mosir", "The Land of the Kamuy (spirits)".
Geography.
The island of Hokkaido is located at the north end of Japan, near Russia, and has coastlines on the Sea of Japan, the Sea of Okhotsk, and the Pacific Ocean. The center of the island has a number of mountains and volcanic plateaus, and there are coastal plains in all directions. Major cities include Sapporo and Asahikawa in the central region and the port of Hakodate facing Honshu.
The governmental jurisdiction of Hokkaido incorporates several smaller islands, including Rishiri, Okushiri Island, and Rebun. (By Japanese reckoning, Hokkaido also incorporates several of the Kuril Islands.) Because the prefectural status of Hokkaido is denoted by the "dō" in its name, it is rarely referred to as "Hokkaido Prefecture", except when necessary to distinguish the governmental entity from the island.
The island ranks 21st in the world by area. It is 3.6% smaller than the island of Ireland while Hispaniola is 6.1% smaller than Hokkaido. By population it ranks 20th, between Ireland and Sicily. Hokkaido's population is 4.7% less than that of the island of Ireland, and Sicily's is 12% lower than Hokkaido's.
In the east, there are two areas (surrounding, for example, Shari and the Nakashibetsu Airport) where a grid with spacing of nearly 3 km is formed by narrow bands of forest. It was designed to buffer wind, especially during blizzards, to protect cattle. It also serves as habitat and transportation corridors for animals and hikers.
Seismic activity.
Like many areas of Japan, Hokkaido is seismically active. Aside from numerous earthquakes, the following volcanoes are still considered active (at least one eruption since 1850):
In 1993, an earthquake of magnitude 7.7 generated a tsunami which devastated Okushiri, killing 202. An earthquake of magnitude 8.3 struck near the island on 26 September 2003.
National parks and quasi-national parks.
There are still many undisturbed forests in Hokkaido, including:
Wildlife.
There are three populations of the Hokkaido brown bear ("Ursus arctos yesoensis"). There are more brown bears than anywhere else in Asia. The Hokkaido brown bear is separated into three distinct lineages. There are only eight lineages in the world. Those on Honshu died out long ago.
Sub prefectures.
From April 2010, Hokkaido has 9 General Subprefectural Bureaus (総合振興局) and 5 Subprefectural Bureaus (振興局). Prior to that, Hokkaido is one of eight prefectures in Japan that have subprefectures (支庁 "shichō"). However, it is the only one of the eight to have such offices covering the whole of its territory outside the main cities (rather than having them just for outlying islands or remote areas). This is mostly due to its great size: many parts of the prefecture are simply too far away to be effectively administered by Sapporo. Subprefectural offices in Hokkaido carry out many of the duties that prefectural offices fulfill elsewhere in Japan.
Before the current political divisions and after 1869, Hokkaido was divided into provinces. See Former provinces of Hokkaido.
Climate.
Hokkaido has relatively cool summers and icy/snowy winters. Most of the island falls in the humid continental climate zone with Köppen climate classification "Dfb" (hemiboreal) in most areas but "Dfa" (hot summer humid continental) in some inland lowlands. The average August temperature ranges from , while the average January temperature ranges from , in both cases depending on elevation and distance from the ocean, though temperatures on the western side of the island tend to be a little warmer than on the eastern.
The northern portion of Hokkaido falls into the taiga biome, with significant snowfall. Snowfall varies widely from as much as on the mountains adjacent to the Sea of Japan down to around on the Pacific coast. The island tends to see isolated snowstorms that develop long-lasting snowbanks, in contrast to the constant flurries seen in the Hokuriku region. Total precipitation varies from on the mountains of the Sea of Japan coast to around (the lowest in Japan) on the Sea of Okhotsk coast and interior lowlands and up to around on the Pacific side.
Unlike the other major islands of Japan, Hokkaido is normally not affected by the June–July rainy season and the relative lack of humidity and typically warm, rather than hot, summer weather makes its climate an attraction for tourists from other parts of Japan.
In winter, the generally high quality of powder snow and numerous mountains in Hokkaido make it a popular region for snow sports. The snowfall usually commences in earnest in November and ski resorts (such as those at Niseko, Furano, Teine and Rusutsu) usually operate between December and April. Hokkaido celebrates its winter weather at the Sapporo Snow Festival.
During the winter, passage through the Sea of Okhotsk is often complicated by large floes of drift ice. Combined with high winds that occur during winter, this frequently brings air travel and maritime activity to a halt beyond the northern coast of Hokkaido. Ports on the open Pacific Ocean and Sea of Japan are generally ice-free year round, though most rivers freeze during the winter.
Major cities and towns.
Hokkaido's largest city is the capital, Sapporo, which is a designated city. The island has two core cities: Hakodate in the south and Asahikawa in the central region. Other important population centers include Kushiro, Obihiro, Kitami, Abashiri, Wakkanai, and Nemuro.
Hokkaido has the highest rate of depopulation in Japan. In 2000, 152 (71.7%) of Hokkaido's 212 municipalities were shrinking. Altogether, shrinking municipalities in Japan in the same year numbered 1,171.
Economy.
Although there is some light industry (most notably paper milling and beer brewing) most of the population is employed by the service sector. In 2001, the service sector and other tertiary industries generated more than three-quarters of the gross domestic product.
However, agriculture and other primary industries play a large role in Hokkaido's economy. Hokkaido has nearly one fourth of Japan's total arable land. It ranks first in the nation in the production of a host of agricultural products, including wheat, soybeans, potatoes, sugar beet, onions, pumpkins, corn, raw milk, and beef. Hokkaido also accounts for 22% of Japan's forests with a sizable timber industry. The prefecture is also first in the nation in production of marine products and aquaculture.
Tourism is an important industry, especially during the cool summertime when visitors are attracted to Hokkaido's open spaces from hotter and more humid parts of Japan and other Asian countries. During the winter, skiing and other winter sports bring other tourists, and increasingly international ones, to the island.
Transportation.
Hokkaido's only land link to the rest of Japan is the Seikan Tunnel. Most travellers travel to the island by air: the main airport is New Chitose Airport at Chitose, just south of Sapporo. Tokyo-Chitose is in the top 10 of the world's busiest air routes, handling more than 40 widebody round trips on several airlines each day. One of the airlines, Air Do was named after Hokkaido. Hokkaido can also be reached by ferry from Sendai, Niigata and some other cities, with the ferries from Tokyo dealing only in cargo.
Within Hokkaido, there is a fairly well-developed railway network (see Hokkaido Railway Company), but many cities can only be accessed by road.
Hokkaido is home to one of Japan's three Melody Roads, which is made from grooves cut into the ground, which when driven over causes a tactile vibration and audible rumbling transmitted through the wheels into the car body.
Education.
The Hokkaido Prefectural Board of Education oversees public schools (except colleges and universities) in Hokkaido. Public elementary and junior high schools (except Hokkaido Noboribetsu Akebi Secondary School and schools attached to Hokkaido University of Education) are operated by municipalities, and public high schools are operated by either the prefectural board or municipalities.
Hokkaido has 37 universities (7 national, 5 local public, and 25 private universities), 34 junior colleges, and 5 colleges of technology (4 national and 1 local public colleges). National universities located in Hokkaido are:
Hokkaido government runs Sapporo Medical University, a medical school in Sapporo.
Sports.
The 1972 Winter Olympics were held in Sapporo.
The sports teams listed below are based in Hokkaido.
International relations.
Hokkaido has relationships with several provinces, states, and other entities worldwide.
As of January 2014, 74 individual municipalities in Hokkaido have sister city agreements with 114 cities in 21 different countries worldwide.
Politics.
Governor.
The current governor of Hokkaido is Harumi Takahashi. She won a fourth term in the gubernatorial election in 2015 with centre-right support. Her first election in 2003 in a close race against centre-left supported Yoshio Hachiro and seven other candidates ended a 20-year streak of victories by Socialist Party heavyweight Takahiro Yokomichi and then his former vice governor Tatsuya Hori who beat Hideko Itō twice by large margins. Itō, a former Socialist Diet member was supported by the Liberal Democratic Party against Hori in 1995 (at the time, Socialists and Liberal Democrats formed the ruling "grand" coalition on the national level); In 1999, Hori was supported by all major non-Communist parties and Itō ran without party support. Before 1983, the governorship had been held by Liberal Democrats Naohiro Dōgakinai and Kingo Machimura for 24 years. In the 1971 election when Machimura retired, the Socialist candidate Shōhei Tsukada lost to Dōgakinai by only 13,000 votes; Tsukada was also supported by the Communist Party – the leftist cooperation in opposition to the US-Japanese security treaty had brought joint Socialist-Communist candidates to victory in many other prefectural and local elections in the 1960s and 1970s. In 1959, Machimura had defeated Yokomichi's father Setsuo in the race to succeed Hokkaido's first elected governor, Socialist Toshibumi Tanaka who retired after three terms. Tanaka had only won the governorship in 1947 in a run-off election against Democrat Eiji Arima because no candidate had received the necessary vote share to win in the first round as required by law at the time.
Assembly.
The Hokkaido Prefectural Assembly has 101 members from 47 electoral districts. As of April 30, 2015, the LDP caucus holds a majority with 51 seats, the DPJ-led group has 26 members. Other groups are the "Hokkaidō Yūshikai" of New Party Daichi and independents with twelve seats, Kōmeitō with eight, and the Japanese Communist Party with four members. General elections for the Hokkaido assembly are currently held together with gubernatorial elections in the unified local elections (last round: April 2015).
National representation.
For the lower house of the National Diet, Hokkaido is divided into twelve single-member electoral districts. In the 2014 election, candidates from the governing coalition of Liberal Democrats and New Komeito won nine districts, Democrats three. For the proportional election segment, Hokkaido and Tokyo are the only two prefectures that form a regional "block" district of their own. The Hokkaido proportional representation block elects eight Representatives. In 2014, the Liberal Democratic Party received 29.8% of the proportional vote and won three seats, the Democratic Party won two (27.6% of the vote), one seat each went to Kōmeitō (12.3%), Japan Innovation Party (9.9%) and – for the first time since the 2000 lower house election – the Japanese Communist Party (12.1%). More than four percent of Hokkaidō proportional votes in 2014 went to a minor protest group named "shiji seitō nashi" ("no party supported"/"[I/we] support no party").
In the upper house of the National Diet, a major reapportionment in the 1990s halved the number of Councillors from Hokkaido per election from four to two. After the elections of 2010 and 2013, the Hokkaido electoral district – like most two-member districts for the upper house – is represented by two Liberal Democrats and two Democrats. In the 2016 upper house election, the district magnitude will be raised to three, Hokkaidō will then temporarily be represented by five members and six after the 2019 election.

</doc>
<doc id="58094" url="https://en.wikipedia.org/wiki?curid=58094" title="Yeso">
Yeso

Yeso may refer to:

</doc>
<doc id="58095" url="https://en.wikipedia.org/wiki?curid=58095" title="La Perouse">
La Perouse

La Perouse may refer to

</doc>
<doc id="58096" url="https://en.wikipedia.org/wiki?curid=58096" title="La Pérouse Strait">
La Pérouse Strait

La Pérouse Strait, or Sōya Strait, is a strait dividing the southern part of the Russian island of Sakhalin (Karafuto) from the northern part of the Japanese island of Hokkaidō, and connecting the Sea of Japan on the west with the Sea of Okhotsk on the east.
The strait is long and deep. A small rocky island, appropriately named Kamen Opasnosti (Russian for "Rock of Danger") is located in the Russian waters in the northeastern part of the strait. Another small island, Bentenjima, lies near the Japanese shore of the strait.
The strait is named after Jean-François de Galaup, comte de Lapérouse, who explored the channel in 1787.
Japan's territorial waters extend to three nautical miles into La Pérouse Strait instead of the usual twelve, reportedly to allow nuclear-armed United States Navy warships and submarines to transit the strait without violating Japan's prohibition against nuclear weapons in its territory.
History.
Between 1848 and 1874, American whaleships passed through the strait in the spring and summer as they made their way from the right whale grounds in the Sea of Japan to the Sea of Okhotsk to hunt right and bowhead whales. The ship "David Paddack" (352 tons), Captain Swain, of Nantucket, was bound home with a full cargo when she wrecked in the strait in 1848.

</doc>
<doc id="58098" url="https://en.wikipedia.org/wiki?curid=58098" title="Magadan">
Magadan

Magadan () is a port town and the administrative center of Magadan Oblast, Russia, located on the Sea of Okhotsk in Nagayevo Bay in Taui Bay and serving as a gateway to the Kolyma region. Population: 
History.
Magadan was founded in 1930 in the Magadan River valley, near the settlement of Nagayevo. During the Stalin era, Magadan was a major transit center for prisoners sent to labor camps. From 1932 to 1953, it was the administrative center of the Dalstroy organization—a vast and brutal forced-labor gold-mining operation and forced-labor camp system. The town later served as a port for exporting gold and other metals mined in the Kolyma region. Its size and population grew quickly as facilities were rapidly developed for the expanding mining activities in the area. Town status was granted to it on July 14, 1939.
Magadan was temporarily transformed into a Potemkin village to mark an official visit by U.S. Vice-President Henry Wallace in May 1944. He took an instant liking to his secret policeman host, admired handiwork done by prisoners, and later glowingly called the town a combination of Tennessee Valley Authority and Hudson's Bay Company. Wallace's collaborative stance towards the Soviet Union discouraged the Democratic Party of the United States from renominating him as vice president later in the summer of 1944, helping lead to the selection of Harry Truman in his place.
Administrative and municipal status.
Magadan is the administrative center of the oblast. Within the framework of administrative divisions, it is, together with the urban-type settlements of Sokol and Uptar, incorporated as the town of oblast significance of Magadan—an administrative unit with the status equal to that of the districts. As a municipal division, the town of oblast significance of Magadan is incorporated as Magadan Urban Okrug.
Economy.
Ship building and fishing are the major industries. The town has a seaport (fully navigable from May to December) and a small international airport, Sokol Airport. There is also a small airport nearby, Magadan 13. The unpaved Kolyma Highway leads from Magadan to the rich gold-mining region of the upper Kolyma River and then on to Yakutsk.
Magadan is very isolated. The nearest major city available by road is Yakutsk, away via an unpaved road which is best used in the winter, especially since there is no bridge over the Lena River at Yakutsk. (The two choices are: ferry from Nizhny Bestyakh during the summer, when the rest of the road may not be passable due to standing water, or over the ice in the dead of winter).
The principal sources of income for the local economy are gold mining and fisheries. Recently, gold production has declined. Fishing production, although improving from year to year, is still well below the allocated quotas, apparently as a result of an aging fleet. Other local industries include pasta and sausage plants and a distillery. Although farming is difficult owing to the harsh climate, there are many public and private farming enterprises.
Culture and religion.
The town has a number of cultural institutions including the Regional Museum of Anthropology, a geological museum, a regional library and a university. The town has the new Orthodox Cathedral Church of the Trinity, a recently completed Roman Catholic Church of the Nativity and the Mask of Sorrow memorial, a large sculpture in memory of Stalin's victims, designed by Ernst Neizvestny. The Church of the Nativity is actually a part of the diocese of Anchorage, Alaska and ministers to the survivors of the labor camps. It is staffed by several priests and nuns.
The town figures prominently in the labour camp literature of Varlam Shalamov and in the eponymous song by Mikhail Krug, and was a focal point of the Long Way Round motorcycle journey made by Ewan McGregor, Charley Boorman and their team in 2004.
Climate.
The climate of Magadan is subarctic (Köppen climate classification "Dfc"). Winters are prolonged and very cold, with up to six months of sub-zero high temperatures, so that the soil remains permanently frozen. Permafrost and tundra cover most of the region. The growing season is only one hundred days long.
Average temperatures on the coast of the Sea of Okhotsk range from in January to in July. Average temperatures in the interior range from in January to in July.
Twin towns and sister cities.
Magadan is twinned with:

</doc>
<doc id="58099" url="https://en.wikipedia.org/wiki?curid=58099" title="Curtly Ambrose">
Curtly Ambrose

Sir Curtly Elconn Lynwall Ambrose, KCN (born 21 September 1963) is a former cricketer from Antigua who played 98 Test matches for the West Indies. A fast bowler, he took 405 Test wickets at an average of 20.99 and topped the ICC Player Rankings for much of his career to be rated the best bowler in the world. His great height—he is 6 feet 7 inches (2.01 m) tall—allowed him to make the ball bounce unusually high after he delivered it; allied to his pace and accuracy, it made him a difficult bowler for batsmen to face. A man of few words during his career, he was notoriously reluctant to speak to journalists. He was chosen as one of the "Wisden" Cricketers of the Year in 1992; after he retired he was entered into the International Cricket Council Hall of Fame and selected as one of West Indies all-time XI by a panel of experts.
Born in Swetes, Antigua, Ambrose came to cricket at a relatively late age, having preferred basketball in his youth, but quickly made an impression as a fast bowler. Progressing through regional and national teams, he was first chosen for the West Indies in 1988. He was almost immediately successful and remained in the team until his retirement in 2000. On many occasions, his bowling was responsible for the West Indies winning matches which seemed lost, particularly in association with Courtney Walsh. Against Australia in 1993, he took seven wickets while conceding a single run; in 1994 he was largely responsible for bowling England out for 46 runs, taking six for 24 (six wickets for 24 runs).
Ambrose's bowling method relied on accuracy and conceding few runs; several of his best performances came when he took wickets in quick succession to devastate the opposition. He was particularly successful against leading batsmen. From 1995, Ambrose was increasingly affected by injury, and several times critics claimed that he was no longer effective. However, he continued to take wickets regularly up until his retirement, although he was sometimes less effective in the early matches of a series. In his final years, the West Indies team was in decline and often relied heavily on Ambrose and Walsh; both men often bowled with little support from the other bowlers. Following his retirement, Ambrose has pursued a career in music as the bass guitarist in a reggae band.
Early life and career.
Ambrose was born in Swetes, Antigua on 21 September 1963, the fourth of seven children. His father was a carpenter from the village. The family had no background in cricket, but his mother was a fan, and Ambrose played in his youth, primarily as a batsman. At school, he performed well academically, particularly in mathematics and French, and became an apprentice carpenter upon leaving at the age of 17. He briefly considered emigrating to America. At the time, his favourite sport was basketball, although he occasionally umpired cricket matches. Ambrose was not particularly tall until he reached his late teens, when he grew several inches to reach a height of . Around this time, his mother encouraged him to become more involved in cricket. Success as a fast bowler in a softball cricket match persuaded Ambrose to play in some club matches at the age of 20. He quickly attracted the attention of coaches and progressed to the St John's cricket team. Selected in the Leeward Islands competition, he took seven for 67 (seven wickets for 67 runs) for Antigua against St Kitts. He made his first-class debut for the Leeward Islands in 1985–86 and took four wickets in the game, but failed to retain his place the following year.
A Viv Richards scholarship provided funding for him to play club cricket in England for Chester Boughton Hall Cricket Club in the highly rated Liverpool Competition during 1986 where he took 84 wickets at an average of 9.80. The following year, he returned to England to play for Heywood Cricket Club in the Central Lancashire League, for whom he took 115 wickets in the season; these experiences helped to improve his bowling technique.
Upon his return to Antigua, Ambrose practised intensely, regained his place in the Leeward Islands team and, in the absence of leading bowlers Winston Benjamin and Eldine Baptiste with the West Indies team, became the main attacking bowler in the side. He was no-balled for throwing in the first match, which "Wisden Cricketers' Almanack" later attributed to confusion caused by his attribute of flicking his wrist prior to releasing the ball to impart extra pace, and there were no subsequent doubts about the legality of his bowling action. Retaining his place when the international bowlers returned, he took 35 wickets—including 12 in a match against Guyana, of which nine were bowled—in five matches in the competition. "Wisden's" report on the West Indian season said his performance was "dominant", although few had heard of him previously. Identifying his yorker as his most effective delivery, it noted that he "never lost his pace, his accuracy, or his thirst for wickets".
International bowler.
Debut and first years.
When Pakistan toured the West Indies in 1988, Ambrose played in the One Day International (ODI) series, taking the place of the recently retired Joel Garner. He made his debut during the first match, on 12 March 1988 in Kingston, Jamaica, taking wickets with his third and ninth deliveries; he ended the innings with four for 39 from 10 overs. In the second match, he took four for 35 and followed with another two wickets in the third. West Indies won those first three matches to take the series, and Ambrose did not play in the fourth or fifth game. In the Test series which followed, Ambrose was less effective. In the first Test, he took two for 121 as West Indies lost at home for the first time in 10 years. "Wisden" noted that his debut was "unimpressive", but that he improved in the subsequent matches. He finished the series with seven wickets at an average of over 50 runs per wicket. Later that year, Ambrose was chosen to tour England. After appearing in early tour games, he was chosen for the first two ODIs, taking three wickets in total, but was omitted from the third. In the Test series, he played in all five matches to take 22 wickets at an average of 20.22; his best figures of four for 58 came in the fourth Test, in which he took seven wickets and was named man of the match. Writing in "Wisden", commentator Tony Cozier described Ambrose as "a ready-made replacement for Garner"; the amount of bounce he generated after the ball pitched "made him a constant menace".
In 1988–89, West Indies took part in an ODI tournament in Sharjah. Ambrose took 8 wickets, and was man of the match with four for 29 when West Indies defeated Pakistan in the final. From there, West Indies travelled to Australia for a series in which Ambrose was a dominant figure. The West Indies won the Test series 3–1, using controversial short-pitched bowling tactics. Ambrose's height made him difficult to play as made the ball bounce more than other bowlers. Writing in "Wisden", John Woodcock noted: "As in England, earlier in 1988, Ambrose's bowling was a telling factor ... advance compensated for something of a decline in effectiveness". In the first Test, he took seven wickets; in the second, he took five wickets in a Test innings for the first time with five for 72, and finished with eight in the game; and in the third, he took six wickets. His performances earned him man of the match award in the first and third games, and he ended the series with 26 wickets at an average of 21.46. He was West Indies leading wicket-taker and headed the team bowling averages. In the ODI tournament that took place during the tour, West Indies defeated Australia in the final; Ambrose took 21 wickets in the series and twice took five wickets in an innings.
Suffering from fatigue and illness, Ambrose was less successful later in 1989 when India toured the West Indies: he took just five wickets in the four-Test series at an average of 54.60.
County cricketer and success against England.
Ambrose made his debut in the English County Championship for Northamptonshire County Cricket Club in 1989—the club signed him for the 1988 season but as he was playing in the West Indies touring team, he was unavailable that year. He took a wicket with his first delivery for the club, but was not particularly successful in the first part of the season; he settled down later and took 28 first-class wickets at 28.39 for Northamptonshire in nine games.
Early in 1990, England toured the West Indies and played four Tests—a fifth was abandoned owing to rain. The visiting team dominated the first part of the series but West Indies eventually won 2–1. Ambrose was unfit for the first Test, which West Indies lost, and the first four ODIs, but returned to take four for 18 in an ODI organised to replace the rained-off second Test. After a drawn third Test, West Indies won the fourth game. The home captain, Viv Richards, set England 356 to win, but after losing early wickets, the English batsmen entered the last hour of the game with five wickets still to fall. Ambrose took the new ball and removed the last five batsmen for 18 runs in 46 deliveries, four of them leg before wicket. He finished with figures of eight for 45, ten wickets in the match, and West Indies levelled the series with a 164-run win. Ambrose was man of the match. He took six wickets in the final match, to finish the series with 20 wickets at 15.35, finishing top of the West Indies' averages. Ambrose, along with the other home bowlers, was described by Alan Lee in "Wisden" as an "awesome handful in the latter part of the series", and described his match-winning spell in the fourth Test as "unforgettable". Ambrose's other appearances for West Indies in 1989–90 were all in ODIs, although he did take more than two wickets in any innings except in the match against England. He also took 22 first-class wickets for the Leeward Islands, and when he returned to England to play for Northamptonshire in 1990, took 58 first-class wickets to top the club's bowling averages. In one-day cricket for the county, he took 13 wickets while conceding an average of just 2.53 runs per over.
Leading bowler in the Universe.
Series against Australia and England.
West Indies toured Pakistan in late 1990, and Ambrose topped the team's bowling averages in a three-match series which was drawn 1–1. He took 14 wickets at 17.07, but was overshadowed slightly by the performances of Ian Bishop. He played the first two ODIs, but missed the third after Pakistan had already won the series, and his best figures in the Tests came in the final match when he took five for 35. Then, when Australia toured West Indies from February 1991, Ambrose took 18 wickets in the five Tests at an average of 27.38. West Indies won the series 2–1, and Ambrose was fourth in the averages, but Tony Cozier observed in "Wisden" that the whole West Indies attack was dependable. Ambrose made an impression batting as part of a West Indian lower batting order which repeatedly added crucial runs during the series. He took part in two important partnerships to help his team recover from a difficult situation, and in the third match, he scored his only half-century in Tests. He also took 20 first-class wickets for Leeward Islands.
West Indies' next matches were in England. The Test series was drawn 2–2 and Ambrose was the team's leading wicket-taker with 28 (averaging 20.00); he also came top of the bowling averages. He had a particular impact on Graeme Hick, who was appearing in Test cricket for the first time, dismissing him six times in seven innings with short-pitched bowling. Accurate bowling was important in the series, played on a series of slow-paced pitches; according to Scyld Berry, writing in "Wisden", "Since the 1988 tour, Ambrose had improved his control to the point where a batsman had to play almost every ball—and not with a scoring stroke, either". Berry suggests that West Indies may have won the series had Viv Richards used a different tactical approach with Ambrose's bowling. The bowler was not fully fit in the final Test, which may have affected the outcome. Berry describes "Ambrose's rise to the status of a giant—with the mannerism of celebrating each wicket by whirling his arms upwards, like a flock of doves taking to the air." Ambrose twice took five wickets in an innings—his best figures were six for 52 in the first Test, when he twice took wickets with consecutive deliveries. Ambrose was named man-of the-match in the third Test and adjudged West Indies man-of-the-series. For his performances, Ambrose was named one of "Wisden's" Cricketers of the Year. The citation remarked on his consistency and stated: "Ambrose has the ability to exert a debilitating psychological influence which so often precipitates a cluster of wickets after the initial breach has been made ... Moreover, he was arguably the essential difference between the two sides in what proved to be a zestful series." The West Indies wicket-keeper, Jeff Dujon, said: "He is mature beyond his years, has pace, accuracy, heart and determination, plus, importantly, real pride in economical figures."
Victory against South Africa.
During the 1991–92 season, West Indies played mainly one-day cricket, taking part in tournaments in Sharjah—where Ambrose took seven wickets, including an analysis of five for 53—and Australia, and took part in the World Cup in Australia and New Zealand. In this tournament, Ambrose took seven wickets in seven games at an average of 33.57 and was the seventh most economical bowler among those who played more than one game. West Indies finished sixth in the qualifying table and failed to reach the semi-finals. Ambrose returned home to play twice for the Leeward Islands in January 1992.
In April 1992, South Africa toured West Indies for the first time, and played their first Test match for 22 years. Ambrose played in all three ODIs, all of which were won by West Indies. The Test match was the first time West Indies bowled under a new playing regulation which permitted only one bouncer per over; this seemed to affect the home bowlers, but Ambrose took two for 47 from 36 overs. South Africa began the final day of the match requiring 79 runs to win with just two batsmen out, but Ambrose and Courtney Walsh took the last eight wickets for 26 runs to bowl West Indies to a 52-run win. On a difficult pitch for batting, the ball bounced unevenly, and both bowlers concentrated on accuracy. Ambrose took six for 34 in the second innings, and was named joint man of the match; in just over 60 overs, he took eight for 81 in the match.
Returning to play for Northamptonshire, he was less effective. Hampered by a knee injury, which necessitated surgery after the English season, and suffering from many dropped catches, he took 50 first-class wickets at an average of 26.14, but his performance compared unfavourably with other bowlers on the team. He was more effective in the NatWest Trophy, a one-day competition that Northamptonshire won that season, in which he conceded fewer than two runs per over across five games.
Second tour of Australia.
The West Indies toured Australia in 1992–93, recovering from losing the second Test to win the final two matches and take the series 2–1. The team also won the annual World Series Cup. In the first three Tests, Ambrose was hampered by pitches which did not suit his bowling and, according to Tony Cozier writing in "Wisden", was often unlucky when he bowled, although he took five for 66 in the first Test. In the final two Tests, he took 19 wickets. In the fourth he took ten wickets, including six for 74 in the first innings; in the second innings, he took three wickets in 19 deliveries and the West Indies won the match by one run. According to Cozier, the captains of both teams, Richie Richardson and Allan Border, "paid tribute to the man who made the result possible: Ambrose consolidated his reputation as the world's leading bowler". On the first day of the decisive final Test, Ambrose took seven wickets at the cost of one run from 32 deliveries and finished with figures of seven for 25. Cozier described it as "one of Test cricket's most devastating spells". West Indies won by an innings and Ambrose was named man of the series, having taken 33 wickets to equal the record in an Australia-West Indies Test series. He topped the West Indian bowling averages with an average of 16.42. Cozier described Ambrose's performance as "instrumental in winning series" and his bowling as "flawless".
In the one-day tournament, Ambrose took 18 wickets at 13.38. He took eight wickets in the two-match final—both games were won by the West Indies. In the first final, he took five for 32, driven to bowl with more hostility when the Australian batsman Dean Jones asked him to remove his white wristbands while bowling. He followed up with three for 26 in the second match to be named player of the finals.
After a one-day tournament in South Africa, West Indies returned home for Test and ODI series against Pakistan. The ODI series was drawn, but the West Indies defeated Pakistan 2–0 in the Tests. Ambrose took nine wickets at 23.11 to be fifth in the team bowling averages. The "Wisden" report suggested that he was suffering from fatigue after his team's busy schedule, but although not at his best, he continued to take important wickets. For Northamptonshire in 1993, Ambrose was second in the team first-class bowling averages with 59 wickets at 20.45.
Having developed a slower ball, and using the yorker more sparingly, Ambrose took five wickets in three games as West Indies won an ODI tournament in Sharjah in late October and November 1993. The team competed in another tournament, this time in India, later that November. They finished as runners-up, and Ambrose took four wickets in five matches. Immediately following this, West Indies toured Sri Lanka to play three ODIs and a Test, a rain-ruined match in which Ambrose took three wickets.
More success against England.
When he returned to the West Indies, Ambrose took 19 first-class wickets for the Leeward Islands at an average of 11.68, in his first appearances for the islands in two years, but as England arrived to tour West Indies, he complained of fatigue and there were rumours he planned to retire. He played in three times in the five-match ODI series, taking two wickets, and took a further two wickets in the first Test, which West Indies won. In "Wisden", Alan Lee described his performances at this time as "lethargic", and in the "Guardian", Paul Allott wrote that he bowled "like a shadow" owing to the effects of continuous cricket. Ambrose was ineffective at the start of the second Test, but recovered, ending the match with eight wickets; according to Lee, he "struck the critical blows of the match" in the first innings. In the third Test, played in Trinidad, he took five for 60 in England's first innings, but after the visiting team built a substantial lead, West Indies were bowled out to leave England needing 194 to win and an hour to bat on the fourth evening. Ambrose took six wickets to leave England 40 for eight at the close of play; the next morning, they were bowled out for 46 and Ambrose had figures of six for 24 in the innings and match figures of 11 for 84; he was named man of the match. Lee described the collapse as "staggering", and judged Ambrose bowling to be "of the highest calibre". He continued: "He delivered one of the most devastating spells of even his career." Allott called it "the definitive spell of fast bowling".
Ambrose took four wickets in the fourth Test, but West Indies lost the match, their first defeat in Barbados for 59 years, and Ambrose was fined £1,000 by the match referee for knocking down his stumps in frustration when he was the last man out. He took one more wicket in the drawn final Test to finish the series with 26 wickets and top the West Indian bowling averages. Writing in "Wisden", Lee summarised Ambrose's performances: "Ambrose was magnificent. He was deservedly named man of the series, not only for taking 26 wickets at an average of 19.96 apiece and winning the Trinidad Test single-handed, but for the more profound truth that West Indies now look to him whenever they need wickets ... carried the attack alone".
Ambrose returned to play for Northamptonshire in 1994, but arrived later than scheduled. Claiming to need a rest, he missed his scheduled flight and arrived four days late. His absence may have contributed to Northamptonshire's elimination in the preliminary stages of the Benson and Hedges Cup. At the time, members of the county were unhappy with Ambrose's performances for the team; the committee fined him, and he expressed contrition. During the remainder of the season, he bowled extremely effectively to take 77 first-class wickets, the most for the club in 18 years, at an average of 14.45 to top the national bowling averages. According to Andrew Radd in "Wisden", the club were mollified by his success, but he wrote: "Rarely in Northamptonshire's history have the performances and the personality of one cricketer dominated a season to the extent that Curtly Ambrose did in 1994." Ambrose missed the final match of the season with a shoulder problem.
Apparent decline.
Shoulder injury.
Ambrose's shoulder injury, caused by his bowling workload, caused him to miss the West Indies' tour of India in the last three months of 1994. Although he returned to join the tour of New Zealand in early 1995, he did not reach his full bowling pace; he took one wicket in the ODI series and five in the two Test matches. He remained in the team when Australia toured the Caribbean later in 1995; the West Indies lost the Test series 2–1, their first defeat in a Test series since 1980. After taking two wickets in four ODIs, Ambrose took 13 wickets at 19.84 in the four-Test series to lead the West Indian averages. He took nine of these wickets in Trinidad during the third Test, when West Indies levelled the series having lost the first Test (the second was drawn). Bowling on a pitch that was extremely difficult for batting, and which both teams considered to be unsatisfactory, Ambrose took nine for 65 in the match and was named man of the match. During the game, Ambrose had to be pulled away from a verbal confrontation with Steve Waugh by the captain, Richardson. But outside of this match, the Australian team judged his bowling to have declined in pace following his shoulder injury, and that he lacked the variety to adapt to a different role. The West Indies' cricket manager, former Test bowler Andy Roberts, publicly claimed during the series that several of his team possessed "attitude problems", and complained that the fast bowlers would not follow his advice.
During the tour of England which followed, Ambrose did not take a wicket in the three-match ODI series; according to journalist Simon Barnes, both Ambrose and the team lacked confidence following their defeat by Australia; he lacked rhythm and displayed signs of frustration and unhappiness. He was more effective in the Test series, and according to Tony Cozier in "Wisden", "was always captable of a spell of incisive, quality bowling". But he was affected by injury throughout the six-match series; he withdrew injured from the third Test having bowled fewer than eight overs and missed the fifth Test completely. Other bowlers in the team overshadowed Ambrose, and it was not until the final Test that he reached his most effective form in taking five for 96 in the first innings and seven wickets in the match. Waving to the crowd as he left the field on the final day with an injury, Ambrose seemed to indicate that he would not tour England again. He ended the series third in the bowling averages with 21 wickets at 24.09. But according to Cozier, the senior players in the team caused problems for the management, and when the players returned home, Ambrose and three other members of the team were fined 10 per cent of their tour fee—in Ambrose's case, the fine was for "general failings of behaviour and attitude", and setting a bad example to younger team-mates.
Along with other senior players, Ambrose was rested from West Indies' next tour, an ODI tournament in October 1995, but he returned to play in a three-team ODI tournament in Australia in December and January. However, affected by the refusal of Brian Lara to tour following after being fined for his behaviour during the tour of England, the team failed to qualify for the final. Ambrose took ten wickets in the tournament, and took three wickets in consecutive innings; in the latter game, he was man of the match. West Indies were more successful in the World Cup in India, Pakistan and Sri Lanka which began in February. They reached the semi-finals, losing to Australia. Ambrose was man of the match with three for 28 in his team's opening match, and took ten wickets at 17.00 in the competition. He conceded an average of just three runs per over over the tournament, the second best among those who played in more than two games. In March, Ambrose played in a home series against New Zealand. In the five match ODI series, 10 wickets at 17.60, including four for 36 in the opening game. He took eight wickets in the two-Test series at an average of 20.50, leading the team averages, and took five for 68 in the second match. During the English cricket season, he returned to Northamptonshire and took 43 wickets in nine games to lead the national bowling averages, but he missed several matches with recurring injuries and his contract was not renewed for the following year. He was replaced by the much younger Mohammad Akram as overseas player.
Team in decline.
Following Australia's victory in 1994–95, when West Indies toured Australia in 1996–97 the series was heavily publicised as a re-match. However, the visiting team were often ineffective, continuing a trend of decline, and depended heavily on their senior players, one of whom was Ambrose. He began the series poorly, continuing a pattern established in several preceding series, and critics suggested that he was no longer effective. After taking only three wickets in the first two Tests, both of which were lost by West Indies, Ambrose told his team-mates that he would take ten wickets in the third. On a difficult pitch for batting, he managed to take nine in the match, including three in the first hour of the game, despite struggling with a hamstring injury. West Indies won, and Ambrose was named man of the match, but he missed the fourth Test with an injury. Writing in "Wisden", Greg Baum suggested that Ambrose absence possibly affected the outcome of the series; Australia won easily to ensure they won the series. Ambrose returned for the final match, and on another difficult batting pitch, took five for 43 on the first day. West Indies won and Ambrose was again man of the match. He led the West Indies bowling averages with 19 wickets at 23.36, but had been the driving factor in West Indies' two wins. Ambrose also played in an ODI tournament during the tour of Australia, taking nine wickets at 27.33. Later in the season, between March and May 1997, India toured West Indies; Ambrose took ten wickets at 30.10 in the Test series, including five for 87 in the second Test, but was no longer the home team's most effective bowler. Then in June, Sri Lanka played a two-Test series, won 1–0 by West Indies. In the first, Ambrose took five for 37 in the first innings, and eight wickets in the game, to be named man of the match. This included his 300th wicket in Test matches; he was the 12th bowler, and fourth West Indian, to reach this landmark. Ambrose also played five ODIs during the West Indies home season, taking nine wickets.
West Indies' loss of form continued in late 1997 when they lost every international match during their tour of Pakistan. Ambrose played in two out of West Indies' three matches in an ODI tournament, taking one wicket, but his performance in taking one wicket in the two Test matches he played—he missed the third match with injury—prompted Fazeer Mohammed, writing in "Wisden", to describe Ambrose as "a shadow of his former self". Any danger that Ambrose might have retired after this series was forestalled when Brian Lara was appointed West Indies captain and immediately spoke to Ambrose and Walsh to ask them to continue in the team. When England toured the West Indies between January and April 1998, he took 30 wickets at 14.26 to top the bowling averages for the series. Many of the pitches during the tour were poor for batting, but Ambrose was very effective, particularly in the second, third and fourth Tests. In addition, he dismissed Mike Atherton, the England captain, six times in the series. Scyld Berry wrote in "Wisden" that Ambrose was "back to something near his peak form ... defied every prediction that he was finished after his tour of Pakistan." In the second Test, Ambrose took eight wickets; he conceded only 23 runs from 26 overs in the first innings and bowled a spell of five wickets for 16 runs from 47 deliveries in the second to complete figures of five for 52. Having won the second match, West Indies lost the third, but according to Matthew Engel, "Ambrose's abiding power was the most constant feature of a fluctuating match". His eight wickets in the game, including five for 25 in the first innings, took him past fifty Test wickets in Trinidad. He followed up with six wickets in West Indies victory in the fourth Test, taking four for 38 in the final innings. Tony Cozier wrote that Ambrose "thundered in, arms and knees pumping like pistons, to generate all of his old pace." Following the Test series, which West Indies won 3–1, Ambrose played in the first three matches of the ODI series, and took three wickets.
Final years of career.
Ambrose and Walsh missed the Mini World Cup ODI tournament in October 1998, in Ambrose's case following damage to his house caused by Hurricane Georges. They returned to the team for West Indies' first ever tour of South Africa, and Ambrose took 13 wickets in the series at an average of 23.76, but West Indies lost every game of the five-match series. In the first Test match, Ambrose and Walsh bowled effectively but lacked support from the other members of the attack. In the second Test, the pair again lacked support, but bowled well. The visiting team generally bowled too many bouncers to be effective, but Ambrose took eight wickets in the game, including six for 51 in the second innings. He was ineffective in the third Test, and despite bowling what Geoffrey Dean in "Wisden" called a "superb opening spell", could not prevent South Africa building up a large total against an attack lacking two other main bowlers. Ambrose pulled out of the attack himself later in the innings with a back injury, and did not bowl in the second innings. He missed the final Test with a hamstring injury. He was fit to play in the first six games of a seven-match ODI series, won 6–1 by South Africa, and took six wickets. In March 1999, West Indies then faced Australia in a home series, and contrary to expectations, West Indies drew the series 2–2. The outcome of the series was decided by a small group of players, including Ambrose, whom Mike Coward described in "Wisden" as "five of the most distinguished cricketers of all time". Ambrose took 19 wickets at 22.26, second to Walsh in the averages. His best figures came in the fourth and final Test, when he took five for 94 in the first innings and eight wickets in the match, but in the third match, although he only took four wickets in total, Coward described Ambrose as "rampant" and wrote that Steve Waugh, who scored 199, had to survive "some extraordinary pace bowling from Ambrose". He played four of the ODIs which followed in April, taking three wickets. The following month, Ambrose took part in the 1999 World Cup in England, and he was the second most economical bowler in the tournament in conceding an average 2.35 runs per over while taking seven wickets at 13.42. West Indies went out in the group stages, and Matthew Engel suggested that the bowlers were tired and judged the team "outright failures".
Following the World Cup, the West Indian selectors chose to rest Ambrose, along with Walsh, from alternate ODI tournaments. Ambrose consequently missed two ODI series, but in October 1999 he played two ODIs in a series against Bangladesh in Dhaka and three in a tournament in Sharjah. In the latter competition, Ambrose conceded five runs from ten overs against Sri Lanka, the second most economical bowling figures from a full allocation of 10 overs in all ODIs. However, in all five matches, he took just one wicket, and he injured his elbow in Sharjah which forced him to miss West Indies' tour of New Zealand which began in December. Ambrose recovered in time to play for the Leeward Island in domestic cricket, taking 31 wickets at 12.03 in seven first-class games. When Zimbabwe toured the West Indies, he returned to the West Indies team to be named man of the match in the first Test—Zimbabwe were bowled out for 63 when chasing 99 runs to win. He took a wicket in the second and final Test, and four wickets in six matches during a three-way ODI series also involving Zimbabwe and Pakistan. These were his final ODIs; in 176 matches, he took 225 wickets at an average of 24.12 and conceding 3.48 runs per over. Pakistan subsequently played a three-Test series against West Indies; in his last home series, Ambrose took 11 wickets at 19.90 to head the West Indian bowling averages.
Before his next series, a five-match series in England, Ambrose announced that he would retire after the final Test, although the president of the West Indies Cricket Board unavailingly tried to persuade him to continue for a little longer. West Indies lost the series 3–1, Tony Cozier, reviewing the series, suggested that only Ambrose and Walsh of the West Indian team emerged from the series with any credit. The other bowlers were ineffective, and Ambrose publicly commented during the series on the lack of support that he and Walsh received. He was second in the averages to Walsh with 17 wickets at 18.64. After taking just one wicket in the first Test, although Martin Johnson, in "Wisden", suggested he bowled very well, Ambrose took five wickets in the second Test but was again unlucky as the batsmen were beaten by many deliveries that he bowled. After this match, Ambrose returned to the West Indies having been rested from an ODI tournament involving England and Zimbabwe. He took four wickets in the first innings of both the third and fourth Tests, passing 400 wickets in the latter match. After he took three wickets in his final Test match, the crowd gave him a standing ovation and the England players formed a guard-of-honour when he came out to bat. In 98 Test matches, he took 405 wickets at an average of 20.99; according to Mike Selvey, in Swetes, his mother rang a bell each time he took a Test wicket.
Having retired from cricket, Ambrose has concentrated on music, playing with several bands. He played bass guitar with the reggae band Big Bad Dread and the Baldhead; one fellow band member was his former team-mate Richie Richardson. Ambrose was appointed a Knight Commander of the Order of the Nation (KCN) by the Antiguan Barbudan government on 28 February 2014, alongside Richardson and Andy Roberts.
Style and technique.
Mike Selvey wrote in "The Guardian" in 1991 that Ambrose had "the sort of easy, repetitive, no-sweat action which is the key to unyielding accuracy. There is no respite and all his other qualities are byproducts." At his peak, Ambrose did not rely on pronounced swing or seam movement of the ball. Instead, he repeatedly bowled into the same areas of the pitch and the height from which he delivered the ball made him extremely difficult to face. The ball bounced sharply after pitching, sometimes deviating slightly from a straight line after pitching on the seam, and frequently took the edge of the batsman's bat to be caught behind the wicket. His 1992 citation as "Wisden" Cricketer of the Year states that he had "outright pace and he generates a disconcerting, steepling bounce from fuller-length deliveries ... His height and a slender, sinewy wrist contribute greatly to the final velocity the ball, the wrist snapping forward at the instant of release to impart extra thrust". Writing in 2001 following Ambrose's retirement, Michael Atherton, whom Ambrose dismissed more often than any other batsman, said: "At his best, there is no doubt that moved beyond the fine line that separates the great from the very good. Quality bowlers essentially need two of three things: pace, movement and accuracy. Ambrose had all three."
Ambrose's height, and the accuracy with which he bowled, made it difficult for batsmen to play forward to the ball; instead they were forced to play with their weight going back. His accuracy meant that he was effective if the pitch favoured batsmen. He bowled an effective yorker, and unlike other fast bowlers, used short-pitched deliveries sparingly, although he could bowl a hostile bouncer, and concentrated on bowling a full length aimed at the wickets. Ambrose rarely engaged in verbal sparring with batsmen, although in later years he occasionally inspected the pitch in an area close to the batsman before an innings began and rubbed his hands to suggest that he would enjoy bowling there. He always aimed to concede as few runs as possible when bowling, and frequently berated himself when he offered an easy delivery from which to score. Following his dismissal of a batsman, Ambrose often celebrated by pumping the air with his fists. With Courtney Walsh, Ambrose developed a reputation for performing at his best when his team seemed likely to lose, and he often took wickets in clusters which devastated the opposition. In addition, he was often most effective against the leading batsmen on a team; he was also capable of exploiting vulnerabilities in the techniques of other batsmen.
As of 2012, Ambrose's 405 Test wickets place him 11th on the list of leading Test wicket-takers. Of those who have taken over 200 Test wickets, Ambrose has the third best bowling average behind Malcolm Marshall and Joel Garner, and has the eighth best economy rate; he rises to third if only those who have taken over 250 wickets are included. For much of his career, Ambrose was rated the world's best bowler in the ICC player rankings, first reaching the top in 1991; he rarely dropped below second and was ranked in the top 10 from 1989 until the end of his career. His highest rating of 912 in the rankings, which he achieved in 1994, is the equal sixth best rating of all time. In 2010, Ambrose was chosen by a panel of writers and experts as a member of ESPNcricinfo's "All-Time XI" for West Indies. The following year, he was inducted into the International Cricket Council Hall of Fame. During his playing days, Ambrose had a reputation for reticence, and rarely spoke to journalists or the opposition. His response to a request for an interview in 1991—"Curtly talks to no-one"— became associated with him throughout his career, but he was more willing to talk to journalists after he retired.

</doc>
<doc id="58100" url="https://en.wikipedia.org/wiki?curid=58100" title="Bard the Bowman">
Bard the Bowman

Bard the Bowman is a character in J. R. R. Tolkien's "The Hobbit". A Man of Laketown and a descendant of the ancient Lords of Dale, Bard manages to kill Smaug, the dragon, after which he becomes king of Dale. Tolkien created the character specifically to kill Smaug, since none of the other protagonists of the story were able to fulfill this role. Bard the Bowman could have been inspired by Wiglaf from Anglo-Saxon poem "Beowulf".
Fictional history.
Bard is a descendant of Girion, the last lord of the city Dale, which had been destroyed by the dragon Smaug two centuries before the events of "The Hobbit", which takes place in year 2941 of the Third Age. He is the captain of a company of archers in Esgaroth (Lake-town), and is tall and grim with black hair. When Smaug attacks Lake-town, Bard is the last of the archers to survive, but the dragon is immune to arrows. However, a thrush speaks to Bard, showing him the weak spot in the dragon's armour in the hollow under Smaug's left breast, which Bilbo had discovered in his conversation with Smaug. He fires his favourite shaft, the family heirloom "Black Arrow", so powerfully that it kills Smaug, who falls in ruin into the lake.
After the dragon's death, Bard joins the survivors of the attack on Lake-town and discovers that they had thought him dead. The survivors receive assistance from the elves of the Mirkwood, and together Thranduil and the able-bodied men of Lake-town travel to the Lonely Mountain to claim a share of the dragon hoard. In the absence of Thorin Oakenshield and his company, all believed to have been killed by the dragon, Bard has a rightful claim to the treasure as the heir of Girion, and also a charitable claim to alleviate the suffering of the people of Lake-town.
However, at the Lonely Mountain, Bard discovers that Thorin Oakenshield, King under the Mountain, is very much alive, along with all his companions. Their response to Bard's claim is to barricade themselves inside the mountain, refusing to surrender any of the treasure.
To break the stalemate, Bilbo Baggins slips out of the mountain at night and offers the Arkenstone to Bard in order to put pressure on Thorin to make peace with the Elves and Men. However, Thorin is unwilling to share any of Smaug's treasure with an armed host at his gates, which causes the elves and men to prepare to attack the mountain. To make matters worse, Thorin's cousin Dáin II Ironfoot arrives to reinforce Thorin's claim to their family home under the mountain. However, a large army of Orcs and Wargs arrives on the scene, forcing the three armies to unite to fight against them. Bard leads the men into battle, reinforced by the arrival of Beorn and the Eagles.
After the death of Thorin in the Battle of Five Armies, Dain becomes King under the Mountain. He redeems the Arkenstone from Bard with a fourteenth of the treasure, which is used to re-establish Dale. Over the next three years, Bard rebuilds the city of Dale and becomes its king. The city begins to prosper again.
Bard's reign lasts for thirty-three years. He is succeeded by his son Bain in 2977, and then by his grandson Brand in 3007.
Creation.
During the drafting of "The Hobbit", Tolkien considered how Smaug should die, and who would kill him. Tolkien's notes for chapter nine show him considering the option of Bilbo killing the dragon in his sleep, piercing his weak point with a lance, similar to the events in Jack the Giant Killer. This idea remained in the notes after the writing of chapter eleven, but after chapter twelve was complete, Tolkien wrote "Dragon killed in the Battle of the Lake" in the margin of his notes.
Bard appears during the drafting for chapter thirteen, when it is said that he kills the dragon with his ancestor Girion's favourite Black Arrow. Tolkien's keeping Bard alive for the rest of the story significantly complicates it since, as the heir of Girion, Bard gives the inhabitants of Lake-town a legitimate claim to Smaug's treasure.
Depictions.
Film.
Bard was voiced by John Stephenson in the 1977 Rankin/Bass animated television musical. Stephenson also voiced the Dwarf Dori and the The Great Goblin.
Bard (or "Berd") was played by Boris Sokolov in the 1985 Russian television film.
Welsh actor Luke Evans portrays Bard in ' (2013) and ' (2014). He was cast in June 2011. Bob Strauss of "Los Angeles Daily News" felt that Evans' portrayal managed to expand on the character, while Erik Kain of "Forbes" felt that his portrayal was "solid", but was "never given quite enough breathing room".
Other.
Bard was voiced by Peter Williams in the 1968 BBC Radio adaptation.
Bard is one of the cards in Iron Crown Enterprises's 1995 collectible card game, with art by Angelo Montanini.
André Sogliuzzo played Bard in the 2003 platform game by Inevitable Entertainment. He also played the part of Ugslap.
Luke Evans reprised his role from the live-action film series in the 2014 follow-up to Warner Bros. Interactive Entertainment's "Lego The Lord of the Rings".
Criticism and analysis.
According to John D. Rateliff, Bard could have been inspired by Wiglaf from Anglo-Saxon poem "Beowulf", which inspired Tolkien with many elements in the final chapters of "The Hobbit". Like Bard, Wiglaf is introduced late into the story, is not named until late in the story, is the only one with enough courage to face a dragon, and is of royal lineage.
Rateliff believes that Bard is the first character in Tolkien's work to experience a happy but tragic fate, unlike Beren, Húrin, and Túrin Turambar. Rateliff sees Bard as a precursor and foreshadower of Aragorn: both restore their ancestor's kingdoms in all their glory. Marjorie Burns believes that Bard is a humble hero like Aragorn, Faramir and Gandalf, all brought into Tolkien's legendarium to replace the powerful unworthy, such as the mayor of Lake-town, Denethor, Boromir, and Saruman. In his initial appearance, Bard is shown as a negative character who always sees the worst side of situations, but Sumner G. Hunnewell believes that Bard shows happiness and generosity after the destruction of Lake-town.

</doc>
<doc id="58101" url="https://en.wikipedia.org/wiki?curid=58101" title="Smaug">
Smaug

Smaug () is a fictional dragon and the primary antagonist in J. R. R. Tolkien's 1937 novel "The Hobbit". He is a powerful, intelligent, malevolent and fearsome dragon who invaded the Dwarf kingdom of Erebor 150 years prior to the events described in the novel. A group of 13 Dwarves mounted a quest to take the kingdom back, aided by the wizard Gandalf and the Hobbit Bilbo Baggins. Smaug is described as "a most specially greedy, strong and wicked worm". Smaug appears in the Hobbit film adaption as one of the main antagonists.
Appearances.
"The Hobbit".
One of the last great Fire-drakes of Middle-earth, Smaug rose to prominence by laying waste to the town of Dale and capturing the Dwarf-kingdom of the Lonely Mountain (Erebor) with all of its treasure. These events occurred some 150 years before the events of "The Hobbit", and Smaug was already centuries old at the time. "The Hobbit" recounts the tale of a party of dwarves (consisting of a few of the original residents of the Lonely Mountain and their descendants), the hobbit Bilbo Baggins, and their quest to recapture the mountain and kill the dragon. In the book, the dragon is sometimes called Smaug the Golden or Smaug the Magnificent.
Centuries spent sleeping atop his gold hoard have caused gold and gemstones to become embedded in the skin of Smaug's underside, augmenting the already impenetrable scales that covered most of his body; but when Bilbo observes Smaug in his lair, he discovers a small bare patch, of which a thrush tells Bard the Bowman, when Smaug later attacks Bard's native town of Esgaroth; whereupon the archer kills Smaug with an arrow. Among the items in Smaug's possession are the Arkenstone and a number of "mithril" mail shirts, one of which was given to Bilbo by Thorin Oakenshield. In "The Lord of the Rings", years later, the shirt saves Bilbo's kinsman, Frodo Baggins, from various injuries.
"The Return of the King".
In Appendix A, section III, of "The Return of the King" under "Durin's Folk", Smaug is mentioned briefly as "the greatest of the dragons of his day". Having heard rumour of the great wealth of Erebor, he "arose and without warning came against King Thrór and descended on the mountain in flames." In this text, dragons are stated to reside in the wastes (Withered Heath) beyond the Grey Mountains, "making war on the Dwarves, and plundering their works". It can be inferred that Smaug came from this region.
"Unfinished Tales".
As stated in the tale "The Quest of Erebor", Gandalf knew that Smaug could pose a serious threat if used by Sauron, then dwelling in Dol Guldur in Mirkwood; assumed that Smaug would not recognize the scent of a Hobbit; and therefore asked Bilbo to accompany the dwarves.
Concept and creation.
Tolkien created numerous pencil sketches and two pieces of more detailed artwork portraying Smaug. The latter were a detailed ink and watercolour labelled "Conversation with Smaug" and a rough coloured pencil and ink sketch entitled "Death of Smaug". While neither of these appeared in the original printing of "The Hobbit" due to cost constraints, both have been included in subsequent editions and "Conversation with Smaug" has been used extensively. "Death of Smaug" was used for the cover of an early UK paperback edition of "The Hobbit".
From 1925 to 1945, Tolkien was a professor of Anglo-Saxon at Oxford University, and a prominent critic of and expert on "Beowulf" — on which he gave a lecture at the British Academy in 1936 and which he described as one of his "most valued sources" for "The Hobbit". Many of Smaug's attributes and behaviour in "The Hobbit" derive directly from the unnamed "old night-scather" in "Beowulf": great age; winged, fiery, and reptilian form; a stolen barrow within which he lies on his hoard; disturbance by a theft; and violent airborne revenge on the lands all about. Smaug was intimately familiar with every last item within his hoard, and instantly noticed the theft of a relatively inconsequential cup by Bilbo Baggins. Tolkien writes that Smaug's rage was the kind which "is only seen when rich folk that have more than they can enjoy lose something they have long had but never before used or wanted." This theft of a cup, Smaug's knowledge of every item in the hoard, and the dragon's ensuing rampage, all echo the story of "Beowulf".
Tolkien may also have been inspired by the talking dragon Fafnir of the "Völsunga saga".
Tolkien noted that "the dragon bears as name—a pseudonym—the past tense of the primitive Germanic verb "smúgan", to squeeze through a hole: a low philological jest."
Smaug was depicted by Tolkien as an intelligent being capable of speech, easily pleased by flattery and fascinated by Bilbo's description of himself in riddles. This is also done in later film adaptations such as "". He is described as having "quite an overwhelming personality" and every time his eyes flash across Bilbo's invisible form, he feels almost compelled to tell him the truth about himself because of the hypnotic power within.
Portrayal in adaptations.
"The Hobbit" (1977).
In the 1977 animated version of "The Hobbit", Smaug was voiced by Richard Boone. In general, Smaug's design in the animated version is consistent with Tolkien's description, save for his face: for rather than the traditional reptilian look associated with dragons, Smaug's face in the animated version has distinctly cat-like features including fur, enlarged ears, and canine teeth. His hypnotic speech is absent, but his acute eyesight is portrayed by highbeam-like lights projected from his eyes.
"The Hobbit" (film series).
On June 16, 2011, it was announced that Smaug would be voiced and interpreted with performance capture by Benedict Cumberbatch in Peter Jackson's three-part adaptation of "The Hobbit", wherein Smaug is presented with a long head, red-golden scales, and piercing yellow-red eyes. The dragon speaks with Received Pronunciation with an underlying growl; Cumberbatch's vocal performance was vocoded using alligator growls. Smaug's design was created with key frame animation, in addition to Cumberbatch's motion capture performance. Weta Digital employed its proprietary "Tissue" software which was honoured in 2013 with a "Scientific and Engineering Award" from the Academy of Motion Picture Arts and Sciences to make the dragon as realistic as possible. In addition, Weta Digital supervisor Joe Letteri said in an interview for "USA Today" that they used classic European and Asian dragons as inspirations to create Smaug.
Smaug was considered one of the highlights of the second film of the series, with several critics hailing him as cinema's greatest dragon. Critics also praised the visual effects company Weta Digital and Cumberbatch's vocal and motion-capture performance for giving Smaug a fully realized personality. Prior to the Hobbit trilogy, Smaug was mentioned in its 2001 sequel "".
Others.
In the 1977 "J.R.R. Tolkien Calendar", the Brothers Hildebrandt depicted Smaug with bright red scales and large bat-like wings. In the 2003 video game release, Smaug was voiced by James Horan.

</doc>
<doc id="58102" url="https://en.wikipedia.org/wiki?curid=58102" title="Beorn">
Beorn

Beorn is a fictional character created by J. R. R. Tolkien. He appears in "The Hobbit" as a "skin-changer", a man who could assume the appearance of a great black bear.
Appearances.
"The Hobbit".
The Man named Beorn lived with his animal retinue (horses, dogs, sheep, and cows, among others) in a wooden house between the Misty Mountains and Mirkwood, to the east of the Anduin. According to Gandalf, Beorn "does not eat them; neither does he hunt or eat wild animals". Gandalf believed that Beorn was either a descendant of the bears who had lived in the Misty Mountains before the arrival of the giants, or he was a descendant of the men who had lived in the region before the arrival of the dragons or Orcs from the north.
Beorn was of immense size and strength for a man, and retained his size and strength in bear-form. He had black hair (in either form) and a thick black beard and broad shoulders (in human form). While not a "giant" outright, Beorn's human form was of such great size that the three and a half foot tall Bilbo judged that he could have easily walked between Beorn's legs without touching his body. Beorn also named the Carrock and created the steps that led from its base to its flat top.
In "The Hobbit", Beorn received Gandalf, Bilbo Baggins, and 13 Dwarves, and aided them in their quest to reclaim their kingdom beneath the Lonely Mountain. He was convinced of their trustworthiness after confirming their tale of encountering the Goblins of the Misty Mountains and Gandalf's slaying of their leader, the Great Goblin. In addition to giving the group much-needed supplies and lodging, Beorn gave them vital information about what path to take while crossing Mirkwood.
Later, hearing of a vast host of Goblins on the move, Beorn arrived at the Lonely Mountain in time to strike the decisive blow in the Battle of Five Armies. In his bear form he slew the Goblin leader, Bolg and his bodyguards. Without direction, the Goblin army scattered and were easy pickings for the other armies of Men, Elves, Dwarves, and Eagles. Beorn often left his home during the narrative of "The Hobbit" for hours or days at a time, for purposes not completely explained.
"The Lord of the Rings".
In the years between the Battle of Five Armies and the War of the Ring, possibly spurred by his interaction with Thorin's company, Beorn emerged from his reclusion, and rose to become a leader of the woodmen living between the Anduin river and the fringes of Mirkwood. As stated by Glóin in "The Fellowship of the Ring", the Beornings also "keep open the High Pass and the Ford of Carrock."
Some time before the War of the Ring itself began, Beorn was succeeded by his son Grimbeorn the Old. His death is not included in the chronologies in "The Return of the King"'s appendices.
Concept and creation.
In naming his character, Tolkien used "beorn", an Old English word for "bear", which later came to mean "man" and "warrior" (with implications of "freeman" and "nobleman" in Anglo-Saxon society). It is related to the Scandinavian names "Björn" (Swedish and Icelandic) and "Bjørn" (Norwegian and Danish), meaning "bear".
Adaptations.
Swedish actor Mikael Persbrandt portrays Beorn in Peter Jackson's "" and in its sequel "." In the film, he indicates that his people once lived in the Misty Mountains, but were conquered by the Orcs under Azog, who captured and tortured his people for sport, and killed them until only one remained. Beorn eventually escaped, but still carries a chain around his wrist from his imprisonment. In the extended edition, Beorn tells Gandalf of the alliance between the Orcs of Moria and the Necromancer of Dol Guldur, and he also inquires about the nine, who have been seen wandering near the High Fells of Rhudaur. Beorn arrives to the Battle of the Five Armies atop a Great Eagle rather than on foot and does not slay Bolg, who is killed by Legolas in the film adaptation (the Orc commander was also changed to be Azog himself, but Thorin kills Azog in single combat instead of Beorn). In the DVD commentary, the production team explained that they normally take great care that characters only speak with accents which were historically present in the British Isles, but they made a major exception for Beorn by letting Persbrandt use his natural Swedish accent. They reasoned that Beorn should logically have a very distinctive and foreign-sounding accent, given that he is the last survivor of an isolated race which had little contact with people from regions such as Gondor or the Shire. 
In the 2003 video game adaptation the original encounter with Beorn at his lodge is omitted. Nevertheless, he still shows up at the Battle of Five Armies to kill Bolg. Beorn only appears in bear form in the game. 
The Beornings appear as trainable units in "" (2003) and in "Third Age Total War" (2013). The Beornings were added as a playable class to the massively multiplayer online role-playing game "The Lord of the Rings Online" in Update 15 (November 2014). The players can play as a male or a female Beorning, and can transform into a bear after building up sufficient wrath whilst engaged in combat. Grimbeorn's Lodge in the Vales of Anduin has also been added to the game as a starter area for the Beorning class and Grimbeorn himself also makes a brief appearance.

</doc>
