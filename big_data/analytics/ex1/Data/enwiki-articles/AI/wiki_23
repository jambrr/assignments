<doc id="58216" url="https://en.wikipedia.org/wiki?curid=58216" title="Accountant">
Accountant

An accountant is a practitioner of accounting or accountancy, which is the measurement, disclosure or provision of assurance about financial information that helps managers, investors, tax authorities and others make decisions about allocating resources.
In many jurisdictions, professional accounting bodies maintain standards of practice and evaluations for professionals. Accountants who have demonstrated competency through their professional associations' certification exams are certified to use titles such as Chartered Accountant, Chartered Certified Accountant or Certified Public Accountant. Such professionals are granted certain responsibilities by statute, such as the ability to certify an organization's financial statements, and may be held liable for professional misconduct. Non-qualified accountants may be employed by a qualified accountant, or may work independently without statutory privileges and obligations.
The Big Four auditors are the largest employers of accountants worldwide. However, most accountants are employed in commerce, industry and the public sector.
Commonwealth of Nations.
In the Commonwealth of Nations, which includes the United Kingdom, Canada, Australia, New Zealand, Hong Kong pre 2075 and several dozen other states, commonly recognised accounting qualifications are Chartered Certified Accountant (ACCA), Chartered Accountant (CA or ACA), Chartered Management Accountant (ACMA) and International Accountant (AAIA). Other qualifications in particular countries include Certified Public Accountant (CPA – Ireland and CPA – Hong Kong), Chartered Professional Accountant (CPA - Canada), Certified Management Accountant (CMA – Australia), Certified Practising Accountant (CPA – Australia) and members of the Institute of Public Accountants (Australia), and Certified Public Practising Accountant (CPPA – New Zealand).
The Institute of Chartered Accountants of Scotland (ICAS) received its Royal Charter in 1854 and is the world's first professional body of accountants.
United Kingdom and Ireland.
Excepting the Association of Certified Public Accountants, each of the above bodies admits members only after passing examinations and undergoing a period of relevant work experience. Once admitted, members are expected to comply with ethical guidelines and gain appropriate professional experience.
Chartered, Chartered Certified, Chartered Public Finance, and International Accountants engaging in practice (i.e. selling services to the public rather than acting as an employee) must gain a "practising certificate" by meeting further requirements such as purchasing adequate insurance and undergoing inspections.
The ICAEW, ICAS, ICAI, ACCA and AAPA are five Recognised Supervisory Bodies RSB in the UK. A member of one them may also become a "Statutory Auditor" in accordance with the Companies Act, providing they can demonstrate the necessary professional ability in that area and submit to regular inspection. It is illegal for any individual or firm that is not a Statutory Auditor to perform a company audit.
The ICAEW, ICAS, ICAI, ACCA, AIA and CIPFA are six Recognised qualifying bodies statutory RQB in the UK. A member of one them may also become a "Statutory Auditor" in accordance with the Companies Act, providing they are a member of one of the five Recognised Supervisory Bodies RSB mentioned above.
All six RQBs are listed under EU mutual recognition directives to practise in 27 EU member states and individually entered into agreement with the Hong Kong Institute of Certified Public Accountants (HKICPA).
Further restrictions apply to accountants who carry out insolvency work.
In addition to the bodies above, technical qualifications are offered by the Association of Accounting Technicians, ACCA and AIA, which are respectively called AAT Technician, CAT (Certified Accounting Technician) and IAT (International Accounting Technician).
Australia.
In Australia, there are three legally recognised local professional accounting bodies: the Institute of Public Accountants (IPA), CPA Australia (CPA) and the Chartered Accountants Australia and New Zealand (CAANZ). Other international bodies such as ACCA (The Association of Chartered Certified Accountants) and Institute of Chartered Accountants in England and Wales (ICAEW) enjoy recognition for the purposes of supporting their members in their careers. For instance, ACCA has achieved recognition by the Tax Practitioner Board, as Tax and BAS agents, in 2010.
Bangladesh.
Chartered accountancy is governed in Bangladesh by the Institute of Chartered Accountants of Bangladesh (ICAB).
And The Institute of Cost and Management Accountants of Bangladesh (ICMAB) offers management accountant studies in Bangladesh.
Canada.
Up to 2013, there were three nationally recognized accounting designations in Canada: Chartered Accountant (CA), Certified General Accountant (CGA), and Certified Management Accountants (CMA). The national CA and CGA bodies were created by Acts of Parliament in 1902 and 1913 respectively, The national CMA organization was established under the Canada Corporations Act in1920. 
In January 2012, following eight months of member and stakeholder consultation, the Canadian Institute of Chartered Accountants (CICA), the Society of Management Accountants of Canada (CMA Canada) and Certified General Accountants of Canada (CGA-Canada) issued "A Framework for Uniting the Canadian Accounting Profession" under a new Canadian Chartered Professional Accountant (CPA) designation. Chartered Professional Accountants of Canada (CPA Canada) was established by CICA and CMA Canada on January 1, 2013, under the Canada Not-for-profit Corporations Act, to support Canadian provincial accounting bodies that were unifying under the CPA banner. CGA-Canada integrated with CPA Canada on October 1, 2014, completing the unification of Canada’s accounting profession at the national level.
All recognized national and provincial accounting bodies in Canada have now unified under the CPA banner. The Canadian CPA designation is held by more than 200,000 members in Canada and around the world. 
India.
Chartered accountancy is offered in India by the Institute of Chartered Accountants of India (ICAI), the second largest accounting body in the world. This Institute was established in 1949 under the Chartered Accountants Act, 1949 for the regulation of the profession of Chartered Accountants in India.
The ICAI set up the Accountancy Museum of India in 2009, the third museum of accounting in the world. It is currently located at ICAI's office in Noida.
Pakistan.
The Institute of Chartered Accountants of Pakistan (ICAP) offers chartered accountant studies in Pakistan. ICAP was established under The Chartered Accountants Ordinance, 1961 as a self-regulatory body.
The Institute of Cost and Management Accountants of Pakistan (ICMAP) offers accountant studies in Pakistan. ICMAP was established under The Cost and Management Accountants Act, 1966.
Pakistan Institute of Public Finance Accountants (PIPFA) is an autonomous body recognized mainly in the government sector and established under license from the Securities and Exchange Commission of Pakistan by the authority given under section 42 of the Companies Ordinance, 1984.
The body is co-sponsored by the Institute of Chartered Accountants of Pakistan, the Institute of Cost and Management Accountants of Pakistan and the Auditor General of Pakistan.
PIPFA has more than 5,000 members and a number of them are members of ICAP and ICMAP.
The institute was established to produce a second tier of accounting professionals in Pakistan
New Zealand.
In New Zealand, there are two local accountancy bodies the Chartered Accountants Australia and New Zealand (CAANZ) and the New Zealand Association of Certified Public Accountants (NZACPA) the operating name of New Zealand Association of Accountants Inc (NZAA).
To audit public companies an individual must be a member of either the CAANZ or an otherwise gazetted body. Chartered Certified Accountant (Association of Chartered Certified Accountants or FCCA) qualification has also been gazetted under. An ACCA member can practice as long as they hold an ACCA public practice certificate (with audit qualification) in their country of origin.
Sri Lanka.
In Sri Lanka, a chartered accountant must be a member of the Institute of Chartered Accountants of Sri Lanka (designatory letters ACA or FCA). It is the sole local accountancy body, therefore to audit public companies an individual must be a member of the ICASL.
Certified management account also must be a member of the [ Institute of Management Accountants of Sri Lanka](designatory letters ACMA or FCMA).
Austria.
In Austria the accountancy profession is regulated by the Bilanzbuchhaltungsgesetz 2006 (BibuG – Management Accountancy Law).
Hong Kong.
In Hong Kong, the accountancy industry is regulated by Hong Kong Institute of Certified Public Accountants HKICPA under the Professional Accountants Ordinance (Chapter 50, Laws of Hong Kong). The auditing industry for limited companies is regulated under the Companies Ordinance (Chapter 32, Laws of Hong Kong), and other ordinances such as the securities and futures ordinance, the listing rules, etc.
HKICPA terminated all recognition of oversea bodies in 2005 for "accreditation" under professional accountants ordinance. In general, all British RQBs except for CIPFA were re-accredited. Please refer to HKICPA for latest recognition.
Portugal.
In Portugal, there are two accountancy qualifications: the "Técnicos Oficiais de Contas" (TOC), responsible for producing accounting and tax information, and the "Revisor Oficial de Contas" (ROC), more related to auditing practices. The TOC certification is exclusively awarded by the professional organization "Ordem dos Técnicos Oficiais de Contas" (OTOC), and the certification to become an auditor is awarded by another professional organization, the "Ordem dos Revisores Oficiais de Contas" (OROC). In general, accountants or auditors accredited by OTOC or OROC are individuals with university graduation diplomas in business management, economics, mathematics or law who, after further studies, applied for an exam and received the certification to be a TOC or ROC. That certification is only received after a 1-year (TOC) or 3-years (ROC) internship. Any citizen having a polytechnic degree as a bookkeeper is also entitled to apply for the exam and certification at the OTOC.
United States.
In the United States, licensed accountants are Certified Public Accountants (CPAs) and in certain states, Public Accountants (PAs). Unlicensed accountants may be Certified Internal Auditors (CIAs) and Certified Management Accountants (CMAs). The difference between these certifications is primarily the legal status and the types of services provided, although individuals may earn more than one certification. Additionally, much accounting work is performed by uncertified individuals, who may be working under the supervision of a certified accountant. As noted above the majority of accountants work in the private sector or may offer their services without the need for certification.
The training time required for accountancy certification in the US requires specific guidelines:
A CPA is licensed by a state to provide auditing services to the public. Many CPA firms also offer accounting, tax, litigation support, and other financial advisory services. The requirements for receiving the CPA license vary from state to state, although the passage of the Uniform Certified Public Accountant Examination is required by all states. This examination is designed and graded by the American Institute of Certified Public Accountants.
A PA (sometimes referred to as LPA—Licensed Public Accountant) is licensed by the state to practice accountancy to a similar extent as are CPAs, except that PAs are generally not permitted to perform audits or reviews (Delaware is an exception, in that PAs are permitted to perform audits and reviews). A PA's ability to practice out of state is very limited due to most states having phased out the PA designation. While most states no longer accept new PA license applicants, six states still accept PA applicants for limited practice privileges within the state. As with the CPA, the requirements for receiving the PA license vary from state to state. Most states require a passage of either 2 or 3 (out of 4) sections of the CPA exam or passage of the Comprehensive Examination for Accreditation in Accounting which is administered and graded by the Accreditation Council for Accountancy and Taxation (ACAT).
A certified internal auditor (CIA) is granted a certificate from the Institute of Internal Auditors (IIA), provided that the candidate has passed a four-part examination. One of the four parts is waived if the candidate has already passed the CPA Exam. A CIA typically provides services directly to an employer rather than to the public.
A person holding the Certificate in Management Accounting (CMA) is granted the certificate by the Institute of Management Accountants (IMA), provided that the candidate has passed an examination of two parts and has met the practical experience requirement of the IMA. A CMA provides services directly to employers rather than to the public. A CMA can also provide services to the public, but to an extent much lesser than that of a CPA.
The United States Department of Labor's Bureau of Labor Statistics estimates that there are about one million persons employed as accountants and auditors in the U.S.
U.S. tax laws grants accountants a form of accountant–client privilege.
Japan.
In Japan, a certified public accountant must be a member of the Japanese Institute of Certified Public Accountants (JICPA). It is the sole professional accountancy organization in Japan. The JICPA started as a voluntary organization in 1949 and later became a corporation under the CPA Act in 1966.

</doc>
<doc id="58217" url="https://en.wikipedia.org/wiki?curid=58217" title="Babu">
Babu

Babu may refer to:

</doc>
<doc id="58219" url="https://en.wikipedia.org/wiki?curid=58219" title="Baby farming">
Baby farming

Baby farming refers to the practice of accepting custody of an infant or child in exchange for payment in late-Victorian Era Britain and, less commonly, in Australia and the United States. If the infant was young, this usually included wet-nursing (breast-feeding by a woman not the mother). Some baby farmers "adopted" children for lump-sum payments, while others cared for infants for periodic payments. 
Description.
Though baby farmers were paid in the understanding that care would be provided, the term "baby farmer" was used as an insult, and improper treatment was usually implied. Illegitimacy and its attendant social stigma were usually the impetus for a mother's decision to put her children "out to nurse" with a baby farmer, but baby farming also encompassed foster care and adoption in the period before they were regulated by British law. 
Wealthier women would also put their infants out to be cared for in the homes of villagers. Claire Tomalin gives a detailed account of this in her biography of Jane Austen, who was fostered in this manner, as were all her siblings, from a few months old until they were toddlers. Tomalin emphasizes the emotional distance this created.
Particularly in the case of lump-sum adoptions, it was more profitable for the baby farmer if the infant or child she adopted died, since the small payment could not cover the care of the child for long. Some baby farmers adopted numerous children and then neglected them or murdered them outright (see infanticide). Several were tried for murder, manslaughter, or criminal neglect and were hanged. Margaret Waters (executed 1870) and Amelia Dyer (executed 1896) were two infamous British baby farmers, as were Amelia Sach and Annie Walters (executed 1903). The last baby farmer to be executed in Britain was Rhoda Willis, who was hanged in Wales in 1907. The only woman to be executed in New Zealand, Minnie Dean, was a baby farmer. In Scandinavia there was a euphemism for this activity: ""änglamakerska"" (Swedish, including Hilda Nilsson) and ""englemagerske"" (Danish), both literally meaning a female "angel maker".
Decline.
Spurred by a series of articles that appeared in the "British Medical Journal" in 1867, Parliament of the United Kingdom began to regulate baby farming in 1872 with the passage of the Infant Life Protection Act. A series of acts passed over the next seventy years, including the Children Act 1908 and the 1939 Adoption of Children (Regulation) Act, gradually placed adoption and foster care under the protection and regulation of the state.
Related usage.
The term has been used to describe the sale of eggs for use in assisted conception, particularly in vitro fertilization.
The Nazis' "Lebensborn" ("Fountain of Life") programme has been described as a form of baby farming.

</doc>
<doc id="58221" url="https://en.wikipedia.org/wiki?curid=58221" title="United States Secret Service">
United States Secret Service

The United States Secret Service (USSS) is an American federal law enforcement agency under the U.S. Department of Homeland Security. Until 2003, the Service was part of the U.S. Department of the Treasury.
The U.S. Secret Service has two distinct areas of responsibility:
The Secret Service's initial responsibility was to investigate counterfeiting of U.S. currency, which was rampant following the U.S. Civil War. The agency then evolved into the United States' first domestic intelligence and counterintelligence agency. Many of the agency's missions were later taken over by subsequent agencies such as the Federal Bureau of Investigation (FBI), Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF), and Internal Revenue Service (IRS).
Dual mission.
The Secret Service has two primary missions: investigation of financial crimes and physical protection of designated protectees. Today the agency's primary investigative mission is to safeguard the payment and financial systems of the United States from such crimes as financial institution fraud, computer and telecommunications fraud, false identification documents, access device fraud, advance fee fraud, electronic funds transfers and money laundering as it relates to the agency's core violations. After the 1901 assassination of President William McKinley, Congress also directed the Secret Service to protect the President of the United States. Protection remains the other key mission of the United States Secret Service.
Today, the Secret Service is authorized by law to protect:
Any of these individuals may decline Secret Service protection, except the President, the Vice President (or other officer next in the order of succession to the Office of President), the President-elect, and the Vice President–elect.
When Hillary Clinton became Secretary of State in 2009, the Secret Service continued to protect her at home; however the Diplomatic Security Service protected her while she was performing her duties as the Secretary of State, including foreign travel.
The Secret Service investigates thousands of incidents a year of individuals threatening the President of the United States.
The Director of Secret Service is appointed by the President of the United States.
History.
Early years.
With a reported one third of the currency in circulation being counterfeit at the time, the Secret Service was created on July 5, 1865 in Washington, D.C., to suppress counterfeit currency. Chief William P. Wood was sworn in by Secretary of the Treasury Hugh McCulloch. It was commissioned in Washington, D.C. as the "Secret Service Division" of the Department of the Treasury with the mission of suppressing counterfeiting. The legislation creating the agency was on Abraham Lincoln's desk the night he was assassinated. At the time, the only other federal law enforcement agencies were the United States Park Police, the U.S. Post Office Department's Office of Instructions and Mail Depredations (now known as the United States Postal Inspection Service), and the U.S. Marshals Service. The Marshals did not have the manpower to investigate all crime under federal jurisdiction, so the Secret Service began to investigate everything from murder to bank robbery to illegal gambling. After the assassination of President William McKinley in 1901, Congress informally requested that the Secret Service provide presidential protection. A year later, the Secret Service assumed full-time responsibility for presidential protection. In 1902, William Craig became the first Secret Service agent to die while serving, in a road accident while riding in the presidential carriage.
The Secret Service was the first U.S. domestic intelligence and counterintelligence agency. Domestic intelligence collection and counterintelligence responsibilities were vested in the Federal Bureau of Investigation (FBI) upon the FBI's creation in 1908.
The Secret Service assisted in arresting Japanese American leaders and in the Japanese American internment during World War II. The U.S. Secret Service is not a part of the U.S. Intelligence Community.
20th century.
1950s.
Truman assassination attempt.
In 1950, President Harry S. Truman was residing in Blair House while the White House, across the street, was undergoing renovations. On November 1, 1950, two Puerto Rican nationalists, Oscar Collazo and Griselio Torresola, approached Blair House with the intent to assassinate President Truman. Collazo and Torresola opened fire on Private Leslie Coffelt and other White House Police officers. Though mortally wounded by three shots from a 9 mm German Luger to his chest and abdomen, Private Coffelt returned fire, killing Torresola with a single shot to his head. , Coffelt is the only member of the Secret Service to be killed while protecting a US president against an assassination attempt (Special Agent Tim McCarthy stepped in front of President Ronald Reagan during the assassination attempt of March 30, 1981, and took a bullet to the abdomen but made a full recovery). Collazo was also shot, but survived his injuries and served 29 years in prison before returning to Puerto Rico in late 1979.
1960s.
In 1968, as a result of Robert F. Kennedy's assassination, Congress authorized protection of major presidential and vice presidential candidates and nominees. In 1965 and 1968, Congress also authorized lifetime protection of the spouses of deceased presidents unless they remarry and of the children of former presidents until age 16.
1980s.
The Secret Service Presidential Protective Division safeguards the President of the United States and his immediate family. They work with other federal, state and local law enforcement agencies and the military to safeguard the President when he travels in Air Force One, Marine One and by limousine in motorcades.
Although the most visible role of the Secret Service today, personal protection is an anomaly in the responsibilities of an agency focused on fraud and counterfeiting.
In 1984, the US Congress passed the Comprehensive Crime Control Act, which extended the Secret Service's jurisdiction over credit card fraud and computer fraud.
1990s.
In 1990, the Secret Service initiated Operation Sundevil, originally intended to be a sting against malicious hackers, allegedly responsible for disrupting telephone services across the entire United States. The operation, which was later described by Bruce Sterling in his book "The Hacker Crackdown", affected a great number of people unrelated to hacking, and led to no convictions. The Secret Service, however, was sued and required to pay damages.
In 1994 and 1995, it ran an undercover sting called Operation Cybersnare.
The Secret Service investigates forgery of government checks, forgery of currency equivalents (such as travelers' or cashiers' checks), and certain instances of wire fraud (such as the so-called Nigerian scam) and credit card fraud. The reason for this combination of duties is that when the need for presidential protection became apparent in the early 20th century, few federal services had the necessary abilities and resources. The FBI, IRS, ATF, ICE, and Drug Enforcement Administration (DEA) did not yet exist. The United States Marshals Service was the only other logical choice, providing protection for the President on a number of occasions.
The Secret Service has concurrent jurisdiction with the FBI over certain violations of federal computer crime laws. They have created 24 Electronic Crimes Task Forces (ECTFs) across the United States. These task forces are partnerships between the Service, federal/state and local law enforcement, the private sector and academia aimed at combating technology-based crimes.
In 1998, President Bill Clinton signed Presidential Decision Directive 62, which established National Special Security Events (NSSE). That directive made the Secret Service responsible for security at designated events.
21st century.
2000s.
In 2000, the Secret Service investigated the website Where's George?, over suspicions that the website was encouraging defacement of U.S. currency. They pressured the website's webmaster, Hank, to stop selling the rubber stamps used by the website's users to mark bills.
September 11 attacks.
The New York City Field office was located at 7 World Trade Center. Immediately after the World Trade Center was attacked as part of the September 11 attacks, Special Agents and other New York Field office employees were among the first to respond with first aid. Sixty-seven Special Agents in New York City, at and near the New York Field Office, helped to set up triage areas and evacuate the towers. One Secret Service employee, Master Special Officer Craig Miller, died during the rescue efforts. On August 20, 2002, Director Brian L. Stafford awarded the Director's Valor Award to employees who assisted in the rescue attempts.
Domestic expansion.
Effective March 1, 2003, the Secret Service transferred from the Treasury to the newly established Department of Homeland Security.
The USA Patriot Act, signed into law by President George W. Bush on October 26, 2001, mandated the U.S. Secret Service to establish a nationwide network of Electronic Crimes Task Forces (ECTFs) to investigate and prevent attacks on financial and critical infrastructures in the United States. As such, this mandate expanded on the agency's first ECTF—the New York Electronic Crimes Task Force, formed in 1995—which brought together federal, state and local law enforcement, prosecutors, private-industry companies, and academia.
The network prioritizes investigations that meet the following criteria:
The network includes ECTFs in the following 28 U.S. cities:
International expansion.
On July 6, 2009, the U.S. Secret Service expanded its fight on cyber-crime by creating the first European Electronic Crime Task Force, based on the successful U.S. domestic model, through a memorandum of understanding with Italian police and postal officials. Over a year later, on August 9, 2010, the agency expanded its European involvement by creating its second overseas ECTF in the United Kingdom.
Both task forces are said to concentrate on a wide range of "computer-based criminal activity," including:
The overseas network includes ECTFs in the following European cities:
2010s.
As of 2010, the Service had over 6,500 employees: 3,200 Special Agents, 1,300 Uniformed Division Officers, and 2,000 technical and administrative employees. Special agents serve on protective details, special teams or sometimes investigate certain financial and homeland security-related crimes.
In September 2014, the United States Secret Service came under criticism following two high-profile incidents involving intruders at the White House. One such intruder entered the East Room of the White House through an unlocked door.
Another incident involved a violation of procedure in which an armed security guard for the Centers for Disease Control and Prevention rode in the same elevator as President Barack Obama during a visit to that agency's headquarters in Atlanta, Georgia, to discuss U.S. response to the Ebola virus epidemic in West Africa. The guard used his phone to record video of Obama and refused to comply with a request to stop. The guard had been arrested multiple times in the past, but had never been convicted of a crime.
Attacks on presidents.
Since the 1960s, Presidents John F. Kennedy (killed), Gerald Ford (twice attacked, but uninjured) and Ronald Reagan (seriously wounded) have been attacked while appearing in public. Agents on scene though not injured during attacks on Presidents include William Greer and Roy Kellerman. One of the agents was Robert DeProspero, the Special Agent In Charge (SAIC) of Reagan's Presidential Protective Division (PPD) from January 1982 to April 1985. DeProspero was deputy to Jerry Parr, the SAIC of PPD during the Reagan assassination attempt on March 30, 1981.
The Kennedy assassination spotlighted the bravery of two Secret Service agents. First, an agent protecting Mrs. Kennedy, Clint Hill, was riding in the car directly behind the presidential limousine when the attack began. While the shooting continued, Hill leapt from the running board of the car he was riding on and jumped onto the back of the President's moving car and guided Mrs. Kennedy from the trunk back into the rear seat of the car. He then shielded the President and the First Lady with his body until the car arrived at the hospital.
Rufus Youngblood was riding in the vice-presidential car. When the shots were fired, he vaulted over the front seat and threw his body over Vice President Lyndon B. Johnson. That evening, Johnson called Secret Service Chief James J. Rowley and cited Youngblood's bravery. Youngblood would later recall some of this in his memoir, "Twenty Years in the Secret Service".
The period following the Kennedy assassination was the most difficult in the modern history of the agency. Press reports indicated that morale among the agents was "low" for months following the assassination. The agency overhauled its procedures in the wake of the Kennedy killing. Training, which until that time had been confined largely to "on-the-job" efforts, was systematized and regularized.
The Reagan assassination attempt also highlighted the bravery of several Secret Service agents, particularly agent Tim McCarthy, who spread his stance to protect Reagan as six bullets were being fired by the would-be assassin, John Hinckley, Jr. McCarthy survived a .22-caliber round in the abdomen. For his bravery, McCarthy received the NCAA Award of Valor in 1982. Jerry Parr, the agent who pushed President Reagan into the limousine, and made the critical decision to divert the presidential motorcade to George Washington University Hospital instead of returning to the White House, was also honored with U.S. Congress commendations for his actions that day. After the near-successful assassination attempt on Ronald Reagan, it was clear that the Secret Service needed to increase its efficiency to protect the President.
Significant investigations.
Arrest and indictment of Max Ray Butler, co-founder of the Carders Market carding website. Butler was indicted by a federal grand jury in Pittsburgh, Pennsylvania, after his September 5, 2007 arrest, on wire fraud and identity theft charges. According to the indictment, Butler hacked over the Internet into computers at financial institutions and credit card processing centers and sold the tens of thousands of credit card numbers that he acquired in the process.
Operation Firewall: In October 2004, 28 suspects—located across eight U.S. states and six countries—were arrested on charges of identity theft, computer fraud, credit-card fraud, and conspiracy. Nearly 30 national and foreign field offices of the U.S. Secret Service, including the newly established national ECTFs, and countless local enforcement agencies from around the globe, were involved in this operation. Collectively, the arrested suspects trafficked in at least 1.7 million stolen credit card numbers, which amounted to $4.3 million of losses to financial institutions. However, authorities estimated prevented loss to the industry to be in hundreds of millions of dollars. The operation, which started in July 2003 and lasted for more than a year, led investigators to identify three cyber-criminal groups: Shadowcrew, Carderplanet, and Darkprofits.
Arrest and indictment of Albert "Segvec" Gonzalez and 11 individuals; three U.S. citizens, one from Estonia, three from Ukraine, two from the People's Republic of China, one from Belarus, and one known only by an online alias. They were arrested on August 5, 2008, for the theft and sale of more than 40 million credit and debit card numbers from major U.S. retailers, including TJX Companies, BJ's Wholesale Club, OfficeMax, Boston Market, Barnes & Noble, Sports Authority, Forever 21, and DSW. Gonzalez, the main organizer of the scheme, was charged with computer fraud, wire fraud, access device fraud, aggravated identity theft, and conspiracy for his leading role in the crime.
Uniformed Division.
The USSS Uniformed Division is a security police similar to the U.S. Capitol Police or DHS Federal Protective Service and is in charge of protecting the physical White House grounds and foreign diplomatic missions in the Washington, D.C. area. Established in 1922 as the White House Police, this organization was fully integrated into the Secret Service in 1930. In 1970, the protection of foreign diplomatic missions was added to the force's responsibilities, and its name was changed to the Executive Protective Service. The name United States Secret Service Uniformed Division was adopted in 1977.
Special Agent.
At a minimum, a prospective agent must be a U.S. citizen, possess a current valid driver's license, possess visual acuity no worse than 20/60 uncorrected, correctable to 20/20 in each eye, and be between the ages of 21 and 37 at the time of appointment. However, preference eligible veterans may apply after age 37. In 2009, the Office of Personnel Management issued implementation guidance on the "Isabella v. Department of State" court decision: OPM Letter.
Special agents receive basic training in two locations. The first phase, the Criminal Investigator Training Program (CITP) is conducted at the Federal Law Enforcement Training Center (FLETC) at Glynco, GA. The second phase, the Special Agent Training Course (SATC) is conducted at the James J. Rowley Training Center, located in Beltsville, MD.
A Secret Service agent's career consists of three phases. During phase one Secret Service special agents spend their first six to eight years on-the-job assigned to a field office. After their field experience, agents are usually transferred to a protective detail where they will stay for four to seven years, during what is known as phase two or the protection phase. Following their protective assignment, many agents return to the field, transfer to a headquarters office, a training office, or other Washington, D.C.–based assignment for phase three of their career. Promotions will affect the typical career path. An agent's working hours depend upon the assignment. Generally, an agent can expect to travel a lot and do a significant amount of shift work, especially during phase two. Throughout their career agents continue their training.
Special Officer.
Special officers (not to be confused with Uniformed Division Officers) work within the Special Agent Division of the USSS and perform a wide range of security functions and support assignments as part of the protective mission for the Secret Service. Whereas special agents will alternate between protection and investigative assignments, special officers are hired only to work protection details. They must have a familiarity with all phases of protective responsibilities sufficient to assist in protective movements, cover designated security posts and drive protective vehicles.
Assignments may include maintaining designated protective security posts; controlling the movement of persons into and around multiple Secret Service facilities and associated areas; inspecting all operational, safety, emergency, and convenience equipment of protective vehicles to ensure peak operating condition; driving protective or follow-up vehicles; monitoring and operating various communications equipment; and employing various advanced x-ray screening technologies in order to detect and identify high-risk items. Special officers are sworn law enforcement officers and are authorized to make arrests in connection with their official duties.
Newly appointed special officers must successfully complete eight (8) weeks of intensive training at the Special Officer Basic Training Course at the Secret Service James J. Rowley Training Center just outside Washington, D.C. The training includes courses such as Criminal Law, Laws of Arrest, Search and Seizure, Control Tactics, Civil Liability, Emergency Medicine, Basic Water Safety, Firearms and Weapons Handling, Radio Communications, Emergency Driving and Physical Fitness Training.
Weapons and equipment.
Since the agency's inception, a variety of weapons have been carried by its agents.
Previous firearms.
Initially the firearms were privately procured and there was little if any standardization. In the 1930s, the USSS issued the Colt M1911A1 pistol in .45 ACP caliber. In the 1950s and 1960s, Special Agents carried the Smith & Wesson Model 36 and Colt Detective Special 38 Special revolvers.
Following President Kennedy's assassination, USSS Special Agents were authorized to carry the .357 Magnum Smith & Wesson Model 19 revolver.
Between 1981 and 1991, the Secret Service issued the Smith & Wesson Model 19 and the Smith & Wesson Model 66 .357 Magnum revolvers, with 2.5-inch barrels all the way up to the 4-inch-barreled models, loaded with hollow-point rounds.
By 1992, the standard issue weapon became the SIG Sauer P228 9mm pistol. This weapon stayed in service through 1999.
The Thompson submachine gun was replaced by the Uzi submachine gun in the 1970s. Uzis utilized by the Secret Service have the common characteristic of slightly shorter than standard barrels. This was due to the fact that the weapons had to be modified to fit inside standard size Samsonite briefcases used to conceal them. The Uzi was phased out in the mid 1990s and replaced by the H&K MP5. The Secret Service was the last Federal agency to use the Uzi.
The M4 carbine was utilized by agents of the Counter Assault Team from the early 1990s until 2006 when it was replaced by the SR-16 carbine.
Current weapons.
The current sidearm for USSS agents is the SIG Sauer P229 chambered in .357 SIG, which entered service in 1999, and also the FN Five-seven pistol. A variety of off duty, back up, and undercover weapons are also authorized.
Agents and officers are trained on standard shoulder weapons that include the FN P90 submachine gun, the 9mm Heckler & Koch MP5 submachine gun, and the 12-gauge Remington 870 shotgun. The continued use of the MP5 remains a source of controversy as many other federal agencies have moved away from submachine guns altogether and replaced them with assault rifles. Despite this, the agency has no current plans to replace this weapon.
As a non-lethal option, Special Agents, Special Officers, and Uniformed Division Officers are armed with the ASP baton, and Uniform Division officers carry pepper spray.
Units assigned to the Special Operations Division carry a variety of non-standard weapons.
The Counter Assault Team (CAT) and the Emergency Response Team (ERT) are both issued the 5.56mm Knight's Armament Company SR-16 CQB assault rifle. CAT also uses 12 gauge Remington 870 MCS breaching shotguns.
Uniform Division technicians assigned to the Counter Sniper (CS) team use custom built .300 Winchester Magnum-chambered bolt-action rifles referred to as JARs ("Just Another Rifle"). These rifles use Remington 700 actions in Accuracy International stocks with Schmidt & Bender optics. CS technicians also use the 7.62mm KAC SR-25/Mk11 Mod 0 semi-automatic sniper rifle with a Trijicon 5.5× ACOG optic.
The Department of Homeland Security has made numerous attempts to bring the Secret Service's weapons procurement in line with the rest of the department. The agency has resisted these inroads and currently maintains an independent acquisition process.
Communications.
The agency uses Motorola XTS radios and surveillance kits in order to maintain communication and are known to use DES encryption keys. When operationally required, military grade radios that utilize Type 1 encryption algorithms are fielded.
Vehicles.
When transporting the President in a motorcade, the Secret Service uses a fleet of custom-built armored Cadillac Parade Limousines, the newest and largest version of which is known as "The Beast". Armored Chevrolet Suburbans are also used when logistics require such a vehicle or when a more low profile appearance is required. For official movement the limousine is affixed with U.S. and presidential flags and the presidential seal on the rear doors. For unofficial events the vehicles are left sterile and unadorned.
Attire.
Special Agents and Special Officers of the Secret Service wear attire that is appropriate for their surroundings, in order to blend in as much as possible. In most circumstances, the attire of a close protection shift is a conservative suit, but it can range from a tuxedo to casual clothing as required by the environment. Stereotypically Secret Service agents are often portrayed wearing reflective sunglasses and a communication earpiece. Often their attire is customized to conceal the wide array of equipment they wear while working protection assignments. Agents wear a distinctive lapel pin that identifies them to other agents.
The attire for Uniformed Division Officers includes standard police uniforms or utility uniforms and ballistic/identification vests for members of the countersniper team, Emergency Response Team (ERT), and canine officers. The shoulder patch of the Uniformed Division consists of the U.S. coat of arms on white or black, depending on the garment to which it is attached. Also, the shoulder patch is embroidered with "U.S. Secret Service Uniformed Division Police" around the emblem.
Field offices.
The Secret Service has agents assigned to 136 field offices and the headquarters in Washington, D.C. The field offices are located in cities throughout the United States and in Brazil (Brasilia), Bulgaria (Sofia), Canada (Montreal, Ottawa, Toronto, Vancouver), Colombia (Bogota), China (Hong Kong), France (Paris, Lyon), Germany (Frankfurt), Italy (Rome), Mexico (Mexico City), Netherlands (The Hague), Romania (Bucharest), Russia (Moscow), South Africa (Pretoria), Spain (Madrid), Thailand (Bangkok), and the United Kingdom (London). The offices in Lyon and The Hague are respectively responsible for liaison with the headquarters of Interpol and Europol, located in those cities.
Misconduct.
In April 2012, an incident involving the president's security detail received international press attention. The incident involved 11 agents and personnel from four branches of the U.S. military; they allegedly engaged prostitutes while assigned to protect the U.S. President at the 6th Summit of the Americas in Cartagena, Colombia. As of April 24, 2012, nine employees had resigned or retired.
After the incident was publicized, the Secret Service implemented new rules for its personnel. The rules prohibit personnel from visiting "non-reputable establishments" and from consuming alcohol less than ten hours before starting work. Additionally, they restrict who is allowed in hotel rooms.
A few weeks later, stories emerged of Secret Service agents hiring strippers and prostitutes prior to Obama's 2011 visit to El Salvador.
In 2015, two inebriated senior service agents drove an official car into the White House complex and collided with a barrier. One of the congressmen in the United States House Committee on Oversight and Government Reform which investigated that incident was Jason Chaffetz. In September 2015, it was revealed that 18 Secret Service employees or supervisors, including Assistant Director Ed Lowery, accessed an unsuccessful 2003 application by Chaffetz for employment with the agency and discussed leaking the information to the media in retaliation for Chaffetz' investigations of agency misconduct. The confidential personal information was later leaked to "The Daily Beast". Agency Director Joe Clancy apologized to Chaffetz and said that disciplinary action would be taken against those responsible.

</doc>
<doc id="58222" url="https://en.wikipedia.org/wiki?curid=58222" title="Fujitsu">
Fujitsu

, commonly referred to as Fujitsu, is a Japanese multinational information technology equipment and services company headquartered in Tokyo, Japan. In 2015, it was the world's fourth-largest IT services provider measured by IT services revenue (after IBM, HP and Accenture). Fortune named Fujitsu as one of the world's most admired companies.
Fujitsu chiefly makes computing products, but the company and its subsidiaries also offer a diversity of products and services in the areas of personal computing, Enterprise Computing, including x86, SPARC and Mainframe server products, as well as storage products, telecommunications, advanced microelectronics, and air conditioning. It has approximately 159,000 employees and its products and services are available in over 100 countries.
Fujitsu is listed on the Tokyo Stock Exchange and is a constituent of the Nikkei 225 and TOPIX indices.
History.
1935 to 2000.
Fujitsu is the second oldest IT company after IBM, established on June 20, 1935, under the name , as a spin-off of the Fuji Electric Company, itself a joint venture between the Furukawa Electric Company and the German conglomerate Siemens which had been founded in 1923. Despite its connections to the Furukawa zaibatsu, Fujitsu escaped the Allied occupation of Japan after the Second World War mostly unscathed.
In 1954, Fujitsu manufactured Japan's first computer, the FACOM 100, and in 1961 launched the transistorized FACOM 222. In 1955, Fujitsu founded Kawasaki Frontale as a company football club; Kawasaki Frontale has been a J. League football club since 1999. In 1967, the company's name was officially changed to the contraction . The company also fields a company American football team, the Fujitsu Frontiers, who play in the corporate X-League, have appeared in 6 Japan X Bowls, winning one, and winning one Rice Bowl.
In 1971, Fujitsu signed an OEM agreement with the Canadian company Consolidated Computers Limited (CCL) to distribute CCL's data entry product, Key-Edit. Fujitsu joined both ICL who earlier began marketing Key-Edit in the British Commonwealth of countries as well as in both western and eastern Europe; and CCL's direct marketing staff in Canada, USA, London (UK) and Frankfurt. Mers Kutt, inventor of Key-Edit and founder of CCL, was the common thread that led to Fujitsu’s later association with ICL and Gene Amdahl.
In 1986, Fujitsu and The Queen's University of Belfast business incubation unit (QUBIS Ltd) established a joint venture called Kainos, a privately held software company based in Belfast, Northern Ireland.
In 1990, Fujitsu acquired 80% of the UK-based computer company International Computers Limited (ICL) for $1.29 billion (ICL was renamed Fujitsu Services in 2002). In September 1990, Fujitsu announced the launch of a new series of mainframe computers which were at that time the fastest in the world. In July 1991, Fujitsu acquired more than half of the Russian company KME-CS (Kazan Manufacturing Enterprise of Computer Systems).
In 1992, Fujitsu introduced the world's first 21-inch full-color plasma display. It was a hybrid, based upon the plasma display created at the University of Illinois at Urbana-Champaign and NHK STRL, achieving superior brightness.
In 1993, Fujitsu formed a flash memory manufacturing joint venture with AMD, Spansion. As part of the transaction, AMD contributed its flash memory group, Fab 25 in Texas, its R&D facilities and assembly plants in Thailand, Malaysia and China; Fujitsu provided its Flash memory business division and the Malaysian Fujitsu Microelectronics final assembly and test operations.
From February 1989 until mid-1997, Fujitsu built the FM Towns PC variant. It started as a proprietary PC variant intended for multimedia applications and computer games, but later became more compatible with regular PCs. In 1993, the FM Towns Marty was released, a gaming console compatible with the FM Towns games.
Fujitsu agreed to acquire the 58 percent of Amdahl Corporation (including the Canada-based DMR consulting group) that it did not already own for around $850 million in July 1997.
In June 1999 Fujitsu's historical connection with Siemens was revived, when the two companies agreed to merge their European computer operations into a new 50:50 joint venture called Fujitsu Siemens Computers, which became the world's fifth-largest computer manufacturing company.
2000 to present.
In April 2002 ICL was re-branded as Fujitsu. On March 2, 2004, Fujitsu Computer Products of America lost a class action lawsuit over hard disk drives with defective chips and firmware. In October 2004, Fujitsu acquired the Australian subsidiary of Atos Origin, a systems implementation company with around 140 employees which specialized in SAP.
In August 2007, Fujitsu signed a £500 million, 10-year deal with Reuters Group under which Reuters outsourced the majority of its internal IT department to Fujitsu. As part of the agreement around 300 Reuters staff and 200 contractors transferred to Fujitsu. In October 2007, Fujitsu announced that it would be establishing an offshore development centre in Noida, India with a capacity to house 1,200 employees, in an investment of US$10 million.
In October 2007, Fujitsu's Australia and New Zealand subsidiary acquired Infinity Solutions Ltd, a New Zealand-based IT hardware, services and consultancy company, for an undisclosed amount.
In January 2009, Fujitsu reached an agreement to sell its HDD business to Toshiba. Transfer of the business was completed on October 1. 2009.
In March 2009, Fujitsu announced that it had decided to convert FDK Corporation, at that time an equity-method affiliate, to a consolidated subsidiary from May 1, 2009 (tentative schedule) by subscribing to a private placement to increase FDK's capital.FDK On April 1, 2009, Fujitsu agreed to acquire Siemens' stake in Fujitsu Siemens Computers for approximately EUR450m. Fujitsu Siemens Computers was subsequently renamed Fujitsu Technology Solutions.
In April 2009, Fujitsu acquired Australian software company Supply Chain Consulting for $48 million deal, just weeks after purchasing the Telstra subsidiary Kaz for $200 million.
Concerning of Net loss forecast amounted 95 billion yen in the year ending March 2013, in February 2013 Fujitsu announced to cut 5,000 jobs which 3,000 jobs in Japan and the rest overseas from its 170,000 employees. Fujitsu will also merge its Large Scale Integrated chip business with that of Panasonic Corporation.
In 2015, Fujitsu Celebrates 80 years since establishment and on the IT side are currently embarked upon the Fujitsu 2015 World Tour which has included 15 major cities globally and been visited by over 10,000 IT professionals with Fujitsu presenting its take on the future of Hyper Connectivity and Human Centric Computing.
In November 2015, Fujitsu Limited and VMware announced new areas of collaboration to empower customers with flexible and secure cloud technologies.
In January 2016, Fujitsu Network Communications Inc. announced a new suite of layered products to advance software-defined networking (SDN) for carriers, service providers and cloud builders. Virtuora NC, based on open standards, is described by Fujitsu as "a suite of standards-based, multi-layer, multi-vendor network automation and virtualization products" that "has been hands-on hardened by some of the largest global service providers."
Operations.
Fujitsu Laboratories.
Fujitsu Laboratories, Fujitsu's Research and Development division, has 1,300 employees and a capital of 5 Billion Yen. It is run by Tatsuo Tomita.
In 2012, Fujitsu announced that it had developed new technology for non-3D camera phones. The technology will allow the camera phones to take 3D photos.
Fujitsu Semiconductor Europe GmbH.
Fujitsu Semicondutor Europe GmbH (FSEU) is a wholly owned subsidiary of Fujitsu Semiconductor Limited, formally known as Fujitsu Microelectronics Europe GmbH. The name change was instituted in 2010. FSEU designs and supplies semiconductor devices and systems solutions to the European automotive, communications, multimedia and industrial segments. Its main design offices are in the UK and Germany.
Fujitsu Technology Solutions.
The CEMEA&I region (Continental Europe, Middle East, Africa & India) plays an important role within the Fujitsu Group. Here, Fujitsu Technology Solutions – evolved from the former joint venture Fujitsu Siemens Computers – holds global responsibility for research, development and distribution of all x86 servers produced by Fujitsu. The company’s Dynamic Infrastructures strategy, was also born here. The term Dynamic Infrastructures stands for a comprehensive range of IT products, solutions, and services – from PCs and notebooks, to data center solutions, and Infrastructure as a Service and Managed Infrastructure services that dynamically adapt and adjust to the ever changing demands of today’s economy
Fujitsu Consulting.
Fujitsu Consulting is the consulting and services arm of the Fujitsu group, providing information technology consulting, implementation and management services.
Fujitsu Consulting was founded in 1973 in Montreal, Canada, under its original name "DMR" (an acronym of the three founder's names: Pierre Ducros, Serge Meilleur and Alain Roy) During the next decade, the company established a presence throughout Quebec and Canada, before extending its reach to international markets. For nearly thirty years, DMR Consulting grew to become an international consulting firm, changing its name to Fujitsu Consulting in 2002 after being acquired by Fujitsu Ltd.
Fujitsu General.
Fujitsu Ltd has a 42% shareholding in Fujitsu General, which manufactures and markets various air conditioning units and humidity control solutions. A similar venture is sponsored by Fujitsu in India, called General Airconditioners.
PFU Limited.
PFU Limited, headquartered in Ishikawa, Japan is a wholly owned subsidiary of Fujitsu Limited. PFU Limited was established in 1960, has approximately 4,600 employees globally and in 2013 turned over 126.4 billion Yen ($1.2 Billion USD). PFU manufactures interactive kiosks, keyboards, network security hardware, embedded computers and imaging products (document scanners) all under the PFU or Fujitsu brand. In addition to hardware PFU also produce desktop and enterprise document capture software and document management software products. PFU has overseas Sales & Marketing offices in Germany (PFU Imaging Solutions Europe Limited), Italy (PFU Imaging Solutions Europe Limited), United Kingdom (PFU Imaging Solutions Europe Limited)and United States of America ( Fujitsu Computer Products of America Inc). PFU Limited are responsible for the design, development, manufacture, sales and support of document scanners which are sold under the Fujitsu brand. Fujitsu are market leaders in professional document scanners with their best selling fi-series, Scansnap and ScanPartner product families as well as Paperstream IP, Paperstream Capture, Scansnap Manager, Cardminder, Magic Desktop and Rack2Filer software products.
Products and services.
Computing products.
Fujitsu's computing product lines include:
PRIMERGY: Fujitsu's server family including Tower Servers, Rack Servers, and Blade Servers.
In May 2011, Fujitsu decided to enter the mobile phone space again, Microsoft announcing plans that Fujitsu would release Windows Phone devices.
ETERNUS: Fujitsu’s storage hardware and software infrastructure as part of the company’s Dynamic Infrastructures Portfolio.
The word "" means "eternal" in Latin. Fujitsu adopted this name for the global storage brand to match the company’s concepts; of protecting customer assets forever and ensuring continuous business operation.
The ETERNUS product lineup includes Disk Storage Systems, Tape Systems, Virtual Tape Appliances, SAN Switches, and Storage Management Software.
Fujitsu PRIMERGY and ETERNUS are distributed by TriTech Distribution Limited in Hong Kong.
LIFEBOOK, AMILO: Fujitsu's range of notebook computers and tablet PCs.
Cloud computing.
Fujitsu offers a public cloud service delivered from data centers in Japan, Australia, Singapore, the United States, the United Kingdom and Germany based on its Global Cloud Platform strategy announced in 2010. The platform delivers Infrastructure-as-a-Service (IaaS) – virtual information and communication technology (ICT) infrastructure, such as servers and storage functionality – from Fujitsu's data centers. In Japan, the service was offered as the On-Demand Virtual System Service (OViSS) and was then launched globally as Fujitsu Global Cloud Platform/S5 (FGCP/S5). Since July 2013 the service has been called IaaS Trusted Public S5. Globally, the service is operated from Fujitsu data centers located in Australia, Singapore, the United States, the United Kingdom, Germany and Japan.
Fujitsu has also launched a Windows Azure powered Global Cloud Platform in a partnership with Microsoft. This offering, delivering Platform-as-a-Service (PaaS), was known as FGCP/A5 in Japan but has since been renamed FUJITSU Cloud PaaS A5 for Windows Azure. It is operated from a Fujitsu data center in Japan. It offers a set of application development frameworks, such as Microsoft .NET, Java and PHP, and data storage capabilities consistent with the Windows Azure platform provided by Microsoft. The basic service consists of compute, storage, Microsoft SQL Azure, and Windows Azure AppFabric technologies such as Service Bus and Access Control Service, with options for inter-operating services covering implementation and migration of applications, system building, systems operation, and support.
Fujitsu acquired RunMyProcess in April 2013, a Cloud-based integration Platform-as-a-Service (PaaS) specialized in workflow automation and business application development.
Fujitsu plans to launch a public Cloud Service K5 in Japan using open-standard technologies, to be made available starting October - December 2015. Outside Japan, to be available starting April - September 2016.
Fujitsu also offers local cloud platforms, such as in Australia, that provide the ability to rely on its domestic data centers which keep sensitive financial data under local jurisdiction and compliance standards.
Microprocessors.
Fujitsu produce SPARC compatible CPU (SPARClite), the "Venus" 128 GFLOP SPARC64 VIIIfx model is included in the K computer, the world's fastest supercomputer in June 2011 with a rating of over 8 petaflops, and in November 2011, K became the first computer to top 10 petaflops in September 2011.
The Fujitsu FR, FR-V and ARM architecture microprocessors are widely used, additionally in ASICs and Application-specific standard products (ASSP) like the Milbeaut with customer variants named Nikon Expeed. They were acquired by Spansion in 2013.
Advertising.
The old slogan ""The possibilities are infinite"" can be found below the company's logo on major advertisements and ties in with the small logo above the letters J and I of the word Fujitsu. This smaller logo represents the symbol for infinity. As of April 2010, Fujitsu is in the process of rolling out a new slogan focused on entering into partnerships with its customers and retiring the "possibilities are infinite" tagline. The new slogan is "shaping tomorrow with you". Along with that several Fujitsu fans have contributed in advertising Fujitsu including Socos, Constantinos, Alex and Nick. A new sushi restaurant is to be opened called Sushitsu.
Environmental record.
Fujitsu reports that all its notebook and tablet PCs released globally comply with the latest Energy Star standard.
Greenpeace's Cool IT Leaderboard of February 2012 "evaluates global IT companies on their leadership in the fight to stop climate change" and ranks Fujitsu 3rd out of 21 leading manufacturers, on the strength of "well-developed case study data of its solutions with transparent methodology" and " out in the Leaderboard for scoring high in the Future Savings Goal criterion."

</doc>
<doc id="58224" url="https://en.wikipedia.org/wiki?curid=58224" title="Babylonian captivity">
Babylonian captivity

The Babylonian captivity or Babylonian exile is the period in Jewish history during which a number of Judahites of the ancient Kingdom of Judah were captives in Babylonia. After the Battle of Carchemish in 605 BCE, Nebuchadnezzar, the king of Babylon, besieged Jerusalem, resulting in tribute being paid by King Jehoiakim. Jehoiakim refused to pay tribute in Nebuchadnezzar's fourth year, which led to another siege in Nebuchadnezzar's seventh year, culminating with the death of Jehoiakim and the exile of King Jeconiah, his court and many others; Jeconiah's successor Zedekiah and others were exiled in Nebuchadnezzar's eighteenth year; a later deportation occurred in Nebuchadnezzar's twenty-third year. The dates, numbers of deportations, and numbers of deportees given in the biblical accounts vary. These deportations are dated to 597 BCE for the first, with others dated at 587/586 BCE, and 582/581 BCE respectively.
After the fall of Babylon to the Persian king Cyrus the Great in 539 BCE, exiled Jews began to return to the land of Judah. According to the biblical book of Ezra, construction of a second temple in Jerusalem began at this time. All these events are considered significant in Jewish history and culture, and had a far-reaching impact on the development of Judaism.
Archaeological studies have revealed that not all of the population of Judah was deported, and that, although Jerusalem was utterly destroyed, other parts of Judah continued to be inhabited during the period of the exile. The return of the exiles was a gradual process rather than a single event, and many of the deportees or their descendants did not return.
Biblical accounts of the exile.
In the late 7th century BCE, the kingdom of Judah was a client state of the Assyrian empire. In the last decades of the century, Assyria was overthrown by Babylon, an Assyrian province. Egypt, fearing the sudden rise of the Neo-Babylonian empire, seized control of Assyrian territory up to the Euphrates river in Syria, but Babylon counter-attacked. In the process Josiah, the king of Judah, was killed in a battle with the Egyptians at the Battle of Megiddo (609 BC).
After the defeat of Pharaoh Necho's army by the Babylonians at Carchemish in 605 BCE, Jehoiakim began paying tribute to Nebuchadnezzar II of Babylon. Some of the young nobility of Judah (such as Daniel, Shadrach, Meshach, and Abednego) were taken to Babylon.
In the following years, the court of Jerusalem was divided into two parties, in support of Egypt and Babylon. After Nebuchadnezzar was defeated in Battle in 601 BCE by Egypt, Judah revolted against Babylon, culminating in a three-month siege of Jerusalem beginning in late 598 BCE. Jehoiakim, the king of Judah, died during the siege, and was succeeded by his son Jehoiachin (also called Jeconiah) at the age of eighteen. The city fell on 2 Adar (March 16) 597 BCE, and Nebuchadnezzar pillaged Jerusalem and its Temple and took Jeconiah, his court and other prominent citizens (including the prophet Ezekiel) back to Babylon. Jehoiakim's uncle Zedekiah was appointed king in his place, but the exiles in Babylon continued to consider Jeconiah as their Exilarch, or rightful ruler.
Despite warnings by Jeremiah and others of the pro-Babylonian party, Zedekiah revolted against Babylon and entered into an alliance with Pharaoh Hophra. Nebuchadnezzar returned, defeated the Egyptians, and again besieged Jerusalem, resulting in the city's destruction in 587 BCE. Nebuchadnezzar destroyed the city wall and the Temple, together with the houses of the most important citizens. Zedekiah and his sons were captured, the sons were executed in front of Zedekiah, who was then blinded, and taken to Babylon with many others (Jer 52:10-11). Judah became a Babylonian province, called Yehud Medinata (Judah Province), putting an end to the independent Kingdom of Judah. (Because of the missing years in the Jewish calendar, rabbinic sources place the date of the destruction of the First Temple at 3338 HC (423 BCE) or 3358 HC (403 BCE)).
The first governor appointed by Babylon was Gedaliah, a native Judahite; he encouraged the many Jews who had fled to surrounding countries such as Moab, Ammon and Edom to return, and took steps to return the country to prosperity. Some time later, a surviving member of the royal family assassinated Gedaliah and his Babylonian advisors, prompting many refugees to seek safety in Egypt. By the end of the second decade of the 6th century, in addition to those who remained in Judah, there were significant Jewish communities in Babylon and in Egypt; this was the beginning of the later numerous Jewish communities living permanently outside Judah in the Jewish Diaspora.
According to the book of Ezra, the Persian Cyrus the Great ended the exile in 538 BCE, the year after he captured Babylon. The exile ended with the return under Zerubbabel the Prince (so-called because he was a descendant of the royal line of David) and Joshua the Priest (a descendant of the line of the former High Priests of the Temple) and their construction of the Second Temple in the period 521–516 BCE.
Archaeological and other non-Biblical evidence.
Nebuchadnezzar's siege of Jerusalem, his capture of King Jeconiah, his appointment of Zedekiah in his place, and the plundering of the city in 597 BCE, as described in 2 Kings in the Bible, are corroborated by a passage in the Babylonian Chronicles:"In the seventh year, in the month of Kislev, the king of Akkad mustered his troops, marched to the Hatti-land, and encamped against the City of Judah and on the ninth day of the month of Adar he seized the city and captured the king. He appointed there a king of his own choice and taking heavy tribute brought it back to Babylon."
Jehoiachin's Rations Tablets, describing ration orders for a captive King of Judah, identified with King Jeconiah, have been discovered during excavations in Babylon, in the royal archives of Nebuchadnezzar. One of the tablets refers to food rations for "Ya’u-kīnu, king of the land of Yahudu" and five royal princes, his sons.
Nebuchadnezzar and the Babylonian forces returned in 588/586 BCE and rampaged through Judah, leaving clear archaeological evidence of destruction in many towns and settlements there. Clay ostraca from this period, referred to as the Lachish letters, were discovered during excavations; one, which was probably written to the commander at Lachish from an outlying base, describes how the signal fires from nearby towns are disappearing: "And may (my lord) be apprised that we are watching for the fire signals of Lachish according to all the signs which my lord has given, because we cannot see Azeqah." This correlates with the book of Jeremiah, which states that Jerusalem, Lachish, and Azekah were the last cities to fall to the Babylonians. Archaeological finds from Jerusalem testify that virtually the whole city within the walls was burnt to rubble in 587 BCE and utterly destroyed.
The biblical books of 2 Kings and Jeremiah give varying numbers of exiles forcibly deported to Babylon, and at one time it was widely believed that virtually the entire population was taken into captivity there. Archaeological excavations and surveys, however, have enabled the population of Judah before the Babylonian destruction to be calculated with a high degree of confidence to have been approximately 75,000. Taking the different biblical numbers of exiles at their highest, 20,000, this would mean that at most 25pc of the population had been deported to Babylon, with the remaining 75pc staying in Judah. Although Jerusalem was destroyed and depopulated, with large parts of the city remaining in ruins for 150 years, numerous other settlements in Judah continued to be inhabited, with no signs of disruption visible in archaeological studies.
The biblical book of Ezra includes two texts said to be decrees of Cyrus the Great, conqueror of the Neo-Babylonian Empire, allowing the deported Jews to return to their homeland after decades and ordering the Temple rebuilt. The differences in content and tone of the two decrees, one in Hebrew and one in Aramaic, have caused some scholars to question their authenticity. The Cyrus Cylinder, an ancient tablet on which is written a declaration in the name of Cyrus referring to restoration of temples and repatriation of exiled peoples, has often been taken as corroboration of the authenticity of the biblical decrees attributed to Cyrus, but other scholars point out that the cylinder's text is specific to Babylon and Mesopotamia and makes no mention of Judah or Jerusalem. Professor Lester L Grabbe asserted that the "alleged decree of Cyrus" regarding Judah, "cannot be considered authentic", but that there was a "general policy of allowing deportees to return and to re-establish cult sites". He also stated that archaeology suggests that the return was a "trickle" taking place over decades, rather than a single event.
As part of the Persian Empire, the former Kingdom of Judah became the province of Judah ("Yehûd medîntā"') with different borders, covering a smaller territory. The population of the province was greatly reduced from that of the kingdom, archeological surveys showing a population of around 30,000 people in the 5th to 4th centuries BCE.
An exhibition in Jerusalem has on display over 100 cuneiform tablets that detail trade in fruits and other commodities, taxes, debts, and credits accumulated between Jews driven from, or convinced to move from Jerusalem by King Nebuchadnezzar around 600 BCE. They include details on one exiled Judean family over four generations, all with Biblical Hebrew names, many still in use today.
Exilic literature and post-exilic revisions of the Torah/Pentateuch.
The exilic period was a rich one for Hebrew literature. Biblical depictions of the exile include Book of Jeremiah 39–43 (which saw the exile as a lost opportunity); the final section of 2 Kings (which portrays it as the temporary end of history); 2 Chronicles (in which the exile is the "Sabbath of the land"); and the opening chapters of Ezra, which records its end. Other works from or about the exile include the stories in Daniel 1–6, Susanna, Bel and the Dragon, the "Story of the Three Youths" (1 Esdras 3:1–5:6), and the books of Tobit and Book of Judith.
The Priestly source, one of the four main sources of the Torah/Pentateuch in the Bible, is primarily a product of the post-exilic period when the former Kingdom of Judah had become the Persian province of Yehud. Also during this Persian period, the final redaction of the Pentateuch took place.
Significance in Jewish history.
In the Hebrew Bible, the captivity in Babylon is presented as a punishment for idolatry and disobedience to Yahweh in a similar way to the presentation of Israelite slavery in Egypt followed by deliverance. The Babylonian Captivity had a number of serious effects on Judaism and Jewish culture. For example, the current Hebrew alphabet was adopted during this period, replacing the Paleo-Hebrew alphabet.
This period saw the last high-point of biblical prophecy in the person of Ezekiel, followed by the emergence of the central role of the Torah in Jewish life. According to many historical-critical scholars, the Torah was altered during this time, and began to be regarded as the authoritative text for Jews. This period saw their transformation into an ethno-religious group who could survive without a central Temple.
This process coincided with the emergence of scribes and sages as Jewish leaders (see Ezra). Prior to exile, the people of Israel had been organized according to tribe. Afterwards, they were organized by smaller family groups. Only the tribe of Levi continued in its temple role after the return. After this time, there were always sizable numbers of Jews living outside Eretz Israel; thus, it also marks the beginning of the "Jewish diaspora", unless this is considered to have begun with the Assyrian Captivity of Israel.
In Rabbinic literature, Babylon was one of a number of metaphors for the Jewish diaspora. Most frequently the term "Babylon" meant the diaspora prior to the destruction of the Second Temple. The post-destruction term for the Jewish Diaspora was "Rome", or "Edom".
Chronology.
The following table is based on Rainer Albertz's work on "Israel in exile". (Alternative dates are possible.)
Further reading.
Maps
Google-Books

</doc>
<doc id="58225" url="https://en.wikipedia.org/wiki?curid=58225" title="Babylonian law">
Babylonian law

Babylonian law is a subset of cuneiform law that has received particular study, owing to the singular extent of the associated archaeological material that has been found for it. So-called "contracts" exist in the thousands, including a great variety of deeds, conveyances, bonds, receipts, accounts, and most important of all, actual legal decisions given by the judges in the law courts. Historical inscriptions, royal charters and rescripts, dispatches, private letters and the general literature afford welcome supplementary information. Even grammatical and lexicographical texts contain many extracts or short sentences bearing on law and custom. The so-called "Sumerian Family Laws" are preserved in this way.
Other cultures involved with ancient Mesopotamia shared the same common laws and precedents, extending to the form of contacts that Kenneth Kitchen has studied and compared to the form of contracts in the Bible with particular note to the sequence of blessings and curses that bind the deal. The Maxims of Ptahhotep and Sharia Law, also include certifications for professionals like doctors, lawyers and skilled craftsmen which prescribe penalties for malpractice very similar to the code of Hammurabi.
The discovery of the now-celebrated Code of Hammurabi (hereinafter simply termed "the Code") has made possible a more systematic study than could have resulted from just the classification and interpretation of other material. Fragments of other Ancient codes exist and have been published, but there still remain many points whereof evidence is still lacking. There survive legal texts from the earliest writings through the Hellenistic period, but evidence on a particular point may be very full for one period and almost entirely lacking for another. The Code forms the backbone of most reconstructions. Fragments of it recovered from Assur-bani-pal's library at Nineveh and later Babylonian copies show that it was studied, divided into chapters, entitled "Ninu ilu sirum" from its incipit (opening words), and recopied for fifteen hundred years or more.
Much Babylonian legal precedent remained in force, even through the Persian, Greek and Parthian conquests, which had little effect on private life in Babylonia; and it survived to influence Romans. The laws and customs that preceded the Code may be called "early"; that of the Neo-Babylonian empire (as well as the Persian, Greek, etc.), "late". The law of Assyria was derived from the Babylonian, but it conserved early features long after they had disappeared elsewhere.
History.
Tribal influence.
The early history of Mesopotamia is the story of a struggle for supremacy between the cities. A metropolis demanded tribute and military support from its subject cities but left their local cults and customs unaffected. City rights and usages were respected by kings and conquerors alike. When the Semitic tribes settled in the cities of Mesopotamia, their tribal customs passed over into city law.
As late as the accession of Assur-bani-pal and Shamash-shum-ukin, we find the Babylonians appending to their city laws that groups of aliens to the number of twenty at a time were free to enter the city; that foreign women, once married to Babylonian husbands, could not be enslaved; and that not even a dog that entered the city could be put to death untried.
The population of Babylonia was multi-ethnic from early times, and intercommunication between the cities was incessant. Every city had a large number of resident aliens. This freedom of intercourse must have tended to assimilate custom. It was, however, reserved for the genius of Hammurabi to make Babylon his metropolis and weld together his vast empire by a uniform system of law.
Hammurabi's Code.
By Hammurabi's time, almost all trace of tribal custom had already disappeared from the law of the Code. It is state law—self-help, blood-feud, and marriage by capture, are all absent; though code of family solidarity, district responsibility, ordeal, and the "lex talionis" (an eye for an eye), are primitive features that remain. The king is a benevolent autocrat, easily accessible to all his subjects, both able and willing to protect the weak against the highest-placed oppressor. The royal power, however, can only pardon when private resentment is appeased. Judges are strictly supervised, and appeal is allowed. The whole land is covered with feudal holdings, masters of the levy, police, etc. There is a regular postal system. The "pax Babylonica" is so assured that private individuals do not hesitate to ride in their carriage from Babylon to the coast of the Mediterranean. The position of women is free and dignified.
The Code did not merely embody contemporary custom or conserve ancient law. It is true that centuries of law-abiding and litigious habitude had accumulated, in the temple archives of each city, vast stores of precedent in ancient deeds and records of judicial decisions and that intercourse had assimilated city custom. The universal habit of writing, and perpetual recourse to written contract, further modified primitive custom and ancient precedent.
If the parties themselves could agree to the terms, the Code as a rule left them free to make contracts. Their deed of agreement was drawn up in the temple by a notary public and confirmed with an oath "by god and the king." It was publicly sealed and witnessed by professional witnesses, as well as by collaterally interested parties. The manner in which it was executed may have been sufficient guarantee that its stipulations were not impious or illegal. Custom or public opinion doubtlessly ensured that the parties would not agree to "wrong". If a dispute arose, the judges dealt first with the contract. They might not sustain it, but if the parties did not dispute it, they were free to observe it. The judges' decision might, however, be appealed. Many contracts contain the proviso that in case of future dispute, the parties would abide by "the decision of the king." The Code made known, in a vast number of cases, what that decision would be, and many cases of appeal to the king were returned to the judges with orders to decide in accordance with it. The Code itself was carefully and logically arranged, its sections arranged by subject matter. Nevertheless, the order is not that of modern scientific treatises, so a somewhat different order than either is most convenient for our purpose.
See also: English translation of Hammurabi's Code
Three classes.
The Code contemplates the whole population as falling into three classes: the "amelu", the "mushkenu" and the "ardu".
The "amelu" was originally a patrician, a man from an elite family, possessed of full civil rights, whose birth, marriage and death were registered. He had aristocratic privileges and responsibilities, and the right to exact retaliation for corporal injuries, but was liable to a heavier punishment for crimes and misdemeanours, higher fees and fines. To this class belonged the king and court, the higher officials, the professions and craftsmen. Over time, the term became a mere courtesy title—already in the Code, when status is not concerned, it is used to denote anyone. There was no property qualification, nor does the term appear to be racial.
It is most difficult to characterize the "mushkenu" exactly. The term in time came to mean "a beggar", and that meaning has passed through Aramaic and Hebrew into many modern languages; but though the Code does not regard him as necessarily poor, he may have been landless. He was free but had to accept monetary compensation for corporal injuries, paid smaller fees and fines, and even paid less offerings to the gods. He inhabited a separate quarter of the city. There is no reason to regard him as specially connected with the court, as a royal pensioner, nor as forming the bulk of the population. The rarity of any references to him in contemporary documents makes further specification conjectural.
The "ardu" was a slave, his master's chattel, and formed a very numerous class. He could acquire property and even own other slaves. His master clothed and fed him and paid his doctor's fees, but took all compensation paid for injury done to him. His master usually found him a slave girl for a wife (the children were then born slaves), often set him up in a house (with farm or business) and simply took an annual rent of him. Otherwise, he might marry a free woman (the children were then free), who might bring him a dower that his master could not touch, and at his death, one-half of his property passed to his master as his heir. He could acquire his freedom by purchase from his master, or might be freed and dedicated to a temple, or even adopted, when he became an "amelu" and not a "mushkenu". Slaves were recruited by purchase abroad, from captives taken in war, or by freemen degraded for debt or crime. A slave often ran away; if caught, the captor was bound to restore him to his master, and the Code fixes a reward of two shekels that the owner must pay the captor. It was about one-tenth of the average value of a slave. To detain or harbour a slave was punishable by death. So was aiding him to escape the city gates. A slave bore an identification mark, removable only by a surgical operation, that later consisted of his owner's name tattooed or branded on the arm. On the other hand, on the great estates in Assyria and its subject provinces there were many serfs, mostly of subject race, settled captives, or quondam slaves; tied to the soil they cultivated and sold with the estate, yet capable of possessing land and property of their own. There is little trace of serfs in Babylonia, unless the "mushkenu" is really a serf.
Citizens tenants of gods.
The god of a city was originally considered the owner of its land, which encircled it with an inner ring of irrigable arable land and an outer fringe of pasture; the citizens were his tenants. The god and his vice regent, the king, had long ceased to disturb tenancy and were content with fixed dues "in naturalia", stock, money or service.
One of the earliest monuments records the purchase by a king of a large estate for his son, paying a fair market price and adding a handsome honorarium to the many owners, in costly garments, plate, and precious articles of furniture. The Code recognizes complete private ownership of land but apparently extends the right to hold land to votaries and merchants; but all land sold was subject to its fixed charges. The king, however, could free land from these charges by charter, which was a frequent way of rewarding those who deserved well of the state.
It is from these charters that we learn of the obligations lying upon land. The state demanded men for the army and the "corvée", as well as dues in kind. A certain area was bound to provide a bowman, together with his linked pikeman (who bore the shield for both), and to furnish them with supplies for the campaign. This area was termed a "bow" as early as the 8th century BC, but the practice goes back much earlier. Later, a horseman was also due from certain areas. A man was only bound to serve a certain number of times, but the land still had to find a man annually. This service was usually discharged by slaves and serfs, but the "amelu" (and perhaps the "mushkenu") also went to war. The bows were grouped together in tens and hundreds. The "corvée" was less regular. Special liabilities also lay upon riparian owners to repair canals, bridges, quays, etc. The letters of Hammurabi often deal with claims to exemption. Religious officials and shepherds in charge of flocks were exempt from military duty.
The state claimed certain proportions of all crops, stock, etc. The king's messengers could commandeer any subject's property, giving a receipt. Further, every city had its own octroi duties, customs, ferry dues, highway and water rates. The king had long ceased to be owner of the land, if he ever was. He had his own royal estates, his private property, and dues from all his subjects. The higher officials had endowments and official residences.
The Code regulates the feudal position of certain classes. They held an estate from the king, consisting of a house, a garden, a field, stock, and a salary, on condition of personal service on the king's errand. They could not delegate the service, on penalty of death. When ordered abroad, they could nominate a capable son to hold the benefice and carry on the duty. If there was no capable son, the state put in a "locum tenens" but granted one-third to the wife to maintain herself and her children. The fief was otherwise inalienable; it could not be sold, pledged, exchanged, sublet, devised or diminished. Other land was leased from the state. Ancestral estate was strictly tied to the family. If a holder would sell, the family kept the right of redemption, and there seems to have been no time limit to its exercise.
Temple.
The temple occupied a most important position. It received income from its estates, from tithes and other fixed dues, as well as from the sacrifices (a customary share) and other offerings of the faithful—vast amounts of all sorts of naturalia, besides money and permanent gifts. The larger temples had many officials and servants.
Originally, perhaps, each town clustered round one temple, and each head of family had a right to minister there and share its receipts. As the city grew, the right to so many days a year at one shrine (or its gate) descended within certain families and became a kind of property that could be pledged, rented or shared within the family, but not alienated. Despite all these demands, the temples became great granaries and storehouses and were also the city archives. The temple had its responsibilities. If a citizen was captured by the enemy and could not ransom himself, the temple of his city must do so. To the temple came the poor farmer to borrow seed, grain, or supplies for harvesters, etc.—advances that he repaid without interest.
The king's power over the temple was not proprietary, but administrative. He might borrow from it, but repaid like other borrowers. The tithe seems to have been considered the rent due to the god for his land. It is not clear that all lands paid tithe; perhaps only such as once had a special connection with the temple.
The Code deals with a class of persons devoted to the service of a god, as vestals or hierodules. The vestals were vowed to chastity, lived together in a great nunnery, were forbidden to enter a tavern, and, together with other votaries, had many privileges.
Property law.
The Code recognizes many ways of disposing of property: sale, lease, barter, gift, dedication, deposit, loan, or pledge, all of which were matters of contract. Sale was the delivery of a purchase (in the case of real estate, symbolized by a staff, a key, or deed of conveyance) in return for purchase money, receipts being given for both. Credit, if given, was treated as a debt, and secured as a loan by the seller to be repaid by the buyer, for which he gave a bond.
The Code only allows claims substantiated by documents, or in some cases the oath of witnesses. Saving contracts and receipts thus assumed a vital importance in Babylon - in fact it could literally be a matter of life or death. A buyer had to be sure of the seller's title. If he bought (or received on deposit) property from even a minor or a slave without witnessing contracts, he would be executed as a thief (§7). If purchased goods were stolen and the rightful owner reclaimed them, he had to prove his purchase by producing the seller and the deed of sale, or witnesses to it; otherwise, he would be adjudged a thief and die. If he proved his purchase, he had to give up the property but could pursue a remedy against the seller or, if the seller had died, could reclaim fivefold from his estate.
A man who bought a slave abroad might find that he had previously been stolen or captured from Babylonia; he would then have to restore him to his former owner without recompense. If he bought property belonging to a feudal holding, or to a ward in Chancery, he had to return it as well as forfeit what he paid for it. He could repudiate the purchase of a slave attacked by the "bennu" sickness within a month (later, a hundred days) and could hold a newly purchased female slave for three days "on approval". A defect of title, or an undisclosed liability, would invalidate a sale at any time.
Leasing.
Landowners frequently cultivated their land themselves, but could also employ a husbandman, or rent it. The husbandman was bound to carry out proper cultivation, raise an average crop, and leave the field in good tilth. In case the crop failed, the Code fixed a statutory return. Land might be leased at a fixed rent, where the Code stipulates that accidental loss fell on the tenant. If leased on profit-sharing terms, the landlord and tenant shared the loss proportionally to their stipulated share of profit. If the tenant paid his rent and kept the land in good tilth, the landlord could not interfere nor forbid subletting.
Wasteland could be leased for reclamation, the tenant being rent-free for three years and paying a stipulated rent in the fourth year. If the tenant neglected to reclaim the land, the Code stipulated that he must hand it over in good tilth and set a statutory rent. Gardens or plantations were leased in the same ways and under the same conditions; but for date groves, four years' free tenure was allowed.
The metayer system was common, especially on temple lands. The landlord found land, labour, oxen for ploughing and working the watering machines, carting, threshing or other implements, grain seed, rations for the workmen and fodder for the cattle. The tenant, or steward, usually had other land of his own. If he stole the seed, rations or fodder, the Code stipulated that his fingers be cut off. If he appropriated or sold the implements, or impoverished or sublet the cattle, he was heavily fined and in default of payment, might be condemned to be torn to pieces by the cattle on the field. Rent was determined by contract.
Irrigation was essential for farming in this region. If the irrigator neglected to repair his dike or left his runnel open and caused a flood, he had to make good the damage done to his neighbours' crops or be sold with his family to pay the cost. The theft of a watering machine, water-bucket or other agricultural implement was heavily fined.
Houses were usually leased for the year, but also for longer terms, rent being paid in advance, half-yearly. The contract generally specified that the house be in good repair, and the tenant was bound to keep it so. The woodwork, including doors and door frames, was removable, and the tenant might bring and take away his own. The Code stipulated that if the landlord re-entered before the term was up, he must remit a fair proportion of the rent. Land could be leased for the purpose of building houses or other buildings on it, the tenant being rent-free for eight or ten years; after which the building came into the landlord's possession.
Hired labour.
Despite the multitude of slaves, hired labour was often needed, especially at harvest. This was a matter of contract, and the employer, who usually paid in advance, might demand a collateral against fulfillment of the work. Cattle were hired for ploughing, working the watering machines, carting, threshing, etc. The Code fixed a statutory wage for sowers, ox-drivers, field-labourers, and hire for oxen, asses, etc.
There were many herds and flocks. The flocks were committed to a shepherd, who gave receipt for them and took them out to pasture. The Code fixed his wage. He was responsible for all care, must restore ox for ox, sheep for sheep and must breed them satisfactorily. Any dishonest use of the flock had to be repaid tenfold, but loss due to disease or wild beasts fell upon the owner. The shepherd made good all loss due to his own neglect. If he let the flock feed on a field of crops, he had to pay damages fourfold; if he turned them into standing crops when they ought to have been folded, he paid twelvefold.
Debt.
In commerce, payment in kind was still common, though contracts usually stipulated cash, naming the currency expected—that of Babylon, Larsa, Assyria, Carchemish, etc. The Code stipulated, however, that a debtor must be allowed to pay in produce according to a statutory scale. If a debtor had neither money nor crops, the creditor must not refuse goods.
Debt was secured on the debtor's own person. Distraint on a debtor's grain was forbidden by the Code; not only must the creditor return it, but his illegal action forfeited his claim altogether. An unwarranted seizure for debt was fined, as was the distraint of a working ox.
If a debtor were seized for debt, he could nominate as "mancipium", or hostage to work off the debt, his wife, child, or slave. The creditor could only hold a wife or child three years as "mancipium". If the "mancipium" died a natural death while in the creditor's possession, no claim could lie against the latter; but if he was the cause of death by cruelty, he had to give son for son, or pay for a slave. He could sell a slave-hostage, but not a slave-girl who had borne her master children; she had to be redeemed by her owner.
The debtor could also pledge his property and in contracts, often pledged a field, house or crop. The Code stipulated, however, that the debtor must take the crop himself and pay the creditor from its yield. If the crop failed, payment was deferred, and no interest could be charged for that year. If the debtor did not cultivate the field himself, he had to pay for its cultivation, but if the field was already cultivated, he must harvest it himself and pay his debt from the crop. If the cultivator did not get a crop, this would not cancel his contract.
Pledges were often made where the intrinsic value of the article was equivalent to the amount of the debt; but antichretic pledge was more common, where the profit of the pledge was a set-off against the interest of the debt. The whole property of a debtor might be pledged as collateral for payment of a debt, without any of it passing through the hands of the creditor. Personal guarantees were often given in Babylon that the debtor would repay, or the guarantor become liable himself.
Trade.
Trade was very extensive. A common procedure was for a merchant to entrust his goods or money to a traveling agent, who sought a market for his goods. The caravans travelled far beyond the limits of the empire.
The Code insisted that the agent should inventory and give a receipt for all that he received. No claim could be made for anything not so entered. Even if the agent made no profit, he was bound to return double what he had received; if he made poor profit, he had to make up the deficiency; but he was not responsible for loss by robbery or extortion on his travels. On his return, the lending merchant must give him a receipt for what was handed over to him. Any false entry or claim on the agent's part was penalised threefold; on the lending merchant's part, sixfold. In normal cases, profits were divided according to contract, usually equally.
A considerable amount of forwarding (advancing wares to the agent up front) was done by the caravans. The carrier gave a receipt for the consignment, took all responsibility, and exacted a receipt upon delivery. If he defaulted, he paid fivefold. He was usually paid in advance. Deposit, especially warehousing of grain, was charged for at one-sixtieth. The warehouse man took all risks and paid double for all shortage, but no claim could be made unless he had given a properly witnessed receipt.
Water traffic on the Euphrates and canal system was early on, quite considerable. Ships, whose tonnage was estimated by the amount of grain they could carry, were continually hired for the transport of all kinds of goods. The Code fixes the price for shipbuilding and insists on the builder's giving a year's guarantee of seaworthiness. It also fixes the rate of hire for ship and crew. The captain was responsible for the freight and the ship; he had to replace all loss. Even if he refloated the ship, he had to pay a fine of half its value for sinking it. In the case of collision, the boat under way was responsible for damages to the boat at anchor.
The Code also regulated the liquor traffic—fixing a fair price for beer and forbidding the connivance of the tavern keeper (a female) at disorderly conduct or treasonable assembly, under pain of death. She was required to take the offenders to the palace—implying an efficient and accessible police system.
Payment through a banker or by written draft against deposit was frequent. Bonds to pay were treated as negotiable. Interest was rarely charged on advances by the temple or wealthy landowners for pressing needs, but this may have been part of the metayer system. The borrowers may have been tenants. Interest was charged at very high rates for overdue loans of this kind. Merchants (and even temples in some cases) made ordinary business loans, charging from 20% to 30%.
Family law.
Marriage.
Marriage retained the form of purchase, but was essentially a contract to be husband and wife together. The marriage of young people was usually arranged between their relatives—the groom's father 
the bride-price, which, with other gifts, the suitor ceremonially presented to the bride's father. This bride-price was usually then handed over by her father to the bride upon her marriage, and so returned into the bridegroom's possession, along with her dowry, which was her portion of the family's inheritance as a daughter.
The bride-price varied greatly, according to the status of the parties, but surpassed the price of a slave. The Code stipulated that if the father did not give the suitor his daughter after accepting the suitor's gifts, he must return the gifts. The bride-price had to be returned even if the father reneged on the marriage contract because of slander of the suitor on the part of the suitor's friend, and the Code stipulated that the slanderer should not marry the girl (and thus would not profit from his slander). Conversely, if a suitor changed his mind, he forfeited the presents.
The dowry might include real estate, but generally consisted of personal effects and household furniture. It remained the wife's for life, descending to her children, if any; otherwise returning to her family, when the husband could deduct the bride-price if it had not been given to her, or return it if it had.
The marriage ceremony included joining hands and the bridegroom uttering a formula of acceptance, such as, "I am the son of nobles, silver and gold shall fill thy lap, thou shalt be my wife, I will be thy husband. Like the fruit of a garden I will give thee offspring." The ceremony must be performed by a freeman.
The marriage contract—without which, the Code ruled that the woman was no wife—usually stated the consequences to which each party was liable for repudiating the other. These by no means necessarily agree with the Code. Many other conditions might also be inserted: such as that the wife should act as maidservant to her mother-in-law or to a first wife.
The married couple formed a single unit in terms of external responsibility, especially for debt. The man was responsible for debts contracted by his wife, even before her marriage, as well as for his own; but he could use her as a "mancipium". Hence the Code allowed a proviso to be inserted in the marriage contract, that the wife should not be seized for her husband's pre-nuptial debts; but stipulated that then he was not responsible for her pre-nuptial debts, and, in any case, that both together were responsible for all debts contracted after marriage. A man might make his wife a settlement by deed of gift, which gave her a life interest in part of his property, and he might reserve to her the right to bequeath it to a favorite child; but she could in no case leave it to her family. Although married, she always remained a member of her father's house—she is rarely named wife of A, but usually daughter of B, or mother of C.
Divorce.
Divorce was the husband's option, but he had to restore the dowry, and if the wife had borne him children, she had custody of them. He then had to assign her the income from property, as well as goods to maintain herself and their children until they grew up. She shared equally with their children in the allowance (and apparently in his estate at his death) and was free to marry again. If she had no children, he returned her dowry to her and paid her a sum equivalent to the bride-price, or a mina of silver if there had been none. The latter is the forfeit usually named in the contract for his repudiation of her.
If the husband could show that his wife had been a bad wife, the Code allowed him to send her away, while he kept the children as well as her dowry; or he could degrade her to the position of a slave in his own house, where she would have food and clothing. The wife might bring an action against her husband for cruelty and neglect and, if she proved her case, obtain a judicial separation, taking her dowry with her. No other punishment fell on the man. If she did not prove her case, but was proved to be a bad wife, she was drowned.
If the wife was left without maintenance during an involuntary absence of her husband (called to war, etc.), she could cohabit with another man, but must return to her husband when he came back, the children of the second union remaining with their own father. If she had maintenance, a breach of the marriage tie was adultery. Willful desertion by, or exile of, the husband dissolved the marriage without penalty to the wife. If he returned, she was not required or even permitted to return to him.
Widowhood.
A widow took her husband's place in the family—living in his house and bringing up the children. She could only remarry with judicial consent, where the judge inventoried the deceased's estate and handed it over to her and her new husband in trust for the children. They could not alienate a single utensil.
If she did not remarry, she lived on in her husband's house and, when the children had grown up, took a child's share in the division of his estate. She retained her dowry and any settlement deeded to her by her husband. This property would come down to her children on her death. If she had remarried, all her children would share equally in her dowry, but the first husband's estate fell only to his children, or to her selection among them, if so empowered.
Childbearing.
Monogamy was the rule, and a childless wife might give her husband a maid to bear him children, who were then reckoned hers. She remained mistress of her maid, and might degrade her to slavery again for insolence, but could not sell her if she had borne her husband children. If the wife did this, the Code did not allow the husband to take a concubine; but if she did not, he could do so. The concubine was a co-wife, though not of the same rank; the first wife had no power over her. A concubine was a free woman, often dowered for marriage, and her children were legitimate and lawful heirs. She could only be divorced on the same conditions as a wife.
If a wife became a chronic invalid, the husband was bound to maintain her in the home they had made together, unless she preferred to take her dowry and return to her father's house; but he was free to remarry. Again, the children of the new wife were legitimate and lawful heirs.
There was no hindrance to a man having children by a slave girl. These children were free, and their mother then could not be sold, though she might be pledged, and she became free upon her master's death. Her children could be legitimized by their father's acknowledgment before witnesses and were often adopted. They then ranked equally in sharing their father's estate; but if not adopted, the wife's children divided and took first choice.
Temple priests were not supposed to have children, yet they could marry and often did. The Code contemplated that such a wife would give a husband a maid, as above.
Free women might marry slaves and still be dowered for the marriage. The children were free, and at the slave's death, the wife took her dowry and half of what she and her husband had acquired in wedlock for self and children; the master taking the other half, as his slave's heir.
A father had control over his children until their marriage. He had a right to their labor in return for their keep. He might hire them out and receive their wages, pledge them for debt, or even sell them outright. Mothers had the same rights in the absence of the father; elder brothers, when both parents were dead. A father had no claim on his married children for support, but they retained the right to inherit on his death.
The daughter was not only in her father's power to be given in marriage, but he might dedicate her to the service of a god as a vestal or a hierodule or give her as a concubine. She had no choice in these matters, often decided in her childhood. An adult daughter might wish to become a votary, perhaps in preference to an uncongenial marriage, and it seems that her father could not refuse her wish.
In all these cases, the father might dower her. If he did not, on his death the brothers were obligated to do so, giving her a full child's share if a wife, a concubine or a vestal, but one-third of a child's share if she were a hierodule or a Marduk priestess. The latter had the privilege of exemption from state dues and absolute disposal of her property. All other daughters had only a life interest in their dowry, which reverted to their family if childless or went to their children if they had any. A father might, however, execute a deed granting a daughter power to leave her property to a favorite brother or sister.
A daughter's estate was usually managed for her by her brothers, but if they dissatisfied her, she could appoint a steward. If she married, her husband then managed it. Sons also appear to have received their share on marriage, but then did not always leave their father's house; they might bring their wives there. This was usual in child marriages.
Adoption.
Adoption was very common, especially when the father (or mother) was childless or had seen all his children grow up and marry away. The child was then adopted to care for the parents' old age. This was done by contract, which usually specified what the parent had to leave and what maintenance was expected. The natural children, if any, were usually consenting parties to an arrangement that cut off their expectations. In some cases they even acquired the estate for the adopted child who was to relieve them of care. If the adopted child failed to carry out the filial duty, the contract was annulled in the law courts. Slaves were often adopted, and if they proved unfilial, were reduced to slavery again.
A craftsman often adopted a son to learn the craft. He profited by the son's labour. If he failed to teach his son the craft, that son could prosecute him and get the contract annulled. This was a form of apprenticeship, and it is not clear whether the apprentice had any filial relation.
A man who had adopted a child, and afterwards married and had a family of his own, could dissolve the contract and must give the adopted child one-third of a child's share in goods, but no real estate. Property could only descend through his legitimate family. Vestals frequently adopted daughters, usually other vestals, to care for them in their old age.
Adoption had to be with consent of the natural parents, who usually executed a deed making over the child, who thus ceased to have any claim upon them. But vestals, hierodules, certain palace officials and slaves had no rights over their children and could raise no objection. Orphans and illegitimate children had no parents to object. Ingratitude by adopted children was severely frowned on by the law: if the adopted child of a prostitute abandoned his foster parents and returned to his biological father's house, his eye was torn out. If an adopted child rejected his foster parents, claiming they were not his mother and father, his tongue was torn out. An adopted child was a full heir; the contract might even assign him the position of eldest son. Usually, he was residuary legatee.
Heirs.
All legitimate children shared equally in the father's estate on his death, reservation being made of a bride-price for an unmarried son, dower for a daughter, or property deeded to favourite children by the father. There was no birthright attaching to the position of eldest son, but he usually acted as executor and, after considering what each had already received, equalized the shares. He even made grants in excess to the others from his own share. If there were two widows with legitimate issue, both families shared equally in the father's estate, until later times, when the first family took two-thirds. Daughters, in the absence of sons, had sons' rights. Children also shared their own mother's property, but had no share in that of a stepmother.
A father could disinherit a son in early times without restriction, but the Code insisted upon judicial consent, and that only for repeated unfilial conduct. In early times, the son who denied his father had his front hair shorn and a slave-mark put on him and could be sold as a slave; while the son who denied his mother had his front hair shorn, was driven round the city as an example and expelled from his home, but not degraded to slavery.
Adultery.
Adultery was punished with the death of both parties by drowning; but if the husband was willing to pardon his wife, the king might intervene to pardon the paramour. For incest between mother and son, both were burned to death; with a stepmother, the man was disinherited; with a daughter, the man was exiled; with a daughter-in-law, he was drowned; with a son's fiancée, he was fined. A wife who for her lover's sake procured her husband's death was gibbeted. A betrothed girl seduced by her prospective father-in-law took her dowry and returned to her family and was free to marry as she chose.
Punishment.
In the criminal code, the ruling principle was the "lex talionis". Eye for eye, tooth for tooth, limb for limb was the penalty for assault upon an "amelu". A sort of symbolic retaliation was the punishment for the offender, seen in cutting off the hand that struck a father or stole a trust; in cutting off the breast of a wet nurse who switched the child entrusted to her for another; in the loss of the tongue that denied father or mother (in Elamite contracts, the same penalty was inflicted for perjury); in the loss of the eye that pried into forbidden secrets. The loss of the surgeon's hand that caused loss of life or limb, or the brander's hand that obliterated a slave's identification mark, are very similar. The slave who struck a freeman or denied his master lost an ear, the organ of hearing and symbol of obedience. A person who brought another into danger of death by false accusation was punished by death. A perjurer was punished by the same penalty the perjurer sought to bring upon another.
The death penalty was freely rendered for theft and other crimes in this section of the Code: for theft involving entering a palace or temple treasury, for illegal purchase from a minor or slave, for selling stolen goods or receiving the same, for common theft in the open (in lieu of multiple-fold restoration) or receiving the same, for false claim to goods, for kidnapping, for assisting or harbouring fugitive slaves, for detaining or appropriating the same, for brigandage, for fraudulent sale of drink, for not reporting criminal conspiracy in one's tavern, for delegation of personal service and refusing to pay the delegate or not sending the delegate, for misappropriating the levy, for harming or robbing one of the king's captains, for causing the death of a house owner through bad construction. The manner of death is not specified for these cases.
This death penalty was also set for conduct that placed another in danger of death. The form of death penalty was specified for the following cases: gibbeting: for burglary (on the spot where crime was committed), later also for encroaching on the king's highway, for getting a slave-brand obliterated, for procuring a husband's death; burning: for incest with own mother, for a vestal entering or opening a tavern, for looting a house on fire (thrown into the fire); drowning: for adultery, rape of a betrothed maiden, bigamy, bad conduct as a wife, seduction of a daughter-in-law.
A curious extension of the "lex talionis" is the death of a creditor's son for his father's having caused the death of a debtor's son as "mancipium"; of a builder's son for his father's causing the death of a house owner's son by bad construction; the death of a man's daughter because her father caused the death of another man's daughter.
Contracts naturally do not usually touch on criminal matters as the above, but marriage contracts do specify death by strangling, drowning, precipitation from a tower or pinnacle of the temple, or by the iron sword, for a wife's repudiation of her husband. We are quite without evidence as to the executioner in all these cases.
Exile was inflicted for incest with a daughter; disinheritance for incest with a stepmother, or for repeated unfilial conduct. Sixty strokes of an ox-hide scourge were awarded for a brutal assault on a superior, both being "amelu". Branding (perhaps the equivalent of degradation to slavery) was the penalty for slander of a married woman or vestal. Permanent deprivation of office fell upon the corrupt judge. Enslavement befell the extravagant wife and unfilial children. Imprisonment was common, but is not mentioned in the Code.
The commonest of all penalties was a fine. This is awarded by the Code for corporal injuries to a "mushkenu" or to a slave (paid to his master), for damages done to property, or for breach of contract. The restoration of goods appropriated, illegally bought, or damaged by neglect, was usually accompanied by a fine, giving it the form of multiple restoration. This might be double, treble, fourfold, fivefold, sixfold, tenfold, twelvefold, or even thirtyfold, according to the enormity of the offence.
The Code recognized the importance of intent. A man who killed another in a quarrel must swear he did not do so intentionally and was then only fined according to the rank of the deceased. The Code does not say what would be the penalty of murder, but death is so often awarded where death is caused, that we can hardly doubt that the murderer was put to death. If the assault only led to injury and was unintentional, the assailant in a quarrel had to pay the doctor's fees. A brander, induced to remove a slave's identification mark, could swear to his ignorance and was free. The owner of an ox that gored a man on the street was only responsible for damages if the ox was known by him to be vicious—even if it caused death. If the "mancipium" died a natural death under the creditor's hand, the creditor was free. In ordinary cases, a person was not responsible for accident or if they exercised more than proper care. Poverty excused bigamy on the part of a deserted wife.
On the other hand, carelessness and neglect were severely punished, as in the case of the unskillful physician, if it led to loss of life or limb, his hands were cut off; a slave had to be replaced, the loss of his eye paid for by half his value; a veterinary surgeon who caused the death of an ox or donkey paid quarter value; a builder whose careless workmanship caused death lost his life or paid for it by the death of his child, replaced slave or goods and in any case, had to rebuild the house or make good any damages due to defective building and repair the defect as well. The boat builder had to make good any defect of construction or damage due to it for a year's warranty.
Throughout the Code, respect is paid to evidence. Suspicion was not enough. The criminal must be taken in the act, e.g. the adulterer, etc. A man could not be convicted of theft unless the goods were found in his possession.
In the case of a lawsuit, the plaintiff proferred his own plea. There is no trace of professional advocates, but the plea had to be in writing, and the notary doubtlessly assisted in the drafting of it. The judge saw the plea, called the other parties before him, and sent for the witnesses. If these were not at hand, he might adjourn the case for their subpoena, specifying a time for up to six months. Pledges might be made to produce the witnesses on a fixed day.
The more important cases, especially those involving life and death, were tried by a bench of judges. With the judges were associated a body of elders who shared in the decision, but whose exact function is not yet clear. Agreements, declarations and non-contentious cases were usually witnessed by one judge and twelve elders.
Parties and witnesses were put on oath. The penalty for false witness was usually the punishment that would have been awarded the victim if convicted. In matters beyond human knowledge, such as the guilt or innocence of an alleged practitioner of magic or a suspected wife, the ordeal by water was used. The accused jumped into the sacred river, and the innocent swam while the guilty drowned. The accused could clear himself by taking an oath if the only knowledge available was his own. The plaintiff could swear to his loss by brigands, the price paid for a slave purchased abroad, or the sum due to him; but great stress was laid on the production of written evidence. It was a serious thing to lose a document. The judges might be satisfied of its existence and terms by the affidavit of the witnesses to it and then issue an order that whenever found, it should be submitted. The clay tablets of contracts that were annulled were broken. The court might even travel to view the property and take with them the sacred symbols with which oaths were made.
Court decisions were set in writing, sealed and witnessed by the judges, the elders, witnesses, and a scribe. Women might act in all these capacities. The parties swore an oath, included in the document, to observe its stipulations. Each party received a copy, and one was kept by the scribe to be stored in the archives.
Appeal to the king was allowed and is well attested. The judges at Babylon seem to have formed a superior court to those of provincial towns, but a defendant might elect to answer the charge before the local court and refuse to plead at Babylon.
Finally, it may be noted that many immoral acts, such as the use of false weights, lying, etc., that could not be brought into court are severely denounced in the Omen Tablets as likely to bring the offender into "the hand of God" as opposed to "the hand of the king".

</doc>
<doc id="58227" url="https://en.wikipedia.org/wiki?curid=58227" title="Arcadia">
Arcadia

Arcadia (, "Arkadía") is one of the regional units of Greece. It is part of the administrative region of Peloponnese. It is situated in the central and eastern part of the Peloponnese peninsula. It takes its name from the mythological character Arcas. In Greek mythology, it was the home of the god Pan. In European Renaissance arts, Arcadia was celebrated as an unspoiled, harmonious wilderness.
Geography.
Arcadia has its present-day capital at Tripoli. It covers about 18% of the Peloponnese peninsula, making it the largest regional unit on the peninsula. Arcadia has a ski resort on Mount Mainalo, located about 20 km NW of Tripoli. Other mountains of Arcadia are the Parnon in the southeast and the Lykaion in the west.
The climate consists of hot summers and mild winters in the eastern part, the southern part, the low-lying areas and the central area at altitudes lower than 1,000 m. The area primarily receives rain during fall and winter months in the rest of Arcadia. Winter snow occurs commonly in the mountainous areas for much of the west and the northern part, the Taygetus area, the Mainalon.
History.
Medieval history.
After the collapse of the Roman power in the west, Arcadia became part of the Greek-speaking Byzantine Empire. Arcadia remained a beautiful, secluded area, and its inhabitants became proverbial as herdsmen leading simple pastoral unsophisticated yet happy lives, to the point that "Arcadia" may refer to some imaginary idyllic paradise, immortalized by Virgil's Eclogues, and later by Jacopo Sannazaro in his pastoral masterpiece, "Arcadia" (1504); see also Arcadia (utopia).
After the Fourth Crusade, the area became a part of the Principality of Achaea, but was progressively recovered by the Byzantine Greeks of the Despotate of the Morea from the 1260s on, a process that lasted until the mid-14th century. The region fell into the hands of the Ottoman Turks in 1460. With the exception of a period of Venetian rule in 1687–1715, the region remained under Turkish control until 1821.
The Latin phrase "Et in Arcadia ego", which is usually interpreted to mean "Even in Arcadia there am I", is an example of "memento mori", a cautionary reminder of the transitory nature of life and the inevitability of death. The phrase is most often associated with a 1647 painting by Nicolas Poussin, also known as "The Arcadian Shepherds". In the painting the phrase appears as an inscription on a tomb discovered by youthful figures in classical garb.
Modern history.
Arcadia was one of the centres of the Greek War of Independence which saw victories in their battles including one in Tripoli. After a victorious revolutionary war, Arcadia was finally incorporated into the newly created Greek state. Arcadia saw economic growth and small emigration.
In the 20th century, Arcadia experienced extensive population loss through emigration, mostly to the Americas. Many Arcadian villages lost half their inhabitants, and fears arose that they would turn into ghost towns. Arcadia now has a smaller population than Corinthia. Demographers expected that its population would halve between 1951 and the early 21st century. The population has fallen to 87,000 in 2011.
An earthquake measuring 5.9 on the Richter magnitude scale shook Megalopoli and the surrounding area in 1965. Large numbers of buildings were destroyed, leaving people homeless. Within a couple of years, the buildings were rebuilt anti-seismically. In 1967, construction began on the Megalopoli Power Plant, which began operating in 1970, producing additional electricity for southern Greece. A mining area south of the plant is the largest mining area in the peninsula and continues to the present day with one settlement moved.
In July and August 2007 forest fires caused damage in Arcadia, notably in the mountains.
In 2008, a theory proposed by classicist Christos Mergoupis suggested that the mummified remains of Alexander the Great (not his actual tomb), may in fact be located in Gortynia-Arkadia, in the Peloponnese of Greece. Since 2008, this research is ongoing and currently being conducted in Greece. The research was first mentioned on CNN International in May 2008.
Language.
When, during the Greek Dark Ages (c. 1200 BC–800 BC), Doric Greek dialects were introduced to the Peloponnese, the older language apparently survived in Arcadia, and formed part of the Arcado-Cypriot group of Greek languages. Arcadocypriot never became a literary dialect, but it is known from inscriptions. Tsan is a letter of the Greek alphabet occurring only in Arcadia, shaped like Cyrillic И; it represents an affricate that developed from labiovelars in context where they became "t" in other dialects.
Tsakonian Greek, still spoken on the coast of modern Arcadia (but in the Classical period considered the southern Argolid coast immediately adjoining Arcadia), is a descendant of Doric Greek, and as such is an extraordinary example of a surviving regional dialect of archaic Greek. The principal cities of Tsakonia are the Arcadian coastal towns of Leonidio and Tyros.
Administration.
The regional unit Arcadia is subdivided into 5 municipalities. These are (number as in the map in the infobox):
Prefecture.
As a part of the 2011 Kallikratis government reform, the regional unit Arcadia was created out of the former prefecture Arcadia (). The prefecture had the same territory as the present regional unit. At the same time, the municipalities were reorganised, according to the table below.
Provinces.
Arcadia was divided into four provinces:
"Note:" Provinces no longer hold any legal status in Greece.
Ancient and modern towns and cities.
The main towns in modern Arcadia are Tripoli, Astros, Vytina, Dimitsana, Lagkadia, Tyros, Leonidio, Levidi, Megalopolis and Stemnitsa.
Ancient cities include Acacesium (founded by Acacus), Asea, Astros, Athinaio, Daseae, Falaisia (Phalesia), Gortys, Hypsus (Stemnitsa), Heraia, Lusi, Lykaio, Lycosura, Mantineia, Megalopoli, Orchomenus (Orchomenos), Tegea, Thoknia, Trapezus, Trikolonoi, Tropaia, Tripoli, Tyros, other cities includes Basilis, Caphyae, Charisia, Ellison, Enispe, Kaous, Karyes, Methydrio, Melangeia, Oryx, Paroria, Pelagos, Rhipe, Stratia, Teuthis and several more. Cities which once belonged in Arcadia include Alea (now in Argolis) and Amilos (now in Achaia).
Economy.
A thermoelectric power station which produces electricity for most of southern Greece, operates to the south of Megalopolis, along with a coal mine.
In agriculture, potato farms (dominant in central and northcentral Arcadia), mixed farming, olive groves, and pasture dominate the plains of Arcadia, especially in the area around Megalopolis and between Tripoli and Levidi.
Transport.
The Moreas Motorway (A7, E65) highway connects Tripoli with Corinth and Athens. It is being extended further southwest to Megalopoli and Kalamata.
Arcadia has two tunnels. The Artemisio Tunnel opened first, followed by the tunnel east of Megalopolis; both serve traffic flowing between Messenia and Athens.

</doc>
<doc id="58229" url="https://en.wikipedia.org/wiki?curid=58229" title="Bacchanalia">
Bacchanalia

The Bacchanalia were Roman festivals of Bacchus, based on various ecstatic elements of the Greek Dionysia. They seem to have been popular, and well-organised, throughout the central and southern Italian peninsula. They were almost certainly associated with Rome's native cult of Liber, and probably arrived in Rome itself around 200 BC but like all mystery religions of the ancient world, very little is known of their rites.
Livy, writing some 200 years after the event, offers a scandalised, extremely colourful account of the Bacchanalia. Modern scholarship takes a skeptical approach to his allegations of frenzied rites, sexually violent initiations of both sexes, all ages and all social classes, and the cult as a murderous instrument of conspiracy against the state. Livy claims that seven thousand cult leaders and followers were arrested, and that most were executed.
Senatorial legislation to reform the Bacchanalia in 186 BC attempted to control their size, organisation, and priesthoods, under threat of the death penalty. This may have been motivated less by the kind of lurid and dramatic rumours that Livy describes than by the senate's determination to assert its civil and religious authority over Rome and her allies, after the prolonged social, political and military crisis of the Second Punic War. The reformed Bacchanalia rites may have been merged with the Liberalia festival. Bacchus, Liber and Dionysus became virtually interchangeable from the late Republican era onward, and their mystery cults persisted well into the Roman Imperial era.
Background and development.
The Bacchanalia were Roman festivals of Bacchus, the Greco-Roman god of wine, freedom, intoxication and ecstasy. They were based on the Greek Dionysia and the Dionysian mysteries, and probably arrived in Rome c. 200 BC via the Greek colonies in southern Italy, and from Etruria, Rome's northern neighbour. Like all mystery cults, the Bacchanalia were held in strict privacy, and initiates were bound to secrecy; what little is known of the cult and its rites derives from Greek and Roman literature, plays, statuary and paintings.
Livy, the principal Roman literary source on the early Bacchanalia, names Paculla Annia, a Campanian priestess of Bacchus, as the founder of a private, unofficial Bacchanalia cult in Rome, based at the grove of Stimula, where the western slope of the Aventine Hill descends to the Tiber. The Aventine was an ethnically mixed district, strongly identified with Rome's plebeian class and the ingress of new and foreign cults. The wine and fertility god Liber Pater ("The Free Father"), divine patron of plebeian rights, freedoms and augury, had a long-established official cult in the nearby temple he shared with Ceres and Libera. Most Roman sources describe him as Rome's equivalent to Dionysus and Bacchus, both of whom were sometimes titled "eleutherios" (liberator).
Livy claims the earliest version as open to women only, and held on three days of the year, in daylight; while in nearby Etruria, north of Rome, a "Greek of humble origin, versed in sacrifices and soothsaying" had established a nocturnal version, added wine and feasting to the mix, and thus acquired an enthusiastic following of women and men; Livy says that Paculla Annia corrupted Rome's unofficial but morally acceptable Bacchic cult by introducing the Etruscan version, with five, always nocturnal cult meetings a month, open to all social classes, ages and sexes—starting with her own sons; the new celebrations and initiations featured wine-fueled violence and violent sexual promiscuity, in which the screams of the abused were drowned out by the din of drums and cymbals. Those who resisted or betrayed the cult were disposed of. Under cover of religion, priests and acolytes broke civil, moral and religious laws with impunity. Livy also claims that while the cult held particular appeal to those of uneducated and fickle mind ("levitas animi"), such as the young, plebeians, women and "men most like women", most of the city's population was involved, and even Rome's highest class was not immune. An ex-initiate and prostitute named Hispala Faecenia, fearing the cult's vengeance for her betrayal but more fearful for her young, upper class client and protegé, told all to the consul Postumius, who presented it to a shocked Roman senate as a dire national emergency. Once investigations were complete, the senate rewarded and protected informants, and suppressed the cult "throughout Italy"—or rather, forced its reformation, in the course of which seven thousand persons were arrested, most of whom were executed.
Reform.
Legislation of 186, known as the "Senatus consultum de Bacchanalibus", brought the Bacchanalia under control of the senate, and thus of the Roman pontifices. The existing cult chapters and colleges were dismantled. Congregations of mixed gender were permitted, but were limited to no more than two men and three women, and any Bacchanalia gathering must seek prior permission from the Senate. Men were forbidden Bacchus' priesthood.
Despite their official suppression, illicit Bacchanals persisted covertly for many years, particularly in Southern Italy, their likely place of origin. The reformed, officially approved Bacchic cults would have borne little resemblance to the earlier crowded, ecstatic and uninhibited Bacchanalia. Similar attrition may have been imposed on Liber's cults; his perceived or actual association with the Bacchanalia may be the reason that his Liberalia "ludi" of 17 March were temporarily moved to Ceres' Cerealia of 12–19 April. They were restored when the ferocity of reaction eased, but in approved, much modified form.
Interpretations.
Livy's account of the Bacchanalia has been described as "tendentious to say the least". As a political and social conservative, he had a deep mistrust of mystery religions, and probably understood any form of Bacchanalia as a sign of Roman degeneracy. Though most of his "dramatis personae" are known historical figures, their speeches are implausibly circumstantial, and his characters, tropes and plot developments draw more from Roman satyr plays than from the Bacchanalia themselves. Paculla Annia is unlikely to have introduced all the changes he attributes to her.
For Livy, the cult's greatest offences arose from indiscriminate mixing of freeborn Romans of both sexes and all ages at night, a time when passions are easily aroused, especially given wine and unrestricted opportunity. Women at these gatherings, he says, outnumbered men; and his account has the consul Postumius stress the overwhelmingly female nature and organisation of the cult. Yet the "Senatus consultum de Bacchanalibus" itself allows women to outnumber men, by three to two, at any permitted gathering; and it expressly forbids Bacchic priesthoods to men. Livy's own narrative names all but one of the offending cult leaders as male, which seems to eliminate any perceived "conspiracy of women". Gender seems to have motivated the Senate's response no more than any other cause.
Livy's insistently negative account of the cult's Greek origins and low moral character—not even Bacchus is exempt from this judgment—may have sought to justify its suppression as a sudden "infiltration of too many Greek elements into Roman worship". The cult had, however, been active in Rome for many years before its supposedly abrupt discovery, and Bacchic and Dionysiac cults had been part of life in Roman and allied, Greek-speaking Italy for many decades. Greek cults and Greek influences had been part of Rome's religious life since the 5th century BC, and Rome's acquisition of foreign cults—Greek or otherwise—through alliance, treaty, capture or conquest was a cornerstone of its foreign policy, and an essential feature of its eventual hegemony. While the pace of such introductions had gathered rapidly during the 3rd century, contemporary evidence of the Bacchanalia reform betrays no anti-Greek or anti-foreign policy or sentiment.
Gruen interprets the "Senatus consultum" as a piece of "realpolitik", a display of the Roman senate's authority to its Italian allies after the Second Punic War, and a reminder to any Roman politician, populist and would-be generalissimo that the Senate's collective authority trumped all personal ambition. Nevertheless, the extent and ferocity of the official response to the Bacchanalia was probably unprecedented, and betrays some form of moral panic on the part of Roman authorities; Burkert finds "nothing comparable in religious history before the persecutions of Christians".
Modern usage.
In modern usage, "bacchanalia" can mean any uninhibited or drunken revelry. The bacchanal in art describes any small group of revellers, often including satyrs and perhaps Bacchus or Silenus, usually in a landscape setting. The subject was popular from the Renaissance onwards, and usually included a large degree of nudity among the figures.

</doc>
<doc id="58230" url="https://en.wikipedia.org/wiki?curid=58230" title="Solon">
Solon

Solon (;  BC) was an Athenian statesman, lawmaker, and poet. He is remembered particularly for his efforts to legislate against political, economic, and moral decline in archaic Athens. His reforms failed in the short term, yet he is often credited with having laid the foundations for Athenian democracy. He wrote poetry for pleasure, as patriotic propaganda, and in defense of his constitutional reforms.
Modern knowledge of Solon is limited by the fact that his works only survive in fragments and appear to feature interpolations by later authors, and by the general paucity of documentary and archaeological evidence covering Athens in the early 6th century BC. Ancient authors such as Herodotus and Plutarch are the main source of information, yet they wrote about Solon long after his death, at a time when history was by no means an academic discipline. Fourth century orators, such as Aeschines, tended to attribute to Solon all the laws of their own, much later times.
Biography.
Solon was born in Athens around 638 B.C. His family was distinguished in Attica as they belonged to a noble or Eupatrid clan although only possessing moderate wealth. Solon's father probably was Execestides. Solon's lineage, therefore, could be traced back to Codrus, the last King of Athens. According to Diogenes Laërtius, he had a brother named Dropides who was an ancestor (six generations removed) of Plato. According to Plutarch, Solon was related to the tyrant Peisistratos for their mothers were cousins. Solon was eventually drawn into the unaristocratic pursuit of commerce.
When Athens and Megara were contesting for the possession of the Salamis Island, Solon was given leadership of the Athenian forces. After repeated disasters, Solon was able to increase the morale and spirits of his body of troops on the strength of a poem he wrote about the islands. Supported by Peisistratos, he defeated the Megarians either by means of a cunning trick or more directly through heroic battle around 595 B.C. The Megarians however refused to give up their claim to the island. The dispute was referred to the Spartans, who eventually awarded possession of the island to Athens on the strength of the case that Solon put to them.
According to Diogenes Laertius, in 594 B.C. Solon was chosen archon or chief magistrate. As archon, Solon discussed his intended reforms with some friends. Knowing that he was about to cancel all debts, these friends took out loans and promptly bought some land. Suspected of complicity, Solon complied with his own law and released his own debtors, amounting to 5 talents (or 15 according to some sources). His friends never repaid their debts.
After he had finished his reforms, he travelled abroad for ten years, so that the Athenians could not induce him to repeal any of his laws. His first stop was Egypt. There, according to Herodotus he visited the Pharaoh of Egypt Amasis II. According to Plutarch, he spent some time and discussed philosophy with two Egyptian priests, Psenophis of Heliopolis and Sonchis of Sais. 
According to Plato's dialogues Timaeus and Critias, he visited Neith's temple at Sais and received from the priests there an account of the history of Atlantis. Next Solon sailed to Cyprus, where he oversaw the construction of a new capital for a local king, in gratitude for which the king named it Soloi.
Solon's travels finally brought him to Sardis, capital of Lydia. According to Herodotus and Plutarch, he met with Croesus and gave the Lydian king advice, which however Croesus failed to appreciate until it was too late. Croesus had considered himself to be the happiest man alive and Solon had advised him, "Count no man happy until he be dead." The reasoning was that at any minute, fortune might turn on even the happiest man and make his life miserable. It was only after he had lost his kingdom to the Persian king Cyrus, while awaiting execution, that Croesus acknowledged the wisdom of Solon's advice.
After his return to Athens, Solon became a staunch opponent of Peisistratos. In protest and as an example to others, Solon stood outside his own home in full armour, urging all who passed to resist the machinations of the would-be tyrant. His efforts were in vain. Solon died shortly after Peisistratos usurped by force the autocratic power that Athens had once freely bestowed upon him. He died in Cyprus at the age of 80 and, in accordance with his will, his ashes were scattered around Salamis, the island where he was born.
The travel writer Pausanias listed Solon among the seven sages whose aphorisms adorned Apollo's temple in Delphi. Stobaeus in the Florilegium relates a story about a symposium, where Solon's young nephew was singing a poem of Sappho's; Solon, upon hearing the song, asked the boy to teach him to sing it. When someone asked, "Why should you waste your time on it?" Solon replied , "So that I may learn it then die." Ammianus Marcellinus however told a similar story about Socrates and the poet Stesichorus, quoting the philosopher's rapture in almost identical terms: "ut aliquid sciens amplius e vita discedam", meaning "in order to go away knowing more out of life".
Background to Solon's reforms.
During Solon's time, many Greek city-states had seen the emergence of tyrants, opportunistic noblemen who had taken power on behalf of sectional interests. In Sicyon, Cleisthenes had usurped power on behalf of an Ionian minority. In Megara, Theagenes had come to power as an enemy of the local oligarchs. The son-in-law of Theagenes, an Athenian nobleman named Cylon, made an unsuccessful attempt to seize power in Athens in 632 BC. Solon was described by Plutarch as having been temporarily awarded autocratic powers by Athenian citizens on the grounds that he had the "wisdom" to sort out their differences for them in a peaceful and equitable manner. According to ancient sources, he obtained these powers when he was elected eponymous archon (594/3 BC). Some modern scholars believe these powers were in fact granted some years after Solon had been archon, when he would have been a member of the Areopagus and probably a more respected statesman by his (aristocratic) peers.
The social and political upheavals that characterised Athens in Solon's time have been variously interpreted by historians from ancient times to the present day. Two contemporary historians have identified three distinct historical accounts of Solon's Athens, emphasizing quite different rivalries: economic and ideological rivalry, regional rivalry and rivalry between aristocratic clans. These different accounts provide a convenient basis for an overview of the issues involved.
The historical account of Solon's Athens has evolved over many centuries into a set of contradictory stories or a complex story that might be interpreted in a variety of ways. As further evidence accumulates, and as historians continue to debate the issues, Solon's motivations and the intentions behind his reforms will continue to attract speculation.
Solon's reforms.
Solon's laws were inscribed on large wooden slabs or cylinders attached to a series of axles that stood upright in the Prytaneion. These "axones" appear to have operated on the same principle as a Lazy Susan, allowing both convenient storage and ease of access. Originally the axones recorded laws enacted by Draco in the late 7th Century (traditionally 621 BC). Nothing of Draco's codification has survived except for a law relating to homicide, yet there is consensus among scholars that it did not amount to anything like a constitution. Solon repealed all Draco's laws except those relating to homicide. During his visit to Athens, Pausanias, the 2nd century AD geographer reported that the inscribed laws of Solon were still displayed by the Prytaneion. Fragments of the axones were still visible in Plutarch's time but today the only records we have of Solon's laws are fragmentary quotes and comments in literary sources such as those written by Plutarch himself. Moreover, the language of his laws was archaic even by the standards of the fifth century and this caused interpretational problems for ancient commentators. Modern scholars doubt the reliability of these sources and our knowledge of Solon's legislation is therefore actually very limited in its details.
Generally, Solon's reforms appear to have been constitutional, economic and moral in their scope. This distinction, though somewhat artificial, does at least provide a convenient framework within which to consider the laws that have been attributed to Solon. Some short-term consequences of his reforms are considered at the end of the section.
Constitutional reform.
Before Solon's reforms, the Athenian state was administered by nine archons appointed or elected annually by the Areopagus on the basis of noble birth and wealth. The Areopagus comprised former archons and it therefore had, in addition to the power of appointment, extraordinary influence as a consultative body. The nine archons took the oath of office while ceremonially standing on a stone in the agora, declaring their readiness to dedicate a golden statue if they should ever be found to have violated the laws. There was an assembly of Athenian citizens (the Ekklesia) but the lowest class (the Thetes) was not admitted and its deliberative procedures were controlled by the nobles. There therefore seemed to be no means by which an archon could be called to account for breach of oath unless the Areopagus favoured his prosecution.
According to the "Athenian Constitution", Solon legislated for all citizens to be admitted into the Ekklesia and for a court (the Heliaia) to be formed from all the citizens. The Heliaia appears to have been the Ekklesia, or some representative portion of it, sitting as a jury. By giving common people the power not only to elect officials but also to call them to account, Solon appears to have established the foundations of a true republic. However some scholars have doubted whether Solon actually included the Thetes in the Ekklesia, this being considered too bold a move for any aristocrat in the archaic period. Ancient sources credit Solon with the creation of a Council of Four Hundred, drawn from the four Athenian tribes to serve as a steering committee for the enlarged Ekklesia. However, many modern scholars have doubted this also.
There is consensus among scholars that Solon lowered the requirements—those that existed in terms of financial and social qualifications—which applied to election to public office. The Solonian constitution divided citizens into four political classes defined according to assessable property a classification that might previously have served the state for military or taxation purposes only. The standard unit for this assessment was one "medimnos" (approximately 12 gallons) of cereals and yet the kind of classification set out below might be considered too simplistic to be historically accurate. 
According to the "Athenian Constitution", only the "pentakosiomedimnoi" were eligible for election to high office as archons and therefore only they gained admission into the Areopagus. A modern view affords the same privilege to the "hippeis". The top three classes were eligible for a variety of lesser posts and only the "thetes" were excluded from all public office.
Depending on how we interpret the historical facts known to us, Solon's constitutional reforms were either a radical anticipation of democratic government, or they merely provided a plutocratic flavour to a stubbornly aristocratic regime, or else the truth lies somewhere between these two extremes.
Economic reform.
Solon's economic reforms need to be understood in the context of the primitive, subsistence economy that prevailed both before and after his time. Most Athenians were still living in rural settlements right up to the Peloponnesian War. Opportunities for trade even within the Athenian borders were limited. The typical farming family, even in classical times, barely produced enough to satisfy its own needs. and yet there is no evidence that Athens possessed any merchant ships until around 525 BC. and by about 525 BC it was able to feed itself only in 'good years'.
Solon's reforms can thus be seen to have taken place at a crucial period of economic transition, when a subsistence rural economy increasingly required the support of a nascent commercial sector. The specific economic reforms credited to Solon are these:
It is generally assumed, on the authority of ancient commentators that Solon also reformed the Athenian coinage. However, recent numismatic studies now lead to the conclusion that Athens probably had no coinage until around 560 BC, well after Solon's reforms. Nevertheless, there are now reasons to suggest that monetization had already begun before Solon's reforms. By early sixth century the Athenians were using silver in the form of a variety of bullion silver pieces for monetary payments. Drachma and obol as a term of bullion value had already been adopted, although the corresponding standard weights were probably unstable.
Solon's economic reforms succeeded in stimulating foreign trade. Athenian black-figure pottery was exported in increasing quantities and good quality throughout the Aegean between 600 BC and 560 BC, a success story that coincided with a decline in trade in Corinthian pottery. The ban on the export of grain might be understood as a relief measure for the benefit of the poor. However, the encouragement of olive production for export could actually have led to increased hardship for many Athenians to the extent that it led to a reduction in the amount of land dedicated to grain. Moreover, an olive produces no fruit for the first six years (but farmers' difficulty of lasting until payback may also give rise to a mercantilist argument in favour of supporting them through that, since the British case illustrates that 'One domestic policy that had a lasting impact was the conversion of "waste lands" to agricultural use. Mercantilists felt that to maximize a nation's power all land and resources had to be used to their utmost...'). The real motives behind Solon's economic reforms are therefore as questionable as his real motives for constitutional reform. Were the poor being forced to serve the needs of a changing economy, was the economy being reformed to serve the needs of the poor, or were Solon's policies the manifestation of a struggle taking place between poorer citizens and the aristocrats?
Moral reform.
In his poems, Solon portrays Athens as being under threat from the unrestrained greed and arrogance of its citizens. Even the earth (Gaia), the mighty mother of the gods, had been enslaved. The visible symbol of this perversion of the natural and social order was a boundary marker called a "horos", a wooden or stone pillar indicating that a farmer was in debt or under contractual obligation to someone else, either a noble patron or a creditor. Up until Solon's time, land was the inalienable property of a family or clan and it could not be sold or mortgaged. This was no disadvantage to a clan with large landholdings since it could always rent out farms in a sharecropping system. A family struggling on a small farm however could not use the farm as security for a loan even if it owned the farm. Instead the farmer would have to offer himself and his family as security, providing some form of slave labour in lieu of repayment. Equally, a family might voluntarily pledge part of its farm income or labour to a powerful clan in return for its protection. Farmers subject to these sorts of arrangements were loosely known as "hektemoroi" indicating that they either paid or kept a sixth of a farm's annual yield. In the event of 'bankruptcy', or failure to honour the contract stipulated by the "horoi", farmers and their families could in fact be sold into slavery.
Solon's reform of these injustices was later known and celebrated among Athenians as the Seisachtheia (shaking off of burdens). As with all his reforms, there is considerable scholarly debate about its real significance. Many scholars are content to accept the account given by the ancient sources, interpreting it as a cancellation of debts, while others interpret it as the abolition of a type of feudal relationship, and some prefer to explore new possibilities for interpretation. The reforms included:
The removal of the "horoi" clearly provided immediate economic relief for the most oppressed group in Attica, and it also brought an immediate end to the enslavement of Athenians by their countrymen. Some Athenians had already been sold into slavery abroad and some had fled abroad to escape enslavement – Solon proudly records in verse the return of this diaspora. It has been cynically observed, however, that few of these unfortunates were likely to have been recovered. It has been observed also that the "seisachtheia" not only removed slavery and accumulated debt, it also removed the ordinary farmer's only means of obtaining further credit.
The seisachtheia however was merely one set of reforms within a broader agenda of moral reformation. Other reforms included:
Demosthenes claimed that the city's subsequent golden age included "personal modesty and frugality" among the Athenian aristocracy. Perhap Solon, by both personal example and legislated reform, established a precedent for this decorum. A heroic sense of civic duty later united Athenians against the might of the Persians. Perhaps this public spirit was instilled in them by Solon and his reforms. Also see Solon and Athenian sexuality.
Aftermath of Solon's reforms.
After completing his work of reform, Solon surrendered his extraordinary authority and left the country. According to Herodotus the country was bound by Solon to maintain his reforms for 10 years, whereas according to Plutarch and the author of the "Athenian Constitution" (reputedly Aristotle) the contracted period was instead 100 years. A modern scholar considers the time-span given by Herodotus to be historically accurate because it fits the 10 years that Solon was said to have been absent from the country. Within 4 years of Solon's departure, the old social rifts re-appeared, but with some new complications. There were irregularities in the new governmental procedures, elected officials sometimes refused to stand down from their posts and occasionally important posts were left vacant. It has even been said that some people blamed Solon for their troubles. Eventually one of Solon's relatives, Peisistratos, ended the factionalism by force, thus instituting an unconstitutionally gained tyranny. In Plutarch's account, Solon accused Athenians of stupidity and cowardice for allowing this to happen.
Poetry.
Solon's verses have come down to us in fragmentary quotations by ancient authors such as Plutarch and Demosthenes who used them to illustrate their own arguments. It is possible that some fragments have been wrongly attributed to him and some scholars have detected interpolations by later authors. He was also the first citizen of Athens to reference the goddess Athena (fr. 4.1-4).
The literary merit of Solon's verse is generally considered unexceptional. Solon's poetry can be said to appear 'self-righteous' and 'pompous' at times and he once composed an elegy with moral advice for a more gifted elegiac poet, Mimnermus. Most of the extant verses show him writing in the role of a political activist determined to assert personal authority and leadership and they have been described by the German classicist Wilamowitz as a "versified harangue" ("Eine Volksrede in Versen"). According to Plutarch however, Solon originally wrote poetry for amusement, discussing pleasure in a popular rather than philosophical way. Solon's elegiac style is said to have been influenced by the example of Tyrtaeus. He also wrote iambic and trochaic verses which, according to one modern scholar, are more lively and direct than his elegies and possibly paved the way for the iambics of Athenian drama.
Solon's verses are mainly significant for historical rather than aesthetic reasons, as a personal record of his reforms and attitudes. However, poetry is not an ideal genre for communicating facts and very little detailed information can be derived from the surviving fragments. According to Solon the poet, Solon the reformer was a voice for political moderation in Athens at a time when his fellow citizens were increasingly polarized by social and economic differences:
πολλοὶ γὰρ πλουτεῦσι κακοί, ἀγαθοὶ δὲ πένονται:<br>
ἀλλ' ἡμεῖς αὐτοῖς οὐ διαμειψόμεθα<br>
τῆς ἀρετῆς τὸν πλοῦτον: ἐπεὶ τὸ μὲν ἔμπεδον αἰεί,<br>
χρήματα δ' ἀνθρώπων ἄλλοτε ἄλλος ἔχει.<br>
Some wicked men are rich, some good are poor;<br>
We will not change our virtue for their store:<br>
Virtue's a thing that none can take away,<br>
But money changes owners all the day.
Here translated by the English poet John Dryden, Solon's words define a 'moral high ground' where differences between rich and poor can be reconciled or maybe just ignored. His poetry indicates that he attempted to use his extraordinary legislative powers to establish a peaceful settlement between the country's rival factions:
His attempts evidently were misunderstood:
Solon gave voice to Athenian 'nationalism', particularly in the city state's struggle with Megara, its neighbour and rival in the Saronic Gulf. Plutarch professes admiration of Solon's elegy urging Athenians to recapture the island of Salamis from Megarian control. The same poem was said by Diogenes Laërtius to have stirred Athenians more than any other verses that Solon wrote:
It is possible that Solon backed up this poetic bravado with true valour on the battlefield.
Solon and Athenian sexuality.
As a regulator of Athenian society, Solon, according to some authors, also formalized its sexual mores. According to a surviving fragment from a work ("Brothers") by the comic playwright Philemon, Solon established publicly funded brothels at Athens in order to "democratize" the availability of sexual pleasure. While the veracity of this comic account is open to doubt, at least one modern author considers it significant that in Classical Athens, three hundred or so years after the death of Solon, there existed a discourse that associated his reforms with an increased availability of heterosexual pleasure.
Ancient authors also say that Solon regulated pederastic relationships in Athens; this has been presented as an adaptation of custom to the new structure of the "polis". According to various authors, ancient lawgivers (and therefore Solon by implication) drew up a set of laws that were intended to promote and safeguard the institution of pederasty and to control abuses against freeborn boys. In particular, the orator Aeschines cites laws excluding slaves from wrestling halls and forbidding them to enter pederastic relationships with the sons of citizens. Accounts of Solon's laws by 4th century orators like Aeschines, however, are considered unreliable for a number of reasons;
Attic pleaders did not hesitate to attribute to him (Solon) any law which suited their case, and later writers had no criterion by which to distinguish earlier from later works. Nor can any complete and authentic collection of his statutes have survived for ancient scholars to consult.
Besides the alleged legislative aspect of Solon's involvement with pederasty, there were also suggestions of personal involvement. According to some ancient authors Solon had taken the future tyrant Peisistratos as his eromenos. Aristotle, writing around 330 BC, attempted to refute that belief, claiming that "those are manifestly talking nonsense who pretend that Solon was the lover of Peisistratos, for their ages do not admit of it," as Solon was about thirty years older than Peisistratos. Nevertheless, the tradition persisted. Four centuries later Plutarch ignored Aristotle's skepticism and recorded the following anecdote, supplemented with his own conjectures:
And they say Solon loved ; and that is the reason, I suppose, that when afterwards they differed about the government, their enmity never produced any hot and violent passion, they remembered their old kindnesses, and retained "Still in its embers living the strong fire" of their love and dear affection.
A century after Plutarch, Aelian also said that Peisistratos had been Solon's "eromenos". Despite its persistence, however, it is not known whether the account is historical or fabricated. It has been suggested that the tradition presenting a peaceful and happy coexistence between Solon and Peisistratos was cultivated during the latter's dominion, in order to legitimize his own rule, as well as that of his sons. Whatever its source, later generations lent credence to the narrative. Solon's presumed pederastic desire was thought in antiquity to have found expression also in his poetry, which is today represented only in a few surviving fragments. The authenticity of all the poetic fragments attributed to Solon is however uncertain – in particular, pederastic aphorisms ascribed by some ancient sources to Solon have been ascribed by other sources to Theognis instead.

</doc>
<doc id="58231" url="https://en.wikipedia.org/wiki?curid=58231" title="Bacchylides">
Bacchylides

Bacchylides (; , "Bakkhylídēs"; century ) was a Greek lyric poet. Later Greeks included him in the canonical list of nine lyric poets which included his uncle Simonides. The elegance and polished style of his lyrics have been noted in Bacchylidean scholarship since at least Longinus. Some scholars, however, have characterized these qualities as superficial charm. He has often been compared unfavourably with his contemporary, Pindar, as "a kind of Boccherini to Pindar's Haydn", yet the differences in their styles doesn't allow for easy comparison and "to blame Bacchylides for not being Pindar is as childish a judgement as to condemn...Marvel for missing the grandeur of Milton." His career coincided with the ascendency of dramatic styles of poetry, as embodied in the works of Aeschylus or Sophocles, and he is in fact one of the last poets of major significance within the more ancient tradition of purely lyric poetry. The most notable features of his lyrics are their clarity in expression and simplicity of thought, making them an ideal introduction to the study of Greek lyric poetry in general and to Pindar's verse in particular.
Life.
This precept, from one of Bacchylides' extant fragments, was considered by his modern editor, Richard Claverhouse Jebb, to be typical of the poet's temperament: "If the utterances scattered throughout the poems warrant a conjecture, Bacchylides was of placid temper; amiably tolerant; satisfied with a modest lot; not free from some tinge of that pensive melancholy which was peculiarly Ionian; but with good sense..."
Bacchylides' lyrics do not seem to have been popular in his own lifetime. Lyrics by his uncle, Simonides, and his rival, Pindar, were known in Athens and were sung at parties, they were parodied by Aristophanes and quoted by Plato, but no trace of Bacchylides' work can be found until the Hellenistic age, when Callimachus began writing some commentaries on them. Like Simonides and Pindar, however, Bacchylides composed lyrics to appeal to the sophisticated tastes of a social elite and his patrons, though relatively few in number, covered a wide, geographical area around the Mediterranean, including for example Delos in The Aegean Sea, Thessaly to the north of mainland Greece and Sicily or Magna Graecia in the west. It has been inferred from the elegance and quiet charm of his lyrics that he only gradually acquired fame towards the end of his life.
Being drawn from sources compiled long after his death, the details of Bacchylides's life are sketchy and sometimes contradictory. According to Strabo, he was born in Ioulis, on the island of Ceos, and his mother was the sister of Simonides. According to Suda, his father's name was Meidon and his grandfather, also named Bacchylides, was a famous athlete, yet according to Etymologicum Magnum his father's name was Meidylus. There is an ancient tradition, upheld for example by Eustathius and Thomas Magister, that he was younger than Pindar and some modern scholars have endorsed it, such as Jebb, who assigns his birth to around 507 BC, whereas Bowra, for example, opted for a much earlier date, around 524–1 BC. Most modern scholars however treat Bacchylides as an exact contemporary of Pindar, placing his birth around 518 BC. According to one account, Bacchylides was banished for a time from his native Ceos and spent this period as an exile in Peloponnesus, where his genius ripened and he did the work which established his fame. Plutarch is the only ancient source for this account and yet it is considered credible on the basis of some literary evidence (Pindar wrote a paean celebrating Ceos, in which he says on behalf of the island "I am renowned for my athletic achievements among Greeks" 4, epode 1, a circumstance that suggests that Bacchylides himself was unavailable at the time.) Observations by Eusebius and Georgius Syncellus can be taken to indicate that Bacchylides might have been still alive at the outbreak of the Peloponnesian War, but modern scholars have differed widely in estimates of the year of his death – Jebb, for example sets it at 428 BC and yet a date around 451 BC is more favoured.
Ceos, where Bacchylides was born and raised, had long had a history of poetical and musical culture, especially in its association with Delos, the focal point of the Cyclades and the principal sanctuary of the Ionian race, where the people of Ceos annually sent choirs to celebrate festivals of Apollo. There was a thriving cult of Apollo on Ceos too, including a temple at Carthaea, a training ground for choruses where, according to Athenaeus, Bacchylides's uncle, Simonides, had been a teacher in his early years. Ceans had a strong sense of their national identity, characterized by their own exotic legends, national folklore and a successful tradition of athletic competition, especially in running and boxing – making the island a congenial home for a boy of quick imagination. Athletic victories achieved by Ceans in panhellenic festivals were recorded at Ioulis on slabs of stone and thus Bacchylides could readily announce, in an ode celebrating one such victory (Ode 2), a total of twenty-seven victories won by his countrymen at the Isthmian Games. Ceans had participated in the defeat of the Persians at the Battle of Salamis and they could take pride in the fact that an elegy composed by Bacchylides's uncle was chosen by Athens to commemorate the Athenians who fell at the Battle of Marathon. Being only thirteen miles from the Athenian cape Sunium, Ceos was in fact necessarily responsive to Athenian influences.
Bacchylides's career as a poet probably benefitted from the high reputation of his uncle, Simonides, whose patrons, when Bacchylides was born, already included Hipparchus (son of Peisistratos), brother of Hippias the tyrant of Athens (527–14 BC) and cultural coordinator of the city at that time. Simonides later introduced his nephew to ruling families in Thessaly and to the Sicilian tyrant, Hieron of Syracuse, whose glittering court attracted artists of the calibre of Pindar and Aeschylus. Bacchylides's first notable success came sometime after 500 BC with commissions from Athens for the great Delian festival (Ode 17) and from Macedonia for a song to be sung at a symposium for the young prince, Alexander I (fr. 20B). Soon he was competing with Pindar for commissions from the leading families of Aegina and, in 476 BC, their rivalry seems to have reached the highest levels when Bacchylides composed an ode celebrating Hieron's first victory at the Olympian Games (Ode 5). Pindar celebrated the same victory but used the occasion to advise the tyrant of the need for moderation in one's personal conduct (Pindar's Olympian Ode 1), whereas Bacchylides probably offered his own ode as a free sample of his skill in the hope of attracting future commissions. Bacchylides was commissioned by Hieron in 470 BC, this time to celebrate his triumph in the chariot race at the Pythian Games (Ode 4). Pindar also composed a celebratory ode for this victory (Pindar's Pythian Ode 1), including however stern, moral advice for the tyrant to rule wisely. Pindar was not commissioned to celebrate Hieron's subsequent victory in the chariot race at the Olympic Games in 468 BC – this, the most prestigious of Hieron's victories, was however celebrated by Bacchylides (Ode 3). The tyrant's apparent preference for Bacchylides over Pindar on this occasion might have been partly due to the Cean poet's simpler language and not just to his less moralizing posture, and yet it is also possible that Bacchylides and his uncle were simply better suited to palace politics than was their more high-minded rival. Alexandrian scholars in fact interpreted a number of passages in Pindar as hostile allusions to Bacchylides and Simonides and this interpretation has been endorsed by modern scholars also.
As a composer of choral lyrics, Bacchylides was probably responsible also for the performance, involving him in frequent travel to venues where musicians and choirs awaited instruction. Ancient authorities testify to his visit to the court of Hieron (478–467) and this is indeed indicated by his fifth Ode (476 BC), where the word "xenos" (V.11) implies that he had already been Hieron's guest, (probably accompanied by his uncle). Verses 15 and 16 of his third ode (468 BC), also for Hieron, indicate that he might have composed that work at Syracuse.
Work.
History.
The poems were collected into critical editions sometime in the late 3rd century BC by the Alexandrian scholar, Aristophanes of Byzantium, who probably restored them to their appropriate metres after finding them written in prose form. They were arranged in nine 'books', exemplifying the following genres (Bacchylides in fact composed in a greater variety of genres than any of the other lyric poets who comprise the canonic nine, with the exception of Pindar, who composed in ten):
The Alexandrian grammarian Didymus (circa 30 BC) wrote commentaries on the work of Bacchylides and the poems appear, from the finding of papyri fragments, to have been popular reading in the first three centuries AD. Their popularity seems to have continued into the 4th century also: Ammianus Marcellinus (xxv. 4) observed that the emperor Julian enjoyed reading Bacchylides, and the largest collection of quotations that survived up until the modern era was assembled by Stobaeus (early 5th century). All that remained of Bacchylides's poetry by 1896, however, were sixty-nine fragments, totalling 107 lines. These few remains of his writings were collected by Brunck, Bergk, Bland, Hartung, and Neue. The oldest sources on Bacchylides and his work are scholia on Homer, Hesiod, Pindar, Aristophanes, Apollonius Rhodius and Callimachus. Other fragments and 'notices' are sprinkled through the surviving works of ancient authors, which they used to illustrate various points they were making, as for example:
Fortunately for Bacchylidean scholarship, a papyrus came to light in Egypt at the end of the 19th century with a text of Greek uncials, which a local claimed to have found in a ransacked tomb, between the feet of a mummy. It was snapped up for a "preposterous" price by the great Egyptologist Wallis Budge, of the British Museum. Budge's plan to return to the museum with the papyrus was unacceptable to the British Consul and to the Egyptian Service of Antiquities so he resorted to desperate measures. In an elaborate plan involving a crate of oranges, switched trains and covert embarcations, he eventually sailed from the Suez with the papyrus dismembered and disguised as a packet of photographs. He presented his find in 1896 to Frederic Kenyon in the British Museum's Department of Manuscripts. Kenyon reassembled 1382 lines, of which 1070 were perfect or easily restored and, the following year, he published an edition of twenty poems, six of them nearly complete. Some more pieces of the Egyptian fragments were fitted together by Friedrich Blass in Germany and then followed the authoritative edition of Bacchylides' poetry by Richard Claverhouse Jebb – a combination of scholars that inspired one academic to comment: "we almost had the Renaissance back again".
As noted by Frederic Kenyon, the papyrus was originally a roll probably about seventeen feet long and about ten inches high, written in the Ptolemaic period, with some Roman characteristics that indicate a transition between styles, somewhere around 50 BC. It reached England in about two hundred torn fragments, the largest about twenty inches in length and containing four and a half columns of writing, the smallest being scraps with barely enough space for one or two letters. The beginning and end sections were missing and the damage done to the roll was not entirely the result of its recent discovery. Kenyon gradually pieced the fragments together, making three independent sections: the first, nine feet long with twenty-two columns of writing; the next section, a little over two feet long with six columns; the third, three and a half feet long with ten columns – a total length of almost fifteen feet and thirty-nine columns. Friedrich Blass later pieced together some of the still detached fragments and concluded that two of the poems on the restored roll (Odes vi. and vii., as numbered by Kenyon in the "editio princeps") must be parts of a single ode (for Lachon of Ceos) – hence even today the poems can be found numbered differently, with Jebb for example one of those following Blass's lead and numbering the poems differently from Kenyon from poem 8 onwards (Kenyon 9 = Jebb 8 and so on).
Bacchylides had become, almost overnight, among the best represented poets of the canonic nine, with about half as many extant verses as Pindar, adding about a hundred new words to Greek lexicons. Ironically, his newly discovered poems sparked a renewed interest in Pindar's work, with whom he was compared so unfavourably that "the students of Pindaric poetry almost succeeded in burying Bacchylides all over again."
Style.
Much of Bacchylides's poetry was commissioned by proud and ambitious aristocrats, a dominant force in Greek political and cultural life in the 6th and early part of the 5th centuries, yet such patrons were gradually losing influence in an increasingly democratic Greek world. The kind of lofty and stately poetry that celebrated the achievements of these archaic aristocrats was within the reach of 'The Cean nightingale', yet he seems to have been more at home in verses of a humbler and lighter strain, even venturing on folksiness and humour.
Lyric poetry was still a vigorous art-form and its genres were already fully developed when Bacchylides started out on his career. From the time of the Peloponnesian War, around the end of his life, the art-form was in decline, as exemplified by the inferior dithyrambs of Philoxenos of Cythera. Meanwhile, tragedy, as developed by Athenian dramatists of the calibre of Aeschylus and Sophocles, had begun to emerge as the leading poetic genre, borrowing the literary dialect, the metres and poetic devices of lyric poetry in general and the dithyramb in particular (Aristotle "Poetics" IV 1449a). The debt however was mutual and Bacchylides borrowed from tragedy for some of his effects – thus Ode 16, with its myth of Deianeira, seems to assume audience knowledge of Sophocles's play, "Women of Trachis", and Ode 18 echoes three plays – Aeschylus's "Persians" and "Suppliants" and Sophocles's "Oedipus Rex". His vocabulary shows the influence of Aeschylus with several words being common to both poets and found nowhere else. The use of gripping and exciting narrative and the immediacy gained from the frequent use of direct speech are thought to be among Bacchylides's best qualities, influencing later poets such as Horace (who imitated him, according to Pomponius Porphyrion, in "Carmen" I. 15, where Nereus predicts the destruction of Troy). These narrative qualities were modelled largely on the work of Stesichorus, whose lyrical treatment of heroic myth influenced, for instance, Ode 5. Whereas however Stesichorus developed graphic images in his poetry that subsequently became established in vase painting, Bacchylides merely employed images already current in his own day. 
Simonides, the uncle of Bacchylides, was another strong influence on his poetry, as for example in his metrical range, mostly dactylo-epitrite in form, with some Aeolic rhythms and a few iambics. The surviving poems in fact are not metrically difficult, with the exception of two odes (Odes XV and XVI, Jebb). He shared Simonides's approach to vocabulary, employing a very mild form of the traditional, literary Doric dialect, with some Aeolic words and some traditional epithets borrowed from epic. Like Simonides, he followed the lyric tradition of coining compound adjectives – a tradition in which the poet was expected to be both innovative and tasteful – but the results are thought by some modern scholars to be uneven. Many of his epithets however serve a thematic and not just a decorative function, as for instance in Ode 3, where the "bronze-walled court" and "well-built halls" of Croesus (Ode 3.30–31 and 3.46) contrast architecturally with the "wooden house" of his funeral pyre (Ode 3.49), in an effect that aims at pathos and which underscores the moral of the ode.
Bacchylides is renowned for his use of picturesque detail, giving life and colour to descriptions with small but skilful touches, often demonstrating a keen sense of beauty or splendour in external nature: a radiance, "as of fire," streams from the forms of the Nereids (XVI. 103 if. Jebb); an athlete shines out among his fellows like "the bright moon of the mid-month night" among the stars (VIII. 27 if.); the sudden gleam of hope which comes to the Trojans by the withdrawal of Achilles is like a ray of sunshine "from beneath the edge of a storm-cloud" (XII – 105 if.); the shades of the departed, as seen by Heracles on the banks of the Cocytus, resemble countless leaves fluttering in the wind on "the gleaming headlands of Ida" (V. 65 if ). Imagery is employed sparingly but often with impressive and beautiful results, such as in the simile of the eagle in Ode 5 below.
Ode 5.
Bacchylides has often been compared unflatteringly with Pindar, as for example by the French critic, Henri Weil: "There is no doubt that he fails of the elevation, and also of the depth, of Pindar. The soaring wing was refused him, and he should never have compared himself, as he does somewhere, to an eagle."
The image of the eagle occurs in Ode 5, which was composed for Hieron of Syracuse in celebration of his Olympic victory with the race-horse Pherenicus in 476 BC. Pindar's "Olympian Ode 1" celebrates the same race and the two poems allow for some interesting comparisons. Bacchylides's Ode 5 includes, in addition to a brief reference to the victory itself, a long mythical episode on a related theme, and a gnomic or philosophical reflection – elements that occur also in Pindar's ode and that seem typical of the victory ode genre. Whereas however Pindar's ode focuses on the myth of Pelops and Tantalus and demonstrates a stern moral about the need for moderation in personal conduct (a reflection on Hieron's political excesses), Bacchylides's ode focuses on the myths of Meleager and Hercules, demonstrating the moral that nobody is fortunate or happy in all things (possibly a reflection on Hieron's chronic illness). This difference in moral posturing was typical of the two poets, with Bacchylides adopting a quieter, simpler and less forceful manner than Pindar. Frederic G. Kenyon, who edited the papyrus poems, took an unsympathetic view of Bacchylides's treatment of myth in general:
Bacchylides however might be better understood as an heir to Stesichorus, being more concerned with story-telling per se, than as a rival of Pindar. But irrespective of any scruples about his treatment of myth, Bacchylides is thought to demonstrate in Ode 5 some of his finest work and the description of the eagle's flight, near the beginning of the poem, has been called by one modern scholar "the most impressive passage in his extant poetry."
Bacchylides's image of the poet as an eagle winging across the sea was not original – Pindar had already used it earlier ("Nemean Odes" 5.20–21). In fact, in the same year that both poets celebrated Pherenicus's Olympic victory, Pindar also composed an ode for Theron of Acragas ("Olympian" 2), in which he likens himself to an eagle confronted with chattering ravens – possibly a reference to Bacchylides and his uncle. It is possible in that case that Bacchylides's image of himself as an eagle in Ode 5 was a retort to Pindar. Moreover, Bacchylides's line "So now for me too countless paths extend in all directions" has a close resemblance to lines in one of Pindar's Isthmian Odes (1.1–2), "A thousand ways ... open on every side widespread before me" but, as the date of Pindar's Isthmian Ode is uncertain, it is not clear in this case who was imitating whom. According to Kenyon, Pindar's idionsyncratic genius entitles him to the benefit of a doubt in all such cases: "... if there be actual imitation at all, it is fairly safe to conclude that it is on the part of Bacchylides." In fact one modern scholar has observed in Bacchylides a general tendency towards imitation, sometimes approaching the level of quotation: in this case, the eagle simile in Ode 5 may be thought to imitate a passage in the Homeric Hymn to Demeter (375–83), and the countless leaves fluttering in the wind on "the gleaming headlands of Ida", mentioned later in the ode, recall a passage in "Iliad" (6.146–9). A tendency to imitate other poets is not peculiar to Bacchylides, however – it was common in ancient poetry, as for example in a poem by Alcaeus (fragment 347), which virtually quotes a passage from Hesiod ("Works and Days" 582–8).
Pindar's Olympian Ode 1 and Bacchylides's Ode 5 differ also in their description of the race – while Pindar's reference to Pherenicus is slight and general ("...speeding / by Alpheus' bank, / His lovely limbs ungoaded on the course...": "Olympian" I.20–21), Bacchylides describes the running of the winner more vividly and in rather more detail – a difference that is characteristic of the two poets:
Ultimately, however, Bacchylides and Pindar share many of the same goals and techniques – the difference is largely one of temperament:
Ode 13.
Ode 13 of the Bacchylides is a Nemean ode performed to honor the athlete Pytheas of Aegina for winning the pancration event of the Nemean games.
Bacchylides begins his ode with the tale of Heracles fighting the Nemean lion, employing the battle to explain why pancration tournaments are now held during the Nemean games. The allusion to Heracles’ fight with the lion is also meant to incite why it is that Pytheas fights for the wreaths of the games: to obtain the undying glory that the heroes of old now possess for their deeds. Bacchylides then sings the praises of Pytheas' home, the island Aegina, and how "her fame excites a dancer’s praise." Bacchylides continues this dancer allusion in praise of Aegina, and ends it by listing some famous men who were born on the island, namely Peleus and Telamon. 
Bacchylides then tells of the greatness of these men’s sons, Achilles and Ajax, alluding to a second myth, the tale of Ajax repelling Hector on the beaches of Troy, keeping the Trojans from burning the Greek ships. Bacchylides relates how Achilles’ inaction spurred the Trojans to false hope, and how their swollen pride led them to be destroyed at the hands of the men they thought they had vanquished. The ode plays upon the fact that those who are listening to Bacchylides have also read the epics of Homer, and understand the whole story behind this scene that would speak poorly of Achilles if people did not know the role he played in the Trojan war.
With this tale complete Bacchylides proclaims once again that the actions he has just told will be forever remembered thanks to the muses, leading once again into his praise of Pytheas and his trainer Menander, who shall be remembered for their great victories in the Pan-Hellenic games, even if an envious rival slights them.
Ode 15.
The Sons of Antenor, or Helen Demanded Back, is the first of Bacchylides’s dithyrambs in the text restored in 1896. The opening is incomplete, as part of the papyrus was damaged. The dithyramb treats a moment in myth before the Trojan war, when Menelaus, Antenor, and Antenor’s sons go to King Priam to demand the return of Helen. As is often the case with ancient Greek literature, Bacchylides plays of the audience’s knowledge of Homer without repeating a scene told by Homer. He instead describes a scene which is new to the audience, but which is given context by knowledge of the Iliad and Odyssey. The story of this embassy was known to Homer, who merely alludes to it at "Iliad" 3.205ff., but it was fully related in the cyclic epic poem "Cypria", according to the "Chrestomathy" of Proclus.
The style also plays off of Homer. Characters are almost always named with their fathers, i.e. Odysseus, son of Laertes (as reconstructed). They are also given epithets, though these are not the traditional Homeric epithets: godly Antenor, upright Justice, reckless Outrage.

</doc>
<doc id="58232" url="https://en.wikipedia.org/wiki?curid=58232" title="List of federal agencies in the United States">
List of federal agencies in the United States

This is a list of agencies of the United States federal government.
Legislative definitions of a federal agency are varied, and even contradictory, and the official United States Government Manual offers no definition. While the Administrative Procedure Act definition of "agency" applies to most executive branch agencies, Congress may define an agency however it chooses in enabling legislation, and subsequent litigation, often involving the Freedom of Information Act and the Government in the Sunshine Act. These further cloud attempts to enumerate a list of agencies.
The executive branch of the federal government includes the Executive Office of the President and the United States federal executive departments (whose secretaries belong to the Cabinet). Employees of the majority of these agencies are considered civil servants.
The majority of the independent agencies of the United States government are also classified as executive agencies (they are independent in that they are not subordinated under a Cabinet position). There are a small number of independent agencies that are not considered part of the executive branch, such as the Library of Congress and Congressional Budget Office, which are administered directly by Congress and thus are legislative branch agencies. The status of these agencies is an open question, however, as Judge Brett Kavanaugh noted in a brief concurrence in "SoundExchange, Inc. v. Librarian of Congress". There is one independent agency in the judicial branch, the United States Sentencing Commission.
Legislative branch.
Agencies within the legislative branch:
Judicial branch.
Agencies within the judicial branch:

</doc>
<doc id="58234" url="https://en.wikipedia.org/wiki?curid=58234" title="Baccio D'Agnolo">
Baccio D'Agnolo

Baccio D'Agnolo (19 May 1462 – 6 March 1543), born Bartolomeo Baglioni, was an Italian woodcarver, sculptor and architect from Florence.
Biography.
"Baccio" is an abbreviation of Bartolomeo, and "d'Agnolo" refers to Angelo, his father's name. He started as a wood-carver, and between 1491 and 1502 did much of the decorative carving in the church of Santa Maria Novella and the Palazzo Vecchio in Florence. Having made his reputation as a sculptor he appears to have turned his attention to architecture, and to have studied at Rome, though the precise date is uncertain; but at the beginning of the sixteenth century he was engaged with the architect Simone del Pollaiolo in restoring the Palazzo Vecchio, and in 1506 he was commissioned to complete the drum of the cupola of the church of Santa Maria del Fiore. The latter work, however, was interrupted on account of adverse criticisms from Michelangelo, and it remained unexecuted.
Baccio d'Agnolo also designed, among others, the Palazzo Borgherini-Rosselli del Turco and the Palazzo Bartolini Salimbeni. The Bartolini palace was the first house to be given frontispieces of columns to the door and windows, previously confined to churches; he was ridiculed by the Florentines for his innovation. Another much-admired work of his was the campanile of the church of Santo Spirito. His studio was the resort of the most celebrated artists of the day, Michelangelo, Andrea Sansovino, the brothers Antonio da Sangallo the Elder and Giuliano da Sangallo and the young Raphael. He died at Florence in 1543, leaving three sons, all architects, the best-known being Giuliano D'Agnolo.
Giorgio Vasari included Baccio in volume IV of his "Vite".

</doc>
<doc id="58235" url="https://en.wikipedia.org/wiki?curid=58235" title="United States Department of Transportation">
United States Department of Transportation

The United States Department of Transportation (USDOT or DOT) is a federal Cabinet department of the U.S. government concerned with transportation. It was established by an act of Congress on October 15, 1966, and began operation on April 1, 1967. It is governed by the United States Secretary of Transportation.
Its mission is to "Serve the United States by ensuring a fast, safe, efficient, accessible, and convenient transportation system that meets our vital national interests and enhances the quality of life of the American people, today and into the future."
History.
Prior to the Department of Transportation, the Under Secretary of Commerce for Transportation administered the functions now associated with the DOT. In 1965, Najeeb Halaby, administrator of the Federal Aviation Administration (FAA), suggested to President Lyndon B. Johnson that transportation be elevated to a cabinet-level post, and that the FAA be folded into the DOT.
Budget.
In 2010, the DOT awarded $742.5 million in funds from the American Recovery and Reinvestment Act to 11 transit projects. The awardees include light rail projects. Other projects include both a commuter rail extension and a subway project in New York City, and a bus rapid transit system in Springfield, Oregon. The funds subsidize a heavy rail project in northern Virginia, completing the Washington Metropolitan Area Transit Authority's Metro Silver Line to connect Washington, D.C., and the Washington Dulles International Airport. (DOT had previously agreed to subsidize the Silver Line construction to Reston, Virginia.)
President Barack Obama's budget request for fiscal year 2010 also included $1.83 billion in funding for major transit projects, of which more than $600 million went towards 10 new or expanding transit projects. The budget provided additional funding for all of the projects currently receiving Recovery Act funding, except for the bus rapid transit project. It also continued funding for another 18 transit projects that are either currently under construction or soon will be.
Following the same the Consolidated Appropriations Act of 2014 delegates $600 million for Infrastructure Investments, referred to as Discretionary Grants.
The Department of Transportation was authorized a budget for Fiscal Year 2014 of $77.2 billion. The budget authorization is broken down as follows:
Freedom of Information Act processing performance.
In the latest Center for Effective Government analysis of 15 federal agencies which receive the most Freedom of Information Act FOIA requests, published in 2015 (using 2012 and 2013 data, the most recent years available), the Department of Transportation earned a D by scoring 65 out of a possible 100 points, i.e. did not earn a satisfactory overall grade.

</doc>
<doc id="58236" url="https://en.wikipedia.org/wiki?curid=58236" title="United States Department of Homeland Security">
United States Department of Homeland Security

The United States Department of Homeland Security (DHS) is a cabinet department of the United States federal government, created in response to the September 11 attacks, and with the primary responsibilities of protecting the territory of the United States and protectorates from and responding to terrorist attacks, man-made accidents, and natural disasters. In fiscal year 2011 it was allocated a budget of $98.8 billion and spent, net, $66.4 billion.
Whereas the Department of Defense is charged with military actions abroad, the Department of Homeland Security works in the civilian sphere to protect the United States within, at, and outside its borders. Its stated goal is to prepare for, prevent, and respond to domestic emergencies, particularly terrorism. On March 1, 2003, DHS absorbed the Immigration and Naturalization Service and assumed its duties. In doing so, it divided the enforcement and services functions into two separate and new agencies: Immigration and Customs Enforcement and Citizenship and Immigration Services. The investigative divisions and intelligence gathering units of the Immigration and Naturalization Service (INS) and Customs Service were merged forming Homeland Security Investigations. Additionally, the border enforcement functions of the INS, including the U.S. Border Patrol, the U.S. Customs Service, and the Animal and Plant Health Inspection Service were consolidated into a new agency under DHS: U.S. Customs and Border Protection. The Federal Protective Service falls under the National Protection and Programs Directorate.
With more than 240,000 employees, DHS is the third largest Cabinet department, after the Departments of Defense and Veterans Affairs. Homeland security policy is coordinated at the White House by the Homeland Security Council. Other agencies with significant homeland security responsibilities include the Departments of Health and Human Services, Justice, and Energy.
The Department of Homeland Security has received substantial criticism over excessive bureaucracy, waste, fraud, ineffectiveness and lack of transparency. Its information sharing centers have been accused of violating American civil liberties and targeting American citizens as potential threats to national security.
__TOC__
Structure.
The Department of Homeland Security is headed by the Secretary of Homeland Security with the assistance of the Deputy Secretary. The Department contains the components listed below. Not all subcomponents are listed; see the linked articles for more details.
Agencies:
Advisory groups:
Other components:
Nomenclature.
In an August 5, 2002 speech, President Bush said: "We're fighting ... to secure freedom in the homeland." Prior to the creation of DHS, American presidents had referred to the U.S. as "the nation" or "the republic", and to its internal policies as "domestic". Also unprecedented was the use, from 2002, of the phrase "the homeland" by White House spokespeople.
Expenditures.
In the United States Federal Budget for 2010, entitled 'A New Era of Responsibility', the DHS was allocated a discretionary budget of $42.7 billion (financial year 2009: $40.1 billion). The end-of-year
DHS Annual Financial Report for financial year 2010 showed a net cost of operations of $56.4 billion (FY 2009, restated: $49.9 billion), out of total budgetary resources of $83.2 billion (FY 2009, restated: $85.2 billion). The components with the highest net cost were US Coast Guard ($12.1 billion), U.S. Customs and Border Protection ($11.6 billion), and Federal Emergency Management Agency ($10.5 billion). Revenues of $10.4 billion were generated in the year (FY 2009, restated: $9.8 billion).
According to the Homeland Security Research Corporation, the combined financial year 2010 state and local HLS markets, which employ more than 2.2 million first responders, totaled $16.5 billion, whereas the DHS HLS market totaled $13 billion. According to the "Washington Post", "DHS has given $31 billion in grants since 2003 to state and local governments for homeland security and to improve their ability to find and protect against terrorists, including $3.8 billion in 2010."
Audit of expenditures.
The DHS independent auditor is KPMG, one of the Big Four audit firms. Due to the level of material weaknesses identified, KPMG were unable to audit the DHS financial statements for FY 2010. KPMG were unable to express an audit opinion on the FY 2009, FY 2008, FY 2007, FY 2005, and FY 2003 financial statements. Attempts to access the reports for FY 2006 and FY 2004 within the 'information for citizens' portal met with a 404 error. The Message from the DHS Chief Financial Officer in the FY 2010 report states 'This Annual Financial Report (AFR) is our principal financial statement of accountability to the President, Congress and the American public. The AFR gives a comprehensive view of the Department's financial activities and demonstrates the Department's stewardship of taxpayer dollars.' The Message from the DHS Chief Financial Officer concludes 'I am extremely proud of the Department's accomplishments ... we will continue to build upon our successes.' The Secretary of Homeland Security endorsed this message saying that the DHS is 'continuing to be responsible stewards of taxpayer resources. The scope of our mission is broad, challenging, and vital to the security of the Nation ... Thank you for your partnership and collaboration. Yours very truly, Janet Napolitano.'
National Terrorism Advisory System.
In 2011 the Department of Homeland Security phased out the old Homeland Security Advisory System with a two-level National Terrorism Advisory System. The system has two types of advisories: Alerts and Bulletins. NTAS Bulletins permit the Secretary to communicate critical terrorism information that, while not necessarily indicative of a specific threat against the United States, can reach homeland security partners or the public quickly, thereby allowing recipients to implement necessary protective measures. Alerts are issued when there is specific and credible information of a terrorist threat against the United States. Alerts themselves have two levels: Elevated and Imminent. An Elevated Alert is issued when there is credible information about an attack by only general information about timing or a target. An Imminent Alert is issued when the threat is very specific and impending in the very near term.
On March 12, 2002, the Homeland Security Advisory System, a color-coded terrorism risk advisory scale, was created as the result of a Presidential Directive to provide a "comprehensive and effective means to disseminate information regarding the risk of terrorist acts to Federal, State, and local authorities and to the American people." Many procedures at government facilities are tied in to the alert level; for example a facility may search all entering vehicles when the alert is above a certain level. Since January 2003, it has been administered in coordination with DHS; it has also been the target of frequent jokes and ridicule on the part of the administration's detractors about its ineffectiveness. After resigning, Tom Ridge stated that he did not always agree with the threat level adjustments pushed by other government agencies.
In January 2003, the office was merged into the Department of Homeland Security and the White House Homeland Security Council, both of which were created by the Homeland Security Act of 2002. The Homeland Security Council, similar in nature to the National Security Council, retains a policy coordination and advisory role and is led by the Assistant to the President for Homeland Security.
As of 13 January 2011 the DHS advised the American public of an 'elevated national threat' level, recommending that all Americans 'should establish an emergency preparedness kit and emergency plan for themselves and their family, and stay informed about what to do during an emergency'.
Creation.
In response to the September 11 attacks, President George W. Bush announced the establishment of the Office of Homeland Security (OHS) to coordinate "homeland security" efforts. The office was headed by former Pennsylvania Governor Tom Ridge, who assumed the title of Assistant to the President for Homeland Security. The official announcement stated:
Ridge began his duties as OHS director on October 8, 2001.
The Department of Homeland Security was established on November 25, 2002, by the Homeland Security Act of 2002. It was intended to consolidate U.S. executive branch organizations related to "homeland security" into a single Cabinet agency. The following 22 agencies were incorporated into the new department:
According to Peter Andreas, a border theorist, the creation of DHS constituted the most significant government reorganization since the Cold War, and the most substantial reorganization of federal agencies since the National Security Act of 1947, which placed the different military departments under a secretary of defense and created the National Security Council and Central Intelligence Agency. DHS also constitutes the most diverse merger of federal functions and responsibilities, incorporating 22 government agencies into a single organization.
Prior to the signing of the bill, controversy about its adoption centered on whether the Federal Bureau of Investigation and the Central Intelligence Agency should be incorporated in part or in whole (neither were included). The bill itself was also controversial for the presence of unrelated "riders", as well as for eliminating certain union-friendly civil service and labor protections for department employees. Without these protections, employees could be expeditiously reassigned or dismissed on grounds of security, incompetence or insubordination, and DHS would not be required to notify their union representatives.
The plan stripped 180,000 government employees of their union rights. In 2002, Bush officials argued that the September 11 attacks made the proposed elimination of employee protections imperative.
Congress ultimately passed the Homeland Security Act of 2002 without the union-friendly measures, and President Bush signed the bill into law on November 25, 2002. It was the largest U.S. government reorganization in the 50 years since the United States Department of Defense was created.
Tom Ridge was named secretary on January 24, 2003 and began naming his chief deputies. DHS officially began operations on January 24, 2003, but most of the department's component agencies were not transferred into the new Department until March 1.
After establishing the basic structure of DHS and working to integrate its components and get the department functioning, Ridge announced his resignation on November 30, 2004, following the re-election of President Bush. Bush initially nominated former New York City Police Department commissioner Bernard Kerik as his successor, but on December 10, Kerik withdrew his nomination, citing personal reasons and saying it "would not be in the best interests" of the country for him to pursue the post. On January 11, 2005, President Bush nominated federal judge Michael Chertoff to succeed Ridge. Chertoff was confirmed on February 15, 2005, by a vote of 98–0 in the U.S. Senate. He was sworn in the same day.
In February 2005, DHS and the Office of Personnel Management issued rules relating to employee pay and discipline for a new personnel system named MaxHR. "The Washington Post" said that the rules would allow DHS "to override any provision in a union contract by issuing a department-wide directive" and would make it "difficult, if not impossible, for unions to negotiate over arrangements for staffing, deployments, technology and other workplace matters."
In August 2005, U.S. District Judge Rosemary M. Collyer blocked the plan on the grounds that it did not ensure collective-bargaining rights for DHS employees.
A federal appeals court ruled against DHS in 2006; pending a final resolution to the litigation, Congress's fiscal year 2008 appropriations bill for DHS provided no funding for the proposed new personnel system.
DHS announced in early 2007 that it was retooling its pay and performance system and retiring the name "MaxHR".
In a February 2008 court filing, DHS said that it would no longer pursue the new rules, and that it would abide by the existing civil service labor-management procedures. A federal court issued an order closing the case.
Seal.
A DHS press release dated June 6, 2003 explains the seal as follows:
The seal was developed with input from senior DHS leadership, employees, and the U.S. Commission on Fine Arts. The Ad Council – which partners with DHS on its Ready.gov campaign – and the consulting company Landor Associates were responsible for graphic design and maintaining heraldic integrity.
Headquarters.
Since its inception, the department has had its temporary headquarters in Washington, D.C.'s Nebraska Avenue Complex, a former naval facility. The site, across from American University, has 32 buildings comprising of administrative space. In early 2007, the Department submitted a $4.1 billion plan to Congress to consolidate its 60-plus Washington-area offices into a single headquarters complex at the St. Elizabeths Hospital campus in Anacostia, Southeast Washington, D.C. The earliest DHS would begin moving to St. Elizabeths is 2012.
The move is being championed by District of Columbia officials because of the positive economic impact it will have on historically depressed Anacostia. The move has been criticized by historic preservationists, who claim the revitalization plans will destroy dozens of historic buildings on the campus. Community activists have criticized the plans because the facility will remain walled off and have little interaction with the surrounding area.
On January 8, 2009, the National Capital Planning Commission approved the Department of Homeland Security's plans to move into the campus of St. Elizabeths Hospital.
In February 2015 the General Services Administration said that the site would open in 2021.
History.
Ready.gov.
Soon after the formation of Department of Homeland Security, the Martin Agency of Richmond, Virginia worked pro bono to create "Ready.gov", a readiness website. The site and materials were conceived in March 2002 and launched in February 2003, just before the launch of the Iraq War. One of the first announcements that garnered widespread public attention to this campaign was one by Tom Ridge in which he stated that in the case of a chemical attack, citizens should use duct tape and plastic sheeting to build a homemade bunker, or "sheltering in place" to protect themselves. As a result, the sales of duct tape skyrocketed and DHS was criticized for being too alarmist.
The site was promoted with banner ads containing automatic audio components on commercial web sites.
National Incident Management System.
On March 1, 2004, the National Incident Management System (NIMS) was created. The stated purpose was to provide a consistent incident management approach for federal, state, local, and tribal governments. Under Homeland Security Presidential Directive-5, all federal departments were required to adopt the NIMS and to use it in their individual domestic incident management and emergency prevention, preparedness, response, recovery, and mitigation program and activities.
National Response Framework.
In December 2004, the National Response Plan (NRP) was created, in an attempt to align federal coordination structures, capabilities, and resources into a unified, all-discipline, and all-hazards approach to domestic incident management. The NRP was built on the template of the NIMS.
On January 22, 2008, the National Response Framework was published in the Federal Register as an updated replacement of the NRP, effective March 22, 2008.
Surge Capacity Force.
The Post-Katrina Emergency Management Reform Act directs the DHS Secretary to designate employees from throughout the Department to staff a Surge Capacity Force (SCF). During a declared disaster, the DHS Secretary will determine if SCF support is necessary. The Secretary will then authorize FEMA to task and deploy designated personnel from DHS components and other Federal Executive Agencies to respond to extraordinary disasters.
Cyber-security.
The DHS National Cyber Security Division (NCSD) is responsible for the response system, risk management program, and requirements for cyber-security in the U.S. The division is home to US-CERT operations and the National Cyber Alert System. The DHS Science and Technology Directorate helps government and private end-users transition to new cyber-security capabilities. This directorate also funds the Cyber Security Research and Development Center, which identifies and prioritizes research and development for NCSD. The center works on the Internet's routing infrastructure (the SPRI program) and Domain Name System (DNSSEC), identity theft and other online criminal activity (ITTC), Internet traffic and networks research (PREDICT datasets and the DETER testbed), Department of Defense and HSARPA exercises (Livewire and Determined Promise), and wireless security in cooperation with Canada.
On October 30, 2009, DHS opened the National Cybersecurity and Communications Integration Center. The center brings together government organizations responsible for protecting computer networks and networked infrastructure.
Criticism.
Excess, waste, and ineffectiveness.
The Department of Homeland Security has been dogged by persistent criticism over excessive bureaucracy, waste, ineffectiveness and lack of transparency. Congress estimates that the department has wasted roughly $15 billion in failed contracts (). In 2003, the department came under fire after the media revealed that Laura Callahan, Deputy Chief Information Officer at DHS with responsibilities for sensitive national security databases, had obtained her bachelor, masters, and doctorate computer science degrees through Hamilton University, a diploma mill in a small town in Wyoming. The department was blamed for up to $2 billion of waste and fraud after audits by the Government Accountability Office revealed widespread misuse of government credit cards by DHS employees, with purchases including beer brewing kits, $70,000 of plastic dog booties that were later deemed unusable, boats purchased at double the retail price (many of which later could not be found), and iPods ostensibly for use in "data storage".
A 2015 inspection of IT infrastructure found that the department was running over a hundred computer systems whose owners were unknown, including Secret and Top Secret databases, many with out of date security or weak passwords. Basic security reviews were absent, and the department had apparently made deliberate attempts to delay publication of information about the flaws.
Data mining (ADVISE).
The Associated Press reported on September 5, 2007, that DHS had scrapped an anti-terrorism data mining tool called ADVISE (Analysis, Dissemination, Visualization, Insight and Semantic Enhancement) after the agency's internal Inspector General found that pilot testing of the system had been performed using data on real people without required privacy safeguards in place. The system, in development at Lawrence Livermore and Pacific Northwest National Laboratory since 2003, has cost the agency $42 million to date. Controversy over the program is not new; in March 2007, the Government Accountability Office stated that "the ADVISE tool could misidentify or erroneously associate an individual with undesirable activity such as fraud, crime or terrorism." Homeland Security's Inspector General later said that ADVISE was poorly planned, time-consuming for analysts to use, and lacked adequate justifications.
Fusion centers.
Fusion centers are terrorism prevention and response centers, many of which were created under a joint project between the Department of Homeland Security and the US Department of Justice's Office of Justice Programs between 2003 and 2007. The fusion centers gather information not only from government sources, but also from their partners in the private sector.
They are designed to promote information sharing at the federal level between agencies such as the Central Intelligence Agency (CIA), Federal Bureau of Investigation (FBI), Department of Justice, US Military and state and local level government. , the Department of Homeland Security recognized at least seventy-two fusion centers. Fusion centers may also be affiliated with an Emergency Operations Center that responds in the event of a disaster.
There are a number of documented criticisms of fusion centers, including relative ineffectiveness at counterterrorism activities, the potential to be used for secondary purposes unrelated to counterterrorism, and their links to violations of civil liberties of American citizens and others.
David Rittgers of the Cato Institute has noted:
a long line of fusion center and DHS reports labeling broad swaths of the public as a threat to national security. The North Texas Fusion System labeled Muslim lobbyists as a potential threat; a DHS analyst in Wisconsin thought both pro- and anti-abortion activists were worrisome; a Pennsylvania homeland security contractor watched environmental activists, Tea Party groups, and a Second Amendment rally; the Maryland State Police put anti-death penalty and anti-war activists in a federal terrorism database; a fusion center in Missouri thought that all third-party voters and Ron Paul supporters were a threat...
MIAC report.
The Missouri Information Analysis Center (MIAC) made news in 2009 for targeting supporters of third party candidates (such as Ron Paul), pro-life activists, and conspiracy theorists as potential militia members. Anti-war activists and Islamic lobby groups were targeted in Texas, drawing criticism from the American Civil Liberties Union.
According to the Department of Homeland Security:
The Privacy Office has identified a number of risks to privacy presented by the fusion center program:
2009 Virginia terrorism threat assessment.
In early April 2009, the Virginia Fusion Center came under criticism for publishing a terrorism threat assessment which stated that certain universities are potential hubs for terror related activity. The report targeted historically black colleges and identified hacktivism as a form of terrorism.
Mail interception.
In 2006, MSNBC reported that Grant Goodman, "an 81-year-old retired University of Kansas history professor, received a letter from his friend in the Philippines that had been opened and resealed with a strip of dark green tape bearing the words "by Border Protection" and carrying the official Homeland Security seal." The letter was sent by a devout Catholic Filipino woman with no history of supporting Islamic terrorism. A spokesman for U.S. Customs and Border Protection "acknowledged that the agency can, will and does open mail coming to U.S. citizens that originates from a foreign country whenever it's deemed necessary":
"All mail originating outside the United States Customs territory that is to be delivered inside the U.S. Customs territory is subject to Customs examination," says the CBP Web site. That includes personal correspondence. "All mail means 'all mail,'" said John Mohan, a CBP spokesman, emphasizing the point.
The Department declined to outline what criteria are used to determine when a piece of personal correspondence should be opened or to say how often or in what volume Customs might be opening mail.
Goodman's story provoked outrage in the blogosphere, as well as in the more established media. Reacting to the incident, "Mother Jones" remarked that "other prying government agencies, Homeland Security wants you to know it is watching you." CNN observed that "the heels of the NSA wiretapping controversy, Goodman's letter raises more concern over the balance between privacy and security."
Employee morale.
In July 2006, the Office of Personnel Management conducted a survey of federal employees in all 36 federal agencies on job satisfaction and how they felt their respective agency was headed. DHS was last or near to last in every category including;
The low scores were attributed to major concerns about basic supervision, management and leadership within the agency. Examples from the survey reveal most concerns are about promotion and pay increase based on merit, dealing with poor performance, rewarding creativity and innovation, leadership generating high levels of motivation in the workforce, recognition for doing a good job, lack of satisfaction with various component policies and procedures and lack of information about what is going on with the organization.
DHS is the only large federal agency to score below 50% in overall survey rankings. It was dead last of large federal agencies in 2014 with 44.0% and fell even lower in 2015 at 43.1%, again last place.
Freedom of Information Act processing performance.
In the latest Center for Effective Government analysis of 15 federal agencies which receive the most Freedom of Information Act FOIA requests, published in 2015 (using 2012 and 2013 data, the most recent years available), the Department of Homeland Security earned a D by scoring 69 out of a possible 100 points, i.e. did not earn a satisfactory overall grade. It also had not updated its regulations since the 2007 FOIA amendments.

</doc>
<doc id="58237" url="https://en.wikipedia.org/wiki?curid=58237" title="Carl Philipp Emanuel Bach">
Carl Philipp Emanuel Bach

Carl Philipp Emanuel Bach (8 March 1714 – 14 December 1788), also formerly spelled Karl Philipp Emmanuel Bach, was a German Classical period musician and composer, the fifth child and second (surviving) son of Johann Sebastian Bach and Maria Barbara Bach. His second name was given in honor of his godfather Georg Philipp Telemann, a friend of Johann Sebastian Bach.
C. P. E. Bach was an influential composer working at a time of transition between his father's baroque style and the classical and romantic styles that followed it. His personal approach, an expressive and often turbulent one known as "" or 'sensitive style', applied the principles of rhetoric and drama to musical structures. Bach's dynamism stands in deliberate contrast to the more mannered galant style also then in vogue.
He was known as the "Berlin Bach" or the "Hamburg Bach".
Life.
Early years: 1714–38.
C. P. E. Bach was born on 8 March 1714 in Weimar to Johann Sebastian Bach and his first wife, Maria Barbara. He was the composer's third son. The composer Georg Philipp Telemann was his godfather. When he was ten years old, he entered the St. Thomas School at Leipzig, where his father had become cantor in 1723. He was one of four Bach children to become professional musicians; all four were trained in music almost entirely by their father. In an age of royal patronage, father and son alike knew that a university education helped prevent a professional musician from being treated as a servant. Carl, like his brothers, pursued advanced studies in jurisprudence at the University of Leipzig in 1731 and at Frankfurt-on-the-Oder in 1735. In 1738, at the age of 24, he obtained his degree but never practiced law, instead turning his attention immediately to music.
Berlin years: 1738–68.
A few months after graduation Bach, armed with a recommendation by Sylvius Leopold Weiss, obtained an appointment at Berlin in the service of Crown Prince Frederick of Prussia, the future Frederick the Great. Upon Frederick's accession in 1740, Bach became a member of the royal orchestra. He was by this time one of the foremost clavier players in Europe, and his compositions, which date from 1731, include about thirty sonatas and concert pieces for harpsichord and clavichord. During his time there, Berlin was a rich artistic environment, where Bach mixed with many accomplished musicians, including several notable former students of his father, and important literary figures, such as Gotthold Ephraim Lessing, with whom the composer would become close friends.
In Berlin, Bach continued to write numerous pieces for solo keyboard, including a series of character pieces, the so-called "Berlin Portraits", including "La Caroline". His reputation was established by the two sets of sonatas which he published with dedications to Frederick the Great (1742) and to Charles Eugene, Duke of Württemberg (1744). In 1746, he was promoted to the post of chamber musician ("") and served the king alongside colleagues like Carl Heinrich Graun, Johann Joachim Quantz, and Franz Benda.
The composer who most influenced Bach's maturing style was unquestionably his father. He drew creative inspiration from his godfather Georg Philipp Telemann, then working in Hamburg, and from contemporaries like George Frideric Handel, Carl Heinrich Graun and Joseph Haydn. Bach's interest in all types of art led to influence from poets, playwrights and philosophers such as Friedrich Gottlieb Klopstock, Moses Mendelssohn and Gotthold Ephraim Lessing. Bach's work itself influenced the work of, among others, Haydn, Mozart, Beethoven and Felix Mendelssohn.
During his residence in Berlin, Bach composed a setting of the "Magnificat" (1749), in which he shows more traces than usual of his father's influence; an Easter cantata (1756); several symphonies and concert works; at least three volumes of songs, including the celebrated "Gellert Songs"; and a few secular cantatas and other occasional pieces. But his main work was concentrated on the clavier, for which he composed, at this time, nearly two hundred sonatas and other solos, including the set "" ("With Changed Reprises", 1760–1768).
While in Berlin, Bach placed himself in the forefront of European music with a treatise, "" ("An Essay on the True Art of Playing Keyboard Instruments"), immediately recognised as a definitive work on keyboard technique. "Both Haydn and Beethoven swore by it." By 1780, the book was in its third edition and laid the foundation for the keyboard methods of Clementi and Cramer. The essay lays out the fingering for each chord and some chord sequences. Bach's techniques continue to be employed today. The first part of the "Essay" contains a chapter explaining the various embellishments in work of the period, e.g., trills, turns, mordents, etc. The second part presents Bach's ideas on the art of figured bass and counterpoint, where he gives preference to the contrapuntal approach to harmonization over the newer ideas of Rameau's theory of harmony and root progressions.
Hamburg: 1768–88.
In 1768, after protracted negotiations, Bach was permitted to relinquish his position in order to succeed his godfather Telemann as director of music ("") at Hamburg. Upon his release from service at the court he was named court composer for Frederick's sister, Princess Anna Amalia. The title was honorary, but her patronage and interest in the oratorio genre may have played a role in nurturing the ambitious choral works that followed.
Bach began to turn more of his energies to ecclesiastical and choral music in his new position. The job required the steady production of music for Protestant church services at the Michaeliskirche (Church of St. Michael) and elsewhere in Hamburg. The following year he produced his most ambitious work, the oratorio "Die Israeliten in der Wüste" ("The Israelites in the Desert"), a composition remarkable not only for its great beauty but for the resemblance of its plan to that of Felix Mendelssohn's "Elijah". Between 1768 and 1788, he wrote twenty-one settings of the Passion, and some seventy cantatas, litanies, motets, and other liturgical pieces. In Hamburg he also presented a number of works by contemporaries, including his father, Telemann, Graun, Handel, Haydn, Salieri and Johann David Holland (1746–1827). Bach's choral output reached its apex in two works: the double chorus "Heilig" ("Holy") of 1776, a setting of the seraph song from the throne scene in Isaiah, and the grand cantata "Die Auferstehung Jesu" ("The Resurrection of Jesus") of 1774–82, which sets a poetic Gospel harmonization by the poet Karl Wilhelm Ramler. Widespread admiration of "Auferstehung" led to three 1788 performances in Vienna sponsored by the Baron Gottfried van Swieten and conducted by Mozart.
Bach married Johanna Maria Dannemann in 1744. Only three of their children lived to adulthood: Johann Adam (1745–89), Anna Carolina Philippina (1747–1804), and Johann Sebastian "the Younger" (1748–78). None became musicians and Johann Sebastian, a promising painter, died in his late twenties during a 1778 trip to Italy. Emanuel Bach died in Hamburg on 14 December 1788. He was buried in the in Hamburg.
Works.
Symphonies.
Among Bach's most popular and recorded works are his symphonies. While in Berlin, he wrote several string symphonies, most of which were later revised to add parts for wind instruments. Of these, the E minor symphony, Wq. 178, has been particularly popular.
In Hamburg, Bach wrote a major set of six string symphonies for Gottfried van Swieten, Wq. 182. These works were not published in his lifetime (van Swieten, who had commissioned them to be written in a more "difficult" style, preferred to retain them for private use,) but since their rediscovery, have become increasingly popular.
However, Bach's masterpieces in the form (by his own estimation) are assuredly the four "Orchester-Sinfonien mit zwölf obligaten Stimmen", Wq. 183, which, as their title suggests, were written with obbligato wind parts that are integral to the texture, rather than being added on to an older string symphony. The first symphony (D major) in the set has been particularly popular, seeing a continuous performance and publication tradition all the way through the 19th century, which makes it the earliest such symphony. Some of its more unusual features have been taken as characteristic of Bach's style: the work, although it is in D major, begins "on" a D major chord, which then turns into a D dominant-seventh chord, outlining "G" major. In fact, there is no cadence on D major (D major is not "confirmed" as the key of the piece) until the beginning of the recapitulation, quite late in the piece.
Concertos.
Bach was a prolific writer of concertos, especially for keyboard. Like his father, he would often transcribe a concerto for various instruments, leading to problems determining which came first. For instance, the three cello concertos (Wq. 170–172), which are cornerstones of that instrument's repertoire, have often been considered to be transcriptions of the harpsichord versions, but recent research has suggested that they might be originally for cello.
Bach's greatest keyboard concertos (by his own estimation) were the "Sei concerti per il cembalo concertato", Wq. 43, which were written to be somewhat more appealing, and somewhat easier to play. His other concertos were written for oboe, flute, and organ. Bach also wrote for more unusual combinations, including an E-flat major concerto for harpsichord piano. Additionally, he wrote several sonatinas for one or more keyboards and orchestra.
Chamber music.
Bach's chamber music forms something of a bridge between stereotypically Baroque and Classical forms. On the one hand, he wrote trio sonatas and solo sonatas with basso continuo (including ones for harp and viola da gamba); on the other, he wrote several accompanied sonatas for piano, violin, and cello, which are more or less early piano trios, and three very popular quartets for keyboard, flute, and viola. Bach also wrote one of the earliest pieces for solo flute, a sonata that is clearly influenced by his father's Partita in A minor for solo flute, BWV 1013.
Keyboard sonatas.
Bach was a prolific writer of keyboard sonatas, many of which were intended for his favored instrument, the clavichord. During his lifetime, he published more collections of keyboard music than anything else, in the following collections:
Much of Bach's energy during his last years was dedicated to the publication of the "Kenner und Liebhaber" collections (which also include fantasias and rondos, see below).
Other keyboard works.
Easily Bach's best-known piece is the "Solfeggietto", Wq. 117/2, to the point that the introduction to "The Essential C.P.E. Bach" is subtitled "Beyond the Solfeggio in C Minor". Several of Bach's other miscellaneous keyboard works have gained fame, including the character piece "La Caroline" and the Fantasia in F-sharp minor, Wq. 67. Bach's fantasias, in particular, have been considered to show him at his most characteristic: they are full of dramatic silences, harmonic surprises, and perpetually varied figuration.
Bach published three major collections of miscellaneous keyboard works during his lifetime: the "Clavierstücke verschiedener Art", Wq. 112 of 1765, and the "Kurze und Leichte Clavierstücke" collections, Wq. 113–14 of 1766. The former includes songs, fantasias, dances, sonatas, fugues, and even a symphony and concerto for solo piano (Bach was later to publish an entire collection of keyboard versions of his symphonies).
Bach also wrote a set of six organ sonatas for the organ of Frederick the Great's sister Wilhelmina.
Music for mechanical instruments.
Mechanical instruments such as the music box and musical clock were popular at the Prussian court, and C.P.E. Bach wrote thirty original compositions for these instruments, grouped together as Wq. 193. At that time, Bach was court musician to King Frederick the Great at Potsdam; the King, who was intrigued by mechanically reproduced music, had mechanical organ clocks built for the City Castle of Potsdam and for the New Palais.
Choral works.
Throughout his lifetime, Bach worked on the "Magnificat in D", Wq. 215. J.S. Bach was alive to hear it in 1749, and C.P.E. continued to revise and perform it as late as 1786. The work clearly shows the influence of J.S. Bach's own Magnificat, including the striking resemblance of the "Deposuit" movements in both works.
His other important choral works include the "Heilig" (German Sanctus), Wq. 217, which he performed together with the "Credo" from his Father's Mass in B minor, the oratorios "Die Israeliten in der Wüste", Wq. 238 and "Die Auferstehung und Himmelfahrt Jesu", Wq. 240, and 21 passions.
Legacy and musical style.
Through the later half of the 18th century, the reputation of Carl Philipp Emanuel Bach stood very high, surpassing that of his father. Haydn and Beethoven admired him and "avidly" collected his music. Mozart said of him, "Bach is the father, we are the children." 
The content of his work is full of invention and, most importantly, extreme unpredictability, and wide emotional range even within a single work, a style that may be categorized as "empfindsamer Stil". It is no less sincere in thought than polished and felicitous in phrase. His keyboard sonatas, for example, mark an important epoch in the history of musical form. Lucid in style, delicate and tender in expression, they are even more notable for the freedom and variety of their structural design; they break away altogether from both the Italian and the Viennese schools, moving instead toward the cyclical and improvisatory forms that would become common several generations later.
He was probably the first composer of eminence who made free use of harmonic color for its own sake. In this way, he compares well with the most important representatives of the First Viennese School. In fact, he exerted enormous influence on the North German School of composers, in particular Georg Anton Benda, Bernhard Joachim Hagen, Ernst Wilhelm Wolf, Johann Gottfried Müthel, and Friedrich Wilhelm Rust. His influence was not limited to his contemporaries and extended to Felix Mendelssohn and Carl Maria von Weber.
His name fell into neglect during the 19th century, with Robert Schumann notoriously opining that "as a creative musician he remained very far behind his father"; others opined that he was "a somewhat feeble imitator of his father's style". All the same, Johannes Brahms held him in high regard and edited some of his music. By the early 20th century, he was better regarded but the revival of C. P. E. Bach's works has been chiefly underway since Helmuth Koch's recordings of his symphonies and Hugo Ruf's recordings of his keyboard sonatas in the 1960s. There is an ongoing project to record his complete works, led by on the Swedish record label BIS. In 2014, the Croatian pianist , in cooperation with the Packard Humanities Institute, the Bach-Archiv Leipzig, the Sächsische Akademie der Wissenschaften zu Leipzig and Harvard University released a 26-CD box set of the complete works for solo piano on the German record label Hänssler Classic, performed on a modern Bösendorfer grand piano.
The works of C. P. E. Bach are known by "Wq" numbers, from Alfred Wotquenne's 1906 catalogue, and by "H" numbers from a catalogue by Eugene Helm (1989).
He was portrayed by Wolfgang Liebeneiner in the 1941 biopic of his brother "Friedemann Bach".
Anniversary year 2014.
2014 marked the 300th anniversary of Carl Philipp Emanuel Bach. All six German Bach cities—Hamburg, Potsdam, Berlin, Frankfurt-on-the-Oder, Leipzig, and Weimar—hosted concerts and other events to commemorate the anniversary.

</doc>
<doc id="58238" url="https://en.wikipedia.org/wiki?curid=58238" title="Yair Bacharach">
Yair Bacharach

Yair Chayim Bacharach (1639, Lipník nad Bečvou, Moravia — 1702) was a German rabbi and major 17th century posek, who lived first in Koblenz and then remainder of his life in Worms and Metz. His grandmother Eva Bacharach was a granddaughter of the Maharal of Prague, and his father Moses Samson Bacharach, and grandfather had served as rabbis of Metz.
He was the author of "Havvot Yair" ("Villages of Yair") a collection of responsa by the title of which is he commonly referred (first published in Frankfurt a Main, 1699); its title is a reference to his grandmother Chava as well as to a place mentioned in Numbers 32:41 and elsewhere in the Jewish Bible. Other work includes his "Mekor Chayim", which was intended as a principal commentary to "Shulkhan Arukh" but was withdrawn by Bacharach when he discovered that other commentaries, notably the Taz and the Magen Avraham, had appeared. It is still regarded a prime source of material concerning "minhagim" (customs) of the area and epoch.
Besides his Halakhic expertise he had complete mastery of all the sciences, music, history and wrote poetry. He compiled a 46 volume encyclopedia on many topics.
In 1689 the Worms community was decimated by the French during the Nine Years' War. Gradually, it was rebuilt. In 1699 he was appointed rabbi of Worms where his father and grandfather had served before him. He served for only three years until his death in 1702. The inscription on his tombstone begins with the words, “A great and dark horror befalls us from the hiding of the light of Rabbeinu...”
In 1982 his major work, "Mekor Chaim", was finally published posthumously by Machon Yerushalayim.

</doc>
<doc id="58240" url="https://en.wikipedia.org/wiki?curid=58240" title="Department of transportation">
Department of transportation

The Department of Transportation (DOT) is the most common name for a government agency in North America devoted to transportation. The largest is the United States Department of Transportation, which oversees interstate travel and is a federal agency. All U.S. states, Canadian provinces, and many local agencies also have similar organizations and provide enforcement through DOT officers within their respective jurisdictions.

</doc>
<doc id="58241" url="https://en.wikipedia.org/wiki?curid=58241" title="Bacharach">
Bacharach

Bacharach (, also known as "Bacharach am Rhein") is a town in the Mainz-Bingen district in Rhineland-Palatinate, Germany. It belongs to the "Verbandsgemeinde" of Rhein-Nahe, whose seat is in Bingen am Rhein, although that town is not within its bounds.
The original name "Baccaracus" points to Celtic beginnings. Above the town lolwlepdoms Stahleck Castle ("Burg Stahleck"), nowadays a youth hostel.
Geography.
Location.
The town lies in the Rhine Gorge, 48 km south of Koblenz.
Constituent communities.
Bacharach is divided into several "Ortsteile". The outlying centre of Steeg lies in the Steeg Valley ("Steeger Tal") off to the side, away from the Rhine. This glen lies between Medenscheid and Neurath to the south and Henschhausen to the north on the heights.
History.
In the early 11th century, Bacharach had its first documentary mention. It may have been that as early as the 7th century, the kingly domain passed into Archbishop of Cologne Kunibert’s ownership; pointing to this is a "Kunibertskapelle" (chapel) on the spot where now stands the "Wernerkapelle". The "Vögte" of the Cologne estate were the Elector of the Palatinate, who over time pushed back Cologne’s influence. Count Palatine already had so much influence that he resided at Stahleck Castle. His successor Konrad von Staufen’s daughter secretly wed at Stahleck Castle a son of the Welfs, who were family foes, leading to Bacharach’s, and indeed the whole County Palatine’s, falling for a short time to Henry of Brunswick. In 1214 the Wittelsbachs became Bacharach’s new lords. Together with the "Unteramt" of Kaub they received here their most important toll and revenue source. In 1314 it was decided to choose Louis the Bavarian as the German king. Furthermore, Bacharach was the most important transfer point for the wine trade, as barrels were offloaded here from the smaller ships that were needed to get by the "Binger Loch" (a quartzite reef in the Rhine upstream near Bingen) and loaded onto bigger ones. From then on, the wine bore the designation "Bacharacher". The timber trade from the Hunsrück also brought Bacharach importance, and in 1356, Bacharach was granted town rights.
Widely visible is the "Wernerkapelle", a "Rheinromantik" landmark of the town, lying on the way up to Stahleck Castle from the town. It is the expanded "Kunibertkapelle", and is still an unfinished Gothic ruin today. Its namesake is Werner of Oberwesel, known in connection with pogroms triggered by his death. According to the Christian blood libel, which was typical of the times, a 16-year-old Werner was murdered on Maundy Thursday 1287 by members of the local Jewish community, who then used his blood for Passover observances. On the grounds of this alleged ritual murder, there arose an anti-Semitic mob who waged a pogrom, wiping out Jewish communities in the Middle and Lower Rhine and Moselle regions. In folk Christianity arose the cult of Werner, which was only stricken from the Bishopric of Trier calendar in 1963.
In 1344, building work began on the town wall, and was already finished about 1400. In 1545, the town, along with the Palatinate, became Protestant under Count Palatine Friedrich II. Stahleck Castle and the town wall could not stop Bacharach from undergoing eight changes in military occupation in the Thirty Years' War, nor the war’s attendant sackings. Moreover, further destruction was wrought by several town fires. Then, in 1689, French troops fighting in the Nine Years' War blew Stahleck Castle and four of the town wall’s towers up.
In 1794, French Revolutionary troops occupied the Rhine’s left bank and in 1802, Bacharach became temporarily French. During the War of the Sixth Coalition the Prussian Field Marshal Blücher, after crossing the Rhine near Kaub, came through Bacharach and the Steeg Valley on New Year’s Night 1813-1814 with his troops on the way to France. Recalling this event is a monument stone somewhat downstream, across from Kaub. After the Congress of Vienna, the town went, along with the Rhine’s left bank, up to and including Bingerbrück, to Prussia. After the harbour silted up, Bacharach fell into a slumber from which it only awoke in the course of the "Rheinromantik". Among the first of the prominent visitors at this time was the French writer Victor Hugo.
Caring for and maintaining Bacharach’s building monuments, spurred on in the early 20th century by the Rhenish Association for Monument Care and Landscape Preservation ("Rheinischer Verein für Denkmalpflege und Landschaftsschutz") which took on the then highly endangered town wall and Stahleck Castle ruin jobs, and the great dedication of the state of Rhineland-Palatinate to the "Wernerkapelle" have seen to it that Bacharach is still a jewel of the "Rheinromantik" and a multifaceted documentary site of mediaeval architecture on the Middle Rhine. The "Wernerkapelle" ruin is under monumental protection and before it a plaque has been placed recalling the inhuman crimes against Jewish residents and also containing a quotation from a prayer by Pope John XXIII for a change in Christians’ thinking in their relationship with the Jews:
“We recognize today that many centuries of blindness have shrouded our eyes, so that we no longer saw the goodliness of Thy Chosen People and no longer recognized our firstborn brother’s traits. We discover now that a mark of Cain stands on our forehead. In the course of the centuries our brother Abel has lain in blood that we spilt, and he has wept tears that we brought forth, because we forgot Thy love. Forgive us the curse that we unrightfully affixed to the Jews’ name. Forgive us for nailing Thee in their flesh for a second time to the Cross. For we knew not what we did..."
Today Bacharach thrives on tourism and wine from Bacharach is still enjoying international popularity. Not to be overlooked, however, are problems arising from a shrinking population, itself brought about by a lack of prospects.
Amalgamations.
On 7 June 1969, the formerly self-administering municipality of Steeg was amalgamated with Bacharach.
Coat of arms.
The town’s arms might be described thus: Per fess at the nombril point sable a lion rampant Or armed, langued and crowned gules, and bendy lozengy argent and azure.
Economy and infrastructure.
Transport.
Bacharach lies on the Rhine’s left bank and can be reached by "Bundesstraße" 9 or the Rhine. Running regularly to and from Bacharach are the excursion ships of the "Köln-Düsseldorfer-Rheinschiffahrt", or KD for short.
Transport routes on the other side of the river can be reached by ferry from the "Engelsburg" (castle) over to Kaub.
The town belongs to the "Rhein-Nahe-Nahverkehrsverbund" – a local transport association. Bacharach lies on the West Rhine Railway and is served by Koblenz—Boppard—Bacharach—Bingen am Rhein—Mainz Regionalbahn trains (as of July 2004).

</doc>
<doc id="58242" url="https://en.wikipedia.org/wiki?curid=58242" title="Louis Petit de Bachaumont">
Louis Petit de Bachaumont

Louis Petit de Bachaumont () (June 2, 1690 – April 29, 1771) was a French writer, whose historical interest has been connected largely to his alleged role in the gossipy "Mémoires secrets pour servir à l'histoire de la République des Lettres". A modern biography brought to general attention his other roles, as an arbiter of taste, an influential art critic and an "urbaniste"
Petit de Bachaumont was of noble family and was brought up at the court of Versailles. He passed his whole life in Paris, however, as the centre of the salon of Mme Doublet de Persan (1677–1771), where criticism of art and literature took the form of malicious gossip. A sort of register of news was kept in a journal of the salon, starting in 1762, which dealt largely in scandals and contained accounts of books suppressed by the censor. Bachaumont's name is commonly connected with the first volumes of this register, which was published anonymously, long after Petit de Bachaumont's death, under the title "Mémoires secrets pour servir à l'histoire de la République des Lettres", but his exact share in the authorship of those years before his death in 1771 is a matter of controversy. The register was continued by Pidansat de Mairobert (1707–1779), who may have had a greater hand in it from the start, and by others, until it reached 36 volumes (covering the years 1774-1779). It is of some value as a historical source, especially for prohibited literature, and full of anecdotes, for which it was sieved by the brothers Goncourt, who revived interest in this obscure figure, whom they presented as the "anecdotier parfait", the reputation, as the "perfect recounter of anecdote" to the present time.
Petit de Bachaumont's studied "indolence", remarked upon in his obituary, was a stylish pose. His major published writings are "Essai sur la peinture, la sculpture et l'architecture" (1751) and his surveys of the Paris salons of 1767 and 1769, in which aesthetics and cultural politics were inseparably entwined. Less noted is his published call in 1749 for the roofing-over of Perrault's classical colonnaded east front of the Palais du Louvre and the clearing away of the ramshackle structures, both those that had been built against it, in order to form a proper Palais du Louvre, and those in the centre of the Cour Carré itself Sections of the palace were in danger of collapse, scarcely touched by royal indifference after 1678; work did begin in 1755 to clear the facade of the Louvre, overseen by the architect Jacques-Germain Soufflot and Marigny, supervisor of the Bâtiments du Roi.
As a critic of art, his recommendation of a young artist named François Boucher appeared in a design memorandum Bachaumont presented the duc de Bouillon, who was occupied with renovating interiors at the Château de Navarre in Normandy, in 1730: "he is very quick, works fast and is not expensive". 
See, in addition to the memoirs of the time, especially the "" of Grimm, Diderot, d'Alembert and others (new ed-, Paris, 1878); Ch. Aubertin, "L'Esprit public au XVIIIe siècle" (Paris, 1872).

</doc>
<doc id="58244" url="https://en.wikipedia.org/wiki?curid=58244" title="Cordite">
Cordite

Cordite is a family of smokeless propellants developed and produced in the United Kingdom since 1889 to replace gunpowder as a military propellant. Like gunpowder, cordite is classified as a low explosive because of its slow burning rates and consequently low brisance. These produce a subsonic deflagration wave rather than the supersonic detonation wave produced by brisants, or high explosives. The hot gases produced by burning gunpowder or cordite generate sufficient pressure to propel a bullet or shell to its target, but not so quickly as to routinely destroy the barrel of the gun.
Cordite was used initially in the .303 British, Mark I and II, standard rifle cartridge between 1891 and 1915; shortages of cordite in World War I led to United States–developed smokeless powders being imported into the UK for use in rifle cartridges. Cordite was also used for large weapons, such as tank guns, artillery and naval guns. It has been used mainly for this purpose since the late 19th century by the UK and British Commonwealth countries. Its use was further developed before World War II, and as Unrotated Projectiles for launching anti-aircraft weapons. Small cordite rocket charges were also developed for ejector seats made by the Martin-Baker Company. Cordite was also used in the detonation system of the Little Boy atomic bomb dropped over Hiroshima in August 1945.
The term cordite generally disappeared from official publications between the wars. During World War II double based propellants were very widely used and there was some use of triple based propellants by artillery. Triple based propellants were used in post-war ammunition designs and remain in production for UK weapons; most double based propellants left service as World War II stocks were expended after the war. For small arms it has been replaced by other propellants, such as the Improved Military Rifle (IMR) line of extruded powder or the WC844 ball propellant currently in use in the 5.56×45mm NATO. Production ceased in the United Kingdom, around the end of the 20th century, with the closure of the last of the World War II cordite factories, ROF Bishopton. Triple base propellant for UK service (for example, the 105 mm L118 Light Gun) is now manufactured in Germany.
Adoption of smokeless powder by the British government.
Replacements for gunpowder (black powder).
Gunpowder, an explosive mixture of sulfur, charcoal and potassium nitrate (also known as saltpetre/saltpeter), was the original propellant employed in firearms and fireworks. It was used from about 10th or 11th century onwards, but it had disadvantages, including the large quantity of smoke it produced. With the 19th-century development of various "nitro explosives", based on the reaction of nitric acid mixtures on materials such as cellulose and glycerine, a search began for a replacement for gunpowder.
Early European smokeless powders.
The first smokeless powder was developed in 1865 by Major Johann F. E. Schultze of the Prussian artillery. His formulation (dubbed Schultze Powder) comprised nitrolignose impregnated with saltpetre or barium nitrate.
In 1882 the Explosive Company of Stowmarket introduced EC Powder, which contained nitro-cotton and nitrates of potassium and barium in a grain gelatinesed by ether alcohol. It had coarser grains than other nitrocellulose powders. It proved unsuitable for rifles, but it remained in long use for shotguns and was later used for grenades and fragmentation bombs.
In 1884, the French chemist Paul Vieille produced a smokeless propellant that had some success. It was made out of collodion (nitrocellulose dissolved in ethanol and ether), resulting in a plastic colloidal substance which was rolled into very thin sheets, then dried and cut up into small flakes. It was immediately adopted by the French military for their Mle 1886 infantry rifle and called Poudre B (for "Poudre Blanche", or "White Powder") to distinguish it from "Black Powder" (gunpowder). The rifle and the cartridge developed to use this powder were known generically as the 8mm Lebel, after the officer who developed its 8 mm full metal jacket bullet.
The following year, 1887, Alfred Nobel invented and patented a smokeless propellant he called Ballistite. It was composed of 10% camphor, 45% nitroglycerine and 45% collodion (nitrocellulose). Over time the camphor tended to evaporate, leaving an unstable explosive.
Development of Cordite.
A United Kingdom government committee, known as the "Explosives Committee", chaired by Sir Frederick Abel, monitored foreign developments in explosives and obtained samples of Poudre B and Ballistite; neither of these smokeless powders was recommended for adoption by the Explosives Committee.
Abel, Sir James Dewar and Dr W Kellner, who was also on the committee, developed and jointly patented (Nos 5,614 and 11,664 in the names of Abel and Dewar) in 1889 a new ballistite-like propellant consisting of 58% nitroglycerine, by weight, 37% guncotton (nitrocellulose) and 5% petroleum jelly. Using acetone as a solvent, it was extruded as spaghetti-like rods initially called "cord powder" or "the Committee's modification of Ballistite", but this was swiftly abbreviated to "Cordite".
Cordite began as a "double-base" propellant. In the 1930s "triple-base" was developed by including a substantial proportion of nitroguanidine. Triple-based propellant reduced the disadvantages of double-base propellant - its relatively high temperature and significant flash. Imperial Chemical Industries's (ICI) World War 2 double-base AN formulation also had a much lower temperature, but it lacked the flash reduction properties of N and NQ triple-base propellants.
Whilst cordite is classified as an explosive, it is not employed as a high explosive. It is designed to deflagrate, or burn, to produce high temperature gases.
Nobel and Abel patent dispute.
Alfred Bernhard Nobel sued Abel and Dewar over an alleged patent infringement. His patent specified that the nitrocellulose should be "of the well-known soluble kind". After losing the case, it went to the Court of Appeal. This dispute eventually reached the House of Lords, in 1895, but it was finally lost because the words "of the well-known soluble kind" in his patent were taken to mean the soluble collodion, and hence specifically excluded the insoluble guncotton. The ambiguous phrase was "soluble nitro-cellulose": soluble nitro-cellulose was known as "Collodion" and was soluble in alcohol. It was employed mainly for medical and photographic use. In contrast, insoluble, in alcohol, nitrocellulose was known as "gun cotton" and was used as an explosive. Nobel's patent refers to the production of Celluloid using camphor and soluble nitrocellulose; and this was taken to imply that Nobel was specifically distinguishing between the use of soluble and insoluble nitrocellulose. For a forensic analysis of the case see The History of Explosives Vol II; The Case for Cordite, John Williams (2014)
Cordite formulations.
It was quickly discovered that the rate of burning could be varied by altering the surface area of the cordite. Narrow rods were used in small-arms and were relatively fast burning, while thicker rods would burn more slowly and were used for longer barrels, such as those used in artillery and naval guns.
Cordite (Mk I) and Cordite MD.
The original Abel-Dewar formulation was soon superseded, as it caused excessive gun barrel erosion. It has since become known as Cordite Mk I.
The composition of cordite was changed to 65% guncotton and 30% nitroglycerine (keeping 5% petroleum jelly) shortly after the end of the Second Boer War. This was known as Cordite MD (modified).
Cordite MD cartridges typically weighed approximately 15% more than the cordite Mk I cartridges they replaced, to achieve the same muzzle velocity, due to the inherently less powerful nature of Cordite MD.
Cordite RDB.
During World War I acetone was in short supply in Great Britain, and a new experimental form was developed for use by the Royal Navy. This was Cordite RDB (= Research Department formula B); which was 52% collodion, 42% nitroglycerine and 6% petroleum jelly. It was produced at HM Factory, Gretna; and the Royal Navy Cordite Factory, Holton Heath.
Acetone for the cordite industry during late World War I was eventually produced through the efforts of Dr. Chaim Weizmann, considered to be the father of industrial fermentation. While a lecturer at Manchester University Weizmann discovered how to use bacterial fermentation to produce large quantities of many desired substances. He used the bacterium Clostridium acetobutylicum (the so-called Weizmann organism) to produce acetone. Weizmann transferred the rights to the manufacture of acetone to the Commercial Solvents Corporation in exchange for royalties. After the Shell Crisis of 1915 during World War I, he was director of the British Admiralty Laboratories from 1916 until 1919.
Cordite RDB was later found to become unstable if stored too long.
Cordite SC.
Research on solvent-free Cordite RDB continued primarily on the addition of stabilizers, which led to the type commonly used in World War II as the main naval propellant. In Great Britain this was known as Cordite SC (= Solventless Cordite). Cordite SC was produced in different shapes and sizes, so the particular geometry of Cordite SC was indicated by the use of letters or numbers, or both, after the SC. For example, SC followed by a number was rod-shaped cord, with the number representing the diameter in thousandths of an inch. "SC T" followed by two sets of numbers indicated tubular propellant, with the numbers representing the two diameters in thousandths.
Two-inch (approximately 50 mm) and three-inch (approximately 75 mm) diameter, rocket Cordite SC charges were developed in great secrecy before World War II for anti-aircraft purposes—the so-called "Z batteries", using Unrotated Projectiles.
Great Britain changed to metric units in the 1960s, so there was a discontinuity in the propellant geometry numbering system.
Cordite N.
An important development during World War II was the addition of another explosive, nitroguanidine, to the mixture to form "triple-base" propellant or Cordite N and NQ. The formulations were slightly different for artillery and naval use. This solved two problems with the large naval guns of the day as fitted to capital ships. It was also used in limited amounts with 25-pr and 5.5-inch artillery. Nitroguanidine produces large amounts of nitrogen when heated, which had the benefit of reducing the muzzle flash, and its lower burning temperature greatly reduced the erosion of the gun barrel.
After World War II production of double based propellants generally ended. Triple based propellants, N and NQ, were the only ones used in new ammunition designs, such as the cartridges for 105mm Field and for 155mm FH70.
Cordite manufacture.
UK Government factories.
In Great Britain cordite was developed for military use at the Royal Arsenal by Abel, Dewar and Kellner, Woolwich, and produced at the Waltham Abbey Royal Gunpowder Mills from 1889 onwards.
At the start of World War I cordite was in production at Waltham Abbey Royal Gunpowder Mills and by seven other suppliers (British Explosives Syndicate Ltd, Chilworth Gunpowder Company Ltd, Cotton Powder Company Ltd, Messrs Curtis's and Harvey Ltd, National Explosives Company Ltd, New Explosives Company Ltd and Nobels Explosive Company Ltd).
. Existing factories were expanded and new ones built notably by Nobel's at Ardeer, HM Factory, Gretna, which straddled the Scotland-England border at Gretna, and the Royal Navy Cordite Factory, Holton Heath
. A factory was also established by the Indian Government at Nilgris. Both the Gretna and the Holton Heath cordite factories closed at the end of World War I.
By the start of World War II Holton Heath had reopened, and an additional factory for the Royal Navy, The Royal Navy Propellant Factory, Caerwent, opened at Caerwent in Wales. A very large Royal Ordnance Factory, ROF Bishopton, was opened in Scotland to manufacture cordite for the British Army and the Royal Air Force. A new cordite factory at Waltham Abbey and two additional ROF's—ROF Ranskill and ROF Wrexham—were also opened. Cordite produced in these factories was sent to filling factories for filling into ammunition.
MoS Agency Factories and ICI Nobel in World War II.
The British Government set up additional cordite factories, not under Royal Ordnance Factory control but as Agency Factories run on behalf of the Ministry of Supply (MoS). The company of ICI Nobel, at Ardeer, was asked in 1939 to construct and operate six factories in southern Scotland. Four of these six were involved in cordite or firearm-propellant manufacture. The works at MoS Drungans (Dumfries) produced guncotton that was converted to cordite at MoS Dalbeattie (triple-base cordite) and at MoS Powfoot (monobase granulated guncotton for small-arms). A smaller site at Girvan, South Ayrshire, now occupied by Grant's distillery, produced cordite and TNT. The ICI Ardeer site also had a mothballed World War I Government-owned cordite factory.
35% of British cordite produced between 1942 and 1945 came from Ardeer and these agency factories. ICI ran a similar works at Deer Park near Melbourne in Australia and in South Africa.
Overseas supplies.
Additional sources of propellant were also sought from the British Commonwealth in both World War I and World War II. Canada, South Africa, and Australia had ICI-owned factories that, in particular, supplied large quantities of cordite.
World War I.
Canadian Explosives Limited was formed in 1910 to produce rifle cordite, at its Beloeil factory, for the Quebec Arsenal. By November 1915 production had been expanded to produce 350,000 lb (159,000 kg) of cordite per month for the Imperial Munitions Board.
The Imperial Munitions Board set up a number of additional explosives factories in Canada. It built The British Cordite Ltd factory at Nobel, Ontario, in 1916/1917, to produce cordite. Production started in mid-1917.
Canadian Explosives Limited built an additional cordite factory at Nobel, Ontario. Work stated in February 1918 and was finished on 24 August 1918. It was designed to produce 1,500,000 lb (681,000 kg) of cordite per month.
Factories, specifically “heavy industry” (Long, and Marland 2009) were important for the provision of munitions. Cordite factories typically employed women (Cook 2006) who put their lives at risk as they packed the shells.
World War II.
The United States did not use cordite, however, several ammunition filling factories were set up in Canada in World War II to fill American propellant supplied by the USA under Lend-Lease. India and Australia were also approached.
Production quantities.
Large quantities of cordite were manufactured in both World Wars for use by the military.
Pre–World War I.
Prior to World War I, most of the cordite used by the British Government was produced in its own factories. Immediately prior to World War I, between 6,000 and 8,000 tons per year of cordite were produced in the United Kingdom by private manufacturers; between 1,000 and 1,500 tons per year were made by Nobel's Explosives, at Ardeer. However, private industry had the capability to produce about 10,000 tons per year, with Ardeer able to produce some 3,000 tons of this total.
World War I.
At the start of World War I, private industry in the UK was asked to produce 16,000 tons of cordite, and all the companies started to expand. HM Factory, Gretna, the largest propellant factory in the United Kingdom, which opened in 1916, was by 1917 producing 800 tons (812 tonne) of Cordite RDB per week (approximately 41,600 tons per year). The Royal Navy had its own factory at Holton Heath.
In 1910, Canadian Explosives Limited produced 3,000 lb (1,362 kg) of rifle cordite per month at its Beloeil factory, for the Quebec Arsenal. By November 1915 production had been expanded to 350,000 lb (159,000 kg) of cordite per month (approximately 1,900 tonnes per year).
The Canadian Explosives Limited cordite factory at Nobel, Ontario was designed to produce 1,500,000 lb (681 tonne) of cordite per month (approximately 8,170 tonnes per year).
Between wars.
HM Factory, Gretna and the Royal Navy Cordite Factory, Holton Heath both closed after the end of the war and the Gretna factory was dismantled. This left the Waltham Abbey and Ardeer factories in production.

</doc>
<doc id="58245" url="https://en.wikipedia.org/wiki?curid=58245" title="Ethnic groups in Chinese history">
Ethnic groups in Chinese history

Ethnic groups in Chinese history refer to various or presumed ethnicities of significance to the history of China, gathered through the study of Classical Chinese literature, Chinese and non-Chinese literary sources and inscriptions, historical linguistics, and archaeological research.
Among the difficulties in the study of ethnic groups in China are the relatively long periods of time involved, together with the large volume of literary and historical records which have accompanied the history of China. Classical Chinese ethnography (like much then-contemporary ethnography) was often sketchy, leaving it unclear as to whether Chinese-depicted names referred to a true ethnic group or a possibly multiethnic political entity. Even then, ethnonyms were sometimes assigned by geographic location or surrounding features, rather than by any features of the people themselves, and often carried little distinction of who the Han Chinese authors considered Chinese and non-Chinese for differences such as lifestyle, language, or governance. Many of the ethnonyms were historically used in such a way as to invite comparison with the word "barbarian". 
English names.
The Chinese exonyms of various ethnic groups encountered in Chinese history can be rendered into English either by transliteration or translation; for instance, "Dí" 狄 is transliterated as "Di" (or "Ti") or translated as "Northern Barbarians". In some cases authors prefer to transliterate specific exonyms as proper nouns, and in other cases to translate generic ones as English "barbarian" (for instance, "Siyi" "Four Barbarians"). The American sinologist Marc S. Abramson explains why "barbarian" is the appropriate translation for general terms like "fan" 番 and "hu" 胡, but not specific ones like "fancai" 番菜 "foreign-style food".
Translations such as "foreigner" and "alien", though possessing an air of scholarly neutrality, are inappropriate as a general translation because they primarily connote geographic and political considerations, implying that individuals and groups so designated were external to the Tang Empire and ineligible to become subjects of the empire. This was frequently not the case with many uses of "fan" and related terms — common among them were "hu" (often used in the Tang to denote Central Asians) and four ethnonyms of great antiquity that, by the Tang, were mostly used generically with implicit geographic considerations: "yi" (east), "man" (south), "rong" (west), and "di" (north) — that largely connoted cultural and ethnic otherness but did not exclude the designated persons or groups from membership in the empire. Although the term "barbarian" has undergone many transformations from its Greek origins to its current English usage, not all of which are relevant to the Tang (such as its use in medieval Europe to denote religious difference, marking non-Christians of various ethnic, geographic, and political affiliations), its consistent association with inferiority, lack of civilization, and externality in the broadest sense often make it the most appropriate choice, including some cases when it is placed in the mouths of non-Han referring to themselves or others. However, its pejorative connotations make it inappropriate as a general translation. Thus, I have chosen not to translate these terms when they designate particular groups, individuals, or phenomena and do not refer to a specific ethnic group, language, geographic place, or cultural complex.
List of ethnic groups.
The following table summarizes the various ethnic groups and/or other social groups of known historical significance to the history of China (any non clear-cut connection is denoted by a question mark):

</doc>
<doc id="58246" url="https://en.wikipedia.org/wiki?curid=58246" title="Nitrocellulose">
Nitrocellulose

Nitrocellulose (also known as cellulose nitrate, flash paper, flash cotton, guncotton, and flash string) is a highly flammable compound formed by nitrating cellulose through exposure to nitric acid or another powerful nitrating agent. When used as a propellant or low-order explosive, it was originally known as guncotton.
Partially nitrated cellulose has found uses as a plastic film and in inks and wood coatings. In 1862 the first man-made plastic, nitrocellulose, (branded Parkesine) was created by Alexander Parkes from cellulose treated with nitric acid and a solvent. In 1868, American inventor John Wesley Hyatt developed a plastic material he named Celluloid, improving on Parkes' invention by plasticizing the nitrocellulose with camphor so that it could be processed into finished form and used as a photographic film. Celluloid was used by Kodak, and other suppliers, from the late 1880s as a film base in photography, X-ray films, and motion picture films, and was known as nitrate film. After numerous fires caused by unstable nitrate films, "safety film" (cellulose acetate film) started to be used from the 1930s in the case of X-ray stock and from 1948 for motion picture film.
Guncotton/Nitrocellulose.
Discovery.
Henri Braconnot discovered in 1832 that nitric acid, when combined with starch or wood fibers, would produce a lightweight combustible explosive material, which he named "xyloïdine". A few years later in 1838, another French chemist, Théophile-Jules Pelouze (teacher of Ascanio Sobrero and Alfred Nobel), treated paper and cardboard in the same way. Jean-Baptiste Dumas obtained a similar material, which he called "nitramidine". These substances were highly unstable and were not practical explosives.
However, around 1846 Christian Friedrich Schönbein, a German-Swiss chemist, discovered a more practical solution.
As he was working in the kitchen of his home in Basel, he spilled a bottle of concentrated nitric acid on the kitchen table. He reached for the nearest cloth, a cotton apron, and wiped it up. He hung the apron on the stove door to dry, and, as soon as it was dry, there was a flash as the apron ignited. His preparation method was the first to be widely imitated—one part of fine cotton wool to be immersed in 15 parts of an equal blend of sulfuric and nitric acids. After two minutes, the cotton was removed and washed in cold water to set the esterification level and remove all acid residue. It was then slowly dried at a temperature below 40 °C (about 100 °F). Schönbein collaborated with the Frankfurt professor Rudolf Christian Böttger, who had discovered the process independently in the same year. By coincidence, a third chemist, the Brunswick professor F. J. Otto had also produced guncotton in 1846 and was the first to publish the process, much to the disappointment of Schönbein and Böttger.
The process uses nitric acid to convert cellulose into cellulose nitrate and water:
The sulfuric acid is present as a catalyst to produce the nitronium ion, NO2+. The reaction is first order and proceeds by electrophilic substitution at the C-OH centers of the cellulose.
Industrial production.
The power of guncotton made it suitable for blasting. As a projectile driver, it had around six times the gas generation of an equal volume of black powder and produced less smoke and less heating.
The patent rights for the manufacture of gun cotton were obtained by John Hall & Son in 1846, and industrial manufacture of the explosive began at a purpose-built factory at Faversham’s Marsh Works in Kent, England a year later. However, the manufacturing process was not properly understood and few safety measures were put in place. A serious explosion in July of that year killed almost two dozen workers, resulting in the immediate closure of the plant. Guncotton manufacture ceased for over 15 years until a safer procedure could be developed.
Further research indicated the importance of very careful washing of the acidified cotton. Unwashed nitrocellulose (sometimes called pyrocellulose) may spontaneously ignite and explode at room temperature, as the evaporation of water results in the concentration of unreacted acid.
The British chemist Frederick Augustus Abel developed the first safe process for guncotton manufacture, which he patented in 1865. The washing and drying times of the nitrocellulose were both extended to 48 hours and repeated eight times over. The acid mixture was changed to two parts sulfuric acid to one part nitric. Nitration can be controlled by adjusting acid concentrations and reaction temperature. Nitrocellulose is soluble in a mixture of alcohol and ether until nitrogen concentration exceeds 12%. Soluble nitrocellulose, or a solution thereof, is sometimes called collodion.
Guncotton containing more than 13% nitrogen (sometimes called insoluble nitrocellulose) was prepared by prolonged exposure to hot, concentrated acids for limited use as a blasting explosive or for warheads of underwater weapons such as naval mines and torpedoes. Safe and sustained production of guncotton began at the Waltham Abbey Royal Gunpowder Mills in the 1860s, and the material rapidly became the dominant explosive, becoming the standard for military warheads, although it remained too potent to be used as a propellant. More-stable and slower-burning collodion mixtures were eventually prepared using less-concentrated acids at lower temperatures for smokeless powder in firearms. The first practical smokeless powder made from nitrocellulose, for firearms and artillery ammunition, was invented by French chemist Paul Vieille in 1884.
Jules Verne viewed the development of guncotton with optimism. He referred to the substance several times in his novels. His adventurers carried firearms employing this substance. The most noteworthy reference is in his "From the Earth to the Moon", in which guncotton was used to launch a projectile into space.
Nitrate film.
On May 2, 1887, Hannibal Goodwin filed a patent for "a photographic pellicle and process of producing same ... especially in connection with roller cameras", but the patent was not granted until 13 September 1898. In the meantime, George Eastman had already started production of roll-film using his own process.
Nitrocellulose was used as the first flexible film base, beginning with Eastman Kodak products in August, 1889. Camphor is used as a plasticizer for nitrocellulose film, often called nitrate film. Goodwin's patent was sold to Ansco, which successfully sued Eastman Kodak for infringement of the patent and was awarded $5,000,000 in 1914 to Goodwin Film.
Nitrate film was used until 1933 for X-ray films (where its flammability hazard was most acute) and for motion picture film until 1951. It was replaced by safety film with an acetate base. Nitrocellulose X-ray film ignition was the cause behind the Cleveland Clinic fire of 1929 in Cleveland, Ohio, which claimed the lives of more than 129 people.
The use of nitrocellulose film for motion pictures led to the requirement for fireproof projection rooms with wall coverings made of asbestos. The US Navy shot a training film for projectionists that included footage of a controlled ignition of a reel of nitrate film, which continued to burn when fully submerged in water. Unlike many other flammable materials, nitrocellulose does not need air to keep burning, as the reaction produces oxygen. Once burning, it is extremely difficult to extinguish. Immersing burning film in water may not extinguish it, and could actually increase the amount of smoke produced. Owing to public safety precautions, the London Underground forbade transport of movies on its system until well past the introduction of safety film.
Cinema fires caused by ignition of nitrocellulose film stock were the cause of the 1926 Dromcolliher cinema tragedy in County Limerick in which 48 people died and the 1929 Glen Cinema disaster in Paisley, Scotland, which killed 69 children. Today, nitrate film projection is normally highly regulated and requires extensive precautionary measures including extra projectionist health and safety training. Projectors certified to run nitrate films have many precautions, among them the chambering of the feed and takeup reels in thick metal covers with small slits to allow the film to run through. The projector is modified to accommodate several fire extinguishers with nozzles aimed at the film gate. The extinguishers automatically trigger if a piece of flammable fabric placed near the gate starts to burn. While this triggering would likely damage or destroy a significant portion of the projection components, it would prevent a fire which could cause far greater damage. Projection rooms may be required to have automatic metal covers for the projection windows, preventing the spread of fire to the auditorium. The Dryden Theatre at the George Eastman Museum is one of a few theaters in the world that is capable of safely projecting nitrate films, and regularly screens films to the public.
Nitrocellulose was found to gradually decompose, releasing nitric acid and further catalyzing the decomposition (eventually into a flammable powder). Decades later, storage at low temperatures was discovered as a means of delaying these reactions indefinitely. The great majority of films produced during the early 20th century are thought to have been lost either through this accelerating, self-catalyzed disintegration or through studio warehouse fires. Salvaging old films is a major problem for film archivists (see film preservation).
Nitrocellulose film base manufactured by Kodak can be identified by the presence of the word 'nitrate' in dark letters along one edge; the word only in clear letters on a dark background indicates derivation from a nitrate base original negative or projection print, but the film in hand itself may be a later print or copy negative, respectively, made on safety film. Acetate film manufactured during the era when nitrate films were still in use was marked 'Safety' or 'Safety Film' along one edge in dark letters. 8, 9.5, and 16 mm film stocks, intended for amateur and other nontheatrical use, were never manufactured with a nitrate base in the west, but rumors exist of 16 mm nitrate film having been produced in the former Soviet Union and/or China.
Replacement filmstocks.
Nitrate dominated the market for professional-use 35 mm motion picture film from the industry's origins to the early 1950s. While cellulose acetate-based so-called "safety film", notably cellulose diacetate and cellulose acetate propionate, was produced in the gauge for small-scale use in niche applications ("e.g.", printing advertisements and other short films to enable them to be sent through the mails without the need for fire safety precautions), the early generations of safety film base had two major disadvantages relative to nitrate: it was much more expensive to manufacture, and considerably less durable in repeated projection. The cost of the safety precautions associated with the use of nitrate was significantly lower than the cost of using any of the safety bases available before 1948. These drawbacks were eventually overcome with the launch of cellulose triacetate base film by Eastman Kodak in 1948. Cellulose triacetate superseded nitrate as the film industry's mainstay base very quickly: Kodak announced the discontinuation of nitrate manufacture in February 1950.
The crucial advantage cellulose triacetate had over nitrate was that it was no more of a fire risk than paper (the stock is often erroneously referred to as "non-flam": this is not true—it is combustible, but not in as volatile or as dangerous a way as nitrate), while it almost matched the cost and durability of nitrate. It remained in almost exclusive use in all film gauges until the 1980s, when polyester/PET film began to supersede it for intermediate and release printing.
Polyester is much more resistant to polymer degradation than either nitrate or triacetate. Although triacetate does not decompose in as dangerous a way as nitrate does, it is still subject to a process known as deacetylation, often nicknamed "vinegar syndrome" (due to the acetic acid smell of decomposing film) by archivists, which causes the film to shrink, deform, become brittle and eventually unusable. PET, like cellulose mononitrate, is less prone to stretching than other available plastics. By the late 1990s, polyester had almost entirely superseded triacetate for the production of intermediate elements and release prints.
Triacetate remains in use for most camera negative stocks because it can be "invisibly" spliced using solvents during negative assembly, while polyester film can only be spliced using adhesive tape patches or ultrasonically, both of which leave visible marks in the frame area. Also, polyester film is so strong, it will not break under tension and may cause serious damage to expensive camera or projector mechanisms in the event of a film jam, whereas triacetate film breaks easily, reducing the risk of damage. Many were opposed to the use of polyester for release prints for precisely this reason, and because ultrasonic splicers are very expensive items, beyond the budgets of many smaller theaters. In practice, though, this has not proved to be as much of a problem as was feared. Rather, with the increased use of automated long-play systems in cinemas, the greater strength of polyester has been a significant advantage in lessening the risk of a film performance being interrupted by a film break.
Despite its self-oxidizing hazards, nitrate is still regarded highly as the stock is more transparent than replacement stocks, and older films used denser silver in the emulsion. The combination results in a notably more luminous image with a high contrast ratio.
Production.
Guncotton.
Guncotton is made by treating cotton (used as the source of cellulose) with concentrated sulfuric acid and 70% nitric acid cooled to 0 °C to produce cellulose trinitrate. While guncotton is dangerous to store, the hazards it presents can be reduced by storing it dampened with various liquids, such as alcohol. For this reason, accounts of guncotton usage dating from the early 20th century refer to "wet guncotton".
Nitrate film.
Cellulose is treated with sulfuric acid and potassium nitrate to give cellulose mononitrate. This was used commercially as 'celluloid', a highly flammable plastic used in the first half of the 20th century for lacquers and photographic film.
Uses.
Because of its explosive nature, not all applications of nitrocellulose were successful. In 1869, with elephants having been poached to near extinction, the billiards industry offered a $10,000 prize to whomever came up with the best replacement for ivory billiard balls. John Wesley Hyatt created the winning replacement, which he created with a new material he discovered called camphored nitrocellulose—the first thermoplastic, better known as celluloid. The invention enjoyed a brief popularity, but the Hyatt balls were extremely flammable, and sometimes portions of the outer shell would explode upon impact. An owner of a billiard saloon in Colorado wrote to Hyatt about the explosive tendencies, saying that he did not mind very much personally but for the fact that every man in his saloon immediately pulled a gun at the sound. The process used by Hyatt to manufacture the billiard balls (US Patent 239,792, 1881) involved placing the mass of nitrocellulose in a rubber bag, which was then placed in a cylinder of liquid and heated. Pressure was applied to the liquid in the cylinder, which resulted in a uniform compression on the nitrocellulose mass, compressing it into a uniform sphere as the heat vaporized the solvents. The ball was then cooled and turned to make a uniform sphere. In light of the explosive results, this process was called the "Hyatt gun method".
Hazards.
Collodion, a solution of nitrocellulose in ether and ethanol, is a flammable liquid.
When dry, nitrocellulose is explosive and can be ignited with heat, spark, or friction. An overheated container of dry nitrocellulose is believed to be the initial cause of the 2015 Tianjin explosions.

</doc>
<doc id="58249" url="https://en.wikipedia.org/wiki?curid=58249" title="Earl">
Earl

An earl is a member of the nobility. The title is Anglo-Saxon, akin to the Scandinavian form jarl, and meant "chieftain", particularly a chieftain set to rule a territory in a king's stead. In Scandinavia, it became obsolete in the Middle Ages and was replaced with duke ("hertig"/"hertug"). In later medieval Britain, it became the equivalent of the continental count (in England in the earlier period, it was more akin to duke; in Scotland it assimilated the concept of mormaer). However, earlier in Scandinavia, "jarl" could also mean sovereign prince. For example, the rulers of several of the petty kingdoms of Norway had in fact the title of "jarl" and in many cases of no lesser power than their neighbours who had the title of king. Alternative names for the "Earl/Count" rank in the nobility structure are used in other countries, such as Hakushaku during the Japanese Imperial era.
In modern Britain, an earl is a member of the peerage, ranking below a marquess and above viscount. A feminine form of "earl" never developed; "countess" is used as the equivalent feminine title.
Etymology.
The term "earl" has been compared to the name of the Heruli, and to runic "erilaz".
Proto-Norse "eril", or the later Old Norse "jarl", came to signify the rank of a leader.
The Norman-derived equivalent "count" (from Latin "comes") was not introduced following the Norman conquest of England though "countess" was and is used for the female title. Geoffrey Hughes writes, "It is a likely speculation that the Norman French title 'Count' was abandoned in England in favour of the Germanic 'Earl' […] precisely because of the uncomfortable phonetic proximity to cunt".
Earls in the United Kingdom and the Commonwealth.
Forms of address.
An earl has the title "Earl of when the title originates from a placename, or "Earl [X" when the title comes from a surname. In either case, he is referred to as "Lord and his wife as "Lady [X". A countess who holds an earldom in her own right also uses "Lady ", but her husband does not have a title (unless he has one in his own right).
The eldest son of an earl, though not himself a peer, is entitled to use a courtesy title, usually the highest of his father's lesser titles (if any); younger sons are styled "The Honourable" ["Forename"] ["Surname"], and daughters, "The Lady" ["Forename"] ["Surname"] (Lady Diana Spencer being a well-known example).
In the peerage of Scotland, when there are no courtesy titles involved, the heir to an earldom, and indeed any level of peerage, is styled "Master of and successive sons as "younger of [X".
England.
Changing power of English earls.
In Anglo-Saxon England, earls had authority over their own regions and right of judgment in provincial courts, as delegated by the king. They collected fines and taxes and in return received a "third penny", one-third of the money they collected. In wartime they led the king's armies. Some shires were grouped together into larger units known as "earldoms", headed by an "ealdorman" or "earl". Under Edward the Confessor earldoms like Wessex, Mercia, East Anglia and Northumbria—names that represented earlier independent kingdoms—were much larger than any shire.
Earls originally functioned essentially as royal governors. Though the title of Earl was nominally equal to the continental duke, unlike them, earls were not de facto rulers in their own right.
After the Norman Conquest, William the Conqueror tried to rule England using the traditional system but eventually modified it to his own liking. Shires became the largest secular subdivision in England and earldoms disappeared. The Normans did create new earls like those of Herefordshire, Shropshire, and Cheshire but they were associated with only a single shire at most. Their power and regional jurisdiction was limited to that of the Norman counts.
There was no longer any administrative layer larger than the shire, and shires became "counties". Earls no longer aided in tax collection or made decisions in country courts and their numbers were small.
King Stephen increased the number of earls to reward those loyal to him in his war with his cousin Empress Matilda. He gave some earls the right to hold royal castles or control the sheriff and soon other earls assumed these rights themselves. By the end of his reign, some earls held courts of their own and even minted their own coins, against the wishes of the king.
It fell to Stephen's successor Henry II to again curtail the power of earls. He took back the control of royal castles and even demolished castles that earls had built for themselves. He did not create new earls or earldoms. No earl was allowed to remain independent of royal control.
The English kings had found it dangerous to give additional power to an already powerful aristocracy, so gradually sheriffs assumed the governing role. The details of this transition remain obscure, since earls in more peripheral areas, such as the Scottish Marches and Welsh Marches and Cornwall, retained some viceregal powers long after other earls had lost them. The loosening of central authority during the Anarchy also complicates any smooth description of the changeover.
By the 13th century, earls had a social rank just below the king and princes, but were not necessarily more powerful or wealthier than other noblemen. The only way to become an earl was to inherit the title or marry into one—and the king reserved a right to prevent the transfer of the title. By the 14th century, creating an earl included a special public ceremony where the king personally tied a sword belt around the waist of the new earl, emphasizing the fact that the earl's rights came from him.
Earls still held influence and as "companions of the king", were regarded as supporters of the king's power. They showed that power for the first time in 1327 when they deposed Edward II. They would later do the same with other kings of whom they disapproved. Still, the number of earls remained the same until 1337 when Edward III declared that he intended to create six new earldoms.
Earls, land and titles.
A loose connection between earls and shires remained for a long time after authority had moved over to the sheriffs. An official defining characteristic of an earl still consisted of the receipt of the "third penny", one-third of the revenues of justice of a shire, that later became a fixed sum. Thus every earl had an association with some shire, and very often a new creation of an earldom would take place in favour of the county where the new earl already had large estates and local influence.
Also, due to the association of earls and shires, the medieval practice could remain somewhat loose regarding the precise name used: no confusion could arise by calling someone earl of a shire, earl of the county town of the shire, or earl of some other prominent place in the shire; these all implied the same. So there were the "earl of Shrewsbury" (Shropshire), "earl of Arundel", "earl of Chichester" (Sussex), "earl of Winchester" (Hampshire), etc.
In a few cases the earl was traditionally addressed by his family name, e.g. the "earl Warenne" (in this case the practice may have arisen because these earls had little or no property in Surrey, their official county). Thus an earl did not always have an intimate association with "his" county. Another example comes from the earls of Oxford, whose property largely lay in Essex. They became earls of Oxford because earls of Essex and of the other nearby shires already existed.
Eventually the connection between an earl and a shire disappeared, so that in the present day a number of earldoms take their names from towns, mountains, or simply surnames. Nevertheless, some consider that the earldoms named after counties (or county towns) retain more prestige.
Scotland.
The oldest earldoms in Scotland (with the exception of the Earldom of Dunbar and March) originated from the office of mormaer, such as the Mormaer of Fife, of Strathearn, etc.; later earldoms developed by analogy.
Coronet.
A British earl is entitled to a coronet bearing eight strawberry leaves (four visible) and eight silver balls (or pearls) around the rim (five visible). The actual coronet is mostly worn on certain ceremonial occasions, but an Earl may bear his coronet of rank on his coat of arms above the shield.
Former Prime Ministers.
An earldom became, with a few exceptions, the default peerage to which a former Prime Minister was elevated. However the last Prime Minister to accept an earldom was Harold Macmillan, who became Earl of Stockton in 1984. In the 1970s life peerages became the norm for former Prime Ministers, though none has accepted any peerage since Margaret Thatcher in 1992.
Scandinavia.
Norway.
In later medieval Norway, the title of "jarl" was the highest rank below the king. The "jarl" was the only one, beside the king himself, who was entitled to have a "hird" (large armed retinue). There was usually no more than one "jarl" in mainland Norway at any one time, sometimes none. The ruler of the Norwegian dependency of Orkney held the title of "jarl", and after Iceland had acknowledged Norwegian overlordship in 1261, a "jarl" was sent there as well as the king's high representative. In mainland Norway, the title of "jarl" was usually used for one of two purposes:
In 1237, "jarl" Skule Bårdsson was given the rank of duke ("hertug"). This was the first time this title had been used in Norway, and meant that the title "jarl" was no longer the highest rank below the king. It also heralded the introduction of new noble titles from continental Europe, which were to replace the old Norse titles. The last "jarl" in mainland Norway was appointed in 1295.
Some Norwegian jarls:
Sweden.
The usage of the title in Sweden was similar to Norway's. Known as jarls from the 12th and 13th century were Birger Brosa, Jon Jarl, Folke Birgersson, Charles the Deaf, Ulf Fase, and the most powerful of all jarls and the last to hold the title, Birger Jarl.
Iceland.
Only one person ever held the title of Earl (or Jarl) in Iceland. This was Gissur Þorvaldsson, who was made Earl of Iceland by King Haakon IV of Norway for his efforts in bringing Iceland under Norwegian kingship during the Age of the Sturlungs.

</doc>
<doc id="58250" url="https://en.wikipedia.org/wiki?curid=58250" title="United States Department of Health and Human Services">
United States Department of Health and Human Services

The United States Department of Health and Human Services (HHS), also known as the Health Department, is a cabinet-level department of the U.S. federal government with the goal of protecting the health of all Americans and providing essential human services. Its motto is "Improving the health, safety, and well-being of America". Before the separate federal Department of Education was created in 1979, it was called the Department of Health, Education, and Welfare (HEW).
History.
Federal Security Agency.
The Federal Security Agency (FSA) was established on July 1, 1939, under the Reorganization Act of 1939, P.L. 76-19. The objective was to bring together in one agency all Federal programs in the fields of health, education, and social security. The first Federal Security Administrator was Paul V. McNutt.
The new agency originally consisted of the following major components: (1) Office of the Administrator, (2) Public Health Service (PHS), (3) Office of Education, (4) Civilian Conservation Corps, and (5) Social Security Board.
Post-WWII.
Organizational Changes
When the war ended, President Truman moved to "strengthen the arm of the Federal Government for better integration of services in the fields of health, education, and welfare."
Unlike statutes authorizing the creation of other executive departments, the contents of Reorganization Plan No. 1 of 1953 were never properly codified within the United States Code, although Congress did codify a later statute ratifying the Plan. Today, the Plan is included as an appendix to Title 5 of the United States Code. The result is that HHS is the only executive department whose statutory foundation today rests on a confusing combination of several codified and uncodified statutes.
Department of Health, Education, and Welfare.
The Department of Health, Education, and Welfare (HEW) was created on April 11, 1953, when Reorganization Plan No. 1 of 1953 became effective. HEW thus became the first new Cabinet-level department since the Department of Labor was created in 1913. The Reorganization Plan abolished the FSA and transferred all of its functions to the Secretary of HEW and all components of the Agency to the Department. The first Secretary of HEW was Oveta Culp Hobby, a native of Texas, who had served as Commander of the Women's Army Corps in World War II and was editor and publisher of the "Houston Post". Sworn in on April 11, 1953, as Secretary, she had been FSA Administrator since January 21, 1953.
The six major program-operating components of the new Department were the Public Health Service, the Office of Education, the Food and Drug Administration, the Social Security Administration, the Office of Vocational Rehabilitation, and St. Elizabeth's Hospital. The Department was also responsible for three Federally-aided corporations: Howard University, the American Printing House for the Blind, and the Columbia Institution for the Deaf (Gallaudet College since 1954).
List of Secretaries of Health, Education, and Welfare
Department of Health and Human Services.
The Department of Health, Education, and Welfare was renamed the Department of Health and Human Services (HHS) in 1979, when its education functions were transferred to the newly created United States Department of Education under the Department of Education Organization Act. HHS was left in charge of the Social Security Administration, agencies constituting the Public Health Service, and Family Support Administration.
In 1995, the Social Security Administration was removed from the Department of Health and Human Services, and established as an independent agency of the executive branch of the United States Government.
HHS is administered by the Secretary of Health and Human Services, who is appointed by the President with the advice and consent of the Senate. The United States Public Health Service (PHS) is the main division of the HHS and is led by the Assistant Secretary for Health. The current Secretary, Sylvia Mathews Burwell, was sworn in on June 9, 2014.
The United States Public Health Service Commissioned Corps, the uniformed service of the PHS, is led by the Surgeon General who is responsible for addressing matters concerning public health as authorized by the Secretary or by the Assistant Secretary of Health in addition to his or her primary mission of administering the Commissioned Corps.
Office of Inspector General.
The Office of the Inspector General (OIG) investigates criminal activity for HHS. The special agents who work for OIG have the same title series "1811", training and authority as other federal criminal investigators, such as the FBI, ATF, DEA and Secret Service. However, OIG Special Agents have special skills in investigating white collar crime related to Medicare and Medicaid fraud and abuse. Organized crime has dominated the criminal activity relative to this type of fraud.
HHS-OIG investigates tens of millions of dollars in Medicare fraud each year. In addition, OIG will continue its coverage of all 50 states and the District of Columbia by its multi-agency task forces (PSOC Task Forces) that identify, investigate, and prosecute individuals who willfully avoid payment of their child support obligations under the Child Support Recovery Act.
HHS-OIG agents also provide protective services to the Secretary of HHS, and other department executives as necessary.
In 2002, the department released Healthy People 2010, a national strategic initiative for improving the health of Americans.
With the passage of the Fraud Enforcement and Recovery Act of 2009 of 2009, and the Affordable Care Act of 2010, the Office of the Inspector General has taken an emboldened stance against healthcare related non-compliance, most notably for violations of Stark Law and the Anti-Kickback Statute.
In 2015, the OIG issued a fraud alert as a warning to hospitals and healthcare systems to monitor and comply with their physician compensation arrangements.
Recent years have seen dramatic increases in both the number and the amounts of Stark Law violation settlements, prompting healthcare experts to identify a need for automated solutions that manage physician arrangements by centralizing necessary information with regard to physician-hospital integration. Contract Management software companies such as Meditract provide options for health systems to organize and store physician contracts. Ludi Inc introduced DocTime Log®, an SaaS solution that specifically addresses this growing concern, automating physician time logging in compliance with contract terms to eliminate Stark Law and Anti-Kickback Statute violations.
Strengthening Communities Fund.
In June 2010 the Department of Health and Human Services created the Strengthening Communities Fund as part of the American Recovery and Reinvestment Act. The fund was appropriated $50 million to be given as grants to organizations in the United States who were engaged in Capacity Building programs. The grants were given to two different types of capacity builders:
and building up nonprofit organization's abilities to tackle economic problems. State, Local and Tribal governments can receive up to $250,000 in two year grants
Organization.
Internal Structure.
The Department of Health and Human Services is led by the United States Secretary of Health and Human Services, a member of the United States Cabinet appointed by the President of the United States with the consent of the United States Senate. The Secretary is assisted in managing the Department by the Deputy Secretary of Health and Human Services, who is also appointed by the President. The Secretary and Deputy Secretary are further assisted by seven Assistant Secretaries, who serve as top Departmental administrators.
Several agencies within HHS are components of the Public Health Service (PHS), including AHRQ, ASPR, ATSDR, CDC, FDA, HRSA, IHS, NIH, SAMHSA, OGHA, and OPHS.
Budget and finances.
The Department of Health and Human Services was authorized a budget for Fiscal Year 2015 of $1.020 trillion. The budget authorization is broken down as follows:
Historical Budgets.
HHS.Gov provides complete details on current and historical budgets for that agency. Budgets for fiscal years prior to 2014 are archived by Archive-It as requested by HHS.
Quick Links: FY2016, FY2015, FY2014, FY2013, FY2012, FY2011, FY2010, FY2009, All HHS budget collections on Archive-It
Programs.
The Department of Health and Human Services' administers 115 programs across its 11 operating divisions. Some highlights include:
Freedom of Information Act processing performance.
In the latest Center for Effective Government analysis of 15 federal agencies which receive the most Freedom of Information Act (United States) (FOIA) requests published in 2015 (using 2012 and 2013 data, the most recent years available), the DHHS ranked second to last, earning an F by scoring 57 out of a possible 100 points, largely due to a low score on its particular disclosure rules. It had deteriorated from a D- in 2013.
Health care reform.
The 2010 United States federal budget established a reserve fund of more than $630 billion over 10 years to finance fundamental reform of the health care system.

</doc>
<doc id="58251" url="https://en.wikipedia.org/wiki?curid=58251" title="Nickel–metal hydride battery">
Nickel–metal hydride battery

A nickel–metal hydride battery, abbreviated NiMH or Ni–MH, is a type of rechargeable battery. The chemical reaction at the positive electrode is similar to that of the nickel–cadmium cell (NiCd), with both using nickel oxyhydroxide (NiOOH). However, the negative electrodes use a hydrogen-absorbing alloy instead of cadmium. A NiMH battery can have two to three times the capacity of an equivalent size NiCd, and its energy density can approach that of a lithium-ion battery.
History.
Work on NiMH batteries began at the Battelle-Geneva Research Center following the technology's invention in 1967. It was based on sintered Ti2Ni+TiNi+x alloys and NiOOH-electrodes. Development was sponsored over nearly two decades by Daimler-Benz and by Volkswagen AG within Deutsche Automobilgesellschaft, now a subsidiary of Daimler AG. The batteries' specific energy reached 50 W·h/kg (180 kJ/kg), power density up to 1000 W/kg and a life of 500 charge cycles (at 100% depth of discharge). Patent applications were filed in European countries (priority: Switzerland), the United States, and Japan. The patents transferred to Daimler-Benz.
Interest grew in the 1970s with the commercialisation of the nickel–hydrogen battery for satellite applications. Hydride technology promised an alternative, less bulky way to store the hydrogen. Research carried out by Philips Laboratories and France's CNRS developed new high-energy hybrid alloys incorporating rare earth metals for the negative electrode. However, these suffered from alloy instability in alkaline electrolyte and consequently insufficient cycle life. In 1987, Willems and Buschow demonstrated a successful battery based on this approach (using a mixture of La0.8Nd0.2Ni2.5Co2.4Si0.1) which kept 84% of its charge capacity after 4000 charge–discharge cycles. More economically viable alloys using mischmetal instead of lanthanum were soon developed. Modern NiMH cells were based on this design. The first consumer grade NiMH cells became commercially available in 1989.
In 1998, Ovonic Battery Co. improved the Ti–Ni alloy structure and composition and patented its innovations.
In 2008, more than two million hybrid cars worldwide were manufactured with NiMH batteries.
In the European Union and due to its Battery Directive, nickel–metal hydride batteries replaced Ni–Cd batteries for portable consumer use.
About 22% of portable rechargeable batteries sold in Japan in 2010 were NiMH. In Switzerland in 2009, the equivalent statistic was approximately 60%. This percentage has fallen over time due to the increase in manufacture of lithium-ion batteries: in 2000, almost half of all portable rechargeable batteries sold in Japan were NiMH.
In 2015 BASF produced a modified microstructure that helped make NiMH batteries more durable, in turn allowing changes to the cell design that saved considerable weight, allowing the gravimetric energy density to reach 140 watt-hours per kilogram.
Electrochemistry.
The negative electrode reaction occurring in a NiMH cell is:
The charge reaction is read left-to-right and the discharge reaction is read right-to-left.
On the positive electrode, nickel oxyhydroxide, NiO(OH), is formed:
The metal M in the negative electrode of a NiMH cell is an intermetallic compound. Many different compounds have been developed for this application, but those in current use fall into two classes. The most common is AB5, where A is a rare earth mixture of lanthanum, cerium, neodymium, praseodymium and B is nickel, cobalt, manganese, or aluminium. Some cells use higher-capacity negative electrode materials based on AB2 compounds, where A is titanium or vanadium and B is zirconium or nickel, modified with chromium, cobalt, iron, or manganese. Any of these compounds serve the same role, reversibly forming a mixture of metal hydride compounds.
When overcharged at low rates, oxygen produced at the positive electrode passes through the separator and recombines at the surface of the negative. Hydrogen evolution is suppressed and the charging energy is converted to heat. This process allows NiMH cells to remain sealed in normal operation and to be maintenance-free.
NiMH cells have an alkaline electrolyte, usually potassium hydroxide. The positive electrode is nickel hydroxide and the negative electrode is hydrogen ions or protons. The hydrogen ions are stored in a metal hydride structure that is the electrode. For separation hydrophilic polyolefin nonwovens are used.
Charge.
Charging voltage is in the range of 1.4–1.6 V/cell. In general, a constant-voltage charging method cannot be used for automatic charging. When fast charging, it is advisable to charge the NiMH cells with a smart battery charger to avoid overcharging, which can damage cells. A NiCd charger is not a substitute for an automatic NiMH charger.
Trickle charging.
The simplest of the safe charging methods is with a fixed low current, with or without a timer. Most manufacturers claim that overcharging is safe at very low currents, below 0.1 C (C/10) (where C is the current equivalent to the capacity of the battery divided by one hour). The Panasonic NiMH charging manual warns that overcharging for long enough can damage a battery and suggests limiting the total charging time to 10 to 20 hours.
Duracell further suggests that a trickle charge at C/300 can be used for batteries that must be kept in a fully charged state. Some chargers do this after the charge cycle, to offset natural self-discharge. A similar approach is suggested by Energizer, which indicates that self-catalysis can recombine gas formed at the electrodes for charge rates up to C/10. This leads to cell heating. The company recommends C/30 or C/40 for indefinite applications where long life is important. This is the approach taken in emergency lighting applications where the design remains essentially the same as in older NiCd units, except for an increase in the trickle charging resistor value.
Panasonic's handbook recommends that NiMH batteries on standby be charged by a lower duty cycle approach, where a pulse of a higher current is used whenever the battery's voltage drops below This can extend battery life and use less energy.
Δ"V" charging method.
In order to prevent cell damage, fast chargers must terminate their charge cycle before overcharging occurs. One method is to monitor the change of voltage with time. When the battery is fully charged the voltage across its terminals drops slightly. The charger can detect this and stop charging. This method is often used with nickel–cadmium cells which display a large voltage drop at full charge. However, the voltage drop is much less pronounced for NiMH and can be non-existent at low charge rates, which can make the approach unreliable.
Another option is to monitor the change of voltage with respect to time and stop when this becomes zero, but this risks premature cutoffs. With this method, a much higher charging rate can be used than with a trickle charge, up to 1 C. At this charge rate, Panasonic recommends to terminate charging when the voltage drops 5–10 mV per cell from the peak voltage. Since this method measures the voltage across the battery, a constant current (rather than a constant voltage) charging circuit is used.
Δ"T" temperature charging method.
The temperature change method is similar in principle to the Δ"V" method. Because the charging voltage is nearly constant, constant-current charging delivers energy at a near-constant rate. When the cell is not fully charged, most of this energy is converted to chemical energy. However, when the cell reaches full charge, most of the charging energy is converted to heat. This increases the rate of change of battery temperature, which can be detected by a sensor such as a thermistor. Both Panasonic and Duracell suggest a maximum rate of temperature increase of per minute. Using a temperature sensor allows an absolute temperature cutoff, which Duracell suggests at With both the Δ"T" and the Δ"V" charging methods, both manufacturers recommend a further period of trickle charging to follow the initial rapid charge.
Safety.
A resettable fuse in series with the cell, particularly of the bimetallic strip type, increases safety. This fuse opens if either the current or the temperature gets too high.
Modern NiMH cells contain catalysts to handle gases produced by over-charging (2 H2 + O2 — catalyst → 2 H2O). However, this only works with overcharging currents of up to 0.1 C (nominal capacity divided by ten hours). This reaction causes batteries to heat, ending the charging process. Some quick chargers have a cooling fan.
A method for very rapid charging called in-cell charge control involves an internal pressure switch in the cell, which disconnects the charging current in the event of overpressure.
One inherent risk with NiMH chemistry is that overcharging causes hydrogen buildup, potentially rupturing the cell. Therefore, cells have a vent to release the gas in the event of serious overcharging.
Nickel metal hydride batteries are made of environmentally friendly materials. The batteries contain only mildly toxic substances and are recyclable.
Loss of capacity.
Memory effect from repeated partial discharge can occur, but is reversible through charge cycling.
Discharge.
A fully charged cell supplies an average 1.25 V/cell during discharge, declining to about 1.0–1.1 V/cell (further discharge may cause permanent damage in the case of multi-cell packs, due to polarity reversal). Under a light load (0.5 ampere), the starting voltage of a freshly charged AA NiMH cell in good condition is about 1.4 volts.
Over-discharge.
Complete discharge can cause reverse polarity in one or more cells, which can permanently damage them. This situation can occur in the common arrangement of four AA cells in series in a digital camera, where one completely discharges before the others due to small differences in capacity among the cells. When this happens, the good cells start to drive the discharged cell in reverse. Some cameras, GPS receivers and PDAs detect the safe end-of-discharge voltage of the series cells and auto-shutdown, but devices such as flashlights and some toys do not. A single cell driving a load or a cell connected in parallel to other cells cannot suffer from polarity reversal, because no other cells are present.
Irreversible damage from polarity reversal is a particular danger, even when a low voltage threshold cutout is employed, should the cells vary in temperature. This is because capacity significantly declines as the cells are cooled. This results in a lower voltage under load of the colder cells.
Self-discharge.
NiMH cells historically had a somewhat higher self-discharge rate (equivalent to internal leakage) than NiCd cells. The self-discharge rate varies greatly with temperature, where lower storage temperature leads to slower discharge rate and longer battery life. The self-discharge is on the first day and stabilizes around per day at room temperature. But at it is approximately three times as high.
Low self-discharge.
The low self-discharge nickel–metal hydride battery (LSD NiMH) has a significantly lower rate of self-discharge. The innovation was introduced in 2005 by Sanyo, under their Eneloop brand. By using an improved electrode separator and improved positive electrode, manufacturers claim the cells retain 70% to 85% of their capacity when stored one year at , compared to about half for normal NiMH batteries. They are otherwise similar to other NiMH batteries, and can be charged in the typical chargers. These cells are marketed as "hybrid", "ready-to-use" or "pre-charged" rechargeables. Retention of charge depends in large part on the battery's impedance or internal resistance (the lower the better), and on its physical size and charge capacity.
Separators keep the two electrodes apart to slow electrical discharge while allowing the transport of ionic charge carriers that close the circuit during the passage of current. High quality separators are critical for battery performance.
Thick separators are one way to reduce self-discharge, but take up space and reduce capacity; while thin separators tend to raise the self-discharge rate. Some batteries may have overcome this tradeoff using thin separators with more precise manufacturing and by using a more advanced sulfonated polyolefin separator.
Low self-discharge cells have lower capacity than standard NiMH cells because of the separator's larger volume. The highest-capacity low-self-discharge AA cells have 2500 mAh capacity, compared to 2700 mAh for high-capacity AA NiMH cells.
Compared to other battery types.
NiMH cells are often used in digital cameras and other high drain devices, where over the duration of single charge use they outperform primary (such as alkaline) batteries.
NiMH cells are advantageous for high current drain applications, largely due to their lower internal resistance. Typical alkaline AA size batteries, which offer approximately 2600 mA·h capacity at low current demand (25 mA), provide only 1300 mA·h capacity with a 500 mA load. Digital cameras with LCDs and flashlights can draw over 1000 mA, quickly depleting them. NiMH cells can deliver these current levels without similar loss of capacity.
Certain devices that were designed to operate using primary alkaline chemistry (or zinc–carbon/chloride) cells will not function with NiMH cells. However most devices compensate for the voltage drop of an alkaline battery as it discharges down to about one volt. Low internal resistance allows NiMH cells to deliver a near-constant voltage until they are almost completely discharged. Battery level indicators overstate the remaining charge if it was designed to read alkaline cells. The voltage of alkaline cells decreases steadily during most of the discharge cycle.
Lithium-ion batteries have a higher specific energy than nickel–metal hydride batteries, but they are significantly more expensive.
Applications.
Consumer electronics.
NiMH batteries have replaced NiCd for many roles, notably small rechargeable batteries. NiMH batteries are commonly available in AA (penlight-size) batteries. These have nominal charge capacities (C) of 1.1–2.8 Ah at 1.2 V, measured at the rate that discharges the cell in five hours. Useful discharge capacity is a decreasing function of the discharge rate, but up to a rate of around 1×C (full discharge in one hour), it does not differ significantly from the nominal capacity. NiMH batteries nominally operate at 1.2 V per cell, somewhat lower than conventional 1.5 V cells, but will operate many devices designed for that voltage.
Electric vehicles.
Applications of NiMH electric vehicle batteries include all-electric plug-in vehicles such as the General Motors EV1, Honda EV Plus, Ford Ranger EV and Vectrix scooter. Hybrid vehicles such as the Toyota Prius, Honda Insight, Ford Escape Hybrid, Chevrolet Malibu Hybrid and Honda Civic Hybrid also use them.
Stanford R. Ovshinsky invented and patented a popular improvement of the NiMH battery and founded Ovonic Battery Company in 1982. General Motors purchased Ovonics' patent in 1994. By the late 1990s, NiMH batteries were being used successfully in many fully electric vehicles, such as the General Motors EV1 and Dodge Caravan EPIC minivan. In October 2000, the patent was sold to Texaco, and a week later Texaco was acquired by Chevron. Chevron's Cobasys subsidiary provides these batteries only to large OEM orders. General Motors shut down production of the EV1 citing lack of battery availability as a chief obstacle. Cobasys control of NiMH batteries created a patent encumbrance for large automotive NiMH batteries.

</doc>
<doc id="58253" url="https://en.wikipedia.org/wiki?curid=58253" title="Marquess">
Marquess

A marquess (; , ) is a nobleman of hereditary rank in various European peerages and in those of some of their former colonies. The term is also used to translate equivalent Asian styles, as in imperial China and Japan.
In Great Britain and Ireland, the correct spelling of the aristocratic title of this rank is marquess (although for aristocratic titles on the European mainland, the French spelling of marquis is often used in English). In Great Britain and Ireland, the title ranks below a duke and above an earl (see "Marquesses in the United Kingdom"). A woman with the rank of a marquess, or the wife of a marquess, is called a marchioness in Great Britain and Ireland or a marquise elsewhere in Europe. The dignity, rank or position of the title is referred to as a marquisate or marquessate.
The theoretical distinction between a marquess and other titles has, since the Middle Ages, faded into obscurity. In times past, the distinction between a count and a marquess was that the land of a marquess, called a march, was on the border of the country, while a count's land, called a county, often was not. As a result of this, a marquess was trusted to defend and fortify against potentially hostile neighbors and was thus more important and ranked higher than a count. The title is ranked below that of a duke, which was often restricted to the royal family and those that were held in high enough esteem to be granted such a title.
In the German lands, a Margrave was a ruler of an immediate Imperial territory (examples include the Margrave of Brandenburg, the Margrave of Baden and the Margrave of Bayreuth), not simply a nobleman like a marquess or marquis in Western and Southern Europe. German rulers did not confer the title of marquis; holders of marquisates in Central Europe were largely associated with the Italian and Spanish crowns.
Etymology.
The word entered the English language from the Old French "marchis" ("ruler of a border area") in the late 13th or early 14th century. The French word was derived from "marche" ("frontier"), itself descended from the Middle Latin "marca" ("frontier"), from which the modern English words "march" and "mark" also descend. The distinction between governors of frontier territories and interior territories was made as early as the founding of the Roman Empire when some provinces were set aside for administration by the senate and more unpacified or vulnerable provinces were administered by the emperor. The titles "duke" and "count" were similarly distinguished as ranks in the late empire, with "dux" (literally, "leader") being used for a provincial military governor and the rank of "comes" (literally "companion," that is, of the Emperor) given to the leader of an active army along the frontier.
Title in the United Kingdom.
In Great Britain and Ireland, the correct spelling for an English aristocrat of this rank is "marquess". The word "marquess" is unusual in English, ending in "-ess" but referring to a male and not a female. A woman with the rank of a marquess, or the wife of a marquess, is called a marchioness in Great Britain and Ireland, or a marquise elsewhere in Europe. The dignity, rank or position of the title is referred to as a marquisate or marquessate.
The honorific prefix "The Most Honourable" is a form of address that precedes the name of a marquess or marchioness in the United Kingdom.
The rank of marquess was a relatively late introduction to the British peerage: no marcher lords had the rank of marquess, though some were earls. On the evening of the Coronation of Queen Victoria in 1838, the Prime Minister Lord Melbourne explained to her why (from her journals):
"I spoke to Ld M. about the numbers of Peers present at the Coronation, & he said it was quite unprecedented. I observed that there were very few Viscounts, to which he replied "There are very few Viscounts," that they were an old sort of title & not really English; that they came from Vice-Comites; that Dukes & Barons were the only real English titles; — that Marquises were likewise not English, & that people were mere made Marquises, when it was not wished that they should be made Dukes".
Marquesal titles in other European languages.
In Italy the equivalent modern rank (as opposed to "margravio") is that of "marchese", the wife of whom is a "marchesa", a good example of how several languages adopted a new word derived from marquis for the modern style, thus distinguishing it from the old "military" margraves. Even where neither title was ever used domestically, such duplication to describe foreign titles can exist.
Equivalent non-Western titles.
Like other major Western noble titles, marquess or marquis is sometimes used to render certain titles in non-Western languages with their own traditions, even though they are, as a rule, historically unrelated and thus hard to compare. However, they are considered "equivalent" in relative rank.
This is the case with:

</doc>
<doc id="58254" url="https://en.wikipedia.org/wiki?curid=58254" title="Peerages in the United Kingdom">
Peerages in the United Kingdom

The peerage is a legal system historically comprising hereditary titles in the United Kingdom (as elsewhere in Europe), comprising various noble ranks, and forms a constituent part of the British honours system.
The term "peerage" can be used both collectively to refer to the entire body of nobles (or a subdivision thereof), and individually to refer to a specific title (modern English language-style using an initial capital in the former case but not the latter). British peerage title holders are termed peers of the Realm.
Under present custom, only members of the Royal Family are nowadays created hereditary peers; the last non-royal creations of hereditary titles being in the Thatcher era, since when Her Majesty's Government (HMG) (whether Conservative or Labour) has refrained from such recommendations. New Labour, elected to power in 1997, sought to eject all hereditary peers from Parliament but PM Tony Blair relented by allowing only 92 members to remain by legislation enacted in 1999.
The House of Lords's purpose is now that of a revising legislative chamber, scrutinising and improving proposed Parliamentary Bills before their enactment. Its membership for the most part comprises Life Peers, created under the Life Peerages Act 1958, which includes those who can add value in specific areas of expertise in parliamentary debates, as well as former MPs and other political appointees from respective political parties.
Peerages are created by the British monarch, like all Crown honours, being affirmed by Letters Patent affixed with the Great Seal of the Realm. HMG recommends to the Sovereign who to be elevated to the peerage, after external vetting by the House of Lords Appointments Commission.
The Sovereign, traditionally the fount of honour, cannot hold a British peerage (although the British Sovereign, whether male or female, is accorded the style of "Duke of Lancaster"). All British subjects who were neither Royal nor Peers of the Realm were previously termed Commoners, regardless of wealth or other social factors, thus all members of a peer's family are (technically) commoners too; the British system thus differs fundamentally from continental European versions, where entire families, rather than individuals, were ennobled. Nobility in Britain is based on title rather than bloodline, and correspondingly HRH The Princess Royal (Princess Anne) who enjoys Royal status as daughter of The Queen, opted for her children to be Commoners by refusing offers of titles, despite their being grandchildren of the Sovereign ("qv." Peter Phillips and Zara Tindall).
Certain personal privileges are afforded to all peers and peeresses, but the main distinction of a peerage nowadays, apart from access to the House of Lords, is the title and style thereby accorded. Succession claims to existing hereditary peerages are regulated by the House of Lords Committee for Privileges and Conduct and administered by The Crown Office.
Baronage evolution.
The modern-day parliamentary peerage is a continuation of the renamed medieval baronage system which existed in feudal times. The requirement of attending Parliament was both a liability and a privilege for those who held land as a tenant-in-chief from the King "per baroniam", that is to say under the feudal contract a King's Baron was responsible for raising knights and troops for the royal military service. Certain other office-holders such as senior clerics and Freemen of the Cinque Ports were deemed barons.
This right, entitlement or "title", began to be granted by decree in the form of a Writ of Summons from 1265 and by Letters Patent from 1388. Additionally, many holders of smaller fiefdoms "per baroniam" ceased to be summoned to parliament, resulting in baronial status becoming personal rather than territorial. Feudal baronies had always been hereditable by primogeniture, but on condition of payment of a fine, termed "relief", derived from the Latin verb "levo" to lift up, meaning a "re-elevation" to a former position of honour. Baronies and other titles of nobility became unconditionally hereditable on the abolition of feudal tenure by the Tenures Abolition Act of 1660, and non-hereditable titles began to be created in 1876 for Law Lords, and in 1958 for Life Peers.
Peerages.
In the UK, five peerages co-exist, namely:
Ranks.
Peers are of five ranks, in descending order of hierarchy:
Baronets, while holders of hereditary titles, are not peers since baronetcies have never conferred noble status, although socially they came to be regarded as part of the aristocracy. Knights, Dames and holders of other British non-hereditary chivalric orders, decorations, and medals are likewise not peers.
The titles of peers are in the form of "(Rank) (Name of Title)" or "(Rank) of (Name of Title)". The name of the title can either be a place name or a surname. The precise usage depends on the rank of the peerage and on certain other general considerations. Dukes always use "of". Marquesses and Earls whose titles are based on place names normally use "of", while those whose titles are based on surnames normally do not. Viscounts, Barons and Lords of Parliament generally do not use "of". However, there are several exceptions to the rule. For instance, Scottish vicecomital titles theoretically include "of", though in practice it is usually dropped. (Thus, the "Viscount of Falkland" is commonly known as the "Viscount Falkland".)
Geographic association.
A territorial designation is often added to the main peerage title, especially in the case of Barons and Viscounts: for instance, "Baroness Thatcher, of Kesteven in the County of Lincolnshire", or "Viscount Montgomery of Alamein, of Hindhead in the County of Surrey". Any designation after the comma does not form a part of the main title. Territorial designations in titles are not updated with local government reforms, but new creations do take them into account. Thus there is a "Baron Knollys, of Caversham in the County of Oxford" (created in 1902), and a "Baroness Pitkeathley, of Caversham in the Royal County of Berkshire" (created in 1997).
It was once the case that a peer administered the place associated with his title (such as an Earl administering a County as High Sheriff or main landowner), but lordships by tenure have not been commonplace since the early Norman period. The only remaining peerages with certain associated rights over land are the Duchy of Cornwall (place), which appertains to the Dukedom of Cornwall, held by the eldest son and heir to the Sovereign, and the Duchy of Lancaster (place), which regular income (revenue) appertains to the Dukedom of Lancaster, held by the Sovereign whose government owns the capital and all capital gains on disposals. In both cases due to the particular function of bona vacantia in these areas, these titles afford rights encompassing the whole territorial designation of the holder, donated by the holder now to registered charities. Separate estates, smaller than counties, form the bulk of the two duchies.
Hereditary peers.
An hereditary peer is a peer of the realm whose dignity may be inherited; those able to inherit it are said to be "in remainder". Hereditary peerage dignities may be created with writs of summons or by letters patent; the former method is now obsolete. Writs of summons summon an individual to Parliament, in the old feudal tradition, and merely "implied" the existence or creation of an hereditary peerage dignity, which is automatically inherited, presumably according to the traditional medieval rules (male-preference primogeniture, similar to the succession of the British crown). Letters patent explicitly create a dignity and specify its course of inheritance (usually agnatic succession, like the Salic Law). Some hereditary titles can pass through and vest in female heirs in a system called coparcenary.
Once created, a peerage dignity continues to exist as long as there are surviving legitimate descendants (or legitimate agnatic descendants) of the first holder, unless a contrary method of descent is specified in the letters patent. Once the heirs of the original peer die out, the peerage dignity becomes extinct. In former times, peerage dignities were often "forfeit" by Acts of Parliament, usually when peers were found guilty of treason. Often, however, the felonious peer's descendants successfully petitioned the Sovereign to restore the dignity to the family. Some dignities, such as the Dukedom of Norfolk, have been forfeit and restored several times. Under the Peerage Act 1963 an individual can disclaim his peerage dignity within one year of inheriting it.
When the holder of a peerage succeeds to the throne, the dignity "merges in the Crown" and ceases to exist.
All hereditary peers in the Peerages of England, Scotland, Great Britain, and the United Kingdom were entitled to sit in the House of Lords, subject only to qualifications such as age and citizenship, but under section 1 of the House of Lords Act 1999 they lost this right. The Act provided that 92 hereditary peers — the Lord Great Chamberlain and the Earl Marshal, along with 90 others exempted through standing orders of the House — would remain in the House of Lords in the interim, pending any reform of the membership to the House. Standing Order 9 provides that those exempted are 75 hereditary peers elected by other peers from and by respective party groups in the House in proportion to their numbers, and fifteen chosen by the whole House to serve as officers of the House.
Representative peers.
From 1707 until 1963 Scottish peers elected 16 representative peers to sit in the House of Lords. Since 1963 they have had the same rights as Peers of the United Kingdom. From 1801 until 1922 Irish peers elected 28 representative peers to sit in the House of Lords. Since 1922, when the Irish Free State became a separate country, no Irish representative peers have been elected, though sitting members retained their seats for life.
Life peers.
The Appellate Jurisdiction Act 1876 and the Life Peerages Act 1958 authorise the regular creation of life peerages, with the right to sit in the House of Lords. Life peers created under both acts are of baronial rank and are always created under letters patent.
Until the formal opening of the Supreme Court of the United Kingdom on 1 October 2009, life peers created under the Appellate Jurisdiction Act were known as "Lords of Appeal in Ordinary" or in common parlance "Law Lords". They performed the judicial functions of the House of Lords and served on the Judicial Committee of the Privy Council. They remained peers for life, but ceased to receive judicial salaries at the age of 75. Under the terms of the Act, there may be no more than 12 Lords of Appeal in Ordinary under the age of 75 at one time. However, after the transfer of the judicial functions of the Lords to the Supreme Court of the United Kingdom, the Act ceased to have meaningful effect.
There is no limit on the number of peerages the Sovereign may create under the Life Peerages Act. Normally life peerages are granted to individuals nominated by political parties or by the House of Lords Appointments Commission, and to honour important public figures such as the Archbishop of Canterbury and the Prime Minister on their retirement.
Under the House of Lords Reform Act 2014 and the House of Lords (Expulsion and Suspension) Act 2015 a life peer may lose membership of the House of Lords permanently in one of four ways:
While these provide for non-membership of the House of Lords, they do not allow a life peer to disclaim their peerage in the same way that a hereditary peer can disclaim theirs.
Styles and titles.
Dukes use "His Grace", Marquesses use "The Most Honourable" and other peers use "The Right Honourable". Peeresses (whether they hold peerages in their own right or are wives of peers) use equivalent styles.
In speech, any peer or peeress except a Duke or Duchess is referred to as "Lord X" or "Lady X". The exception is a "suo jure" baroness (that is, one holding the dignity in her own right, usually a life peeress), who may also be called "Baroness X" in normal speech, though "Lady X" is also common usage. Hence, Baroness Thatcher, a "suo jure" life peeress, was referred to as either "Baroness Thatcher" or "Lady Thatcher". "Baroness" is incorrect for female holders of Scottish Lordships of Parliament, who are not Baronesses; for example, the 21st Lady Saltoun is known as "Lady Saltoun", not "Baroness Saltoun".
A peer is referred to by his peerage even if it is the same as his surname, thus Baron Owen is "Lord Owen" not "Lord David Owen", though such incorrect forms are commonly used.
Some peers, particularly life peers who were well known before their ennoblement, do not use their peerage titles. Others use a combination: for example, the author John Julius Norwich is John Julius Cooper, 2nd Viscount Norwich.
Individuals who use the style "Lord" or "Lady" are not necessarily peers. Children of peers use special titles called courtesy titles. The heir apparent of a duke, a marquess, or an earl generally uses his father's highest lesser peerage dignity as his own. Hence, the Duke of Devonshire's son is called Marquess of Hartington. Such an heir apparent is called a "courtesy peer", but is a commoner until such time as he inherits (unless summoned by a writ in acceleration).
Younger sons of dukes and marquesses prefix "Lord" to their first names as courtesy titles while daughters of dukes, marquesses and earls use "Lady". Younger sons of earls and children of viscounts, barons and lords of Parliament use "The Honourable".
Privilege of peerage.
The privilege of peerage is the body of privileges that belongs to peers, their wives and their unremarried widows. The privilege is distinct from parliamentary privilege, and applies to all peers, not just members of the House of Lords. It still exists, although "occasions of its exercise have now diminished into obscurity."
Although the extent of the privilege has been ill-defined, three features survived to the 20th century: the right to be tried by fellow peers in the Lord High Steward's Court and in the House of Lords (abolished in 1948); the personal right of access to the Sovereign at any time, but this privilege has long been obsolete; and the right to be exempt from civil arrest (a privilege that has been used only twice since 1945). All privileges of a peerage is lost if a peer disclaims his or her peerage under the Peerage Act 1963.
History.
When William of Normandy conquered England, he divided the nation into many "manors", the owners of which came to be known as barons; those who held many manors were known as "greater barons", while those with fewer manors were the "lesser barons". When Kings summoned their barons to Royal Councils, the greater barons were summoned individually by the Sovereign, lesser barons through sheriffs. In 1254, the lesser barons ceased to be summoned, and the body of greater barons evolved into the House of Lords. Since the Crown was itself a hereditary dignity, it seemed natural for seats in the upper House of Parliament to be so as well. By the beginning of the 14th century, the hereditary characteristics of the Peerage were well developed. The first peer to be created by patent was Lord Beauchamp of Holt in the reign of Richard II.
The modern peerage system is a vestige of the custom of English kings in the 12th and 13th centuries; in the late 14th century, this right (or "title") began to be granted by decree, and titles also became inherited with the rest of an estate under the system of primogeniture. Non-hereditary positions began to be created again in 1867 for Law Lords, and 1958 generally.
The ranks of baron and earl date to feudal, and perhaps Anglo-Saxon, times. The ranks of duke and marquess were introduced in the 14th century, and that of viscount in the 15th century. While peerages for life were often created in the early days of the peerage, their regular creation was not provided for by Act of Parliament until the Appellate Jurisdiction Act 1876.
Counterparts.
Other feudal monarchies equally held a similar system, grouping high nobility of different rank titles under one term, with common privileges and/or in an assembly, sometimes legislative and/or judicial.
Itō Hirobumi and the other Meiji leaders deliberately modeled the Japanese House of Peers on the House of Lords, as a counterweight to the popularly elected House of Representatives ("Shūgiin").
In France, the system of pairies (peerage) existed in two different versions: the exclusive 'old' in the French kingdom, in many respects an inspiration for the English and later British practice, and the very prolific Chambre des Pairs under the Bourbon Restoration (1814–1848).
In Spain and Portugal, the closest equivalent title was Grandee; in Hungary, Magnat.
In the Kingdom of Sicily a peerage was instituted in 1812 in connection with the abolition of feudalism: peers were nominated based on the taxable incomes of their formerly-feudal estates.
In the Holy Roman Empire, instead of an exclusive aristocratic assembly, the Imperial Diet being its legislative body, membership of which, expressed by the title Prince of the Holy Roman Empire, was granted to allied princely families, and various minor ones, Princes of the Church (parallel to the Lords Spiritual) and in some cases restricted to a collective 'curiate' vote in a 'bench', such as the Grafenbank.
In the medieval Irish nobility, Gaelic nobles were those presented with the White Wand or "slat" in a formal ceremony, and presented it by another noble. It was the primary symbol of lordship and effectively reserved only for the three tiers of kings (provincial, regional, local) and for those princely and comital families descending from them in control of significant territories. The total number was between 100 and 150 at any time.

</doc>
<doc id="58255" url="https://en.wikipedia.org/wiki?curid=58255" title="Duke">
Duke

A duke (male) (British English: or American English: ) or duchess (female) can either be a monarch ruling over a duchy or a member of the nobility, historically of highest rank below the monarch. The title comes from French "duc", itself from the Latin "dux", 'leader', a term used in republican Rome to refer to a military commander without an official rank (particularly one of Germanic or Celtic origin), and later coming to mean the leading military commander of a province.
During the Middle Ages the title (as "Herzog") signified first among the Germanic monarchies. Dukes were the rulers of the provinces and the superiors of the counts in the cities and later, in the feudal monarchies, the highest-ranking peers of the king. A duke may or may not be, "ipso facto", a member of the nation's peerage: in the United Kingdom and Spain all dukes are/were also peers of the realm, in France some were and some were not, while the term is not applicable to dukedoms of other nations, even where an institution similar to the peerage (e.g., Grandeeship, Imperial Diet, Hungarian House of Magnates) existed.
During the 19th century many of the smaller German and Italian states were ruled by Dukes or Grand Dukes. But at present, with the exception of the Grand Duchy of Luxembourg, there are no dukes ruling as monarchs. Duke remains the highest hereditary title (aside from titles borne by the reigning or formerly reigning dynasty) in Portugal (though now a republic), Spain, and the United Kingdom. In Sweden, members of the Royal Family are given a personal dukedom at birth. The Pope, as a temporal sovereign, has also, though rarely, granted the title of Duke or Duchess to persons for services to the Holy See. In some realms the relative status of "duke" and "prince", as titles borne by the nobility rather than by members of reigning dynasties, varied—e.g., in Italy and the Netherlands.
A woman who holds in her own right the title to such duchy or dukedom, or is the wife of a duke, is normally styled duchess. Queen Elizabeth II, however, is known by tradition as Duke of Normandy in the Channel Islands and Duke of Lancaster in Lancashire.
Duchy versus dukedom.
A duchy is the territory or geopolitical entity ruled by a duke. The term implies a territorial domain, within which the duke has actual subjects or significant land holdings, with respect to which the duke has or had unique legal privileges, e.g., sovereignty or manorial rights or entitlement to certain duties or income from residents (e.g., the "corvée"), etc. A dukedom is the title or status of a duke, a rank in the present or past nobility, and is not necessarily attached to a duchy. A few examples exist today: The Grand Duchy of Luxembourg is a fully independent state and its head, the Grand Duke, is a sovereign monarch reigning over his Luxembourgish subjects. The Duke of Cornwall holds both the dukedom (title) and duchy (estate holdings), the latter being the source of his personal income; those living on the ducal estates are subjects of the British sovereign and owe neither fealty nor services to the duke "per se". In Scotland the male heir apparent to the British crown is always the Duke of Rothesay as well, but this is a dukedom (title) without a duchy. Similarly, the British monarch rules and owns the Duchy of Lancaster as Duke of Lancaster, but it is held separately from the Crown, with the income of the duchy estates providing the Sovereign's Privy Purse. The Channel Islands are two of the three remaining Crown Dependencies, the last vestiges of the lands of the Duchy of Normandy. The Islanders in their loyal toast will say "La Reine, notre Duc" (The Queen, Our Duke). Though the title was apparently renounced under the Treaty of Paris in 1259, the Crown still maintains that the title is retained: "In 1106, William's youngest son Henry I seized the Duchy of Normandy from his brother Robert; since that time, the English Sovereign has always held the title Duke of Normandy," and that "By 1205, England had lost most of its French lands, including Normandy. However, the Channel Islands, part of the lost Duchy, remained a self-governing possession of the English Crown. While the islands today retain autonomy in government, they owe allegiance to The Queen in her role as Duke of Normandy."
Middle Ages.
During the Middle Ages, after Roman power in Western Europe collapsed, the title was still employed in the Germanic kingdoms, usually to refer to the rulers of old Roman provinces.
Albania.
In 1332, Robert of Taranto succeeded his father, Philip. Robert's uncle, John, did not wish to do him homage for the Principality of Achaea, so Robert received Achaea from John in exchange for 5,000 ounces of gold and the rights to the diminished Kingdom of Albania. John took the style of Duke of Durazzo (today Durrës).
In 1368, Durazzo fell to Karl Thopia, who was recognized by Venice as "Prince of Albania".
Visigoths.
The Visigoths retained the Roman divisions of their kingdom in the Iberian Peninsula and it seems that dukes ruled over these areas. They were the most powerful landowners and, along with the bishops, elected the king, usually from their own midst. They were the military commanders and in this capacity often acted independently from the king, most notably in the latter period before the Muslim invasions.
The army was structured decimally with the highest unit, the thiufa, probably corresponding to about 1,000 people from each "civitas" (city district). The cities were commanded by counts, who were in turn answerable to the dukes, who called up the "thiufae" when necessary.
Lombards.
When the Lombards entered Italy, the Latin chroniclers called their war leaders "duces" in the old fashion. These leaders eventually became the provincial rulers, each with a recognized seat of government. Though nominally loyal to the king, the concept of kingship was new to the Lombards and the dukes were highly independent, especially in central and southern Italy, where the Duke of Spoleto and the Duke of Benevento were "de facto" sovereigns. In 575, when Cleph died, a period known as the Rule of the Dukes, in which the dukes governed without a king, commenced. It lasted only a decade before the disunited magnates, in order to defend the kingdom from external attacks, elected a new king and even diminished their own duchies to provide him with a handsome royal demesne.
The Lombard kings were usually drawn from the duke pool when the title was not hereditary. The dukes tried to make their own offices hereditary. Beneath them in the internal structure were the counts and gastalds, a uniquely Lombard title initially referring to judicial functions, similar to a count's, in provincial regions
Franks.
The Franks employed dukes as the governors of Roman provinces, though they also led military expeditions far from their duchies. The dukes were the highest-ranking officials in the realm, typically Frankish (whereas the counts were often Gallo-Roman), and formed the class from which the kings' generals were chosen in times of war. The dukes met with the king every May to discuss policy for the upcoming year, the so-called Mayfield.
In Burgundy and Provence, the titles of patrician and prefect were commonly employed instead of duke, probably for historical reasons relating to the greater Romanization of those provinces. But the titles were basically equivalent.
In late Merovingian Gaul, the mayors of the palace of the Arnulfing clan began to use the title "dux et princeps Francorum": "duke and prince of the Franks". In this title, "duke" implied supreme military control of the entire nation ("Francorum", the Franks) and it was thus used until the end of the Carolingian dynasty in France in 987.
England.
Anglo-Saxon times.
The highest political division beneath that of kingdom among the Anglo-Saxons was the ealdormanry and, while the title ealdorman was replaced by the Danish "eorl" (later earl) over time, the first ealdormen were referred to as "duces" (the plural of the original Latin "dux") in the chronicles. So in Anglo-Saxon England, where the Roman political divisions were largely abandoned, the grade of duke was retained as supreme landlord after the king. But after the Norman conquest, their power and regional jurisdiction was limited to that of the Norman counts.
Late medieval times.
Edward III of England created the first three English dukedoms (Cornwall, Lancaster, and Clarence) by naming his eldest son Edward, the Black Prince, as Duke of Cornwall in 1337. Upon the death of the Black Prince, the duchy of Cornwall passed to his nine-year-old son, who would eventually succeed his grandfather as Richard II.
The duchy of Lancaster was created by Edward III in 1351 for Henry of Grosmont, but became extinct upon the duke's death in 1361. The following year, Edward III bestowed the title (2nd creation) on his fourth son, John of Gaunt, who was also married to the first duke's daughter. On the same day Edward III also created his second son, Lionel of Antwerp, as Duke of Clarence.
All five of Edward III's surviving sons eventually became dukes. In 1385, ten years after their father's death, his heir Richard II created dukedoms for his last two uncles on the same day. Thomas of Woodstock was named Duke of Gloucester and Edmund of Langley became Duke of York, thereby founding the House of York, which later fought for the throne with John of Gaunt's Lancastrian descendants during the Wars of the Roses.
By 1483, a total of 16 ducal titles had been created: Cornwall, Lancaster, Clarence, Gloucester, York, Ireland, Hereford, Aumale, Exeter, Surrey, Norfolk, Bedford, Somerset, Buckingham, Warwick and Suffolk. Some became extinct, others had multiple creations, and some had merged with the crown upon the holder's accession to the throne. When the Plantagenet dynasty came to an end at the Battle of Bosworth Field on 22 August 1485, only four ducal titles remained extant, of which two were now permanently associated with the crown. John de la Pole was Duke of Suffolk and John Howard was Duke of Norfolk (2nd creation), while the duchy of Cornwall was reserved as a title and source of income for the eldest son of the sovereign, and the duchy of Lancaster was now held by the monarch.
Norfolk perished alongside Richard III at Bosworth field, and the title was forfeit. It was restored to his son Thomas thirty years later by Henry VIII, as one of a number of dukes created or recreated by the Tudor dynasty over the ensuing century. England's premier ducal title, Norfolk, remains in the Howard family to this day.
The modern age.
In the 19th century, the sovereign dukes of Parma and Modena in Italy, and of Anhalt, Brunswick-Lüneburg, Nassau, Saxe-Coburg-Gotha, Saxe-Meiningen and Saxe-Altenburg in Germany survived Napoleon's reorganization.
Since the unification of Italy in 1870 and the end of monarchy in Germany in 1918, there have no longer been any reigning dukes in Europe; Luxembourg is ruled by a grand duke, a higher title, just below king.
In the United Kingdom, the inherited position of a duke along with its dignities, privileges, and rights is a dukedom. However, the title of "duke" has never been associated with independent rule in the British Isles: they hold dukedoms, not duchies (excepting the Duchy of Cornwall and the Duchy of Lancaster). Dukes in the United Kingdom are addressed as "Your Grace" and referred to as "His Grace". Currently, there are twenty-seven dukedoms in the Peerage of England, Peerage of Scotland, Peerage of Great Britain, Peerage of Ireland and Peerage of the United Kingdom, held by twenty-four different people (see List of Dukes in order of precedence).
Equivalents in other European languages.
See wikt:en:duke for equivalents in other European languages.
Royal dukes.
Various royal houses traditionally awarded (mainly) dukedoms to the sons and in some cases, the daughters, of their respective sovereigns; others include at least one dukedom in a wider list of similarly granted titles, nominal dukedoms without any actual authority, often even without an estate. Such titles are still conferred on royal princes or princesses in the current European monarchies of Belgium, Spain, Sweden and the United Kingdom.
Other historical cases occurred for example in Denmark, Finland (as a part of Sweden) and France, Portugal and some former colonial possessions such as Brazil and Haiti.
United Kingdom.
In the United Kingdom, ducal titles which have been given within the royal family include Duke of Cornwall, Duke of Lancaster, Duke of Clarence, Duke of York, Duke of Gloucester, Duke of Bedford, Duke of Cumberland, Duke of Cambridge, Duke of Rothesay, Duke of Albany, Duke of Ross, Duke of Edinburgh, Duke of Kent, Duke of Sussex, and Duke of Connaught and Strathearn. Following his abdication in 1936 the former King Edward VIII was given the title Duke of Windsor.
Belgium.
In Belgium, the title of Duke of Brabant (historically the most prestigious in the Low Countries, and containing the federal capital Brussels), if still vacant, has been awarded preferentially to the eldest son and heir apparent of the king, other male dynasts receiving various lower historical titles (much older than Belgium, and in principle never fallen to the Belgian crown), such as Count of Flanders (King Leopold III's so-titled brother Charles held the title when he became the realm's temporary head of state as prince-regent) and Prince of Liège (a secularised version of the historical prince-bishopric; e.g. King Albert II until he succeeded his older brother Baudouin I).
Denmark.
Denmark's kings gave appanages in their twin-duchies of Schleswig-Holstein (now three-fourths of them is part of Germany, but then the Holstein half of it was part of the Holy Roman Empire in personal union with Denmark proper) to younger sons and/or their male-line descendants, with a specific though not sovereign title of Duke, e.g., Duke of Gottorp, Duke of Sonderburg, Duke of Augustenborg, Duke of Franzhagen, Duke of Beck, Duke of Glucksburg and Duke of Norburg.
Iberian peninsula.
When the Christian Reconquista, sweeping the Moors from the former Caliphate of Córdoba and its taifa-remnants, transformed the territory of former Suevic and Visigothic realms into Catholic feudal principalities, none of these warlords was exactly styled Duke. A few (as Portugal itself) started as Count (even if the title of Dux was sometimes added), but soon all politically relevant princes were to use the royal style of King.
Portugal.
In Portugal, the title of Duke was granted for the first time in 1415 to infante Peter and infante Henry, the second and third sons of king John I, following their participation in the successful Conquest of Ceuta. Pedro became the first Duke of Coimbra and Henry the first Duke of Viseu.
From the reign of king Manuel I, the title of Duke of Beja was given to the second son of the monarch. This was changed during the Liberal regime in the 19th century (with queen Maria II), when the first infante (second son of the monarch) got the title of Duke of Porto and the second infante (third son) was known as Duke of Beja.
There are examples of Duke as a subsidiary title, granted to the most powerful noble Houses:
Usually, the title of Duke was granted to relatives of the Royal Family, such as the infantes or natural sons of the monarch. There are exceptions, such as António José de Ávila, who, although not having any relation to the royal family, was given the title of duke of Ávila and Bolama in the 19th Century.
Spain.
Spanish infantes and infantas were usually given a dukedom upon marriage, excepting the heir apparent who is the Prince of Asturias. This title is nowadays not hereditary but carries a Grandeza de España. The current royal duchesses are: HRH the Duchess of Badajoz (Infanta Maria del Pilar), HRH the Duchess of Soria (Infanta Margarita) (although she inherited the title of Duchess of Hernani from her cousin and is second holder of that title), and HRH the Duchess of Lugo (Infanta Elena).
In Spain all the dukes hold the court rank of "Grande", i.e., Grandee of the realm, which had precedence over all other feudatories.
Nordic countries.
The Northern European duchies of Halland, Jutland, Lolland, Osilia and Reval existed in the Middle Ages. The longest-surviving duchy was Schleswig, i.e., "Sonderjylland" (a portion of which later became part of Germany). Its southern neighbor, the duchy of Holstein, in personal union with the Danish crown, was nonetheless always a German principality. The two duchies jointly became a member of the German "Bundesland" as "Schleswig-Holstein" in the 19th century.
In Sweden, medieval duchies of Finland, Södermanland, Skåne, and Halland were some appanages for princes of the reigning dynasty. In modern times almost every province in Sweden was used as the territorial designation for a royal prince's dukedom.
Sweden had a history of making the sons of its kings ruling princes of vast duchies, but this ceased in 1622. Only one non-royal person was ever given a dukedom. Title-wise, however, all Swedish princes since 1772, and princesses since 1980, are given a dukedom for life. Currently, there are two dukes and four duchesses. The territorial designations of these dukedoms refer to six of the Provinces of Sweden.
Key parts of Finland were sometimes under a Duke of Finland during the Swedish reign. Some of the provinces are still considered duchies for the purposes of heraldry.
France and other former monarchies.
See appanage (mainly for the French kingdom) and the list in the geographical section below, which also treats special ducal titles in orders or national significance.
France.
The highest precedence in the realm, attached to a feudal territory, was given to the twelve original pairies (en: "peers"), which also had a traditional function in the royal coronation, comparable to the German imperial archoffices. Half of them were ducal: three ecclesiastical (the six prelates all ranked above the six secular peers of the realm) and three temporal, each time above three counts of the same social estate:
The "Prince-Bishops" with ducal territories among them were:
Later, the Archbishop of Paris was given the title of "duc de Saint-Cloud" with the dignity of peerage, but it was debated if he was an ecclesiastical peer or merely a bishop holding a lay peerage.
The secular dukes in the peerage of the realm were, again in order of precedence:
It should be noted that the theory of the participation of the peers in the coronation was laid down in the late 13th century, when some of the peerage (the Duchy of Normandy and the County of Toulouse) had already been merged in the crown.
At the end of this same century, the king elevated some counties into duchies, a practice that increased up until the Revolution. Many of this duchies were also peerages (the so-called 'new peerages').
Italy, Germany and Austria.
In Italy, Germany and Austria the title of "duke" ("duca" in Italian, and "Herzog" in German) was quite common. As the Holy Roman Empire of the German Nation (HRE) was until its dissolution a feudal structure, most of its Dukes were actually reigning in their lands. As the titles from the HRE were taken over after its dissolution, or in Italy after their territories became independent of the Empire, both countries also had a share of fully sovereign dukes. Also, in Germany in many ducal families every agnate would bear the ducal title of the family as a courtesy title.
In Italy some important sovereign ducal families were the Visconti and the Sforza, who ruled Milan;the Savoia in Piedmont; the Medici of Florence; the Farnese of Parma and Piacenza; the Cybo-Malaspina of Massa; the Gonzaga of Mantua; the Este of Modena and Ferrara. The maritime republics of Venice and Genoa were ruled by elected Doges, a word which comes from the same Latin root as "Duke".
In Germany, important ducal families were the Wittelsbachs in Bavaria, the Welfs in Hannover, the ducal family of Cleves, the Wettins in Saxony (with its Ernestine branch divided into several duchies), the Württembergs, the Mecklenburgs and the Habsburgs in Austria as "Archdukes". In the German Confederation the Nassaus, the Ascanians of Anhalt, the Welf branch of Brunswick and the Ernestine lines of the Saxon duchies were the sovereign ducal families.
Elsewhere in Europe.
Hungary.
In the Kingdom of Hungary no ducal principalities existed but duchies were often formed for members of the dynasty as appanages. During the rule of the Árpád dynasty dukes held territorial powers, some of them even minted coins, but later this title became more often nominal.
These duchies usually were
In the Jagellonian era (1490–1526) only two dukes did not belong to the royal dynasty: John Corvin (the illegitimate son of Matthias Corvinus) and Lőrinc Újlaki (whose father was the king of Bosnia), and both bore the title as royal dukes.
After the Battle of Mohács the Habsburg kings rewarded Hungarian aristocrats (like the Esterházys) with princely titles, but they created these titles as Holy Roman Emperors, not as kings of Hungary.
Greece.
As the Catholic crusaders overran Orthodox Christian parts of the Byzantine empire, they installed several crusader states (see Frangokratia), some of which were of ducal rank:
The Byzantines retained the title "dux", transcribed as "doux" in Greek. As in the later Roman Empire, it remained a military office. In the 10th century, it was given to the military commanders over several "themata" (also known as "katepano"), and in the late 11th century it became used for the governor of a "thema".
In Italy and other western countries, the later Byzantine appanages of the Palaiologan period were sometimes translated as duchies: the Morea, Mesembria, Selymbria and Thessaloniki. However, as these had Greek holders, they were titled "Archon" ("magistrate") or "Despotes".
In the independent Kingdom of Greece, the style of Duke of Sparta was instituted in 1868 upon the birth of Constantine I as a distinct title for the crown prince of Greece.
Slavic and nearby countries.
Generally, confusion reigns whether to translate the usual ruler titles, "knyaz/ knez/ ksiaze" etc. as Prince (analogous to the German Fürst) or as Duke;
Netherlands.
After Belgium and the Netherlands separated in 1830, the title of duke no longer existed in the Netherlands. There is, however, one exception; the title "Hertog van Limburg" ("Duke of Limburg") still exists. This title, however, is an exclusive title for the head of state (the monarch, i.e., the king or queen of the Netherlands).
Post-colonial non-European states.
Empire of Brazil.
In the Empire of Brazil duke was the highest rank for people born outside the imperial house and only three dukedoms were created. Two of these titles were for relatives of Emperor Pedro I: an illegitimate daughter and a brother-in-law who received the title when married to Pedro I's daughter Maria II. The third, given to Luís Alves de Lima e Silva, was the only dukedom created during the reign of Pedro II. None of these titles were hereditary, just like every other title in the Brazilian nobility system.
Haiti.
The royal Christophe dynasty created eight hereditary dukedoms, in rank directly below the nominal princes. They were short-lived and only recognised in the country.
Equivalents.
Like other major Western noble titles, Duke is sometimes used to render (translate) certain titles in non-western languages. "Duke" is used even though those titles are generally etymologically and often historically unrelated and thus hard to compare. However, they are considered roughly equivalent, especially in hierarchic aristocracies such as feudal Japan, useful as an indication of relative rank.
India.
Indian feudal system cannot be fully translated to its European counterparts. The closest equivalent to a Duchy is a large Jagir. Thus, a Jagirdar, Deshmukh, Patil and Zamindar are closely equivalent to a Duke.
China.
During the era of feudalism in Ancient China (Spring and Autumn and the Warring States), the equivalent titles to Grand Marquis or Grand Duke were often granted to the nobility and governors of the individual kingdoms and principalities. Noble titles also existed in subsequent periods.
The Duke of Yansheng noble title was granted to the descendants of Confucius. In 1935, the Nationalist Government changed the title to Sacrificial Official to Confucius (大成至聖先師奉祀官), which still exists as an office of the Republic of China, de facto hereditary.
Nonhereditary dukedoms and other lesser titles were also awarded, sometimes posthumously (see posthumous names), during the imperial period of Chinese history to recognize distinguished civil and military officials without the burdens of supporting a feudal peerage. For example, Emperor Lizong of Song granted the posthumous title Duke of Hui (徽国公) to the Neo-Confucian thinker Zhu Xi.
Indonesia.
The Javanese kingdom of Majapahit, which dominated eastern Java in the 14th and 15th centuries, was divided into "nagara" (provinces). The administration of these "nagara" was entrusted to members of the royal family, who bore the title of "Bhre"—i.e., "Bhra i", "lord of" (the word "bhra" being akin to the Thai "Phra"), followed by the name of the land they were entrusted with: for example a sister of king Hayam Wuruk (r. 1350–1389) was "Bhre Lasem", "lady of Lasem". This system was similar to the Apanage system in Western Europe.
Sultan Agung, king of Mataram in Central Java (r. 1613–1645), would entrust the administration of territories he gradually conquered all over the island of Java, to officials bearing the title of "Adipati", this title is hereditary. Such territories were called "Kadipaten".
The VOC (Dutch East Indies Company), while gradually taking control of Javanese territory, would maintain the existing Mataram administrative structure. "Adipati" were called ""regenten"" in Dutch, and the territories they administered, ""regentschappen"".
In the 19th century, the Javanese term for "regent" was "bupati". French traveller Gérard Louis Domeny de Rienzi mentions "bapati".
The "bupati" have been maintained in the modern Indonesian administrative subdivision structure, heading a "kabupaten", the subdivision of a "provinsi" or province.
The word "Adipati" is still found in the official title of the hereditary dukes Mangkunegara of Surakarta and Paku Alam of Yogyakarta—i.e., "Kanjeng Gusti Pangeran Adipati Arya" (shortened into KGPAA).

</doc>
<doc id="58256" url="https://en.wikipedia.org/wiki?curid=58256" title="Wax">
Wax

Waxes are a diverse class of organic compounds that are hydrophobic, malleable solids near ambient temperatures. They include higher alkanes and lipids, typically with melting points above about 40 °C (104 °F), melting to give low viscosity liquids. Waxes are insoluble in water but soluble in organic, nonpolar solvents. Natural waxes of different types are produced by plants and animals and occur in petroleum.
Chemistry.
Waxes are organic compounds that characteristically consist of long alkyl chains. Synthetic waxes are long-chain hydrocarbons (alkanes or paraffins) that lack substituted functional groups. Natural waxes may contain unsubstituted hydrocarbons, such as higher alkanes, but may also include various types of substituted long chain compounds, such as fatty acids, primary and secondary long chain alcohols, ketones and aldehydes. They may also contain esters of fatty acids and long chain alcohols. 
Plant and animal waxes.
Waxes are synthesized by many plants and animals. Those of animal origin typically consist of wax esters derived from a variety of carboxylic acids and fatty alcohols. In waxes of plant origin characteristic mixtures of unesterified hydrocarbons may predominate over esters. The composition depends not only on species, but also on geographic location of the organism.
Animal waxes.
The most commonly known animal wax is beeswax, but other insects secrete waxes. A major component of the beeswax used in constructing honeycombs is the ester myricyl palmitate which is an ester of triacontanol and palmitic acid. Its melting point is 62-65 °C. Spermaceti occurs in large amounts in the head oil of the sperm whale. One of its main constituents is cetyl palmitate, another ester of a fatty acid and a fatty alcohol. Lanolin is a wax obtained from wool, consisting of esters of sterols.
Plant waxes.
Plants secrete waxes into and on the surface of their cuticles as a way to control evaporation, wettability and hydration. The epicuticular waxes of plants are mixtures of substituted long-chain aliphatic hydrocarbons, containing alkanes, alkyl esters, fatty acids, primary and secondary alcohols, diols, ketones, aldehydes. 
From the commercial perspective, the most important plant wax is carnauba wax, a hard wax obtained from the Brazilian palm "Copernicia prunifera". Containing the ester myricyl cerotate, it has many applications, such as confectionery and other food coatings, car and furniture polish, floss coating, surfboard wax and other uses. Other more specialized vegetable waxes include candelilla wax and ouricury wax.
Petroleum derived waxes.
Although many natural waxes contain esters, paraffin waxes are hydrocarbons, mixtures of alkanes usually in a homologous series of chain lengths. These materials represent a significant fraction of petroleum. They are refined by vacuum distillation. Paraffin waxes are mixtures of saturated n- and iso- alkanes, naphthenes, and alkyl- and naphthene-substituted aromatic compounds. The degree of branching has an important influence on the properties. Millions of tons of paraffin waxes are produced annually. They are used in foods (such as chewing gum and cheese wrapping), in candles and cosmetics, as non-stick and waterproofing coatings and in polishes.
Montan wax.
Montan wax is a fossilized wax extracted from coal and lignite. It is very hard, reflecting the high concentration of saturated fatty acids and alcohols. Although dark brown and smelly, they can be purified and bleached to give commercially useful products.
Polyethylene and related derivatives.
Some waxes are synthesized by cracking polyethylene at 400 °C. The products have the formula (CH2)nH2, where n ranges between about 50 and 100. As of 1995, about 200 million kilograms/y were consumed.
Uses.
Waxes are mainly consumed industrially as components of complex formulations, often for coatings. The main use of polyethylene and polypropylene waxes is in the formulation of colourants for plastics. Waxes confer matting effects and wear resistance to paints. Polyethylene waxes are incorporated into inks in the form of dispersions to decrease friction. They are employed as release agents. They are also used as slip agents, e.g. in furniture, and corrosion resistance.
Candles.
Waxes and hard fats such as tallow are used to make candles, used for lighting and decoration.
Wax products.
Waxes are used as finishes and coatings for wood products. Beeswax is frequently used as a lubricant on drawer slides where wood to wood contact occurs.
Other uses.
Sealing wax was used to close important documents in the Middle Ages. Wax tablets were used as writing surfaces. There were different types of wax in the Middle Ages, namely four kinds of wax (Ragusan, Montenegro, Byzantine, and Bulgarian), "ordinary" waxes from Spain, Poland, and Riga, unrefined waxes and colored waxes (red, white, and green). Waxes are used to make wax paper, impregnating and coating paper and card to waterproof it or make it resistant to staining, or to modify its surface properties. Waxes are also used in shoe polishes, wood polishes, and automotive polishes, as mold release agents in mold making, as a coating for many cheeses, and to waterproof leather and fabric. Wax has been used since antiquity as a temporary, removable model in lost-wax casting of gold, silver and other materials.
Wax with colorful pigments added has been used as a medium in encaustic painting, and is used today in the manufacture of crayons and colored pencils. Carbon paper, used for making duplicate typewritten documents was coated with carbon black suspended in wax, typically montan wax, but has largely been superseded by photocopiers and computer printers. In another context, lipstick and mascara are blends of various fats and waxes colored with pigments, and both beeswax and lanolin are used in other cosmetics. Ski wax is used in skiing and snowboarding. Also, the sports of surfing and skateboarding often use wax to enhance the performance.
Some waxes are considered food-safe and are used to coat wooden cutting boards and other items that come into contact with food. Beeswax or coloured synthetic wax is used to decorate Easter eggs in Romania, Ukraine, Poland, and the Czech Republic. Paraffin wax is used in making chocolate covered bon-bons. Wax is also used in wax bullets, which are used as simulation aids.

</doc>
<doc id="58258" url="https://en.wikipedia.org/wiki?curid=58258" title="Honeycomb">
Honeycomb

A honeycomb is a mass of hexagonal wax cells built by honey bees in their nests to contain their larvae and stores of honey and pollen.
Beekeepers may remove the entire honeycomb to harvest honey. Honey bees consume about 8.4 lb (4 kg) of honey to secrete 1 lb (500 g) of wax, so it makes economic sense to return the wax to the hive after harvesting the honey, commonly called "pulling honey" or "robbing the bees" by beekeepers. The structure of the comb may be left basically intact when honey is extracted from it by uncapping and spinning in a centrifugal machine—the honey extractor. If the honeycomb is too worn out, the wax can be reused in a number of ways, including making sheets of comb foundation with hexagonal pattern. Such foundation sheets allow the bees to build the comb with less effort, and the hexagonal pattern of worker-sized cell bases discourages the bees from building the larger drone cells.
Fresh, new comb is sometimes sold and used intact as comb honey, especially if the honey is being spread on bread rather than used in cooking or as a sweetener.
Broodcomb becomes dark over time, because of the cocoons embedded in the cells and the tracking of many feet, called travel stain by beekeepers when seen on frames of comb honey. Honeycomb in the "supers" that are not allowed to be used for brood (e.g. by the placement of a queen excluder) stays light-coloured.
Numerous wasps, especially Polistinae and Vespinae, construct hexagonal prism-packed combs made of paper instead of wax; in some species (such as "Brachygastra mellifica"), honey is stored in the nest, thus technically forming a paper honeycomb. However, the term "honeycomb" is not often used for such structures.
Honeycomb geometry.
The axes of honeycomb cells are always quasihorizontal, and the nonangled rows of honeycomb cells are always horizontally (not vertically) aligned. Thus, each cell has two vertical walls, with "floors" and "ceilings" composed of two angled walls(disparity with image "Honeycomb-Process"). The cells slope slightly upwards, between 9 and 14°, towards the open ends.
Two possible explanations exist as to why honeycomb is composed of hexagons, rather than any other shape. First, the hexagonal tiling creates a partition with equal-sized cells, while minimizing the total perimeter of the cells. Known in geometry as the honeycomb conjecture, this was given by Jan Brożek and proved much later by Thomas Hales. Thus, a hexagonal structure uses the least material to create a lattice of cells within a given volume. A second reason, given by D'Arcy Wentworth Thompson, is that the shape simply results from the process of individual bees putting cells together: somewhat analogous to the boundary shapes created in a field of soap bubbles. In support of this, he notes that queen cells, which are constructed singly, are irregular and lumpy with no apparent attempt at efficiency.
The closed ends of the honeycomb cells are also an example of geometric efficiency, albeit three-dimensional and little-noticed. The ends are trihedral (i.e., composed of three planes) sections of rhombic dodecahedra, with the dihedral angles of all adjacent surfaces measuring 120°, the angle that minimizes surface area for a given volume. (The angle formed by the edges at the pyramidal apex, known as the tetrahedral angle, is approximately 109° 28' 16" ().)
<br>The three-dimensional geometry of a honeycomb cell
The shape of the cells is such that two opposing honeycomb layers nest into each other, with each facet of the closed ends being shared by opposing cells.
<br>Opposing layers of honeycomb cells fit together
Individual cells do not show this geometric perfection: in a regular comb, deviations of a few percent from the "perfect" hexagonal shape occur. In transition zones between the larger cells of drone comb and the smaller cells of worker comb, or when the bees encounter obstacles, the shapes are often distorted. Cells are also angled up about 13° from horizontal to prevent honey from dripping out.
In 1965, László Fejes Tóth discovered the trihedral pyramidal shape (which is composed of three rhombi) used by the honeybee is not the theoretically optimal three-dimensional geometry. A cell end composed of two hexagons and two smaller rhombuses would actually be .035% (or about one part per 2850) more efficient. This difference is too minute to measure on an actual honeycomb, and irrelevant to the hive economy in terms of efficient use of wax, considering wild comb varies considerably from any mathematical notion of "ideal" geometry.

</doc>
<doc id="58261" url="https://en.wikipedia.org/wiki?curid=58261" title="Honey bee">
Honey bee

A honey bee (or honeybee), in contrast with the stingless honey bee, is any bee member of the genus Apis, primarily distinguished by the production and storage of honey and the construction of perennial, colonial nests from wax. Honey bees are the only extant members of the tribe Apini, all in the genus "Apis". Currently, only seven species of honey bee are recognized, with a total of 44 subspecies, though historically, from six to eleven species have been recognized. Honey bees represent only a small fraction of the roughly 20,000 known species of bees. Some other types of related bees produce and store honey, but only members of the genus "Apis" are true honey bees. The study of bees including honey bees is known as melittology.
Etymology and name.
The genus name "Apis" is Latin for "bee".
Although modern dictionaries may refer to "Apis" as either honey bee or honeybee, entomologist Robert Snodgrass explains that correct usage is to use two words, i.e. honey bee, as it is a kind or type of bee, whereas it is correct to run the two words together as in dragonfly or butterfly, because the latter are not flies. Honey bee, not honeybee, is the listed common name in the Integrated Taxonomic Information System, the Entomological Society of America Common Names of Insects Database, and the Tree of Life Web Project.
Origin, systematics and distribution.
Honey bees appear to have their center of origin in South and Southeast Asia (including the Philippines), as all the extant species except "Apis mellifera" are native to that region. Notably, living representatives of the earliest lineages to diverge ("Apis florea" and "Apis andreniformis") have their center of origin there.
The first "Apis" bees appear in the fossil record at the Eocene–Oligocene boundary (34 mya), in European deposits. The origin of these prehistoric honey bees does not necessarily indicate Europe as the place of origin of the genus, only that the bees were present in Europe by that time. Few fossil deposits are known from South Asia, the suspected region of honey bee origin, and fewer still have been thoroughly studied.
No "Apis" species existed in the New World during human times before the introduction of "A. mellifera" by Europeans. Only one fossil species is documented from the New World, "Apis nearctica", known from a single 14-million-year-old specimen from Nevada.
The close relatives of modern honey bees – "e.g." bumblebees and stingless bees – are also social to some degree, and social behavior seems a plesiomorphic trait that predates the origin of the genus. Among the extant members of "Apis", the more basal species make single, exposed combs, while the more recently evolved species nest in cavities and have multiple combs, which has greatly facilitated their domestication.
Most species have historically been cultured or at least exploited for honey and beeswax by humans indigenous to their native ranges. Only two of these species have been truly domesticated, one ("A. mellifera") at least since the time of the building of the Egyptian pyramids, and only that species has been moved extensively beyond its native range.
Today's honey bees constitute three clades.</ref>
Genetics.
The chromosome counts of female bees for the three clades are: "Micrapis" 2N = 16, "Megapis" 2N = 16, and "Apis" 2N = 32. Drones of all species have 1N chromosome counts. The genome of "Apis" has been mapped.
Drones (males) are produced from unfertilized eggs, so represent only the DNA of the queen that laid the eggs, i.e. have only a mother. Workers and queens (both female) result from fertilized eggs, so have both a mother and a father. Arrhenotokous parthenogenesis, A modified form of parthenogenesis controls sex differentiation. The sex allele is polymorphic, and so long as two different variants are present, a female bee results. If both sex alleles are identical, diploid drones are produced. Honey bees detect and destroy diploid drones after the eggs hatch.
Queens typically mate with multiple drones on more than one mating flight. Once mated, they lay eggs and fertilize them as needed from sperm stored in the spermatheca. Since the number of sex alleles is limited – about 18 are known in "Apis" – a queen will most likely mate with one or more drones having sex alleles identical with one of the sex alleles in the queen. The queen, then, typically produces a percentage of diploid drone eggs.
"Micrapis".
"Apis florea" and "Apis andreniformis" are small honey bees of southern and southeastern Asia. They make very small, exposed nests in trees and shrubs. Their stings are often incapable of penetrating human skin, so the hive and swarms can be handled with minimal protection. They occur largely sympatrically, though they are very distinct evolutionarily and are probably the result of allopatric speciation, their distribution later converging. Given that "A. florea" is more widely distributed and "A. andreniformis" is considerably more aggressive, honey is, if at all, usually harvested from the former only. They are the most ancient extant lineage of honey bees, maybe diverging in the Bartonian (some 40 million years ago or slightly later) from the other lineages, but do not seem to have diverged from each other a long time before the Neogene. "Apis florea" have smaller wing spans than its sister species. "Apis florea" are also completely yellow with the exception of the scutellum of workers, which is black.
"Megapis".
One species is recognized in the subgenus "Megapis". It usually builds single or a few exposed combs on high tree limbs, on cliffs, and sometimes on buildings. They can be very fierce. Periodically robbed of their honey by human "honey hunters", colonies are easily capable of stinging a human being to death if provoked.
"Apis".
The eastern species include three or four species. The reddish Koschevnikov's bee ("Apis koschevnikovi") from Borneo is well distinct; it probably derives from the first colonization of the island by cave-nesting honey bees. "Apis cerana", the eastern honey bee proper, is the traditional honey bee of southern and eastern Asia, kept in hives in a similar fashion to "A. mellifera", though on a much smaller and regionalised scale. It has not been possible yet to resolve its relationship to the Bornean "A. c. nuluensis" and "Apis nigrocincta" from the Philippines to satisfaction; the most recent hypothesis is that these are indeed distinct species, but that "A. cerana" is still paraphyletic, consisting of several good species.
"A. mellifera", the most common domesticated species, was the third insect to have its genome mapped. It seems to have originated in eastern tropical Africa and spread from there to Northern Europe and eastwards into Asia to the Tien Shan range. It is variously called the European, western or common honey bee in different parts of the world. Many subspecies have adapted to the local geographic and climatic environments; in addition, hybrid strains, such as the Buckfast bee, have been bred. Behavior, color, and anatomy can be quite different from one subspecies or even strain to another.
Regarding phylogeny, this is the most enigmatic honey bee species. It seems to have diverged from its eastern relatives only during the Late Miocene. This would fit the hypothesis that the ancestral stock of cave-nesting honey bees was separated into the western group of East Africa and the eastern group of tropical Asia by desertification in the Middle East and adjacent regions, which caused declines of food plants and trees that provided nest sites, eventually causing gene flow to cease. The diversity of subspecies is probably the product of a largely Early Pleistocene radiation aided by climate and habitat changes during the last ice age. That the western honey bee has been intensively managed by humans for many millennia – including hybridization and introductions – has apparently increased the speed of its evolution and confounded the DNA sequence data to a point where little of substance can be said about the exact relationships of many "A. mellifera" subspecies.
"Apis mellifera" is not native to the Americas, so was not present upon the arrival of the European explorers and colonists. However, other native bee species were kept and traded by indigenous peoples. In 1622, European colonists brought the dark bee ("A. m. mellifera") to the Americas, followed later by Italian bees ("A. m. ligustica") and others. Many of the crops that depend on honey bees for pollination have also been imported since colonial times. Escaped swarms (known as "wild" bees, but actually feral) spread rapidly as far as the Great Plains, usually preceding the colonists. Honey bees did not naturally cross the Rocky Mountains; they were transported by the Mormon pioneers to Utah in the late 1840s, and by ship to California in the early 1850s.
Africanized bee.
Africanized bees (known colloquially as "killer bees") are hybrids between European stock and one of the African subspecies "A. m. scutellata"; they are often more aggressive than European bees and do not create as much of a honey surplus, but are more resistant to disease and are better foragers. Originating by accident in Brazil, they have spread to North America and constitute a pest in some regions. However, these strains do not overwinter well, so are not often found in the colder, more northern parts of North America. The original breeding experiment for which the African bees were brought to Brazil in the first place has continued (though not as intended). Novel hybrid strains of domestic and redomesticated Africanized bees combine high resilience to tropical conditions and good yields. They are popular among beekeepers in Brazil.
Beekeeping.
Two species of honey bee, "A. mellifera" and "A. cerana indica", are often maintained, fed, and transported by beekeepers. Modern hives also enable beekeepers to transport bees, moving from field to field as the crop needs pollinating and allowing the beekeeper to charge for the pollination services they provide, revising the historical role of the self-employed beekeeper, and favoring large-scale commercial operations.
Colony collapse disorder.
Beekeepers in Western countries have been reporting slow declines of stocks for many years, apparently due to impaired protein production, changes in agricultural practice, or unpredictable weather. In early 2007, abnormally high die-offs (30–70% of hives) of European honey bee colonies occurred in North America; such a decline seems unprecedented in recent history. This has been dubbed "colony collapse disorder" (CCD); it is unclear whether this is simply an accelerated phase of the general decline due to stochastically more adverse conditions in 2006, or a novel phenomenon. CCD is unique due to the lack of evidence as to what causes the sudden die-off of adult worker bees, as well as few to no dead bees found around the hive.
Research is beginning to determine the causes of CCD, with the weight of evidence is leaning towards CCD being a syndrome rather than a disease, as it seems to be caused by a combination of various contributing factors rather than a single pathogen or poison. However, in April 2013, after a report was released by the European Food Safety Authority identifying the significant risks of the class of pesticides called neonicotinoids, the European Union called for a two-year restriction on neonicotinoid pesticides. In 2015, an 11-year British study showed a definitive relationship between increasing agricultural use of neonicotinoid and escalating honey bee colony losses at a landscape level. This is the first field study to establish a link between neonicotinoids and CCD.
A 2007 study linked CCD with Israeli acute paralysis virus at a level of statistic significance. IAPV was found in 83.3% of hives with CCD, and has a predictive value of 96.1%, making it one of the most probable candidates as the infectious agent in CCD.
One other possible hypothesis is that the bees are falling victim to a combination of insecticides and parasites. Feral honey bees are prone to high levels of deformed wing virus (DWV). The varroa mite thrives in honey bee colonies by sucking the hemolymph of honey bees, causing open wounds that are susceptible to varroosis. Higher levels of DWV are more prevalent in colonies that are not being treated for varroosis. Tobacco ring spot virus (TRSV) spreads and negatively affects the health of honey bees indirectly. TRSV has a wide host range. It can be transmitted from infected plant hosts, through parasites such as varroa mites, and ultimately infect insects like the honey bee. In January 2012, a researcher discovered "Apocephalus borealis" larvae, a parasitic fly known to prey on bumble bees and wasps, in a test tube containing a dead honey bee believed to have been affected by CCD.
No effective preventative measures against CCD have been suggested to date.
As of 2015, beehive losses remain high but not due to CCD but to other factors as reported by the USDA.
Lifecycle.
As in a few other types of eusocial bees, a colony generally contains one queen bee, a fertile female; seasonally up to a few thousand drone bees, or fertile males; and tens of thousands of sterile female worker bees. Details vary among the different species of honey bees, but common features include:
Winter survival.
In cold climates, honey bees stop flying when the temperature drops below about 10 °C (50 °F) and crowd into the central area of the hive to form a "winter cluster". The worker bees huddle around the queen bee at the center of the cluster, shivering to keep the center between 27 °C (81 °F) at the start of winter (during the broodless period) and 34 °C (93 °F) once the queen resumes laying. The worker bees rotate through the cluster from the outside to the inside so that no bee gets too cold. The outside edges of the cluster stay at about 8–9 °C (46–48 °F). The colder the weather is outside, the more compact the cluster becomes. During winter, they consume their stored honey to produce body heat. The amount of honey consumed during the winter is a function of winter length and severity, but ranges in temperate climates from 15 to 50 kg (30 to 100 lb). In addition, certain bees, including the Western honey bee as well as "Apis cerana", are known to engage in effective methods of nest thermoregulation systems during periods of varying temperature including the summer as well as the winter. During the winter, however, this is achieved through fanning and water evaporation from water collected in various fields. 
Pollination.
Species of "Apis" are generalist floral visitors, and pollinate a large variety of plants, but by no means all plants. Of all the honey bee species, only "A. mellifera" has been used extensively for commercial pollination of crops and other plants. The value of these pollination services is commonly measured in the billions of dollars. Bees collect 66 lb of pollen per year, per hive.
Nutrition.
            Honey bees obtain all of their nutritional requirements from a diverse combination of pollen and nectar. Pollen is the only natural protein source for honey bees. Adult worker honey bees consume 3.4-4.3 mg of pollen per day to meet a dry matter requirement of 66-74% protein. The rearing of one larva requires 125-187.5 mg pollen or 25-37.5 mg protein for proper development. Dietary proteins are broken down into amino acids, ten of which are considered essential to honey bees: methionine, tryptophan, arginine, lysine, histidine, phenylalanine, isoleucine, threonine, leucine, and valine. Of these amino acids, honey bees require highest concentrations of leucine, isoleucine, and valine, however elevated concentrations of arginine and lysine are required for brood rearing. In addition to these amino acids, some B vitamins including biotin, folic acid, nicotinamide, riboflavin, thiamine, pentothenate, and most importantly, pyridoxine are required to rear larvae. Pyridoxine is the most prevalent B vitamin found in royal jelly and concentrations vary throughout the foraging season with lowest concentrations found in May and highest concentrations found in July and August. Honey bees lacking dietary pyridoxine were unable to rear brood. 
Pollen is also a lipid source for honey bees ranging from 0.8% to 18.9%. Lipids are metabolized during the brood stage for precursors required for future biosynthesis. Fat-soluble vitamins A, D, E, and K are not considered essential but have shown to significantly improve the number of brood reared. Honey bees ingest phytosterols from pollen to produce 24-methylenecholesterol and other sterols as they cannot directly synthesize cholesterol from phytosterols. Nurse bees have the ability to selectively transfer sterols to larvae through brood food.
Nectar is collected by foraging worker bees as a source of water and carbohydrates in the form of sucrose. The dominant monosaccharides in honey bee diets are fructose and glucose but the most common circulating sugar in hemolymph is trehalose which is a disaccharide consisting of two glucose molecules. Adult worker honey bees require 4 mg of utilizable sugars per day and larvae require about 59.4 mg of carbohydrates for proper development.
Honey bees require water to maintain osmotic homeostasis, prepare liquid brood food, and to cool the hive through evaporation. A colony’s water needs can generally be met by nectar foraging as it has high water content. Occasionally on hot days or when nectar is limited, foragers will collect water from streams or ponds to meet the needs of the hive.
Bee products.
Honey.
Honey is the complex substance made when the nectar and sweet deposits from plants and trees are gathered, modified, and stored in the honeycomb by honey bees as a food source for the colony. All living species of "Apis" have had their honey gathered by indigenous peoples for consumption, though for commercial purposes, only "A. mellifera" and "A. cerana" have been used to any degree. Honey is sometimes also gathered by humans from the nests of various stingless bees.
In 1911, a bee culturist estimated a quart (about a litre) of honey represented bees flying over an estimated 48,000 miles to gather the nectar needed to produce the honey.
Nectar.
Nectar, a liquid high in sucrose, is produced in plant glands known as nectaries. It is an important energy resource for honey bees and plays a significant role in foraging economics and evolutionary differentiation between different subspecies. It was proposed through an experiment conducted with the African honey bee, "A. m. scutellata", that nectar temperature impacts the foraging decisions of honey bees.
Beeswax.
Worker bees of a certain age secrete beeswax from a series of glands on their abdomens. They use the wax to form the walls and caps of the comb. As with honey, beeswax is gathered by humans for various purposes.
Pollen.
Bees collect pollen in their pollen baskets and carry it back to the hive. In the hive, pollen is used as a protein source necessary during brood-rearing. In certain environments, excess pollen can be collected from the hives of "A. mellifera" and "A. cerana". It is often eaten as a health supplement. It also has been used with moderate success as a source of pollen for hand pollination However, pollen collected by bees and harvested for pollination must be used within a few hours because it loses its potency rapidly, possibly because of the effects of enzymes or other chemicals from the bees.
Bee Bread.
Worker bees combine pollen, honey and glandular secretions and allow it to ferment in the comb to make bee bread. The fermentation process releases additional nutrients from the pollen and can produce antibiotics and fatty acids which inhibit spoilage. Bee bread is eaten by nurse bees (younger workers) who then produce the protein-rich royal jelly needed by the queen and developing larvae in their hypopharyngeal glands.
Propolis.
Propolis or bee glue is created from resins, balsams, and tree saps. Those species of honey bees that nest in tree cavities use propolis to seal cracks in the hive. Dwarf honey bees use propolis to defend against ants by coating the branch from which their nest is suspended to create a sticky moat. Propolis is consumed by humans as a health supplement in various ways and also used in some cosmetics.
Sexes and castes.
A caste is a different form, morphologically or reproductively, within the same sex of a species. Honey bees have three castes: drones, workers, and queens. Drones are male, while workers and queens are female.
Drones.
Males, or drones, are typically haploid, having only one set of chromosomes. They are produced by the queen if she chooses not to fertilize an egg; or by an unfertilized laying worker. Diploid drones may be produced if an egg is fertilized but is homozygous for the sex-determination allele. Drones take 24 days to develop and may be produced from summer through autumn. Drones have large eyes used to locate queens during mating flights. They do not have a stinger.
Workers.
Workers have two sets of chromosomes. They are produced from an egg that the queen has selectively fertilized from stored sperm. Workers typically develop in 21 days. A typical colony may contain as many as 60,000 worker bees. Workers exhibit a wider range of behaviors than either queens or drones. Their duties change upon the age of the bee in the following order (beginning with cleaning out their own cell after eating through their capped brood cell): feed brood, receive nectar, clean hive, guard duty, and foraging. Some workers engage in other specialized behaviors, such as "undertaking" (removing corpses of their nestmates from inside the hive).
Workers have morphological specializations, including the pollen basket "(corbicula)", abdominal glands that produce beeswax, brood-feeding glands, and barbs on the sting. Under certain conditions (for example, if the colony becomes queenless), a worker may develop ovaries.
Queens.
Queen honey bees are created at the decision of the worker bees by feeding a larva only royal jelly throughout its development, rather than switching from royal jelly to pollen once the larva grows past a certain size. Queens are produced in oversized cells and develop in only 16 days; they differ in morphology and behavior from worker bees. In addition to the greater size of the queen, she has a functional set of ovaries, and a spermatheca, which stores and maintains sperm after she has mated. "Apis" queens practice polyandry, with one female mating with multiple males. The highest documented mating frequency for an "Apis" queen is in "Apis nigrocincta", where queens mate with an extremely high number of males with observed numbers of different matings ranging from 42 to 69 drones per queen. The sting of queens is not barbed like a worker's sting, and queens lack the glands that produce beeswax. Once mated, queens may lay up to 2,000 eggs per day. They produce a variety of pheromones that regulate behavior of workers, and helps swarms track the queen's location during the migratory phase.
Defense.
All honey bees live in colonies where the workers sting intruders as a form of defense, and alarmed bees release a pheromone that stimulates the attack response in other bees. The different species of honey bees are distinguished from all other bee species (and virtually all other Hymenoptera) by the possession of small barbs on the sting, but these barbs are found only in the worker bees. The sting and associated venom sac of honey bees are also modified so as to pull free of the body once lodged (autotomy), and the sting apparatus has its own musculature and ganglion, which allow it to keep delivering venom once detached. The worker dies after the sting becomes lodged and is subsequently torn loose from the bee's abdomen. The honey bee's venom, known as apitoxin, carries several active components, the most abundant of which is melittin, and the most destructive is phospholipase A2.
This complex apparatus, including the barbs on the sting, is thought to have evolved specifically in response to predation by vertebrates, as the barbs do not usually function (and the sting apparatus does not detach) unless the sting is embedded in fleshy tissue. While the sting can also penetrate the membranes between joints in the exoskeleton of other insects (and is used in fights between queens), in the case of "Apis cerana japonica", defense against larger insects such as predatory wasps (e.g. Asian giant hornet) is usually performed by surrounding the intruder with a mass of defending worker bees, which vibrate their muscles vigorously to raise the temperature of the intruder to a lethal level ("balling"). Previously, heat alone was thought to be responsible for killing intruding wasps, but recent experiments have demonstrated the increased temperature in combination with increased carbon dioxide levels within the ball produce the lethal effect. This phenomenon is also used to kill a queen perceived as intruding or defective, an action known to beekeepers as 'balling the queen', named for the ball of bees formed.
Defense can vary based on the habitat of the bee. In the case of those honey bee species with open combs (e.g., "A. dorsata"), would-be predators are given a warning signal that takes the form of a "Mexican wave" that spreads as a ripple across a layer of bees densely packed on the surface of the comb when a threat is perceived, and consists of bees momentarily arching their bodies and flicking their wings. In cavity dwelling species such as Apis nigrocincta, entrances to these cavities are guarded and checked for intruders in incoming traffic. Another act of defense against nest invaders, particularly wasps, is "body shaking," a violent and pendulum like swaying of the abdomen, performed by worker bees.
Competition.
Honey bees are known to compete largely with "Bombus hortorum", a bumblebee species, because they forage at the same sites. To resolve the issue and maximize both their total consumption during foraging, bumblebees forage early in the morning, while honey bees forage during the afternoon.
Communication.
Honey bees are known to communicate through many different chemicals and odors, as is common in insects, but also using specific behaviors such as dances that convey information about the quality and type of resources in the environment, and where these resources are located. The details of the signalling being used vary from species to species; for example, the two smallest species, "Apis andreniformis" and "A. florea", dance on the upper surface of the comb, which is horizontal (not vertical, as in other species), and worker bees orient the dance in the actual compass direction of the resource to which they are recruiting.
"Apis mellifera carnica" honey bees use their antennae asymmetrically for social interactions with a strong lateral preference to use their right antennae.
There has been speculation as to honeybee consciousness.
Symbolism.
The bee was revived as a symbol of government by Emperor Napoleon I of France.
Both the "Atharva Veda" and the ancient Greeks associated lips anointed with honey with the gift of eloquence and even of prescience. The priestess at Delphi was the "Delphic Bee". The "Quran" has a chapter titled "The Bee".
A community of honey bees has often been employed throughout history by political theorists as a model of human society: this image occurs in Aristotle and Plato; in Virgil and Seneca; in Erasmus and Shakespeare; in Marx and Tolstoy.
Honey bees, signifying immortality and resurrection, were royal emblems of the Merovingians. The bee also is the heraldic emblem of the Barberini.

</doc>
<doc id="58263" url="https://en.wikipedia.org/wiki?curid=58263" title="List of counties in Alabama">
List of counties in Alabama

The U.S. state of Alabama has 67 counties. Each county serves as the local level of government within its borders. The land enclosed by the present state borders was joined to the United States of America gradually. Following the American Revolutionary War, West Florida was ceded to Spain by treaty while the remainder was organized primarily as the Mississippi Territory, and later the Alabama Territory. The territorial assembly established some of the earliest county divisions that have survived to the present, including the earliest county formation, that of Washington County, created on June 4, 1800. In 1814, the Treaty of Fort Jackson opened the territory to American settlers, which in turn led to a more rapid rate of county creation. Alabama was admitted to the Union as the 22nd state in 1819. The Alabama state legislature formed additional counties from former native lands as the Indian Removal Act took effect and settlers populated different areas of Alabama. In 1820, Alabama had 29 counties. By 1830 there were 36 and Native Americans still occupied large areas of land in northeast and far western Alabama. By 1840, 49 counties had been created; 52 by 1850; 65 by 1870; and the present 67 counties by 1903. Houston County was the last county created in the state, on February 9, 1903.
According to 2010 U. S. Census data, the average population of Alabama's 67 counties is 71,399, with Jefferson County as the most populous (658,466), and Greene County (9,045) the least. The average land area is 756 sq mi (1,958 km2). The largest county is Baldwin (1,590 sq mi, 4,118 km2) and the smallest is Etowah (535 sq mi, 1,386 km2). The Constitution of Alabama requires that any new county in Alabama cover at least in area, effectively limiting the creation of new counties in the state.
The Alabama Department of Revenue's Motor Vehicle Division issues standard automobile license plates that bear a one- or two-digit number identifying the county in which the vehicle is registered. This number is given in the fourth column in the table below. The first three prefixes are reserved for the state's historically most populous counties, and thereafter proceed alphabetically. Individual license plate numbers are assigned sequentially in each licensing office. The numbers are in the format "XAA1111" or "XXAA111", depending on whether the prefix is one or two digits. Overflow registrations are accommodated by substituting a letter for one of the registration numbers, such that XXZ999Z is followed by XXA0A0A. Outdated Info for current plates (2014)
The Federal Information Processing Standard (FIPS) code, used by the United States government to uniquely identify counties, is provided with each entry. The FIPS code links in the table point to U. S. Census "quick facts" pages for each county.

</doc>
<doc id="58264" url="https://en.wikipedia.org/wiki?curid=58264" title="Fig wasp">
Fig wasp

Fig wasps are wasps of the superfamily Chalcidoidea which spend their larval stage inside figs. Most are pollinators but others are herbivores. The non-pollinators belong to several groups within the superfamily Chalcidoidea, while the pollinators are in the family Agaonidae. While pollinating fig wasps are gall-makers, the remaining types either make their own galls or usurp the galls of other fig wasps; reports of them being parasitoids are considered dubious.
Taxonomy.
The fig wasps are a polyphyletic group, including several unrelated lineages whose similarities are based upon their shared association with figs; efforts are underway to resolve the matter, and remove a number of constituent groups to other families, particularly the Pteromalidae and Torymidae. Thus, the number of genera in the family is in flux. The family Agaonidae has been recently updated to include all the pollinating fig wasps and the subfamily Sycophaginae.
The remaining taxa such as Epichrysomallinae, Sycoecinae, Otitesellinae, and Sycoryctinae should be included in the Pteromalidae.
Morphological adaptations.
Among the Agaonidae, the female is a normal insect, while the males are mostly wingless. The males' only tasks are to mate with the females while still within the fig syconium and to chew a hole for the females to escape from the fig interior. This is the reverse of Strepsiptera and the bagworm, where the male is a normal insect and the female never leaves the host.
The non-pollinating wasps have developed impressive morphological adaptations in order to oviposit eggs inside the fig but from the outside: an extremely long ovipositor.
Most fig inflorescences contain three kinds of flowers: male, short female, and long female. Female fig wasps can reach the ovaries of short female flowers with their ovipositors, but not long female flowers. Thus, the short flowers grow wasps, whereas the long flowers become seeds. In figs of this sort, the crunchy bits in the fruit contain both seeds and wasps. However, several commercial and ornamental varieties of fig are parthenocarpic and do not require pollination; these varieties are not visited by fig wasps.
Life cycle.
The life cycle of the fig wasp is closely intertwined with that of the fig tree it inhabits. The wasps that inhabit a particular tree can be divided into two groups; pollinating and nonpollinating. The pollinating wasps are part of an obligate nursery pollination mutualism with the fig tree. Both life cycles of the two groups, however, are very similar.
Though the lives of individual species differ, a pollinating fig wasp life cycle is as follows. In the beginning of the cycle, a mature female pollinator wasp enters the immature "fruit" (actually a stem-like structure known as a syconium) through a small natural opening, the ostiole and deposits her eggs in the cavity. Forcing her way through the ostiole, she often loses her wings and most of her antennae. To facilitate her passage through the ostiole, the underside of the female's head is covered with short spines that provide purchase on the walls of the ostiole. In depositing her eggs, the female also deposits pollen she picked up from her original host fig. This pollinates some of the female flowers on the inside surface of the fig and allows them to mature. After the female wasp lays her eggs and follows through with pollination, she dies. 
After pollination, there are several species of non-pollinating wasps which deposit their eggs before the figs harden. These wasps act as parasites to either the fig or possibly the pollinating wasps. As the fig develops, the wasp eggs hatch and develop into larvae. After going through the pupal stage, the mature male’s first act is to mate with a female. The males of many species lack wings and are unable to survive outside the fig for a sustained period of time. After mating, a male wasp begins to dig out of the fig, creating a tunnel through which the females escape.
Once out of the fig, the male wasps quickly die. The females find their way out, picking up pollen as they do. They then fly to another tree of the same species, where they deposit their eggs and allow the cycle to begin again.
Coevolution.
The fig–wasp mutualism originated between 70 and 90 million years ago as the product of a unique evolutionary event. Since then, cocladogenesis and coadaptation on a coarse scale between wasp genera and fig sections has been supported by both morphological and molecular studies. This illustrates the tendency towards coradiation of figs and wasps. Such strict cospeciation should result in identical phylogenetic trees for the two lineages and recent work mapping fig sections onto molecular phylogenies of wasp genera and performing statistical comparisons has provided strong evidence for cospeciation at that scale.
Groups of genetically well-defined pollinator wasp species coevolve in association with groups of genetically poorly defined figs. The constant hybridization of the figs promotes the constant evolution of new pollinator wasp species. Host switching and pollinator host sharing may contribute to the incredible diversity of figs.
Genera.
Fig wasps genera and classification according to the various publications:

</doc>
<doc id="58265" url="https://en.wikipedia.org/wiki?curid=58265" title="List of counties in Delaware">
List of counties in Delaware

The United States state of Delaware has only three counties: New Castle, Kent, and Sussex, the least in the United States. The origin of the county boundaries goes back to former court districts. The powers of the counties' legislative bodies are limited to issues such as zoning and development.
Politics and government.
Each county elects a legislative body (known in New Castle and Sussex counties as the "County Council", and in Kent County as the "Levy Court"). The counties are able to raise taxes and borrow money. They also have control over garbage disposal, water supply, sewerage, zoning, development, and building codes.
Most functions which are handled on a county-by-county basis in other states—such as court and law enforcement—have been centralized in Delaware, leading to a significant concentration of power in the Delaware state government. The counties were historically divided into hundreds, which were used as tax reporting and voting districts until the 1960s. However, the hundreds now serve no administrative role; their only current official legal use is in real-estate title descriptions.
History.
Following the English conquest of 1664, all of the land on the western side of the Delaware River and Delaware Bay was governed as part of the New York Colony and administered from the town of New Castle. During the brief recapture of the colony by the Dutch in 1673, additional court districts were created around Upland and Whorekill. The latter was also known as Hoornkill, and is now the town of Lewes. The court at New Castle was left with the central portion of the colony. The jurisdiction left to the court at became New Castle County, and the county seat remained at New Castle until 1881 when it was moved to Wilmington. In 1680, Whorekill District was divided into Deale County and St. Jones County. After this division, Lewes became the county seat of Deale, which was later renamed "Sussex County". The former Upland District was named after the New Sweden settlement of Upland, and was renamed Chester County in 1682. Chester County is now located within the present boundaries of Pennsylvania.
Lord Baltimore, the Proprietor of Maryland, claimed all present-day Delaware, and organized its northern and eastern portions as Durham County, Maryland. However, this county existed only on paper. The southern and western portions of present-day Sussex County were organized as portions of several adjacent Maryland counties and were not recognized as part of Delaware until the Mason-Dixon Survey was run in 1767. In 1791, with the expansion of Sussex County to the south and west, the county seat was moved to Georgetown. The county seat of St. Jones (renamed "Kent County" in 1681) is at Dover.
After 2000, a fourth "Appoquinimink County" was proposed to be carved out of New Castle County. The motivation for this failed effort was to end the zoning restrictions of the Unified Development Code on the undeveloped farmland. The proposed boundaries extended beyond Appoquinimink Hundred to include all land south of the C&D Canal with Middletown as the proposed seat.
County information.
The Federal Information Processing Standard (FIPS) code, which is used by the United States government to uniquely identify counties, is provided with each entry. The FIPS code for each county links to census data for that county.

</doc>
<doc id="58267" url="https://en.wikipedia.org/wiki?curid=58267" title="Conceptual schema">
Conceptual schema

A conceptual schema is a high-level description of a business's informational needs. It typically includes only the main concepts and the main relationships among them. Typically this is a first-cut model, with insufficient detail to build an actual database.This level describes the structure of the whole database for a group of users. The conceptual model is also known as the data model as data model can be used to describe the conceptual schema when a database system is implemented. It hides the internal details of physical storage and targets on describing entities, datatype, relationships and constraints.
Overview.
A conceptual schema or conceptual data model is a map of concepts and their relationships used for databases. This describes the semantics of an organization and represents a series of assertions about its nature. Specifically, it describes the things of significance to an organization ("entity classes"), about which it is inclined to collect information, and characteristics of ("attributes") and associations between pairs of those things of significance ("relationships").
Because a conceptual schema represents the semantics of an organization, and not a database design, it may exist on various levels of abstraction. The original ANSI four-schema architecture began with the set of "external schemas" that each represent one person's view of the world around him or her. These are consolidated into a single "conceptual schema" that is the superset of all of those external views. A data model can be as concrete as each person's perspective, but this tends to make it inflexible. If that person's world changes, the model must change. Conceptual data models take a more abstract perspective, identifying the fundamental things, of which the things an individual deals with are just examples.
The model does allow for what is called inheritance in object oriented terms. The set of instances of an entity class may be subdivided into entity classes in their own right. Thus, each instance of a "sub-type" entity class is also an instance of the entity class's "super-type". Each instance of the super-type entity class, then is also an instance of one of the sub-type entity classes.
Super-type/sub-type relationships may be "exclusive" or not. A methodology may require that each instance of a super-type may "only" be an instance of "one" sub-type. Similarly, a super-type/sub-type relationship may be "exhaustive" or not. It is exhaustive if the methodology requires that each instance of a super-type "must be" an instance of a sub-type. A sub-type named other is often necessary.
Data structure diagram.
A data structure diagram (DSD) is a data model or diagram used to describe conceptual data models by providing graphical notations which document entities and their relationships, and the constraints that bind them.

</doc>
<doc id="58268" url="https://en.wikipedia.org/wiki?curid=58268" title="Sydney, Nova Scotia">
Sydney, Nova Scotia

Sydney (Scottish Gaelic: "Baile Shidni") is a community and former city in Nova Scotia, Canada. Situated on Cape Breton Island's east coast, it belongs administratively to the Cape Breton Regional Municipality. Sydney was founded in 1785 by the British; it was incorporated as a city in 1904, and dissolved on 1 August 1995, when it was amalgamated into the regional municipality. It served as the Cape Breton Island colony's capital, until 1820, when the colony merged with Nova Scotia and the capital moved to Halifax.
A rapid population expansion occurred just after the turn of the 20th century, when Sydney was home to one of North America's main steel mills. During both the First and Second World Wars, it was a major staging area for England-bound convoys. The post-war period witnessed a major decline in the number of people employed at the Dominion Steel and Coal Corporation (DOSCO) steel mill, and the Nova Scotia and Canadian governments had to nationalize it in 1967 to save the region's biggest employer, forming the new crown corporation called the Sydney Steel Corporation (SYSCO). The city's population steadily decreased since the early 1970s due to the plant's fortunes, and SYSCO was finally closed in 2001. Today, the main industries are in customer support call centres and tourism. Together with Sydney Mines, North Sydney, New Waterford and Glace Bay Sydney forms the Industrial Cape Breton region.
History.
Early history 1700s to 1899.
Prior to a permanent settlement being established, there was significant activity along the shore. 
During the American Revolution, on 1 November 1776, John Paul Jones - the father of the American Navy - set sail in command of "Alfred" to free hundreds of American prisoners working in the coal mines in eastern Cape Breton. Although winter conditions prevented the freeing of the prisoners, the mission did result in the capture of the "Mellish", a vessel carrying a vital supply of winter clothing intended for John Burgoyne's troops in Canada. A few years into the war there was also a naval engagement between French ships and a British convoy off Sydney, Nova Scotia, near Spanish River (1781), Cape Breton. French ships (fighting with the Americans) were re-coaling and defeated a British convoy. Six French sailors were killed and 17 British, with many more wounded.
Sydney was founded after the war by Colonel Joseph Frederick Wallet DesBarres, and named in honour of Thomas Townshend, 1st Viscount Sydney, who was serving as the Home Secretary in the British cabinet. Lord Sydney appointed Col. DesBarres lieutenant-governor of the new colony of Cape Breton Island. In November 1784 the 600-ton ship "Blenheim" landed a group that consisted primarily of English citizens and disbanded soldiers. A group of Loyalists from the state of New York, fleeing the aftermath of the American Revolution, were added to the immigrants upon their arrival in the neighbouring colony of Nova Scotia. DesBarres arrived at Sydney on 7 January 1785. He held the first meeting of his executive council on 21 February 1785, where he was proclaimed lieutenant-governor in a formal manner and the first minutes of the new colony were taken. The site DesBarres chose for the new settlement was along the Southwest Arm of Sydney Harbour, a drowned valley of the Sydney River, which forms part of Spanish Bay. Between 1784 and 1820, Sydney was the capital of the British colony of Cape Breton Island. The colony was disbanded and merged with neighbouring Nova Scotia as part of the British government's desire to develop the abundant coal fields surrounding Sydney Harbour; the leases being held by the Duke of York. In 1826, the leases were transferred to the General Mining Association and industrial development around Sydney began to take shape.
Steel town 1900–1945.
By the early 20th century Sydney became home to one of the world's largest steel plants, fed by the numerous coal mines in the area under the ownership of the Dominion Steel and Coal Corporation (DOSCO). Sydney's economy was a significant part of Industrial Cape Breton with its steel plant and harbour and railway connections adjoining the coal mining towns of Glace Bay, New Waterford, Sydney Mines and Reserve Mines. The economic boom brought about by industrialization saw the community incorporate as a city in 1903. The growth continued until the 1930s, with the Great Depression causing a slow down in production and growth. World War Two brought prosperity again for the plant, and the coal mines.
Sydney Harbour played an important role during World War II once a Royal Canadian Navy base, , was established to stage supply convoys bound for Europe. These convoys tended to be slower and had the prefix SC for Slow Convoy. Convoy SC 7 typified the dangers inherent with the Nazi U-boats off the coast of Cape Breton and Newfoundland during the Battle of the Atlantic, when 20 of the 35 merchant cargo vessels were sunk on their journey to England. Sydney Harbour was one of the hotspots of the Battle of the St. Lawrence. Two notable shipping attacks occurred during this battle: the sinking of the train ferry in October 1942 on its way from North Sydney to Port aux Basque, Newfoundland; and the sinking of the Sydney-based HMCS "Shawinigan" on 24 November 1944 in the Cabot Strait, near Cape North, on Cape Breton Island. Sydney's coal shipping and steel manufacturing made a significant contribution to the Allied war effort, however federal Minister of Industry, C. D. Howe favoured Central Canada's steel industry given its proximity to a larger workforce and less exposure to coastal attack.
Post-war years 1950–2014.
By the late 1960s the coal and steel industries had fallen on hard times. Friday, 13 October 1967, became known as "Black Friday," so named after Hawker Siddeley Canada, the plant's owners, announced they were closing it in April 1968. Both the provincial and federal government were involved in negotiating with the steel plant's owners, when Cape Breton's citizens held the largest protest in the city's history on 19 November 1967: "The Parade of Concern." Around 20,000 people marched about a mile from the plant's gates to a horse racetrack to show their support for the steel plant. Newly appointed Nova Scotia premier G.I. Smith and federal Health Minister, and Cape Breton MP, Allan J. MacEachen spoke to the crowd and assured them that their respective governments were going to help. Four days later the Smith government announced that they were taking over the plant starting in 1968.
Both the steel and coal industries continued under government ownership for the rest of the 20th century. By the early 1990s, both industries were in trouble again, and were permanently closed by the end of 2001.
Forced to diversify its economy after the closures of the steel plant and coal industries, Sydney has examined a variety of economic development possibilities including tourism and culture, light manufacturing and information technology. Cleaning up the former steel plant, and the toxic Sydney Tar Ponds it left behind in Muggah's Creek, were a source of controversy due to its health effects on residents, although it has provided some employment since SYSCO closed. The tar pond cleanup was completed in 2013 with the opening of Open Hearth Park, which sits on the direct site of the former steel plant and has hosted events such as an Aerosmith concert in September 2014.
Geography.
Sydney is on the east bank of the Sydney River where it discharges into South Arm of Sydney Harbour. Elevation ranges from sea level to above sea level.
The majority of properties within the former city limits have been impacted by development and an extensive urban road network. The central business district is located on a peninsula extending into South Arm formed by Sydney River on the west side and Muggah Creek on the east side. The largest park in the former city limits is Wentworth Park.
Distinctive neighbourhoods include Whitney Pier in the north east end next to the former steel plant site, Ashby in the east end, Hardwood Hill in the south end and the "North End" located on the peninsula which contains the Holy Angels convent and the Sydney Garrison known as Victoria Park, headquarters of the Cape Breton Highlanders reserve infantry regiment. The former city completely encircles the Membertou First Nation (First Nations Reserve 28A and 28B).
Climate.
Sydney experiences a cool summer, and windy, wet and stormy winter, version of a humid continental climate (Köppen "Dfb") that is significantly moderated by the community's proximity to the Atlantic Ocean. The highest temperature ever recorded was on 18 August 1935,
Due to the relatively strong influence from large bodies of water, Sydney experiences strong seasonal lag, meaning February is the year's coldest month on average, and August is the year's warmest month on average. By contrast, in most continental climates in the Northern Hemisphere, January is the coldest month, July the warmest.
In other respects, too, Sydney's climate varies significantly from that of other areas with humid continental climates. The most significant variations are that Sydney experiences unusually cool summers, and relatively windy, wet and stormy winters, relative to other humid-continental areas such as in the interior of North America. Annual temperatures are instead rather similar to areas around the Baltic Sea in north-eastern Europe at much higher latitudes, although Sydney's seasonal lag is stronger. Although Sydney has some maritime influence, similar latitudes on the other side of the Atlantic have significantly milder climates in all seasons except summer. Sydney is in the direct path of fall and winter storms (in the U.S., called nor'easters) migrating from the U.S. Northeastern and New England states; these storms can attain tremendous intensity by the time they approach Sydney, with high winds, heavy snow, ice and/or rain events common, primarily from October to March. Summer thunderstorms are rare in Sydney, because nearby bodies of cool water sharply inhibit the combination of heat and humidity that fuels summer-season thunderstorms elsewhere (for example, the United States' central and southeastern states, and east-central and northern China).
While occasional thunderstorms and other rains can occur in summer, June through August are Sydney's driest months on average. Sydney's average annual precipitation cycle reflects these realities; the year's driest month, on average, is July; its wettest month, on average, is December. Average annual precipitation in Sydney is nearly 60 inches, virtually the highest found anywhere in Canada outside coastal British Columbia. Snowfall is heavy, averaging over 110 inches per winter season. However, winter-season storms are variable, and can bring changing precipitation types, commonly from ice/snow to rain and possibly back to ice/snow. As such, actual snow accumulation is variable. A winter storm can bring accumulating snow, followed by heavy rain, then a brief return to snow or ice, resulting in no or minimal additional snow accumulation. Overall, Sydney's climate is moderately cold and strikingly variable, wet, stormy and windy from fall to early spring (October to March), and more stable and drier in summer (June to August).
Demographics.
Statistics Canada classifies Sydney as a medium population centre, which for census purposes includes the neighbouring communities of Westmount, a significant portion of Sydney River, and other portions of the former Cape Breton County. The 2011 population of the Sydney census area, was 31,597, making it the largest population centre on Cape Breton Island.
Economy.
Sydney suffered an economic decline for several decades in the later part of the 20th century as local coal and steel industries underwent significant changes. The closure of the Sydney Steel Corporation's steel mill and the Cape Breton Development Corporation's coal mines in 2000-2001 have resulted in attempts by the municipal, provincial and federal governments to diversify the area economy.
At the start of the 21st century, Sydney faces a significant challenge in the cleanup of the Sydney Tar Ponds, a tidal estuary contaminated with a variety of coal-based wastes from coke ovens that supplied the steel industry. After extensive public consultation and technical study, a $400 million CAD cleanup plan jointly funded by the federal and provincial governments awaits further environmental assessment.
In one part of Whitney Pier, residents of Frederick St. discovered contamination within several homes and in surrounding soil, including a toxic orange substance oozing into local basements. Testing of the substance lasted over a year and many were outraged by delays, although some residents were subsequently relocated to a safer residential area nearby.
High unemployment and lack of opportunities have resulted in many educated young people leaving the community for jobs in other parts of Canada and the US. Demographic changes, including an aging population and decrease in the birth rate have begun to affect the area's economic outlook. Specifically, many residents have opted to seek work in Alberta and Ontario.
Sydney's economy was buoyed by the 2011 announcement of funding for the Sydney Harbour dredging project, which was completed in 2012. The dredge, which is expected to lead to commercialization of the port, is purported to create hundreds of jobs in the area, and position Sydney as a world-class harbour facility. Other important investments that have helped position Sydney as an eastern hub of Nova Scotia include the twinning of Highway 125 and the creation of the Centre for Sustainability in the Environment at nearby Cape Breton University, which draws hundreds of international students each year.
Tourism.
In recent decades, Cape Breton Island has become home to a significant tourism industry, with Sydney (as the island's largest urban centre) being a prime beneficiary. Until the early 2000s when its economy was tied to the steel industry, Sydney had been overlooked as a tourist destination, with the more centrally located scenic village of Baddeck being a preferred location for tourists transiting the Cabot Trail. However, Sydney has recently witnessed a revival as a result of significant government investment in cruise ship facilities and a waterfront revitalization plan which has seen a boardwalk and marinas constructed, and the world's largest fiddle. This funding is part of the post-industrial adjustment package offered by the federal and provincial governments.
Sydney's tourism draw is increasingly linked to its cultural asset as being the urban heart of Cape Breton Island. Its population is a diverse mixture of nationalities which contributes to various Scottish, Acadian, African Canadian and eastern European cultural events being held throughout the year. Sydney's accommodation sector is centrally located to attractions in Louisbourg (home of the Fortress of Louisbourg), Glace Bay (home of the Glace Bay Miners Museum), Baddeck (home of the Alexander Graham Bell Museum), as well as popular touring destinations such as the Cabot Trail, Cape Breton Highlands National Park, and Bras d'Or Lake.
Transportation.
Sydney is served by Highway 125 which connects to Highway 105 and encircles the former city limits to its eastern terminus. Trunk 4 forms an important secondary road in Sydney running along the Sydney River, connecting to Glace Bay. Trunk 22, connecting to Louisbourg, and Trunk 28, connecting Whitney Pier through to New Waterford, form minor secondary roads.
Sydney is home to two private freight railway companies. The Cape Breton and Central Nova Scotia Railway makes Sydney its eastern terminus and provides rail connections to CN in Truro via Port Hawkesbury. The Sydney Coal Railway connects a bulk coal unloading pier in Whitney Pier with the Lingan Generating Station in Lingan. Daily passenger rail service was provided by Via Rail Canada until budget cuts on January 15, 1990. A weekly tourist train, the "Bras d'Or" was operated by Via Rail Canada from 2000 to 2004 until being discontinued.
Sydney's port facilities include the privately owned bulk coal unloading pier in Whitney Pier as well as the publicly owned Sydney Marine Terminal at the northern edge of the central business district. A recently opened cruise ship pavilion welcomes several dozen cruise ships every year, with the majority visiting in late summer or early fall to take in fall foliage tours. Other port facilities on Sydney Harbour are located outside the former city limits in Point Edward (Sydport) and North Sydney (Marine Atlantic ferry terminal).
The J.A. Douglas McCurdy Sydney Airport is located several kilometres outside the former city limits in Reserve Mines. Air Canada Express operates 7 flights daily with direct service to Halifax and Toronto. As of February 13, 2009, WestJet operates 1 flight daily to and from Toronto between May and November. Other carriers may also offer seasonal service. WestJet also offers regional flights to and from Halifax.
Media.
Sydney is the island's largest commercial centre and home to the "Cape Breton Post" daily newspaper, as well as one television station, CJCB-TV, a member of the CTV Television Network. CJCB was the first television station in Nova Scotia, going on air on 9 October 1954. It was also the eastern terminus of the original country-wide microwave network that went live on 1 July 1958, with the Canada's first coast to coast television broadcast. From its beginnings until 1972, CJCB-TV was the area's CBC affiliate.
Sydney's first radio station was CJCB-AM, founded by Nate Nathanson, and went on the air on 14 February 1929. The Nathanson family would go on to open an FM radio station in 1957, CJCB-FM, and the above-mentioned television station. CBC began operating its own station, CBI-AM, in November 1948. It was part of the CBC's Trans-Canada Network, while CJCB became a CBC affiliate for its Dominion Network. In 1962, the CBC combined the two networks, making CBI the only CBC station, and CJCB became an independent. In 1978, the CBC opened CBI-FM, which belonged to the CBC Stereo network. After 1997, CBI-AM belongs to CBC Radio One and CBI-FM belongs to CBC Radio Two. Besides the CBC and CJCB stations, there are other FM radio stations serving the area, most coming into the market in the early 21st century.
Education.
Sydney is part of the Cape Breton – Victoria Regional School Board and is home to one public English language secondary school: Sydney Academy, which is linked to several elementary and intermediate schools. Holy Angels, a female-only Catholic high school founded in the late 1800s, closed at the end of the 2011 school year. A French language school, Étoile de l'Acadie, is also located in Sydney and is part of the Conseil scolaire acadien provincial school board.
In 1951, the original campus of what became Cape Breton University was founded as the Xavier Junior College, affiliated with St. Francis Xavier University and was located in Sydney.
Sydney also has other post secondary and private career colleges, including the Cape Breton Business College founded in 1958.
Sports.
Semi-professional hockey has a long tradition in Sydney. In December 1912, a group formed a professional hockey club to challenge for the Stanley Cup. The short-lived Sydney Millionaires, who received that nickname because the players were the highest paid in the Maritimes, won the 1913 Maritime Professional Hockey League championship. Their victory allowed them to challenge the Quebec Bulldogs, the then current cup holder, in Quebec City. On 10 March 1913, the Millionaires lost the second and final game of the Stanley Cup, and folded shortly thereafter.
From 1988 to 1996, Sydney was home to the Cape Breton Oilers of the AHL, the primary farm team of the NHL's Edmonton Oilers. They won that league's championship, the Calder Cup, in 1993. The franchise moved to Hamilton, Ontario after the 1995-96 season, becoming the Hamilton Bulldogs.
The Cape Breton Screaming Eagles of the QMJHL play their home games at Centre 200. The franchise, which came into the league in 1969 as the Sorel Éperviers, moved to Sydney from Granby, Quebec in 1997, just one year after winning the Memorial Cup.
In September 2015, the National Basketball League of Canada officially admitted the Cape Breton Highlanders into the league starting in the 2016–17 season.

</doc>
<doc id="58273" url="https://en.wikipedia.org/wiki?curid=58273" title="List of counties in Florida">
List of counties in Florida

There are 67 counties in the state of Florida. It became a territory of the U.S. in 1821 with two counties complementing the provincial divisions retained as a Spanish territory: Escambia to the west and St. Johns to the east, divided by the Suwanee River. All of the other counties were apportioned from these two original counties. Florida became the 27th U.S. state in 1845, and its last county was created in 1925 with the formation of Gilchrist County from a segment of Alachua County. Florida's counties are subdivisions of the state government. In 1968, counties gained the power to develop their own charters. All but two of Florida's county seats are incorporated municipalities. The exceptions are Crawfordville, county seat of rural Wakulla County, and East Naples, located outside Naples city limits in Collier County.
The names of Florida's counties reflect its diverse cultural heritage. Some are named for Southern political leaders and Spanish explorers, marking the influence of Spanish sovereignty, while others are named for Spanish saints, Native American placenames used by the Spanish, and political leaders of the United States. Natural features of the region, including rivers, lakes, and flora, are also commonly used for county names. Florida has counties named for participants on both sides of Second Seminole War: Miami-Dade County is partially named for Francis L. Dade, a Major in the U.S. Army at the time; Osceola County is named for a Native American resistance leader during the war.
Population figures are based on the 2010 United States Census. The population of Florida is 18,801,310, an increase of 17.6% from 2000. The average population of Florida's counties is 280,616; Miami-Dade County is the most populous (2,662,874) and Liberty County is the least (8,365). The average land area is 805 sq mi (2,085 km2). The largest county is Palm Beach County (2,034 sq mi, 5,268 km2) and the smallest is Union County (240 sq mi, 622 km2). The total area of the state is 65,795  sq miles; of this, the land area of the state constitutes while the water area constitutes 11,868  sq miles.
The Federal Information Processing Standard (FIPS) is used by the U.S. government to uniquely identify counties, and is provided for each entry. These codes link to the United States Census Bureau's "quick facts" for each county. Florida's FIPS code of 12 is used to distinguish from counties in other states. For example, Alachua County's unique nationwide identifier is 12001.
__TOC__
Former counties.
Fayette County was created in 1832 from the portion of Jackson County east of the Chipola River, with county seat at Ochesee (now in Calhoun County east of Altha). In 1834 it was merged back into Jackson County.
Renamed counties.
Five counties in Florida have been renamed. Most renamings occurred between 1845 and 1861, during the first sixteen years of Florida's statehood. One occurred in 1997, when Dade County changed its name to Miami-Dade County.
Proposed counties.
Two counties were proposed in Florida's state legislature, but neither actually became counties. A bill was passed by the legislature to create Bloxham County, but residents did not vote to approve it. See Leigh Read County, Florida for the events surrounding the proposed county.

</doc>
<doc id="58275" url="https://en.wikipedia.org/wiki?curid=58275" title="List of counties in Idaho">
List of counties in Idaho

This is a list of 44 counties in the U.S. state of Idaho.
Each county in Idaho has a license plate prefix, according to the first letter of the county name. The first county for a given letter is given #1, the second county #2, etc. For example, Ada and Adams are the only two counties with the letter 'A'. Since Ada comes before Adams alphabetically, Ada is '1A' while Adams is '2A.' There are four counties that start with the letter 'L': Latah, Lemhi, Lewis, and Lincoln; the license plate prefixes for these counties are 1L, 2L, 3L, and 4L, respectively.
Elmore, Idaho, Kootenai, Nez Perce, Shoshone, Valley, and Washington counties are the only ones in the state with those beginning letters. Therefore, the license plate prefix would be the first letter of the county name, without a number. The letter 'B' has ten counties, 'C' has seven, and 'L' has four; the remaining letters have two or fewer.
When the Idaho Territory was created in March 1863, there were five original counties: Shoshone, Nez Perce, Idaho, Boise, and Missoula. Kootenai, Owyhee, and Oneida were created by 1865, Ada was created in 1866, and when the territory reached Idaho's present day dimensions in 1868, Lemhi was formed. By 1880, 13 counties were created. Ten years later, when Idaho became a state, 18 counties were created. In 1893, Fremont and Bannock counties were created. By 1900, Idaho had 21 counties. Ten years later, only two new counties were created. Between 1910 and 1920, 21 new counties were created, bringing the number of counties to 44, where it remains today.
Remember the counties.
In some fourth grade classrooms, students memorize the counties with the following poem:
Counties of Idaho Poem
Ada is first with our capital town,
Adams’ Seven Devils go straight up and down.
Then ten counties start with B;
Bannock, Bear Lake, Benewah three;
Bingham, Blaine, Boise, Bonner,
Bonneville, Boundary, Butte make ten.
Then the next seven start with C:
Camas, Canyon, Caribou three.
Cassia, Clark, Clearwater, Custer,
Are the Idaho C’s we can muster.
Elmore, Franklin, Fremont, Gem,
Gooding and Idaho don’t forget them.
Flatlands of Jefferson,
Potatoes of Jerome,
Kootenai, Latah, we’re almost home.
Lemhi and Lewis,
Hurry, hurry, hurry!
Lincoln with its ice caves
Very very burry.
Madison, Minidoka, Nez Perce;
Our Indian accent grows worse and worse.
Oneida, Owyhee, a little faster please
Payette and Power are the only Ps.
Shoshone, Teton, Twin Falls, almost done,
Valley County and Washington.
"Author unknown"

</doc>
<doc id="58276" url="https://en.wikipedia.org/wiki?curid=58276" title="List of counties in Indiana">
List of counties in Indiana

The U.S. state of Indiana has 92 counties. Each county serves as the local level of government within its borders. Although Indiana was organized into the United States since the Northwest Ordinance in 1787, its land was not always available for settlement. Eventually, land was purchased from Native Americans by treaties and Indian removals. The oldest counties are generally in the south near the Ohio River, whereas newer ones were in the north in territory acquired later. The oldest and newest counties in Indiana are Knox County, created in 1790, and Newton County, created in 1859.
As of the 2000 United States Census, the population of Indiana was 6,045,485, the average population of Indiana's 92 counties is 65,712, with Marion County as the most populous (903,393), and Ohio County (5,623) the least. 54 counties have 30,000 or more people; 16 counties have populations exceeding 100,000, five of which exceed 250,000; and only five counties have fewer than 10,000 people. The average land area is . The largest county is Allen (657 sq. mi., 1,702 km²) and the smallest is Ohio (86 sq. mi., 223 km²). According to the Constitution of Indiana, no county may be created of less than , nor may any county smaller than this be further reduced in size.
County government in Indiana consists of two bodies, the county council and the commissioners.
Many Indiana counties are named for United States Founding Fathers and personalities of the American Revolutionary War, the War of 1812 and Battle of Tippecanoe; early leaders of Indiana Territory and Indiana, as well as surrounding states like Michigan and Kentucky; plus Native American tribes and geographical features.
The Federal Information Processing Standard (FIPS) code, which is used by the United States government to uniquely identify states and counties, is provided with each entry. Indiana's code is 18, which when combined with any county code would be written as 18XXX. The FIPS code for each county links to census data for that county.
In Indiana, the most commonly seen number associated with counties is the state county code, which is a sequential number based on the alphabetical order of the county.
It has been used on automobile license plates since 1963. It first held a prominent place on the left side of the plates as part of the license plate number until the year 2008 when it was moved above the serial number and 2012 when it was moved to the lower right corner. On license plate numbers, county codes 93 - 99 were also used for Marion county in addition to 49.
__NOTOC__

</doc>
<doc id="58277" url="https://en.wikipedia.org/wiki?curid=58277" title="List of counties in Iowa">
List of counties in Iowa

There are 99 counties in the U.S. state of Iowa. The first two counties, Des Moines County and Dubuque County, were created in 1834 when Iowa was still part of the Michigan Territory. In preparation for Michigan's statehood, part of Michigan Territory was formed into Wisconsin Territory in 1836. Two years later, the western portion was split off to become Iowa Territory. The south-eastern part of Iowa Territory became Iowa, the 29th state in the union, on 28 December 1846, by which point 44 counties had been created. Counties continued to be created by the state government until 1857, when the last county, Humboldt County, was created. One of the most significant days in Iowa county history was January 15, 1851, on which 49 counties were created.
The Iowa Constitution of 1857, which is still in effect today, states that counties must have an area of at least , nor can any county be reduced below that size by boundary changes. However, exceptions to this rule were granted, as ten counties have areas below this size. (The table below shows land area, but the Constitution deals with total area.) The smallest county (Dickinson) has a land area of , while the largest (Kossuth) has an area 973 sq mi (2,520 km²). Polk County is the most densely populated county at , an increase in density from 2000 when it was . Polk County contains the state's capital and largest city, Des Moines. In addition Iowa has one of the fewest number of counties whose boundaries are dictated by natural means, the vast majority of which being formed by lines of survey instead, resulting in a large number of "box counties".
__NOTOC__
County information.
The number in the column headed "#" is the one used on the map from the National Atlas of the United States, shown on the left. The Federal Information Processing Standard (FIPS) code, which is used by the United States government to uniquely identify counties, is provided with each entry. The FIPS code for each county links to census data for that county.
Former counties.
The following counties no longer exist:

</doc>
<doc id="58278" url="https://en.wikipedia.org/wiki?curid=58278" title="List of counties in Kansas">
List of counties in Kansas

This is a list of counties in the U.S. state of Kansas. Select from the links at right to go directly to an article, or browse the listing below for additional information. Every license plate issued by the state contains the same two-letter abbreviation for the county in which its vehicle is registered.
Kansas has 105 counties, the sixth-highest total of any state. Many of the counties in the eastern part of the state are named after prominent Americans from the late 18th and early-to-mid-19th centuries, while those in the central and western part of the state are named for figures in the American Civil War. Several counties throughout the state bear names of Native American origin. No Kansas county has two words in its name.
Wyandotte County and the city of Kansas City operate as a unified government. As of January 1, 2009 Greeley County and the city of Tribune unified to form the Unified Government of Greeley County.

</doc>
<doc id="58279" url="https://en.wikipedia.org/wiki?curid=58279" title="Diffusivity">
Diffusivity

Diffusivity is a rate of diffusion, a measure of the rate at which particles or heat or fluids can spread.
It is measured differently for different mediums.
Diffusivity may refer to:

</doc>
<doc id="58281" url="https://en.wikipedia.org/wiki?curid=58281" title="List of counties in Maine">
List of counties in Maine

<onlyinclude>This is a list of the sixteen counties in the U.S. state of Maine. Before statehood, Maine was officially part of the state of Massachusetts and was called the District of Maine. Maine was granted statehood on March 15, 1820 as part of the Missouri Compromise. Nine of the sixteen counties had their borders defined while Maine was still part of Massachusetts, and hence are older than the state itself. Even after 1820, the exact location of the northern border of Maine was disputed with Britain, until the question was settled and the northern counties took their final, official form by the Webster-Ashburton Treaty, signed in 1842. Almost all of Aroostook County was disputed land until the treaty was signed.
The first county to be created was York County, created as York County, Massachusetts by the government of the Massachusetts Bay Colony in 1652 to govern territories it claimed in southern Maine. No new counties have been created since 1860, when Knox County and Sagadahoc County were created. The most populous counties tend to be located in the southwestern portion of the state, along the Atlantic seaboard. The largest counties in terms of land area are inland and further north. Maine's county names derive from a mix of British, American, and Native American sources, reflecting Maine's pre-colonial, colonial, and national heritage.
The Federal Information Processing Standard (FIPS) code, which is used by the United States government to uniquely identify states and counties, is provided with each entry. Maine's code is 23, which when combined with any county code would be written as 23XXX. The FIPS code for each county links to census data for that county.
<onlyinclude>
List.
<includeonly>
Song.
A song is taught to many elementary school children across the state, entitled the Maine County Song, to aid in memorizing the names of the state's 16 counties. It is sung to the tune of Yankee Doodle.
An alternate version as put forth by the Maine Secretary of State's Kids' Page:

</doc>
<doc id="58282" url="https://en.wikipedia.org/wiki?curid=58282" title="Thermal diffusivity">
Thermal diffusivity

In heat transfer analysis, thermal diffusivity is the thermal conductivity divided by density and specific heat capacity at constant pressure. It measures the ability of a material to conduct thermal energy relative to its ability to store thermal energy, and is approximately analogous to whether a material is "cold to the touch". It has the SI unit of m²/s. Thermal diffusivity is usually denoted "α" but "a", "κ", "K", and "D" are also used. The formula is:
where
Together, formula_5 can be considered the volumetric heat capacity (J/(m³·K)).
As seen in the heat equation,
thermal diffusivity is the ratio of the time derivative of temperature to its curvature, quantifying the rate at which temperature concavity is "smoothed out". In a sense, thermal diffusivity is the measure of thermal inertia. In a substance with high thermal diffusivity, heat moves rapidly through it because the substance conducts heat quickly relative to its volumetric heat capacity or 'thermal bulk'.
Thermal diffusivity is often measured with the flash method. It involves heating a strip or cylindrical sample with a short energy pulse at one end and analyzing the temperature change (reduction in amplitude and phase shift of the pulse) a short distance away.

</doc>
<doc id="58283" url="https://en.wikipedia.org/wiki?curid=58283" title="Prandtl number">
Prandtl number

The Prandtl number (Pr) or Prandtl group is a dimensionless number, named after the German physicist Ludwig Prandtl, defined as the ratio of momentum diffusivity to thermal diffusivity. That is, the Prandtl number is given as:
where:
Note that whereas the Reynolds number and Grashof number are subscripted with a length scale variable, the Prandtl number contains no such length scale in its definition and is dependent only on the fluid and the fluid state. As such, the Prandtl number is often found in property tables alongside other properties such as viscosity and thermal conductivity.
For most gases over a wide range of temperature and pressure, is approximately constant. Therefore, it can be used to determine the thermal conductivity of gases at high temperatures, where it is difficult to measure experimentally due to the formation of convection currents.
Typical values for are:
Small values of the Prandtl number, , means the thermal diffusivity dominates. Whereas with large values, , the momentum diffusivity dominates the behavior.
For example, the listed value for liquid mercury indicates that the heat conduction is more significant compared to convection, so thermal diffusivity is dominant.
However, for engine oil, convection is very effective in transferring energy from an area in comparison to pure conduction, so momentum diffusivity is dominant.
In heat transfer problems, the Prandtl number controls the relative thickness of the momentum and thermal boundary layers. When is small, it means that the heat diffuses quickly compared to the velocity (momentum). This means that for liquid metals the thickness of the thermal boundary layer is much bigger than the velocity boundary layer.
The mass transfer analog of the Prandtl number is the Schmidt number.

</doc>
<doc id="58285" url="https://en.wikipedia.org/wiki?curid=58285" title="Nusselt number">
Nusselt number

In heat transfer at a boundary (surface) within a fluid, the Nusselt number (Nu) is the ratio of convective to conductive heat transfer across (normal to) the boundary. In this context, convection includes both advection and diffusion. Named after Wilhelm Nusselt, it is a dimensionless number. The conductive component is measured under the same conditions as the heat convection but with a (hypothetically) (or motionless) fluid. A similar non-dimensional parameter is Biot Number, with the difference that the thermal conductivity is of the solid body and not the fluid.
A Nusselt number close to one, namely convection and conduction of similar magnitude, is characteristic of "slug flow" or laminar flow. A larger Nusselt number corresponds to more active convection, with turbulent flow typically in the 100–1000 range.
The convection and conduction heat flows are parallel to each other and to the surface normal of the boundary surface, and are all perpendicular to the mean fluid flow in the simple case.
where "h" is the convective heat transfer coefficient of the flow, "L" is the characteristic length, "k" is the thermal conductivity of the fluid. 
In contrast to the definition given above, known as "average Nusselt number", local Nusselt number is defined by taking the length to be the distance from the surface boundary to the local point of interest.
The "mean", or "average", number is obtained by integrating the expression over the range of interest, such as:
The mass transfer analog of the Nusselt number is the Sherwood number.
Introduction.
An understanding of convection boundary layers is necessary to understanding convective heat transfer between a surface and a fluid flowing past it. A thermal boundary layer develops if the fluid free stream temperature and the surface temperatures differ. A temperature profile exists due to the energy exchange resulting from this temperature difference. The temperature profile only exists if a flux capacitor is present as discovered by Dr. Chan with help from Dr Koblich.
The heat transfer rate can then be written as,
And because heat transfer at the surface is by conduction,
These two terms are equal; thus
Rearranging,
Making it dimensionless by multiplying by representative length L,
The right hand side is now the ratio of the temperature gradient at the surface to the reference temperature gradient. While the left hand side is similar to the Biot modulus. This becomes the ratio of conductive thermal resistance to the convective thermal resistance of the fluid, otherwise known as the Nusselt number, Nu.
Derivation.
The Nusselt number may be obtained by a non dimensional analysis of Fourier's law since it is equal to the dimensionless temperature gradient at the surface:
Indeed, if: formula_11, and formula_12
we arrive at
then we define
so the equation becomes
By integrating over the surface of the body:
formula_16,
where formula_17
Empirical Correlations.
Typically, for free convection, the average Nusselt number is expressed as a function of the Rayleigh number and the Prandtl number, written as: 
Otherwise, for forced convection, the Nusselt number is generally a function of the Reynolds number and the Prandtl number, or 
Free convection.
Free convection at a vertical wall.
Cited as coming from Churchill and Chu:
Free convection from horizontal plates.
If the characteristic length is defined
where formula_22 is the surface area of the plate and formula_23 is its perimeter.
Then for the top surface of a hot object in a colder environment or bottom surface of a cold object in a hotter environment
And for the bottom surface of a hot object in a colder environment or top surface of a cold object in a hotter environment
Forced convection on flat plate
Flat plate in laminar flow.
The local Nusselt number for laminar flow over a flat plate is given by
The average Nusselt number for laminar flow over a flat plate is given by
Forced convection in turbulent pipe flow.
Gnielinski correlation.
Gnielinski's correlation for turbulent flow in tubes:
where f is the Darcy friction factor that can either be obtained from the Moody chart or for smooth tubes from correlation developed by Petukhov:
The Gnielinski Correlation is valid for:
Dittus-Boelter equation.
The Dittus-Boelter equation (for turbulent flow) is an explicit function for calculating the Nusselt number. It is easy to solve but is less accurate when there is a large temperature difference across the fluid. It is tailored to smooth tubes, so use for rough tubes (most commercial applications) is cautioned. The Dittus-Boelter equation is:
where:
The Dittus-Boelter equation is valid for
Example The Dittus-Boelter equation is a good approximation where temperature differences between bulk fluid and heat transfer surface are minimal, avoiding equation complexity and iterative solving. Taking water with a bulk fluid average temperature of 20 °C, viscosity 10.07×10−4 Pa·s and a heat transfer surface temperature of 40 °C (viscosity 6.96×10−4, a viscosity correction factor for formula_41 can be obtained as 1.45. This increases to 3.57 with a heat transfer surface temperature of 100 °C (viscosity 2.82×10−4 Pa·s), making a significant difference to the Nusselt number and the heat transfer coefficient.
Sieder-Tate correlation.
The Sieder-Tate correlation for turbulent flow is an implicit function, as it analyzes the system as a nonlinear boundary value problem. The Sieder-Tate result can be more accurate as it takes into account the change in viscosity (formula_42 and formula_43) due to temperature change between the bulk fluid average temperature and the heat transfer surface temperature, respectively. The Sieder-Tate correlation is normally solved by an iterative process, as the viscosity factor will change as the Nusselt number changes.
where:
The Sieder-Tate correlation is valid for
Forced convection in fully developed laminar pipe flow.
For fully developed internal laminar flow, the Nusselt numbers are constant-valued. The values depend on the hydraulic diameter.
For internal Flow:
where:
Convection with uniform surface heat flux for circular tubes.
From Incropera & DeWitt,
Convection with uniform surface temperature for circular tubes.
For the case of constant surface temperature,

</doc>
<doc id="58286" url="https://en.wikipedia.org/wiki?curid=58286" title="Native American gaming">
Native American gaming

Native American gaming refers to casinos, bingo halls, and other gambling operations on Indian reservations or other tribal land in the United States. Because these areas have tribal sovereignty, states have limited ability to forbid gambling there, as codified by the Indian Gaming Regulatory Act of 1988. As of 2011, there were 460 gambling operations run by 240 tribes, with total annual revenue of $27 billion.
History.
In the early 1970s, Russell and Helen Bryan, a married Chippewa couple living in a mobile home on Indian lands in northern Minnesota, received a property tax bill from the local county, Itasca County. The Bryans had never received a property tax bill from the county before. Unwilling to pay it, they took the tax notice to local legal aid attorneys at Leech Lake Legal Services, who brought suit to challenge the tax in the state courts. The Bryans lost their case in the state district court, and they lost again on appeal in a unanimous decision by the Minnesota Supreme Court. They then sought review in the United States Supreme Court. The Supreme Court granted review, and in a sweeping and unanimous decision authored by Justice Brennan, the Supreme Court held not only that states do not have authority to tax Indians on Indian reservations, but that they also lack the authority to "regulate" Indian activities by Indians on Indian reservations. As Gaming Law Professor Kevin K. Washburn has explained, the stage was now set for Indian gaming. Within a few years, enterprising Indians and tribes began to operate Indian bingo operations in numerous different locations around the United States.
Under the leadership of Howard Tommie, the Seminole Tribe of Florida built a large high-stakes bingo building on their reservation near Fort Lauderdale, Florida. The tribe planned for the bingo hall to be open six days a week, contrary to Florida state law which only allows two days a week for bingo halls to be open, as well as going over the maximum limit of $100 jackpots. The law was enacted from the charity bingo limits set by Catholic Churches. The sheriff of Broward County, where the Indian reservation lies, made arrests the minute the bingo hall opened, and the tribe sued the county ("Seminole Tribe v. Butterworth"), stating that Indian tribes have sovereignty rights that are protected by the federal government from interference by state government. A District court ruled in favor of the Indians, citing Chief Justice John Marshall in "Worcester v. Georgia". Here began the legal war of Indian gaming with a win for the Seminoles.
Controversy arose when Indians began putting private casinos, bingo rooms, and lotteries on reservation lands and began setting gaming prizes which were above the maximum legal limit of the state. The Indians argued for sovereignty over their reservations to make them immune from state laws such as Public Law 280, which granted states to have criminal jurisdiction over Indian reservations. States were afraid that Indians would have a significant competitive advantage over other gambling establishments in the state which were regulated, which would thus generate a vast amount of income for tribes.
In the late 1970s and continuing into the next decade, the delicate question concerning the legality of tribal gaming and immunity from state law hovered over the Supreme Court. The Court addressed the potential gambling had for organized crime through the Organized Crime Control Act of 1970. A report by the Department of Justice presented to the Senate Select Committee on Indian Affairs on March 18, 1992 concluded that through several years of FBI investigation, that organized crime had failed to infiltrate Indian gaming and that there was no link between criminal activity in Indian gaming and organized crime
Cabazon Band, 1980.
In the early 1960s, the Cabazon Band of Mission Indians, near Indio, California, were extremely poor and did not have much land because of neglected 1850s treaties by state senators. As Stuart Banner states, the Cabazon Band and the neighboring Morongo Reservation had "some HUD buildings and a few trailers, but that was about it. There was nothing really there. The people simply didn't have a lot." The Cabazon Band turned to casino operations, opening bingo and poker halls in 1980. Shortly thereafter, the Indio police and the Riverside County Sheriff shut down the gambling halls and arrested numerous Indians while seizing any cash and merchandise held in the tribe's possession. The Cabazon Band sued in federal court ("California v. Cabazon Band") and won, as did the Seminole Tribe in Florida. Although the tribe won in the lower courts, the Supreme Court reviewed the case in 1986 to reach a decision over whether Indian reservations are controlled by state law. The Court again ruled that Indian gaming was to be regulated exclusively by Congress and the federal government, not state government; with tribal sovereignty upheld, the benefits of gaming became available to many tribes.
Indian Gaming Regulatory Act.
In 1988 Congress passed the Indian Gaming Regulatory Act (IGRA) (signed by President Ronald Reagan) which kept tribal sovereignty to create casino like halls, but the states and Indians must be in Tribal-State compacts and the federal government has the power to regulate the gaming. These compacts have been used by state officials to confiscate Indian casino revenue which serves as a "special" tax on Indian reservations. Essentially, the tribes still have "exclusive right" to all classes of gaming except when states do not accept that class or it clashes with federal law.
Class III Indian gaming became a large issue for the states and federal government, because of these court cases, as Congress debated over a bill for Indian gaming called the Indian Gaming Regulatory Act.
Currently all attempts to challenge the Indian Gaming Regulatory Act on constitutional grounds have failed.
After President Reagan signed the IGRA, Indian gaming revenue skyrocketed from $100 million in 1988 to $16.7 billion in 2006. Following the IGRA, the National Indian Gaming Commission was created as a federal agency in 1988 to regulate high-stakes Indian gaming.
The Commission consists of three members: a chairman who is appointed by the US President with consent of the Senate, and two associate members appointed by the Secretary of the Interior. Each member serves a three-year term and must pass a detailed background check by the US Attorney General.
The NIGC withholds certain powers over Class II and Class III gaming. These include budget approval, civil fines, fees, subpoenas, and permanent orders. The NIGC monitors Class II gaming on Indian lands on a continuing basis through inspection, investigation, access to records, and contracts. As for Class III gaming, all contracts must be approved by the chairman of the NIGC. 200 of the 562 federally recognized tribes created Class III gaming of large casinos and high jackpots.
This rise of gaming not only brought great revenue, but also corruption. In January 2006, a court case involving lobbyists convicted of felonies such as conspiracy, fraud, and tax evasion. This was known as the Jack Abramoff Indian lobbying scandal. These lobbyists, Jack Abramoff, Ralph Reed, Jr., Grover Norquist, and Michael Scanlon, bribed members of Congress when lobbying for Indian casinos then they over charged their Indian clients; this generated around $90 million in fees from the Indians.
2006 legislation.
In 2006, Congress introduced legislation to protect their own casino interests from those tribes that are outside reservations. Further, the Bureau of Indian Affairs (BIA) has faced increasing pressure to tighten regulatory policy and oversight of casino approvals. In particular, the BIA has been instructed by Congress to implement new procedures after two decades of IGRA's existence. These procedures would allow local communities to have more influence in the siting of casinos in their community, and would make the process of casino approval more transparent. To many tribes, however, the proposed regulations will further encroach on tribal sovereignty.
Industry.
Statistics provided by the National Indian Gaming Commission (NIGC), indicate that there are 460 Indian gaming establishments in the US. These casinos are operated by 240 federally recognized tribes and offer Class I, Class II and Class III gaming. Gaming is divided into 3 classes. Class I and Class II are traditional Indian gaming such as bingo halls, poker halls, and lotteries, and requires no license. Class III gambling has high jackpots and high-stake games such as casinos, jai alai, and racetracks, and states feared that organized crime would infiltrate the Class III gaming on their reservations. The revenue generated in these establishments was close to $27.1 billion in 2011 up from $12.8 billion in 2001. The regions with largest revenues in 2011 were Sacramento ($6.9 billion) and Washington D. C. ($6.7 billion). The Native American gaming industry has been described as "recession-resistant", although tribes in many states (including Arizona, California, Connecticut and New Mexico) saw revenues fall at a similar rate to commercial casinos during the Great Recession of 2007-2009.
Tribal casinos in the eastern US generated roughly $3.8 billion in FY02. Those in the Central US recorded gross revenues of approximately $5.9 billion, while those in the Western US generated nearly $4.8 billion. Most of the revenues generated in the Indian gaming are from casinos located in or near large metropolitan areas. Currently, 12% of Indian gaming establishments generate 65% of Indian gaming revenues. Indian gaming operations located in the populous areas of the West Coast (primarily California) represent the fastest growing sector of the Indian gaming industry. As suggested by the above figures, the vast majority of tribal casinos are much less financially successful, particularly those in the Midwest and Great Plains. Many tribes see this limited financial success as being tempered by decreases in reservation unemployment and poverty rates, although socioeconomic deficits remain.
As of 2008 there are 562 federally recognized tribes in the United States, many of which have chosen not to game.
California gaming.
The largest casino in the state of California is the Pechanga Resort and Casino in Temecula, with 3,000+ slot machines and approximately of gaming space. Other notable gaming operations in California include the Morongo Casino, Resort & Spa, and the Chumash Casino.
Oklahoma gaming.
Indian gaming revenues in Oklahoma rose to $3.23 billion in 2010, representing 44 percent of all U.S. casinos. Oklahoma surpassed Connecticut as second in the United States for gaming revenue, according to Alan Meister, an economist with Nathan Associates Inc.
Oklahoma has 113 tribal casinos, more than any other state in the U.S. 
A 2015 report on U.S. Gaming says that Oklahoma has the most gaming machines.
WinStar World Casino in Thackerville, Oklahoma, is the third largest casino in North America with more than 500,000 square feet of gaming floor. The Indian Gaming Regulatory Act of 1988 mandates that net revenues of such gaming be directed to tribes for government, economic development and general welfare use; to charitable organizations and to help fund local governments. 
Approved by voters in 2004, Oklahoma’s State-Tribal Gaming Act created a tribal gaming compact allowing federally recognized American Indian tribes to operate, electronic bonanza-style bingo games, electronic amusement games, electronic instant bingo games and non house-banked card games. The current compact expires Jan. 1, 2020.
The Oklahoma Indian Welfare Act allowed any recognized tribe in Oklahoma to be federally incorporated, have the right to self-determination and make their own bylaws.
Connecticut gaming.
The Foxwoods Resort Casino opened in 1992 in Ledyard, Connecticut. Operated by the Mashantucket Pequot Tribe and earning $1.5 billion, it is more profitable than any one casino in Las Vegas or Atlantic City. With 7,200 slot machines and 380 table games, making the Foxwoods Casino the largest casino in the USA and second largest in the world after Venetian Macao with 550,000 square feet and casino space. The agreement between the Mashantucket Pequot Tribal Nation and the State of Connecticut promises the state $80 million or 25% of their annual slot revenue. For the first 10 years of operation, the state has received more than $1.7 billion from Foxwoods alone.
The Mohegan Sun Resort & Casino is also located in Connecticut. It has been in operation since 1996 and is operated by the Mohegan tribe and the South African casino conglomerate. This enterprise is and consists of 6,500 slot machines and 180 table games. It is the second largest casino in the United States, located a few miles away from Foxwoods in Uncasville, Connecticut.
The success of both casinos is due in no small part to their location roughly halfway between New York City and Boston.
The economic recession that began in 2007 took a heavy toll of receipts, and by 2012 both Foxwoods in Connecticut and its nearby rival the Mohegan Sun were deeply in debt. The "New York Times" said "Foxwoods is fighting for its life," with debts of $2.3 billion. In August 2012, the tribe owning the Foxwoods Casino restructured over a billion dollars in debt in an attempt to remain profitable.
Impact on Native American Economics.
Native American gaming has, in some instances, changed the face of tribal economies, but it has also proven to be very ineffective in other situations. Although tribal victories over the governmental and cultural oppression in the 1950s yielded a dynamic transformation, economic success fell short in comparison. Unemployment was down and personal income had increased, but only a handful of tribes had made economic changes. Their strides were spotty and fluctuated greatly from each Indian reservation. This was happening because, for most tribes, their lands were not economically productive, infrastructure was poor, and they were far away from prospering markets of large populations. In order to address the issue of poverty, Indian tribes were required to fuel some type of economic development. Indians sold some of their tribal land to prospecting non-Indians in order to stimulate economic growth, but tribal gaming has proved to be the single largest amount of income in the Indian community. However the United States government intervened in tribal affairs throughout the rise of Indian gaming.
Many tribal governments have seen substantial improvements in their ability to provide public services to their members, such as building schools, improving infrastructure, and shoring up the loss of native traditions. Tribal gaming operations have not been without controversy, however. A small number of tribes have been able to distribute large per-capita payments, generating considerable public attention. Additionally, the national expansion of Indian Gaming has led to a practice critics call "reservation shopping". This term describes tribes that, with the backing of casino investors, attempt to locate a casino off their reservation, usually near a large urban center. However, although authorized by the Indian Gaming Regulatory Act, only three such "off-reservation" casinos have been built to date.
Indian Gaming Working Group.
In June 2004, in an effort to identify and direct resources to Indian gaming matters, the FBI and NIGC created the Indian Gaming Working Group (IGWG). The IGWG's purpose is to identify resources to address the most pressing criminal violations in the area of Indian gaming. This group consists of representatives from a variety of FBI subprograms (i.e. Economic Crimes Unit, Money Laundering Unit, LCN/Organized Crime Unit, Asian Organized Crime Unit, Public Corruption/Government Fraud Unit, Cryptographic Racketeering Analysis Unit, and Indian Country Special Jurisdiction Unit) and other federal agencies, which include Department of Interior Office of Inspector General (DOI-OIG), NIGC, Internal Revenue Service Tribal Government Section (IRS-TGS), Department of Treasure Financial Crimes Enforcement Network (FINCEN), Department of Justice (DOJ), and Bureau of Indian Affairs Office of Law Enforcement Services (BIA-OLES). The IGWG meets monthly to review Indian gaming cases deemed to have a significant impact on the Indian gaming industry. As a result of these meetings, several investigations have been initiated and the IGWG, through its member agencies, has provided financial resources, travel funds, liaison assistance, personnel resources, coordination assistance and consultation.
The IGWG works in the following manner:
In order to properly detect the presence of illegal activity in the Indian gaming industry law enforcement offices with jurisdiction in Indian gaming violations should:

</doc>
<doc id="58287" url="https://en.wikipedia.org/wiki?curid=58287" title="Grashof number">
Grashof number

The Grashof number (Gr) is a dimensionless number in fluid dynamics and heat transfer which approximates the ratio of the buoyancy to viscous force acting on a fluid. It frequently arises in the study of situations involving natural convection. It is named after the German engineer Franz Grashof.
Applications.
The Grashof number is:
where:
The "L" and "D" subscripts indicate the length scale basis for the Grashof Number.
The transition to turbulent flow occurs in the range "108 < GrL < 109" for natural convection from vertical flat plates. At higher Grashof numbers, the boundary layer is turbulent; at lower Grashof numbers, the boundary layer is laminar.
The product of the Grashof number and the Prandtl number gives the Rayleigh number, a dimensionless number that characterizes convection problems in heat transfer.
Mass transfer.
There is an analogous form of the Grashof number used in cases of natural convection mass transfer problems.
where:
and:
Derivation.
The first step to deriving the Grashof number is manipulating the volume expansion coefficient, formula_6 as follows.
It should be noted that the formula_8 in the equation above, which represents specific volume, is not the same as the formula_8 in the subsequent sections of this derivation, which will represent a velocity. This partial relation of the volume expansion coefficient, formula_6, with respect to fluid density, formula_11, given constant pressure, can be rewritten as
where:
There are two different ways to find the Grashof number from this point. One involves the energy equation while the other incorporates the buoyant force due to the difference in density between the boundary layer and bulk fluid.
Energy Equation.
This discussion involving the energy equation is with respect to rotationally symmetric flow. This analysis will take into consideration the effect of gravitational acceleration on flow and heat transfer. The mathematical equations to follow apply both to rotational symmetric flow as well as two-dimensional planar flow.
where:
In this equation the superscript n is to differentiate between rotationally symmetric flow from planar flow. The following characteristics of this equation hold true.
This equation expands to the following with the addition of physical fluid properties:
From here we can further simplify the momentum equation by setting the bulk fluid velocity to 0 ("u" = 0).
This relation shows that the pressure gradient is simply a product of the bulk fluid density and the gravitational acceleration. The next step is to plug in the pressure gradient into the momentum equation.
Further simplification of the momentum equation comes by substituting the volume expansion coefficient, density relationship formula_28, found above, and kinematic viscosity relationship, formula_29, into the momentum equation.
To find the Grashof Number from this point, the preceding equation must be non-dimensionalized. This means that every variable in the equation should have no dimension and should instead be a ratio characteristic to the geometry and setup of the problem. This is done by dividing each variable by corresponding constant quantities. Lengths are divided by a characteristic length, formula_31. Velocities are divided by appropriate reference velocities, formula_32, which, considering the Reynolds number, gives formula_33. Temperatures are divided by the appropriate temperature difference, formula_34. These dimensionless parameters look like the following:
The asterisks represent dimensionless parameter. Combining these dimensionless equations with the momentum equations gives the following simplified equation.
where:
The dimensionless parameter enclosed in the brackets in the preceding equation is known as the Grashof Number:
Buckingham Pi Theorem.
Another form of dimensional analysis that will result in the Grashof number is known as the Buckingham Pi theorem. This method takes into account the buoyancy force per unit volume, formula_45 due to the density difference in the boundary layer and the bulk fluid.
This equation can be manipulated to give,
The list of variables that are used in the Buckingham Pi method is listed below, along with their symbols and dimensions.
With reference to the Buckingham Pi Theorem there are 9 – 5 = 4 dimensionless groups. Choose "L", formula_48 "k", "g" and formula_49 as the reference variables. Thus the formula_50 groups are as follows:
Solving these formula_55 groups gives:
From the two groups formula_60 and formula_61 the product forms the Grashof number:
Taking formula_29 and formula_64 the preceding equation can be rendered as the same result from deriving the Grashof number from the energy equation.
In forced convection the Reynolds number governs the fluid flow. But, in natural convection the Grashof number is the dimensionless parameter that governs the fluid flow. Using the energy equation and the buoyant force combined with dimensional analysis provides two different ways to derive the Grashof number.

</doc>
<doc id="58288" url="https://en.wikipedia.org/wiki?curid=58288" title="Louse">
Louse

Louse (plural: lice) is the common name for members of the order Phthiraptera, which contains nearly 5,000 species of wingless insect. Lice are obligate parasites, living externally on warm-blooded hosts which include every species of bird and mammal, except for monotremes, pangolins, bats and cetaceans. Lice are vectors of diseases such as typhus.
Chewing lice live among the hairs or feathers of their host and feed on skin and debris, while sucking lice pierce the host's skin and feed on blood and other secretions. They usually spend their whole life on a single host, cementing their eggs, which are known as nits, to hairs or feathers. The eggs hatch into nymphs, which moult three times before becoming fully grown, a process that takes about four weeks.
Humans host three species of louse, the head louse, the body louse and the pubic louse. The body louse has the smallest genome of any known insect; it has been used as a model organism and has been the subject of much research.
Lice were ubiquitous in human society until at least the Middle Ages. They appear in folktales, songs such as "The Kilkenny Louse House", and novels such as James Joyce's "Finnegans Wake". They commonly feature in the psychiatric disorder delusional parasitosis. A louse was one of the early subjects of microscopy, appearing in Robert Hooke's 1667 book, "Micrographia".
Classification.
The order Phthiraptera is clearly a monophyletic grouping, united as the members are by a number of derived features including their parasitism on warm-blooded vertebrates and the combination of their metathoracic ganglia with their abdominal ganglia to form a single ventral nerve junction. The order has traditionally been divided into two suborders, the sucking lice (Anoplura) and the chewing (Mallophaga); however, recent classifications suggest that the Mallophaga are paraphyletic and four suborders are now recognized:
Nearly 5,000 species of louse have been identified, about 4,000 being parasitic on birds and 800 on mammals. Lice are present on every continent in all the habitats that their host animals and birds occupy. They are found even in the Antarctic, where penguins carry 15 species of lice (in the genera "Austrogonoides" and "Nesiotinus").
Description.
Sucking lice are small wingless insects ranging from in length. They have narrow heads and oval, flattened bodies. They have no ocelli, and their compound eyes are reduced in size or absent. Their antennae are short with three to five segments, and their mouth parts, which are retractable into their head, are adapted for piercing and sucking. There is a cibarial pump at the start of the gut; it is powered by muscles attached to the inside of the cuticle of the head. The mouthparts consist of a proboscis which is toothed, and a set of stylets arranged in a cylinder inside the proboscis, contaiing a salivary canal (ventrally) and a food canal (dorsally). The thoracic segments are fused, the abdominal segments are separate, and there is a single large claw at the tip of each of the six legs.
Chewing lice are also flattened and can be slightly larger than sucking lice, ranging in length from . They are similar to sucking lice in form but the head is wider than the thorax and all species have compound eyes. There are no ocelli and the mouthparts are adapted for chewing. The antennae have three to five segments and are slender in the suborder Ischnocera, but club-shaped in the suborder Amblycera. The legs are short and robust, and terminated by one or two claws. Many lice are specific to a single species of host and have co-evolved with it. They are usually cryptically coloured to match the fur or feathers of the host.
Biology.
Lice are divided into two groups: sucking lice, which obtain their nourishment from feeding on the sebaceous secretions and body fluids of their host; and chewing lice, which are scavengers, feeding on skin, fragments of feathers or hair, and debris found on the host's body. Most are found on only specific types of animals, and, in some cases, on only a particular part of the body; some animals are known to host up to fifteen different species, although one to three is typical for mammals, and two to six for birds. For example, in humans, different species of louse inhabit the scalp and pubic hair. Lice generally cannot survive for long if removed from their host. Some species of chewing lice house symbiotic bacteria in bacteriocytes in their bodies. These may assist in digestion because if the insect is deprived of them, it will die. If their host dies, lice can opportunistically use phoresis to hitch a ride on a fly and attempt to find a new host.
A louse's color varies from pale beige to dark gray; however, if feeding on blood, it may become considerably darker. Female lice are usually more common than males, and some species are parthenogenetic, with young developing from unfertilized eggs. A louse's egg is commonly called a nit. Many lice attach their eggs to their hosts' hair with specialized saliva; the saliva/hair bond is very difficult to sever without specialized products. Lice inhabiting birds, however, may simply leave their eggs in parts of the body inaccessible to preening, such as the interior of feather shafts. Living louse eggs tend to be pale whitish, whereas dead louse eggs are yellower.
Lice are exopterygotes, being born as miniature versions of the adult, known as nymphs. The young moult three times before reaching the final adult form, usually within a month after hatching.
Ecology.
The average number of lice per host tends to be higher in large-bodied bird species than in small ones. Lice have an aggregated distribution across bird individuals, i.e. most lice live on a few birds, while most birds are relatively free of lice. This pattern is more pronounced in territorial than in colonial—more social—bird species.
Host organisms that dive under water to feed on aquatic prey harbor fewer taxa of lice.
Bird taxa that are capable of exerting stronger antiparasitic defense—such as stronger T cell immune response or larger uropygial glands—harbor more taxa of Amblyceran lice than others.
Reductions in the size of host populations may cause a long-lasting reduction of louse taxonomic richness, for example, birds introduced into New Zealand host fewer species of lice there than in Europe.
Louse sex ratios are more balanced in more social hosts and more female-biased in less social hosts, presumably due to the stronger isolation among louse subpopulations (living on separate birds) in the latter case. The extinction of a species results in the extinction of its host-specific lice. Host-switching is a random event that would seem very rarely likely to be successful, but speciation has occurred over evolutionary time-scales so it must be successfully accomplished sometimes.
Lice may reduce host life expectancy if the infestation is heavy, but most seem to have little effect on their host. The habit of dust bathing in domestic hens is probably an attempt by the birds to rid themselves of lice. Lice may transmit microbial diseases and helminth parasites, but most individuals spend their whole life cycle on a single host and are only able to transfer to a new host opportunistically. 
Ischnoceran lice may reduce the thermoregulation effect of the plumage; thus heavily infested birds lose more heat than others.
Lice infestation is a disadvantage in the context of sexual rivalry.
The human body louse "Pediculus humanus humanus" has had its genome sequenced, and it turns out that it has the smallest insect genome yet known. This louse can transmit certain diseases while the human head louse ("P. h. capitis"), to which it is closely related, cannot. With their simple life history and small genomes, the pair make ideal model organisms to study the molecular mechanisms behind the transmission of pathogens and vector competence. In 2015 there were 5 cases of louse-borne relapsing fever being transmitted to locals reported in Italy.
Interaction with humans.
Prehistory.
Humans host three different kinds of lice: head lice, body lice, and pubic lice. Lice infestations can be controlled with lice combs, and medicated shampoos or washes.
Lice have been the subject of significant DNA research in the 2000s that led to discoveries on human evolution. The three species of sucking lice that parasitize human being belong to two genera: "Pediculus" and "Phthirus". head lice ("Pediculus humanus capitis"), body lice ("Pediculus humanus corporis"), and pubic lice ("Phthirus pubis"). Human head and body lice (genus Pediculus) share a common ancestor with chimpanzee lice, while pubic lice (genus "Phthirus") share a common ancestor with gorilla lice. Using phylogenetic and cophylogenetic analysis, Reed et al. hypothesized that "Pediculus" and "Phthirus" are sister taxa and monophyletic. In other words, the two genera descended from the same common ancestor. The age of divergence between "Pediculus" and its common ancestor is estimated to be 6-7 million years ago, which matches the age predicted by chimpanzee-hominid divergence. Because parasites rely on their hosts, host-parasite cospeciation events are likely.
For example, genetic evidence suggests that our human ancestors acquired pubic lice from gorillas approximately 3-4 million years ago. Unlike the genus "Pediculus", the divergence in "Phthirus" does not match the age of host divergence that likely occurred 7 million years ago. Reed et al. propose a "Phthirus" species host-switch around 3-4 million years ago. While it is difficult to determine if a parasite-host switch occurred in evolutionary history, this explanation is the most parsimonious (containing the fewest evolutionary changes).
Additionally, the DNA differences between head lice and body lice provide corroborating evidence that humans used clothing between 80,000 and 170,000 years ago, before leaving Africa. Human head and body lice occupy distinct ecological zones: head lice live and feed on the scalp, while body lice live on clothing and feed on the body. Because body lice require clothing to survive, the divergence of head and body lice from their common ancestor provides an estimate of the date of introduction of clothing in human evolutionary history.
The mitochondrial genome of the human species of body lice ("Pediculus humanus humanus"), the head louse ("Pediculus humanus capitis") and the pubic louse ("Phthirus pubis") fragmented into a number of minichromosomes, at least seven million years ago. Analysis of mitochondrial DNA in human body and hair lice reveals that greater genetic diversity existed in African than in non-African lice. Human lice can also shed light on human migratory patterns in pre-history. The dominating theory of anthropologists regarding human migration is the Out of Africa Hypothesis. Genetic diversity accumulates over time, and mutations occur at a relatively constant rate. Because there is more genetic diversity in African lice, the lice and their human hosts must have existed in Africa before anywhere else.
Modern history.
Lice have been intimately associated with human society throughout history. In the Middle Ages, they were essentially ubiquitous. At the death of Thomas Becket, Archbishop of Canterbury in 1270, it was recorded that "The vermin boiled over like water in a simmering cauldron, and the onlookers burst into alternate weeping and laughing". A mediaeval treatment for lice was an ointment made from pork grease, incense, lead, and aloe.
Robert Hooke's 1667 book, "Micrographia: or some physiological descriptions of minute bodies made by magnifying glasses with observations and Inquiries thereupon", illustrated a human louse, drawn as seen down an early microscope.
Margaret Cavendish's satirical "The Description of a New World, Called The Blazing-World" (1668) has "Lice-men" as "mathematicians", investigating nature by trying to weigh the air like the real scientist Robert Boyle.
In 1935 the Harvard medical researcher Hans Zinsser wrote the book "Rats, Lice and History", showing that both body and head lice transmit typhus between humans. Despite this, the modern view is that only the body louse can transmit the disease.
Soldiers in the trenches of the First World War suffered severely from lice, and the typhus they carried. The Germans boasted that they had lice under effective control, but themselves suffered badly from lice in the Second World War on the Eastern Front, especially in the Battle of Stalingrad. "Delousing" became a grim euphemism for the extermination of Jews in concentration camps such as Auschwitz under the Nazi regime.
In the psychiatric disorder delusional parasitosis, patients express a persistent irrational fear of animals such as lice and mites, imagining that they are continually infested and complaining of itching, with "an unshakable false belief that live organisms are present in the skin".
In literature and folklore.
James Joyce's 1939 book "Finnegans Wake" has the character Shem the Penman infested with "foxtrotting fleas, the lieabed lice, ... bats in his belfry".
Clifford E. Trafzer's "A Chemehuevi Song: The Resilience of a Southern Paiute Tribe" retells the story of Sinawavi (Coyote)'s love for Poowavi (Louse). Her eggs are sealed in a basket woven by her mother, who gives it to Coyote, instructing him not to open it before he reaches home. Hearing voices coming from it, however, Coyote opens the basket and the people, the world's first human beings, pour out of it in all directions.
The Irish songwriter John Lyons (b. 1934) wrote the popular song "The Kilkenny Louse House". The song contains the lines "Well we went up the stairs and we put out the light, Sure in less than five minutes, I had to show fight. For the fleas and the bugs they collected to march, And over me stomach they formed a great arch". It has been recorded by Christie Purcell (1952), Mary Delaney on "From Puck to Appleby" (2003), and the Dubliners on "Double Dubliners" (1972) among others.
Robert Burns dedicated a poem to the Louse, inspired by witnessing one on a lady's bonnet in church: "Ye ugly, creepin, blastid wonner, Detested, shunn'd, by saint and sinner, How dare ye set your fit upon her, sae fine lady! Gae somewhere else, and seek your dinner on some poor body." John Milton in "Paradise Lost" mentioned the biblical plague of lice visited upon pharoah: "Frogs, lice, and flies must all his palace fill with loathed intrusion, and filled all the land." John Ray recorded a Scottish proverb, "Gie a beggar a bed and he'll repay you with a Louse."
In Shakespeare's "Troilus and Cressida", Thersites compares Menelaus, brother of Agamemnon, to a louse: "Ask me not what I would be, if I were not Thersites; for I care not to be the louse of a lazar, so I were not Menelaus."

</doc>
