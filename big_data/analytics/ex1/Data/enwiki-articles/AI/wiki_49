<doc id="60520" url="https://en.wikipedia.org/wiki?curid=60520" title="Boxer Rebellion">
Boxer Rebellion

The Boxer Rebellion, Boxer Uprising or Yihequan Movement was a violent anti-foreign and anti-Christian uprising which took place in China towards the end of the Qing dynasty between 1899 and 1901. It was initiated by the Militia United in Righteousness ("Yihetuan"), known in English as the "Boxers", an offshoot of the Baguadao ("Way of the Eight Symbols") folk religious network of north China, and was motivated by proto-nationalist sentiments and opposition to imperialist expansion and associated Christian missionary activity. The Great Powers intervened and defeated the Chinese forces.
The uprising took place against a background of severe drought and the disruption caused by the growth of foreign spheres of influence. After several months of growing violence against the foreign and Christian presence in Shandong and the North China plain in June 1900, Boxer fighters, convinced they were invulnerable to foreign weapons, converged on Beijing with the slogan "Support Qing government and exterminate the foreigners." Foreigners and Chinese Christians sought refuge in the Legation Quarter. In response to reports of an armed invasion to lift the siege, the initially hesitant Empress Dowager Cixi supported the Boxers and on June21 declared war on the foreign powers. Diplomats, foreign civilians and soldiers as well as Chinese Christians in the Legation Quarter were placed under siege by the Imperial Army of China and the Boxers for 55 days.
Chinese officialdom was split between those supporting the Boxers and those favoring conciliation, led by Prince Qing. The supreme commander of the Chinese forces, the Manchu General Ronglu (Junglu), later claimed that he acted to protect the besieged foreigners. The Eight-Nation Alliance, after being initially turned back, brought 20,000 armed troops to China, defeated the Imperial Army, and captured Beijing on August14, lifting the siege of the Legations. Uncontrolled plunder of the capital and the surrounding countryside ensued, along with the summary execution of those suspected of being Boxers.
The Boxer Protocol of 7 September, 1901 provided for the execution of government officials who had supported the Boxers, provisions for foreign troops to be stationed in Beijing, and 450 million taels of silver—more than the government's annual tax revenue—to be paid as indemnity over the course of the next thirty-nine years to the eight nations involved.
Historical background.
Origins of the Boxers.
The Righteous and Harmonious Fists or "Boxers United in Righteousness" (Yihequan/I-ho-chuan) was a secret society which arose in the inland sections of the northern coastal province of Shandong. American missionaries were probably the first to refer to the well-trained, athletic young men as "Boxers", because of the martial arts and calisthenics they practiced. The Boxers' primary practice was spirit possession, which involved "the whirling of swords, violent prostrations, and chanting incantations to Taoist and Buddhist spirits".
The excitement and moral force of these possession rituals was especially attractive to unemployed and powerless village men, many of whom were teenagers. The Boxers believed that through training, diet, martial arts and prayer they could perform extraordinary feats, such as flight. Furthermore, they popularly claimed that millions of "spirit soldiers" would descend from the heavens and assist them in purifying China of foreign oppression. The Boxers, armed with rifles and swords, claimed supernatural invulnerability towards blows of cannon, rifle shots, and knife attacks. The Boxer beliefs were characteristic of millenarian movements, related to such practices as the Native American Ghost Dance, a practice of a different society under stress.
Several secret societies in Shandong prepared the way for the Boxers. In spite of ambivalence toward their heterodox practices, in 1895, Yuxian, a Manchu who was then prefect of Caozhou and would later become provincial governor, used the Big Swords Society in fighting bandits. The Big Swords, emboldened by this official support, also attacked their local Catholic village rivals, who turned to the Church for protection. The Big Swords responded by attacking Catholic churches and burning them. "The line between Christians and bandits", remarks one recent historian, "became increasingly indistinct." As a result of diplomatic pressure in the capital, Yuxian executed several Big Sword leaders, but did not punish anyone else. More secret societies started emerging after this.
The early years saw a variety of village activities, not a broad movement or a united purpose. Like the Red Boxing school or the Plum Flower Boxers, the Boxers of Shandong were more concerned with traditional social and moral values, such as filial piety, than with foreign influences. One leader, for instance, Zhu Hongdeng (Red Lantern Zhu), started as a wandering healer, specializing in skin ulcers, and gained wide respect by refusing payment for his treatments. Zhu claimed descent from Ming dynasty emperors, since his surname was the surname of the Ming Imperial Family. He announced that his goal was to "Revive the Qing and destroy the foreigners" ("扶清灭洋": "Fu Qing mie yang").
Although women were not allowed to join the Boxer units, they formed their own groups, the Red Lanterns. Local lore reported that they were able to fly, walk on water, set Christians' homes on fire, and stop foreign guns, powers which the male Boxers themselves did not claim. But the only reliable account of their actual activities comes from the Battle of Tientsin, when they nursed wounded Boxers and did work such as sewing and cleaning.
Causes of conflict and unrest.
International tension and domestic unrest fueled the spread of the Boxer movement. First, a drought followed by floods in Shandong province in 1897–1898 forced farmers to flee to cities and seek food. As one observer said, "I am convinced that a few days' heavy rainfall to terminate the long-continued drought ... would do more to restore tranquility than any measures which either the Chinese government or foreign governments can take."
A major cause of discontent in north China was missionary activity. The Treaty of Tientsin (or Tianjin) and the Convention of Peking, signed in 1860 after the Second Opium War, had granted foreign missionaries the freedom to preach anywhere in China and to buy land on which to build churches. On 1 November 1897, a band of armed men who were perhaps members of the Big Swords Society stormed the residence of a German missionary from the Society of the Divine Word and killed two priests. This attack is known as the Juye Incident. When Kaiser Wilhelm II received news of these murders, he dispatched the German East Asia Squadron to occupy Jiaozhou Bay on the southern coast of the Shandong peninsula. Germany's action triggered a "scramble for concessions" by which Britain, France, Russia and Japan also secured their own sphere of influence in China.
In October 1898, a group of Boxers attacked the Christian community of Liyuantun village where a temple to the Jade Emperor had been converted into a Catholic church. Disputes had surrounded the church since 1869, when the temple had been granted to the Christian residents of the village. This incident marked the first time the Boxers used the slogan "Support the Qing, destroy the foreigners" ("扶清灭洋": "Fu Qing mie yang") that would later characterise them. The "Boxers" called themselves the "Militia United in Righteousness" for the first time one year later, at the Battle of Senluo Temple (October 1899), a clash between Boxers and Qing government troops. By using the word "Militia" rather than "Boxers", they distanced themselves from forbidden martial arts sects, and tried to give their movement the legitimacy of a group that defended orthodoxy.
Aggression toward missionaries and Christians drew the ire of foreign (mainly European) governments. In 1899, the French minister in Beijing helped the missionaries to obtain an edict granting official status to every order in the Roman Catholic hierarchy, enabling local priests to support their people in legal or family disputes and bypass the local officials. After the German government took over Shandong many Chinese feared that the foreign missionaries and quite possibly all Christian activities were imperialist attempts at "carving the melon", i.e., to divide and colonize China piece by piece. A Chinese official expressed the animosity towards foreigners succinctly, "Take away your missionaries and your opium and you will be welcome."
The early growth of the Boxer movement coincided with the Hundred Days' Reform (11 June – 21 September 1898). Progressive Chinese officials, with support from Protestant missionaries, persuaded the Guangxu Emperor to institute reforms which alienated many conservative officials by their sweeping nature. Such opposition from conservative officials led Empress Dowager Cixi to intervene and reverse the reforms. The failure of the reform movement disillusioned many educated Chinese and thus further weakened the Qing government. After the reforms ended, the conservative Empress Dowager Cixi seized power and placed the reformist Guangxu Emperor under house arrest.
The national crisis was widely seen as being caused by foreign aggression. Foreign powers had defeated China in several wars, asserted a right to promote Christianity and imposed unequal treaties under which foreigners and foreign companies in China were accorded special privileges, extraterritorial rights and immunities from Chinese law, causing resentment and xenophobic reactions among the Chinese. France, Japan, Russia and Germany carved out spheres of influence, so that by 1900 it appeared that China would likely be dismembered, with foreign powers each ruling a part of the country. Thus, by 1900, the Qing dynasty, which had ruled China for more than two centuries, was crumbling and Chinese culture was under assault by powerful and unfamiliar religions and secular cultures.
Boxer War.
Intensifying crisis.
In January 1900, with a majority of conservatives in the imperial court, Empress Dowager Cixi changed her long policy of suppressing Boxers, and issued edicts in their defence, causing protests from foreign powers. In spring 1900, the Boxer movement spread rapidly north from Shandong into the countryside near Beijing. Boxers burned Christian churches, killed Chinese Christians and intimidated Chinese officials who stood in their way. American Minister Edwin H. Conger cabled Washington, "the whole country is swarming with hungry, discontented, hopeless idlers." On 30 May the diplomats, led by British Minister Claude Maxwell MacDonald, requested that foreign soldiers come to Beijing to defend the legations. The Chinese government reluctantly acquiesced, and the next day an international force of 435 navy troops from eight countries disembarked from warships and travelled by train from Dagu (Taku) to Beijing. They set up defensive perimeters around their respective missions.
On 5 June, the railway line to Tianjin was cut by Boxers in the countryside and Beijing was isolated. On 11 June, at Yongding gate, the secretary of the Japanese legation, , was attacked and killed by the soldiers of general Dong Fuxiang, who were guarding the southern part of the Beijing walled city. Armed with Mauser rifles but wearing traditional uniforms, Dong's troops had threatened the foreign Legations in the fall of 1898 soon after arriving in Beijing, so much that troops from the United States Marine Corps had been called to Beijing to guard the legations. The German Kaiser Wilhelm II was so alarmed by the Chinese Muslim troops that he requested the Caliph Abdul Hamid II of the Ottoman Empire to find a way to stop the Muslim troops from fighting. The Caliph agreed to the Kaiser's request and sent Enver Pasha ("not" the future Young Turk leader) to China in 1901, but the rebellion was over by that time.
Also on 11 June, the first Boxer, dressed in his finery, was seen in the Legation Quarter. The German Minister, Clemens von Ketteler, and German soldiers captured a Boxer boy and inexplicably executed him. In response, thousands of Boxers burst into the walled city of Beijing that afternoon and burned many of the Christian churches and cathedrals in the city, burning some victims alive. American and British missionaries had taken refuge in the Methodist Mission and an attack there was repulsed by American Marines. The soldiers at the British Embassy and German Legations shot and killed several Boxers, alienating the Chinese population of the city and nudging the Qing government toward support of the Boxers. The Muslim Gansu braves and Boxers, along with other Chinese then attacked and killed Chinese Christians around the legations in revenge for foreign attacks on Chinese.
Seymour Expedition.
As the situation grew more violent, a second international force of 2,000 sailors and marines under the command of the British Vice-Admiral Edward Seymour, the largest contingent being British, was dispatched from Dagu to Beijing on 10 June 1900. The troops were transported by train from Dagu to Tianjin with the agreement of the Chinese government, but the railway between Tianjin and Beijing had been severed. Seymour resolved to move forward and repair the railway, or progress on foot if necessary, keeping in mind that the distance between Tianjin and Beijing was only 120 km. When Seymour left Tianjin and started toward Beijing, it angered the imperial court. As a result, the pro-Boxer Manchu Prince Duan became leader of the Zongli Yamen (foreign office), replacing Prince Qing. Prince Duan was a member of the imperial Aisin Gioro clan (foreigners called him a "Blood Royal"), and Empress Dowager Cixi had named his son as next in line for the imperial throne. He became the effective leader of the Boxers, and he was extremely anti-foreigner like his friend Dong Fuxiang, and wanted to expel them from China. He soon ordered the Qing imperial army to attack the foreign forces. Confused by conflicting orders from Beijing, General Nie Shicheng let Seymour's army pass by in their trains.
After leaving Tianjin, the convoy quickly reached Langfang, but found the railway there to be destroyed. Seymour's engineers tried to repair the line, but the allied army found itself surrounded, as the railway both behind and in front of them had been destroyed. They were attacked from all parts by Chinese irregulars and Chinese governmental troops. Five thousand of Dong Fuxiang's "Gansu Braves" and an unknown number of "Boxers" won a costly but major victory over Seymour's troops at the Battle of Langfang on 18 June. As the allied European army retreated from Langfang, they were constantly fired upon by cavalry, and artillery bombarded their positions. It was reported that the Chinese artillery was superior to the European artillery, since the Europeans did not bother to bring along much for the campaign, thinking they could easily sweep through Chinese resistance. The Europeans could not locate the Chinese artillery, which was raining shells upon their positions. Mining, engineering, flooding and simultaneous attacks were employed by Chinese troops. The Chinese also employed pincer movements, ambushes and sniper tactics with some success against the foreigners.
News arrived on 18 June regarding attacks on foreign legations. Seymour decided to continue advancing, this time along the Beihe river, toward Tongzhou, from Beijing. By the 19th, they had to abandon their efforts due to progressively stiffening resistance and started to retreat southward along the river with over 200 wounded. Commandeering four civilian Chinese junks along the river, they loaded all their wounded and remaining supplies onto them and pulled them along with ropes from the riverbanks. By this point they were very low on food, ammunition and medical supplies. Unexpectedly they then happened upon the Great Xigu Arsenal, a hidden Qing munitions cache of which the Allied Powers had had no knowledge until then. They immediately captured and occupied it, discovering not only Krupp field guns, but rifles with millions of rounds of ammunition, along with millions of pounds of rice and ample medical supplies.
There they dug in and awaited rescue. A Chinese servant was able to infiltrate through the Boxer and Qing lines, informing the Eight Powers of the Seymour troops' predicament. Surrounded and attacked nearly around the clock by Qing troops and Boxers, they were at the point of being overrun. On 25 June, a regiment composed of 1,800 men (900 Russian troops from Port Arthur, 500 British seamen, with an ad hoc mix of other assorted Alliance troops) finally arrived on foot from Tientsin to rescue Seymour. Spiking the mounted field guns and setting fire to any munitions that they could not take (an estimated £3 million worth), Seymour, his force, and the rescue mission marched back to Tientsin, unopposed, on 26 June. Seymour's casualties during the expedition were 62 killed and 228 wounded.
Conflicting attitudes within the Qing imperial court.
Meanwhile, in Beijing, on 16 June, Empress Dowager Cixi summoned the imperial court for a mass audience and addressed the choices between using the Boxers to evict the foreigners from the city or seeking a diplomatic solution. In response to a high official who doubted the efficacy of the Boxers' magic, Cixi replied: 
Both sides of the debate at the imperial court realised that popular support for the Boxers in the countryside was almost universal and that suppression would be both difficult and unpopular, especially when foreign troops were on the march.
Two factions were active during this debate. On one side were anti-foreigners who viewed foreigners as invasive and imperialistic and evoked a nativist populism. They advocated taking advantage of the Boxers to achieve the expulsion of foreign troops and foreign influences. The pro-foreigners on the other hand advanced rapprochement with foreign governments, seeing the Boxers as superstitious and ignorant.
The event that tilted the Qing imperial government irrevocably toward support of the Boxers and war with the foreign powers was the attack of foreign navies on the Dagu Forts near Tianjin, on 17 June 1900.
Siege of the Beijing legations.
On 15 June, Qing imperial forces deployed electric mines in the River Beihe (Peiho) to prevent the Eight-Nation Alliance from sending ships to attack. 
With a difficult military situation in Tianjin and a total breakdown of communications between Tianjin and Beijing, the allied nations took steps to reinforce their military presence significantly. On 17 June they took the Dagu Forts commanding the approaches to Tianjin, and from there brought increasing numbers of troops on shore. When Cixi received an ultimatum demanding that China surrender total control over all its military and financial affairs to foreigners, 
she defiantly stated before the entire Grand Council, "Now they Powers have started the aggression, and the extinction of our nation is imminent. If we just fold our arms and yield to them, I would have no face to see our ancestors after death. If we must perish, why not fight to the death?" 
It was at this point that Cixi began to blockade the legations with the armies of the Peking Field Force, which began the siege. Cixi stated that "I have always been of the opinion, that the allied armies had been permitted to escape too easily in 1860. Only a united effort was then necessary to have given China the victory. Today, at last, the opportunity for revenge has come", and said that millions of Chinese would join the cause of fighting the foreigners since the Manchus had provided "great benefits" on China. 
On receipt of the news of the attack on the Dagu Forts on the 19th of June, Empress Dowager Cixi immediately sent an order to the legations that the diplomats and other foreigners depart Beijing under escort of the Chinese army within 24 hours.
The next morning, diplomats from the besieged legations met to discuss the Empress's offer. The majority quickly agreed that they could not trust the Chinese army. Fearing that they would be killed, they agreed to refuse the Empress's demand. The German Imperial Envoy, Baron Klemens Freiherr von Ketteler, was infuriated with the actions of the Chinese army troops and determined to take his complaints to the royal court. Against the advice of the fellow foreigners, the baron left the legations with a single aide and a team of porters to carry his sedan chair. On his way to the palace, von Ketteler was killed on the streets of Beijing by a Manchu captain. His aide managed to escape the attack and carried word of the baron's death back to the diplomatic compound. At this news, the other diplomats feared they also would be murdered if they left the legation quarter and they chose to continue to defy the Chinese order to depart Beijing. The legations were hurriedly fortified. Most of the foreign civilians, which included a large number of missionaries and businessmen, took refuge in the British legation, the largest of the diplomatic compounds. Chinese Christians were primarily housed in the adjacent palace (Fu) of Prince Su who was forced to abandon his property by the foreign soldiers.
On the 21st of June, Empress Dowager Cixi declared war against all foreign powers. Regional governors who commanded substantial modernised armies, such as Li Hongzhang at Canton, Yuan Shikai in Shandong, Zhang Zhidong at Wuhan and Liu Kunyi at Nanjing, refused to join in the imperial court's declaration of war and withheld knowledge of it from the public in the south. Yuan Shikai used his own forces to suppress Boxers in Shandong, and Zhang entered into negotiations with the foreigners in Shanghai to keep his army out of the conflict. The neutrality of these provincial and regional governors left the majority of Chinese out of the conflict.
The legations of the United Kingdom, France, Germany, Italy, Austria-Hungary, Spain, Belgium, the Netherlands, the United States, Russia and Japan were located in the Beijing Legation Quarter south of the Forbidden City. The Chinese army and Boxer irregulars besieged the Legation Quarter from 20 June to 14 August 1900. A total of 473 foreign civilians, 409 soldiers, marines and sailors from eight countries, and about 3,000 Chinese Christians took refuge there. Under the command of the British minister to China, Claude Maxwell MacDonald, the legation staff and military guards defended the compound with small arms, three machine guns, and one old muzzle-loaded cannon, which was nicknamed the "International Gun" because the barrel was British, the carriage Italian, the shells Russian and the crew American. Chinese Christians in the legations led the foreigners to the cannon and it proved important in the defence. Also under siege in Beijing was the Northern Cathedral ("Beitang") of the Catholic Church. The Beitang was defended by 43 French and Italian soldiers, 33 Catholic foreign priests and nuns, and about 3,200 Chinese Catholics. The defenders suffered heavy casualties especially from lack of food and mines which the Chinese exploded in tunnels dug beneath the compound. The number of Chinese soldiers and Boxers besieging the Legation Quarter and the Beitang is unknown.
On the 22nd and 23rd of June, Chinese soldiers and Boxers set fire to areas north and west of the British Legation, using it as a "frightening tactic" to attack the defenders. The nearby Hanlin Academy, a complex of courtyards and buildings that housed "the quintessence of Chinese scholarship ... the oldest and richest library in the world", caught fire. Each side blamed the other for the destruction of the invaluable books it contained.
After the failure to burn out the foreigners, the Chinese army adopted an anaconda-like strategy. The Chinese built barricades surrounding the Legation Quarter and advanced, brick by brick, on the foreign lines, forcing the foreign legation guards to retreat a few feet at a time. This tactic was especially used in the Fu, defended by Japanese and Italian sailors and soldiers, and inhabited by most of the Chinese Christians. Fusillades of bullets, artillery and firecrackers were directed against the Legations almost every night—but did little damage. Sniper fire took its toll among the foreign defenders. Despite their numerical advantage, the Chinese did not attempt a direct assault on the Legation Quarter although in the words of one of the besieged, "it would have been easy by a strong, swift movement on the part of the numerous Chinese troops to have annihilated the whole body of foreigners ... in an hour." American missionary Frank Gamewell and his crew of "fighting parsons" fortified the Legation Quarter, but impressed Chinese Christians to do most of the physical labour of building defences.
The Germans and the Americans occupied perhaps the most crucial of all defensive positions: the Tartar Wall. Holding the top of the tall and wide wall was vital. The German barricades faced east on top of the wall and west were the west-facing American positions. The Chinese advanced toward both positions by building barricades even closer. "The men all feel they are in a trap", said the American commander, Capt. John T. Myers, "and simply await the hour of execution." On 30 June, the Chinese forced the Germans off the Wall, leaving the American Marines alone in its defence. At the same time, a Chinese barricade was advanced to within a few feet of the American positions and it became clear that the Americans had to abandon the wall or force the Chinese to retreat. At 2 am on 3 July, 56 British, Russian and American marines and sailors, under the command of Myers, launched an assault against the Chinese barricade on the wall. The attack caught the Chinese sleeping, killed about 20 of them, and expelled the rest of them from the barricades. The Chinese did not attempt to advance their positions on the Tartar Wall for the remainder of the siege.
Sir Claude MacDonald said 13 July was the "most harassing day" of the siege. The Japanese and Italians in the Fu were driven back to their last defence line. The Chinese detonated a mine beneath the French Legation pushing the French and Austrians out of most of the French Legation. On 16 July, the most capable British officer was killed and the journalist George Ernest Morrison was wounded. But American Minister Edwin Hurd Conger established contact with the Chinese government and on 17 July, an armistice was declared by the Chinese. More than 40% of the legation guards were dead or wounded. The motivation of the Chinese was probably the realization that an allied force of 20,000 men had landed in China and retribution for the siege was at hand.
Officials and commanders at cross purposes.
The Manchu General Ronglu concluded that it was futile to fight all of the powers simultaneously, and declined to press home the siege. The Manchu Zaiyi (Prince Duan), an anti-foreign friend of Dong Fuxiang, wanted artillery for Dong's troops to destroy the legations. Ronglu blocked the transfer of artillery to Zaiyi and Dong, preventing them from attacking. Ronglu forced Dong Fuxiang and his troops to pull back from completing the siege and destroying the legations, thereby saving the foreigners and making diplomatic concessions. Ronglu and Prince Qing sent food to the legations, and used their Manchu Bannermen to attack the Muslim Gansu Braves ("Kansu Braves" in the spelling of the time) of Dong Fuxiang and the Boxers who were besieging the foreigners. They issued edicts ordering the foreigners to be protected, but the Gansu warriors ignored it, and fought against Bannermen who tried to force them away from the legations. The Boxers also took commands from Dong Fuxiang. Ronglu also deliberately hid an Imperial Decree from General Nie Shicheng. The Decree ordered him to stop fighting the Boxers because of the foreign invasion, and also because the population was suffering. Due to Ronglu's actions, General Nie continued to fight the Boxers and killed many of them even as the foreign troops were making their way into China. Ronglu also ordered Nie to protect foreigners and save the railway from the Boxers. Because parts of the Railway were saved under Ronglu's orders, the foreign invasion army was able to transport itself into China quickly. General Nie committed thousands of troops against the Boxers instead of against the foreigners. Nie was already outnumbered by the Allies by 4,000 men. General Nie was blamed for attacking the Boxers, as Ronglu let Nie take all the blame. At the Battle of Tianjin (Tientsin), General Nie decided to sacrifice his life by walking into the range of Allied guns.
Xu Jingcheng, who had served as the Qing Envoy to many of the same states under siege in the Legation Quarter, argued that "the evasion of extraterritorial rights and the killing of foreign diplomats are unprecedented in China and abroad." Xu and five other officials urged Empress Dowager Cixi to order the repression of Boxers, the execution of their leaders, and a diplomatic settlement with foreign armies. The Empress Dowager, outraged, sentenced Xu and the five others to death for "willfully and absurdly petitioning the Imperial Court" and "building subversive thought." They were executed on July 28, 1900 and their severed heads placed on display at Caishikou Execution Grounds in Beijing.
Reflecting this vacillation, some Chinese soldiers were quite liberally firing at foreigners under siege from its very onset. Empress Dowager Cixi did not personally order imperial troops to conduct a siege, and on the contrary had ordered them to protect the foreigners in the legations. Prince Duan led the Boxers to loot his enemies within the imperial court and the foreigners, although imperial authorities expelled Boxer troops after they were let into the city and went on a looting rampage against both the foreign and the Qing imperial forces. Older Boxers were sent outside Beijing to halt the approaching foreign armies, while younger men were absorbed into the Muslim Gansu army.
With conflicting allegiances and priorities motivating the various forces inside Beijing, the situation in the city became increasingly confused. The foreign legations continued to be surrounded by both Qing imperial and Gansu forces. While Dong Fuxiang's Gansu army, now swollen by the addition of the Boxers, wished to press the siege, Ronglu's imperial forces seem to have largely attempted to follow Empress Dowager Cixi's decree and protect the legations. However, to satisfy the conservatives in the imperial court, Ronglu's men also fired on the legations and let off firecrackers to give the impression that they, too, were attacking the foreigners. Inside the legations and out of communication with the outside world, the foreigners simply fired on any targets that presented themselves, including messengers from the imperial court, civilians and besiegers of all persuasions. Dong Fuxiang was denied artillery held by Ronglu which stopped him from leveling the legations, and when he complained to Empress Dowager Cixi on June 23, she dismissively said that "Your tail, is becoming too heavy to wag." The Alliance discovered large amounts of unused Chinese Krupp artillery and shells after the siege was lifted.
The armistice, although occasionally broken, endured until 13 August when, with an allied army led by the British Alfred Gaselee approaching Beijing to relieve the siege, the Chinese launched their heaviest fusillade on the Legation Quarter. As the foreign army approached, Chinese forces melted away.
Gaselee Expedition.
Foreign navies started building up their presence along the northern China coast from the end of April 1900. Several international forces were sent to the capital, with varying success, and the Chinese forces were ultimately defeated by the Eight-Nation Alliance of Austria-Hungary, France, Germany, Italy, Japan, Russia, the United Kingdom and the United States.
British Lieutenant-General Alfred Gaselee acted as the commanding officer of the Eight-Nation Alliance, which eventually numbered 55,000. The main contingent was composed of Japanese (20,840), Russian (13,150), British (12,020), French (3,520), U.S. (3,420), German (900), Italian (80), Austro-Hungarian (75) and anti-Boxer Chinese troops. The "First Chinese Regiment" which was praised for its performance, consisted of Chinese collaborators serving in the British military. The international force finally captured Tianjin on 14 July under the command of the Japanese Colonel Kuriya, after one day of fighting.
Notable events included the seizure of the Dagu Forts commanding the approaches to Tianjin and the boarding and capture of four Chinese destroyers by British Commander Roger Keyes. Among the foreigners besieged in Tianjin was a young American mining engineer named Herbert Hoover, who would go on to become the 31st President of the United States.
The march from Tianjin to Beijing of about 120 km included about 20,000 allied troops. On 4 August, there were approximately 70,000 Qing imperial troops and anywhere from 50,000 to 100,000 Boxers along the way. The allies only encountered minor resistance, fighting battles at Beicang and Yangcun. At Yangcun, the 14th Infantry Regiment of the U.S. and British troops led the assault. The weather was a major obstacle. Conditions were extremely humid with temperatures sometimes reaching . These high temperatures and insects plagued the Allies. Soldiers dehydrated and horses died. Chinese villagers killed Allied troops who searched for wells.
The heat killed Allied soldiers, who foamed at the mouth. The tactics along the way were gruesome on either side. Allied soldiers beheaded already dead Chinese corpses, bayoneted or beheaded live Chinese, and raped Chinese girls and women. Cossacks were reported to have killed Chinese civilians almost automatically and Japanese kicked a Chinese soldier to death. The Chinese responded with violence and mutilation, slaughtered captured Russians, and Lieutenant Smedley Butler saw the remains of two Japanese soldiers who were tortured and killed by the Chinese, who gouged the eyes and cut off the tongues of Japanese soldiers before nailing them to doors. Lieutenant Butler was wounded during the expedition in the leg and chest by bullets, later receiving the Brevet Medal in recognition for his actions.
The international force reached Beijing on 14 August. Following the defeat of Beiyang army during the humiliating First Sino-Japanese War, the Chinese government had invested heavily in modernising the imperial army, which was equipped with modern Mauser repeater rifles and Krupp artillery. Three modernised divisions consisting of Manchu Bannermen protected the Beijing Metropolitan region. Two of them were under the command of the anti-Boxer Prince Qing and Ronglu, while the anti-foreign Prince Duan commanded the ten-thousand-strong Hushenying, or "Tiger Spirit Division", which had joined the Gansu Braves and Boxers in attacking the foreigners. It was a Hushenying captain who had assassinated the German diplomat Ketteler. The Tenacious Army under Nie Shicheng received western style training under German and Russian officers in addition to their modernised weapons and uniforms. They effectively resisted the Alliance at the Battle of Tientsin before retreating and astounded the Alliance forces with the accuracy of their artillery during the siege of the Tianjin concessions (the artillery shells failed to explode upon impact due to corrupt manufacturing). The Gansu Braves under Dong Fuxiang, which some sources descried as "ill disciplined", were armed with modern weapons but were not trained according to western drill and wore traditional Chinese uniforms. They led the defeat of the Alliance at Langfang in the Seymour Expedition and were the most ferocious in besieging the Legations in Beijing. Some Banner forces were given modernised weapons and western training, becoming the Metropolitan Banner forces, which were decimated in the fighting. Among the Manchu dead was the father of the writer Lao She.
The British won the race among the international forces to be the first to reach the besieged Legation Quarter. The U.S. was able to play a role due to the presence of U.S. ships and troops stationed in Manila since the U.S. conquest of the Philippines during the Spanish–American War and the subsequent Philippine Insurrection. In the U.S. military, the action in the Boxer Rebellion was known as the China Relief Expedition. American soldiers scaling the walls of Beijing is an iconic image of the Boxer Rebellion.
The British Army reached the legation quarter on the afternoon of 14 August and relieved the Legation Quarter. The Beitang was relieved on 16 August, first by Japanese soldiers and then, officially, by the French.
Evacuation of the Qing imperial court from Beijing to Xi'an.
In the early hours of 15 August, just as the Foreign Legations were being relieved, Empress Dowager Cixi, dressed in the padded blue cotton of a farm woman, the Guangxu Emperor, and a small retinue climbed into three wooden ox carts and escaped from the city covered with rough blankets. Legend has it that the Empress Dowager then either ordered that the Guangxu Emperor's favourite concubine, Consort Zhen, be thrown down a well in the Forbidden City or tricked her into drowning herself. The journey was made all the more arduous by the lack of preparation, but the Empress Dowager insisted this was not a retreat, rather a "tour of inspection." After weeks of travel, the party arrived in Xi'an in Shaanxi province, beyond protective mountain passes where the foreigners could not reach, deep in Chinese Muslim territory and protected by the Gansu Braves. The foreigners had no orders to pursue the Empress Dowager, so they decided to stay put. Ma Yukun and Dong Fuxiang's soldiers were the ones who guarded the court during the evacuation.
The Muslim Gansu Braves under the general Ma Fulu engaged in fierce fighting during the Battle of Peking at Zhengyang Gate against the Eight Nation Alliance. Ma Fulu and 100 of his fellow Hui and Dongxiang Muslim soldiers from his home village died in that battle. Ma Fulu's paternal cousins Ma Fugui 馬福貴, Ma Fuquan 馬福全, and his paternal nephews Ma Yaotu 馬耀圖, and Ma Zhaotu 馬兆圖 died in the battle. The Battle at Zhengyang was fought against the British. Ma Fulu's brother Ma Fuxiang took over his posts. The Gansu Braves escorted the imperial family to Xi'an when they decided to flee. The Muslim general Ma Anliang was part of the escort. Ma Fuxiang was rewarded by the Guangxu Emperor, being appointed governor of Altay for his service. Ma Fuxing also served under Ma Fulu to guard the imperial court during the fighting. Ma Biao, who became famous for fighting the Japanese in the Second Sino-Japanese War, served under the Muslim general Ma Haiyan while fighting in the Boxer Rebellion and guarding the imperial court. Ma Haiyan died of exhaustion after the imperial court reached its destination, and his son Ma Qi took over his posts. The Muslim troops were described as ""the bravest of the brave, the most fanatical of fanatics : and that is why the defence of the Emperor's city had been entrusted to them.""
Russian invasion of Manchuria.
The Russian Empire and the Qing Empire had maintained a long peace, starting with the Treaty of Nerchinsk in 1689, but Tsarist forces took advantage of Chinese defeats to impose the Aigun Treaty of 1858 and the Treaty of Peking of 1860 which ceded formerly Chinese territory in Manchuria to Russia, much of which is held by Russia to the present day (Primorye). The Russians aimed for control over the Amur River for navigation, and the all weather ports of Dairen and Port Arthur in the Liaodong peninsula. The rise of Japan as an Asian power provoked Russia's anxiety, especially in light of expanding Japanese influence in Korea. Following Japan's victory in the First Sino-Japanese War of 1895, the Triple Intervention of Russia, Germany and France forced Japan to return the territory won in Liaodong, leading to a de facto Sino-Russian alliance.
Local Chinese in Manchuria were incensed at these Russian advances and began to harass Russians and Russian institutions, such as the Chinese Eastern Railway. In June 1900, the Chinese bombarded the town of Blagoveshchensk on the Russian side of the Amur. The Czar's government used the pretext of Boxer activity to move some 200,000 troops into the area to crush the Boxers. The Chinese used arson to destroy a bridge carrying a railway and a barracks on 27 July. The Boxers destroyed railways and cut lines for telegraphs and burned the Yantai mines.
By 21 September, Russian troops took Jilin and Liaodong, and by the end of the month completely occupied Manchuria, where their presence was a major factor leading to the Russo-Japanese War.
The Chinese Honghuzi bandits of Manchuria, who had fought alongside the Boxers in the war, did not stop when the Boxer rebellion was over, and continued guerilla warfare against the Russian occupation up to the Russo-Japanese war when the Russians were defeated by Japan.
Massacre of missionaries and Chinese Christians.
Orthodox, Protestant and Catholic missionaries and their Chinese parishioners were massacred throughout northern China, some by Boxers and others by government troops and authorities. After the declaration of war on Western powers in June 1900, Yuxian, who had been named governor of Shanxi in March of that year, implemented a brutal anti-foreign and anti-Christian policy. On 9 July, reports circulated that he had executed forty-four foreigners (including women and children) from missionary families whom he had invited to the provincial capital Taiyuan under the promise to protect them. Although the purported eye witness accounts have recently been questioned as improbable, this event became a notorious symbol of Chinese anger, known as the Taiyuan Massacre. By the summer's end, more foreigners and as many as 2,000 Chinese Christians had been put to death in the province. Journalist and historical writer Nat Brandt has called the massacre of Christians in Shanxi "the greatest single tragedy in the history of Christian evangelicalism."
In 1900, insurgents placed a wooden cross in front of the only open gate to a mission station. Nearly 100 students were inside. They were told to either come out of the building and walk on top of the cross or be shot. A number of students came out and walked on the cross, and their lives were spared. One girl came out and knelt down before the cross and prayed. She then stood up, walked around the cross and toward the insurgents. She was shot and killed. The rest of the students followed her example and walked around the cross. They were all shot and killed.
During the Boxer Rebellion as a whole, a total of 136 Protestant missionaries and 53 children were killed, and 47 Catholic priests and nuns. Thirty thousand Chinese Catholics, 2,000 Chinese Protestants, and 200 to 400 of the 700 Russian Orthodox Christians in Beijing were estimated to have been killed. Collectively, the Protestant dead were called the China Martyrs of 1900. 222 of Russian Christian Chinese Martyrs including St. Metrophanes were locally canonised as New Martyrs on 22 April 1902, after archimandrite Innocent (Fugurovsky), head of the Russian Orthodox Mission in China, solicited the Most Holy Synod to perpetuate their memory. This was the first local canonisation for more than two centuries. The Boxers went on to murder Christians across 26 prefectures.
The White Lotus sect was attacked by the Boxers.
Aftermath.
Occupation, looting and atrocities.
Beijing, Tianjin, and other cities in northern China were occupied for more than one year by the international expeditionary force under the command of German General Alfred Graf von Waldersee. Atrocities by foreign troops were common, but German troops in particular were criticized. The German force arrived too late to take part in the fighting, but undertook punitive expeditions to the countryside. Kaiser Wilhelm II on July 27 during departure ceremonies for the German relief force included an impromptu, but intemperate reference to the Hun invaders of continental Europe would later be resurrected by British propaganda to mock Germany during the First World War and Second World War:
The Germans were not the only offenders. French troops ravaged the countryside around Beijing on behalf of Chinese Catholics. The Americans and British paid General Yuan Shikai and his army (the Right Division) to help the Eight Nation Alliance suppress the Boxers. Yuan Shikai's forces killed tens of thousands of people in their anti Boxer campaign in Zhili Province and Shandong after the Alliance captured Beijing. Yuan operated out of Baoding during the campaign, which ended in 1902. Li Hongzhang commanded Chinese soldiers to kill "Boxers" by and to assist the foreign invaders.
One newspaper called aftermath of the siege a "carnival of loot", and others called it "an orgy of looting" by soldiers, civilians and missionaries. These characterisations called to mind the sacking of the Summer Palace in 1860. Each nationality accused the others of being the worst looters. An American diplomat, Herbert G. Squiers, filled several railroad cars with loot. The British Legation held loot auctions every afternoon and proclaimed, "looting on the part of British troops was carried out in the most orderly manner." However, one British officer noted, "it is one of the unwritten laws of war that a city which does not surrender at the last and is taken by storm is looted." For the rest of 1900-1901, the British held loot auctions everyday except Sunday in front of the main-gate to the British Legation. Many foreigners, including Sir Claude Maxwell MacDonald and Lady Ethel MacDonald and George Ernest Morrison of "The Times", were active bidders among the crowd. Many of these looted items ended up in Europe. The Catholic Beitang or North Cathedral was a "salesroom for stolen property."
The American commander General Adna Chaffee banned looting by American soldiers, but the ban was ineffectual.
The missionaries were the most condemned. To provide restitution to missionaries and Chinese Christian families whose property had been destroyed, William Ament, a missionary of American Board of Commissioners for Foreign Missions, guided American troops through villages to punish those he suspected of being Boxers and confiscate their property. When Mark Twain read of this expedition, he wrote a scathing essay, that attacked the "Reverend bandits of the American Board," especially targeting Ament, one of the most respected missionaries in China. The controversy was front page news during much of 1901. Ament's counterpart on the distaff side was doughty British missionary Georgina Smith who presided over a neighborhood in Beijing as judge and jury.
It was reported that Japanese troops were astonished by other Alliance troops raping civilians. Roger Keyes, who commanded the British destroyer "Fame" and accompanied the Gaselee Expedition, noted that the Japanese had brought their own "regimental wives" (prostitutes) to the front to keep their soldiers from raping Chinese civilians. Thousands of Chinese women committed suicide; "The Daily Telegraph" journalist E. J. Dillon stated it was to avoid rape by Alliance forces, and he witnessed the mutilated corpses of Chinese women who were raped and killed by the Alliance troops. The French commander dismissed the rapes, attributing them to "gallantry of the French soldier." A foreign journalist, George Lynch, said "there are things that I must not write, and that may not be printed in England, which would seem to show that this Western civilization of ours is merely a veneer over savagery."
Many Bannermen supported the Boxers and shared their anti-foreign sentiment. The German Minister Clemens von Ketteler was assassinated by a Manchu. Bannermen had been devastated in the First Sino-Japanese War in 1895 and Banner armies were destroyed while resisting the invasion. In the words of historian Pamela Crossley, their living conditions went "from desperate poverty to true misery." When thousands of Manchus fled south from Aigun during the fighting in 1900, their cattle and horses were stolen by Russian Cossacks who then burned their villages and homes to ashes. The clan system of the Manchus in Aigun was obliterated by the despoliation of the area at the hands of the Russian invaders.
Reparations.
After the capture of Peking by the foreign armies, some of Empress Dowager Cixi's advisers advocated that the war be carried on, arguing that China could have defeated the foreigners as it was disloyal and traitorous people within China who allowed Beijing and Tianjin to be captured by the Allies, and that the interior of China was impenetrable. They also recommended that Dong Fuxiang continue fighting. The Empress Dowager was practical, however, and decided that the terms were generous enough for her to acquiesce when she was assured of her continued reign after the war and that China would not be forced to cede any territory. Ralph L. Powell judged that the war would have been bogged down for the Alliance if China opted for guerilla insurgency.
On 7 September 1901, the Qing imperial court agreed to sign the "Boxer Protocol" also known as Peace Agreement between the Eight-Nation Alliance and China. The protocol ordered the execution of 10 high-ranking officials linked to the outbreak and other officials who were found guilty for the slaughter of foreigners in China. Alfons Mumm (Freiherr von Schwarzenstein), Ernest Satow and Komura Jutaro signed on behalf of Germany, Britain and Japan respectively.
China was fined war reparations of 450,000,000 taels of fine silver (≈ @ 1.2 ozt/tael) for the loss that it caused. The reparation was to be paid within 39 years, and would be 982,238,150 taels with interest (4 percent per year) included. To help meet the payment it was agreed to increase the existing tariff from an actual 3.18 percent to 5 percent, and to tax hitherto duty-free merchandise. The sum of reparation was estimated by the Chinese population (roughly 450 million in 1900), to let each Chinese pay one tael. Chinese custom income and salt tax were enlisted as guarantee of the reparation. China paid 668,661,220 taels of silver from 1901 to 1939, equivalent in 2010 to ≈US$61 billion on a purchasing power parity basis.
A large portion of the reparations paid to the United States was diverted to pay for the education of Chinese students in U.S. universities under the Boxer Indemnity Scholarship Program. To prepare the students chosen for this program an institute was established to teach the English language and to serve as a preparatory school. When the first of these students returned to China they undertook the teaching of subsequent students; from this institute was born Tsinghua University. Some of the reparation due to Britain was later earmarked for a similar program.
The China Inland Mission lost more members than any other missionary agency:
58 adults and 21 children were killed. However, in 1901, when the allied nations were demanding compensation from the Chinese government, Hudson Taylor refused to accept payment for loss of property or life in order to demonstrate the meekness and gentleness of Christ to the Chinese.
The French Catholic vicar apostolic, Msgr. Alfons Bermyn wanted foreign troops garrisoned in Inner Mongolia, but the Governor refused. Bermyn petitioned the Manchu Enming to send troops to Hetao where Prince Duan's Mongol troops and General Dong Fuxiang's Muslim troops allegedly threatened Catholics. It turned out that Bermyn had created the incident as a hoax.
The Qing government did not capitulate to all the foreign demands. The Manchu governor Yuxian (), was executed, but the imperial court refused to execute the Han Chinese General Dong Fuxiang, although he had also encouraged the killing of foreigners during the rebellion. An execution was impossible to be demanded of the court by the Allies because Dong Fuxiang was the one protecting the Imperial Court. Empress Dowager Cixi intervened when the Alliance demanded him executed and Dong was only cashiered and sent back home. Instead, Dong Fuxiang lived a life of luxury and power in "exile" in his home province of Gansu. Upon Dong's death in 1908, all honors which had been stripped from him were restored and he was given a full military burial.
In addition to sparing Dong Fuxiang, the Qing also refused to exile the Boxer supporter Prince Duan to Xinjiang, as the Allies demanded. Instead, he moved to Alashan, west of Ningxia, and lived in Wangyeh Fu, where the local Mongol Prince lived. He then moved to Ningxia during the Xinhai Revolution when the Muslims took control of Ningxia, and finally, moved to Xinjiang with Sheng Yun.
Long-term consequences.
The European great powers finally ceased their ambitions of colonizing China having learned from the Boxer rebellions that the best way to deal with China was through the ruling dynasty, rather than directly with the Chinese people (a sentiment embodied in the adage: "The people are afraid of officials, the officials are afraid of foreigners, and the foreigners are afraid of the people"()), and even briefly assisted the Qing in their war against the Japanese to prevent a Japanese domination in the region.
Concurrently, this period marks the ceding of European great power interference in Chinese affairs, with the Japanese replacing the Europeans as the dominant power for their lopsided involvement in the war against the Boxers as well as their victory in the First Sino-Japanese War. With the toppling of the Qing that followed and the rise of the Nationalist Kuomintang, European sway within China was reduced to symbolic status. After taking Manchuria in 1905, Japan came to dominate Asian affairs both militarily and culturally with many of the Chinese scholars also educated in Japan with the most prominent example being Sun Yat-Sen who would later found the Nationalist movement of the Kuomintang in China.
In October 1900, Russia occupied the provinces of Manchuria, a move which threatened Anglo-American hopes of maintaining what remained of China's territorial integrity and the country's openness to commerce under the Open Door Policy.
Japan's clash with Russia over Liaodong and other provinces in eastern Manchuria, due to the Russian refusal to honour the terms of the Boxer protocol which called for their withdrawal, led to the Russo-Japanese War when two years of negotiations broke down in February 1904. The Russian Lease of the Liaodong (1898) was confirmed. Russia was ultimately defeated by an increasingly confident Japan.
Besides the compensation, Empress Dowager Cixi reluctantly started some reforms despite her previous views. Under her reforms known as the New Policies started in 1901, the imperial examination system for government service was eliminated and as a result the system of education through Chinese classics was replaced with a European liberal system that led to a university degree. Along with the formation of new military and police organisations, the reforms also simplified central bureaucracy and made a start on revamping taxation policies. After the deaths of Cixi and the Guangxu Emperor in 1908, the prince regent Zaifeng (Prince Chun), the Guangxu Emperor's brother, launched further reforms.
The effect on China was a weakening of the dynasty and its national defense capabilities. The government structure was temporarily sustained by the Europeans. Behind the international conflict, it further deepened internal ideological differences between northern-Chinese anti-foreign royalists and southern-Chinese anti-Qing revolutionists. This scenario in the last years of the Qing dynasty gradually escalated into a chaotic warlord era in which the most powerful northern warlords were hostile towards the revolutionaries in the south who overthrew the Qing monarchy in 1911. The rivalry was not fully resolved until the northern warlords were defeated by the Kuomintang's 1926–28 Northern Expedition. Prior to the final defeat of the Boxer Rebellion, all anti-Qing movements in the previous century, such as the Taiping Rebellion, had been successfully suppressed by the Qing.
Historian Walter LaFeber has argued that President William McKinley's decision to send 5,000 American troops to quell the rebellion marks "the origins of modern presidential war powers":
McKinley took a historic step in creating a new, 20th century presidential power. He dispatched the five thousand troops without consulting Congress, let alone obtaining a declaration of war, to fight the Boxers who were supported by the Chinese government ... Presidents had previously used such force against non-governmental groups that threatened U.S. interests and citizens. It was now used, however, against recognised governments, and without obeying the Constitution's provisions about who was to declare war.
Arthur M. Schlesinger, Jr. concurred, writing that:
The intervention in China marked the start of a crucial shift in the presidential employment of armed force overseas. In the 19th century, military force committed without congressional authorization had been typically used against nongovernmental organizations. Now it was beginning to be used against sovereign states, and, in the case of Theodore Roosevelt, with less consultation than ever.
In the Second Sino-Japanese War, when the Japanese asked the Muslim general Ma Hongkui to defect and become head of a Muslim puppet state under the Japanese, Ma responded through Zhou Baihuang, the Ningxia Secretary of the Nationalist Party to remind the Japanese military chief of staff Itagaki Seishiro that many of his relatives fought and died in battle against Eight Nation Alliance forces during the Battle of Peking, including his uncle Ma Fulu, and that Japanese troops made up the majority of the Alliance forces so there would be no cooperation with the Japanese.
"“恨不得馬踏倭鬼，給我已死先烈雪仇，與後輩爭光”。" ""I am eager to stomp on the dwarf devils" (A derogatory term for Japanese)", I will give vengeance for the already dead martyrs, achieving glory with the younger generation."" said by Muslim General Ma Biao during the Second Sino-Japanese War with reference to his service in the Boxer Rebellion where he already fought the Japanese before World War II, in which he became famous for his victories and wiped out an entire Japanese unit at the Battle of Huaiyang. During World War II, the China Information Publishing Company included an article titled ""Boxer Veteran Fights Again"" on Ma Biao in Volume 4 of its publication "China at War", which discussed both his service in the Boxer Rebellion in 1900 and his fight against the Japanese in World War II in Henan.
The Muslim martial arts master Wang Zi-Ping served with the Boxers against the Eight Nation Alliance during the war.
Controversies and changing views of the Boxers.
From the beginning, views differed as to whether the Boxers were better seen as anti-imperialist, patriotic, and proto-nationalist or as "uncivilized", irrational, and futile opponents of inevitable change. The historian Joseph Esherick comments that "confusion about the Boxer Uprising is not simply a matter of popular misconceptions", for "there is no major incident in China's modern history on which the range of professional interpretation is as great."
Foreign educated Chinese liberals like Hu Shi often condemned the Boxers for their irrationality and barbarity. Chinese nationalists initially disdained them for their superstition and xenophobia. Dr. Sun Yat-sen, the founding father of the Republic of China and of the Nationalist Party at first believed that the Boxer Movement was stirred up by the Qing government's rumors, which "caused confusion among the populace", and delivered "scathing criticism" of the Boxers' "anti-foreignism and obscurantism." Sun praised the Boxers for their "spirit of resistance" but called them "bandits." Students shared an ambivalent attitude to the Boxers, stating that while the uprising originated from the "ignorant and stubborn people of the interior areas", their beliefs were "brave and righteous", and could "be transformed into a moving force for independence." After the fall of the Qing dynasty in 1911, nationalist Chinese became more sympathetic to the Boxers. In 1918 Sun praised their fighting spirit and said the Boxers were courageous and fearless, fighting to the death against the Alliance armies, specifically the Battle of Yangcun. The leader of the New Culture Movement, Chen Duxiu, forgave the "barbarism of the Boxer... given the crime foreigners committed in China", and contended that it was those "subservient to the foreigners" that truly "deserved our resentment".
In other countries, views of the Boxers were complex and contentious. Mark Twain said that "the Boxer is a patriot. He loves his country better than he does the countries of other people. I wish him success." The Russian writer Leo Tolstoy also praised the Boxers. He accused Nicholas II of Russia and Wilhelm II of Germany of being chiefly responsible for the lootings, rapes, and murders in what he saw as Christian brutality of the Russians and other western troops. The Russian revolutionary Vladimir Lenin mocked the Russian government's claim that it was protecting Christian civilization: "Poor Imperial Government! So Christianly unselfish, and yet so unjustly maligned! Several years ago it unselfishly seized Port Arthur, and now it is unselfishly seizing Manchuria; it has unselfishly flooded the frontier provinces of China with hordes of contractors, engineers, and officers, who, by their conduct, have roused to indignation even the Chinese, known for their docility." The Indian Bengali Hindu Rabindranath Tagore attacked the European colonialists. A number of Indian soldiers in the British Indian Army agreed that the Boxers were right and the British stole from the Temple of Heaven a bell, which was given back to China by the Indian military in 1994. The American evangelist Rev. Dr. George F. Pentecost spoke out against western imperialism in China and in favor of the Boxers, justifying the Boxer uprising, saying: "In America, we think of the Boxer uprising as a movement of the 'heathen' against the Christian missionaries. In spite of the fact that Christian missionaries were tortured and killed, the Boxer uprising was nothing of the sort. It was a patriotic movement to expel the 'foreign devils'-just that-the foreign devils. The Malay pirates whom the Chinese first called foreign devils were literally that, and the representatives of the so-called Christian nation are little less. Suppose the great nations of Europe were to put their fleets together, came over here, seize Portland, move on down to Boston, then New York, then Philadelphia, and so on down the Atlantic Coast and around the Gulf of Galveston? Suppose they took possession of these port cities, drove our people into the hinterland, built great warehouses and factories, brought in a body of dissolute agents, and calmly notified our people that henceforward they would manage the commerce of the country? Would we not have a Boxer movement to drive those foreign European Christian devils out of our country? The cases are the same." Rev. Dr. Robert S, MacArthur reminded Americans that Americans massacred Chinese during the anti-Chinese riots in the 19th century and it was hypocritical for Americans to complain of Boxer massacres of Americans in China : ""Have we not had our Denis Kearney and other sand lots oraters, shouting with a coarse brogue of foreign countries still on their tongues, 'The chinese must go'? Is it remarkable that this cry echoes to China and takes there the form 'The foreign devils must go'? Have we not had our mobs and riots in New Orleans and in New York and in Akron, Ohio? Probably more Chinese have been killed by American mobs than European have been killed during these recent Chinese uprisings. China might well send a few missionaries to Tammany Hall. It may well be doubted whether there ever was in China or any other part of heathendom a political organization so vile."". The Russian newspaper Amurskii Krai ran an article slamming the killing of innocent civilians who were not involved in the fighting by the Russians and that "restraint" "civilization" and "culture" instead of "racial hatred" and "destruction" was becoming of a "civilized Christian nation" - : ""But the fact that they had trustingly remained in our midst, only increases our guilt. They confidently believed that the Russian people fought in the battle fields, killing armed foes; they did not know that we can herd together peaceful, unarmed persons, half dead from fear, and slaughter them in cold blood. How shall we atone for our guilt? By what feats of goodness and virtue shall we remove the blemish that we have put on ourselves? What shall we tell civilized people? We shall have to say to them: "Do not consider us as brothers anymore. We are mean and terrible people; we have killed those who hid at our place, who sought our protection."""
The events also left a longer impact. The historian Robert Bickers found that for the British in China the Boxer rising served as the "equivalent of the Indian 'mutiny'" and came to represent the Yellow Peril. Later events, he adds, such as the Chinese Nationalist Revolution of the 1920s and even the activities of the Red Guards of the 1960s, were perceived as being in the shadow of the Boxers.
In Taiwan (Republic of China) and Hong Kong, history textbooks often show the Boxer as uncivilised, irrational and xenophobic. But in the People's Republic of China, government textbooks presented the Boxer movement as an anti-imperialist, patriotic peasant movement whose failure was due to the lack of leadership from the modern working class, and described the international army as an invading force. In recent decades, however, large-scale projects of village interviews and explorations of archival sources have led historians in China to take a more nuanced view. Some non-Chinese scholars, such as Joseph Esherick, have seen the movement as anti-imperialist; while others hold that the concept "nationalistic" is anachronistic because the Chinese nation had not been formed and the Boxers were more concerned with regional issues. Paul Cohen's recent study includes a survey of "the Boxers as myth", showing how their memory was used in changing ways in 20th century China from the New Culture Movement to the Cultural Revolution.
In recent years the Boxer question has been debated in the People's Republic of China. In 1998, the critical scholar Wang Yi argued that the Boxers had features in common with the extremism of the Cultural Revolution. Both events had the external goal of "liquidating all harmful pests" and the domestic goal of "eliminating bad elements of all descriptions" and this relation was rooted in "cultural obscurantism." Wang explained to his readers the changes in attitudes towards the Boxers from the condemnation of the May Fourth Movement to the approval expressed by Mao Zedong during the Cultural Revolution. In 2006 Yuan Weishi, a professor of philosophy at Zhongshan University in Guangzhou, wrote that the Boxers by their "criminal actions brought unspeakable suffering to the nation and its people! These are all facts that everybody knows, and it is a national shame that the Chinese people cannot forget." Yuan charged that history text books had been lacking in neutrality in presenting the Boxer Uprising as a "magnificent feat of patriotism", and not presenting the view that the majority of the Boxer rebels were both violent and xenophobic. In response, some labeled Yuan Weishi a "traitor" (Hanjian).
Terminology.
The first reports coming from China in 1898 referred to the village activists as "Yihequan", (Wade–Giles: I Ho Ch'uan). The first known use of the term "Boxer" was September 1899 in a letter from missionary Grace Newton in Shandong. It appears from context that "Boxer" was a known term by that time, possibly coined by the Shandong missionaries Arthur H. Smith and Henry Porter. Smith says in his book of 1902 that the name
I Ho Ch'uan... literally denotes the 'Fists' (Ch'uan) of Righteousness (or Public) (I) Harmony (Ho), in apparent allusion to the strength of united force which was to be put forth. As the Chinese phrase 'fists and feet' signifies boxing and wrestling, there appeared to be no more suitable term for the adherents of the sect than 'Boxers,' a designation first used by one or two missionary correspondents of foreign journals in China, and later universally accepted on account of the difficulty of coining a better one.
On 6 June 1900 the "Times" of London used the term "rebellion" in quotation marks, presumably to indicate their view that the rising was in fact instigated by Empress Dowager Cixi. The historian Lanxin Xiang refers to the "so called 'Boxer Rebellion,'" and explains that "while peasant rebellion was nothing new in Chinese history, a war against the world's most powerful states was." The name "Boxer Rebellion", concludes Joseph Esherick, another recent historian, is truly a "misnomer", for the Boxers "never rebelled against the Manchu rulers of China and their Qing dynasty" and the "most common Boxer slogan, throughout the history of the movement, was "support the Qing, destroy the Foreign." He adds that only after the movement was suppressed by the Allied Intervention did both the foreign powers and influential Chinese officials realize that the Qing would have to remain as government of China in order to maintain order and collect taxes to pay the indemnity. Therefore, in order to save face for the Empress Dowager and the imperial court, the argument was made that the Boxers were rebels and that support from the imperial court came only from a few Manchu princes. Esherick concludes that the origin of the term "rebellion" was "purely political and opportunistic", but it has shown a remarkable staying power, particularly in popular accounts.
Other recent Western works refer to the "Boxer Movement", "Boxer War" or Yihetuan Movement, while Chinese studies use 义和团运动 (Yihetuan yundong), that is, "Yihetuan Movement." In his discussion of the general and legal implications of the terminology involved, the German scholar Thoralf Klein notes that all of the terms, including the Chinese ones, are "posthumous interpretations of the conflict." He argues that each term, whether it be "uprising", "rebellion" or "movement" implies a different definition of the conflict. Even the term "Boxer War", which has become widely used by recent scholars in the West, raises questions, as war was never declared, and Allied troops behaved as a punitive expedition in colonial style, not in a declared war with legal constraints. The Allies took advantage of the fact that China had not signed "The Laws and Customs of War on Land", a key document at the 1899 Hague Peace Conference. They argued that China had violated its provisions but themselves ignored them. 
Later representations.
By 1900, many new forms of media had matured, including illustrated newspapers and magazines, postcards, broadsides and advertisements, all of which presented images of the Boxers and of the invading armies. The rebellion was covered in the foreign illustrated press by artists and photographers. Paintings and prints were also published including Japanese wood-blocks. In the following decades, the Boxers were a constant subject for comment. A sampling includes:

</doc>
<doc id="60521" url="https://en.wikipedia.org/wiki?curid=60521" title="HMS Scorpion (1863)">
HMS Scorpion (1863)

HMS "Scorpion" was an ironclad turret ship of the Royal Navy, built by John Laird Sons & Company, at Birkenhead. She was one of two sister ships secretly ordered from the Laird shipyard in 1862 by the Confederate States of America. To conceal her true ownership, all concerned endorsed the fiction that she was being constructed as the Egyptian warship "El Tousson". She was to have been named "North Carolina" upon delivery to the Confederates. The British government seized the pair of ironclads in October 1863, a few months after their launch and before they could be completed.
Design and description.
"Wivern" and her sister were intended, together with other warships, to break the Federal blockade of Confederate coastal cities and to hold some Northern cities for ransom. The ships had an length between perpendiculars of , a beam of , and a draught of at deep load. They displaced . The hull was divided by 12 watertight bulkheads and the ships had a double bottom beneath the engine and boiler rooms. Their crew consisted of 152 officers and ratings.
The "Scorpion"-class ships had two horizontal direct-acting steam engines, built by Lairds, each driving a single propeller shaft, using steam provided by four tubular boilers. The engines produced a total of which gave the ships a maximum speed of . The ships carried of coal, enough to steam at . They were barque-rigged with three masts. The funnel was made semi-retractable to reduce wind resistance while under sail.
No ordnance had been ordered by the Confederates before the ships were seized in 1863, but in British service they mounted a pair of 9-inch rifled muzzle-loading guns in each turret. The guns could fire both solid shot and explosive shells. According to Parkes, going from full depression to full elevation supposedly took one hour in smooth water and with an even keel!
The "Scorpion"-class ships had a complete waterline belt of wrought iron that was thick amidships and thinned to at the bow and at the stern. It completely covered the hull from the upper deck to below the waterline. The armour protection of the turrets was quite elaborate. The inside of the turret was lined with of iron boiler plate to which T-shaped beams were bolted. The space between the beams was filled with of teak. This was covered by an iron lattice thick that was covered in turn by of teak. The iron plates were bolted to the outside using bolts that ran through to the interior iron "skin". The area around the gun ports was reinforced by 4.5-inch plates to give a total thickness of 10 inches. The turret roof consisted of T-shaped beams covered by iron plates.
Construction and career.
In early 1864, the Admiralty purchased both for the Royal Navy and named them "Scorpion" and . Commissioned in July 1865, "Scorpion" was assigned to the Channel Fleet until 1869, with time out for a refit that reduced her sailing rig from a bark to a schooner. In late 1869, she moved to Bermuda for coast and harbour defence service. "Scorpion" remained there for over three decades before being removed from the effective list. "Scorpion" was sunk as a target in 1901 but raised the next year and sold in February 1903. She was lost at sea while under tow to the U.S., where she was to be scrapped.

</doc>
<doc id="60523" url="https://en.wikipedia.org/wiki?curid=60523" title="1954 FIFA World Cup">
1954 FIFA World Cup

The 1954 FIFA World Cup, the fifth staging of the FIFA World Cup, was held in Switzerland from 16 June to 4 July. Switzerland was chosen as hosts in July 1946. The tournament set a number of all-time records for goal-scoring, including the highest average goals scored per game. The tournament was won by West Germany, who defeated Hungary 3–2 in the final, giving them their first title. 
In the first 8 minutes, Hungary was ahead 2-0, but by half time, Germany was equalized. Then, Rahn scored Germany's third goal making Germany have the lead. This is considered one of the most disappointed matches ever in world cup history.
Host selection.
Switzerland was awarded the tournament unopposed on 22 July 1946, the same day that Brazil was selected for the 1950 World Cup, in Luxembourg City.
Qualification.
The hosts (Switzerland) and the defending champions (Uruguay) qualified automatically. Of the remaining 14 places, 11 were allocated to Europe (including Egypt, Turkey and Israel), two to the Americas, and one to Asia.
Scotland, Turkey and South Korea made their World Cup debuts at this tournament (Turkey and Scotland had qualified for the 1950 competition but both withdrew). Austria appeared for the first time since 1934. Turkey would not participate at a finals again until the 2002 competition, while South Korea's next appearance would be in 1986.
The third and fourth place teams from 1950, Sweden and Spain, both failed to qualify. In a shock result, Spain was eliminated by Turkey: after the two countries had tied a three-game series, Turkey progressed by drawing of lots.
German teams were allowed to qualify again, after having been banned from the 1950 FIFA World Cup. West Germany
qualified against fellow Germans from the Saarland (which then was a French protectorate), while East Germany had not entered, cancelling international football games after the East German uprising of 1953.
Argentina declined to participate for the third World Cup in succession.
Summary.
Format.
The 1954 tournament used a unique format. The sixteen qualifying teams were divided into four groups of four teams each. Each group contained two seeded teams and two unseeded teams. Only four matches were scheduled for each group, each pitting a seeded team against an unseeded team. This contrasts with the usual round-robin in which every team plays every other team: six matches in each group. Another oddity was that extra time, which in most tournaments is not employed at the group stage, "was" played in the group games if the score was level after 90 minutes, with the result being a draw if the scores were still level after 120 minutes.
Two points were awarded for a win and one for a draw. The two teams with the most points from each group progressed to the knockout stage. If the first and second placed teams were level on points, lots were drawn to decide which team would top the group. However, if the second and third placed teams were level on points, there was a play-off to decide which team would progress to the next stage.
It turned out that two of the four groups required play-offs, and the other two required drawing of lots between the two top teams. The play-offs were between Switzerland and Italy, and Turkey and West Germany: in both matches the unseeded teams (Switzerland and West Germany) repeated earlier victories against the seeds (Italy and Turkey) to progress. In the other two groups, lots were drawn to determine the first-place teams: resulting in Uruguay and Brazil finishing above Austria and Yugoslavia, respectively.
A further unusual feature of the format was that the four group-winning teams were drawn against each other in the knockout stages to produce one finalist, and the four second-placed teams played against each other to produce the second finalist. In subsequent tournaments it has become customary to draw group winners against second-placed teams in the first knockout round.
In any knockout game tied after 90 minutes, 30 minutes of extra time were played. If the scores had still been level after extra time, in any knockout game other than the final, lots would have been drawn to decide which team progressed. However, if the final had been tied after extra time, it would have been replayed, with lots deciding the winner only if the replay was also tied after extra time. In the event, all the knockout games were decided in either normal time or extra time, with no replays or drawing of lots being required.
Seeding.
Before qualification was complete, the eight seeded teams were determined by FIFA based on world rankings. They were Austria, Brazil, England, France, Hungary, Italy, Spain and Uruguay.
These seedings were thrown into disarray when, in an unexpected result, Turkey eliminated Spain in qualification. FIFA resolved this situation by giving Turkey the seeding that had previously been allocated to Spain.
Results.
West Germany, who had been reinstated as full FIFA members only in 1950 and were unseeded, convincingly won the first of two encounters with the seeded Turkish side at Wankdorf stadium in Berne. The Koreans, the other unseeded team, lost 0–7 and 0–9, with West Germany being denied the chance to play such an easy opponent. Sepp Herberger, the West German coach, gambled against the seeded team of Hungary by sending in a reserve side, and lost 3–8; so they had to play off against Turkey, a match that they easily won. Hungary's team captain Ferenc Puskás, considered by many as the best player in the world in that time, was injured by West German defender Werner Liebrich, and had to miss the next two matches of his team, only to show up in the final again, still being in a questionable condition.
In the quarter-finals, the favourites Hungary beat Brazil 4–2 in one of the most violent matches in football history, which became infamous as the Battle of Berne. Meanwhile, the World Cup holders Uruguay sent England out of the tournament, also by 4–2. West Germany dispatched Yugoslavia 2–0, and Austria beat the host nation Switzerland in the game that saw the most goals in any World Cup match, 7–5.
In the first semi-final, West Germany beat Austria 6–1.
The other semi-final, one of the most exciting games of the tournament, saw Hungary go into the second half leading Uruguay 1–0, only for the game to be taken to extra time with a score after 90 minutes of 2–2. The deadlock was broken by Sándor Kocsis with two late goals to take Hungary through to the final, with Uruguay finally losing their unbeaten record in World Cup Final matches. Uruguay then went on to be beaten for a second time as Austria secured third place.
Final: "The Miracle of Bern".
The Wankdorf Stadion in Berne saw 60,000 people cram inside to watch the final between West Germany and Hungary, a rematch of a first round game, which Hungary had won 8–3 against the reserves of the German team. The Golden Team of the Hungarians were favourites, as they were unbeaten for a record of 32 consecutive matches, but they had had two tough play-off matches. It started raining on match day – in Germany this was dubbed "Fritz-Walter-Wetter" ("Fritz Walter's weather") because the West German team captain Fritz Walter was said to play his best in the rain. Adi Dassler had provided shoes with exchangeable studs.
Hungary's Ferenc Puskás played again in the final, even though he was not fully fit. Despite this he put his team ahead after only six minutes and with Zoltán Czibor adding another two minutes later it seemed that the pre-tournament favourites would take the title. However, with a quick goal from Max Morlock in the 10th and the equalizer of Helmut Rahn in the 19th, the tide began to turn.
The second half saw telling misses by the Hungarian team. Barely six minutes before the end of the match, the popular German radio reporter Herbert Zimmermann gave the most famous German piece of commentary, recommending that "Rahn should shoot from deep", which he did. The second goal from Rahn gave West Germany a 3–2 lead while the Hungarian reporter György Szepesi burst into tears. Later, Zimmermann called Puskás offside before he kicked the ball into Toni Turek's net with 2 minutes left. While referee Ling pointed to the centre spot, linesman Griffiths signalled offside. After a one-minute consultation, referee Ling disallowed the claimed equalizer.
The West Germans were handed the Jules Rimet Trophy and the title of World Cup winners, while the crowd sang along to the tune of the national anthem of West Germany. In Germany the success is known as "The Miracle of Berne", upon which a 2003 film of the same name was based. For the Hungarians, the defeat was a disaster, and remains controversial due to claimed referee errors and claims of doping.
One controversy concerns the 2–2 equaliser. Hungarian goalie Gyula Grosics jumped to catch Fritz Walter's corner shot, but in plain sight of the camera, Hans Schäfer obstructed him, and so the ball reached Rahn unhindered. The second controversy concerns allegations of doping to explain the better condition of the West German team in the second half. Though teammates steadfastly denied this rumour, German historian Guido Knopp claimed in a 2004 documentary for German public channel ZDF that the players were injected with shots of vitamin C at half-time, using a needle earlier taken from a Soviet sports doctor, which would also explain the wave of jaundice among team members following the tournament. A Leipzig University study in 2010 posited that the West German players had been injected with the banned substance methamphetamine.
Most controversial was the offside ruling for Puskás's intended 87th minute equalizer. The camera filming the official footage was in a bad position to judge the situation, but eyewitnesses claimed that the referee was wrong, including West German substitute player Alfred Pfaff. However, since then, unofficial footage surfaced evidencing no offside (shown on North German regional public channel NDR in 2004.)
Records.
The following all-time records were set or equalled at this tournament, and have not subsequently been surpassed:
All matches in one tournament
Team records for one tournament
Records for a single game
Other landmarks.
For the first time there was television coverage, and special coins were issued to mark the event.
The 11 goals scored by Kocsis of Hungary not only led the World Cup but bettered the previous record (set by Brazilian Ademir in the previous tournament) by two goals. Kocsis' mark was broken by Just Fontaine's 13 goals in 1958. Despite not winning the 1954 tournament, their fourth-place finish and their two previous World Cup titles made Uruguay the most successful World Cup nation for eight years, until Brazil won their second title in 1962. Hungary's 9–0 win against Korea during the group stages remains the biggest margin of victory in FIFA World Cup history, later equalled by Yugoslavia over Zaire (9–0) in 1974 and Hungary over El Salvador (10–1) in 1982.
West Germany also became the first team to win the World Cup after having lost a match at the finals (losing 8–3 to Hungary in the group stage). This feat was subsequently repeated by West Germany in 1974, Argentina in 1978 and Spain in 2010, who all lost group matches 1–0. Coincidentally, all three teams won against Netherlands sides in the final.
West Germany's 1954 victory remains the only time that a team has won the World Cup without playing any team from outside its own continent (Turkey is geographically partly in Asia, but qualified from Europe and has always been affiliated with UEFA).
West Germany's victory in the final is considered one of the greatest upsets of all time and one of the finest achievements in German sporting history. The West German team was made up of amateur players, as Germany did not have a professional league at this time, while the Hungarians were "de jure" amateurs, like all the communist countries at that time, but playing football as professionals, mainly for Budapesti Honvéd FC and later for major clubs like Real Madrid and Barcelona in Spain, and were ranked best in the world. This is the only time a team has won the World Cup with amateur footballers.
Venues.
Six venues in six cities (1 venue in each city) hosted the tournament's 26 matches. The most used stadium was the St. Jakob stadium in Basel, which hosted 6 matches. The venues in Bern, Zurich and Lausanne each hosted 5 matches, the venue in Geneva hosted 4 matches and the venue in Lugano only hosted 1 match.
Squads.
For a list of all squads that appeared in the final tournament, see "1954 FIFA World Cup squads".
Goalscorers.
With 11 goals, Sándor Kocsis is the top scorer in the tournament. In total, 140 goals were scored by 63 different players, with four of them credited as own goals.
FIFA retrospective ranking.
In 1986, FIFA published a report that ranked all teams in each World Cup up to and including 1986, based on progress in the competition, overall results and quality of the opposition. The rankings for the 1954 tournament were as follows:
In film.
The final scene of Rainer Werner Fassbinder's film "The Marriage of Maria Braun" takes place during the finals of the 1954 World Cup; in the scene's background, the sports announcer is celebrating West Germany's victory and shouting ""Deutschland ist wieder was!"" (Germany is something again); the film uses this as the symbol of Germany's recovery from the ravages of the Second World War.
Sönke Wortmann's 2003 German box-office hit "The Miracle of Bern" (in German: "Das Wunder von Bern") re-tells the story of the German team's route to victory through the eyes of a young boy who admires the key player of the final, Helmut Rahn.

</doc>
<doc id="60524" url="https://en.wikipedia.org/wiki?curid=60524" title="General semantics">
General semantics

General semantics is a self improvement and therapy program begun in the 1920s that seeks to regulate human mental habits and behaviors. After partial launches under the names "human engineering" and "humanology", Polish-American originator Alfred Korzybski (1879–1950) fully launched the program as "general semantics" in 1933 with the publication of "Science and Sanity: An Introduction to Non-Aristotelian Systems and General Semantics".
The sourcebook for general semantics, "Science and Sanity", presents general semantics as both a theoretical and a practical system whose adoption can reliably alter human behavior in the direction of greater sanity. Starting around 1940, university English professor S.I. Hayakawa (1906–1992), speech professor Wendell Johnson, speech professor Irving J. Lee, and others assembled elements of general semantics into a package suitable for incorporation into mainstream communications curricula. The Institute of General Semantics, which Korzybski and co-workers founded in 1938, continues today. General Semantics as a movement has waned considerably since the 1950s, although many of its ideas live on in other movements, such as Neuro Linguistic Programming. and Rational Emotive Behavior Therapy.
Overview.
"Identification" and "the silent level".
In the 1946 "Silent and Verbal Levels" diagram, the arrows and boxes denote ordered stages in human neuro-evaluative processing that happens in an instant. Although newer knowledge in biology has more sharply defined what the text in these 1946 boxes labels "electro-colloidal," the diagram remains, as Korzybski wrote in his last published paper in 1950, "satisfactory for our purpose of explaining briefly the most general and important points." General semantics postulates that most people "identify," or fail to differentiate the serial stages or "levels" within their own neuro-evaluative processing. "Most people," Korzybski wrote, ""identify in value" levels I, II, III, and IV and react "as if" our verbalizations about the first three levels were 'it.' Whatever we may say something 'is' obviously "is not" the 'something' on the silent levels." 
By making it a 'mental' habit to find and keep one's bearings among the ordered stages, general semantics training seeks to sharpen internal orientation much as a GPS device may sharpen external orientation. Once trained, general semanticists affirm, a person will act, respond, and make decisions more appropriate to any given set of happenings. Although producing saliva constitutes an appropriate response when lemon juice drips onto the tongue, a person has inappropriately identified when an imagined lemon or the word "l–e–m–o–n" triggers a salivation response.
"Once we differentiate, differentiation becomes the denial of identity," Korzybski wrote in "Science and Sanity". "Once we discriminate among the objective and verbal levels, we learn 'silence' on the unspeakable objective levels, and so introduce a most beneficial neurological 'delay'—engage the cortex to perform its natural function." British-American philosopher Max Black, an influential critic of general semantics, called this neurological delay the "central aim" of general semantics training, "so that in responding to verbal or nonverbal stimuli, we are aware of what it is that we are doing."
In the 21st century, the physiology underlying identification and the neurological delay is thought to involve autoassociative memory, a neural mechanism crucial to intelligence. Briefly explained, autoassociative memory retrieves previously stored representations that most closely conform to any current incoming pattern (level II in the general semantics diagram) arriving from the senses. According to the memory-prediction model for intelligence, if the stored representations resolve the arriving patterns, this constitutes "understanding," and brain activity shifts from evaluation to triggering motor responses. When the retrieved representations do "not" sufficiently resolve newly arrived patterns, evaluating persists, engaging higher layers of the cortex in an ongoing pursuit of resolution. The additional time required for signals to travel up and down the cortical hierarchy constitutes what general semantics calls a "beneficial neurological delay."
Abstracting and consciousness of abstracting.
Identification prevents what general semantics seeks to promote: the additional cortical processing experienced as a delay. Korzybski called his remedy for identification "consciousness of abstracting." The term "abstracting" is used ubiquitously in "Science and Sanity." Korzybski's use of the term is somewhat unique and requires study to understand his meaning. He discussed the problem of identification in terms of "confusions of orders of abstractions" and "lack of consciousness of abstracting." To be conscious of abstracting is to differentiate among the "levels" described above, levels II-IV being abstractions of level I (whatever level I "is"—all we really get are abstractions). The techniques Korzybski prescribed to help a person develop consciousness of abstracting he called "extensional devices." 
Extensional devices.
Satisfactory accounts of general semantics extensional devices can be found easily. This article seeks to explain briefly only the "indexing" devices. Suppose you teach in a school or university. Students enter your classroom on the first day of a new term, and, if you identify these new students to a memory association retrieved by your brain, you under-engage your powers of observation and your cortex. Indexing makes explicit a differentiating of studentsthis term from studentsprior terms. You survey the new students, and indexing explicitly differentiates student1 from student2 from student3, etc. Suppose you recognize one student—call her Anna—from a prior course in which Anna either excelled or did poorly. Again, you escape identification by your indexed awareness that Annathis term, this course is different from Annathat term, that course. Not identifying, you both expand and sharpen your apprehension of "students" with an awareness rooted in fresh silent-level observations.
Language as a core concern.
Autoassociative memory in the memory-prediction model describes neural operations in mammalian brains generally. A special circumstance for humans arises with the introduction of language components, both as fresh stimuli and as stored representations. Language considerations figure prominently in general semantics, and three language and communications specialists who embraced general semantics, university professors and authors Hayakawa, Wendell Johnson and Neil Postman, played major roles in framing general semantics, especially for non-readers of "Science and Sanity".
The science.
Many recognized specialists in the knowledge areas where Korzybski claimed to have anchored general semantics—biology, epistemology, mathematics, neurology, physics, psychiatry, etc.— supported his work in his lifetime, including Cassius J. Keyser, C. B. Bridges, W. E. Ritter, P. W. Bridgman, G. E. Coghill, William Alanson White, Clarence B. Farrar, David Fairchild, and Erich Kähler. Korzybski wrote in the preface to the third edition of "Science and Sanity" (1947) that general semantics "turned out to be an empirical natural science." 
But the type of existence, if any, of universals and abstract objects is an issue of serious debate within metaphysical philosophy. So Black summed up general semantics as "some hypothetical neurology fortified with dogmatic metaphysics." And in 1952, two years after Korzybski died, American skeptic Martin Gardner wrote, "[Korzybski's] work moves into the realm of cultism and pseudo-science."
Former Institute of General Semantics executive director Steve Stockdale has compared GS to yoga. "First, I'd say that there is little if any benefit to be gained by just "knowing" something about general semantics. The benefits come from maintaining an awareness of the principles and attitudes that are derived from GS and applying them as they are needed. You can sort of compare general semantics to yoga in that respect... knowing about yoga is okay, but to benefit from yoga you have to "do" yoga." Similarly, Kenneth Burke explains Korzybski's kind of semantics contrasting it, in "A Grammar of Motives", with a kind of Burkean poetry by saying ""Semantics" is essentially scientist, an approach to language in terms of knowledge, whereas poetic forms are kinds of action".
History.
Early attempts at validation.
The First American Congress for General Semantics convened in March 1935 at the Central Washington College of Education in Ellensburg, WA. In introductory remarks to the participants, Korzybski said: General semantics formulates a new experimental branch of natural science, underlying an empirical theory of human evaluations and orientations and involving a definite neurological mechanism, present in all humans. It discovers direct neurological methods for the stimulation of the activities of the human cerebral cortex and the direct introduction of beneficial neurological 'inhibition'... He added that general semantics "will be judged by experimentation." One paper presented at the congress reported dramatic score improvements for college sophomores on standardized intelligence tests after six weeks of training by methods prescribed in Chapter 29 of "Science and Sanity."
Interpretation as semantics.
General semantics accumulated only a few early experimental validations. In 1938, economist and writer Stuart Chase praised and popularized Korzybski in "The Tyranny of Words". Chase called Korzybski "a pioneer" and described "Science and Sanity" as "formulating a genuine science of communication. The term which is coming into use to cover such studies is 'semantics,' matters having to do with signification or meaning." Because Korzybski, in "Science and Sanity", had articulated his program using "semantic" as a standalone qualifier on hundreds of pages in constructions like "semantic factors," "semantic disturbances," and especially "semantic reactions," to label the general semantics program "semantics" amounted to only a convenient shorthand.
Hayakawa read "The Tyranny of Words," then "Science and Sanity", and in 1939 he attended a Korzybski-led workshop conducted at the newly organized Institute of General Semantics in Chicago. In the introduction to his own "Language in Action", a 1941 Book of the Month Club selection, Hayakawa wrote, "[Korzybski's] principles have in one way or another influenced almost every page of this book..." But, Hayakawa followed Chase's lead in interpreting general semantics as making communication its defining concern. When Hayakawa co-founded the Society for General Semantics and its publication "ETC.:A Review of General Semantics" in 1943—he would continue to edit "ETC." until 1970—Korzybski and his followers at the Institute of General Semantics began to complain that Hayakawa had wrongly coopted general semantics. In 1985, Hayakawa gave this defense to an interviewer: "I wanted to treat general semantics as a subject, in the same sense that there's a scientific concept known as gravitation, which is independent of Isaac Newton. So after a while, you don't talk about Newton anymore; you talk about gravitation. You talk about semantics and not Korzybskian semantics." 
Lowered sights.
The regimen in the Institute's seminars, greatly expanded as team-taught seminar-workshops starting in 1944, continued to develop following the prescriptions laid down in Chapter XXIX of "Science and Sanity." The structural differential, patented by Korzybski in the 1920s, remained among the chief training aids to help students reach "the silent level," a prerequisite for achieving "neurological delay." Innovations in the seminar-workshops included a new "neuro-relaxation" component, led by dancer and Institute editorial secretary Charlotte Schuchardt (1909–2002).
But although many people were introduced to general semantics—perhaps the majority through Hayakawa's more limited 'semantics'—superficial lip service seemed more common than the deep internalization that Korzybski and his co-workers at the Institute aimed for. Marjorie Kendig (1892–1981), probably Korzybski's closest co-worker, director of the Institute after his death, and editor of his posthumously published "Collected Writings: 1920-1950", wrote in 1968:I would guess that I have known about 30 individuals who have in some degree adequately, by my standards, mastered this highly general, very simple, very difficult system of orientation and method of evaluating—reversing as it must all our cultural conditioning, neurological canalization, etc...
To me the "great error" Korzybski made—and I carried on, financial necessity—and for which we pay the price today in many criticisms, consisted in not restricting ourselves to training very thoroughly "a very few people" who would be competent to utilize the discipline in various fields and to train others. We should have done this before encouraging anyone to popularize or spread the word (horrid phrase) in societies for general semantics, by talking "about" general semantics instead of learning, using, etc. the methodology to "change" our essential epistemological assumptions, premises, etc. (unconscious or conscious), i.e. the "un"-learning basic to learning to learn.
Yes, large numbers of people do enjoy making a philosophy of general semantics. This saves them the pain of rigorous training so simple and general and limited that it seems obvious when "said", yet so difficult.
Successors at the Institute of General Semantics continued for many years along the founders' path. Stuart Mayper (1916–1997), who studied under Karl Popper, introduced Popper's principle of falsifiability into the seminar-workshops he led at the Institute starting in 1977. More modest pronouncements gradually replaced Korzybski's claims that general semantics can change human nature and introduce an era of universal human agreement. In 2000, Robert Pula (1928–2004), whose roles at the Institute over three decades included Institute director, editor-in-chief of the Institute's "General Semantics Bulletin", and leader of the seminar-workshops, characterized Korzybski's legacy as a "contribution toward the improvement of human evaluating, to the amelioration of human woe..."
Hayakawa died in 1992. The Society for General Semantics merged into the Institute of General Semantics in 2003. In 2007, Martin Levinson, president of the Institute's Board of Trustees, teamed with Paul D. Johnston, executive director of the Society at the date of the merger, to teach general semantics with a light-hearted "Practical Fairy Tales for Everyday Living". The Institute currently offers no training workshops.
Other institutions supporting or promoting general semantics in the 21st century include the New York Society for General Semantics, the European Society for General Semantics, the Australian General Semantics Society, and the Balvant Parekh Centre for General Semantics and Other Human Sciences (Baroda, India).
Connections to other disciplines.
General semantics has important links with analytic philosophy and the philosophy of science; it could be characterized without too much distortion as applied analytic philosophy. The influence of Ludwig Wittgenstein and the Vienna Circle, and of early operationalists and pragmatists such as Charles Sanders Peirce, is particularly clear in the foundational ideas of general semantics. Korzybski himself acknowledged many of these influences.
The concept of "silence on the objective level" attributed to Korzybski and his insistence on consciousness of abstracting are parallel to some central ideas in Zen Buddhism. Korzybski is not recorded to have acknowledged any influence from this quarter, but he formulated general semantics during the same years that the first popularizations of Zen were becoming part of the intellectual currency of educated speakers of English. On the other hand, later Zen-popularizer Alan Watts was influenced by ideas from general semantics.
L. Ron Hubbard is widely believed to have used the theory in his creation of Dianetics and later to have incorporated it into Scientology, and acknowledges this in several texts; the first of these two movements in turn introduced general semantics to a wider audience in the early 1950s, including popular science fiction writer A. E. van Vogt, personal growth theorist Harvey Jackins and his movement Re-evaluation Counseling and movements like Gestalt therapy. The founders of these movements did not themselves credit Korzybski for their ideas.
General semantics has survived most profoundly in the cognitive therapies that emerged in the 1950s and 1960s. Albert Ellis (1913–2007), who developed Rational emotive behavior therapy, acknowledged influence from general semantics and delivered the Alfred Korzybski Memorial Lecture in 1991. The Bruges (Belgium) center for Solution Focused Therapy operates under the name Korzybski Institute Training and Research Center. George Kelly, founder of Personal Construct Psychology, was influenced by general semantics. Frederick Perls and Paul Goodman, founders of Gestalt therapy are said to have been influenced by Korzybski Wendell Johnson wrote "People in Quandaries: The Semantics of Personal Adjustment" in 1946, which stands as the first attempt to form a therapy from general semantics
Ray Solomonoff (July 25, 1926 – December 7, 2009) was influenced by Korzybski. Solomonoff was the inventor of algorithmic probability, and founder of algorithmic information theory (aka Kolmogorov complexity). 
Another scientist influenced by Korzybski (verbal testimony) is Paul Vitanyi (born July 21, 1944), a scientist in the theory of computation.
During the 1940s, 1950s, and 1960s, general semantics entered the idiom of science fiction, most notably through the works of A. E. van Vogt, "The World of Null-A" and its sequels, Robert A. Heinlein, "Gulf",
and Frank Herbert, in "Dune" and "Whipping Star". The ideas of general semantics became a sufficiently important part of the shared intellectual toolkit of genre science fiction to merit parody by Damon Knight and others; they have since shown a tendency to reappear in the work of more recent writers such as Samuel R. Delany, Suzette Haden Elgin and Robert Anton Wilson. In 2008, John Wright extended van Vogt's Null-A series with "Null-A Continuum". William Burroughs references Korzybski's time binding principle in his essay The Electronic Revolution, and elsewhere.
Neil Postman, founder of New York University's media ecology program in 1971, edited "ETC.: A Review of General Semantics" from 1976 to 1986. Postman's student Lance Strate, a co-founder of the Media Ecology Association, served as executive director of the Institute of General Semantics from 2007 to 2010.

</doc>
<doc id="60525" url="https://en.wikipedia.org/wiki?curid=60525" title="List of Intel microprocessors">
List of Intel microprocessors

This generational and chronological list of Intel processors attempts to present all of Intel's processors from the pioneering 4-bit 4004 (1971) to the present high-end offerings, which include the 64-bit Itanium 2 (2002), Intel Core i7, and Xeon E3 and E5 series processors (2015). Concise technical data are given for each product.
The 4-bit processors.
Intel 4004.
First microprocessor (single-chip IC processor)
MCS-4 Family:
Microcontrollers.
They are ICs with CPU, RAM, ROM (or PROM or EPROM), I/O Ports, Timers & Interrupts
Intel 8048.
MCS-48 family:
Intel 8051.
MCS-51 Family:
Intel 80151.
MCS-151 Family:
Intel 80251.
MCS-251 Family:
The bit-slice processor.
3000 Family.
Introduced in the third quarter of 1974, these components used bipolar Schottky transistors. Each component implemented two bits of a processor function; packages could be interconnected to build a processor with any desired word length. 
Members of the family:
Bus width 2*"n" bits data/address (depending on number "n" of slices used)
32-bit processors: the 80486 range.
80486DX2.
Runs at twice the speed of the external bus (FSB).
Fits on Socket 3
32-bit processors: P6/Pentium M microarchitecture.
Celeron (Pentium II-based).
Pentium II Xeon "(chronological entry)"
Celeron (Pentium III Coppermine-based).
XScale "(chronological entry - non-x86 architecture)"
Pentium 4 (not 4EE, 4E, 4F), Itanium, P4-based Xeon, Itanium 2 "(chronological entries)"
32-bit processors: NetBurst microarchitecture.
Pentium 4.
Itanium "(chronological entry - new non-x86 architecture)"
Xeon.
Itanium 2 "(chronological entry - new non-x86 architecture)"
64-bit processors: Intel 64 – Nehalem microarchitecture.
Core i7.
TODO:
Westmere
Intel 805xx product codes.
Intel discontinued the use of part numbers such as 80486 in the marketing of mainstream x86-architecture microprocessors with the introduction of the Pentium brand in 1993. However, numerical codes, in the 805xx range, continued to be assigned to these processors for internal and part numbering uses. The following is a list of such product codes in numerical order:

</doc>
<doc id="60528" url="https://en.wikipedia.org/wiki?curid=60528" title="List of colleges and universities in California">
List of colleges and universities in California

This is a list of colleges and universities in California.

</doc>
<doc id="60529" url="https://en.wikipedia.org/wiki?curid=60529" title="USS Wasp">
USS Wasp

USS "Wasp" may refer to: 

</doc>
<doc id="60530" url="https://en.wikipedia.org/wiki?curid=60530" title="List of professional sports teams in California">
List of professional sports teams in California

Major professional sports teams.
Major League Baseball.
San Francisco Giants.
1 World Championships won while playing in California
National Football League.
Los Angeles Rams.
1 World Championships won while playing in California

</doc>
<doc id="60531" url="https://en.wikipedia.org/wiki?curid=60531" title="Anna Leonowens">
Anna Leonowens

Anna Harriette Leonowens (born Anna Harriet Emma Edwards; 5 November 1831 – 19 January 1915) was an Anglo-Indian or Indian-born British travel writer, educator and social activist.
She became well-known with the publication of her memoirs, beginning with "The English Governess at the Siamese Court" (1870), which chronicled her experiences in Siam (modern Thailand), as teacher to the children of the Siamese King Mongkut. Leonowens' own account has been fictionalised in Margaret Landon's 1944 best-selling novel "Anna and the King of Siam", as well as films and television series based on the book, most notably Rodgers and Hammerstein's 1951 hit musical "The King and I".
During the course of her life, Leonowens also lived in Aden, Australia, Singapore, the United States and Canada. Among other achievements, she co-founded the Nova Scotia College of Art and Design.
Early life and family.
Anna Leonowens' mother, Mary Glascott, married her father, Sergeant Thomas Edwards, a non-commissioned officer of the Sappers and Miners, on 15 March 1829 in Tannah. Edwards was from London and a former cabinetmaker.She was born in Ahmednagar district, India, on 5 November 1831, three months after the death of her father. While she was christened Anna Harriet Emma Edwards, Leonowens later changed Harriet to "Harriette" and ceased using her third given name (Emma).
Leonowens' maternal grandfather, William Vawdrey (or Vaudrey) Glascott, was an English-born commissioned officer of the 4th Regiment, Bombay Native Infantry, in the Bombay Army. Glascott arrived in India in 1810, and was apparently married in 1815, although his wife's name is not known. According to biographer Susan Morgan, the only viable explanation for the complete and deliberate lack of information regarding Glascott's wife, in official British records, is that she "was not European". Morgan suggests that she was "most likely ... Anglo-Indian (of mixed race) born in India." Anna's mother, Mary Anne Glascott, was born in 1815 or 1816.
For most of her adult life, Anna Edwards had no contact with her family and took pains to disguise her origins by claiming that she had been born with the surname "Crawford" in Caernarfon and giving her father's rank as Captain. By doing so, she protected not only herself but her children, who would have had greater opportunities if their mixed-race heritage remained unknown. Investigations uncovered no record of her birth at Caernarfon, news which came as a shock to the town that had long claimed her as one of its most famous natives.
On 24 April 1845, Anna's 15-year-old sister, Eliza Julia Edwards, married James Millard, a Sergeant-Major with the 4th Troop Artillery, Indian Army in Deesa, Banaskantha, Gujarat, India. Their daughter, Eliza Sarah Millard, born in 1848 in India, married on 7 October 1864 in Surat, Gujarat, India. Her husband was Edward John Pratt, a 38-year-old British civil servant who had served in the Indian Navy. One of their sons, William Henry Pratt, born 23 November 1887 upon their return to London, was better known by his stage name of Boris Karloff, making her his great-aunt. Anna Edwards never approved of her sister's marriage, and her self-imposed separation from the family was so complete that, decades later, when a Pratt relative contacted her, she replied by threatening suicide if he persisted.
Mary Edwards later married an Irish soldier, Patrick Donohoe of the Royal Engineers. Anna Edwards's relationship with her stepfather Donohoe was not a happy one, and she later accused him of putting pressure on her, like her sister (with whom she also fell out), to marry a much older man. In 1847, Donohoe was seconded as assistant supervisor of public works in Aden. If the rest of the family went with him or stayed in India is unsure. 
Anna Leonowens later claimed that she had gone on a three-year tour through Egypt and the Middle East with the orientalist Reverend George Percy Badger and his wife. However, recent biographies consider this episode to be fictitious. Anna may have met Badger in India and listened to or read reports about his travels.
Marriage, Western Australia, and widowhood.
At the end of 1849, Anna Edwards returned with her family to India, where in Poona, over the objections of her stepfather and mother, she married her childhood sweetheart, Thomas Leon (or Lane/Lean) Owens; he later merged his second and last names as Leonowens. Her husband was a civilian clerk (rather than the army officer suggested by her memoir). 
In 1852 the young couple, accompanied by Anna's uncle, W. V. Glasscott, sailed to Australia via Singapore, where they boarded the barque "Alibi". The journey from Singapore was long and Anna gave birth to a son, Thomas, while on board. On 8 March 1853, nearing the Western Australian coast, the "Alibi" was almost wrecked on a reef. Ten days later Anna, Thomas, their newborn son and Glasscott arrived in Perth. Glasscott and Thomas Leonowens quickly found employment as clerks in the colonial administration. Later in 1853, Glasscott accepted a position as government commissariat storekeeper at Lynton, a small and remote settlement that was the site of Lynton Convict Depot. Glasscott became involved in frequent disagreements with the abrasive Resident Magistrate, William Burges. Within three years Glasscott had returned to India and taken up a career in teaching (before dying suddenly in 1856). 
Anna Leonowens – using her middle name of Harriett – tried to start a school for young ladies. However, in March 1854, Thomas junior died at the age of 13 months, and later that year, a daughter, Avis Annie, was born. In 1855, Thomas Leonowens was appointed to Glasscott's former position with the commissariat at Lynton, and the family moved there. At Lynton, Anna Leonowens gave birth to a son, Louis. During late 1856, Thomas Leonowens also served briefly as magistrate's clerk under William Burges. Like Glasscott, Thomas clashed with Burges, but survived until the Convict Depot was closed in 1857, and he was transferred to a more senior position with the Commissariat in Perth.
The Leonowens family left Australia abruptly in April 1857, sailing to Singapore, and then moving to Penang, where Thomas found work as a hotel keeper. In or before the first week of May 1859, Thomas Leonowens died of "apoplexy" and was buried (7 May 1859) in the Protestant Cemetery in Penang. His death left Anna Leonowens an impoverished widow. Of their four children, the two eldest had died in infancy. To support her surviving daughter Avis and son Louis, Leonowens again took up teaching, and opened a school for the children of British officers in Singapore. While the enterprise was not a financial success, it established her reputation as an educator.
Royal governess.
In 1862, Leonowens accepted an offer made by the consul in Singapore, Tan Kim Ching, to teach the wives and children of Mongkut, King of Siam. The king wished to give his 39 wives and concubines and 82 children a modern Western education on scientific secular lines, which earlier missionaries' wives had not provided. Leonowens sent her daughter Avis to school in England, and took her son Louis with her to Bangkok. She succeeded Dan Beach Bradley, an American missionary, as teacher to the Siamese court.
Leonowens served at court until 1867, a period of nearly six years, first as a teacher and later as language secretary for the king. Although her position carried great respect and even a degree of political influence, she did not find the terms and conditions of her employment to her satisfaction, and came to be regarded by the king himself as a "difficult woman and more difficult than generality".
In 1868, Leonowens was on leave for her health in England and had been negotiating a return to the court on better terms when Mongkut fell ill and died. The king mentioned Leonowens and her son in his will, though they did not receive a legacy. The new monarch, fifteen-year-old Chulalongkorn, who succeeded his father, wrote Leonowens a warm letter of thanks for her services. He did not invite her to resume her post but they corresponded amicably for many years. At the age of 27, Louis Leonowens returned to Siam and was granted a commission of Captain in the Royal Cavalry. Chulalongkorn made reforms for which his former tutor claimed some of the credit, including the abolition of the practice of prostration before the royal person. However, many of those same reforms were goals established by his father.
Literary career.
By 1869, Leonowens was in New York City, where she opened a school for girls for a brief period on Staten Island, and began contributing travel articles to a Boston journal, "Atlantic Monthly", including "The Favorite of the Harem", reviewed by the "New York Times" as "an Eastern love story, having apparently a strong basis of truth". She expanded her articles into two volumes of memoirs, beginning with "The English Governess at the Siamese Court" (1870), which earned her immediate fame but also brought charges of sensationalism. In her writing, she casts a critical eye over court life; the account is not always a flattering one, and has become the subject of controversy in Thailand; she has also been accused of exaggerating her influence with the king. There have also been claims of fabrication: the likelihood of the argument over slavery, for example, when King Mongkut was for 27 years a Buddhist monk and later abbot, before ascending to the throne. It is thought that his religious training and vocation would never have permitted the views expressed by Leonowens' cruel, eccentric and self-indulgent monarch.
Leonowens was a feminist and in her writings she tended to focus on what she saw as the subjugated status of Siamese women, including those sequestered within the "Nang Harm", or royal harem. She emphasised that although Mongkut had been a forward-looking ruler, he had desired to preserve customs such as prostration and sexual slavery which seemed unenlightened and degrading. The sequel, "Romance of the Harem" (1873), incorporates tales based on palace gossip, including the king's alleged torture and execution of one of his concubines, Tuptim; the story lacks independent corroboration and is dismissed as out of character for the king by some critics. A great granddaughter, Princess Vudhichalerm Vudhijaya (b. 21 May 1934), stated in a 2001 interview, "King Mongkut was in the monk's hood for 27 years before he was king. He would never have ordered an execution. It is not the Buddhist way." She added that the same Tuptim was her grandmother and had married Chulalongkorn. (He had 36 wives.)
While in the United States, Leonowens also earned much-needed money through popular lecture tours. At venues such as the house of Mrs. Sylvanus Reed in Fifty-third Street, New York City, in the regular members' course at Association Hall, or under the auspices of bodies such as the Long Island Historical Society, she lectured on subjects including "Christian Missions to Pagan Lands" and "The Empire of Siam, and the City of the Veiled Women". The "New York Times" reported: "Mrs. Leonowens' purpose is to awaken an interest, and enlist sympathies, in behalf of missionary labors, particularly in their relation to the destiny of Asiatic women." She joined the literary circles of New York and Boston and made the acquaintance of local lights on the lecture circuit, such as Oliver Wendell Holmes, Henry Wadsworth Longfellow and Harriet Beecher Stowe, author of "Uncle Tom's Cabin", a book whose anti-slavery message Leonowens had brought to the attention of the royal household. She said the book influenced Chulalongkorn's reform of slavery in Siam, a process he had begun in 1868, and which would end with its total abolition in 1915. Meanwhile, Louis had accumulated debts in the U.S. by 1874 and fled the country. He became estranged from his mother and did not see her for 19 years.
Canada.
In 1878, Leonowens’s daughter Avis Annie Crawford Connybeare married Thomas Fyshe, a Scottish banker and the cashier (general manager) of the Bank of Nova Scotia in Halifax, where she resided for nineteen years as she continued to travel the world. This marriage ended the family's money worries.
Leonowens resumed her teaching career and taught daily from 9 am to 12 noon for an autumn half at the Berkeley School of New York at 252 Madison Avenue, Manhattan, beginning on 5 October 1880; this was a new preparatory school for colleges and schools of science and her presence was advertised in the press. Leonowens visited Russia in 1881, shortly after the assassination of Tsar Alexander II, and other European countries, and continued to publish travel articles and books.
She settled in Halifax, Nova Scotia, Canada, where she again became involved in women's education, and was a suffragist and one of the founders of the Local Council of Women of Halifax and the Nova Scotia College of Art and Design. After nineteen years, she moved to Montreal, Quebec.
Leonowens's son, Louis, returned to Siam and became an officer in the Siamese royal cavalry. He married Caroline Knox, a daughter of Sir Thomas George Knox, the British consul-general in Bangkok (1824–1887), and his Thai wife, Prang Yen. Under Chulalongkorn's patronage, Louis Leonowens founded the successful trading company that bears his name, Louis T. Leonowens & Co. Ltd. which is still trading in Thailand.
Anna Leonowens met Chulalongkorn again when he visited London in 1897, thirty years after she had left Siam. During this audience the king took the opportunity to express his thanks in person but he also voiced his dismay at the inaccuracies in Leonowens' books.
Anna Leonowens died on 19 January 1915, at 83 years of age. She was interred in Mount Royal Cemetery in Montreal.
Anna Leonowens in fiction and film.
Margaret Landon's novel "Anna and the King of Siam" (1944) provides a fictionalised look at Anna Leonowens's years at the royal court, developing the abolitionist theme that resonated with her American readership. In 1946, Talbot Jennings and Sally Benson adapted it into the screenplay for a dramatic film of the same name, starring Irene Dunne and Rex Harrison. In response, Thai authors Seni and Kukrit Pramoj wrote their own account in 1948 and sent it to American politician and diplomat Abbot Low Moffat (1901–1996), who drew on it for his biography "Mongkut, the King of Siam" (1961). Moffat donated the Pramoj brothers' manuscript to the Library of Congress in 1961.
Landon had, however, created the iconic image of Leonowens, and "in the mid-20th century she came to personify the eccentric Victorian female traveler". The novel was adapted as a hit musical by Rodgers and Hammerstein, "The King and I" (1951), starring Gertrude Lawrence and Yul Brynner, which ran 1,246 performances on Broadway and was also a hit in London and on tour. In 1956, a film version was released, with Deborah Kerr starring in the role of Leonowens and Brynner reprising his role as the king. Revived many times on stage (with Brynner starring in revivals until 1985), the musical has remained a favourite of the theatregoing public.
The humorous depiction of Mongkut as a polka-dancing despot, as well as the king's and Anna's apparent romantic feeling for each other, is condemned as disrespectful in Thailand, where the Rodgers and Hammerstein film and musical were banned by the government. The 1946 film version of "Anna and the King of Siam" starring Rex Harrison as Mongkut was allowed to be shown in Thailand, although it was banned in newly independent India as an inaccurate insult by westerners to an Eastern king. In 1950, the Thai government did not permit the film to be shown for the second time in Thailand. The books "Romance in the Harem" and "An English Governess at the Siamese Court" were not banned in Thailand. There were even Thai translations of these books by respected Thai writer "Humorist" (Ob Chaivasu).
During a visit to the United States in 1960, the monarch of Thailand, King Bhumibol (a great-grandson of Mongkut), and his entourage explained that from what they could gather from the reviews of the musical, the characterisation of Mongkut seemed "90 percent exaggerated. My great-grandfather was really quite a mild and nice man." Years later, during her 1985 visit to New York, Bhumibol's wife, Queen Sirikit, went to see the Broadway musical at the invitation of Yul Brynner. The then ambassador of Thailand to the US gave another reason for Thailand's disapproval of "The King and I": its ethno-centric attitude and its barely hidden insult on the whole Siamese nation as childish and inferior to the Westerners.
In 1972, Twentieth Century Fox produced a non-musical American TV series for CBS, "Anna and the King", with Samantha Eggar taking the part of Leonowens and Brynner reprising his role as the king. Margaret Landon charged the makers with "inaccurate and mutilated portrayals" of her literary property and sued unsuccessfully for copyright infringement. The series was not a success and was cancelled after only 13 episodes. In 1999 an animated film using the songs of the musical was released by Warner Bros. Animation. In the same year, Jodie Foster and Chow Yun-fat starred in a new feature-length cinematic adaptation of Leonowens' books, also titled "Anna and the King". One Thai critic complained that the filmmakers had made Mongkut "appear like a cowboy"; this version was also banned by censors in Thailand.
Leonowens appears as a character in Paul Marlowe's novel "Knights of the Sea", in which she travels from Halifax to Baddeck in 1887 to take part in a campaign to promote women's suffrage during a by-election.

</doc>
<doc id="60533" url="https://en.wikipedia.org/wiki?curid=60533" title="CSS Scorpion">
CSS Scorpion

CSS "Scorpion" was a "Squib"-class torpedo boat procured late in 1864 by the Confederate States Navy and armed with a spar torpedo fitted to her stem. She performed picket duty in the James River under command of Lieutenant E. Lakin, CSN.
On January 23 to January 25, 1865, torpedo boats 
"Scorpion", and , under the overall command of Lieutenant Charles W. Read, CSN, joined Flag Officer J.K. Mitchell's James River Squadron in the abortive attack on General Ulysses S. Grant's main supply base at City Point, Virginia. Attempting to rejoin her consort, the ironclad ran aground above Trent's Reach; "Scorpion" ended up fast ashore also and was severely damaged by the magazine explosion which destroyed nearby gunboat , on January 24. Abandoned, she fell into Federal hands.

</doc>
<doc id="60534" url="https://en.wikipedia.org/wiki?curid=60534" title="Shilling">
Shilling

The shilling is a unit of currency formerly used in the United Kingdom, Australia, and other British Commonwealth countries. The word "shilling" comes from "scilling", an accounting term that dates back to Anglo-Saxon times, and from there back to Old Norse, where it means "division". In fact, many Norse-influenced countries use the term too.
Slang terms for the old shilling coins include "bob" and "hog".
One abbreviation for shilling is s (for "solidus", see £sd). Often it was informally represented by a slash, standing for a long s or ſ, thus "1/6" would be 1 shilling and sixpence, often pronounced "one and six" (and equivalent to 18d; the shilling itself was valued at 12d). A price with no pence was written with a slash and a dash: "11/–." Quite often a triangle or (serif) apostrophe would be used to give a neater appearance, such as "1'6" or "11'–." In Africa, it is often abbreviated sh.
During the Great Recoinage of 1816, the mint was instructed to coin one troy pound (weighing 5760 grains) of standard (0.925 fine) silver into 66 shillings, or its equivalent in other denominations. This effectively set the weight of the shilling, and its subsequent decimal replacement 5 new pence coin, at 87.2727 grains or 5.655 grams from 1816 to 1990, when a new smaller 5p coin was introduced.
In the past, the English world has had various myths about the shilling. One myth was that it was deemed to be the value of a cow in Kent or a sheep elsewhere.
British Isles.
Kingdom of England.
In England, a shilling was a coin used from the reign of Henry VII (or Edward VI "ca" 1550) until the Acts of Union ended the Kingdom of England (when, in the terms of Article 16 of the Articles of Union created by the Acts of Union of 1707, a common currency for the new United Kingdom was created).
Kingdom of Scotland.
The term "shilling" () was in use in Scotland from early medieval times.
Great Britain and the UK.
The common currency created in 1707 by Article 16 of the Articles of Union continued in use until decimalisation in 1971. In the traditional pounds, shillings and pence system, there were 20 shillings per pound and 12 pence per shilling, and thus there were 240 pence in a pound.
Three coins denominated in multiple shillings were also in circulation at this time. They were:
At decimalisation in 1971, the shilling coin was superseded by the new five-pence piece, which initially was of identical size and weight and had the same value, and inherited the shilling's slang name of a "bob".
Irish shillings.
Between 1701 and the unification of the currencies in 1825, the Irish shilling was valued at 13 pence and known as the "black hog", as opposed to the 12-pence English shillings which were known as "white hogs".
In the Irish Free State and Republic of Ireland the shilling was issued as "scilling" in Irish. It was worth 1/20th of an Irish pound, and was interchangeable at the same value to the British coin, which continued to be used in Northern Ireland. The coin featured the bull on the obverse side. The first minting from 1928 until 1941 contained 75% silver, more than the equivalent British coin. The original Irish shilling coin (retained after decimalisation)) was finally withdrawn from circulation on 1 January 1993, as a smaller five-pence coin was introduced.
Other countries in (former) British Empire/ Commonwealth.
Australian shillings.
Australian shillings, twenty of which made up one Australian pound, were first issued in 1910, with the Australian coat of arms on the reverse and King Edward VII on the face. The coat of arms design was retained through the reign of King George V until a new ram's head design was introduced for the coins of King George VI. This design continued until the last year of issue in 1963. In 1966, Australia's currency was decimalised and the shilling was replaced by a ten cent coin (Australian), where 10 shillings made up one Australian dollar.
The slang term for a shilling coin in Australia was "deener". The slang term for a shilling as currency unit was "bob", the same as in the United Kingdom.
After 1966, shillings continued to circulate, as they were replaced by 10-cent coins of the same size and weight.
New Zealand shilling.
New Zealand shillings, twenty of which made up one New Zealand pound, were first issued in 1933 and featured the image of a Maori warrior carrying a taiaha "in a warlike attitude" on the reverse. In 1967, New Zealand's currency was decimalised and the shilling was replaced by a ten cent coin of the same size and weight. Smaller 10-cent coins were introduced in 2006.
Maltese shillings.
Shillings were used in Malta, prior to decimalisation in 1972, and had a face value of five Maltese cents.
Ceylonese shillings.
In British Ceylon, a shilling (, ) was equivalent to eight fanams. With the replacement of the rixdollar by the rupee in 1852, a shilling was deemed to be equivalent to half a rupee. On the decimalisation of the currency in 1869, a shilling was deemed to be equivalent to 50 Ceylon cents. The term continued to be used colloquially until the late 20th century.
East African shillings.
The East African shilling was in use in the British colonies and protectorates of British Somaliland, Kenya, Tanganyika, Uganda and Zanzibar from 1920, when it replaced the rupee, until after those countries became independent, and in Tanzania after that country was formed by the merger of Tanganyika and Zanzibar in 1964. Upon independence in 1960, the East African shilling in the State of Somaliland (former British Somaliland) and the Somali somalo in the Trust Territory of Somalia (former Italian Somaliland) were replaced by the Somali shilling.
In 1966, the East African Monetary Union broke up, and the member countries replaced their currencies with the Kenyan shilling, the Ugandan shilling and the Tanzanian shilling, respectively. Though all these currencies have different values at present, there were plans to reintroduce the East African shilling as a new common currency by 2009, although this has not come about.
Northern America.
In the thirteen British colonies that became the United States in 1776, British money was often in circulation. Each colony issued its own paper money, with pounds, shillings, and pence used as the standard units of account. Some coins were minted in the colonies, such as the 1652 pine-tree shilling in the Massachusetts Bay Colony. After the United States adopted the dollar as its unit of currency and accepted the gold standard, one British shilling was worth 24 US cents. Due to ongoing shortages of US coins in some regions, shillings continued to circulate deep into the 19th century. Shillings are described as the standard monetary unit throughout the autobiography of Solomon Northup (1853) and mentioned several times in the Horatio Alger, Jr. story, "Ragged Dick" (1868).
Somali shilling.
Overview.
The Somali shilling is the official currency of Somalia. It is subdivided into 100 "cents" (English), "senti" (Somali, also سنت) or "centesimi" (Italian).
The Somali shilling has been the currency of parts of Somalia since 1921, when the East African shilling was introduced to the former British Somaliland protectorate. Following independence in 1960, the somalo of Italian Somaliland and the East African shilling (which were equal in value) were replaced at par in 1962 by the Somali shilling. Names used for the denominations were cent, centesimo (plural: centesimi) and سنت (plurals: سنتيمات and سنتيما) together with shilling, scellino (plural: scellini) and شلن.
That same year, the "Banca Nazionale Somala" issued notes for 5, 10, 20 and 100 scellini/shillings. In 1975, the "Bankiga Qaranka Soomaaliyeed" (Somali National Bank) introduced notes for 5, 10, 20 and 100 shilin/shillings. These were followed in 1978 by notes of the same denominations issued by the "Bankiga Dhexe Ee Soomaaliya" (Central Bank of Somalia). 50 shilin/shillings notes were introduced in 1983, followed by 500 shilin/shillings in 1989 and 1000 shilin/shillings in 1990. Also in 1990 there was an attempt to reform the currency at 100 to 1, with new banknotes of 20 and 50 new shilin prepared for the redenomination.
Following the breakdown in central authority that accompanied the civil war, which began in the early 1990s, the value of the Somali shilling was disrupted. The Central Bank of Somalia, the nation's monetary authority, also shut down operations. Rival producers of the local currency, including autonomous regional entities such as the Somaliland territory, subsequently emerged.
Somalia's newly established Transitional Federal Government revived the defunct Central Bank of Somalia in the late 2000s. In terms of financial management, the monetary authority is in the process of assuming the task of both formulating and implementing monetary policy. Owing to a lack of confidence in the Somali shilling, the US dollar is widely accepted as a medium of exchange alongside the Somali shilling. Dollarization notwithstanding, the large issuance of the Somali shilling has increasingly fueled price hikes, especially for low value transactions. This inflationary environment, however, is expected to come to an end as soon as the Central Bank assumes full control of monetary policy and replaces the presently circulating currency introduced by the private sector.
Somaliland shilling.
The Somaliland shilling is the official currency of Somaliland, a self-declared republic that is internationally recognised as an autonomous region of Somalia. The currency is not recognised as legal tender by the international community, and it currently has no official exchange rate. It is regulated by the Bank of Somaliland, the territory's central bank. Although the authorities in Somaliland have attempted to bar usage of the Somali shilling, Somalia's official currency is still the preferred means of exchange for many peoples in the region.
Other.
Elsewhere in the former British Empire, forms of the word "shilling" remain in informal use.
In Vanuatu and Solomon Islands, "selen" is used in Bislama and Pijin to mean "money"; in Malaysia, "syiling" (pronounced like "shilling") means "coin". In Egypt and Jordan the "shillin" () is equal to 1/20th (five "qirshes" — , ) of the Egyptian pound or the Jordanian dinar.
Austrian schilling.
The Austrian schilling was the currency of Austria between 1924 and 1938 and again between 1945 and 2002. It was replaced by the euro at a fixed parity of €1 = 13.7603 schilling. The schilling was divided into 100 groschen.
Other countries' shillings.
Other European shillings.
Shillings were issued in the Scandinavian countries "(skilling)" until the Scandinavian Monetary Union of 1873, and in the city of Hamburg, Germany.
In Poland "szeląg" was used.
Low Countries.
In the principalities covering present Netherlands, Belgium and Luxemburg, the cognate term "schelling" was used as an equivalent 'arithmetic' currency, a 'solidus' representing 12 'denarii' or 1/20 'pound', while actual coins were rarely physical multiples of it, but still expressed in these terms.
Other.
The "sol" (later the "sou"), both also derived from the Roman solidus, were the equivalent coins in France, while the (nuevo) sol (PEN) remains the currency of Peru.
As in France, the Peruvian sol was originally named after the Roman solidus, but the name of the Peruvian currency is now much more closely linked to the Spanish word for the sun ("sol"). This helps explain the name of its temporary replacement, the inti, named for the Incan sun god.

</doc>
<doc id="60536" url="https://en.wikipedia.org/wiki?curid=60536" title="Geography of California">
Geography of California

California is a U.S. state on the western coast of North America. Covering an area of , California is geographically diverse. The Sierra Nevada, the fertile farmlands of the Central Valley, and the arid Mojave Desert of the south are some of the major geographic features of this U.S. state. It is home to some of the world's most exceptional trees: the tallest (coast redwood), most massive (Giant Sequoia), and oldest (bristlecone pine). It is also home to both the highest (Mt. Whitney) and lowest (Death Valley) points in the 48 contiguous states.
The state is generally divided into Northern and Southern California, although the boundary between the two is not well defined. San Francisco is decidedly a Northern California city and Los Angeles likewise a Southern California one, but areas in between do not often share their confidence in geographic identity. The US Geological Survey defines the geographic center of the state at a point near North Fork, California.
Earth scientists typically divide the state into eleven distinct geomorphic provinces with clearly defined boundaries. They are, from north to south, the Klamath Mountains, the Cascade Range, the Modoc Plateau, the Basin and Range, the Coast Ranges, the Central Valley, the Sierra Nevada, the Transverse Ranges, the Mojave Desert, the Peninsular Ranges, and the Colorado Desert. Here, the Los Angeles Basin, the Channel Islands, and the Pacific Ocean are treated as distinct regions.
State boundaries.
The boundaries of California were defined by Spanish claims of Mexico, as part of the province of Alta California. The northern boundary of Spanish claims was set at 42 degrees latitude by the Adams–Onis Treaty of 1819. The states of Nevada and Utah, also originally part of Alta California, also use that line for their northern boundaries. The southern boundary, between California and Mexico, was established by the Treaty of Guadalupe Hidalgo that ended the Mexican–American War in 1848. The line is about 30 miles north of the former Alta California southern boundary. The eastern boundary consists of two straight lines: a north-south line from the northern border to the middle of Lake Tahoe, and a second line angling southeast to the Colorado River. From that point, south–southwest of Davis Dam on Lake Mohave, the southeast boundary follows the Colorado River to the international border west of Yuma. The eastern and south-eastern boundaries were decided upon during the debates of the California Constitutional Convention in 1849.
Northern California.
Northern California usually refers to the state's northernmost 48 counties.
The main population centers of Northern California include San Francisco Bay Area (which includes the cities of San Francisco, Oakland, and the largest city of the region, San Jose), and Sacramento (the state capital) as well as its metropolitan area. It also contains redwood forests, along with the Sierra Nevada including Yosemite Valley and Lake Tahoe, Mount Shasta (the second-highest peak in the Cascade Range after Mount Rainier in Washington), and the northern half of the Central Valley, one of the world's most productive agricultural regions. The climate can be generally characterized by its marine to warm Mediterranean climates along the coast, to somewhat Continental Mediterranean Climate in the valley to alpine climate zones in the high mountains. Apart from the San Francisco Bay Area and Sacramento metropolitan areas (and some other cities in the Central Valley), it is a region of relatively low population density. Northern California's economy is noted for being the de facto world leader in industries such as high technology (both software and semiconductor), as well as being known for clean power, biomedical, government, and finance.
Klamath Mountains.
The Klamath Mountains are a mountain range in northwest California and southwest Oregon, the highest peak being Mount Eddy in Trinity County, California, at . They have a very varied geology, with substantial areas of serpentine and marble, and a climate characterized by moderately cold winters with very heavy snowfall, and warm very dry summers with limited rainfall. As a consequence of the geology, they have a unique flora including several endemic or near-endemic species, such as Lawson's Cypress (Chamaecyparis lawsoniana) and Foxtail Pine (Pinus balfouriana). Brewer's Spruce (Picea breweriana) and Kalmiopsis (Kalmiopsis leachiana) are relict species, remaining since the last ice age.
Cascade Range.
The Cascade Range is a mountainous region stretching from the Fraser River in British Columbia, Canada down to south of Lassen Peak, California. The Cascades (as they are called for short) are part of the Pacific Ring of Fire, the ring of volcanoes around the Pacific Ocean. All of the known historic eruptions in the contiguous United States have been from either Cascade volcanoes or near Mono Lake. Lassen Peak was the last Cascade volcano to erupt in California, from 1914 to 1921. Lassen is the most southerly active volcano of the Cascade chain.
This region is located in the northeastern section of the state bordering Oregon and Nevada, mostly north of the Central Valley and the Sierra Nevada mountain range. The area is centered on Mount Shasta, near the Trinity Alps. Mount Shasta is a dormant volcano, but there is some evidence that it erupted in the 18th Century.
Modoc Plateau.
In the northeast corner of the state lies the Modoc Plateau, an expanse of lava flows that formed a million years ago and now lie at an altitude of . The plateau has many cinder cones, juniper flats, pine forests, and seasonal lakes. The plateau lies between the Cascade Range to the west and the Warner Mountains to the east. The Lost River watershed drains the north part of the plateau, while southern watersheds either collect in basin reservoirs or flow into Big Sage Reservoir and thence to the Pit River.
Nine percent of the plateau is protected as reserves or wilderness areas, such as the Modoc National Wildlife Refuge. The plateau supports large herds of mule deer ("Odocoileus Hemionus"), Rocky Mountain Elk ("Cervus Canadensis"), and pronghorn ("Antilocapra Americana"). Herds of wild horses and livestock grazing have altered the original high desert ecosystem of the plateau.
Basin and Range.
To the east of the Sierra is the Basin and Range geological province, which extends into Nevada. The Basin and Range is a series of mountains and valleys (specifically horsts and grabens), caused by the extension of the Earth's crust. One notable feature of the Basin and Range is Mono Lake, which is the oldest lake in North America. The Basin and Range also contains the Owens Valley, the deepest valley in North America (more than 10,000 feet (3 km) deep, as measured from the top of Mount Whitney).
In the eastern part of the state, below the Sierra Nevada, there is a series dry lake beds that were filled with water during the last ice age (fed by ice melt from alpine glaciers but never directly affected by glaciation; see pluvial). Many of these lakes have extensive evaporite deposits that contain a variety of different salts. In fact, the salt sediments of many of these lake beds have been mined for many years for various salts, most notably borax (this is most famously true for Owens Lake and Death Valley).
In this province reside the White Mountains, which are home to the oldest living organism in the world, the bristlecone pine
Coast Ranges.
To the west of the Central Valley lies the Coast Ranges, including the Diablo Range, just east of San Francisco, and the Santa Cruz Mountains, to the south of San Francisco. The Coast Ranges north of San Francisco become increasingly foggy and rainy. These mountains are noted for their coast redwoods, the tallest trees on earth, which live within the range of the coastal fog.
Central Valley.
California's geography is largely defined by its central feature — the Central Valley, a huge, fertile valley between the coastal mountain ranges and the Sierra Nevada. The northern part of the Central Valley is called the Sacramento Valley, after its main river, and the southern part is called the San Joaquin Valley , after its main river. The whole Central Valley is watered by mountain-fed rivers (notably the San Joaquin, Kings, and Sacramento) that drain to the San Francisco Bay system. The rivers are sufficiently large and deep that several inland cities, notably Stockton, and Sacramento are seaports.
The southern tip of the valley has interior drainage and thus is not technically part of the valley at all. Tulare Lake, once 570 square miles (1,476 square kilometers) and now dry and covered with agricultural fields, once filled much of the area.
Sierra Nevada.
In the east of the state lies the Sierra Nevada, which runs north–south for . The highest peak in the contiguous United States, Mount Whitney at 14,505 feet (4,421 m), lies within the Sierra Nevada. The topography of the Sierra is shaped by uplift and glacial action.
The Sierra has 200–250 sunny days each year, warm summers, fierce winters, and varied terrain, a rare combination of rugged variety and pleasant weather. The famous Yosemite Valley lies in the Central Sierra. The large, deep freshwater Lake Tahoe lies to the North of Yosemite. The Sierra is also home to the Giant Sequoia, the most massive trees on Earth.
The most famous hiking and horse-packing trail in the Sierra is the John Muir Trail, which goes from the top of Mt. Whitney to Yosemite valley, and which is part of the Pacific Crest Trail that goes from Mexico to Canada. The three major national parks in this province are Yosemite National Park, Kings Canyon National Park, and Sequoia National Park.
Southern California.
The term Southern California usually refers to the ten southern-most counties of the state. This definition coincides neatly with the county lines at 35° 47′ 28″ north latitude, which form the northern borders of San Luis Obispo, Kern, and San Bernardino counties. Another definition for Southern California uses the Tehachapi Mountains as the northern boundary.
Southern California consists of a heavily developed urban environment, home to some of the largest urban areas in the state, along with vast areas that have been left undeveloped. With over 22 million people, roughly 60% of California's population resides in Southern California. It is the second-largest urbanized region in the United States, second only to the Washington/Philadelphia/New York/Boston Northeastern Megalopolis. Whereas these cities are dense, with major downtown populations and significant rail and transit systems, much of Southern California is famous for its large, spread-out, suburban communities and use of automobiles and highways. The dominant areas are Los Angeles, Orange County, San Diego, and Riverside-San Bernardino, each of which is the center of its respective metropolitan area, composed of numerous smaller cities and communities. The urban area is also host to an international metropolitan region in the form of San Diego–Tijuana, created by the urban area spilling over into Baja California.
Southern California is noted for industries including the film industry, residential construction, entertainment industry, and military aerospace. Other industries include software, automotive, ports, finance, tourism, biomedical, and regional logistics.
Transverse Ranges.
Southern California is separated from the rest of the state by the east-west trending Transverse Ranges, including the Tehachapi, which separate the Central Valley from the Mojave Desert. Urban Southern California intersperses the valleys between the Santa Susana Mountains, Santa Monica Mountains and San Gabriel Mountains, which range from the Pacific Coast, eastward over , to the San Bernardino Mountains, north of San Bernardino. The highest point of the range is Mount San Gorgonio at . The San Gabriel Mountains have Mount Wilson observatory, where the redshift was discovered in the 1920s.
The Transverse Ranges include a series of east–west trending mountain ranges that extend from Point Conception at the western tip of Santa Barbara County, eastward (and a bit south) to the east end of the San Jacinto Mountains in western Riverside County. The Santa Ynez Mountains make up the westernmost ranges, extending from Point Conception to the Ventura River just west-northwest of Ojai, in Ventura County. Pine Mountain Ridge, Nordhoff Ridge–Topatopa Mountains, Rincon Peak–Red Mountain, Sulphur Mountain, Santa Paula Ridge, South Mountain–Oat Mountain–Santa Susana Mountains, Simi Hills, Conejo Mountains–Santa Monica Mountains are all part of the Western Transverse Ranges, in Ventura and western Los Angeles Counties.
The Liebre Mountains occupy the northwest corner of Los Angeles County, and represent a northwestern extension of the San Gabriel Mountains, both on the Pacific Plate side of the San Andreas Fault. The fault divides the San Gabriel Mountains from the San Bernardino Mountains further to the east in San Bernardino County.
It is possible to surf in the Pacific Ocean and ski on a mountain during the same winter day in Southern California.
Los Angeles Basin.
For the last 15 million years, the Los Angeles, San Gabriel, and Santa Ana Rivers have deposited sediment from the Transverse Ranges along the southern coast of California. That sediment has formed the large, flat expanse of land known as the Los Angeles Basin, on which lives most of the population of Los Angeles and Orange Counties.
At its deepest point, near where the Los Angeles River meets the Rio Hondo, the sediment forming the basin is deep. The fact that so much sediment, which is naturally less stable than other geologic formations, underlies Los Angeles and its environs is one of the reasons earthquakes are such a danger to the metropolitan area.
Mojave Desert.
There are harsh deserts in the Southeast of California. These deserts are caused by a combination of the cold offshore current, which limits evaporation, and the rain shadow of the mountains. The prevailing winds blow from the ocean inland. When the air passes over the mountains, adiabatic cooling causes most water in the air to rain on the mountains. When the air returns to sea level on the other side of the mountains, it recompresses, warms and dries, parching the deserts. When the wind blows from inland, the resulting hot dry foehn winds are called the Santa Ana Winds.
The Mojave Desert is bounded by the peninsular Tehachapi Mountains on the Northwest, together with the San Gabriel and the San Bernardino Mountains on the Southwest. These Western boundaries are quite distinct, forming the dominant pie-slice shaped Antelope Valley in Southern California. The outlines of this valley are caused by the two largest faults in California: the San Andreas and the Garlock. The Mojave Desert extends Eastward into the State of Nevada. The Mojave Desert receives less than 6 inches (150 mm) of rain a year and is generally between 3,000 and 6,000 feet (1,000 and 2,000 m) of elevation. Areas such as the Antelope Valley desert which is a high desert received snow each year, in the past it could snow 2-3 times a year; however, recently snow level has declined significantly to once a year or less. Most of the towns and cities in the California portion of the Mojave are relatively small, except for Palmdale and Lancaster. However, some are quite famous like Barstow, a popular stop on the famous U.S. Route 66. The Mojave Desert also contains the lowest, hottest place in the Americas: Death Valley, where temperature normally approaches 120 °F (49 °C) in late July and early August.
Peninsular Ranges.
The southernmost mountains of California are the Peninsular Ranges, which are East of San Diego and continue into Baja California (Mexico) in the Sierra San Pedro Martir. The Peninsular Ranges contain the Laguna Mountains, the San Jacinto Mountains, the Santa Rosa Mountains, the Santa Ana Mountains and the Palomar Mountain Range, notable for its famous Palomar observatory. San Jacinto Peak's eastern shoulder has a cable tram that runs from the desert floor to nearly the top of the mountain where riders can set off hiking or go cross-country skiing.
Colorado Desert.
To the east of the peninsular ranges lie the Colorado and Sonoran Deserts, which extend into Arizona and Mexico.
The ground elevation is generally lower and in some areas was compressed downward, therefore the eastern Coachella and Imperial Valleys north of the U.S.-Mexican border are below sea level, the lowest community in the U.S. is Calipatria, California at below sea level. 
One feature of the desert is the Salton Sea, an inland lake that was formed in 1905 when a swollen Colorado River breached a canal near the U.S.-Mexico border and flowed into the Salton Sink (Salton Basin) for almost two years. Today, the Salton Sea, a new version of historic Lake Cahuilla, remains as California's largest lake.
The Channel Islands and Palos Verdes.
The Channel Islands are a group of islands off the coast of Southern California. They are divided into two groups, the Northern Channel Islands and the Southern Channel Islands. There are eight islands total:
Four of the islands are located in Santa Barbara County, two are located in Ventura County, and two are located in Los Angeles County. The islands have relatively few people. The only island with a sizable settlement is Santa Catalina, with its towns of Avalon and Two Harbors. The islands of Anacapa, San Miguel, Santa Barbara, Santa Cruz, and Santa Rosa make up the Channel Islands National Park. There is also a marine sanctuary in the islands, the Channel Islands National Marine Sanctuary. The Channel Islands, and in particular San Nicolas Island, are famous for the Lost Woman of San Nicolas, or Juana Maria. This woman was the main character in the book Island of the Blue Dolphins by Scott O’Dell.
The Palos Verdes Peninsula has the same geologic origins as the Channel Islands. Once an island north of Santa Catalina, Palos Verdes is today connected to the mainland. Over millions of years, sediment from nearby mountains extended the shoreline of the Los Angeles Basin until it reached Palos Verdes.
Pacific Ocean.
The Pacific Ocean lies to the west of California. Sea temperatures rarely exceed 65 °F (18 °C), even in summer, because of up-welling deep waters with dissolved nutrients. Therefore, most sea life in and around California more closely resembles Arctic, rather than tropical, biotopes. The sea off California is remarkably fertile, a murky green filled with fish, rather than the clear dead blue of most tropical seas. Before 1930, there was an extremely valuable sardine (herring) fishery off Monterey, but this was depleted, an event later famous as the background to John Steinbeck's "Cannery Row".
Geology.
Faults, volcanoes, and tsunamis.
Earthquakes occur due to faults that run the length of the Pacific coast, the largest being the San Andreas Fault. Major historical earthquakes include, with the magnitudes listed:
Coastal cities are vulnerable to tsunamis from locally generated earthquakes as well as those elsewhere in the Pacific Ring of Fire. The Great Chilean earthquake tsunami (1960) killed one person and caused $500,000 to $1,000,000 dollars of damage in Los Angeles, damaged harbors in many coastal cities, and flooded streets in Crescent City. Waves from the Alaskan Good Friday earthquake of 1964 killed twelve people in Crescent City and caused damage as far south as Los Angeles. USGS has released UCERF California earthquake forecast which models earthquake occurrence in California.
California is also home to several volcanoes, including Lassen Peak, which erupted in 1914 and 1921, and Mount Shasta.
Continental drift.
California, when only partially explored by the Spanish, was once thought to be an island, as when the southern Baja California Peninsula is approached from the Gulf of California the land appears to the west. It is expected, through the motions of plate tectonics that the sea floor spreading now acting in the Gulf of California (also known as the Sea of Cortez) will eventually extend through Southern California and along the San Andreas fault to below San Francisco, finally forming a long island in less than 150 million years. (For comparison, this is also the approximate age of the Atlantic Ocean.) Predictions suggest that this island will eventually collide with Alaska after an additional 100 million years.
Climate.
California's climate varies widely, from arid to subarctic, depending on latitude, elevation, and proximity to the coast. Coastal and Southern parts of the state have a Mediterranean climate, with somewhat rainy winters and dry summers. The influence of the ocean generally moderates temperature extremes, creating warmer winters and substantially cooler summers, especially along the coastal areas.
The state is subject to coastal storms during the winter. Eastern California is subject to summertime thunderstorms caused by the North American monsoon. Dry weather during the rest of the year produces conditions favorable to wildfires. California hurricanes occur less frequently than their counterparts on the Atlantic Ocean. Higher elevations experience snowstorms in the winter months.
Floods are occasionally caused by heavy rain, storms, and snowmelt. Steep slopes and unstable soil make certain locations vulnerable to landslides in wet weather or during earthquakes.

</doc>
<doc id="60540" url="https://en.wikipedia.org/wiki?curid=60540" title="Leslie Groves">
Leslie Groves

Lieutenant General Leslie Richard Groves Jr. (17 August 1896 – 13 July 1970) was a United States Army Corps of Engineers officer who oversaw the construction of the Pentagon and directed the Manhattan Project, a top secret research project that developed the atomic bomb during World War II. As the son of a United States Army chaplain, Groves lived at a number of Army posts during his childhood. He graduated fourth in his class at the United States Military Academy at West Point in 1918 and was commissioned into the US Army Corps of Engineers. In 1929, he went to Nicaragua as part of an expedition whose purpose was to conduct a survey for the Inter-Oceanic Nicaragua Canal. Following the 1931 Nicaragua earthquake, Groves took over responsibility for Managua's water supply system, for which he was awarded the Nicaraguan Presidential Medal of Merit. He attended the Command and General Staff School at Fort Leavenworth, Kansas, in 1935 and 1936, and the Army War College in 1938 and 1939, after which he was posted to the War Department General Staff.
In 1940 Groves, who "had a reputation as a doer, a driver, and a stickler for duty", became special assistant for construction to the Quartermaster General, tasked with inspecting construction sites and checking on their progress. In August 1941, he was given responsibility for the gigantic office complex to house the War Department's 40,000 staff which would ultimately become the Pentagon. In September 1942, Groves took charge of the Manhattan Project. He was involved in most aspects of the atomic bomb's development. He participated in the selection of sites for research and production at Oak Ridge, Tennessee; Los Alamos, New Mexico; and Hanford, Washington. He directed the enormous construction effort, made critical decisions on the various methods of isotope separation, acquired raw materials, directed the collection of military intelligence on the German nuclear energy project and helped select the cities in Japan that were chosen as targets. Groves wrapped the Manhattan Project in security but failed to prevent the Union of Soviet Socialist Republics from conducting a successful espionage program that stole some of its most important secrets.
After the war, Groves remained in charge of the Manhattan Project until responsibility for nuclear weapons production was handed over to the United States Atomic Energy Commission in 1947. He then headed the Armed Forces Special Weapons Project, which had been created to control the military aspects of nuclear weapons. Groves realized that in the rapidly shrinking postwar military he would not be given any assignment approaching in importance the one he had held in the Manhattan Project, and he decided to leave the Army in 1948. He was promoted to lieutenant general just before his retirement on 29 February 1948 in recognition of his leadership of the bomb program. By a special Act of Congress, his date of rank was backdated to 16 July 1945, the date of the Trinity nuclear test. Groves went on to become a vice-president at Sperry Rand.
Early life.
Leslie Richard Groves Jr. was born in Albany, New York, on 17 August 1896, the third son of four children of a pastor, Leslie Richard Groves Sr., and his wife Gwen née Griffith. A descendant of French Huguenots who came to America in the 17th century, Leslie Groves Sr. resigned as pastor of the Sixth Presbyterian church in Albany in December 1896 to become a United States Army chaplain. He was posted to the 14th Infantry at Vancouver Barracks in Washington in 1897. Following the outbreak of the Spanish–American War in 1898, Chaplain Groves was sent to Cuba with the 8th Infantry. On returning to Vancouver Barracks, he was ordered to rejoin the 14th Infantry in the Philippines; service in the Philippine–American War and the Boxer Rebellion followed. The 14th Infantry returned to the United States in 1901 and moved to Fort Snelling, Minnesota. The family relocated to there from Vancouver, then moved to Fort Hancock, New Jersey, the next year, and returned to Vancouver in 1905. Chaplain Groves was hospitalized with tuberculosis at Fort Bayard in 1905. He decided to settle in southern California and bought a house in Altadena. His next posting was to Fort Apache, Arizona. The family spent their summers there and returned to Altadena where the children attended school.
In 1911, Chaplain Groves was ordered to return to the 14th Infantry, which was now stationed at Fort William Henry Harrison, Montana. Here young Dick Groves met Grace (Boo) Wilson, the daughter of Colonel Richard Hulbert Wilson, a career Army officer who had served with Chaplain Groves with the 8th Infantry in Cuba. In 1913, the 14th Infantry moved once more, this time to Fort Lawton, Washington. Dick Groves entered Queen Anne High School in nearby Seattle in 1913. In September of that year, he commenced his final year of high school, and also enrolled at the University of Washington. He attempted to secure an appointment to the United States Military Academy at West Point in 1914, earning a nomination from the president, which allowed him to compete for a vacancy, but did not score a sufficiently high enough mark on the examination. Charles W. Bell from California's 9th congressional district accepted Groves as an alternate for one of his appointments, but the principal nominee accepted. Instead, Groves enrolled at Massachusetts Institute of Technology. In 1916, Groves took the examinations for admission to West Point again and this time he was accepted. "Entering West Point fulfilled my greatest ambition. I had been brought up in the Army, and in the main had lived on Army posts all my life," Groves said after the fact.
Groves' class entered West Point on 15 June 1916, but the United States declaration of war on Germany in April 1917 led to the course being shortened to what was known as the War Emergency Course (WEC), which graduated early on 1 November 1918. Groves came fourth in his class, and was commissioned as a second lieutenant into the United States Army Corps of Engineers. The Corps of Engineers was the usual appointment for the highest-ranking cadets in a class.
Between the wars.
After the traditional month's leave following graduation from West Point, Groves reported to Camp A. A. Humphreys, Virginia, in December 1918, where he was promoted to first lieutenant on 1 May 1919. He was sent to France in June on an educational tour of the European battlefields of World War I. After returning from Europe, Groves became a student officer at the Engineer School at Camp Humphreys in September 1919. On graduation he was posted to the 7th Engineers at Fort Benning, Georgia, as a company commander. He returned to Camp Humphreys in February 1921 for the Engineer Basic Officers' Course. On graduation in August 1921, he was posted to the 4th Engineers, stationed at Camp Lewis, Washington. He was then posted to Fort Worden in command of a survey detachment. This was close to Seattle, so he was able to pursue his courtship of Grace Wilson (1897–1986), who had become a kindergarten teacher. They were married in St. Clement's Episcopal Church in Seattle on 10 February 1922. Their marriage produced two children: a son, Richard Hulbert, born in 1923, and a daughter, Gwen, born in 1928.
In November 1922, Groves received his first overseas posting, as a company commander with the 3rd Engineers at the Schofield Barracks in Hawaii. He earned a commendation for his work there, constructing a trail from Kahuku to Pupukea. In November 1925 he was posted to Galveston, Texas, as an assistant to the District Engineer, Major Julian Schley. Groves' duties included opening the channel at Port Isabel and supervising dredging operations in Galveston Bay. In 1927 he became commander of Company D, 1st Engineers, at Fort DuPont, Delaware. During the he was sent to Fort Ethan Allen, Vermont, to assist with a detachment of the 1st Engineers. After a pontoon bridge they constructed was swamped and swept away by the flood waters, Groves was accused of negligence. A month later Groves and several of his men were seriously injured, one fatally, when a block of TNT prematurely detonated. Groves' superior wrote a critical report on him, but the Chief of Engineers, Major General Edgar Jadwin, interceded, attributing blame to Groves' superiors instead. Groves was returned to Fort DuPont.
In 1929, Groves departed for Nicaragua in charge of a company of the 1st Engineers as part of an expedition whose purpose was to conduct a survey for the Inter-Oceanic Nicaragua Canal. Following the 1931 Nicaragua earthquake, Groves took over responsibility for Managua's water supply system, for which he was awarded the Nicaraguan Presidential Medal of Merit. Groves was promoted to captain on 20 October 1934. He attended the Command and General Staff School at Fort Leavenworth, Kansas, in 1935 and 1936, after which he was posted to Kansas City, Missouri, as assistant to the commander of the Missouri River Division. In 1938 and 1939 he attended the Army War College. On 1 July 1939, he was posted to the War Department General Staff in Washington, D.C.
World War II.
Construction Division.
Groves was promoted to major on 1 July 1940. Three weeks later, he became special assistant for construction to the Quartermaster General, Major General Edmund B. Gregory. The two men had known each other a long time, as Groves' father was a close friend of Gregory's. At this point, the US Army was about to embark on a national mobilization, and it was the task of the Construction Division of the Quartermaster Corps to prepare the necessary accommodations and training facilities for the vast army that would be created. The enormous construction program had been dogged by bottlenecks, shortages, delays, spiralling costs, and poor living conditions at the construction sites. Newspapers began publishing accounts charging the Construction Division with incompetence, ineptitude, and inefficiency. Groves, who "had a reputation as a doer, a driver, and a stickler for duty", was one of a number of engineer officers brought in to turn the project around. He was tasked with inspecting construction sites and checking on their progress.
On 12 November 1940, Gregory asked Groves to take over command of the Fixed Fee Branch of the Construction Division as soon as his promotion to colonel came through. Groves assumed his new rank and duties on 14 November 1940. Groves later recalled:
Groves instituted a series of reforms. He installed phone lines for the Supervising Construction Quartermasters, demanded weekly reports on progress, ordered that reimbursement vouchers be processed within a week, and sent expediters to sites reporting shortages. He ordered his contractors to hire whatever special equipment they needed and to pay premium prices if necessary to guarantee quick delivery. Instead of allowing construction of camps to proceed in whatever order the contractors saw fit, Groves laid down priorities for completion of camp facilities, so that the troops could begin moving in even while construction was still under way. By mid-December, the worst of the crisis was over. Over half a million men had been mobilized and essential accommodations and facilities for two million men were 95 per cent complete. Between 1 July 1940 and 10 December 1941, the Construction Division let contracts worth $1,676,293,000 ($ with inflation), of which $1,347,991,000 ($ with inflation), or about 80 per cent, were fixed-fee contracts.
On 19 August 1941, Groves was summoned to a meeting with the head of the Construction Division, Brigadier General Brehon B. Somervell. In attendance were Captain Clarence Renshaw, one of Groves' assistants; Major Hugh J. Casey, the chief of the Construction Division's Design and Engineering Section; and George Bergstrom, a former president of the American Institute of Architects. Casey and Bergstrom had designed an enormous office complex to house the War Department's 40,000 staff together in one building, a five-story, five-sided structure, which would ultimately become the Pentagon. The Pentagon had a total square footage of —twice that of the Empire State Building—making it the largest office building in the world. The estimated cost was $35 million ($ with inflation), and Somervell wanted of floor space available by 1 March 1942. Bergstrom became the architect-engineer with Renshaw in charge of construction, reporting directly to Groves. At its peak the project employed 13,000 persons. By the end of April, the first occupants were moving in and of space was ready by the end of May. In the end, the project cost some $63 million ($ with inflation).
Groves steadily overcame one crisis after another, dealing with strikes, shortages, competing priorities and engineers who were not up to their tasks. He worked six days a week in his office in Washington, D.C. During the week he would determine which project was in the greatest need of personal attention and pay it a visit on Sunday. Groves later recalled that he was "hoping to get to a war theater so I could find a little peace."
Manhattan Project.
The Manhattan Engineer District (MED) was formally established by the Chief of Engineers, Major General Eugene Reybold on 16 August 1942. The name was chosen by Groves and MED's district engineer, Colonel James C. Marshall. Like other engineer districts, it was named after the city where its headquarters was located, at 270 Broadway. Unlike the others, however, it had no geographic boundaries, only a mission: to develop an atomic bomb. Moreover, Marshall had the authority of a division engineer head and reported directly to Reybold. Although Reybold was satisfied with the progress being made, Dr. Vannevar Bush was less so. He felt that aggressive leadership was required, and suggested the appointment of a prestigious officer as overall project director. Somervell, now Chief of Army Service Forces, recommended Groves. Somervell met Groves outside the hearing room where Groves had been testifying before a United States Congress committee on military housing and informed him that "The Secretary of War has selected you for a very important assignment, and the President has approved the selection ... If you do the job right, it will win the war." Groves could not hide his disappointment at not receiving a combat assignment: "Oh, that thing," he replied.
Groves met with Major General Wilhelm D. Styer in his office at the Pentagon to discuss the details. They agreed that in order to avoid suspicion, Groves would continue to supervise the Pentagon project. He would be promoted to brigadier general, as it was felt that the title "general" would hold more sway with the academic scientists working on the Manhattan Project. Groves therefore waited until his promotion came through on 23 September 1942 before assuming his new command. His orders placed him directly under Somervell rather than Reybold, with Marshall now answerable to Groves. Groves was given authority to sign contracts for the project from September 1, 1942.
Under Secretary of War Robert P. Patterson (retrospectively) delegated his authority from the President under the War Powers Act of 1941 in a memorandum to Groves dated April 17, 1944. Groves delegated the authority to Nichols, except that contracts of $5 million or more required his authority. The written authority was only given in 1944 when Nichols was about to sign a contract with Du Pont, and it was found that Nichols original authority to sign project contracts from Colonel Marshall was based on a verbal authority from Styer, and Nichols only had the low delegated authority of a divisional engineer.
Groves soon decided to establish his project headquarters on the fifth floor of the New War Department Building (now known as the Harry S Truman Building) in Washington, D.C., where Marshall had maintained a liaison office. In August 1943, the MED headquarters (and Nichols, who was in charge of the production facilities at Hanford and Oak Ridge) moved to Oak Ridge, Tennessee, but the name of the district did not change.
Construction accounted for roughly 90 percent of the Manhattan Project's total cost. The day after Groves took over, he and Marshall took a train to Tennessee to inspect the site that Marshall had chosen for the proposed production plant at Oak Ridge. Groves was suitably impressed with the site, and steps were taken to condemn the land. Protests, legal appeals, and congressional inquiries were to no avail. By mid-November US Marshals were tacking notices to vacate on farmhouse doors, and construction contractors were moving in.
Meanwhile, Groves had met with J. Robert Oppenheimer, the University of California, Berkeley physicist, and discussed the creation of a laboratory where the bomb could be designed and tested. Groves was impressed with the breadth of Oppenheimer's knowledge. A long conversation on a train in October 1942 convinced Groves and his deputy Kenneth Nichols that Oppenheimer thoroughly understood the issues involved in setting up a laboratory in a remote area. These were features that Groves found lacking in other scientists, and he knew that broad knowledge would be vital in an interdisciplinary project that would involve not just physics, but chemistry, metallurgy, ordnance and engineering.
In October 1942 Groves and Oppenheimer inspected sites in New Mexico, where they selected a suitable location for the laboratory at Los Alamos, New Mexico. Unlike Oak Ridge, the ranch school at Los Alamos, along with of surrounding forest and grazing land, was soon acquired. Groves also detected in Oppenheimer something that many others did not, an "overweening ambition" which Groves reckoned would supply the drive necessary to push the project to a successful conclusion. Groves became convinced that Oppenheimer was the best and only man to run the laboratory.
Few agreed with him in 1942. Oppenheimer had little administrative experience and, unlike other potential candidates, no Nobel Prize. There was also concern about whether Oppenheimer was a security risk, as many of his associates were communists, including his brother Frank Oppenheimer, his wife Kitty and his girlfriend Jean Tatlock. Oppenheimer's Communist Party connections soon came to light, but Groves personally waived the security requirements and issued Oppenheimer a clearance on 20 July 1943. Groves' faith in Oppenheimer was ultimately justified. Oppenheimer's inspirational leadership fostered practical approaches to designing and building bombs. Asked years later why Groves chose him, Oppenheimer replied that the general "had a fatal weakness for good men." Isidor Rabi considered the appointment "a real stroke of genius on the part of General Groves, who was not generally considered to be a genius ..."
Groves made critical decisions on prioritizing the various methods of isotope separation and acquiring raw materials needed by the scientists and engineers. By the time he assumed command of the project, it was evident that the AA-3 priority rating that Marshall had obtained was insufficient. The top ratings were AA-1 through AA-4 in descending order, although there was also a special AAA rating reserved for emergencies. Ratings AA-1 and AA-2 were for essential weapons and equipment, so Colonel Lucius D. Clay, the deputy chief of staff at Services and Supply for requirements and resources, felt that the highest rating he could assign was AA-3, although he was willing to provide an AAA rating on request for critical materials to remove bottlenecks. Groves went to Donald M. Nelson, the chairman of the War Production Board and, after threatening to take the matter to the President, obtained a AAA priority for the Manhattan project. It was agreed that the AA-3 priority would still be used where possible.
The Combined Development Trust was established by the governments of the United Kingdom, United States and Canada in June 1944, with Groves as its chairman, to procure uranium and thorium ores on international markets. In 1944, the trust purchased of uranium oxide ore from companies operating mines in the Belgian Congo. In order to avoid briefing US Secretary of the Treasury Henry Morgenthau Jr. on the project, a special account not subject to the usual auditing and controls was used to hold Trust monies. Between 1944 and the time he resigned from the Trust in 1947, Groves deposited a total of $37.5 million into the Trust's account.
In 1943, the Manhattan District became responsible for collecting military intelligence on Axis atomic research. Groves created Operation Alsos, special intelligence teams that would follow in the wake of the advancing armies, rounding up enemy scientists and collecting what technical information and technology they could. Alsos teams ultimately operated in Italy, France and Germany. The security system resembled that of other engineer districts. The Manhattan District organized its own counterintelligence which gradually grew in size and scope, but strict security measures failed to prevent the Soviets from conducting a successful espionage program that stole some of its most important secrets.
Groves met with the Chief of United States Army Air Forces, General Henry H. Arnold, in March 1944 to discuss the delivery of the finished bombs to their targets. Groves was hoping that the Boeing B-29 Superfortress would be able to carry the finished bombs. The 509th Composite Group was duly activated on 17 December 1944 at Wendover Army Air Field, Utah, under the command of Colonel Paul W. Tibbets. A joint Manhattan District – USAAF targeting committee was established to determine which cities in Japan should be targets; it recommended Kokura, Hiroshima, Niigata and Kyoto. At this point, Secretary of War Henry L. Stimson intervened, announcing that he would be making the targeting decision, and that he would not authorize the bombing of Kyoto. Groves attempted to get him to change his mind several times and Stimson refused every time. Kyoto had been the capital of Japan for centuries, and was of great cultural and religious significance. In the end, Groves asked Arnold to remove Kyoto not just from the list of nuclear targets, but from targets for conventional bombing as well. Nagasaki was substituted for Kyoto as a target.
Groves was promoted to temporary major general in March 1944. After the atomic bombing of Hiroshima and Nagasaki became public knowledge, he was awarded the Distinguished Service Medal. His citation read:
Groves had previously been nominated for the Distinguished Service Medal for his work on the Pentagon, but to avoid drawing attention to the Manhattan Project, it had not been awarded at the time. After the war, the Decorations Board decided to change it to a Legion of Merit. In recognition of his work on the project, the Belgian government made him a Commander of the Order of the Crown and the British government made him an honorary Companion of the Order of the Bath.
After the war.
Responsibility for nuclear power and nuclear weapons was transferred from the Manhattan District to the United States Atomic Energy Commission on 1 January 1947. On 29 January 1947, Secretary of War Robert P. Patterson and Secretary of the Navy James V. Forrestal issued a joint directive creating the Armed Forces Special Weapons Project (AFSWP) to control the military aspects of nuclear weapons. Groves was appointed its chief on 28 February 1947. In April, AFSWP moved from the New War Department Building to the fifth floor of the Pentagon. Groves had already made a start on the new mission by creating Sandia Base in 1946.
The Chief of Staff of the United States Army, General of the Army Dwight D. Eisenhower, met with Groves on 30 January 1948 to evaluate his performance. Eisenhower recounted a long list of complaints about Groves pertaining to his rudeness, arrogance, insensitivity, contempt for the rules and maneuvering for promotion out of turn. Eisenhower made it clear that Groves would never become Chief of Engineers. Groves realized that in the rapidly shrinking postwar military he would not be given any assignment approaching in importance the one he had held in the Manhattan Project, as such posts would go to combat commanders returning from overseas, and he decided to leave the Army. He was promoted to lieutenant general just before his retirement on 29 February 1948 in recognition of his leadership of the Manhattan Project. By special Act of Congress his date of rank was backdated to 16 July 1945, the date of the Trinity nuclear test.
Later life.
Groves went on to become a vice president at Sperry Rand, an equipment and electronics firm, and moved to Darien, Connecticut, in 1948. He retired from Sperry Rand in 1961. He also served as president of the West Point alumni organization, the "Association of Graduates". He presented General of the Army Douglas MacArthur the Sylvanus Thayer Award in 1962, which was the occasion of MacArthur's famous speech to the United States Military Academy Corps of Cadets. In retirement, Groves wrote an account of the Manhattan Project entitled "Now It Can Be Told", originally published in 1962. In 1964, he moved back to Washington, D.C.
Groves suffered a heart attack caused by chronic calcification of the aortic valve on 13 July 1970. He was rushed to Walter Reed Army Medical Center, where he died that night. A funeral service was held in the chapel at Fort Myer, Virginia, after which Groves was interred in Arlington National Cemetery next to his brother Allen, who had died of pneumonia in 1916. Groves is memorialized as the namesake of Leslie Groves Park along the Columbia River, near the Hanford Site in Richland.

</doc>
<doc id="60541" url="https://en.wikipedia.org/wiki?curid=60541" title="Hannelore Kohl">
Hannelore Kohl

Hannelore Kohl (7 March 1933 in Berlin – 5 July 2001) was the first wife of former German Chancellor Helmut Kohl. She met him for the first time at a prom in Ludwigshafen, Germany, when she was 15 years old.
She was born in Berlin and was christened Johanna Klara Eleonore Renner. Her father was Wilhelm Renner, who headed the employment office at Hugo Schneider AG that developed the successful one-man anti-tank weapon, the Panzerfaust. Later, she chose the portmanteau "Hannelore" to be used as her first name.
In the days following Germany's defeat in World War II, at the age of 12, Hannelore Kohl was raped by Red Army soldiers and subsequently “thrown out of a window like a sack of potatoes by the Russians.” In addition to the obvious psychological impact, the attacks left her with a fractured vertebra and back pain for the rest of her life. In order to help others with similar injuries, in 1983 she founded the Kuratorium ZNS, a foundation that helps those with trauma-induced injuries to the central nervous system, and became its president.
On 5 July 2001, Hannelore was found dead at age 68 in her Ludwigshafen home. She had apparently committed suicide with an overdose of sleeping pills, after years of suffering from what she had claimed to be a very rare and painful photo allergy induced by an earlier penicillin treatment that had forced her to avoid practically all sunlight for years. In 2005, the Kuratorium ZNS was renamed ZNS - Hannelore Kohl Stiftung in her honor.
However, journalist Andrew Gimson, writing in "The Spectator", cast doubt upon the official version of events. Similar questions were also raised by the German newsmagazine "Stern" and the BBC.
Kohl's collection of German-style cooking recipes, "Kulinarische Reise durch Deutsche Länder" ("Culinary Journey through German Regions"), was published in 1996.

</doc>
<doc id="60542" url="https://en.wikipedia.org/wiki?curid=60542" title="Adams State University">
Adams State University

Adams State University (ASU) is a small, state-supported liberal arts university in Alamosa, Colorado, U.S., in the San Luis Valley, home to the Great Sand Dunes National Park and Preserve. ASU offers undergraduate programs in physical and social sciences, in fine arts, business and nursing, and specializes in educator curricula in several disciplines. ASU also offers graduate degrees in, among others, history, art, business (MBA), and educator programs, including counselor education. There is also a postgraduate (PhD) program in counselor education. The University has an active athletic program, both in participatory sports and in athletics educator training; the Adams State Grizzlies intramural teams compete under the auspices of the Rocky Mountain Athletic Conference.
History.
ASU was founded in 1921 as a teacher's college. Billy Adams, a Colorado legislator who would later become a three-term governor of Colorado, worked for three decades before obtaining the authorization to found Adams State Normal School in 1921, to provide higher education opportunities for teachers from remote and rural areas of Colorado, such as the San Luis Valley, and see them work in those same areas.
In 1926, Harriet Dalzell Hester became the university's first graduate. She became the school's first librarian and an Alamosa County school superintendent. 
On May 22, 2012, Colorado Governor John Hickenlooper signed a bill changing the name from Adams State College to Adams State University. The change became official on August 7, 2012.
Campus.
ASU is located in the heart of the San Luis Valley. All of the university's academic and residential buildings are located on its contiguous 90-acre (36.4-hectare) campus. Alamosa has a population of about 15,000.
Academic buildings.
The main administration building and oldest building on campus is Richardson Hall, named after the school's first president, Dr. Ira Richardson. The home of the math and science curriculum, Porter Hall, is named for alumnus William A. Porter, the creator of E-Trade and a major benefactor of the school. McDaniel Hall, named for donor and emeritus faculty member Dr. John McDaniel, is the main venue for English, psychology, history, sociology, and teacher education classes.
Campus edifices for the performing arts include the ASU Theater (erected in 2001), the Music Building (which underwent major renovations in 2011) and the Leon Memorial Concert Hall.
Athletic facilities.
There are two gyms and an indoor pool. The Rex Activity Center for student recreation includes weights, exercise bikes and a basketball court, and Plachy Hall includes the gym and indoor pool and field house as part of the Athletics Department.
The Rex Stadium has undergone major renovation including the addition of the Residence at the Rex. The new complex includes suites for game viewing. The new residence hall provides one of the most impressive views, with a view of Mount Blanca (one of the 14ers of Colorado) to the east and overlooking the track and football field to the west. A new $750,000 video-tron screen displays action and replays at one end of the field.
Residences.
There are currently six on-campus apartment complexes (Houtchens, McCurry, Moffat, Petteys, Savage and Residence at the Rex) that include private bedrooms for two to three students, a kitchen/living room and private bath, in addition to three traditional dormitory halls (Conour, Coronado and Girault). Most entering freshmen are housed in Coronado and Girault Halls. The main cafeteria, La Mesa Dining Hall, in the Student Union Building is newly renovated.
Athletics.
The school's sports teams are now called the Grizzlies and were formerly known as the Indians. They participate in the NCAA's Division II, and in the Rocky Mountain Athletic Conference. Athletic groups include:
Presidents.
Presidents have been:

</doc>
<doc id="60543" url="https://en.wikipedia.org/wiki?curid=60543" title="Pope Theodore I">
Pope Theodore I

Pope Theodore I (; died 14 May 649) was Pope from 24 November 642 to his death in 649.
Life.
According to the "Liber Pontificalis", he was a Greek inhabitant of Jerusalem whose father Theodorus had been a bishop in the city. He was among the many Syrian clergy who fled to Rome following the Muslim conquest of the Levant.
He was made a cardinal deacon (possibly around 640) and a full cardinal by Pope John IV.
His election was supported by the exarch and he was installed on 24 November 642, succeeding John IV. 
The main focus of his pontificate was the continued struggle against the heretical Monothelites. He refused to recognize Paul as the Patriarch of Constantinople, because his predecessor, Pyrrhus, had not been correctly replaced. He pressed Emperor Constans II to withdraw the "Ecthesis" of Heraclius. While his efforts made little impression on Constantinople, it increased the opposition to the heresy in the West; Pyrrhus even briefly recanted his heresy (645), but was excommunicated in 648. Paul was excommunicated in 649. In response, Paul destroyed the Roman altar in the palace of Placidia and exiled or imprisoned the papal nuncios. But he also sought to end the issue with the Emperor by promulgating the Type of Constans, ordering that the "Ecthesis" be taken down and seeking to end discussion on the doctrine.
Theodore planned the Lateran Council of 649 to condemn the "Ecthesis", but died before he could convene it. His successor, Pope Martin I, did so instead. Theodore was buried in St. Peter's Basilica. 
His feast day in the Orthodox Church is on 18 May.

</doc>
<doc id="60545" url="https://en.wikipedia.org/wiki?curid=60545" title="NewtonScript">
NewtonScript

NewtonScript is a prototype-based programming language created to write programs for the Newton platform. It is heavily influenced by the Self programming language, but modified to be more suited to needs of mobile and embedded devices.
History.
Traditional computers, at least in the desktop role, have two modes; "on" and "off". When moving from one mode to the other the state of the machine is lost from memory, and requires a sometimes lengthy "boot" process to return the machine to the "on" state. This does not suffice for a PDA type device where the user expects the machine to be available almost instantly for taking down quick notes. Yet, with the technology available at the time, leaving a PDA "on" for any length of time was impractical, as this would drain the battery too much to make it useful for carrying around.
In the Newton platform, the system had two states that were more like "on" and "sleeping". When moving to the sleeping state the memory was not lost and instead the system simply stopped working on the contents of memory, which allowed for many of the chips inside to be turned off. This greatly extended battery life, yet still allowed the machine to turn back on almost instantly.
With the main memory always being kept alive, the system becomes much more amenable to use as a persistent object store. Many object-oriented systems, like Smalltalk, are based on a continually running object world (known as an "image" or, when saved as a disk file, a "snapshot"), so using the Newton platform with an object-oriented system seemed quite natural.
The developers then began looking for languages to use on the system. The Newton platform was originally going to be programmed in the new Dylan programming language, but a lengthy series of delays eventually led to it being abandoned. The team had looked at Self and were very interested in it, but at the time Self was not yet ready for real-world use.
The result was a modified version of Self known as NewtonScript. Written primarily by Walter Smith, the language was a part of the "Newton Toolkit", introduced along with the first Newton device (the Apple MessagePad) on August 3, 1993.
One of the advantages of NewtonScript's prototype based inheritance was reduced memory usage, a key consideration in the 128 KB Newton. The prototype of a GUI object could actually be stored in ROM, so there was no need to copy default data or functions into working memory. For example, a developer might create a new button instance. If the button uses the default font, accessing its font "slot" (i.e., property or member variable) will return a value that is actually stored in ROM; the button instance in RAM does not have a value in its own font slot, so the prototype inheritance chain is followed until a value is found. If the developer then changes the button's font, setting its font slot to a new value will override the prototype; this override value is stored in RAM. NewtonScript's "differential inheritance" therefore made efficient use of the Newton's expensive flash RAM by storing the bulk of the default data and code in the PDA's cheaper and much larger ROM.
NewtonScript vs. Self.
Changes were primarily aimed at three perceived problems with Self.
One is that the typical Self snapshot requires 32 MB of RAM to run in, whereas the Newton platform was designed to use only 128 KB for the operating system. This required some serious paring down of the engine to make it fit and still have room for applications.
Another issue was performance. Since the language would be used for the entire system, as opposed to just running on an existing operating system, it needed to run as fast as possible.
Finally, the inheritance system in the normal Self engine had a single parent object, whereas GUIs typically have two — one for the objects and another for the GUI layout that is typically handled via the addition of a slot in some sort of GUI-hierarchy object (like View).
The syntax was also modified to allow a more text-based programming style, as opposed to Self's widespread use of a GUI environment for programming. This allowed Newton programs to be developed on a computer running the Toolkit, where the programs would be compiled and then downloaded to a Newton device for running.
However this also led to what is generally considered the most serious flaw of the system. Since the code was written on one platform and run on another, it was practically impossible to debug. Better debugging code in the Newton engine would have helped offset this problem to some degree, but the limited memory made this difficult. Instead the developer would get a vague indication along with an error code, without any ability to match it to lines in the original code. However, software packages exist to allow Newton programs to be written on the Newton device itself.
Legacy.
NewtonScript is also one of the conceptual ancestors (together with Smalltalk, Self, Act1, Lisp and Lua) of a recently created general-purpose programming language called Io. NewtonScript employs an inheritance model called differential inheritance where only the differences with its parent prototype are stored in a list of properties (known as slots in Io). This is a very useful feature for resource-constrained systems. The Io language implements the same differential inheritance model.
The prototype-based object model of Self and NewtonScript was used in JavaScript, the most popular and visible language to use the concept so far.

</doc>
<doc id="60546" url="https://en.wikipedia.org/wiki?curid=60546" title="Unique factorization domain">
Unique factorization domain

In mathematics, a unique factorization domain (UFD) is a commutative ring, which is an integral domain, and in which every non-zero non-unit element can be written as a product of prime elements (or irreducible elements), uniquely up to order and units, analogous to the fundamental theorem of arithmetic for the integers. UFDs are sometimes called factorial rings, following the terminology of Bourbaki.
Unique factorization domains appear in the following chain of class inclusions:
Definition.
Formally, a unique factorization domain is defined to be an integral domain "R" in which every non-zero element "x" of "R" can be written as a product (an empty product if "x" is a unit) of irreducible elements "p"i of "R" and a unit "u":
and this representation is unique in the following sense:
If "q"1...,"q""m" are irreducible elements of "R" and "w" is a unit such that
then "m" = "n", and there exists a bijective map φ : {1...,"n"} → {1...,"m"} such that "p""i" is associated to "q"φ("i") for "i" ∈ {1, ..., "n"}.
The uniqueness part is usually hard to verify, which is why the following equivalent definition is useful:
Examples.
Most rings familiar from elementary mathematics are UFDs:
Non-example:
Properties.
Some concepts defined for integers can be generalized to UFDs:
Equivalent conditions for a ring to be a UFD.
A Noetherian integral domain is a UFD if and only if every height 1 prime ideal is principal (a proof is given below). Also, a Dedekind domain is a UFD if and only if its ideal class group is trivial. In this case it is in fact a principal ideal domain.
There are also equivalent conditions for non-noetherian integral domains. Let "A" be an integral domain. Then the following are equivalent.
In practice, (2) and (3) are the most useful conditions to check. For example, it follows immediately from (2) that a PID is a UFD, since, in a PID, every prime ideal is generated by a prime element.
For another example, consider a Noetherian integral domain in which every height one prime ideal is principal. Since every prime ideal has finite height, it contains height one prime ideal (induction on height), which is principal. By (2), the ring is a UFD.

</doc>
<doc id="60547" url="https://en.wikipedia.org/wiki?curid=60547" title="UFD">
UFD

UFD may refer to:

</doc>
<doc id="60548" url="https://en.wikipedia.org/wiki?curid=60548" title="Planetarium">
Planetarium

A planetarium (plural planetaria or "planetariums") is a theatre built primarily for presenting educational and entertaining shows about astronomy and the night sky, or for training in celestial navigation.
A dominant feature of most planetaria is the large dome-shaped projection screen onto which scenes of stars, planets and other celestial objects can be made to appear and move realistically to simulate the complex 'motions of the heavens'. The celestial scenes can be created using a wide variety of technologies, for example precision-engineered 'star balls' that combine optical and electro-mechanical technology, slide projector, video and fulldome projector systems, and lasers. Whatever technologies are used, the objective is normally to link them together to provide an accurate relative motion of the sky. Typical systems can be set to display the sky at any point in time, past or present, and often to show the night sky as it would appear from any point of latitude on Earth.
Planetaria range in size from the Hayden Planetarium's 21-meter dome seating 423 people, to three-meter inflatable portable domes where children sit on the floor. Such portable planetaria serve education programs outside of the permanent installations of museums and science centers.
The term "planetarium" is sometimes used generically to describe other devices which illustrate the solar system, such as a computer simulation or an orrery. "Planetarium software" refers to a software application that renders a three-dimensional image of the sky onto a two-dimensional computer screen. The term "planetarian" is used to describe a member of the professional staff of a planetarium.
History.
Early.
Archimedes is attributed with possessing a primitive planetarium device that could predict the movements of the Sun and the Moon and the planets. The discovery of the Antikythera mechanism proved that such devices already existed during antiquity. Campanus of Novara (1220–1296) described a planetary equatorium in his "Theorica Planetarum", and included instructions on how to build one. The Globe of Gottorf built around 1650 had constellations painted on the inside. These devices would today usually be referred to as orreries (named for the Earl of Orrery, an Irish peer: an 18th-century Earl of Orrery had one built). In fact, many planetaria today have what are called projection orreries, which project onto the dome a Sun with planets (usually limited to Mercury up to Saturn) going around it in something close to their correct relative periods.
The small size of typical 18th century orreries limited their impact, and towards the end of that century a number of educators attempted some larger scale simulations of the heavens. The efforts of Adam Walker (1730–1821) and his sons are noteworthy in their attempts to fuse theatrical illusions with educational aspirations. Walker's Eidouranion was the heart of his public lectures or theatrical presentations. Walker's son describes this "Elaborate Machine" as "twenty feet high, and twenty-seven in diameter: it stands vertically before the spectators, and its globes are so large, that they are distinctly seen in the most distant parts of the Theatre. Every Planet and Satellite seems suspended in space, without any support; performing their annual and diurnal revolutions without any apparent cause". Other lecturers promoted their own devices: R E Lloyd advertised his Dioastrodoxon, or Grand Transparent Orrery, and by 1825 William Kitchener was offering his Ouranologia, which was in diameter. These devices most probably sacrificed astronomical accuracy for crowd-pleasing spectacle and sensational and awe-provoking imagery.
The oldest, still working planetarium can be found in the Dutch town Franeker. It was built by Eise Eisinga (1744–1828) in the living room of his house. It took Eisinga seven years to build his planetarium, which was completed in 1781.
In 1905 Oskar von Miller (1855–1934) of the Deutsches Museum in Munich commissioned updated versions of a geared orrery and planetarium from M Sendtner, and later worked with Franz Meyer, chief engineer at the Carl Zeiss optical works in Jena, on the largest mechanical planetarium ever constructed, capable of displaying both heliocentric and geocentric motion. This was displayed at the Deutsches Museum in 1924, construction work having been interrupted by the war. The planets travelled along overhead rails, powered by electric motors: the orbit of Saturn was 11.25 m in diameter. 180 stars were projected onto the wall by electric bulbs.
While this was being constructed, von Miller was also working at the Zeiss factory with German astronomer Max Wolf, director of the Landessternwarte Heidelberg-Königstuhl observatory of the University of Heidelberg, on a new and novel design, inspired by Wallace W. Atwood's work at the Chicago Academy of Sciences and by the ideas of Walther Bauersfeld and Rudolf Straubel at Zeiss. The result was a planetarium design which would generate all the necessary movements of the stars and planets inside the optical projector, and would be mounted centrally in a room, projecting images onto the white surface of a hemisphere. In August 1923, the first (Model I) Zeiss planetarium projected images of the night sky onto the white plaster lining of a 16 m hemispherical concrete dome, erected on the roof of the Zeiss works. The first official public showing was at the Deutsches Museum in Munich on October 21, 1923.
After World War II.
When Germany was divided into East and West Germany after the war, the Zeiss firm was also split. Part remained in its traditional headquarters at Jena, in East Germany, and part migrated to West Germany. The designer of the first planetaria for Zeiss, Walther Bauersfeld, also migrated to West Germany with the other members of the Zeiss management team. There he remained on the Zeiss West management team until his death in 1959.
The West German firm resumed making large planetaria in 1954, and the East German firm started making small planetaria a few years later. Meanwhile, the lack of planetarium manufacturers had led to several attempts at construction of unique models, such as one built by the California Academy of Sciences in Golden Gate Park, San Francisco, which operated 1952-2003. The Korkosz brothers built a large projector for the Boston Museum of Science, which was unique in being the first (and for a very long time only) planetarium to project the planet Uranus. Most planetaria ignore Uranus as being at best marginally visible to the naked eye.
A great boost to the popularity of the planetarium worldwide was provided by the Space Race of the 1950s and 60s when fears that the United States might miss out on the opportunities of the new frontier in space stimulated a massive program to install over 1,200 planetaria in U.S. high schools.
Armand Spitz recognized that there was a viable market for small inexpensive planetaria. His first model, the Spitz A, was designed to project stars from a dodecahedron, thus reducing machining expenses in creating a globe. Planets were not mechanized, but could be shifted by hand. Several models followed with various upgraded capabilities, until the A3P, which projected well over a thousand stars, had motorized motions for latitude change, daily motion, and annual motion for Sun, Moon (including phases), and planets. This model was installed in hundreds of high schools, colleges, and even small museums from 1964 to the 1980s.
Japan entered the planetarium manufacturing business in the 1960s, with Goto and Minolta both successfully marketing a number of different models. Goto was particularly successful when the Japanese Ministry of Education put one of their smallest models, the E-3 or E-5 (the numbers refer to the metric diameter of the dome) in every elementary school in Japan.
Phillip Stern, as former lecturer at New York City's Hayden Planetarium, had the idea of creating a small planetarium which could be programmed. His Apollo model was introduced in 1967 with a plastic program board, recorded lecture, and film strip. Unable to pay for this himself, Stern became the head of the planetarium division of Viewlex, a mid-size audio-visual firm on Long Island. About thirty canned programs were created for various grade levels and the public, while operators could create their own or run the planetarium live. Purchasers of the Apollo were given their choice of two canned shows, and could purchase more. A few hundred were sold, but in the late 1970s Viewlex went bankrupt for reasons unrelated to the planetarium business.
During the 1970s, the OmniMax movie system (now known as IMAX Dome) was conceived to operate on planetarium screens. More recently, some planetaria have re-branded themselves as "dome theaters", with broader offerings including wide-screen or "wraparound" films, fulldome video, and laser shows that combine music with laser-drawn patterns.
Learning Technologies Inc. in Massachusetts offered the first easily portable planetarium in 1977. Philip Sadler designed this patented system which projected stars, constellation figures from many mythologies, celestial coordinate systems, and much else, from removable cylinders (Viewlex and others followed with their own portable versions).
When Germany reunified in 1989, the two Zeiss firms did likewise, and expanded their offerings to cover many different size domes.
Computerized planetaria.
In 1983, Evans & Sutherland installed the first planetarium projector displaying computer graphics (Hansen Planetarium, Salt Lake City, Utah)—the Digistar I projector used a vector graphics system to display starfields as well as line art.
The newest generation of planetaria offer a fully digital projection system, using fulldome video technology. This gives the operator great flexibility in showing not only the modern night sky as visible from Earth, but any other image they wish (including the night sky as visible from points far distant in space and time).
A new generation of home planetaria was released in Japan by Takayuki Ohira in cooperation with Sega. Ohira is worldwide known as a mastermind for building portable planetaria used at exhibitions and events such as the Aichi World Expo in 2005. Later, the Megastar star projectors released by Takayuki Ohira were installed in several science museums around the world. Meanwhile, Sega Toys continues to produce the Homestar series intended for home use, however by projecting 10,000 stars on the ceiling makes it semi-professional.
In 2009 Microsoft Research and Go-Dome partnered on the WorldWide Telescope project. The goal of the project is to bring sub-$1000 planetaria to small groups of school children as well as provide technology for large public planetaria.
Technology.
Domes.
Planetarium domes range in size from 3 to 35 m in diameter, accommodating from 1 to 500 people. They can be permanent or portable, depending on the application. 
The realism of the viewing experience in a planetarium depends significantly on the dynamic range of the image, i.e., the contrast between dark and light. This can be a challenge in any domed projection environment, because a bright image projected on one side of the dome will tend to reflect light across to the opposite side, "lifting" the black level there and so making the whole image look less realistic. Since traditional planetarium shows consisted mainly of small points of light (i.e., stars) on a black background, this was not a significant issue, but it became an issue as digital projection systems started to fill large portions of the dome with bright objects (e.g., large images of the sun in context). For this reason, modern planetarium domes are often not painted white but rather a mid grey colour, reducing reflection to perhaps 35-50%. This increases the perceived level of contrast.
A major challenge in dome construction is to make seams as invisible as possible. Painting a dome after installation is a major task and, if done properly, the seams can be made almost to disappear.
Traditionally, planetarium domes were mounted horizontally, matching the natural horizon of the real night sky. However, because that configuration requires highly inclined chairs for comfortable viewing "straight up", increasingly domes are being built tilted from the horizontal by between 5 and 30 degrees to provide greater comfort. Tilted domes tend to create a favoured 'sweet spot' for optimum viewing, centrally about a third of the way up the dome from the lowest point. Tilted domes generally have seating arranged 'stadium-style' in straight, tiered rows; horizontal domes usually have seats in circular rows, arranged in concentric (facing center) or epicentric (facing front) arrays.
Planetaria occasionally include controls such as buttons or joysticks in the arm-rests of seats to allow audience feedback that influences the show in real time.
Often around the edge of the dome (the 'cove') are:
Traditionally, planetaria needed many incandescent lamps around the cove of the dome to help audience entry and exit, to simulate sunrise and sunset, and to provide working light for dome cleaning. More recently, solid-state LED lighting has become available that significantly decreases power consumption and reduces the maintenance requirement as lamps no longer have to be changed on a regular basis.
The world's largest mechanical planetarium is located in Monico, Wisconsin. The "Kovac Planetarium". It is 22 feet in diameter and weighs two tons. The globe is made of wood and is driven with a variable speed motor controller. This is the largest mechanical planetarium in the world, larger than the "Atwood Globe" in Chicago (15 feet in diameter) and one third the size of the Hayden.
Some new planetariums now feature a glass floor, which allows spectators to stand near the center of a sphere surrounded by projected images in all directions, giving the impression of floating in outer space. For example, a small planetarium at AHHAA in Tartu, Estonia features such an installation, with special projectors for images below the feet of the audience, as well as above their heads.
Traditional electromechanical/optical projectors.
Traditional planetarium projection apparatus uses a hollow ball with a light inside, and a pinhole for each star, hence the name "star ball". With some of the brightest stars (e.g. Sirius, Canopus, Vega), the hole must be so big to let enough light through that there must be a small lens in the hole to focus the light to a sharp point on the dome. In later and modern planetarium star balls, the individual bright stars often have individual projectors, shaped like small hand-held torches, with focusing lenses for individual bright stars. Contact breakers prevent the projectors from projecting below the 'horizon'.
The star ball is usually mounted so it can rotate as a whole to simulate the Earth's daily rotation, and to change the simulated latitude on Earth. There is also usually a means of rotating to produce the effect of precession of the equinoxes. Often, one such ball is attached at its south ecliptic pole. In that case, the view cannot go so far south that any of the resulting blank area at the south is projected on the dome. Some star projectors have two balls at opposite ends of the projector like a dumbbell. In that case all stars can be shown and the view can go to either pole or anywhere between. But care must be taken that the projection fields of the two balls match where they meet or overlap.
Smaller planetarium projectors include a set of fixed stars, Sun, Moon, and planets, and various nebulae. Larger projectors also include comets and a far greater selection of stars. Additional projectors can be added to show twilight around the outside of the screen (complete with city or country scenes) as well as the Milky Way. Others add coordinate lines and constellations, photographic slides, laser displays, and other images.
Each planet is projected by a sharply focused spotlight that makes a spot of light on the dome. Planet projectors must have gearing to move their positioning and thereby simulate the planets' movements. These can be of these types:-
Despite offering a good viewer experience, traditional star ball projectors suffer several inherent limitations. From a practical point of view, the low light levels require several minutes for the audience to "dark adapt" its eyesight. "Star ball" projection is limited in education terms by its inability to move beyond an earth-bound view of the night sky. Finally, in most traditional projectors the various overlaid projection systems are incapable of proper occultation. This means that a planet image projected on top of a star field (for example) will still show the stars shining through the planet image, degrading the quality of the viewing experience. For related reasons, some planetaria show stars below the horizon projecting on the walls below the dome or on the floor, or (with a bright star or a planet) shining in the eyes of someone in the audience.
However, the new breed of Optical-Mechanical projectors using fiber-optic technology to display the stars show a much more realistic view of the sky.
Digital projectors.
An increasing number of planetaria are using digital technology to replace the entire system of interlinked projectors traditionally employed around a star ball to address some of their limitations. Digital planetarium manufacturers claim reduced maintenance costs and increased reliability from such systems compared with traditional "star balls" on the grounds that they employ few moving parts and do not generally require synchronisation of movement across the dome between several separate systems. Some planetaria mix both traditional opto-mechanical projection and digital technologies on the same dome.
In a fully digital planetarium, the dome image is generated by a computer and then projected onto the dome using a variety of technologies including cathode ray tube, LCD, DLP or laser projectors. Sometimes a single projector mounted near the centre of the dome is employed with a fisheye lens to spread the light over the whole dome surface, while in other configurations several projectors around the horizon of the dome are arranged to blend together seamlessly.
Digital projection systems all work by creating the image of the night sky as a large array of pixels. Generally speaking, the more pixels a system can display, the better the viewing experience. While the first generation of digital projectors were unable to generate enough pixels to match the image quality of the best traditional "star ball" projectors, high-end systems now offer a resolution that approaches the limit of human visual acuity.
LCD projectors have fundamental limits on their ability to project true black as well as light, which has tended to limit their use in planetaria. LCOS and modified LCOS projectors have improved on LCD contrast ratios while also eliminating the “screen door” effect of small gaps between LCD pixels. “Dark chip” DLP projectors improve on the standard DLP design and can offer relatively inexpensive solution with bright images, but the black level requires physical baffling of the projectors. As the technology matures and reduces in price, laser projection looks promising for dome projection as it offers bright images, large dynamic range and a very wide color space.
Show content.
Worldwide, most planetaria provide shows to the general public. Traditionally, shows for these audiences with themes such as "What's in the sky tonight?", or shows which pick up on topical issues such as a religious festival (often the Christmas star) linked to the night sky, have been popular. Pre-recorded and live presentation formats are possible. Live format are preferred by many venues because a live expert presenter can answer on-the-spot questions raised by the audience.
Since the early 1990s, fully featured 3-D digital planetaria have added an extra degree of freedom to a presenter giving a show because they allow simulation of the view from any point in space, not only the earth-bound view which we are most familiar with. This new virtual reality capability to travel through the universe provides important educational benefits because it vividly conveys that space has depth, helping audiences to leave behind the ancient misconception that the stars are stuck on the inside of a giant celestial sphere and instead to understand the true layout of the solar system and beyond. For example, a planetarium can now 'fly' the audience towards one of the familiar constellations such as Orion, revealing that the stars which appear to make up a co-ordinated shape from our earth-bound viewpoint are at vastly different distances from Earth and so not connected, except in human imagination and mythology. For especially visual or spatially aware people, this experience can be more educationally beneficial than other demonstrations.
Music is an important element to fill out the experience of a good planetarium show, often featuring forms of space-themed music, or music from the genres of space music, space rock, or classical music.

</doc>
<doc id="60549" url="https://en.wikipedia.org/wiki?curid=60549" title="Orrery">
Orrery

An orrery is a mechanical model of the solar system that illustrates or predicts the relative positions and motions of the planets and moons, usually according to the heliocentric model. It may also represent the relative sizes of these bodies; but since accurate scaling is often not practical due to the actual large ratio differences, a subdued approximation may be used instead. Though the Greeks had working planetaria, the first orrery that was a planetarium of the modern era was produced in 1704, and one was presented to Charles Boyle, 4th Earl of Orrery – whence came the name. They are typically driven by a clockwork mechanism with a globe representing the Sun at the centre, and with a planet at the end of each of the arms.
History.
Early versions.
The Antikythera mechanism, discovered in 1900 in a wreck off the Greek island of Antikythera and extensively studied, exhibited the diurnal motions of the Sun, Moon, and the five known planets. It has been dated between 150 and 100 BC. The Antikythera hand driven mechanism is now considered one of the first orreries, but for many decades was ignored as it was thought to be far too complex to be genuine. It was geocentric and used as a mechanical calculator designed to calculate astronomical positions.
According to Cicero, the Roman philosopher who was writing in the first century BC, Posidonius constructed a planetary model.
In 1348, Giovanni Dondi built the first known clock driven mechanism which displays the ecliptical position of Moon, Sun, Mercury, Venus, Mars, Jupiter and Saturn according to the complicated ptolemeic planetary theories. The clock itself is lost, but Dondi left a complete description of the astronomic gear trains of his clock.
As late as 1650, P. Schirleus built a geocentric planetarium with the Sun as a planet, and with Mercury and Venus revolving around the Sun as its moons.
At the court of William IV, Landgrave of Hesse-Kassel two complicated astronomic clocks were built in 1561 and 1563-1568, which show on four sites the ecliptical position of Sun, Mercury, Venus, Mars, Jupiter and Saturn, the Moon, Sun and Dragon (Nodes of the Moon) according to Ptolemy, a Calendar, the Sunrise and Sunset and an automated celestial sphere with an animated Sun symbol which, for the first time on a celestial globe, show the real position of the sun, including the equation of time. The clocks are now on display in Kassel at the Astronomisch-Physikalisches Kabinett and in Dresden at the Mathematisch-Physikalischer Salon.
In "De revolutionibus orbium coelestium", published in Nuremberg in 1543, Nicolaus Copernicus challenged the Western teaching of a geocentric universe in which the Sun revolved daily around the Earth. He observed that some Greek philosophers had proposed a heliocentric universe. This simplified the apparent epicyclic motions of the planets, making it feasible to represent the planets' paths as simple circles. This could be modelled by the use of gears. Tycho Brahe's improved instruments made precise observations of the skies (1576–1601), and from these Johannes Kepler (1621) deduced that planets orbited the Sun in ellipses. In 1687 Isaac Newton explained the cause of elliptic motion in his theory of gravitation.
The modern orrery.
Clock makers George Graham and Thomas Tompion built the first modern orrery around 1704 in England. Graham gave the first model, or its design, to the celebrated instrument maker John Rowley of London to make a copy for Prince Eugene of Savoy. Rowley was commissioned to make another copy for his patron Charles Boyle, 4th Earl of Orrery, from which the device took its name in English. This model was presented to Charles' son John, later the 5th Earl of Cork and 5th Earl of Orrery. Independently, Christiaan Huygens published details of a heliocentric planetary machine in 1703, which he built while resident in Paris between 1665 and 1681. He calculated the gear trains needed to represent a year of 365.242 days, and used that to produce the cycles of the principal planets.
Joseph Wright's painting "A Philosopher giving a Lecture on the Orrery in which a lamp is put in place of the Sun" (ca. 1766), which hangs in Derby Museum and Art Gallery, depicts a group listening to a lecture by a natural philosopher. The Sun in a brass orrery provides the only light in the room. The orrery depicted in the painting has rings, which give it an appearance similar to that of an armillary sphere. The demonstration was thereby able to depict eclipses.
To put this in chronological context, in 1762 John Harrison's marine chronometer first enabled accurate measurement of longitude. In 1766, astronomer Johann Daniel Titius first demonstrated that the mean distance of each planet from the Sun could be represented by the following progression:
That is, 0.4, 0.7, 1.0, 1.6, 2.8, 5.2 ... The numbers refer to astronomical units, the mean distance between Sun and Earth, which is 1.496 × 10⁸ km (93 × 10⁶ miles). The Derby Orrery does not show mean distance, but demonstrated the relative planetary movements.
Eisinga's Planetarium was built from 1774 to 1781 by Eise Eisinga in his home in Franeker, in the Netherlands. It displays the planets across the width of a room's ceiling, and has been in operation almost continually since it was created. This orrery is a planetarium in both senses of the word: a complex machine showing planetary orbits, and a theatre for depicting the planets' movement. Eisinga house was bought by the Dutch Royal family who gave him a pension.
In 1764, Benjamin Martin devised a new type of planetary model, in which the planets were carried on brass arms leading from a series of concentric or coaxial tubes. With this construction it was difficult to make the planets revolve, and to get the moons to turn around the planets. Martin suggested that the conventional orrery should consist of three parts: the planetarium where the planets revolved around the Sun, the tellurion (also "tellurian" or "tellurium") which showed the inclined axis of the Earth and how it revolved around the Sun, and the lunarium which showed the eccentric rotations of the Moon around the Earth. In one orrery, these three motions could be mounted on a common table, separately using the central spindle as a prime mover.
Explanation.
All orreries are "planetariums" or "planetaria" (alternative plural). The term orrery has only existed since 1714. A grand orrery is one that includes the outer planets known at the time of its construction. The word planetarium has been captured, and now usually refers to hemispherical theatres in which images of the night sky are projected onto an overhead surface. Planetariums (orreries) can range widely in size from hand-held to room-sized. An orrery is used to demonstrate the motion of the planets, while a mechanical device used to predict eclipses and transits is called an astrarium.
An orrery should properly include the Sun, the Earth and the Moon (plus optionally other planets). A model that only includes the Earth, the Moon and the Sun is called a tellurion or tellurium, and one which only includes the Earth and the Moon is a lunarium. A jovilabe is a model of Jupiter and its moons.
A planetarium will show the "orbital period" of each planet and the "rotation rate", as shown in the table above. A tellurion will show the earth with the moon revolving around the sun. It will use the angle of "inclination of the equator" from the table above to show how it rotates around its own axis. It will show the earth's moon, rotating around the earth. A lunarium is designed to show the complex motions of the moon as it revolves around the earth.
Orreries are usually not built to scale. Some fixed Solar System scale models have been built and are often many kilometres in size. Human orreries, where humans move about as the planets, have also been constructed, but most are temporary. There is a permanent human orrery at Armagh Observatory in Northern Ireland, which has the six ancient planets, Ceres, and comets Halley and Encke. Uranus and beyond are also shown, but in a fairly limited way. Another is at Sky's the Limit Observatory and Nature Center in Twentynine Palms, CA. This is a true to scale (20 billion to one), true to position (accurate to within four days) human orrery. The first four planets are relatively close to one another, but the next four require a certain amount of hiking in order to visit them.
A normal mechanical clock could be used to produce an extremely simple orrery with the Sun in the centre, Earth on the minute hand and Jupiter on the hour hand; Earth would make 12 revolutions around the Sun for every 1 revolution of Jupiter. Note however that Jupiter's actual year is 11.86 Earth years long, so this particular example would lose accuracy rapidly. A real orrery would be more accurate and include more planets, and would perhaps make the planets rotate as well.
Projection orreries.
Many planetariums (buildings) have a projection orrery, which projects onto the dome of the planetarium a Sun with either dots or small images of the planets. These usually are limited to the planets from Mercury to Saturn, although some include Uranus. The light sources for the planets are projected onto mirrors which are geared to a motor which drives the images on the dome. Typically the Earth will circle the Sun in one minute, while the other planets will complete an orbit in time periods proportional to their actual motion. Thus Venus, which takes 224.7 days to orbit the Sun, will take 37 seconds to complete an orbit on an orrery, and Jupiter will take 11 minutes, 52 seconds.
Some planetariums have taken advantage of this to use orreries to simulate planets and their moons. Thus Mercury orbits the Sun in 0.24 of an Earth year, while Phobos and Deimos orbit Mars in a similar 4:1 time ratio. Planetarium operators wishing to show this have placed a red cap on the Sun (to make it resemble Mars) and turned off all the planets but Mercury and Earth. Similar tricks can be used to show Pluto and its five moons.
Notable orreries.
Shoemaker John Fulton of Fenwick, Ayrshire, built three between 1823 and 1833. The last is in Glasgow's Kelvingrove Art Gallery and Museum.
The Franeker Planetarium built by a wool carder named Eise Eisinga in his own living room, in the small city of Franeker in Friesland, is in fact an orrery. It was constructed between 1774 and 1781. The "face" of the model looks down from the ceiling of a room, with most of the mechanical works in the space above the ceiling. It is driven by a pendulum clock, which has 9 weights or ponds. The planets move around the model in real time.
An innovative concept is to have people play the role of the moving planets and other Solar System objects. Such a model, called a human orrery, has been laid out with precision at the Armagh Observatory.
Meccano Planetaria.
The first Meccano Orrery was described in June 1918 Meccano Manual, though it is in the last quarter of the 20th century that Alan Partridge, John Nuttall, Pat Briggs and Michael Whiting have experimented with the limitations and possibilities of this medium. There are six methods of building orreries:
Virtual Orreries.
The first virtual Orrery was created in 2013 by Cattle Point Foundation volunteers at Cattle Point DARK SKY Urban Star Park. The orrery is called "The Salish Sea Walk of the Planets". It was built on Google Maps as there was a contentious local issue that the vernal pools by the edge of the Salish Sea, where the globally rare Macoun's Meadowfoam and Victoria Owl-Clover exist, might be damaged by creating cairns and encouraging walkers to explore the Orrery.
As well as highlighting the plight of the rare plants, the Orrery has served to put the spotlight on the Coast Salish and specifically the local clan, the Lkwungen upon whose traditional land Cattle Point Star Park lies.
The same spotlight also illuminates the unique Salish Sea "stories" from several sciences. Biologists recognize that the marine waters off Cattle Point DARK SKY Star Park are critical habitat for the Orcas of the Salish Sea. The sea is also a good habitat for the Giant Pacific Octopus; and, in the Southern Salish Sea, the greatly overfished Pacific Herring - resulting in the relatively low abundance of birds; Ornithologists appreciate the Marbled Murrelets, and Rhinoceros Auklets which are of great interest to visiting birdwatchers especially flying by day and night, in and out of the DARK SKY star park; noting that Cattle Point is surrounded by the historic Victoria Harbour Migratory Bird Sanctuary (est. Oct.27, 1923). This was established to control hunting in 1923, and now harbours amazing urban life; geologists note that the Orrery's SUN sits on top of the Leech River/Devils Mountain fault line ; and archaeologists celebrate the large number of archaeological sites from the SUN to MERCURY (i.e. within the Star park down along the seafront to the mouth of Bowker Creek), all part of an ancient Lkwungen seaport known as Sitchanalth hypothesized to have been destroyed by the great Tsunami of 930AD. 
The Orrery quickly evolved from being contained within the Star Park, to taking on a size previously unimagined by the volunteers. It is now over 8,500 kilometers in size reaching out to communities along the Salish Sea's North West Pacific edge and then up along the West coast of Vancouver Island. As an example, the furthest "planet" PLUTO is located in Bamfield. The most distant "object" in the Solar System is the Oort Cloud and has been positioned (approximately, virtually and symbolically) at the Canadian Embassy in Beijing. This effectively serves to illustrate the enormous distances involved in the solar system. "The Salish Sea Walk of the Planets" name symbolizes the fictional journey of the Coast Salish riding inbound inside a long period Comet from Proxima Centauri to Earth many thousands of years ago.

</doc>
<doc id="60554" url="https://en.wikipedia.org/wiki?curid=60554" title="Bamburgh">
Bamburgh

Bamburgh ( ) is a large village and civil parish on the coast of Northumberland, England. It had a population of 454, decreasing to 414 at the 2011 census.
It is notable for two reasons: the imposing Bamburgh Castle, overlooking the beach, seat of the former Kings of Northumbria, and at present owned by the Armstrong family (see William George Armstrong); and its association with the Victorian heroine, Grace Darling, who is buried there.
Its extensive sandy beach was awarded the Blue Flag rural beach award in 2005. The Bamburgh sandy hills, an area of sand dunes which are a Site of Special Scientific Interest, stand behind the award-winning beach. Bamburgh is popular with holidaymakers and is within the Northumberland Coast Area of Outstanding Natural Beauty.
History.
Bamburgh Castle, then called "Din Guardi", may have been the capital of the Brythonic kingdom of Bryneich between about AD 420 and 547. In 547 the castle was taken by the invading Angles led by Ida son of Eoppa and was renamed Bebbanburgh by one of his successors, Æthelfrith, after his wife Bebba, according to the "Historia Brittonum". From then onwards the castle became the capital of the Anglian kingdom of Bernicia until it merged with its southern neighbour, Deira, in 634. After the two realms united as Northumbria the capital was moved to York.
Bamburgh was again the capital of local Bernician rulers after the Viking destruction of the old Northumbrian kingdom in 867. Initially puppets of the Vikings, they later had more autonomy under either the Vikings or Kings of united England. The rulers of Bernicia held the title of High Reeve of Bamburgh from at least 913 until 1041, when the last was killed by Harthacnut; sometimes – 954–963 and 975–1016 – they also served as Earls of York. The castle was destroyed in a renewed Viking attack in 993 and in 1018 the Lothian part of Bernicia was ceded to Scotland, significantly reducing the area controlled from Bamburgh.
Edward IV ruled all England in 1464, during the Wars of the Roses, in which time the Percy family, Earls of Northumberland, were based at Bamburgh Castle.
Sir Thomas Mallory considered Bamburgh to be Lancelot's castle Joyous Gard. The Victorian poet Algernon Charles Swinburne agreed and called it "The noblest hold in all the North."
Swinburne swam here, as did the novelist E. M. Forster who adopted the Forsters of Bamb-bra as his ancestors.
St Aidan's Church.
According to Bede, St Aidan built a wooden church outside the castle wall in AD 635, and he died here in AD 652. A wooden beam preserved inside the church is traditionally said to be the one on which he rested as he died.
The present church dates from the late 12th century, though some pre-conquest stonework survives in the north aisle. The chancel, said to be the second longest in the country (60 ft; 18m), was added in 1230; it contains an 1895 reredos in Caen stone by W.S. Hicks, depicting northern saints of the 7th and 8th centuries. There is an effigy of local heroine Grace Darling in the North Aisle. Her memorial is sited in the churchyard in such a position that it can be seen by passing ships.
Governance.
An electoral ward of the same name exists. This ward includes Belford and also stretches south to Ellingham with a total population taken at the 2011 census of 4,846.
Bamburgh Lighthouse.
Bamburgh Lighthouse was built by Trinity House in 1910 to guide shipping both passing along the Northumberland coast and in the waters around the Farne Islands. It was extensively modernised in 1975 and is now monitored from the Trinity House Operations and Planning Centre in Harwich. Routine maintenance is carried out by a local attendant. It is the most northerly land-based lighthouse in England.
When originally built, the lamp was mounted on a skeletal steel tower (the footprint of which can still be seen within the compound) which stood alongside the white building which housed an acetylene plant to power the lamp. (A similar arrangement can be seen today at Peninnis Lighthouse.) During electrification in 1975 the tower was removed, and the lantern was placed instead on top of the (now redundant) acetylene building. Keepers' accommodation has never been needed, as the light was automated from the start.
See also.
<br>
External links.
<br>

</doc>
<doc id="60555" url="https://en.wikipedia.org/wiki?curid=60555" title="Grace Darling">
Grace Darling

Grace Horsley Darling (24 November 1815 – 20 October 1842) was an English lighthouse keeper's daughter, famed for participating in the rescue of survivors from the shipwrecked "Forfarshire" in 1838. The paddlesteamer ran aground on the Farne Islands off the coast of Northumberland in northeast England; nine members of her crew were saved.
Biography.
Grace Darling was born on 24 November 1815 at her grandfather's cottage in Bamburgh in Northumberland. She was the seventh of nine children (four brothers and four sisters) born to William and Thomasin Darling, and when only a few weeks old she was taken to live on Brownsman Island, one of the Farne Islands, in a small cottage attached to the lighthouse.
Her father ran the lighthouse (built in 1795) for Trinity House and earned a salary of £70 per annum with a bonus of £10 for satisfactory service. The accommodation was basic and the lighthouse was not in the best position to guide shipping to safety, so in 1826 the family moved to the newly constructed lighthouse on Longstone Island.
Longstone Lighthouse had better accommodation, but the island itself was slightly less hospitable, so William would row back to Brownsman to gather vegetables from their former garden and to feed the animals. The family spent most of their time on the ground floor of the lighthouse which consisted of a large room, heated by a wood stove. The room was their living room, dining room and kitchen in one and had a spiral staircase leading to three bedrooms above and of course the light at the top of the tower.
In the early hours of 7 September 1838, Darling, looking from an upstairs window, spotted the wreck and survivors of the "Forfarshire" on Big Harcar, a nearby low rocky island. The "Forfarshire" had foundered on the rocks and broken in half: one of the halves had sunk during the night.
She and her father William determined that the weather was too rough for the lifeboat to put out from Seahouses (then North Sunderland), so they took a rowing boat (a 21 ft, 4-man Northumberland coble) across to the survivors, taking a long route that kept to the lee side of the islands, a distance of nearly a mile. Darling kept the coble steady in the water while her father helped four men and the lone surviving woman, Mrs. Dawson, into the boat. Although she survived the sinking, Mrs Dawson had lost her two young children during the night. William and three of the rescued men then rowed the boat back to the lighthouse. Darling then remained at the lighthouse while William and three of the rescued crew members rowed back and recovered four more survivors.
Meanwhile the lifeboat had set out from Seahouses but arrived at Big Harcar rock after Darling and her father had completed their rescue operation: all they found were the dead bodies of Mrs Dawson's children and of a vicar. It was too dangerous to return to North Sunderland so they rowed to the lighthouse to take shelter. Darling's brother, William Brooks Darling, was one of the seven fishermen in the lifeboat. The weather deteriorated to the extent that everyone was obliged to remain at the lighthouse for three days before returning to shore.
The "Forfarshire" had been carrying 62 people. The vessel broke in two almost immediately upon hitting the rocks. Those rescued by Darling and her father were from the bow section of the vessel which had been held by the rocks for some time before sinking. All that remained at daybreak was the portside paddlebox casing. Nine other passengers and crew had managed to float off a lifeboat from the stern section before it too sank, and were picked up in the night by a passing Montrose sloop and brought into South Shields that same night.
As news of her role in the rescue reached the public, her combination of bravery and simple virtue set her out as exemplary, and led to an uneasy role as the nation's heroine. Grace and her father were awarded the Silver Medal for bravery by the Royal National Institution for the Preservation of Life from Shipwreck, later named the Royal National Lifeboat Institution. Subscriptions and donations totaling over £700 were raised for her, including £50 from Queen Victoria; more than a dozen portrait painters sailed to her island home to capture her likeness, and hundreds of gifts, letters, and even marriage proposals were delivered to her.
Her unexpected wealth and fame were such that the Duke of Northumberland took on a role as her self-appointed guardian and founder of a trust, established to look after the donations offered to her. His personal gifts to her and her family included a timepiece, and a silver teapot.
In 1842, Grace fell ill while visiting the mainland, and was in convalescence with her cousins, the MacFarlanes, in their house in Narrowgate, Alnwick. The Duchess of Northumberland heard of her situation, and arranged for her to be moved to better accommodation close to Alnwick Castle, and tended to the ailing heroine in person as well as providing Grace with the services of the ducal family physician.
Grace's condition declined, however, and in the final stages of her illness she was conveyed to the place of her birth, in Bamburgh. Grace Darling died of tuberculosis in October 1842, aged 26.
Legacy.
Darling is buried with her father and mother in a modest grave in St. Aidan’s churchyard, Bamburgh, where a nearby elaborate cenotaph commemorates her life. A plain stone monument to her was erected in St. Cuthbert’s Chapel on Great Farne Island in 1848.
Darling’s achievement was celebrated in her lifetime: she received a large financial reward in addition to the plaudits of the nation. A number of fictionalised depictions propagated the Grace Darling legend, such as "Grace Darling, or the Maid of the Isles" by Jerrold Vernon (1839), which gave birth to the legend of “the girl with windswept hair”. Her deed was committed to verse by William Wordsworth in his poem "Grace Darling" (1843). A lifeboat with her name was presented to Holy Island. One of a series of Victorian paintings by William Bell Scott at Wallington Hall in Northumberland depicts her rescue. The McManus Galleries in Dundee includes three paintings by Thomas Musgrave Joy which celebrate Grace Darling's deeds with the "Forfarshire".
At Bamburgh, there is a museum dedicated to her achievements and the seafaring life of the region. It re-opened in December 2007 following renovation. The Royal National Lifeboat Institution Mersey class lifeboat at Seahouses bears the name "Grace Darling".
Singer/songwriter Dave Cousins of Strawbs wrote "Grace Darling" (on "Ghosts") in tribute and as a love song. North East musical playwright Dennis A Westgate wrote a musical based on the life of Grace Darling, exploring her life from childhood through to her death in 1842. The premiere was performed by a community theatre company based in York, The York Stars, July 2010 to help promote Grace Darling and the work of the RNLI.
The children's singing group "The Limeliters" sang a different "Grace Darling" (featuring the refrain "Help, help, came a desperate yelp!") in their 1962 album, recorded live in concert, "Through Children's Eyes".
In 1992 indie band The Hit Parade released "Grace Darling" a song that imagines the death of Grace Darling in Bamburgh.
It was suggested by Richard Armstrong in his 1965 biography "Grace Darling: Maid and Myth" that she may have suffered from a cleft lip. He is the only biographer to put forward this theory, which has been strongly disputed.

</doc>
<doc id="60556" url="https://en.wikipedia.org/wiki?curid=60556" title="William Armstrong, 1st Baron Armstrong">
William Armstrong, 1st Baron Armstrong

William George Armstrong, 1st Baron Armstrong (26 November 1810 – 27 December 1900) was an English industrialist who founded the Armstrong Whitworth manufacturing concern on Tyneside. He was also an eminent scientist, inventor and philanthropist. In collaboration with the architect Richard Norman Shaw, he built Cragside in Northumberland, the first house in the world to be lit by hydroelectricity. He is regarded as the inventor of modern artillery.
Armstrong was knighted in 1859 after giving his gun patents to the government. In 1887, in Queen Victoria's golden jubilee year, he was raised to the peerage as Baron Armstrong of Cragside, becoming the first engineer – and, indeed, the first scientist – to join the House of Lords.
Early life.
Armstrong was born in Newcastle upon Tyne, at 9 Pleasant Row, Shieldfield, about a mile from the city centre. Although the house in which he was born no longer exists, an inscribed granite tablet marks the spot on which it once stood. At that time the area, next to the Pandon Dene, was rural. His father, also called William, was a corn merchant on the Newcastle quayside, who rose through the ranks of Newcastle society to become mayor of the town in 1850. An elder sister, Anne, born in 1802, was named after his mother, the daughter of Addison Potter.
Armstrong was educated at private schools in Newcastle and Whickham, near Gateshead, until he was sixteen, when he was sent to Bishop Auckland Grammar School. While there, he often visited the nearby engineering works of William Ramshaw. During his visits he met his future wife, Ramshaw’s daughter Margaret, six years his senior.
Armstrong’s father was set on him following a career in the law, and so he was articled to Armorer Donkin, a solicitor friend of his father’s. He spent five years in London studying law and returned to Newcastle in 1833. In 1835 he became a partner in Donkin’s business and the firm became Donkin, Stable and Armstrong. Armstrong married Margaret Ramshaw in 1835, and they built a house in Jesmond Dene, on the eastern edge of Newcastle. Armstrong worked for eleven years as a solicitor, but during his spare time he showed great interest in engineering.
Change of career.
Armstrong was a very keen angler, and while fishing on the River Dee at Dentdale in the Pennines, he saw a waterwheel in action, supplying power to a marble quarry. It struck Armstrong that much of the available power was being wasted. When he returned to Newcastle, he designed a rotary engine powered by water, and this was built in the High Bridge works of his friend Henry Watson. Unfortunately, little interest was shown in the engine. Armstrong subsequently developed a piston engine instead of a rotary one and decided that it might be suitable for driving a hydraulic crane. In 1846 his work as an amateur scientist was recognized when he was elected a Fellow of the Royal Society.
In 1845 a scheme was set in motion to provide piped water from distant reservoirs to the households of Newcastle. Armstrong was involved in this scheme and he proposed to Newcastle Corporation that the excess water pressure in the lower part of town could be used to power a Quayside crane specially adapted by himself. He claimed that his hydraulic crane could unload ships faster and more cheaply than conventional cranes. The Corporation agreed to his suggestion, and the experiment proved so successful that three more hydraulic cranes were installed on the Quayside.
The success of his hydraulic crane led Armstrong to consider setting up a business to manufacture cranes and other hydraulic equipment. He therefore resigned from his legal practice. Donkin, his legal colleague, supported him in his career move, providing financial backing for the new venture. In 1847 the firm of W.G. Armstrong & Company bought of land alongside the river at Elswick, near Newcastle, and began to build a factory there. The new company received orders for hydraulic cranes from Edinburgh and Northern Railways and from Liverpool Docks, as well as for hydraulic machinery for dock gates in Grimsby. The company soon began to expand. In 1850 the company produced 45 cranes and two years later, 75. It averaged 100 cranes per year for the rest of the century. In 1850 over 300 men were employed at the works, but by 1863 this had risen to 3,800. The company soon branched out into bridge building, one of the first orders being for the Inverness Bridge, completed in 1855.
Hydraulic accumulator.
Armstrong was responsible for developing the hydraulic accumulator. Where water pressure was not available on site for the use of hydraulic cranes, Armstrong often built high water towers to provide a supply of water at pressure. However, when supplying cranes for use at New Holland on the Humber Estuary, he was unable to do this because the foundations consisted of sand. After much careful thought he produced the hydraulic accumulator, a cast-iron cylinder fitted with a plunger supporting a very heavy weight. The plunger would slowly be raised, drawing in water, until the downward force of the weight was sufficient to force the water below it into pipes at great pressure. The accumulator was a very significant, if unspectacular, invention, which found many applications in the following years.
Armaments.
In 1854, during the Crimean War, Armstrong read about the difficulties the British Army experienced in manoeuvring its heavy field guns. He decided to design a lighter, more mobile field gun, with greater range and accuracy. He built a breech-loading gun with a strong, rifled barrel made from wrought iron wrapped around a steel inner lining, designed to fire a shell rather than a ball. In 1855 he had a five-pounder ready for inspection by a government committee. The gun proved successful in trials, but the committee thought a higher caliber gun was needed, so Armstrong built an 18-pounder on the same design.
After trials, this gun was declared to be superior to all its rivals. Armstrong surrendered the patent for the gun to the British government, rather than profit from its design. As a result he was created a Knight Bachelor and in 1859 was presented to Queen Victoria. Armstrong became employed as Engineer of Rifled Ordnance to the War Department. In order to avoid a conflict of interests if his own company were to manufacture armaments, Armstrong created a separate company, called Elswick Ordnance Company, in which he had no financial involvement. The new company agreed to manufacture armaments for the British government and no other. Under his new position, Armstrong worked to bring the old Woolwich Arsenal up to date so that it could build guns designed at Elswick.
However, just when it looked as if the new gun was about to become a great success, a great deal of opposition to the gun arose, both inside the army and from rival arms manufacturers, particularly Joseph Whitworth of Manchester. Stories were publicised that the new gun was too difficult to use, that it was too expensive, that it was dangerous to use, that it frequently needed repair and so on. All of this smacked of a concerted campaign against Armstrong. Armstrong was able to refute all of these claims in front of various government committees, but he found the constant criticism very wearying and depressing. In 1862 the government decided to stop ordering the new gun and return to muzzle loaders. Also, because of a drop in demand, future orders for guns would be supplied from Woolwich, leaving Elswick without new business. Compensation was eventually agreed with the government for the loss of business to the company. Unfortunately, the government would not release the company from its agreement not to sell armaments abroad, so that avenue was closed to it. Eventually, the restriction was relaxed, and the company was able to sell guns to both sides in the American Civil War.
Warships.
In 1864 the two companies, W.G. Armstrong & Company and Elswick Ordnance Company merged to form Sir W.G. Armstrong & Company. Armstrong had resigned from his employment with the War Office, so there was no longer a conflict of interest. The company turned its attention to naval guns. In 1867 Armstrong reached an agreement with Charles Mitchell, a shipbuilder in Low Walker, whereby Mitchells would build warships and Elswick would provide the guns. The first ship, in 1868 was HMS "Staunch", a gunboat.
In 1876, because the 18th-century bridge at Newcastle restricted access by ships to the Elswick works, Armstrong’s company paid for a new Swing Bridge to be built, so that warships could have their guns fitted at Elswick. In 1882 Armstrong’s company merged with Mitchells to form Sir William Armstrong, Mitchell and Co. Ltd. and in 1884 a shipyard opened at Elswick to specialise in warship production. The first vessels produced were the torpedo cruisers "Panther" and "Leopard" for the Austro-Hungarian Navy. The first battleship produced at Elswick was H.M.S "Victoria", launched in 1887. The ship was originally to be named "Renown", but the name was changed in honour of the Queen's Golden Jubilee. Armstrong drove the first and last rivets. The ship was ill-fated, as she was involved in a collision with H.M.S. "Camperdown" in 1893 and sank with the loss of 358 men, including Vice-Admiral Sir George Tryon. An important customer of the Elswick yard was Japan, which took several cruisers, some of which defeated the Russian fleet at the Battle of Tsushima in 1905. It was claimed that every Japanese gun used in the battle was provided by Elswick. Elswick was the only factory in the world that could build a battleship and arm it completely.
The Elswick works continued to prosper, and by 1870 it stretched for three-quarters of a mile along the riverside. The population of Elswick, which was 3,539 in 1851, had increased by 1871 to 27,800. In 1894, Elswick built and installed the steam-driven pumping engines, hydraulic accumulators and hydraulic pumping engines to operate London’s Tower Bridge. In 1897 the company merged with the company of Armstrong’s old rival, Joseph Whitworth, and became Sir W.G. Armstrong, Whitworth & Co Ltd. Whitworth was by this time dead.
Armstrong gathered many excellent engineers at Elswick. Notable among them were Andrew Noble and George Wightwick Rendel, whose design of gun-mountings and hydraulic control of gun-turrets were adopted worldwide. Rendel introduced the cruiser as a naval vessel. There was great rivalry and dislike between Noble and Rendel, which became open after Armstrong’s death.
Cragside.
From 1863 onwards, although Armstrong remained the head of his company, he became less involved in its day-to-day running. He appointed several very able men to senior positions and they continued his work. When he married, he acquired a house called Jesmond Dean (sic), which is now demolished, and not to be confused with the nearby Jesmond Dene House. Armstrong's house was to the west of Jesmond Dene, Newcastle, and thus not far from his birthplace, and he began to landscape and improve land that he bought within the Dene. In 1860 he paid local architect John Dobson to design a Banqueting Hall overlooking the Dene, which still survives. His house close to Newcastle was convenient for his practice as a solicitor and his work as an industrialist, but when he had more spare time he longed for a house in the country.
He had often visited Rothbury as a child, when he was afflicted by a severe cough, and he had fond memories of the area. In 1863 he bought some land in a steep-sided, narrow valley where the Debdon Burn flows towards the River Coquet near Rothbury. He had the land cleared and supervised the building of a house perched on a ledge of rock, overlooking the burn. He also supervised a programme of planting trees and mosses so as to cover the rocky hillside with vegetation.
His new house was called Cragside, and over the years Armstrong added to the Cragside estate. Eventually the estate was and had seven million trees planted, together with five artificial lakes and of carriage drives. The lakes were used to generate hydro-electricity, and the house was the first in the world to be lit by hydro-electricity, using incandescent lamps provided by the inventor Joseph Swan.
As Armstrong spent less and less time at the Elswick works, he spent more and more time at Cragside, and it became his main home. In 1869 he commissioned the celebrated architect Richard Norman Shaw to enlarge and improve the house, and this was done over a period of 15 years. In 1883 Armstrong gave Jesmond Dene, together with its banqueting hall to the city of Newcastle. He retained his house next to the Dene. Armstrong entertained several eminent guests at Cragside, including the Shah of Persia, the King of Siam, the prime minister of China and the Prince and Princess of Wales.
Later life.
In 1873 he served as High Sheriff of Northumberland. He was elected as the president of the Institution of Civil Engineers in December 1881 and served in that capacity for the next year. He was conferred with Honorary Membership of the Institution of Engineers and Shipbuilders in Scotland in 1884.[http://www.iesis.org/honorary-fellows.html] In 1886 he was persuaded to stand as a Unionist Liberal candidate for Newcastle, but was unsuccessful, coming third in the election. That same year he was presented with the Freedom of the City of Newcastle. In 1887 he was raised to the peerage as Baron Armstrong, of Cragside in the County of Northumberland. His last great project, begun in 1894, was the purchase and restoration of the huge Bamburgh Castle on the Northumberland coast, which remains in the hands of the Armstrong family. His wife, Margaret, died in September 1893, at their house in Jesmond. Armstrong died at Cragside on 27 December 1900, aged ninety. He was buried in Rothbury churchyard, alongside his wife. The couple had no children, and Armstrong’s heir was his great-nephew William Watson-Armstrong. He was succeeded as chairman of the company by his one-time protégé, Andrew Noble.
Such was Armstrong's fame as a gun-maker that he is thought to be a possible model for George Bernard Shaw's arms magnate in "Major Barbara". The title character in Iain Pears' historical-mystery novel "Stone's Fall" also has similarities to Armstrong.
His attitude to armaments.
There is no evidence that Armstrong agonised over his decision to go into armament production. He once said: "If I thought that war would be fomented, or the interests of humanity suffer, by what I have done, I would greatly regret it. I have no such apprehension". He also said: "It is our province, as engineers to make the forces of matter obedient to the will of man; those who use the means we supply must be responsible for their legitimate application".
Views on renewable energy.
Armstrong advocated the use of renewable energy. Stating that coal "was used wastefully and extravagantly in all its applications", he predicted in 1863 that England would cease to produce coal within two centuries. As well as advocating the use of hydroelectricity, he also supported solar power, stating that the solar energy received by in tropical areas would "exert the amazing power of 4000 horses acting for nearly nine hours every day"
The benefactor.
Armstrong donated the long wooded gorge of Jesmond Dene to the people of the city of Newcastle upon Tyne in 1883, as well as Armstrong Bridge and Armstrong Park nearby. The University of Newcastle was originally founded by Lord Armstrong in 1871 as the College of Physical Science, later Armstrong College in 1904. He was twice president of the Institution of Mechanical Engineers. Armstrong gave £11,500 towards the building of Newcastle's Hancock Natural History Museum, which was completed in 1882. This was an enormous sum equivalent to over £555,000 in 2010. Lord Armstrong's generosity extended beyond his death. In 1901 his heir, William Watson-Armstrong gave £100,000 (equivalent to £ in ), for the building of the new Royal Victoria Infirmary in Newcastle upon Tyne. Its original 1753 building at Forth Banks near the river Tyne were inadequate and impossible to expand. In 1903 the barony of Armstrong was revived in favour of William Watson-Armstrong.

</doc>
<doc id="60557" url="https://en.wikipedia.org/wiki?curid=60557" title="Emmeline Pankhurst">
Emmeline Pankhurst

Emmeline Pankhurst (née Goulden; 15 July 1858 – 14 June 1928) was a British political activist and leader of the British suffragette movement who helped women win the right to vote. In 1999 "Time" named Pankhurst as one of the , stating: "she shaped an idea of women for our time; she shook society into a new pattern from which there could be no going back." She was widely criticised for her militant tactics, and historians disagree about their effectiveness, but her work is recognised as a crucial element in achieving women's suffrage in Britain.
Born in Moss Side, Manchester to politically active parents, Pankhurst was introduced at the age of 14 to the women's suffrage movement. On 18 December 1879, she married Richard Pankhurst, a barrister 24 years her senior known for supporting women's right to vote; they had five children over the next ten years. He supported her activities outside the home, and she founded and became involved with the Women's Franchise League, which advocated suffrage for both married and unmarried women. When that organisation broke apart, she tried to join the left-leaning Independent Labour Party through her friendship with socialist Keir Hardie but was initially refused membership by the local branch on account of her sex. While working as a Poor Law Guardian, she was shocked at the harsh conditions she encountered in Manchester's workhouses.
In 1903, five years after her husband died, Pankhurst founded the Women's Social and Political Union (WSPU), an all-women suffrage advocacy organisation dedicated to "deeds, not words." The group identified as independent from – and often in opposition to – political parties. It became known for physical confrontations: its members smashed windows and assaulted police officers. Pankhurst, her daughters, and other WSPU activists received repeated prison sentences, where they staged hunger strikes to secure better conditions. As Pankhurst's eldest daughter Christabel took leadership of the WSPU, antagonism between the group and the government grew. Eventually the group adopted arson as a tactic, and more moderate organisations spoke out against the Pankhurst family. In 1913 several prominent individuals left the WSPU, among them Pankhurst's daughters Adela and Sylvia. Emmeline was so furious that she "gave a ticket, £20, and a letter of introduction to a suffragette in Australia, and firmly insisted that she emigrate." Adela complied and the family rift was never healed. Sylvia became a socialist.
With the advent of the First World War, Emmeline and Christabel called an immediate halt to militant suffrage activism in support of the British government's stand against the "German Peril." They urged women to aid industrial production and encouraged young men to fight, becoming prominent figures in the white feather movement. In 1918 the Representation of the People Act granted votes to all men over the age of 21 and women over the age of 30. This discrepancy was intended to ensure that men did not become minority voters as a consequence of the huge number of deaths suffered during the First World War.
Pankhurst transformed the WSPU machinery into the Women's Party, which was dedicated to promoting women's equality in public life. In her later years, she became concerned with what she perceived as the menace posed by Bolshevism and joined the Conservative Party and was selected as a Conservative Party candidate for Stepney in 1927. She died on 14 June 1928, only weeks before the Conservative government's Representation of the People Act (1928) extended the vote to all women over 21 years of age on 2 July 1928. She was commemorated two years later with a statue in London's Victoria Tower Gardens.
Family and birth.
Emmeline Pankhurst was born on 15 July 1858 in the Manchester suburb of Moss Side. Although her birth certificate states otherwise, she believed that her birthday was a day earlier, on Bastille Day. Most biographies, including those written by her daughters, repeat this claim. Feeling a kinship with the female revolutionaries who stormed the Bastille, she said in 1908: "I have always thought that the fact that I was born on that day had some kind of influence over my life." The reason for the discrepancy remains unclear.
The family into which she was born had been steeped in political agitation for generations. Her mother, Sophia Jane Craine, was descended from the Manx people of the Isle of Man and counted among her ancestors men charged with social unrest and slander. In 1881 the Isle of Man was the first country to grant women the right to vote in national elections. Her father, Robert Goulden, came from a modest Manchester merchant family with its own background of political activity. His mother worked with the Anti-Corn Law League, and his father was present at the Peterloo massacre, when cavalry charged and broke up a crowd demanding parliamentary reform.
Their first son died at the age of two, but the Gouldens had ten other children; Emmeline was the eldest of five daughters. Soon after her birth the family moved to Seedley in Pendleton on the outskirts of Salford, where her father had co-founded a small business. Goulden was active in local politics, serving for several years on the Salford Town Council. He was also an enthusiastic supporter of dramatic organisations including the Manchester Athenaeum and the Dramatic Reading Society. He owned a theatre in Salford for several years, where he played the leads in several plays by William Shakespeare. Pankhurst absorbed an appreciation of drama and theatrics from her father, which she used later in social activism.
Childhood.
The Gouldens included their children in social activism. As part of the movement to end slavery in the US, Goulden welcomed American abolitionist Henry Ward Beecher when he visited Manchester. Sophia Jane Goulden used the novel "Uncle Tom's Cabin" – written by Beecher's sister Harriet Beecher Stowe – as a regular source of bedtime stories for their sons and daughters. In her 1914 autobiography "My Own Story," Pankhurst recalls visiting a bazaar at a young age to collect money for newly freed slaves in the United States.
Pankhurst began to read books when she was very young – according to one source, at the age of three. She read the "Odyssey" at the age of nine and enjoyed the works of John Bunyan, especially his 1678 story "The Pilgrim's Progress". Another of her favourite books was Thomas Carlyle's three-volume treatise ""; she later said the work "remained all my life a source of inspiration."
Despite her avid consumption of books, however, Emmeline was not given the educational advantages enjoyed by her brothers. Their parents believed that the girls needed most to learn the art of "making home attractive" and other skills desired by potential husbands. The Gouldens deliberated carefully about future plans for their sons' education, but they expected their daughters to marry young and avoid paid work. Although they supported women's suffrage and the general advancement of women in society, the Gouldens believed their daughters incapable of the goals of their male peers. Feigning sleep one evening as her father came into her bedroom, Emmeline Goulden heard him pause and say to himself: "What a pity she wasn't born a lad."
It was through her parents' interest in women's suffrage that Pankhurst was first introduced to the subject. Her mother received and read the "Women's Suffrage Journal", and Pankhurst grew fond of its editor, Lydia Becker. At the age of 14, she returned home from school one day to find her mother on her way to a public meeting about women's voting rights. After learning that Becker would be speaking, she insisted on attending. Pankhurst was enthralled by Becker's address and wrote later: "I left the meeting a conscious and confirmed suffragist."
A year later she arrived in Paris to attend the École Normale de Neuilly. The school provided its female pupils with classes in chemistry and bookkeeping, in addition to traditionally feminine arts such as embroidery. Her roommate was Noémie, the daughter of Henri Rochefort, who had been imprisoned in New Caledonia for his support of the Paris Commune. The girls shared tales of their parents' political exploits, and remained good friends for years. Pankhurst was so fond of Noémie and the school that after graduating she returned with her sister Mary as a parlour boarder. Noémie had married a Swiss painter and quickly found a suitable French husband for her English friend. When Robert Goulden refused to provide a dowry for his daughter, the man withdrew his offer of marriage and Pankhurst returned, miserable, to Manchester.
Marriage and family.
In the autumn of 1878, at the age of 20, Emmeline Goulden met and began a courtship with Richard Pankhurst, a barrister who had advocated women's suffrage – and other causes, including freedom of speech and education reform – for years. Richard, 44 years old when they met, had earlier resolved to remain a bachelor to better serve the public. Their mutual affection was powerful, but the couple's happiness was diminished by the death of his mother the following year. Sophia Jane Goulden chastised her daughter for "throwing herself" at Richard and urged her without success to exhibit more aloofness. Emmeline suggested to Richard that they avoid the legal formalities of marriage by entering into a free union; he objected on the grounds that she would be excluded from political life as an unmarried woman. He noted that his colleague Elizabeth Wolstenholme Elmy had faced social condemnation before she formalised her marriage to Ben Elmy. Emmeline Goulden agreed, and they were wed in St Luke's Church, Pendleton on 18 December 1879.
During the 1880s, living at the Goulden cottage with her parents in Seedley, Emmeline Pankhurst tended to her husband and children, but still devoted time to political activities. Although she gave birth to five children in ten years, both she and Richard believed that she should not be "a household machine." Thus a servant was hired to help with the children as Pankhurst involved herself with the Women's Suffrage Society. Their daughter Christabel was born on 22 September 1880, less than a year after the wedding. Pankhurst gave birth to another daughter, Estelle Sylvia, in 1882 and their son Francis Henry, nicknamed Frank, in 1884. Soon afterwards Richard Pankhurst left the Liberal Party. He began expressing more radical socialist views and argued a case in court against several wealthy businessmen. These actions roused Robert Goulden's ire and the mood in the house became tense. In 1885 the Pankhursts moved to Chorlton-on-Medlock, and their daughter Adela was born. They moved to London the following year, where Richard ran unsuccessfully for election as a Member of Parliament and Pankhurst opened a small fabric shop called Emerson and Company.
In 1888 Francis developed diphtheria and died on 11 September. Overwhelmed with grief, Pankhurst commissioned two portraits of the dead boy but was unable to look at them and hid them in a bedroom cupboard. The family concluded that a faulty drainage system at the back of their house had caused their son's illness. Pankhurst blamed the poor conditions of the neighbourhood, and the family moved to a more affluent middle class district at Russell Square. She was soon pregnant once more and declared that the child was "Frank coming again." She gave birth to a son on 7 July 1889 and named him Henry Francis in honour of his deceased brother.
Pankhurst made their Russell Square home into a centre for grieving sisters, attracting activists of many types. She took pleasure in decorating the house – especially with furnishings from Asia – and clothing the family in tasteful apparel. Her daughter Sylvia later wrote: "Beauty and appropriateness in her dress and household appointments seemed to her at all times an indispensable setting to public work." The Pankhursts hosted a variety of guests including US abolitionist William Lloyd Garrison, Indian MP Dadabhai Naoroji, socialist activists Herbert Burrows and Annie Besant, and French anarchist Louise Michel.
Women's Franchise League.
In 1888 Britain's first nationwide coalition of groups advocating women's right to vote, the National Society for Women's Suffrage (NSWS), split after a majority of members decided to accept organisations affiliated with political parties. Angry at this decision, some of the group's leaders, including Lydia Becker and Millicent Fawcett, stormed out of the meeting and created an alternative organisation committed to the "old rules," called the Great College Street Society after the location of its headquarters. Pankhurst aligned herself with the "new rules" group, which became known as the Parliament Street Society (PSS). Some members of the PSS favoured a piecemeal approach to gaining the vote. Because it was often assumed that married women did not need the vote since their husbands "voted for them," some PSS members felt that the vote for single women and widows was a practical step along the path to full suffrage. When the reluctance within the PSS to advocate on behalf of married women became clear, Pankhurst and her husband helped organise another new group dedicated to voting rights for all women – married and unmarried.
The inaugural meeting of the Women's Franchise League (WFL) was held on 25 July 1889, at the Pankhurst home in Russell Square. William Lloyd Garrison spoke at the meeting, warning the audience that the US abolition movement had been hampered by individuals advocating moderation and patience. Early members of the WFL included Josephine Butler, leader of the Ladies National Association for the Repeal of the Contagious Diseases Acts; the Pankhursts' friend Elizabeth Wolstenholme Elmy; and Harriot Eaton Stanton Blatch, daughter of US suffragist Elizabeth Cady Stanton.
The WFL was considered a radical organisation, since in addition to women's suffrage it supported equal rights for women in the areas of divorce and inheritance. It also advocated trade unionism and sought alliances with socialist organisations. The more conservative group that emerged from the NSWS split spoke out against what they called the "extreme left" wing of the movement. The WFL reacted by ridiculing the "Spinster Suffrage party" and insisting that a wider assault on social inequity was required. The group's radicalism caused some members to leave; both Blatch and Elmy resigned from the WFL. The group fell apart one year later.
Independent Labour Party.
Pankhurst's shop never succeeded and he had trouble attracting business in London. With the family's finances in jeopardy, Richard travelled regularly to northwest England, where most of his clients were. In 1893 the Pankhursts closed the store and returned to Manchester. They stayed for several months in the seaside town of Southport, then moved briefly to the village of Disley and finally settled into a house in Manchester's Victoria Park. The girls were enrolled in Manchester Girls' High School, where they felt confined by the large student population and strictly regimented schedule.
Pankhurst began to work with several political organisations, distinguishing herself for the first time as an activist in her own right and gaining respect in the community. One biographer describes this period as her "emergence from Richard's shadow." In addition to her work on behalf of women's suffrage, she became active with the Women's Liberal Federation (WLF), an auxiliary of the Liberal Party. She quickly grew disenchanted with the group's moderate positions, however, especially its unwillingness to support Irish Home Rule and the aristocratic leadership of Archibald Primrose.
In 1888 Pankhurst had met and befriended Keir Hardie, a socialist from Scotland. He was elected to parliament in 1891 and two years later helped to create the Independent Labour Party (ILP). Excited about the range of issues which the ILP pledged to confront, Pankhurst resigned from the WLF and applied to join the ILP. The local branch refused her admission on the grounds of her sex, but she eventually joined the ILP nationally. Christabel later wrote of her mother's enthusiasm for the party and its organising efforts: "In this movement she hoped there might be the means of righting every political and social wrong."
One of her first activities with the ILP found Pankhurst distributing food to poor men and women through the Committee for the Relief of the Unemployed. In December 1894 she was elected to the position of Poor Law Guardian in Chorlton-on-Medlock. She was appalled by the conditions she witnessed first-hand in the Manchester workhouse:Pankhurst immediately began to change these conditions, and established herself as a successful voice of reform on the Board of Guardians. Her chief opponent was a passionate man named Mainwaring, known for his rudeness. Recognising that his loud anger was hurting his chances of persuading those aligned with Pankhurst, he kept a note nearby during meetings: "Keep your temper!"
After helping her husband with another unsuccessful parliamentary campaign, Pankhurst faced legal troubles in 1896 when she and two men violated a court order against ILP meetings at Boggart Hole Clough. With Richard's volunteering his time as legal counsel, they refused to pay fines, and the two men spent a month in prison. The punishment was never ordered for Pankhurst, however, possibly because the magistrate feared public backlash against the imprisonment of a woman so respected in the community. Asked by an ILP reporter if she were prepared to spend time in prison, Pankhurst replied: "Oh, yes, quite. It wouldn't be so very dreadful, you know, and it would be a valuable experience." Although ILP meetings were eventually permitted, the episode was a strain on Pankhurst's health and caused loss of income for their family.
Richard's death.
During the struggle at Boggart Hole Clough, Richard Pankhurst began to experience severe stomach pains. He had developed a gastric ulcer, and his health deteriorated in 1897. The family moved briefly to Mobberley, with the hope that country air would help his condition. He soon felt well again, and the family returned to Manchester in the autumn. In the summer of 1898 he suffered a sudden relapse. Pankhurst had taken their oldest daughter Christabel to Corsier, Switzerland, to visit her old friend Noémie. A telegram arrived from Richard, reading: "I am not well. Please come home, my love." Leaving Christabel with Noémie, Pankhurst returned immediately to England. On 5 July, while on a train from London to Manchester, she noticed a newspaper announcing the death of Richard Pankhurst.
The loss of her husband left Pankhurst with new responsibilities and a significant amount of debt. She moved the family to a smaller house, resigned from the Board of Guardians, and was given a paid position as Registrar of Births and Deaths in Chorlton. This work gave her more insight into the conditions of women in the region. She wrote in her autobiography: "They used to tell me their stories, dreadful stories some of them, and all of them pathetic with that patient and uncomplaining pathos of poverty." Her observations of the differences between the lives of men and women, for example in relation to illegitimacy, reinforced her conviction that women needed the right to vote before their conditions could improve. In 1900 she was elected to the Manchester School Board and saw new examples of women suffering unequal treatment and limited opportunities. During this time she also re-opened her store, with the hope that it would provide additional income for the family.
The individual identities of the Pankhurst children began to emerge around the time of their father's death. Before long they were all involved in the struggle for women's suffrage. Christabel enjoyed a privileged status among the daughters, as Sylvia noted in 1931: "She was our mother's favourite; we all knew it, and I, for one, never resented the fact." Christabel did not share her mother's fervour for political work, however, until she befriended the suffrage activists Esther Roper and Eva Gore-Booth. She soon became involved with the suffrage movement and joined her mother at speaking events. Sylvia took lessons from a respected local artist, and soon received a scholarship to the Manchester School of Art. She went on to study art in Florence and Venice. The younger children, Adela and Harry, had difficulty finding a path for their studies. Adela was sent to a local boarding school, where she was cut off from her friends and contracted head lice. Harry also had difficulty at school; he suffered from measles and vision problems.
Women's Social and Political Union.
By 1903 Pankhurst believed that years of moderate speeches and promises about women's suffrage from members of parliament (MPs) had yielded no progress. Although suffrage bills in 1870, 1886, and 1897 had shown promise, each was defeated. She doubted that political parties, with their many agenda items, would ever make women's suffrage a priority. She even broke with the ILP when it refused to focus on Votes for Women. It was necessary to abandon the patient tactics of existing advocacy groups, she believed, in favour of more militant actions. Thus on 10 October 1903 Pankhurst and several colleagues founded the Women's Social and Political Union (WSPU), an organisation open only to women and focused on direct action to win the vote. "Deeds," she wrote later, "not words, was to be our permanent motto."
The group's early militancy took non-violent forms. In addition to making speeches and gathering petition signatures, the WSPU organised rallies and published a newsletter called "Votes for Women." The group also convened a series of "Women's Parliaments" to coincide with official government sessions. When a bill for women's suffrage was filibustered on 12 May 1905, Pankhurst and other WSPU members began a loud protest outside the Parliament building. Police immediately forced them away from the building, where they regrouped and demanded passage of the bill. Although the bill was never resurrected, Pankhurst considered it a successful demonstration of militancy's power to capture attention. Pankhurst declared in 1906: "We are at last recognized as a political party; we are now in the swim of politics, and are a political force."
Before long, all three of her daughters became active with the WSPU. Christabel was arrested after spitting at a policeman during a meeting of the Liberal Party in October 1905; Adela and Sylvia were arrested a year later during a protest outside Parliament. Pankhurst was arrested for the first time in February 1908, when she tried to enter Parliament to deliver a protest resolution to Prime Minister H. H. Asquith. She was charged with obstruction and sentenced to six weeks in prison. She spoke out against the conditions of her confinement, including vermin, meagre food, and the "civilised torture of solitary confinement and absolute silence" to which she and others were ordered. Pankhurst saw imprisonment as a means to publicise the urgency of women's suffrage; in June 1909 she struck a police officer twice in the face to ensure she would be arrested. Pankhurst was arrested seven times before women's suffrage was approved. During her trial on 21 October 1908 she told the court: "We are here not because we are law-breakers; we are here in our efforts to become law-makers."
The exclusive focus of the WSPU on votes for women was another hallmark of its militancy. While other organisations agreed to work with individual political parties, the WSPU insisted on separating itself from – and in many cases opposing – parties which did not make women's suffrage a priority. The group protested against all candidates belonging to the party of the ruling government, since it refused to pass women's suffrage legislation. This brought them into immediate conflict with Liberal Party organisers, particularly since many Liberal candidates supported women's suffrage. (One early target of WSPU opposition was future Prime Minister Winston Churchill; his opponent attributed Churchill's defeat in part to "those ladies who are sometimes laughed at.")
Members of the WSPU were sometimes heckled and derided for spoiling elections for Liberal candidates. On 18 January 1908, Pankhurst and her associate Nellie Martel were attacked by an all-male crowd of Liberal supporters who blamed the WSPU for costing them a recent by-election to the Conservative candidate. The men threw clay, rotten eggs, and stones packed in snow; the women were beaten and Pankhurst's ankle was severely bruised. Similar tensions later formed with Labour. Until party leaders made the vote for women a priority, however, the WSPU vowed to continue its militant activism. Pankhurst and others in the union saw party politics as distracting to the goal of women's suffrage and criticised other organisations for putting party loyalty ahead of women's votes.
As the WSPU gained recognition and notoriety for its actions, Pankhurst resisted efforts to democratise the organisation itself. In 1907 a small group of members led by Teresa Billington-Greig called for more involvement from the rank-and-file suffragettes at the union's annual meetings. In response, Pankhurst announced at a WSPU meeting that elements of the organisation's constitution relating to decision-making were void and cancelled the annual meetings. She also insisted that a small committee chosen by the members in attendance be allowed to co-ordinate WSPU activities. Pankhurst and her daughter Christabel were chosen (along with Mabel Tuke and Emmeline Pethick Lawrence) as members of the new committee. Frustrated, several members including Billington-Greig and Charlotte Despard quit to form their own organisation, the Women's Freedom League. In her 1914 autobiography Pankhurst dismissed criticism of the WSPU's leadership structure:if at any time a member, or a group of members, loses faith in our policy; if any one begins to suggest that some other policy ought to be substituted, or if she tries to confuse the issue by adding other policies, she ceases at once to be a member. Autocratic? Quite so. But, you may object, a suffrage organisation ought to be democratic. Well the members of the W. S. P. U. do not agree with you. We do not believe in the effectiveness of the ordinary suffrage organisation. The W. S. P. U. is not hampered by a complexity of rules. We have no constitution and by-laws; nothing to be amended or tinkered with or quarrelled over at an annual meeting ... The W. S. P. U. is simply a suffrage army in the field.
Tactical intensification.
On 21 June 1908 500,000 activists rallied in Hyde Park to demand votes for women; Asquith and leading MPs responded with indifference. Angered by this intransigence and abusive police activity, some WSPU members increased the severity of their actions. Soon after the rally, twelve women gathered in Parliament Square and tried to deliver speeches for women's suffrage. Police officers seized several of the speakers and pushed them into a crowd of opponents who had gathered nearby. Frustrated, two WSPU members – Edith New and Mary Leigh – went to 10 Downing Street and hurled rocks at the windows of the Prime Minister's home. They insisted their act was independent of WSPU command, but Pankhurst expressed her approval of the action. When a magistrate sentenced New and Leigh to two months' imprisonment, Pankhurst reminded the court of how various male political agitators had broken windows to win legal and civil rights throughout Britain's history.
In 1909 the hunger strike was added to the WSPU's repertoire of resistance. On 24 June Marion Wallace Dunlop was arrested for writing an excerpt from the Bill of Rights (1688 or 1689) on a wall in the House of Commons. Angered by the conditions of the jail, Dunlop went on a hunger strike. When it proved effective, fourteen women imprisoned for smashing windows began to fast. WSPU members soon became known around the country for holding prolonged hunger strikes to protest their incarceration. Prison authorities frequently force-fed the women, using tubes inserted through the nose or mouth. The painful techniques (which, in the case of mouth-feeding, required the use of steel gags to force the mouth open) brought condemnation from suffragists and medical professionals.
These tactics caused some tension between the WSPU and more moderate organisations, which had coalesced into the National Union of Women's Suffrage Societies (NUWSS). That group's leader, Millicent Fawcett, originally hailed WSPU members for their courage and dedication to the cause. By 1912, however, she declared that hunger strikes were mere publicity stunts and that militant activists were "the chief obstacles in the way of success of the suffrage movement in the House of Commons." The NUWSS refused to join a march of women's suffrage groups after demanding without success that the WSPU end its support of property destruction. Fawcett's sister Elizabeth Garrett Anderson later resigned from the WSPU for similar reasons.
Press coverage was mixed; many journalists noted that crowds of women responded positively to speeches by Pankhurst, while others condemned her radical approach to the issue. The "Daily News" urged her to endorse a more moderate approach, and other press outlets condemned the breaking of windows by WSPU members. In 1906 "Daily Mail" journalist Charles Hands referred to militant women using the diminutive term "suffragette" (rather than the standard "suffragist"). Pankhurst and her allies seized the term as their own, and used it to differentiate themselves from moderate groups.
The last half of the century's first decade was a time of sorrow, loneliness and constant work for Pankhurst. In 1907 she sold her home in Manchester and began an itinerant lifestyle, moving from place to place as she spoke and marched for women's suffrage. She stayed with friends and in hotels, carrying her few possessions in suitcases. Although she was energised by the struggle–and found joy in giving energy to others– her constant travelling meant separation from her children, especially Christabel, who had become the national coordinator of the WSPU. In 1909, as Pankhurst planned a speaking tour of the United States, Harry was paralysed after his spinal cord became inflamed. She hesitated to leave the country while he was ill, but she needed money to pay for his treatment and the tour promised to be lucrative. On her return from a successful tour, she sat by Harry's bedside as he died on 5 January 1910. Five days later she buried her son, then spoke before 5,000 people in Manchester. Liberal Party supporters who had come to heckle her remained quiet as she addressed the crowd.
Conciliation, force-feeding, and arson.
After the Liberal losses in the 1910 elections, ILP member and journalist Henry Brailsford helped organise a Conciliation Committee for Women's Suffrage, which gathered 54 MPs from various parties. The group's Conciliation Bill looked to be a narrowly defined but still significant possibility to achieve the vote for women. Thus the WSPU agreed to suspend its support for window-breaking and hunger strikes while it was being negotiated. When it became clear that the bill would not pass, Pankhurst declared: "If the Bill, in spite of our efforts, is killed by the Government, then ... I have to say there is an end to the truce." When it was defeated, Pankhurst led a protest march of 300 women to Parliament Square on 18 November. They were met with aggressive police response, directed by Home Secretary Winston Churchill: officers punched the marchers, twisted arms, and pulled on women's breasts. Although Pankhurst was allowed to enter Parliament, Prime Minister Asquith refused to meet her. The incident became known as Black Friday.
As subsequent Conciliation Bills were introduced, WSPU leaders advocated a halt to militant tactics. In March 1912 the second bill was in jeopardy and Pankhurst joined a fresh outbreak of window-smashing. Extensive property damage led police to raid the WSPU offices. Pankhurst and Emmeline Pethick-Lawrence were tried at the Old Bailey and convicted of conspiracy to commit property damage. Christabel, who by 1912 was the chief coordinator for the organisation, was also wanted by police. She fled to Paris, where she directed WSPU strategy in exile. Inside Holloway Prison Emmeline Pankhurst staged her first hunger strike to improve conditions for other suffragettes in nearby cells; she was quickly joined by Pethick-Lawrence and other WSPU members. She described in her autobiography the trauma caused by force-feeding during the strike: "Holloway became a place of horror and torment. Sickening scenes of violence took place almost every hour of the day, as the doctors went from cell to cell performing their hideous office." When prison officials tried to enter her cell, Pankhurst raised a clay jug over her head and announced: "If any of you dares so much as to take one step inside this cell I shall defend myself."
Pankhurst was spared further force-feeding attempts after this incident, but she continued to violate the law and – when imprisoned – starve herself in protest. During the following two years she was arrested numerous times but was frequently released after several days because of her ill-health. Later, the Asquith government enacted the Cat and Mouse Act, which allowed similar releases for other suffragettes facing ill-health due to hunger strikes. Prison officials recognised the potential public relations disaster that would erupt if the popular WSPU leader were force-fed or allowed to suffer extensively in jail. Still, police officers arrested her during talks and as she marched. She tried to evade police harassment by wearing disguises and eventually the WSPU established a jujutsu-trained female bodyguard squad to physically protect her against the police. She and other escorts were targeted by police, resulting in violent scuffles as officers tried to detain Pankhurst.
In 1912 WSPU members adopted arson as another tactic to win the vote. After Prime Minister Asquith had visited the Theatre Royal in Dublin, suffragette activists Gladys Evans, Mary Leigh, Lizzie Baker and Mabel Capper of Oxford Street, Manchester attempted to cause an explosion using gunpowder and benzine, which resulted in minimal damage. During the same evening Mary Leigh threw an axe at the carriage containing John Redmond, the Lord Mayor, and Prime Minister Asquith. Over the next two years women set fire to a refreshments building in Regent's Park, an orchid house at Kew Gardens, pillar boxes, and a railway carriage. Although Pankhurst confirmed that these women had not been commanded by her or Christabel, they both assured the public that they supported the arsonist suffragettes. There were similar incidents around the country. One WSPU member, for example, put a small hatchet into the Prime Minister's carriage inscribed with the words: "Votes for Women," and other suffragettes used acid to burn the same slogan into golf courses used by MPs. In 1914 Mary Richardson slashed the Velasquez painting "Rokeby Venus" to protest against Pankhurst's imprisonment.
Defection and dismissal.
The WSPU's approval of property destruction led to the departure of several important members. The first were Emmeline Pethick-Lawrence and her husband Frederick. They had long been integral members of the group's leadership but found themselves in conflict with Christabel about the wisdom of such volatile tactics. After returning from a vacation in Canada they found that Pankhurst had expelled them from the WSPU. The pair found the decision appalling, but to avoid a schism in the movement they continued to praise Pankhurst and the organisation in public. Around the same time, Emmeline's daughter Adela left the group. She disapproved of WSPU endorsement of property destruction and felt that a heavier emphasis on socialism was necessary. Adela's relationship with her family – especially Christabel – was also strained as a result.
The deepest rift in the Pankhurst family came in November 1913 when Sylvia spoke at a meeting of socialists and trade unionists in support of labour organiser Jim Larkin. She had been working with the East London Federation of Suffragettes (ELFS), a local branch of the WSPU which had a close relationship with socialists and organised labour. The close connection to labour groups and Sylvia's appearance on stage with Frederick Pethick-Lawrence – who also addressed the crowd – convinced Christabel that her sister was organising a group that might challenge the WSPU in the suffrage movement. The dispute became public, and members of groups including the WSPU, ILP, and ELFS braced themselves for a showdown.
In January Sylvia was summoned to Paris, where Emmeline and Christabel were waiting. Their mother had just returned from another tour of the US, and Sylvia had just been released from prison. All three women were exhausted and stressed, which added considerably to the tension. In her 1931 book "The Suffrage Movement" Sylvia describes Christabel as an unreasonable figure, haranguing her for refusing to toe the WSPU line:She turned to me. "You have your own ideas. We do not want that; we want all our women to take their instructions and walk in step like an army!" Too tired, too ill to argue, I made no reply. I was oppressed by a sense of tragedy, grieved by her ruthlessness. Her glorification of autocracy seemed to me remote indeed from the struggle we were waging, the grim fight even now proceeding in the cells. I thought of many others who had been thrust aside for some minor difference.With their mother's blessing, Christabel ordered Sylvia's group to dissociate from the WSPU. Pankhurst tried to persuade the ELFS to remove the word "suffragettes" from its name, since it was inextricably linked to the WSPU. When Sylvia refused, her mother switched to fierce anger in a letter:You are unreasonable, always have been & I fear always will be. I suppose you were made so! ... Had you chosen a name which we could approve we could have done much to launch you & advertise your society by name. Now you must take your own way of doing so. I am sorry but you make your own difficulties by an incapacity to look at situations from other people's point of view as well as your own. Perhaps in time you will learn the lessons that we all have to learn in life.Adela, unemployed and unsure of her future, had become a worry for Pankhurst as well. She decided that Adela should move to Australia, and paid for her relocation. They never saw one another again.
First World War.
When the First World War began in August 1914, Emmeline and Christabel considered that the threat posed by Germany was a danger to all humanity, and that the British government needed the support of all citizens. They persuaded the WSPU to halt all militant suffrage activities until fighting on the European mainland ended. It was no time for dissent or agitation; Christabel wrote later: "This was national militancy. As Suffragists we could not be pacifists at any price." A truce with the government was established, all WSPU prisoners were released, and Christabel returned to London. Emmeline and Christabel set the WSPU into motion on behalf of the war effort. In her first speech after returning to Britain, Christabel warned of the "German Peril". She urged the gathered women to follow the example of their French sisters, who – while the men fought – "are able to keep the country going, to get in the harvest, to carry on the industries". Emmeline urged men to volunteer for the front lines.
Sylvia and Adela, meanwhile, did not share their mother's enthusiasm for the war. As committed pacifists, they rejected the WSPU's support for the government. Sylvia's socialist perspective convinced her that the war was another example of capitalist oligarchs exploiting poor soldiers and workers. Adela, meanwhile, spoke against the war in Australia and made public her opposition to conscription. In a short letter, Emmeline told Sylvia: "I am ashamed to know where you and Adela stand." She had a similar impatience for dissent within the WSPU; when long-time member Mary Leigh asked a question during a meeting in October 1915, Pankhurst replied: "hat woman is a pro German and should leave the hall. ... I denounce you as a pro German and wish to forget that such a person ever existed." Some WSPU members were outraged by this sudden rigid devotion to the government, the leadership's perceived abandonment of efforts to win the vote for women, and questions about how funds collected on behalf of suffrage were being managed with regard to the organisation's new focus. Two groups split from the WSPU: The Suffragettes of the Women's Social and Political Union (SWSPU) and the Independent Women's Social and Political Union (IWSPU), each dedicated to maintaining pressure toward women's suffrage.
Pankhurst put the same energy and determination she had previously applied to women's suffrage into patriotic advocacy of the war effort. She organised rallies, toured constantly delivering speeches, and lobbied the government to help women enter the work force while men were overseas fighting. Another issue which concerned her greatly at the time was the plight of so-called war babies, children born to single mothers whose fathers were on the front lines. Pankhurst established an adoption home at Campden Hill designed to employ the Montessori method of childhood education. Some women criticised Pankhurst for offering relief to parents of children born out of wedlock, but she declared indignantly that the welfare of children–whose suffering she had seen firsthand as a Poor Law Guardian–was her only concern. Due to lack of funds, however, the home was soon turned over to Princess Alice. Pankhurst herself adopted four children, whom she renamed Kathleen King, Flora Mary Gordon, Joan Pembridge and Elizabeth Tudor. They lived in London, where–for the first time in many years–she had a permanent home, at Holland Park. Asked how, at the age of 57 and with no steady income, she could take on the burden of bringing up four more children, Pankhurst replied: "My dear, I wonder I didn't take forty."
Russian delegation.
Pankhurst visited North America in 1916 together with the former Secretary of State for Serbia, Čedomilj Mijatović, whose nation had been at the centre of fighting at the start of the war. They toured the United States and Canada, raising money and urging the US government to support Britain and its Canadian and other allies. Two years later, after the US entered the war, Pankhurst returned to the United States, encouraging suffragettes there – who had not suspended their militancy – to support the war effort by sidelining activities related to the vote. She also spoke about her fears of communist insurgency, which she considered a grave threat to Russian democracy.
By June 1917 the Russian Revolution had strengthened the Bolsheviks, who urged an end to the war. Pankhurst's translated autobiography had been read widely in Russia, and she saw an opportunity to put pressure on the Russian people. She hoped to convince them not to accept Germany's conditions for peace, which she saw as a potential defeat for Britain and Russia. UK Prime Minister David Lloyd George agreed to sponsor her trip to Russia, which she took in June. She told one crowd: "I came to Petrograd with a prayer from the English nation to the Russian nation, that you may continue the war on which depends the face of civilisation and freedom." Press response was divided between left and right wings; the former depicted her as a tool of capitalism, while the latter praised her devout patriotism.
In August she met with Alexander Kerensky, the Russian Prime Minister. Although she had been active with the socialist-leaning ILP in years past, Pankhurst had begun to see leftist politics as disagreeable, an attitude which intensified while she was in Russia. The meeting was uncomfortable for both parties; he felt that she was unable to appreciate the class-based conflict driving Russian policy at the time. He concluded by telling her that English women had nothing to teach women in Russia. She later told the "New York Times" that he was the "biggest fraud of modern times" and that his government could "destroy civilisation."
Accomplishment of suffrage (1918).
When she returned from Russia, Pankhurst was delighted to find that women's right to vote was finally on its way to becoming a reality. The 1918 Representation of the People Act removed property restrictions on men's suffrage and granted the vote to women over the age of 30 (with several restrictions). As suffragists and suffragettes celebrated and prepared for its imminent passage, a new schism erupted: should women's political organisations join forces with those established by men? Many socialists and moderates supported unity of the sexes in politics, but Emmeline and Christabel Pankhurst saw the best hope in remaining separate. They reinvented the WSPU as the Women's Party, still open only to women. Women, they said, "can best serve the nation by keeping clear of men's party political machinery and traditions, which, by universal consent, leave so much to be desired." The party favoured equal marriage laws, equal pay for equal work, and equal job opportunities for women. These were matters for the post-war era, however. While the fighting continued the Women's Party demanded no compromise in the defeat of Germany; the removal from government of anyone with family ties to Germany or pacifist attitudes; and shorter work hours to forestall labour strikes. This last plank in the party's platform was meant to discourage potential interest in Bolshevism, about which Pankhurst was increasingly anxious.
Post-war activities.
In the years after the 1918 Armistice, Pankhurst continued to promote her nationalist vision of British unity. She maintained a focus on women's empowerment, but her days of fighting with government officialdom were over. She defended the presence and reach of the British Empire: "Some talk about the Empire and Imperialism as if it were something to decry and something to be ashamed of. t is a great thing to be the inheritors of an Empire like ours ... great in territory, great in potential wealth. ... If we can only realise and use that potential wealth we can destroy thereby poverty, we can remove and destroy ignorance." For years she travelled around England and North America, rallying support for the British Empire and warning audiences about the dangers of Bolshevism.
Emmeline Pankhurst also became active in political campaigning again when a bill was passed allowing women to run for the House of Commons. Many Women's Party members urged Pankhurst to stand for election, but she insisted that Christabel was a better choice. She campaigned tirelessly for her daughter, lobbying Prime Minister Lloyd George for his support and at one point delivering a passionate speech in the rain. Christabel lost by a very slim margin to the Labour Party candidate, and the recount showed a difference of 775 votes. One biographer called it "the bitterest disappointment of Emmeline's life." The Women's Party withered from existence soon afterward.
As a result of her many trips to North America, Pankhurst became fond of Canada, stating in an interview that "there seems to be more equality between men and women than in any other country I know." In 1922 she applied for Canadian "permission to land" (a prerequisite to status as a "British Subject with Canadian Domicile") and rented a house in Toronto, where she moved with her four adopted children. She became active with the Canadian National Council for Combating Venereal Diseases (CNCCVD), which worked against the sexual double-standard which Pankhurst considered particularly harmful to women. During a tour of Bathurst, the mayor showed her a new building which would become the Home for Fallen Women. Pankhurst replied: "Ah! Where is your Home for Fallen Men?" Before long, however, she grew tired of long Canadian winters, and she ran out of money. She returned to England in late 1925.
Back in London Emmeline was visited by Sylvia, who had not seen her mother in years. Their politics were by now very different, and Sylvia was living, unmarried, with an Italian anarchist. Sylvia described a moment of familial affection when they met, followed by a sad distance between them. Emmeline's adopted daughter Mary, however, remembered the meeting differently. According to her version, Emmeline set her teacup down and walked silently out of the room, leaving Sylvia in tears. Christabel, meanwhile, had become a convert to Adventism and devoted much of her time to the church. The British press sometimes made light of the varied paths followed by the once indivisible family.
In 1926 Pankhurst joined the Conservative Party and two years later ran as a candidate for Parliament in Whitechapel and St George's. Her transformation from a fiery supporter of the ILP and window-smashing radical to an official Conservative Party member surprised many people. She replied succinctly: "My war experience and my experience on the other side of the Atlantic have changed my views considerably." Her biographers insist that the move was more complex; she was devoted to a programme of women's empowerment and anti-communism. Both the Liberal and Labour parties bore grudges for her work against them in the WSPU, and the Conservative Party had a victorious record after the war and a significant majority. Pankhurst's membership of the Conservative Party may have had as much to do with ensuring her aims of obtaining the vote for women were achieved as with ideology.
Illness and death.
Emmeline Pankhurst's campaign for Parliament was pre-empted by her ill health and a final scandal involving Sylvia. The years of touring, lectures, imprisonment and hunger strikes had taken their toll; fatigue and illness became a regular part of Pankhurst's life. Even more painful, however, was the news in April 1928 that Sylvia had given birth out of wedlock. She had named the child Richard Keir Pethick Pankhurst, in memory of her father, her ILP comrade, and her colleagues from the WSPU respectively. Emmeline was further shocked to see a report from a newspaper in the US that declared that "Miss Pankhurst" – a title usually reserved for Christabel – boasted of her child being a triumph of "eugenics," since both parents were healthy and intelligent. In the article, Sylvia also spoke of her belief that "marriage without legal union" was the most sensible option for liberated women. These offences against the social dignity which Pankhurst had always valued devastated the elderly woman; to make matters worse, many people believed the "Miss Pankhurst" in newspaper headlines referred to Christabel. After hearing the news, Emmeline spent an entire day crying; her campaign for Parliament ended with the scandal.
As her health went downhill, Emmeline Pankhurst moved into a nursing home in Hampstead. She requested that she be treated by the doctor who attended to her during her hunger strikes. His use of the stomach pump had helped her feel better while in prison; her nurses were sure that the shock of such treatment would severely wound her, but Christabel felt obligated to carry out her mother's request. Before the procedure could be carried out, however, she fell into a critical condition from which none expected her to recover. On Thursday 14 June 1928 Pankhurst died, at the age of 69. She was interred in Brompton Cemetery in London.
Legacy.
News of Emmeline Pankhurst's death was announced around the country, and extensively in North America. Her funeral service on 18 June was filled with her former WSPU colleagues and those who had worked beside her in various capacities. The "Daily Mail" described the procession as "like a dead general in the midst of a mourning army." Women wore WSPU sashes and ribbons, and the organisation's flag was carried alongside the Union Flag. Christabel and Sylvia appeared together at the service, the latter with her child. Adela did not attend. Press coverage around the world recognised her tireless work on behalf of women's right to vote – even if they didn't agree on the value of her contributions. The "New York Herald Tribune" called her "the most remarkable political and social agitator of the early part of the twentieth century and the supreme protagonist of the campaign for the electoral enfranchisement of women."
Shortly after the funeral, one of Pankhurst's bodyguards from her WSPU days, Katherine Marshall, began raising funds for a memorial statue. In spring 1930 her efforts bore fruit, and on 6 March her statue in Victoria Tower Gardens was unveiled. A crowd of radicals, former suffragettes, and national dignitaries gathered as former Prime Minister Stanley Baldwin presented the memorial to the public. In his address, Baldwin declared: "I say with no fear of contradiction, that whatever view posterity may take, Mrs. Pankhurst has won for herself a niche in the Temple of Fame which will last for all time." Sylvia was the only Pankhurst daughter in attendance; Christabel, touring North America, sent a telegram which was read aloud. While planning the agenda for the day, Marshall had intentionally excluded Sylvia, who in her opinion had hastened Pankhurst's death.
During the twentieth century Emmeline Pankhurst's value to the movement for women's suffrage was debated passionately, and no consensus was achieved. Her daughters Sylvia and Christabel weighed in with books, scornful and laudatory respectively, about their time in the struggle. Sylvia's 1931 book "The Suffrage Movement" describes her mother's political shift at the start of the First World War as the beginning of a betrayal of her family (especially her father) and the movement. It set the tone for much of the socialist and activist history written about the WSPU and particularly solidified Emmeline Pankhurst's reputation as an unreasonable autocrat. Christabel's ""Unshackled: The Story of How We Won the Vote,"" released in 1959, paints her mother as generous and selfless to a fault, offering herself completely to the most noble causes. It provided a sympathetic counterpart to Sylvia's attacks and continued the polarised discussion; detached and objective assessment has rarely been a part of Pankhurst scholarship.
Recent biographies show that historians differ about whether Emmeline Pankhurst's militancy helped or hurt the movement; however, there is general agreement that the WSPU raised public awareness of the movement in ways that proved essential. Baldwin compared her to Martin Luther and Jean-Jacques Rousseau: individuals who were not the sum total of the movements in which they took part, but who nevertheless played crucial roles in struggles of social and political reform. In the case of Pankhurst, this reform took place in both intentional and unintentional ways. By defying the roles of wife and mother as the docile companion, Pankhurst paved the way for feminists who would later decry her support for empire and sustainable social values.
Emmeline Pankhurst's importance to the United Kingdom was demonstrated again in 1929, when a portrait of her was added to the National Portrait Gallery. In 1987 one of her homes in Manchester was opened as the Pankhurst Centre, an all-women gathering space and museum. In 2002, Pankhurst was placed at number 27 in the BBC's poll of the 100 Greatest Britons.
In January 2016, following a public vote, it was announced that a statue of Emmeline Pankhurst would be unveiled in Manchester in 2019; the first woman to be honoured with a statue in the city since Queen Victoria over 100 years ago.
In popular culture.
The BBC dramatised the life of Emmeline Pankhurst in the six-part serial "Shoulder to Shoulder" in 1974, with Welsh actress Siân Phillips in the role. In the 2015 film "Suffragette" Pankhurst played by Meryl Streep appears in several scenes.

</doc>
<doc id="60558" url="https://en.wikipedia.org/wiki?curid=60558" title="ARM architecture">
ARM architecture

ARM, originally Acorn RISC Machine, later Advanced RISC Machine, is a family of reduced instruction set computing (RISC) architectures for computer processors, configured for various environments. British company ARM Holdings develops the architecture and licenses it to other companies, who design their own products that implement one of those architecturesincluding systems-on-chips (SoC) that incorporate memory, interfaces, radios, etc. It also designs cores that implement this instruction set and licenses these designs to a number of companies that incorporate those core designs into their own products.
A RISC-based computer design approach means processors require fewer transistors than typical complex instruction set computing (CISC) x86 processors in most personal computers. This approach reduces costs, heat and power use. Such reductions are desirable traits for light, portable, battery-powered devicesincluding smartphones, laptops, tablet and notepad computers, and other embedded systems.
The company periodically releases updates to its cores. All cores from ARM Holdings support a 32-bit address space (only pre-ARMv3 chips, as in original Acorn Archimedes, had smaller) and 32-bit arithmetic; the ARMv8-A architecture, announced in October 2011, adds support for a 64-bit address space and 64-bit arithmetic. Instructions for ARM Holdings' cores have 32 bits wide fixed-length instructions, but later versions of the architecture also support a variable-length instruction set that provides both 32- and 16-bit wide instructions for improved code density. Some cores can also provide hardware execution of Java bytecodes.
With over 50 billion ARM processors produced , ARM is the most widely used instruction set architecture in terms of quantity produced. Currently, the widely used Cortex cores, older "classic" cores, and specialized SecurCore cores variants are available for each of these to include or exclude optional capabilities.
History.
The British computer manufacturer Acorn Computers first developed the Acorn RISC Machine architecture (ARM) in the 1980s to use in its personal computers. Its first ARM-based products were coprocessor modules for the BBC Micro series of computers. After the successful BBC Micro computer, Acorn Computers considered how to move on from the relatively simple MOS Technology 6502 processor to address business markets like the one that was soon dominated by the IBM PC, launched in 1981. The "Acorn Business Computer" (ABC) plan required that a number of second processors be made to work with the BBC Micro platform, but processors such as the Motorola 68000 and National Semiconductor 32016 were considered unsuitable, and the 6502 was not powerful enough for a graphics based user interface.
According to Sophie Wilson, all the tested processors at that time performed about the same, with about a 4 Mbit/second bandwidth.
After testing all available processors and finding them lacking, Acorn decided it needed a new architecture. Inspired by white papers on the Berkeley RISC project, Acorn considered designing its own processor. A visit to the Western Design Center in Phoenix, where the 6502 was being updated by what was effectively a single-person company, showed Acorn engineers Steve Furber and Sophie Wilson they did not need massive resources and state-of-the-art research and development facilities.
Wilson developed the instruction set, writing a simulation of the processor in BBC BASIC that ran on a BBC Micro with a second 6502 processor. This convinced Acorn engineers they were on the right track. Wilson approached Acorn's CEO, Hermann Hauser, and requested more resources. Hauser gave his approval and assembled a small team to implement Wilson's model in hardware.
Acorn RISC Machine: ARM2.
The official "Acorn RISC Machine" project started in October 1983. They chose VLSI Technology as the "silicon partner", as they were a source of ROMs and custom chips for Acorn. Wilson and Furber led the design. They implemented it with a similar efficiency ethos as the 6502. A key design goal was achieving low-latency input/output (interrupt) handling like the 6502. The 6502's memory access architecture had let developers produce fast machines without costly direct memory access hardware.
The first samples of ARM silicon worked properly when first received and tested on 26 April 1985.
The first ARM application was as a second processor for the BBC Micro, where it helped in developing simulation software to finish development of the support chips (VIDC, IOC, MEMC), and sped up the CAD software used in ARM2 development. Wilson subsequently rewrote BBC BASIC in ARM assembly language. The in-depth knowledge gained from designing the instruction set enabled the code to be very dense, making ARM BBC BASIC an extremely good test for any ARM emulator. The original aim of a principally ARM-based computer was achieved in 1987 with the release of the Acorn Archimedes. In 1992, Acorn once more won the Queen's Award for Technology for the ARM.
The ARM2 featured a 32-bit data bus, 26-bit address space and 27 32-bit registers. Eight bits from the program counter register were available for other purposes; the top six bits (available because of the 26-bit address space) served as status flags, and the bottom two bits (available because the program counter was always word-aligned) were used for setting modes. The address bus was extended to 32 bits in the ARM6, but program code still had to lie within the first 64 MB of memory in 26-bit compatibility mode, due to the reserved bits for the status flags. The ARM2 had a transistor count of just 30,000, compared to Motorola's six-year-older 68000 model with around 40,000. Much of this simplicity came from the lack of microcode (which represents about one-quarter to one-third of the 68000) and from (like most CPUs of the day) not including any cache. This simplicity enabled low power consumption, yet better performance than the Intel 80286. A successor, ARM3, was produced with a 4 KB cache, which further improved performance.
Apple, DEC, Intel, Marvell: ARM6, StrongARM, XScale.
In the late 1980s Apple Computer and VLSI Technology started working with Acorn on newer versions of the ARM core. In 1990, Acorn spun off the design team into a new company named Advanced RISC Machines Ltd., which became ARM Ltd when its parent company, ARM Holdings plc, floated on the London Stock Exchange and NASDAQ in 1998.
The new Apple-ARM work would eventually evolve into the ARM6, first released in early 1992. Apple used the ARM6-based ARM610 as the basis for their Apple Newton PDA. In 1994, Acorn used the ARM610 as the main central processing unit (CPU) in their RiscPC computers. DEC licensed the ARM6 architecture and produced the StrongARM. At 233 MHz, this CPU drew only one watt (newer versions draw far less). This work was later passed to Intel as a part of a lawsuit settlement, and Intel took the opportunity to supplement their i960 line with the StrongARM. Intel later developed its own high performance implementation named XScale, which it has since sold to Marvell. Transistor count of the ARM core remained essentially the same size throughout these changes; ARM2 had 30,000 transistors, while ARM6 grew only to 35,000.
Market share.
In 2005, about 98% of all mobile phones sold used at least one ARM processor. In 2010, producers of chips based on ARM architectures reported shipments of 6.1 billion ARM-based processors, representing 95% of smartphones, 35% of digital televisions and set-top boxes and 10% of mobile computers. In 2011, the 32-bit ARM architecture was the most widely used architecture in mobile devices and the most popular 32-bit one in embedded systems. In 2013, 10 billion were produced and "ARM-based chips are found in nearly 60 percent of the world’s mobile devices".
Licensing.
Core licence.
ARM Holdings' primary business is selling IP cores, which licensees use to create microcontrollers (MCUs), CPUs, and systems-on-chips based on those cores. The original design manufacturer combines the ARM core with other parts to produce a complete device, typically one that can be built in existing semiconductor fabs at low cost and still deliver substantial performance. The most successful implementation has been the ARM7TDMI with hundreds of millions sold. Atmel has been a precursor design center in the ARM7TDMI-based embedded system.
The ARM architectures used in smartphones, PDAs and other mobile devices range from ARMv5 to ARMv6, used in low-end devices, to ARMv7-A used in current high-end devices. ARMv7 includes a hardware floating-point unit (FPU), with improved speed compared to software-based floating-point.
In 2009, some manufacturers introduced netbooks based on ARM architecture CPUs, in direct competition with netbooks based on Intel Atom. According to analyst firm IHS iSuppli, by 2015, ARM ICs may be in 23% of all laptops.
ARM Holdings offers a variety of licensing terms, varying in cost and deliverables. ARM Holdings provides to all licensees an integratable hardware description of the ARM core as well as complete software development toolset (compiler, debugger, software development kit) and the right to sell manufactured silicon containing the ARM CPU.
SoC packages integrating ARM's core designs include Nvidia Tegra's first three generations, CSR plc's Quatro family, ST-Ericsson's Nova and NovaThor, Silicon Labs's Precision32 MCU, Texas Instruments's OMAP products, Samsung's Hummingbird and Exynos products, Apple's A4, A5, and A5X, and Freescale's i.MX.
Fabless licensees, who wish to integrate an ARM core into their own chip design, are usually only interested in acquiring a ready-to-manufacture verified IP core. For these customers, ARM Holdings delivers a gate netlist description of the chosen ARM core, along with an abstracted simulation model and test programs to aid design integration and verification. More ambitious customers, including integrated device manufacturers (IDM) and foundry operators, choose to acquire the processor IP in synthesizable RTL (Verilog) form. With the synthesizable RTL, the customer has the ability to perform architectural level optimisations and extensions. This allows the designer to achieve exotic design goals not otherwise possible with an unmodified netlist (high clock speed, very low power consumption, instruction set extensions, etc.). While ARM Holdings does not grant the licensee the right to resell the ARM architecture itself, licensees may freely sell manufactured product such as chip devices, evaluation boards and complete systems. Merchant foundries can be a special case; not only are they allowed to sell finished silicon containing ARM cores, they generally hold the right to re-manufacture ARM cores for other customers.
ARM Holdings prices its IP based on perceived value. Lower performing ARM cores typically have lower licence costs than higher performing cores. In implementation terms, a synthesizable core costs more than a hard macro (blackbox) core. Complicating price matters, a merchant foundry that holds an ARM licence, such as Samsung or Fujitsu, can offer fab customers reduced licensing costs. In exchange for acquiring the ARM core through the foundry's in-house design services, the customer can reduce or eliminate payment of ARM's upfront licence fee.
Compared to dedicated semiconductor foundries (such as TSMC and UMC) without in-house design services, Fujitsu/Samsung charge two- to three-times more per manufactured wafer. For low to mid volume applications, a design service foundry offers lower overall pricing (through subsidisation of the licence fee). For high volume mass-produced parts, the long term cost reduction achievable through lower wafer pricing reduces the impact of ARM's NRE (Non-Recurring Engineering) costs, making the dedicated foundry a better choice.
Companies that have designed chips with ARM cores include Amazon.com's Annapurna Labs subsidiary, Analog Devices, Apple, AppliedMicro, Atmel, Broadcom, Cypress Semiconductor, Freescale Semiconductor (now NXP Semiconductors), Nvidia, NXP, Qualcomm, Renesas, Samsung Electronics, ST Microelectronics and Texas Instruments.
Architectural licence.
Companies can also obtain an ARM "architectural licence" for designing their own CPU cores using the ARM instruction sets. These cores must comply fully with the ARM architecture. Companies that have designed cores that implement an ARM architecture include Apple, AppliedMicro, Broadcom, Nvidia, Qualcomm, and Samsung Electronics.
Cores.
ARM Holdings provides a list of vendors who implement ARM cores in their design (application specific standard products (ASSP), microprocessor and microcontrollers).
Example applications of ARM cores.
ARM cores are used in a number of products, particularly PDAs and smartphones. Some computing examples are Microsoft's first generation Surface and Surface 2, Apple's iPads, and Asus's Eee Pad Transformer tablet computers. Others include Apple's iPhone smartphone and iPod portable media player, Canon PowerShot digital cameras, Nintendo DS handheld game consoles and TomTom turn-by-turn navigation systems.
In 2005, ARM Holdings took part in the development of Manchester University's computer SpiNNaker, which used ARM cores to simulate the human brain.
ARM chips are also used in Raspberry Pi, BeagleBoard, BeagleBone, PandaBoard and other single-board computers, because they are very small, inexpensive and consume very little power.
32-bit architecture.
The 32-bit ARM architecture, such as ARMv7-A, is the most widely used architecture in mobile devices.
Since 1995, the "ARM Architecture Reference Manual" has been the primary source of documentation on the ARM processor architecture and instruction set, distinguishing interfaces that all ARM processors are required to support (such as instruction semantics) from implementation details that may vary. The architecture has evolved over time, and version seven of the architecture, ARMv7, defines three architecture "profiles":
Although the architecture profiles were first defined for ARMv7, ARM subsequently defined the ARMv6-M architecture (used by the Cortex M0/M0+/M1) as a subset of the ARMv7-M profile with fewer instructions.
CPU modes.
Except in the M-profile, the 32-bit ARM architecture specifies several CPU modes, depending on the implemented architecture features. At any moment in time, the CPU can be in only one mode, but it can switch modes due to external events (interrupts) or programmatically.
Instruction set.
The original (and subsequent) ARM implementation was hardwired without microcode, like the much simpler 8-bit 6502 processor used in prior Acorn microcomputers.
The 32-bit ARM architecture (and the 64-bit architecture for the most part) includes the following RISC features:
To compensate for the simpler design, compared with processors like the Intel 80286 and Motorola 68020, some additional design features were used:
Arithmetic instructions.
ARM includes integer arithmetic operations for add, subtract, and multiply; some versions of the architecture also support divide operations.
ARM supports 32-bit x 32-bit multiplies with either a 32-bit result or 64-bit result, though Cortex-M0 / M0+ / M1 cores don't support 64-bit results. Some ARM cores also support 16-bit x 16-bit and 32-bit x 16-bit multiplies.
The divide instructions are only included in the following ARM architectures:
Registers.
Registers R0 through R7 are the same across all CPU modes; they are never banked.
Registers R8 through R12 are the same across all CPU modes except FIQ mode. FIQ mode has its own distinct R8 through R12 registers.
R13 and R14 are banked across all privileged CPU modes except system mode. That is, each mode that can be entered because of an exception has its own R13 and R14. These registers generally contain the stack pointer and the return address from function calls, respectively.
Aliases:
The Current Program Status Register (CPSR) has the following 32 bits.
Conditional execution.
Almost every ARM instruction has a conditional execution feature called predication, which is implemented with a 4-bit condition code selector (the predicate). To allow for unconditional execution, one of the four-bit codes causes the instruction to be always executed. Most other CPU architectures only have condition codes on branch instructions.
Though the predicate takes up four of the 32 bits in an instruction code, and thus cuts down significantly on the encoding bits available for displacements in memory access instructions, it avoids branch instructions when generating code for small codice_1 statements. Apart from eliminating the branch instructions themselves, this preserves the fetch/decode/execute pipeline at the cost of only one cycle per skipped instruction.
The standard example of conditional execution is the subtraction-based Euclidean algorithm:
In the C programming language, the loop is:
In ARM assembly, the loop is transformed into:
and coded as:
which avoids the branches around the codice_2 and codice_3 clauses.
If codice_4 and codice_5 are equal then neither of the codice_6 instructions will be executed, eliminating the need for a conditional branch to implement the codice_7 check at the top of the loop, for example had codice_8 (less than or equal) been used.
One of the ways that Thumb code provides a more dense encoding is to remove the four bit selector from non-branch instructions.
Other features.
Another feature of the instruction set is the ability to fold shifts and rotates into the "data processing" (arithmetic, logical, and register-register move) instructions, so that, for example, the C statement
could be rendered as a single-word, single-cycle instruction:
This results in the typical ARM program being denser than expected with fewer memory accesses; thus the pipeline is used more efficiently.
The ARM processor also has features rarely seen in other RISC architectures, such as PC-relative addressing (indeed, on the 32-bit ARM the PC is one of its 16 registers) and pre- and post-increment addressing modes.
The ARM instruction set has increased over time. Some early ARM processors (before ARM7TDMI), for example, have no instruction to store a two-byte quantity.
Pipelines and other implementation issues.
The ARM7 and earlier implementations have a three-stage pipeline; the stages being fetch, decode and execute. Higher-performance designs, such as the ARM9, have deeper pipelines: Cortex-A8 has thirteen stages. Additional implementation changes for higher performance include a faster adder and more extensive branch prediction logic. The difference between the ARM7DI and ARM7DMI cores, for example, was an improved multiplier; hence the added "M".
Coprocessors.
The ARM architecture (pre-ARMv8) provides a non-intrusive way of extending the instruction set using "coprocessors" that can be addressed using MCR, MRC, MRRC, MCRR, and similar instructions. The coprocessor space is divided logically into 16 coprocessors with numbers from 0 to 15, coprocessor 15 (cp15) being reserved for some typical control functions like managing the caches and MMU operation on processors that have one.
In ARM-based machines, peripheral devices are usually attached to the processor by mapping their physical registers into ARM memory space, into the coprocessor space, or by connecting to another device (a bus) that in turn attaches to the processor. Coprocessor accesses have lower latency, so some peripherals—for example an XScale interrupt controller—are accessible in both ways: through memory and through coprocessors.
In other cases, chip designers only integrate hardware using the coprocessor mechanism. For example, an image processing engine might be a small ARM7TDMI core combined with a coprocessor that has specialised operations to support a specific set of HDTV transcoding primitives.
Debugging.
All modern ARM processors include hardware debugging facilities, allowing software debuggers to perform operations such as halting, stepping, and breakpointing of code starting from reset. These facilities are built using JTAG support, though some newer cores optionally support ARM's own two-wire "SWD" protocol. In ARM7TDMI cores, the "D" represented JTAG debug support, and the "I" represented presence of an "EmbeddedICE" debug module. For ARM7 and ARM9 core generations, EmbeddedICE over JTAG was a de facto debug standard, though not architecturally guaranteed.
The ARMv7 architecture defines basic debug facilities at an architectural level. These include breakpoints, watchpoints and instruction execution in a "Debug Mode"; similar facilities were also available with EmbeddedICE. Both "halt mode" and "monitor" mode debugging are supported. The actual transport mechanism used to access the debug facilities is not architecturally specified, but implementations generally include JTAG support.
There is a separate ARM "CoreSight" debug architecture, which is not architecturally required by ARMv7 processors.
DSP enhancement instructions.
To improve the ARM architecture for digital signal processing and multimedia applications, DSP instructions were added to the set. These are signified by an "E" in the name of the ARMv5TE and ARMv5TEJ architectures. E-variants also imply T, D, M and I.
The new instructions are common in digital signal processor architectures. They include variations on signed multiply–accumulate, saturated add and subtract, and count leading zeros.
SIMD extensions for multimedia.
Introduced in the ARMv6 architecture, this was a precursor to Advanced SIMD, also known as NEON.
Jazelle.
Jazelle DBX (Direct Bytecode eXecution) is a technique that allows Java Bytecode to be executed directly in the ARM architecture as a third execution state (and instruction set) alongside the existing ARM and Thumb-mode. Support for this state is signified by the "J" in the ARMv5TEJ architecture, and in ARM9EJ-S and ARM7EJ-S core names. Support for this state is required starting in ARMv6 (except for the ARMv7-M profile), though newer cores only include a trivial implementation that provides no hardware acceleration.
Thumb.
To improve compiled code-density, processors since the ARM7TDMI (released in 1994) have featured the "Thumb" instruction set, which have their own state. (The "T" in "TDMI" indicates the Thumb feature.) When in this state, the processor executes the Thumb instruction set, a compact 16-bit encoding for a subset of the ARM instruction set. Most of the Thumb instructions are directly mapped to normal ARM instructions. The space-saving comes from making some of the instruction operands implicit and limiting the number of possibilities compared to the ARM instructions executed in the ARM instruction set state.
In Thumb, the 16-bit opcodes have less functionality. For example, only branches can be conditional, and many opcodes are restricted to accessing only half of all of the CPU's general-purpose registers. The shorter opcodes give improved code density overall, even though some operations require extra instructions. In situations where the memory port or bus width is constrained to less than 32 bits, the shorter Thumb opcodes allow increased performance compared with 32-bit ARM code, as less program code may need to be loaded into the processor over the constrained memory bandwidth.
Embedded hardware, such as the Game Boy Advance, typically have a small amount of RAM accessible with a full 32-bit datapath; the majority is accessed via a 16-bit or narrower secondary datapath. In this situation, it usually makes sense to compile Thumb code and hand-optimise a few of the most CPU-intensive sections using full 32-bit ARM instructions, placing these wider instructions into the 32-bit bus accessible memory.
The first processor with a Thumb instruction decoder was the ARM7TDMI. All ARM9 and later families, including XScale, have included a Thumb instruction decoder.
Thumb-2.
"Thumb-2" technology was introduced in the "ARM1156 core", announced in 2003. Thumb-2 extends the limited 16-bit instruction set of Thumb with additional 32-bit instructions to give the instruction set more breadth, thus producing a variable-length instruction set. A stated aim for Thumb-2 was to achieve code density similar to Thumb with performance similar to the ARM instruction set on 32-bit memory.
Thumb-2 extends the Thumb instruction set with bit-field manipulation, table branches and conditional execution. At the same time, the ARM instruction set was extended to maintain equivalent functionality in both instruction sets. A new "Unified Assembly Language" (UAL) supports generation of either Thumb or ARM instructions from the same source code; versions of Thumb seen on ARMv7 processors are essentially as capable as ARM code (including the ability to write interrupt handlers). This requires a bit of care, and use of a new "IT" (if-then) instruction, which permits up to four successive instructions to execute based on a tested condition, or on its inverse. When compiling into ARM code, this is ignored, but when compiling into Thumb it generates an actual instruction. For example:
All ARMv7 chips support the Thumb instruction set. All chips in the Cortex-A series, Cortex-R series, and ARM11 series support both "ARM instruction set state" and "Thumb instruction set state", while chips in the Cortex-M series support only the Thumb instruction set.
Thumb Execution Environment (ThumbEE).
"ThumbEE" (erroneously called "Thumb-2EE" in some ARM documentation), marketed as Jazelle RCT (Runtime Compilation Target), was announced in 2005, first appearing in the "Cortex-A8" processor. ThumbEE is a fourth Instruction set state, making small changes to the Thumb-2 extended Thumb instruction set. These changes make the instruction set particularly suited to code generated at runtime (e.g. by JIT compilation) in managed "Execution Environments". ThumbEE is a target for languages such as Java, C#, Perl, and Python, and allows JIT compilers to output smaller compiled code without impacting performance.
New features provided by ThumbEE include automatic null pointer checks on every load and store instruction, an instruction to perform an array bounds check, and special instructions that call a handler. In addition, because it utilises Thumb-2 technology, ThumbEE provides access to registers r8-r15 (where the Jazelle/DBX Java VM state is held). Handlers are small sections of frequently called code, commonly used to implement high level languages, such as allocating memory for a new object. These changes come from repurposing a handful of opcodes, and knowing the core is in the new ThumbEE Instruction set state.
On 23 November 2011, ARM Holdings deprecated any use of the ThumbEE instruction set, and ARMv8 removes support for ThumbEE.
Floating-point (VFP).
"VFP" (Vector Floating Point) technology is an "FPU" (Floating-Point Unit) coprocessor extension to the ARM architecture (implemented differently in ARMv8 - coprocessors not defined there). It provides low-cost single-precision and double-precision floating-point computation fully compliant with the "ANSI/IEEE Std 754-1985 Standard for Binary Floating-Point Arithmetic". VFP provides floating-point computation suitable for a wide spectrum of applications such as PDAs, smartphones, voice compression and decompression, three-dimensional graphics and digital audio, printers, set-top boxes, and automotive applications. The VFP architecture was intended to support execution of short "vector mode" instructions but these operated on each vector element sequentially and thus did not offer the performance of true single instruction, multiple data (SIMD) vector parallelism. This vector mode was therefore removed shortly after its introduction, to be replaced with the much more powerful NEON Advanced SIMD unit.
Some devices such as the ARM Cortex-A8 have a cut-down "VFPLite" module instead of a full VFP module, and require roughly ten times more clock cycles per float operation. Pre-ARMv8 architecture implemented floating-point/SIMD with the coprocessor interface. Other floating-point and/or SIMD units found in ARM-based processors using the coprocessor interface include FPA, FPE, iwMMXt, some of which were implemented in software by trapping but could have been implemented in hardware. They provide some of the same functionality as VFP but are not opcode-compatible with it.
In Debian Linux, and derivatives such as Ubuntu, armhf (ARM hard float) refers to the ARMv7 architecture including the additional VFP3-D16 floating-point hardware extension (and Thumb-2) above.
Advanced SIMD (NEON).
The "Advanced SIMD" extension (aka "NEON" or "MPE" Media Processing Engine) is a combined 64- and 128-bit SIMD instruction set that provides standardized acceleration for media and signal processing applications. NEON is included in all Cortex-A8 devices but is optional in Cortex-A9 devices. NEON can execute MP3 audio decoding on CPUs running at 10 MHz and can run the GSM adaptive multi-rate (AMR) speech codec at no more than 13 MHz. It features a comprehensive instruction set, separate register files and independent execution hardware. NEON supports 8-, 16-, 32- and 64-bit integer and single-precision (32-bit) floating-point data and SIMD operations for handling audio and video processing as well as graphics and gaming processing. In NEON, the SIMD supports up to 16 operations at the same time. The NEON hardware shares the same floating-point registers as used in VFP. Devices such as the ARM Cortex-A8 and Cortex-A9 support 128-bit vectors but will execute with 64 bits at a time, whereas newer Cortex-A15 devices can execute 128 bits at a time.
ProjectNe10 is ARM's first open source project (from its inception). The Ne10 library is a set of common, useful functions written in both NEON and C (for compatibility). The library was created to allow developers to use NEON optimisations without learning NEON but it also serves as a set of highly optimised NEON intrinsic and assembly code examples for common DSP, arithmetic and image processing routines. The code is available on GitHub.
Security extensions (TrustZone).
The Security Extensions, marketed as TrustZone Technology, is in ARMv6KZ and later application profile architectures. It provides a low-cost alternative to adding another dedicated security core to an SoC, by providing two virtual processors backed by hardware based access control. This lets the application core switch between two states, referred to as worlds (to reduce confusion with other names for capability domains), in order to prevent information from leaking from the more trusted world to the less trusted world. This world switch is generally orthogonal to all other capabilities of the processor, thus each world can operate independently of the other while using the same core. Memory and peripherals are then made aware of the operating world of the core and may use this to provide access control to secrets and code on the device.
Typical applications of TrustZone Technology are to run a rich operating system in the less trusted world, and smaller security-specialized code in the more trusted world (named TrustZone Software, a TrustZone optimised version of the Trusted Foundations Software developed by Trusted Logic Mobility), allowing much tighter digital rights management for controlling the use of media on ARM-based devices, and preventing any unapproved use of the device. Trusted Foundations Software was acquired by Gemalto. Giesecke & Devrient developed a rival implementation named Mobicore. In April 2012 ARM Gemalto and Giesecke & Devrient combined their TrustZone portfolios into a joint venture Trustonic. Open Virtualization and T6 are open source implementations of the trusted world architecture for TrustZone.
In practice, since the specific implementation details of TrustZone are proprietary and have not been publicly disclosed for review, it is unclear what level of assurance is provided for a given threat model.
No-execute page protection.
As of ARMv6, the ARM architecture supports no-execute page protection, which is referred to as "XN", for "eXecute Never".
Large Physical Address Extension.
The Large Physical Address Extension, which extends the physical address size from 32 bits to 40 bits, was added to the ARMv7-A architecture in 2011.
ARMv8-R.
The ARMv8-R sub-architecture, announced after the ARMv8-A, shares some features except that it is not 64-bit.
64/32-bit architecture.
ARMv8-A.
Announced in October 2011, ARMv8-A (often called ARMv8 although not all variants are 64-bit such as ARMv8-R) represents a fundamental change to the ARM architecture. It adds a 64-bit architecture, named "AArch64", and a new "A64" instruction set. AArch64 provides user-space compatibility with ARMv7-A ISA, the 32-bit architecture, therein referred to as "AArch32" and the old 32-bit instruction set, now named "A32". The Thumb instruction sets are referred to as "T32" and have no 64-bit counterpart. ARMv8-A allows 32-bit applications to be executed in a 64-bit OS, and a 32-bit OS to be under the control of a 64-bit hypervisor. ARM announced their Cortex-A53 and Cortex-A57 cores on 30 October 2012. Apple was the first to release an ARMv8-A compatible core (Apple A7) in a consumer product (iPhone 5S). AppliedMicro, using an FPGA, was the first to demo ARMv8-A. The first ARMv8-A SoC from Samsung is the Exynos 5433 in the Galaxy Note 4, which features two clusters of four Cortex-A57 and Cortex-A53 cores in a big.LITTLE configuration; but it will run only in AArch32 mode.
To both AArch32 and AArch64, ARMv8-A makes VFPv3/v4 and advanced SIMD (NEON) standard. It also adds cryptography instructions supporting AES and SHA-1/SHA-256.
ARMv8.1-A.
In December 2014, ARMv8.1-A, an update with "incremental benefits over v8.0", was announced. The enhancements fall into two categories:
Expected "product introductions mid-2015" with server CPU makers likely to adopt and Apple "will likely jump to the new architecture". "The incremental updates in ARMv8.1-A revolve around memory addressing, security, virtualization and throughput. ARMv8-A code will run on v8.1 cores."

</doc>
<doc id="60559" url="https://en.wikipedia.org/wiki?curid=60559" title="Emily Davison">
Emily Davison

Emily Wilding Davison (11 October 1872 – 8 June 1913) was a militant suffragette who fought for women's suffrage in Britain. She was jailed on nine occasions and force-fed 101 times. She stepped in front of King George V's horse Anmer at the Epsom Derby on 4 June 1913, suffering fatal injuries. Her funeral on 14 June 1913 was organised by the Women's Social and Political Union (WSPU). Thousands of suffragettes accompanied the coffin and tens of thousands of people lined the streets of London. After a service in Bloomsbury, her coffin was taken by train to the family grave in Morpeth, Northumberland.
Modern historians agree that Davison was trying to disturb the Derby to draw attention to her cause, rather than to commit suicide, and 2013 analysis of newsreel has supported the idea that Davison was reaching up to attach a scarf to the bridle of the King's horse. Analysis of newsreel also indicated that her position before she stepped out onto the track would have given her a clear view of the oncoming race, further countering the belief that she ran out in a haphazard way to kill herself. 
Early life and education.
Davison was born in Blackheath, Kent, the daughter of Charles Davison (of Morpeth, Northumberland) and Margaret Davison (of Longhorsley, Northumberland). She had two sisters and a brother; also various half-siblings from her father's first marriage including a half-brother, retired naval captain Henry Jocelyn Davison, who gave evidence at her inquest.
She later attended Kensington Prep School and won a bursary to Royal Holloway College in 1891 to study literature and modern foreign languages. However, she was forced to drop out in January 1892 because her father died and her mother could not afford the fees of £30 a term. She then became a private governess before becoming a teacher in Edgbaston and Worthing, raising enough money to study Biology, Chemistry, English Language and Literature at St Hugh's College, Oxford. She obtained first-class honours in her final exams, though women were not at that time admitted to degrees at Oxford. Davison then began teaching the daughters of the Moorhouse family in Spratton, Northamptonshire.
Activism.
In 1906, Davison joined the Women's Social and Political Union (WSPU). Formed in 1903 by Emmeline Pankhurst, the WSPU brought together those who felt strongly that militant, confrontational tactics were needed to achieve women's suffrage. In 1908, Davison left her teaching post to dedicate herself completely to the movement. In the same year she entered the University of London examinations as an external candidate for a degree in Modern Foreign Languages.
She gained a reputation as a militant and violent campaigner. On her own initiative and without the approval of the WSPU, her actions developed from disrupting meetings to stone throwing and arson. She was arrested and imprisoned for various offences nine times, including a violent attack on a man she mistook for the Chancellor of the Exchequer, David Lloyd George. During many of these prison terms she went on hunger strike and was force-fed.
On 2 April 1911, the night of the 1911 census, Davison hid in a cupboard in St Mary Undercroft, the chapel of the Palace of Westminster, overnight so that on the census form she could legitimately give her place of residence that night as the "House of Commons". Census documents from the year 1911 state that Emily Wilding Davison was found "hiding in the crypt" in the Houses of Parliament. In 1999 a plaque to commemorate the event was set in place by Tony Benn MP.
In June 1912, near the end of a six-month sentence in Holloway Prison for arson, when Davison and dozens of fellow suffragettes were being subjected to force-feeding, she threw herself down a 10-metre iron staircase. Her intention, as she wrote afterwards, was to stop the suffering of everyone else by carrying out this action. As a result she suffered severe head and spinal damage, causing discomfort for the remaining twelve months of her life.
Injury at Epsom Derby.
On 4 June 1913, Davison attended the Epsom Derby. St John Ervine was standing beside her and noted that she seemed rather agitated. As the race was underway, Davison ducked under the railing and moved onto the track. Some say Davison tried to grab the bridle of the horse owned by King George V, Anmer. Film of the event shows that Davison had something in her hand, leading to suggestions that she was carrying a suffragette flag or poster, and a Channel 4 film presented by Clare Balding gave credence to the idea that this might have been a folded silk scarf bearing suffragette slogans. The horse collided with her (possibly as it tried to jump over her to avoid a collision) and she fell to the ground, where she was trampled by its hooves, as it, too, fell. Meanwhile, the jockey, Herbert Jones, was thrown, but had his foot caught in the stirrup. The horse did a somersault, got up, and resumed running the race, dragging the unconscious Jones before his foot came loose. Bystanders unsuccessfully attempted to revive both Davison and Jones, before they were carried off by ambulances. Jones survived, but Davison did not.
Davison's purpose in attending the Derby is not clear. Her purchase of a return rail ticket and a ticket to a suffragette dance later that day, both of which are now in the collection of the Women's Library in London, suggest that martyrdom was not her intention. Later research has indicated that returns were the only type of rail ticket available for purchase, it is noted that she carefully kept the return half in her purse. Further evidence is a postcard she wrote to her sister Laetitia, who lived in France and to whom she was very close, which suggests she was going on holiday a few days after the Derby to visit her sister and her niece.
It is a possibility that Davison entered the race track with the aim of attaching something bearing a message or slogan to Anmer, so that when the horse crossed the finishing line, it would be flying the WSPU flag. According to police reports, two flags were found in her possession. Pathé News captured the incident on film. Film, taken at Tattenham Corner, shows Davison stepping out onto the racecourse just as the leading horses swept by. She was then seen standing in the middle of the racecourse as two more horses passed on the inside of her, and was then knocked to the ground by one of the last few trailing horses, the King's horse, Anmer. The film is unclear, but it is possible that by this point she had taken the banner of the WSPU out from where it was concealed in her clothing, with the intention of attaching it to the horse. Eyewitnesses at the time were divided as to her motivation, with many feeling that she had simply intended to cross the track, believing that all horses had passed. Others reported that she had attempted to pull down the King's horse. It is sometimes suggested that a few weeks beforehand Davison and other suffragettes were "practising" grabbing horses in the park near her mother's house in Morpeth and that they drew straws to decide who should be the one to go to Epsom.
Horse racing historian Michael Tanner, in a 2011 TV interview at Epsom, argued that, as Davison was standing on the inside of the bend at Tattenham Corner amidst heaving crowds, and with no racetrack commentary as there is today, it would not have been possible to know whether the King's horse had already gone past. In addition, he said, considering the speeds the horses were going, it would not have been possible for her to identify any particular horse even if she had meant to. This would suggest that the fact it was the King's horse that she collided with was just a coincidence. Tanner later described the story of Davison "practising" with galloping horses and "drawing straws" as "folklore at best, pure hokum at worst," emphasising that "by 1913 Davison's modus operandi was acting alone – no one knew of her plans, in Morpeth or elsewhere."
The 2013 Channel 4 film suggested Davison intended to throw a "Votes for Women" sash around the neck of the King's horse to gain publicity for her cause. A sash allegedly found at the scene immediately after the collision was purchased at auction by author Barbara Gorna, the closest losing bidder being the Jockey Club, and now hangs in the Houses of Parliament. This theory received support from a 2013 examination of the incident, in which forensic experts examined and correlated footage captured by three different newsreel cameras, and determined that Davison was much closer to the start of the bend than had been previously assumed, and might have had a much clearer view of the oncoming horses than previously thought. It concluded that Davison, who clearly carried something in her hand, could have been holding a folded "Votes for Women" sash as she ducked under the barrier, intended to attach it to the king's horse, and had no intention of deliberately throwing herself under the horse.
However, in his 2013 book "The Suffragette Derby", Tanner examined the provenance of this "sash", which is in fact a scarf, and found this theory wanting: its original owner, Richard Pittway Burton, was not Epsom's Clerk of the Course, as claimed, but an East End docker with no racing connection whatsoever. Nor, Tanner argued, could the article in Davison's hand be safely identified as a scarf in the first place: he said the evidence had been skewed to suit this theory. In a letter to the "Racing Post" Tanner deplored the reiteration of "several myths" attached to Davison that he claimed to have debunked in his book, and expressed deep reservations about the film footage analysis, arguing that "from her position wedged tight against the rail, Davison would need to have been on a 20-foot ladder to have seen over the heads of the people to her right and then the leading bunch of nine horses to single out the figure of Anmer hidden behind... she was already ducking under the rail as the first horses passed and had missed two-thirds of the field altogether – which for all she knew may have included Anmer. It was pure chance that she stumbled upon Anmer."
Death.
Davison died four days later in Epsom Cottage Hospital due to a fractured skull and internal injuries caused by the incident. Jones suffered a mild concussion. In 1928, at the funeral of Emmeline Pankhurst, Jones laid a wreath "to do honour to the memory of Mrs Pankhurst and Miss Emily Davison".
Commemoration.
Davison is buried in the churchyard of St. Mary the Virgin, Morpeth, Northumberland, in a family plot where her father was buried in 1893. The cemetery is about 7 miles south of Longhorsley, where she had lived with her mother and family. A memorial service, which attracted a great crowd, was held at St. George's church in London on 14 June 1913. Her coffin was brought by train to Morpeth for burial on 15 June. Her gravestone bears the WSPU slogan, "Deeds not words."
On 18 April 2013, a plaque was unveiled at Epsom racecourse to mark the centenary of the death. An Emily Wilding Davison Memorial Campaign was also established ahead of the centenary to campaign for a minute's silence at the 2013 Epsom Derby. However, the campaign failed after the racecourse said that this would be "logistically impossible".
Legacy.
Like other acts of suffragette militancy, Davison's actions divided public opinion, some admiring her courage, others decrying the disruption of sport, the injury to jockey Herbert Jones, and the slight to the King.
But the direct consequence was to galvanise male political support for suffrage, in the form of the Northern Men's Federation for Women's Suffrage. This initially took the form of a deputation to the Prime Minister Asquith; when this was rebuffed, it became a standing organisation. Its president was the former actress Maud Arncliffe-Sennett. It was mainly composed of town councillors, ministers, lawyers and similar civic figures from Glasgow and Edinburgh, and had little following beyond central Scotland, even in Davison's Northumberland.
Beyond the Federation it is difficult to distinguish Davison's effect from that of the broader militant tradition in Britain, which continued until the political landscape was changed by the outbreak of World War I.
Emily Davison is the subject of an opera, "Emily" (2013), by the British composer Tim Benjamin. She is also the subject of a song by American rock singer Greg Kihn, whose elegy "Emily Davison" is included on his first album, 1976's "Greg Kihn". Davison also appears as a supporting character in the 2015 film "Suffragette", in which she is portrayed by Natalie Press. Her death forms the climax of the film.

</doc>
<doc id="60560" url="https://en.wikipedia.org/wiki?curid=60560" title="Tetrapod">
Tetrapod

The superclass Tetrapoda (Ancient Greek τετραπόδηs tetrapodēs, "four-footed"), or the tetrapods , comprises the first four-limbed vertebrates and their descendants, including the living and extinct amphibians, reptiles, mammals, birds, and some ancient fish such as the Coelacanth. Tetrapods evolved from the lobe-finned fishes around 390 million years ago in the middle Devonian Period, with modern tetrapod groups having appeared by the late Devonian, 367.5 million years ago. The specific aquatic ancestors of the tetrapods, and the process by which land colonization occurred, remain unclear, and are areas of active research and debate among palaeontologists at present.
While most species today are terrestrial, the first tetrapods were fully aquatic. Amphibians today generally remain semiaquatic, living the first stage of their lives as fish-like tadpoles. Amniotes evolved about 340 million years ago (crown amniotes 318 mya), and their descendants drove most amphibians to extinction. One population of amniotes diverged into lizards, dinosaurs, birds and their relatives, while another diverged into mammals and their extinct relatives. Several groups of tetrapods, such as the caecilians, snakes, cetaceans, sirenians, and moas have lost some or all of their limbs. In addition, many tetrapods have returned to partially aquatic or fully aquatic lives throughout the history of the group (modern examples of fully aquatic tetrapods include cetaceans and sirenians). The first returns to an aquatic lifestyle may have occurred as early as the Carboniferous Period, whereas other returns occurred as recently as the Cenozoic, as in cetaceans, pinnipeds, and several modern amphibians.
The change from a body plan for breathing and navigating in water to a body plan enabling the animal to move on land is one of the most profound evolutionary changes known. It is also becoming increasingly well-understood as a result of more transitional fossil finds and improved phylogenetic analysis.
Definitions.
Tetrapods can be defined in cladistics as the nearest common ancestor of all living amphibians (the lissamphibians) and all living amniotes (reptiles, birds, and mammals), along with all of the descendants of that ancestor. This is a node-based definition (the node being the nearest common ancestor). The group so defined is the crown group, or crown tetrapods. The term tetrapodomorph is used for the stem-based definition: any animal that is more closely related to living amphibians, reptiles, birds, and mammals than to living dipnoi (lungfishes). The group so defined is known as the tetrapod total group.
Stegocephalia is a larger group equivalent to some broader uses of the word "tetrapod", used by scientists who prefer to reserve the word "tetrapod" for the crown group (based on the nearest common ancestor of living forms). Such scientists use the term "stem-tetrapod" to refer to those tetrapod-like vertebrates that are not members of the crown group, including the tetrapodomorph fishes
The two subclades of crown tetrapods are Batrachomorpha and Reptiliomorpha. Batrachomorphs are all animals sharing a more recent common ancestry with living amphibians than with living amniotes (reptiles, birds, and mammals). Reptiliomorphs are all animals sharing a more recent common ancestry with living amniotes than with living amphibians.
Biodiversity.
Tetrapoda includes four classes: amphibians, reptiles, mammals, and birds. Overall, the biodiversity of lissamphibians, as well as of tetrapods generally, has grown exponentially over time; the more than 30,000 species living today are descended from a single amphibian group in the Early to Middle Devonian. However, that diversification process was interrupted at least a few times by major biological crises, such as the Permian–Triassic extinction event, which at least affected amniotes. The overall composition of biodiversity was driven primarily by amphibians in the Palaeozoic, dominated by reptiles in the Mesozoic and expanded by the explosive growth of birds and mammals in the Cenozoic. As biodiversity has grown, so has the number of niches that tetrapods have occupied. The first tetrapods were aquatic and fed primarily on fish. Today, the Earth supports a great diversity of tetrapods that live in many habitats and subsist on a variety of diets. The following table shows summary estimates for each tetrapod class from the "IUCN Red List of Threatened Species", 2014.3, for the number of extant species that have been described in the literature, as well as the number of threatened species.
Evolution.
Origin.
Ancestry.
Tetrapods evolved from early bony fishes (Osteichthyes), specifically from the tetrapodomorph branch of lobe-finned fishes (Sarcopterygii), living in the early to middle Devonian period.
The first tetrapods probably evolved in the Emsian stage of the Early Devonian from Tetrapodomorph fish living in shallow water environments.
The very earliest tetrapods would have been animals similar to "Acanthostega", with legs and lungs as well as gills, but still primarily aquatic and unsuited to life on land.
The earliest tetrapods inhabited saltwater, brackish-water, and freshwater environments, as well as environments of highly variable salinity. These traits were shared with many early lobed-finned fishes. As early tetrapods are found on two Devonian continents, Laurussia (Euramerica) and Gondwana, as well as the island of North China, it is widely supposed that early tetrapods were capable of swimming across the shallow (and relatively narrow) continental-shelf seas that separated these landmasses.
Since the early 20th century, several families of tetrapodomorph fishes have been proposed as the nearest relatives of tetrapods, among them the rhizodonts (notably Sauripterus), the osteolepidids, the tristichopterids (notably Eusthenopteron), and more recently the elpistostegalians (also known as Panderichthyida) notably the genus Tiktaalik.
Among the notable features of Tiktaalik are the absence of bones covering the gills. These bones would otherwise connect the shoulder girdle with skull, making the shoulder girdle part of the skull. With the loss of the gill-covering bones, the shoulder girdle is separated from the skull, connected to the torso by muscle and other soft-tissue connections. The result is the appearance of the neck. With the exception of Tiktaalik, this feature is found only in tetrapods, not in tetrapodomorph fishes. Tiktaalik also had a pattern of bones in the skull roof (upper half of the skul) that bears similarity to the end-Devonian tetrapod Ichthyostega. The two also shared a semi-rigid ribcage of overlapping ribs which could have served as a substitute for a rigid spine. In conjunction with robust forelimbs and shoulder girdle, both Tiktaalik and Ichthyostega may have had the ability to locomote on land in the manner of a seal, with the forward portion of the torso elevated, the hind part dragging behind. And finally, the fin bones of Tiktaalik are somewhat similar to the limb bones of tetrapods.
There are, however, issues, among them Tiktaalik's long spine with far more vertebra than in any known tetrapod or any other known tetrapodomorph fish. Of even greater concern is the date: the oldest tetrapod trace fossils (tracks and trackways) predate Tiktaalik by a considerable margin. Several hypotheses have been proposed to explain the date discrepancy: 1) The nearest common ancestor of tetrapods and Tiktaalik dates to the Early Devonian. By this hypothesis, the Tiktaalik lineage is the closest to tetrapods, but Tiktaalik itself was late-surviving relict. 2) Tiktaalik represents a case of parallel evolution. 3) Tetrapods evolved more than once.
Devonian fossils.
The oldest evidence for the existence of tetrapods comes from trace fossils, tracks (footprints) and trackways found in Zachełmie, Poland, dated to the Eifelian stage of the Middle Devonian, 390-1 mya. The adult tetrapods had an estimated length of 2.5 m (8 feet). They lived in a lagoon with an average depth of 1–2 m, although it is not known at what depth the underwater tracks were made. The lagoon was inhabited by a variety of marine organisms and was apparently salt water. The average water temperature was 30 degrees C (86 F). The second oldest evidence for tetrapods, also tracks and trackways, date from 386 mya (Valentia Island, Ireland)
The oldest partial fossils of tetrapods date from the Frasnian beginning ~380 mya. These include Elginerpeton and Obruchevichthys. Some paleontologists dispute their status as true (digit-bearing) tetrapods.
All known forms of Frasnian tetrapods became extinct in the Late Devonian extinction, also known as the end-Frasnian extinction. This marked the beginning of a gap in the tetrapod fossil record known as the Famennian gap, occupying roughly the first half of the Famennian stage.
The oldest near-complete tetrapod fossils, Acanthostega and Ichthyostega, date from the second half of the Fammennian. Although both were essentially four-footed fish, Ichthyostega is the earliest known tetrapod that may have had the ability to pull itself onto land and drag itself forward with its forelimbs. There is no evidence that it did so, only that it may have been anatomically capable of doing so.
The end-Fammenian marked another extinction, known as the end-Fammenian extinction or the Hangenberg event, which is followed by another gap in the tetrapod fossil record, Romer's gap, also known as the Tournaisian gap. This gap, which was initially 30 million years, but has been gradually reduced over time, currently occupies much of the 13.9-million year Tournaisian, the first stage of the Carboniferous period.
Palaeozoic tetrapods.
Devonian stem-tetrapods.
Tetrapod-like vertebrates first appeared in the early Devonian period. These early "stem-tetrapods" would have been animals similar to "Ichthyostega", with legs and lungs as well as gills, but still primarily aquatic and unsuited to life on land. The Devonian stem-tetrapods went through two major bottlenecks during what the Late Devonian extinctions, also known as the end-Frasnian and end-Fammenian extinctions. These extinction events led to the disappearance of stem-tetrapods with fish-like features. When stem-tetrapods reappear in the fossil record in early Carboniferous deposits, some 10 million years later, the adult forms of some are somewhat adapted to a terrestrial existence. Why they went to land in the first place is still debated.
Carboniferous tetrapods.
During the early Carboniferous, the number of digits on hands and feet of stem-tetrads became standardized at no more than five, as lineages with more digits died out. By mid-Carboniferous times, the stem-tetrapods had radiated into two branches of true ("crown group") tetrapods. Modern amphibians are derived from either the temnospondyls or the lepospondyls (or possibly both), whereas the anthracosaurs were the relatives and ancestors of the amniotes (reptiles, mammals, and kin). The first amniotes are known from the early part of the Late Carboniferous. Amphibians must return to water to lay eggs; in contrast, amniote eggs have a membrane ensuring gas exchange out of water and can therefore be laid on land.
Amphibians and amniotes were affected by the Carboniferous Rainforest Collapse (CRC), an extinction event that occurred ~300 million years ago. The sudden collapse of a vital ecosystem shifted the diversity and abundance of major groups. Amniotes were more suited to the new conditions. They invaded new ecological niches and began diversifying their diets to include plants and other tetrapods, previously having been limited to insects and fish.
Permian tetrapods.
In the Permian period, in addition to temnospondyl and anthracosaur clades, there were two important clades of amniote tetrapods, the sauropsids and the synapsids. The latter were the most important and successful Permian animals.
The end of the Permian saw a major turnover in fauna during the Permian–Triassic extinction event. There was a protracted loss of species, due to multiple extinction pulses. Many of the once large and diverse groups died out or were greatly reduced.
Mesozoic tetrapods.
The diapsids (a subgroup of the sauropsids) began to diversify during the Triassic, giving rise to the turtles, crocodiles, and dinosaurs. In the Jurassic, lizards developed from other diapsids. In the Cretaceous, snakes developed from lizards and modern birds branched from a group of theropod dinosaurs.
By the late Mesozoic, the groups of large, primitive tetrapod that first appeared during the Paleozoic such as temnospondyls and amniote-like tetrapods had gone extinct. Many groups of synapsids, such as anomodonts and therocephalians, that once comprised the dominant terrestrial fauna of the Permian, also became extinct during the Mesozoic; however, during the Jurassic, one synapsid group (Cynodontia) gave rise to the modern mammals, which survived through the Mesozoic to later diversify during the Cenozoic.
Cenozoic tetrapods.
Following the great faunal turnover at the end of the Mesozoic, seven major groups of tetrapods persisted into the Cenozoic era. One of them, the Choristodera, became extinct 20 million years ago for unknown reasons. The surviving six are:
Classification.
The classification of tetrapods has a long history. Traditionally, tetrapods are divided into four classes based on gross anatomical and physiological traits. Snakes and other legless reptiles are considered tetrapods because they are sufficiently like other reptiles that have a full complement of limbs. Similar considerations apply to caecilians and aquatic mammals. Newer taxonomy is frequently based on cladistics instead, giving a variable number of major "branches" (clades) of the tetrapod family tree.
As is the case throughout evolutionary biology today, there is debate over how to properly classify the groups within Tetrapoda. Traditional biological classification sometimes failrs to recognize evolutionary transitions between older groups and descendant groups with markedly different characteristics. For example, the birds, which evolved from the dinosaurs, are defined as a separate group from them, because they represent a distinct new type of physical form and functionality. In phylogenetic nomenclature, in contrast, the newer group is always included in the old. For this school of taxonomy, dinosaurs and birds are not groups in contrast to each other, but rather birds are a sub-type "of" dinosaurs.
History of classification.
The tetrapods, including all large- and medium-sized land animals, have been among the best understood animals since earliest times. By Aristotle's time, the basic division between mammals, birds and egg-laying tetrapods (the "herptiles") was well known, and the inclusion of the legless snakes into this group was likewise recognized. With the birth of modern biological classification in the 18th century, Linnaeus used the same division, with the tetrapods occupying the first three of his six classes of animals. While reptiles and amphibians can be quite similar externally, the French zoologist Pierre André Latreille recognized the large physiological differences at the beginning of the 19th century and split the herptiles into two classes, giving the four familiar classes of tetrapods: amphibians, reptiles, birds and mammals.
Modern classification.
With the basic classification of tetrapods settled, a half a century followed where the classification of living and fossil groups was predominately done by experts working within classes. In the early 1930s, American vertebrate palaeontologist Alfred Romer (1894–1973) produced an overview, drawing together taxonomic work from the various subfields to create an orderly taxonomy in his "Vertebrate Paleontology". This classical scheme with minor variations is still used in works where systematic overview is essential, e.g. Benton (1998) and Knobill and Neill (2006). While mostly seen in general works, it is also still used in some specialist works like Fortuny & al. (2011). The taxonomy down to subclass level shown here is from Hildebrand and Goslow (2001):
This classification is the one most commonly encountered in school textbooks and popular works. While orderly and easy to use, it has come under critique from cladistics. The earliest tetrapods are grouped under Class Amphibia, although several of the groups are more closely related to amniotes than to modern day amphibians. Traditionally, birds are not considered a type of reptile, but crocodiles are more closely related to birds than they are to other reptiles, such as lizards. Birds themselves are thought to be descendents of theropod dinosaurs. Basal non-mammalian synapsids ("mammal-like reptiles") traditionally also sort under Class Reptilia as a separate subclass, but they are more closely related to mammals than to living reptiles. Considerations like these have led some authors to argue for a new classification based purely on phylogeny, disregarding the anatomy and physiology.
Relationships.
Stem-tetrapods.
Stem tetrapods are all animals more closely related to tetrapods than to lungfish, but excluding the tetrapod crown group. The cladogram below illustrates the relationships of stem-tetrapods, from Swartz, 2012:
Crown group.
Crown tetrapods are defined as the nearest common ancestor of all living tetrapods (amphibians, reptiles, birds, and mammals) along with all of the descendants of that ancestor.
The inclusion of certain extinct groups in the crown Tetrapoda depends on the relationships of modern amphibians, or lissamphibians. There are currently three major hypotheses on the origins of lissamphibians. In the temnospondyl hypothesis (TH), lissamphibians are most closely related to dissorophoid temnospondyls, which would make temnospondyls tetrapods. In the lepospondyl hypothesis (LH), lissamphibians are the sister taxon of lysorophian lepospondyls, making lepospondyls tetrapods and temnospondyls stem-tetrapods. In the polyphyletic hypothesis (PH), frogs and salamanders evolved from dissorophoid temnospondyls while caecilians come out of microsaur lepospondyls, making both lepospondyls and temnospondyls true tetrapods.
Temnospondyl hypothesis (TH).
This hypothesis comes in a number of variants, most of which have lissamphibians coming out of the dissorophoid temnospondyls, usually with the focus on amphibamids and branchiosaurids.
The Temnospondyl Hypothesis is the currently favored or majority view, supported by Ruta "et al" (2003a,b), Ruta and Coates (2007), Coates "et al" (2008), Sigurdsen and Green (2011), and Schoch (2013,2014).
Cladogram modified after Coates, Ruta and Friedman (2008).
Lepospondyl hypothesis (LH).
Cladogram modified after Laurin, "How Vertebrates Left the Water" (2010).
Polyphyly hypothesis (PH).
This hypothesis has batrachians (frogs and salamander) coming out of dissorophoid temnospondyls, with caecilians out of microsaur lepospondyls. There are two variants, one developed by Carroll, the other by Anderson.
Cladogram modified after Schoch, Frobisch, (2009).
Anatomy and physiology of early tetrapods.
The tetrapod's ancestral fish, tetrapodomorph, possessed similar traits to those inherited by the early tetrapods, including internal nostrils and a large fleshy fin built on bones that could give rise to the tetrapod limb. Their palatal and jaw structures were similar to those of early tetrapods, and their dentition was similar too, with labyrinthine teeth fitting in a pit-and-tooth arrangement on the palate.
A major difference between early tetrapodomorph fishes and early tetrapods was in the relative development of the front and back skull portions; the snout is much less developed than in most early tetrapods and the post-orbital skull is exceptionally longer than an amphibian's.
To propagate in the terrestrial environment, animals had to overcome certain challenges. Their bodies needed additional support, because buoyancy was no longer a factor. Water retention was now important, since it was no longer the living matrix, and could be lost easily to the environment. Finally, animals needed new sensory input systems to have any ability to function reasonably on land.
Skull.
A notable characteristic that make a tetrapod's skull different from a fish's are the relative frontal and rear portion lengths. The fish had a long rear portion while the front was short; the orbital vacuities were thus located towards the anterior end. In the tetrapod, the front of the skull lengthened, positioning the orbits farther back on the skull.
Neck.
In tetrapodomorph fishes such as Eusthenopteron, the part of the body that would later become the neck was covered by a number of gill-covering bones known as the opercular series. These bones functioned as part of pump mechanism for forcing water through the mouth and past the gills. When the mouth opened to take in water, the gill flaps closed (including the gill-covering bones), thus ensuring that water entered only through the mouth. When the mouth closed, the gill flaps opened and water was forced through the gills. In Acanthostega, a basal tetrapod, the gill-covering bones have disappeared, although the underlying gill arches are still present. Besides the opercular series, Acanthostega also lost the throat-covering bones (gular series). The opercular series and gular series combined are sometimes known as the operculo-gular or operculogular series. Other bones in the neck region lost in Acanthostega (and later tetrapods) include the extrascapular series and the supracleithral series. Both sets of bones connect the shoulder girdle to the skull. With the loss of these bones, tetrapods acquired a neck, allowing the head to rotate somewhat independently of the torso. This, in turn, required stronger soft-tissue connections between head and torso, including muscles and ligaments connecting the skull with the spine and shoulder girdle. Bones and groups of bones were also consolidated and strengthened.
In Carboniferous tetrapods, the neck joint (occiput) provided a pivot point for the spine against the back of the skull. In tetrapodomorph fishes such as Eusthenopteron, no such neck joint existed. Instead, the notochord (a sort of spine made of cartilage) entered a hole in the back of the braincase and continued to the middle of the braincase. Acanthostega had the same arrangement as Eusthenopteron, and thus no neck joint. The neck joint evolved independently in different lineages of early tetrapods.
Dentition.
Tetrapods had a tooth structure known as "plicidentine" characterized by infolding of the enamel as seen in cross-section. The more extreme version found in early tetrapods is known as "labyrinthodont" or "labyrinthodont plicidentine." This type of tooth structure has evolved independently in several types of bony fishes, both ray-finned and lobe finned, some modern lizards, and in a number of tetrapodomorph fishes. The infolding appears to evolve when a fang or large tooth grows in a small jaw, erupting when it still weak and immature. The infolding provides added strength to the young tooth, but offers little advantage when the tooth is mature. Such teeth are associated with feeding on soft prey in juveniles.
Axial skeleton.
With the move from water to land, the spine had to resist the bending caused by body weight and had to provide mobility where needed. Previously, it could bend along its entire length. Likewise, the paired appendages had not been formerly connected to the spine, but the slowly strengthening limbs now transmitted their support to the axis of the body.
Girdles.
The shoulder girdle was disconnected from the skull, resulting in improved terrestrial locomotion. The early sarcopterygians cleithrum was retained as the clavicle, and the interclavicle was well-developed, lying on the underside of the chest. In primitive forms, the two clavicles and the interclavical could have grown ventrally in such a way as to form a broad chest plate. The upper portion of the girdle had a flat, scapular blade, with the glenoid cavity situated below performing as the articulation surface for the humerus, while ventrally there was a large, flat coracoid plate turning in toward the midline.
The pelvic girdle also was much larger than the simple plate found in fishes, accommodating more muscles. It extended far dorsally and was joined to the backbone by one or more specialized sacral ribs. The hind legs were somewhat specialized in that they not only supported weight, but also provided propulsion. The dorsal extension of the pelvis was the ilium, while the broad ventral plate was composed of the pubis in front and the ischium in behind. The three bones met at a single point in the center of the pelvic triangle called the acetabulum, providing a surface of articulation for the femur.
Limbs.
Fleshy lobe-fins supported on bones seem to have been an ancestral trait of all bony fishes (Osteichthyes). The ancestors of the ray-finned fishes (Actinopterygii) evolved their fins in a different direction. The Tetrapodomorph ancestors of the Tetrapods further developed their lobe fins. The paired fins had bones distinctly homologous to the humerus, ulna, and radius in the fore-fins and to the femur, tibia, and fibula in the pelvic fins.
The paired fins of the early sarcopterygians were smaller than tetrapod limbs, but the skeletal structure was very similar in that the early sarcopterygians had a single proximal bone (analogous to the humerus or femur), two bones in the next segment (forearm or lower leg), and an irregular subdivision of the fin, roughly comparable to the structure of the carpus / tarsus and phalanges of a hand.
Locomotion.
In typical early tetrapod posture, the upper arm and upper leg extended nearly straight horizontal from its body, and the forearm and the lower leg extended downward from the upper segment at a near right angle. The body weight was not centered over the limbs, but was rather transferred 90 degrees outward and down through the lower limbs, which touched the ground. Most of the animal's strength was used to just lift its body off the ground for walking, which was probably slow and difficult. With this sort of posture, it could only make short broad strides. This has been confirmed by fossilized footprints found in Carboniferous rocks.
Feeding.
Early tetrapods had a wide gaping jaw with weak muscles to open and close it. In the jaw were moderate-sized palatal and vomerine (upper) and coronoid (lower) fangs, as well rows of smaller teeth. This was in contrast to the larger fangs and small marginal teeth of earlier tetrapodomorph fishes such as Eusthenopteron. Although this indicates a change in feeding habits, the exact nature of the change in unknown. Some scholars have suggested a change to bottom-feeding or feeding in shallower waters (Ahlberg and Milner 1994). Others have suggesting a mode of feeding comparable to that of the Japanese giant salamander, which uses both suction feeding and direct biting to eat small crustaceans and fish. A study of these jaws shows that they were used for feeding underwater, not on land.
In later terrestrial tetrapods, two methods of jaw closure emerge: static and kinetic inertial (also known as snapping). In the static system, the jaw muscles are arranged in such a way that the jaws have maximum force when shut or nearly shut. In the kinetic inertial system, maximum force is applied when the jaws are wide open, resulting in the jaws snapping shut with great velocity and momentum. Although the kinetic inertial system is occasionally found in fish, it requires special adaptations (such as very narrow jaws) to deal with the high viscosity and density of water, which would otherwide impede rapid jaw closure.
The tetrapod tongue is built from muscles that once controlled gill openings. The tongue is anchored to the hyoid bone, which was once the lower half of a pair of gill bars (the second pair after the ones that evolved into jaws). The tongue did not evolve until the gills began to disappear. Acanthostega still had gills, so this would have been a later development. In an aquatically feeding animals, the food supported by water and can literally float (or get sucked in) to the mouth. On land, the tongue becomes important.
Respiration.
The evolution of early tetrapod respiration was influenced by an event known as the "charcoal gap," a period of more than 20 million years, in the middle and late Devonian, when atmospheric oxygen levels were too low to sustain wildfires. During this time, fish inhabiting anoxic waters (very low in oxygen) would have been under evolutionary pressure to develop their air-breathing ability.
Early tetrapods probably relied on four methods of respiration: with lungs, with gills, cutaneous respiration (skin breathing), and breathing through the lining of the digestive tract, especially the mouth.
Gills.
The early tetrapod Acanthostega had at least three and probably four pairs of gill bars, each containing deep grooves in the place where one would expect to find the afferent branchial artery. This strongly suggests that functional gills were present. Some aquatic temnospondyls retained internal gills at least into the early Jurassic.
Lungs.
Lungs originated as an extra pair of pouches in the throat, behind the gill pouches. They were probably present in the last common ancestor of bony fishes. In some fishes they evolved into swim bladders for maintaining buoyancy. Lungs and swim bladders are homologous (descended from a common ancestral form) as is the case for the pulmonary artery (which delivers deoxygenated blood from the heart to the lungs) and the arteries that supply swim bladders. Air was introduced into the lungs by a process known as buccal pumping.
In the earliest tetrapods, exhalation was probably accomplished with the aid of the muscles of the torso (the thoracoabdominal region). Inhaling with the ribs was either primitive for amniotes, or evolved independently in at least two different lineages of amniotes. It is not found in amphibians. The muscularized diaphragm is unique to mammals.
Recoil aspiration.
Although tetrapods are widely thought to have inhaled through buccal pumping (mouth pumping), according to an alternative hypothesis, aspiration (inhalation) occurred through passive recoil of the exoskeleton in a manner similar to the contemporary primitive ray-finned fish polypterus. This fish inhales through its spiracle (blowhole), an anatomical feature present in early tetrapods. Exhalation is powered by muscles in the torso. During exhalation, the bony scales in the upper chest region become indented. When the muscles are relaxed, the bony scales spring back into position, generating considerable negative pressure within the torso, resulting in a very rapid intake of air through the spiracle.
Cutaneous respiration.
Skin breathing, known as cutaneous respiration, is common in fish and amphibians, and occur both in and out of water. In some animals waterproof barriers impede the exchange of gasses through the skin. For example, and keratin in human skin, the scales of reptiles, and modern proteinaceous fish scales impede exchange of gasses. However, early tetrapods had scales made of highly vascularized bone covered with skin. For this reason, it is though that early tetrapods could engage some significant amount of skin breathing.
Carbon dioxide metabolism.
Although air-breathing fish can absorb oxygen through their lungs, the lungs tend to be ineffective for discharging carbon dioxide. In tetrapods, the ability of lungs to discharge CO2 came about gradually, and was not fully attained until the evolution of amniotes. The same limitation applies to gut air breathing (GUT), i.e., breathing with the lining of the digestive tract. Tetrapod skin would have been effective for both absorbing oxygen and discharging CO2, but only up to a point. For this reason, early tetrapods may have experienced chronic hypercapnia (high levels of blood CO2). This is not uncommon in fish that inhabit waters high in CO2.
According to one hypothesis, the "sculpted" or "ornamented" dermal skull roof bones found in early tetrapods may have been related to a mechanism for relieving respiratory acidosis (acidic blood caused by excess CO2) through compensatory metabolic alkalosis.
Circulation.
Early tetrapods probably had a three-chambered heart, as do modern amphibians and reptiles, in which oxygenated blood from the lungs and de-oxygenated blood from the respiring tissues enters by separate atria, and is directed via a spiral valve to the appropriate vessel — aorta for oxygenated blood and pulmonary vein for deoxygenated blood. The spiral valve is essential to keeping the mixing of the two types of blood to a minimum, enabling the animal to have higher metabolic rates, and be more active than otherwise.
Senses.
Olfaction.
The difference in density between air and water causes smells (certain chemical compounds detectable by chemoreceptors) to behave differently. An animal first venturing out onto land would have difficulty in locating such chemical signals if its sensory apparatus was designed for aquatic detection.
Lateral line system.
Fish have a lateral line system that detects pressure fluctuations in the water. Such pressure is non-detectable in air, but grooves for the lateral line sense organs were found on the skull of early tetrapods, suggesting either an aquatic or largely aquatic habitat. Modern amphibians, which are semi-aquatic, exhibit this feature whereas it has been retired by the higher vertebrates.
Vision.
Changes in the eye came about because the refractive index of light differs between air and water, so the focal length of the lens altered to function in air. The eye was now exposed to a relatively dry environment rather than being bathed by water, so eyelids developed and tear ducts evolved to produce a liquid to moisten the eyeball.
Early tetrapods inherited a set of five rod and cone opsins known as the vertebrate opsins.
Four cone opsins were present in the first vertebrate, inherited from invertebrate ancestors:
A single rod opsin, rhodopsin, was present in the first jawed vertebrate, inherited from a jawless vertebrate ancestor:
Balance.
Tetrapods retained the balancing function of the middle ear from fish ancestry.
Hearing.
Air vibrations could not set up pulsations through the skull as in a proper auditory organ. The spiracle was retained as the otic notch, eventually closed in by the tympanum, a thin, tight membrane.
The hyomandibula of fish migrated upwards from its jaw supporting position, and was reduced in size to form the stapes. Situated between the tympanum and braincase in an air-filled cavity, the stapes was now capable of transmitting vibrations from the exterior of the head to the interior. Thus the stapes became an important element in an impedance matching system, coupling airborne sound waves to the receptor system of the inner ear. This system had evolved independently within several different amphibian lineages.
The impedance matching ear had to meet certain conditions to work. The stapes had to be perpendicular to the tympanum, small and light enough to reduce its inertia, and suspended in an air-filled cavity. In modern species that are sensitive to over 1 kHz frequencies, the footplate of the stapes is 1/20th the area of the tympanum. However, in early amphibians the stapes was too large, making the footplate area oversized, preventing the hearing of high frequencies. So it appears they could only hear high intensity, low frequency sounds—and the stapes more probably just supported the brain case against the cheek.
Only in the early Triassic, about hundred million years after they conquered land, did the tympanic middle ear evolve (independently) in all the tetrapod lineages.

</doc>
<doc id="60562" url="https://en.wikipedia.org/wiki?curid=60562" title="Redlining">
Redlining

In the United States, redlining is the practice of denying services, either directly or through selectively raising prices, to residents of certain areas based on the racial or ethnic makeups of those areas. While some of the most famous examples of redlining regard denying financial services such as banking or insurance, other services such as health care or even supermarkets, can be denied to residents to carry out redlining. The term "redlining" was coined in the late 1960s by John McKnight, a sociologist and community activist. It refers to the practice of marking a red line on a map to delineate the area where banks would not invest; later the term was applied to discrimination against a particular group of people (usually by race or sex) irrespective of geography.
During the heyday of redlining, the areas most frequently discriminated against were black inner city neighborhoods. For example, in Atlanta in the 1980s, a Pulitzer Prize-winning series of articles by investigative-reporter Bill Dedman showed that banks would often lend to lower-income whites but not to middle- or upper-income blacks. The use of blacklists is a related mechanism also used by redliners to keep track of groups, areas, and people that the discriminating party feels should be denied business or aid or other transactions. In the academic literature, redlining falls under the broader category of credit rationing.
Reverse redlining occurs when a lender or insurer targets nonwhite consumers, not to deny them loans or insurance, but rather to charge them more than could be charged to a comparable white consumer.
History.
Although informal discrimination and segregation had existed in the United States, the specific practice called "redlining" began with the National Housing Act of 1934, which established the Federal Housing Administration (FHA). Racial segregation and discrimination against minorities and minority communities pre-existed this policy. The implementation of this federal policy aggravated the decay of minority inner city neighborhoods caused by the withholding of mortgage capital, and made it even more difficult for neighborhoods to attract and retain families able to purchase homes. In 1935, the Federal Home Loan Bank Board (FHLBB) asked Home Owners' Loan Corporation (HOLC) to look at 239 cities and create "residential security maps" to indicate the level of security for real-estate investments in each surveyed city. 
The assumptions in redlining resulted in a large increase in residential racial segregation and urban decay in the United States. Urban planning historians theorize that the maps were used by private and public entities for years afterwards to deny loans to people in black communities. But, recent research has indicated that the HOLC did not redline in its own lending activities, and that the racist language reflected the bias of the private sector and experts hired to conduct the appraisals.
On the maps, the newest areas—those considered desirable for lending purposes—were outlined in green and known as "Type A". These were typically affluent suburbs on the outskirts of cities. "Type B" neighborhoods, outlined in blue, were considered "Still Desirable", whereas older "Type C" were labeled "Declining" and outlined in yellow.
"Type D" neighborhoods were outlined in red and were considered the most risky for mortgage support. These neighborhoods tended to be the older districts in the center of cities; often they were also black neighborhoods.
Some redlined maps were also created by private organizations, such as J.M. Brewer's 1934 map of Philadelphia. Private organizations created maps designed to meet the requirements of the Federal Housing Administration's underwriting manual. The lenders had to consider FHA standards if they wanted to receive FHA insurance for their loans. FHA appraisal manuals instructed banks to steer clear of areas with ""inharmonious racial groups"", and recommended that municipalities enact racially restrictive zoning ordinances.
Following a National Housing Conference in 1973, a group of Chicago community organizations led by The Northwest Community Organization (NCO) formed National People's Action (NPA), to broaden the fight against disinvestment and mortgage redlining in neighborhoods all over the country. This organization, led by Chicago housewife Gale Cincotta and Shel Trapp, a professional community organizer, targeted The Federal Home Loan Bank Board, the governing authority over Federally chartered Savings & Loan institutions (S&L) that held at that time the bulk of the country's home mortgages. NPA embarked on an effort to build a national coalition of urban community organizations to pass a national disclosure regulation or law to require banks to reveal their lending patterns.
For many years, urban community organizations had battled neighborhood decay by attacking blockbusting, forcing landlords to maintain properties, and requiring cities to board up and tear down abandoned properties. These actions addressed the short-term issues of neighborhood decline. Neighborhood leaders began to learn that these issues and conditions were symptoms of a disinvestment that was the true, though hidden underlying cause of these problems. They changed their strategy as more data was learned.
With the help of NPA, a coalition of loosely affiliated community organizations began to form. At the Third Annual Housing Conference held in Chicago in 1974, eight hundred delegates representing 25 states and 35 cities attended. The strategy focused on the Federal Home Loan Bank Board (FHLBB), which oversaw S&L's in cities all over the country.
In 1974 Chicago's Metropolitan Area Housing Association (MAHA), made up of representatives of local organizations, succeeded in having the Illinois State Legislature pass laws mandating disclosure and outlawing redlining. In Massachusetts, organizers allied with NPA confronted a unique situation. Over 90% of home mortgages were held by state-chartered savings banks. A Jamaica Plain neighborhood organization pushed the disinvestment issue into the statewide gubernatorial race. The Jamaica Plain Banking & Mortgage Committee and its citywide affiliate, The Boston Anti-redlining Coalition (BARC), won a commitment from Democratic candidate Michael S. Dukakis to order statewide disclosure through the Massachusetts State Banking Commission. After Dukakis was elected, his new Banking Commissioner ordered banks to disclose mortgage-lending patterns by zip code. The suspected redlining was revealed.
NPA and its affiliates achieved disclosure of lending practices with the passage of The Home Mortgage Disclosure Act of 1975. The required transparency and review of loan practices began to change lending practices. NPS began to work on reinvestment in areas that had been neglected. Their support helped gain passage in 1977 of the "Community Reinvestment Act".
Impact.
"As a consequence of redlining, neighborhoods that local banks deemed unfit for investment were left underdeveloped or in disrepair. Attempts to improve these neighborhoods with even relatively small-scale business ventures were commonly obstructed by financial institutions that continued to label the underwriting as too risky or simply rejected them outright. When existing businesses collapsed, new ones were not allowed to replace them, often leaving entire blocks empty and crumbling. Consequently African Americans in those neighborhoods were frequently limited in their access to banking, healthcare, retail merchandise, and even groceries." according to blackpast.org contributor Brent Gaspaire. Redlining paralyzed the housing market, lowered property values in certain areas and encouraged landlord abandonment. As abandonment increased, the population density became lower. Abandoned buildings served as havens for drug dealing and other illegal activity, increasing social problems and reluctance of people to invest in these areas.
The film "Revolution '67" examines the practice of redlining that occurred in Newark, New Jersey in the 1960s.
Challenges.
In the United States, the Fair Housing Act of 1968 was passed to fight the practice. According to the Department of Housing and Urban Development "The "Fair Housing Act" makes it unlawful to discriminate in the terms, conditions, or privileges of sale of a dwelling because of race or national origin. The Act also makes it unlawful for any person or other entity whose business includes residential real estate-related transactions to discriminate against any person in making available such a transaction, or in the terms or conditions of such a transaction, because of race or national origin." The Office of Fair Housing and Equal Opportunity was tasked with administering and enforcing this law. Anyone who suspects that their neighborhood has been redlined is able to file a housing discrimination complaint. The Community Reinvestment Act of 1977 further required banks to apply the same lending criteria in all communities. Although open redlining was made illegal in the 70s through community reinvestment legislation, the practice may have continued in less overt ways. AIDS activists allege redlining of health insurance against the LGBT community in response to the AIDS crisis.
ShoreBank, a community-development bank in Chicago's South Shore neighborhood, was a part of the private-sector fight against redlining. Founded in 1973, ShoreBank sought to combat racist lending practices in Chicago's African-American communities by providing financial services, especially mortgage loans, to local residents. In a 1992 speech, then-Presidential candidate Bill Clinton called ShoreBank "the most important bank in America." On August 20, 2010, the bank was declared insolvent, closed by regulators and most of its assets were acquired by Urban Partnership Bank.
Current issues.
Dan Immergluck writes that in 2002 small businesses in black neighborhoods received fewer loans, even after accounting for business density, business size, industrial mix, neighborhood income, and the credit quality of local businesses. Gregory D. Squires wrote in 2003 that data showed that race continues to affect the policies and practices of the insurance industry. Workers living in American inner cities have more difficulty finding jobs than do suburban workers. Redlining has helped preserve segregated living patterns for blacks and whites in the United States, as discrimination is often contingent on the racial composition of neighborhoods and the race of the applicant. Lending institutions such as Wells Fargo have been shown to treat black mortgage applicants differently when they are buying homes in white neighborhoods than when buying homes in black neighborhoods.
Mortgages.
Reverse redlining occurs when a lender or insurer particularly targets minority consumers, not to deny them loans or insurance, but to charge them more than would be charged to a similarly situated majority consumer, specifically marketing the most expensive and onerous loan products. These communities had largely been ignored by most lenders just a couple of decades earlier. In the 2000s some financial institutions considered black communities as suitable for subprime mortgages. Wells Fargo partnered with churches in black communities, where the pastor would deliver "wealth building" seminars in their sermons, and the bank would make a donation to the church in return for every new mortgage application. Working-class blacks wanted a part of the nation’s home-owning trend.
A survey of two districts of similar incomes, one being largely white and the other largely black, found that bank branches in the black community offered largely subprime loans and almost no prime loans. Studies found out that high-income blacks were almost twice as likely to end up with subprime home-purchase mortgages as did low-income whites. Some loan officers referred to blacks as “mud people” and to subprime lending as “ghetto loans.” A lower savings rate and a distrust of banks, stemming from a legacy of redlining, may help explain why there are fewer branches in minority neighborhoods. In the early 21st century, brokers and telemarketers actively pushed subprime mortgages. A majority of the loans were refinance transactions, allowing homeowners to take cash out of their appreciating property or pay off credit card and other debt.
Several state attorneys general have begun investigating these practices, which may violate fair lending laws. The NAACP filed a class-action lawsuit charging systematic racial discrimination by more than a dozen banks.
Redlining Property Type. Other forms of redlining include the nullification of mortgage loans based on internal bank policies and procedures that fail to recognize complex property types. Co-Op and condo conversions in New York City are one such example. These building types are often made up of legacy rent-controlled and rent-stabilized units or may contain another protected class of tenant. Lenders who practice redlining often cite "sponsor concentration" or "high rental concentration" as an excuse to redline the property type. Such internal policies run counter to state and municipal laws and statutes.
Retail.
Retail redlining is a spatially discriminatory practice among retailers. Taxicab services and delivery food may not serve certain areas, based on their ethnic-minority composition and assumptions about business (and perceived crime), rather than data and economic criteria, such as the potential profitability of operating in those areas. Consequently, consumers in these areas are vulnerable to prices set by fewer retailers. They may be exploited by retailers who charge higher prices and/or offer them inferior goods.
Credit cards.
Credit card redlining is a spatially discriminatory practice among credit card issuers, of providing different amounts of credit to different areas, based on their ethnic-minority composition, rather than on economic criteria, such as the potential profitability of operating in those areas. Scholars assess certain policies, such as credit card issuers reducing credit lines of individuals with a record of purchases at retailers frequented by so-called "high-risk" customers, to be akin to redlining.
Insurance.
Racial profiling or redlining has a long history in the property-insurance industry in the United States. From a review of industry underwriting and marketing materials, court documents, and research by government agencies, industry and community groups, and academics, it is clear that race has long affected and continues to affect the policies and practices of the insurance industry. Home-insurance agents may try to assess the ethnicity of a potential customer just by telephone, affecting what services they offer to inquiries about purchasing a home-insurance policy. This type of discrimination is called linguistic profiling. There have also been concerns raised about redlining in the automotive insurance industry. Review of insurance scores based on credit are shown to have unequal results by ethnic group. The Ohio Department of Insurance in the early 21st century allows insurance providers to use maps and collection of demographic data by zip code in determining insurance rates. This practice has been criticized as a kind of redlining. Insurance rates should be related to data about claims.
Student loans.
In December 2007, a class action lawsuit was brought against student loan lending giant Sallie Mae in the United States District Court for the District of Connecticut. The class alleged that Sallie Mae discriminated against African American and Hispanic private student loan applicants.
The case alleged that the factors Sallie Mae used to underwrite private student loans caused a disparate impact on students attending schools with higher minority populations. The suit also alleged that Sallie Mae failed to properly disclose loan terms to private student loan borrowers.
Environmental racism.
Policies related to redlining and urban decay can also act as a form of environmental racism, which in turn have an impact on public health. Urban minority communities may face environmental racism in the form of parks that are smaller, less accessible and of poorer quality than those in more affluent or white areas in some cities. This may have an indirect impact on health, since young people have fewer places to play, and adults have fewer opportunities for exercise.
Robert Wallace writes that the pattern of the AIDS outbreak during the '80s was affected by the outcomes of a program of "planned shrinkage" directed at African-American and Hispanic communities. It was implemented through systematic denial of municipal services, particularly fire protection resources, essential to maintain urban levels of population density and ensure community stability. Institutionalized racism affects general health care as well as the quality of AIDS health intervention and services in minority communities. The over-representation of minorities in various disease categories, including AIDS, is partially related to environmental racism. The national response to the AIDS epidemic in minority communities was slow during the '80s and '90s, showing an insensitivity to ethnic diversity in prevention efforts and AIDS health services.
Liquorlining.
Some service providers target low-income neighborhoods for nuisance sales. When those services are believed to have adverse effects on a community, they may considered to be a form of "reverse redlining." The term "liquorlining" is sometimes used to describe high densities of liquor stores in low income and/or minority communities relative to surrounding areas. High densities of liquor stores are associated with crime and public health issues, which may in turn drive away supermarkets, grocery stores, and other retail outlets, contributing to low levels of economic development. Controlled for income, nonwhites face higher concentrations of liquor stores than do whites.
Further reading.
Hallahan, Kirk. "The Mortgage Redlining Controversy 1972–1975" http://lamar.colostate.edu/~pr/redlining.pdf
Westgate, Michael and Ann Vick., "Gale Force, The Battles For Disclosure and Community Reinvestment", Harvard Book Store, 2nd edition, 2011. ISBN 978-0-615-44901-2

</doc>
<doc id="60563" url="https://en.wikipedia.org/wiki?curid=60563" title="Chancellor of Germany (1949–)">
Chancellor of Germany (1949–)

The Chancellor of the Federal Republic of Germany (in German called , literally "Federal Chancellor", or ' for short) is, under the German 1949 constitution, the head of government of Germany. It is historically a continuation of the office of Chancellor (, later ', Chancellor of the Realm) that was originally established as the office of Chancellor of the North German Confederation in 1867. The 1949 constitution increased the role of the Chancellor compared to the 1919 Weimar Constitution by making the Chancellor much more independent of the influence of the Federal President and granting the Chancellor the right to set the guidelines for all policy areas, thus making them the real chief executive. The role is generally comparable to that of Prime Minister in other parliamentary democracies.
There have been eight chancellors since 1949. The current Chancellor of Germany is Angela Merkel, who was elected in 2005. She is the first female Chancellor since the establishment of the original office in 1867, and known in German as ', the feminine form of '. Merkel is also the first Chancellor elected since the fall of the Berlin Wall to have been raised in the former East Germany.
History of position.
The office of Chancellor has a long history, stemming back to the Holy Roman Empire. The title was at times used in several states of German-speaking Europe. The power and influence of this office varied strongly over time. Otto von Bismarck in particular had a great amount of power, but it was not until 1949 that the Chancellor was established as the central executive authority of Germany.
Due to his administrative tasks, the head of the chapel of the imperial palace during the Holy Roman Empire was called Chancellor. The Archbishop of Mainz was German Chancellor until the end of the Holy Roman Empire in 1806 while the Archbishop of Cologne was Chancellor of Italy and the Archbishop of Trier of Burgundy. These three Archbishops were also Prince-electors of the empire. Already in medieval times the Chancellor had political power like Willigis of Mainz (Archchancellor 975–1011, regent for Otto III 991–994) or Rainald von Dassel (Chancellor 1156–1162 and 1166–1167) under Frederick I.
The modern office of Chancellor was established with the North German Confederation, of which Otto von Bismarck became Chancellor of the Confederation (official German title: "Bundeskanzler") in 1867. After unification of Germany in 1871, the office became known in German as "Reichskanzler" ("Reich Chancellor", literally "Chancellor of the Realm"). Since the adoption of the current constitution of Germany (the "Basic Law" or "Grundgesetz") in 1949 the formal title of the office is once again Bundeskanzler (Federal Chancellor).
In the now defunct German Democratic Republic (GDR, East Germany), which existed from 7 October 1949 to 3 October 1990 (when the territory of the former GDR was reunified with the Federal Republic of Germany), the position of Chancellor did not exist. The equivalent position was called either Minister President "(Ministerpräsident)" or Chairman of the Council of Ministers of the GDR "(Vorsitzender des Ministerrats der DDR)". (See Leaders of East Germany.)
Role.
West Germany's 1949 constitution, the Basic Law ("Grundgesetz"), invests the Federal Chancellor ("Bundeskanzler") with central executive authority. Since the 1961 election, the two major parties (CDU/CSU and SPD) call their leading candidates for the federal election "chancellor-candidate" ("Kanzlerkandidat"), although this is not an official term and any party can nominate a Kanzlerkandidat (even if there is no chance at all to lead or even become part of a government coalition). The Federal Government ("Bundesregierung") consists of the Federal Chancellor and his or her cabinet ministers, called "Bundesminister" (Federal Ministers).
The chancellor's authority emanates from the provisions of the Basic Law and from his or her status as leader of the party (or coalition of parties) holding a majority of seats in the "Bundestag" ("Federal Diet", the lower house of the German Federal Parliament). With the exception of Helmut Schmidt, the chancellor has usually also been chairman of his or her own party. This was the case with Chancellor Gerhard Schröder from 1999 until he resigned the chairmanship of the SPD in 2004.
The first chancellor, Konrad Adenauer, set many precedents that continue today. He arrogated nearly all major decisions to himself, and established the chancellorship as the clear focus of power in Germany. He often treated his ministers as mere extensions of his authority rather than colleagues - which they are according to the German constitution as the Chancellor sets the guidelines for all fields of government policy. While his successors have tended to be less domineering, the chancellor has acquired enough ex officio authority (in addition to his constitutional powers) that Germany is often described by constitutional law experts as a "chancellor democracy."
The chancellor determines the composition of the Federal Cabinet. The President formally appoints and dismisses cabinet ministers, at the recommendation of the chancellor; no parliamentary approval is needed. According to the Basic Law, the chancellor may set the number of cabinet ministers and dictate their specific duties. Chancellor Ludwig Erhard had the largest cabinet, with twenty-two ministers in the mid-1960s. Helmut Kohl presided over 17 ministers at the start of his fourth term in 1994; the 2002 cabinet, the second of Chancellor Gerhard Schröder, had 13 ministers and the Angela Merkel cabinet as of 22 November 2005 has 15.
Article 65 of the Basic Law sets forth three principles that define how the executive branch functions:
Appointment mechanism.
Every four years, after national elections and the convocation of the newly elected members of the "Bundestag" ("Federal Diet", the lower house of the German Federal Parliament), the Federal Chancellor is elected by a majority of the members of the "Bundestag" upon the proposal of the President ("Bundespräsident", literally "Federal President"). This vote is one of the few cases where a majority of all elected members of the "Bundestag" must be achieved, as opposed to a mere majority of those that are currently assembled. This is referred to as the "Kanzlermehrheit" (chancellor's majority), and is designed to ensure the establishment of a stable government. It has in the past occasionally forced ill or pregnant members to have to attend parliament when a party's majority was only slim.
Unlike regular voting by the "Bundestag", the vote to elect the chancellor is by secret ballot. This is intended to ensure that the chancellor's majority does not depend on members of his or her party only outwardly showing support.
If the nominee of the President is not elected, the "Bundestag" may elect its own nominee within fourteen days. If no-one is elected within this period, the "Bundestag" will attempt an election. If the person with the highest number of votes has a majority, the President must appoint him or her. If the person with the highest number of votes does not have a majority, the President may either appoint them or call new elections for the "Bundestag". As all chancellors have been elected in the first vote as yet (1949–2010) neither of these constitutional provisions has been applied.
The Federal Chancellor is the only member of the federal government elected by the "Bundestag". The other cabinet ministers (called "Bundesminister", "Federal Ministers") are chosen by the Federal Chancellor himself or herself, although they are formally appointed by the Federal President on the Federal Chancellor's proposal.
Confidence.
Unlike in other parliamentary legislatures, the "Bundestag" or "Federal Diet" (lower house of the German Federal Parliament) cannot remove the Chancellor with a traditional motion of no confidence. Instead, the removal of a Chancellor is only possible when the majority of the "Bundestag" members agrees on a successor, who is then immediately sworn in as new Federal Chancellor. This procedure is called "constructive motion of no confidence" "(konstruktives Misstrauensvotum)" and was created to avoid the situation that existed in the Weimar Republic, where it was easier to gather a parliament majority willing to remove a government in office than to find a majority capable of supporting a new stable government.
In order to garner legislative support in the "Bundestag", the chancellor can also ask for a motion of confidence ("Vertrauensfrage", literally "question of trust"), either combined with a legislative proposal or as a standalone vote. Only if such a vote fails may the Federal President dissolve the "Bundestag".
Style of address.
The correct style of address in German is "Herr Bundeskanzler" (male) or "Frau Bundeskanzlerin" (female). Use of the mixed form "Frau Bundeskanzler" was deprecated by the government in 2004 because it is regarded as impolite.
Salary.
Holding the third-highest state office available within the Federal Republic of Germany, the Chancellor of Germany receives €220,000 per annum and a €22,000 bonus, i.e. one and two thirds of Salary Grade B11 (according to § 11 (1) a of the Federal Law on MinistresBundesministergesetz, BGBl. 1971 I p. 1166 and attachment IV to the Federal Law on Salaries of OfficersBundesbesoldungsgesetz, BGBl. 2002 I p. 3020).

</doc>
<doc id="60564" url="https://en.wikipedia.org/wiki?curid=60564" title="Takeru Kobayashi">
Takeru Kobayashi

Competition and records.
Born in Nagano, Japan, Kobayashi set his first record at his rookie appearance on July 4, 2001, when he ate 50 hot dogs in 12 minutes at the Nathan's Coney Island Hot Dog Eating Contest, doubling the previous record of 25. The record was so unexpected that when Kobayashi got to the later numbers, the organizers ran out of signs indicating how many dogs Kobayashi had eaten and had to resort to handwritten signs. Kobayashi would go on to break his own record three times in winning the contest six consecutive times (2001–2006).
In the 2006 Krystal Square Off, Kobayashi's mark of 97 hamburgers was 30 better than his winning total in 2005 and 28 better than the World Record he set in 2004.
At a speed-eating contest in Hong Kong on August 13, 2005, Kobayashi consumed 83 vegetarian jiaozi dumplings in 8 minutes. The next day, he ate 100 roasted pork buns in 12 minutes. Kobayashi also won the 2005 Alka-Seltzer US Open of Competitive Eating, a three-hour IFOCE elimination tournament on ESPN, as well as the Glutton Bowl, a two-hour IFOCE eating special that aired on the Fox Network in 2002. However, on Fox's 2003 show "Man vs. Beast", Kobayashi lost in an eating competition against a 1089-pound Kodiak bear, when he ate 31 bunless hot dogs in 2 minutes and 36 seconds to the bear's 50. In a 2014 interview, Kobayashi claims to have beaten the bear in the rehearsal. (In October 2012, Kobayashi broke the record held by the bear at the Texas state fair.)
On August 5, 2006, Kobayashi set yet another world record at the Johnsonville World Bratwurst Eating Championship in Sheboygan, Wisconsin, by downing 58 bratwurst sausages in 10 minutes, shattering the previous record of 35 set the previous year by Sonya Thomas.
On September 23, 2006, Takeru Kobayashi set the world record at the Phantom Food Festival in Boston, Massachusetts, for eating 41 Summer Shack lobster rolls in 10 minutes, replacing the previous record of 22 rolls. Other world-eating records held by Kobayashi include of cow brains in 15 minutes and of rice balls in 30 minutes.
On June 25, 2007, Kobayashi announced on his blog that he seriously injured his jaw during training. He stated that he could only open his jaw about the width of a fingertip. Kobayashi's participation in the July 4, 2007, Nathan's contest continued as scheduled. He was able to eat a personal record 63 hot dogs, though his mark was bettered by Joey Chestnut's 66.
On July 4, 2008, Kobayashi once again competed in the Nathan's contest. He ate 59 hot dogs.
Kobayashi went on to defeat Joey Chestnut, on May 31, 2009, in a Pizza Hut P'Zone competition at Sony Studios in Culver City, California. The competition aired on Spike TV on June 21.
In July 2009, Kobayashi visited Puerto Rico in a special appearance for Taco Bell's Why Pay More Challenge, eating 64 tacos in 15 minutes for a local charity.
On July 4, 2009, he competed again in the Nathan's contest. He ate 64.5 hot dogs and buns.
On September 27, 2009, Kobayashi defeated Chestnut again with a score of 93 (68 Krystals, 5 Big Angus Burgers), earning the $20,000 top prize. Chestnut was second, with 81, and Pat "Deep Dish" Bertoletti finished third, with 76.
On July 4, 2011, Kobayashi competed on the rooftop of a Manhattan bar simultaneously with the Nathan's Contest at Coney Island via a live video simulcast of the event. Kobayashi finished 69 hot dogs, one more than the officially recognized previous world record. That world record stands as the highest ever eaten today.
On January 23, 2012. Kobayashi went on The Wendy Williams Show to set the record for eating the most Twinkies in one minute, for the "Save The Twinkie" campaign, and set a new world record of 14 Twinkies.
On February 3, 2012, Kobayashi set the new Wing Bowl record for eating chicken wings at Wing Bowl XX, held at the Wells Fargo Center in Philadelphia. His total was 337 wings in his first competition in that event.
On August 26, 2012, Kobayashi set the new world record at the New York State Fair in Syracuse for eating 110 hot dogs in 10 minutes.
In October 2012, Kobayashi set the new world record at the Texas State Fair for eating 60 hot dogs in 2 minutes 35 seconds.
On June 30, 2012, Kobayashi revealed the Major League Eating (MLE) contract he was required to sign in order to compete in Nathan's Fourth of July hot dog eating competition. The year-long contract limited him to $40,000 and took away any rights to endorse or engage in anything outside of what MLE mandated.
On July 4, 2012, Kobayashi competed in the Crif Dog Classic. He ate 58.5 hot dogs and buns.
On October 11, 2012, Kobayashi set the new world record at the Gringo Bandito Taco Challenge by eating 106 tacos in 10 minutes.
On July 21, 2013, Kobayashi defended his title at the Gringo Bandito Taco Challenge.
On October 6, 2013, Kobayashi won "LET 'EM EAT" Canada's biggest pizza eating contest for the fourth year in a row.
On August 4, 2014, Kobayashi set the new world record at "LET 'EM EAT" Canada's biggest pizza eating contest by eating 62 slices of pizza (15 and a half pizzas) in 12 minutes.
Training and techniques.
Kobayashi expands his stomach for a competition by eating larger and larger amounts of food, and then exercises to ensure that fat will not impede expansion of his stomach during a competition.
Kobayashi's official web site gives his height as 173 cm and his weight as 58 kg (128 lb). However he's weighed as much as 87 kg (192 lb) according to a June 29, 2006 blog entry. As of July 4, 2009, Kobayashi weighed in at 60 kg (132 lb) for the annual Fourth of July hot dog eating competition on Coney Island.
Kobayashi is also known for his trademark body wiggle, referred to by some as the "Kobayashi Shake", to force food down his esophagus and settle more compactly in his stomach. He eats hot dogs by splitting the frankfurter in half, dipping the buns in water, and then stuffing both parts in his mouth. He calls this the Solomon Method.
Arrest and contractual disputes.
July 4, 2010 arrest.
On June 28, 2010, Kobayashi announced he would not compete in the Nathan's Fourth of July Hot Dog Eating Competition. The impasse was reportedly due to the MLE's insistence that Kobayashi signed an exclusive contract with the organization that would prevent him from competing in contests not sanctioned by MLE.
On July 4, 2010, Kobayashi was in attendance at the Nathan's International Hot Dog Eating Contest, watching from the crowd. Wearing a black T-shirt that read "Free Kobi", Kobayashi mingled with the crowd, standing inside a police-barricaded pen just under the stage. After the competition ended, he slipped up the stage stairs and went onto the stage. Although he was initially ushered by security officers up to the stage, one security officer (thought to have been requested by George Shea), quickly arrested him from the back. Kobayashi resisted in surprise of what was happening to him, hanging on to the barricades and fences before being taken to the police car. Some witnesses reported that Kobayashi was attempting to congratulate the winner, Joey Chestnut, co-host and MLE President Richard Shea, stated that " tried to jump on stage during the awards ceremony to disrupt it." With the crowd chanting at him, Kobayashi was arrested. He was charged with resisting arrest, trespassing, and obstructing government administration and subsequently was taken to jail awaiting an appearance in Brooklyn Criminal Court.
Kobayashi's interpreter and publicist, Maggie James, said he had originally gone in hopes to cheer on his fellow competitive eaters, but after arriving and the chanting from the fans, he was swooped onto the stage due to the excitement. She said "There's a contract dispute, they weren't giving him his freedom. It was unfair."
Kobayashi told reporters he had a sandwich and a glass of milk while being held. "I am very hungry," he said. "I wish there were hot dogs in jail."
On August 5, 2010 all charges against Kobayashi were dismissed by a judge in Brooklyn. Despite his record six consecutive victories in their annual event, Nathan's removed Kobayashi's image from their "Wall of Fame" in 2011.
After Kobayashi left Nathan's, the hot dog contest lost sponsorship from Old Navy, Heinz Tomato Ketchup, Pepto-Bismol, and was down year-to-year. With an average 0.7 HH U.S. rating, it was off just a tenth of a point from 2012, when it aired on ESPN. ESPN averaged 1.949 million viewers for 2011's Nathan's Famous Hot Dog Eating Contest, but went down 41% to 1.15 million viewers in 2013.
July 4, 2011 competing events.
In 2011, Kobayashi was still barred from the annual Nathan's event due to the contract dispute. On July 4, he competed on the rooftop of a Manhattan bar, 230 Fifth, for the duration of the Coney Island contest. Two official judges from the Athletic Association of NY observed Kobayashi while the live broadcast of the event played next to him on a large television screen. Kobayashi finished with 69 hot dogs, becoming the first to set this world record, which to this day has not been surpassed.
July 4, 2012 competing events.
In 2012, Kobayashi was still barred from the annual Nathan's event due to the contract dispute. Kobayashi ate 58.5 at Crif dog classic, eating a different type hot dog from Nathan's Famous Fourth of July International Hot Dog Eating Contest.
July 4, 2014 competing events.
Kobayashi ate 113 bunless Nathan's hot dogs at 230 Fifth.
Other pursuits.
In 2005, Kobayashi appeared in ESPN sports center commercial.
In 2007, Kobayashi appeared in MasterCard commercial and Coors Light commercial.
In 2008 Kobayashi appeared in Western Canada Lottery Corporation commercial.
On May 30, 2009, Kobayashi attended the Spike Guys' Choice Awards.
In November 2010, Kobayashi appeared in a magazine featuring men's clothing published as an offshoot of V magazine, VMAN 20th Winter.
In November 2010, Kobayashi competed against Donkey Kong in a banana eating contest at the Rio-Can Centre in Toronto as part of the launch for Nintendo's Donkey Kong Country Returns.
On July 7, 2011, Kobayashi made a guest appearance at Hewlett Packard event 2011. The other guests were Snoop Dogg, Sugar Ray, Dan Finnerty, Third Eye Blind, Candlebox.
In 2011, Kobayashi appeared in TVB commercial.
In Spring 2011, Kobayashi appeared in his first major fashion editorial in Canada's The Block magazine as a model. Additionally, Kobayashi is an aspiring dog trainer, with six labradoodles he calls his "hot dogs."
On March 20, 2012, Kobayashi appeared in a Jake and Amir video produced by College Humor.
In June 2012, Kobayashi made a special guest appearance and a taco demonstration at The Offspring's release party for their album "Days Go By".
In 2012, Kobayashi appeared in Eight O'Clock Coffee, and Hofmann commercial.
In 2012, Kobayashi appeared alongside close childhood friend, Joe Rogan, on a celebrity edition of "Fear Factor".
In 2013, Kobayashi appeared in Just-Eat and Thuzio commercials.
Kobayashi has been featured on Late Night with Jimmy Falon, Saturday Night Live, MTV's True Life, MTV After Hours With Josh Horowitz, The Daily Show with Jon Stewart, The Wendy Williams Show and has done original features with Buzzfeed.com, CollegeHumor.com and SI.com, and is a featured user on the foodie mobile and web-based app Foodspotting.
On July 4, 2013, Kobayashi unveiled his new line of all-beef midwestern grain-fed hot dogs, known officially as "Kobi Dogs" at Eventi Hotel in New York.
On September 16, 2014, he appeared in a YouTube video to be competing with a hamster. The video ends in Kobayashi acknowledging his defeat by putting a medal around the hamster's neck.
On September 22, 2015, Kobayashi, along with Patrick Bertoletti, Kevin Strahle and Bob Shoudt consumed a 40-pound goat in 13 minutes and 22 seconds at Taco In A Bag in Chicago.
Kobayashi's eating abilities partially inspired the King of the Hill (season 7) episode, "The Fat and the Furious." This episode originally aired on November 10, 2002.
Kobayashi also helped inspire the 2005 episode "Dog eat Dog." The episode features a victim who ate himself to death, in part from eating several hot dogs at a hot dog eating contest.
Kobayashi is mentioned by Will Ferrell's character, Ricky Bobby in the 2006 film, "".
Kobayashi appears in the ending cinematic of level three, "Around the World in 80 Bites" in the 2007 video game, The Simpsons Game.

</doc>
<doc id="60567" url="https://en.wikipedia.org/wiki?curid=60567" title="President of Germany">
President of Germany

The President of Germany, officially the President of the Federal Republic of Germany (German: "Bundespräsident der Bundesrepublik Deutschland"),</ref> is the head of state of Germany.
Germany has a parliamentary system of government in which the Federal Chancellor is the nation's leading political figure and "de facto" chief executive. However, the President has a role which, while not an executive post, is more than ceremonial. Presidents have extensive discretion regarding the way they exercise their official duties. The Federal President gives direction to general political and societal debates and has some important "reserve powers" in case of political instability (such as those provided for by Article 81 of the Basic Law).
Under Article 59 (1) of the Basic Law (German Constitution), the Federal President represents the Federal Republic of Germany in matters of international law, concludes treaties with foreign states on its behalf and accredits diplomats. Furthermore, all federal laws must be signed by the President before they can come into effect; however, he or she can only veto a law that he/she believes to violate the constitution.
The Federal President, by his or her actions and public appearances, represents the state itself, its existence, its legitimacy, and unity. The President's office involves an integrative role and the control function of upholding the law and the constitution. It is a matter of political tradition – not legal restrictions – that the Federal President generally does not comment routinely on issues in the news, particularly when there is some controversy among the political parties. This distance from day-to-day politics and daily governmental issues allows the Federal President to be a source of clarification, to influence public debate, to voice criticism, offer suggestions and make proposals. In order to exercise this power, he/she traditionally acts above party politics.
The current officeholder is Joachim Gauck who was elected on 18 March 2012.
Selection.
The president is elected by secret ballot, without debate, for a term of five years by the Federal Convention which mirrors the aggregated majority situation of the Bundestag and the parliaments of the 16 German federal states. The convention consists of all Bundestag members as well as an equal number of delegates chosen by the legislatures of the "Länder" (states). The delegates of each "Land" to the Federal Convention are elected by the members of the state legislature under a form of proportional representation. However it is not required that "Land" delegates themselves be members of a legislature; often prominent citizens are chosen.
In total, the Federal Convention numbers more than one thousand members. The German constitution, the Basic Law, requires that it be convened no later than thirty days before the expiration of the sitting president's term. The body is convened and chaired by the President of the German Bundestag. From 1979 to 2009, all these conventions have been held on 23 May, the date of the foundation of the Federal Republic in 1949. However, the two latest elections were held on different dates after the incumbent presidents stepped down before the end of their terms since they had to be held within 30 days of Horst Köhler's and Christian Wulff's resignations in 2010 and 2012 respectively.
In the first two rounds of the election process, the Federal Convention attempts to elect a president by an absolute majority of votes cast. If, after two votes, no single candidate has received this level of support, in the third and final vote the candidate endorsed by a plurality of votes cast is elected. 
The process of electing the president is usually determined by party politics. Usually, the candidate of the majority party or coalition in the Bundestag is considered to be the likely winner. However, if the opposition has turned in a strong showing in state elections, it can potentially have enough support to defeat the government's candidate. For this reason, presidential elections can indicate the result of an upcoming general election. According to a long-standing adage in German politics, "if you can create a president, you can form a government." 
Qualifications.
The office of president is open to all Germans who are entitled to vote in Bundestag elections and have reached the age of 40, but no one may serve more than two consecutive five-year terms. The president must not be a member of the federal government or of a legislature at either the federal or state level.
Oath.
On taking office the president must take the following oath, stipulated by Article 56 of the Basic Law, before the assembled members of the Bundestag and Bundesrat (however he or she is permitted to omit the religious references if so desired):
I swear that I will dedicate my efforts to the well-being of the German people, enhance their benefits, avert harm from them, uphold and defend the Constitution and the statutes of the Federation, fulfil my duties conscientiously, and do justice to all. (So help me God.)
Duties and functions.
The Federal President is involved in the formation of the Federal Government and remains in close cooperation with it. Basically the President is free to act on his own accord. However, according to Article 58 of the German constitution, most orders and directives of the Federal President require the countersignature of the Federal Chancellor or the corresponding Federal Minister. This rule ensures the coherence of government action. Therefore, the Federal President also receives the Federal Chancellor regularly for talks on current policy issues. He or she also holds talks with individual Federal Ministers and other senior officials at his own discretion. The "Head of the Office of the Federal President" represents the President in the meetings of the Federal Cabinet and reports back to the Federal President.
The Federal President's most prominent duties include:
Appointment of the Federal Government.
The Federal President proposes an individual as Federal Chancellor and then, provided he or she is subsequently elected by the Bundestag, appoints him or her to the office. However, the Bundestag is free to disregard the president's proposal and elect another individual to the post, whom the president is then obliged to appoint. The president appoints and dismisses the remaining members of the Federal Government "upon the proposal of the Chancellor." The president can dismiss the Chancellor, but only in the event that the Bundestag passes a Constructive Vote of No Confidence. If this occurs, the president must dismiss the chancellor and appoint the successor requested by the Bundestag.
Other appointments.
The president appoints federal judges, federal civil servants and military officers. All such appointments require the counter-signature of either the chancellor or the relevant cabinet minister.
Dissolution of the Bundestag.
In the event that the Bundestag elects an individual for the office of chancellor by a plurality of votes, rather than a majority, the president can, at his or her discretion, either appoint that individual as chancellor or dissolve the Bundestag, triggering a new election. In the event that a vote of confidence is defeated in the Bundestag, and the incumbent chancellor proposes a dissolution, the president may, at his discretion, dissolve the body within 21 days. As of 2010, this power has only been applied three times in the history of the Federal Republic. In all three occurrences it is doubtful whether the motives for that dissolution were in accordance with the constitution's intentions. Each time the incumbent chancellor called for the vote of confidence with the stated intention of being defeated, in order to be able to call for new elections before the end of their regular term, as the Basic Law does not give the Bundestag a right to dissolve itself. The most recent occurrence was on 1 July 2005, when Chancellor Gerhard Schröder asked for a vote of confidence, which was defeated.
Promulgation of the law.
All federal laws must, after counter-signature, be signed by the president before they can come into effect. Upon signing, the president has to check if the law was passed according to the order mandated by the constitution and/or if the content of the law is constitutional. If not, he or she has the right (and, some argue, the duty) to refuse to sign the law. This has happened rather rarely.
Foreign relations.
The president represents Germany in the World (Art. 59 Basic Law), holds foreign visits and receives foreign dignitaries. He or she also concludes treaties with foreign nations (which do not come into effect until affirmed by the Bundestag), accredits German diplomats and receives the letters of accreditation of foreign diplomats.
Pardons and honours.
According to Article 60 (2) of the German Constitution the Federal President exercises the power to pardon. This means he "has the authority to revoke or commute penal or disciplinary sentences in individual cases. The Federal President cannot, however, issue an amnesty waiving or commuting sentences for a whole category of offences. That requires a law enacted by the German Bundestag in conjunction with the Bundesrat. Due to the federal structure of Germany the Federal President is only responsible for dealing with certain criminal matters (e.g. espionage and terrorism) and disciplinary proceedings against federal civil servants, federal judges and soldiers".
State of legislational emergency.
In the event of a national crisis, the Basic Law designates the president as a mediator. If the Bundestag rejects a motion of confidence, but neither a new chancellor is elected nor the Bundestag is dissolved, the president may, by request of the cabinet, declare a "legislative state of emergency", which is quite different from a conventional state of emergency: If it is declared, during a limited period of time, bills proposed by the cabinet and designated as "urgent", but rejected by the Bundestag, become law nonetheless, if the Bundesrat does pass them. But the legislative state of emergency does not suspend basic human rights nor does it grant the executive branch any exceptional power. Such an emergency has never been declared.
Politics and influence.
Though candidates are usually selected by a political party or parties, the president nonetheless is traditionally expected to refrain from being an active member of any party after assuming office. Every president to date has let his or her party membership rest dormant during his term of office. Presidents have, however, spoken publicly about their personal views on political matters. The very fact that a president is expected to remain above politics usually means that when he does speak out on an issue, it is considered to be of great importance. In some cases, a presidential speech has dominated German political debate for a year or more.
Reserve powers.
According to article 81 of the German constitution the president can declare an "Legislation Emergency" and allow the federal government and the Bundesrat to enact laws without the approval of the Bundestag (lower house of parliament). He also has important decisive power regarding the appointment of a chancellor who was elected by a relative majority only, or the dissolution of the Bundestag under certain circumstances.
It is also theoretically possible, albeit a drastic step which has not happened since 1945, that the president refuses to sign legislation merely because he disagrees with its content, thus vetoing it, or refuse to approve a cabinet appointment. In all cases in which a bill was not signed by the Federal President, all presidents have claimed that the bill in question was manifestly unconstitutional. For example, in the autumn of 2006, President Köhler did so twice within three months. Also, in some cases, a president has signed a law while asking that the political parties refer the case to the Federal Constitutional Court in order to test the law's constitutionality.
Succession.
The Basic Law did not create an office of vice president. If the president is outside of the country, or the position is vacant, the President of the Bundesrat (a position that is rotated among the state premiers on an annual basis) temporarily assumes the powers of the president until a successor is elected without assuming the office of president as such. While doing so, he or she does not continue to exercise the role of chair of the Bundesrat. If the president dies, resigns or is otherwise removed from office, a successor is to be elected within thirty days. This process was triggered for the first time on May 31, 2010, when Horst Köhler resigned the office, as all his predecessors (with the exception of Heinrich Lübke, who announced in 1968 that he would resign the following year, his resignation taking effect after the regular election of his successor and just three months before the scheduled end of his term of office) had served their terms in full. Jens Böhrnsen, Mayor of Bremen and at the time President of the Bundesrat, assumed the powers and duties of head of state. The same took place in 2012 after Christian Wulff resigned; then Horst Seehofer, Minister President of Bavaria, as President of the Bundesrat assumed the powers and duties of head of state.
Impeachment and removal.
While in office the president enjoys immunity from prosecution and cannot be voted out of office or recalled. The only mechanism for removing the president is impeachment by the Bundestag or Bundesrat for willfully violating German law. Once the Bundestag impeaches the president, the Federal Constitutional Court is charged with determining if he or she is guilty of the offence. If the charge is sustained the court has the authority to remove the president from office.
Presidential office and symbols.
Office.
The Office of the Federal President is a supreme federal authority. It organizes the President's work, supports the Federal President in the performance of his duties as Head of State and coordinates his working relationships to other parts of the German government and administration. Its top official, who takes precedence over all other German state secretaries, is the Head of the Office of the Federal President. The office and its staff advises the Federal President, informs him of all developments in domestic and foreign affairs and carries out the instructions of the Federal President or forwards these to the corresponding ministry or authority.
Residences.
The official residence of the Federal President is Bellevue Palace in Berlin. The President's second official residence is the Hammerschmidt Villa in the former capital city of West Germany Bonn.
Transportation.
The Federal President's car is usually black, made in Germany and has the numberplate "0 – 1" with the presidential standard on the right wing of the car. The President also uses a VIP helicopter operated by the Federal Police and VIP aircraft (Bombardier Global 5000, Airbus A319CJ, Airbus A310 or A340) operated by the German Ministry of Defence. When the President is on board, the flight's callsign is "German Airforce 001".
Presidential standard.
The standard of the President of Germany was adopted on 11 April 1921, and used in this design until 1933. A slightly modified version also existed from 1926, that was used in addition to the 1921 version. In 1933, these versions were both replaced by another modified version, that was used until 1935.
The Weimar-era presidential standard from 1921 was adopted again as presidential standard by a decision by President Theodor Heuss on 20 January 1950, when he also formally adopted other Weimar-era state symbols including the coat of arms. The eagle ("Reichsadler", now called "Bundesadler") in the design that was used in the coat of arms and presidential standard in the Weimar Republic and today was originally introduced by a decision by President Friedrich Ebert on 11 November 1919.
History.
The modern day position of German President is significantly different from the Reich President of the Weimar Republic – a position which held considerable power and was regarded as a Supreme Government Executive.
Weimar Republic.
The position of President of Germany was first established by the Weimar Constitution, which was drafted in the aftermath of World War I and the abdication of Emperor Wilhelm II in 1918. In Germany the new head of state was called the "Reichspräsident".
Friedrich Ebert (SPD) served as Germany's first president, followed by Paul von Hindenburg. The office effectively came to an end upon Hindenburg's death in 1934 and its powers merged with those of Chancellor. Adolf Hitler now ruled Germany as "Führer und Reichskanzler", combining his previous positions in party and government. The office however was not abolished and briefly revived at the end of the Second World War when Hitler appointed Grand Admiral Karl Dönitz as his successor as President of Germany. Dönitz agreed to the surrender to the Allies and was arrested a few days later.
The Weimar Constitution created a semi-presidential system in which power was divided between the president, a cabinet and a parliament. The president enjoyed far greater power than the current president and had an active political role, rather than a largely ceremonial one. The influence of the president also increased greatly as a result of the instability of the Weimar period. The president had authority to appoint the Chancellor and could dismiss the entire cabinet at any time. However it was also necessary for the cabinet to enjoy the confidence of the Reichstag (parliament) because it could be removed by a vote of no confidence. All bills had to receive the signature of the president to become law and, although he did not have an absolute veto on legislation, he could insist that a law be submitted for the approval of voters in a referendum. The president also had authority to dissolve the Reichstag, conduct foreign affairs, and command the armed forces. Article 48 of the constitution also provided the president sweeping powers in the event of a crisis. If there was a threat to "public order and security" he could legislate by decree and suspend civil rights.
The Weimar constitution provided that the president be directly elected and serve a seven-year term. The election involved a form of the two-round system. However the first president was elected by the National Assembly and subsequently only two direct presidential elections actually occurred. These were the election of Paul von Hindenburg in 1925 and his re-election in 1932.
The system created by the Weimar constitution led to a number of problems. In particular, the fact that the president could appoint the cabinet, while the Reichstag had only a power of dismissal, created a high cabinet turn-over as ministers were appointed by the president only to be dismissed by the Reichstag shortly afterwards. Eventually Hindenburg stopped trying to appoint cabinets that enjoyed the confidence of the Reichstag and ruled by means of three "presidential cabinets" ("Präsidialkabinette"). Hindenburg was also able to use his power of dissolution to by-pass the Reichstag. If the Reichstag threatened to censure his ministers or revoke one of his decrees he could simply dissolve the body and be able to govern without its interference until elections had been held. This led to eight Reichstag elections taking place in the 14 years of the Republic's existence; only one parliamentary term, that of 1920–1924, was completed without elections being held early.
German Democratic Republic (East Germany).
Socialist East Germany established the office of a head of state with the title of President of the Republic (German: "Präsident der Republik") in 1949, but abandoned the office with the death of the first president, Wilhelm Pieck, in 1960 in favour of a collective head of state. All government positions of the East German socialist republic, including the presidency, were appointed by the ruling Socialist Unity Party of Germany.
Federal Republic of Germany (West Germany).
With the promulgation of the Grundgesetz in 1949, the office of President (in German: "Bundespräsident") was created in West Germany. Partly due to the misuse of presidential powers in the Weimar Republic, the office's powers were significantly reduced. Not only is he indirectly elected, but most of the real power was transferred to the federal chancellor.
Because the reunification of Germany in 1990 was accomplished by the five East German states joining the Federal Republic, the Federal President became the President of all German states.

</doc>
<doc id="60569" url="https://en.wikipedia.org/wiki?curid=60569" title="Rectifier">
Rectifier

A rectifier is an electrical device that converts alternating current (AC), which periodically reverses direction, to direct current (DC), which flows in only one direction. The process is known as rectification. Physically, rectifiers take a number of forms, including vacuum tube diodes, mercury-arc valves, copper and selenium oxide rectifiers, semiconductor diodes, silicon-controlled rectifiers and other silicon-based semiconductor switches. Historically, even synchronous electromechanical switches and motors have been used. Early radio receivers, called crystal radios, used a "cat's whisker" of fine wire pressing on a crystal of galena (lead sulfide) to serve as a point-contact rectifier or "crystal detector".
Rectifiers have many uses, but are often found serving as components of DC power supplies and high-voltage direct current power transmission systems. Rectification may serve in roles other than to generate direct current for use as a source of power. As noted, detectors of radio signals serve as rectifiers. In gas heating systems flame rectification is used to detect presence of a flame.
Because of the alternating nature of the input AC sine wave, the process of rectification alone produces a DC current that, though unidirectional, consists of pulses of current. Many applications of rectifiers, such as power supplies for radio, television and computer equipment, require a "steady" constant DC current (as would be produced by a battery). In these applications the output of the rectifier is smoothed by an electronic filter (usually a capacitor) to produce a steady current.
More complex circuitry that performs the opposite function, converting DC to AC, is called an inverter.
Rectifier devices.
Before the development of silicon semiconductor rectifiers, vacuum tube thermionic diodes and copper oxide- or selenium-based metal rectifier stacks were used. With the introduction of semiconductor electronics, vacuum tube rectifiers became obsolete, except for some enthusiasts of vacuum tube audio equipment. For power rectification from very low to very high current, semiconductor diodes of various types (junction diodes, Schottky diodes, etc.) are widely used.
Other devices that have control electrodes as well as acting as unidirectional current valves are used where more than simple rectification is required—e.g., where variable output voltage is needed. High-power rectifiers, such as those used in high-voltage direct current power transmission, employ silicon semiconductor devices of various types. These are thyristors or other controlled switching solid-state switches, which effectively function as diodes to pass current in only one direction.
Rectifier circuits.
Rectifier circuits may be single-phase or multi-phase (three being the most common number of phases). Most low power rectifiers for domestic equipment are single-phase, but three-phase rectification is very important for industrial applications and for the transmission of energy as DC (HVDC).
Single-phase rectifiers.
Half-wave rectification.
In half-wave rectification of a single-phase supply, either the positive or negative half of the AC wave is passed, while the other half is blocked. Because only one half of the input waveform reaches the output, mean voltage is lower. Half-wave rectification requires a single diode in a single-phase supply, or three in a three-phase supply. Rectifiers yield a unidirectional but pulsating direct current; half-wave rectifiers produce far more ripple than full-wave rectifiers, and much more filtering is needed to eliminate harmonics of the AC frequency from the output.
The no-load output DC voltage of an ideal half-wave rectifier for a sinusoidal input voltage is:
where:
Full-wave rectification.
A full-wave rectifier converts the whole of the input waveform to one of constant polarity (positive or negative) at its output. Full-wave rectification converts both polarities of the input waveform to pulsating DC (direct current), and yields a higher average output voltage. Two diodes and a center tapped transformer, or four diodes in a bridge configuration and any AC source (including a transformer without center tap), are needed. Single semiconductor diodes, double diodes with common cathode or common anode, and four-diode bridges, are manufactured as single components.
For single-phase AC, if the transformer is center-tapped, then two diodes back-to-back (cathode-to-cathode or anode-to-anode, depending upon output polarity required) can form a full-wave rectifier. Twice as many turns are required on the transformer secondary to obtain the same output voltage than for a bridge rectifier, but the power rating is unchanged.
The average and root-mean-square no-load output voltages of an ideal single-phase full-wave rectifier are:
Very common double-diode rectifier vacuum tubes contained a single common cathode and two anodes inside a single envelope, achieving full-wave rectification with positive output. The 5U4 and 5Y3 were popular examples of this configuration.
Three-phase rectifiers.
Single-phase rectifiers are commonly used for power supplies for domestic equipment. However, for most industrial and high-power applications, three-phase rectifier circuits are the norm. As with single-phase rectifiers, three-phase rectifiers can take the form of a half-wave circuit, a full-wave circuit using a center-tapped transformer, or a full-wave bridge circuit.
Thyristors are commonly used in place of diodes to create a circuit that can regulate the output voltage. Many devices that provide direct current actually "generate" three-phase AC. For example, an automobile alternator contains six diodes, which function as a full-wave rectifier for battery charging.
Three-phase, half-wave circuit.
An uncontrolled three-phase, half-wave circuit requires three diodes, one connected to each phase. This is the simplest type of three-phase rectifier but suffers from relatively high harmonic distortion on both the AC and DC connections. This type of rectifier is said to have a pulse-number of three, since the output voltage on the DC side contains three distinct pulses per cycle of the grid frequency.
Three-phase, full-wave circuit using center-tapped transformer.
If the AC supply is fed via a transformer with a center tap, a rectifier circuit with improved harmonic performance can be obtained. This rectifier now requires six diodes, one connected to each end of each transformer secondary winding. This circuit has a pulse-number of six, and in effect, can be thought of as a six-phase, half-wave circuit.
Before solid state devices became available, the half-wave circuit, and the full-wave circuit using a center-tapped transformer, were very commonly used in industrial rectifiers using mercury-arc valves. This was because the three or six AC supply inputs could be fed to a corresponding number of anode electrodes on a single tank, sharing a common cathode.
With the advent of diodes and thyristors, these circuits have become less popular and the three-phase bridge circuit has become the most common circuit.
Three-phase bridge rectifier.
For an uncontrolled three-phase bridge rectifier, six diodes are used, and the circuit again has a pulse number of six. For this reason, it is also commonly referred to as a six-pulse bridge.
For low-power applications, double diodes in series, with the anode of the first diode connected to the cathode of the second, are manufactured as a single component for this purpose. Some commercially available double diodes have all four terminals available so the user can configure them for single-phase split supply use, half a bridge, or three-phase rectifier.
For higher-power applications, a single discrete device is usually used for each of the six arms of the bridge. For the very highest powers, each arm of the bridge may consist of tens or hundreds of separate devices in parallel (where very high current is needed, for example in aluminium smelting) or in series (where very high voltages are needed, for example in high-voltage direct current power transmission).
For a three-phase full-wave diode rectifier, the ideal, no-load average output voltage is
If thyristors are used in place of diodes, the output voltage is reduced by a factor cos(α):
Or, expressed in terms of the line to line input voltage:
Where:
The above equations are only valid when no current is drawn from the AC supply or in the theoretical case when the AC supply connections have no inductance. In practice, the supply inductance causes a reduction of DC output voltage with increasing load, typically in the range 10–20% at full load.
The effect of supply inductance is to slow down the transfer process (called commutation) from one phase to the next. As result of this is that at each transition between a pair of devices, there is a period of overlap during which three (rather than two) devices in the bridge are conducting simultaneously. The overlap angle is usually referred to by the symbol μ (or u), and may be 20 30° at full load.
With supply inductance taken into account, the output voltage of the rectifier is reduced to:
The overlap angle μ is directly related to the DC current, and the above equation may be re-expressed as:
Where:
Twelve-pulse bridge.
Although better than single-phase rectifiers or three-phase half-wave rectifiers, six-pulse rectifier circuits still produce considerable harmonic distortion on both the AC and DC connections. For very high-power rectifiers the twelve-pulse bridge connection is usually used. A twelve-pulse bridge consists of two six-pulse bridge circuits connected in series, with their AC connections fed from a supply transformer that produces a 30° phase shift between the two bridges. This cancels many of the characteristic harmonics the six-pulse bridges produce.
The 30 degree phase shift is usually achieved by using a transformer with two sets of secondary windings, one in star (wye) connection and one in delta connection.
Voltage-multiplying rectifiers.
The simple half-wave rectifier can be built in two electrical configurations with the diode pointing in opposite directions, one version connects the negative terminal of the output direct to the AC supply and the other connects the positive terminal of the output direct to the AC supply. By combining both of these with separate output smoothing it is possible to get an output voltage of nearly double the peak AC input voltage. This also provides a tap in the middle, which allows use of such a circuit as a split rail power supply.
A variant of this is to use two capacitors in series for the output smoothing on a bridge rectifier then place a switch between the midpoint of those capacitors and one of the AC input terminals. With the switch open, this circuit acts like a normal bridge rectifier. With the switch closed, it act like a voltage doubling rectifier. In other words, this makes it easy to derive a voltage of roughly 320 V (±15%, approx.) DC from any 120 V or 230 V mains supply in the world, this can then be fed into a relatively simple switched-mode power supply. However, for a given desired ripple, the value of both capacitors must be twice the value of the single one required for a normal bridge rectifier; when the switch is closed each one must filter the output of a half-wave rectifier, and when the switch is open the two capacitors are connected in series with an equivalent value of half one of them.
Rectifier efficiency.
Rectifier efficiency (η) is defined as the ratio of DC output power to the input power from the AC supply. Even with ideal rectifiers with no losses, the efficiency is less than 100% because some of the output power is AC power rather than DC which manifests as ripple superimposed on the DC waveform. For a half-wave rectifier efficiency is very poor,
Thus maximum efficiency for a half-wave rectifier is,
Similarly, for a full-wave rectifier,
Efficiency is reduced by losses in transformer windings and power dissipation in the rectifier element itself. Efficiency can be improved with the use of smoothing circuits which reduce the ripple and hence reduce the AC content of the output. Three-phase rectifiers, especially three-phase full-wave rectifiers, have much greater efficiencies because the ripple is intrinsically smaller. In some three-phase and multi-phase applications the efficiency is high enough that smoothing circuitry is unnecessary.
Rectifier losses.
A real rectifier characteristically drops part of the input voltage (a voltage drop, for silicon devices, of typically 0.7 volts plus an equivalent resistance, in general non-linear)—and at high frequencies, distorts waveforms in other ways. Unlike an ideal rectifier, it dissipates some power.
An aspect of most rectification is a loss from the peak input voltage to the peak output voltage, caused by the built-in voltage drop across the diodes (around 0.7 V for ordinary silicon p–n junction diodes and 0.3 V for Schottky diodes). Half-wave rectification and full-wave rectification using a center-tapped secondary produces a peak voltage loss of one diode drop. Bridge rectification has a loss of two diode drops. This reduces output voltage, and limits the available output voltage if a very low alternating voltage must be rectified. As the diodes do not conduct below this voltage, the circuit only passes current through for a portion of each half-cycle, causing short segments of zero voltage (where instantaneous input voltage is below one or two diode drops) to appear between each "hump".
Peak loss is very important for low voltage rectifiers (for example, 12 V or less) but is insignificant in high-voltage applications such as HVDC.
Rectifier output smoothing.
While half-wave and full-wave rectification can deliver unidirectional current, neither produces a constant voltage. Producing steady DC from a rectified AC supply requires a smoothing circuit or filter. In its simplest form this can be just a reservoir capacitor or smoothing capacitor, placed at the DC output of the rectifier. There is still an AC ripple voltage component at the power supply frequency for a half-wave rectifier, twice that for full-wave, where the voltage is not completely smoothed.
Sizing of the capacitor represents a tradeoff. For a given load, a larger capacitor reduces ripple but costs more and creates higher peak currents in the transformer secondary and in the supply that feeds it. The peak current is set in principle by the rate of rise of the supply voltage on the rising edge of the incoming sine-wave, but in practice it is reduced by the resistance of the transformer windings. In extreme cases where many rectifiers are loaded onto a power distribution circuit, peak currents may cause difficulty in maintaining a correctly shaped sinusoidal voltage on the ac supply.
To limit ripple to a specified value the required capacitor size is proportional to the load current and inversely proportional to the supply frequency and the number of output peaks of the rectifier per input cycle. The load current and the supply frequency are generally outside the control of the designer of the rectifier system but the number of peaks per input cycle can be affected by the choice of rectifier design.
A half-wave rectifier only gives one peak per cycle, and for this and other reasons is only used in very small power supplies. A full wave rectifier achieves two peaks per cycle, the best possible with a single-phase input. For three-phase inputs a three-phase bridge gives six peaks per cycle. Higher numbers of peaks can be achieved by using transformer networks placed before the rectifier to convert to a higher phase order.
To further reduce ripple, a capacitor-input filter can be used. This complements the reservoir capacitor with a choke (inductor) and a second filter capacitor, so that a steadier DC output can be obtained across the terminals of the filter capacitor. The choke presents a high impedance to the ripple current. For use at power-line frequencies inductors require cores of iron or other magnetic materials, and add weight and size. Their use in power supplies for electronic equipment has therefore dwindled in favour of semiconductor circuits such as voltage regulators.
A more usual alternative to a filter, and essential if the DC load requires very low ripple voltage, is to follow the reservoir capacitor with an active voltage regulator circuit. The reservoir capacitor must be large enough to prevent the troughs of the ripple dropping below the minimum voltage required by the regulator to produce the required output voltage. The regulator serves both to significantly reduce the ripple and to deal with variations in supply and load characteristics. It would be possible to use a smaller reservoir capacitor (these can be large on high-current power supplies) and then apply some filtering as well as the regulator, but this is not a common strategy. The extreme of this approach is to dispense with the reservoir capacitor altogether and put the rectified waveform straight into a choke-input filter. The advantage of this circuit is that the current waveform is smoother and consequently the rectifier no longer has to deal with the current as a large current pulse, but instead the current delivery is spread over the entire cycle. The disadvantage, apart from extra size and weight, is that the voltage output is much lower – approximately the average of an AC half-cycle rather than the peak.
Applications.
The primary application of rectifiers is to derive DC power from an AC supply (AC to DC converter). Virtually all electronic devices require DC, so rectifiers are used inside the power supplies of virtually all electronic equipment.
Converting DC power from one voltage to another is much more complicated. One method of DC-to-DC conversion first converts power to AC (using a device called an inverter), then uses a transformer to change the voltage, and finally rectifies power back to DC. A frequency of typically several tens of kilohertz is used, as this requires much smaller inductance than at lower frequencies and obviates the use of heavy, bulky, and expensive iron-cored units.
Rectifiers are also used for detection of amplitude modulated radio signals. The signal may be amplified before detection. If not, a very low voltage drop diode or a diode biased with a fixed voltage must be used. When using a rectifier for demodulation the capacitor and load resistance must be carefully matched: too low a capacitance makes the high frequency carrier pass to the output, and too high makes the capacitor just charge and stay charged.
Rectifiers supply polarised voltage for welding. In such circuits control of the output current is required; this is sometimes achieved by replacing some of the diodes in a bridge rectifier with thyristors, effectively diodes whose voltage output can be regulated by switching on and off with phase fired controllers.
Thyristors are used in various classes of railway rolling stock systems so that fine control of the traction motors can be achieved. Gate turn-off thyristors are used to produce alternating current from a DC supply, for example on the Eurostar Trains to power the three-phase traction motors.
Rectification technologies.
Electromechanical.
Before about 1905 when tube type rectifiers were developed, power conversion devices were purely electro-mechanical in design. Mechanical rectification systems used some form of rotation or resonant vibration (e.g. vibrators) driven by electromagnets, which operated a switch or commutator to reverse the current.
These mechanical rectifiers were noisy and had high maintenance requirements. The moving parts had friction, which required lubrication and replacement due to wear. Opening mechanical contacts under load resulted in electrical arcs and sparks that heated and eroded the contacts. They also were not able to handle AC frequencies above several thousand cycles per second.
Synchronous rectifier.
To convert alternating into direct current in electric locomotives, a synchronous rectifier may be used . It consists of a synchronous motor driving a set of heavy-duty electrical contacts. The motor spins in time with the AC frequency and periodically reverses the connections to the load at an instant when the sinusoidal current goes through a zero-crossing. The contacts do not have to "switch" a large current, but they must be able to "carry" a large current to supply the locomotive's DC traction motors.
Vibrating rectifier.
These consisted of a resonant reed, vibrated by an alternating magnetic field created by an AC electromagnet, with contacts that reversed the direction of the current on the negative half cycles. They were used in low power devices, such as battery chargers, to rectify the low voltage produced by a step-down transformer. Another use was in battery power supplies for portable vacuum tube radios, to provide the high DC voltage for the tubes. These operated as a mechanical version of modern solid state switching inverters, with a transformer to step the battery voltage up, and a set of vibrator contacts on the transformer core, operated by its magnetic field, to repeatedly break the DC battery current to create a pulsing AC to power the transformer. Then a second set of rectifier contacts on the vibrator rectified the high AC voltage from the transformer secondary to DC.
Motor-generator set.
A "motor-generator set", or the similar "rotary converter", is not strictly a rectifier as it does not actually "rectify" current, but rather "generates" DC from an AC source. In an "M-G set", the shaft of an AC motor is mechanically coupled to that of a DC generator. The DC generator produces multiphase alternating currents in its armature windings, which a commutator on the armature shaft converts into a direct current output; or a homopolar generator produces a direct current without the need for a commutator. M-G sets are useful for producing DC for railway traction motors, industrial motors and other high-current applications, and were common in many high-power D.C. uses (for example, carbon-arc lamp projectors for outdoor theaters) before high-power semiconductors became widely available.
Electrolytic.
The electrolytic rectifier was a device from the early twentieth century that is no longer used. A home-made version is illustrated in the 1913 book "The Boy Mechanic" but it would only be suitable for use at very low voltages because of the low breakdown voltage and the risk of electric shock. A more complex device of this kind was patented by G. W. Carpenter in 1928 (US Patent 1671970).
When two different metals are suspended in an electrolyte solution, direct current flowing one way through the solution sees less resistance than in the other direction. Electrolytic rectifiers most commonly used an aluminum anode and a lead or steel cathode, suspended in a solution of tri-ammonium ortho-phosphate.
The rectification action is due to a thin coating of aluminum hydroxide on the aluminum electrode, formed by first applying a strong current to the cell to build up the coating. The rectification process is temperature-sensitive, and for best efficiency should not operate above 86 °F (30 °C). There is also a breakdown voltage where the coating is penetrated and the cell is short-circuited. Electrochemical methods are often more fragile than mechanical methods, and can be sensitive to usage variations, which can drastically change or completely disrupt the rectification processes.
Similar electrolytic devices were used as lightning arresters around the same era by suspending many aluminium cones in a tank of tri-ammonium ortho-phosphate solution. Unlike the rectifier above, only aluminium electrodes were used, and used on A.C., there was no polarization and thus no rectifier action, but the chemistry was similar.
The modern electrolytic capacitor, an essential component of most rectifier circuit configurations was also developed from the electrolytic rectifier.
Plasma type.
Mercury-arc.
A rectifier used in high-voltage direct current (HVDC) power transmission systems and industrial processing between about 1909 to 1975 is a "mercury-arc rectifier" or "mercury-arc valve". The device is enclosed in a bulbous glass vessel or large metal tub. One electrode, the cathode, is submerged in a pool of liquid mercury at the bottom of the vessel and one or more high purity graphite electrodes, called anodes, are suspended above the pool. There may be several auxiliary electrodes to aid in starting and maintaining the arc. When an electric arc is established between the cathode pool and suspended anodes, a stream of electrons flows from the cathode to the anodes through the ionized mercury, but not the other way (in principle, this is a higher-power counterpart to flame rectification, which uses the same one-way current transmission properties of the plasma naturally present in a flame).
These devices can be used at power levels of hundreds of kilowatts, and may be built to handle one to six phases of AC current. Mercury-arc rectifiers have been replaced by silicon semiconductor rectifiers and high-power thyristor circuits in the mid 1970s. The most powerful mercury-arc rectifiers ever built were installed in the Manitoba Hydro Nelson River Bipole HVDC project, with a combined rating of more than 1 GW and 450 kV.
Argon gas electron tube.
The General Electric Tungar rectifier was an argon gas-filled electron tube device with a tungsten filament cathode and a carbon button anode. It operated similarly to the thermionic vacuum tube diode, but the gas in the tube ionized during forward conduction, giving it a much lower forward voltage drop so it could rectify lower voltages. It was used for battery chargers and similar applications from the 1920s until lower-cost metal rectifiers, and later semiconductor diodes, supplanted it. These were made up to a few hundred volts and a few amperes rating, and in some sizes strongly resembled an incandescent lamp with an additional electrode.
The 0Z4 was a gas-filled rectifier tube commonly used in vacuum tube car radios in the 1940s and 1950s. It was a conventional full-wave rectifier tube with two anodes and one cathode, but was unique in that it had no filament (thus the "0" in its type number). The electrodes were shaped such that the reverse breakdown voltage was much higher than the forward breakdown voltage. Once the breakdown voltage was exceeded, the 0Z4 switched to a low-resistance state with a forward voltage drop of about 24 V.
Vacuum tube (valve).
The thermionic vacuum tube diode, originally called the Fleming valve, was invented by John Ambrose Fleming in 1904 as a detector for radio waves in radio receivers, and evolved into a general rectifier. It consisted of an evacuated glass bulb with a filament heated by a separate current, and a metal plate anode. The filament emitted electrons by thermionic emission (the Edison effect), discovered by Thomas Edison in 1884, and a positive voltage on the plate caused a current of electrons through the tube from filament to plate. Since only the filament produced electrons, the tube would only conduct current in one direction, allowing the tube to rectify an alternating current.
Vacuum diode rectifiers were widely used in power supplies in vacuum tube consumer electronic products, such as phonographs, radios, and televisions, for example the All American Five radio receiver, to provide the high DC plate voltage needed by other vacuum tubes. "Full-wave" versions with two separate plates were popular because they could be used with a center-tapped transformer to make a full-wave rectifier. Vacuum rectifiers were made for very high voltages, such as the high voltage power supply for the cathode ray tube of television receivers, and the kenotron used for power supply in X-ray equipment. However, compared to modern semiconductor diodes, vacuum rectifiers have high internal resistance due to space charge and therefore high voltage drops, causing high power dissipation and low efficiency. They are rarely able to handle currents exceeding 250 mA owing to the limits of plate power dissipation, and cannot be used for low voltage applications, such as battery chargers. Another limitation of the vacuum tube rectifier is that the heater power supply often requires special arrangements to insulate it from the high voltages of the rectifier circuit.
In musical instrument amplification (especially for electric guitars), the slight delay or "sag" between a signal increase (for instance, when a guitar chord is struck hard and fast) and the corresponding increase in output voltage is a notable effect of tube rectification, and results in compression. The choice between tube rectification and diode rectification is a matter of taste; some amplifiers have both and allow the player to choose.
Solid state.
Crystal detector.
The cat's-whisker detector was the earliest type of semiconductor diode. It consisted of a crystal of some semiconducting mineral, usually galena (lead sulfide), with a light springy wire touching its surface. Invented by Jagadish Chandra Bose and developed by G. W. Pickard around 1906, it served as the radio wave rectifier in the first widely used radio receivers, called crystal radios. Its fragility and limited current capability made it unsuitable for power supply applications. It became obsolete around 1920, but later versions served as microwave detectors and mixers in radar receivers during World War 2.
Selenium and copper oxide rectifiers.
Once common until replaced by more compact and less costly silicon solid-state rectifiers in the 1970s, these units used stacks of metal plates and took advantage of the semiconductor properties of selenium or copper oxide. While selenium rectifiers were lighter in weight and used less power than comparable vacuum tube rectifiers, they had the disadvantage of finite life expectancy, increasing resistance with age, and were only suitable to use at low frequencies. Both selenium and copper oxide rectifiers have somewhat better tolerance of momentary voltage transients than silicon rectifiers.
Typically these rectifiers were made up of stacks of metal plates or washers, held together by a central bolt, with the number of stacks determined by voltage; each cell was rated for about 20 V. An automotive battery charger rectifier might have only one cell: the high-voltage power supply for a vacuum tube might have dozens of stacked plates. Current density in an air-cooled selenium stack was about 600 mA per square inch of active area (about 90 mA per square centimeter).
Silicon and germanium diodes.
In the modern world, silicon diodes are the most widely used rectifiers for lower voltages and powers, and have largely replaced earlier germanium diodes. For very high voltages and powers, the added need for controllability has in practice led to replacing simple silicon diodes with high-power thyristors (see below) and their newer actively gate-controlled cousins.
High power: thyristors (SCRs) and newer silicon-based voltage sourced converters.
In high-power applications, from 1975 to 2000, most mercury valve arc-rectifiers were replaced by stacks of very high power thyristors, silicon devices with two extra layers of semiconductor, in comparison to a simple diode.
In medium-power transmission applications, even more complex and sophisticated voltage sourced converter (VSC) silicon semiconductor rectifier systems, such as insulated gate bipolar transistors (IGBT) and gate turn-off thyristors (GTO), have made smaller high voltage DC power transmission systems economical. All of these devices function as rectifiers.
Current research.
A major area of research is to develop higher frequency rectifiers, that can rectify into terahertz and light frequencies. These devices are used in optical heterodyne detection, which has myriad applications in optical fiber communication and atomic clocks. Another prospective application for such devices is to directly rectify light waves picked up by tiny antenna, called nantennas, to produce DC electric power. It is thought that arrays of nantennas could be a more efficient means of producing solar power than solar cells.
A related area of research is to develop smaller rectifiers, because a smaller device has a higher cutoff frequency. Research projects are attempting to develop a unimolecular rectifier, a single organic molecule that would function as a rectifier.

</doc>
<doc id="60570" url="https://en.wikipedia.org/wiki?curid=60570" title="IBM POWER">
IBM POWER

IBM POWER may refer to:

</doc>
<doc id="60572" url="https://en.wikipedia.org/wiki?curid=60572" title="Visual Instruction Set">
Visual Instruction Set

Visual Instruction Set, or VIS, is a SIMD instruction set extension for SPARC V9 microprocessors developed by Sun Microsystems. There are four versions of VIS: VIS 1, VIS 2, VIS 2+, and VIS 3.
History.
VIS 1 was introduced in 1994 and was first implemented by Sun in their UltraSPARC microprocessor (1995) and by Fujitsu in their SPARC64 GP microprocessors (2000).
VIS 2 was first implemented by the UltraSPARC III. All subsequent UltraSPARC and SPARC64 microprocessors implement the instruction set.
VIS 3 was first implemented in the SPARC T4 microprocessor. 
Differences vs x86.
VIS is not an instruction toolkit like Intel's MMX and SSE. MMX has only 8 registers shared with the FPU stack, while SPARC processors have 32 registers, also aliased to the double-precision (64-bit) floating pointer registers.
As with the SIMD instruction set extensions on RISC processors, VIS strictly conform to the main principle of RISC: keep the instruction set concise and efficient.
This design is very different from comparable extensions on CISC processors, such as MMX, SSE, SSE2, SSE3, SSE4, 3DNow!.
Sometimes, programmers must use several VIS instructions to accomplish an operation that can be done with only one MMX or SSE instruction, but it should be kept in mind that fewer instructions do not automatically result in better performance.
Functionality.
VIS re-uses existing SPARC V9 64-bit floating point registers to hold multiple 8, 16, or 32-bit integer values. In this respect, VIS is more similar to the design of MMX than other SIMD architectures such as SSE/SSE2/AltiVec.
VIS includes a number of operations primarily for graphics support, so most of them are only for integers. These include 3D to 2D conversion, edge processing and pixel distance.
There are four ways to use VIS in code:

</doc>
