<doc id="60874" url="https://en.wikipedia.org/wiki?curid=60874" title="Photoluminescence">
Photoluminescence

Photoluminescence (abbreviated as PL) is light emission from any form of matter after the absorption of photons (electromagnetic radiation). It is one of many forms of luminescence (light emission) and is initiated by photoexcitation (excitation by photons), hence the prefix "photo-". Following excitation various relaxation processes typically occur in which other photons are re-radiated. Time periods between absorption and emission may vary: ranging from short femtosecond-regime for emission involving free-carrier plasma in inorganic semiconductors up to milliseconds for phosphorescent processes in molecular systems; and under special circumstances delay of emission may even span to minutes or hours.
Observation of photoluminescence at a certain energy can be viewed as indication that excitation populated an excited state associated with this transition energy.
While this is generally true in atoms and similar systems, correlations and other more complex phenomena also act as sources for photoluminescence in many-body systems such as semiconductors. A theoretical approach to handle this is given by the semiconductor luminescence equations.
Forms of photoluminescence.
Photoluminescence processes can be classified by various parameters such as the energy of the exciting photon with respect to the emission.
Resonant excitation describes a situation in which photons of a particular wavelength are absorbed and equivalent photons are very rapidly re-emitted. This is often referred to as resonance fluorescence. For materials in solution or in the gas phase, this process involves electrons but no significant internal energy transitions involving molecular features of the chemical substance between absorption and emission. In crystalline inorganic semiconductors where an electronic band structure is formed, secondary emission can be more complicated as events may contain both coherent such as resonant Rayleigh scattering where a fixed phase relation with the driving light field is maintained (i.e. energetically elastic processes where no losses are involved) and incoherent contributions (or inelastic modes where some energy channels into an auxiliary loss mode),
The latter originate, e.g., from the radiative recombination of excitons, Coulomb-bound electron-hole pair states in solids. Resonance fluorescence may also show significant quantum optical correlations.
More processes may occur when a substance undergoes internal energy transitions before re-emitting the energy from the absorption event. Electrons change energy states by either resonantly gaining energy from absorption of a photon or losing energy by emitting photons. In chemistry-related disciplines, one often distinguishes between fluorescence and phosphorescence. The prior is typically a fast process, yet some amount of the original energy is dissipated so that re-emitted light photons will have lower energy than did the absorbed excitation photons. The re-emitted photon in this case is said to be red shifted, referring to the reduced energy it carries following this loss (as the Jablonski diagram shows). For phosphorescence, absorbed photons undergo intersystem crossing where they enter into a state with altered spin multiplicity (see term symbol), usually a triplet state. Once energy from this absorbed electron is transferred in this triplet state, electron transition back to the lower singlet energy states is quantum mechanically forbidden, meaning that it happens much more slowly than other transitions. The result is a slow process of radiative transition back to the singlet state, sometimes lasting minutes or hours. This is the basis for "glow in the dark" substances.
Photoluminescence is an important technique for measuring the purity and crystalline quality of semiconductors such as GaAs and InP and for quantification of the amount of disorder present in a system. Several variations of photoluminescence exist, including photoluminescence excitation (PLE) spectroscopy.
Time-resolved photoluminescence (TRPL) is a method where the sample is excited with a light pulse and then the decay in photoluminescence with respect to time is measured. This technique is useful for measuring the minority carrier lifetime of III-V semiconductors like gallium arsenide (GaAs).
Photoluminescence properties of direct-gap semiconductors.
In a typical PL experiment, a semiconductor is excited with a light-source that provides photons with an energy larger than the bandgap energy.
The incoming light excites a polarization that can be described with the semiconductor Bloch equations. Once the photons are absorbed, electrons and holes are formed with finite momenta formula_1 in the conduction and valence bands, respectively. The excitations then undergo energy and momentum relaxation towards the band gap minimum. Typical mechanisms are Coulomb scattering and the interaction with phonons. Finally, the electrons recombine with holes under emission of photons.
Ideal, defect-free semiconductors are many-body systems where the interactions of charge-carriers and lattice vibrations have to be considered in addition to the light-matter coupling. In general, the PL properties are also extremely sensitive to internal electric fields and to the dielectric environment (such as in photonic crystals) which impose further degrees of complexity. A precise microscopic description is provided by the semiconductor luminescence equations.
Ideal quantum-well structures.
An ideal, defect-free semiconductor quantum well structure is a useful model system to illustrate the fundamental processes in typical PL experiments. The discussion is based on results published in Klingshirn (2012) and Balkan (1998).
The fictive model structure for this discussion has two confined quantized electronic and two hole subbands, e1, e2 and h1,h2, respectively.
The linear absorption spectrum of such a structure shows the exciton resonances of the first (e1h1) and the second quantum well subbands (e2h2), as well as the absorption from the corresponding continuum states and from the barrier.
Photoexcitation.
In general, three different excitation conditions are distinguished: resonant, quasi-resonant, and non-resonant. For the resonant excitation, the central energy of the laser corresponds to the lowest exciton resonance of the quantum well. No or only a negligible amount of the excess energy is injected to the carrier system. For these conditions, coherent processes contribute significantly to the spontaneous emission. The decay of polarization creates excitons directly. The detection of PL is challenging for resonant excitation as it is difficult to discriminate contributions from the excitation, i.e., stray-light and diffuse scattering from surface roughness. Thus, speckle and resonant Rayleigh-scattering are always superimposed to the incoherent emission.
In case of the non-resonant excitation, the structure is excited with some excess energy. This is the typical situation used in most PL experiments as the excitation energy can be discriminated using a spectrometer or an optical filter.
One has to distinguish between quasi-resonant excitation and barrier excitation.
For quasi-resonant conditions, the energy of the excitation is tuned above the ground state but still below the barrier absorption edge, for example, into the continuum of the first subband. The polarization decay for these conditions is much faster than for resonant excitation and coherent contributions to the quantum well emission are negligible. The initial temperature of the carrier system is significantly higher than the lattice temperature due to the surplus energy of the injected carriers. Finally, only the electron-hole plasma is initially created. It is then followed by the formation of excitons.
In case of barrier excitation, the initial carrier distribution in the quantum well strongly depends on the carrier scattering between barrier and the well.
Relaxation.
Initially, the laser light induces coherent polarization in the sample, i.e., the transitions between electron and hole states oscillate with the laser frequency and a fixed phase. The polarization dephases typically on a sub-100 fs time-scale in case of nonresonant excitation due to ultra-fast Coulomb- and phonon-scattering.
The dephasing of the polarization leads to creation of populations of electrons and holes in the conduction and the valence bands, respectively. 
The lifetime of the carrier populations is rather long, limited by radiative and non-radiative recombination such as Auger recombination.
During this lifetime a fraction of electrons and holes may form excitons, this topic is still controversially discussed in the literature.
The formation rate depends on the experimental conditions such as lattice temperature, excitation density, as well as on the general material parameters, e.g., the strength of the Coulomb-interaction or the exciton binding energy.
The characteristic time-scales are in the range of hundreds of picoseconds in GaAs; they appear to be much shorter in wide-gap semiconductors.
Directly after the excitation with short (femtosecond) pulses and the quasi-instantaneous decay of the polarization, the carrier distribution is mainly determined by the spectral width of the excitation, e.g., a laser pulse. The distribution is thus highly non-thermal and resembles a Gaussian distribution, centered at a finite momentum. In the first hundreds of femtoseconds, the carriers are scattered by phonons, or at elevated carrier densities via Coulomb-interaction. The carrier system successively relaxes to the Fermi–Dirac distribution typically within the first picosecond. Finally, the carrier system cools down under the emission of phonons. This can take up to several nanoseconds, depending on the material system, the lattice temperature, and the excitation conditions such as the surplus energy.
Initially, the carrier temperature decreases fast via emission of optical phonons. This is quite efficient due to the comparatively large energy associated with optical phonons, (36meV or 420K in GaAs) and their rather flat dispersion, allowing for a wide range of scattering processes under conservation of energy and momentum. Once the carrier temperature decreases below the value corresponding to the optical phonon energy, acoustic phonons dominate the relaxation. Here, cooling is less efficient due their dispersion and small energies and the temperature decreases much slower beyond the first tens of picoseconds. At elevated excitation densities, the carrier cooling is further inhibited by the so-called hot-phonon effect. The relaxation of a large number of hot carriers leads to a high generation rate of optical phonons which exceeds the decay rate into acoustic phonons. This creates a non-equilibrium "over-population" of optical phonons and thus causes their increased reabsorption by the charge-carriers significantly suppressing any cooling. A system thus cools slower, the higher the carrier density is.
Radiative recombination.
The emission directly after the excitation is spectrally very broad, yet still centered in the vicinity of the strongest exciton resonance. 
As the carrier distribution relaxes and cools, the width of the PL peak decreases and the emission energy shifts to match the ground state of the exciton for ideal samples without disorder. The PL spectrum approaches its quasi-steady-state shape defined by the distribution of electrons and holes. Increasing the excitation density will change the emission spectra. They are dominated by the excitonic ground state for low densities. Additional peaks from higher subband transitions appear as the carrier density or lattice temperature are increased as these states get more and more populated. Also, the width of the main PL peak increases significantly with rising excitation due to excitation-induced dephasing and the emission peak experiences a small shift in energy due to the Coulomb-renormalization and phase-filling.
In general, both exciton populations and plasma, uncorrelated electrons and holes, can act as sources for photoluminescence as described in the semiconductor-luminescence equations. Both yield very similar spectral features which are difficult to distinguish; their emission dynamics, however, vary significantly. The decay of excitons yields a single-exponential decay function since the probability of their radiative recombination does not depend on the carrier density. The probability of spontaneous emission for uncorrelated electrons and holes, is approximately proportional to the product of electron and hole populations eventually leading to a non-single-exponential decay described by a hyperbolic function.
Effects of disorder.
Real material systems always incorporate disorder. Examples are structural defects in the lattice or disorder due to variations of the chemical composition. Their treatment is extremely challenging for microscopic theories due to the lack of detailed knowledge about perturbations of the ideal structure. Thus, the influence of the extrinsic effects on the PL is usually addressed phenomenologically. In experiments, disorder can lead to localization of carriers and hence drastically increase the photoluminescence life times as localized carriers cannot as easily find nonradiative recombination centers as can free ones.
Photoluminescent material for temperature detection.
In phosphor thermometry, the temperature dependence of the photoluminescence process is exploited to measure temperature.

</doc>
<doc id="60875" url="https://en.wikipedia.org/wiki?curid=60875" title="Triboluminescence">
Triboluminescence

Triboluminescence is an optical phenomenon in which light is generated through the breaking of chemical bonds in a material when it is pulled apart, ripped, scratched, crushed, or rubbed (see tribology). The phenomenon is not fully understood, but appears to be caused by the separation and reunification of electrical charges. The term comes from the Greek τρίβειν ("to rub"; see tribology) and the Latin "lumen" (light). Triboluminescence can be observed when breaking sugar crystals and peeling adhesive tapes.
Triboluminescence is often used as a synonym for fractoluminescence (a term sometimes used when referring only to light emitted from fractured crystals). Triboluminescence differs from piezoluminescence in that a piezoluminescent material emits light when it is deformed, as opposed to broken. These are examples of mechanoluminescence, which is luminescence resulting from any mechanical action on a solid.
History.
Uncompahgre Ute Indians.
The Uncompahgre Ute Indians from Central Colorado are one of the first documented groups of people in the world credited with the application of mechanoluminescence involving the use of quartz crystals to generate light. The Ute constructed special ceremonial rattles made from buffalo rawhide which they filled with clear quartz crystals collected from the mountains of Colorado and Utah. When the rattles were shaken at night during ceremonies, the friction and mechanical stress of the quartz crystals impacting together produced flashes of light visible through the translucent buffalo hide.
Later descriptions.
The first recorded observation is attributed to English scholar Francis Bacon when he recorded in his 1620 "Novum Organum" that "It is well known that all sugar, whether candied or plain, if it be hard, will sparkle when broken or scraped in the dark." The scientist Robert Boyle also reported on some of his work on triboluminescence in 1663. In the late 1790s, sugar production began to produce more refined sugar crystals. These crystals were formed into a large solid cone for transport and sale. This solid cone of sugar had to be broken into usable chunks using a device known as sugar nips. People began to notice that as sugar was "nipped" in low light, tiny bursts of light were visible.
A historically important instance of triboluminescence occurred in Paris in 1675. Astronomer Jean-Felix Picard observed that his barometer was glowing in the dark as he carried it. His barometer consisted of a glass tube that was partially filled with mercury. Whenever the mercury slid down the glass tube, the empty space above the mercury would glow. While investigating this phenomenon, researchers discovered that static electricity could cause low-pressure air to glow. This discovery revealed the possibility of electric lighting.
Mechanism of action.
Materials scientists have not yet arrived at a full understanding of the effect, but the current theory of triboluminescence — based upon crystallographic, spectroscopic, and other experimental evidence — is that upon fracture of asymmetrical materials, charge is separated. When the charges recombine, the electric discharge ionizes the surrounding air, causing a flash of light. Research further suggests that crystals which display triboluminescence must lack symmetry (thus being anisotropic in order to permit charge separation) and be poor conductors. However, there are substances which break this rule, and which do not possess asymmetry, yet display triboluminescence anyway, such as hexakis(antipyrine)terbium iodide. It is thought that these materials contain impurities, which confer properties of asymmetry to the substance.
The biological phenomenon of triboluminescence is conditioned by recombination of free radicals during mechanical activation.
Examples.
A diamond may begin to glow while being rubbed. This occasionally happens to diamonds while a facet is being ground or the diamond is being sawn during the cutting process. Diamonds may fluoresce blue or red. Some other minerals, such as quartz, are triboluminescent, emitting light when rubbed together.
Ordinary Pressure-sensitive tape ("Scotch tape") displays a glowing line where the end of the tape is being pulled away from the roll. In 1953, Soviet scientists first observed that unpeeling a roll of tape in a vacuum produced X-rays. The mechanism of X-ray generation was studied further in 2008.
Also, when sugar crystals are crushed, tiny electrical fields are created, separating positive and negative charges that then create sparks while trying to reunite. Wint-O-Green Life Savers work especially well for creating such sparks, because wintergreen oil (methyl salicylate) is fluorescent and converts ultraviolet light into blue light.
Triboluminescence is biological phenomen observed in mechanical deformation and contact electrization of epidermal surface of osseous and soft tissues, at chewing food, at friction in joints of vertebrae, during sexual intercourse, and during blood circulation.
Fractoluminescence.
"Fractoluminescence" is often used as a synonym for triboluminescence. It is the emission of light from the fracture (rather than rubbing) of a crystal, but fracturing often occurs with rubbing. Depending upon the atomic and molecular composition of the crystal, when the crystal fractures a charge separation can occur making one side of the fractured crystal positively charged and the other side negatively charged. Like in triboluminescence, if the charge separation results in a large enough electric potential, a discharge across the gap and through the bath gas between the interfaces can occur. The potential at which this occurs depends upon the dielectric properties of the bath gas.
EMR propagation during fracturing.
The emission of electromagnetic radiation (EMR) during plastic deformation and crack propagation in metals and rocks have been studied. The EMR emissions from metals and alloys have also been explored and confirmed. Molotskii presented a dislocation mechanism for this type of EMR emissions. Recently, Srilakshmi and Misra reported an additional phenomenon of secondary EMR during plastic deformation and crack propagation in uncoated and metal-coated metals and alloys.
Theory.
EMR during the micro-plastic deformation and crack propagation from several metals and alloys and transient magnetic field generation during necking in ferromagnetic metals were reported by Misra (1973–75), which have been confirmed and explored by several researchers. Tudik and Valuev (1980) were able to measure the EMR frequency during tensile fracture of iron and aluminum in the region 1014¬¬ Hz by using photomultipliers. Srilakshmi and Misra (2005a) also reported an additional phenomenon of secondary electromagnetic radiation in uncoated and metal-coated metals and alloys. If a solid material is subjected to stresses of large amplitudes, which can cause plastic deformation and fracture, emissions such as thermal, acoustic, ions, exo-emissions occur. With the discovery of new materials and advancement in instrumentation to measure effects of EMR, crack formation and fracture; the EMR emissions effect becomes important.
Deformation induced EMR.
The study of deformation is essential for the development of new materials. Deformation in metals depends on temperature, type of stress applied, strain rate, oxidation and corrosion. Deformation induced EMR can be divided into three categories: effects in ionic crystal materials; effects in rocks and granites; and, effects in metals and alloys. EMR emission depends on the orientation of the grains in individual crystals since material properties are different in differing directions. Amplitude of EMR pulse increases as long as the crack continues to grow as new atomic bonds are broken and it leads to EMR. Pulse starts to decay when crack halts. Observations from experiments showed that emitted EMR signals contain mixed frequency components.
Test methods to measure EMR.
Most widely tensile test method is used to characterize the mechanical properties of materials. From any complete tensile test record, one can obtain important informations about the material’s elastic properties, the character and extent of plastic deformation, yield and tensile strengths and toughness. These informations which can be obtained from one test justifies the extensive use of tensile test in engineering materials research. Therefore, investigations of EMR emissions are mainly based on the tensile test of the specimens.
From experiments, it can be shown that tensile crack formation excites more intensive EMR than shear cracking, increasing the elasticity, strength and loading rate during uniaxial loading increases amplitude. Poissions ratio is a key parameter for EMR characterization during triaxial compression. If the poissions ratio is lower, it is harder for the material to strain transversally and hence higher is the probability of new fractures. Mechanism of plastic deformation is very important for safe operation of any component under dynamic conditions.
Uses and applications.
This EMR can be utilized in developing sensors/smart materials. This technique can be implemented in powder metallurgy technique also. EMR is one of these emissions which accompany large deformation. If an element can be identified which gives maximum EMR response with minimum mechanical stimulus then it can be incorporated into main material and thus set new trends in the development of smart material. The deformation induced EMR can serve as a strong tool for failure detection and prevention.
Orel V.E. invented the device to measure EMR whole blood and lymphocytes in laboratory diagnostics.

</doc>
<doc id="60876" url="https://en.wikipedia.org/wiki?curid=60876" title="Markov chain">
Markov chain

A Markov chain (discrete-time Markov chain or DTMC), named after Andrey Markov, is a random process that undergoes transitions from one state to another on a state space. It must possess a property that is usually characterized as "memorylessness": the probability distribution of the next state depends only on the current state and not on the sequence of events that preceded it. This specific kind of "memorylessness" is called the Markov property. Markov chains have many applications as statistical models of real-world processes.
Introduction.
A Markov chain is a stochastic process with the Markov property. The term "Markov chain" refers to the sequence of random variables such a process moves through, with the Markov property defining serial dependence only between adjacent periods (as in a "chain"). It can thus be used for describing systems that follow a chain of linked events, where what happens next depends only on the current state of the system.
In the literature, different kinds of Markov process are designated as "Markov chains". Usually the term is reserved for a process with a discrete set of times, i.e. a discrete-time Markov chain (DTMC). On the other hand, a few authors use the term "Markov process" to refer to a continuous-time Markov chain without explicit mention.
While the time parameter is usually discrete, the state space of a Markov chain does not have any generally agreed-on restrictions: the term may refer to a process on an arbitrary state space. However, many applications of Markov chains employ finite or countably infinite (that is, discrete) state spaces, which have a more straightforward statistical analysis. Besides time-index and state-space parameters, there are many other variations, extensions and generalisations (see Variations). For simplicity, most of this article concentrates on the discrete-time, discrete state-space case, unless mentioned otherwise.
The changes of state of the system are called transitions. The probabilities associated with various state changes are called transition probabilities. The process is characterized by a state space, a transition matrix describing the probabilities of particular transitions, and an initial state (or initial distribution) across the state space. By convention, we assume all possible states and transitions have been included in the definition of the process, so there is always a next state, and the process does not terminate.
A discrete-time random process involves a system which is in a certain state at each step, with the state changing randomly between steps. The steps are often thought of as moments in time, but they can equally well refer to physical distance or any other discrete measurement. Formally, the steps are the integers or natural numbers, and the random process is a mapping of these to states. The Markov property states that the conditional probability distribution for the system at the next step (and in fact at all future steps) depends only on the current state of the system, and not additionally on the state of the system at previous steps.
Since the system changes randomly, it is generally impossible to predict with certainty the state of a Markov chain at a given point in the future. However, the statistical properties of the system's future can be predicted. In many applications, it is these statistical properties that are important.
A famous Markov chain is the so-called "drunkard's walk", a random walk on the number line where, at each step, the position may change by +1 or −1 with equal probability. From any position there are two possible transitions, to the next or previous integer. The transition probabilities depend only on the current position, not on the manner in which the position was reached. For example, the transition probabilities from 5 to 4 and 5 to 6 are both 0.5, and all other transition probabilities from 5 are 0. These probabilities are independent of whether the system was previously in 4 or 6.
Another example is the dietary habits of a creature who eats only grapes, cheese, or lettuce, and whose dietary habits conform to the following rules:
This creature's eating habits can be modeled with a Markov chain since its choice tomorrow depends solely on what it ate today, not what it ate yesterday or any other time in the past. One statistical property that could be calculated is the expected percentage, over a long period, of the days on which the creature will eat grapes.
A series of independent events (for example, a series of coin flips) satisfies the formal definition of a Markov chain. However, the theory is usually applied only when the probability distribution of the next step depends non-trivially on the current state.
Many other examples of Markov chains exist.
Formal definition.
A Markov chain is a sequence of random variables "X"1, "X"2, "X"3, ... with the Markov property, namely that the probability of moving to next state depends only on the present state and not on the previous states
The possible values of "X""i" form a countable set "S" called the state space of the chain.
Markov chains are often described by a sequence of directed graphs, where the edges of graph "n" are labeled by the probabilities of going from one state at time "n" to the other states at time "n+1", formula_3. The same information is represented by the transition matrix from time "n" to time "n+1". However, Markov chains are frequently assumed to be time-homogeneous (see variations below), in which case the graph and matrix are independent of "n" and are thus not presented as sequences.
These descriptions highlight the structure of the Markov chain that is independent of the initial distribution formula_4. When time-homogeneous, the chain can be interpreted as a state machine assigning a probability of hopping from each vertex or state to an adjacent one. The probability formula_5 of the machine's state can be analyzed as the statistical behavior of the machine with an element formula_6 of the state space as input, or as the behavior of the machine with the initial distribution formula_7 is the Iverson bracket.
The fact that some sequences of states might have zero probability of occurring corresponds to a graph with multiple connected components, where we omit edges that would carry a zero transition probability. For example, if "a" has a nonzero probability of going to "b", but "a" and "x" lie in different connected components of the graph, then formula_8 is defined, while formula_9 is not.
Example.
A state diagram for a simple example is shown in the figure on the right, using a directed graph to picture the state transitions. The states represent whether a hypothetical stock market is exhibiting a bull market, bear market, or stagnant market trend during a given week. According to the figure, a bull week is followed by another bull week 90% of the time, a bear week 7.5% of the time, and a stagnant week the other 2.5% of the time. Labelling the state space {1 = bull, 2 = bear, 3 = stagnant} the transition matrix for this example is
The distribution over states can be written as a stochastic row vector with the relation . So if at time the system is in state , then three time periods later, at time the distribution is
In particular, if at time the system is in state 2 (bear), then at time the distribution is
Using the transition matrix it is possible to calculate, for example, the long-term fraction of weeks during which the market is stagnant, or the average number of weeks it will take to go from a stagnant to a bull market. Using the transition probabilities, the steady-state probabilities indicate that 62.5% of weeks will be in a bull market, 31.25% of weeks will be in a bear market and 6.25% of weeks will be stagnant, since:
A thorough development and many examples can be found in the on-line monograph
Meyn & Tweedie 2005.
A finite state machine can be used as a representation of a Markov chain. Assuming a sequence of independent and identically distributed input signals (for example, symbols from a binary alphabet chosen by coin tosses), if the machine is in state "y" at time "n", then the probability that it moves to state "x" at time "n" + 1 depends only on the current state.
Transient evolution.
The probability of going from state "i" to state "j" in "n" time steps is
and the single-step transition is
For a time-homogeneous Markov chain:
and
The "n"-step transition probabilities satisfy the Chapman–Kolmogorov equation, that for any "k" such that 0 < "k" < "n",
where "S" is the state space of the Markov chain.
The marginal distribution Pr("X""n" = "x") is the distribution over states at time "n". The initial distribution is Pr("X"0 = "x"). The evolution of the process through one time step is described by
Note: The superscript ("n") is an index and not an exponent.
Properties.
Reducibility.
A state "j" is said to be accessible from a state "i" (written "i" → "j") if a system started in state "i" has a non-zero probability of transitioning into state "j" at some point. Formally, state "j" is accessible from state "i" if there exists an integer "nij" ≥ 0 such that
This integer is allowed to be different for each pair of states, hence the subscripts in nij.
Allowing "n" to be zero means that every state is defined to be accessible from itself.
A state "i" is said to communicate with state "j" (written "i" ↔ "j") if both "i" → "j" and "j" → "i". A set of states "C" is a communicating class if every pair of states in "C" communicates with each other. A communicating class is closed if the probability of leaving the class is zero, namely that if "i" is in "C" but "j" is not, then "j" is not accessible from "i". It can be shown that communication in this sense is an equivalence relation and thus that communicating classes are the equivalence classes of this relation.
The set of communicating classes forms a directed, acyclic graph by inheriting the arrows from the original state space. A communicating class is closed if and only if it has no outgoing arrows in this graph.
A state "i" is said to be essential or final if for all "j" such that "i" → "j" it is also true that "j" → "i". A state "i" is inessential if it is not essential. A state is final if and only if its communicating class is closed.
A Markov chain is said to be irreducible if its state space is a single communicating class; in other words, if it is possible to get to any state from any state.
Periodicity.
A state "i" has period "k" if any return to state "i" must occur in multiples of "k" time steps. Formally, the period of a state is defined as
(where "gcd" is the greatest common divisor) provided that this set is not empty. Otherwise the period is not defined. Note that even though a state has period "k", it may not be possible to reach the state in "k" steps. For example, suppose it is possible to return to the state in {6, 8, 10, 12, ...} time steps; "k" would be 2, even though 2 does not appear in this list.
If "k" = 1, then the state is said to be aperiodic: returns to state "i" can occur at irregular times. It can be demonstrated that a state "i" is aperiodic if and only if there exists "n" such that for all "n' ≥ n",
Otherwise ("k" > 1), the state is said to be periodic with period "k". A Markov chain is aperiodic if every state is aperiodic. An irreducible Markov chain only needs one aperiodic state to imply all states are aperiodic.
Every state of a bipartite graph has an even period.
Transience.
A state "i" is said to be transient if, given that we start in state "i", there is a non-zero probability that we will never return to "i". Formally, let the random variable "Ti" be the first return time to state "i" (the "hitting time"):
The number
is the probability that we return to state "i" for the first time after "n" steps.
Therefore, state "i" is transient if
State "i" is recurrent (or persistent) if it is not transient.
Recurrent states are guaranteed (with probability 1) to have a finite hitting time.
Recurrence and transience are class properties, that is, they either hold or do not hold equally for all members of a communicating class.
Mean recurrence time.
Even if the hitting time is finite with probability "1", it needs not have a finite expectation.
The mean recurrence time at state "i" is the expected return time "Mi":
State "i" is positive recurrent (or non-null persistent) if "Mi" is finite; otherwise, state "i" is null recurrent (or null persistent).
Expected number of visits.
It can be shown that a state "i" is recurrent if and only if the expected number of visits to this state is infinite, i.e.,
Absorbing states.
A state "i" is called absorbing if it is impossible to leave this state. Therefore, the state "i" is absorbing if and only if
If every state can reach an absorbing state, then the Markov chain is an absorbing Markov chain.
Ergodicity.
A state "i" is said to be ergodic if it is aperiodic and positive recurrent. In other words, a state "i" is ergodic if it is recurrent, has a period of "1" and it has finite mean recurrence time. If all states in an irreducible Markov chain are ergodic, then the chain is said to be ergodic.
It can be shown that a finite state irreducible Markov chain is ergodic if it has an aperiodic state. A Markov chain has the ergodic property if there's a finite number "N" such that any state can be reached from any other state in exactly "N" steps. In case of a fully connected transition matrix where all transitions have a non-zero probability, this condition is fulfilled with "N"=1. A Markov chain with more than one state and just one out-going transition per state cannot be ergodic.
Steady-state analysis and limiting distributions.
If the Markov chain is a time-homogeneous Markov chain, so that the process is described by a single, time-independent matrix formula_31, then the vector formula_32 is called a stationary distribution (or invariant measure) if formula_33 it satisfies
An irreducible chain has a stationary distribution if and only if all of its states are positive recurrent. In that case, "π" is unique and is related to the expected return time:
where formula_38 is the normalizing constant. Further, if the positive recurrent chain is both irreducible and aperiodic, it is said to have a "limiting" distribution; for any "i" and "j",
Note that there is no assumption on the starting distribution; the chain converges to the stationary distribution regardless of where it begins. Such "formula_40" is called the equilibrium distribution of the chain.
If a chain has more than one closed communicating class, its stationary distributions will not be unique (consider any closed communicating class formula_41 in the chain; each one will have its own unique stationary distribution formula_42. Extending these distributions to the overall chain, setting all values to zero outside the communication class, yields that the set of invariant measures of the original chain is the set of all convex combinations of the formula_42's). However, if a state "j" is aperiodic, then
and for any other state "i", let "fij" be the probability that the chain ever visits state "j" if it starts at "i",
If a state "i" is periodic with period "k" > 1 then the limit
does not exist, although the limit
does exist for every integer "r".
Steady-state analysis and the time-inhomogeneous Markov chain.
A Markov chain need not necessarily be time-homogeneous to have an equilibrium distribution. If there is a probability distribution over states formula_32 such that
for every state "j" and every time "n" then formula_32 is an equilibrium distribution of the Markov chain. Such can occur in Markov chain Monte Carlo (MCMC) methods in situations where a number of different transition matrices are used, because each is efficient for a particular kind of mixing, but each matrix respects a shared equilibrium distribution.
Finite state space.
If the state space is finite, the transition probability distribution can be represented by a matrix, called the transition matrix, with the ("i", "j")th element of P equal to
Since each row of P sums to one and all elements are non-negative, P is a right stochastic matrix.
Stationary distribution relation to eigenvectors and simplices.
A stationary distribution π is a (row) vector, whose entries are non-negative and sum to 1, is unchanged by the operation of transition matrix P on it and so is defined by
By comparing this definition with that of an eigenvector we see that the two concepts are related and that
is a normalized (formula_54) multiple of a left eigenvector e of the transition matrix PT with an eigenvalue of 1. If there is more than one unit eigenvector then a weighted sum of the corresponding stationary states is also a stationary state. But for a Markov chain one is usually more interested in a stationary state that is the limit of the sequence distributions for some initial distribution.
The values of stationary distribution formula_55 are associated with the state space of P and its eigenvectors have their relative proportions preserved. Since the components of π are positive and the constraint that their sum is unity can be rewritten as formula_56 we see that the dot product of π with a vector whose components are all 1 is unity and that π lies on a simplex.
Time-homogeneous Markov chain with a finite state space.
If the Markov chain is time-homogeneous, then the transition matrix P is the same after each step, so the "k"-step transition probability can be computed as the "k"-th power of the transition matrix, P"k".
If the Markov chain is irreducible and aperiodic, then there is a unique stationary distribution π. Additionally, in this case P"k" converges to a rank-one matrix in which each row is the stationary distribution π, that is,
where 1 is the column vector with all entries equal to 1. This is stated by the Perron–Frobenius theorem. If, by whatever means, formula_58 is found, then the stationary distribution of the Markov chain in question can be easily determined for any starting distribution, as will be explained below.
For some stochastic matrices P, the limit formula_59 does not exist while the stationary distribution does, as shown by this example:
Note that this example illustrates a periodic Markov chain.
Because there are a number of different special cases to consider, the process of finding this limit if it exists can be a lengthy task. However, there are many techniques that can assist in finding this limit. Let P be an "n"×"n" matrix, and define formula_62
It is always true that
Subtracting Q from both sides and factoring then yields
where I"n" is the identity matrix of size "n", and 0"n","n" is the zero matrix of size "n"×"n". Multiplying together stochastic matrices always yields another stochastic matrix, so Q must be a stochastic matrix (see the definition above). It is sometimes sufficient to use the matrix equation above and the fact that Q is a stochastic matrix to solve for Q. Including the fact that the sum of each the rows in P is 1, there are "n+1" equations for determining "n" unknowns, so it is computationally easier if on the one hand one selects one row in Q and substitute each of its elements by one, and on the other one substitute the corresponding element (the one in the same column) in the vector 0, and next left-multiply this latter vector by the inverse of transformed former matrix to find Q.
Here is one method for doing so: first, define the function "f"(A) to return the matrix A with its right-most column replaced with all 1's. If ["f"(P − In)]−1 exists then
One thing to notice is that if P has an element P"i","i" on its main diagonal that is equal to 1 and the "i"th row or column is otherwise filled with 0's, then that row or column will remain unchanged in all of the subsequent powers P"k". Hence, the "i"th row or column of Q will have the 1 and the 0's in the same positions as in P.
Convergence speed to the stationary distribution.
As stated earlier, from the equation formula_66, (if exists) the stationary (or steady state) distribution π is a left eigenvector of row stochastic matrix P. Then assuming that P is diagonalizable or equivalently that P has n linearly independent eigenvectors, speed of convergence is elaborated as follows. For non-diagonalizable matrices, one may start with the Jordan normal form of P and proceed with a bit more involved set of arguments in a similar way.
Let U be the matrix of eigenvectors (each normalized to having an L2 norm equal to 1) where each column is a left eigenvector of P and let Σ be the diagonal matrix of left eigenvalues of P, i.e. Σ = diag("λ"1,"λ"2,"λ"3...,"λ""n"). Then by eigendecomposition
Let the eigenvalues be enumerated such that 1 = |"λ"1| > |"λ"2| ≥ |"λ"3| ≥ ... ≥ |"λ""n"|. Since P is a row stochastic matrix, its largest left eigenvalue is 1. If there is a unique stationary distribution, then the largest eigenvalue and the corresponding eigenvector is unique too (because there is no other π which solves the stationary distribution equation above). Let u"i" be the "i"th column of U matrix, i.e. u"i" is the left eigenvector of P corresponding to λ"i". Also let x be a length n row vector that represents a valid probability distribution; since the eigenvectors u"i" span R"n", we can write
for some set of "a""i"∈ℝ. If we start multiplying P with x from left and continue this operation with the results, in the end we get the stationary distribution π. In other words, π = u"i" ← xPPP...P = xP"k" as "k" goes to infinity. That means
since UU−1 = I the identity matrix and power of a diagonal matrix is also a diagonal matrix where each entry is taken to that power.
since the eigenvectors are orthonormal. Then
Since π = u1, π("k") approaches to π as "k" goes to infinity with a speed in the order of "λ"2/"λ"1 exponentially. This follows because |"λ"2| ≥ |"λ"3| ≥ ... ≥ |"λ""n"|, hence "λ"2/"λ"1 is the dominant term. Random noise in the state distribution π can also speed up this convergence to the stationary distribution.
Reversible Markov chain.
A Markov chain is said to be reversible if there is a probability distribution π over its states such that
for all times "n" and all states "i" and "j".
This condition is known as the detailed balance condition (some books call it the local balance equation).
Considering a fixed arbitrary time "n" and using the shorthand
the detailed balance equation can be written more compactly as
The single time-step from "n" to "n"+1 can be thought of as each person "i" having "πi" dollars initially and paying each person "j" a fraction "pij" of it. The detailed balance condition states that upon each payment, the other person pays exactly the same amount of money back. Clearly the total amount of money π each person has remains the same after the time-step, since every dollar spent is balanced by a corresponding dollar received. This can be shown more formally by the equality
which essentially states that the total amount of money person "j" receives (including from himself) during the time-step equals the amount of money he pays others, which equals all the money he initially had because it was assumed that all money is spent (i.e. "pji" sums to 1 over "i"). The assumption is a technical one, because the money not really used is simply thought of as being paid from person "j" to himself (i.e. "pjj" is not necessarily zero).
As "n" was arbitrary, this reasoning holds for any "n", and therefore for reversible Markov chains π is always a steady-state distribution of Pr("X"n+1 = "j" | "X"n = "i") for every "n".
If the Markov chain begins in the steady-state distribution, "i.e.", if Pr("X"0 = "i") = π"i", then Pr("X""n" = "i") = π"i" for all "n" and the detailed balance equation can be written as
The left- and right-hand sides of this last equation are identical except for a reversing of the time indices "n" and "n" + 1.
Kolmogorov's criterion gives a necessary and sufficient condition for a Markov chain to be reversible directly from the transition matrix probabilities. The criterion requires that the products of probabilities around every closed loop are the same in both directions around the loop.
Reversible Markov chains are common in Markov chain Monte Carlo (MCMC) approaches because the detailed balance equation for a desired distribution π necessarily implies that the Markov chain has been constructed so that π is a steady-state distribution. Even with time-inhomogeneous Markov chains, where multiple transition matrices are used, if each such transition matrix exhibits detailed balance with the desired π distribution, this necessarily implies that π is a steady-state distribution of the Markov chain.
Closest reversible Markov chain.
For any time-homogeneous Markov chain given by a transition matrix formula_79, any norm formula_80 on formula_81 which is induced by a scalar product, and any probability vector formula_40, there exists a unique transition matrix formula_83 which is reversible according to formula_40
and which is closest to formula_85 according to the norm formula_86 The matrix formula_83 can be computed by solving a quadratic-convex optimization problem.
For example, consider the following Markov chain:
This Markov chain is not reversible. According to the Frobenius Norm the closest reversible Markov chain according to formula_88 can be computed as 
If we choose the probability vector randomly as formula_89, then the closest reversible Markov chain according to the Frobenius norm is approximately given by
Bernoulli scheme.
A Bernoulli scheme is a special case of a Markov chain where the transition probability matrix has identical rows, which means that the next state is even independent of the current state (in addition to being independent of the past states). A Bernoulli scheme with only two possible states is known as a Bernoulli process.
General state space.
For an overview of Markov chains on a general state space, see the article Markov chains on a measurable state space.
Harris chains.
Many results for Markov chains with finite state space can be generalized to chains with uncountable state space through Harris chains. The main idea is to see if there is a point in the state space that the chain hits with probability one. Generally, it is not true for continuous state space, however, we can define sets "A" and "B" along with a positive number "ε" and a probability
measure "ρ", such that
Then we could collapse the sets into an auxiliary point "α", and a recurrent Harris chain can be modified to contain "α". Lastly, the collection of Harris chains is a comfortable level of generality, which is broad enough to contain a large number of interesting examples, yet restrictive enough to allow for a rich theory.
The use of Markov chains in Markov chain Monte Carlo methods covers cases where the process follows a continuous state space.
Locally interacting Markov chains.
Considering a collection of Markov chains whose evolution takes in account the state of other Markov chains, is related to the notion
of locally interacting Markov chains. This corresponds to the situation when the state space has a (Cartesian-) product form.
See interacting particle system and stochastic cellular automata(probabilistic cellular automata).
See for instance "Interaction of Markov Processes"
or
Applications.
Research has reported the application and usefulness of Markov chains in a wide range of topics such as physics, chemistry, medicine, music, game theory and sports.
Physics.
Markovian systems appear extensively in thermodynamics and statistical mechanics, whenever probabilities are used to represent unknown or unmodelled details of the system, if it can be assumed that the dynamics are time-invariant, and that no relevant history need be considered which is not already included in the state description.
Chemistry.
Markov chains and continuous-time Markov processes are useful in chemistry when physical systems closely approximate the Markov property. The classical model of enzyme activity, Michaelis–Menten kinetics, can be viewed as a Markov chain, where at each time step the reaction proceeds in some direction. While Michaelis-Menten is fairly straightforward, far more complicated reaction networks can also be modeled with Markov chains.
An algorithm based on a Markov chain was also used to focus the fragment-based growth of chemicals in silico towards a desired class of compounds such as drugs or natural products. As a molecule is grown, a fragment is selected from the nascent molecule as the "current" state. It is not aware of its past (i.e., it is not aware of what is already bonded to it). It then transitions to the next state when a fragment is attached to it. The transition probabilities are trained on databases of authentic classes of compounds.
Also, the growth (and composition) of copolymers may be modeled using Markov chains. Based on the reactivity ratios of the monomers that make up the growing polymer chain, the chain's composition may be calculated (e.g., whether monomers tend to add in alternating fashion or in long runs of the same monomer). Due to steric effects, second-order Markov effects may also play a role in the growth of some polymer chains.
Similarly, it has been suggested that the crystallization and growth of some epitaxial superlattice oxide materials can be accurately described by Markov chains.
Testing.
Several theorists have proposed the idea of the Markov chain statistical test (MCST), a method of conjoining Markov chains to form a "Markov blanket", arranging these chains in several recursive layers ("wafering") and producing more efficient test sets—samples—as a replacement for exhaustive testing. MCSTs also have uses in temporal state-based networks; Chilukuri et al.'s paper entitled "Temporal Uncertainty Reasoning Networks for Evidence Fusion with Applications to Object Detection and Tracking" (ScienceDirect) gives a background and case study for applying MCSTs to a wider range of applications.
Speech recognition.
Hidden Markov models are the basis for most modern automatic speech recognition systems.
Information sciences.
Markov chains are used throughout information processing. Claude Shannon's famous 1948 paper "A Mathematical Theory of Communication", which in a single step created the field of information theory, opens by introducing the concept of entropy through Markov modeling of the English language. Such idealized models can capture many of the statistical regularities of systems. Even without describing the full structure of the system perfectly, such signal models can make possible very effective data compression through entropy encoding techniques such as arithmetic coding. They also allow effective state estimation and pattern recognition. Markov chains also play an important role in reinforcement learning.
Markov chains are also the basis for hidden Markov models, which are an important tool in such diverse fields as telephone networks (which use the Viterbi algorithm for error correction), speech recognition and bioinformatics (such as in rearrangements detection).
The LZMA lossless data compression algorithm combines Markov chains with Lempel-Ziv compression to achieve very high compression ratios.
Queueing theory.
Markov chains are the basis for the analytical treatment of queues (queueing theory). Agner Krarup Erlang initiated the subject in 1917. This makes them critical for optimizing the performance of telecommunications networks, where messages must often compete for limited resources (such as bandwidth).
Internet applications.
The PageRank of a webpage as used by Google is defined by a Markov chain. It is the probability to be at page formula_92 in the stationary distribution on the following Markov chain on all (known) webpages. If formula_93 is the number of known webpages, and a page formula_92 has formula_95 links to it then it has transition probability formula_96 for all pages that are linked to and formula_97 for all pages that are not linked to. The parameter formula_98 is taken to be about 0.85.
Markov models have also been used to analyze web navigation behavior of users. A user's web link transition on a particular website can be modeled using first- or second-order Markov models and can be used to make predictions regarding future navigation and to personalize the web page for an individual user.
Statistics.
Markov chain methods have also become very important for generating sequences of random numbers to accurately reflect very complicated desired probability distributions, via a process called Markov chain Monte Carlo (MCMC). In recent years this has revolutionized the practicability of Bayesian inference methods, allowing a wide range of posterior distributions to be simulated and their parameters found numerically.
Economics and finance.
Markov chains are used in finance and economics to model a variety of different phenomena, including asset prices and market crashes. The first financial model to use a Markov chain was from Prasad "et al." in 1974. Another was the regime-switching model of James D. Hamilton (1989), in which a Markov chain is used to model switches between periods of high volatility and low volatility of asset returns. A more recent example is the Markov Switching Multifractal model of Laurent E. Calvet and Adlai J. Fisher, which builds upon the convenience of earlier regime-switching models. It uses an arbitrarily large Markov chain to drive the level of volatility of asset returns.
Dynamic macroeconomics heavily uses Markov chains. An example is using Markov chains to exogenously model prices of equity (stock) in a general equilibrium setting.
Credit rating agencies produce annual tables of the transition probabilities for bonds of different credit ratings.
Social sciences.
Markov chains are generally used in describing path-dependent arguments, where current structural configurations condition future outcomes. An example is the reformulation of the idea, originally due to Karl Marx's Das Kapital, tying economic development to the rise of capitalism. In current research, it is common to use a Markov chain to model how once a country reaches a specific level of economic development, the configuration of structural factors, such as size of the commercial bourgeoisie, the ratio of urban to rural residence, the rate of political mobilization, etc., will generate a higher probability of transitioning from authoritarian to democratic regime.
Mathematical biology.
Markov chains also have many applications in biological modelling, particularly population processes, which are useful in modelling processes that are (at least) analogous to biological populations. The Leslie matrix is one such example, though some of its entries
are not probabilities (they may be greater than 1). Another example is the modeling of cell shape in dividing sheets of epithelial cells. Yet another example is the state of ion channels in cell membranes.
Markov chains are also used in simulations of brain function, such as the simulation of the mammalian neocortex.
Genetics.
Markov chains have been used in population genetics in order to describe the change in gene frequencies in small populations affected by genetic drift, for example in diffusion equation method described by Motoo Kimura.
Games.
Markov chains can be used to model many games of chance. The children's games Snakes and Ladders and "Hi Ho! Cherry-O", for example, are represented exactly by Markov chains. At each turn, the player starts in a given state (on a given square) and from there has fixed odds of moving to certain other states (squares).
Music.
Markov chains are employed in algorithmic music composition, particularly in software such as CSound, Max and SuperCollider. In a first-order chain, the states of the system become note or pitch values, and a probability vector for each note is constructed, completing a transition probability matrix (see below). An algorithm is constructed to produce output note values based on the transition matrix weightings, which could be MIDI note values, frequency (Hz), or any other desirable metric.
A second-order Markov chain can be introduced by considering the current state "and" also the previous state, as indicated in the second table. Higher, "n"th-order chains tend to "group" particular notes together, while 'breaking off' into other patterns and sequences occasionally. These higher-order chains tend to generate results with a sense of phrasal structure, rather than the 'aimless wandering' produced by a first-order system.
Markov chains can be used structurally, as in Xenakis's Analogique A and B. Markov chains are also used in systems which use a Markov model to react interactively to music input.
Usually musical systems need to enforce speciﬁc control constraints on the ﬁnite-length sequences they generate, but control constraints are not compatible with Markov models, since they induce long-range dependencies that violate the Markov hypothesis of limited memory. In order to overcome this limitation, a new approach has been proposed.
Baseball.
Markov chain models have been used in advanced baseball analysis since 1960, although their use is still rare. Each half-inning of a baseball game fits the Markov chain state when the number of runners and outs are considered. During any at-bat, there are 24 possible combinations of number of outs and position of the runners. Mark Pankin shows that Markov chain models can be used to evaluate runs created for both individual players as well as a team.
He also discusses various kinds of strategies and play conditions: how Markov chain models have been used to analyze statistics for game situations such as bunting and base stealing and differences when playing on grass vs. astroturf.
Markov text generators.
Markov processes can also be used to generate superficially real-looking text given a sample document: they are used in a variety of recreational "parody generator" software (see dissociated press, Jeff Harrison, Mark V Shaney
These processes are also used by spammers to inject real-looking hidden paragraphs into unsolicited email and post comments in an attempt to get these messages past spam filters.
In the bioinformatics field, they can be used to simulate DNA sequences.
Fitting.
When fitting a Markov chain to data, situations where parameters poorly describe the situation may highlight interesting trends.
History.
Andrey Markov produced the first results (1906) for these processes, purely theoretically.
A generalization to countably infinite state spaces was given by Kolmogorov (1936).
Markov chains are related to Brownian motion and the ergodic hypothesis, two topics in physics which were important in the early years of the twentieth century. However, Markov first pursued this in 1906 as part of his argument against Pavel Nekrasov, in particular to make the case that the law of large numbers can be extended to dependent events. In 1913, he applied his findings to the first 20,000 letters of Pushkin's "Eugene Onegin". By 1917, more practical application of his work was made by Erlang to obtain formulas for call loss and waiting time in telephone networks.
Seneta provides an account of Markov's motivations and the theory's early development. The term "chain" was used by Markov (1906) to suggest a sequence of pairwise dependent variables.

</doc>
<doc id="60877" url="https://en.wikipedia.org/wiki?curid=60877" title="Diamond cutting">
Diamond cutting

Diamond cutting is the practice of changing a diamond from a rough stone into a faceted gem. Cutting diamond requires specialized knowledge, tools, equipment, and techniques because of its extreme difficulty.
The first guild of diamond cutters and polishers (diamantaire) was formed in 1375 in Nuremberg, Germany, and led to the development of various types of "cut". This has two meanings in relation to diamonds. The first is the shape: square, oval, and so on. The second relates to the specific quality of cut within the shape, and the quality and price will vary greatly based on the cut quality. Since diamonds are one of the hardest materials, special diamond-coated surfaces are used to grind the diamond down. The first major development in diamond cutting came with the "Point Cut" during the later half of the 14th century: the Point Cut follows the natural shape of an octahedral rough diamond crystal, eliminating some waste in the cutting process.
Diamond cutting, as well as overall processing, is concentrated in a few cities around the world. The main diamond trading centers are Antwerp, Tel Aviv, and Dubai from where roughs are sent to the main processing centers of India and China. Diamonds are cut and polished in Surat, India and the Chinese cities of Guangzhou and Shenzhen. India in recent years has held between 19-31% of the world market in polished diamonds and China has held 17% of the world market share in a recent year. Another important diamond center is New York City.
Diamond cutting process.
The diamond cutting process includes these steps; "planning", "cleaving" or "sawing", "bruting", "polishing", and "final inspection".
Planning.
Diamond manufacturers analyze diamond rough from an economic perspective, with two objectives steering decisions made about how a faceted diamond will be cut. The first objective is that of maximum return on investment for the piece of diamond rough. The second is how quickly the finished diamond can be sold. Scanning devices are used to get a 3-dimensional computer model of the rough stone. Also, inclusions are photographed and placed on the 3D model, which is then used to find an optimal way to cut the stone.
Maximizing value.
The process of maximizing the value of finished diamonds, from a rough diamond into a polished gemstone, is both an art and a science. The choice of cut is influenced by many factors. Market factors include the exponential increase in value of diamonds as weight increases, referred to as "weight retention", and the popularity of certain shapes amongst consumers. Physical factors include the original shape of the rough stone, and location of the inclusions and flaws to be eliminated.
Weight retention.
The weight retention analysis studies the diamond rough to find the best combination of finished stones as it relates to "per carat" value. For instance, a 2.20 carat (440 mg) octahedron may produce (i) either two half carat (100 mg) diamonds whose combined value may be higher than that of (ii) a 0.80 carat (160 mg) diamond + 0.30 carat (60 mg) diamond that could be cut from the same rough diamond.
The round brilliant cut and square brilliant cuts are preferred when the crystal is an octahedron, as often two stones may be cut from one such crystal. Oddly shaped crystals, such as macles are more likely to be cut in a "fancy cut"—that is, a cut other than the round brilliant—which the particular crystal shape lends itself to.
Even with modern techniques, the cutting and polishing of a diamond crystal always results in a dramatic loss of weight, about 50%. Sometimes the cutters compromise and accept lesser proportions and symmetry in order to avoid inclusions or to preserve the weight. Since the per-carat price of a diamond shifts around key milestones (such as 1.00 carat), many one-carat (200 mg) diamonds are the result of compromising "Cut quality" for "Carat weight".
Color retention.
In colored diamonds, cutting can influence the color grade of the diamond, thereby raising its value. Certain cut shapes are used to intensify the color of the diamond. The radiant cut is an example of this type of cut.
Natural green color diamonds most often have merely a surface coloration caused by natural irradiation, which does not extend through the stone. For this reason green diamonds are cut with significant portions of the original rough diamond's surface ("naturals") left on the finished gem. It is these "naturals" that provide the color to the diamond.
Turnaround minimization.
The other consideration of diamond planning is how quickly a diamond will sell. This consideration is often unique to the type of manufacturer. While a certain cutting plan may yield a better value, a different plan may yield diamonds that will sell sooner, providing an earlier return on the investment.
Cleaving or sawing.
Cleaving is the separation of a piece of diamond rough into separate pieces, to be finished as separate gems.
Sawing is the use of a diamond saw or laser to cut the diamond rough into separate pieces.
Bruting.
Bruting is the process whereby two diamonds are set onto spinning axles turning in opposite directions, which are then set to grind against each other to shape each diamond into a round shape. This can also be known as girdling.
Polishing.
Polishing is the name given to process whereby the facets are cut onto the diamond and final polishing is performed. The process takes the steps "blocking", "faceting", also called "brillianteering", and "polishing".
Final inspection.
The final stage involves thoroughly cleaning the diamond in acids, and examining the diamond to see whether it meets the quality standards of the manufacturer.
Cutting process.
It is possible only because the hardness of diamond varies widely according to the direction in which one is trying to cut or grind.
A simplified round brilliant cut process includes the following stages:
This is just one, although a fairly common way of creating a round brilliant cut. The actual process also includes many more stages depending on the size and quality of the rough stone. For example, bigger stones are first scanned to get the three-dimensional shape, which is then used to find the optimal usage. The scanning may be repeated after each stage and bruting may be done in several steps, each bringing the girdle closer to the final shape.

</doc>
<doc id="60878" url="https://en.wikipedia.org/wiki?curid=60878" title="The Lion in Winter">
The Lion in Winter

The Lion in Winter is a 1966 play by James Goldman, depicting the personal and political conflicts of Henry II of England, his wife Eleanor of Aquitaine, their children and their guests during Christmas, 1183. It premiered on Broadway at the Ambassador Theatre on 3 March 1966, starring Robert Preston and Rosemary Harris, who won a Tony Award for her portrayal of Eleanor. It was adapted by Goldman into an Academy Award-winning 1968 film of the same name, starring Peter O'Toole and Katharine Hepburn. The play has been produced numerous times, including Broadway and West End revivals.
Synopsis.
Set during Christmas 1183 at Henry II of England's castle in Chinon, Anjou, Angevin Empire, the play opens with the arrival of Henry's wife Eleanor of Aquitaine, whom he has had imprisoned since 1173. The story concerns the gamesmanship between Henry, Eleanor, their three surviving sons Richard, Geoffrey, and John, and their Christmas Court guest, the King of France, Philip II "Augustus" (), who was the son of Eleanor's ex-husband, Louis VII of France (by his third wife, Adelaide). Also involved is Philip's half-sister Alais (by Louis VII's second wife Constance), who has been at court since she was betrothed to Richard at age eight, but has since become Henry's mistress.
Productions.
The play premiered at the Ambassador Theatre on 3 March 1966. Directed by Noel Willman, it starred Robert Preston as Henry, Rosemary Harris as Eleanor, James Rado as Richard, and Christopher Walken as Philip. Harris won a Tony Award for Best Performance by a Leading Actress in a Play.
The play was first performed in a production of note with a racially diverse cast in 1992 by the multicultural chamber theatre Excaliber Productions, Ltd. at The Wabash Triangle Cafe in St. Louis. Excaliber Founder and Joseph Jefferson Citation Award-winning actor Darryl Maximilian Robinson directed and starred as King Henry II with actresses Anna Altman and Deborah Phillips alternating as Queen Eleanor. The critically praised 12th-century costumes were by Anjula Chan, who also appeared as Princess Alais. Future popular animated film voice-over actor Carey S. Means played Prince Richard the Lionheart. 
The play was revived in March 1999, starring Laurence Fishburne as Henry and Stockard Channing as Eleanor, directed by Michael Mayer. Channing was nominated for a Tony.
The play was produced by Unseam'd Shakespeare Company in 2002.
The play was revived in November 2011 at the Theatre Royal Haymarket, London, starring Robert Lindsay as Henry, and Joanna Lumley as Eleanor, directed by Trevor Nunn.
The play formed part of the Summer and Fall 2012 Seasons at the American Shakespeare Center's Blackfriars Playhouse, presented in complementary repertory with William Shakespeare's "King John".
The play was performed as part of Berkshire Theatre Group's 2013 season with Rhys Boatwright as Geoffrey. 
A 2014 production by the Colony Theater Company in Burbank, California starred Mariette Hartley as Eleanore and Ian Buchanan as Henry. Brendan Ford played Richard and Hartley's daughter Justine, Alais.
Historicity.
"The Lion in Winter" is fictional and none of the dialogue and actions are historical; there was not a Christmas Court at Chinon in 1183. However, the events leading up to the story are generally accurate. There is no definitive evidence that Alais was Henry's mistress (although Richard later resisted marrying Alais on the basis of this claim). The real Henry had many mistresses (and several illegitimate children). Eleanor had persuaded their sons to rebel against Henry in 1173, and for her role in the rebellion she was imprisoned by Henry until his death in 1189.
Dramatic adaptations.
Films.
The play was adapted into a 1968 film, with Peter O'Toole as Henry and Katharine Hepburn as Eleanor, and a 2003 television movie, with Patrick Stewart and Glenn Close.
Pastiches and parodies.
A radio parody of "The Lion in Winter" entitled "The Leopard in Autumn" by Neil Anthony was originally broadcast in BBC Radio 4 in 2001 and 2002 and subsequently re-broadcast on BBC Radio 4 Extra in 2011. Broadcast in two series, it starred David Swift as Prince Ludovico, the ambitious and henpecked ruler of Monte Guano (the smallest and most inconsequential city-state in Renaissance Italy), Siân Phillips as his wife Princess Plethora, Graham Crowden as Francesco (Ludovico's perpetually drunken secretary), Saskia Wickham as Countess Rosalie (Ludovico's mistress Plethora's full knowledge and approval), and as Ludovico's perpetually squabbling sons: Nick Romero as the overly religious Salvatore (whose ambition is to become Pope some day), Paul Bigley as Allesandro (an eternally hopeful would-be artist and inventor) and Christopher Kellen as Guido (a fierce follower of Martin Luther).
The Fox TV drama "Empire" is explicitly based on "The Lion in Winter". It concerns a dysfunctional family that owns a record label named Empire, with all the members scheming and manipulating for power. There are numerous allusions to the play: the family is named Lyon, the father runs an empire while the mother, a very formidable woman, has been imprisoned for many years. Together, they have three sons: a serious, studious, master manipulator son; an intelligent, talented son, who is gay and the mother's favorite but rejected by the father; and a youngest son who is a favorite of the father, but who is spoiled and irresponsible. The recently freed mother schemes with the father and three sons for control of their empire, while at the same time slinging numerous verbal barbs at each other.

</doc>
<doc id="60879" url="https://en.wikipedia.org/wiki?curid=60879" title="Electroluminescence">
Electroluminescence

Electroluminescence (EL) is an optical phenomenon and electrical phenomenon in which a material emits light in response to the passage of an electric current or to a strong electric field. This is distinct from black body light emission resulting from heat (incandescence), from a chemical reaction (chemiluminescence), sound (sonoluminescence), or other mechanical action (mechanoluminescence).
Mechanism.
Electroluminescence is the result of radiative recombination of electrons and holes in a material, usually a semiconductor. The excited electrons release their energy as photons - light. Prior to recombination, electrons and holes may be separated either by doping the material to form a p-n junction (in semiconductor electroluminescent devices such as light-emitting diodes) or through excitation by impact of high-energy electrons accelerated by a strong electric field (as with the phosphors in electroluminescent displays).
It has been recently shown that as a solar cell improves its light-to-electricity efficiency (improved open-circuit voltage), it will also improve its electricity-to-light (EL) efficiency
Examples of electroluminescent materials.
Electroluminescent devices are fabricated using either organic or inorganic electroluminescent materials. The active materials are generally semiconductors of wide enough bandwidth to allow exit of the light.
The most typical inorganic thin-film EL (TFEL) is ZnS:Mn with yellow-orange emission. Examples of the range of EL material include:
Practical implementations.
The most common electroluminescent (EL) devices are composed of either powder (primarily used in lighting applications) or thin films (for information displays.)
"Light-emitting capacitor", or LEC, is a term used since at least 1961 to describe electroluminescent panels. that are still made as night lights and backlights for instrument panel displays. The drawbacks of conventional electroluminescent lights are low efficiency and lifetimes limited to hundreds of hours. Electroluminescent panels are a capacitor where the dielectric between the outside plates is a phosphor that gives off photons when the capacitor is charged. By making one of the contacts transparent, the large area exposed emits light.
Electroluminescent automotive instrument panel backlighting, with each gauge pointer also an individual light source, entered production on 1960 Chrysler and Imperial passenger cars, and was continued successfully on several Chrysler vehicles through 1967.
Sylvania Lighting Division in Salem and Danvers, MA, produced and marketed an EL night lamp (right), under the trade name "Panelescent" at roughly the same time that the Chrysler instrument panels entered production. These lamps have proven incredibly reliable, with some samples known to be still functional after nearly 50 years of continuous operation. Later in the 1960s, Sylvania's Electronic Systems Division in Needham, MA developed and manufactured several instruments for the Apollo Lunar Lander and Command Module using electroluminescent display panels manufactured by the Electronic Tube Division of Sylvania at Emporium, PA. Raytheon, Sudbury, MA, manufactured the Apollo guidance computer, which used a Sylvania electroluminescent display panel as part of its display-keyboard interface (DSKY).
Powder phosphor-based electroluminescent panels are frequently used as backlights to liquid crystal displays. They readily provide a gentle, even illumination to the entire display while consuming relatively little electric power. This makes them convenient for battery-operated devices such as pagers, wristwatches, and computer-controlled thermostats, and their gentle green-cyan glow is a common sight in the technological world. They do, however, require relatively high voltage (between 60 and 600 volts). For battery-operated devices, this voltage must be generated by a converter circuit within the device; this converter often makes an audible whine or siren sound while the backlight is activated. For line-voltage-operated devices, it may be supplied directly from the power line. Electroluminescent nightlights operate in this fashion. Brightness per unit area increases with increased voltage and frequency.
Thin film phosphor electroluminescence was first commercialized during the 1980s by Sharp Corporation in Japan, Finlux (Oy Lohja Ab) in Finland, and Planar Systems in the USA. Here, bright, long-life light emission is achieved in thin film yellow-emitting manganese-doped zinc sulfide material. Displays using this technology were manufactured for medical and vehicle applications where ruggedness and wide viewing angles were crucial, and liquid crystal displays were not well developed. In 1992, Timex introduced its Indiglo EL display on some watches.
Recently, blue-, red-, and green-emitting thin film electroluminescent materials that offer the potential for long life and full color electroluminescent displays have been developed.
In either case, the EL material must be enclosed between two electrodes and at least one electrode must be transparent to allow the escape of the produced light. Glass coated with indium tin oxide is commonly used as the front (transparent) electrode while the back electrode is coated with reflective metal. Additionally, other transparent conducting materials, such as carbon nanotube coatings or PEDOT can be used as the front electrode.
The display applications are primarily passive (i.e., voltages are driven from edge of the display cf. driven from a transistor on the display). Similar to LCD trends, there have also been Active Matrix EL (AMEL) displays demonstrated, where circuitry is added to prolong voltages at each pixel. The solid-state nature of TFEL allows for a very rugged and high-resolution display fabricated even on silicon substrates. AMEL displays of 1280x1024 at over 1000 lines per inch (lpi) have been demonstrated by a consortium including Planar Systems.
Electroluminescent technologies have low power consumption compared to competing lighting technologies, such as neon or fluorescent lamps. This, together with the thinness of the material, has made EL technology valuable to the advertising industry. Relevant advertising applications include electroluminescent billboards and signs. EL manufacturers are able to control precisely which areas of an electroluminescent sheet illuminate, and when. This has given advertisers the ability to create more dynamic advertising that is still compatible with traditional advertising spaces.
An EL film is a so-called Lambertian radiator: unlike with neon lamps, filament lamps, or LEDs, the brightness of the surface appears the same from all angles of view; electroluminescent light is not directional and therefore hard to compare with (thermal) light sources measured in lumens or lux. The light emitted from the surface is perfectly homogeneous and is well-perceived by the eye. EL film produces single-frequency (monochromatic) light that has a very narrow bandwidth, is absolutely uniform and visible from a great distance.
In principle, EL lamps can be made in any color. However, the commonly used greenish color closely matches the peak sensitivity of human vision, producing the greatest apparent light output for the least electrical power input. Unlike neon and fluorescent lamps, EL lamps are not negative resistance devices so no extra circuitry is needed to regulate the amount of current flowing through them.
Electroluminescent lighting is now used as an application for public safety identification involving alphanumeric characters on the roof of vehicles for clear visibility from an aerial perspective.
Electroluminescent lighting, especially electroluminescent wire (EL wire), has also made its way into clothing as many designers have brought this technology to the entertainment and night life industry.
Engineers have developed an electroluminescent "skin" that can stretch more than six times its original size while still emitting light. This hyper-elastic light-emitting capacitor (HLEC) can endure more than twice the strain of previously tested stretchable displays. It consists of layers of transparent hydrogel electrodes sandwiching an insulating elastomer sheet. The elastomer changes luminance and capacitance when stretched, rolled and otherwise deformed. In addition to its ability to emit light under a strain of greater than 480 percent its original size, the group's HLEC was shown to be capable of being integrated into a soft robotic system. Three six-layer HLEC panels were bound together to form a crawling soft robot, with the top four layers making up the light-up skin and the bottom two the pneumatic actuators. The discovery could lead to significant advances in health care, transportation, electronic communication and other areas.

</doc>
<doc id="60880" url="https://en.wikipedia.org/wiki?curid=60880" title="Electrical phenomena">
Electrical phenomena

Electrical phenomena are commonplace and unusual events that can be observed and that illuminate the principles of the physics of electricity and are explained by them.
Electrical phenomena are a somewhat arbitrary division of
electromagnetic phenomena.
Some examples are

</doc>
<doc id="60883" url="https://en.wikipedia.org/wiki?curid=60883" title="Watch">
Watch

A watch is a small timepiece intended to be carried or worn by a person. It is designed to keep working despite the motions caused by the person's activities. A wristwatch is designed to be worn on a wrist, attached by a watch strap or other type of bracelet. A pocket watch is designed for a person to carry in a pocket.
Watches evolved in the 17th century from spring-powered clocks, which appeared as early as the 14th century. The first watches were strictly mechanical, driven by clockwork. As technology progressed, mechanical devices, used to control the speed of the watch, were largely superseded by vibrating quartz crystals that produce accurately timed electronic pulses. Some watches use radio clock technology to regularly correct the time. The first digital electronic watch was developed in 1970.
Most inexpensive and medium-priced watches, used mainly for timekeeping, are electronic watches with quartz movements. Expensive collectible watches, valued more for their elaborate craftsmanship, aesthetic appeal and glamorous design than for simple timekeeping, often have purely mechanical movements and are powered by springs, even though these movements are generally less accurate and more expensive than electronic ones. Various extra features, called "complications", such as moon-phase displays and the different types of tourbillon, are sometimes included. Modern watches often display the day, date, month and year, and electronic watches may have many other functions. Time-related features such as timers, chronographs and alarm functions are common. Some modern designs incorporate calculators, GPS and Bluetooth technology or have heart-rate monitoring capabilities. Watches incorporating GPS receivers use them not only to determine their position. They also receive and use time signals from the satellites, which make them essentially perfectly accurate timekeepers, even over long periods of time.
Developments in the 2010s include smartwatches, which are elaborate computer-like electronic devices designed to be worn on a wrist. They generally incorporate timekeeping functions, but these are only small fractions of what the watch can do.
The study of timekeeping is known as horology.
History.
Watches evolved from portable spring-driven clocks, which first appeared in 15th century Europe. Watches weren't widely worn in pockets until the 17th century. One account says that the word "watch" came from the Old English word "woecce" which meant "watchman", because it was used by town watchmen to keep track of their shifts at work. Another says that the term came from 17th century sailors, who used the new mechanisms to time the length of their shipboard "watches" (duty shifts).
A great leap forward in accuracy occurred in 1657 with the addition of the balance spring to the balance wheel, an invention disputed both at the time and ever since between Robert Hooke and Christiaan Huygens. This innovation increased watches' accuracy enormously, reducing error from perhaps several hours per day to perhaps 10 minutes per day, resulting in the addition of the minute hand to the face from around 1680 in Britain and 1700 in France.
The increased accuracy of the balance wheel focused attention on errors caused by other parts of the movement, igniting a two century wave of watchmaking innovation. The first thing to be improved was the escapement. The verge escapement was replaced in quality watches by the cylinder escapement, invented by Thomas Tompion in 1695 and further developed by George Graham in the 1720s. Improvements in manufacturing such as the tooth-cutting machine devised by Robert Hooke allowed some increase in the volume of watch production, although finishing and assembling was still done by hand until well into the 19th century.
A major cause of error in balance wheel timepieces, caused by changes in elasticity of the balance spring from temperature changes, was solved by the bimetallic temperature compensated balance wheel invented in 1765 by Pierre Le Roy and improved by Thomas Earnshaw. The lever escapement was the single most important technological breakthrough, and was invented by Thomas Mudge in 1759 and improved by Josiah Emery in 1785, although it only gradually came into use from about 1800 onwards, chiefly in Britain.
The British had predominated in watch manufacture for much of the 17th and 18th centuries, but maintained a system of production that was geared towards high quality products for the elite. Although there was an attempt to modernise clock manufacture with mass production techniques and the application of duplicating tools and machinery by the British Watch Company in 1843, it was in the United States that this system took off. Aaron Lufkin Dennison started a factory in 1851 in Massachusetts that used interchangeable parts, and by 1861 it was running a successful enterprise incorporated as the Waltham Watch Company.
Wristwatch.
The concept of the wristwatch goes back to the production of the very earliest watches in the 16th century. Elizabeth I of England received a wristwatch from Robert Dudley in 1571, described as an arm watch. The oldest surviving Wristwatch (then described as a bracelet watch) is one made in 1806 and given to Joséphine de Beauharnais. From the beginning, wrist watches were almost exclusively worn by women, while men used pocket-watches up until the early 20th century.
Wristwatches were first worn by military men towards the end of the 19th century, when the importance of synchronizing manoeuvres during war, without potentially revealing the plan to the enemy through signalling, was increasingly recognized. The Garstin Company of London patented a 'Watch Wristlet' design in 1893, but they were probably producing similar designs from the 1880s. Officers in the British Army began using wristwatches during colonial military campaigns in the 1880s, such as during the Anglo-Burma War of 1885. During the First Boer War, the importance of coordinating troop movements and synchronizing attacks against the highly mobile Boer insurgents became paramount, and the use of wristwatches subsequently became widespread among the officer class. The company Mappin & Webb began production of their successful 'campaign watch' for soldiers during the campaign at the Sudan in 1898 and accelerated production for the Second Boer War a few years later. In continental Europe Girard-Perregaux and other Swiss watch makers began supplying German naval officers with wrist watches in about 1880.
These early models were essentially standard pocket-watches fitted to a leather strap but, by the early 20th century, manufacturers began producing purpose-built wristwatches. The Swiss company, Dimier Frères & Cie patented a wristwatch design with the now standard wire lugs in 1903. Hans Wilsdorf moved to London in 1905 and set up his own business with his brother-in-law Alfred Davis, Wilsdorf & Davis, providing quality timepieces at affordable prices; the company later became Rolex. Wilsdorf was an early convert to the wristwatch, and contracted the Swiss firm Aegler to produce a line of wristwatches.
The impact of the First World War dramatically shifted public perceptions on the propriety of the man's wristwatch, and opened up a mass market in the postwar era. The creeping barrage artillery tactic, developed during the war, required precise synchronization between the artillery gunners and the infantry advancing behind the barrage. Service watches produced during the War were specially designed for the rigours of trench warfare, with luminous dials and unbreakable glass. The British War Department began issuing wristwatches to combatants from 1917. By the end of the war, almost all enlisted men wore a wristwatch, and after they were demobilized, the fashion soon caught on: the British "Horological Journal" wrote in 1917 that "the wristlet watch was little used by the sterner sex before the war, but now is seen on the wrist of nearly every man in uniform and of many men in civilian attire." By 1930, the ratio of wrist- to pocket watches was 50 to 1. The first successful self-winding system was invented by John Harwood in 1923.
The introduction of the quartz watch in 1969 was a revolutionary improvement in watch technology. In place of a balance wheel which oscillated at perhaps 5 or 6 beats per second, it used a quartz crystal resonator which vibrated at 8,192 Hz, driven by a battery-powered oscillator circuit. Since the 1980s, more quartz watches than mechanical ones have been marketed.
Movement.
A movement of a watch is the mechanism that measures the passage of time and displays the current time (and possibly other information including date, month and day). Movements may be entirely mechanical, entirely electronic (potentially with no moving parts), or they might be a blend of both. Most watches intended mainly for timekeeping today have electronic movements, with mechanical hands on the watch face indicating the time.
Mechanical movements.
Compared to electronic movements, mechanical watches are less accurate, often with errors of seconds per day, and they are sensitive to position, temperature and magnetism. They are also costly to produce, require regular maintenance and adjustments, and are more prone to failures. Nevertheless, the craftsmanship of mechanical watches still attracts interest from part of the watch-buying public, especially among the watch collectors. Skeleton watches are designed to leave the mechanism visible for aesthetic purposes.
A mechanical movement uses an escapement mechanism to control and limit the unwinding and winding parts of a spring, converting what would otherwise be a simple unwinding into a controlled and periodic energy release. A mechanical movement also uses a balance wheel together with the balance spring (also known as a hairspring) to control motion of the gear system of the watch in a manner analogous to the pendulum of a pendulum clock. The tourbillon, an optional part for mechanical movements, is a rotating frame for the escapement, which is used to cancel out or reduce the effects of gravitational bias to the timekeeping. Due to the complexity of designing a tourbillon, they are very expensive, and only found in prestigious watches.
The pin-lever escapement (called the Roskopf movement after its inventor, Georges Frederic Roskopf), which is a cheaper version of the fully levered movement, was manufactured in huge quantities by many Swiss manufacturers as well as by Timex, until it was replaced by quartz movements.
Tuning-fork watches use a type of electromechanical movement. Introduced by Bulova in 1960, they use a tuning fork with a precise frequency (most often 360 hertz) to drive a mechanical watch. The task of converting electronically pulsed fork vibration into rotary movements is done via two tiny jeweled fingers, called pawls. Tuning-fork watches were rendered obsolete when electronic quartz watches were developed. Quartz watches were cheaper to produce besides being more accurate.
Traditional mechanical watch movements use a spiral spring called a mainspring as a power source. In "manual watches" the spring must be rewound periodically by the user by turning the watch crown. Antique pocketwatches were wound by inserting a separate key into a hole in the back of the watch and turning it. Most modern watches are designed to run 40 hours on a winding and thus must be wound daily, but some run for several days and a few have 192-hour mainsprings and are wound weekly.
Automatic watches.
A "self-winding" or "automatic" watch is one that rewinds the mainspring of a mechanical movement by the natural motions of the wearer's body. The first self-winding mechanism was invented for pocket watches in 1770 by Abraham-Louis Perrelet, but the first "self-winding", or "automatic", wristwatch was the invention of a British watch repairer named John Harwood in 1923. This type of watch winds itself without requiring any special action by the wearer. It uses an eccentric weight, called a winding rotor, which rotates with the movement of the wearer's wrist. The back-and-forth motion of the winding rotor couples to a ratchet to wind the mainspring automatically. Self-winding watches usually can also be wound manually to keep them running when not worn or if the wearer's wrist motions are inadequate to keep the watch wound.
In April 2014 the Swatch Group launched the "sistem51" wristwatch. It has a purely mechanical movement consisting of only 51 parts, including a novel self-winding mechanism with a transparent oscillating weight. So far, it is the only mechanical movement manufactured entirely on a fully automated assembly line. The low parts count and the automated assembly make it an inexpensive mechanical Swiss watch, which can be considered a successor to "Roskopf" movements, although of higher quality.
Electronic movements.
Electronic movements, also known as quartz movements, have few or no moving parts, except a quartz crystal which is made to vibrate by the piezoelectric effect. A varying electric voltage is applied to the crystal, which responds by changing its shape so, in combination with some electronic components, it functions as an oscillator. It resonates at a specific highly stable frequency, which is used to accurately pace a timekeeping mechanism. Most quartz movements are primarily electronic but are geared to drive mechanical hands on the face of the watch to provide a traditional analog display of the time, a feature most consumers still prefer.
In 1959 Seiko placed an order with Epson (a daughter company of Seiko and the 'brain' behind the quartz revolution) to start developing a quartz wristwatch. The project was codenamed 59A. By the 1964 Tokyo Summer Olympics, Seiko had a working prototype of a portable quartz watch which was used as the time measurements throughout the event.
The first prototypes of an electronic quartz wristwatch (not just "portable" quartz watches as the Seiko timekeeping devices at the Tokyo Olympics in 1964) were made by the CEH research laboratory in Neuchâtel, Switzerland. From 1965 through 1967 pioneering development work was done on a miniaturized 8192 Hz quartz oscillator, a thermo-compensation module and an inhouse-made, dedicated integrated circuit (unlike the hybrid circuits used in the later Seiko Astron wristwatch). As a result, the BETA 1 prototype set new timekeeping performance records at the International Chronometric Competition held at the Observatory of Neuchâtel in 1967. In 1970, 18 manufacturers exhibited production versions of the beta 21 wristwatch, including the Omega Electroquartz as well as Patek Philippe, Rolex Oysterquartz and Piaget
The first quartz watch to enter production was the Seiko 35 SQ Astron, which hit the shelves on 25 December 1969, swiftly followed by the Swiss Beta 21, and then a year later the prototype of one of the world's most accurate wristwatches to date: the Omega Marine Chronometer. Thanks to the technology having been developed by the Swiss, Seiko could not patent the whole movement of the quartz wristwatch, thus allowing other manufacturers to participate in the rapid growth and development of the quartz watch market, This ended — in less than a decade — almost 100 years of dominance by the mechanical wristwatch legacy. Modern quartz movements are produced in very large quantities, and even the cheapest wristwatches typically have quartz movements. Whereas mechanical movements can typically be off by several seconds a day, an inexpensive quartz movement in a child's wristwatch may still be accurate to within half a second per day — ten times more accurate than a mechanical movement.
After a consolidation of the mechanical watch industry in Switzerland during the 1970s, mass production of quartz wristwatches took off under the leadership of the Swatch Group of companies, a Swiss conglomerate with vertical control of the production of Swiss watches and related products. For quartz wristwatches, subsidiaries of Swatch manufacture watch batteries (Renata), oscillators (Oscilloquartz, now Micro Crystal AG) and integrated circuits (Ebauches Electronic SA, renamed EM Microelectronic-Marin). The launch of the new SWATCH brand in 1983 was marked by bold new styling, design and marketing. Today, the Swatch Group maintains its position as the world's largest watch company.
Seiko's efforts to combine the quartz and mechanical movements bore fruit after 20 years of research, leading to the introduction of the Seiko Spring Drive, first in a limited domestic market production in 1999 and to the world in September 2005. The Spring Drive keeps time within quartz standards without the use of a battery, using a traditional mechanical gear train powered by a spring, without the need for a balance wheel either.
Radio time signal watches are a type of electronic quartz watch which synchronizes (time transfers) its time with an external time source such as in atomic clocks, time signals from GPS navigation satellites, the German DCF77 signal in Europe, WWVB in the US, and others. Movements of this type may — among others — synchronize the time of day and the date, the leap-year status, and the state of daylight saving time (on or off). However, other than the radio receiver, these watches are normal quartz watches in all other aspects.
Electronic watches require electricity as a power source, and some mechanical movements and hybrid electronic-mechanical movements also require electricity. Usually the electricity is provided by a replaceable battery. The first use of electrical power in watches was as a substitute for the mainspring, to remove the need for winding. The first electrically powered watch, the Hamilton Electric 500, was released in 1957 by the Hamilton Watch Company of Lancaster, Pennsylvania.
Watch batteries (strictly speaking cells, as a battery is composed of multiple cells) are specially designed for their purpose. They are very small and provide tiny amounts of power continuously for very long periods (several years or more). In most cases, replacing the battery requires a trip to a watch-repair shop or watch dealer; this is especially true for watches that are water-resistant, as special tools and procedures are required for the watch to remain water-resistant after battery replacement. Silver-oxide and lithium batteries are popular today; mercury batteries, formerly quite common, are no longer used, for environmental reasons. Cheap batteries may be alkaline, of the same size as silver-oxide cells but providing shorter life. Rechargeable batteries are used in some solar-powered watches.
Some electronic watches are powered by the movement of the wearer. For instance, Seiko's kinetic-powered quartz watches use the motion of the wearer's arm: turning a rotating weight which causes a tiny generator to supply power to charge a rechargeable battery that runs the watch. The concept is similar to that of self-winding spring movements, except that electrical power is generated instead of mechanical spring tension.
Solar powered watches are powered by light. A photovoltaic cell on the face (dial) of the watch converts light to electricity, which is used to charge a rechargeable battery or capacitor. The movement of the watch draws its power from the rechargeable battery or capacitor. As long as the watch is regularly exposed to fairly strong light (such as sunlight), it never needs battery replacement. Some models need only a few minutes of sunlight to provide weeks of energy (as in the Citizen Eco-Drive). Some of the early solar watches of the 1970s had innovative and unique designs to accommodate the array of solar cells needed to power them (Synchronar, Nepro, Sicura and some models by Cristalonic, Alba, Seiko and Citizen). As the decades progressed and the efficiency of the solar cells increased while the power requirements of the movement and display decreased, solar watches began to be designed to look like other conventional watches.
A rarely used power source is the temperature difference between the wearer's arm and the surrounding environment (as applied in the Citizen Eco-Drive Thermo).
Display.
Analog.
Traditionally, watches have displayed the time in analog form, with a numbered dial upon which are mounted at least a rotating hour hand and a longer, rotating minute hand. Many watches also incorporate a third hand that shows the current second of the current minute. Watches powered by quartz usually have a second hand that snaps every second to the next marker. Watches powered by a mechanical movement appears to have a gliding second hand, although it is actually not gliding; the hand merely moves in smaller steps, typically 1/5 of a second, corresponding to the beat (half period) of the balance wheel. In some escapements (for example the "duplex" escapement), the hand advances every two beats (full period) of the balance wheel, typically 1/2 second in those watches, or even every four beats (two periods, 1 second), in the "double duplex" escapement. A truly gliding second hand is achieved with the "tri-synchro regulator" of Spring Drive watches. All of the hands are normally mechanical, physically rotating on the dial, although a few watches have been produced with "hands" that are simulated by a liquid-crystal display.
Analog display of the time is nearly universal in watches sold as jewelry or collectibles, and in these watches, the range of different styles of hands, numbers, and other aspects of the analog dial is very broad. In watches sold for timekeeping, analog display remains very popular, as many people find it easier to read than digital display; but in timekeeping watches the emphasis is on clarity and accurate reading of the time under all conditions (clearly marked digits, easily visible hands, large watch faces, etc.). They are specifically designed for the left wrist with the stem (the knob used for changing the time) on the right side of the watch; this makes it easy to change the time without removing the watch from the wrist. This is the case if one is right-handed and the watch is worn on the left wrist (as is traditionally done). If one is left-handed and wears the watch on the right wrist, one has to remove the watch from the wrist to reset the time or to wind the watch.
Analog watches as well as clocks are often marketed showing a display time of approximately 1:50 or 10:10. This creates a visually pleasing smile-like face on upper half of the watch, in addition to enclosing the manufacturer's name. Digital displays often show a time of 12:08, where the increase in the number of active segments or pixels gives a positive feeling.
Tactile.
Tissot, a Swiss luxury watchmaker, makes the Silen-T wristwatch with a touch-sensitive face that vibrates to help the user to tell time eyes-free. The bezel of the watch features raised bumps at each hour maker; after briefly touching the face of the watch, the wearer runs a finger around the bezel clockwise. When the finger reaches the bump indicating the hour, the watch vibrates continuously, and when the finger reaches the bump indicating the minute, the watch vibrates intermittently.
Eone Timepieces, Washington D.C.-based company, launched its first tactile analog wristwatch, the "Bradley", on 11 July 2013 on the "Kickstarter" website. The device is primarily designed for sight-impaired users, who can use the watch's two ball bearings to determine the time, but it is also suitable for general use. The watch features raised marks at each hour and two moving, magnetically attached ball bearings. One ball bearing, on the edge of the watch, indicates the hour, while the other, on the face, indicates the minute.
Digital.
A digital display simply shows the time as a number, "e.g.", "12:08" instead of a short hand pointing towards the number 12 and a long hand 8/60 of the way round the dial. The digits are usually shown as a seven-segment display.
The first digital "mechanical" pocket watches appeared in the late 19th century. In the 1920s, the first digital mechanical wristwatches appeared.
The first digital "electronic" watch, a Pulsar LED prototype in 1970, was developed jointly by Hamilton Watch Company and Electro-Data, founded by George H. Thiess. John Bergey, the head of Hamilton's Pulsar division, said that he was inspired to make a digital timepiece by the then-futuristic digital clock that Hamilton themselves made for the 1968 science fiction film "". On 4 April 1972, the Pulsar was finally ready, made in 18-carat gold and sold for $2,100. It had a red light-emitting diode (LED) display.
Digital LED watches were very expensive and out of reach to the common consumer until 1975, when Texas Instruments started to mass-produce LED watches inside a plastic case. These watches, which first retailed for only $20, reduced to $10 in 1976, saw Pulsar lose $6 million and the Pulsar brand sold to Seiko.
An early LED watch that was rather problematic was The Black Watch made and sold by British company Sinclair Research in 1975. This was only sold for a few years, as production problems and returned (faulty) product forced the company to cease production.
Most watches with LED displays required that the user press a button to see the time displayed for a few seconds, because LEDs used so much power that they could not be kept operating continuously. Usually the LED display color would be red. Watches with LED displays were popular for a few years, but soon the LED displays were superseded by liquid crystal displays (LCDs), which used less battery power and were much more convenient in use, with the display always visible and no need to push a button before seeing the time. Only in darkness you had to press a button to light the display with a tiny light bulb, later illuminating LEDs.
The first LCD watch with a six-digit LCD was the 1973 Seiko 06LC, although various forms of early LCD watches with a four-digit display were marketed as early as 1972 including the 1972 Gruen Teletime LCD Watch, and the Cox Electronic Systems Quarza. In Switzerland, Ebauches Electronic SA presented a prototype eight-digit LCD wristwatch showing time and date at the MUBA Fair, Basle, in March 1973, using a Twisted Nematic LCD manufactured by Brown, Boveri & Cie, Switzerland, which became the supplier of LCDs to Casio for the "CASIOTRON" watch in 1974.
A problem with Liquid Crystal Displays is that they use polarized light. If, for example, the user is wearing polarized sunglasses, the watch may be difficult to read because the plane of polarization of the display is roughly perpendicular to that of the glasses. If the light that illuminates the display is polarized, for example if it comes from a blue sky, the display may be difficult or impossible to read.
From the 1980s onward, digital watch technology vastly improved. In 1982 Seiko produced the Seiko TV Watch that had a television screen built in, and Casio produced a digital watch with a thermometer as well as another that could translate 1,500 Japanese words into English. In 1985, Casio produced the CFX-400 scientific calculator watch. In 1987 Casio produced a watch that could dial your telephone number and Citizen revealed one that would react to your voice. In 1995 Timex released a watch which allowed the wearer to download and store data from a computer to their wrist. Some watches, such as the Timex Datalink USB, feature dot matrix displays. Since their apex during the late 1980s to mid-1990s high technology fad, digital watches have mostly become simpler, less expensive time pieces with little variety between models.
Illuminated.
Many watches have displays that are illuminated, so they can be used in darkness. Various methods have been used to achieve this.
Mechanical watches often have luminous paint on their hands and hour marks. In the mid-20th century, radioactive material was often incorporated in the paint, so it would continue to glow without any exposure to light. Radium was often used but produced small amounts of radiation outside the watch that might have been hazardous.
Tritium was used as a replacement, since the radiation it produces has such low energy that it cannot penetrate a watch glass. However, tritium is expensive — it has to be made in a nuclear reactor — and it has a half-life of only about 12 years so the paint remains luminous for only a few years. Nowadays, tritium is used in specialized watches, e.g., for military purposes (See Tritium illumination). For other purposes, luminous paint is sometimes used on analog displays, but no radioactive material is contained in it. This means that the display glows soon after being exposed to light and quickly fades.
Watches that incorporate batteries often have electric illumination of their displays. However, lights consume far more power than electronic watch movements. To conserve the battery, the light is activated only when the user presses a button. Usually, the light remains lit for a few seconds after the button is released, which allows the user to move the hand out of the way.
In some early digital watches, LED displays were used, which could be read as easily in darkness as in daylight. The user had to press a button to light up the LEDs, which meant that the watch could not be read without the button being pressed, even in full daylight.
In some cheaper types of watches, small incandescent lamps or LEDs illuminate the display, which is not intrinsically luminous. These tend to produce very non-uniform illumination. Incandescent lamps are very wasteful of electricity. Other watches use electroluminescent material to produce uniform illumination of the background of the display, against which the hands or digits can be seen.
Talking watches.
Talking watches are also available, intended for the blind or visually impaired. They speak the time out loud at the press of a button. This has the disadvantage of disturbing others nearby, or at least alerting everyone that the wearer is checking the time. Tactile watches are preferred to avoid this awkwardness, but talking watches are preferred for those who are not confident in their ability to read a tactile watch reliably.
Handedness.
Wristwatches with analog displays generally have a small knob, called the crown, that can be used to adjust the time and, in mechanical watches, wind the spring. Almost always, the crown is located on the right-hand side of the watch. This makes it inconvenient to use if the watch is being worn on the right wrist. Usually, therefore, watches are worn on the left wrist, even if the wearer is left-handed.
In exceptional cases, the crown is on the left side of the watch. This is, for example, to prevent it from digging into the wrists of golf players.
Digital watches generally have push-buttons that can be used to make adjustments. These are usually equally easy to use on either wrist.
Functions.
All watches provide the time of day, giving at least the hour and minute, and usually the second. Most also provide the current date, and often the day of the week as well. However, many watches also provide a great deal of information beyond the basics of time and date. Some watches include alarms. Other elaborate and more expensive watches, both pocket and wrist models, also incorporate striking mechanisms or repeater functions, so that the wearer could learn the time by the sound emanating from the watch. This announcement or striking feature is an essential characteristic of true clocks and distinguishes such watches from ordinary timepieces. This feature is available on most digital watches.
A "complicated watch" has one or more functions beyond the basic function of displaying the time and the date; such a functionality is called a complication. Two popular complications are the chronograph complication, which is the ability of the watch movement to function as a stopwatch, and the moonphase complication, which is a display of the lunar phase. Other more expensive complications include Tourbillon, Perpetual calendar, Minute repeater, and Equation of time. A truly complicated watch has many of these complications at once (see Calibre 89 from Patek Philippe for instance). Some watches can both indicate the direction of Mecca and have alarms that can be set for all daily prayer requirements. Among watch enthusiasts, complicated watches are especially collectible. Some watches include a second 12-hour or 24-hour display for UTC or GMT.
The similar-sounding terms chronograph and chronometer are often confused, although they mean altogether different things. A chronograph is a watch with an added duration timer, often a stopwatch complication (as explained above), while a chronometer watch is a timepiece that has met an industry standard test for performance under pre-defined conditions: a chronometer is a high quality mechanical or a thermo-compensated movement that has been tested and certified to operate within a certain standard of accuracy by the COSC (Contrôle Officiel Suisse des Chronomètres). The concepts are different but not mutually exclusive; so a watch can be a chronograph, a chronometer, both, or neither.
Many computerized wristwatches have been developed, but none have had long-term sales success, because they have awkward user interfaces due to the tiny screens and buttons, and a short battery life. As miniaturized electronics became cheaper, watches have been developed containing calculators, tonometers, barometers, altimeters, a compass using both hands to show the N/S direction, video games, digital cameras, keydrives, GPS receivers and cellular phones. A few astronomical watches show phase of the Moon and other celestial phenomena. In the early 1980s Seiko marketed a watch with a television in it. Such watches have also had the reputation as unsightly and thus mainly geek toys. Several companies have however attempted to develop a computer contained in a wristwatch (see also wearable computer).
Electronic sports watches, combining timekeeping with GPS and/or activity tracking, address the general fitness market and have the potential for commercial success (Garmin forerunner, Garmin Vivofit, Epson, announced model of Swatch Touch series).
Braille watches have analog displays with raised bumps around the face to allow blind users to tell the time. Their digital equivalents use synthesised speech to speak the time on command.
Uses.
Fashion.
Wristwatches and antique pocket watches are often appreciated as jewelry or as collectible works of art rather than just as timepieces. This has created several different markets for wristwatches, ranging from very inexpensive but accurate watches (intended for no other purpose than telling the correct time) to extremely expensive watches that serve mainly as personal adornment or as examples of high achievement in miniaturization and precision mechanical engineering.
Traditionally, men's dress watches appropriate for informal (business), semi-formal, and formal attire are gold, thin, simple, and plain, but increasingly rugged, complicated, or sports watches are considered by some to be acceptable for such attire. Some dress watches have a cabochon on the crown and many women's dress watches have faceted gemstones on the face, bezel, or bracelet. Some are made entirely of faceted sapphire (corundum).
Many fashion and department stores offer a variety of less-expensive, trendy, "costume" watches (usually for women), many of which are similar in quality to basic quartz timepieces but which feature bolder designs. In the 1980s, the Swiss Swatch company hired graphic designers to redesign a new annual collection of non-repairable watches.
Trade in counterfeit watches, which mimic expensive brand-name watches, constitutes an estimated market per year.
Space.
The zero-gravity environment and other extreme conditions encountered by astronauts in space require the use of specially tested watches.
The first ever watch to be sent into space was a Russian "Pobeda" watch from the Petrodvorets Watch Factory. It was sent on a single orbit flight on the space ship Korabl-Sputnik 4 on March 9, 1961. The watch had been attached without authorisation to the wrist of Chernuchka, a dog that successfully did exactly the same trip as Yuri Gagarin, with exactly the same rocket and equipment, just a month before Gagarin's flight.
On 12 April 1961, Yuri Gagarin wore a Shturmanskie (a transliteration of "Штурманские" which actually means “navigator’s”) wristwatch during his historic first flight into space. The Shturmanskie was manufactured at the First Moscow Factory. Since 1964, the watches of the First Moscow Factory have been marked by the trademark “Полёт”, transliterated as “POLJOT”, which means “flight” in Russian and is a tribute to the many space trips its watches have accomplished. In the late 1970s, Poljot launched a new chrono movement, the 3133. With a 23 jewel movement and manual winding (43 hours), it was a modified Russian version of the Swiss Valjoux 7734 of the early 1970s. Poljot 3133 were taken into space by astronauts from Russia, France, Germany and Ukraine. On the arm of Valeriy Polyakov, a Poljot 3133 chronograph movement-based watch set a space record for the longest space flight in history.
Through the 1960s, a large range of watches were tested for durability and precision under extreme temperature changes and vibrations. The Omega Speedmaster Professional was selected by NASA, the U.S. space agency. Heuer became the first Swiss watch in space thanks to a Heuer Stopwatch, worn by John Glenn in 1962 when he piloted the Friendship 7 on the first manned U.S. orbital mission. The Breitling Navitimer Cosmonaute was designed with a 24-hour analog dial to avoid confusion between AM and PM, which are meaningless in space. It was first worn in space by U.S. astronaut Scott Carpenter on 24 May 1962 in the Aurora 7 mercury capsule.
Since 1994 Fortis is the exclusive supplier for manned space missions authorized by the Russian Federal Space Agency. China National Space Administration (CNSA) astronauts wear the Fiyta spacewatches. At BaselWorld, 2008, Seiko announced the creation of the first watch ever designed specifically for a space walk, Spring Drive Spacewalk. Timex Datalink is flight certified by NASA for space missions and is one of the watches qualified by NASA for space travel. The Casio G-Shock DW-5600C and 5600E, DW 6900, and DW 5900 are Flight-Qualified for NASA space travel.
Various Timex Datalink models were used both by cosmonauts and astronauts.
Scuba diving.
Watches may be crafted to become water resistant. These watches are sometimes called diving watches when they are suitable for scuba diving or saturation diving. The International Organization for Standardization issued a standard for water resistant watches which also prohibits the term "waterproof" to be used with watches, which many countries have adopted.
Water resistance is achieved by the gaskets which forms a watertight seal, used in conjunction with a sealant applied on the case to help keep water out. The material of the case must also be tested in order to pass as water resistant.
None of the tests defined by ISO 2281 for the Water Resistant mark are suitable to qualify a watch for scuba diving. Such watches are designed for everyday life and must be water resistant during exercises such as swimming. They can be worn in different temperature and pressure conditions but are under no circumstances designed for scuba diving.
The standards for diving watches are regulated by the ISO 6425 international standard. The watches are tested in static or still water under 125% of the rated (water)pressure, thus a watch with a 200-metre rating will be water resistant if it is stationary and under 250 metres of static water. The testing of the water resistance is fundamentally different from non-dive watches, because every watch has to be fully tested. Besides water resistance standards to a minimum of 100 metre depth rating ISO 6425 also provides eight minimum requirements for mechanical diver's watches for scuba diving (quartz and digital watches have slightly differing readability requirements). For diver's watches for mixed-gas saturation diving two additional requirements have to be met.
Watches are classified by their degree of water resistance, which roughly translates to the following (1 metre = 3.281 feet):
Some watches use bar instead of meters, which may then be multiplied by 10, and then subtract 10 to be approximately equal to the rating based on metres. Therefore, a 5 bar watch is equivalent to a 40-metre watch. Some watches are rated in atmospheres (atm), which are roughly equivalent to bar.
Using a watch and the sun as a compass.
There is a traditional method by which an analog watch can be used to locate north and south. The Sun appears to move in the sky over a 24-hour period while the hour hand of a 12-hour clock face takes twelve hours to complete one rotation. In the northern hemisphere, if the watch is rotated so that the hour hand points toward the Sun, the point halfway between the hour hand and 12 o'clock will indicate south. For this method to work in the southern hemisphere, the 12 is pointed toward the Sun and the point halfway between the hour hand and 12 o'clock will indicate north. During daylight saving time, the same method can be employed using 1 o'clock instead of 12. This method is accurate enough to be useful only at fairly high latitudes.

</doc>
<doc id="60885" url="https://en.wikipedia.org/wiki?curid=60885" title="Photoconductivity">
Photoconductivity

Photoconductivity is an optical and electrical phenomenon in which a material becomes more electrically conductive due to the absorption of electromagnetic radiation such as visible light, ultraviolet light, infrared light, or gamma radiation.
When light is absorbed by a material such as a semiconductor, the number of free electrons and electron holes increases and raises its electrical conductivity. To cause excitation, the light that strikes the semiconductor must have enough energy to raise electrons across the band gap, or to excite the impurities within the band gap. When a bias voltage and a load resistor are used in series with the semiconductor, a voltage drop across the load resistors can be measured when the change in electrical conductivity of the material varies the current through the circuit.
Classic examples of photoconductive materials include :
Applications.
When a photoconductive material is connected as part of a circuit, it functions as a resistor whose resistance depends on the light intensity. In this context, the material is called a photoresistor (also called "light-dependent resistor" or "photoconductor"). The most common application of photoresistors is as photodetectors, i.e. devices that measure light intensity. Photoresistors are not the "only" type of photodetector—other types include charge-coupled devices (CCDs), photodiodes and phototransistors—but they are among the most common. Some photodetector applications in which photoresistors are often used include camera light meters, street lights, clock radios, and infrared detectors.
Negative photoconductivity.
Some materials exhibit deterioration in photoconductivity upon exposure to illumination. One prominent example is hydrogenated amorphous silicon (a-Si:H) in which a metastable reduction in photoconductivity is observable (see Staebler–Wronski effect). Other materials that were reported to exhibit negative photoconductivity include molybdenum disulfide, graphene, and metal nanoparticles.

</doc>
<doc id="60886" url="https://en.wikipedia.org/wiki?curid=60886" title="Lev Yashin">
Lev Yashin

Lev Ivanovich Yashin (, 22 October 1929 – 20 March 1990), nicknamed the "Black Spider" or the "Black Panther", was a Soviet-Russian football goalkeeper, considered by many to be the greatest goalkeeper in the history of the game. He was known for his athleticism in goal, imposing stature and reflex saves. 
He was also deputy chairman of the Football Federation of the Soviet Union.
Yashin earned iconic status for revolutionizing the goalkeeping position by stamping his authority on the entire defence. He shouted orders at his defenders, came off his line to intercept crosses and also ran out to meet onrushing attackers, done at a time when goalkeepers spent the 90 minutes standing in the goal waiting to be called into action. His performances made an indelible impression on a global audience at the 1958 World Cup, the first to be broadcast internationally. He dressed head to toe in black, thus earning his nickname the 'Black Spider', which enhanced his popularity.
Yashin appeared in four World Cups from 1958 to 1970, and in 2002 was chosen on the FIFA Dream Team of the history of World Cups. In 1994 he was chosen for the FIFA World Cup All-Time Team, and in 1998 was chosen a member of the World Team of the 20th Century. He made over 150 penalty saves and kept over 270 clean sheets in his career, winning a gold medal at the 1956 Olympic football tournament, and the 1960 European Championships. In 1963, Yashin received the Ballon d'Or, the only goalkeeper ever to receive the award. He was voted the best goalkeeper of the 20th century by the IFFHS.
Early life.
Yashin was born in Moscow to a family of industrial workers. When he was 12, the Second World War forced him to turn to factory work to aid in the war effort. He was sent to work in a military factory in Moscow, where he played for its football team. It was there that he was spotted and invited to join the Dynamo Moscow youth team.
Career.
Dynamo Moscow.
Yashin’s debut for Dynamo came in 1950 in a friendly match. It was not the debut he would have hoped for, as he conceded a soft goal scored straight from a clearance by the opposing keeper. That year he played in only two league games, and did not appear in a senior match again until 1953. But he remained determined, and stayed at Dynamo in the reserves waiting for another opportunity. Yashin also played goalie for the Dynamo ice hockey team during those early years of trying to break into the senior squad. He managed to win a USSR ice hockey cup in 1953 and was third in the USSR ice hockey championship as goalkeeper.
He spent his professional football career with Dynamo Moscow, from 1950 to 1970, winning the USSR football championship five times and the USSR Cup three times. Yashin’s club team-mate, rival and mentor was Alexei ‘Tiger’ Khomich, the keeper of the Soviet national team, who had become famous for his role in Dynamo Moscow’s British tour. He also internally rivalled goalkeeper Walter Sanaya, who left the club in 1953.
National team.
In 1954, Yashin was called up to the national team, and would go on to gather 78 caps. With the national team he won the 1956 Summer Olympics and the 1960 European Championship. He also played in three World Cups, in 1958, 1962 and 1966. Yashin is credited with four clean sheets out of the 12 games he played in the World Cup finals. 
The 1958 World Cup, played in Sweden, put Yashin on the map for his performances, with the Soviet Union advancing to the quarter-finals. In a group stage match against the eventual Cup winners Brazil, which the Soviet team lost 2–0, Yashin’s performance prevented the score from becoming a rout. He was selected into the All-Star Team that World Cup.
In 1962, despite suffering two concussions during the tournament, he once again led the team to a quarter-final finish, before losing to host country Chile. That tournament showed that Yashin was all too human, having made some uncharacteristic mistakes. In the game against Colombia, which the Soviet Union was leading 4–1, Yashin let in a few soft goals, including a goal scored by Marcos Coll directly from a corner kick (the first and the only goal scored directly from a corner in FIFA World Cup history). The game finished in a 4–4 tie, which led the French newspaper l'Equipe to predict the end of Yashin’s career. He did, however, make an outstanding save against Chile in the Quarter-Final. Despite this, the Soviet Union suffered a 2-1 defeat and were eliminated from the World Cup.
Despite the disappointment of the 1962 World Cup, Yashin would bounce back to win the Ballon d'Or in 1963. One of his best performances that year was the FA Centenary match, when he appeared in the ‘Rest of the World XI’ against England at Wembley Stadium, and made a number of breathtaking and almost unbelievable saves. From that point onward he was known all over the world as the "Black Spider" because he wore a distinctive all-black outfit and because it seemed as though he had eight arms to save almost everything. But to his fans, he was always the fearless "Black Panther". He often played wearing a cloth cap of burnt-brick colour. Yashin led the Soviet team to its best showing at the FIFA World Cup, a fourth-place finish in the 1966 World Cup held in England.
Always ready to give advice to his comrades, Yashin even made a fourth trip to the World Cup finals in 1970, held in Mexico, as the third-choice back-up and an assistant coach. The Soviet team again reached the quarter-finals. In 1971, in Moscow, he played his last match for Dynamo Moscow. Lev Yashin’s FIFA testimonial match was held at the Lenin Stadium in Moscow with 100,000 fans attending and a host of football stars, including Pelé, Eusébio and Franz Beckenbauer.
Accolades.
Yashin remains the only goalkeeper to have won the Ballon d'Or Award, which he received in 1963. He also stopped 151 penalty kicks during his career, far more than any other goalkeeper in history, and kept over 270 clean sheets. For his outstanding service to the people and to his country, Yashin was awarded the Order of Lenin in 1967, the highest award of the USSR.
Yashin would always organize the defensive game of his team, often so fiercely that even his wife accused him of yelling too much on the pitch. He rarely captained his teams, as the accepted custom of appointing a goalkeeper captain was virtually unheard-of in that era, but his leadership on the field was always evident. Yashin was one of the goalkeepers that began the practice of punching balls out in difficult situations instead of trying to catch them. Other novel practices he developed were the quick throw of the ball to begin a counterattack, coming out of the penalty area to anticipate danger, and the command and organization of the defenders – practices now quite common among goalkeepers. When asked what his secret was, he would reply that the trick was "to have a smoke to calm your nerves, then toss back a strong drink to tone your muscles."
In 1994, FIFA established the Lev Yashin Award for the best goalkeeper at the World Cup finals. FIFA polls named Yashin as the sole goalkeeper in World Team of the 20th Century. World Soccer Magazine named him in their The 100 Greatest Players of the 20th century. Many commentators still consider Yashin the best keeper in the history of football, which resulted in the fact he was chosen to be the goalkeeper in most of the world-all-time teams ever written (including the FIFA World Cup All-Time Team and the FIFA Dream Team).
Post-playing career.
After retiring from playing, Yashin spent almost 20 years in various administrative positions at Dynamo Moscow. A bronze statue of Lev Yashin was erected at the Dynamo Stadium in Moscow.
In 1986, following a thrombophlebitis contracted while he was in Budapest, Yashin underwent the amputation of one of his legs. He died in 1990 of stomach cancer, despite a surgical intervention in an attempt to save his life. He was given a State funeral as a Soviet Honoured Master of Sport.
Yashin was survived by wife Valentina Timofeyevna and daughters Irina and Elena. His grandson Vasili Frolov played as a goalkeeper for "Dynamo".
Legacy.
The following works are devoted to Yashin:

</doc>
<doc id="60889" url="https://en.wikipedia.org/wiki?curid=60889" title="Skull crucible">
Skull crucible

The Skull Crucible process was developed at the Lebedev Physical Institute in Moscow to manufacture cubic zirconia. It was invented to solve the problem of cubic zirconia's melting-point being too high for even platinum crucibles. In essence, by heating only the center of a volume of cubic zirconia, the material forms its own "crucible" from its cooler outer layers. The term "skull" refers to these outer layers forming a shell enclosing the molten volume. Zirconium oxide powder is heated then gradually allowed to cool. Heating is accomplished by radio frequency induction using a coil wrapped around the apparatus. The outside of the device is water-cooled in order to keep the RF coil from melting and also to cool the outside of the zirconium oxide and thus maintain the shape of the zirconium powder.
Since zirconium oxide in its solid state does not conduct electricity, a piece of zirconium metal is placed inside the gob of zirconium oxide. As the zirconium melts it oxidizes and blends with the now molten zirconium oxide which now will conduct electricity and be heated by RF induction.
When the zirconium oxide is melted on the inside (but not completely, since the outside needs to remain solid) the amplitude of the RF induction coil is gradually reduced and crystals form as the material cools. Normally this would form zirconium oxide crystals with a monoclinic crystal structure. In order to maintain a cubic crystal structure a stabilizer is added, magnesium, calcium or yttrium oxide as well as any material add to color the crystal.
After the mixture cools the outer shell is broken off and the interior of the gob is then used to manufacture gemstones.

</doc>
<doc id="60891" url="https://en.wikipedia.org/wiki?curid=60891" title="Surveying">
Surveying

Surveying or land surveying is the technique, profession, and science of determining the terrestrial or three-dimensional position of points and the distances and angles between them. A land surveying professional is called a land surveyor. These points are usually on the surface of the Earth, and they are often used to establish land maps and boundaries for ownership, locations like building corners or the surface location of subsurface features, or other purposes required by government or civil law, such as property sales.
Surveyors work with elements of geometry, trigonometry, regression analysis, physics, engineering, metrology, programming languages and the law. They use equipment like total stations, robotic total stations, GPS receivers, retroreflectors, 3D scanners, radios, handheld tablets, digital levels, drones, GIS and surveying software.
Surveying has been an element in the development of the human environment since the beginning of recorded history. The planning and execution of most forms of construction require it. It is also used in transport, communications, mapping, and the definition of legal boundaries for land ownership. It is an important tool for research in many other scientific disciplines.
Definitions.
ACSM.
The American Congress on Surveying and Mapping (ACSM), defines surveying as "the science and art of making all essential measurements to determine the relative position of points or physical and cultural details above, on, or beneath the surface of the Earth, and to depict them in a usable form, or to establish the position of points or details."
Also per ACSM, the type of surveying known as "land surveying" is "the detailed study or inspection, as by gathering information through observations, measurements in the field, questionnaires, or research of legal instruments, and data analysis in the support of planning, designing, and establishing of property boundaries. It involves the re-establishment of cadastral surveys and land boundaries based on documents of record and historical evidence, as well as certifying surveys (as required by statute or local ordinance) of subdivision plats or maps, registered land surveys, judicial surveys, and space delineation. Land surveying can include associated services such as mapping and related data accumulation, construction layout surveys, precision measurements of length, angle, elevation, area, and volume, as well as horizontal and vertical control surveys, and the analysis and utilization of land survey data."
FIG.
The International Federation of Surveyors defines the function of surveying as:
A surveyor is a professional person with the academic qualifications and technical expertise to conduct one, or more, of the following activities;
History.
Ancient surveying.
Basic surveyance has occurred since humans built the first large structures. The prehistoric monument at Stonehenge (c. 2500 BC) was set out by prehistoric surveyors using peg and rope geometry.
In ancient Egypt, a rope stretcher would use simple geometry to re-establish boundaries after the annual floods of the Nile River. The almost perfect squareness and north-south orientation of the Great Pyramid of Giza, built c. 2700 BC, affirm the Egyptians' command of surveying. The "Groma" instrument originated in Mesopotamia (early 1st millennium BC).
The mathematician Liu Hui described ways of measuring distant objects in his work "Haidao suanjing" or "The Sea Island Mathematical Manual", published in 263 AD.
The Romans recognized land surveyors as a profession. They established the basic measurements under which the Roman Empire was divided, such as a tax register of conquered lands (300 AD). Roman surveyors were known as "Gromatici".
In medieval Europe, beating the bounds maintained the boundaries of a village or parish. This was the practice of gathering a group of residents and walking around the parish or village to establish a communal memory of the boundaries. Young boys were included to ensure the memory lasted as long as possible.
In England, William the Conqueror commissioned the Domesday Book in 1086. It recorded the names of all the land owners, the area of land they owned, the quality of the land, and specific information of the area's content and inhabitants. It did not include maps showing exact locations.
Modern surveying.
Abel Foullon described a plane table in 1551, but it is thought that the instrument was in use earlier as his description is of a developed instrument.
Gunter's chain was introduced in 1620 by English mathematician Edmund Gunter. It enabled plots of land to be accurately surveyed and plotted for legal and commercial purposes.
Leonard Digges described a Theodolite that measured horizontal angles in his book "A geometric practice named Pantometria" (1571). Joshua Habermel (:de:Erasmus Habermehl) created a theodolite with a compass and tripod in 1576. Johnathon Sission was the first to incorporate a telescope on a theodolite in 1725.
In the 18th century, modern techniques and instruments for surveying began to be used. Jesse Ramsden introduced the first precision theodolite in 1787. It was an instrument for measuring angles in the horizontal and vertical planes. He created his great theodolite using an accurate dividing engine of his own design. Ramsden's theodolite represented a great step forward in the instrument's accuracy. William Gascoigne invented an instrument that used a telescope with an installed crosshair as a target device, in 1640. James Watt developed an optical meter for the measuring of distance in 1771; it measured the parallactic angle from which the distance to a point could be deduced.
Dutch mathematician Willebrord Snellius (a.k.a. Snell) introduced the modern systematic use of triangulation. In 1615 he surveyed the distance from Alkmaar to Bergen op Zoom, approximately 70 miles (110 kilometres). The survey was a chain of quadrangles containing 33 triangles in all. Snell showed how planar formulae could be corrected to allow for the curvature of the earth. He also showed how to resection, or calculate, the position of a point inside a triangle using the angles cast between the vertices at the unknown point. These could be measured more accurately than bearings of the vertices, which depended on a compass. His work established the idea of surveying a primary network of control points, and locating subsidiary points inside the primary network later. Between 1733 and 1740, Jacques Cassini and his son César undertook the first triangulation of France. They included a re-surveying of the meridian arc, leading to the publication in 1745 of the first map of France constructed on rigorous principles. By this time, triangulation methods were by then well established for local map-making,
It was only towards the end of the 18th century that detailed triangulation network surveys mapped whole countries. In 1784, a team from General William Roy's Ordnance Survey of Great Britain began the Principal Triangulation of Britain. The first Ramsden theodolite was built for this survey. The survey was finally completed in 1853. The Great Trigonometric Survey of India began in 1801. The Indian survey had an enormous scientific impact. It was responsible for one of the first accurate measurements of a section of an arc of longitude, and for measurements of the geodesic anomaly. It named and mapped Mount Everest and the other Himalayan peaks. Surveying became a professional occupation in high demand at the turn of the 19th century with the onset of the Industrial Revolution. The profession developed more accurate instruments to aid its work. Industrial infrastructure projects used surveyors to lay out canals, roads and rail,
In the US, the Land Ordinance of 1785 created the Public Land Survey System. It formed the basis for dividing the western territories into sections to allow the sale of land. The PLSS divided states into township grids which were further divided into sections and fractions of sections.
Napoleon Bonaparte founded continental Europe's first cadastre in 1808. This gathered data on the number of parcels of land, their value, land usage, and names. This system soon spread around Europe.
Robert Torrens introduced the Torrens system in South Australia in 1858. Torrens intended to simplify land transactions and provide reliable titles via a centralized register of land. The Torrens system was adopted in several other nations of the English-speaking world.
20th century.
At the beginning of the century surveyors had improved the older chains and ropes, but still faced the problem of accurate measurement of long distances. Dr Trevor Lloyd Wadley developed the Tellurometer during the 1950s. It measures long distances using two microwave transmitter/receivers.
During the late 1950s Geodimeter introduced electronic distance measurement (EDM) equipment. EDM units use a multi frequency phase shift of light waves to find a distance. These instruments saved the need for days or weeks of chain measurement by measuring between points kilometers apart in one go.
Advances in electronics allowed miniaturization of EDM. In the 1970s the first instruments combining angle and distance measurement appeared, becoming known as total stations. Manufacturers added more equipment by degrees, bringing improvements in accuracy and speed of measurement. Major advances include tilt compensators, data recorders, and on-board calculation programs.
The first Satellite positioning system was the US Navy TRANSIT system. The first successful launch took place in 1960. The system's main purpose was to provide position information to Polaris missile submarines. Surveyors found they could use field receivers to determine the location of a point. Sparse satellite cover and large equipment made observations laborious, and inaccurate. The main use was establishing benchmarks in remote locations.
The US Air force launched the first prototype satellites of the Global Positioning System (GPS) in 1978. GPS used a larger constellation of satellites and improved signal transmission to provide more accuracy. Early GPS observations required several hours of observations by a static receiver to reach survey accuracy requirements. Recent improvements to both satellites and receivers allow Real Time Kinematic (RTK) surveying. RTK surveys get high-accuracy measurements by using a fixed base station and a second roving antenna. The position of the roving antenna can be tracked.
21st century.
The theodolite, total station, and RTK GPS survey remain the primary methods in use.
Remote sensing and satellite imagery continue to improve and become cheaper, allowing more commonplace use. Prominent new technologies include three-dimensional (3D) scanning and use of lidar for topographical surveys. UAV technology along with photogrammetric image processing is also appearing.
Surveying equipment.
Hardware.
The main surveying instruments in use around the world are the theodolite, measuring tape, total station, 3D scanners, GPS/GNSS, level and rod. Most instruments screw onto a tripod when in use. Tape measures are often used for measurement of smaller distances. 3D scanners and various forms of aerial imagery are also used.
The Theodolite is an instrument for the measurement of angles. It uses two separate "circles", "protractors" or "alidades" to measure angles in the horizontal and the vertical plane. A telescope mounted on trunnions is aligned vertically with the target object. The whole upper section rotates for horizontal alignment. The vertical circle measures the angle that the telescope makes against the vertical, known as the vertical angle. The horizontal circle uses an upper and lower plate. When beginning the survey, the surveyor points the instrument in a known direction (bearing), and clamps the lower plate in place. The instrument can then rotate to measure the bearing to other objects. If no bearing is known or direct angle measurement is wanted, the instrument can be set to zero during the initial sight. It will then read the angle between the initial object, the theodolite itself, and the item that the telescope aligns with.
The Gyrotheodolite is a form of theodolite that uses a gyroscope to orient itself in the absence of reference marks. It is used in underground applications.
The total station is a development of the theodolite with an electronic distance measurement device (EDM). A total station can be used for leveling when set to the horizontal plane. Since their introduction, total stations have shifted from optical-mechanical to fully electronic devices.
Modern top-of-the-line total stations no longer need a reflector or prism to return the light pulses used for distance measurements. They are fully robotic, and can even e-mail point data to a remote computer and connect to satellite positioning systems, such as Global Positioning System. Real Time Kinematic GPS systems have increased the speed of surveying, but they are still only horizontally accurate to about 20 mm and vertically to 30–40 mm.
GPS surveying differs from other GPS users in the equipment and methods used. Static GPS uses two receivers placed in position for a considerable length of time. The long span of time lets the receiver compare measurements as the satellites orbit. The changes as the satellites orbit also provide the measurement network with well conditioned geometry. This produces an accurate baseline that can be over 20 km long. RTK surveying uses one static antenna and one roving antenna. The static antenna tracks changes in the satellite positions and atmospheric conditions. The surveyor uses the roving antenna to measure the points needed for the survey. The two antennas use a radio link that allows the static antenna to send corrections to the roving antenna. The roving antenna then applies those corrections to the GPS signals it is receiving to calculate its own position. RTK surveying covers smaller distances than static methods. This is because divergent conditions further away from the base reduce accuracy.
Surveying instruments have characteristics that make them suitable for certain uses. Theodolites and levels are often used by constructors rather than surveyors in first world countries. The constructor can perform simple survey tasks using a relatively cheap instrument. Total stations are workhorses for many professional surveyors because they are versatile and reliable in all conditions. The productivity improvements from a GPS on large scale surveys makes them popular for major infrastructure or data gathering projects. One-person robotic-guided total stations allow surveyors to measure without extra workers to aim the telescope or record data. A fast but expensive way to measure large areas is with a helicopter, using a GPS to record the location of the helicopter and a laser scanner to measure the ground. To increase precision, surveyors place beacons on the ground (about apart). This method reaches precisions between 5–40 cm (depending on flight height).
Surveyors use ancillary equipment such as: tripods and instrument stands; staves and beacons used for sighting purposes; PPE; vegetation clearing equipment; digging implements for finding survey markers buried over time; hammers for placements of markers in various surfaces and structures; and portable radios for communication over long lines of sight.
Software.
Land surveyors, construction professionals and civil engineers using total station, GPS, 3D scanners and other collector data use Land Surveying Software to increase efficiency, accuracy and productivity. Land Surveying Software is a staple of contemporary land surveying.
Surveying techniques.
Surveyors determine the position of objects by measuring angles and distances. The factors that can affect the accuracy of their observations are also measured. They then use this data to create vectors, bearings, co-ordinates, elevations, areas, volumes, plans and maps. Measurements are often split into horizontal and vertical components to simplify calculation.
GPS and astronomic measurements also need measurement of a time component.
Distance measurement.
Before EDM devices, distances were measured using a variety of means. These included chains having links of a known length such as a Gunter's chain, or measuring tapes made of steel or invar. To measure horizontal distances, these chains or tapes were pulled taut to reduce sagging and slack. The distance had to be adjusted for heat expansion. Attempts to hold the measuring instrument level would also be made. When measuring up a slope, the surveyor might have to "break" (break chain) the measurement- use an increment less than the total length of the chain. Perambulators, or measuring wheels, were used to measure longer distances but not to a high level of accuracy. Tacheometry is the science of measuring distances by measuring the angle between two ends of an object with a known size. It was sometimes used before to the invention of EDM where rough ground made chain measurement impractical.
Angle measurement.
Historically, horizontal angles were measured by using a compass to provide a magnetic bearing. The deflection from the bearing was recorded. Later, more precise scribed discs later improved better angular resolution. Mounting telescopes with reticles atop the disc allowed more precise sighting. (see theodolite). Levels and calibrated circles allowed measurement of vertical angles. verniers allowed measurement to a fraction of a degree, such as with a turn-of-the-century transit.
The Plane table provided a graphical method of recording and measuring angles, which reduced the amount of mathematics required.
By observing the bearing from every vertex in a figure, a surveyor can measure around the figure. The final observation will be between the two points first observed, except with a 180° difference. This is called a "close". If the first and last bearings are different, this shows the error in the survey, called the "angular misclose". The surveyor can use this information to prove that the work meets the expected standards.
Levelling.
The simplest method for measuring height is with an altimeter using air pressure to find height. When more precise measurements are needed, means like precise levels (also known as differential leveling) are used. When precise leveling, a series of measurements between two points are taken using an instrument and a measuring rod. Differences in height between the measurements are added and subtracted in a series to get the net difference in elevation between the two endpoints. With the Global Positioning System (GPS), elevation can be measured with satellite receivers. Usually GPS is somewhat less accurate than traditional precise leveling, but may be similar over long distances.
When using an optical level, the endpoint may be out of the effective range of the instrument. There may be obstructions or large changes of elevation between the endpoints. In these situations, extra setups are needed. "Turning" is a term used when referring to moving the level to take an elevation shot from a different location. To "turn" the level, one must first take a reading and record the elevation of the point the rod is located on. While the rod is being kept in exactly the same location, the level is moved to a new location where the rod is still visible. A reading is taken from the new location of the level and the height difference is used to find the new elevation of the level gun. This is repeated until the series of measurements is completed. The level must be horizontal to get a valid measurement. Because of this, if the horizontal crosshair of the instrument is lower than the base of the rod, the surveyor will not be able to sight the rod and get a reading. The rod can usually be raised up to 25 feet high, allowing the level to be set much higher than the base of the rod.
Determining position.
The primary way of determining one's position on the earth's surface when no known positions are nearby is by astronomic observations. Observations to the sun, moon and stars could all be made using navigational techniques. Once the instrument's position and bearing to a star is determined, the bearing can be transferred to a reference point on the earth. The point can then be used as a base for further observations. Survey-accurate astronomic positions were difficult to observe and calculate and so tended to be a base off which many other measurements were made. Since the advent of the GPS system, astronomic observations are rare as GPS allows adequate positions to be determined over most of the surface of the earth.
Reference networks.
Few survey positions are derived from first principles. Instead, most surveys points are measured relative to previous measured points. This forms a reference or "control" network where each point can be used by a surveyor to determine their own position when beginning a new survey.
Survey points are usually marked on the earth's surface by objects ranging from small nails driven into the ground to large beacons that can be seen from long distances. The surveyors can set up their instruments on this position and measure to nearby objects. Sometimes a tall, distinctive feature such as a steeple or radio aerial has its position calculated as a reference point that angles can be measured against.
"Triangulation" is a method of horizontal location favoured in the days before EDM and GPS measurement. It can determine distances, elevations and directions between distant objects. Since the early days of surveying, this was the primary method of determining accurate positions of objects for topographic maps of large areas. A surveyor first needs to know the horizontal distance between two of the objects, known as the baseline. Then the heights, distances and angular position of other objects can be derived, as long as they are visible from one of the original objects. High-accuracy transits or theodolites were used, and angle measurements repeated for increased accuracy. See also Triangulation in three dimensions.
"Offsetting" is an alternate method of determining position of objects, and was often used to measure imprecise features such as riverbanks. The surveyor would mark and measure two known positions on the ground roughly parallel to the feature, and mark out a baseline between them. At regular intervals, a distance was measured at right angles from the first line to the feature. The measurements could then be plotted on a plan or map, and the points at the ends of the offset lines could be joined to show the feature.
"Traversing" is a common method of surveying smaller areas. The surveyor starts from an old reference mark or known position and places a network of reference marks covering the survey area. They then measure bearings and distances between the reference marks, and to the target features. Most traverses form a loop pattern or link between two prior reference marks to allow the surveyor to check their measurements are correct.
Datum and coordinate systems.
Many surveys do not calculate positions on the surface of the earth, but instead measure the relative positions of objects. However, often the surveyed items need to be compared to outside data, such as boundary lines or previous surveys objects. The oldest way of describing a position is via latitude and longitude, and often a height above sea level. As the surveying profession grew it created Cartesian coordinate systems to simplify the mathematics for surveys over small parts of the earth. The simplest coordinate systems assume that the earth is flat and measure from an arbitrary point, known as a 'datum' (singular form of data). The coordinate system allows easy calculation of the distances and direction between objects over small areas. Large areas distort due to the earth's curvature. North is often defined as true north at the datum.
For larger regions, it is necessary to model the shape of the earth using an ellipsoid or a geoid. Many countries have created coordinate-grids customized to lessen error in their area of the earth.
Errors and accuracy.
A basic tenet of surveying is that no measurement is perfect, and that there will always be a small amount of error. There are three classes of survey errors:
Surveyors avoid these errors by regular checks on their equipment, using consistent methods, and by good design of their reference network. Redundancy of measurements allows the use of averaging and allows outlier measurements to be discarded. Independent checks like measuring a point from two or more locations or using two different methods are used. Errors can be detected by comparing the results of the two measurements.
Once the surveyor has calculated the level of the errors in his work, it is adjusted. This is the process of distributing the error between all measurements. Each observation is weighted according to how much of the total error it is likely to have caused and part of that error is allocated to it in a proportional way. The most common methods of adjustment are the Bowditch method, also known as the compass rule, and the Principle of least squares method.
The Surveyor must be able to distinguish between accuracy and precision. In the United States, surveyors and civil engineers use units of feet wherein a survey foot breaks down into 10ths and 100ths. Many deed descriptions containing distances are often expressed using these units (125.25 ft). On the subject of accuracy, surveyors are often held to a standard of one one-hundredth of a foot; about 1/8 inch. Calculation and mapping tolerances are much smaller wherein achieving near-perfect closures are desired. Though tolerances will vary from project to project, in the field and day to day usage beyond a 100th of a foot is often impractical.
Types of surveys.
Local professional organisation or regulatory bodies classify specializations of surveying in different ways. Broad groups are:
Plane and geodetic surveying.
Based on the considerations and true shape of the earth, surveying is broadly classified into two types.
"Plane surveying" assumes the earth is flat. Curvature and spheroidal shape of the earth is neglected. In this type of surveying all triangles formed by joining survey lines are considered as plane triangles. It is employed for small survey works where errors due to the earth's shape are too small to matter.
In "geodetic surveying" curvature of the earth is taken into account while calculating reduced levels, angles, bearings and distances. This type of surveying is only employed for large survey works. Generally the survey works below 260 kilometers radius are treated as plane and beyond that is treated as geodetic. Thus in this type of surveying necessary corrections are applied to reduced levels, bearings and other observations.
The surveying profession.
The basic principles of surveying have changed little over the ages, but the tools used by surveyors have evolved. Engineering, especially civil engineering, often needs surveyors.
Surveyors help determine the placement of roads, railways, reservoirs, dams, pipelines, retaining walls, bridges, and buildings. They establish the boundaries of legal descriptions and political divisions. They also provide advice and data for "geographical information systems" (GIS) that record land features and boundaries.
Surveyors must have a thorough knowledge of algebra, basic calculus, geometry, and trigonometry. They must also know the laws that deal with surveys, real property, and contracts.
Most jurisdictions recognize three different levels of qualification:
"Survey assistants" or "chainmen" are usually unskilled workers who help the surveyor. They place target reflectors, find old reference marks, and mark points on the ground. The term 'chainman' derives from past use of measuring chains. An assistant would move the far end of the chain under the surveyor's direction.
"Survey technicians" often operate survey instruments, run surveys in the field, do survey calculations, or draft plans. A technician usually has no legal authority and cannot certify his work. Not all technicians are qualified, but qualifications at the certificate or diploma level are available.
"Licensed, registered, or chartered surveyors" usually hold a degree or higher qualification. They are often required to pass further exams to join a professional association or to gain certifying status. Surveyors are responsible for planning and management of surveys. They have to ensure that their surveys, or surveys performed under their supervision, meet the legal standards. Many principals of surveying firms hold this status.
Informal surveying.
Not all surveys are carried out by professional surveyors. Depending on the jurisdiction and circumstances, the builders of a structure may set it out themselves. Surveyors often set out the most significant corners of a building. The builders then lay out the rest of the building themselves using simple surveying techniques.
Licensing.
Licensing requirements vary with jurisdiction, and are commonly consistent within national borders. Prospective surveyors usually have to receive a degree in surveying, followed by a detailed examination of their knowledge of surveying law and principles specific to the region they wish to practice in, and undergo a period of on-the-job training or portfolio building before they are awarded a license to practise. Licensed surveyors usually receive a post nominal, which varies depending on where they qualified. The system has replaced older apprenticeship systems.
A licensed land surveyor is generally required to sign and seal all plans. The state dictates the format, showing their name and registration number.
In many jurisdictions, surveyors must mark their registration number on survey monuments when setting boundary corners. Monuments take the form of capped iron rods, concrete monuments, or nails with washers.
Surveying institutions.
Most countries' governments regulate at least some forms of surveying. Their survey agencies establish regulations and standards. Standards control accuracy, surveying credentials, monumentation of boundaries and maintenance of geodetic networks. Many nations devolve this authority to regional entities or states/provinces. Cadastral surveys tend to be the most regulated because of the permanence of the work. Lot boundaries established by cadastral surveys may stand for hundreds of years without modification.
Most jurisdictions also have a form of professional institution representing local surveyors. These institutes often endorse or license potential surveyors, as well as set and enforce ethical standards. The largest institution is the International Federation of Surveyors (Abbreviated FIG, for ). They represent the survey industry worldwide.
Building surveying.
Most English-speaking countries consider building surveying a distinct profession. They have their own professional associations and licensing requirements. Building surveyors focus on investigating the condition of buildings as well as legal compliance work.
Cadastral surveying.
One of the primary roles of the land surveyor is to determine the boundary of real property on the ground. The surveyor must determine where the adjoining landowners wish to put the boundary. The boundary is established in legal documents and plans prepared by attorneys, engineers, and land surveyors. The surveyor then puts monuments on the corners of the new boundary. They might also find or resurvey the corners of the property monumented by prior surveys.
Cadastral land surveyors are licensed by governments.
The cadastral survey branch of the Bureau of Land Management (BLM) conducts most cadastral surveys in the United States. They consult with Forest Service, National Park Service, Army Corps of Engineers, Bureau of Indian Affairs, Fish and Wildlife Service, Bureau of Reclamation, and others. The BLM used to be known as the General Land Office (GLO).
In states organized per the Public Land Survey System (PLSS), surveyors must carry out BLM cadastral surveys under that system.
Cadastral surveyors often have to work around changes to the earth that obliterate or damage boundary monuments. When this happens, they must consider evidence that is not recorded on the title deed. This is known as extrinsic evidence.

</doc>
<doc id="60895" url="https://en.wikipedia.org/wiki?curid=60895" title="Land of Hope and Glory">
Land of Hope and Glory

"Land of Hope and Glory" is a British patriotic song, with music by Edward Elgar and lyrics by A. C. Benson, written in 1902.
Composition.
The music to which the words of the refrain "Land of Hope and Glory, &c" below are set is the "trio" theme from Edward Elgar's "Pomp and Circumstance March No. 1". The words were fitted to the melody on the suggestion of King Edward VII who told Elgar he thought the melody would make a great song. When Elgar was requested to write a work for the King's coronation, he worked the suggestion into his "Coronation Ode", for which he asked the poet and essayist A. C. Benson to write the words. The last section of the "Ode" uses the march's melody.
Due to the King's illness, the coronation was postponed. Elgar created a separate song, which was first performed by Madame Clara Butt in June 1902. In fact, only the first of the seven stanzas of the Ode's final section was re-used, as the first four lines of the second stanza below. This stanza is the part which is popularly sung today.
Lyrics.
<poem>
"Solo"
"Chorus"
"Solo"
"Chorus"
</poem>
"Wider still and wider".
The writing of the song is contemporaneous with the publication of Cecil Rhodes' will—in which he bequeathed his considerable wealth for the specific purpose of promoting "the extension of British rule throughout the world", and added a long detailed list of territories which Rhodes wanted brought under British rule and colonised by British people. The reference to the extension of the British Empire's boundaries may reflect the Boer War, recently won at the time of writing, in which the United Kingdom gained further territory, endowed with considerable mineral wealth.
Usage.
Proposed anthem for England.
England currently has no agreed national anthem, with "God Save the Queen", the national anthem of the United Kingdom, often being used in sporting events in which England competes separately from the other Home Nations. However, there are calls for this to be changed, and a 2006 survey conducted by the BBC suggested that 55% of the English public would rather have "Land of Hope and Glory" than "God Save the Queen" as their national anthem.
Commonwealth Games.
Prior to 2010, "Land of Hope and Glory" was used as the victory anthem of England team at the Commonwealth Games.
On St George's Day, 23 April 2010, the Commonwealth Games Council for England launched a poll to allow the public to decide which anthem would be played at the 2010 Commonwealth Games in Delhi, India. Voters chose between "God Save the Queen", "Jerusalem" and "Land of Hope and Glory" with the winning song, "Jerusalem", being adopted as the official anthem for Team England.
BBC Proms.
"Land of Hope and Glory" has traditionally been sung as the first song amidst flag-waving at the climax of the Last Night of the Proms.
Rugby.
At international rugby league matches, England often sang "Land of Hope and Glory" as their national anthem. While their anthem changed to "God Save the Queen" after the dissolution of the Great Britain side in 2007, it is still tradition for the team to use "Land of Hope and Glory" as their walk-out theme.
"Land of Hope and Glory" is sung by English fans at home England rugby union games in Twickenham after the home and away National Anthems have been sung. "Land of Hope and Glory" is sung by the crowd as the teams assemble for kick off; this began as a response to the New Zealand team's haka.
Football.
Supporters of Wolverhampton Wanderers Football Club (the team Elgar supported) sing a version of the song with the lyrics changed to "We will follow the Wanderers over land sea and water". as do their local rivals West Bromwich Albion sing "We will follow the Albion over land sea and water". Supporters of Huddersfield Town sing 'We're all following Huddersfield, over land and sea'. Derby County football club supporters sing “We all follow Derby, over land and sea (and Leicester)”, similarly MK Dons fans sing "We all follow the MK, over the land and sea (and Wycombe!)".
In Wales Aberystwyth Town supporters sing a version of the song, 'We all follow the Aber, over land and sea and Bangor! we all follow the Aber, on to victory'. Leeds United supporters sing a version of the song that goes as follows; 'Land of hope and glory, Yorkshire shall be free, We all follow United, onto victory'. 
In London, Spurs fans have been heard to sing "We hate Nottingham Forest. We hate Arsenal, too. We hate Manchester United, but Tottenham we love you."
Films.
"Land of Hope and Glory" was sung by Jeanette MacDonald in the 1941 MGM film, "Smilin' Through".
The song inspired the rather ironic title of the 1987 film "Hope and Glory", depicting WWII through the eyes of a 10-year-old boy.
The song is also used in the 2012 Japanese film "Little Maestra". It is set in a small fishing village in Shikamachi, Ishikawa Prefecture, who depend on the local amateur orchestra as their favorite source of entertainment. When the conductor dies unexpectedly, the townspeople recruit the man’s granddaughter, a high school student with a talent for conducting. The song is heard three times throughout the movie.
United States and Canada.
In the United States and Canada the instrumental version of this song is traditionally associated with high school and college (university) graduations. It is played as a processional or recessional. During ceremonies for larger schools this piece is played repeatedly. It may be played for as long as the graduates are walking, which can be longer than some symphonies.
It was the entrance music of American professional wrestler Randy "Macho Man" Savage, who died in 2011.

</doc>
<doc id="60899" url="https://en.wikipedia.org/wiki?curid=60899" title="Greasy spoon">
Greasy spoon

Greasy spoon is a colloquial term for a small, cheap restaurant or diner typically specialising in fried foods. According to the "Oxford English Dictionary", the term originated in the United States and is now used in various English-speaking countries.
The name "greasy spoon" is a reference to the typically high-fat, high-calorie menu items such as eggs and bacon. The term has been used to refer to a "small cheap restaurant" since at least the 1920s.
United States.
Many typical American greasy spoons focus on fried or grilled food, such as fried eggs, bacon, burgers, hash browns, waffles, pancakes, omelettes, deep fried chicken, and sausages. These are often accompanied by baked beans, french fries, coleslaw, or toast. Soups and chili con carne are generally available.
Since the 1970s, many Greek immigrants have entered the business. As a result, gyro and souvlaki meats are now a common part of the repertoire, often served as a side dish with breakfast and as a replacement for bacon or sausage.
A full meal may be available for a special price, sometimes called a blue-plate special. Regional fare is often served. Coffee, iced tea, and soft drinks are the typical beverages, and pie and ice cream are popular desserts.
United Kingdom.
In the UK, greasy spoons typically offer a wider range of foods, often taking advantage of inexpensive seasonal ingredients. In the United Kingdom, greasy spoons are also commonly referred to as "cafes" (occasionally as "working men's cafes") and colloquially as "caff". Not all cafes are greasy spoons, however. A greasy spoon in the UK is commonly an independently owned business and rarely, if ever, part of a chain or group. Increasingly, they are gradually being forced out of business by large coffee house chains and fast food franchises.
The typical working men's cafe serves mainly fried or grilled food, such as fried eggs, bacon, black pudding, bubble and squeak, burgers, sausages, mushrooms and chips. These are often accompanied by baked beans, cooked tomatoes, and fried bread. These are served in a variety of combinations and are generally referred to as "breakfast" even if they are available all day.
Hot and cold sandwiches are also often available: the bacon butty and sausage sandwich are particularly popular. The main drink in a British working men's cafe is usually tea, especially "builder's tea" (a nickname for a mug of strong black tea, such as English breakfast tea, usually served with milk and sugar and is typically robust and flavourful with a brisk character and a dark red colour). Often the only coffee available will be instant, though this has slowly changed with the increased proliferation of coffee drinking. British working men's cafes will sometimes also offer bread and butter pudding, apple crumble, and rhubarb crumble.
The greasy spoon was the mainstay of British lorry drivers who travelled the major trunk roads such as the A1 and the A6 prior to the opening of the motorways. These cafes were not only stops where the driver could eat, but also made convenient meeting places where the trade unions could talk to their members. In 2001, a story broke in the UK press about how the European Union were making an attempt to ban the greasy spoon cafes. This turned out to be a hoax, a fairly typical Euromyth based on an exaggeration of an EU report about eating habits of long-distance drivers and their health.
In the United Kingdom, the traditional greasy spoon has been in decline due to the rise of fast-food chains; they nevertheless remain numerous all over the UK, especially in certain parts of London, Birmingham, Manchester, Derby, and many seaside towns. The demand for their style of cuisine has resulted in the establishment of greasy spoons all over the world, and particularly in European coastal resorts located within an hour's coach ride from charter airlines' destinations, in which full breakfasts may be available all day.

</doc>
<doc id="60900" url="https://en.wikipedia.org/wiki?curid=60900" title="Carp">
Carp

Carp are various species of oily freshwater fish from the family Cyprinidae, a very large group of fish native to Europe and Asia.
Biology.
The cypriniformes (family Cyprinidae) are traditionally grouped with the Characiformes, Siluriformes, and Gymnotiformes to create the superorder Ostariophysi, since these groups share some common features. These features include being found predominantly in fresh water and possessing Weberian ossicles, an anatomical structure derived from the first five anterior-most vertebrae, and their corresponding ribs and neural crests. The third anterior-most pair of ribs is in contact with the extension of the labyrinth and the posterior with the swim bladder. The function is poorly understood, but this structure is presumed to take part in the transmission of vibrations from the swim bladder to the labyrinth and in the perception of sound, which would explain why the Ostariophysi have such a great capacity for hearing.
Most cypriniformes have scales and teeth on the inferior pharyngeal bones which may be modified in relation to the diet. "Tribolodon" is the only cyprinid genus which tolerates salt water. Several species move into brackish water but return to fresh water to spawn. All of the other cypriniformes live in continental waters and have a wide geographical range. Some consider all cyprinid fishes carp, and the family Cyprinidae itself is often known as the carp family. In colloquial use, carp usually refers only to several larger cyprinid species such as "Cyprinus carpio" (common carp), "Carassius carassius" (Crucian carp), "Ctenopharyngodon idella" (grass carp), "Hypophthalmichthys molitrix" (silver carp), and "Hypophthalmichthys nobilis" (bighead carp). Carp have long been an important food fish to humans. Several species such as the various goldfish breeds and the domesticated common carp variety known as koi have been popular ornamental fishes. As a result, carp have been introduced to various locations, though with mixed results. Several species of carp are listed as invasive species by the U.S. Department of Agriculture, and, worldwide, large sums of money are spent on carp control.
Recreational fishing.
In 1653 Izaak Walton wrote in "The Compleat Angler", "The Carp is the queen of rivers; a stately, a good, and a very subtle fish; that was not at first bred, nor hath been long in England, but is now naturalised."
Carp are variable in terms of angling value.
Aquaculture.
Various species of carp have been domesticated and reared as food fish across Europe and Asia for thousands of years. These various species appear to have been domesticated independently, as the various domesticated carp species are native to different parts of Eurasia. Aquaculture has been pursued in China for at least 2,400 years. A tract by Fan Li in the fifth century BC details many of the ways carp were raised in ponds. The common carp, "Cyprinus carpio", is originally from Central Europe. Several carp species (collectively known as Asian carp) were domesticated in East Asia. Carp that are originally from South Asia, for example catla ("Gibelion catla"), rohu ("Labeo rohita") and mrigal ("Cirrhinus cirrhosus"), are known as Indian carp. Their hardiness and adaptability have allowed domesticated species to be propagated all around the world.
Although the carp was an important aquatic food item, as more fish species have become readily available for the table, the importance of carp culture in Western Europe has become less important. Demand has declined, partly due to the appearance of more desirable table fish such as trout and salmon through intensive farming, and environmental constraints. However, fish production in ponds is still a major form of aquaculture in Central and Eastern Europe, including the Russian Federation, where most of the production comes from low or intermediate-intensity ponds. In Asia, the farming of carp continues to surpass the total amount of farmed fish volume of intensively sea-farmed species, such as salmon and tuna.
Breeding.
Selective breeding programs for the common carp include improvement in growth, shape, and resistance to disease. Experiments carried out in the USSR used crossings of broodstocks to increase genetic diversity, and then selected the species for traits such as growth rate, exterior traits and viability, and/or adaptation to environmental conditions such as variations in temperature. selected carp for fast growth and tolerance to cold, the Ropsha carp. The results showed a 30 to 77.4% improvement of cold tolerance, but did not provide any data for growth rate. An increase in growth rate was observed in the second generation in Vietnam, Moav and Wohlfarth (1976) showed positive results when selecting for slower growth for three generations compared to selecting for faster growth. Schaperclaus (1962) showed resistance to the dropsy disease wherein selected lines suffered low mortality (11.5%) compared to unselected (57%).
The major carp species used traditionally in Chinese aquaculture are the black, grass, silver and bighead carp. In the 1950s, the Pearl River Fishery Research Institute in China made a technological breakthrough in the induced breeding of these carps, which has resulted in a rapid expansion of freshwater aquaculture in China. In the late 1990s, scientists at the Chinese Academy of Fishery Sciences developed a new variant of the common carp called the Jian carp. This fish grows rapidly and has a high feed conversion rate. Over 50% of the total aquaculture production of carp in China has now converted to Jian carp.
As ornamental fish.
Carp, along with many of their cyprinid relatives, are popular ornamental aquarium and pond fish. The two most notable ornamental carps are goldfish and koi. Goldfish and koi have advantages over most other ornamental fishes, in that they are tolerant of cold (they can survive in water temperatures as low as 4 °C), can survive at low oxygen levels, and can tolerate low water quality.
Goldfish ("Carassius auratus") were originally domesticated from the Prussian carp ("Carassius gibelio"), a dark greyish-brown carp native to Asia. They were first bred for color in China over a thousand years ago. Due to selective breeding, goldfish have been developed into many distinct breeds, and are found in various colors, color patterns, forms and sizes far different from those of the original carp. Goldfish were kept as ornamental fish in China for thousands of years before being introduced to Japan in 1603, and to Europe in 1611.
Koi are a domesticated subspecies of common carp ("Cyprinus carpio") that have been selectively bred for color. The common carp was introduced from China to Japan, where selective breeding of the common carp in the 1820s in the Niigata region resulted in koi. In Japanese culture, koi are treated with affection, and seen as good luck. They are popular in other parts of the world as outdoor pond fish.

</doc>
<doc id="60901" url="https://en.wikipedia.org/wiki?curid=60901" title="Pomp and Circumstance Marches">
Pomp and Circumstance Marches

The Pomp and Circumstance Marches (full title "Pomp and Circumstance Military Marches"), Op. 39, are a series of marches for orchestra composed by Sir Edward Elgar.
The title.
The title is taken from Act III, Scene 3 of Shakespeare's "Othello":
<poem>Farewell the neighing steed and the shrill trump,
The spirit-stirring drum, th'ear-piercing fife,
The royal banner, and all quality,
Pride, "pomp, and circumstance" of glorious war!</poem>
But also, on the score of the first march, Elgar set as a motto for the whole set of marches a verse from Lord de Tabley's poem "The March of Glory", which (as quoted by Elgar's biographer Basil Maine) begins
<poem>Like a proud music that draws men on to die
Madly upon the spears in martial ecstasy,
A measure that sets heaven in all their veins
   And iron in their hands.
I hear the Nation march
Beneath her ensign as an eagle's wing;
O'er shield and sheeted targe
The banners of my faith most gaily swing;
Moving to victory with solemn noise,
With worship and with conquest, and the voice of myriads.</poem>
proclaiming the "shows of things" (Maine's quotation marks): the naïve assumption that the splendid show of military pageantry—"Pomp"—has no connection with the drabness and terror—"Circumstance"—of actual warfare. The first four marches were all written before the events of World War I shattered that belief, and the styles in which wars were written about spurned the false romance of the battle-song.
The marches.
The "Pomp and Circumstance" marches are
The first five were all published by Boosey & Co. as Elgar's Op. 39, and each of the marches is dedicated to a particular musical friend of Elgar's.
Each march takes about five minutes to play.
March No. 1 in D.
Dedication.
March No. 1 was composed in 1901 and dedicated "to my friend Alfred E. Rodewald and the members of the Liverpool Orchestral Society".
Instrumentation.
The instrumentation is: two piccolos (2nd "ad lib."), two flutes, two oboes, two clarinets in A, bass clarinet in A, two bassoons, contrabassoon, four horns in F, two trumpets in F, two cornets in A, three trombones, tuba, three timpani, percussion (bass drum, cymbals, triangle, side drum, jingles, and tambourine ad lib.), two harps, organ, and strings.
History.
The best known of the set, it had its premiere, along with the more reserved second March, in Liverpool on 19 October 1901, with Elgar conducting the Liverpool Orchestral Society. Both marches were played two days later at a London Promenade Concert in the Queen's Hall London, conducted by Henry Wood, with March No. 1 played second, and the audience "...rose and yelled... the one and only time in the history of the Promenade concerts that an orchestral item was accorded a double encore."
The "Trio" contains the tune known as "Land of Hope and Glory". In 1902 the tune was re-used, in modified form, for the "Land of hope and glory" section of his "Coronation Ode" for King Edward VII. The words were further modified to fit the original tune, and the result has since become a fixture at the Last Night of the Proms, and an English sporting anthem.
In the United States, the "Trio" section "Land of Hope and Glory" of March No. 1 is often known simply as "Pomp and Circumstance" or as "The Graduation March" and is played as the at virtually all high school and some college graduation ceremonies. It was first played at such a ceremony on 28 June 1905, at Yale University, where the Professor of Music Samuel Sanford had invited his friend Elgar to attend commencement and receive an honorary doctorate of music. Elgar accepted, and Sanford made certain he was the star of the proceedings, engaging the New Haven Symphony Orchestra, the College Choir, the Glee Club, the music faculty members, and New York musicians to perform two parts from Elgar's oratorio "The Light of Life" and, as the graduates and officials marched out, "Pomp and Circumstance" March No. 1. Elgar repaid the compliment by dedicating his "Introduction and Allegro" to Sanford later that year. The tune soon became "de rigueur" at American graduations, used primarily as a processional at the opening of the ceremony.
Description.
March No. 1 opens with an introduction marked "Allegro, con molto fuoco." The introduction leads to a new theme: strong pairs of beats alternating with short notes, and a bass which persistently clashes with the tune. The bass tuba and full brass is held back until the section is repeated by the full orchestra. A little rhythmic pattern is played by the strings, then repeated high and low in the orchestra before the section is concluded by a chromatic upward scale from the woodwind. The whole of this lively march section is repeated. The bridging section between this and the well-known "Trio" has rhythmic chords from the brass punctuating high held notes from the wind and strings, before a fanfare from trumpets and trombones leads into the theme with which the march started. There are a few single notes that quieten, ending with a single quiet tap from side drum and cymbal accompanied by all the bassoons. The famous, lyrical "Land of Hope and Glory" "trio" follows (in the subdominant key of G), played softly (by the first violins, four horns and two clarinets) and repeated by the full orchestra including two harps. What follows is a repetition of what has been heard before, including a fuller statement of the "Trio" (this time in the 'home' key of D) in which the orchestra is joined by organ as well as the two harps. The march ends, not with the big tune, but with a short section containing a brief reminder of the brisk opening march.
March No. 2 in A minor.
Dedication.
March No. 2 was composed in 1901 and dedicated "To my friend Granville Bantock".
Instrumentation.
The instrumentation is: piccolo, 2 flutes, 2 oboes, 2 clarinets in A, bass clarinet in A, 2 bassoons, contrabassoon, 4 horns in F, 2 trumpets in F, 2 cornets in A, 3 trombones, tuba, timpani (3), percussion (2 side drums, triangle, glockenspiel & jingles, bass drum & cymbals), and strings.
History.
It was first performed, as was March No. 1, by the Liverpool Orchestral Society conducted by Alfred Rodewald, in Liverpool on 19 October 1901. Both marches were played two days later at a London Promenade Concert.
Description.
The second is the shortest and most simply constructed of the marches. The composer Charles Villiers Stanford is said to have preferred this march to the first, and thought this the finest of all the marches. After a loud call to attention from the brass, a simple "staccato" theme, tense and repetitive, is played quietly by the strings, being gradually joined by other instruments before building up to an abrupt climax. This section is repeated. The second theme, confidently played by horns and clarinets, with contrasting triple and duple rhythms, is one which was sketched by Elgar a few years before: this is developed and ends with flourishes from the strings and brass joined by the glockenspiel. The opening "staccato" theme returns, concluded by a quiet swirling bass passage, which leads into the "Trio" section (in the tonic major key of A) which consists of a delightfully simple tune in thirds played by the woodwind (flutes, oboes, clarinets and bassoons), answered conclusively by the strings and brass. This "Trio" section is repeated, and the march concluded with a brilliant little coda, which includes a drum roll on the snare drum, a shattering chord in A Minor, briefly played by horns, and followed by a final cadence.
March No. 3 in C minor.
Dedication.
March No. 3 was completed in November 1904 and published in 1905. It was dedicated "To my friend Ivor Atkins". It was first performed on 8 March 1905, in the Queen's Hall, London, conducted by the composer.
Instrumentation.
The instrumentation is: piccolo, 2 flutes, 2 oboes, cor anglais, 2 clarinets in B, bass clarinet in B, 3 bassoons, contrabassoon, 4 horns in F, 2 trumpets in B, 2 cornets in B, 3 trombones, tuba, timpani (3), percussion (tenor drum, side drum, bass drum & cymbals), and strings.
Description.
March No. 3 differs from the others in its opening mood, which is deliberately solemn. It begins with a dark subdued quick march led by low clarinets, three bassoons and the horns (with drum-beats inserted between the notes of the tune), before a vigorous theme (with brass alone at the first beats), erupts from the full orchestra. The dark theme re-appears, is then restarted boldly, then ended abruptly. The central section commences with a perky tune played by a solo clarinet with simple string accompaniment, which is followed by another of Elgar's noble tunes played by the strings of the orchestra. All the themes re-appear and there is the final section which ends abruptly.
March No. 4 in G.
March No. 4 is as upbeat and ceremonial as No. 1, containing another big tune in the central "Trio" section.
Dedication.
March No. 4 was completed on 7 June 1907, and dedicated "To my friend Dr. G. Robertson Sinclair, Hereford". It was first performed on 24 August 1907, in the Queen's Hall, London, conducted by the composer.
Instrumentation.
The instrumentation is: piccolo (with 3rd flute), 2 flutes, 2 oboes, cor anglais, 2 clarinets in B, bass clarinet in B, 2 bassoons, contrabassoon, 4 horns in F, 3 trumpets in A, 3 trombones, tuba, timpani (3), percussion (side drum, bass drum & cymbals), 2 harps, and strings.
History.
The "Trio" was used by Elgar in a song called "The King's Way" which he wrote, to his wife's words, in celebration of the opening of an important new London street called Kingsway in 1909.
In World War II, No. 4 also acquired words: a patriotic poem by A. P. Herbert with the refrain beginning "All men must be free" was used as "Song of Liberty".
In the wedding of Charles, Prince of Wales, and Lady Diana Spencer, "Pomp and Circumstance" No. 4 served as the recessional. As Diana's veil was lifted and the couple bowed and curtsied to Queen Elizabeth II, the opening notes sounded and continued as they walked down the aisle of St Paul's Cathedral out to the portico and the waiting crowds.
Description.
The march has an opening section consisting mainly of two-bar rhythmic phrases which are repeated in various forms, and a lyrical "Trio" constructed like the famous "Land of Hope and Glory" trio of March No. 1.
The first eight bars of the march is played by the full orchestra with the melody played by the violas and upper woodwind. Both harps play from the beginning, while the cellos, double basses and timpani contribute a simple bass figure. The bass clarinet, contrabassoon, trombones and tuba are held "in reserve" for the repeat, when the first violins join the violas with the tune. There are subdued fanfares from the brass interrupted by little flourishes from the strings before the opening march is repeated. There is pause, then a little section which starts forcefully but quietens, leading into the "Trio". The "Trio" follows the pattern of March No. 1, with the melody (in the subdominant key of C) played by clarinet, horn and violins. The violins start the "Trio" tune on the lowest note they can play, an "open" G-string, which gives a recognisable "twang" to this one note, and they are directed to play the passage ""sul G"" on the same string, for the sake of the tone-colour, and the accompaniment is from the harps, low strings and bassoons. The grand tune is repeated, as we expect, by the full orchestra; the opening march section returns; the grand tune is repeated again in the "home" key of G major; and the last word is had by a re-statement of the opening rhythmic patterns. The march prepares the audience for its end as surely as a train pulling into a station, with the violins, violas, and cellos ending on their resonant "open" G.
March No. 5 in C.
Dedication.
March No. 5 was composed in 1930, much later than the others, and dedicated "To my friend Dr. Percy C. Hull, Hereford". Its first public performance was on 20 September 1930 in a Queen's Hall concert conducted by Sir Henry Wood, though it had been recorded two days earlier in the Kingsway Hall, London, conducted by Elgar himself in spite of his poor health.
Instrumentation.
The instrumentation is: piccolo, 2 flutes, 2 oboes, cor anglais, 2 clarinets in B, bass clarinet in B, 2 bassoons, contrabassoon, 4 horns in F, 3 trumpets in B, 3 trombones, tuba, timpani (3), percussion (side drum, bass drum & cymbals), and strings.
Description.
Without introduction, its opening episode is extended with enormous confidence and proceeds directly into the "Trio" section. The "Trio" starts quietly in a similar way to the introduction of his First Symphony: just a moving bass line and a tune, also in the same key (A). The tune is re-stated strongly, as we expect, then developed. The re-statement of the opening employs the same instruments of the orchestra, but is this time started as soft as possible for just four bars before a quick "crescendo" restores its spirit to as it was in the beginning. There is more development before a big return of the "Trio" theme, in the home key of C, and a triumphant ending which might bring to mind the conclusion of Grieg's "In the Hall of the Mountain King".
March No. 6 in G minor.
History.
Elgar left sketches for a sixth "Pomp and Circumstance" march, to be the final work in the set. In 2005, these were sent by the lawyer for the Elgar Will Trust in a bundle to the English composer Anthony Payne. Also included was an article titled "Circumstantial Evidence" by the Elgar authority Christopher Kent from the August 1997 "Musical Times" explaining the sketches. One idea in the sketches was marked by the composer "jolly good". Kent believed that Elgar's compositional thoughts and time were by then engaged with the Third Symphony and "The Spanish Lady", and that the main theme for the march was "unpromising".
Payne determined there was not enough in the sketches to complete the march, but fortunately three pages of score in Elgar's handwriting were discovered at the Royal School of Church Music Colles Library marked "P&C 6". In 2006, the score and sketches were turned into a performing version. Payne noted in the program notes that "Nowhere else in the Pomp and Circumstance marches does Elgar combine compound and duple metres in this way". Payne concluded the piece with a brief allusion to the first Pomp and Circumstance March.
The world premiere was on 2 August 2006 with Andrew Davis conducting the BBC Symphony Orchestra at The Proms at Royal Albert Hall. The first recording was by the BBC National Orchestra of Wales under Richard Hickox.
Instrumentation.
The instrumentation is: piccolo, 2 flutes, 2 oboes, cor anglais, 2 clarinets in B, bass clarinet in B, 2 bassoons, contrabassoon, 4 horns in F, 3 trumpets in B, 3 trombones, tuba, timpani (4), percussion (side drum, cymbals, bass drum, jingles, glockenspiel), and strings.
Arrangements.
For piano solo: The first four marches were arranged by Adolf Schmid and March No. 5 by Victor Hely-Hutchinson.
For piano duo: March No. 1 was arranged by Adolf Schmid.
For organ: March No. 1 was arranged by Edwin H. Lemare and March No. 4 was arranged by G. R. Sinclair. Marches 1–5 have been arranged in simplified and abbreviated form by William McVicker; concert transcriptions of Marches 2, 3, and 5, matching the Lemare and Sinclair arrangements, have been made by Michael Brough for use at Holy Trinity Sloane Street but have not yet been published.
For military band: The first four marches were arranged by M. Retford and March No. 5 by T. Conway Brown.
For brass band: March No. 1 was arranged (transposed to B) by J. Ord Hume.

</doc>
<doc id="60902" url="https://en.wikipedia.org/wiki?curid=60902" title="FAT filesystem and Linux">
FAT filesystem and Linux

Linux has several filesystem drivers for the File Allocation Table (FAT) filesystem format. These are commonly known by the names used in the mount command to invoke particular drivers in the kernel: "msdos", "vfat", and "umsdos".
Differences, advantages, and disadvantages.
All of the Linux filesystem drivers support all three FAT types, namely FAT12, FAT16 and FAT32. Where they differ is in the provision of support for long filenames, beyond the 8.3 filename structure of the original FAT filesystem format, and in the provision of Unix file semantics that do not exist as standard in the FAT filesystem format such as file permissions. The filesystem drivers are mutually exclusive. Only one can be used to mount any given disk volume at any given time. Thus the choice among them is determined by what long filenames and Unix semantics they support and what use one wants to make of the disk volume.
msdos.
The "msdos" filesystem driver provides no extra Unix file semantics and no long filename support. If a FAT disk filesystem is mounted using this driver, only 8.3 filenames will be visible, no long filenames will be accessible, nor will any long filename data structures of any kind on the disk volume be maintained. The "vfat" filesystem driver provides long filename support using the same disk data structures that Microsoft Windows uses for VFAT long filename support on FAT format volumes, but it does not support any extra Unix file semantics. The "umsdos" filesystem driver provides long filename support, and extra Unix file semantics. However, it does so using on-disk data structures that are not recognized by any filesystem drivers for any operating systems other than Linux.
umsdos.
The key advantage to "umsdos" out of the three is that it provides full Unix file semantics. Therefore, it can be used in situations where it is desirable to install Linux on and run it from a FAT disk volume, which require such semantics to be available. However, Linux installed on and running from such a disk volume is slower than Linux installed on and running from a disk volume formatted with, for example, the ext2 filesystem format. Further, unless a utility program is regularly run every time that one switches from running Windows to running Linux, certain changes made to files and directories on the disk by Windows will cause error messages about inaccessible files in Linux.
vfat.
"vfat", whilst lacking full Unix file semantics and lacking the ability to have Linux installed on and running from a FAT disk volume, does not have the aforementioned disadvantages of "umsdos" when it comes to simply sharing data on a FAT disk volume between Linux and other operating systems such as Windows. Its data structures are the same as those used by Windows for VFAT long filenames, and it does not require running a synchronization utility in order to prevent Windows and Linux data structures from becoming disjoint. For this reason, it is the most appropriate of Linux's FAT filesystem drivers to use in the majority of situations.
Commonalities.
As mentioned previously, all of the Linux filesystem drivers support all of the three File Allocation Table sizes, 12-bit, 16-bit, and 32-bit. Other common features that they all support are various Linux mounting options (specified with the -o option to the mount command):
Data structures of umsdos.
The "umsdos" FAT filesystem driver stores all of the extra information relating to Unix file semantics in what, to another FAT filesystem driver, appears to be just a normal file in each directory and subdirectory, named --LINUX-.---.
In the absence of this file in any given directory, and thus by default, the "umsdos" filesystem driver provides the same semantics as the "msdos" filesystem driver does for the directory: only 8.3 filenames and no extra Unix file semantics. To enable the "umsdos" driver's extra abilities, it is necessary to create that file in the directory and synchronize its internal data with the normal FAT data for any existing entries already in the directory. This is done with a tool called umssync.
This is the utility program that is run, across every directory on the disc volume, every time that one switches from running Windows to running Linux, in order for the "umsdos" filesystem driver to incorporate any changes made to files and directories by Windows into its private data structures in its --LINUX-.--- file. By default, the umssync tool creates --LINUX-.--- files in directories if they do not already exist, resulting in such a file in every directory in the disc volume. When switching between Windows and Linux this behaviour is not often considered desirable. Therefore, the normal mode of operation when invoking umssync after switching from Windows to Linux (which is usually done by running the tool at Linux boot time from a startup script) is to employ the -c option to the command, which prevents the creation of any new --LINUX-.--- files in directories that do not already possess them.
Installing Linux on and booting it from FAT volumes using umsdos.
As mentioned, "umsdos" permits installing Linux on, and then bootstrapping and running it from, a FAT format disc volume. The advantage of this is that it permits the use of Linux on a computer where DOS is already installed, without requiring that the hard disc be repartitioned. Linux is not bootstrapped directly from a Volume Boot Record in such a scenario. Instead DOS is first bootstrapped, and loadlin is used to then bootstrap Linux from DOS.
The convention for such an installation is for the Linux root directory to be a subdirectory of the actual root directory of the DOS boot volume, e.g. C:\LINUX . The various Linux top-level directories are thus, to DOS, directories such as C:\LINUX\ETC (for /etc), C:\LINUX\BIN (for /bin), C:\LINUX\LIB (for /lib), and so forth. The "umsdos" filesystem driver automatically prepends the C:\LINUX\ to all pathnames. The location of the Linux root directory is supplied to the "umsdos" filesystem driver in the first place via an option to the loadlin command. So, for example, for the aforegiven root directory loadlin would be invoked with a command line such as .
The installation of Linux into such a directory in the first place simply involves unpacking files from an archive into that directory and its subdirectories. Such an installation also generally requires the use of a swap file rather than a swap partition for Linux, however this is related to the desire not to repartition the hard disc and unrelated to the "umsdos" filesystem driver per se.
Development history and kernel/distribution support.
Most of the major Linux distributions, including RedHat, SuSE, and Debian, do not employ "umsdos" to permit installation of Linux on a FAT disc volume. A few distributions do, however. These include distributions such as Phat Linux, a distribution created by two schoolchildren which installs in C:\PHAT on DOS by unpacking a ZIP file and is booted by running a COMMAND.COM script named LINUX.BAT, and ZipSlack.
The UMSDOS project was started in 1992 by Jacques Gelinas and made available to the net in January 1994 as a patch. It was included in the standard distribution starting with kernel 1.1.36. UMSDOS was removed from the Linux 2.6.11 kernel for lack of maintenance. UVFAT, an extension of UMSDOS to use the Windows data structures for long filenames instead of its own, was discontinued before release. They should work in 2.4.x kernels.
Earlier Linux distributions which used UMSDOS are MuLinux, Monkey Linux and Winlinux 2000.
Accessing FAT formatted volumes without kernel support.
Although the filesystem drivers in the kernel make it possible to access files and directories on FAT formatted volumes in the normal manner, it is also possible to do so without kernel driver support, using the utility programs that form the mtools utility suite. Like the "vfat" FAT filesystem driver, mtools provides long filename support using the same disc data structures that Microsoft Windows uses.
Alternately, one of the FUSE filesystem drivers may be used—FatFuse, FuseFat or mountlo.
POSIX Overlay Filesystem.
A modern equivalent of UMSDOS is POSIX Overlay Filesystem (posixovl). It works in FUSE. http://sourceforge.net/projects/posixovl/

</doc>
<doc id="60903" url="https://en.wikipedia.org/wiki?curid=60903" title="Larry Page">
Larry Page

Lawrence "Larry" Page (born March 26, 1973) is an American computer scientist and Internet entrepreneur who co-founded Google Inc. with Sergey Brin, and is the CEO of Google's parent company, Alphabet Inc. After stepping aside as CEO in August 2001 in favour of Eric Schmidt, Page re-assumed the role in April 2011. He announced his intention to step aside a second time in July 2015 to become CEO of Alphabet, under which Google's assets would be reorganized. Under Page, Alphabet is seeking to deliver major advancements in a variety of industries. Page is the inventor of PageRank, Google's best-known search ranking algorithm.
Page is a board member of the X Prize Foundation (XPRIZE) and was elected to the National Academy of Engineering in 2004. Page received the Marconi Prize in 2004.
Early life and education.
Page was born in East Lansing, Michigan, United States (U.S.). His father, Carl Vincent Page, Sr., earned a PhD in computer science from the University of Michigan in 1965, when the field was being established, and has been described by BBC reporter Will Smale as a "pioneer in computer science and artificial intelligence." He was a computer science professor at Michigan State University and Page's mother, Gloria, was an instructor in computer programming at Lyman Briggs College at Michigan State University. Page's mother is Jewish, but he was not raised in a religious household.
During an interview, Page recalled his childhood, noting that his house "was usually a mess, with computers, science and technology magazines and "Popular Science" magazines all over the place", an environment in which he immersed himself. Page was an avid reader during his youth, writing in his 2013 Google founders letter that "I remember spending a huge amount of time poring over books and magazines". According to writer Nicholas Carlson, the combined influence of Page's home atmosphere and his attentive parents "fostered creativity and invention". Page also played saxophone and studied music composition while growing up. Page has mentioned that his musical education inspired his impatience and obsession with speed in computing. "In some sense I feel like music training led to the high-speed legacy of Google for me,". In an interview Page said that "In music you’re very cognizant of time. Time is like the primary thing" and that "If you think about it from a music point of view, if you’re a percussionist, you hit something, it’s got to happen in milliseconds, fractions of a second".
Page was first attracted to computers when he was six years old, as he was able to "play with the stuff lying around"—first-generation personal computers—that had been left by his parents. He became the "first kid in his elementary school to turn in an assignment from a word processor". His older brother also taught him to take things apart and before long he was taking "everything in his house apart to see how it worked". He said that "from a very early age, I also realized I wanted to invent things. So I became really interested in technology and business. Probably from when I was 12, I knew I was going to start a company eventually."
Page attended the Okemos Montessori School (now called Montessori Radmoor) in Okemos, Michigan, from 1975 to 1979, and graduated from East Lansing High School in 1991. He attended Interlochen Center for the Arts as a saxophonist for two summers while in high school. Page holds a Bachelor of Science in computer engineering from the University of Michigan, with honors and a Master of Science in computer science from Stanford University. While at the University of Michigan, Page created an inkjet printer made of Lego bricks (literally a line plotter), after he thought it possible to print large posters cheaply with the use of inkjet cartridges—Page reverse-engineered the ink cartridge, and built all of the electronics and mechanics to drive it. Page served as the president of the Beta Epsilon chapter of the Eta Kappa Nu fraternity, and was a member of the 1993 "Maize & Blue" University of Michigan Solar Car team. As an undergrad at the University of Michigan, he proposed that the school replace its bus system with a PRT System which is essentially a driverless monorail with separate cars for every passenger. He also developed a business plan for a company that would use software to build a music synthesizer during this time.
PhD studies and research.
After enrolling in a computer science PhD program at Stanford University, Page was in search of a dissertation theme and considered exploring the mathematical properties of the World Wide Web, understanding its link structure as a huge graph—his supervisor, Terry Winograd, encouraged him to pursue the idea, and Page recalled in 2008 that it was the best advice he had ever received. He also considered doing research on telepresence and autonomous cars during this time.
Page focused on the problem of finding out which web pages link to a given page, considering the number and nature of such backlinks as valuable information for that page—the role of citations in academic publishing would also become pertinent for the research. Sergey Brin, a fellow Stanford PhD student, would soon join Page's research project, nicknamed "BackRub." Together, the pair authored a research paper titled "The Anatomy of a Large-Scale Hypertextual Web Search Engine," which became one of the most downloaded scientific documents in the history of the Internet at the time.
Page and Brin used the former's basic HTML programming skills to set up a simple search page for users, as they did not have a web page developer to create anything visually elaborate. They also began using any computer part they could find to assemble the necessary computing power to handle searches by multiple users. As their search engine grew in popularity among Stanford users, it required additional servers to process the queries. In August 1996, the initial version of Google, still on the Stanford University website, was made available to Internet users.By early 1997, the BackRub page described the state as follows:
BackRub already exhibited the rudimentary functions and characteristics of a search engine: a query input was entered and it provided a list of backlinks ranked by importance. Page recalled: "We realized that we had a querying tool. It gave you a good overall ranking of pages and ordering of follow-up pages." Page said that in mid-1998 they finally realized the further potential of their project: "Pretty soon, we had 10,000 searches a day. And we figured, maybe this is really real."
Some compared Page and Brin's vision to the impact of Johannes Gutenberg, the inventor of modern printing:
The comparison was also noted by the authors of "The Google Story": "Not since Gutenberg ... has any new invention empowered individuals, and transformed access to information, as profoundly as Google." Also, not long after the two "cooked up their new engine for web searches, they began thinking about information that was at the time beyond the web," such as digitizing books and expanding health information.
Google.
1998–2001.
Founding.
Mark Malseed wrote in a 2007 feature story:
Soliciting funds from faculty members, family and friends, Brin and Page scraped together enough to buy some servers and rent that famous garage in Menlo Park. ... after, Sun Microsystems co-founder Andy Bechtolsheim wrote a $100,000 check to "Google, Inc." The only problem was, "Google, Inc." did not yet exist—the company hadn't yet been incorporated. For two weeks, as they handled the paperwork, the young men had nowhere to deposit the money."
In 1998, Brin and Page incorporated Google, Inc. with the initial domain name of "Googol," derived from a number that consists of one followed by one hundred zeros—this represented the vast amount of data that the search engine was intended to explore. Following inception, Page appointed himself as CEO, while Brin, named Google's co-founder, served as Google's president. Writer Nicholas Carlson wrote in 2014:
While Google is often thought of as the invention of two young computer whizzes—Sergey and Larry, Larry and Sergey—the truth is that Google is a creation of Larry Page, helped along by Sergey Brin.
The pair's mission was: "to organize the world’s information and make it universally accessible and useful." With a US$1-million loan from friends and family, the inaugural team eventually moved into a Mountain View office by the start of 2000. In 1999, Page experimented with smaller sized server units so that Google could fit more into each square meter of the third-party warehouses that the company rented to store their servers, which eventually led to a search engine that ran much faster than Google's competitors at the time.
By June 2000, Google had indexed one billion Internet URLs, or Uniform Resource Locators, making it the most comprehensive search engine on the Web at the time. The company cited NEC Research Institute data in its June 26 press release, stating that "there are more than 1 billion web pages online today," with Google "providing access to 560 million full-text indexed web pages and 500 million partially indexed URLs."
Early management style.
During his first tenure as CEO, Page embarked on a failed attempt to fire all of Google's project managers in 2001. Page's plan involved all of Google’s engineers reporting to a VP of engineering, who would then report directly to him—Page explained that he didn’t like non-engineers supervising engineers due to their limited technical knowledge. Page even documented his management tenets for his team to use as a reference:
Even though Page's new model was unsustainable and led to disgruntlement among the affected employees, his issue with engineers being managed by non-engineering staff gained traction more broadly. Eventually, the practice of only instating engineers into the management roles of engineering teams was established as a standard across Silicon Valley.
Page also believed that the faster Google’s search engine returned answers, the more it would be used. He fretted over milliseconds and pushed his engineers—from those who developed algorithms to those who built data centers—to think about lag times. He also pushed for keeping Google’s home page famously sparse in its design because it would help the search results load faster.
2001–2011.
Changes in management and expansion.
After Silicon Valley's two most prominent investors, Kleiner Perkins Caufield & Byers and Sequoia Capital, agreed to invest a combined total of $25 million into Google, they applied pressure on Page to step down as CEO so that a more experienced leader could build a "world-class management team." Page eventually became amenable to the idea after meeting with other technology CEOs, including Steve Jobs and Intel’s Andrew Grove. Eric Schmidt, who had been hired as Chairman of Google in March 2001, left his full-time position as the CEO of Novell to take on the same role at Google in August of the same year, and Page moved aside to assume the President of Products role.
Under Schmidt's leadership, Google underwent a period of major growth and expansion, which included its initial public offering (IPO) on August 20, 2004. However, he always acted in consultation with Page and Brin when he embarked on initiatives such as the hiring of an executive team and the creation of a sales force management system. Furthermore, Page remained the boss at Google in the eyes of the employees, as he gave final approval on all new hires and it was Page who provided the signature for the IPO, the latter making him a billionaire at the age of thirty.
Page led the acquisition of Android for $50 million in 2005 to fulfill his ambition to place handheld computers in the possession of consumers so that they could access Google from anywhere. The purchase was made without Schmidt's knowledge, but the CEO was not perturbed by the relatively small acquisition. Page became passionate about Android, and spent large amounts of time with Android CEO and cofounder Andy Rubin. By September 2008, T-Mobile launched the G1, the first phone using Android software and, by 2010, 17.2 percent of the handset market consisted of Android sales, overtaking Apple for the first time. Android became the world’s most popular mobile operating system shortly afterward.
Assumption of CEO position at Google.
Following a January 2011 announcement, Page officially became the chief executive of Google on April 4, 2011, while Schmidt stepped down to become executive chairman. By this time, Google had over $180 billion market capitalization and more than 24,000 employees.
After Schmidt announced the end of his tenure as CEO on January 20, 2011, he jokingly tweeted on Twitter: "Adult-supervision no longer needed." Quartz organizational management reporter, Max Nisen, described the decade prior to Page's second appointment as Google's CEO as his "lost decade." While Page continued to exert a significant influence at Google during this time, overseeing product development and other operations, he became increasingly disconnected and less responsive over time.
2011-2013.
As Google's new CEO, Page's two key goals were the development of greater autonomy for the executives overseeing the most important divisions, and higher levels of collaboration, communication and unity among the teams. Page also formed what the media called the "L-Team," a group of senior vice-presidents who reported directly to him and worked in close proximity to his office for a portion of the working week. Additionally, he reorganized the company’s senior management, placing a CEO-like manager at the top of Google's most important product divisions, including YouTube, AdWords, and Google Search.
In accordance with a more cohesive team environment, Page declared a new "zero tolerance for fighting" policy that contrasted with his approach during the early days of Google, when he would use his harsh and intense arguments with Brin as an exemplar for senior management. Page had changed his thinking during his time away from the CEO role, as he eventually arrived at the conclusion that his greatly ambitious goals required a harmonious team dynamic. As part of Page's collaborative rejuvenation process, Google's products and applications were consolidated and underwent an aesthetic overhaul.
Changes and consolidation process.
At least 70 of Google's products, features and services were eventually shut down by March 2013, while the appearance and nature of the remaining ones were unified. Jon Wiley, lead designer of Google Search at the time, codenamed Page's redesign overhaul, which officially commenced on April 4, 2011, "Project Kennedy," based on Page's use of the term "moonshots" to describe ambitious projects in a January 2013 "Wired" interview. An initiative named "Kanna" previously attempted to create a uniform design aesthetic for Google's range of products, but it was too difficult at that point in the company's history for one team to drive such change. Matias Duarte, senior director of the Android user experience at the time that "Kennedy" started, explained in 2013 that "Google passionately cares about design." Page proceeded to consult with the Google Creative Lab design team, based in New York City, to find an answer to his question of what a "cohesive vision" of Google might look like.
The eventual results of "Kennedy," which were progressively rolled out from June 2011 until January 2013, were described by The Verge technology publication as focused upon "refinement, white space, cleanliness, elasticity, usefulness, and most of all simplicity." The final products were aligned with Page's aim for a consistent suite of products that can "move fast," and "Kennedy" was called a "design revolution" by Duarte. Page's "UXA" (user/graphics interface) design team then emerged from the "Kennedy" project, tasked with "designing and developing a true UI framework that transforms Google's application software into a beautiful, mature, accessible and consistent platform for its users." Unspoken of in public, the small UXA unit was designed to ensure that "Kennedy" became an "institution."
Acquisition strategy and new products.
When acquiring products and companies for Google, Page asked whether the business acquisition passed the toothbrush test as an initial qualifier, asking the question "Is it something you will use once or twice a day, and does it make your life better?". This approach looked for usefulness above profitability, and long-term potential over near-term financial gain, which has been noted as rare in business acquiring processes.
With Facebook's influence rapidly expanding during the start of Page's second tenure, he finally responded to the intensive competition with Google's own social network, Google+, in mid-2011. After several delays, the social network was released through a very limited field test and was led by Vic Gundotra, Google's then senior vice president of social.
In August 2011, Page announced that Google would spend $12.5 billion to acquire Motorola Mobility. The purchase was primarily motivated by Google's need to secure patents to protect Android from lawsuits by companies including Apple Inc. Page wrote on Google's official blog on August 15, 2011 that "companies including Microsoft and Apple are banding together in anti-competitive patent attacks on Android. The United States Department of Justice had to intervene in the results of one recent patent auction to "protect competition and innovation in the open source software community"... Our acquisition of Motorola will increase competition by strengthening Google’s patent portfolio, which will enable us to better protect Android from anti-competitive threats from Microsoft, Apple and other companies".
Page also ventured into hardware and Google unveiled the Chromebook in May 2012. The hardware product was a laptop that ran on a Google operating system, Chrome OS.
2013–2015.
In January 2013, Page participated in a rare interview with Wired magazine, in which writer Steven Levy discussed Page's "10X" mentality—Google employees are expected to create products and services that are at least 10 times better than those of its competitors—in the introductory blurb. Astro Teller, the head of Google X, explained to Levy that 10X is "just core to who he is," while Page's "focus is on where the next 10X will come from." In his interview with Levy, Page referred to the success of YouTube and Android as examples of "crazy" ideas that investors were not initially interested in, saying: "If you’re not doing some things that are crazy, then you’re doing the wrong things." Page also stated that he was "very happy" with the status of Google+, and discussed concerns over the Internet in relation to the SOPA bill and an International Telecommunication Union proposal that had been recently introduced:
... I do think the Internet’s under much greater attack than it has been in the past. Governments are now afraid of the Internet because of the Middle East stuff, and so they’re a little more willing to listen to what I see as a lot of commercial interests that just want to make money by restricting people’s freedoms. But they’ve also seen a tremendous user reaction, like the backlash against SOPA. I think that governments fight users’ freedoms at their own peril.
At the May 2013 I/O developers conference in San Francisco, Page delivered a keynote address and said that "We're at maybe 1% of what is possible. Despite the faster change, we're still moving slow relative to the opportunities we have. I think a lot of that is because of the negativity... Every story I read is Google vs someone else. That's boring. We should be focusing on building the things that don't exist" and that he was "sad the Web isn't advancing as fast as it should be" citing a perceived focus on negativity and zero sum games among some in the technology sector as a cause for that. In response to an audience question, Page noted an issue that Google had been experiencing with Microsoft, whereby the latter made its Outlook program interoperable with Google, but did not allow for backward compatibility—he referred to Microsoft's practice as "milking off." During the question-and-answer section of his keynote, Page expressed interest in Burning Man, which Brin had previously praised—it was a motivating factor for the latter during Schmidt's hiring process, as Brin liked that Schmidt had attended the week-long annual event.
In September 2013, Page launched the independent Calico initiative, a R&D project in the field of biotechnology. Google announced that Calico seeks to innovate and make improvements in the field of human health, and appointed Art Levinson, chairman of Apple's board and former CEO of Genentech, to be the new division's CEO. Page's official statement read: "Illness and aging affect all our families. With some longer term, moonshot thinking around healthcare and biotechnology, I believe we can improve millions of lives."
Page participated in a March 2014 TedX conference that was held in Vancouver, Canada. The presentation was scripted by Page's chief PR executive Rachel Whetstone, and Google’s CMO Lorraine Twohill, and a demonstration of an artificially intelligent computer program was displayed on a large screen.
Page responded to a question about corporations, noting that corporations largely get a "bad rap", which he stated was because they were probably doing the same incremental things they were doing "50 or 20 years ago". He went on to juxtapose that kind of incremental approach to his vision of Google counteracting calcification through driving technology innovation at a high rate. Page mentioned Elon Musk and SpaceX:
"He wants to go to Mars to back up humanity. That’s a worthy goal. We have a lot of employees at Google who’ve become pretty wealthy. You’re working because you want to change the world and make it better ... I’d like for us to help out more than we are."
Page also mentioned Nikola Tesla with regards to invention and commercialization:
"Invention is not enough. Tesla invented the electric power we use, but he struggled to get it out to people... You have to combine both things: invention and innovation focus, plus the company that can commercialize things and get them to people."
Page announced a major management restructure in October 2014 so that he would no longer need to be responsible for day-to-day product-related decision making. In a memo, Page said that Google's core businesses would be able to progress in a typical manner, while he could focus on the next generation of ambitious projects, including Google X initiatives; access and energy, including Google Fiber; smart-home automation through Nest Labs; and biotechnology innovations under Calico. Page maintained that he would continue as the unofficial "chief product officer." Subsequent to the announcement, the executives in charge of Google's core products reported to then Google Senior Vice President Sundar Pichai, who reported directly to Page.
In a November 2014 interview, Page stated that he prioritized the maintenance of his "deep knowledge" of Google's products and breadth of projects, as it had been a key motivating factor for team members. In relation to his then role as the company's CEO, Page said: "I think my job as CEO—I feel like it’s always to be pushing people ahead."
Alphabet.
On August 10, 2015, Page announced on Google's official blog that Google had restructured into a number of subsidiaries of a new holding company known as Alphabet Inc with Page becoming CEO of Alphabet Inc and Sundar Pichai assuming the position of CEO of Google Inc. In his announcement, Page described the planned holding company as follows:
As well as explaining the origin of the company's name:
Other interests.
Page is an investor in Tesla Motors. He has invested in renewable energy technology, and with the help of Google.org, Google's philanthropic arm, promotes the adoption of plug-in hybrid electric cars and other alternative energy investments.
Page is also interested in the socio-economic effects of advanced intelligent systems and how advanced digital technologies can be used to create abundance (as described in ), provide for people's needs, shorten the workweek, and mitigate the potential detrimental effects of technological unemployment.
Page also helped to set up Singularity University, a transhumanist think-tank. 
Google is one of the institution's corporate founders and still funds scholarships at Singularity University.
Personal life.
In 2007, Page married Lucinda Southworth on Necker Island, the Caribbean island owned by Richard Branson. Southworth is a research scientist, and the sister of actress and model Carrie Southworth. Page and Southworth have two children, born in 2009 and 2011.
On February 18, 2005, Page was granted the deed on a 9000-sq ft Spanish Colonial Revival architecture house in Palo Alto, California designed by American artistic polymath Pedro Joseph de Lemos, a former curator of the Stanford Art Museum and founder of the Carmel Art Institute, after the historic building had been on the market for years with an asking price of US$7.95 million. A two-story stucco archway spans the driveway and the home features intricate stucco work, as well as stone and tile in California Arts and Crafts movement style built to resemble de Lemos family's castle in Spain. The hacienda was constructed between 1931-41 by de Lemos. It is also on the National Register of Historic Places.In 2009 Page began purchasing properties and tearing down homes adjacent to his home in Palo Alto to make room for a large ecohouse, the existing buildings were "deconstructed" and the materials donated for reuse. The ecohouse was designed to "minimize the impact on the environment,". Page worked with an arborist to replace some trees that were in poor health with others that used less water to maintain. Page also applied for Green Point Certification, with points given for use of recycled and low or no-VOC (volatile organic compound) materials and for a roof garden with solar panels. The house's exterior features zinc cladding and plenty of windows, including a wall of sliding-glass doors in the rear, it also includes eco-friendly elements such as permeable paving in the parking court and a pervious path through the trees on the property. The 6,000-sq ft house also observes other green home design features such as organic architecture building materials and low volatile organic compound paint.
In 2011, Page became the owner of the US$ 45 million 193-ft superyacht 'Senses', 'Senses' comes equipped with a helipad, gym, multi-level sun decks, ten luxury suites, a crew of 14 and interior design by famed French designer Philippe Starck. 'Senses' also has extensive ocean exploration capabilities, the superyacht was created to explore the world’s oceans in comfort and it carries a very comprehensive inventory of equipment for that purpose. 'Senses' was built by Fr. Schweers Shipyard in Germany at their Berne shipyard. 'Senses' features a displacement steel hull and a steel/aluminium superstructure, with teak decks. 'Senses' is equipped with an ultra-modern stabilization system which reduces the free surface effect and results in a smoother cruising experience underway.
Page announced on his Google+ profile in May 2013 that his right vocal cord is paralyzed from a cold that he contracted the previous summer, while his left cord was paralyzed in 1999. Page explained that he has been suffering from a vocal cord issue for 14 years, and, as of his May 2013 post, doctors were still unable to identify the exact cause of the problem. The Google+ post also revealed that Page had donated a considerable sum of money to a vocal-cord nerve-function research program at the Voice Health Institute in Boston, U.S. The program, at Massachusetts General Hospital, is led by Steven Zeitels, the Eugene B. Casey Professor of Laryngeal Surgery. An anonymous source stated that the donation exceeded $20 million.
In October 2013, "Business Insider" reported that Page's paralyzed vocal cords are caused by an autoimmune disease called Hashimoto's thyroiditis, and prevented him from undertaking Google quarterly earnings conference calls for an indefinite period.
In November 2014, Page's family foundation, the Carl Victor Page Memorial Fund, reportedly holding assets in excess of a billion dollars at the end of 2013, gave $15 million to aid the effort against the Ebola virus epidemic in West Africa. Page wrote on his Google+ page that "My wife and I just donated $15 million...Our hearts go out to everyone affected."
Awards and accolades.
1998-2009.
"PC Magazine" has praised Google as among the Top 100 Web Sites and Search Engines (1998) and awarded Google the Technical Excellence Award for Innovation in Web Application Development in 1999. In 2000, Google earned a Webby Award, a People's Voice Award for technical achievement, and in 2001, was awarded Outstanding Search Service, Best Image Search Engine, Best Design, Most Webmaster Friendly Search Engine, and Best Search Feature at the Search Engine Watch Awards." In 2002, Page was named a World Economic Forum Global Leader for Tomorrow and along with Brin, was named by the Massachusetts Institute of Technology (MIT)'s "Technology Review" publication as one of the top 100 innovators in the world under the age of 35, as part of its yearly TR100 listing (changed to "TR35" after 2005).
In 2003, both Page and Brin received a MBA from IE Business School, in an honorary capacity, "for embodying the entrepreneurial spirit and lending momentum to the creation of new businesses." In 2004, they received the Marconi Foundation's prize and were elected Fellows of the Marconi Foundation at Columbia University. In announcing their selection, John Jay Iselin, the Foundation's president, congratulated the two men for "their invention that has fundamentally changed the way information is retrieved today.". Page and Brin were also Award Recipients and National Finalists for the EY Entrepreneur of the Year Award in 2003.
Also in 2004, X PRIZE chose Page as a trustee of their board and he was elected to the National Academy of Engineering. In 2005, Brin and Page were elected Fellows of the American Academy of Arts and Sciences.
In 2008 Page received the Communication Award from King Felipe at the Princess of Asturias Awards on behalf of Google.
2009-present.
In 2009, Page received an honorary doctorate from the University of Michigan during a graduation commencement ceremony. In 2011, he was ranked 24th on the Forbes list of billionaires, and as the 11th richest person in the U.S. In 2015, Page's "Powerful People" profile on the "Forbes" site states that Google is "the most influential company of the digital era."
As of July 2014, the Bloomberg Billionaires Index lists Page as the 17th richest man in the world, with an estimated net worth of $32.7 billion. At the completion of 2014, "Fortune" magazine named Page its "Businessperson of the Year," declaring him "the world’s most daring CEO."
In October 2015, Page was named number one in Forbes' "America's Most Popular Chief Executives", as voted by its employees.

</doc>
<doc id="60904" url="https://en.wikipedia.org/wiki?curid=60904" title="Sergey Brin">
Sergey Brin

Sergey Mikhaylovich Brin (; born August 21, 1973) is a Russian-born American computer scientist, internet entrepreneur, and philanthropist. Together with Larry Page, he co-founded Google. Today, Brin serves as President of Google's parent company, Alphabet Inc. According to Forbes List February 2016, he is jointly one of three people listed as 11th richest in the world (21 overall), with a net worth of .
Brin immigrated to the United States with his family from the Soviet Union at the age of 6. He earned his bachelor's degree at the University of Maryland, following in his father's and grandfather's footsteps by studying mathematics, as well as computer science. After graduation, he moved to Stanford University to acquire a PhD in computer science. There he met Page, with whom he later became friends. They crammed their dormitory room with inexpensive computers and applied Brin's data mining system to build a web search engine. The program became popular at Stanford and they suspended their PhD studies to start up Google in a rented garage.
"The Economist" referred to Brin as an "Enlightenment Man", and as someone who believes that "knowledge is always good, and certainly always better than ignorance", a philosophy that is summed up by Google's mission statement, "Organize the world's information and make it universally accessible and useful," and unofficial motto, "Don't be evil".
Early life and education.
Brin was born in Moscow in the Soviet Union, to Russian Jewish parents, Yevgenia and Mikhail Brin, both graduates of Moscow State University. His father is a mathematics professor at the University of Maryland, and his mother a researcher at NASA's Goddard Space Flight Center.
In 1979, when Brin was six years old, his family felt compelled to immigrate to the United States. In an interview with Mark Malseed, co-author of "The Google Story", Sergey's father explains how he was "forced to abandon his dream of becoming an astronomer even before he reached college". Mikhail Brin claims Communist Party heads barred Jews from upper professional ranks by denying them entry to universities, and that Jews were excluded from the physics departments in particular. Mikhail Brin therefore changed his major to mathematics where he received nearly straight A's. He said, "Nobody would even consider me for graduate school because I was Jewish." According to Brin, at Moscow State University, Jews were required to take their entrance exams in different rooms from non-Jewish applicants and they were marked on a harsher scale.
The Brin family lived in a three-room apartment in central Moscow, which they also shared with Sergey's paternal grandmother. Brin told Malseed, "I've known for a long time that my father wasn't able to pursue the career he wanted", but Brin only picked up the details years later after they had settled in the United States. In 1977, after his father returned from a mathematics conference in Warsaw, Poland, Mikhail Brin announced that it was time for the family to emigrate. "We cannot stay here any more", he told his wife and mother. At the conference, he was able to "mingle freely with colleagues from the United States, France, England and Germany and discovered that his intellectual brethren in the West were not 'monsters.'" He added, "I was the only one in the family who decided it was really important to leave."
Sergey's mother was less willing to leave their home in Moscow, where they had spent their entire lives. Malseed writes, "For Genia, the decision ultimately came down to Sergey. While her husband admits he was thinking as much about his own future as his son's, for her, 'it was 80/20' about Sergey." They formally applied for their exit visa in September 1978, and as a result his father was "promptly fired". For related reasons, his mother also had to leave her job. For the next eight months, without any steady income, they were forced to take on temporary jobs as they waited, afraid their request would be denied as it was for many refuseniks. During this time his parents shared responsibility for looking after him and his father taught himself computer programming. In May 1979, they were granted their official exit visas and were allowed to leave the country. At an interview in October 2000, Brin said, "I know the hard times that my parents went through there and am very thankful that I was brought to the States."
In the summer of 1990, a few weeks before his 17th birthday, his father led a group of high school math students, including Sergey, on a two-week exchange program to the Soviet Union. His roommate on the trip was future CMU computer science professor John Stamper. As Brin recalls, the trip awakened his childhood fear of authority and he remembered that "his first impulse on confronting Soviet oppression had been to throw pebbles at a police car." Malseed adds, "On the second day of the trip, while the group toured a sanatorium in the countryside near Moscow, Brin took his father aside, looked him in the eye and said, 'Thank you for taking us all out of Russia.'"
Brin attended elementary school at Paint Branch Montessori School in Adelphi, Maryland, but he received further education at home; his father, a professor in the department of mathematics at the University of Maryland, encouraged him to learn mathematics and his family helped him retain his Russian-language skills. He attended Eleanor Roosevelt High School in Greenbelt, Maryland. In September 1990 Brin enrolled in the University of Maryland, where he received his Bachelor of Science from the Department of Computer Science in 1993 with honors in computer science and mathematics, which is part of the University of Maryland College of Computer, Mathematical, and Natural Sciences.
Brin began his graduate study in computer science at Stanford University on a graduate fellowship from the National Science Foundation. In 1993, he interned at Wolfram Research, who were the developers of Mathematica. As of 2008, he is on leave from his PhD studies at Stanford.
Search engine development.
During an orientation for new students at Stanford, he met Larry Page. They seemed to disagree on most subjects. But after spending time together, they "became intellectual soul-mates and close friends". Brin's focus was on developing data mining systems while Page's was in extending "the concept of inferring the importance of a research paper from its citations in other papers". Together, the pair authored a paper titled "The Anatomy of a Large-Scale Hypertextual Web Search Engine".
To convert the backlink data gathered by BackRub's web crawler into a measure of importance for a given web page, Brin and Page developed the PageRank algorithm, and realized that it could be used to build a search engine far superior to existing ones. The new algorithm relied on a new kind of technology that analyzed the relevance of the backlinks that connected one Web page to another. Combining their ideas, the pair began utilizing Page's dormitory room as a machine laboratory, and extracted spare parts from inexpensive computers to create a device that they used to connect the nascent search engine with Stanford's broadband campus network. After filling Page's room with equipment, they then converted Brin's dorm room into an office and programming center, where they tested their new search engine designs on the Web. The rapid growth of their project caused Stanford's computing infrastructure to experience problems.
Page and Brin used the former's basic HTML programming skills to set up a simple search page for users, as they did not have a web page developer to create anything visually elaborate. They also began using any computer part they could find to assemble the necessary computing power to handle searches by multiple users. As their search engine grew in popularity among Stanford users, it required additional servers to process the queries. In August 1996, the initial version of Google, still on the Stanford University website, was made available to Internet users.
By early 1997, the BackRub page described the state as follows:
BackRub already exhibited the rudimentary functions and characteristics of a search engine: a query input was entered and it provided a list of backlinks ranked by importance. Page recalled: "We realized that we had a querying tool. It gave you a good overall ranking of pages and ordering of follow-up pages." Page said that in mid-1998 they finally realized the further potential of their project: "Pretty soon, we had 10,000 searches a day. And we figured, maybe this is really real."
Some compared Page and Brin's vision to the impact of Johannes Gutenberg, the inventor of modern printing:
The comparison was also noted by the authors of "The Google Story": "Not since Gutenberg... has any new invention empowered individuals, and transformed access to information, as profoundly as Google." Also, not long after the two "cooked up their new engine for web searches, they began thinking about information that was at the time beyond the web," such as digitizing books and expanding health information.
Other interests.
Brin is working on other, more personal projects that reach beyond Google. For example, he and Page are trying to help solve the world's energy and climate problems at Google's philanthropic arm, Google.org, which invests in the alternative energy industry to find wider sources of renewable energy. The company acknowledges that its founders want "to solve really big problems using technology".
In October 2010, for example, they invested in a major offshore wind power development to assist the East coast power grid, which will eventually become one of about a dozen offshore wind farms that are proposed for the region. A week earlier they introduced a car that, with "artificial intelligence", can drive itself using video cameras and radar sensors. In the future, drivers of cars with similar sensors would have fewer accidents. These safer vehicles could therefore be built lighter and require less fuel consumption. They are trying to get companies to create innovative solutions to increasing the world's energy supply. He is an investor in Tesla Motors, which has developed the Tesla Roadster, a range battery electric vehicle as well as the Tesla Model S, a range battery electric vehicle.
In 2004, he and Page were named "Persons of the Week" by "ABC World News Tonight". In January 2005 he was nominated to be one of the World Economic Forum's "Young Global Leaders". In June 2008, Brin invested $4.5 million in Space Adventures, the Virginia-based space tourism company. His investment will serve as a deposit for a reservation on one of Space Adventures' proposed flights in 2011. Space Adventures, the only company that sends tourists to space, has sent five of them so far.
Brin and Page jointly own a customized Boeing 767-200 and a Dornier Alpha Jet, and pay $1.3 million a year to house them and two Gulfstream V jets owned by Google executives at Moffett Federal Airfield. The aircraft have had scientific equipment installed by NASA to allow experimental data to be collected in flight.
In 2012, Brin has been involved with the Project Glass program and has demoed eyeglass prototypes. Project Glass is a research and development program by Google to develop an augmented reality head-mounted display (HMD). The intended purpose of Project Glass products would be the hands-free displaying of information currently available to most smartphone users, and allowing for interaction with the Internet via natural language voice commands.
Brin was also involved in the Google driverless car project. In September 2012, at the signing of the California Driverless Vehicle Bill, Brin predicted that within five years, robotic cars will be available to the general public.
Brin is a supporter of lab-grown meat and kite-energy systems.
"The Economist" magazine describes Brin's approach to life, like Page's, as based on a vision summed up by Google's motto, "of making all the world's information 'universally accessible and useful.
Censorship of Google in China.
Remembering his youth and his family's reasons for leaving the Soviet Union, he "agonized over Google's decision to appease the Communist government of China by allowing it to censor search engine results", but he decided that the Chinese would still be better off than without having Google available.
On January 12, 2010, Google reported a large cyber attack on its computers and corporate infrastructure that began a month earlier, which included accessing two Gmail accounts and the theft of Google's intellectual property. After the attack was determined to have originated in China, the company stated that it would no longer agree to censor its search engine in China and may exit the country altogether. David Drummond, Google's Senior Vice President of Corporate Development, reported that "a primary goal of the attackers was accessing the Gmail accounts of Chinese human rights activists, but that the attack also targeted 20 other large companies in the finance, technology, media and chemical sectors." It was later reported that the attack had also targeted "one of Google's crown jewels, a password system that controls access by millions of users worldwide".
In late March 2010, it officially discontinued its China-based search engine while keeping its uncensored Hong Kong site in operation. Speaking for Google, Brin stated during an interview, "One of the reasons I am glad we are making this move in China is that the China situation was really emboldening other countries to try and implement their own firewalls." During another interview with "Der Spiegel", he added, "For us it has always been a discussion about how we can best fight for openness on the Internet. We believe that this is the best thing that we can do for preserving the principles of the openness and freedom of information on the Internet."
Senator Byron Dorgan stated that "Google's decision is a strong step in favor of freedom of expression and information." And Congressman Bob Goodlatte said, "I applaud Google for its courageous step to stop censoring search results on Google.cn. Google has drawn a line in the sand and is shining a light on the very dark area of individual liberty restrictions in China." From the business perspective, many recognize that the move is likely to affect Google's profits. "The New Republic" adds that "Google seems to have arrived at the same link that was obvious to Andrei Sakharov: the one between science and freedom," referring to the move as "heroism".
Personal life.
In May 2007, Brin married biotech analyst and entrepreneur Anne Wojcicki in the Bahamas. They had a son together in December 2008 and a daughter in late 2011. In August 2013, it was announced Brin and his then-wife were living separately. In June 2015, Brin and Wojcicki finalized their divorce.
Brin's mother, Eugenia, has been diagnosed with Parkinson's disease. In 2008, he decided to make a donation to the University of Maryland School of Medicine, where his mother is being treated. Brin used the services of 23andMe and discovered that although Parkinson's is generally not hereditary, both he and his mother possess a mutation of the LRRK2 gene (G2019S) that puts the likelihood of him developing Parkinson's in later years between 20% and 80%. When asked whether ignorance was not bliss in such matters, he stated that his knowledge means that he can now take measures to ward off the disease. An editorial in "The Economist" magazine states that "Mr Brin regards his mutation of LRRK2 as a bug in his personal code, and thus as no different from the bugs in computer code that Google’s engineers fix every day. By helping himself, he can therefore help others as well. He considers himself lucky. ... But Mr. Brin was making a much bigger point. Isn’t knowledge always good, and certainly always better than ignorance?"
Brin and his ex-wife also run The Brin Wojcicki Foundation.
Awards and accolades.
2002–2009.
In 2002, Brin, along with Larry Page, was named the MIT Technology Review TR100, as one of the top 100 innovators in the world under the age of 35. In 2003, both Brin and Page received an honorary MBA from IE Business School "for embodying the entrepreneurial spirit and lending momentum to the creation of new businesses...". In 2004, they received the Marconi Foundation Prize, the "Highest Award in Engineering", and were elected Fellows of the Marconi Foundation at Columbia University. "In announcing their selection, John Jay Iselin, the Foundation's president, congratulated the two men for their invention that has fundamentally changed the way information is retrieved today."
In 2003, Brin and Page were both Award Recipients and National Finalists for the EY Entrepreneur of the Year Award 
In 2004, Brin received the Academy of Achievement's Golden Plate Award with Larry Page at a ceremony in Chicago, Illinois.
2009–present.
In November 2009, "Forbes" decided Brin and Page were the fifth most powerful people in the world. Earlier that same year, in February, Brin was inducted into the National Academy of Engineering, which is "among the highest professional distinctions accorded to an engineer ... honors those who have made outstanding contributions to engineering research, practice...". He was selected specifically, "for leadership in development of rapid indexing and retrieval of relevant information from the World Wide Web". In their "Profiles" of Fellows, the National Science Foundation included a number of earlier awards:
According to "Forbes", he is the 20th richest person in the world with a personal wealth of US$30 billion as of June 2014.

</doc>
<doc id="60906" url="https://en.wikipedia.org/wiki?curid=60906" title="Socialist Unity Party of Germany">
Socialist Unity Party of Germany

The Socialist Unity Party of Germany () was the governing Marxist–Leninist political party of the German Democratic Republic from its formation in 1946 until it was dissolved after the Peaceful Revolution in 1989.
The GDR functioned nominally as a multi-party state with the SED playing a central role. Other parties in alliance with the SED were the Christian Democratic Union, the Liberal Democratic Party, the Democratic Farmers' Party, and the National Democratic Party. In the 1980s, the SED rejected the liberalisation policies of Soviet leader Mikhail Gorbachev, such as "perestroika" and "glasnost", which would lead to the GDR's isolation from the restructuring USSR and the party's downfall in the autumn of 1989.
The party's dominant figure from 1950 to 1971, and effective leader of East Germany, was Walter Ulbricht. In 1953, an uprising against the Party was met with violent suppression by the Ministry of State Security and the Soviet Army. In 1971, Ulbricht was succeeded by Erich Honecker who presided over a stable period in the development of the GDR until he was forced to step down during the 1989 revolution. The party's last leader, Egon Krenz, was unsuccessful in his attempt to retain the SED's hold on political governance of the GDR and was imprisoned after German reunification.
The SED's long-suppressed reform wing took over the party in the fall of 1989. In hopes of changing its image, on 16 December it renamed itself the Party of Democratic Socialism (PDS), abandoning Marxism–Leninism and becoming a mainstream democratic socialist party. It received 16.4% of the vote in the 1990 parliamentary elections. In 2007, the PDS merged with Labour and Social Justice (WASG) into The Left ("Die Linke"), the third largest party in the German parliament following the 2013 federal election.
Early history.
The SED was founded on 21 April 1946 by a merger of the Social Democratic Party of Germany (SPD) and the Communist Party of Germany (KPD) which was based in the Soviet occupation zone of Germany and the Soviet-occupied sector of Berlin. Official East German and Soviet histories portrayed this merger as a voluntary pooling of efforts by the socialist parties. However, there is much evidence that the merger was more troubled than commonly portrayed. By all accounts, the Soviet occupation authorities applied great pressure on the SPD's eastern branch to merge with the KPD. The newly merged party, with the help of the Soviet authorities, swept to victory in the 1946 elections for local and regional assemblies held in the Soviet zone. However, these elections were held under less-than-secret conditions, thus setting the tone for the next four decades. A truer picture of the SED's support came with the local elections in Berlin, which were the first honest elections held there since the Nazi era. In that contest, the SED got less than half the votes of the SPD. The bulk of the Berlin SPD remained aloof from the merger, even though Berlin was deep inside the Soviet zone.
The Soviet Military Administration in Germany (Russian initials: SVAG) directly governed the eastern areas of Germany following World War II, and their intelligence operations carefully monitored all political activities. An early intelligence report from SVAG Propaganda Administration director Lieutenant Colonel Sergei Ivanovich Tiulpanov (see "External Links" below) indicates that the former KPD and SPD members created different factions within the SED and remained rather mutually antagonistic for some time after the formation of the new party. Also reported was a great deal of difficulty in convincing the masses that the SED was a German political party, and not merely a tool of the Soviet occupation force.
According to Tiulpanov, many former members of the KPD expressed the sentiment that they had "forfeited revolutionary positions, that [the KPD alone would have succeeded much better had there been no SED, and that the Social Democrats are not to be trusted" (Tiulpanov, 1946). Also, Tiulpanov indicated that there was a marked "political passivity" among former SPD members, who felt they were being treated unfairly and as second-class party members by the new SED administration. As a result, the early SED party apparatus frequently became effectively immobilised as former KPD members began discussing any proposal, however small, at great length with former SPD members, so as to achieve consensus and avoid offending them. Soviet intelligence claimed to have a list of names of an SPD group within the SED that was covertly forging links with the SPD in the West and even with the Western Allied occupation authorities.
A problem for the Soviets that they identified with the early SED was its potential to develop into a nationalist party. At large party meetings, members applauded speakers who talked of nationalism much more than when they spoke of solving social problems and gender equality. Some even proposed the idea of establishing an independent German socialist state free of both Soviet and Western influence, and of soon regaining the formerly German land that the Yalta Conference, and ultimately the Potsdam Conference, had (re)allocated to Poland, the USSR and Czechoslovakia.
Soviet negotiators reported that SED politicians frequently pushed past the boundaries of the political statements which had been approved by the Soviet monitors, and there was some initial difficulty making regional SED officials realize that they should think carefully before opposing the political positions decided upon by the Central Committee in Berlin.
A monopoly of power.
Although it was nominally a merger of equals, from the beginning the SED was dominated by Communists. By the late 1940s, the SED began to purge most recalcitrant Social Democrats from its ranks. By the time of East Germany's formal establishment in 1949, the SED was a full-fledged Communist party—essentially the KPD under a new name. It began to develop along lines similar to other Communist parties in the Soviet bloc.
Although other parties nominally continued to exist, the Soviet occupation authorities forced them to join in the National Front of Democratic Germany, a nominal coalition of parties that was for all intents and purposes controlled by the SED. By ensuring that Communists predominated on the list of candidates put forward by the National Front, the SED effectively predetermined the composition of legislative bodies in the Soviet zone, and from 1949 in East Germany.
Over the years, the SED gained a reputation as one of the most hardline parties in the Soviet bloc. When Mikhail Gorbachev initiated reforms in the Soviet Union in the 1980s, the SED held to an orthodox line.
Organisation.
Basic organisation.
The party organisation was based on, and co-located with, the institutions of the German Democratic Republic. Its influence stood behind and shaped every facet of public life. The party required every member to live by the mantra "Where there is a comrade, the party is there too" ("Wo ein Genosse ist, da ist die Partei"). This meant that the party organisation was at work in publicly owned industrial and quasi-commercial enterprises, machine and tractor stations, publicly owned farms and in the larger agricultural cooperatives, expressly mandated to monitor and regulate the operational management of each institution.
The smallest organisational unit in the party was the Party Group. Group members elected one of their number Party Group Organiser (PGO), to take responsibility for Party Work. There were also a Treasurer, an Agitator, and according to the size of the group other associated members included in the Party Group leadership. Where there were several Party Groups operating in a single place they would be combined in a Departmental Party Organisation (APO / "Abteilungsparteiorganisation") which in turn would have its own leadership and an APO Party Secretariat.
Party conference.
The Party conference was formally the party's leading institution.
Increasingly, party conferences were planned with military-level precision. Their choreography was carefully undertaken to ensure that they were understood as high-profile society events. They were very much more than mere political functions. Delegates were selected from the regional and sectional party organisations according to criteria determined by the Party Central Committee. Care was taken over the proportions of women, of youth representatives, of members from approved Mass organisations and of "exemplary" workers.
Party Secretaries.
Party secretaries existed at different levels within the party. They usually held their offices on an unsalaried basis, often combining their party secretarial duties with a salaried function. Where a basic administrative unit grew beyond a certain size tensions tended to arise between the party secretary and fellow committee members, and at this point a full-time salaried party secretary would be appointed. Party secretaries in very large industrial combines and other economically important institutions would combine their party secretarial roles with membership of a more powerful body, applying a structural element maintained right up to the level of the Party Central Committee. The task of the Party Secretaries was the organisation of political work. They prepared the party meetings and organised political training in partnership with the party leaderships. They ensured implementation of and compliance with party decisions, and undertook general reporting and leadership duties. They were also required to provide a monthly report on "Morale and Opinions" (""Stimmungen und Meinungen"") concerning the people covered by their party secretarial duties.
Where work on occasion attracted criticism, there were many ways on which changes could be passed on. This fact lay behind the burgeoning bureaucratization of the party apparatus and the presence of Stalinistic tendencies. Party secretaries underwent a special monthly political process that included instructive guidance and verification by representatives from higher level party committees. Along with their party responsibilities, party secretaries were members of the state administration, and they secured the leadership role that the SED claimed for itself in businesses and offices. Managerial decisions were discussed and ultimately decided in party committees. This meant that a manager, provided he was a party member, was committed to implementing those decisions.
Sectional directorates.
The basic organisional unit in an organisation or department was placed under the control of the party's sectional leadership team (""SED-Kreisleitung""). There were in total 262 of these sectional leadership teams, including one each for the Free German Youth (FDJ), the Trade Union Federation (FDGB), the Foreign Ministry, the Foreign Trade Ministry, the State Railway organisation, the military branches of the Interior Ministry, the Ministry for State Security (Stasi), the National People's Army, each of which had its own integrated political administrative structure.
Regional directorates.
The party's regional structure started with the country's fifteen regions. Regional level government structure changed dramatically with the abolition of regional assemblies in 1952, but each administrative structure always had party secretary, applying a structure also replicated in administrative structures at local levels. The regional party leadership team (""SED Bezirksleitung""/ BL) was an elected body, membership of which was unpaid. It worked alongside the administrative body of paid officials who were occasionally also members of the party leadership team. At a regional level the SED leadership team was typically supported by a First Secretary and a Second Secretary, and a secretariat team responsible for "Agitation and propaganda", Economy, Science, Culture and Agriculture. There were also regional teams to shadow the regional teams of national institutions such as the Free FDJ, the FDGB and the Planning Commission.
Central Committee.
Except when the Party Congress was in session, the Party Central Committee was the party's leading element. Power was centred on the Committee Secretariat, which was chaired by a First Secretary (1953-1976) or a General Secretary (1976-1989). This function was combined with chairmanship of the Politburo. The General Secretary until 1971 was Walter Ulbricht: he was succeeded by Erich Honecker. In the political hierarchy of the German Democratic Republic members of the Central Committee ranked above government ministers.
In July 1950, at the third Party Conference, the SED's Central Committee was elected on the Soviet model, which at this time employed a single list electoral system: most members of the serving party executive were replaced. It was striking that more than 62% of the new Central Committee members had been members of the Communist Party (KPD) before the party merger of 1946. Four years on, there was little sign of the KPD/SPD parity that had been invoked when the SED was created.
By 1989 membership of the Central Committee had increased to 165: there were also 57 people listed as candidates for membership. All the high ranking party functionaries were represented in it along with other senior government officials (provided they were already party members). Beyond the professional functionaries and politicians the Committee also included the chiefs of the country's leading institutions and industrial combines, the president of the country's Writers' Association, top military officers and party veterans.
The Party Central Committee, reflecting the country's overall power structure, was overwhelmingly male: the proportion of women never rose above 15%.
Politburo of the Central Committee.
The most important day-to-day work of the Central Committee was undertaken by the Politburo, a small circle of senior party officers, comprising between 15 and 25 members, along with approximately 10 (non-voting) candidate members. The politburo members included approximately ten Central Committee Secretaries. The General Secretary of the Central Committee also held the Chairmanship of the Politburo (along with all his other functions). The country's government, formally headed by the Council of Ministers, was required only to implement the decisions of the politburo. This meant that the Council of Ministers was under the permanent control of the Party Committees, a structure that ensured the "leading role of The Party" implicit in the national constitution (and spelled out expressly after the constitutional changes introduced for 1968). The chairmen of the Council of Ministers and the president of the National legislature "("Volkskammer")" were also members of the politburo.
Secretariat of the Central Committee.
The Central Committee Secretariat met each Wednesday to implement decisions finalised by the Politburo the previous day and to prepare the agenda for the Central Committee's next weekly meeting. The Secretariat comprised the Central Committee Party Secretaries. The Secretariat played a decisive role in selecting the Nomenklatura of the Central Committee. Nomenklatura members were the holders of the top 300 or so positions in the party and the state: changes to the Nomenklatura membership list required the approval of the Central Committee Secretariat.
Party Congresses.
The 1st Congress.
The 1st Party Congress "(Vereinigungsparteitag)", which convened on 21 April 1946, was the unification congress. This congress elected two co-chairmen to lead the party: Wilhelm Pieck, former leader of the eastern KPD, and Otto Grotewohl, former leader of the eastern SPD. The union was initially intended to apply to the whole of occupied Germany. The union was rejected consistently in the three western occupation zones, where both parties remained independent. The union of the two parties was thus effective only in the Soviet zone. The SED was modeled after the Communist Party of the Soviet Union. In 1946, the unification was announced in the Soviet occupation zone with an emblem of a handshake.
The 2nd Congress.
The 2nd Party Congress convened from 20–24 July 1947. It adopted a fresh party statute and transformed the party executive committee into a central committee "(Zentralkomitee" or "ZK").
The 3rd Congress.
The 3rd Party Congress convened in July 1950 and emphasized industrial progress. The industrial sector, employing 40% of the working population, was subjected to further nationalization, which resulted in the formation of "people's enterprises" (German: "Volkseigener Betrieb", VEB). These enterprises incorporated 75% of the industrial sector. At the same time, the party completed its transformation into a more orthodox Soviet-style party with the election of Walter Ulbricht as the party's first secretary.
The 6th Congress.
The 6th Party Congress convened from 15–21 January 1963. The congress approved a new party program and a new party membership statute. Walter Ulbricht was re-elected as the party's First Secretary. A new economic policy was introduced, more strongly centralized - the "New Economic System".
The 7th Congress.
First Secretary Walter Ulbricht announced the "ten requirements of the socialist moral and ethics". During his report at the 7th Party Congress in 1967, Erich Honecker had called for a return to an orthodox Socialist economic system, away from the recently instituted New Economic System. But the about-face in economic policy that year cannot be attributed to Honecker's advancement alone. During the previous two winters, the GDR had been plagued with power shortages and traffic breakdowns.
The 8th Congress.
From 1971 onwards, congresses were held every five years. The last was the 11th Party Congress in April 1986. In theory the party congresses set policy and elected the leadership, provided a forum for discussing the leadership's policies, and undertook activities that served to legitimize the party as a mass movement. They were formally empowered to pass both the party program and the statutes, to establish the general party line, to elect the members of the Central Committee and the members of the Central Auditing Commission, and to approve the Central Committee's report. Between congresses the Central Committee could convene a party conference to resolve policy and personnel issues.
In the spring of 1971, the 8th Congress rolled back some of the programs associated with the Ulbricht era and emphasized short-term social and economic problems. The SED used the occasion to announce its willingness to cooperate with West Germany and the Soviet Union in helping to solve a variety of international problems, particularly the future political status of Berlin. Another major development initiated at the congress was a strengthening of the Council of Ministers at the expense of the Council of State; this shift subsequently played an important role in administering the "Main Task" program. The SED further proclaimed that greater emphasis would be devoted to the development of a "socialist national culture" in which the role of artists and writers would be increasingly important. Honecker was more specific about the SED's position toward the intelligentsia at the Fourth Plenum of the Central Committee, where he stated: "As long as one proceeds from the firm position of socialism, there can in my opinion be no taboos in the field of art and literature. This applies to questions of content as well as of style, in short to those questions which constitute what one calls artistic mastery."
The 9th Congress.
The 9th Party Congress in May 1976 can be viewed as a midpoint in the development of SED policy and programs. Most of the social and economic goals announced at the 8th Congress had been reached; however, the absence of a definitive statement on further efforts to improve the working and living conditions of the population proved to be a source of concern. The SED sought to redress these issues by announcing, along with the Council of Ministers and the leadership of the FDGB, a specific program to raise living standards. The 9th Congress initiated a hard line in the cultural sphere, which contrasted with the policy of openness and tolerance enunciated at the previous congress. Six months after the 9th Congress, for example, the GDR government withdrew permission for the singer Wolf Biermann to live in East Germany. The congress also highlighted the fact that East Germany had achieved international recognition in the intervening years. East Germany's growing involvement in both the East European economic system and the global economy reflected its new international status. This international status and the country's improved diplomatic and political standing were the major areas stressed by this congress. The 9th Party Congress also served as a forum for examining the future challenges facing the party in domestic and foreign policy. On the foreign policy front, the major events were various speeches delivered by representatives of West European Marxist–Leninist parties, particularly the Italian, Spanish, and French, all of which expressed in varying ways ideological differences with the Soviet Union. At the same time, although allowing different views to be heard, the SED rejected many of these criticisms in light of its effort to maintain the special relationship with the Soviet Union emphasized by Honecker. Another major point of emphasis at the congress was the issue of inter-German détente. On the East German side, the benefits were mixed. The GDR regime considered economic benefits as a major advantage, but the party viewed with misgivings the rapid increase in travel by West Germans to and through the GDR. Additional problems growing out of the expanding relationship with West Germany included conflict between Bonn and East Berlin on the rights and privileges of West German news correspondents in East Germany; the social unrest generated by the "two-currency" system, in which East German citizens who possessed West German D-marks were given the privilege of purchasing scarce luxury goods at special currency stores (Intershops); and the ongoing arguments over the issue of separate citizenship for the two German states, which the SED proclaimed but which the West German government refused to recognize as late as 1987.
During the 9th Congress, the SED also responded to some of the public excitement and unrest that had emerged in the aftermath of the signing of the Helsinki Accords, the human rights documents issued at the meetings in 1975 of the Conference on Security and Cooperation in Europe. Before the congress was convened, the SED had conducted a "People's Discussion" in order openly to air public concerns related to East Germany's responsibility in honoring the final document of the Helsinki conference.
The 10th Congress.
The 10th Congress, which took place in April 1981, celebrated the status quo; the meeting unanimously re-elected Honecker to the office of general secretary, and there were no electoral surprises, as all incumbents except the ailing 76-year-old Albert Norden were returned to the "Politbüro" and the Secretariat. The congress highlighted the importance of policies that had been introduced or stressed at the two previous congresses and that had dominated East German life during the 1970s. As in the past, Honecker stressed the importance of the ties to the Soviet Union. In his closing remarks, he stated: "Our party, the SED, is linked forever with the party of Lenin, CPSU." A delegation led by chief party ideolougue Mikhail Suslov, a member of the CPSU "Politburo", represented the CPSU at the SED congress. Honecker reiterated earlier positions on the relationship between the two German states, stressing that they were two sovereign states that had developed along different lines since World War II, and that their differences had to be respected by both sides as they continued efforts toward peaceful coexistence despite membership in antagonistic alliances. In his speeches, Honecker, along with other SED officials, devoted greater attention to Third World countries than he had done in the past. Honecker mentioned the continually increasing numbers of young people from African, Asian, and Latin American countries who received their higher education in East Germany, and he referred to many thousands of people in those countries who had been trained as apprentices, skilled workers, and instructors by teams from East Germany.
The bulk of the Central Committee report delivered at the opening session of the congress by the general secretary discussed the economic and social progress made during the five years since the 9th Congress. Honecker detailed the increased agricultural and industrial production of the period and the resultant social progress as, in his words, the country continued "on the path to socialism and communism." Honecker called for even greater productivity in the next five years, and he sought to spur individual initiative and productivity by recommending a labor policy that would reward the most meritorious and productive members of society.
The 11th Congress.
The 11th Congress, held 17–21 April 1986, unequivocally endorsed the SED and Honecker, whom it confirmed for another term as party head. The SED celebrated its achievements as the "most successful party on German soil", praised East Germany as a "politically stable and economically efficient socialist state", and declared its intention to maintain its present policy course. East Germany's successes, presented as a personal triumph for Honecker, marked a crowning point in his political career. Mikhail Gorbachev's presence at the congress endorsed Honecker's policy course, which was also strengthened by some reshuffling of the party leadership. Overall, the 11th Congress exhibited confidence in East Germany's role as the strongest economy and the most stable country in Eastern Europe. Gorbachev praised the East German experience as proof that central planning could be effective and workable in the 1980s.
Official statements on the subject of foreign policy were mixed, particularly with respect to East Germany's relations with West Germany and the rest of Western Europe. Honecker's defense of his policy of "constructive dialogue" appeared in tune with Gorbachev's own calls for disarmament and détente in Europe. However, the SED leadership made it unequivocally clear that its foreign policy, including relations with West Germany, would remain closely coordinated with Moscow's. Although Honecker's criticism of West Germany was low key, Gorbachev's was sharp, attacking Bonn's participation in the United States Strategic Defense Initiative and the alleged "revanchism" in West Germany. However, after a final round of talks with Gorbachev, Honecker signed a hard-line communiqué that openly attacked the policies of the West German government. Overall, Gorbachev's statements suggested that the foreign policy emphasis would be on a common foreign policy adhered to by all members of the Warsaw Pact under Soviet direction. Until the 11th Party Congress, East German leaders had maintained that small and medium states had a significant role to play in international affairs. As a result of Soviet pressure, such statements disappeared from East German commentary on foreign policy.
Final days: collapse of the SED.
On the day of the 40th anniversary of the founding of the GDR, 7 October 1989, the old Social Democratic Party was (illegally) refounded. The rest of October saw widespread protests across the country, including in East Berlin and Leipzig. At a special "Politbüro" meeting on 18 October, Honecker was voted out as general secretary and replaced by Egon Krenz, the party's number-two leader. Krenz tried to portray himself as a reformer, but few believed him. He was almost as detested as Honecker himself, and most of the populace remembered that only four months earlier, he'd gone to China to thank the regime there for the suppression in Tiananmen Square. Krenz made some attempts to adjust state policy. However, he could not (or would not) satisfy the growing demands of the people for increased freedom.
One of the regime's efforts to stem the tide ended up being its death knell. On 9 November the SED "Politbüro" drafted new travel regulations allowing anyone who wanted to visit West Germany to do so by crossing East Germany's borders with official permission. However, no one told the party's unofficial spokesman, East Berlin party boss Günter Schabowski, that the regulations were to take effect the next afternoon. When a reporter asked him when the regulations were to be in place, Schabowski assumed they were already in effect and replied, "As far as I know--effective immediately, without delay." This was widely interpreted as a decision to open the Berlin Wall. Thousands of East Berliners crowded at the Wall, demanding to be let through. Unprepared and unwilling to use force, the guards let them through.
The fall of the Wall destroyed the SED politically. On 1 December 1989, the GDR parliament "(Volkskammer)" rescinded the clause in the GDR Constitution enshrining the SED's guaranteed right to rule, formally ending Communist rule in East Germany. On 3 December 1989, the entire Central Committee and "Politbüro"—including Krenz—resigned.
Rebirth as the PDS.
Some younger members of the SED had been receptive to Gorbachev's reforms, but had more or less been silenced until the events of 1989. Soon after the SED abandoned power, Gregor Gysi, a reformist, was elected to the new post of party chairman. In his first speech, Gysi admitted that the SED was responsible for the country's economic problems—thus repudiating everything the party had done since 1949. He also declared that the party needed to adopt a new form of socialism. As December wore on, most of the party's hardliners—including Honecker, Krenz and others—were pushed out as the party made a desperate attempt to change its image. By the time of a special 16 December congress, the SED was no longer a Marxist–Leninist party. To distance itself from its repressive past, the party added "Party of Democratic Socialism" (PDS) to its name. On 4 February 1990, what remained of the party was renamed solely as the PDS. On 18 March 1990, the PDS was roundly defeated in the first—and as it turned out, only—free elections in the GDR; the Alliance for Germany coalition, led by the Christian Democratic Union (CDU), won on a platform of speedy reunification with the west.
The SED had sequestered money overseas in secret accounts, including some which turned up in Liechtenstein in 2008. This was returned to the German government, as the PDS had rejected claims to overseas SED assets in 1990. The vast majority of domestic SED assets were transferred to the GDR government before unification. Legal issues over back taxes possibly owed by the PDS on former SED assets were eventually settled in 1995, when an agreement between the PDS and the Independent Commission on Property of Political Parties and Mass Organizations of the GDR was confirmed by the Berlin Administrative Court.
The PDS survived the reunification of Germany. It was represented in the Bundestag without interruption until 2007, and eventually began growing again. It has remained influential in former eastern Germany, especially at the state and local levels. It has been important in addressing east-German issues and addressing social problems. In 2007 the PDS merged with the western-based Labour and Social Justice – The Electoral Alternative (WASG) to create the new party The Left ("Die Linke"), which has resulted in a higher acceptance in western states, the party now also being represented in the parliaments of Schleswig-Holstein, Lower Saxony, Bremen, North Rhine-Westphalia, Saarland, Hesse and Hamburg.
West Berlin branch.
Initially the SED had a branch in West Berlin, but in 1962 that branch became a separate party called the Socialist Unity Party of West Berlin ("Sozialistische Einheitspartei Westberlins" - SEW). Merged into Party of Democratic Socialism (Germany) dissolved 2007.

</doc>
<doc id="60907" url="https://en.wikipedia.org/wiki?curid=60907" title="Gene Rayburn">
Gene Rayburn

Gene Rayburn (December 22, 1917 – November 29, 1999) was an American radio and television personality. He is best known as the host of various editions of the popular American television game show "Match Game" for over two decades.
Background.
Born Eugene Jelyevich in Christopher, Illinois, he was the only child of Croatian immigrants. Rayburn's father died when he was an infant and his mother moved to Chicago, where she met Milan Rubessa. After she married Rubessa, Rayburn took the name Eugene Rubessa . Rayburn graduated from Lindblom Technical High School and later from Knox College. While a student at Lindblom, he was senior class president and acted in the plays "Robert of Sicily", and "Mrs. Wiggs of the Cabbage Patch".
Rayburn was married to Helen Ticknor from 1940 until her death in October 1996. They had one child, a daughter, Lynne. After Lynne's birth, Rayburn enlisted in the U.S. Army Air Force and served in World War II.
Gene chose the stage name "Rayburn" by randomly sticking his finger in the phone book.
Radio career.
Before appearing in television, Rayburn was a very successful actor and radio performer. He had a popular morning drive time radio show in New York City, first with Jack Lescoulie ("Anything Goes") and later with Dee Finch (Rayburn & Finch) on WNEW (now WBBR). Radio history pegs Rayburn's pairings with Lescoulie and Finch as helping to popularize the now-familiar morning drive radio format. When Rayburn left WNEW, Dee Finch continued the format with Gene Klavan.
Rayburn later landed the lead in the Broadway musical "Bye Bye Birdie" when Dick Van Dyke left the production to star in his eponymous classic sitcom "The Dick Van Dyke Show".
Television career.
Breaking into television as the original announcer on Steve Allen's "Tonight", Gene Rayburn began a long association with game-show producers Mark Goodson and Bill Todman in 1953. He first appeared on Robert Q. Lewis's "The Name's the Same"; Rayburn frequently sat in for regular panelist Carl Reiner, lending a comic touch to the panel. In 1955, he took over as host of the summer replacement game show, "Make the Connection", from original host, Jim McKay. From there he hosted shows such as "Choose Up Sides", "Dough Re Mi", and the daytime version of "Tic Tac Dough". On radio, Rayburn became one of the many hosts of the NBC program "Monitor" in 1961 and remained with the show until 1973.
In an uncredited role (he reportedly did not want his name to appear), Rayburn played a TV interviewer in the 1959 movie "It Happened to Jane" starring Doris Day.
Rayburn was also a frequent panelist in the 1960s and 1970s on "What's My Line?" and "To Tell the Truth", where the interviewing skills he had burnished on "Monitor" made him a popular questioner.
"Match Game".
From 1962 to 1969 Rayburn hosted "Match Game". In the original version, which aired from New York on NBC, Rayburn read questions to two panels, each consisting of a celebrity and two audience members. The questions in the original game were ordinary, like "Name a kind of muffin," or "John loves his ____________." Rayburn usually played it straight, though he would make jokes as the situation warranted. Because it was a live show, very few episodes were recorded for posterity; only four are known to exist. The show was canceled in 1969 to make room for the topical, short-lived game show "Letters to Laugh-In".
Goodson-Todman revived "Match Game" in 1973 for CBS, this time as a California-based game show. Rayburn returned as host and introduced a new format in which two contestants tried to match the responses of six celebrities. Writer Dick DeBartolo, a veteran of the original show, created funnier and often risqué questions ("After being hit by a steamroller, Norman had to slide his ____________ under the door.") Rayburn reveled in this freewheeling new approach and often indulged in funny voices, banter with the celebrities, and mock arguments with the technical crew. Millions tuned in, and it soon became the highest-rated show on daytime television.
From 1973 to 1977, "Match Game" was #1 among all daytime network game shows—three of those years it was the highest rated of "all" daytime shows.
The daytime revival of "The Match Game", which featured regular panelists Richard Dawson, Brett Somers and Charles Nelson Reilly, ran until 1979 on CBS and another three years in first-run syndication. A concurrent night-time version, "Match Game PM", aired from 1975 to 1980. Rayburn was nominated for two Daytime Emmy Awards for Outstanding Host or Hostess in a Game or Audience Participation Show. 
During the years when "The Match Game" was taped in Los Angeles, Rayburn lived in Osterville, Massachusetts, on Cape Cod, and would commute to California every two weeks and tape 12 shows over the course of a weekend (five daytime shows and one nighttime show per taping day).
In 1983, a year after the syndicated "Match Game" disappeared, the show was revived as part of the "Match Game–Hollywood Squares Hour", with Rayburn hosting the Match Game segment and sitting on the panel of the "Hollywood Squares" segment (a unique case of a host directly participating in the gameplay). The show lasted nine months on NBC.
Rayburn knitted socks as a publicity stunt during his time on "Rayburn and Finch", and later became proficient at needlepoint; he used the time on long plane rides from New York to Los Angeles with his hobby. In 1974, Goodson made a surprise on-air appearance to congratulate Rayburn on making the show #1 among daytime television programs, and presented him with a needlepoint bag.
During his time in the Air Force, Rayburn was trained in meteorology and occasionally demonstrated his knowledge of the weather on "Match Game". Rayburn was also a dedicated tennis enthusiast and often made subtle references to the sport on the show.
Other game shows/television appearances.
During and between his "Match Game" years, Rayburn served as guest panelist on two other Goodson-Todman shows, "What's My Line?" and "To Tell the Truth". Also during the run of the 1970s "Match Game", Gene and wife Helen appeared on the game show "Tattletales", hosted by Bert Convy. Three years after the original "Match Game" was cancelled, Rayburn hosted the short-lived Heatter-Quigley Productions show, "The Amateur's Guide to Love". In 1983 he hosted a pilot for Reg Grundy Productions called "Party Line", which later became "Bruce Forsyth's Hot Streak".
Rayburn appeared as a contestant during a tournament of game show hosts on the original version of "Card Sharks" in 1980 and was a celebrity guest on "Password Plus" several times between 1980 and 1982.
Rayburn appeared on "Fantasy Island" as a game-show host — he and another host played by Jan Murray were game show rivals who vied to win the woman they both loved by creating the ultimate game show, with life-or-death consequences.
Rayburn once hosted a local New York City-based show on WNEW-TV (now WNYW), "Helluva Town," and between game show stints in 1982-83 he returned to WNEW as host of a weekly local talk/lifestyles show called "Saturday Morning Live". He ended his brief tenure to return as co-host of "The Match Game/Hollywood Squares Hour".
Rayburn's last game show hosting duties were on 1985's "Break the Bank" (he was replaced by Joe Farago after 13 weeks), and "The Movie Masters", an AMC cable game show that ran from 1989 to 1990.
Just before production was to begin on a new Rayburn-emceed "Match Game" revival in 1985, an "Entertainment Tonight" reporter publicly disclosed that Rayburn was much older than many believed. Rayburn had trouble finding jobs after that, blaming the reporter for revealing his age and subjecting him to age discrimination.
Rayburn was a guest star on the 2/24/1979 episode of The Love Boat playing a love interest to Fannie Flagg.
Rayburn portrayed himself on a "Saturday Night Live" sketch in 1990, which featured Susan Lucci (as her character from "All My Children", Erica Kane). He returned as one of Kane's many previous husbands, to stop another marriage (officiated by his old "Choose Up Sides" co-star Don Pardo) with the host of a game show portrayed by Phil Hartman. He also continued to make appearances on talk shows throughout the late 1980s and 90s, usually to discuss classic game shows, including appearances on "Vicki!" and "The Maury Povich Show" and "The Late Show with Ross Shafer". Coincidentally, Shafer would host the 1990 "Match Game" revival. Around the same time, he also made an appearance on New York shock jock Howard Stern's late-night TV variety show, as one of the stars of his "Hollywood Squares" parody, "Homeless Howiewood Squares", in which homeless people were supposedly the contestants; he occupied the bottom left-square, possible as a reference to his position on the panel of the disastrous "Match Game-Hollywood Squares Hour" earlier in the decade.
Gene Rayburn co-hosted—with his wife and Peter Emmons—the Drum Corps International (DCI) finals of the DCI Championship for two years, which were telecast nationwide on PBS from Philadelphia's Franklin Field in 1976, and Denver's old Mile High Stadium in 1977.
Death.
Rayburn's last TV appearance was a 1998 interview with "Access Hollywood" intended to coincide with the 25th anniversary of the hit CBS game show "Match Game". Portions of the interview have been rebroadcast on the Game Show Network, which in 2001 showed portions of another previously unaired interview during the first airing of its "Match Game Blankathon".
Though in poor health, Rayburn appeared in person to accept a Lifetime Achievement Award from the Academy of Television Arts & Sciences. A month later, he died at his daughter's Gloucester, Massachusetts, home of congestive heart failure on November 29, 1999. He was cremated and his ashes spread in the garden of his daughter's home.

</doc>
<doc id="60908" url="https://en.wikipedia.org/wiki?curid=60908" title="Common carp">
Common carp

The common carp or European carp, ("Cyprinus carpio") is a widespread freshwater fish of eutrophic waters in lakes and large rivers in Europe and Asia. The wild populations are considered vulnerable to extinction, but the species has also been domesticated and introduced into environments worldwide, and is often considered a very destructive invasive species, being included in the List of the world's 100 worst invasive species. It gives its name to the carp family Cyprinidae. The species is listed as Vulnerable by the IUCN.
Taxonomy.
The three subspecies are:
It is related to the common goldfish ("Carassius auratus"), with which it is capable of interbreeding.
History.
The common carp is native to Asia, and has been introduced to every part of the world with the exception of the Middle East and the poles. They are the third most frequently introduced species worldwide, and their history as a farmed fish dates back to Roman times. Carp are used as food in many areas, but are now also regarded as a pest in some regions due to their ability to out-compete native fish stocks. The original common carp was found in the inland delta of the Danube River about 2000 years ago, and was torpedo-shaped and golden-yellow in colour. It had two pairs of barbels and a mesh-like scale pattern. Although this fish was initially kept as an exploited captive, it was later maintained in large, specially built ponds by the Romans in south-central Europe (verified by the discovery of common carp remains in excavated settlements in the Danube delta area). As aquaculture became a profitable branch of agriculture, efforts were made to farm the animals, and the culture systems soon included spawning and growing ponds. The common carp's native range also extends to the Black Sea, Caspian Sea and Aral Sea.
Both European and Asian subspecies have been domesticated. In Europe, domestication of carp as food fish was spread by monks between the 13th and 16th centuries. The wild forms of carp had reached the delta of the Rhine in the 12th century already, probably also with some human help. Variants that have arisen with domestication include the mirror carp, with large, mirror-like scales (linear mirror – scaleless except for a row of large scales that run along the lateral line; originating in Germany), the leather carp (virtually unscaled except near dorsal fin), and the fully scaled carp. Koi carp (錦鯉 ("nishikigoi") in Japanese, 鯉魚 (pinyin: "lĭ yú") in Chinese) is a domesticated ornamental variety that originated in the Niigata region of Japan in the 1820s. They also invaded the Great Lakes in 1896 when the area near Newmarket, Ontario, flooded and allowed them to escape into the Holland River.
Physiology.
Wild common carp are typically slimmer than domesticated forms, with body length about four times body height, red flesh, and a forward-protruding mouth. Their average growth rate by weight is about half the growth rate of domesticated carp They do not reach the lengths and weights of domesticated carp, which (range, 3.2–4.8 times) can grow to a maximum length of , a maximum weight of over , and an oldest recorded age of 65 years, but reliable information seems to exist about "nishikigoi" of over 100 years. The largest recorded carp, caught by an angler in January 2010 at Lac de curtons (Rainbow Lake) near Bordeaux, France, weighed . The largest recorded carp, caught by British angler, Colin Smith, in 2013 at Etang La Saussaie Fishery, France, weighed 45.59 kilograms (100.5 lb). The average size of the common carp is around 40–80 cm (15.75-31.5 inches) and 2–14 kg (4.5-31 lb).
Like other Cyprinids, common carp have been observed to be exceptional at leaping out of the water when threatened by predators, or frightened by passing watercraft.
Habitat.
Although tolerant of most conditions, common carp prefer large bodies of slow or standing water and soft, vegetative sediments. As schooling fish, they prefer to be in groups of five or more. They naturally live in temperate climates in fresh or slightly brackish water with a pH of 6.5–9.0 and salinity up to about 0.5%, and temperatures of 3 to 35°C. The ideal temperature is 23 to 30°C, with spawning beginning at 17–18°C; they easily survive winter in a frozen-over pond, as long as some free water remains below the ice. Carp are able to tolerate water with very low oxygen levels, by gulping air at the surface.
Diet.
Common carp are omnivorous. They can eat a herbivorous diet of water plants, but prefer to scavenge the bottom for insects, crustaceans (including zooplankton), crawfish, and benthic worms.
Reproduction.
An egg-layer, a typical adult female can lay 300,000 eggs in a single spawn. Although carp typically spawn in the spring, in response to rising water temperatures and rainfall, carp can spawn multiple times in a season. In commercial operations, spawning is often stimulated using a process called hypophysation, where lyophilized pituitary extract is injected into the fish. The pituitary extract contains gonadotropic hormones which stimulate gonad maturation and sex steroid production, ultimately promoting reproduction.
Predation.
A single carp can lay over a million eggs in a year, yet their population remains the same, so the eggs and young perish in similarly vast numbers. Eggs and fry often fall victim to bacteria, fungi, and the vast array of tiny predators in the pond environment. Carp which survive to juvenile are preyed upon by other fish such as the northern pike and largemouth bass, and a number of birds (including cormorants, herons, goosanders, and ospreys) and mammals (including otter and mink).
Introduction into other habitats.
Common carp have been introduced, sometimes illegally, to most continents and some 59 countries. Due to their reproductive rate and their feeding habit of grubbing through bottom sediments for food, they are notorious for altering their environments. In feeding, they may destroy, uproot, disturb and eat submerged vegetation, causing serious damage to native duck, such as canvasbacks, and fish populations. Similar to the grass carp, the vegetation they consume is not completely digested, and rots after excretion, raising the nutritional level of the water and causing excessive algae growth. They destroy nests of other fish and eat their eggs, reducing their numbers significantly.
In Australia, enormous anecdotal and mounting scientific evidence indicates introduced carp are the cause of permanent turbidity and loss of submergent vegetation in the Murray-Darling river system, with severe consequences for river ecosystems, water quality and native fish species. In Victoria, Australia, common carp has been declared as noxious fish species, the quantity a fisher can take is unlimited. In South Australia, it is an offence for this species to be released back to the wild. An Australian company converts common carp into plant fertilizer.
Efforts to eradicate a small colony from Tasmania's Lake Crescent without using chemicals have been successful, but the long-term, expensive and intensive undertaking is an example of both the possibility and difficulty of safely removing the species once it is established. One proposal, regarded as environmentally questionable, is to control common carp by deliberate exposing them to carp-specific koi herpes virus with its high mortality rate. The CSIRO has developed a technique for genetically modifying carp to that they only produce male offspring. This daughterless carp method shows promise for totally eradicating carp from Australia's waterways.
Common carp were brought to the United States in 1831. In the late 19th century, they were distributed widely throughout the country by the government as a food-fish, but they are no longer prized as a food-fish. As in Australia, their introduction has been shown to have negative environmental consequences, and they are usually considered to be invasive species. Millions of dollars are spent annually by natural resource agencies to control common carp populations in the United States.
In Utah Lake Utah, the common carp's population is expected to be reduced by 75% by using nets to catch millions of them and either give them to people who will eat them or processing them into fertilizer. This, in turn, will give the native June sucker a chance to recover its declining population. Another method is by trapping them in tributaries they use to spawn with seine nets and exposing them to rotenone. This method has shown to reduce their impact within 24 hours and greatly increase the native vegetation and desirable fish species. This also leaves the baby carp easily preyed upon by native fish.
Common carp are believed to have been introduced into the Canadian province of British Columbia from Washington. They were first noted in the Okanagan Valley in 1912, as was their rapid growth in population. Carp are currently distributed in the lower Columbia (Arrow Lakes), lower Kootenay, Kettle (Christina Lake), and throughout the Okanagan system.
As food and sport.
"Cyprinus carpio" is the number one fish of aquaculture. The annual tonnage of common carp, not to mention the other cyprinids, produced in China alone exceeds the weight of all other fish, such as trout and salmon, produced by aquaculture worldwide. Roughly three million tonnes are produced annually, accounting for 14% of all farmed freshwater fish in 2002. China is by far the largest commercial producer, accounting for about 70% of carp production. Carp is eaten in many parts of the world both when caught from the wild and raised in aquaculture. In Central Europe, it is a traditional part of a Christmas Eve dinner. The carp as Christmas food was first mentioned by William of Rubruck, who ate it for the Christmas dinner in the court of the Mongol khan Möngke in 1253. Many people in Poland, Germany, Czech Republic, Slovakia and Hungary buy a live carp and bring it home two or three days before Christmas Eve. It is kept for one or two days in a bathtub, and then killed. A traditional Czech Christmas Eve dinner is a thick soup of carp's head and offal, fried carp meat with potato salad or boiled carp in black sauce. In some Czech families, the carp is not killed, but after Christmas returned to a river or pond. A Slovak Christmas Eve dinner is quite similar, with soup varying according to the region and fried carp as the main dish. In Western Europe, the carp is cultivated more commonly as a sport fish, although there is a small market as food fish. Carp are mixed with other common fish to make gefilte fish, popular in Jewish cuisine.
Common carp are extremely popular with anglers in many parts of Europe, and their popularity as quarry is slowly increasing among anglers in the United States (though destroyed as pests in many areas), and southern Canada. Carp are also popular with spear, bow, and fly fishermen.
The Romans farmed carp and this pond culture continued through the monasteries of Europe and to this day. In China, Korea and Japan, carp farming took place as early as the Yayoi Period (c. 300 BC – 300 AD).
Carp eggs, used for caviar, are increasingly popular in the United States.

</doc>
<doc id="60909" url="https://en.wikipedia.org/wiki?curid=60909" title="Match Game">
Match Game

Match Game is an American television panel game show that premiered on NBC in 1962 and was revived several times over the course of the next few decades. The game featured contestants trying to come up with answers to fill-in-the-blank questions, with the object being to match answers given by celebrity panelists.
"The Match Game" in its original version ran on NBC's daytime lineup from 1962 until 1969. The show returned with a significantly changed format in 1973 on CBS (also in daytime) and became a major success, with an expanded panel, larger cash payouts and emphasis on humor. The CBS series, referred to on air as "Match Game 73" to start and updated every new year, ran until 1979 on CBS, at which point it moved to first-run syndication (now without the year attached to the title, as "Match Game") and ran for three more seasons, ending in 1982. Concurrently with the daily run, from 1975 to 1981 a weekly prime time version, "Match Game PM", was also offered in syndication.
"Match Game" returned to NBC in 1983 as part of a sixty-minute hybrid series with "Hollywood Squares", then saw a daytime run on ABC in 1990 and another for syndication in 1998. All of these revivals used the 1970s format as their basis, with varying degrees of modifications.
The series was a production of Mark Goodson/Bill Todman Productions, along with its successor companies, and has been franchised around the world often under the name "Blankety Blanks".
In 2013, "TV Guide" ranked it #4 in its list of the 60 greatest game shows ever.
1962–69, NBC.
The pilot for the original version of "The Match Game", created by Goodson-Todman staffer Frank Wayne, bore little resemblance to its more famous descendant. Taped December 5, 1962 with Gene Rayburn as host, Peggy Cass and Peter Lind Hayes each headed a team of two non-celebrities who attempted to match answers to simple questions. All six contestants wrote down their answers to a question. If two team members matched answers the team earned 10 points and if all three team members matched, the team earned 20 points. The first team to score at least 50 points won the game and received $100. The winning team moved on to a bonus round, attempting to guess the answer to a recent audience survey. Each correct match was worth $25 for a possible top prize of $300. The series premiered on December 31 with Arlene Francis and Skitch Henderson. The show was taped in Studio 8H at 30 Rockefeller Plaza in New York City, which was later used for "The Phil Donahue Show" and "The Rosie O'Donnell Show" and now houses NBC Sports at Studio 8G.
A team scored 25 points if two teammates matched answers or 50 points if all three players matched. The first team to score 100 points won $100 and played the Audience Match, which featured three survey questions (some of which, especially after 1963, featured a numeric-answer format; e.g., "we surveyed 50 women and asked them how much they should spend on a hat," a format similar to the one that would later be used on "Family Feud" and "Card Sharks"). Each player who agreed with the most popular answer to a question earned the team $50, for a possible total of $450.
The questions used in the game were commonplace: "Name a kind of muffin," "Write down one of the words to ‘Row, Row, Row Your Boat’ other than ‘Row,’ ‘Your’ or ‘Boat’" or "John loves his _____." The humor in the original series came largely from the panelists' reactions to the other answers (especially on the occasional all-star episodes). In 1963, NBC cancelled the series with six weeks left to be recorded. Question writer Dick DeBartolo came up with a funnier set of questions, like "Mary likes to pour gravy all over John's _____", and submitted it to Mark Goodson. With the knowledge that the show couldn't be cancelled again, Goodson gave the go-ahead for the more risque-sounding questionsa decision that caused a significant boost in ratings and an "un-cancellation" by NBC.
"The Match Game" consistently won its time slot from 1963 to 1966 and again from April 1967 to July 1968, with its ratings allowing it to finish third among all network daytime games for the 1963–64 and 1967–68 seasons (by the latter season, NBC was the dominant channel in the game show genre; ABC was still an also-ran and CBS had mostly dropped out of the genre). NBC also occasionally used special episodes of the series as a gap-filling program in prime time if one of its movies had an irregular time slot. Although the series still did well in the ratings (despite the popularity of ABC's horror-themed soap opera "Dark Shadows"), it was canceled in 1969 along with other games in a major daytime programming overhaul, being replaced by "Letters to Laugh-In" which, although a spin-off of the popular prime time series "Rowan & Martin's Laugh-In" ended in just three months on December 26.
"The Match Game" continued through September 26, 1969 on NBC for 1,760 episodes, airing at 4:00pm Eastern (3:00pm Central), running 25 minutes due to a five-minute newscast. Since announcer Johnny Olson split time between New York and Miami to announce "The Jackie Gleason Show", one of the network's New York staff announcers (such as Don Pardo or Wayne Howell) would fill in for Olson when he could not attend a broadcast.
On March 27, 1967 the show added a "Telephone Match" game, in which a home viewer and a studio audience member attempted to match a simple fill-in-the-blank question similar to the 1970s' "Head-To-Head Match". A successful match won a jackpot which started at $500 and increased by $100 per day until won.
Very few episodes of the 1960s "The Match Game" survive (see episode status below).
"Match Game 73–79" (1973–79, CBS).
In the early 1970s, CBS vice president Fred Silverman began overhauling the network's programming as part of what has colloquially become known as the rural purge. As part of this overhaul, the network reintroduced game shows beginning in 1972. One of the first new offerings was "The New Price Is Right", a radically overhauled version of the 1950s game show "The Price Is Right". The success of "The New Price Is Right" prompted Silverman to commission more game shows. In the summer of 1973, Mark Goodson and Bill Todman took a similar approach in adapting "The Match Game" by reworking the show, moving it to Los Angeles, adding more celebrities and increasing the amount of prize money that could be won (it was this show, along with "The $10,000 Pyramid" and "Three on a Match" of the same time, that reintroduced five-figure prizes for the first time since the quiz show scandals).
The result was the "all-new, star-studded, big-money" "Match Game 73" for CBS, with Rayburn returning as host and Olson returning as announcer. The year in the title was updated on the New Year's Eve broadcast for the next six years. The game play for this version had two solo contestants attempting to match the answers given by a six-celebrity panel. Richard Dawson was the first regular panelist. Due to CBS News coverage of the Watergate hearings, the network delayed the premiere one week from its slated date of June 25 to July 2.
The first week's panelists were Dawson, Michael Landon, Vicki Lawrence, Jack Klugman, Jo Ann Pflug and Anita Gillette. Rayburn reassured viewers of the first CBS show that "This is your old favorite, updated with more action, more money and, as you can see, more celebrities." The first few weeks of the show were somewhat different from the rest of the run. At first, many of the questions fit into the more bland and innocuous mold of the earlier seasons of the original series. In addition, many of the frequent panelists on the early episodes were not regulars later in the series but who had appeared on the 1960s version, including Klugman, Arlene Francis, and Bert Convy, the last of whom would later be chosen as host of the show's 1990 revival before being diagnosed with a brain tumor which eventually took his life.
However, the double entendre in the question "Johnny always put butter on his _____" marked a turning point in the questions on the show. Soon, the tone of Rayburn's questions changed notably, leaving behind the staid topics that "The Match Game" had first disposed of in 1963 for more risqué humor. Celebrity panelists Brett Somers (Klugman's wife at the time) and Charles Nelson Reilly began as guest panelists on the program, with Somers brought in at the request of Klugman, who felt she would make a nice fit on the program. The chemistry between Somers and Reilly prompted Goodson-Todman and CBS to hire them as regular panelists; Somers remained on the show until 1982, while Reilly continued appearing through the 1983–84 and 1990–91 revivals, with a brief break from 1974–75 when Gary Burghoff, Nipsey Russell, and Rip Taylor substituted for him.
Reilly was late for the taping of two episodes; Goodson filled in for him for the first few minutes of one, and announcer Johnny Olson did the same on the other. Celebrity panelists appeared in week-long blocks, due to the show's production schedule. A number of celebrities, including Betty White, Dick Martin, Marcia Wallace, Bill Daily, Fannie Flagg, and Patti Deutsch were semi-regular panelists, usually appearing several times a year. Celebrity panelists also included personalities from other Goodson-Todman produced game shows, such as "The Price Is Right's" Bob Barker and Janice Pennington.
Format.
Two contestants competed on each episode. On the CBS version, the champion was seated in the upstage (red circle) seat and the challenger (opponent) was seated in the downstage (green triangle) seat. On the syndicated versions, which had no returning champions, positions were determined by a backstage coin toss. The object was to match the answers of the six celebrity panelists to fill-in-the-blank statements.
The main game was played in two rounds (three on "Match Game PM" after the first season). The opponent was given a choice of two statements labeled either "A" or "B". Rayburn read the statement and the six celebrities wrote their answers on index cards. After they finished, the contestant verbally gave an answer. Rayburn then asked each celebrity, one at a time beginning in the upper left hand corner of the panel, to respond with their answer.
While early questions were similar to the NBC version (e.g., "Every morning, John puts on his cereal"), the questions quickly became more humorous and risque. Comedy writer Dick DeBartolo, who had participated in the 1960s "Match Game", contributed broader and saucier questions. Frequently, the statements were written with bawdy, double entendre answers in mind. (One example was, "Did you catch a glimpse of that girl on the corner? She has the world's biggest [blank.")
Frequently, the audience responded appropriately as Rayburn critiqued the contestant's answer. (For the "world's biggest" question, Rayburn might show disdain to an answer such as "fingers" or "bag" and compliment an answer such as "rear end" or "boobs", often also commenting on the audience's approving or disapproving response.) The audience usually groaned or booed when a contestant or celebrity gave a bad or inappropriate answer, whereas they cheered and applauded in approval of a good answer. Sometimes, they howled at a risque answer.
The contestant earned one point for each celebrity who wrote down the same answer (or reasonably similar as determined by the judges; for example, "rear end" matched "bottom" or a similar euphemism) up to a maximum of six points for matching everyone on the celebrity panel. After one contestant played, the second contestant played the other question.
A handful of potential answers were prohibited, the most notable being any synonym for genitalia. In instances where Marcia Wallace gave the censorable answer, the word "Oops!" was superimposed over the index card and Wallace's mouth, accompanied by a slide whistle muting the spoken response.
Popular questions featured a character named "Dumb Dora" or "Dumb Donald." These questions often began, "Dumb Dora is "so" dumb..." To this, in a routine taken from "The Tonight Show Starring Johnny Carson," the audience would respond en masse, "How dumb "is" she?" This expanded to the generalized question form "is "SO" [adjective...;" to this, the audience would respond, "How "is" he/she?" Rayburn would finish the question or, occasionally, deride the audience's lack of unison and make them try the response again. Other common subjects of questions were Superman/Lois Lane, King Kong/Fay Wray, panelists on the show (most commonly Brett Somers), politicians, and Howard Cosell. Questions also often featured characters such as "Ugly Edna" (later "Ugly Ulfrea"), "Horrible Hannah/Hank," "Rodney Rotten," and occasionally "Voluptuous Velma." Some questions dealt with the fictitious (and often sleazy) country of "Nerdo Crombezia" or the world's greatest salesman, who could sell anything to anyone.
Rayburn always played the action for laughs, and frequently tried to read certain questions in character, such as "Old Man Periwinkle" or "Old Mrs. Pervis." He also did the same with Confucius or Count Dracula. Regular panelist Charles Nelson Reilly, a Broadway director, often responded with comments such as "I like it when you act" and "That character was really very good. Along with the other two that you do," to the amusement of the audience.
In the second round, the contestants attempted to match the celebrities whom they had not matched in the first round. On the CBS version, the challenger always began the second round (unless that contestant had matched all six stars; in this situation, the champion selected from the two questions available). This meant that a champion who had only answered one question could be ahead of a challenger who had played both questions, rendering the final question moot. On the syndicated versions, the leader after a round played first in the next round. In case of a tie score, the contestant who had not selected their own question in the previous round made the selection in the tie-breaker round.
The first round questions usually had a number of plausible answers, while the second round questions were generally easier and were usually puns that were meant to lead to an obvious answer, in order to allow a trailing contestant to catch up. For instance, ""molars"" would be the definitive answer for "Did you hear about the new religious group of dentists? They call themselves the "Holy _____.""
On "Match Game PM," a third round was added after the first season as games proved to be too short to fill the half-hour. Again, the only celebrities who played were those who did not match that contestant in previous rounds. In "Match Game PM," the questions with the most obvious answers were typically used in the third round.
If the contestants had the same score at the end of the game, the scores were reset and the contestants played one tiebreaker question each, again attempting to match all six celebrities. On "Match Game PM," or on the syndicated daytime show if time was running short, a time-saving variant of the tie-breaker was used that reversed the game play. The contestants wrote their answers first on a card in secret, then the celebrities were canvassed to give their answers verbally. Originally, this included regulars Somers, Reilly and Dawson only, but when Dawson left the show, the canvass was expanded to include all six panelists in the usual order. The first celebrity response to match a contestant's answer gave that contestant the victory. If there was still no match, which was rare, the round was replayed with a new question. On the CBS version, the tie-breaker went on until there was a clear winner. If it came to the sudden-death tie-breaker, only the final question (the one that ultimately broke the tie) was kept and aired.
The CBS daytime version had returning champions and the gameplay "straddled" between episodes, meaning episodes often began and ended with games in progress. On this version, champions stayed until they were defeated or won $25,000, whichever occurred first. Originally, this amount was the network's winnings limit; anything above that amount was forfeited, but the rule was later changed so that although champions retired after winning $25,000, they kept any winnings up to $35,000. During the six-year run of "Match Game" on CBS, only one champion, Carolyn Raisner, retired undefeated with $32,600, the highest total ever won on "Match Game".
On the daily 1979–82 syndicated version, two contestants played against each other in two games, and then both retired. The show was timed so that two new contestants appeared each Monday; this was necessary as the tapes of the show were shipped between stations, and weeks could not be aired in any discernible order. (This was a common syndication practice at the time, known as "bicycling.") Usually, three pairs of contestants competed in a total of six games over the five episodes for each week.
On Friday episodes which ran short, during the first season, a game was played with audience members for a small cash prize, usually $50. The game was played with regular panelist Brett Somers first. A word or phrase with a blank would be asked of Somers, and she would write it down on her card. Rayburn would then circulate amongst audience members who raised their hands to play, and if the audience member matched the answer Somers had written down, then they would win $50. Rayburn would continue picking on audience members until someone matched the answer. If there was more time left, the same game would be played with Charles Nelson Reilly responding to and writing down an answer for another audience member to guess. Rayburn sometimes seemed frustrated by this part of the show and with the answers given by some of the audience members; at the end of one episode, he was shown collapsed in one of the audience seats, seemingly exhausted.
Episodes of "Match Game PM" were self-contained, with two new contestants appearing each week.
Super Match.
The contestant who matched the most celebrities at the end of the game won the game and went on to play the Super Match, which consisted of the Audience Match and the Head-To-Head Match segments, for additional money. On the CBS version, the winner of the main game won $100.
Audience Match.
A two-to-four-word phrase was given, with part of the phrase blank, and the contestant attempted to fill-in the most common response based on a prior studio audience survey. The contestant consulted three celebrities for suggestions, and chose their favorite of those answers or one of their own. The top three answers were then revealed in ascending order. The most popular answer in the survey was worth $500, the second-most popular $250, and the third most popular $100. If a contestant failed to match any of the three answers, the bonus round ended. The idea for "Family Feud" was derived from the Audience Match.
Two Audience Matches were played on "Match Game PM," for a possible total of $10,000, or $20,000 after the Star Wheel was introduced.
Head-To-Head Match.
A contestant who won money in the Audience Match then had the opportunity to win ten times that amount (therefore, $5,000, $2,500, or $1,000) by exactly matching another fill-in-the-blank response with one celebrity panelist. Originally, the contestant chose the celebrity; later, the celebrity who played this match was determined by the Star Wheel. In the very start of the 1970s series, Rayburn read the question before the celebrity was chosen, but this was changed after a few weeks. The format of these matches was much shorter and non-humorous, typically requiring the contestant and celebrity to choose from a number of similar familiar phrases, for example, "Baseball _____" (baseball game, baseball diamond, etc.). The contestant was instructed that their response must be an exact match, although singular/plural matches were usually accepted, whereas synonyms were not.
The panelist chosen most often by contestants to play the Head-to-Head Match was Richard Dawson, who usually matched with the contestants that chose him. Dawson, in fact, was such a popular choice for the second half of the Super Match that the producers instituted a rule during 1975 which forbade contestants from choosing the same panelist for consecutive Head-To-Head Matches, in an effort to give the other celebrities a chance to play. After six weeks, however, the rule was discarded.
Star Wheel.
In 1978, the producers made a second attempt to ensure that each celebrity would receive a chance to play the Head-To-Head Match. Instead of simply choosing a celebrity, the contestant spun a wheel that was divided into six sections, each marked with a different celebrity's name. Once the wheel stopped, he/she tried to match against the indicated celebrity. If the wheel did not make at least one complete revolution, the contestant was required to spin again.
The introduction of the Star Wheel also brought about a change in the bonus payout structure. Each section included several gold stars; if the wheel stopped with its pointer on a star, the Head-To-Head Match was played for double value; this had a maximum of $10,000 on the daytime series and $20,000 on "Match Game PM."
When the Star Wheel was first introduced, each section contained five stars in a continuous white border, and the prize was doubled if the wheel stopped with its pointer anywhere in that area. Beginning with the premiere of the 1979 syndicated version, the wheel was re-designed so that each section had three stars in separate, evenly spaced squares; the pointer now had to be on a square in order to double the money.
Ironically, the wheel stopped on Dawson the first time it was used, inspiring four of the panelists (including Dawson) to stand up from their places and leave the set momentarily out of disbelief. Rayburn yelled, "Now wait a minute! Get back here!" He then got the four panelists to sit back down, after which guest panelist Mary Wickes said, "Do you know what that wheel cost us? And it's right back to Richard!"
A version of the Star Wheel was also used on the 1990 version of the show.
Staffing and ratings.
The 1973–82 versions were produced by veteran Goodson-Todman producer Ira Skutch, who also wrote some questions and acted as on-stage judge. Marc Breslow directed, while Robert Sherman was associate producer and head writer.
When CBS revamped "Match Game" in 1973 with more of a focus on risqué humor, ratings more than doubled in comparison with the NBC incarnation. Within eleven weeks, "Match Game '73" was the most watched program on daytime television. By summer 1974, it grew into an absolute phenomenon with high school students and housewives, scoring remarkable ratings among the 12–34 age demographic. The best ratings this version of "Match Game" saw were in the 1975–76 season when it drew a 12.5 rating with a 15 share, higher numbers than that of some prime-time series; this was due in part to the fact that it had been paired with "The Price Is Right," a hit in its own right, during this time. It surpassed records as the most popular daytime program ever with a record 11 million daily viewers, one that held until the "Luke and Laura" supercouple storyline gripped viewers on ABC's "General Hospital" some years later.
Every New Year's Eve, when the two-digit year designation in the "Match Game" sign was updated, there was a New Year's party with the cast and studio audience. Up to and including the 1977–78 changeover, a new sign was built each year. Coinciding with a redesign of the set, a new sign was built with interchangeable digits that could be swapped as the years changed. Additionally, this sign allowed for a "PM" logo to be attached for tapings of the syndicated program instead of using an entirely different sign.
In 1976, the show's success, and celebrity panelist Richard Dawson's popularity, prompted Goodson-Todman to develop a new show for ABC, titled "Family Feud," with Dawson hosting. This show became a major hit in its own right, eventually surpassing the parent program. "Feud" was said to be based on Dawson's expertise in "Match Game's" Super Match, specifically the Audience Match segment of it.
Meanwhile, "Match" kept its high standing in the ratings despite a short-lived move ahead one half-hour during summer and fall 1975. In late 1977, however, CBS made a fatal mistake regarding the show's time slot. Noting a ratings boon resulted when "Price" and "Match" were paired in afternoons, a major hole in the schedule had developed in the morning slot that "Price" had left behind. In an attempt to resolve the crisis, CBS moved "Match" along with "Price" back to the morning time slot. However, because much of "Match's" audience was composed of students who were in school at that time of day, ratings began to sag and eventually free fall; many of these students did not return. As a result, "Family Feud" quickly supplanted "Match" as television's highest-rated game show.
CBS attempted to correct the problem on December 12, 1977, with a scheduling shuffle among "Match," "Price," and "Tattletales." In a move that turned out to do even more damage, the network moved "Match" to its 1960s timeslot of 4:00pm, a time slot which by this point many local stations were preempting in favor of local or syndicated programming. As a result, "Match Game" was unable to get the audience it once did in the 1960s at 4:00.
1978 changes and cancellation.
On June 28, 1978, the "pick a star" format used in the Head-to-Head Match was replaced with the "Star Wheel." While the show's top prize could potentially be doubled and the new feature allowed more celebrities the chance to participate in the end game, it also eliminated what effectively was Richard Dawson's "spotlight" feature. Dawson, dissatisfied with the change and more focused on his role as host of "Family Feud," left the panel on "Match Game" a few weeks afterwards.
On July 19, a new "Match Game" set was built by CBS, changed from the original bright orange to a new set with blue and white colors, as well as revamping the logo from the curved letters to a straight-line lettering it would use for the rest of the run. (This logo also forms the base of the 2012 English-language Canadian revival version's logo.) The newly designed "Match Game" sign meant that a whole new sign no longer had to be built each year as had been done previously. An attachment designating the year was simply taken off the end of the revamped "Match Game '78" sign and replaced with a new one numbered '79 on New Year's Eve of 1978, which actually aired January 2, 1979, becoming "Match Game '79." (An alternate attachment was used for "Match Game PM.")
At 4:00pm, the show trailed "Feud," "Price," and NBC's "Wheel of Fortune," and it fell out of the top three game shows in 1979 for the first time in the CBS run (as opposed to a solid and twice top-3 hit in the 1960s). The 1,439th and final CBS episode aired on April 20, 1979however, the show did "not" air on April 5, causing the Friday episode from that week to air on April 9. The last nine aired episodes were culled together from three separate taping sessions, leaving six unaired.
"Match Game PM" (1975–81, weekly syndication).
On September 8, 1975 the first syndicated version, a weekly nighttime series dubbed "Match Game PM," premiered. The series, sold to many ABC affiliates (including the network's owned and operated stations such as WABC-TV in New York), was produced by Goodson-Todman and distributed by Jim Victory Television, G-T's syndication partner for "Concentration."
"Match Game PM" was the first version of the game with self-contained episodes. The front game was originally played the same way as the daytime "Match Game" with two rounds of questions, but in the second season, a third round of questioning was added to fill time in the half-hour. The maximum score a contestant could achieve remained six points, with matched celebrities not playing subsequent questions.
Tiebreakers were conducted differently from the daytime version. A "Super-Match"-style question was asked, and the contestants wrote down their answers, then called on celebrities for a match. Originally, only Somers, Reilly and Dawson played in the tiebreaker, but after Dawson's departure in 1978, all six celebrities played.
"Match Game PM's" Super-Match used two Audience Matches, with the answer values combined and multiplied by ten for the Head-To-Head Match, with a maximum of $11,000 available. When the Star Wheel was introduced, that potential payout grew to $21,000 if a contestant spun a double.
"Match Game PM" ran until the end of the 1980–81 TV season. For its last two seasons, the show's affiliate count went down significantly due in large part to a daily syndicated version that debuted in September 1979, although some markets, like New York, kept both shows on the air. WCBS-TV ran the daily syndicated version as WABC-TV continued to air episodes of "Match Game PM" into its final season. The show aired 230 episodes over six seasons, and remains the longest-running version to air in syndication.
Later revivals.
1979–82, daily syndication.
The rules and gameplay were the same as before, including the Star Wheel Bonus, but the format was altered slightly. Each contestant on this version of "Match Game" played a two-game match against another contestant, and the Super Match was played after each game. As on "Match Game PM", a contestant did not win any money for winning the game. There were also no returning champions on the daily syndicated series, as two new contestants began each match. The Star Wheel reduced the golden star sections to three, making it more difficult to double the winnings in the Head-to-Head match.
The maximum payout for a contestant was $21,000 (two $500 Audience Matches and two $10,000 Head-To-Head Match wins), the same its syndicated sister series "Match Game PM" was offering during this time.
For the first two seasons Bill Daily, Dick Martin, Richard Paul, and Bob Barker were among the male semi-regulars who filled Dawson's old spot on the panel. McLean Stevenson, who had done so once in September 1978 and twice near the end of the second year of this version, appeared in nearly all of Season Three (1981–82) and became a regular from the eleventh taped week through the end of the season. (Typical of Stevenson's fortunes at the time, which had him as the star of a string of short-lived television series, "Match Game" ended its run at the end of that season.)
The fee plugs which had aired in the middle of the show on the CBS version were featured during the closing credits. The ticket plugs were now shown on every episode. Each ticket plug had two people's faces merged into one image by putting a man's face on a woman's head, putting a mustache on a woman's face, or putting a pair of red lips on a man's face or simply putting two halves of the faces together. The 1990 ABC version used a similar sequence to introduce the stars.
The syndicated "Match Game" helped exacerbate the perception of the 4:00pm time slot being a "death slot" for network programming. After CBS canceled "Match Game 79", the network moved the long-running soap opera "Love of Life" into the vacant timeslot. Although the syndicated "Match Game" was not a direct cause of the ratings problems "Love of Life" facedthe 4:00pm timeslot, the last network daytime slot, had been a problem for CBS, NBC, and ABC for years and "Love of Life" had seen a precipitous drop in ratings since the April 1979 move to the late afternoon many stations ran the syndicated series against the veteran soap opera and, in the case of some CBS affiliates and owned-and-operated stations, preempted "Love of Life" in favor of the new "Match Game". ("Love of Life" aired its final episode on February 1, 1980, twenty-one weeks after the debut of the new "Match Game".) The daytime syndicated show produced 525 episodes, running until September 10, 1982 exactly three years after its debut.
"Match Game"'s 1973–82 run was taped in Studio 33 at CBS Television City in Los Angeles, except for one week of shows in 1974 in which it was shot in Studio 41.
"The Match Game-Hollywood Squares Hour" (1983–84, NBC).
In 1983, producer Mark Goodson teamed up with Orion Television (who had recently acquired the rights to "Hollywood Squares") and NBC to create "The Match Game-Hollywood Squares Hour". Rayburn, after a year as a morning show host in New York, agreed to return as host. However, few of the regular "Squares" cast appeared on this version. Jon Bauman (""Sha Na Na"") served as the lone regular panelist on this version, and the two swapped seats for "Hollywood Squares" with Bauman serving as host and Rayburn as the lower-left-hand square. Gene Wood served as announcer with Johnny Olson, Bob Hilton and Rich Jeffries substituting.
These rules were roughly the same as those of "Match Game PM" with both contestants given three chances apiece to match each panelist once. The major difference was in the tie-breaker. Four answers to a Super Match-like statement (example: "_____, New Jersey") were secretly shown to the contestants (examples: "Atlantic City", "Hoboken", "Newark", "Trenton"). They each chose one by number. The host then polled the celebrities for verbal responses. The first panelist to give an answer selected by one of the contestants won the game for that contestant. The winner of the "Match Game" segment played the returning champion in the "Hollywood Squares" segment with the eventual winner of "Squares" playing the Super-Match.
In the Super Match, the Audience Match featured payoffs of $1,000, $500, and $250. If a contestant did not make an Audience Match, the game did not end, but the contestant was given $100 and the game continued to the Head to Head Match.
For the Head-To-Head Match, the game reverted to the contestant picking the celebrity, and each celebrity had a hidden multiplier (10, 20, 30) for which the contestant would be playing for the number of times the Audience Match money won in the Head-To-Head Match, with the maximum amount available being $30,000. Champions remained on the program for up to five days unless defeated.
"The Match Game-Hollywood Squares Hour" ran from October 31, 1983 to July 27, 1984. Several music cues from the program are still used today as background music during prize descriptions on "The Price Is Right".
1990–91, ABC.
In 1989, ABC, which had not carried a daytime game show since "Bargain Hunters" in 1987, ordered a revival of "Match Game" for its lineup. A week's worth of pilot episodes were commissioned and Bert Convy, who was hosting "3rd Degree" for his own production company at the time, was asked to host. The network agreed to pick up the revival for a summer 1990 premiere.
However, the revival ran into a major snag right away. In April 1990 Convy was diagnosed with a terminal brain tumor, which took his life the following year, and was forced to step aside as host. Gene Rayburn, who had just finished hosting "The Movie Masters" for AMC, expressed interest in taking over his old role, but the show's producers went in a different direction and offered the position to Ross Shafer, the former host of Fox's "Late Show" and the USA Network dating series "Love Me, Love Me Not". Charles Nelson Reilly returned as a regular panelist and Brett Somers served as a guest panelist for several weeks. Vicki Lawrence, Sally Struthers, Brad Garrett, Bill Kirchenbauer, and Ronn Lucas were among the semi-regulars for this version of the show. Gene Wood returned as announcer, with Bob Hilton filling in for one week. Marcia Wallace, Betty White, Dick Martin, Dolly Martin, Jo Anne Worley, Edie McClurg & Jimmie Walker were among other panelists who also appeared on earlier versions of the show.
For this edition of "Match Game", the game consisted of a total of four rounds. Two players, one usually a returning champion, played. Unlike the previous "Match Game" series since 1973, the game was played for money rather than points. The first round was played in the traditional manner, with the two contestants trying to make as many matches as possible at $50 for each match.
The second round added a new wrinkle to the game. The round was called Match-Up and was played using Super Match-style fill-in questions, with both contestants choosing a panelist to play the round with. For each question, Shafer would first read the statement with the blank. The contestant was shown two answers and chose one, and once the choice was made Shafer revealed the choices to the celebrity, who then gave his/her own guess. If they matched the contestant received $50 each time it happened. Each contestant had thirty seconds to make as many matches as possible and play always started with the trailing contestant entering the round.
After the contestants played a second classic "Match Game" round for the same stakes, the game concluded with a second round of Match-Up. Play started with the trailing contestant again, who chose a new celebrity to play with. This time, the round was played for forty-five seconds and each match paid $100. Once the first contestant finished, the second player took their turn. If the second player made enough matches to pass the first contestant before time expired, he/she won the game and advanced to the Super Match; otherwise, the first player won. The second player could also win without having to play the second Match-Up, provided that the first player did not compile enough matches to pass his/her score.
If the game ended in a tie, one last fill-in-the-blank phrase was shown to both contestants but with three choices. The champion chose an answer first while the challenger chose one of the remaining answers. After the choices were made, the last celebrity who played the second Match-Up round made a choice of his/her own. Originally the star had a choice of all three, later he/she had a choice of the chosen two without any knowledge of who chose what. The player with the answer said by that celebrity won an additional $100 and the game. On the first show, the red player chose which contestant should play the final Match-Up question (either himself/herself or his/her opponent). The player chosen selected the answer, then chose which celebrity to match. A successful match won the game for the contestant, but an incorrect answer won the game for the opponent.
The Super Match was played similar to the 1978–82 version of the round, beginning with the Audience Match. Initially the payouts were the same as on the 1970s series, with the top answer worth $500, the second $250, and the third $100. The $50 consolation prize for not coming up with a top three answer that had debuted on "Match Game-Hollywood Squares Hour" was kept for this series. After several weeks, the second and third place answers increased to $300 and $200 and the consolation amount doubled to $100.
Once the contestant's Audience Match winnings were determined they then faced the Star Wheel to determine the stake for the Head-to-Head Match, with a maximum amount of $10,000 available. The Star Wheel was slightly modified for this "Match Game" series, as the contestant did not spin the actual wheel and there were no stars under the celebrities' names. Instead the wheel was fixed in place and the contestant spun a green arrow attached to its rim in order to determine the celebrity. Each celebrity had two red dots placed under their name and the stake was doubled if the wheel landed on one of them.
Otherwise, play was the same as before: the contestant and panelist had to match exactly in order to win the Super Match. Champions could stay for up to five days or until they were defeated, and for the first time a network "Match Game" series was not subject to a winnings limit; ABC, who had enforced a strict $20,000 limit for years on its game shows, had stopped this practice by 1990. (Although NBC had no network-imposed limit, "MGHS" was a combination of two shows and not a single like the CBS and ABC series were.)
Because many ABC stations in major Eastern Time markets carried local news at 12:00 pm, the show was mostly seen in smaller markets and on independent stations in some larger markets without network clearances (which had affected the previous occupier of the timeslot, soap opera "Ryan's Hope"), and was canceled after one season. The show's 250th and final episode aired on July 12, 1991. Ross Shafer announced that the show would be moving back to CBS for the 1991–92 season on the finale, but this never materialized. The following Monday, "Home" was temporarily expanded to 90 minutes to fill the show's timeslot (ABC would return the noon timeslot to its affiliates in 1992). "Match Game" was ABC's last daytime game show.
1998–99, daily syndication.
In 1996, a pilot was produced (see below) for a new revival of the show, just five years after the previous incarnation had left the air. While that version (which did not air) had a much greater departure from the game's original format, the producers significantly retooled the format to create a somewhat more faithful remake of the program, which was picked up in syndication and began in fall 1998. It is the only version of the show to not air on a broadcast network (as the 1979–82 version and "Match Game PM" were essentially continuations of the CBS version).
Michael Burger hosted this revived version of the show, while Paul Boland served as its announcer. The only celebrity guests who had appeared on previous versions of the show were Vicki Lawrence (who appeared on two weeks of the 1970s version and regularly on the 1990–91 version) and Nell Carter (who had appeared on the final week in 1991). The regular panelists on this version were Carter, Lawrence, and Judy Tenuta, and semi-regulars were George Hamilton, John Salley, Coolio, and Rondell Sheridan. Production returned to Studio 33 at CBS Television City on this version.
This incarnation of "Match Game" was played with rules similar to that of the 1973–82 versions with a few exceptions. The show featured a panel of only five celebrities instead of the usual six. Questions in this version were not labeled A or B; instead titles with puns were a clue as to the content. As on the 1990–91 version, all five panelists played each round regardless of whether they matched a contestant on the first question; correct matches in the second round were worth two "points" while those in the first were awarded one.
After two rounds, the highest scorer played the Super Match, which was played similar to its 1973–78 incarnation (with the exception of the 1983 rule change, $50 in this version, for an unsuccessful match), including the $5,000 top prize.
This version was noted for its sometimes over-the-top risqué humor of the celebrities and contestants. For instance, the prohibition on answers such as genitalia was no longer existent. On many episodes, answers that were deemed inappropriate for daytime TV were edited out with a "cuckoo" dubbed over the audible answer and a "CENSORED" graphic over the answer card and sometimes the person's mouth.
While Burger generally received positive reviews for his hosting, the series was mostly panned. Its humor was seen to have crossed the line from risqué into the out-and-out dirty and many stations pushed it into late-night slots. Its low budget and lack of returning champions (staples of several modern game shows) were also focal points for criticism. This was especially since two of the previous three versions to air all featured returning champions and offered cash prizes well in excess of $10,000 in an era when purchasing power was roughly twice that of 1998.
This version lasted one season, running from September 21, 1998 to May 1999, with repeats airing until September 17, 1999.
"Gameshow Marathon" (2006, CBS).
On June 22, 2006, "Match Game" was the sixth of seven classic game shows featured in CBS' month-long "Gameshow Marathon" hosted by Ricki Lake and announced by Rich Fields, and the second of two "semi-final" games in the tournament. The contestants were Kathy Najimy and Lance Bass with Betty White, George Foreman, Kathy Griffin, Bruce Vilanch, Adam Carolla, and Adrianne Curry as the panel. White retained her normal sixth-seat position and was the only one from the original series to appear for this segment of "Gameshow Marathon".
Lake used the same signature long-thin Sony ECM-51 telescoping microphone Rayburn used during the CBS version, and the set was rebuilt to be almost an exact match of that used from 1973 to 1978. Najimy won the game, scoring five matches to Bass's three.
The format was that of "Match Game PM", except that in the Super-Match the Head-To-Head Match was played for 50 times the amount won in the two Audience Matches ($50,000), which was won.
Portions of the set were repackaged and sent to Studio 33 for the taping of the failed "Match Game" revival for TBS (see below).
"Match Game" (Canada).
A Canadian revival of "Match Game" debuted on The Comedy Network October 15, 2012. The series uses theme music similar to the 1973–82 version and is hosted by Darrin Rose, with Seán Cullen and Debra DiGiovanni as permanent panelists. On April 4, 2013, it was announced that due to high ratings, the show would return for a 60-episode second season, which premiered on September 2. The first season was taped in Montreal, with production moving to Showline Studios in Toronto for season 2.
Gameplay is similar to the 1990 U.S. revival; two rounds are played, with all six celebrities participating in both rounds, and each match is worth 50 points (100 points starting in season 2). The third round is "Match-Up!", with each contestant given 45 seconds to match/his her chosen celebrity partner, and successful matches are again worth 50 points (100 starting in season 2). The player with more points at the end of this round wins the game and receives the cash equivalent of their score (for example, if the champion's final score was 450 points, the payoff would be $450).
Unlike any previous version, the Audience Match portion of the "Super Match" is not played for a payoff, but simply to determine the value of the Head-to-Head Match. The potential payoffs are $2,000–$1,500–$1,000 ($2,500–$2,000–$1,500 starting in season 2), or $500 ($1,000 starting in season 2) for an unsuccessful match. If the champion manages a lucky Star Wheel spin, as in earlier versions, the value is doubled for a payoff of up to $4,000 ($5,000 starting in season 2).
2016 version.
The first of ten episodes hosted by Alec Baldwin are scheduled to premiere on ABC (which had previously aired the 1990 version) on June 26, 2016 at 10:00pm EST; it will air as part of ABC's "Sunday Fun and Games" block alongside the returning "Celebrity Family Feud" and "The $100,000 Pyramid" with Michael Strahan. It also marks the series' return to New York, having taped there during the 1960s.
Episode status.
1962–69.
Only 11 episodes are known to survivethe pilot and ten kinescope recordings, all of which are archived at the Paley Center for Media. Nine of these are black-and-white kinescopes and one is a color episode (from 1969 and on videotape). The pilot has since fallen into the public domain.
In 1965, "The Match Game" began to be produced on color videotape; however, none of the tapes are known to have survived the wiping and re-use procedures of NBC during that period as none of the surviving episodes are in color.
Game Show Network (GSN) owns the rights to, and has occasionally aired, three episodes from this series; it most recently aired two during the "Match Game" marathon on Christmas Day 2012. One of them is the 1962 pilot with Peggy Cass and Peter Lind Hayes; the other is an all-star match featuring Cass, Betty White and Joan Fontaine against Bennett Cerf, Henry Morgan, Robert Q. Lewis, apparently from January 1964. GSN also owns the rights to a July 1964 episode featuring Orson Bean and Jayne Mansfield. These episodes have been reaired on Buzzr.
1973–82.
All three versions that aired during this period are presumed to be intact, and currently air on both Buzzr and GSN. This was the very first program to air on GSN during its launch in 1994. GSN has also aired all 16 episodes that were recorded in 1979 but not aired by CBS at the time.
1983–84.
All episodes are intact, but due to cross-ownershipMetro-Goldwyn-Mayer owns the then-rights to "Hollywood Squares" (at the time of "MGHS" it was co-produced by Orion Television) while FremantleMedia owns "Match Game" have never been rerun.
1990–91.
All episodes of this version are intact, along with all five Bert Convy pilots. GSN aired this version as recently as 2004, and the VH1 miniseries "Game Show Moments Gone Bananas" aired a clip from a Convy pilot, as well as a clip with Ross Shafer. GSN aired one of the Convy pilots on December 25, 2012, as part of a "Match Game" marathon.
1998–99.
The series is intact, and brief clips have been seen on various game show blooper specials. GSN aired an episode of this run as part of a "Match Game" marathon on Christmas Day 2012.
Unsold pilots.
1985.
Plans were made to re-launch "Match Game" as a stand-alone series in daily syndication in conjunction with the revival of the nighttime version of "The Price Is Right". Rayburn was once again to serve as host, but he had already committed to "Break the Bank" at the time, and was unavailable. The project was postponed, and reruns from the 1979–82 daily series aired instead.
1987.
Rayburn was fired from "Break the Bank" after 13 weeks and several disputes with the producers, and by late 1986 was once again available. The January 19, 1987 issue of "Broadcasting & Cable" a trade advertisement promoting another five-day-a-week revival attempt in syndication for Fall 1987, again with Rayburn as host. The advertisement featured a red-colored version of the 1978–82 logo and was promoted as featuring a "Celebrity Panel-the biggest names in entertainment" plus "big cash prizes for lots of excitement". Coca-Cola Telecommunications was to syndicate the program.
1996 ("Match Game 2/MG2").
A pilot was shot in September 1996 at KTLA Studios in California for a revised version called "Match Game 2" ("MG2") with Charlene Tilton (a panelist on the 1979–82 version) as host. The panel for this show included Downtown Julie Brown, David Chokachi, Gil Gerard, Rondell Sheridan, and Kathleen Kinmont.
The format featured gameplay not used in any other version:
Many elements of this pilot, such as a change from a six celebrities to five, were kept in for a second pilot shot a year later with Michael Burger as host.
2004 ("What The Blank!", FOX).
"Vanity Fair" and TVgameshows.net reported in May 2004 that a pilot called "What the Blank!" was taped for FOX and hosted by Fred Willard for air during the Summer 2004 "off" season.
It was said that the game was an incorporation of 21st-century elements into the classic game as well as an added feature that people from along the streets would be able to participate for matching with contestants and celebrities in "Street Smarts"-style.
FOX abruptly canceled the series before the show made it to air; at least one pilot, with Randy West announcing and with Zach Galifianakis, Martin Mull and Anna Nicole Smith as panelists, was taped.
2008 (TBS).
TBS commissioned a pilot for a revived "Match Game" as part of an overhaul of its late night television programming. On June 21, 2008, Andrew Daly hosted a pilot episode with panelists Super Dave Osborne, Sarah Silverman, Scott Thompson, Rashida Jones, Norm Macdonald and Niecy Nash. The show used a reproduction of the 1973–78 version of the "Match Game" set.
Gameplay for the front game was the same as "Match Game PM", with three rounds of front play. The Super Match bonus was played differently, however. Instead of a single Audience Match question, 5 full-length survey questions were asked of the player in 30 seconds (similar to the “Fast Money” round in "Family Feud"). The player had to give what they thought was the most-popular response to each question in that time. When time expired, the player was allowed to ask a celebrity what THEY thought might be the top answer for one of the questions. The player could then decide to keep their own answer or change it for the star's response. This was repeated twice for two more of the questions, each with a different celebrity. For each match, the player earned $1,000, for a possible total bank of $5,000. The player then chose a star to play the "Head-To-Head Match" to try to double their bank (for a possible $10,000 in bonus winnings).
TBS eventually passed on the project in favor of "Lopez Tonight".
Reruns.
The 1973–82 incarnations are shown in reruns daily on GSN. Virtually all episodes of this version are still extant, although some reportedly are not shown due to celebrities' refusals of clearances and others have been banned for various reasons (usually for answers from either contestants or celebrities). Other episodes no longer air on GSN due to tape damage. On November 26, 2006 the network broadcast an hour-long documentary titled "The Real Match Game Story: Behind The Blank" featuring rarely seen footage of the 1960s version, many odd or memorable moments from the main 1973–82 runs, plus interviews with Rayburn, Somers, Dawson, DeBartolo, producer Ira Skutch, and others involved in the show's production. The 1990–91 ABC version has also had runs on GSN, most recently throughout 2002–04. On December 25, 2012, an episode of the 1998 version along with a Bert Convy pilot aired on GSN for the first time as part of a "Match Game" marathon. Buzzr also airs reruns of the show, particularly from the first half of its 1978 run.
Music.
"Match Game" featured several theme songs throughout its various runs. From 1962 to 1967, Bert Kaempfert's instrumental "A Swingin' Safari" was used as the theme; a slightly different rendition (Billy Vaughn's cover of the same song) was used on the pilot. From 1967 to 1969, a new theme composed by Score Productions was used.
When the program returned in 1973, Goodson-Todman once again turned to Score Productions for a music package. A new theme, performed by "The Midnight Four", was composed by Score staff composer Ken Bichel with a memorable "funk" guitar intro, and similar elements and instruments from this theme were also featured in the numerous "think cues" heard when the panel wrote down their answers. Alternate think cues were extracted from the music packages for "Tattletales" and "The Money Maze". In keeping with the zany atmosphere, the music supervisors also used other notable musical works to add to humorous situations. Among the non-Score Productions music heard on occasion was the "burlesque" music titled "The Stripper", and a version of "Stars And Stripes Forever".
The music for "The Match Game-Hollywood Squares Hour" was composed by Edd Kalehoff. None of the music used from the 1970s version was used in this version. The main theme song and several of its cue variations are still used on "The Price Is Right".
In 1990, Bichel re-orchestrated his 1970s theme with more modern instruments with new think cues (with the classic intro/think cue re-orchestrated). The 1998 version again used music from Score Productions.
Merchandise.
Home games.
Several home game versions based on the 1960s and 1970s American television version were published by Milton Bradley from 1963 through 1978, in multiple editions.
"The Match Game" (1963–69).
Starting in 1963, Milton Bradley made six editions of the NBC version. Each game contained crayons, wipe-off papers, 100 perforated cards with six questions per card, a plastic scoreboard tray with colored pegs and chips, and 6 "Scribble Boards". After the first edition, the vinyl "scribble boards" and crayons were replaced with six "magic slates" and wooden styli.
The main object of the game is for contestants to try to write answers to questions that will "match" their partners' answers. The rules for a six-contestant game are the same as on the TV show (with similar scoring, such as receiving points for matching two answers and more points for matching all three answers), but the home game also has variations for fewer than six contestants. No bonus game is included.
Milton Bradley also created a Fine Edition and a Collector's Edition with more questions. The magic slates came enclosed in a gold-looking folder, plus a dial to keep score instead of the pegboard. The scoring and point values were just like the TV show. The only difference between the Fine Edition and the Collector's Edition is that instead of being packaged in a normal cardboard box, it came in a leatherette case with buttons on the front apron.
"Match Game" (1974–78).
Starting in 1974, Milton Bradley created three more editions based on the most famous CBS version. Each edition contained a game board with a plastic stand, two game booklets (one with instructions) with material for 92 complete games (368 Main Game Questions and 92 "Audience Match" and "Head-to-Head Match" questions), two magic slates and styli (only of the Head-to-Head portion), and play money.
As in the 1970s version, two contestants have two chances to match as many of the six "celebrities" as possible. Celebrity answers are printed in the booklets, and after the contestant gives an answer, the M.C. reads the celebrity responses one by one, marking correct answers on the game board. A contestant can get up to six matches in one game. The contestant with the most matches plays the "Super Match" round (the MC reads the question and the responses) for a chance to win money (with an "Audience Match" and a "Head-to-Head Match" similar to the TV show) of up to $5,000.
Interactive Online Versions.
After much success with their online version of "Family Feud", Uproar.com released a single-player version of "Match Game" in 2001. However, as of September 30, 2006, the website has been temporarily shut-down, no longer offering any game show based games of any kind.
GSN offered a version called "Match Game: Interactive" on their own website that allowed users to play along with the show while watching. However, as of January 1, 2007, only those shows that airing between 7PM and 10PM were interactive as "Match Game" itself was not one of them.
Mobile version.
Prior to their Interactive online game, GSN also had an Interactive mobile phone version based on "Match Game PM" courtesy of Goldpocket iTV.
Slot machine.
A five reels video slot machine based on the 1973–82 version was released at various US casinos by WMS Gaming in 2004. The game features caricatures of Jimmie Walker, Brett Somers, Charles Nelson Reilly, Morgan Fairchild (even though she has never appeared on any incarnations of the show itself), Rip Taylor and Vicki Lawrence as the panel and Gene Rayburn as the host. The Slot machine's bonus round stays faithful to the original game format where round one is adapted from the main game while round two features the big-money, "Supermatch" bonus round.
DVDs.
A DVD set called "The Best of Match Game" featuring a collection of more than 30 episodes of the 1970s version including the original 1962 pilot episode (which was originally called "The Match Game") was released in 2006. A less-than-stellar eight-episode collection, called "The Best of "Match Game": Dumb Dora Is So Dumb Edition!", was released later on in 2007.
In 2007, Endless Games released a DVD game featuring hilarious questions and clips from the 1970s version. Its gameplay was similar to that of the 1970s version; however, it allowed up to six players rather than two. Scoring for the game was also slightly different as well, as every match in the round one was worth $50 each while in round two, every match was worth $100. Also, the Super Match round was played differently. The audience match portion was played after round one by the leading player(s), while a correct match doubled the winnings of the player(s) score.
In popular culture.
The show RuPaul's Drag Race has parodied "Match Game" in a segment called "Snatch Game" since the second season, which aired in 2010.

</doc>
<doc id="60911" url="https://en.wikipedia.org/wiki?curid=60911" title="Press Your Luck">
Press Your Luck

Press Your Luck is an American television daytime game show created by Bill Carruthers and Jan McCormack. It premiered on CBS on September 19, 1983 and ended on September 26, 1986. In the show, contestants collected spins by answering trivia questions and then used the spins on an 18-space game board to win cash and prizes. The person who amassed the most in cash and prizes at the end of the game won. Peter Tomarken was the show's host, and Rod Roddy was the primary announcer. John Harlan and Charlie O'Donnell filled in as substitute announcers for Roddy on different occasions. "Press Your Luck" was videotaped before a studio audience at CBS Television City, in Studios 33 and 43 in Hollywood, California. The show was a revival of the earlier Carruthers production "Second Chance", which was hosted by Jim Peck and aired on ABC during 1977.
The show was known for the "Whammy", a red cartoon creature with a high-pitched voice. Landing on any of the Whammy's spaces on the game board took away the contestant's money, accompanied by an animation that would show the Whammy taking the loot, but frequently being chased away, blown up, or otherwise humiliated in the process. The Whammies were created and animated by Savage Steve Holland and Bill Kopp, and voiced by Carruthers. Approximately 85 different animations were used.
Gameplay.
Three contestants competed on each episode, usually a returning champion and two new challengers.
Each game began with a trivia round where the contestants tried to earn spins, which would then be used on the show's gameboard, referred to as the Big Board. A question would be posed to the contestants, who tried to be the first to buzz in with a correct answer. Once a contestant gave an answer, his/her opponents were given a choice of that answer or two additional answers provided by Tomarken and selected one. If the contestant that buzzed in with the answer gave the correct one, he/she earned three spins. A correct multiple choice answer was worth one spin. If none of the three contestants buzzed in with an answer within five seconds, three answers were given to the contestants and they earned one spin each if they chose correctly. If a contestant buzzed in but failed to give an answer, that contestant was locked out of the question and it was treated the same way as if nobody had buzzed in.
After four questions were asked, play moved to the Big Board. The board consisted of eighteen squares, each of which had a screen in it that displayed one of three items which changed every few seconds, and a randomizer light which the contestants stopped by hitting their buzzer. The most common spaces offered cash, with an extra spin attached to some of them, and prizes, with some being directional spaces that either allowed the contestant to choose between two squares or moved their position to a different part of the board. Cash amounts and prize values were added to the contestant's score, while landing on any of several Whammy spaces reset the score to zero.
In the first Big Board round, play started with the contestant with the fewest spins unless there was a tie, in which case the contestant seated furthest left started. For each square the contestant stopped the randomizer light on, the value of that square was added to his/her bank and he/she kept playing until running out of spins or deciding to pass. Any passed spins went to the contestant's opponent with the higher amount of money. If there was a tie among the passing contestant's opponents, the contestant who passed the spins had the choice as to which contestant would receive them. A contestant receiving passed spins had to take them and could not pass unless he/she earned additional spins by hitting the squares offering them or if a Whammy came up during his/her turn, in which case any remaining passed spins became earned spins. Play continued until the contestants exhausted all of their spins. If at any point in the game a contestant hit four Whammies, he/she was eliminated from the match and any unused spins remaining were lost.
Once each contestant had completed his/her turn on the Big Board, they played a second round of trivia questions with the same rules as before. A second Big Board round followed, with much higher stakes in play. This time, contestants played in order from least amount of money to highest amount of money unless there was a tie between two or more contestants, in which case the contestant with the least amount of spins would start the round. Any passed spins, as before, went to the contestant with the next highest amount of money. 
The contestant in the lead at the end of the second Big Board round became the day's champion, kept his/her winnings, and got to return on the next show as long as the show's winnings limits were not reached (see below). If two or all three contestants finished the match tied, they returned on the next show. In the rare occurrence that two contestants Whammied out of the game, the remaining contestant was given a choice to end the game or keep spinning to try to win more money. The choice was given after each spin the contestant took, and the game continued until he/she ran out of spins, stopped the game, or Whammied out. If the contestant managed to Whammy out, the game ended with no winner and three new contestants would play on the next show.
Board values.
In the first Big Board round, cash amounts ranged from $100 to $1,500 and prizes typically were worth no more than $2,000. The second round featured cash amounts from $500 to $5,000, and prizes potentially worth $6,000 or more. Three special squares also appeared throughout the course of the show. The first, "Double your $$", added a cash amount equal to the contestant's score at the time. This square later became "Double Your $$ + One Spin", awarding a spin in addition to the cash amount. "Add-A-One" added a "1" to the front of the contestant's current score (e.g., $0 became $10; $500 became $1,500; and $2,000 became $12,000). The third, "$2,000 or Lose-1-Whammy", offered the contestant a choice of adding $2,000 to his/her score ($2,000 was automatically added if (s)he has no Whammies), or removing a Whammy received earlier in the game. Add-A-One was only featured in the first Big Board round, with the others only appearing in the second Big Board round.
One square present in both Big Board rounds was Big Bucks. This square, appearing third from the right in the bottom row, automatically moved the selector light to the corresponding position in the top row. The top dollar values in this square in round one were $1,000, $1,250 and $1,500. For the second round, the top dollar values were $3,000, $4,000, and $5,000, all of which awarded an extra spin.
In both rounds, the value of a prize was announced only after it had been claimed, and a new prize was put on the board in its place.
Limits on winnings.
Any contestant who won five games or exceeded the winnings cap retired undefeated. From September 19, 1983 to October 31, 1984, any contestant who won over $25,000 retired undefeated, but contestants could keep up to $50,000. The CBS game show winnings cap was raised to $50,000 on November 1, 1984, with contestants being able to keep up to $75,000.
Home Player Spin.
"Home Player Spins" were featured three times during sweeps periods: May 14 – June 8, 1984, January 21 – February 15, 1985 and October 21 – November 22, 1985. Each of the three contestants was assigned a postcard with the name of an at-home player prior to the start of the episode. One spin in the final round was designated as the Home Player Spin at the start of the round, and when that spin occurred, whatever the contestant landed on during that spin was added to their own total and also awarded to the home player. If the contestant hit a Whammy, the home player received $500. If the contestant landed on a space that awarded money and an additional spin, the in-studio contestant received the money and the spin, but the home player only received the money.
At the close of the October–November 1985 contest, that episode's in-studio winner drew a card from a bowl containing the names of each of the 75 at-home participants featured over the five-week period. After drawing the name, the contestant took one spin on a modified board that showed only cash values and directional squares (no Whammies, prizes, or squares that offered additional spins were present). The value landed on, multiplied by the total number of spins earned by the three contestants in the second question round, was then awarded to the home player whose name was drawn.
Broadcast history.
Original run.
Peter Tomarken, who had just ended a 13-week gig as the host of "Hit Man" on NBC, was tapped as host for "Press Your Luck". The pilot was taped on May 18, 1983, and the actual show began both tapings and airings four months later on September 10 of that year. The show premiered on September 19, 1983 on CBS at 10:30 AM ET (9:30 CT/MT/PT), replacing "Child's Play", and placing it between "The New $25,000 Pyramid" and "The Price Is Right". "Press Your Luck" competed against "Sale of the Century" for first place in the 10:30 AM morning time slot over the next two years. 
On January 6, 1986, CBS relocated "Press Your Luck" in order to make room for a Bob Eubanks-hosted revival of "Card Sharks". "Press Your Luck" replaced "Body Language" in the network's 4:00 PM afternoon time slot. Although some CBS affiliates carrying the program in 1986 outside of the 4:00 PM ET time slot tape-delayed it for broadcast the next morning (including the network's owned-and-operated stations in New York and Los Angeles), many CBS affiliates dropped the program. The last episode of the show aired on September 26, 1986, but it was not acknowledged as the finale. The final tapings took place in August of that same year, when its cancellation was first announced. After the show ended its run, CBS returned the 4:00 PM timeslot to its affiliates.
Reruns.
In early 1987, 130 episodes of the show were packaged by Republic Pictures for Syndicated reruns to a handful of local stations. These episodes originally aired on CBS from February 25 to August 23, 1985, and were also the first to be shown on USA Network from September 14, 1987 (the day USA Network picked up the show for its block of afternoon game show reruns) to March 11, 1988. "Press Your Luck" remained on the schedule until October 13, 1995.
The series was later purchased by FremantleMedia, who also owns the Goodson-Todman and Reg Grundy libraries. Since then, the company has handled revivals and video game licenses, such as with "Whammy!" and the 2009 video game. On June 8, 2006, "Press Your Luck" was featured as the fourth round of "Gameshow Marathon" on CBS.
Game Show Network (GSN) aired the show from 2001 to 2009, airing episodes from February 1984 – November 1985. GSN resumed airing the show in 2012, airing episodes from the September 1983 premiere to February 1984. From 2014 to 2015, GSN aired episodes 561 to 696, which originally ran from November 1985 to May 1986. From 2001 to 2003, Larson's episodes did not air on the network until they were incorporated in "Big Bucks: The Press Your Luck Scandal" – including footage not aired during the original CBS broadcast.
Currently, "Press Your Luck" can be seen on Game Show Network and Fremantle's BUZZR.
Notable contestants.
Michael Larson.
In 1984, a self-described unemployed ice cream truck driver named Michael Larson made it onto the show. After watching the show at home with the use of stop-motion on a VCR, Larson discovered that the presumed random patterns of the game board were not actually random and he was able to memorize the sequences to help him stop the board where and when he wanted. On the single game in which he appeared, an initially tentative Larson spun a Whammy on his very first turn, but then played 45 consecutive spins without hitting a second one. The game ran for so long that CBS aired the episode in two parts, June 8 and 11, 1984. In the end, Larson earned a total of $110,237 in cash and prizes, a record for the most money in cash and prizes won by a contestant in a single appearance on a daytime network game show. In 2006, when Vickyann Chrobak-Sadowski won $147,517 in cash and prizes on the Season 35 premiere of "The Price Is Right", it was not enough to surpass Larson's inflation-adjusted record.
Although CBS investigated Larson, they determined that figuring out the patterns was not cheating and let him keep his winnings. The board was subsequently reprogrammed with up to 32 new patterns to help prevent against another contestant from being able to memorize the board as Larson had. Later, in 1994, "TV Guide" magazine interviewed Larson and revealed the background of this episode including his decision to pass his remaining spins after he lost concentration and missed his target squares.
Larson, through meticulous watching of the show, had figured out patterns to key off of the square next to the square in the upper left-hand corner of the board (which, in that he numbered the squares from the upper-left clockwise, was numbered "2") and that, several squares later, would end up either on a spot on the right side of the screen in which all three slides would contain smaller amounts of money plus a spin (numbered "8") or the spot in the top center of the screen (numbered "4") in which the "Big Bucks" (the largest amounts of money) plus a spin always resided. Not only would he not hit a Whammy if he landed on those two squares, but he would also be guaranteed to continue gaining more spins as long as he desired. The story, and this strategy, were told in a two-hour documentary on GSN titled "Big Bucks: The Press Your Luck Scandal" in March 2003. GSN also aired a special rematch edition of "Whammy! The All-New Press Your Luck", featuring the two runners-up from the show, host Tomarken and Michael Larson's brother James (Michael Larson had died of throat cancer in 1999).
In July 2010, Michael's brother James, and his former wife at the time of winning, were interviewed for PRI's "This American Life" for the episode "Million Dollar Idea".
Others.
Aside from Michael Larson, several contestants later found fame outside of game shows:
"Whammy! The All-New Press Your Luck".
In 2002, a revival titled "Whammy! The All-New Press Your Luck" (shortened to "Whammy!" in 2003) hosted by Todd Newton premiered on Game Show Network. New episodes initially aired through 2003, and reruns continue to air on GSN.
Several changes to the rules and aesthetics of the game were made. Three new contestants appeared on each episode with no returning champions, much less cash was available as well as more prizes, the board was entirely computerized (as well as redesigned), and the first question round was eliminated. Additionally, "Big Bank" spaces were added to the board in season two, which placed an accumulating jackpot to a contestant's bank when that contestant landed on the space and answered a question correctly.
International versions.
The series was presented by Ian Turpie with John Deeks as announcer on Seven Network from 1987 to 1988. Grundy Worldwide packaged this version, with Bill Mason as executive producer. This version used the same Whammy animations as the original, as well as a similar set (a Grundy tradition); however, the Big Board used considerably lower dollar values. Prior to this, there was an Australian version of "Second Chance" that aired in 1977 on Network Ten hosted by Earle Bailey and Christine Broadway and also produced by Grundy.
A German version entitled "Glück am Drücker" ("Good Luck on the Trigger") aired on RTLplus in 1992 with Al Munteanu as host. It had an animated vulture named "Raffi" steal cash and prizes from contestants instead of Whammies.
Another remake, "Drück Dein Glück" ("Push Your Luck"), aired daily in 1999 on RTL II with Guido Kellerman as host. And just like Glück am Drücker, Instead of Whammies, a shark named Hainz der Geldhai ("Hainz the Money Shark") "ate" the contestant's money. This version also had a unique rule where landing a car won the game automatically, regardless of the scores.
GMA Network aired a version called "Whammy! Push Your Luck" based on the short-lived 2002–03 GSN remake called "Whammy! The All-New Press Your Luck" from 2007 to 2008 hosted by Paolo Bediones and Rufa Mae Quinto. The program used the same (redubbed) Whammy animations as the 2000s updated American version.
A Taiwanese variety show called Slugger Attack aired a segment based on this game on Taiwan Television from 1985 to 1995. It used a naughty ghost instead of animated whammies.
A Turkish version of PYL called "Şansini Dene" ("Try Your Luck") aired on Kanal D from 1994 to 1996, hosted by Oktay Kaynarca.
An ITV version ran for two seasons from June 6, 1991 to September 20, 1992 on ITV in the HTV West region, with Paul Coia as host. The series was made on a small budget, using a point-based system with the day's winner receiving £200. This eliminated much of the excitement present in other versions, and declining ratings led to a switch from prime time to Saturday afternoons during the first season. When the show's second season premiered in 1992, it was moved to Sunday afternoons. The show was canceled following the second season due to budget cuts that resulted from the ITV franchise auctions, as well as lower ratings figures.
Merchandise.
In 1988, GameTek released a home computer game of "Press Your Luck" for IBM PC compatibles and the Commodore 64. Ludia Inc. (now part of RTL Group, which owns the show franchise) along with Ubisoft released an adaptation called "Press Your Luck: 2010 Edition" on October 27, 2009 for PC, iPhone, iPad, iPod Touch, Nintendo DS and Wii. Prior to this, on August 24, 2010, the game was released for the PlayStation 3 (via PSN) as part of the "Game Show Party" bundle pack (PS3 only) that also included "Family Feud: 2010 Edition" and "The Price is Right: 2010 Edition". and on PlayStation 3's PSN download service from August 24, 2010.
Shuffle Master was the first to develop a video slot machine version based on the show in 2000. It was also featured in the PC game "Reel Deal Casino: Shuffle Master Edition" in 2003. Currently, WMS Gaming develops video slot machines based on the show like the "Big Event" version with Todd Newton of Whammy! fame in 2008, a "Community Bonus" version in 2010 and a "3-reel mechanicals" in 2011. A now defunct online slot game was once developed for online UK casinos.
GSN featured a short-lived interactive version of "Press Your Luck" that featured a play-along element as rerun episodes of the show aired simultaneously.
A kiosk version debuted at Planet Hollywood in 2011.
In 2006, Imagination Entertainment released a DVD TV game hosted by Todd Newton of Whammy! The All-New Press Your Luck fame, with Peter Kent as the announcer. The DVD game included three Question Rounds and three Big Board Rounds.
An electronic handheld game was released by Irwin Toys in 2008.
Several U.S. states have included "Press Your Luck" scratcher games in their state lotteries.
In January 2012, an app developed by Fremantle subsidiary Ludia and based on "Press Your Luck" debuted on Facebook. Ten contestants compete in a single-question round together, all answering the same multiple-choice questions. There are six questions in total, each worth between $500 and $1,000, or a Whammy. A correct answer earns the question's value multiplied by the number of contestants who answered incorrectly or ran out of time (e.g., answering the $500 question correctly with three other contestants answering incorrectly earns $1,500). Bonus cash is given to the three contestants who answer the questions correctly in the shortest amount of time. Answering the Whammy question incorrectly causes the contestant to lose any money accumulated to that point.
The top three contestants go on to the big-board round, with each getting five spins. Gameplay is similar as on the 1980s series.
In September 2012, Ludia released "Press Your Luck Slots" on Facebook.
Ludia released an app version of "Press Your Luck" Slots for the iPhone, iPod Touch and iPad on April 22, 2013.

</doc>
<doc id="60912" url="https://en.wikipedia.org/wiki?curid=60912" title="Q (James Bond)">
Q (James Bond)

Q is a fictional character in the James Bond films and film novelizations. Q (standing for Quartermaster as well as a reference to the deceptive Q-ships), like M, is a job title rather than a name. He is the head of Q Branch (or later Q Division), the fictional research and development division of the British Secret Service.
Q has appeared in 21 of the 24 Eon Productions James Bond films, the exceptions being "Live and Let Die", the 2006 "Casino Royale" and "Quantum of Solace". The character was also featured in both non-Eon Bond films, the 1967 "Casino Royale" and "Never Say Never Again".
Novels.
The character Q never appears in Ian Fleming's novels, and only the Q Branch is mentioned; although Q does appear in the novelizations by Christopher Wood, and the later novels by John Gardner and Raymond Benson.
In John Gardner's novels, the post of Q is taken over by Ann Reilly (called Q'ute by her colleagues). She also forms a relationship with Bond. It is supposed that she held the post for a short while only, because Raymond Benson's novels return Boothroyd to the post without explanation.
Charles Fraser-Smith is widely credited as the inspiration for Q due to the spy gadgets he built for the Special Operations Executive. These were called Q-devices, after the Royal Navy's World War I Q-ships. In the Fleming novels there are frequent references to Q and Q Branch with phrases like "see Q for any equipment you need" ("Casino Royale") and "Q Branch would handle all of that" ("Diamonds Are Forever"), with a reference to "Q's craftsmen" in "From Russia with Love".
Major Boothroyd.
In the sixth novel, "Dr. No", the service armourer Major Boothroyd appears for the first time. Fleming named the character after Geoffrey Boothroyd, a firearms expert who lived in Glasgow, Scotland who had written to the novelist suggesting that Bond was not using the best firearms available.
Ann Reilly.
Boothroyd is also referenced occasionally in the Bond novels of John Gardner, but the author preferred instead to focus on a new character, Ann Reilly, who is introduced in the first Gardner novel, "Licence Renewed" and promptly dubbed "Q'ute" by Bond.
Films.
In the films, Major Boothroyd first appears in "Dr. No" and later in "From Russia with Love", although played by different actors. Desmond Llewelyn stated that though he was credited as playing "Major Boothroyd", the original line spoken by M, "Ask Major Boothroyd to come in" was replaced with "the armourer" as director Terence Young stated Boothroyd was a different character.
Beginning in Guy Hamilton's "Goldfinger" and in each film thereafter Major Boothroyd is most often referred to as Q; however, in "The Spy Who Loved Me" (1977) he is referred to once again as Major Boothroyd in dialogue.
In most films in which Q appears, he is restricted to a "behind the scenes" involvement, either based in London or in secret bases out in the field. Three notable exceptions in which Q becomes directly involved in Bond's missions occur in "Octopussy", in which Q actually participates in field work, including the final battle against the villain's henchmen, and "Licence to Kill" in which he joins Bond in the field after 007 goes rogue.
Also in "Spectre", aiding Bond to disappear, and out in the field.
Eon Productions.
Peter Burton: 1962.
In the first film, "Dr. No", Boothroyd is played by Peter Burton in only one scene in which he replaces Bond's .380 ACP Beretta M1934 pistol with the signature .32 Walther PPK handgun. He is referred to by M as "the armourer," and later as Major Boothroyd. Scheduling conflicts prevented Burton from reprising the role in "From Russia with Love".
Featured in
Desmond Llewelyn: 1963–1999.
Beginning with "From Russia with Love", Desmond Llewelyn portrayed the character in every official film except "Live and Let Die" until his death in 1999. In the 1977 film "The Spy Who Loved Me", as Q delivered the underwater Lotus, Major Anya Amasova/Agent XXX (Barbara Bach) greets Q as "Major Boothroyd".
While briefing Bond on the gadgets that he is going to use on his mission, Q often expresses irritation and impatience at Bond's wandering attention, often telling him to "pay attention, 007", and Bond's seemingly playful lack of respect for his equipment, telling the agent, "I "never" joke about my work, 007". In "Thunderball", Bond can be heard muttering "Oh no" when Q joins him in the Bahamas.
However, on occasion, Q has shown a warm and fatherly concern for 007's welfare, such as at Bond's wedding in "On Her Majesty's Secret Service", when he assures Bond that he is available if Bond ever requires his help despite Bond planning to leave MI6, and when, at the behest of Miss Moneypenny, he secretly sneaks gadgets out of MI6 to help Bond survive his vendetta against the drug tyrant Sanchez in "Licence to Kill". Arriving unannounced in Isthmus City (posing as Bond's uncle – similar to how he posed as Bond's father in "You Only Live Twice"), he flatly tells the agent, "If it hadn't been for Q Branch, you'd have been dead long ago" – to which Bond has no answer. Q has also assisted Bond in a more active role in his missions in "Octopussy", remaining to aid Bond in person even after another ally is killed. He frequently refers to Bond as "007", rather than by his name.
In "GoldenEye", Q shares a joke with Bond for the first time, and in "The World Is Not Enough" when he reveals his plan to retire, Bond is saddened at the prospect. Q signs off with "Now pay attention, 007," and then offers some words of advice:
"Q:" "I've always tried to teach you two things: First, never let them see you bleed.""Bond:" "And second?""Q:" "Always have an escape plan." – before he is lowered out of view.
This was the final film appearance of Desmond Llewelyn as Q in the James Bond series, although he would revive the role once again as Q in a Heineken commercial, a TV cross-promotion for "The World Is Not Enough". Llewellyn died in a car crash just weeks after the film's release. Between films he also starred as Q in various commercials for a diversity of products and companies. These included Bond collectable merchandise, TV3, Hyundai motorcars, LG video recorders, Highland Superstores, Visa credit cards, and Reach electric toothbrushes, the latter of which featured Q briefing himself in the mirror.
Featured in
Films:
Games:
Llewelyn also portrays Q in the Eon Productions-produced 1967 TV special "Welcome to Japan, Mr. Bond", as well as portraying Q in the documentary "Highly Classified: The World of 007", which is included on the "Tomorrow Never Dies" Ultimate Edition DVD. Llewelyn's likeness was also used to portray the Q character in 2005's video game "", though the voice of Q was portrayed by Phil Proctor. Llewelyn has appeared in more Bond films — seventeen — than any other actor to date.
John Cleese: 2002.
In "The World Is Not Enough" an assistant to Q was introduced, played by John Cleese. His real name was never revealed, but he was initially credited as R in "The World Is Not Enough", stemming from a joke in which Bond asks the elder Q: "If you're Q, does that make him R?"
Between films, Cleese was still referred to as "R" in the video games "The World is Not Enough" (2000), "007 Racing" (2000) and "Agent Under Fire" (2001), though not all of the video games are canonical. He was officially referred to as "Q" in "Die Another Day" (2002) following actor Llewelyn's death in 1999. In 2004, Cleese was featured as Q in the video game "".
Initially portrayed as rather clumsy, R then became more self-assured and more in the style of his predecessor. They both shared the same attitude towards their professional work, requesting that Bond be more careful in the testing laboratories and return his equipment intact. In "Die Another Day", Bond at first refers to R as "Quartermaster" but, silently impressed by the gadgets he is given, calls him "Q" at the end of their meeting. (The "Die Another Day" DVD reveals that Bond initially saw R as an 'interloper', only awarding the proper title of 'Q' after R has proven himself.)
According to an interview on the "Die Another Day" DVD, Pierce Brosnan was very glad to rename Cleese's character 'Q', rather than 'R', because his native Irish accent made it difficult to pronounce 'R' with a convincing English accent.
In the 007 game, "Everything or Nothing", Cleese's Q has an assistant, Miss Nagai, portrayed by Misaki Ito.
Featured in
Films:
Games:
In the 2010 video game "", Major Boothroyd is not seen, but it is mentioned that Bill Tanner works for Q Branch.
Ben Whishaw: 2012–.
The character of Q did not appear in 2006's "Casino Royale" or its sequel, "Quantum of Solace" (2008). Bond actor Daniel Craig expressed concern over the character's absence, and expressed his hope that Q would return in "Skyfall". In November 2011, it was announced that British actor Ben Whishaw had been cast in the role. Whishaw, aged 31 in 2012, became the youngest actor to play the role. In "Skyfall", Q's gadgets were comparatively simple, consisting of a miniaturised radio and a gun coded to Bond's palmprint so only Bond could fire it. Q is demonstrated to be highly knowledgeable on the subject of computer security to the point where he designed some of the most sophisticated security protocols in existence. He shows disdain for field agents, believing their particular skill sets to be secondary to his own, but does acknowledge their usefulness under certain circumstances. However, he is also somewhat short-sighted; while engrossed in the puzzle of a security system set up by Raoul Silva, the film's main antagonist, he is unaware that he is inadvertently facilitating Silva's escape from MI6 custody until Silva actually escapes. Whishaw returns as Q in "Spectre", assisting 007 on his mission, similar to Q's assistance to Bond in 1989's "Licence to Kill". Q meets 007 in Austria where he outruns Spectre agents after a ring he eventually decodes, revealing the organization's existence. Q returns to London to assist Moneypenny and M in foiling Max Denbeigh's launch of the Nine Eyes intelligence network. At the end he provides Bond with his remodeled Aston Martin DB5.
Featured in Films:
Non-Eon films.
Geoffrey Bayldon: 1967.
In the 1967 version of "Casino Royale", Q is portrayed by Geoffrey Bayldon, but instead of outfitting James Bond, he provides gadgets for Evelyn Tremble (who is portrayed by Peter Sellers). In the film, Q is assisted by Fordyce (John Wells).
Featured in
Alec McCowen: 1983.
In the 1983 film "Never Say Never Again", Q Branch is headed by a man (played by Alec McCowen) referred to by Bond as Algernon and Algy, though his opening line is "Nice to know old Q can still surprise you 00s." In the closing credits, he is named as "Q Algy". Q Branch itself is depicted as underfunded and ramshackle compared to the high-tech surroundings of the Eon films. He also has a very different attitude to other Q's, by commenting that it had been very dull without Bond, and now that he is back, hopes that there will be "plenty of gratuitous sex and violence".
Featured in

</doc>
<doc id="60913" url="https://en.wikipedia.org/wiki?curid=60913" title="Stigmergy">
Stigmergy

Stigmergy is a mechanism of indirect coordination, through the environment, between agents or actions. The principle is that the trace left in the environment by an action stimulates the performance of a next action, by the same or a different agent. In that way, subsequent actions tend to reinforce and build on each other, leading to the spontaneous emergence of coherent, apparently systematic activity.
Stigmergy is a form of self-organization. It produces complex, seemingly intelligent structures, without need for any planning, control, or even direct communication between the agents. As such it supports efficient collaboration between extremely simple agents, who lack any memory, intelligence or even individual awareness of each other.
History.
The term "stigmergy" was introduced by French biologist Pierre-Paul Grassé in 1959 to refer to termite behavior. He defined it as: "Stimulation of workers by the performance they have achieved." It is derived from the Greek words στίγμα "stigma" "mark, sign" and ἔργον "ergon" "work, action", and captures the notion that an agent’s actions leave signs in the environment, signs that it and other agents sense and that determine and incite their subsequent actions.
Later on, a distinction was made between the stigmergic phenomenon, which is specific to the guidance of additional work, and the more general, non-work specific incitation, for which the term "sematectonic" communication was coined by E. O. Wilson, from the Greek words σῆμα "sema" "sign, token", and τέκτων "tecton" "craftsman, builder": "There is a need for a more general, somewhat less clumsy expression to denote the evocation of any form of behavior or physiological change by the evidences of work performed by other animals, including the special case of the guidance of additional work."
Stigmergy is now one of the key concepts in the field of swarm intelligence.
Stigmergic behavior in lower organisms.
Stigmergy was first observed in social insects. For example, ants exchange information by laying down pheromones (the trace) on their way back to the nest when they have found food. In that way, they collectively develop a complex network of trails, connecting the nest in the most efficient way to the different food sources. When ants come out of the nest searching for food, they are stimulated by the pheromone to follow the trail towards the food source. The network of trails functions as a shared external memory for the ant colony.
In computer science, this general method has been applied in a variety of techniques called ant colony optimization, which search for solutions to complex problems by depositing "virtual pheromones" along paths that appear promising.
Other eusocial creatures, such as termites, use pheromones to build their complex nests by following a simple decentralized rule set. Each insect scoops up a 'mudball' or similar material from its environment, invests the ball with pheromones, and deposits it on the ground, initially in a random spot. However, termites are attracted to their nestmates' pheromones and are therefore more likely to drop their own mudballs on top of their neighbors'. The larger the heap of mud becomes, the more attractive it is, and therefore the more mud will be added to it (positive feedback). Over time this leads to the construction of pillars, arches, tunnels and chambers.
Stigmergy has even been observed in bacteria, various species of which differentiate into distinct cell types and which participate in group behaviors that are guided by sophisticated temporal and spatial control systems. Spectacular examples of multicellular behavior can be found among the myxobacteria. Myxobacteria travel in "swarms" containing many cells kept together by intercellular molecular signals. Most myxobacteria are predatory: individuals benefit from aggregation as it allows accumulation of extracellular enzymes which are used to digest prey microorganisms. When nutrients are scarce, myxobacterial cells aggregate into "fruiting bodies", within which the swarming cells transform themselves into dormant myxospores with thick cell walls. The fruiting process is thought to benefit myxobacteria by ensuring that cell growth is resumed with a group (swarm) of myxobacteria, rather than isolated cells. Similar life cycles have developed among the cellular slime molds. The best known of the myxobacteria, "Myxococcus xanthus" and "Stigmatella aurantiaca", are studied in various laboratories as prokaryotic models of development.
Analysis of human behavior.
Stigmergy studied in eusocial creatures and physical systems, has been proposed as a model of analyzing some robotics systems, multi-agent systems, communication in computer networks, and online communities.
On the Internet there are many collective projects where users interact only by modifying local parts of their shared virtual environment. Wikipedia is an example of this. The massive structure of information available in a wiki, or an open source software project such as the FreeBSD kernel could be compared to a termite nest; one initial user leaves a seed of an idea (a mudball) which attracts other users who then build upon and modify this initial concept, eventually constructing an elaborate structure of connected thoughts.
In addition the concept of stigmergy has also been used to describe how cooperative work such as building design may be integrated. Designing a large contemporary building involves a large and diverse network of actors (e.g. architects, building engineers, static engineers, building services engineers). Their distributed activities may be partly integrated through practices of stigmergy.
Analysis of human social movements.
The rise of Open Source software in the 21st century has disrupted the business models of some proprietary software providers, and Open content projects like Wikipedia have threatened the business models of companies like Britannica. Researchers have studied collaborative open source projects, arguing they provide insights into the emergence of large-scale peer production and the growth of gift economy. 
Stigmergy also occurs with social movements, such as the arc from Wikileaks’ cable release in Summer 2010 to the developments in global Occupy movement. The Occupy movement itself operates stigmergically, with innovations developed by one node becoming part of the total movement’s common toolkit.
Stigmergic society.
Heather Marsh, associated with the Occupy Movement, Wikileaks, and Anonymous, has proposed a new social system where competition as a driving force would be replaced with a more collaborative society. This proposed society would not use representative democracy but new forms of governance generated by user groups and collaborative methods including stigmergy. "With stigmergy, an initial idea is freely given, and the project is driven by the idea, not by a personality or group of personalities. No individual needs permission (competitive) or consensus (cooperative) to propose an idea or initiate a project."
The Hong Kong Umbrella Movement in 2014 were quoted recommending stigmergy as a way forward. 

</doc>
<doc id="60915" url="https://en.wikipedia.org/wiki?curid=60915" title="M. A. R. Barker">
M. A. R. Barker

Muhammad Abd-al-Rahman Barker (born Phillip Barker, November 3, 1929 – March 16, 2012), was a professor of Urdu and South Asian Studies who created one of the first roleplaying games, Empire of the Petal Throne, and wrote several fantasy/science fantasy novels based in his associated world setting of Tékumel.
Early life.
Born in Spokane, Washington, descended from ancestors who had originally settled in America in 1626, Barker's childhood was spent around Washington and Idaho. As a youth he had an interest in "fairy stories, history and literature" which would be further influenced by such films as "The Thief of Bagdad"; all of which helped to turn his casual "wargames" with toy soldiers more towards fantasy. From this his fictional lands of Tsolyanu and others, in what was later to become Tékumel, emerged and were embellished further in middle and high school years during which time he commenced construction of armies of hand-carved figures to represent his creations. Also at an early age, Barker's interest in languages was piqued by neighboring children of Basque origin who were able to exclude others from their secret conversations in their native tongue.
Academic life and creative networking.
In, and just before 1950, while Barker was studying at the University of Washington under Melville Jacobs, he became involved with small press publications, writing articles, short stories and contributing reviews to "Fanscient" and the local clubzine "Sinisterra"; the latter of which contained his review of, and content from, Jack Vance relating to his recently published book, "The Dying Earth". Also at this time, Barker corresponded with other authors who contributed to those same publications, including Lin Carter in whose writings and linguistic experiments he took an interest and with whom he finally put to paper the story line of his own created world.
He received a Fulbright Scholarship in 1951 to study Indian languages and on his first trip to India that year converted to Islam; "for purely theological reasons. It seemed like a more logical religion", according to Fine, although Barker himself admitted at the time to an " feeling of awe and religious ecstasy" upon hearing the recitations of the 99 Names of Allah at the Taj Mahal.
Later academic studies and career.
Barker attended the University of California, Berkeley for graduate studies, writing a dissertation on Klamath language, collecting traditional myths, legends, tales, and oral histories and later publishing a grammar and dictionary on the language.
He taught at the Institute of Islamic Studies at McGill University from around 1958/9 until 1972 and became active in the development of Urdu and Baluchi instruction materials for English-speaking students following a period of two years from 1960 when he was attached to Panjab University. Some of these are still recommended university course study materials as of 2010. From 1972 he moved to teach at the University of Minnesota in Minneapolis, where he chaired the Department of South Asian studies until his retirement in the early 1990s, a few years after that department was disbanded due to reduced funding.
"The forgotten Tolkien".
While at Berkeley, Barker had not set aside his world creation project. Indeed, despite stepping back somewhat from an active role in the published science fiction/fantasy fandom, he had commenced "proto-gaming" with a group of like-minded science fiction fans including fellow linguist Bill Shipley and Victor Golla, producing elaborate documents to support the exploration of that shared world.
Having watched the "Dungeons & Dragons" games started by Mike Mornard, one of the original testers for D&D, when he moved to Minneapolis from Lake Geneva, Barker resolved to create his own ruleset based on his own created world and the game mechanics from D&D. After six weeks, this was self-published in August 1974 as Empire of the Petal Throne and play commenced forthwith, including such occasional members as Dave Arneson - who singled out Barker and Tekumel as being his favorite GM and roleplaying game, respectively - from early days.
Once Gary Gygax's attention had been drawn to Barker's work, it was decided that TSR would publish a revised version of the game mechanics along with a condensed version of his campaign setting. TSR's "Empire of the Petal Throne" was published in 1975 for Gen Con VIII, making it TSR's third role-playing game to be published. In a Dragon Magazine editorial from December, 1976, editor Tim Kask drew comparisons between the world of Tékumel and J. R. R. Tolkien's Middle-earth not in terms of literature created, nor that his work was derivative of Tolkien's (being well-advanced by the time "The Lord of the Rings" was released), but rather regarding the in-depth detail in the setting, mythos and linguistic backgrounds and concluded that "In terms of development of detail, I think EPT of the Petal Throne has it over Middle Earth in the matters that most concern gamers" since it had been developed by a "wargamer", whereas Tolkien had no such background and having died prior to the release of D&D was thus unable to address this new pastime personally.
Barker disliked the limited support given to the setting, and after 1977 he took his world of Tékumel from TSR and ultimately moved it on to a succession of additional publishers: Imperium Publishing (1978), Adventure Games (1981), Gamescience (1983-1984), Tékumel Games (1983-1986), Different Worlds Publications (1987-1988), TOME (1991-1994), Tita's House of Games (1997-2002), Zottola Publishing (2002-2003) and Guardians of Order (2005). Due to Dave Arneson's personal friendship with Barker, Adventures Games released several Tékumel related books, including army lists, maps and other general reference material. Barker's RPG novel "The Man of Gold" (July, 1984), was set in Tekumel and published by DAW.
Despite having had a head start on other in-depth campaign settings and seeing his game released no less than four times with various supplements and magazine articles, many which he contributed to, and having authored five books using the same setting, Barker's Tékumel in both roleplaying and literary domains is still well known to only a relatively small audience, leading German magazine Der Spiegel in 2009 to publish an article on Barker's life entitled "Der vergessene Tolkien" ("The forgotten Tolkien"). The article quotes friends and acquaintances who posit that this may be, at least in part, due to the unfamiliarity of the setting compared with Western society, echoing Fine's observations from 1983, and possibly even that Tékumel was released to the gaming world too early on, when players had only just started to experiment with their own invented worlds rather than fitting their play into pre-configured, non-literary domains with novel backgrounds.
In 2008, Barker founded the Tékumel Foundation along with many of his long-time players, to preserve and manage rights relating to his creations in future.
Barker died in home hospice on March 16, 2012. He is survived by his wife, Ambereen.
Partial bibliography.
Language Texts.
Barker studied various languages academically and helped author and co-author various publications relating to some of those, including the following:
Published by the University of California Press:
Published by the McGill University Institute of Islamic Studies:
Roleplaying.
Tékumel has spawned five professionally published roleplaying games over the course of the years. It was also reportedly a major influence on other creations such as "Hârn" and the "Skyrealms of Jorune".
Novels.
Barker has written five novels set in the world of Tékumel - in chronological reading order these are:

</doc>
<doc id="60917" url="https://en.wikipedia.org/wiki?curid=60917" title="Lola Ridge">
Lola Ridge

Lola Ridge, born Rose Emily Ridge (12 December 1873 Dublin – 19 May 1941 Brooklyn) was an Irish-American anarchist poet and an influential editor of avant-garde, feminist, and Marxist publications. She is best remembered for her long poems and poetic sequences, published in numerous magazines and collected in five books of poetry. Along with other political poets of the early Modernist period, Ridge has received renewed critical attention since the beginning of the 21st century and is praised for making poetry directly from harsh urban life. A new selection of her poetry was published in 2007 and a biography in 2016.
Early life and marriages.
She was born Rose Emily Ridge in 1873 in Dublin, Ireland to Joseph Henry and Emma (Reilly) Ridge and was their only surviving child. When Rose was 13, her mother emigrated with her to New Zealand, where Emma later married a Scottish miner. Rose Ridge became politically active there. In 1895, while living in New Zealand, Rose Ridge married the manager of a gold mine. After they divorced, she moved to Sydney, attending Trinity College and also studying painting at Académie Julienne with Rossi Ashton.
Ridge emigrated to the United States after her mother died, settling first in San Francisco in 1907. There she identified as Lola Ridge, a poet and painter. She had her first poem published in the US in 1908 in "Overland Monthly".
She later moved to New York, settling in Greenwich Village. After supporting herself writing ad copy, she left that to focus on her poetry. Working as a model and in a factory, she became involved in working class politics and protests. Peter Quartermain described her in the "Dictionary of Literary Biography" described her as "the nearest prototype in her time of the proletarian poet of class conflict, voicing social protest or revolutionary idealism."
Lola Ridge's first book of poetry was published in 1918. On 22 October 1919, she married David Lawson, a fellow radical.
Literary career.
After living for some time in New York, Ridge gained considerable notice with her long poem, "The Ghetto", first published in 1918 in "The New Republic". It was included in her first book, "The Ghetto and Other Poems," published that year. The title poem portrays the Jewish immigrant community of Hester Street in the Lower East Side of New York. It explores the effects of capitalism, gender and generational conflict in ways that bear comparison to the works of Charles Reznikoff. But she also expressed the individuality of numerous immigrants, to show they were as various as other Americans and shared many human qualities. The book was a critical success.
This recognition led to opportunities for Ridge; she became involved with and edited new "avant-garde" magazines such as "" in 1919, and "Broom," founded in 1921 by Harold Loeb, for which she was the American editor from 1922–1923, while he published in Rome. While working with Loeb, she had an apartment next to the basement office of "Broom" in the townhouse of his estranged wife Marjorie Content.
Ridge published 61 poems from 1908 to 1937 in such leading magazines as "Poetry," "New Republic," and "The Saturday Review of Literature". She was a contributing editor to "The New Masses."
She wrote and published four more books of poetry through 1935, and single poems into 1937. Her work was also collected in anthologies. Her third book, "Red Flag" (1927) collected much of her political poetry.
In 1929, Ridge was accepted for a residency at the writers colony of Yaddo. That year she published "Firehead", a long poem that was a radical retelling of Jesus' crucifixion. It and her last book, published in 1935 were more philosophical compared to her earlier work.
She was awarded a Guggenheim Fellowship in 1935. She received the Shelley Memorial Award by the Poetry Society of America for the years 1934 and 1935. Publishing until 1937, she died in 1941 of pulmonary tuberculosis.
Political activities.
Ridge did not join any political party, but was active in radical causes. She protested against the executions of Sacco and Vanzetti in 1927, and was among those arrested that day. In the 1930s, she supported the defence of Tom Mooney and Warren Billings, who had been framed for a 1916 bombing at the Preparedness Day Parade in San Francisco.
21st-century Appreciation.
With renewed scholarly interest in her work since the late 20th century, a selection of her first three books of poetry was published posthumously as "Light in Hand: Selected Early Poems" (2007), edited and with an introduction by Daniel Tobin. He notes that she is "part of the confluence of politics, culture and the burgeoning of women's voices at the advent of modernism to the start of World War II."
Robert Pinsky, former Poet Laureate of the United States, wrote that contemporary readers needed "to appreciate the magnitude and freshness of her enterprise: to make poetry out of the actual city." He likens her to 18th-century British poet William Blake in her ability to express the perspective of children, evoking "innocence and experience in a way that blurs the ambiguous boundary between them." Pinsky also notes that Ridge preceded American Hart Crane, known for his long poem "The Bridge" about the Brooklyn Bridge, in her assigning "ecstatic, high language of the past, especially of the Elizabethans, to the squalid and the sublime realities of the actual, 20th-century American city."

</doc>
<doc id="60918" url="https://en.wikipedia.org/wiki?curid=60918" title="Scottish Football League">
Scottish Football League

The Scottish Football League (SFL) was a league featuring professional and semi-professional football clubs mostly from Scotland. From its foundation in 1890 until the breakaway Scottish Premier League (SPL) was formed in 1998, the SFL represented the top level of football in Scotland. After 1998, the SFL represented levels 2 to 4 of the Scottish football league system. In June 2013, the SFL merged with the SPL to form the Scottish Professional Football League.
The SFL was associated with a title sponsor from the 1985–86 season. As this sponsor has changed over the years the league was known in turn as the Fine Fare League, B&Q League, Bell's Scottish Football League and finally as the Irn-Bru Scottish Football League. The SFL also organised two knock-out cup competitions, the Scottish League Cup and the Scottish Challenge Cup.
History.
Formation.
Organised football in Scotland began in 1873 with the formation of the Scottish Football Association (SFA). During the next 15 years or so, clubs would play friendly matches, Scottish Cup ties and local cup (e.g. Glasgow Cup or East of Scotland Shield) ties. The Football League, initially containing clubs from the North West and Midlands of England, was formed in 1888. This had been done in response to the professionalisation of football in England in 1885, with the regular diet of league fixtures replacing the haphazard arrangement of friendlies. Many Scottish players, known as the Scotch Professors, moved to the English league clubs to receive the relatively high salaries on offer.
This prompted Scottish clubs into thinking about forming their own league. In March 1890, the secretary of Renton wrote to thirteen other clubs inviting them to discuss the organisation of a league. All of the clubs accepted the invitation, except Queen's Park and Clyde. Amateur club Queen's Park, who were the oldest organised club in Scotland and had played a key role in the development of football, were opposed to the league because it would lead to professionalism and eliminate many of the smaller clubs. These concerns were to prove well-founded, as six of the founder members would leave the league before 1900.
The Scottish Football League (SFL) was inaugurated on 30 April 1890. The first season of competition, 1890–91, commenced with 11 clubs because St Bernard's were not elected. The eleven original clubs in membership were Abercorn, Cambuslang, Celtic, Cowlairs, Dumbarton, Heart of Midlothian, Rangers, Renton, St Mirren, Third Lanark and Vale of Leven. Renton were expelled after five games of the 1890–91 season for playing against St Bernard's, who had been found guilty of concealed professionalism. Renton raised an action against the SFA in the Court of Session and won, which meant that their SFA and SFL memberships were restored.
In the 1890–91 season, Rangers and Dumbarton were level at the top of the league on 29 points. The teams drew 2–2 in a play-off match, but no further thought had been given to separating teams by another method and the championship was shared. Goal average was introduced for the 1921–22 season and replaced by goal difference for the 1971–72 season.
Split into divisions.
The league proved to be highly successful, and in 1893 a Second Division was formed by the inclusion of a number of clubs previously in the Scottish Football Alliance. Promotion was initially based on a ballot of clubs; automatic promotion was not introduced until 1922.
The onset of World War I saw the Second Division but not the First Division being suspended, not restarting again until 1921 when the Central Football League was absorbed as a new division with automatic promotion.
Third division.
In 1923, the League decided to introduce a Third Division. The Western Football League (in Scotland) was used as its backbone but the new set-up lasted only three years before it collapsed under heavy financial losses.
From 1926 until 1946, the League returned to two divisions. Post-World War II reforms saw the League resume with three divisions.
Postwar seasons saw the divisions renamed 'A', 'B' and 'C' with the last section also including reserve sides. In 1949, the 'C' Division was expanded to two sections – North-West and South-East. The withdrawal of the reserves from 'C' Division in 1955 saw a return to two divisions with the five first teams in Division C being given automatic promotion. There were then 18 clubs in Division A and 19 in Division B. In 1956 the divisions were renamed Division 1 and Division 2.
Clydebank were elected to Division 2 as the 20th club in 1966, but following the demise of Third Lanark in 1967, the Second Division kept operating with just 19 clubs; the situation would not be corrected until the next change of format, which happened in 1975.
This change of structure split the league into three divisions, Premier, First, and Second Divisions. This permitted more frequent fixtures between the top clubs; the expectation was that meant greater revenue for them, and it was hoped it would stimulate greater interest, at a time when attendance at league matches had dropped alarmingly. A new club entered the league, Meadowbank Thistle, but would eventually become Livingston in 1995. This three-divisional structure (of 38 clubs) continued until 1994.
Four-division period and SPL split.
After a couple of decades, the league again reorganised, with four divisions of 10 clubs, as Inverness Caledonian Thistle and Ross County were elected to round out the league. At the same time, the SFL adopted the system of three points for a win. In 1998 the Premier Division clubs split from the league to form the Scottish Premier League (SPL). The remaining leagues, of ten clubs each, kept their names and the Premier Division was not reconstituted, leaving First, Second and Third Divisions. Part of the agreement was that the SPL would expand to 12 clubs in 2000. The SFL then took in two new members to replace the two clubs lost to the SPL. Highland League clubs Elgin City and Peterhead were admitted, increasing the total number of clubs in the Scottish football league system to 42.
From 2005, the SFL determined a promotion and relegation place between each division according to playoffs between four clubs. The playoffs were contested between the ninth placed (second bottom) club in the higher division and the second, third and fourth placed clubs in the lower division. It was therefore possible for a team finishing fourth in the Second Division or Third Division to be promoted, rather than the clubs finishing immediately above them in the standings. It was also possible for the ninth placed club to retain their position in the higher division.
In March 2007, a self-conducted review found the league to be three times more expensive to run than equivalent leagues in England, with a report stating the league structure was "outdated". The report found that the Football Conference has four employees looking after 68 clubs, while the SFL had 14 people running leagues with just 30 clubs.
Merger.
No clubs were relegated from the bottom end of the Scottish Football League, although there were changes of membership due to clubs going out of business. The Scottish Football Association were keen for a pyramid system to be instituted. SFL First Division clubs wanted to gain a greater share of the media revenue generated by the SPL. In 2013, both the SPL and SFL voted in favour of merging to form the new Scottish Professional Football League. The number of divisions and clubs in each division remained the same, but there were changes to the financial distribution model.
Cup competitions.
The Scottish Football League organised two knock-out cup competitions: the Scottish League Cup and the Scottish Challenge Cup. The League Cup was established in 1946, succeeding the wartime Southern League Cup. Unlike the Scottish Cup, organised by the Scottish Football Association, the League Cup was only open to Scottish Football League clubs. Scottish Premier League clubs continued to participate in the League Cup after the top tier clubs broke away in 1998. Until the mid-1990s, the competition winner was eligible to participate in the UEFA Cup, but this was discontinued due to a loss of European places.
The Scottish Challenge Cup was instituted in 1990, to celebrate the League's centenary. The Challenge Cup was only open to Scottish Football League clubs outside the top division of the Scottish football league system. From 2011, two Highland Football League clubs were allowed to participate each year in the Challenge Cup, to give a round number of 32 clubs participating. Both the League Cup and the Challenge Cup continued under the auspices of the Scottish Professional Football League.
League sponsorship and media rights.
From 1985, the League accepted sponsorships for its main competition. Below is a list of sponsors and the League's name under their sponsorship:
The League's cup competitions have had different sponsors, with the Scottish League Cup first attracting sponsorship in 1979. The competition was revamped in 1984, adopting a straight knock-out format, when Skol Lager began its sponsorship. The Co-operative Insurance company sponsored the League Cup for 12 seasons, until the 2010–11 competition. It has since been sponsored by the Scottish Government, under the name of the "Scottish Communities League Cup". The Scottish Challenge Cup was created by League sponsor B&Q in 1990, but it was cancelled in 1998–99 due to a lack of sponsorship. Since 2008, the Challenge Cup has attracted its own sponsor, with BBC Alba and Ramsdens providing support.
Before 1979, the major source of revenue to Scottish Football League clubs, apart from their attendances, was from the football pools. In the year ended 31 March 1983, the pools generated £1.08 million out of a total of £1.46 million. By 1990, this source of income had been overtaken by revenue from sponsorships and television rights. As of 1990, 75% of these central revenues were split equally between the 38 member clubs, with the remaining 25% allocated according to each club's position in the league ladder. During the 1970s and 1980s, the main terrestrial television companies (STV and BBC Scotland) produced shows ("Scotsport" and "Sportscene" respectively) containing highlights of league matches. The revenues from these broadcasts were relatively small, with the companies paying less than £1000 per match in the mid-1970s. BBC Radio Scotland had exclusive rights for live radio coverage of matches at this time, with independent stations such as Radio Clyde providing coverage via score updates and analysis.
The first live television broadcast of a Scottish league match was not until April 1986. Earlier in the 1985–86 season, there had been no television coverage at all due to a dispute between the League and the broadcasters. The birth of satellite broadcaster British Sky Broadcasting (Sky TV) changed the situation significantly. As ITV had an exclusive contract for live coverage of games in the English league, the first match shown on Sky was a Scottish Premier Division match between Rangers and Dundee United in April 1991. A year later, the top division English clubs formed a breakaway Premier League, signing an exclusive television contract with Sky. Live Scottish Premier Division games were shown on STV during the 1990s, but the top division clubs formed the breakaway Scottish Premier League in 1998 and signed an exclusive broadcast contract with Sky.
This left the remaining Scottish Football League clubs without live coverage, although STV continued to show highlights of First Division games in their "Football First" show. Scots Gaelic channel BBC Alba provided coverage of Scottish Football League games, including the Challenge Cup, from its launch in 2008. Live coverage on English language channels returned to Scottish Football League games in the 2012–13 season, as Sky and ESPN agreed contracts to show Third Division matches involving Rangers. These arrangements secured revenues that had been under threat due to the financial collapse of Rangers.
Member clubs.
Of the original SFL clubs, Celtic, Heart of Midlothian, St Mirren, Dumbarton and Rangers are the only clubs today playing in the successor Scottish Professional Football League. Every other club is either defunct or out of the League.
Past winners.
When the Scottish Football League was established in 1890, all of the clubs played in just one division. In 1893 the Scottish Football League absorbed many clubs from the Scottish Football Alliance and had enough clubs to form another division. The existing division was renamed the First Division and the new division was called the Second Division. Nevertheless, promotion and relegation between the top two divisions was not automatic until 1921–22 when the Second Division was brought back after a hiatus provoked by World War I which affected only that division; hence some teams of the era winning the Second Division twice in a row before being promoted, and some Second Division winners being never promoted at all.
A third tier of Scottish league football was first established in the 1923–24 season, but it only lasted for two full seasons due to financial difficulties. A third tier league (called Division C) was reintroduced in 1946–47. Division C, which also included reserve teams of higher division clubs, operated as a national competition for the first three seasons but thereafter it was split into two regional sections. During this period only full-strength clubs (not reserve teams) were promoted if they finished as champions. The two-division tier was abolished after the 1954–55 season.
Since the 1975–76 season there has been a third tier, known as the Second Division. The top tier became the Premier Division and the second tier became known as the First Division. A fourth tier, known as the Third Division, was introduced in 1994. The last major change within the Scottish football league system was in 1998–99, when the Premier Division clubs broke away from the Scottish Football League to form the Scottish Premier League. The remaining Scottish Football League divisions continued as before.
Scottish Football League XI.
The SFL was the organising body of the Scottish Football League XI, a select side which represented the SFL in matches against other leagues, including The Football League, the League of Ireland, the Irish league and the Italian league. These matches began in 1892, soon after the foundation of the SFL. Before the Second World War, inter-league matches were only second in importance to Scotland international matches. After the war, however, the inter-league matches became less important as European club football was instituted and clubs withdrew players due to fixture congestion. The last inter-league match was played in 1980, while a Scottish Football League XI was last selected in 1990 for a match against Scotland, to mark the centenary of the SFL.

</doc>
<doc id="60919" url="https://en.wikipedia.org/wiki?curid=60919" title="University of London">
University of London

The University of London is a collegiate research university located in London, England, consisting of 18 constituent colleges, 10 research institutes and a number of central bodies.
The university is the second largest university by number of full-time students in the United Kingdom, with campus-based students and over 50,000 distance learning students in the University of London International Programmes. The university was established by Royal Charter in 1836, as a degree-awarding examination board for students holding certificates from University College London (previously called London University) and King's College London and "other such other Institutions, corporate or unincorporated, as shall be established for the purpose of Education, whether within the Metropolis or elsewhere within our United Kingdom". The university moved to a federal structure in 1900.
For most practical purposes, ranging from admissions to funding, the constituent colleges operate on a semi-independent basis, with some recently obtaining the power to award their own degrees whilst remaining in the federal university. The nine largest colleges of the university are King's College London; University College London; Birkbeck; Goldsmiths; the London Business School; Queen Mary; Royal Holloway; SOAS; and the London School of Economics and Political Science. The specialist colleges of the university include Heythrop College, specialising in philosophy and theology, and St George's, specialising in medicine. Imperial College London was formerly a member before it left the University of London in 2007. On 16 July 2015 it was announced that City University London would join the federal University of London, becoming one of its constituent colleges from August 2016.
Many notable individuals have passed through the university, either as staff or students, including at least 4 monarchs, 52 presidents or prime ministers, 74 Nobel laureates, 6 Grammy winners, 2 Oscar winners and 3 Olympic gold medalists.
In post-nominals, the University of London is commonly abbreviated as Lond. or, more rarely, Londin., from the Latin "Universitas Londiniensis" after their degree abbreviations.
History.
19th century.
University College London (UCL) was founded under the name London University in 1826 as a secular alternative to the religious universities of Oxford and Cambridge. In response to the theological controversy surrounding such educational establishment, King's College London (KCL) was founded and was the first to be granted a royal charter (in 1829).
Yet to receive a royal charter, UCL in 1834 renewed its application for a royal charter as a university (originally applied for in 1830), which would grant it the power to confer degrees. In response to this, opposition to "exclusive" rights grew among the London medical schools. The idea of a general degree awarding body for the schools was discussed in the medical press. and in evidence taken by the Select Committee on Medical Education. However, the blocking of a bill to open up Oxford and Cambridge degrees to dissenters led to renewed pressure on the Government to grant degree awarding powers to an institution that would not apply religious tests, particularly as the degrees of the new University of Durham were also to be closed to non-Anglicans.
In 1835, the Government announced the response to UCL's petition for a charter. Two charters would be issued, one to UCL incorporating it as a college rather than a university, without degree awarding powers, and a second "establishing a Metropolitan University, with power to grant academical degrees to those who should study at the London University College, or at any similar institution which his Majesty might please hereafter to name".
Following the issuing of its charter on the 28th November 1836, the University started drawing up regulations for degrees in March 1837. Unfortunately the death of William IV in June threw up a problem – the charter had been granted "during our Royal will and pleasure", meaning it was annulled by the King's death. Queen Victoria issued a second charter on 5 December 1837, reincorporating the University. The University awarded its first degrees in 1839, all to students from UCL and KCL.
The university established by the charters of 1836 and 1837 was essentially an examining board with the right to award degrees in Arts, Laws and Medicine. However, the university did not have the authority to grant degrees in theology, considered the senior faculty in the other three English universities. In medicine, the university was given the right to determine which medical schools provided sufficient medical training. In Arts and Law, by contrast, it would examine students from UCL, King's College, or any other school or college granted a royal warrant, effectively giving the government control of which colleges could affiliate to the university. Beyond the right to submit students for examination, there was no other connection between the affiliated colleges and the university.
In 1849 the University held its first graduation ceremony at Somerset House following a petition to the Senate from the graduates, who had previously received their degrees without any ceremony. About 250 students graduated at this ceremony. The London academic robes of this period were distinguished by their "rich velvet facings".
The list of affiliated colleges grew by 1858 to include over 50 institutions, including all other British universities. In that year, a new charter effectively abolished the affiliated colleges system by opening up the examinations to everyone whether they attended an affiliated college or not. This led the Earl of Kimberley, a member of the university's senate, to tell the House of Lords in 1888 "that there were no Colleges affiliated to the University of London, though there were some many years ago". The reforms of 1858 also incorporated the graduates of the university into a convocation, similar to those of Oxford, Cambridge and Durham, and authorised the granting of degrees in science, the first BSc being awarded in 1860.
The expanded role meant the university needed more space, particularly with the growing number of students at the provincial university colleges. Between 1867 and 1870 a new headquarters was built at 6 Burlington Gardens, providing the university with exam halls and offices.
In 1863, via a fourth charter, the university gained the right to grant degrees in surgery. This 1863 charter remains the authority under which the university is incorporated, although all its other provisions were abolished under the 1898 University of London Act.
In 1878, the university set another first when it became the first university in the UK to admit women to degrees, via the grant of a supplemental charter. Four female students obtained Bachelor of Arts degrees in 1880 and two obtained Bachelor of Science degrees in 1881, again the first in the country.
In the late 19th century, the University came under criticism for merely serving as a centre for the administration of tests, and there were calls for a "teaching university" for London. UCL and KCL considered separating from the University to form a separate university, variously known as the Albert University, Gresham University and Westminster University. Following two Royal Commissions the University of London Act 1898 was passed, reforming the university and giving it a federal structure with responsibility for monitoring course content and academic standards within its institutions. This was implemented in 1900 with the approval of new statutes for the university.
20th century.
The reforms initiated by the 1898 act came into force with the approval of the new federal statutes in 1900. Many of the colleges in London became schools of the university, including UCL, KCL,
Bedford College, Royal Holloway and the London School of Economics. Regent's Park College, which had affiliated in 1841, became an official divinity school of the university in 1901 (the new statutes having given London the right to award degrees in theology); Goldsmiths College joined in 1904; Imperial College was founded in 1907; Queen Mary College joined in 1915; the School of Oriental and African Studies was founded in 1916; and Birkbeck College, which was founded in 1823, joined in 1920.
The previous provision for colleges outside London was not abandoned on federation, instead London offered two routes to degrees: "internal" degrees offered by schools of the university and "external" degrees offered at other colleges (now the University of London International Programmes).
UCL and KCL, whose campaign for a teaching university in London had resulted in the university's reconstitution as a federal institution, went even further than becoming schools of the University and were actually merged into it. UCL's merger, under the 1905 University College London (Transfer) Act, happened in 1907. The charter of 1836 was surrendered and all of UCL's property became the University of London's. KCL followed in 1910 under the 1908 King's College London (Transfer) Act. This was a slightly more complicated case, as the theological department of the college (founded in 1846) did not merge into the university but maintained a separate legal existence under KCL's 1829 charter.
The expansion of the university's role meant that the Burlington Garden premises were insufficient, and in March 1900 it moved to the Impetial Institute in South Kensington.
However it's continued rapid expansion meant that it had outgrown its new premises by the 1920s, requiring yet another move. A large parcel of land in Bloomsbury near the British Museum was acquired from the Duke of Bedford and Charles Holden was appointed architect with the instruction to create a building "not to suggest a passing fashion inappropriate to buildings which will house an institution of so permanent a character as a University." This unusual remit may have been inspired by the fact that William Beveridge, having just become director of LSE, upon asking a taxi driver to take him to the University of London was met with the response "Oh, you mean the place near the Royal School of Needlework". Holden responded by designing Senate House, the current headquarters of the university, and at the time of completion the second largest building in London.
During the Second World War, the colleges of the university (with the exception of Birkbeck) and their students left London for safer parts of the UK, while Senate House was used by the Ministry of Information, with its roof becoming an observation point for the Royal Observer Corps. Though the building was hit by bombs several times, it emerged from the war largely unscathed; rumour at the time had it that the reason the building had fared so well was that Adolf Hitler had planned to use it as his headquarters in London.
The latter half of the last century was less eventful. In 1948, Athlone Press was founded as the publishing house for the university, and sold to the Bemrose Corporation in 1979, subsequent to which it was acquired by Continuum publishing. However, the post-WWII period was mostly characterised by expansion and consolidation within the university, such as the acquisition as a constituent body of the Jesuit theological institution Heythrop College on its move from Oxfordshire in 1969.
The 1978 University of London Act saw the university defined as a federation of self-governing colleges, starting the process of decentralisation that would lead to a marked transference of academic and financial power in this period from the central authorities in Senate House to the individual colleges. In the same period, UCL and KCL regained their legal independence via acts of parliament and the issuing of new royal charters. UCL was reincorporate in 1977, while KCL's new charter in 1980 reunited the main body of the college with the corporation formed in 1829. One of the largest shifts in power of this period came in 1993, when HEFCE switched from funding the University of London, which then allocated money to the colleges, to funding the colleges directly and them paying a contribution to the University.
There was also a tendency in the late 20th century for smaller colleges to be amalgamated into larger "super-colleges". Some of the larger colleges (most notably UCL, KCL, LSE and Imperial) periodically put forward the possibility of their departure from the university, although no steps were taken to actually putting this into action until the early 21st century.
21st century.
In 2002, Imperial College and UCL mooted the possibility of a merger, raising the question of the future of the University of London and the smaller colleges within it. Subsequently considerable opposition from academic staff of both UCL and Imperial led to a rejection of the merger.
Despite this failure, the trend of decentralising power continued.
A significant development in this process was the closing down of the Convocation of all the university's alumni in October 2003; this recognised that individual college alumni associations were now increasingly the centre of focus for alumni. However, the university continued to grow even as it moved to a looser federation, and, in 2005, admitted the Central School of Speech and Drama.
On 9 December 2005, Imperial College became the second constituent body (after Regent's Park College) to make a formal decision to leave the university. Its council announced that it was beginning negotiations to withdraw from the university in time for its own centenary celebrations, and in order to be able to award its own degrees. On 5 October 2006, the University of London accepted Imperial's formal request to withdraw from it. Imperial became fully independent on 9 July 2007, as part of the celebrations of the college's centenary.
The "Times Higher Education Supplement" announced in February 2007 that the London School of Economics, University College London and King's College London all planned to start awarding their own degrees, rather than degrees from the federal University of London as they had done previously, from the start of the academic year starting in Autumn 2007. Although this plan to award their own degrees did not amount to a decision to leave the University of London, the THES suggested that this 'rais new doubts about the future of the federal University of London'.
The School of Pharmacy, University of London merged with UCL on 1 January 2012, becoming the UCL School of Pharmacy within the Faculty of Life Sciences. This was followed on 2 December 2014 by the Institute of Education also merging with UCL, becoming the UCL Institute of Education.
Since 2010, the university has been outsourcing support services such as cleaning and portering. This has prompted industrial action by the largely Latin American workforce under the "3Cosas" campaign (the 3Cosas – 3 causes –being sick pay, holiday pay, and pensions for outsourced workers on parity with staff employed directly by the university). The 3Cosas campaigners were members of the UNISON trade union. However, documents leaked in 2014 revealed that UNISON representatives tried to counter the 3Cosas campaign in meetings with university management. The 3Cosas workers subsequently transferred to the Independent Workers Union of Great Britain.
Following good results in the Research Excellence Framework in December 2014, City University London said that they were exploring the possibility of joining the University of London. It was subsequently announced in July 2015 that City would join the University of London in August 2016. It will cease to be an independent university and become a college as "City, University of London".
Campuses.
The university owns a considerable central London estate of 180 buildings on 12 hectares in Bloomsbury, near Russell Square tube station.
Some of the university's colleges have their main buildings on the estate. The Bloomsbury Campus also contains eight Halls of Residence and Senate House, which houses the Senate House Library, the chancellor's official residence and previously housed the School of Slavonic and East European Studies, now part of University College London (UCL) and housed in its own new building. Almost all of the School of Advanced Study is housed in Senate House and neighbouring Stewart House.
The university also owns many of the squares that formed part of the Bedford Estate, including Gordon Square, Tavistock Square, Torrington Square and Woburn Square, as well as several properties outside Bloomsbury, with many of the university's colleges and institutes occupying their own estates across London:
The university also has several properties outside London, including a number of residential and catering units further afield and the premises of the University of London Institute in Paris, which offers undergraduate and postgraduate degrees in French and historical studies.
Organisation and administration.
The nine largest institutions of the federal university, usually termed "the colleges", are Birkbeck, Goldsmiths, King's College London, the London Business School, Queen Mary, Royal Holloway, SOAS, LSE and UCL. Formerly a constituent college, Imperial College London left the University of London in 2007.
For most practical purposes, ranging from admission of students to negotiating funding from the government, the 18 constituent "colleges" are treated as individual universities. Legally speaking they are known as "Recognised Bodies", with the authority to examine students and award them degrees of the university. Some colleges have the power to award their own degrees instead of those of the university; those which exercise that power include:
Most decisions affecting the constituent colleges and institutions of the University of London are made at the level of the colleges or institutions themselves. The University of London does retain its own decision-making structure, however, with the Collegiate Council and Board of Trustees, responsible for matters of academic policy. The Collegiate Council is made up of the Heads of Colleges of the university.
The 12 institutes, or "Listed Bodies", within the University of London offer courses leading to degrees that are both examined and awarded by the University of London. Additionally, twelve universities in England, several in Canada and many in other Commonwealth countries (notably in East Africa) began life as associate colleges of the university offering such degrees. By the 1970s, almost all of these colleges had achieved independence from the University of London. An increasing number of overseas and UK-based academic institutes offer courses to support students registered for the University of London International Programmes's diplomas and degrees and the Teaching Institutions Recognition Framework enables the recognition of these institutions.
Colleges.
The current constituent colleges of the University of London are as follows:
Former colleges and schools.
Some colleges and schools of the University of London have been amalgamated into larger colleges or left the University of London. These include:
Imperial College London
Royal Holloway, University of London
King's College
University College London
Queen Mary, University of London
Others
University colleges in the external degree programme.
A number of major universities originated as university colleges teaching the degrees of (what is now) the University of London International Programmes.
A number of other colleges had degrees validated and awarded by the University of London.
Colleges in special relation.
Between 1946 and 1970, the university entered into 'schemes of special relation' with university colleges in the Commonwealth of Nations. These schemes encouraged the development of independent universities by offering a relationship with the University of London. University colleges in these countries were granted a Royal Charter. An Academic Board of the university college negotiated with the University of London over the entrance requirements for the admission of students, syllabuses, examination procedures and other academic matters. During the period of the special relationship, graduates of the colleges were awarded University of London degrees.
Some of the colleges which were in special relation are listed below, along with the year in which their special relation was established.
In 1970, the 'Schemes of Special Relation' were phased out.
Coat of arms.
The University of London first received a grant of arms in April 1838. The arms depict a cross of St George upon which there is a Tudor rose surrounded by detailing and surmounted by a crown. Above all of this there is a blue field with an open book upon it.
The arms are described in the grant as:
Academic dress.
The University of London had established a rudimentary code for academic dress by 1844. The university was the first to devise a system of academic dress based on faculty colours, an innovation that was subsequently followed by most other universities.
Since their being granted autonomous degree awarding powers, the Institute of Education, King's College London, The London School of Economics and Political Science and University College London have each introduced their own form of academic dress. Queen Mary, University of London will, as of 2014, introduce its own form of academic dress to reflect its autonomous degree awarding powers. The remaining colleges of the university continue to use the University of London academic dress.
Student life.
As of , students (approximately 5% of all UK students) attended one of the University of London's affiliated schools. Additionally, over 45,000 students follow the University of London International Programmes.
The ULU building on Malet Street (close to Senate House) was home to the University of London Union, which acted as the student union for all University of London students alongside the individual college and institution unions. The building is now rebranded as 'Student Central, London', offering full membership to current University of London students, and associate membership to students at other universities, and other groups. The union previously owned "London Student," the largest student newspaper in Europe, which now runs as a digital news organisation
Sports, clubs and traditions.
Though most sports teams are organised at the college level, ULU ran a number of sports clubs of its own, some of which (for example the basketball team) compete in BUCS leagues. The union also organised its own leagues for college teams to participate in. These leagues and sports clubs are supported by Friends of University of London Sport which aims to promote them.
In addition to these, ULU catered for sports not covered by the individual colleges through clubs such as the University of London Union Lifesaving Club, which helps students gain awards and learn new skills in lifesaving as well as sending teams to compete throughout the country in the BULSCA league.
The university's ice hockey squad, the ULU Dragons, have been successful in the British Universities Ice Hockey Association Division 1 and Division 2. The Dragons have also previously competed in tournaments including professional teams and have come away with several gold and silver medals from these events.
ULU also organised a number of societies, ranging from Ballroom and Latin American Dance to Shaolin Kung Fu, and from the University of London Big Band to the Breakdancing Society. Affiliated to the university is the University of London Society of Change Ringers, a society for bellringers at all London universities.
The university runs the University of London Boat Club.
The university also has a representative football team, which dates back to 1913 and is a collection of the best players from the various colleges. The team plays games against sides such as Cambridge's and Oxford's 'Blues' sides as well as the R.A.F, Navy and Army. Currently the team has use of both Motspur Park Athletics Stadium (Fulham F.C.'s training ground, and a former University of London property) and the Honourable Artillery Company's grounds for training and home match purposes. Former players and managers of the team include Bobby Robson and Jimmy Hill.
University of London Orienteering Club is an umbrella club for all University of London orienteering groups. Members participate in orienteering events across the UK, and occasionally further afield. In 1997, the club sent a team to participate in the US championships in Colorado.
The University of London Symphony Orchestra (ULSO) is a leading student orchestra within the UK. It comprises approximately 70 – 100 students from the University of London annually and welcomes world-renowned conductors and soloists. ULSO dates back to 1955 is well known for performing some of the most challenging works in the repertoire. The orchestra has played in some of London's foremost concert halls including Cadogan Hall, St. John's Smith Square, Duke's Hall and has been on tour in Hong Kong and Italy in recent years.
Student housing.
The university operates the following eight intercollegiate halls of residence, which accommodate students from most of its colleges and institutions:
The Garden Halls
Notable people.
Notable alumni, faculty and staff.
A large number of famous individuals have passed through the University of London, either as staff or students, including at least 4 monarchs, 52 presidents or prime ministers, 74 Nobel laureates, 6 Grammy winners, 2 Oscar winners and 3 Olympic gold medalists.
Staff and students of the university, past and present, have contributed to a number of important scientific advances, including the discovery of vaccines by Edward Jenner and Henry Gray (author of "Gray's Anatomy"). Additional vital progress was made by University of London people in the following fields: the discovery of the structure of DNA (Francis Crick, Maurice Wilkins and Rosalind Franklin); the invention of modern electronic computers (Tommy Flowers); the discovery of penicillin (Alexander Fleming and Ernest Chain); the development of X-Ray technology (William Henry Bragg and Charles Glover Barkla); discoveries on the mechanism of action of Interleukin 10 (Anne O'Garra); the formulation of the theory of electromagnetism (James Clerk Maxwell); the determination of the speed of light (Louis Essen); the development of antiseptics (Joseph Lister); the development of fibre optics (Charles K. Kao); and the invention of the telephone (Alexander Graham Bell).
Notable political figures who have passed through the University of London include Muhammad Haji Ibrahim Egal, Romano Prodi, Junichiro Koizumi, Aung San Suu Kyi, Htin Kyaw - 9th President of Myanmar, Archbishop Desmond Tutu, Taro Aso, Walter Rodney, Nelson Mandela, John F. Kennedy, Dr. B. R. Ambedkar and Mahatma Gandhi.
In the arts field the university has produced the novelists Malcolm Bradbury, G. K. Chesterton, H. G. Wells, Thomas Hardy, Arthur C. Clarke, J.G. Ballard and the poet John Keats. Many artists have been associated with the university, including Jonathan Myles-Lea, and several of the leading figures in the Young British Artists movement (including Ian Davenport, Tracey Emin and Damien Hirst). Outstanding musicians across a wide range include the conductor Sir Simon Rattle, the soprano Felicity Lott and both members of Gilbert and Sullivan to Mick Jagger, Elton John, Dido, and members of the bands Coldplay, Keane, Suede, The Velvet Underground, Blur, Iron Maiden, Placebo, The Libertines, Queen, and Hong Kong singer-actress Karen Mok.
The University of London has also played host to film directors (Christopher Nolan, Derek Jarman), philosophers (Karl Popper, Roger Scruton), explorers (David Livingstone), international academics (Sam Karunaratne), Riccarton High School Head of Commerce, Tom Neumann and leading businessmen (Michael Cowpland, George Soros).
Chancellors.
The Chancellors of the University of London since its founding are as follows:

</doc>
<doc id="60920" url="https://en.wikipedia.org/wiki?curid=60920" title="Tetrahydrocannabinol">
Tetrahydrocannabinol

Tetrahydrocannabinol (THC, dronabinol by INN), or more precisely its main isomer (−)-"trans"-Δ9-tetrahydrocannabinol, is the principal psychoactive constituent (or cannabinoid) of cannabis. It can be an amber or gold colored glassy solid when cold, which becomes viscous and sticky if warmed.
Like most pharmacologically-active secondary metabolites of plants, THC in "Cannabis" is assumed to be involved in self-defense, perhaps against herbivores. THC also possesses high UV-B (280–315 nm) absorption properties, which, it has been speculated, could protect the plant from harmful UV radiation exposure.
THC, along with its double bond isomers and their stereoisomers, is one of only three cannabinoids scheduled by the UN Convention on Psychotropic Substances (the other two are dimethylheptylpyran and parahexyl). It was listed under Schedule I in 1971, but reclassified to Schedule II in 1991 following a recommendation from the WHO. Based on subsequent studies, the WHO has recommended the reclassification to the less-stringent Schedule III. Cannabis as a plant is scheduled by the Single Convention on Narcotic Drugs (Schedule I and IV).
A pharmaceutical formulation is available by prescription in the U.S. and Canada under the brand name Marinol.
Medical uses.
Dronabinol is the INN for a pure isomer of THC, (–)-"trans"-Δ9-tetrahydrocannabinol, which is the main isomer found in cannabis. It is used to treat anorexia in people with HIV/AIDS as well as for refractory nausea and vomiting in people undergoing chemotherapy. It is safe and effective for these uses.
THC is also an active ingredient in nabiximols, a specific extract of "Cannabis" that was approved as a botanical drug in the United Kingdom in 2010 as a mouth spray for people with multiple sclerosis to alleviate neuropathic pain, spasticity, overactive bladder, and other symptoms.
Adverse effects.
Acute toxicity.
There has never been a documented human fatality solely from overdosing on tetrahydrocannabinol. However, numerous reports have suggested an association of cannabis smoking with an increased risk of myocardial infarction (heart attack); however, oral administration does not have this effect. Information about the toxicity of THC is primarily based on results from non-human studies. The toxicity depends on the route of administration and the laboratory animal.
The estimated lethal dose of intravenous dronabinol in humans is 30 mg/kg, meaning lethality is unlikely. The typical medicinal dosage administered is two 2.5 mg capsules daily for an 80 kg man (~170 lb). A lethal dose for such a person would be approximately 960 of those capsules infused intravenously. Non-fatal overdoses have occurred: "Significant CNS symptoms in antiemetic studies followed oral doses of 0.4 mg/kg (28 mg/70 kg) of dronabinol capsules."
A meta analysis of clinical trials conducted using standardized cannabis extracts or THC conducted by the American Academy of Neurology found that of 1619 persons treated with cannabis products (including some treated with smoked cannabis and nabiximols), 6.9% discontinued due to side effects, compared to 2.2% of 1,118 treated with placebo. Detailed information regarding side effects was not available from all trials, but nausea, increased weakness, behavioral or mood changes, suicidal ideation, hallucinations, dizziness, and vasovagal symptoms, fatigue, and feelings of intoxication were each described as side effects in at least two trials. There was a single death rated by the investigator as "possibly related" to treatment. This person had a seizure followed by aspiration pneumonia. The paper does not describe whether this was one of the subjects from the epilepsy trials.
Overdose.
An overdose of dronabinol usually presents with lethargy, decreased motor coordination, slurred speech, and postural hypotension. The FDA estimates the lethal human dose of intravenous dronabinol to be 30 mg/kg (2100 mg/ 70 kg).
Pharmacology.
Mechanism of action.
The actions of THC result from its partial agonist activity at the cannabinoid receptor CB1 (Ki=10nM), located mainly in the central nervous system, and the CB2 receptor (Ki=24nM), mainly expressed in cells of the immune system. The psychoactive effects of THC are primarily mediated by its activation of CB1G-protein coupled receptors, which result in a decrease in the concentration of the second messenger molecule cAMP through inhibition of adenylate cyclase.
The presence of these specialized cannabinoid receptors in the brain led researchers to the discovery of endocannabinoids, such as anandamide and 2-arachidonoyl glyceride (2-AG). THC targets receptors in a manner far less selective than endocannabinoid molecules released during retrograde signaling, as the drug has a relatively low cannabinoid receptor efficacy and affinity. In populations of low cannabinoid receptor density, THC may act to antagonize endogenous agonists that possess greater receptor efficacy. THC is a lipophilic molecule and may bind non-specifically to a variety of entities in the brain and body, such as adipose tissue (fat).
THC, similarly to cannabidiol, albeit less potently, is an allosteric modulator of the μ- and δ-opioid receptors.
Due to its partial agonistic activity, THC appears to result in greater downregulation of cannabinoid receptors than endocannabinoids, further limiting its efficacy over other cannabinoids. While tolerance may limit the maximal effects of certain drugs, evidence suggests that tolerance develops irregularly for different effects with greater resistance for primary over side-effects, and may actually serve to enhance the drug's therapeutic window. However, this form of tolerance appears to be irregular throughout mouse brain areas.
THC, as well as other cannabinoids that contain a phenol group, possesses mild antioxidant activity sufficient to protect neurons against oxidative stress, such as that produced by glutamate-induced excitotoxicity.
Pharmacokinetics.
THC is metabolized mainly to 11-OH-THC by the body. This metabolite is still psychoactive and is further oxidized to 11-nor-9-carboxy-THC (THC-COOH). In humans and animals, more than 100 metabolites could be identified, but 11-OH-THC and THC-COOH are the dominating metabolites. Metabolism occurs mainly in the liver by cytochrome P450 enzymes CYP2C9, CYP2C19, and CYP3A4. More than 55% of THC is excreted in the feces and ~20% in the urine. The main metabolite in urine is the ester of glucuronic acid and THC-COOH and free THC-COOH. In the feces, mainly 11-OH-THC was detected.
Physical and chemical properties.
Discovery and structure identification.
The discovery of THC, by a team of researchers from Hebrew University Pharmacy School, was first reported in 1964,
Solubility.
An aromatic terpenoid, THC has a very low solubility in water, but good solubility in most organic solvents, specifically lipids and alcohols. THC, CBD, CBN, CBC, CBG and over 113 other molecules make up the phytocannabinoid family.
Biosynthesis.
In the "Cannabis" plant, THC occurs mainly as tetrahydrocannabinolic acid (THCA, 2-COOH-THC, THC-COOH). Geranyl pyrophosphate and olivetolic acid react, catalysed by an enzyme to produce cannabigerolic acid, which is cyclized by the enzyme THC acid synthase to give THCA. Over time, or when heated, THCA is decarboxylated, producing THC. The pathway for THCA biosynthesis is similar to that which produces the bitter acid humulone in hops.
Detection in body fluids.
THC, 11-OH-THC and THC-COOH can be detected and quantified in blood, urine, hair, oral fluid or sweat using a combination of immunoassay and chromatographic techniques as part of a drug use testing program or in a forensic investigation.
History.
THC was first isolated in 1964 by Raphael Mechoulam and Yechiel Gaoni at the Weizmann Institute of Science.
Since at least 1986, the trend has been for THC in general, and especially the Marinol preparation, to be downgraded to less and less stringently-controlled schedules of controlled substances, in the U.S. and throughout the rest of the world.
On May 13, 1986, the Drug Enforcement Administration (DEA) issued a Final Rule and Statement of Policy authorizing the "Rescheduling of Synthetic Dronabinol in Sesame Oil and Encapsulated in Soft Gelatin Capsules From Schedule I to Schedule II" (DEA 51 FR 17476-78). This permitted medical use of Marinol, albeit with the severe restrictions associated with Schedule II status. For instance, refills of Marinol prescriptions were not permitted. At its 1045th meeting, on April 29, 1991, the Commission on Narcotic Drugs, in accordance with article 2, paragraphs 5 and 6, of the Convention on Psychotropic Substances, decided that Δ9-tetrahydrocannabinol (also referred to as Δ9-THC) and its stereochemical variants should be transferred from Schedule I to Schedule II of that Convention. This released Marinol from the restrictions imposed by Article 7 of the Convention (See also United Nations Convention Against Illicit Traffic in Narcotic Drugs and Psychotropic Substances).
An article published in the April–June 1998 issue of the Journal of Psychoactive Drugs found that "Healthcare professionals have detected no indication of scrip-chasing or doctor-shopping among the patients for whom they have prescribed dronabinol". The authors state that Marinol has a low potential for abuse.
In 1999, Marinol was rescheduled from Schedule II to III of the Controlled Substances Act, reflecting a finding that THC had a potential for abuse less than that of cocaine and heroin. This rescheduling constituted part of the argument for a 2002 petition for removal of cannabis from Schedule I of the Controlled Substances Act, in which petitioner Jon Gettman noted, "Cannabis is a natural source of dronabinol (THC), the ingredient of Marinol, a Schedule III drug. There are no grounds to schedule cannabis in a more restrictive schedule than Marinol".
At its 33rd meeting, in 2003, the World Health Organization Expert Committee on Drug Dependence recommended transferring THC to Schedule IV of the Convention, citing its medical uses and low abuse potential.
Society and culture.
Brand names.
Dronabinol is marketed as Marinol, a registered trademark of Solvay Pharmaceuticals. Dronabinol is also marketed, sold, and distributed by PAR Pharmaceutical Companies under the terms of a license and distribution agreement with SVC pharma LP, an affiliate of Rhodes Technologies. Dronabinol is available as a prescription drug (under Marinol) in several countries including the United States, Germany, South Africa and Australia. In the United States, Marinol is a Schedule III drug, available by prescription, considered to be non-narcotic and to have a low risk of physical or mental dependence. Efforts to get cannabis rescheduled as analogous to Marinol have not succeeded thus far, though a 2002 petition has been accepted by the DEA. As a result of the rescheduling of Marinol from Schedule II to Schedule III, refills are now permitted for this substance. Marinol's U.S. Food and Drug Administration (FDA) approvals for medical use has raised much controversy as to why natural THC is considered a schedule I drug.
Comparisons with medical cannabis.
Female cannabis plants contain more than 60 cannabinoids, including cannabidiol (CBD), thought to be the major anticonvulsant that helps people with multiple sclerosis; and cannabichromene (CBC), an anti-inflammatory which may contribute to the pain-killing effect of cannabis.
It takes over one hour for Marinol to reach full systemic effect, compared to seconds or minutes for smoked or vaporized cannabis. Some people accustomed to inhaling just enough cannabis smoke to manage symptoms have complained of too-intense intoxication from Marinol's predetermined dosages. Many people using Marinol have said that Marinol produces a more acute psychedelic effect than cannabis, and it has been speculated that this disparity can be explained by the moderating effect of the many non-THC cannabinoids present in cannabis. For that reason, alternative THC-containing medications based on botanical extracts of the cannabis plant such as nabiximols are being developed. Mark Kleiman, director of the Drug Policy Analysis Program at UCLA's School of Public Affairs said of Marinol, "It wasn't any fun and made the user feel bad, so it could be approved without any fear that it would penetrate the recreational market, and then used as a club with which to beat back the advocates of whole cannabis as a medicine." Mr. Kleiman's opinion notwithstanding, clinical trials comparing the use of cannabis extracts with Marinol in the treatment of cancer cachexia have demonstrated equal efficacy and well-being among subjects in the two treatment arms. United States federal law currently registers dronabinol as a Schedule III controlled substance, but all other cannabinoids remain Schedule I, except synthetics like nabilone.
Research.
Its status as an illegal drug in most countries can make research difficult; for instance in the United States where the National Institute on Drug Abuse was the only legal source of cannabis for researchers until it recently became legalized in Colorado, Washington state, Oregon, Alaska, and Washington D.C.
In April 2014 the American Academy of Neurology published a systematic review of the efficacy and safety of medical marijuana and marijuana-derived products in certain neurological disorders. The review identified 34 studies meeting inclusion criteria, of which 8 were rated as Class I quality. The study found evidence supporting the effectiveness of the cannabis extracts that were tested and THC in treating certain symptoms of multiple sclerosis, but found insufficient evidence to determine the effectiveness of the tested cannabis products in treating several other neurological diseases.
Several of the clinical trials exploring the safety and efficacy of "oral cannabis extract" that were reviewed by the AAN were conducted using "Cannador", made by the Institute for Clinical Research (IKF) in Berlin, which is a capsule with a standardized "Cannabis sativa" extract; the cannabis grown in Switzerland and processed in Germany. Each capsule of Cannador contains 2.5mg Δ9- tetrahydrocannabinol and cannabidiols are standardized to a range 0.8–1.8mg.

</doc>
