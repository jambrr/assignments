<doc id="56359" url="https://en.wikipedia.org/wiki?curid=56359" title="Leo Szilard">
Leo Szilard

Leo Szilard (; ; until age 2; February 11, 1898 – May 30, 1964) was a Jewish Hungarian-American physicist and inventor. He conceived the nuclear chain reaction in 1933, patented the idea of a nuclear reactor with Enrico Fermi, and in late 1939 wrote the letter for Albert Einstein's signature that resulted in the Manhattan Project that built the atomic bomb.
Szilard initially attended Palatine Joseph Technical University in Budapest, but his engineering studies were interrupted by service in the Austro-Hungarian Army during World War I. He left Hungary for Germany in 1919, enrolling at Technische Hochschule (Institute of Technology) in Berlin-Charlottenburg, but became bored with engineering and transferred to Friedrich Wilhelm University, where he studied physics. He wrote his doctoral thesis on Maxwell's demon, a long-standing puzzle in the philosophy of thermal and statistical physics. Szilard was the first to recognize the connection between thermodynamics and Information theory.
In addition to the nuclear reactor, Szilard submitted patent applications for a linear accelerator in 1928, and a cyclotron in 1929. He also conceived the idea of an electron microscope. Between 1926 and 1930, he worked with Einstein on the development of the Einstein refrigerator. After Adolf Hitler became chancellor of Germany in 1933, Szilard urged his family and friends to flee Europe while they still could. He moved to England, where he helped found the Academic Assistance Council, an organization dedicated to helping refugee scholars find new jobs. While in England he discovered a means of isotope separation known as the Szilard–Chalmers effect.
Foreseeing another war in Europe, Szilard moved to the United States in 1938, where he worked with Enrico Fermi and Walter Zinn on means of creating a nuclear chain reaction. He was present when this was achieved on December 2, 1942. He worked for the Manhattan Project's Metallurgical Laboratory on aspects of nuclear reactor design. He drafted the Szilard petition advocating a demonstration of the atomic bomb, but the Interim Committee chose to use them against cities without warning.
After the war, Szilard switched to biology. He invented the chemostat, discovered feedback inhibition, and was involved in the first cloning of a human cell. He publicly sounded the alarm against the development of the cobalt bomb, a new kind of nuclear weapon that might destroy all life on the planet. Diagnosed with bladder cancer in 1960, he underwent treatment using a cobalt-60 treatment that he had designed. He helped found the Salk Institute for Biological Studies, where he became a resident fellow. He died in his sleep of a heart attack in 1964.
Early life.
Leo Spitz was born in Budapest in what was then the Kingdom of Hungary, on February 11, 1898. His middle-class Jewish parents, Louis Spitz, a civil engineer, and Tekla Vidor, raised Leó on the Városligeti Fasor in Pest. He had two younger siblings, a brother, Béla, born in 1900, and a sister, Rózsi (Rose), born in 1901. On October 4, 1900, the family changed its surname from the German "Spitz" to the Hungarian "Szilard", a name that means "solid" in Hungarian. Despite having a religious background, Szilard became an agnostic. From 1908 to 1916 he attended "Reáliskola" high school in his home town. Showing an early interest in physics and a proficiency in mathematics, in 1916 he won the Eötvös Prize, a national prize for mathematics.
With World War I raging in Europe, Szilard received notice on January 22, 1916, that he had been drafted into the 5th Fortress Regiment, but he was able to continue his studies. He enrolled as an engineering student at the Palatine Joseph Technical University, which he entered in September 1916. The following year he joined the Austro-Hungarian Army's 4th Mountain Artillery Regiment, but immediately was sent to Budapest as an officer candidate. He rejoined his regiment in May 1918 but in September, before being sent to the front, he fell ill with Spanish Influenza and was returned home for hospitalization. Later he was informed that his regiment had been nearly annihilated in battle, so the sickness probably saved his life. He was discharged honorably in November 1918, after the end of the war.
In January 1919, Szilard resumed his engineering studies, but Hungary was in a chaotic political situation with the rise of the Hungarian Soviet Republic under Béla Kun. Szilard and his brother Béla founded their own political group, the Hungarian Association of Socialist Students, with a platform based on a scheme of Szilard's for taxation reform. He was convinced that socialism was the answer to Hungary's post-war problems, but not that of Kun's Hungarian Socialist Party, which had close ties to the Soviet Union. When Kun's government tottered, the brothers officially changed their religion from "Israelite" to "Calvinist", but when they attempted to re-enroll in what was now the Budapest University of Technology, they were prevented from doing so by nationalist students because they were Jews.
Convinced that there was no future for him in Hungary, Szilard left for Berlin via Austria on December 25, 1919, and enrolled at the Technische Hochschule (Institute of Technology) in Berlin-Charlottenburg. He was soon joined by his brother Béla. Szilard became bored with engineering, and his attention turned to physics. This was not taught at the Technische Hochschule, so he transferred to Friedrich Wilhelm University, where he attended lectures given by Albert Einstein, Max Planck, Walter Nernst, James Franck and Max von Laue. He also met fellow Hungarian students Eugene Wigner, John von Neumann and Dennis Gabor. His doctoral dissertation on thermodynamics "Über die thermodynamischen Schwankungserscheinungen" (On The Manifestation of Thermodynamic Fluctuations), praised by Einstein, won top honors in 1922. It involved a long-standing puzzle in the philosophy of thermal and statistical physics known as Maxwell's demon, a thought experiment originated by the physicist James Clerk Maxwell. The problem was thought to be insoluble, but in tackling it Szilard recognized the connection between thermodynamics and Information theory.
Szilard was appointed as assistant to von Laue at the Institute for Theoretical Physics in 1924. In 1927 he finished his habilitation and became a "Privatdozent" (private lecturer) in physics. For his habilitation lecture, he produced a second paper on Maxwell's Demon, "Über die Entropieverminderung in einem thermodynamischen System bei Eingriffen intelligenter Wesen" (On the reduction of entropy in a thermodynamic system by the intervention of intelligent beings), that had actually been written soon after the first. This introduced the thought experiment now called the Szilard engine and became important in the history of attempts to understand Maxwell's demon. The paper is also the first equation of negative entropy and information. As such, it established Szilard as one of the founders of information theory, but he did not publish it until 1929, and did not pursue it further. Claude E. Shannon, who took it up in the 1950s, acknowledged Szilard's paper as his starting point.
Throughout his time in Berlin, Szilard worked on numerous technical inventions. In 1928 he submitted a patent application for the linear accelerator, not knowing of Gustav Ising's prior 1924 journal article and Rolf Widerøe's operational device, and in 1929 applied for one for the cyclotron. He also conceived the electron microscope. Between 1926 and 1930, he worked with Einstein to develop the Einstein refrigerator, notable because it had no moving parts. He did not build all of these devices, or publish these ideas in scientific journals, and so credit for them often went to others. As a result, Szilard never received the Nobel Prize, but Ernest Lawrence was awarded it for the cyclotron in 1939 and Ernst Ruska for the electron microscope in 1986.
Developing the idea of the nuclear chain reaction.
Szilard received German citizenship in 1930, but was already uneasy about the political situation in Europe. When Adolf Hitler became chancellor of Germany in January 20, 1933, Szilard urged his family and friends to flee Europe while they still could. He moved to England, and transferred his savings of £1,595 from his bank in Zurich to one in London. He lived in hotels where lodging and meals cost about £5/5 a week. For those less fortunate, he helped found the Academic Assistance Council, an organization dedicated to helping refugee scholars find new jobs, and persuaded the Royal Society to provide accommodation for it at Burlington House. He enlisted the help of academics such as Harald Bohr, G. H. Hardy, Archibald Hill and Frederick G. Donnan. By the outbreak of World War II in 1939, it had helped to find places for over 2,500 refugee scholars.
In September 12, 1933, Szilard read an article in "The Times" summarizing a speech given by Lord Rutherford in which Rutherford rejected the feasibility of using atomic energy for practical purposes. The speech remarked specifically on the recent 1932 work of his students, John Cockcroft and Ernest Walton, in "splitting" lithium into alpha particles, by bombardment with protons from a particle accelerator they had constructed. Rutherford went on to say:
Szilard was so annoyed at Rutherford's dismissal that he conceived of the idea of nuclear chain reaction (analogous to a chemical chain reaction), using recently discovered neutrons. The idea did not use the mechanism of nuclear fission, which was not yet discovered, but Szilard realized that if neutrons could initiate any sort of energy-producing nuclear reaction, such as the one that had occurred in lithium, and could be produced themselves by the same reaction, energy might be obtained with little input, since the reaction would be self-sustaining. The following year he filed for a patent on the concept of the neutron-induced nuclear chain reaction. Richard Rhodes described Szilard's moment of inspiration:
In early 1934, Szilard began working at St Bartholomew's Hospital in London. Working with a young physicist on the hospital staff, Thomas A. Chalmers, he began studying radioactive isotopes for medical purposes. It was known that bombarding elements with neutrons could produce either heavier isotopes of an element, or a heavier element, a phenomenon known as the Fermi Effect after its discoverer, the Italian physicist Enrico Fermi. When they bombarded ethyl iodide with neutrons produced by a radon-beryllium source, they found that the heavier radioactive isotopes of iodine separated from the compound. Thus, they had discovered a means of isotope separation. This method became known as the Szilard–Chalmers effect, and was widely used in the preparation of medical isotopes. He also attempted unsuccessfully to create a nuclear chain reaction using beryllium by bombarding it with X-rays. In 1936, Szilard assigned his chain-reaction patent to the British Admiralty to ensure its secrecy.
Manhattan Project.
Columbia University.
Szilard visited Béla and Rose and her husband, the painter Peter Detre, in Switzerland in September 1937. After a rainstorm, he and his siblings spent an afternoon in an unsuccessful attempt to build a prototype collapsible umbrella. One reason for the visit was that he had decided to emigrate to the United States, as he believed that another war in Europe was inevitable and imminent. He reached New York on the liner on January 2, 1938. Over the next few months he moved from place to place, conducting research with Maurice Goldhaber at the University of Illinois at Urbana–Champaign, and then the University of Chicago, University of Michigan and the University of Rochester, where he undertook experiments with indium but again failed to initiate a chain reaction.
In November 1938, Szilard moved to New York City, taking a room at the King's Crown Hotel near Columbia University. He encountered John R. Dunning, who invited him to speak about his research at an afternoon seminar in January 1939. That month, Niels Bohr brought news to New York of the discovery of nuclear fission in Germany by Otto Hahn and Fritz Strassmann, and its theoretical explanation by Lise Meitner, and Otto Frisch. When Szilard found out about it on a visit to Wigner at Princeton University, he immediately realized that uranium might be the element capable of sustaining a chain reaction.
Unable to convince Fermi that this was the case, Szilard set out on his own. He obtained permission from the head of the Physics Department at Columbia, George B. Pegram, to use a laboratory for three months. To fund his experiment, he borrowed $2,000 from a fellow inventor, Benjamin Liebowitz. He wired Frederick Lindemann at Oxford and asked him to send a beryllium cylinder. He convinced Walter Zinn to become his collaborator, and hired Semyon Krewer to investigate processes for manufacturing pure uranium and graphite.
Szilard and Zinn conducted a simple experiment on the seventh floor of Pupin Hall at Columbia, using a radium-beryllium source to bombard uranium with neutrons. Initially nothing registered on the oscilloscope, but then Zinn realized that it was not plugged in. On doing so, they discovered significant neutron multiplication in natural uranium, proving that a chain reaction might be possible. Szilard later described the event: "We turned the switch and saw the flashes. We watched them for a little while and then we switched everything off and went home". He understood the implications and consequences of this discovery, though. "That night, there was very little doubt in my mind that the world was headed for grief".
While they had demonstrated that the fission of uranium produced more neutrons than it consumed, this was still not a chain reaction. Szilard persuaded Fermi and Herbert L. Anderson to try a larger experiment using of uranium. To maximize the chance of fission, they needed a neutron moderator to slow the neutrons down. Hydrogen was a known moderator, so they used water. The results were disappointing. It became apparent that hydrogen slowed neutrons down, but also absorbed them, leaving fewer for the chain reaction. Szilard then suggested Fermi use carbon, in the form of graphite. He felt he would need about of graphite and of uranium. As a back-up plan, Szilard also considered where he might find a few tons of heavy water; deuterium would not absorb neutrons like ordinary hydrogen, but would have the similar value as a moderator. Such quantities of materiel would require a lot of money.
Szilard drafted a confidential letter to the President, Franklin D. Roosevelt, explaining the possibility of nuclear weapons, warning of the German nuclear weapon project, and encouraging the development of a program that could result in their creation. With the help of Wigner and Edward Teller, he approached his old friend and collaborator Einstein in August 1939, and convinced him to sign the letter, lending his fame to the proposal. The Einstein–Szilard letter resulted in the establishment of research into nuclear fission by the U.S. government, and ultimately to the creation of the Manhattan Project. Roosevelt gave the letter to his aide, Brigadier General Edwin M. "Pa" Watson with the instruction: "Pa, this requires action!"
An Advisory Committee on Uranium was formed under Lyman J. Briggs, a scientist and the director of the National Bureau of Standards. Its first meeting on October 21, 1939, was attended by Szilard, Teller and Wigner, who persuaded the Army and Navy to provide $6,000 for Szilard to purchase supplies for experiments—in particular, more graphite. A 1940 Army intelligence report on Fermi and Szilard, prepared when the United States had not yet entered World War II, expressed reservations about both. While it contained some errors of fact about Szilard, it correctly noted his dire prediction that Germany would win the war.
Fermi and Szilard met with representatives of National Carbon Company, who manufactured graphite, where Szilard made another important discovery. By quizzing them about impurities in their graphite, he found that it contained boron, a neutron absorber. He then had graphite manufacturers produce boron-free graphite. Had he not done so, they might have concluded, as the German nuclear weapon project did, that graphite was unsuitable for use as a neutron moderator. Like the German project, Fermi and Szilard still believed that enormous quantities of uranium would be required for an atomic bomb, and therefore concentrated on producing a controlled chain reaction. Fermi determined that fissioning uranium atom produced 1.73 neutrons on average. It was enough, but a careful design was called for to minimize losses. Szilard worked up various designs for a nuclear reactor. "If the uranium project could have been run on ideas alone," Wigner later remarked, "no one but Leo Szilard would have been needed."
Metallurgical Laboratory.
The December 6, 1941, meeting of the National Defense Research Committee resolved to proceed with an all-out effort to produce atomic bombs, a decision given urgency by the Japanese attack on Pearl Harbor the following day that brought the United States into World War II, and then formal approval by Roosevelt in January 1942. Arthur H. Compton from the University of Chicago was appointed head of research and development. Against Szilard's wishes, Compton concentrated all the groups working on reactors and plutonium at the Metallurgical Laboratory of the University of Chicago. Compton laid out an ambitious plan to achieve a chain reaction by January 1943, start manufacturing plutonium in nuclear reactors by January 1944, and produce an atomic bomb by January 1945.
In January 1942, Szilard joined the Metallurgical Laboratory in Chicago as a research associate, and later the chief physicist. Alvin Weinberg noted that Szilard served as the project "gadfly", asking all the embarrassing questions. Szilard provided important insights. While uranium-238 did not fission with the slow, moderated neutron, it might still fission with the fast neutrons produced by fission. This effect was small but crucial. Szilard made suggestions that improved the uranium canning process, and worked with David Gurinsky and Ed Creutz on a method for recovering uranium from its salts.
A vexing question at the time was how a production reactor should be cooled. Taking a conservative view that every possible neutron must be preserved, the majority opinion initially favored cooling with helium, which would absorbed very few neutrons. Szilard argued that if this was a concern, then liquid bismuth would be a better choice. He supervised experiments with it, but the practical difficulties turned out to be too great. In the end, Wigner's plan to use ordinary water as a coolant won out. When the coolant issue became too heated, Compton and the director of the Manhattan Project, Brigadier General Leslie R. Groves, Jr., moved to dismiss Szilard, who was still a German citizen, but the Secretary of War, Henry L. Stimson, refused to do so. Szilard was therefore present on December 2, 1942, when the first man-made self-sustaining nuclear chain reaction was achieved in the first nuclear reactor under viewing stands of Stagg Field, and shook Fermi's hand.
Szilard became a naturalized citizen of the United States in March 1943. The Army offered Szilard $25,000 for his inventions before November 1940, when he officially joined the project. He refused. He was the co-holder, with Fermi, of the patent on the nuclear reactor. In the end he sold his patent to the government for reimbursement of his expenses, some $15,416, plus the standard $1 fee. He continued to work with Fermi and Wigner on nuclear reactor design, and is credited with coining the term "breeder reactor".
With an enduring passion for the preservation of human life and political freedom, Szilard hoped that the U.S. government would not use nuclear weapons, but that the mere threat of such weapons would force Germany and Japan to surrender. He also worried about the long-term implications of nuclear weapons, predicting that their use by the United States would start a nuclear arms race with Russia. He drafted the Szilard petition advocating demonstration of the atomic bomb. The Interim Committee instead chose to use atomic bombs against cities over the protests of Szilard and other scientists. Afterwards, he lobbied for amendments to the Atomic Energy Act of 1946 that placed nuclear energy under civilian control.
After the war.
In 1946, Szilard secured a research professorship at the University of Chicago that allowed him to dabble in biology and the social sciences. He teamed up with Aaron Novick, a chemist who had worked at the Metallurgical Laboratory during the war. The two men saw biology as a field that had not been explored as much as physics, and was ready for scientific breakthroughs. It was a field that Szilard had been working on in 1933 before he had become subsumed in the quest for a nuclear chain reaction. The duo made considerable advances. They invented the chemostat, a device for regulating the growth rate of the microorganisms in a bioreactor, and developed methods for measuring the growth rate of bacteria. They discovered feedback inhibition, an important factor in processes such as growth and metabolism. Szilard gave essential advice to Theodore Puck and Philip I. Marcus for their first cloning of a human cell in 1955.
Before relation with his later wife Gertrud Weiss, Leo Szilard's life partner in the period 1927 - 1934 was kindergarten teacher and opera singer Gerda Philipsborn, which also worked as volunteer in Berlin asylum organization for refugee children and in 1932 moved to India to continue in this work. Szilard married Gertrud (Trude) Weiss, a physician, in a civil ceremony in New York on October 13, 1951. They had known each other since 1929, and had frequently corresponded and visited each other ever since. Weiss took up a teaching position at the University of Colorado in April 1950, and Szilard began staying with her in Denver for weeks at a time when they had never been together for more than a few days before. Single people living together was frowned upon in the conservative United States at the time, and after they were discovered by one of her students, Szilard began to worry that she might lose her job. Their relationship remained a long-distance one, and they kept news of their marriage quiet. Many of his friends were shocked when they found out, as it was widely believed that Szilard was a born bachelor.
In 1949 Szilard wrote a short story titled "My Trial as a War Criminal" in which he imagined himself on trial for crimes against humanity after the United States lost a war with the Soviet Union. He publicly sounded the alarm against the development of salted bombs, explaining in radio talk on February 26, 1950, that a cobalt bomb, a new kind of nuclear weapon using cobalt as a tamper, might destroy all life on the planet. While Time magazine compared him to Chicken Little, and the Atomic Energy Commission dismissed the idea, scientists debated whether it was feasible or not. The Bulletin of the Atomic Scientists commissioned a study by James R. Arnold that concluded that it was.
Szilard published a book of short stories, "The Voice of the Dolphins" (1961), in which he dealt with the moral and ethical issues raised by the Cold War and his own role in the development of atomic weapons. The title story described an international biology research laboratory in Central Europe. This became reality after a meeting in 1962 with Victor F. Weisskopf, James Watson and John Kendrew. When the European Molecular Biology Laboratory was established, the library was named The Szilard Library and the library stamp features dolphins. Other honors that he received included the Atoms for Peace Award in 1959, and the Humanist of the Year in 1960. A lunar crater on the far side of the Moon was named after him in 1970. The Leo Szilard Lectureship Award, established in 1974, is given in his honor by the American Physical Society.
In 1960, Szilard was diagnosed with bladder cancer. He underwent cobalt therapy at New York's Memorial Sloan-Kettering Hospital using a cobalt 60 treatment regimen that he designed himself. A second round of treatment with an increased dose followed in 1962. The doctors tried to tell him that the increased radiation dose would kill him, but he said it wouldn't, and that anyway he would die without it. The higher dose did its job and his cancer never returned. This treatment became standard for many cancers and is still used.
Szilard spent his last years as a fellow of the Salk Institute for Biological Studies in La Jolla, California, which he had helped to create. He was appointed a non-resident fellow there in July 1963, and became a resident fellow in April 1, 1964, after moving to La Jolla in February. On May 30, 1964, he died in his sleep of a heart attack; when Trude awoke, she was unable to revive him. His remains were cremated. His papers are in the library at the University of California in San Diego.

</doc>
<doc id="56360" url="https://en.wikipedia.org/wiki?curid=56360" title="Sorbitol">
Sorbitol

Sorbitol, also known as glucitol, is a sugar alcohol with a sweet taste which the human body metabolizes slowly. It can be obtained by reduction of glucose, changing the aldehyde group to a hydroxyl group. Most sorbitol is made from corn syrup, but it is also found in apples, pears, peaches, and prunes. It is converted to fructose by sorbitol-6-phosphate 2-dehydrogenase. Sorbitol is an isomer of mannitol, another sugar alcohol; the two differ only in the orientation of the hydroxyl group on carbon 2. While similar, the two sugar alcohols have very different sources in nature, melting points, and uses.
Uses.
Sweetener.
Sorbitol is a sugar substitute. It may be listed under the inactive ingredients listed for some foods and products. Its INS number and E number is 420. Sorbitol has approximately 60% the sweetness of sucrose (table sugar).
Sorbitol is referred to as a nutritive sweetener because it provides dietary energy: 2.6 kilocalories (11 kilojoules) per gram versus the average 4 kilocalories (17 kilojoules) for carbohydrates. It is often used in diet foods (including diet drinks and ice cream), mints, cough syrups, and sugar-free chewing gum.
It also occurs naturally in many stone fruits and berries from trees of the genus "Sorbus".
Laxative.
Sorbitol can be used as a non-stimulant laxative via an oral suspension or enema. As with other sugar alcohols, gastrointestinal distress may result when food products that contain sorbitol are consumed. Sorbitol exerts its laxative effect by drawing water into the large intestine, thereby stimulating bowel movements. Sorbitol has been determined safe for use by the elderly, although it is not recommended without consultation with a clinician. Sorbitol is found in some dried fruits and may contribute to the laxative effects of prunes. Sorbitol was discovered initially in the fresh juice of mountain ash (Sorbus aucuparia) berries in 1872. It is found in the fruits of apples, plums, pears, cherries, dates, peaches, and apricots.
Medical applications.
Sorbitol is used in bacterial culture media to distinguish the pathogenic from most other strains of "E. coli", as it is usually incapable of fermenting sorbitol, but 93% of known "E. coli" strains are capable of doing so.
A treatment using sorbitol and ion-exchange resin sodium polystyrene sulfonate (tradename Kayexalate), helps remove excess potassium ions when in a hyperkalaemic state. The resin exchanges sodium ions for potassium ions in the bowel, while sorbitol helps to eliminate it. In 2010 the U.S. FDA issued a warning of increased risk for GI necrosis with this combination.
Sorbitol is also used in the manufacture of softgels to store single doses of liquid medicines.
Health care, food, and cosmetic uses.
Sorbitol often is used in modern cosmetics as a humectant and thickener. Sorbitol often is used in mouthwash and toothpaste. Some transparent gels can be made only with sorbitol, as it has a refractive index sufficiently high for transparent formulations. It is also used frequently in "sugar free" chewing gum.
Sorbitol is used as a cryoprotectant additive (mixed with sucrose and sodium polyphosphates) in the manufacture of surimi, a processed fish paste. It is also used as a humectant in some cigarettes.
Sorbitol sometimes is used as a sweetener and humectant in cookies and other foods that are not identified as "dietary" items.
Miscellaneous uses.
A mixture of sorbitol and potassium nitrate has found some success as an amateur solid rocket fuel.
Sorbitol is identified as a potential key chemical intermediate for production of fuels from biomass resources. Carbohydrate fractions in biomass such as cellulose undergo sequential hydrolysis and hydrogenation in the presence of metal catalysts to produce sorbitol. Complete reduction of sorbitol opens the way to alkanes, such as hexane, which can be used as a biofuel. Hydrogen required for this reaction can be produced by aqueous phase reforming of sorbitol.
The above chemical reaction is exothermic; 1.5 moles of sorbitol generate approximately 1 mole of hexane. When hydrogen is co-fed, no carbon dioxide is produced.
It is also added after electroporation of yeasts in transformation protocols, allowing the cells to recover by raising the osmolarity of the medium.
Medical importance.
Aldose reductase is the first enzyme in the sorbitol-aldose reductase pathway responsible for the reduction of glucose to sorbitol, as well as the reduction of galactose to galactitol. Too much sorbitol trapped in retinal cells, the cells of the lens, and the Schwann cells that myelinate peripheral nerves can damage these cells, leading to retinopathy, cataracts and peripheral neuropathy, respectively. Aldose reductase inhibitors, which are substances that prevent or slow the action of aldose reductase, are currently being investigated as a way to prevent or delay these complications, which frequently occur in the setting of long-term hyperglycemia that accompanies poorly controlled diabetes. It is thought that these agents may help to prevent the accumulation of intracellular sorbitol that leads to cellular damage in diabetics.
Adverse medical effects.
People with untreated celiac disease often present sorbitol malabsorption, as a result of the small bowel damage. Sorbitol malabsorption is an important cause for persisting symptoms in patients already on a gluten-free diet. It has been suggested that sorbitol hydrogen breath test is a useful tool to detect celiac disease because of a strict correlation between cut-off value and intestinal lesions. Nevertheless, its use to diagnosis in clinical practice is not recommended by the Rome Consensus Conference on “Methodology and indications of H2-breath testing in gastrointestinal diseases” and may be indicated for research purpose.
It has been noted that the sorbitol added to sodium polystyrene sulfonate (SPS, used in the treatment of hyperkalemia) can cause complications in the GI tract, including bleeding, perforated colonic ulcers, ischemic colitis and colonic necrosis, particularly in patients with uremia. The authors of the paper in question cite a study on rats (both non-uremic and uremic) in which all uremic rats died on a sorbitol enema regimen, whilst uremic rats on non-sorbitol regimens – even with SPS included – showed no signs of colonic damage. In humans, it is suggested that the risk factors for sorbitol-induced damage include "... immunosuppression, hypovolemia, postoperative setting, hypotension after hemodialysis, and peripheral vascular disease." They conclude that SPS-sorbitol should be used with caution, and that "Physicians need to be aware of SPS-sorbitol GI side effects while managing hyperkalemia." 
Overdose effects.
Ingesting large amounts of sorbitol can lead to abdominal pain, flatulence, and mild to severe diarrhea. Sorbitol ingestion of per day as sugar-free gum has led to severe diarrhea leading to unintended weight loss of 11 kg (24 lb; 1 st 10 lb) in eight months, in a woman originally weighing 52 kg (115 lb; 8 st 3 lb); another patient required hospitalization after habitually consuming per day.

</doc>
<doc id="56361" url="https://en.wikipedia.org/wiki?curid=56361" title="Freeflying">
Freeflying

Freeflying is a skydiving discipline which began in the late 1980s when Olav Zipser began experimenting with non-traditional forms of bodyflight. Zipser founded the FreeFly Clowns as a two-person competitive team with Mike Vail in 1992, and was joined by Omar Alhegelan (1st ever FAI Freestyle World Cup & World Champion), Charles Bryan, and Stefania Martinengo in 1994. The FreeFly Clowns are also credited with opening the first school to teach freeflying, The First School of Modern SkyFlying.
Freeflying broke into the limelight in 1996 when the SSI Pro Tour added freeflying as a three-person competitive discipline at the second televised event (with Skysurfing), part of ESPN's Destination Extreme series. 150 countries watched the FreeFly Clowns (Olav Zipser, Charles Bryan and Omar Alhegelan) as they took 1st place in all four international competitions along with other teams like, the Flyboyz (Eli Thompson, Mike Ortiz, Knut Krecker, Fritz Pfnür), Team AirTime (Tony Urugallo, Jim O'Reilly, Peter Raymond, Brian Germain), and many other pioneers of freeflying showed off their best moves. In 1996 and 1997, the SSI Pro Tour staged eight televised events in both North America and Europe with $36,000 in cash prizes awarded to freefly teams. SSI invited the 1997 Pro World Champions, the Flyboyz, to participate in the 1998 ESPN X Games as an unofficial exhibition.
The resulting global television exposure made legends out of the FreeFly Clowns, the Flyboyz, and others. A once fledgling offshoot of the mainstream, freeflying now comprises fully one-half of the overall skydiving community.
Olav Zipser's Space Games used the space ball as a research and measuring device to provide a constant speed and direction from which individual athletes could be trained, rated, raced against each other and judged. The Space Games took FreeFlying to the next level from 1998.
Thanks to the efforts by Arizona Freeflight llc (Omar Alhegelan & Kama Mountz) who ran test competitions & wrote and submitted the rules for futures competitions; In 2000 FreeFly was accepted as a skydiving discipline by the International Parachute Commission (IPC) and the first official FreeFly National & international Championships were held worldwide.
Explanation.
Freeflying is an expansion of skydiving which includes the traditional belly-to-earth positions, but extends into vertical flight where the flyer is in an upright position (falling feet first) or in an inverted position (falling head first). These positions increase freefall speeds and make new types of formations and routines possible.
A freeflyer, in order to fully understand the aerodynamic power of his/her body in freefall, needs to first learn to control all of the skydiving forms: box position (belly-to-earth, traditional skydiving position), back flying (back-to-earth), head-up flying, head-down flying, and side flying. These positions are not held for the duration of a skydive. Freeflying can, and usually does, involve constant transitions in position and speeds, with vertical and horizontal orientations. This can involve constantly flowing skydives, with all positions explored, or more static skydives where flyers are concentrating on building a large formation while flying in one of these freefly positions.
Due to the increased freefall speed and potentially faster horizontal speeds, freeflying has dangers beyond that of a normal skydive. Extra care must be taken for freefall skydive groups to stay away from belly-to-earth skydivers to avoid collisions. Since most parachutes are not designed to be opened at speeds higher than that of normal belly flying, freeflyers must transition back to the "belly to earth" position and slow down their descent for several seconds before deploying their parachute.
While freeflying is a younger and more extreme addition to skydiving, it is becoming a popular event in competitions and world records.
Back flying.
Back flying is the ability to fly on the back in a stable and controlled fashion. This skill is critical so that when the flyer flips out of some of the more advanced positions they stay in control and do not endanger themselves or other skydivers.
Sit flying.
Sit flying is called such because it looks similar to the position taken while sitting in a chair. 
For flying a sit, the feet are oriented toward the relative wind and 90-degree bends maintained at the knees, hips, and shoulders. To move around, the flyer redirects the airflow in the opposite direction the jumper wants to go. Newtonian mechanics then push the flyer in the desired direction. Fall rate changes (descending faster or slower) can also be made.
Head down.
A person falling in the "head down" position has less cross-sectional area exposed to the air while falling, which results in much faster fall rates. Average speeds while flying head down are around . Due to the increased speed, every movement made can cause the skydiver to become unstable or disoriented; thus increasing the risk involved in skydiving.
Records.
The world's largest vertical (head down) formation took place on Friday, 31 July 2015, when a multinational team of 164 skydivers, some traveling at speeds of over 200 mph, linked over Skydive Chicago, in Ottawa, Illinois, USA. This broke the previous record of 138 linked skydivers, set on Saturday, 4 August 2012, also at Skydive Chicago.
Marc Hauser set the world record for the fastest horizontal free fall at 304 km/h in Empuriabrava, Spain, without specialized equipment, in October 2012. 

</doc>
<doc id="56368" url="https://en.wikipedia.org/wiki?curid=56368" title="Andrew Inglis Clark">
Andrew Inglis Clark

Andrew Inglis Clark (24 February 1848 -14 November 1907) was an Australian Founding Father and the principal author of the Australian Constitution, he was also an engineer, barrister, politician, electoral reformer and jurist. He initially qualified as an engineer, however he re-trained as a barrister in order to effectively fight for social causes which deeply concerned him. After a long political career, mostly spent as Attorney-General, he was appointed a Senior Justice of the Supreme Court of Tasmania. Despite being acknowledged as the leading expert on the Australian Constitution, he was never appointed to the High Court of Australia.
He popularised the Hare-Clark voting system, and introduced it to Tasmania. In addition Clark was a prolific author, though most of his writings were never published, rather they were circulated privately. Clark was also Vice-Chancellor of the University of Tasmania. Throughout his life, Clark was a progressive. He championed the rights of worker to organise through trades unions, universal suffrage (including women's suffrage) and the rights to a fair trial - all issues which today we take for granted, but were so radical in the 1880s that he was described as a 'communist' by the Hobart Mercury.
"Clark was an Australian Jefferson, who, like the great American Republican, fought for Australian independence; an autonomous judiciary; a wider franchise and lower property qualifications; fairer electoral boundaries; checks and balances between the judicature, legislature and executive; modern, liberal universities; and a Commonwealth that was federal, independent and based on natural rights."
Clark made significant contributions to the Australian Constitution. Of the 96 sections of his draft, 86 are recognisable in the 128 sections of the final document.
Yet he also had a rich and warm home life. He is described as "never too busy to mend a toy for a child, and his wife once wrote on hearing of his imminent return from America: 'to celebrate your return I must do something or "bust"'".
Early life and marriage.
Clark was born in Hobart, Tasmania, the son of a Scottish engineer, Alexander Clark. He was educated at Hobart High School. After leaving school, he was apprenticed to his family's engineering business, becoming a qualified engineer, and finally its business manager. His father had established a highly successful engineering business, based on an iron foundry. The business was also involved with industrial design and construction of flour mills, water mills, coal mines and other substantial undertaking.
He grew to manhood during the 1860s, when the major issue, even in remote Tasmania, was the American Civil War and emancipation. This last issue had an especial resonance in Tasmania where a form of slavery, transportation, had been abolished as recently as 1853. Convicts were still a common sight for years later. As late as 1902, Clark would publicly be moved to tears when discussing slavery. Clark became fascinated by all things American.
In 1872, Clark disappointed his father by leaving to study law, becoming an Articled clerk with R. P. Adams. He was called to the bar in 1877.
Clark, as a child attended a Baptist Sabbatical School until 1872 when the chapel was dissolved on a motion put by Clark due to the "lack of discipline and proper order of government in worship." He then joined a Unitarian chapel, which led him into contact with leading American Unitarians, including Moncure Conway and Oliver Wendell Holmes, Jr. The friendship formed with the latter would strongly influence his views and the development of the Clarks' draft of the Australian Constitution.
Early in his life, Clark developed a passion for justice and liberty. He joined the "Minerva Club" where he participated in debate on contemporary social issues. In 1874, he edited its journal "Quadrilateral". As a 'young ardent republican', he was also a member of the"American Club", where at the 1876 annual dinner, he declared "We have met here tonight in the name of the principles which were proclaimed by the founders of the Anglo-American Republic… and we do so because we believe those principles to be permanently applicable to the politics of the world". He was inspired by Italian Risorgimento, especially by Joseph Mazzini of whom he had a picture in every room. He became a radical, a democrat and a republican.
In 1878 he married Grace Ross, the daughter of a local shipbuilder John Ross, with whom he had five sons and two daughters:
One of the many mysteries of Clark's private life is the circumstances of his marriage. As the son of a prominent family, and a leading figure of his church who was marrying the daughter of a well-known business man, his marriage might have been expected to be a major social event. Instead, they slipped away to Melbourne, where they were married in the presence of a few friends.
Political career.
In 1878, Clark stood for election to the House of Assembly, despite his reputation as an extreme ultra-republican. He was attacked by the Hobart Mercury for "holding such very extreme ultra-republican, if not revolutionary, ideas" that his proper place should be among the 'Communists', and the Launceston Examiner as "stranger from Hobart". He was elected, unopposed to the electorate of Norfolk Plains. His election was largely due to the influence of Thomas Reiby, a political power broker and a recent Premier.
Clark was the founder of the Southern Tasmania Political Reform Association, whose agenda included manhood suffrage, fixed term parliaments, and electoral reform. While a member of the House of Assembly, Clark was regarded as republican and ultra-progressive. He was one of the few members legislate as a backbencher and introduce a private members bill. He failed to reform industrial law by amending the Master and Servant Act, but he succeeded with the Criminal Procedure Amendment Act in 1881. He also assisted with reframing the customs tariff.
In the 1882 election, Clark was defeated. He failed when he stood for election in 1884 (East Hobart) and 1886 (South Hobart). In 1887, Clark was re-elected, in a by-election as member for East Hobart. In 1888, he was re-elected as member for South Hobart and remained there until the seat was abolished 1897. He was then the member for Hobart until he resigned upon his appointment to the Supreme Court in 1898.
In March 1888, he became Attorney General in the government of Sir Philip Fysh. Since the Premier was in the Legislative Council, Clark was responsible for introducing legislation into the Assembly. Over the next five years he shepharded through the lower house much progressive and humanitarian legislation. His goal was to break the power of property in Tasmanian politics. The legislation covered such diverse reforms as legalising trades unions, providing parliamentary salaries, preventing cruelty to animals, reforming laws on lunacy, trusteeship and companies, the custody of children and the protection of children from neglect and abuse. He also introduced laws to restrict the immigration of Chinese. Clark failed in his attempts to impose a land tax, introduce universal (including female) suffrage and centralise the police.
Clark was the most important 19th-century Attorney-General of Tasmania. His considerable drafting skills enabled him to modernise and simplify the law over a number of areas. He introduced a total of 228 bills into the Assembly. His best known achievement as Attorney-General was the introduction of proportional representation based on the Hare-Clark system of the single transferrable vote;
One of the major political issues addressed by Clark during his career concerned the Tasmanian Main Line Railway - a railway which connected Tasmania's two main cites, Hobart and Launceston. In 1873, the Main Line Railway Company began the construction of the line, which opened in 1876. There were a series of disputes between the Company and the government over payments due to the Company under its Deed of Concession. Clark had spoken about the problem, advocating the acquisition of the Company by the government as early as 1878. With his dual qualifications as both an engineer and a lawyer, Clark was in a unique position to understand the issues involved. As Attorney-General, he was the government's chief negotiator.
In 1889, the Supreme Court awarded the Company arrears of interest. Clark urged the government to appeal, and in 1890 he went to England to argue the case before the Privy Council. Clark may have been a poor speaker in court, but he was a superb negotiator. It was his "forte". With full powers, he settled the case out of court by arranging the purchase of the Company's property by the government
In 1891, Clark returned to Tasmania from London by way of the United States. It was a fateful choice. He was introduced to a fellow Unitarian Oliver Wendell Holmes Jr, with whom he corresponded for the rest of his life. The contacts and people he met in Boston were to profoundly inform his views about political constitutions. Not the least of the consequences was the introduction of the term Commonwealth to describe the Australian polity.
In 1892, the fall of the Fysh government ended Clark's term as Attorney-General. When Sir Edward Braddon formed a government in 1894, Clark again became Attorney-General, the same year he was given the title 'Honourable' for life. He resigned in 1897, when his colleagues failed to consult him over the lease of Crown land to private interests, after which he became Leader of the Opposition. Clark left politics to become a Justice of the Supreme Court of Tasmania in 1898.
Hare-Clark electoral system.
In 1896, after several failed attempts, Clark was able to get a system of proportional representation adopted by the Tasmanian Parliament, but it was to be only on a trial basis for both Hobart (to elect 6 MPs) and Launceston (to elect 4 MPs). The Hare-Clark system was abandoned in 1901 and then re-adopted in 1907. It continues in use to the current day.
"The specific modification introduced by Mr A I Clark, Attorney-General for Tasmania, is the provision devised by him for eliminating the element of chance in the selection and distribution of quota-excesses or surplus transfer votes."
The provision described as Clark's own was to transfer all votes to 'next order of preference', rather than a random sample. This first 'Hare-Clark system', as it was immediately known, was renewed annually until suspended in 1902 and then finally re-introduced for the whole State in 1907.
In 1896, after several failed attempts Clark was able to get a system of proportional representation adopted by the Tasmanian Parliament:- see Single Transferable Vote. The Tasmanian system of STV (now copied by the Australian Capital Territory) has become known as "Hare-Clark" in his honour (and in honour of Thomas Hare.) Clark published "Studies in Australian Constitutional Law" (Melbourne) in 1901.
Early legal career.
Clark was called to bar in 1877. He soon gained a reputation as a criminal lawyer in a 'poisoning case', but went on to gain a large practice in civil and commercial law as well. He practiced law both while in and out of parliament. During those periods when he was not serving as Attorney-General, he worked hard to build a successful practice. He failed to find his fortune in the law due to his generosity and refusal 'to accept anything beyond a reasonable and modest fee'. In 1887 he went into partnership with Matthew Wilkes Simmons.
His career in private practice gave him a broad grounding in the law which stood him in good stead once he was promoted to the bench. Clark was knowledgeable in all branches of the law, but pre-eminent as a constitutional lawyer and jurist.
Clark, never in robust health, in fact described as "small, spare and nervous" by Alfred Deakin, died in 1907. He is buried in the old Queenborough Cemetery at Sandy Bay.

</doc>
<doc id="56369" url="https://en.wikipedia.org/wiki?curid=56369" title="Bell's theorem">
Bell's theorem

Bell's theorem is a ‘no-go theorem’ that draws an important distinction between quantum mechanics (QM) and the world as described by classical mechanics. This theorem is named after John Stewart Bell.
In its simplest form, Bell's theorem states:
Cornell solid-state physicist David Mermin has described the appraisals of the importance of Bell's theorem in the physics community as ranging from "indifference" to "wild extravagance". Lawrence Berkeley particle physicist Henry Stapp declared: "Bell's theorem is the most profound discovery of science."
Bell's theorem rules out local hidden variables as a viable explanation of quantum mechanics (though it still leaves the door open for non-local hidden variables). Bell concluded:
Bell summarized one of the least popular ways to address the theorem, superdeterminism, in a 1985 BBC Radio interview:
Historical background.
In the early 1930s, the philosophical implications of the current interpretations of quantum theory troubled many prominent physicists of the day, including Albert Einstein. In a well-known 1935 paper, Boris Podolsky and co-authors Einstein and Nathan Rosen (collectively "EPR") sought to demonstrate by the EPR paradox that QM was incomplete. This provided hope that a more-complete (and less-troubling) theory might one day be discovered. But that conclusion rested on the seemingly reasonable assumptions of "locality" and "realism" (together called "local realism" or "local hidden variables", often interchangeably). In the vernacular of Einstein: locality meant no instantaneous ("spooky") action at a distance; realism meant the moon is there even when not being observed. These assumptions were hotly debated in the physics community, notably between Nobel laureates Einstein and Niels Bohr.
In his groundbreaking 1964 paper, "On the Einstein Podolsky Rosen paradox", physicist John Stewart Bell presented an analogy (based on spin measurements on pairs of entangled electrons) to EPR's hypothetical paradox. Using their reasoning, he said, a choice of measurement setting here should not affect the outcome of a measurement there (and vice versa). After providing a mathematical formulation of locality and realism based on this, he showed specific cases where this would be inconsistent with the predictions of QM theory.
In experimental tests following Bell's example, now using quantum entanglement of photons instead of electrons, John Clauser and Stuart Freedman (1972) and Alain Aspect "et al". (1981) demonstrated that the predictions of QM are correct in this regard, although relying on additional unverifiable assumptions that open loopholes for local realism.
In October 2015, Hensen and co-workers reported that they performed a loophole-free Bell test which might force one to reject at least one of the principles of locality, realism, or freedom (the last leads to alternative superdeterministic theories). Two of these logical possibilities, non-locality and non-realism, correspond to well-developed interpretations of quantum mechanics, and have many supporters; this is not the case for the third logical possibility, non-freedom. Conclusive experimental evidence of the violation of Bell's inequality would drastically reduce the class of acceptable deterministic theories but would not falsify absolute determinism, which was described by Bell himself as “... not just inanimate nature running on behind-the-scenes clockwork, but with our behaviour, including our belief that we are free to choose to do one experiment rather than another, absolutely predetermined.” However, Bell himself considered absolute determinism an implausible solution.
Overview.
Bell's theorem states that any physical theory that incorporates local realism cannot reproduce all the predictions of quantum mechanical theory. Because numerous experiments agree with the predictions of quantum mechanical theory, and show differences between correlations that could not be explained by local hidden variables, the experimental results have been taken by many as refuting the concept of local realism as an explanation of the physical phenomena under test. For a hidden variable theory, if Bell's conditions are correct, the results that agree with quantum mechanical theory appear to indicate superluminal effects, in contradiction to the principle of locality.
These three key concepts – locality, realism, freedom – are highly technical and much debated. In particular, the concept of "realism" is now somewhat different from what it was in discussions in the 1930s. It is more precisely called "counterfactual definiteness"; it means that we may think of outcomes of measurements that were not actually performed as being just as much part of reality as those that were made. "Locality" is short for "local relativistic causality". (Currently accepted quantum field theories "are" local in the terminology of the Lagrangian formalism and axiomatic approach.) "Freedom" refers to the physical possibility of determining settings on measurement devices independently of the internal state of the physical system being measured.
The theorem is usually proved by consideration of a quantum system of two entangled qubits. The most common examples concern systems of particles that are entangled in spin or polarization. Quantum mechanics allows predictions of correlations that would be observed if these two particles have their spin or polarization measured in different directions. Bell showed that if a local hidden variable theory holds, then these correlations would have to satisfy certain constraints, called Bell inequalities. However, for the quantum correlations arising in the specific example considered, those constraints are not satisfied, hence the phenomenon being studied cannot be explained by a local hidden variables theory.
Following the argument in the Einstein–Podolsky–Rosen (EPR) paradox paper (but using the example of spin, as in David Bohm's version of the EPR argument), Bell considered an experiment in which there are "a pair of spin one-half particles formed somehow in the singlet spin state and moving freely in opposite directions." The two particles travel away from each other to two distant locations, at which measurements of spin are performed, along axes that are independently chosen. Each measurement yields a result of either spin-up (+) or spin-down (−); it means, spin in the positive or negative direction of the chosen axis.
The probability of the same result being obtained at the two locations depends on the relative angles at which the two spin measurements are made, and is strictly between zero and one for all relative angles other than perfectly parallel or antiparallel alignments (0° or 180°). Since total angular momentum is conserved, and since the total spin is zero in the singlet state, the probability of the same result with parallel (antiparallel) alignment is 0 (1). This last prediction is true classically as well as quantum mechanically.
Bell's theorem is concerned with correlations defined in terms of averages taken over very many trials of the experiment. The correlation of two binary variables is usually defined in quantum physics as the average of the products of the pairs of measurements. Note that this is different from the usual definition of correlation in statistics. The quantum physicist's "correlation" is the statistician's "raw (uncentered, unnormalized) product moment". They are similar in that, with either definition, if the pairs of outcomes are always the same, the correlation is +1; if the pairs of outcomes are always opposite, the correlation is -1; and if the pairs of outcomes agree 50% of the time, then the correlation is 0. The correlation is related in a simple way to the probability of equal outcomes, namely it is equal to twice the probability of equal outcomes, minus one.
Measuring the spin of these entangled particles along anti-parallel directions—i.e., along the same axis but in opposite directions, the set of all results is perfectly correlated. On the other hand, if measurements are performed along parallel directions they always yield opposite results, and the set of measurements shows perfect anti-correlation. This is in accord with the above stated probabilities of measuring the same result in these two cases. Finally, measurement at perpendicular directions has a 50% chance of matching, and the total set of measurements is uncorrelated. These basic cases are illustrated in the table below. Columns should be read as "examples" of pairs of values that could be recorded by Alice and Bob with time increasing going to the right.
With the measurements oriented at intermediate angles between these basic cases, the existence of local hidden variables could agree with a linear dependence of the correlation in the angle but, according to Bell's inequality (see below), could not agree with the dependence predicted by quantum mechanical theory, namely, that the correlation is the negative cosine of the angle. Experimental results match the curve predicted by quantum mechanics.
Over the years, Bell's theorem has undergone a wide variety of experimental tests. However, various common deficiencies in the testing of the theorem have been identified, including the "detection loophole" and the "communication loophole". Over the years experiments have been gradually improved to better address these loopholes. In 2015, the first experiment to simultaneously address all of the loopholes was performed.
To date, Bell's theorem is generally regarded as supported by a substantial body of evidence and there are few supporters of local hidden variables, though the theorem is continually the subject of study, criticism, and refinement.
Importance of the theorem.
Bell's theorem, derived in his seminal 1964 paper titled "On the Einstein Podolsky Rosen paradox", has been called, on the assumption that the theory is correct, "the most profound in science". Perhaps of equal importance is Bell's deliberate effort to encourage and bring legitimacy to work on the completeness issues, which had fallen into disrepute. Later in his life, Bell expressed his hope that such work would "continue to inspire those who suspect that what is proved by the impossibility proofs is lack of imagination."
The title of Bell's seminal article refers to the 1935 paper by Einstein, Podolsky and Rosen that challenged the completeness of quantum mechanics. In his paper, Bell started from the same two assumptions as did EPR, namely (i) "reality" (that microscopic objects have real properties determining the outcomes of quantum mechanical measurements), and (ii) "locality" (that reality in one location is not influenced by measurements performed simultaneously at a distant location). Bell was able to derive from those two assumptions an important result, namely Bell's inequality. The theoretical (and later experimental) violation of this inequality implies that at least one of the two assumptions must be false.
In two respects Bell's 1964 paper was a step forward compared to the EPR paper: firstly, it considered more hidden variables than merely the element of physical reality in the EPR paper; and Bell's inequality was, in part, liable to be experimentally tested, thus raising the possibility of testing the local realism hypothesis. Limitations on such tests to date are noted below. Whereas Bell's paper deals only with deterministic hidden variable theories, Bell's theorem was later generalized to stochastic theories as well, and it was also realised that the theorem is not so much about hidden variables, as about the outcomes of measurements that could have been taken instead of the one actually taken. Existence of these variables is called the assumption of realism, or the assumption of counterfactual definiteness.
After the EPR paper, quantum mechanics was in an unsatisfactory position: either it was incomplete, in the sense that it failed to account for some elements of physical reality, or it violated the principle of a finite propagation speed of physical effects. In a modified version of the EPR thought experiment, two hypothetical observers, now commonly referred to as "Alice" and "Bob", perform independent measurements of spin on a pair of electrons, prepared at a source in a special state called a "spin singlet state". It is the conclusion of EPR that once Alice measures spin in one direction (e.g. on the "x" axis), Bob's measurement in that direction is determined with certainty, as being the opposite outcome to that of Alice, whereas immediately before Alice's measurement Bob's outcome was only statistically determined (i.e., was only a probability, not a certainty); thus, either the spin in each direction is an "element of physical reality", or the effects travel from Alice to Bob instantly.
In QM, predictions are formulated in terms of probabilities — for example, the probability that an electron will be detected in a particular place, or the probability that its spin is up or down. The idea persisted, however, that the electron in fact has a "definite" position and spin, and that QM's weakness is its inability to predict those values precisely. The possibility existed that some unknown theory, such as a "hidden variables theory", might be able to predict those quantities exactly, while at the same time also being in complete agreement with the probabilities predicted by QM. If such a hidden variables theory exists, then because the hidden variables are not described by QM the latter would be an incomplete theory.
Local realism.
The concept local realism is formalized to state and prove Bell's theorem and generalizations. A common approach is the following:
Perfect anti-correlation would require . Implicit in assumption 1) above, the hidden parameter space has a probability measure and the expectation of a random variable on with respect to is written
where for accessibility of notation we assume that the probability measure has a probability density that therefore is nonnegative and integrates to . The hidden parameter is often thought of as being associated with the source but it can just as well also contain components associated with the two measurement devices.
Bell inequalities.
Bell inequalities concern measurements made by observers on pairs of particles that have interacted and then separated. Assuming local realism, certain constraints must hold on the relationships between the correlations between subsequent measurements of the particles under various possible measurement settings. Let and be as above. Define for the present purposes three correlation functions:
where is the number of measurements yielding "spin up" in the direction of measured by Alice (first subscript ) "and" "spin up" in the direction of measured by Bob. The other occurrences of are analogously defined.
The two-particle spin space is the tensor product of the two-dimensional spin Hilbert spaces of the individual particles. Each individual space is an irreducible representation space of the rotation group SO(3). The product space decomposes as a direct sum of irreducible representations with definite total spins and of dimensions and respectively. Full details may be found in Clebsch—Gordan decompostion. The total spin zero subspace is spanned by the singlet state in the product space, a vector explicitly given by
with adjoint in this representation
The way single particle operators act on the product space is exemplified below by the example at hand; one defines the tensor product of operators, where the factors are single particle operators, thus if are single particle operators,
and
etc, where the superscript in parentheses indicates on which Hilbert space in the tensor product space the action is intended and the action is defined by the right hand side. The singlet state has total spin as may be verified by application of the operator of total spin by a calculation similar to that presented below. 
The expectation value of the operator
in the singlet state can be calculated straightforwardly. One has, by definition of the Pauli matrices,
Upon left application of this on one obtains
Likewise, application (to the left) of the operator corresponding to on yields
The inner products on the tensor product space is defined by
Given this, the expectation value reduces to
With this notation, a concise summary of what follows can be made.
Original Bell's inequality.
The inequality that Bell derived can then be written as:
where and refer to three arbitrary settings of the two analysers. This inequality is however restricted in its application to the rather special case in which the outcomes on both sides of the experiment are always exactly anticorrelated whenever the analysers are parallel. The advantage of restricting attention to this special case is the resulting simplicity of the derivation. In experimental work the inequality is not very useful because it is hard, if not impossible, to create "perfect" anti-correlation.
This simple form does have the virtue of being quite intuitive. It is easily seen to be equivalent to the following elementary result from probability theory. Consider three (highly correlated, and possibly biased) coin-flips , and "Z", with the property that:
then "X" and "Z" must also yield the same outcome at least 98% of the time. The number of mismatches between "X" and "Y" (1/100) plus the number of mismatches between "Y" and "Z" (1/100) are together the "maximum possible" number of mismatches between "X" and "Z" (a simple Boole–Fréchet inequality).
Imagine a pair of particles that can be measured at distant locations. Suppose that the measurement devices have settings, which are angles—e.g., the devices measure something called spin in some direction. The experimenter chooses the directions, one for each particle, separately. Suppose the measurement outcome is binary (e.g., spin up, spin down). Suppose the two particles are perfectly anti-correlated—in the sense that whenever both measured in the same direction, one gets identically opposite outcomes, when both measured in opposite directions they always give the same outcome. The only way to imagine how this works is that both particles leave their common source with, somehow, the outcomes they will deliver when measured in any possible direction. (How else could particle 1 know how to deliver the same answer as particle 2 when measured in the same direction? They don't know in advance how they are going to be measured...). The measurement on particle 2 (after switching its sign) can be thought of as telling us what the same measurement on particle 1 would have given.
Start with one setting exactly opposite to the other. All the pairs of particles give the same outcome (each pair is either both spin up or both spin down). Now shift Alice's setting by one degree relative to Bob's. They are now one degree off being exactly opposite to one another. A small fraction of the pairs, say "f", now give different outcomes. If instead we had left Alice's setting unchanged but shifted Bob's by one degree (in the opposite direction), then again a fraction "f" of the pairs of particles turns out to give different outcomes. Finally consider what happens when both shifts are implemented at the same time: the two settings are now exactly two degrees away from being opposite to one another. By the mismatch argument, the chance of a mismatch at two degrees can't be more than twice the chance of a mismatch at one degree: it cannot be more than 2"f".
Compare this with the predictions from quantum mechanics for the singlet state. For a small angle , measured in radians, the chance of a different outcome is approximately formula_20 as explained by small-angle approximation. At two times this small angle, the chance of a mismatch is therefore about 4 times larger, since formula_21. But we just argued that it cannot be more than 2 times as large.
This intuitive formulation is due to David Mermin. The small-angle limit is discussed in Bell's original article, and therefore goes right back to the origin of the Bell inequalities.
CHSH inequality.
Generalizing Bell's original inequality, John Clauser, Michael Horne, Abner Shimony and R. A. Holt introduced the CHSH inequality, which puts classical limits on the set of four correlations in Alice and Bob's experiment, without any assumption of perfect correlations (or anti-correlations) at equal settings
Making the special choice formula_23, denoting formula_24, and assuming perfect anti-correlation at equal settings, perfect correlation at opposite settings, therefore formula_25 and formula_26, the CHSH inequality reduces to the original Bell inequality. Nowadays, (1) is also often simply called "the Bell inequality", but sometimes more completely "the Bell-CHSH inequality".
Derivation of CHSH inequality.
With abbreviated notation
the CHSH inequality can be derived as follows. Each of the four quantities is and each depends on . It follows that for any , one of and is zero, and the other is . From this it follows that
and therefore
At the heart of this derivation is a simple algebraic inequality concerning four variables, , which take the values only:
The CHSH inequality is seen to depend only on the following three key features of a local hidden variables theory: (1) realism: alongside of the outcomes of actually performed measurements, the outcomes of potentially performed measurements also exist at the same time; (2) locality, the outcomes of measurements on Alice's particle don't depend on which measurement Bob chooses to perform on the other particle; (3) freedom: Alice and Bob can indeed choose freely which measurements to perform.
The "realism" assumption is actually somewhat idealistic, and Bell's theorem only proves non-locality with respect to variables that only "exist" for metaphysical reasons. However, before the discovery of quantum mechanics, both realism and locality were completely uncontroversial features of physical theories.
Bell inequalities are violated by quantum mechanical predictions.
The measurements performed by Alice and Bob are spin measurements on electrons. Alice can choose between two detector settings labeled "a" and "a"′; these settings correspond to measurement of spin along the "z" or the "x" axis. Bob can choose between two detector settings labeled "b" and "b"′; these correspond to measurement of spin along the "z"′ or "x"′ axis, where the coordinate system is rotated 135° relative to the coordinate system. The spin observables are represented by the 2 × 2 self-adjoint matrices:
These are the Pauli spin matrices normalized so that the corresponding eigenvalues are . As is customary, we use the bra–ket notation to denote the eigenvectors of by
Let formula_33 be the spin singlet state for a pair of electrons discussed in the EPR paradox. This is a specially constructed state described by the following vector in the tensor product
Now let us apply the CHSH formalism to the measurements that can be performed by Alice and Bob.
The operators formula_36 correspond to Bob's spin measurements along "x"′ and "z"′. Note that the operators commute with the operators, so we can apply our calculation for the correlation. In this case, we can show that the CHSH inequality fails. In fact, a straightforward calculation shows that 
so that
Bell's Theorem: If the quantum mechanical formalism is correct, then the system consisting of a pair of entangled electrons cannot satisfy the principle of local realism. Note that is indeed the upper bound for quantum mechanics called Tsirelson's bound. The operators giving this maximal value are always isomorphic to the Pauli matrices.
Practical experiments testing Bell's theorem.
Experimental tests can determine whether the Bell inequalities required by local realism hold up to the empirical evidence.
Actually, most experiments have been performed using polarization of photons rather than spin of electrons (or other spin-half particles). The quantum state of the pair of entangled photons is not the singlet state, and the correspondence between angles and outcomes is different from that in the spin-half set-up. The polarization of a photon is measured in a pair of perpendicular directions. Relative to a given orientation, polarization is either vertical (denoted by V or by +) or horizontal (denoted by H or by -). The photon pairs are generated in the quantum state
where formula_41 and formula_42 denotes the state of a single vertically or horizontally polarized photon, respectively (relative to a fixed and common reference direction for both particles).
When the polarization of both photons is measured in the same direction, both give the same outcome: perfect correlation. When measured at directions making an angle 45 degrees with one another, the outcomes are completely random (uncorrelated). Measuring at directions at 90 degrees to one another, the two are perfectly anti-correlated. In general, when the polarizers are at an angle to one another, the correlation is . So relative to the correlation function for the singlet state of spin half particles, we have a positive rather than a negative cosine function, and angles are halved: the correlation is periodic with period instead of .
Bell's inequalities are tested by "coincidence counts" from a Bell test experiment such as the optical one shown in the diagram. Pairs of particles are emitted as a result of a quantum process, analysed with respect to some key property such as polarisation direction, then detected. The setting (orientations) of the analysers are selected by the experimenter.
Bell test experiments to date overwhelmingly violate Bell's inequality.
Two classes of Bell inequalities.
The "fair sampling" problem was faced openly in the 1970s. In early designs of their 1973 experiment, Freedman and Clauser used "fair sampling" in the form of the Clauser–Horne–Shimony–Holt (CHSH) hypothesis. However, shortly afterwards Clauser and Horne made the important distinction between inhomogeneous (IBI) and homogeneous (HBI) Bell inequalities. Testing an IBI requires that we compare certain coincidence rates in two separated detectors with the singles rates of the two detectors. Nobody needed to perform the experiment, because singles rates with all detectors in the 1970s were at least ten times all the coincidence rates. So, taking into account this low detector efficiency, the QM prediction actually satisfied the IBI. To arrive at an experimental design in which the QM prediction violates IBI we require detectors whose efficiency exceeds 82.8% for singlet states, but have very low dark rate and short dead and resolving times. This is now within reach.
Practical challenges.
Because, at that time, even the best detectors didn't detect a large fraction of all photons, Clauser and Horne recognized that testing Bell's inequality required some extra assumptions. They introduced the "No Enhancement Hypothesis" (NEH):
Given this assumption, there is a Bell inequality between the coincidence rates with polarizers and coincidence rates without polarizers.
The experiment was performed by Freedman and Clauser, who found that the Bell's inequality was violated. So the no-enhancement hypothesis cannot be true in a local hidden variables model.
While early experiments used atomic cascades, later experiments have used parametric down-conversion, following a suggestion by Reid and Walls, giving improved generation and detection properties. As a result, the most recent experiments with photons no longer suffer from the detection loophole (see Bell test experiments). This makes the photon the first experimental system for which all main experimental loopholes have been surmounted, albeit presently only in separate experiments (Giustina et al. (2013), "Bell violation using entangled photons without the fair-sampling assumption", Nature 497, 227–230; B.G. Christensen et al. (2013), "Detection-Loophole-Free Test of Quantum Nonlocality, and Applications", arXiv:1306.5772).
Metaphysical aspects.
Most advocates of the hidden-variables idea believe that experiments have ruled out local hidden variables. They are ready to give up locality, explaining the violation of Bell's inequality by means of a non-local hidden variable theory, in which the particles exchange information about their states. This is the basis of the Bohm interpretation of quantum mechanics, which requires that all particles in the universe be able to instantaneously exchange information with all others. A 2007 experiment ruled out a large class of non-Bohmian non-local hidden variable theories.
If the hidden variables can communicate with each other faster than light, Bell's inequality can easily be violated. Once one particle is measured, it can communicate the necessary correlations to the other particle. Since in relativity the notion of simultaneity is not absolute, this is unattractive. One idea is to replace instantaneous communication with a process that travels backwards in time along the past light cone. This is the idea behind a transactional interpretation of quantum mechanics, which interprets the statistical emergence of a quantum history as a gradual coming to agreement between histories that go both forward and backward in time.
A few advocates of deterministic models have not given up on local hidden variables. For example, Gerard 't Hooft has argued that the superdeterminism loophole cannot be dismissed.
A possible (but not universally accepted) solution is offered by the many worlds theory of quantum mechanics. According to this, not only is collapse of the wave function illusory, but the apparent random branching of possible futures when quantum systems interact with the macroscopic world is also an illusion. Measurement does not lead to a random choice of possible outcome; rather, the only ingredient of quantum mechanics is the unitary evolution of the wave function. All possibilities co-exist forever and the only reality is the quantum mechanical wave function. According to this view, two distant observers both split into superpositions when measuring a spin. The Bell inequality violations are no longer counterintuitive, because it is not clear which copy of the observer B will seen by observer A when they compare notes. If reality includes all the different outcomes, locality in physical space (not outcome space) places no restrictions on how the split observers can meet up.
This point underlines the fact that the argument that realism is incompatible with quantum mechanics and locality depends on a particular formalization of the concept of realism. In its weakest form, the assumption underpinning that particular formalization is called counterfactual definiteness. This is the assumption that outcomes of measurements that are not performed are just as real as those of measurements that were performed. Counterfactual definiteness is an uncontroversial property of all classical physical theories prior to quantum theory, due to their determinism. Many worlds interpretations are not only counterfactually indefinite, but are also factually indefinite. The results of all experiments, even ones that have been performed, are not uniquely determined.
If one chooses to reject counterfactual definiteness, reality has been made smaller, and there is no non-locality problem. On the other hand, one is thereby introducing irreducible or intrinsic randomness into our picture of the world: randomness that cannot be "explained" as merely the reflection of our ignorance of underlying, variable, physical quantities. Non-determinism becomes a fundamental property of nature.
Assuming counterfactual definiteness, reality has been enlarged, and there is a non-locality problem. On the other hand, in the many-worlds interpretation of quantum mechanics, reality consists only of a deterministically evolving wave function and non-locality is a non-issue.
There have also been repeated claims that Bell's arguments are irrelevant because they depend on hidden assumptions that, in fact, are questionable—though none of these claims have ever achieved much support. For example, E. T. Jaynes claimed in 1989 that there are two hidden assumptions in Bell's theorem that could limit its generality. According to him:
However, Richard D. Gill has argued that Jaynes misunderstood Bell's analysis. Gill points out that in the same conference volume in which Jaynes argues against Bell, Jaynes confesses to being extremely impressed by a short proof by Steve Gull presented at the same conference, that the singlet correlations could not be reproduced by a computer simulation of a local hidden variables theory. According to Jaynes (writing nearly 30 years after Bell's landmark contributions), it would probably take us another 30 years to fully appreciate Gull's stunning result.
A recent flurry of activity about implications for determinism arose with the paper: "The Free Will Theorem" which stated "the response of a spin 1 particle to a triple experiment is free—that is to say, is not a function of properties of that part of the universe that is earlier than this response with respect to any given inertial frame." This theorem raised awareness of a tension between determinism fully governing an experiment (on the one hand) and Alice and Bob being free to choose any settings they like for their observations (on the other). The philosopher David Hodgson supports this theorem as showing that determinism is "unscientific", and that quantum mechanics allows observers (at least in some instances) the freedom to make observations of their choosing, thereby leaving the door open for free will.
Final remarks.
The violations of Bell's inequalities, due to quantum entanglement, provide near definitive demonstrations of something that was already strongly suspected: that quantum physics cannot be represented by any version of the classical picture of physics. Some earlier elements that had seemed incompatible with classical pictures included complementarity and wavefunction collapse. The Bell violations show that no resolution of such issues can avoid the ultimate strangeness of quantum behavior.
The EPR paper "pinpointed" the unusual properties of the "entangled states", e.g. the above-mentioned singlet state, which is the foundation for present-day applications of quantum physics, such as quantum cryptography; one application involves the measurement of quantum entanglement as a physical source of bits for Rabin's oblivious transfer protocol. This non-locality was originally supposed to be illusory, because the standard interpretation could easily do away with action-at-a-distance by simply assigning to each particle definite spin-states for all possible spin directions. The EPR argument was: therefore these definite states exist, therefore quantum theory is incomplete, since they do not appear in the theory. Bell's theorem showed that the "entangledness" prediction of quantum mechanics has a degree of non-locality that cannot be explained away by any local theory.
What is powerful about Bell's theorem is that it doesn't refer to any particular physical theory. It shows that nature violates the most general assumptions behind classical pictures, not just details of some particular models. No combination of local deterministic and local random variables can reproduce the phenomena predicted by quantum mechanics and repeatedly observed in experiments.
Further reading.
The following are intended for general audiences.

</doc>
<doc id="56371" url="https://en.wikipedia.org/wiki?curid=56371" title="Mass (liturgy)">
Mass (liturgy)

Mass is one of the names by which the sacrament of the Eucharist is commonly called in the Catholic Church, Western Rite Orthodox churches and many Old Catholic, Anglican, and Lutheran churches, as well as some Methodist churches. Apart from "Eucharist" others are the "Lord's Supper", the "Breaking of Bread", the "Eucharistic assembly (synaxis)", the "memorial of the Lord's Passion and Resurrection", the "Holy Sacrifice", the "Holy and Divine Liturgy" and "Holy Communion". In these denominations, the term "Mass" often refers to the entire church service in general. Some Protestants employ terms such as "Divine Service" or "service of worship", rather than the word "Mass", although other Protestants, such as Anglicans and Lutherans, use the word. For the celebration of the Eucharist in Eastern churches, including those in full communion with the Holy See, other terms such as the "Divine Liturgy", the "Qurbono Qadisho" or "Holy Qurbana" and the "Badarak" are normal.
Etymology.
The English noun "mass" is derived from Middle Latin "missa". The Latin word was adopted in Old English as "mæsse" (via a Vulgar Latin form "*messa"), and was sometimes glossed as "sendnes" (i.e. "a sending, dismission"). 
The Latin term "missa" itself was in use by the 6th century.
It is most likely derived from the concluding formula "Ite, missa est" ("Go; the dismissal is made"); "missa" here is a Late Latin substantive corresponding to classical "missio".
Historically, however, there have been other explanations of the noun "missa", i.e. as not derived from the formula "ite, missa est".
Fortescue (1910) cites older, "fanciful" etymological explanations, notably a latinization of Hebrew "matzâh" (מַצָּה) "unleavened bread; oblation", a derivation favoured in the 16th century by Reuchlin and Luther, or Greek "initiation", or even Germanic "mese" "assembly".
Already Du Cange (1678) reports "various opinions on the origin" of the noun "missa" "mass",
including the derivation from Hebrew "matzah" ("Missah, id est, oblatio"), here attributed to Caesar Baronius. The Hebrew derivation is learned speculation from 16th-century philology; medieval authorities did derive the noun "missa" from the verb "mittere", but not in connection with the formula "ite, missa est".
Thus, "De divinis officiis" (9th century) explains the word as "a mittendo, quod nos mittat ad Deo" ("from 'sending', that which sends us towards God"), 
while Rupert of Deutz (early 12th century) derives it from a "dismissal" of the "enmities which had been between God and men" ("inimicitiarum quæ erant inter Deum et homines").
Mass in the Catholic Church.
The Catholic Church sees the Mass or Eucharist as "the source and summit of the Christian life", to which the other sacraments are oriented. The Catholic Church believes that the Mass is exactly the same sacrifice that Jesus Christ offered on the Cross at Calvary. The term "Mass" is generally used only in the Latin Church, while the Byzantine Rite Eastern Catholic Churches use the analogous term "Divine Liturgy" and other Eastern Catholic Churches have terms such as Holy Qurbana. Although similar in outward appearance to the Anglican Mass or Lutheran Mass, the Catholic Church distinguishes between its own Mass and theirs on the basis of what it views as the validity of the orders of their clergy, and as a result, does not ordinarily permit intercommunion between members of these Churches. However, in the Decree on Ecumenism, produced by Vatican II in 1964, the Catholic Church also notes its understanding that when other faith groups (such as Lutherans, Anglicans, and Presbyterians) "commemorate His death and resurrection in the Lord's Supper, they profess that it signifies life in communion with Christ and look forward to His coming in glory."
Within the fixed structure outlined below, which is specific to the Ordinary Form of the Roman Rite, the Scripture readings, the antiphons sung or recited during the entrance procession or communion, and certain other prayers vary each day according to the liturgical calendar. For more information regarding the structure and history of the approved Extraordinary Form of the Mass in the Roman Rite see Mass (Catholic Church)
Introductory rites.
The priest enters, with a deacon, if there is one, and altar servers (who may act as crucifer, torch-bearers and thurifer). After making the sign of the cross and greeting the people liturgically, he begins the Act of Penitence. This concludes with the priest's prayer of absolution, "which, however, lacks the efficacy of the Sacrament of Penance". The Kyrie, eleison (Lord, have mercy), is sung or said, followed by the Gloria in excelsis Deo (Glory to God in the highest), an ancient praise, if appropriate for the liturgical season. The Introductory Rites are brought to a close by the Collect Prayer.
Liturgy of the Word.
On Sundays and solemnities, three Scripture readings are given. On other days there are only two. If there are three readings, the first is from the Old Testament (a term wider than "Hebrew Scriptures", since it includes the Deuterocanonical Books), or the Acts of the Apostles during Eastertide. The first reading is followed by a psalm, either sung responsorially or recited. The second reading is from the New Testament, typically from one of the Pauline epistles. A Gospel Acclamation is then sung as the Book of the Gospels is processed, sometimes with incense and candles, to the ambo. The final reading and high point of the Liturgy of the Word is the proclamation of the Gospel by the deacon or priest. At least on Sundays and Holy Days of Obligation, a homily, a sermon that draws upon some aspect of the readings or the liturgy of the day, is then given. Finally, the Creed is professed on Sundays and solemnities, and it is desirable that in Masses celebrated with the people the Universal Prayer or Prayer of the Faithful should usually follow.
Liturgy of the Eucharist.
The Liturgy of the Eucharist begins with the preparation of the altar and gifts, after which the congregation stands, as the priest gives the exhortation to pray, "Pray, brethren, that my sacrifice and yours may be acceptable to God, the almighty Father." The congregation responds: "May the Lord accept the sacrifice at your hands, for the praise and glory of his name, for our good, and the good of all his holy Church." The priest then pronounces the variable prayer over the gifts.
The Eucharistic Prayer, "the centre and high point of the entire celebration", then begins with a dialogue between priest and people. The priest continues with one of many Eucharistic Prayer thanksgiving prefaces, which lead to the reciting of the Sanctus acclamation. The Eucharistic Prayer includes the epiclesis, a prayer that the gifts offered may by the power of the Holy Spirit become the body and blood of Christ. The central part is the Institution Narrative and Consecration, recalling the words and actions of Jesus at his Last Supper, which he told his disciples to do in remembrance of him. Immediately after the Consecration and the display to the people of the consecrated elements, the priest says: "The mystery of faith", and the people pronounce the acclamation, using one of the three prescribed formulae. It concludes with a doxology, with the priest lifting up the paten with the host and the deacon (if there is one) the chalice, and the singing or recitation of the Amen by the people.
Communion rite.
All together recite or sing the "Lord's Prayer" ("Pater Noster" or "Our Father"). The priest introduces it with a short phrase and follows it up with a prayer called the embolism and the people respond with the doxology. The sign of peace is exchanged and then the "Lamb of God" ("Agnus Dei" in Latin) litany is sung or recited, while the priest breaks the host and places a piece in the main chalice; this is known as the rite of fraction and commingling.
The priest then presents the transubstantiated elements to the congregation, saying: "Behold the Lamb of God, behold him who takes away the sins of the world. Blessed are those called to the supper of the Lamb." Then all repeat: "Lord, I am not worthy that you should enter under my roof, but only say the word and my soul shall be healed." The priest then receives Communion and, with the help, if necessary, of extraordinary ministers, distributes Communion to the people, who usually approach in procession and receives standing. Singing by all the faithful during the Communion procession is encouraged, to highlight the communitarian nature of the Communion bread. Silence is called for following the Communion procession. A Prayer After Communion is then proclaimed by the priest while all stand.
Concluding rite.
The priest imparts a simple blessing or a solemn blessing to those present. The deacon or, in his absence, the priest himself then dismisses the people, choosing one of four formulas, of which the first is "Ite, missa est" in Latin or its equivalent in other languages. The congregation responds: "Thanks be to God." The priest and other ministers then leave, often to the accompaniment of a recessional hymn.
Mass in Anglicanism.
"Mass" is one of many terms used to describe the Eucharist in the Anglican tradition. More frequently, the term used is either "Holy Communion", "Holy Eucharist", or the "Lord's Supper". Occasionally the term used in Eastern churches, the "Divine Liturgy", is also used. In the English-speaking Anglican world, the term used often identifies the Eucharistic theology of the person using it. "Mass" is frequently used by Anglo-Catholics.
Structure of the rite.
The various Eucharistic liturgies used by national churches of the Anglican Communion have continuously evolved from the 1549 and 1552 editions of the "Book of Common Prayer" which both owed their form and contents chiefly to the work of Thomas Cranmer, who had rejected the medieval theology of the Mass in about 1547. Although the 1549 rite retained the traditional sequence of the Mass, its underlying theology was Cranmer's and the four-day debate in the House of Lords during December 1548 makes it clear that this had already moved far beyond traditional Catholicism. In the 1552 revision, this was made clear by the restructuring of the elements of the rite while retaining nearly all the language so that it became, in the words of an Anglo-Catholic liturgiologist (Arthur Couratin) "a series of communion devotions; disembarrassed of the Mass with which they were temporarily associated in 1548 and 1549". Some rites, such as the 1637 Scottish rite and the 1789 rite in the United States, went back to the 1549 model. From the time of the Elizabethan Settlement in 1559 the services allowed for a certain variety of theological interpretation. Today's rites generally follow the same general five-part shape(some or all of the following elements may be altered, transposed or absent depending on the rite, the liturgical season and use of the province or national church):
The liturgy is divided into two main parts: The Liturgy of the Word (Gathering, Proclaiming and Hearing the Word, Prayers of the People) and the Liturgy of the Eucharist (together with the Dismissal), but the entire liturgy itself is also properly referred to as the Holy Eucharist. The sequence of the liturgy is almost identical to the Roman Rite, except the Confession of Sin ends the Liturgy of the Word in the Anglican rites in North America, while in the Roman Rite and in Anglican rites in many jurisdictions the Confession is near the beginning of the service.
Special Masses.
The Anglican tradition includes separate rites for Nuptial Masses, Funeral Masses, and votive Masses. The Eucharist is an integral part of many other sacramental services, including ordination and Confirmation.
Ceremonial.
Some Anglo-Catholic parishes use Anglican versions of the Tridentine Missal, such as the "English Missal", "The Anglican Missal", or the "American Missal", for the celebration of Mass, all of which are intended primarily for the celebration of the Eucharist. Many Anglo-Catholic parishes in the Church of England use "A Manual of Anglo-Catholic Devotion" (successor to the earlier "A Manual of Catholic Devotion"). In the Episcopal Church USA, a traditional-language, Anglo-Catholic adaptation of the 1979 "Book of Common Prayer" has been published ("An Anglican Service Book").
All of these books contain such features as meditations for the presiding celebrant(s) during the liturgy, and other material such as the rite for the blessing of palms on Palm Sunday, propers for special feast days, and instructions for proper ceremonial order. These books are used as a more expansively Catholic context in which to celebrate the liturgical use found in the Book of Common Prayer and related liturgical books.
These are often supplemented in Anglo-Catholic parishes by books specifying ceremonial actions, such as "A Priest's Handbook" by Dennis G. Michno, "Ceremonies of the Eucharist" by Howard E. Galley, "" by C.P.A. Burnett, and "Ritual Notes" by E.C.R. Lamburn. Other guides to ceremonial include the General Instruction of the Roman Missal, "Ceremonies of the Modern Roman Rite" (Peter Elliott), "Ceremonies of the Roman Rite Described" (Adrian Fortescue), and "The Parson's Handbook" (Percy Dearmer). In Evangelical Anglican parishes, the rubrics detailed in the "Book of Common Prayer" are sometimes considered normative.
Mass in Lutheranism.
In the Book of Concord, Article XXIV ("Of the Mass") of the Augsburg Confession (1530) begins thus: "Falsely are our churches accused of abolishing the Mass; for the Mass is retained among us, and celebrated with the highest reverence. We do not abolish the Mass but religiously keep and defend it... we keep the traditional liturgical form... In our churches Mass is celebrated every Sunday and on other holy days, when the sacrament is offered to those who wish for it after they have been examined and absolved (Article XXIV)".
Martin Luther rejected parts of the Roman Rite Catholic Mass, specifically the Canon of the Mass, which, as he argued, did not conform with . That verse contrasts the Old Testament priests, who needed to make a sacrifice for sins on a regular basis, with the single priest Christ, who offers his body only once as a sacrifice. The theme is carried out also in , , and . Luther composed as a replacement a revised Latin-language rite, "Formula missae" in 1523 and the vernacular Deutsche Messe in 1526.
As such, historically, the Lutheran Church has stated that the Lutheran Mass is "the only Mass founded in the Scriptures of God, in accordance with the plain and incontestable institution of the Saviour."
In German, the Scandinavian languages, Finnish, and some English Lutherans, use the word "Mass" for their corresponding service, but in most English-speaking churches, they call it the "Divine Service", "Holy Communion, or "the Holy Eucharist".
The celebration of the Mass in Lutheran churches follows a similar pattern to other traditions, starting with public confession (Confiteor) by all and a Declaration of Grace said by the priest or pastor. There follow the "Introit", "Kyrie", "Gloria", collect, the readings with an alleluia (alleluia is not said during Lent), homily (or sermon) and recitation of the Nicene Creed. The Service of the Eucharist includes the General intercessions, Preface, Sanctus and Eucharistic Prayer, elevation of the host and chalice and invitation to the Eucharist. The Agnus Dei is chanted while the clergy and assistants first commune, followed by lay communicants. Postcommunion prayers and the final blessing by the priest ends the Mass. A Catholic or Anglican of the Anglo-Catholic party would find its elements familiar, in particular the use of the sign of the cross, kneeling for prayer and the Eucharistic Prayer, bowing to the processional crucifix, kissing the altar, incense (among some), chanting, and vestments.
Lutheran churches often celebrate the Eucharist each Sunday, if not at every worship service. This aligns with Luther's preference and the Lutheran confessions. Also, eucharistic ministers take the sacramental elements to the sick in hospitals and nursing homes. The practice of weekly communion is increasingly the norm again in most Lutheran parishes throughout the world. The bishops and pastors of the larger Lutheran bodies have strongly encouraged this restoration of the weekly Mass.
The celebration of the Eucharist may form a part of services for weddings, funerals, retreats, the dedication of a church building and annual synod conventions. The Mass is also an important aspect of ordinations and confirmations in Lutheran churches.
Calendrical usage.
The English suffix "" (equivalent to modern English "mass") can label certain prominent (originally religious) feasts or seasons based on a traditional liturgical year, for example:
External links.
Roman Catholic doctrine
Present form of the Roman rite of the Mass
Tridentine form of the Roman rite of the Mass
Anglican Doctrine and practice
Lutheran doctrine

</doc>
<doc id="56372" url="https://en.wikipedia.org/wiki?curid=56372" title="Framing error">
Framing error

Framing error can refer to the following:

</doc>
<doc id="56374" url="https://en.wikipedia.org/wiki?curid=56374" title="List of major opera composers">
List of major opera composers

This list provides a guide to opera composers, as determined by their presence on a majority of compiled lists of significant opera composers. (See the "Lists Consulted" section for full details.) The composers run from Jacopo Peri, who wrote the first ever opera in late 16th century Italy, to John Adams, one of the leading figures in the contemporary operatic world. The brief accompanying notes offer an explanation as to why each composer has been considered major. Also included is a section about major women opera composers, compiled from the same lists. For an introduction to operatic history, see opera. The organisation of the list is by birthdate.
Major opera composers.
1550–1699.
<onlyinclude>
Female opera composers.
A number of reasons, including the high cost of production and high status of opera, have been suggested to explain the relatively few women who have been composers of opera, and no woman composer met the criteria for inclusion above. However, some experts in our sample disagreed, and named either or both of the women below as comparable to those already listed:
References.
Notes
Lists consulted.
This list was compiled by consulting ten lists of great opera composers, created by recognized authorities in the field of opera, and selecting all of the composers who appeared on at least six of these (i.e. all composers on a majority of the lists). Judith Weir appears on four of the ten lists consulted, more than any other female composer in the sample. The lists used were:
Note:

</doc>
<doc id="56375" url="https://en.wikipedia.org/wiki?curid=56375" title="Aniara">
Aniara

Aniara () is a poem of science fiction written by Swedish Nobel laureate Harry Martinson in 1956. It was published on 13October 1956. The title comes from ancient Greek ἀνιαρός, "sad, despairing", plus special resonances that the sound "a" had for Martinson.
"Aniara" is an effort to " between science and poetry, between the wish to understand and the difficulty to comprehend." Martinson translates scientific imagery into the poem: for example, the "curved space" from Einstein's general theory of relativity is likely an inspiration for Martinson's description of the cosmos as "a bowl of glass." Martinson also said he was influenced by Paul Dirac.
Structure and content.
The poem consists of 103 cantos and relates the tragedy of a space ship ( long and wide) which, originally bound for Mars with a cargo of colonists from the ravaged Earth, after an accident is ejected from the solar system and into an existential struggle. The style is symbolic, sweeping and innovative for its time, with creative use of neologisms to suggest the science fictional setting:
The first 29 cantos of "Aniara" had previously been published in Martinson's collection "Cikada" (1953), under the title "Sången om Doris och Mima" ("The Song of Doris and Mima"), relating the departure from Earth, the accidental near-collision with an asteroid (incidentally named Hondo, another name for the main Japanese isle where Hiroshima is situated) and ejection from the solar system, the first few years of increasing despair and distractions of the passengers, until news is received of the destruction of their home port (and perhaps of Earth). According to Martinson, he dictated the initial cycle as in a fever after a troubling dream, affected by the Cold War and the Soviet suppression of the 1956 Hungarian revolution; in another version, the first 29 cantos were said to be inspired by an astronomic observation of Andromeda Galaxy.
One of the major themes explored is the nature and necessity of art, symbolised by the semi-mystical machinery of the "Mima", who relieves the ennui of crew and passengers with scenes of far-off times and places, and whose operator is also the sometimes naïve main narrator. The rooms of Mima, according to Martinson, represent different kinds of life styles or forms of consciousness. The accumulated destruction the Mima witnesses impels her to destroy herself in despair, to which she, the machine, is finally moved by the "white tears of the granite" melted by the "phototurb" which annihilates their home port, the great city of Dorisburg. Without the succour of the Mima, the erstwhile colonists seek distraction in sensual orgies, memories of their own and earlier lives, low comedy, religious cults, observations of strange astronomical phenomena, empty entertainments, science, routine tasks, brutal totalitarianism, and in all kinds of human endeavour, but ultimately cannot face the emptiness outside and inside.
In form, the poems are metrical and mostly rhymed, using both traditional and individual forms, several alluding to a wide range of Swedish and Nordic poetry, such as the Finnish Kalevala.
Adaptations.
An opera by Karl-Birger Blomdahl also called "Aniara" premiered in 1959 with a libretto by Erik Lindegren based on Martinson's poem; it was also staged in Hamburg, Brussels and Darmstadt.
Swedish musician Kleerup released an album based on "Aniara" in 2012.
A melding of Aniara and Beethoven's opera Fidelio was staged by the Opéra de Lyon under the direction of American artistt Gary Hill in 2013.
The fourth album from the Swedish progressive metal band Seventh Wonder called "The Great Escape" is based on "Aniara".
Translations.
"Aniara" was translated into English as "Aniara, A Review of Man in Time and Space" by Hugh MacDiarmid and E. Harley Schubert in 1956. It was translated again into English by Stephen Klass and Leif Sjöberg for a 1999 edition. The book is not currently in print.
Reception.
Theodore Sturgeon, reviewing a 1964 American edition for a genre audience, declared that "Martinson's achievement here is an inexpressible, immeasurable sadness. transcends panic and terror and even despair [and leaves you in the quiet immensities, with the feeling that you have spent time, and have been permanently tinted, by and with an impersonal larger-than-God force."
Cultural references.
The poem was referenced in Vernor Vinge's hard science fiction novel "A Fire Upon the Deep".
It was also an influence for Poul Anderson's hard science fiction novel "Tau Zero".
The song "On aika soittaa sinfonia" ("It's time to play a symphony") on the Finnish rock musician Tuomari Nurmio's critically acclaimed 1982 album Punainen Planeetta ("The Red Planet") is inspired by the poem.
The Swedish progressive metal band Seventh Wonder's 2010 album The Great Escape (Seventh Wonder album) contains a 30-minute track of the same name which is based on the "Aniara" saga.
The interior design of the restaurant at the First Hotel in the Swedish town of Olofström is inspired by the poem.

</doc>
<doc id="56379" url="https://en.wikipedia.org/wiki?curid=56379" title="The Brothers Johnson">
The Brothers Johnson

The Brothers Johnson were an American funk and R&B band consisting of American musicians and brothers George ("Lightnin' Licks") and Louis E. Johnson ("Thunder Thumbs"). They achieved their greatest success from the mid-1970s to early '80s, with three singles topping the R&B charts ("I'll Be Good to You", "Strawberry Letter 23", and "Stomp!").
Background.
Formation.
Guitarist/vocalist George and bassist/vocalist Louis formed the band Johnson Three Plus One with older brother Tommy and their cousin Alex Weir while attending school in Los Angeles, California. When they became professionals, the band backed such touring R&B acts as Bobby Womack and the Supremes. George and Louis Johnson later joined Billy Preston's band and wrote "Music in My Life" and "The Kids and Me" for him before leaving his group in 1973. In 1976, The Brothers covered the Beatles' song, "Hey Jude", for the ephemeral musical documentary "All This and World War II".
Quincy Jones hired them to play on his LP "Mellow Madness", and recorded four of their songs, including "Is It Love That We're Missing?" and "Just a Taste of Me".
After touring with various artists including Bobby Womack and Billy Preston, they were hired by Quincy Jones for a tour in Japan and produced their debut album "Look Out For #1", released in March 1976 (#9 US) Their "Right on Time" album was released in May 1977 and reached number 13 on the Billboard Hot 200. "Blam!!" came out in August 1978 and reached number 7 on the Billboard 200.
Two of the duo's songs were featured on the soundtrack of the 1976 film "Mother, Jugs & Speed". The instrumental track "Thunder Thumbs and Lightnin' Licks" refers to the brothers' nicknames. "Get the Funk Out Ma Face" was cowritten with Quincy Jones.
Their popular album "Light Up The Night" was released in March 1980 and rose to #5 on the Billboard 200. It was number 46 on the "Top 100 LPs of 1980" list in "Rolling Stone Magazine". The brothers self-produced the subsequent album, "Winners"; released in July 1981, it only reached #48 on the Billboard 200.
Among their most popular songs are "I'll Be Good to You" ("Billboard" Hot 100 #3 in 1976), "Strawberry Letter 23" (Hot 100 #5 in 1977, originally recorded by Shuggie Otis), "Ain't We Funkin' Now" (1978), and "Stomp!" (Hot 100 #7 and Hot Dance Music/Club Play #1 in 1980). Their styles include funk, and R&B ballads. Each album also included at least one instrumental cut that would either be considered lite jazz ("Tomorrow" 1976, "Q" 1977, "Smilin' On Ya" 1980, "Tokyo" 1984) or Funk ("Thunder Thumbs &Lightning Licks" 1976, "Brother Man" 1976, "Mista Cool" 1978, "Celebrations" 1980).
1982 Split.
The duo split up in 1982 to pursue separate projects.
Louis Johnson's solo work.
Louis Johnson recorded a gospel music album in 1981 with his own group Passage, which included his then-wife Valerie Johnson and former Brothers Johnson percussionist/singer Richard Heath. He played bass on Michael Jackson's "Off The Wall" and "Thriller". In 1985 he recorded a single, "Kinky", on Capitol Records; it appears on his "Evolution" album which was exclusively released in Europe that year. Louis then made 3 instructional videotapes for the Starlicks video-distribution company in which he shared his bass-playing skills. The first was released in 1985. He then settled down to enjoy family life with his wife and son, but by 1988 his then-manager Diane Taren talked him into going back into the recording studio. He started his bass academy during the 1990s and gave workshop clinics via his own Website. Louis Johnson died on May 21, 2015.
George Johnson's solo work.
George Johnson released one single in 1985, "Back Against The Wall", on Quincy Jones' own Qwest label. A complete album (recorded but unreleased) came from that session, as George confirmed when he and Louis were interviewed around 1987/88 for "Blues & Soul Magazine" in the United Kingdom (see link below). George also delivered guitar work for Steve Arrington's album "Dancing in the Key of Life" (1985) and had ad-libbed vocals on the track "Think Back And Remember" from the "Galaxian" album by the Jeff Lorber Fusion, released in 1981 on Arista Records.
Various 1980s reunions and other projects.
In 1984 the brothers briefly reunited in the recording studio. The resulting Leon Sylvers-produced LP, "Out of Control", did not equal their past success, but it did garner them another R&B hit with "You Keep Me Coming Back". They teamed up again in 1988 to record "Kickin'", the title track of which was a collaboration with their then-neighbor Irene Cara. This album's success was even more limited, but it did include the minor hit "Kick it to the Curb".
Between the two albums, both George and Louis released their aforementioned solo material and also appeared on "Street Shadows", an album by keyboardist/arranger David Diggs, who had provided horn and string arrangements for "Winners", "Blast", and Louis' "Passage". "Last Night", "Street"s opening track, showcases George's bass-guitar playing. He previously showed his bass skills on tracks like "Teaser" from "Winners" and "The Great Awakening" from "Blast", the same way Louis shows his guitar skills on the duo's various compositions.
Also during this time, the band's song "Tomorrow" (originally an instrumental on the B-side of "Get The Funk Out Ma Face") was recorded with vocals by Tevin Campbell for Quincy Jones' "Back on the Block" release in 1989. This album also included Jones' hit remake of the Brothers Johnson's "I'll Be Good to You", featuring Ray Charles and Chaka Khan.
The 2002 reunion tour and death of Louis Johnson.
Besides the brothers' brief appearance in Japan around 1994 and George guest-appearing at a Graham Central Station concert in Japan (including a released double-CD), the duo launched an expanded US tour in 2002 which got positive, wide exposure. It was visited by many fans and various artists in the entertainment business.
Along with a website and discussion-forum, online visitors could share their experiences of the shows by wandering through the Land of Ladies and reliving Funkadelia's heyday. A few years later, a combi-release of live-CD + DVD was released under the name "Strawberry Letter 23: Live".
Until recently, the brothers have been doing performances on their own. In 2006, Louis gave a duo-show with a drummer on the "Poetry in Motion 1 Festival" in Maryland. In late 2007 George performed with his own band at a Detroit-Festival, including a persona called Sir Nose. These days George performs with a special band, an initiative of Michael Henderson that includes Adina Howard, Cherrelle, Ray Parker Jr., and others.
Louis Johnson died May 21, 2015. No cause of death was given.

</doc>
<doc id="56380" url="https://en.wikipedia.org/wiki?curid=56380" title="Laṅkāvatāra Sūtra">
Laṅkāvatāra Sūtra

The Laṅkāvatāra Sūtra (Sanskrit: ; ) is a sutra of Mahāyāna Buddhism. The sūtra recounts a teaching primarily between the Buddha and a bodhisattva named Mahāmati ("Great Wisdom"). The sūtra is set in Laṅkā, the island fortress capital of Rāvaṇa, the king of rākṣasas. The title of this text roughly translates as "Scripture of the Descent into Laṅkā."
The "Laṅkāvatāra Sūtra" figured prominently in the development of Chinese, Tibetan and Japanese Buddhism. It is notably an important sūtra in Chan Buddhism and its Japanese version, Zen.
Sūtra doctrine.
The "Laṅkāvatāra Sūtra" draws upon the concepts and doctrines of Yogācāra and Buddha-nature. The most important doctrine issuing from the "Laṅkāvatāra Sūtra" is that of the primacy of consciousness (Skt. "vijñāna") and the teaching of consciousness as the only reality. In the sūtra, the Buddha asserts that all the objects of the world, and the names and forms of experience, are merely manifestations of the mind:
Because the world is seen as being "mind-only" or "consciousness-only", all phenomena are void, empty of self (atman) and illusory:
The "Laṅkāvatāra Sūtra" describes the various tiers of consciousness in the individual, culminating in the tathagatagarbha (womb of the Buddhas) or "storehouse consciousness" (Skt. Ālayavijñāna), which is the base of the individual's deepest awareness and his tie to the cosmic.
However, the Buddha makes clear that the Buddha-nature is not a self (atman) and is empty of self-nature. He states that it is merely a useful means (upaya) of teaching the dharma to others:
The tathagatagarbha or "Buddha-nature" doctrine has been interpreted as an expression of the doctrines of pratītyasamutpāda "dependent origination" and emptiness. While seemingly monistic in nature, describing the tathagatagarbha as eternal (nitya) and immutable ('atman'), this doctrine is ultimately based on emptiness. According to Japanese scholar Yamaguchi Susumu, the most important point in the tathagatagarbha literature is that "the 'pratitysamutpada' is the 'tathagatagarbha'." Likewise, Ichijo Ogawa, argues that 'tathatagatagarbha' is basically equivalent to emptiness and the nature of the mind which allows it to understand emptiness. This interpretation is based on a passage from the "Ratnagotravibhāga", which states that "all sentient beings are possessed of the 'tathagatagarbha'".
History and editions.
According to Asanga Tillekharatna, "it is generally believed that the sutra was compiled during 350-400 CE," although "many who have studied the sutra are of opinion that the introductory chapter and the last two chapters were added to the book at a later period." A number of ancient translations of the "Laṅkāvatāra Sūtra" were made from Sanskrit into the Chinese language, as early as the 3rd century CE with a translation by the Indian monk Dharmarakṣa. Of these, only three are now extant.
The first extant Chinese translation is Taishō Tripiṭaka 670 (楞伽阿跋多羅寶經). This is the earliest edition which was translated by Guṇabhadra in 443 CE, and divided into four fascicles. This edition by Guṇabhadra is said to be the one handed down from the founder of Chan Buddhism, Bodhidharma, to the Second Patriarch, Dazu Huike, saying:
The second extant Chinese translation is Taishō Tripiṭaka 671 (入楞伽經). This second edition was translated by Bodhiruci in 513 CE, and divided into ten fascicles. This edition is criticized in the imperial preface to the later translation, which says that it contains extra words and sentences mixed in that detract from the original meaning.
The third extant Chinese translation is Taishō Tripiṭaka 672 (大乘入楞伽經). This third edition was translated by Śikṣānanda in 700-704 CE, and divided into seven fascicles. This final translation was made at the behest of Empress Wu Zetian, after Śikṣānanda had completed his 80-fascicle translation of the "Avatamsaka Sutra". This translation is said to have employed five separate Sanskrit editions for accuracy. Before the final edits to this version had been made, Śikṣānanda returned to India, and another Indian monk came to China who had studied the Buddhist sutras for 25 years in India, and who knew the Laṅkāvatāra Sūtra. He was then given the task of revising the translation made by Śikṣānanda.
In addition to these Chinese translations, an extant Sanskrit edition of the "Laṅkāvatāra Sūtra" is available as well as a Tibetan edition.

</doc>
<doc id="56386" url="https://en.wikipedia.org/wiki?curid=56386" title="Barry White">
Barry White

Barry White (born Barry Eugene Carter; September 12, 1944 – July 4, 2003) was an American composer and singer-songwriter.
A three-time Grammy Award–winner known for his distinctive bass-baritone voice and romantic image, White's greatest success came in the 1970s as a solo singer and with the Love Unlimited Orchestra, crafting many enduring soul, funk, and disco songs such as his two biggest hits, "You're the First, the Last, My Everything" and "Can't Get Enough of Your Love, Babe".
During the course of his career in the music business, White achieved 106 gold albums worldwide, 41 of which also attained platinum status. White had 20 gold and 10 platinum singles, with worldwide record sales in excess of 100 million. He is one of the world's best-selling artists of all time. His influences included Rev. James Cleveland, Ray Charles, Aretha Franklin, and Elvis Presley plus Motown artists The Supremes, The Four Tops, and Marvin Gaye.
Early life.
Barry White was born Barry Eugene Carter in Galveston, Texas, and grew up in the high-crime areas of South Central Los Angeles. White was the older of two kids: his brother Darryl was 13 months younger. He grew up listening to his mother's classical music collection, and first took to the piano emulating what he heard on the records. White has often been credited with playing piano at age eleven on Jesse Belvin's 1956 hit single, "Goodnight My Love." However, in a 1995 interview with the Boston Herald's Larry Katz, White denied writing or arranging the song. He believed the story was an exaggeration by journalists. While White and Belvin lived in the same neighborhood, Belvin was twelve years older than White. Barry White also stated that he had no involvement with Bob & Earl's 1963 hit single Harlem Shuffle, a song he is credited with producing.
White's voice deepened suddenly when he was fourteen. White recalled: "a child I had a normal squeaky kid voice. Then as a teenager, that completely changed. My mother cried because she knew her baby boy had become a man."
Gang life and jail sentence.
His brother Darryl was murdered in a clash with a rival gang, and White himself was jailed—at the age of 16—for stealing $30,000 worth of Cadillac tires.
While in jail, White listened to Elvis Presley singing "It's Now or Never" on the radio, an experience he later credited with changing the course of his life.
Music career.
The 1960s.
After his release from jail, he left gang life and began a musical career at the beginning of the 1960s in singing groups. He first released "Too Far to Turn Around" in 1960 as part of The Upfronts before working for various small independent labels in Los Angeles. He also recorded several singles under his own name in the early 1960s, backed by vocal groups the Atlantics (for the Rampart and Faro labels) and the Majestics (for the Linda and Jordan labels).
Bob Keane of Del-Fi Records—the man who discovered Ritchie Valens—hired him as an A&R man in the mid 1960s, and White started working with the label's artists, including Viola Wills and The Bobby Fuller Four, as a songwriter, session musician, and arranger. He discovered singer Felice Taylor and arranged her song "I Feel Love Comin' On" as well as "Harlem Shuffle" for Bob & Earl. Both records became big hits in the UK. He also wrote "Doin' the Banana Split" for TV bubblegum act The Banana Splits in 1968.
The 1970s as producer.
In 1972, he got his big break producing a girl group he had discovered called Love Unlimited. Formed in imitative style of the Motown girl group The Supremes, the group members had gradually honed their talents with White for two years previously until they signed contracts with Uni Records. His friend Paul Politi hooked him up with music industry businessman Larry Nunes, who helped to finance their album. After it was recorded, Nunes took the recording to Russ Regan, who was the head of the Uni label owned by MCA. The album, 1972's "From A Girl's Point of View We Give to You... Love Unlimited", became a million album seller and the first of White's string of long-titled albums and singles.
White produced, wrote and arranged their classic soul ballad "Walkin' in the Rain with the One I Love", which climbed to #14 in the "Billboard" Hot 100 Pop chart and #6 on the "Billboard" R&B chart in late 1972. This single also reached #12 in the UK chart. White's voice can clearly be heard in this piece as he plays the lover who answers the phone call of the female lead.
Soon after, Regan left Uni for 20th Century Records. Without Regan, White's relationship with Uni soured. With his relationship with Uni over and Love Unlimited contract-bound with the label, White was able to switch both his production deal and the group to 20th Century Records. (They recorded several other hits throughout the 1970s, "I Belong to You", which spent over five months on the "Billboard" R&B chart in 1974 including a week at #1 and "Under the Influence of Love", which hit #3 on the "Billboard" Pop album charts. White married the lead singer of the group, Glodean James, on July 4, 1974.)
The 1970s as solo artist.
White wanted to work with another act but decided to work with a solo male artist. While working on a few demos for a male singer, he made three song demos of himself singing and playing, but Nunes heard them and insisted that he re-record and release them himself as a solo recording artist. After arguing for days about it, White was finally persuaded to release the songs himself although he was initially reluctant to step out in front of the microphone.
He then wrote several other songs and recorded them for what eventually became an entire album of music. He was going to use the name "White Heat," but decided on using his given name instead. White was still hesitating up to the time the label copy was made. It eventually became the first solo White album, 1973's "I've Got So Much to Give". It included the title track and his first solo chart hit, "I'm Gonna Love You Just a Little More Baby", which also rose to #1 on the "Billboard" R&B charts as well as #3 on the "Billboard" Pop charts in 1973 and stayed in the top 40 for many weeks.
Other chart hits by White included "Never, Never Gonna Give Ya Up" (#2 R&B, #7 Pop in 1973), "Can't Get Enough of Your Love, Babe" (# 1 Pop and R&B in 1974), "You're the First, the Last, My Everything" (#1 R&B, #2 Pop in 1974), "What Am I Gonna Do with You" (#1 R&B, #8 Pop in 1975), "Let the Music Play" (#4 R&B in 1976), "It's Ecstasy When You Lay Down Next to Me" (#1 R&B, #4 Pop in 1977) and "Your Sweetness is My Weakness" (#2 R&B in 1978) and others. White also had a strong following in the UK, where he scored five Top 10 hits and a #1 for "You're the First, the Last, My Everything".
The Love Unlimited Orchestra.
In 1973 White created The Love Unlimited Orchestra, a 40-piece orchestral group to be used originally as a backing band for the girl-group Love Unlimited. However, White had other plans, and in 1973 he released a single with "Love's Theme" (written by him and played by the Orchestra), that same track reached #1 on the "Billboard" Pop charts. Later, in 1974, he made the first album of the Love Unlimited Orchestra, "Rhapsody in White", containing "Love's Theme". White is sometimes credited with ushering in the "disco" sound, seamlessly combining R&B music with classical music. Some also regard "Love's Theme" as the first hit in the actual "disco era".
Barry White would continue to make albums with the Orchestra, achieving some successes such as: "Rhapsody in White"; "Satin Soul"; "Forever in Love"; "Midnight Groove"; "My Sweet Summer Suite", Remake of "Theme From King Kong". The Orchestra ceased to make albums in 1983, but continued to support Barry White as a backing band.
The 1980s.
After six years White left 20th Century in 1979 to launch his own label, Unlimited Gold, with CBS/Columbia Records. Although his success on the pop charts slowed down as the disco era came to an end, he maintained a loyal following throughout his career. Despite several albums over the next three years he failed to repeat his earlier successes, with no singles managing to reach the "Billboard" Hot 100 except for 1982's "Change," climbing into the Billboard R&B Top 20 (#12). His label venture was exacting a heavy financial cost on White, so he concentrated on mostly touring and finally folded his label in 1983.
After four years he signed with A&M Records, and with the release of 1987's "The Right Night & Barry White", the single entitled "Sho' You Right" made it to the "Billboard" R&B charts, peaking at #17.
In 1989 he released "The Man Is Back!" and with it had three top 40 singles on the "Billboard" R&B charts: "Super Lover", which made it to #34, "I Wanna Do It Good to Ya", which made it to #26, and "When Will I See You Again", which made it to #32.
The 1990s.
A 1970s nostalgia fad allowed White to enjoy a renewed wave of popularity in the 1990s. After participating in the song "The Secret Garden (Sweet Seduction Suite)" from Quincy Jones's 1989 album "Back On the Block", White mounted an effective comeback with several albums, each more successful than the last. He returned to the top of the charts in 1991 with the album "Put Me in Your Mix", which reached #8 on the "Billboard" R&B Albums chart and the song by the same name reached #2 on the "Billboard" R&B singles chart.
In 1994 he released "The Icon Is Love", which went to #1 on the "Billboard" R&B album charts, and the single "Practice What You Preach" gave him his first #1 on the "Billboard" R&B singles chart in almost 20 years. The album was nominated for a Grammy in the Best R&B Album category, but lost to TLC's "CrazySexyCool".
In 1996, White recorded the duet "In Your Wildest Dreams" with Tina Turner. 1996 also saw the release of "Space Jam" and its soundtrack, on which White had a duet with Chris Rock, called "Basketball Jones," a remake of Cheech & Chong's "Basketball Jones" from 1973.
His final album, 1999's "Staying Power", resulted in his last hit song "Staying Power," which placed #45 on the "Billboard" R&B charts. The single won him two Grammy Awards in the categories Best Male R&B Vocal Performance and Best Traditional R&B Vocal Performance.
His autobiography, "Love Unlimited", written with Mark Eliot, was published in 1999 by Broadway Books.
Acting career.
Over the course of his career, White sometimes did voice-over work for TV and movies. He voiced the character Bear in the 1975 film "Coonskin" and also played the character Sampson in the movie's live-action segments.
He appeared as himself in a few episodes of "The Simpsons", and most importantly the episode "Whacking Day" in which Bart and Lisa used his famously deep bass singing voice, played through loudspeakers placed on the ground, to lull and attract snakes. White was a fan of the show, and had reportedly contacted the staff about wanting to make a guest appearance.
He played the role of a bus driver for a Prodigy commercial in 1995, and he also portrayed the voice of a rabbit in a Good Seasons salad dressing mix commercial, singing a song called "You Can't Bottle Love".
In addition, he did some work for car commercials, most famously for Oldsmobile, and later on, Jeep.
He also provided voice over for Arby's Restaurant commercials on TV and Radio to promote their 'Market Fresh' menu.
His voice can also be heard in Apple's first iBook commercial.
He made three guest appearances on the comedy-drama TV series "Ally McBeal", as his music was often featured on the show in dream sequences.
Illness and death.
White was overweight for most of his adult life—weighing according to Casey Kasem—and suffered from related health problems. In October 1995, he was admitted to a hospital as a result of high blood pressure. In August 1999, White was forced to cancel approximately a month's worth of tour dates owing to exhaustion, high blood pressure, and a hectic schedule. In September 2002, he was hospitalized with kidney failure attributed to chronic diabetes mellitus and high blood pressure.
While undergoing dialysis and awaiting a kidney transplant in May 2003, he suffered a severe stroke, which forced him to retire from public life. At around 9:30 a.m. (PDT) on July 4, 2003, 29 years to the day after he married Glodean, White died at Cedars-Sinai Medical Center in Los Angeles at the age of 58. His remains were cremated, and the ashes were scattered by his family off the California coast.
Tributes.
On September 20, 2004, he was posthumously inducted into the Dance Music Hall of Fame at a ceremony held in New York. On September 12, 2013, which would have been White's 69th birthday, he was posthumously awarded the 2,506th star on the Hollywood Walk of Fame at 6914 Hollywood Blvd. in the category of recording. The show "Counting Cars" paid tribute to White by restoring the last car he owned for his widow, Glodean.
In an obituary affectionately referring to White by his familiar nickname, 'The Walrus of Love,' the BBC recalled "the rich timbres of one of the most distinctive soul voices of his generation, about which it was once said: 'If chocolate fudge cake could sing, it would sound like Barry White.'".

</doc>
<doc id="56396" url="https://en.wikipedia.org/wiki?curid=56396" title="Anaximenes">
Anaximenes

Anaximenes may refer to:

</doc>
<doc id="56397" url="https://en.wikipedia.org/wiki?curid=56397" title="Steven Brust">
Steven Brust

Steven Karl Zoltán Brust (born November 23, 1955) is an American fantasy and science fiction author of Hungarian descent. He is best known for his series of novels about the assassin Vlad Taltos, one of a disdained minority group of humans living on a world called Dragaera. His recent novels also include "The Incrementalists" (2013), with co-author Skyler White.
As a drummer and singer-songwriter, Brust has recorded one solo album and two albums as a member of Cats Laughing. Brust also co-wrote songs on two albums recorded in the mid-1990s by the band Boiled in Lead.
Writing career.
The Dragaeran books.
The Vlad Taltos series, written as high fantasy with a science fiction underpinning, is set on a planet called Dragaera. The events of the series take place in an Empire mostly inhabited and ruled by the Dragaerans, a genetically engineered humanoid species, having characteristics such as greatly extended lifespans and heights averaging about seven feet. Referred to as "elfs" by some humans, they refer to themselves as "human." The Dragaeran Empire controls a region that is "enclouded" by a perpetual overcast that blocks the sun from view.
Vlad Taltos is one of the human minority (known by Dragaerans as "Easterners"), which exists as a lower class in the Empire. Vlad also practices the human art of witchcraft; "táltos" is Hungarian for a kind of supernatural person in folklore. Though human, he is a citizen of the Empire because his social-climbing father bought a title in one of the less reputable of the 17 Dragaeran Great Houses. The only Great House that sells memberships this way is, not coincidentally, also the one that maintains a criminal organization. Vlad proves surprisingly successful in this organization. Despite being a human and a criminal, he has a number of high-ranking Dragaeran friends, and often gets caught up in important events.
Brust has written 14 published novels in the series, which is proposed to run to nineteen novels – one named for each of the Great Houses, one named for Vlad himself ("Taltos"), and a final novel which Brust has said will be titled "The Final Contract". The first three novels resemble private-eye detective stories, perhaps the closest being Robert B. Parker's Spenser series. The later novels are more varied than the first three. Though they read like fantasy, there are science-fictional explanations for some things.
Brust has also written another series set in Dragaera, the "Khaavren Romances", set centuries before Vlad's time. Since Dragaerans live for thousands of years, many characters appear in both series. It is partly an homage to Alexandre Dumas, père's novels about the Three Musketeers, and is five volumes long, following the pattern of Dumas' series. The books are presented as historical novels written by Paarfi of Roundwood, a Dragaeran roughly contemporary with Vlad. Paarfi's old-fashioned, elaborate, and highly verbose writing is explicitly based on Dumas', though with a dialogue style that is, at times, based on Tom Stoppard's wordgames in "Rosencrantz & Guildenstern Are Dead" (according to Pamela Dean's introduction to "Five Hundred Years After").
The two series are finally brought together in the thirteenth novel in the Vlad series, "Tiassa", which can also be viewed as the sixth novel in the Khaavren series. "Tiassa" comprises what are in effect three related novellas, each told in a different style and connected by a common theme. The first section reads like the first three novels in the series, with a first-person narration by Vlad but including Khaavren's son, Piro; the second section has a different viewpoint character in each of its chapters; and the third section is narrated by Paarfi in the style of the earlier "Khaavren Romances", with Khaavren as the viewpoint character and interacting with Vlad.
Short stories.
Most of Brust's short stories are set in shared universes. These include Emma Bull's and Will Shetterly's "Liavek", Robert Asprin's "Thieves' World", Neil Gaiman's "Sandman" and Terri Windling's "Borderland Series".
Style and literary theory.
Brust was a founding member of a Minnesota-based writers' group called The Scribblies, which included Emma Bull, Pamela Dean, Will Shetterly, Nate Bucklin, Kara Dalkey, and Patricia Wrede. He also was a founding member of the Pre-Joycean Fellowship.
He has rejected a distinction between science fiction and fantasy, stating that no belief in such a distinction can withstand an encounter with the writing of Roger Zelazny.
Writing style.
There is a certain amount of variation in the writing style amongst the Taltos novels, as well as between Brust's various series. Brust uses a different narrative approach in almost every novel in the Taltos series. Some of these approaches are more purely stylistic and have minor effects on the actual story-telling; some are profound and involve the point of view of characters whom the reader never expected to get to know so well.
Further, as the writing of the Taltos novels has spanned over two decades, they have been influenced by events in Brust's own life. A fascination with the Mafia – subsequently brought into a somewhat shocking perspective by the murder of a friend – profoundly influenced his storylines, as did the breakup of his marriage. The events and arguments of his books, especially "Teckla", are acknowledged by Brust to be influenced by his lifelong interest in Marxist theory and practice. Brust's parents were activists in the Socialist Equality Party and he continues to identify as a "Trotskyist sympathizer," linking to the SEP-affiliated World Socialist Website on his personal website.
Literary theory.
In contrast to contemporary academic studies in literature, Brust has put forward what he called "The Cool Stuff Theory of Literature":All literature consists of whatever the writer thinks is cool. The reader will like the book to the degree that he agrees with the writer about what's cool. And that works all the way from the external trappings to the level of metaphor, subtext, and the way one uses words. In other words, I happen not to think that full-plate armor and great big honking greatswords are cool. I don't like 'em. I like cloaks and rapiers. So I write stories with a lot of cloaks and rapiers in 'em, 'cause that's cool. Guys who like military hardware, who think advanced military hardware is cool, are not gonna jump all over my books, because they have other ideas about what's cool.
Brust elaborated, "The novel should be understood as a structure built to accommodate the greatest possible amount of cool stuff."
Motifs.
The character Devera, usually a cute brown-eyed girl of about nine, appears as a motif in all of Brust's novels. In the Dragaeran books her name is Devera. She is the (future) daughter of another character and seems to be able to appear anywhere in time and space. In Brust's non-Dragaeran books her appearances are usually brief and not always obvious.
Musical recordings and performances.
Brust is a singer-songwriter and drummer who has recorded a solo album, and who has played in the Minneapolis-based folk rock band Cats Laughing, and with the Albany Free Traders, and Morrigan.
Brust also co-wrote two songs on the 1994 album "Antler Dance" by the band Boiled in Lead, as well as many of the songs on BiL's 1995 multimedia CD "Songs from The Gypsy".
Cats Laughing.
On April 3, 2015, Brust performed as part of Cats Laughing in a reunion concert at the Minicon 50 science fiction convention in Bloomington, Minnesota. A live CD and a DVD with documentary footage are expected to follow.
"A Rose for Iconoclastes" (1993).
AllMusic reviewer Steven McDonald wrote, "Brust serves up a decent folksy stew with a few blasts of sarcastic humor, salted with performances from a handful of well-known friends." According to McDonald, "the writing tends to be stronger in the lyrical department than in the compositional area," and Brust's "satirical material tends to work better than the more serious material."
The album's title is a reference to "A Rose for Ecclesiastes", a short story by Brust's literary hero and mentor Roger Zelazny.
Two songs from this album, "I Was Born About Ten Million Songs Ago" and "Backward Message," were featured by Doctor Demento on his syndicated program, receiving radio airplay on shows from 1994 through 2009. "I Was Born About Ten Million Songs Ago" also appeared on an anthology, "Dr. Demento's Basement Tapes #3", later part of a limited-edition CD boxed set.
"Songs from The Gypsy" (1995).
AllMusic reviewer Steven McDonald called "Songs from The Gypsy" "an example of Brust's serious songwriting working well."
Conversely, a critical review by AllMusic's Roch Parisien emphasized that ""Songs from The Gypsy" represents a failure of multimedia integration. As an audio CD, the disc serves up ten songs, ranging from acoustic trad to bluesy rockers, that ironically form a less cohesive whole than previous Boiled in Lead releases. The better numbers (like the title track) incorporate Celtic rock with Hungarian, Middle Eastern and other interesting worldbeat influences." Parisien found the album's integration with the novel unsuccessful, in that the novel's 17 chapters were presented as "scrollable text only, which also intersperse some 80 song lyric excerpts that you can play from hot buttons. Annoyingly, you must flip back to a main menu index to move from one chapter to the next." Parisien concluded, "Despite Brust's engrossingly poetic, impressionist story inspired by Hungarian folk tales and revolving around three Gypsy brothers, the project does not overcome the primary limitation of bringing literature to the computer screen, that being that the computer offers an inhospitable environment for viewing literature-length text." The review, written in 1995, predated a wave of popular e-book readers that began to emerge about ten years later.
Other performances.
Brust has performed dramatically in several Shockwave Radio Theater productions, notably "Closing Ceremonies (aka The Fall of the House of Usherette)" and "PBS Liavek".
Award nominations.
Brust's short story "When The Bow Breaks" was nominated for the 1999 Nebula Award, although it did not reach the final ballot.
"Five Hundred Years After" was nominated for the 1995 Locus Poll Award (Best Fantasy Novel). Other novels nominated for various Locus Poll Awards were "Brokedown Palace," "The Gypsy," "Agyar," and "Freedom & Necessity."
"Dragon" was a finalist for the 1999 Minnesota Book Awards in the Fantasy & Science Fiction category. "Freedom and Necessity" was a 1998 finalist for the same category, while "The Phoenix Guards" was a finalist in 1992.
Brust discovered in August 2006 that he had made the "New York Times" extended bestseller list at number 30 with "Dzur". He mentioned his ambivalence on this subject online. "SciFi Wire" posted an interview with Brust after "Dzur" came out.
Trivia.
Book title nicknames.
Brust is known for his propensity to give his books alternate titles for his own amusement. These have cropped up in numerous interviews and online forums, starting with "Jarhead" for "Jhereg". Examples include:
Brust does not have nicknames for collaborations out of respect for his collaborators, stating "It's one thing to not want to take myself seriously, and another thing to—I want to take them seriously."
Bibliography.
Brust's novels have been translated into German, Russian, Polish, Dutch, Czech, French, Spanish, Hebrew and Bulgarian.
Dragaera.
There are two series set in the world of Dragaera, namely "The Khaavren Romances" and the "Vlad Taltos" novels. They are set in different periods in the world, but some characters are common to both series.
Vlad Taltos.
There are currently 14 novels in the series (19 are planned).
Chronological order of novels:
Omnibus volumes:
The Khaavren Romances.
The series consists of three works (published as five books), and has been completed.
Short stories.
So far, at least one short story set in the Draegara universe has been published. It is available online at tor.com.

</doc>
<doc id="56398" url="https://en.wikipedia.org/wiki?curid=56398" title="Phase diagram">
Phase diagram

A phase diagram in physical chemistry, engineering, mineralogy, and materials science is a type of chart used to show conditions (pressure, temperature, volume, etc.) at which thermodynamically distinct phases occur and coexist at equilibrium.
Overview.
Common components of a phase diagram are "lines of equilibrium" or "phase boundaries", which refer to lines that mark conditions under which multiple phases can coexist at equilibrium. Phase transitions occur along lines of equilibrium.
Triple points are points on phase diagrams where lines of equilibrium intersect. Triple points mark conditions at which three different phases can coexist. For example, the water phase diagram has a triple point corresponding to the single temperature and pressure at which solid, liquid, and gaseous water can coexist in a stable equilibrium.
The solidus is the temperature below which the substance is stable in the solid state. The liquidus is the temperature above which the substance is stable in a liquid state. There may be a gap between the solidus and liquidus; within the gap, the substance consists of a mixture of crystals and liquid (like a "slurry").
Types of phase diagrams.
2D phase diagrams.
The simplest phase diagrams are pressure–temperature diagrams of a single simple substance, such as water. The axes correspond to the pressure and temperature. The phase diagram shows, in pressure–temperature space, the lines of equilibrium or phase boundaries between the three phases of solid, liquid, and gas.
The curves on the phase diagram show the points where the free energy (and other derived properties) becomes non-analytic: their derivatives with respect to the coordinates (temperature and pressure in this example) change discontinuously (abruptly). For example, the heat capacity of a container filled with ice will change abruptly as the container is heated past the melting point. The open spaces, where the free energy is analytic, correspond to single phase regions. Single phase regions are separated by lines of non-analytical behavior, where phase transitions occur, which are called phase boundaries.
In the diagram on the left, the phase boundary between liquid and gas does not continue indefinitely. Instead, it terminates at a point on the phase diagram called the critical point. This reflects the fact that, at extremely high temperatures and pressures, the liquid and gaseous phases become indistinguishable, in what is known as a supercritical fluid. In water, the critical point occurs at around Tc = , pc = and ρc = 356 kg/m³.
The existence of the liquid–gas critical point reveals a slight ambiguity in labelling the single phase regions. When going from the liquid to the gaseous phase, one usually crosses the phase boundary, but it is possible to choose a path that never crosses the boundary by going to the right of the critical point. Thus, the liquid and gaseous phases can blend continuously into each other. The solid–liquid phase boundary can only end in a critical point if the solid and liquid phases have the same symmetry group.
The solid–liquid phase boundary in the phase diagram of most substances has a positive slope; the greater the pressure on a given substance, the closer together the molecules of the substance are brought to each other, which increases the effect of the substance's intermolecular forces. Thus, the substance requires a higher temperature for its molecules to have enough energy to break out of the fixed pattern of the solid phase and enter the liquid phase. A similar concept applies to liquid–gas phase changes. Water, because of its particular properties, is one of the several exceptions to the rule.
Other thermodynamic properties.
In addition to just temperature or pressure, other thermodynamic properties may be graphed in phase diagrams. Examples of such thermodynamic properties include specific volume, specific enthalpy, or specific entropy. For example, single-component graphs of temperature vs. specific entropy (T vs. s) for water/steam or for a refrigerant are commonly used to illustrate thermodynamic cycles such as a Carnot cycle, Rankine cycle, or vapor-compression refrigeration cycle.
In a two-dimensional graph, two of the thermodynamic quantities may be shown on the horizontal and vertical axes. Additional thermodynamic quantities may each be illustrated in increments as a series of lines - curved, straight, or a combination of curved and straight. Each of these iso-lines represents the thermodynamic quantity at a certain constant value.
3D phase diagrams.
An orthographic projection of the 3D p–v–T graph showing pressure and temperature as the vertical and horizontal axes collapses the 3D plot into the standard 2D pressure–temperature diagram. When this is done, the solid–vapor, solid–liquid, and liquid–vapor surfaces collapse into three corresponding curved lines meeting at the triple point, which is the collapsed orthographic projection of the triple line.
Binary phase diagrams.
Other much more complex types of phase diagrams can be constructed, particularly when more than one pure component is present. In that case, concentration becomes an important variable. Phase diagrams with more than two dimensions can be constructed that show the effect of more than two variables on the phase of a substance. Phase diagrams can use other variables in addition to or in place of temperature, pressure and composition, for example the strength of an applied electrical or magnetic field, and they can also involve substances that take on more than just three states of matter.
One type of phase diagram plots temperature against the relative concentrations of two substances in a mixture called a "binary phase diagram", as shown at right. Such a mixture can be either a solid solution, eutectic or peritectic, among others. These two types of mixtures result in very different graphs.
Another type of binary phase diagram is a "boiling-point diagram" for a mixture of two components, i. e. chemical compounds.
For two particular volatile components at a certain pressure such as atmospheric pressure, a boiling-point diagram shows what vapor (gas) compositions are in equilibrium with given liquid compositions depending on temperature. In a typical binary boiling-point diagram, temperature is plotted on a vertical axis and mixture composition on a horizontal axis.
A simple example diagram with hypothetical components 1 and 2 in a non-azeotropic mixture is shown at right. The fact that there are two separate curved lines joining the boiling points of the pure components means that the vapor composition is usually not the same as the liquid composition the vapor is in equilibrium with. See Vapor–liquid equilibrium for more information.
In addition to the above-mentioned types of phase diagrams, there are thousands of other possible combinations. Some of the major features of phase diagrams include congruent points, where a solid phase transforms directly into a liquid. There is also the peritectoid, a point where two solid phases combine into one solid phase during cooling. The inverse of this, when one solid phase transforms into two solid phases during heating, is called the eutectoid.
A complex phase diagram of great technological importance is that of the iron–carbon system for less than 7% carbon (see steel).
The x-axis of such a diagram represents the concentration variable of the mixture. As the mixtures are typically far from dilute and their density as a function of temperature is usually unknown, the preferred concentration measure is mole fraction. A volume-based measure like molarity would be inadvisable.
Crystal phase diagrams.
Polymorphic and polyamorphic substances have multiple crystal or amorphous phases, which can be graphed in a similar fashion to solid, liquid, and gas phases.
Mesophase diagrams.
Some organic materials pass through intermediate states between solid and liquid; these states are called mesophases. Attention has been directed to mesophases because they enable display devices and have become commercially important through the so-called liquid-crystal technology. Phase diagrams are used to describe the occurrence of mesophases.

</doc>
<doc id="56422" url="https://en.wikipedia.org/wiki?curid=56422" title="Arnhem">
Arnhem

Arnhem or ( or ; , , South Guelderish: "Èrnem") is a city and municipality, situated in the eastern part of the Netherlands. It is the capital of the province of Gelderland and located on both banks of the rivers Nederrijn and Sint-Jansbeek, which was the source of the city's development. Arnhem had a population of in and is one of the larger cities of the Netherlands. The municipality is part of the city region Arnhem-Nijmegen, which has a combined 736,500 inhabitants. Arnhem is home to the Hogeschool van Arnhem en Nijmegen, ArtEZ Institute of the Arts, Netherlands Open Air Museum, Royal Burgers' Zoo and National Sports Centre Papendal.
History.
Early history.
The oldest archeological findings of human activity around Arnhem are two firestones of about 70,000 years ago. These come from the stone age, when the Neanderthals lived in this part of Europe. In Schuytgraaf, remnants of a hunters camp from around 5000 BC have been discovered. In Schaarsbergen, 12 grave mounds were found from 2400 BC, which brought the so-called Neolithic revolution to the area of Arnhem, i.e., the rise of the farmers.
The earliest settlement in Arnhem dates from 1500 BC, of which traces have been found on the Hoogkamp, where the Van Goyenstraat is currently located. In the inner city, around the Sint-Jansbeek, traces of settlement have been found from around 700 BC, while the first traces south of the Rhine have been found dating to around 500 BC, in the "Schuytgraaf".
Though the early tracks of settlements did show that the early residents of Arnhem descended from the forests on the hills, Arnhem was not built on the banks of the river Rhine, but a little higher along the Sint-Jansbeek. Arnhem arose on the location where the road between Nijmegen and Utrecht/Zutphen split. Seven streams provided the city with water, and only when the flow of the Rhine was changed in 1530, was the city located on the river.
Middle Ages.
Arnhem was first mentioned as such in 893 as "Arneym" or "Arentheym".
In 1233 Count Otto II of Guelders from Zutphen, conferred city rights on the town, which had belonged to the abbey of Prüm, settled in, and fortified it. Arnhem entered the Hanseatic League in 1443. In 1473, it was captured by Charles the Bold of Burgundy.
16th and 17th century.
In 1514, Charles of Egmond, duke of Guelders, took it from the dukes of Burgundy; in 1543, it fell to the emperor Charles V. As capital of the so-called "Kwartier van Veluwe" it joined the Union of Utrecht during the Eighty years war in 1579. After its capture from the Spanish forces by Dutch and English troops in 1585 the city became part of the Republic of the Seven United Provinces of the Netherlands.
The French occupied the town 1672–74.
18th and 19th century.
From 1795 to 1813, it was reoccupied by the French, by both revolutionary and imperial forces.
In the early 19th century, the former fortifications were almost completely dismantled, to give space for town expansion. The "Sabelspoort" (Sabresgate) is the only remaining part of the medieval walls.
In the 19th century, Arnhem was a genteel resort town famous for its picturesque beauty. It was known as "het Haagje van het oosten" (The Little Hague of the East), mainly because a number of rich former sugar barons or planters from the Indies settled there, as they did in The Hague. Even now the city is famous for its parks and greenery. The urbanization in the north on hilly terrain is also quite unusual for the Netherlands.
The Battle of Arnhem.
In World War II, during Operation Market Garden (September 1944), the British 1st Airborne Division and the Polish 1st Independent Parachute Brigade were given the task of securing the bridge at Arnhem. The units were parachuted and glider-landed into the area on 17 September and later. The bulk of the force was dropped rather far from the bridge and never met their objective. A small force of British 1st Airborne managed to make their way as far as the bridge but was unable to secure both sides. The Allied troops encountered stiff resistance from the German 9th and 10th SS Panzer divisions, which had been stationed in and around the city.
The British force at the bridge eventually ran out of ammunition and were captured on 21 September, and a full withdrawal of the remaining forces was made on 26 September. These events were dramatized in the 1977 movie "A Bridge Too Far". (The bridge scenes in the movie were shot in Deventer, where a similar bridge over the IJssel was available, as the area around Arnhem bridge had changed too much to represent WWII era Arnhem). As a tribute, the rebuilt bridge was renamed 'John Frost-bridge' after the commander of the paratroopers. The official commemoration is 17 September.
The current bridge is the third almost-identical bridge built at the same spot. The Dutch Army destroyed the first bridge when the Germans invaded the Netherlands in 1940. The second bridge was destroyed by the US Army Air Forces shortly after the 1944 battle.
Liberation.
A second battle of Arnhem took place in April 1945 when the city was liberated by the British 49th (West Riding) Infantry Division fighting as part of the First Canadian Army.
Just outside Arnhem, in the town of Oosterbeek the Commonwealth War Graves Commission built the Arnhem Oosterbeek War Cemetery which contains the graves of most of those killed during the September landings, and many of those killed in later fighting in the area.
Names of Arnhem.
Through the ages, the area of Arnhem has been known by various names, both official and unofficial.
The name "Arnhem" comes from "Arneym", much earlier "Arentheem", and originally derived from Latin "Arenacum". The Dutch name literally means ""home of the eagle"" (arend means eagle in Dutch) and stems from the many eagles that used to inhabit the hills and the woods of Arnhem. The name Arneym is first mentioned in 893 by the monastery Sint-Salvatorabdij. The name Arenacum, the first mention of the area which became known as Arnhem, comes from the Roman era and means ""with eagles"".
"Èrnem" is the name of the city in the local dialect, South Guelderish. In everyday life, the name is not often used by the inhabitants of Arnhem, who seldom speak with the Arnhemian accent/dialect any more. This accent is now mainly confined to the working class areas.
"Arnheim" is the German name for Arnhem; it more clearly refers to the origin of the name (heim = home).
Hague of the East ("Haagje van het Oosten" in Dutch)<br>
In the second half of the 19th century, Arnhem was an elitist city and therefore was sometimes called The Hague of the east of the Netherlands.
Green city on the Rhine or Park City<br>
The image of Arnhem on the Rijn, with green forests in the background, has always been a much-loved theme of painters. Besides that, Arnhem has many parks. This has earned Arnhem the name "Green city on the Rhine" (from the 17th century) or "Park City" (from the 19th century).
Around 814 there is a written reference to "Meginhardeswich", which is now, as the present-day "Meijnerswijk", part of Arnhem. In 847 it was plundered by the Vikings.
When the Romans came to the Netherlands c. 50 BC, the area around was called "Oppidium Arnoldi Villa". The settlement itself was called "Arenacum".
Topography.
Topographic map image of Arnhem (city), September 2014.
Population centres.
The municipality of Arnhem consists of the city of Arnhem and the following surrounding suburbs and former villages:
Places of interest.
The "Groote Kerk" (St. Eusebius), built 1452–1560, lost most of its tower during World War II, of which a part has been reconstructed to a modern design and opened in 1964. Officially the tower is not part of the church and is owned by the municipality.
The house of Maarten van Rossum, a general serving Duke Charles van Gelre, has been the town hall since 1830: The satyrs in its Renaissance ornamentation earned it the name "Duivelshuis" ("devil's house").
The Netherlands Open Air Museum is located outside the city. It includes antique houses, farms, factories, and windmills from different parts of the Netherlands. Two other windmills stand in Arnhem itself, De Hoop and De Kroon.
Burgers' Zoo is one of the biggest and most-visited zoos in the Netherlands, featuring an underwater walkthrough, desert, mangrove, rainforest, etc.
The Gelredome, the home of Vitesse Arnhem, the city's Eredivisie team in football, is a unique facility that features a retractable roof and a slide-out grass pitch. The concept has been fully duplicated since then by the Veltins-Arena in Gelsenkirchen, Germany, and the University of Phoenix Stadium in Glendale, Arizona, USA, and partially by the Sapporo Dome in Japan (which has a sliding pitch but a fixed roof).
The KEMA Toren (formerly known as "SEP Control Tower") is the highest structure of the town. It is a 140-m-high TV tower.
Sport.
Sport in the city is principally focussed on its association football club Vitesse Arnhem. Arnhem was the host city for the 1980 Summer Paralympics.
Transport.
Arnhem has a main central railway station since 1845 – Arnhem Centraal railway station, which is serviced by several intercity lines and the ICE to Düsseldorf and further on to Frankfurt. Nowadays, there are also NS Hispeed trains to other destinations abroad, with some coaches going as far as Moscow. The intercity lines provide direct connections to Utrecht, Nijmegen, and Zutphen. It is also the terminus for several local railway services. Arnhem has three other stations, namely Arnhem Velperpoort (since 1953), Arnhem Presikhaaf (since 1969), and Arnhem Zuid (since 2005).
Arnhem is unique in the Netherlands with its trolleybus system.
Climate.
Arnhem features the same climate (Cfb, oceanic climate) as most of the Netherlands, however, its location on the foothills of the Veluwe, the largest forest in the Netherlands, contributes to some higher precipitation values.
International relations.
Twin towns – Sister cities.
Arnhem is twinned with:

</doc>
<doc id="56433" url="https://en.wikipedia.org/wiki?curid=56433" title="Operation Market Garden">
Operation Market Garden

Operation Market Garden (17–25 September 1944) was an unsuccessful Allied military operation, fought in the Netherlands and Germany in the Second World War. The operation was split into two sub-operations:
Market Garden contained the largest airborne operation up to that point.
Field Marshal Montgomery's strategic goal was to encircle the heart of German industry, the Ruhr, in a pincer movement. The northern end of the pincer would circumvent the northern end of the Siegfried Line giving easier access into Germany. The aim of Operation Market Garden was to establish the northern end of a pincer ready to project deeper into Germany. Allied forces would project north from Belgium, through Holland, across the Rhine and consolidate north of Arnhem on the Dutch/German border ready to close the pincer.
The operation made massed use of airborne forces, whose tactical objectives were to secure the bridges and allow a rapid advance by armored ground units to consolidate north of Arnhem. The operation required the seizure of the bridges across the Maas (Meuse River), two arms of the Rhine (the Waal and the Lower Rhine) together with crossings over several smaller canals and tributaries.
Several bridges between Eindhoven and Nijmegen were captured at the beginning of the operation. Lieutenant-General Brian Horrocks' XXX Corps ground force advance was delayed by the initial failure of the airborne units to secure bridges at Son and Nijmegen. German forces demolished the bridge over the Wilhelmina Canal at Son before being secured by the 101st Airborne Division. The 82nd Airborne Division's failure to capture the main road bridge over the river Waal at Nijmegen before 20 September also delayed the advance of XXX Corps.
At the furthest point of the airborne operation at Arnhem, the British 1st Airborne Division encountered initial strong resistance. The delays in capturing the bridges at Son and Nijmegen gave time for German forces, including armored divisions, to be moved into Arnhem from Germany. In the ensuing battle, only a small force managed to capture the north end of the Arnhem road bridge and after the ground forces failed to relieve them, the paratroopers were overrun on 21 September. The remainder of the 1st Airborne Division were trapped in a small pocket west of the bridge, having to be evacuated on 25 September.
The Allies had failed to cross the Rhine and the river remained a barrier to their advance into Germany until offensives at Remagen, Oppenheim, Rees and Wesel in March 1945. The failure of Market Garden to form a foothold over the Rhine ended Allied expectations of finishing the war by Christmas 1944.
Background.
After major defeats in Normandy in July and August, 1944, remnants of German forces withdrew across the Low Countries and eastern France towards the German border by the end of August. In the north, in the first week of September, the British 21st Army Group, under Field Marshal Bernard Montgomery, sent its British Second Army commanded by Lieutenant-General Sir Miles Dempsey advancing on a line running from Antwerp to the northern border of Belgium while its First Canadian Army, under Lieutenant-General Harry Crerar, was pursuing its task of recapturing the ports of Dieppe, Le Havre and Boulogne-sur-Mer. To the south, the U.S. 12th Army Group under Lieutenant General Omar Bradley was nearing the German border and had been ordered to orient on the Aachen gap with Lieutenant General Courtney Hodges' U.S. First Army, in support of Montgomery's advance on the Ruhr. Meanwhile, the group's U.S. Third Army, under Lieutenant General George S. Patton, moved eastward towards the Saar. At the same time, the U.S. 6th Army Group under General Jacob L. Devers was advancing towards Germany after their landings in southern France.
Logistics problems.
To disrupt German logistics efforts, the Allies had spent considerable effort, prior to D-Day, in bombing the French rail network, although aware this would also affect their own operations in the event of a breakout. The Overlord plan had foreseen this, calling for the exploitation of ports in Brittany to move the supply points forward as the armies moved. Eisenhower persisted with his plans to capture these ports, but some argued that the capture of Le Havre and Antwerp made this unnecessary.
By August, supply sources for the armies were still limited to the original invasion beaches, the nearby deep water port of Cherbourg at the tip of the Cotentin peninsula, and some minor ports in Normandy. Although over-the-beach supply operations outperformed expectations, September saw deteriorating weather and rising seas and the end of their usefulness was clearly in sight. Deep-water ports were therefore required; Cherbourg was useful, but far from the front. The massive port of Antwerp was captured virtually intact by Montgomery's troops on 4 September, but the Scheldt Estuary leading to it was still under German control. The failure to open the ports in Antwerp has been called "one of the greatest tactical mistakes of the war". Other important ports on the English Channel coast, such as Dunkirk, remained in German hands until May 1945.
Major efforts to re-open the rail network were started, and by the end of August, 18,000 men, including 5,000 prisoners of war, were engaged in railway construction. After many delays, the first trainload of supplies reached the US Third Army depot at Le Mans on 17 August. But these efforts were far too late to have any effect on the battles taking place after Operation Cobra and the subsequent breakout into France. Instead, all supplies for the armies had to be carried forward by truck, and there were simply not enough trucks for this effort. Advancing divisions of the US 12th Army Group left all their heavy artillery and half their medium artillery west of the Seine, freeing their trucks to move supplies for other units. The 21st Army Group stripped two of its divisions of their transport, and four British truck companies were loaned to the Americans.
Organisation of the Red Ball Express did much to lessen the impact of the transport shortage but this "ad hoc" operation could not solve the problem. As the Allied pursuit across France and Belgium continued, distances increased beyond the range of a single truck, requiring fuel to be brought forward in those trucks to re-fuel operations further from the ports. Fuel consumption soared. Soon it took five times as much fuel to deliver supplies as was actually delivered. Fuel pipelines were constructed to shorten supply lines, but were too time-consuming to build to be of much short-term use. By 28 August the Communications Zone could no longer guarantee fuel deliveries and both the US First and Third Armies reported less than a day's supply on hand. Furthermore, the stripping of the armies of their own transport had the effect of seriously slowing their own maneuverability.
On 30 August, the drastic steps were taken to suspend imports entirely; 21st Army Group would draw on its reserves in Normandy until the ports of Dieppe and Boulogne-sur-Mer could be opened. The situation was exacerbated by the fact that 1,400 British three-ton trucks were found to be useless because of faulty pistons in their engines — they could have moved 800 tons per day, enough for two divisions. Offensive operations slowed to a standstill, allowing the German forces their first respite in weeks.
Strategy.
Following the Allied breakout from Normandy and the closure of the Falaise pocket, Supreme Commander General Dwight D. Eisenhower favoured pursuit of the seemingly shattered German armies northwards and eastwards across the Seine, and ultimately to the Rhine on a broad front. While agreeing that Montgomery's drive towards the Ruhr should have priority, he still thought it was important to "get Patton moving again". To that end, in the first week of September 1944, Eisenhower authorised (U.S) First Army to cross the Rhine near Cologne, Bonn and Koblenz while (U.S.) Third Army crossed near Mannheim, Mainz and Karlsruhe. Eisenhower relied on speed, which in turn depended on logistics, which he conceded were "stretched to the limit". This strategy was contested by his subordinates, particularly Montgomery, who argued that with the supply situation deteriorating, he would not be able to reach the Ruhr, but "a relocation of our present resources of every description "would" be adequate to get "one" thrust to Berlin". SHAEF did provide Montgomery with additional resources, principally additional locomotives and rolling stock, and priority for air supply.
Montgomery initially suggested "Operation Comet", a limited airborne "coup de main" operation that was to be launched on 2 September 1944. Comet envisioned using the 1st Airborne Division, along with the Polish 1st Independent Parachute Brigade, to secure several bridges over the Rhine River to aid the Allied advance into the North German Plain. The Divisional Headquarters for the 1st Airborne Division, with the 1st Airlanding Brigade and the Polish 1st Independent Parachute Brigade were to land at Nijmegen, 1st Parachute Brigade was to land at Arnhem, and 4th Parachute Brigade was to land at Grave. However several days of poor weather and Montgomery's concerns over increasing levels of German resistance caused him to postpone the operation and then cancel it on 10 September.
Comet was replaced by a more ambitious plan to bypass the Siegfried Line by hooking around its northern end, allowing the Allies to cross the Rhine with large forces and trap the German Fifteenth Army between Arnhem and the shores of the IJsselmeer: Operation Market Garden. On 10 September Dempsey told Montgomery that he had doubts about this plan and that he instead favoured an advance north-eastwards between the Reichswald forest and the Ruhr to Wesel. Montgomery replied that he had just received a signal from London that something needed to be done to neutralise the V-2 launch sites around the Hague (which were bombarding London) and that the plan must therefore proceed. Montgomery flew to Brussels that afternoon to meet Eisenhower. Montgomery requested Eisenhower's Chief Administrative Officer to leave the meeting but insisted on his own remaining. He then tore a file of Eisenhower's messages to shreds in front of him and argued for a concentrated northern thrust, simultaneously demanding priority of supply.
Eisenhower, convinced that German forces faced imminent collapse, was equally adamant that advance on a broad front was correct. However, he consented to Operation Market Garden, giving it "limited priority" in terms of supplies but as part of his advance on a broad front. Eisenhower promised that allied aircraft and American trucks would deliver 1,000 tons of supplies per day. In vain, Montgomery complained about this to the Vice-Chief of the Imperial General Staff in London, Lieutenant-General Sir Archibald Nye.
For Market Garden, the U.S. 82nd and 101st Airborne Divisions would be maintained from British stocks for all common items such as food and fuel. Non-common items like ammunition, ordnance and signal and engineer stores were delivered by the Red Ball Express or by rail to No. 6 Army Roadhead at Grammont. Three newly arrived U.S. infantry divisions (the 26th, 95th, and 104th) were stripped of their transport, which was used to form provisional truck companies. These were assigned to the Red Ball Express, releasing eight companies to Red Lion, a special route to support Market-Garden. Red Lion convoys exceeded their target, delivering 650 tons per day instead of 500. Half of the tonnage hauled was supplies for the 82nd and 101st Airborne Divisions.
Eisenhower's decision to launch Market Garden was influenced by his desire to keep the retreating Germans under pressure. However, he was also under pressure from the U.S. to use the Airborne Army as soon as possible. After Normandy, the airborne forces had been withdrawn to reform in England, re-forming into the First Allied Airborne Army of two British and three U.S. airborne divisions and a Polish brigade. In the following months, plans for eighteen airborne operations had been drafted but then cancelled at short notice, mostly when the rapidly moving Allied ground forces overran the intended drop zones.
Geography.
Highway 69 (later nicknamed "Hell's Highway") leading through the planned route was two lanes wide, generally raised above the surrounding flat terrain of polder. The ground on either side of the highway was in places too soft to support tactical vehicle movement and there were numerous dikes and drainage ditches. Dikes tended to be topped by trees or large bushes and roads and paths were lined with trees. In early autumn this meant that observation would be seriously restricted.
There were six major water obstacles between the XXX Corps' jumping-off point and the objective of the north bank of the Nederrijn: the Wilhelmina Canal at Son wide; the Zuid-Willems Canal at Veghel ; the Maas River at Grave ; the Maas-Waal Canal ; the Waal River at Nijmegen ; and the Nederrijn at Arnhem . Plans were made to seize bridges across all these obstacles nearly simultaneously — any failure to do so could result in serious delay or even defeat. In case bridges were demolished by the Germans, XXX Corps had plans to rebuild them. To this end, a vast quantity of bridging material was collected, along with 2,300 vehicles to carry it and 9,000 engineers to assemble it.
Although the area is generally flat and open with less than a variation in altitude, Lieutenant-General Brian Horrocks, commander of XXX Corps recalled that "The country was wooded and rather marshy which made any outflanking operation impossible." There were two important hills, high, that represented some of the highest ground in the Netherlands; one north and west of Arnhem and one in the 82nd Airborne Division's zone, Groesbeek ridge. Seizure and defence of this hill was considered vital to holding the highway bridges.
Allied preparation.
The plan of action consisted of two operations:
Market.
Market would employ four of the six divisions of the First Allied Airborne Army. The U.S. 101st Airborne Division, under Major General Maxwell D. Taylor, would drop in two locations just north of XXX Corps to take the bridges northwest of Eindhoven at Son and Veghel. The 82nd Airborne Division, under Brigadier General James M. Gavin, would drop northeast of them to take the bridges at Grave and Nijmegen and the British 1st Airborne Division, under Major-General Roy Urquhart, with the Polish 1st Independent Parachute Brigade, under Brigadier General Stanisław Sosabowski, attached would drop at the extreme north end of the route, capturing the road bridge at Arnhem and the rail bridge at Oosterbeek. The 52nd (Lowland) Infantry Division would be flown to the captured Deelen Airfield on D+5.
The First Allied Airborne Army had been created on 16 August as the result of British requests for a coordinated headquarters for airborne operations, a concept approved by General Eisenhower on 20 June. The British had strongly hinted that a British officer—Browning in particular—be appointed its commander. Browning for his part decided to bring his entire staff with him on the operation to establish his field HQ using the much-needed 32 Horsa gliders for administrative personnel, and six Waco CG-4A gliders for U.S. Signals’ personnel. Since the bulk of both troops and aircraft were American, Brereton, a U.S. Army Air Forces officer, was named by Eisenhower on 16 July and appointed by SHAEF on 2 August. Brereton had no experience in airborne operations but had extensive command experience at the air force level in several theatres, most recently as commander of Ninth Air Force, which gave him a working knowledge of the operations of IX Troop Carrier Command.
Market would be the largest airborne operation in history, delivering over 34,600 men of the 101st, 82nd and 1st Airborne Divisions and the Polish Brigade. 14,589 troops were landed by glider and 20,011 by parachute. Gliders also brought in 1,736 vehicles and 263 artillery pieces. 3,342 tons of ammunition and other supplies were brought by glider and parachute drop.
To deliver its 36 battalions of airborne infantry and their support troops to the continent, the First Allied Airborne Army had under its operational control the 14 groups of IX Troop Carrier Command, and after 11 September the 16 squadrons of 38 Group (an organization of converted bombers providing support to resistance groups) and a transport formation, 46 Group.
The combined force had 1,438 C-47/Dakota transports (1,274 USAAF and 164 RAF) and 321 converted RAF bombers. The Allied glider force had been rebuilt after Normandy until by 16 September it numbered 2,160 CG-4A Waco gliders, 916 Airspeed Horsas (812 RAF and 104 US Army) and 64 General Aircraft Hamilcars. The U.S. had only 2,060 glider pilots available, so that none of its gliders would have a co-pilot but would instead carry an extra passenger.
Because the C-47s served as paratrooper transports and glider tugs and because IX Troop Carrier Command would provide all the transports for both British parachute brigades, this massive force could deliver only 60 percent of the ground forces in one lift. This limit was the reason for the decision to split the troop-lift schedule into successive days. Ninety percent of the USAAF transports on the first day would drop parachute troops, with the same proportion towing gliders on the second day (the RAF transports were almost entirely used for glider operations). Brereton rejected having two airlifts on the first day, although this had been accomplished during Operation Dragoon, albeit with forty-five more minutes of daylight against negligible opposition.
17 September was on a dark moon and in the days following it the new moon set before dark. Allied airborne doctrine prohibited big operations in the absence of all light, so the operation would have to be carried out in daylight. The risk of "Luftwaffe" interception was judged small, given the crushing air superiority of Allied fighters but there were concerns about the increasing number of flak units in the Netherlands, especially around Arnhem. Brereton's experience with tactical air operations judged that flak suppression would be sufficient to permit the troop carriers to operate without prohibitive loss. The invasion of Southern France had demonstrated that large scale daylight airborne operations were feasible. Daylight operations, in contrast to those in Sicily and Normandy, would have much greater navigational accuracy and time-compression of succeeding waves of aircraft, tripling the number of troops that could be delivered per hour. The time required to assemble airborne units on the drop zone after landing would be reduced by two-thirds.
IX Troop Carrier Command's transport aircraft had to tow gliders and drop paratroopers, duties that could not be performed simultaneously. Although every division commander requested two drops on the first day, Brereton's staff scheduled only one lift based on the need to prepare for the first drop by bombarding German flak positions for half a day and a weather forecast on the afternoon of 16 September (which soon proved erroneous) that the area would have clear conditions for four days, so allowing drops during them.
After one week preparations were declared complete. The planning and training for the airborne drops at Sicily and Normandy had taken months. One United States Air Force historian noted that Market was the only large airborne operation of the Second World War in which the USAAF "had no training program, no rehearsals, almost no exercises, and a...low level of tactical training."
Gavin, commanding the U.S. 82nd Airborne Division, was skeptical of the plan. In his diary he wrote, "It looks very rough. If I get through this one I will be very lucky." He was also highly critical of Browning, writing that he "...unquestionably lacks the standing, influence and judgment that comes from a proper troop experience... his staff was superficial... Why the British units fumble along... becomes more and more apparent. Their tops lack the know-how, never do they get down into the dirt and learn the hard way."
Garden.
Garden consisted primarily of XXX Corps and was initially spearheaded by the Guards Armoured Division, with the 43rd Wessex and 50th Northumbrian Infantry Divisions in reserve. They were expected to arrive at the south end of the 101st Airborne Division's area on the first day, the 82nd's by the second day and the 1st's by the fourth day at the latest. The airborne divisions would then join XXX Corps in the breakout from the Arnhem bridgehead.
Four days was a long time for an airborne force to fight unsupported. In addition the Allied paratroopers lacked adequate anti-tank weapons. Even so, before Operation Market Garden started it seemed to the Allied high command that the German resistance had broken. Most of the German Fifteenth Army in the area appeared to be fleeing from the Canadians and they were known to have no "Panzergruppen". It was thought that XXX Corps would face limited resistance on their route up Highway 69 and little armour. Meanwhile, the German defenders would be spread out over trying to contain the pockets of airborne forces, from the Second Army in the south to Arnhem in the north.
German preparation.
The rout of the "Wehrmacht" during July and August led the Allies to believe that the German army was a spent force unable to reconstitute its shattered units. During those two months the "Wehrmacht" had suffered a string of defeats with heavy losses. Between 6 June and 14 August it had suffered 23,019 killed in action, 198,616 missing or taken prisoner and 67,240 wounded. Many of the formations the "Wehrmacht" had possessed at the beginning of the Normandy campaign had been annihilated or had been reduced to skeleton formations by the end of August. As the German armies retreated towards the German frontier, they were often harried by air attacks and bombing raids by aircraft of the allied air forces, inflicting casualties and destroying vehicles. Attempts to halt the Allied advance often seemed fruitless as hurried counter-attacks and blocking positions were brushed aside and at times there seemed to be too few German units to hold anywhere. By early September the situation was beginning to change. The failure of the British 21st Army Group to seal off the Scheldt Estuary area had allowed the 65,000 troops of the German Fifteenth Army to be extricated from the area with 225 guns and 750 trucks via a flotilla of commandeered freighters, barges and small boats. From there they moved to the Netherlands.
Adolf Hitler began to take a personal interest in the apparent disintegration of Army Group B, which comprised the German armies in northern France, Belgium, and the Netherlands. On 4 September he recalled "Generalfeldmarschall" Gerd von Rundstedt, who had been in retirement since Hitler had dismissed him as "Wehrmacht" Commander-in-Chief West on 2 July, and reinstated him in his former command, replacing "Generalfeldmarschall" Walter Model, who had taken command just 18 days previously and would henceforth command only Army Group B. Rundstedt immediately began to plan a defence against what Wehrmacht intelligence judged to be 60 Allied divisions at full strength, although Eisenhower in fact possessed only 49 divisions.
Model set out to stop the Allied advance. The German 719th Infantry Division, part of LXXXVIII Corps, was dispatched south to the Albert Canal and Model requested reinforcements from Germany, stating that he would require twenty-five infantry divisions and six armoured divisions to hold; he envisioned a line stretching from Antwerp via Maastricht to Metz and from there to follow the line of the Albert Canal to the Meuse and the Siegfried Line. Meanwhile, Colonel General Kurt Student, commander of the "Fallschirmjaeger", the German airborne forces, received orders from Alfred Jodl, Chief of the Operations Staff of the "Oberkommando der Wehrmacht", to immediately move from Berlin and proceed to the Netherlands, where he would collect all available units and build a front near the Albert Canal, which was to be held at all costs. This front was to be held by the new First Parachute Army, a euphemistic name for a paper formation. Its units were scattered throughout Germany and the Netherlands and consisted either of units in the process of being formed or remnants cadred by survivors of previous units.
Though the situation seemed dire, the German front was beginning to form into what Robert Kershaw terms 'a crust'. Leadership, initiative and a good staff system were beginning to create a defence out of chaos. On 4 September the 719th infantry division began to dig in along the Albert Canal and was soon joined by forces under the command of Lieutenant General Kurt Chill. Although Chill only officially commanded the 85th Infantry Division, which had suffered heavy casualties during the retreat from Normandy, he had assumed command of the remnants of the 84th and 89th Infantry Divisions "en route". Initially ordered to take his command to the Rhineland for rest and reinforcements, Chill disregarded the order and moved his forces to the Albert Canal, linking up with the 719th; he also had 'reception centres' set up at the bridges crossing the Albert Canal, where small groups of retreating troops were picked up and turned into 'ad hoc' units. By 7 September the 176th Infantry Division, a "Kranken" division composed of elderly men and men with various medical complaints, had arrived from the Siegfried Line and elements of the First Parachute Army began to appear. At this stage the Army consisted of approximately seven "Fallschirmjaeger" regiments composed of some 20,000 airborne troops along with a collection of anti-aircraft batteries and a mix of 25 self-propelled guns and tank destroyers. "Kriegsmarine" and SS units were also allocated to Student's command, and Hitler had promised Model that 200 Panther tanks would be sent straight from the production lines; he also ordered all Tiger tanks, "Jagdpanther" self-propelled guns and 88 mm guns that were available in Germany be transferred to the West.
On 5 September, Model's forces were bolstered by the arrival of the II SS Panzer Corps, which consisted of the 9th SS and 10th SS Panzer Divisions under the command of Lieutenant General Wilhelm Bittrich. The Corps had been reduced to approximately 6,000–7,000 men, 20–30% of its original strength in the course of continuous action since late June including in the Falaise pocket; losses in officers and NCOs had been especially high. Model ordered the two divisions to rest and refit in 'safe' areas behind the new German line; these areas coincidentally were to be Eindhoven and Arnhem. The 10th SS Panzer Division was to be restored to full strength in order to provide an armoured reserve and thus the 9th SS Panzer Division was ordered to transfer all of its heavy equipment to its sister division; it was intended that the 9th would then be transported to Germany for replenishment. At the time of Operation Market-Garden, the 10th SS Panzer Division had an approximate strength of 3,000 men; an armoured infantry regiment, divisional reconnaissance battalion, two artillery battalions and an engineer battalion, all partially motorized. Other formations were appearing to strengthen the German defences. Between 16 and 17 September two infantry divisions from Fifteenth Army assembled in Brabant, understrength but well-equipped and able to act as a reserve. Near Eindhoven and Arnhem a number of scratch formations were being assembled. Several SS units, including an NCO training battalion and a "panzergrenadier" reserve battalion, were being prepared to enter combat and Luftwaffe and Kriegsmarine personnel were being grouped into "Fliegerhorst" and "Schiffstammabteilung" formations. There were also a number of training battalions that were being equipped, several depot battalions from the "Hermann Goering" Panzer Division and various artillery, anti-aircraft and field police units scattered throughout the north of the Netherlands.
Intelligence.
German.
Von Rundstedt and Model suspected that a large Allied offensive was imminent, having received many intelligence reports that described a 'constant stream' of reinforcements to the right wing of the British Second Army. The senior intelligence officer of Army Group B believed the Second Army would launch an offensive in the direction of Nijmegen, Arnhem and Wesel with a primary objective of reaching the industrial area along the Ruhr river. He was convinced that airborne troops would be used in this offensive but was unsure where they would be deployed, suspecting areas along the Siegfried Line north of Aachen or possibly even near the Saar. Second Army would assemble its units at the Maas-Scheldt and Albert Canals. The right wing of the Army would be the assault force, composed primarily of armoured units, which would force a crossing of the Maas and attempt to break through to the Ruhr industrial area near Roermond. The left wing would cover the Army's northern flank by moving up to the Waal near Nijmegen and isolating the German 15th Army situated on the Dutch coast.
Allied.
A number of reports about German troop movements reached Allied high command, including details about the identity and location of German armoured formations. Station X at Bletchley Park monitored and decrypted German Ultra intelligence reports and sent them to senior Allied commanders but they only reached army headquarters level and were not passed down any lower. On 16 September ULTRA decrypts revealed the movement of 9th and 10th SS Panzer Divisions to Nijmegen and Arnhem, creating enough concern for Eisenhower to send his Chief of Staff, Lieutenant General Walter Bedell Smith, to raise the issue with Montgomery on 10 September; however, Montgomery dismissed Smith's concerns and refused to alter the plans for the landing of 1st Airborne Division at Arnhem. Further information about the location of the German Panzer Divisions at Arnhem was revealed by aerial photographs of Arnhem taken by a photo-reconnaissance Spitfire XI from RAF's No. 16 Squadron, as well as information from members of the Dutch resistance. Fearing that 1st Airborne Division might be in grave danger if it landed at Arnhem the chief intelligence officer of the division, Major Brian Urquhart, arranged a meeting with Browning and informed him of the armour present at Arnhem. Browning dismissed his claims and ordered the division's senior medical officer to send Urquhart on sick leave on account of "nervous strain and exhaustion".
Battle.
Day 1: Sunday, 17 September 1944.
Early successes.
Operation Market Garden opened with Allied success all round. In the first landing, almost all troops arrived on top of their drop zones without incident. In the 82nd Airborne Division, 89% of troops landed on or within of their drop zones and 84% of gliders landed on or within of their landing zones. This contrasted with previous operations where night drops had resulted in units being scattered by up to . Losses to enemy aircraft and flak were light; German flak was described in reports as "heavy but inaccurate".
In the south, the 101st met little resistance and captured four of five bridges assigned to them. After a brief delay caused by an 88 mm gun and a machine gun post, the bridge at Son was blown up by the Germans on approach. Later that day several small attacks by the German 59th Infantry Division were beaten off. Small units of the 101st moved south of Son, towards Eindhoven. Later that day they made contact with German forces. Elements of the 44th Royal Tank Regiment were advancing in the VIII Corps sector who assisted the 101st.
To their north, the 82nd arrived with a small group dropped near Grave securing the bridge. They also succeeded in capturing one of the vitally important bridges over the Maas-Waal canal, the lock-bridge at Heumen. The 82nd concentrated their efforts to seize the Groesbeek Heights instead of capturing their prime objective, the Nijmegen bridge. The capture of the Groesbeek Heights was to set up a blocking position on the high ground to prevent a German attack out of the nearby Reichswald and to deny the heights to German artillery observers. Browning, the commander of the 1st Airbourne Army agreed with the assertions of Gavin, the commander of the 82nd, that Groesbeek Heights are the priority. Gavin wanted to occupy the Grave and Maas (Meuse)-Waal canal bridges before Nijmegen bridges. He would only send troops when these bridges were secure releasing troops to seize the Nijmegen bridge. Before the operation on the 15 September Gavin verbally ordered Lt-Col Linquist of the 508th to send a battalion to the Nijmegen bridge after landing. He had decided that there were enough troops for the other objectives. Linquist later said he understood he should send a battalion after his regiment had completed their earlier assigned targets. Linquist's battalion approached the bridge that evening delaying the seizure of the bridge. The battalion was stopped by a SS unit that had driven south from Arnhem. A part of the SS unit returned to Arnhem but found the northern end of the Arnhem bridge occupied by the British 1st Airborne. In an attempt to cross the bridge most of the SS unit was killed including the commander.
The 508th Parachute Infantry Regiment was tasked with taking the long Nijmegen highway bridge if possible but because of miscommunication they did not start until late in the day. They faced the same disadvantage as the British at Arnhem in dropping many miles from their objective. Had they been dropped nearer their objective or attacked earlier they would have faced only a dozen Germans. By the time the 508th attacked, troops of the 9th SS Reconnaissance Battalion were arriving. The attack failed, leaving the Nijmegen bridge in German hands.
This was vital; unlike some of the bridges to the south which were over smaller rivers and canals that could be bridged by engineering units, the Nijmegen and Arnhem bridges crossed two arms of the Rhine that could not be bridged easily. If either of the Nijmegen or Arnhem bridges were not captured and held, the advance of XXX Corps would be blocked and Operation Market Garden would fail.
British landings.
The 1st Airborne Division landed at 13:30 without serious incident but problems associated with the poor plan began soon after. Only half of the Division arrived with the first lift and only half of these (1st Parachute Brigade) could advance on the bridge. The remaining troops had to defend the drop zones overnight for the arrival of the second lift on the following day. Thus the Division's primary objective had to be tackled by less than half a brigade. While the paratroopers marched eastwards to Arnhem, the Reconnaissance Squadron was to race to the bridge in their jeeps and hold it until the rest of the Brigade arrived. The unit set off to the bridge late and having traveled only a short distance the vanguard was halted by a strong German defensive position; the squadron could make no further progress.
This had grave consequences. Five hours after the initial landing, feeling that the British were tied down in Arnhem, the Reconnaissance Battalion of the 9th SS Panzer Division was able to cross the Arnhem bridge and drive to Nijmegen and the bridge over the Waal branch of the Rhine. No British airborne unit was at the bridge.
Arnhem veteran Tom Hicks of 1st Parachute Squadron of the Royal Engineers described the problems the paratroops faced: "They (the Germans) had guns that outranged ours. We had no artillery with us so they could just lay off and pick you off kind of thing. If we wanted to get a gun out of action we had to send a patrol out, do it man to man kind of thing." 
Two of the three battalions of the 1st Parachute Brigade were slowed down by small German units of a training battalion which had quickly established a thin blocking line covering the obvious routes into Arnhem. Lieutenant-Colonel John Frost's 2nd Parachute Battalion, advancing eastwards along the southernmost road into Arnhem near the Rhine, found its route largely undefended. They arrived at the bridge in the evening and set up defensive positions at the north end. They were joined by Brigade HQ, led by Major Tony Hibbert, which was the only other unit to reach the bridge.
Two attempts to capture the arched steel bridge and its southern approach failed. Of the other battalions, the 3rd Parachute Battalion had only covered half the distance to the bridge when they halted for the night, the rear of their column being under attack and needing time to catch up. The 1st Parachute Battalion was similarly fragmented, yet pushed on around the flank of the German line throughout the night. Frequent skirmishes resulted in their making little more progress. The 3rd Battalion under Captain James Cleminson, KBE, MC, ambushed a German staff car and killed the commander of Arnhem's garrison, Major-General Friedrich Kussin, as well as his aide and his driver.
Communication breakdown.
Some loss of communication between the bridge and Divisional Headquarters in one of the drop zones was expected, because separated them and the main radio used throughout the Division was the Type 22 set designed to have an effective range of . The British radios did not function at any range; some had difficulty receiving signals from just a few hundred metres and others received nothing at all. It was found after landing that the radios had been set to different frequencies, two of which coincided with those of German and British public broadcasting stations. Other theories have been advanced to explain the greatly reduced range of the 1st Airborne Division's radio sets. Thus communication between 1st Airborne units was poor while German defences were being coordinated and reinforced. John Greenacre's study points out that radio communications failures were experienced by the Division before, were warned about prior to the operation, and provisioned for by bringing extra field telephone wire. The more powerful WS19HP set was used by 1st Brigade on D+1.
The only means of calling for close air support was through two special American units dropped with the 1st Airborne Division. These units were equipped with "Veeps": jeeps having Very High Frequency SCR-193 crystal sets. It was found impossible to communicate with aircraft on the higher of two frequencies for this and the sets could not be tuned to the lower frequency. Despite efforts to re-tune them, one set was soon destroyed by mortar fire and the other abandoned the next day, cutting the 1st Airborne's only possible link with RAF fighter-bombers. The pilots were under orders not to attack on their own initiative since from the air there was no easy way to distinguish friend from foe; together with poor weather, this led to a critical lack of air support.
After the war it was identified that the Royal Corps of Signals was either unaware, or did not make aware Divisional Signals of the communication problems identified in November 1943 due to sun spots by the Scientific Advisor's Office to the 21st Army Group. Consequently, Urquhart ordered the 4 m antennae to be used, which were useless due to physics of radio propagation. The wrong frequencies were part of the same problem due to Signals personnel not being aware of the scientific considerations behind radio communications.
XXX Corps advance.
On the morning of 17 September Lieutenant-General Brian Horrocks was given confirmation that the operation was to take place that day. At 12:30 hours Horrocks received a signal that the first wave of the airborne forces had left their bases within the United Kingdom and set the time for the ground attack to start at 14:35 hours. At 14:15 hours 300 guns of the Corps artillery opened fire, firing a rolling barrage in front of XXX Corps start line that was wide and in depth. The barrage was supported by seven squadrons of RAF Hawker Typhoons firing rockets at all known German positions along the road to Valkenswaard.
The advance was led by tanks and infantry of the Irish Guards and started on time when Lieutenant Keith Heathcote, commanding the lead tank, ordered his driver to advance. The lead units of the Irish Guards Group had broken out of XXX Corps bridgehead on the Meuse-Escaut canal and crossed into the Netherlands by 15:00 hours. After crossing the border the Irish Guards were ambushed by infantry and anti-tank guns dug in on both sides of the main road. Portions of the artillery barrage were refired and fresh waves of Hawker Typhoons were called in. The Guardsmen moved forward to clear the German positions, manned by elements from two German parachute battalions and two battalions of the 9th SS Division, and soon routed the German forces flanking the road. Interrogation of captured German soldiers led to some of them willingly, others after being threatened, pointing out the remaining German positions. The fighting soon died down and the advance resumed. By last light the town of Valkenswaard had been reached and occupied by the Irish Guards Group.
Horrocks had expected that the Irish Guards would have been able to advance the to Eindhoven within two-three hours; however, they had only covered . The operation was already starting to fall behind schedule. In Valkenswaard engineers were moved up to construct a Class 40 Bailey bridge over a stream, which was completed within 12 hours.
German reactions.
On the German side, it was soon clear what was happening. Field Marshal Walter Model was staying at the Tafelberg Hotel in Oosterbeek, a village to the west of Arnhem, when the British began to land in the countryside to the west of Oosterbeek. He rapidly deduced the likely focus of the attack and after evacuating his headquarters, organised a defence. Wilhelm Bittrich, commanding the 2nd SS Panzer Corps, sent a reconnaissance company of the 9th SS Panzer Division to Nijmegen to reinforce the bridge defences. By midnight, Model had gained a clear picture of the situation and had organised the defence of Arnhem. The confusion usually caused by airborne operations was absent at Arnhem and the advantage of surprise was lost. During the operation, the Germans recovered a copy of the Market-Garden plan from the body of an American officer, who should not have carried it into combat.
Day 2: Monday, 18 September.
Allied weather forecasters correctly predicted that England would be covered in fog on the morning of 18 September. The Second Lift was postponed for three hours and thick low clouds began to develop over the southern part of the battle zone, spreading during the day over the area, hampering supply and air support (Seven of the next eight days had poor weather and all air operations were cancelled on 22 and 24 September).
1st Airborne zone.
The 1st and 3rd Parachute Battalions pushed towards the Arnhem bridge during the early hours and had made good progress but they were frequently halted in skirmishes as soon as it became light. With their long and unwieldy columns having to halt to beat off attacks whilst the troops in front carried on unaware, the Germans delayed segments of the two battalions, fragmented them and mopped up the remnants.
Early in the day the 9th SS Reconnaissance Battalion (sent south the day before) concluded it was not needed in Nijmegen and returned to Arnhem. Though aware of the British troops at the bridge, it attempted to cross by force and was beaten back with heavy losses, including its commanding officer, SS-Hauptsturmführer Viktor Gräbner.
By the end of the day the 1st and 3rd Parachute Battalions had entered Arnhem and were within of the bridge with approximately 200 men, one-sixth their original strength. Most of the officers and non-commissioned officers had been killed, wounded or captured. The Second Lift was delayed by fog and jumped onto a landing zone under heavy attack but landed at full strength (the 4th Parachute Brigade consisting of the 10th, 11th and 156th Battalions of the Parachute Regiment, commanded by Brigadier-General John Winthrop Hackett) and C and D Companies of the 2nd South Staffordshire Regiment.
82nd Airborne zone.
Grave proved to be well defended and German forces continued to press on the 82nd deployed on the Groesbeek heights to the east of Nijmegen. The 505th Parachute Infantry Regiment defended against German attacks in Horst, Grafwegen and Riethorst. Early in the day, German counterattacks seized one of the Allied landing zones where the Second Lift was scheduled to arrive at 13:00. The 508th Parachute Infantry Regiment attacked at 13:10 and cleared the LZ by 14:00, capturing 16 German flak pieces and 149 prisoners. Delayed by weather in Britain, the Second Lift did not arrive until 15:30. This lift brought in elements of the 319th and 320th Glider Field Artillery battalions, the 456th Parachute Field Artillery battalion and medical support elements. Twenty minutes later, 135 B-24 bombers dropped supplies from low level.
101st Airborne zone.
Faced with the loss of the bridge at Son, the 101st unsuccessfully attempted to capture a similar bridge a few kilometres away at Best but found the approach blocked. Other units continued moving to the south and eventually reached the northern end of Eindhoven. At 06:00 hours the Irish Guards Group resumed the advance while facing determined resistance from German infantry and tanks. Around noon the 101st Airborne were met by the lead reconnaissance units from XXX Corps. At 16:00 radio contact alerted the main force that the Son bridge had been destroyed and requested that a Bailey bridge be brought forward. By nightfall the Guards Armoured Division had established itself in the Eindhoven area however transport columns were jammed in the packed streets of the town and were subjected to German aerial bombardment during the night. XXX Corps engineers, supported by German prisoners of war, constructed a class 40 Bailey bridge within 10 hours across the Wilhelmina Canal. During the day the British VIII and XII Corps, supporting the main attack, had forged bridgeheads across Meuse-Escaut Canal while facing stiff German resistance; 50th (Northumbrian) Infantry Division was transferred from XXX Corps to VIII Corps so to relieve XXX Corps from having to secure the ground gained thus far. Throughout the day German attacks were launched against XXX Corps and against the newly gained bridgeheads over the Meuse–Escaut Canal, all without success.
Day 3: Tuesday, 19 September.
Arnhem.
During the early morning hours the 1st Parachute Brigade began its attack towards Arnhem Bridge, with the 1st Battalion leading supported by remnants of the 3rd Battalion, with the 2nd South Staffordshires on the 1st Battalion's left flank and the 11th Battalion following. As soon as it became light the 1st Battalion was spotted and halted by fire from the main German defensive line. Trapped in open ground and under heavy fire from three sides, the 1st Battalion disintegrated and what remained of the 3rd Battalion fell back. The 2nd South Staffordshires were similarly cut off and, save for about 150 men, overcome by midday. The 11th Battalion, (which had stayed out of much of the fighting) was then overwhelmed in exposed positions while attempting to capture high ground to the north. With no hope of breaking through, the 500 remaining men of these four battalions withdrew westwards in the direction of the main force, away in Oosterbeek. 
The 2nd Battalion and attached units (approximately 600 men) were still in control of the northern approach ramp to the Arnhem bridge. The Germans recognised that they would not be moved by infantry attacks such as those that had been bloodily repulsed on the previous day so instead they heavily shelled the short British perimeter with mortars, artillery and tanks; systematically demolishing each house to enable their infantry to exploit gaps and dislodge the defenders. Although in battle against enormous odds, the British clung to their positions and much of the perimeter was held. 
Oosterbeek.
To the north of Oosterbeek the 4th Parachute Brigade led an attempt by the 1st Airborne Division to break through the German lines but communication difficulties and enemy resistance caused the attack to fail with heavy losses. The Division, scattered far and wide and hard pressed by the enemy on all sides had lost its offensive capability. Unable to help Lt.-Col. Frost at the bridge, the remaining soldiers attempted to withdraw into a defensive pocket at Oosterbeek and hold a bridgehead on the north bank of the Rhine.
The parachute elements of the Polish 1st Independent Parachute Brigade had remained in England because of dense fog. Their gliders, mainly carrying anti-tank guns and vehicles, were able to take off but had the misfortune to arrive above the landing zone just as the 4th Parachute Brigade was retreating across it and the gliders came under fire from German units pursuing the Brigade.
Nijmegen.
At 08:20, the 504th Parachute Infantry Regiment made contact with the Grenadier Guards of the XXX Corps at Grave. This enabled the Regiment to move on to other missions and place the 3rd Battalion in division reserve. By this time, according to the plan, they were due in Arnhem. XXX Corps were eight miles (13 km) from Arnhem with six hours in hand, "The earlier delays had been made up" A combined effort to take the Nijmegen bridge was mounted by two companies from the Guards Armoured Division and the 2nd Battalion, 505th Parachute Infantry Regiment. The attack got within of the bridge before being stopped; skirmishing continued throughout the night. A plan was made to attack the south end of the bridge again while the 3rd Battalion, 504th Parachute Infantry Regiment, planned to cross the river in boats downstream and then attack the north end. The boats were requested for late afternoon but did not arrive at that time. Once again XXX Corps was held up in front of a bridge which should have been captured before they arrived.
The 1st and 5th battalions, Coldstream Guards, were attached to the division. A supply attempt by 35 C-47s (out of 60 sent) was unsuccessful; the supplies were dropped from a high altitude and could not be recovered. Bad weather over English bases prevented the scheduled big glider mission carrying the 325th Glider Infantry Regiment from taking off, ending any hope for the scheduled reinforcements for the 82nd Airborne.
Wijchen.
At 09:50 the 504th Parachute Infantry Regiment was going forward to Wijchen, to attack the Edithbridge from its south end. The bridge was secured. After this fierce engagement they pushed on to the traffic bridge south of Wijchen. Another fierce engagement followed and this bridge was secured.
Eindhoven–Veghel.
To their south, units of the 101st sent to take Best the day before, were forced to yield to German counter-attacks during the morning. British tanks arriving during the day helped push back the Germans by late afternoon. Later a small force of Panther tanks arrived at Son and started firing on the Bailey bridge. These too were beaten back by anti-tank guns that had recently landed, and the bridge was secured. On the night of 19/20 September, 78 German bombers took off to attack Eindhoven. The Allies had no antiaircraft guns in the city, allowing the Germans to drop "a clear golden cluster of parachute flares" and bomb Eindhoven without suffering any losses. The city centre was shattered and the water pressure failed; over 200 houses were "gutted" and 9,000 buildings were damaged. The raid inflicted over 1,000 civilian casualties, including 227 dead. An ammunition convoy and trucks carrying gasoline were also hit. General Matthew Ridgway, in Eindhoven during the attack, wrote: "Great fires were burning everywhere, ammo trucks were exploding, gasoline trucks were on fire, and debris from wrecked houses clogged the streets." Elements of the 101st, based in and around the city, witnessed the attack and escaped loss. The 506th Parachute Infantry Regiment rushed into the burning city and rescued civilians during the night. According to Rick Atkinson, this was "the only large, long-range air strike by German bombers during the fall of 1944".
Day 4: Wednesday, 20 September.
Arnhem bridge.
Lt. Colonel John Frost's force at the bridge continued to hold and established communication via the public telephone system with 1st Division around noon learning that the division had no hope of relieving them and that XXX Corps was stopped to the south in front of Nijmegen bridge. By the afternoon the British positions around the north end of Arnhem bridge had weakened considerably. Casualties, mostly wounded, were high from constant shelling. An acute lack of ammunition, especially anti-tank munitions, enabled enemy armour to demolish British positions from point-blank range. Food, water and medical supplies were scarce, and so many buildings were on fire and in such serious danger of collapse that a two-hour truce was arranged to evacuate the wounded (including Lieutenant-Colonel Frost) into German captivity. Frederick Gough took over as commander when Frost left. While leading a remnant group in withdrawal from the bridge, toward Oosterbeek, for a joining with the rest of the 1st Division, Major Hibbert was captured.
The Germans overcame pockets of resistance throughout the day, gaining control of the northern bridge approaches and permitting reinforcements to cross the span and reinforce units further south near Nijmegen. The remaining British troops continued to fight on, some with just fighting knives but by early Thursday morning almost all had been taken prisoner. The last radio message broadcast from the bridge – "Out of ammo, God save the King" – was heard only by German radio intercept operators.
While it was estimated that the 1st Airborne Division, 10,000 strong, would only need to hold the Arnhem bridge for two days, 740 had held it for twice as long against far heavier opposition than anticipated. While 81 British soldiers died defending Arnhem bridge, German losses cannot be stated with any accuracy, though they were high; 11 units known to have participated in the fighting reported 50% casualties after the battle. In memory of the fighting there, the bridge has been renamed the "John Frost Bridge".
Oosterbeek.
Further west, the remnants of the 1st Airborne Division were gathering at Oosterbeek for their last stand; those already there were not seriously challenged by the enemy that day. To the east of the village, the 1st, 3rd and 11th Parachute Battalions and the 2nd South Staffordshires were organised into a defensive position. In desperate fighting later in the day, they repulsed an enemy attack which threatened to cut the division off from the Rhine and seal the fate of the bridgehead.
In the woods to the west of Oosterbeek the 4th Parachute Brigade fought its way towards the divisional perimeter but was attacked by German troops supported by artillery, mortars and tanks, (some mounting flame-throwers). The brigade had many casualties and the 10th Battalion reached Oosterbeek in the early afternoon with only 60 men.
In the rear, the 156th Parachute Battalion fought off numerous enemy attacks before counter-attacking; the Germans did not know they were fighting men who were in full retreat. The battalion, down to 150 men, mounted a bayonet charge to capture a hollow in the ground in the woods where they were pinned down by enemy attacks for the next eight hours. Towards the end of the day, 75 men fixed bayonets, broke through the German lines and retreated to the Allied pocket at Oosterbeek.
Nijmegen.
The 82nd did not drop men on both sides of the Nijmegen bridge: all troops were dropped on the south side of the Waal river. Gavin's plan had no means to seize the Nijmegen bridge other than by frontal assault from the south. Gavin took no boats: there was no option of a river crossing until XXX Corp came up from the south. Boats requested by the 82nd Airborne from XXX Corps arrived in the afternoon, not the morning. A hasty daylight assault crossing was ordered. At about 15:00, the 3rd Battalion, 504th PIR, commanded by Major Julian Cook, began the river assault across the Waal. The American paratroopers were rowed across the Waal by members of C/307th Engineer Battalion in 26 canvas assault boats. A shortage of paddles required some troopers to paddle the craft with rifle butts. About half the boats survived the crossing under heavy fire and eleven survived the first two crossings. Before the day was over, C/307th crossed the Waal five times while ferrying across two battalions of the 504th. The surviving paratroopers then proceeded to the village of Lent on the far bank to the north end of the bridge. The costly attack was nicknamed "Little Omaha" in reference to Omaha Beach. 200 paratroopers were killed, while German losses exceeded 267. German forces withdrew from both ends of the bridge after the XXX Corps Guards tanks secured the bridge at 18:30, D+4.
British Army officer Robert Kershaw interviewed 10th SS Panzer Division commander Heinz Harmel in the 1980s for his book "It Never Snows In September". Harmel stated:
In the hardback version of the book Kershaw has a copy of Harmel's artillery map which shows German troops between Nijmegen and Arnhem were extremely thin, a handful of security pickets with rifles at the Betuwe midpoint in Elst. By 22:00, D+4 Frost and Hibbert had been overrun at the Arnhem bridge, away. However Harmel never mentioned it was dark by the time the Guards tanks reached the village of Lent meeting the 82nd troops. Harmel also did not know, and never mentioned, that three Tiger tanks, one heavy gun and two companies of infantry were heading south from Arnhem to Lent, as the Guards tanks crossed the Nijmegen bridge.
Sergeant Peter Robinson, of the Guards Armoured Division who led the charge in his tank over the Nijmegen road bridge stated:
Initially four tanks crossed the bridge with a high probability some of the German explosive charges for demolition would activate. British engineers had cut some charges on the south of the bridge. As the tanks moved over the bridge they were fired on by Panzerfausts, and had grenades dropped on them by German troops in the bridge girders - 180 German bodies were recovered from the girders with some unaccounted falling into the river below. Once across the bridge only a few 82nd troops met the first tanks as they crossed the bridge. After crossing the bridge one tank was destroyed and another badly damaged, yet moving, and was driven to the village of Lent on the north side of the bridge by the only survivor of the attack - a Sgt Knight - who feigned being dead. The rest of the crews were killed, injured, and taken prisoner. One tank destroyed a German Sturmgeschütz assault tank lying in wait. The Guards tanks met the bulk of the 82nd troops north of the bridge in the village of Lent, 1 km north of the bridge and in darkness, after clearing out SS troops from the village and setting the church ablaze. On the road out of Lent, on the northern side of the railway bridge, the leading tank met two hidden German anti-tank guns in darkness. Even if the guns were located and destroyed, German troops with Panzerfausts were on the road and four available Guards tanks were low on ammunition. Only one of the four available tanks was a Firefly, mounting a gun capable of destroying a Tiger tank. Three Tiger tanks were heading south to Lent, unbeknownst to the Guards tank crews. Unable to locate the anti-tank guns, the tanks stopped.
The Germans were still threatening the northern end of the bridge. Many of the Guards tanks were unavailable to run north over the bridge still assisting the 82nd and XXX Corps troops in Nijmegen. The Guards who were over the bridge could not leave the northern end of the bridge for fear of recapture. At Lent only 5 tanks were available including the damaged tank, which took on some 82nd troops as tank crew who in previous service had driven Sherman tanks. For the night this tank had a British and American crew. One tank, manned by Capt Lord Carington, was stationed at the northern end of the bridge alone for 45 minutes, waiting for XXX Corps infantry relief who were fighting Germans in the girders as they moved across the bridge. The tank was attacked by the Germans with a Panzerfaust. After clearing the bridge of Germans in the girders, the Irish Guards crossed the bridge positioning a defence line. The line was reinforced with 82nd troops.
To the east, German attacks on the Groesbeek Heights made significant progress, capturing the only remaining bridge suitable for tanks. A counterattack at Mook by elements of the 505th PIR and 1st Battalion, the Coldstream Guards of XXX Corps forced the Germans back to their line of departure by 20:00. The 508th PIR lost ground at Im Thal and Legewald, when attacked by German infantry and tanks. By now it was evident that the German plan was to cut the highway, split up the Airborne units and cut off the advanced elements of XXX Corps. To the south, running battles between the 101st and various German units continued. Eventually several Panther tanks managed to cut the roads but pulled back when low on ammunition.
Day 5: Thursday, 21 September.
Oosterbeek.
Approximately 3,584 survivors of the 1st Airborne Division established themselves in the buildings and woods around Oosterbeek with the intention of holding a bridgehead on the north side of the Rhine until XXX Corps could arrive. Throughout the day their position was heavily attacked on all sides. In the southeast, Lonsdale Force (the remnants of the 1st, 3rd, and 11th Parachute Battalions and 2nd South Staffordshires) repulsed a big attack aided by the fire of the divisional light artillery. In the north the 7th King's Own Scottish Borderers were almost overrun during the afternoon but a counterattack with bayonets restored the situation and the heavily depleted battalion moved further south to occupy a narrower front. The most serious attack of the day was made at dawn against "B" Company, 1st Battalion, Border Regiment which controlled a vital area of high ground in the southwestern tip of the perimeter overlooking the Heveadorp ferry crossing at Driel, which was the division's only straightforward means of receiving reinforcements from the south. The company was attacked by enemy infantry and armour, including captured French tanks equipped with flamethrowers, and the heights were lost. Counterattacks failed and the remnants of the company were redeployed. The division was left in a precarious position, controlling just of the riverbank. The division held ground to similar attacks elsewhere on their front.
A supply attempt by RAF Stirlings of 38 Group was disrupted by the only Luftwaffe fighter interception during the operation. Fw 190s intercepted the Stirlings at low altitude and shot down 15. Anti-aircraft fire accounted for 8 further losses. The Fw 190s were able to penetrate the screen of Allied fighters sent to cover the drop when the U.S. 56th Fighter Group was late in arriving in its patrol sector between Lochem and Deventer. The 56th redeemed itself to an extent by shooting down 15 of the 22 Fw 190s as they departed.
Polish paratroopers enter the battle.
After two days of delay due to the weather, the Polish 1st Independent Parachute Brigade under Major-General Stanislaw Sosabowski entered the battle on the afternoon of 21 September, delivered at about 17:15 by 114 C-47s of the U.S. 61st and 314th Troop Carrier Groups. Two of the brigade's three battalions were dropped amidst heavy German fire, opposite the 1st Airborne Division's position on a new drop zone south of the Rhine near the village of Driel. The third battalion was dropped 12–15 miles away near Grave. Overall, the poor coordination by the British air transfer officers and persistent attacks by Luftwaffe aircraft caused their supplies to be dropped away on the opposite side of the Rhine.
Intending to use the Heveadorp ferry to reinforce the division, they discovered that the opposite bank was dominated by the enemy and that the ferry was missing; it was later found downstream past the road bridge, completely unserviceable. Unable to help the British, the Polish withdrew to Driel for the night and organised defence there, with the Rhine behind their backs and German units increasing in strength around them. The brigade had lost 25% of its fighting strength, amounting to 590 casualties. Several attempts to cross the Rhine on improvised equipment could only be partly successful due to heavy German fire and inability by the 1st Airborne to secure the landing area on the Rhine's northern bank. The 1st Airborne Division made radio contact during the day with guns of the 64th Medium Regiment of XXX Corps' artillery which had advanced with the ground forces and were assigned to the division for support. Unlike many others, this radio link worked throughout the battle and the regiment provided valuable fire support to the division.
Nijmegen.
Despite the capture of Nijmegen bridge and the clearing of the town on the previous evening, the five tanks of Guards Armoured Division which were across the river did not advance due to: darkness, one tank having been hit, meeting hidden German anti-tank guns, not knowing the full situation on the road ahead and having to secure the northern end of the bridge until infantry were fully in place. Unbeknown to the leading tank crews three Tiger tanks and two companies of infantry were heading down the road south from Arnhem to Lent. The Division resumed its advance about 18 hours later, at noon in daylight with reinforcements from Nijmegen.
Lieutenant-General Brian Horrocks claimed he needed to hold his force as his troops were still fighting in Nijmegen and supplies were slow coming up the single road from Belgium. The Coldstream Guards Group were repulsing an attack on the Groesbeek position, the Irish Guards Group had moved back south to Eindhoven to meet another attack, the Grenadiers had just captured the approaches to the bridge with assistance by the US 82nd paratroops and had five tanks across to support securing the north end of the bridge and the Welsh Guards were reserve for the 82nd Airborne. The Guards Armoured Division was scattered over twenty-five square miles of the south bank of the Waal. Horrocks stated, "Jim Gavin, the divisional commander, could have had no idea of the utter confusion that reigned in Nijmegen at the time, with sporadic battles going on all over the place, and particularly on our one road to the rear where chaos reigned".
The Market Garden plan depended upon a single highway as the route of advance and supply. This imposed a delay, although the delay was not that great. A problem was that other units could not be deployed on other routes to maintain momentum. Brigadier General Gavin's diary comment was: 
Gavin is silent on the 36 hour delay caused by his failure to capture the bridge on schedule. The historian Max Hastings wrote:
Another version of events by Robin Neillands quotes Captain Lord Carington 
The delay enabled the Germans to reinforce the defence already established at Ressen (an SS infantry battalion, eleven tanks, an infantry battalion, two 88 mm batteries, twenty 20 mm flak and the remnants of the fighting at Nijmegen south of Arnhem aided by use of the bridge following their capture of its northern end. The advance of the Guards, hindered by marshes that prevented off-road movement, was soon halted by a firm German defensive line. The Guards spearhead did not having the strength to outflank the line. The 43rd Division was ordered to take over the lead, work its way around the enemy positions and make contact with the Polish airborne troops at Driel to the west. The 43rd was away and there was a traffic jam between them and Nijmegen. It was not until the following day, Friday, that the whole division crossed the River Waal and began its advance.
The Germans, clearly starting to gain the upper hand at Arnhem, continued counterattacking all along the path of XXX Corps. XXX Corps still managed to advance with the 101st Airborne Division and XXX Corps holding ground.
At about 15:00, 406 C-47 glider tugs and 33 C-47 cargo carriers delivered supplies to the 82nd Airborne Division. About 60% of the supplies were recovered with 351 of the gliders being counted as effective, partly with the help of Dutch civilians. Most of the 82nd and 101st, reinforced with British armoured units, were engaged in defensive fighting with the objective of holding the highway corridor. Small engagements were fought along the whole length of the corridor.
Day 6: Friday, 22 September ("Black Friday").
The Germans, wary after unsuccessful and costly attacks the previous day, shelled and mortared the airborne positions heavily. By the end of the battle some 110 guns had been brought to Oosterbeek as the Germans shifted to the tactics that had worked so well at Arnhem bridge. Attacks were limited, conducted against specific positions and even individual houses. Numerous well-sited British anti-tank guns also caused German reluctance to attack. The survivors of the 1st Airborne were outnumbered 4 to 1. The Polish 1st Parachute Brigade at Driel, unable to cross the Rhine, nonetheless forced a redeployment of German forces. Fearing a Polish attempt to recapture Arnhem bridge or, worse, an attempt to cut the road to the south and so trap the 10th SS Panzer Division then blocking the route of the Guards Armoured Division to Arnhem, the Germans withdrew 2,400 troops from Oosterbeek. They were moved south of the river to engage the Polish paratroopers at Driel, making attacks to little effect through the day. 
Link-up between the Poles and XXX Corps.
The fog lifted as leading elements of the 43rd Division attempted to advance to Driel, exposing them to German fire. They arrived in Driel during the evening. Lacking assault craft, an unsuccessful attempt was made that night to put elements of the Polish brigade across the river. British and Polish engineers on both sides of the Rhine had worked through the day to improvise a crossing using small boats linked by signals cable but the cable kept breaking forcing the Polish troops to slowly row across against the strong current. The attempt was made under enemy observation and fire and only 52 soldiers of the 8th Polish Parachute Company survived the crossing before a halt was called at dawn. 
While much of the corridor was firmly in Allied hands, German counterattacks were still being mounted along its length. During the previous night, two mixed armoured formations on either side of Highway 69 attacked between Veghel and Grave; one group managed to cut the highway and prevent any further advance to Arnhem. 
Day 7: Saturday, 23 September.
The Germans had figured out what the Poles were attempting to do and they spent the rest of the day trying to cut off the British in their northern bridgehead from the riverside. The British managed to hold on and both sides suffered heavy losses. The Germans also attacked the Poles on the south side in order to tie them down but several tanks arrived from XXX Corps and they were beaten off. Boats and engineers from the Canadian army also arrived that day and another river crossing that night landed 150 troops of the Polish 3rd Parachute Battalion on the north bank of the Rhine.
To the south several more German attacks from their position astride the road were stopped but the road was still cut. XXX Corps then sent a unit of the Guards Armoured Division south and re-took the road. The rest of the force to the north continued to wait for infantry to move up, still only a few kilometres south of Arnhem.
The 325th GIR was finally delivered to reinforce the 82nd Airborne, originally planned for 19 September, and while it was immediately 75% effective, arrived far too late to affect the battle in that sector.
Day 8: Sunday, 24 September.
Another German force cut the road to the south of Veghel and set up defensive positions for the night. It was not clear to the Allies at this point how much of a danger this represented but the principal objective of Operation Market Garden, i.e. the Allied crossing of the Rhine, was abandoned this day and the decision made to go over to the defensive with a new front line in Nijmegen. Nonetheless, an attempt was made on Sunday night to reinforce the 1st Airborne Division with the 4th Battalion, The Dorsetshire Regiment. Two companies were put across the river but the location of the crossing point was ill-advised and the Dorsets landed among German positions. Fragmented by their landing and immediately pinned down, of the 315 men who crossed only 75 reached Oosterbeek; the remainder were taken prisoner. As a result of this failure, it was decided to withdraw the 1st Airborne Division from its bridgehead on the northern side of the Rhine.
Day 9: Monday, 25 September.
At dawn the 1st Airborne Division received their orders to withdraw across the Rhine; this was called "Operation Berlin". This could not be done until nightfall and in the meantime the division struggled to survive. In a departure from their cautious attritional tactics of the previous days, the Germans formed two potent SS battlegroups and made a significant thrust along a narrow front in the eastern sector. This succeeded in breaking through the thin front line and for a time the division was in peril. The attack met with increasing resistance as it pushed deeper into the British lines and was finally broken up by a heavy bombardment of the 64th Medium Regiment.
Employing every ruse to give the Germans the impression that their positions were unchanged, the 1st Airborne Division began its withdrawal at 22:00. British and Canadian engineer units ferried the troops across the Rhine, covered by the Polish 3rd Parachute Battalion on the north bank. By early the next morning they had withdrawn 2,398 survivors, leaving 300 men to surrender on the north bank at first light, when German fire prevented their rescue. Of approximately 10,600 men of the 1st Airborne Division and other units who fought north of the Rhine, 1,485 had died and 6,414 were taken prisoner of whom one third were wounded.
To the south the newly arrived 50th (Northumbrian) Infantry Division attacked the Germans holding the highway and secured it by the next day. Allied positions in the Nijmegen Salient as it came to be known, were manned throughout the rest of September and October by airborne units, then handed over to the First Canadian Army in November 1944 and remained unchanged until February 1945 when Operation Veritable was launched on the Rhineland, advancing east instead of north towards Arnhem.
Losses.
XXX Corps suffered fewer than 1,500 casualties, which stands in stark contrast to the 8,000 casualties suffered by the 1st Airborne Division. On several occasions, units of the flanking British Corps made contact with paratroopers before units of XXX Corps, and fought on to support them until the end of the operation. The higher toll by the 101st Airborne Division reflects the reality that aside from contending with the local German defenders, they also had to combat German troops retreating from the XXX Corps advance.
German casualties are harder to determine, as the records are mostly incomplete. The official casualties estimated by Rundstedt are 3,300 but these numbers are challenged by historians. Conservative estimates range from 6,400, 8,000, to as high as 9,800–13,300. Kershaw gives a detailed but incomplete list of the participated German units and their casualties and concludes with 6,315 – 8,925 overall German casualties. A contemporary paper of the 21st Army Group mentions that 16,000 German prisoners were taken during Operation Market Garden, but it is unclear how those numbers relate to later casualty estimates.
Transport Command Victoria Cross.
On 19 September, RAF Douglas Dakota Mk. III, "KG374", c/n 12383, (ex-USAAF C-47A-DK, "42-92568"), 'YS-DM', of 271 Squadron, RAF Down Ampney, Gloucester, piloted by F/Lt. David S. Lord, was hit by AA in the starboard engine while on a supply sortie for beleaguered troops at Arnhem. Despite fire spreading to all of the starboard wing, the pilot spent ten minutes making two passes over very small dropzones (which, unknown to the crew, had been overrun by German forces) to drop eight ammunition panniers. Just after the last one was dropped, the fuel tank exploded, tearing off the wing, and only navigator F/O Harry A. King escaped from the stricken aircraft, descending by parachute. He was captured and made POW the following morning, spending the rest of the war in Stalag Luft I at Barth. Killed While Flying (KWF) were pilot Lord, second pilot P/O R. E. H. "Dickie" Medhurst (son of Air Chief Marshal Sir Charles Medhurst), wireless operator F/O Alec F. Ballantyne, and four air despatchers of 223 Company RASC, Cpl. P. Nixon, Dvr. A. Rowbotham, Dvr. J. Ricketts and Dvr. L. Harper. Following the release of King from prison camp, full details of the action became known and pilot Lord received a posthumous Victoria Cross on 13 November 1945, the only VC awarded to any member of Transport Command during the Second World War. In May 1949 the Dutch Government awarded Harry King the Netherlands Bronze Cross.
Aftermath.
Debate on Allied strategy and tactics.
Operation Market Garden has remained a controversial battle for several reasons. Allied tactics and strategy have been much debated. The operation was the result of a strategy debate at the highest levels of Allied command in Europe. Much post-war analysis has thus probed the alternatives that were not taken, such as giving priority to securing the Scheldt estuary. Some historians maintain that Market Garden was a good idea that was executed poorly, and that concentrating one's forces in an attempt to break through at one point is a more effective strategy than trying to advance on a broad front. 
Optimistic planning.
Among the controversial aspects of the plan was the necessity that all the main bridges be taken. The terrain was also ill-suited for the mission of XXX Corps. Brereton had ordered that the bridges along XXX Corps' route should be captured with ""thunderclap surprise"". It is therefore surprising in retrospect that the plans placed so little emphasis on capturing the important bridges immediately with forces dropped directly on them. In the case of Veghel and Grave where this was done, the bridges were captured with only a few shots being fired.
The decision to drop the 82nd Airborne Division on the Groesbeek Heights, several kilometres from the Nijmegen Bridge, has been questioned because it resulted in a long delay in its capture. Browning and Gavin considered holding a defensive blocking position on the ridge a prerequisite for holding the highway corridor. Gavin generally favoured accepting the higher initial casualties involved in dropping as close to objectives as possible in the belief that distant drop zones would result in lower chances of success. With the 82nd responsible for holding the centre of the salient, he and Browning decided the ridge must take priority. Combined with the 1st Airborne Division's delays within Arnhem, which left the Arnhem bridge open to traffic until 20:00, the Germans were given vital hours to reinforce their hold on the bridge.
At Arnhem, the RAF planners selected the drop zones, refusing to drop near the town on the north side of the target bridge because of flak at Deelen. Another suitable drop zone just to the south of the bridge was rejected because it was thought to be too marshy for landing gliders containing the force's heavier equipment, however that same drop zone was selected for the 1st Polish Independent Parachute Brigade in the third lift, which suggests they were well aware of its suitability. Urquhart made his objections to the RAF planners who were unmoved, even when he informed them that the troops and glider pilots were willing to take whatever risks landing closer to the objectives entailed. Urquhart made the best of the RAF planners' decision and thus the three main landing and drop zones were from the bridge, with the fourth being away.
Weather.
A precarious timetable at the mercy of the weather resulted in the 101st Airborne Division being without its artillery for two days, the 82nd Airborne without its artillery for a day and without its glider infantry regiment for four days and the British 1st Airborne division without its fourth brigade until the fifth day. The more time required to complete the air drops, the longer each division had to devote forces to defending the drop and landing zones, weakening their offensive power.
Priority of operation.
Several weeks prior to the plan taking shape, the British had captured Antwerp and its all-important port facilities. This action had the potential to greatly shorten the Allies' supply lines and trap Gustav-Adolf von Zangen's 15th Army of 80,000 men on the south side of the Scheldt Estuary. Instead, Von Zangen's men, with most of their heavy equipment including their artillery, escaped by boat to South Beveland peninsula (Zeeland province, the Netherlands). In September, the peninsula could have been sealed by a short advance of only past Antwerp. Instead, because priority on supplies went to Market Garden, the First Canadian Army paused at Antwerp and then fought the costly Battle of the Scheldt in October. In the aftermath of Market Garden, Antwerp was not made operational until 28 November. By 1 October, over 240 Allied supply ships were waiting, unable to unload their cargo because of the limited port facilities on the continent.
Missed opportunities.
Arnhem bridge was not the only Rhine crossing. Had the Market Garden planners realized that a ferry was available at Driel, the British might have secured that instead of the Arnhem bridge. Being a shorter distance away from their western drop and landing zones, the 1st Parachute Brigade could have concentrated to hold the Oosterbeek heights, instead of one battalion farther away at the road bridge; in this case, Arnhem was "one bridge too many". A contrasting view is that the attack into Arnhem was intended to capture the rail bridge, the pontoon bridge and the road bridge; that the rail bridge was blown in the face of Frost's 2nd Parachute Battalion, the pontoon bridge had been disabled by the removal of several sections and that this left only the road bridge intact, the Heveadorp ferry was no substitute for a bridge.
Hypothetically, had XXX Corps pushed north, they might have arrived at the south end and secured it (had the Guards Armoured sent more than five Shermans across the bridge and had they not been later stopped by the German position at Ressen), leaving the way open for another crossing to the north at some other point. There was the smaller possibility of arriving with Frost's force intact. This perceived "lack of guts" caused some bitterness at the time among members of both the British 1st Airborne and the US 82nd Airborne. As it was, XXX Corps did not resume the drive to Arnhem that night but eighteen hours later.
The commander of XXX Corps advocated another course of action. About to the west was another bridge at Rhenen, which he predicted would be undefended, because of all the efforts being directed on Oosterbeek. This was true but the corps was never authorised to take the bridge; if they had, it is almost certain they would have crossed unopposed into the rear of the German lines. By this time, it appears that Montgomery was more concerned with the German assaults on Market Garden's lengthy 'tail'.
Despite the heroism, bad choices were made throughout and opportunities were ignored. The commander of the Glider Pilot Regiment had asked for a small force with gliders to land on the southern side of the bridge at Arnhem to quickly capture it but he was denied. This was surprising in light of the fact that in Normandy, the British 6th Airborne Division had used such coup-de-main tactics to take Pegasus Bridge. In Britain, the commander of the British 52nd (Lowland) Infantry Division, whose troops were slated to fly into a captured airfield, pleaded with his superiors to allow a brigade to fly in with gliders to assist Major-General Urquhart's trapped forces. Browning declined the offer, "as situation better than you think" and reaffirmed his intention to fly the 52nd Division in to Deelen airfield as planned. This was probably fortunate, as glider landings on undefended landing zones before the eyes of an alert enemy could have resulted in catastrophe. There was another airfield near Grave and the 52nd Lowland could have been landed there, as the 1st Light Anti-Tank Battery did on 26 September. The Polish 1st Parachute Brigade commander Major-General Stanisław Sosabowski, was prepared to try a dangerous drop through the fog which held up his deployment but again was refused.
Market Garden was a risky plan that required a willingness to gamble at the tactical, small-unit level. Unfortunately, the detailed planning and leadership required at that level was not always present. The 1st Airborne Division, the least experienced in working as a whole division was given the most difficult distant objective. The failure of the 82nd Airborne Division to attach maximum importance to the early capture of Nijmegen Bridge was a fatal mistake. XXX Corps was also criticized for its "inability" to keep to the operation's timetable. The most notable example of this was on Wednesday 20 September, when Nijmegen Bridge had finally been captured and the Guards Armoured Division, after crossing, promptly came to a halt for the night to rest, refuel and rearm. XXX Corps was delayed at Son by a bridge demolition and the delay at Nijmegen (having arrived by D+3, within the maximum time estimate, having compensated for the delay to build a Bailey Bridge at Son) was caused by having to help the 82nd's paratroopers capture the town and bridges. The lead unit of XXX Corps, the Guards Armoured Division, was led by a commander (Allan Adair) whom Montgomery had sought to remove prior to D-Day. This action was blocked due to Adair's popularity. Gavin regretted giving his division's most important tasks (Groesbeek ridge and Nijmegen) to the 508th Parachute Infantry Regiment rather than his best regiment, Tucker's 504th Parachute Infantry Regiment.
Intelligence failure.
Unlike the American airborne divisions in the area, British forces at Arnhem ignored the local Dutch resistance. There was a good reason for this: Britain's spy network in the Netherlands had been thoroughly and infamously compromised — the so-called "England game", which had only been discovered in April 1944. Perhaps assuming that the Dutch resistance would be similarly penetrated, British intelligence took pains to minimise all civilian contact. U.S. units, without this bad experience, made use of Dutch help. As things turned out, knowledge of the Driel ferry or of the underground's secret telephone network could have changed the result of the operation, especially since Allied radio equipment failed, having to rely on messengers. The latter was very important: it would have given the XXX Corps and Airborne High Command knowledge about the dire situation at Arnhem.
After the war, claims arose that the Dutch resistance had indeed been penetrated. One high-ranking Dutch officer who had worked in counter-intelligence at SHAEF, Lieutenant-Colonel Oreste Pinto published a popular book, "Spy Catcher", part-memoir and part counter-intelligence handbook. Pinto, who had made a name for himself in World War I for his part in uncovering Mata Hari, claimed that a minor figure in the Dutch resistance, Christiaan Lindemans (nicknamed "King Kong") had been a German agent and had betrayed Operation Market Garden to the Germans. Lindemans was arrested in October 1944, but committed suicide in his cell in 1946 while awaiting trial. In 1969, French journalist and historian Anne Laurens concluded that Lindemans had been a double agent.
Allied reflections.
In 1948, Eisenhower wrote that "The attack began well and unquestionably would have been successful except for the intervention of bad weather." Eisenhower was isolated in the SHAEF HQ at Granville, which did not even have radio or telephone links, so his staff were largely ignorant of the details of the operation. Bedell Smith’s objections were brushed aside by Montgomery, as were those of Montgomery’s chief of staff Freddie de Guingand who went to England on sick leave. Responsibility for the failure "began with Eisenhower and extended to Montgomery, Brereton, Browning, and, on the ground side, Dempsey and Horrocks, neither of whom ... galvanised their tank units while there was still time to have seized and held Arnhem bridge". In the end Browning and Montgomery made Sosabowski (who had been ignored) and the Poles the scapegoat. D'Este notes that Montgomery’s admission of a mistake was unique: "the only admission of failure by a senior Allied commander". Eisenhower wrote to Urquhart: "In this war there has been no single performance by any unit that has more greatly inspired me or more highly excited my admiration, than the nine days action of your division between 17 and 26 September".
Montgomery predicted that "in years to come it will be a great thing for a man to be able to say: 'I fought at Arnhem'." Montgomery claimed that Market Garden was "90% successful" and said:
CBS war correspondent Bill Downs, who was assigned to Montgomery's campaign since the Normandy invasion, famously said of Nijmegen that it was "...a single, isolated battle that ranks in magnificence and courage with Guam, Tarawa, Omaha Beach...a story that should be told to the blowing of bugles and the beating of drums for the men whose bravery made the capture of this crossing over the Waal River possible."
Subsequent combat in the Netherlands.
After Operation Market Garden failed to establish a bridgehead across the Rhine, Allied forces launched offensives on two fronts in the south of the Netherlands. To secure shipping to the vital port of Antwerp they advanced northwards and westwards, taking the Scheldt Estuary in the Battle of the Scheldt. Allied forces also advanced eastwards in Operation Aintree to secure the banks of the Meuse as a natural boundary for the established salient. This attack on the German bridgehead west of the Meuse near Venlo was for the Allies an unexpectedly protracted affair, which included the Battle of Overloon.
In February 1945, Allied forces in Operation Veritable advanced from the Groesbeek heights which had been taken during Market Garden, and into Germany, crossing the Rhine in March during Operation Plunder. As a result of Operation Plunder, the city of Arnhem was finally liberated by I Canadian Corps on 14 April 1945 after two days of fighting. A surrender of the remaining German forces in the west of the Netherlands was signed on 5 May.
Famine in the Netherlands.
A tragic consequence of the operation's failure was the Hongerwinter (Hungerwinter). During the battle Dutch railway workers, incited by the Dutch government in London, went on strike in order to aid the Allied assault. In retribution Germany forbade food transportation, and in the following winter more than twenty thousand Dutch citizens starved to death.
Commemoration.
Memorials and remembrance.
The prized Arnhem bridge for which the British had fought so hard did not survive the war. As the front line stabilised south of the Rhine, B-26 Marauders of 344th Bomb Group, USAAF destroyed it on 7 October to deny its use to the Germans. It was replaced with a bridge of similar appearance in 1948 and renamed John Frost Bridge (John Frostbrug) on 17 December 1977.
There are a number of monuments in the Arnhem area. A memorial near Arnhem reads
On 16 September 1994, 101st Airborne veterans unveiled a "Monument for the Dutch" in Sint-Oedenrode. The monument is a gift from the veterans to the civilians who fought alongside of the U.S. troops, much to the surprise and relief of the U.S. soldiers. The inscription on the monument is in English and reads "Dedicated to the people of the Corridor by the veterans of the 101st Airborne Division, in grateful appreciation of their courage, compassion and friendship".
On 31 May 2006, Polish 1st Independent Airborne Brigade was awarded the Dutch Military William Order by HM Queen Beatrix for gallantry at Arnhem during Operation Market Garden in 1944. The American 82nd Airborne Division had previously been awarded the same order for gallantry during the operation on 8 October 1945.
Several museums in the Netherlands are dedicated to Operation Market Garden, including the National Liberation Museum 1944–1945 in Groesbeek, Wings of Liberation Museum Park in Best (near Eindhoven) and Airborne Museum Hartenstein in Oosterbeek. Annually there is a commemorative walk in Oosterbeek on the first Saturday of September which attracts tens of thousands of participants.
A Commemorative Project plaque was unveiled on 23 June 2009, to commemorate the unique military and historical ties between Canada and the Netherlands. A hole, a par five, on the south course (Hylands Golf Course Uplands) in Ottawa, Ontario was named "Arnhem, in honour of the Royal Canadian Artillery squadrons that took part in Second World War allied airborne Operation MARKET GARDEN from September 17 to 26, 1944. The operation, intended to secure a series of bridges so the allies could advance into Germany, fell short when the allied forces were unsuccessful in securing the bridge over the Rhine at Arnhem."
The village of Somerby in Leicestershire has a memorial hall dedicated to the men of the 10th battalion who were based there and who did not return. Each year there is a parade in their honour led by the Seaforth Highlanders.
Film.
Operation Market Garden was the subject of the 1946 film "Theirs Is the Glory". This film mixed original footage from the battle with re-enactments, shot on location in Arnhem. Many of the actors portraying the paratroopers were soldiers who fought in the battle. Some played themselves, including Kate ter Horst, Frederick Gough, John Frost and Stanley Maxted, the Canadian journalist who posted gripping reports from the front at Arnhem. "A Bridge Too Far" is a 1977 epic war film, based on the 1974 book of the same name by Cornelius Ryan. It was adapted by William Goldman, directed by Richard Attenborough and had an all-star cast. Unlike the earlier film, it covered the entire operation from all sides, British, American, German, Polish and Dutch. Dramatizations of the actions of the 101st Airborne Division, 506th PIR during the battle (with cameo scenes also of XXX Corps, British paratroopers and Canadian engineers) formed part of the HBO television miniseries "Band of Brothers".
Notes.
Footnotes
Citations

</doc>
<doc id="56434" url="https://en.wikipedia.org/wiki?curid=56434" title="Julia set">
Julia set

In the context of complex dynamics, a topic of mathematics, the Julia set and the Fatou set are two complementary sets (Julia 'laces' and Fatou 'dusts') defined from a function. Informally, the Fatou set of the function consists of values with the property that all nearby values behave similarly under repeated iteration of the function, and the Julia set consists of values such that an arbitrarily small perturbation can cause drastic changes in the sequence of iterated function values.
Thus the behavior of the function on the Fatou set is 'regular', while on the Julia set its behavior is 'chaotic'.
The Julia set of a function "f" is commonly denoted "J"("f"), and the Fatou set is denoted "F"("f"). These sets are named after the French mathematicians Gaston Julia and Pierre Fatou whose work began the study of complex dynamics during the early 20th century.
Formal definition.
Let "f"("z") be a complex rational function from the plane into itself, that is, formula_1, where "p"("z") and "q"("z") are complex polynomials. Then there is a finite number of open sets "F"1, ..., "Fr", that are left invariant by "f"("z") and are such that:
The last statement means that the termini of the sequences of iterations generated by the points of "Fi" are either precisely the same set, which is then a finite cycle, or they are finite cycles of circular or annular shaped sets that are lying concentrically. In the first case the cycle is "attracting", in the second it is "neutral".
These sets "Fi" are the Fatou domains of "f"("z"), and their union is the Fatou set "F"("f") of "f"("z"). Each of the Fatou domains contains at least one critical point of "f"("z"), that is, a (finite) point "z" satisfying formula_2, or "z" = ∞, if the degree of the numerator "p"("z") is at least two larger than the degree of the denominator "q"("z"), or if formula_3 for some "c" and a rational function "g"("z") satisfying this condition.
The complement of "F"("f") is the Julia set "J"("f") of "f"("z"). "J"("f") is a nowhere dense set (it is without interior points) and an uncountable set (of the same cardinality as the real numbers). Like "F"("f"), "J"("f") is left invariant by "f"("z"), and on this set the iteration is repelling, meaning that formula_4 for all "w" in a neighbourhood of "z" (within "J"("f")). This means that "f"("z") behaves chaotically on the Julia set. Although there are points in the Julia set whose sequence of iterations is finite, there are only a countable number of such points (and they make up an infinitely small part of the Julia set). The sequences generated by points outside this set behave chaotically, a phenomenon called "deterministic chaos".
There has been extensive research on the Fatou set and Julia set of iterated rational functions, known as rational maps. For example, it is known that the Fatou set of a rational map has either 0,1,2 or infinitely many components. Each component of the Fatou set of a rational map can be classified into one of four different classes.
Properties of the Julia set and Fatou set.
The Julia set and the Fatou set of "f" are both completely invariant under iterations of the holomorphic function "f":
Examples.
For formula_8 the Julia set is the unit circle and on this the iteration is given by doubling of angles (an operation that is chaotic on the points whose argument is not a rational fraction of formula_9). There are two Fatou domains: the interior and the exterior of the circle, with iteration towards 0 and ∞, respectively.
For formula_10 the Julia set is the line segment between −2 and 2. There is one Fatou domain: the points not on the line segment iterate towards ∞. (Apart from a shift and scaling of the domain, this iteration is equivalent to formula_11 on the unit interval, which is commonly used as an example of chaotic system.)
These two functions are of the form formula_12, where "c" is a complex number. For such an iteration the Julia set is not in general a simple curve, but is a fractal, and for some values of "c" it can take surprising shapes. See the pictures below.
For some functions "f"("z") we can say beforehand that the Julia set is a fractal and not a simple curve. This is because of the following result on the iterations of a rational function:
Theorem. Each of the Fatou domains has the same boundary, which consequently is the Julia set.
This means that each point of the Julia set is a point of accumulation for each of the Fatou domains. Therefore, if there are more than two Fatou domains, "each" point of the Julia set must have points of more than two different open sets infinitely close, and this means that the Julia set cannot be a simple curve. This phenomenon happens, for instance, when "f"("z") is the Newton iteration for solving the equation formula_13:
The image on the right shows the case "n" = 3.
Quadratic polynomials.
A very popular complex dynamical system is given by the family of complex quadratic polynomials, a special case of rational maps. Such quadratic polynomials can be expressed as 
where "c" is a complex parameter.
The parameter plane of quadratic polynomials - that is, the plane of possible "c"-values - gives rise to the famous Mandelbrot set. Indeed, the Mandelbrot set is defined as the set of all "c" such that formula_16 is connected. For parameters outside the Mandelbrot set, the Julia set is a Cantor space: in this case it is sometimes referred to as Fatou dust.
In many cases, the Julia set of "c" looks like the Mandelbrot set in sufficiently small neighborhoods of "c". This is true, in particular, for so-called 'Misiurewicz' parameters, i.e. parameters "c" for which the critical point is pre-periodic. For instance:
In other words the Julia sets formula_16 are locally similar around Misiurewicz points.
Generalizations.
The definition of Julia and Fatou sets easily carries over to the case of certain maps whose image contains their domain; most notably transcendental meromorphic functions and Adam Epstein's finite-type maps.
Julia sets are also commonly defined in the study of dynamics in several complex variables.
The potential function and the real iteration number.
The Julia set for formula_8 is the unit circle, and on the outer Fatou domain, the "potential function" φ("z") is defined by φ("z") = log|"z"|. The equipotential lines for this function are concentric circles. As formula_19 we have
where formula_21 is the sequence of iteration generated by "z". For the more general iteration formula_22, it has been proved that if the Julia set is connected (that is, if "c" belongs to the (usual) Mandelbrot set), then there exist a biholomorphic map ψ between the outer Fatou domain and the outer of the unit circle such that formula_23. This means that the potential function on the outer Fatou domain defined by this correspondence is given by:
This formula has meaning also if the Julia set is not connected, so that we for all "c" can define the potential function on the Fatou domain containing ∞ by this formula. For a general rational function "f"("z") such that ∞ is a critical point and a fixed point, that is, such that the degree "m" of the numerator is at least two larger than the degree "n" of the denominator, we define the "potential function" on the Fatou domain containing ∞ by:
where "d" = "m" − "n" is the degree of the rational function.
If "N" is a very large number (e.g. 10100), and if "k" is the first iteration number such that formula_26, we have that
for some real number formula_28, which should be regarded as the "real iteration number", and we have that:
where the last number is in the interval [0, 1).
For iteration towards a finite attracting cycle of order "r", we have that if "z*" is a point of the cycle, then formula_30 (the "r"-fold composition), and the number
is the "attraction" of the cycle. If "w" is a point very near "z*" and "w"' is "w" iterated "r" times, we have that
Therefore the number formula_33 is almost independent of "k". We define the potential function on the Fatou domain by:
If ε is a very small number and "k" is the first iteration number such that formula_35, we have that
for some real number formula_28, which should be regarded as the real iteration number, and we have that:
If the attraction is ∞, meaning that the cycle is "super-attracting", meaning again that one of the points of the cycle is a critical point, we must replace α by
where "w"' is "w" iterated "r" times and the formula for φ("z") by:
And now the real iteration number is given by:
For the colouring we must have a cyclic scale of colours (constructed mathematically, for instance) and containing "H" colours numbered from 0 to "H"−1 ("H" = 500, for instance). We multiply the real number formula_28 by a fixed real number determining the density of the colours in the picture, and take the integral part of this number modulo "H".
The definition of the potential function and our way of colouring presuppose that the cycle is attracting, that is, not neutral. If the cycle is neutral, we cannot colour the Fatou domain in a natural way. As the terminus of the iteration is a revolving movement, we can, for instance, colour by the minimum distance from the cycle left fixed by the iteration.
Field lines.
If we colour the Fatou domain according to the iteration number (and "not" the real iteration number), the bands of iteration show the course of the equipotential lines. If the iteration is towards ∞ (as is the case with the outer Fatou domain for the usual iteration formula_43), we can easily show the course of the field lines, namely by altering the colour according as the last point in the sequence of iteration is above or below the "x"-axis (first picture), but in this case (more precisely: when the Fatou domain is super-attracting) we cannot draw the field lines coherently - at least not by the method we describe here. In this case a field line is also called an external ray.
Let "z" be a point in the attracting Fatou domain. If we iterate "z" a large number of times, the terminus of the sequence of iteration is a finite cycle "C", and the Fatou domain is (by definition) the set of points whose sequence of iteration converges towards "C". The field lines issue from the points of "C" and from the (infinite number of) points that iterate "into" a point of "C". And they end on the Julia set in points that are non-chaotic (that is, generating a finite cycle). Let "r" be the order of the cycle "C" (its number of points) and let "z*" be a point in "C". We have formula_44 (the r-fold composition), and we define the complex number α by
If the points of "C" are formula_46, α is the product of the "r" numbers formula_47. The real number 1/|α| is the "attraction" of the cycle, and our assumption that the cycle is neither neutral nor super-attracting, means that 1 < 1/|α| < ∞. The point "z*" is a fixed point for formula_48, and near this point the map formula_48 has (in connection with field lines) character of a rotation with the argument β of α (that is, formula_50).
In order to colour the Fatou domain, we have chosen a small number ε and set the sequences of iteration formula_51 to stop when formula_35, and we colour the point "z" according to the number "k" (or the real iteration number, if we prefer a smooth colouring). If we choose a direction from "z*" given by an angle θ, the field line issuing from "z*" in this direction consists of the points "z" such that the argument ψ of the number formula_53 satisfies the condition that
For if we pass an iteration band in the direction of the field lines (and away from the cycle), the iteration number "k" is increased by 1 and the number ψ is increased by β, therefore the number formula_55 is constant along the field line.
A colouring of the field lines of the Fatou domain means that we colour the spaces between pairs of field lines: we choose a number of regularly situated directions issuing from "z*", and in each of these directions we choose two directions around this direction. As it can happen that the two field lines of a pair do not end in the same point of the Julia set, our coloured field lines can ramify (endlessly) in their way towards the Julia set. We can colour on the basis of the distance to the centre line of the field line, and we can mix this colouring with the usual colouring. Such pictures can be very decorative (second picture).
A coloured field line (the domain between two field lines) is divided up by the iteration bands, and such a part can be put into a one-to-one correspondence with the unit square: the one coordinate is (calculated from) the distance from one of the bounding field lines, the other is (calculated from) the distance from the inner of the bounding iteration bands (this number is the non-integral part of the real iteration number). Therefore we can put pictures into the field lines (third picture).
Plotting the Julia set.
Methods : 
Using backwards (inverse) iteration (IIM).
As mentioned above, the Julia set can be found as the set of limit points of the set of pre-images of (essentially) any given point. So we can try to plot the Julia set of a given function as follows. Start with any point "z" we know to be in the Julia set, such as a repelling periodic point, and compute all pre-images of "z" under some high iterate formula_56 of "f".
Unfortunately, as the number of iterated pre-images grows exponentially, this is not feasible computationally. However, we can adjust this method, in a similar way as the "random game" method for iterated function systems. That is, in each step, we choose at random one of the inverse images of "f".
For example, for the quadratic polynomial "fc", the backwards iteration is described by
At each step, one of the two square roots is selected at random.
Note that certain parts of the Julia set are quite difficult to access with the reverse Julia algorithm. For this reason, one must modify IIM/J ( it is called MIIM/J) or use other methods to produce better images.
Using DEM/J.
As a Julia set is infinitely thin we cannot draw it effectively by backwards iteration from the pixels. It will appear fragmented because of the impracticality of examining infinitely many startpoints. Since the iteration count changes vigorously near the Julia set, a partial solution is to imply the outline of the set from the nearest color contours, but the set will tend to look muddy.
A better way to draw the Julia set in black and white is to estimate the distance of pixels (DEM) from the set and to color every pixel whose center is close to the set. The formula for the distance estimation is derived from the formula for the potential function φ("z"). When the equipotential lines for φ("z") lie close, the number formula_58 is large, and conversely, therefore the equipotential lines for the function formula_59 should lie approximately regularly. It has been proven that the value found by this formula (up to a constant factor) converges towards the true distance for z converging towards the Julia set.
We assume that "f"("z") is rational, that is, formula_1 where "p"("z") and "q"("z") are complex polynomials of degrees "m" and "n", respectively, and we have to find the derivative of the above expressions for φ("z"). And as it is only formula_21 that varies, we must calculate the derivative formula_62 of formula_21 with respect to "z". But as formula_64 (the "k"-fold composition), formula_62 is the product of the numbers formula_66, and this sequence can be calculated recursively by formula_67, starting with formula_68 ("before" the calculation of the next iteration formula_69).
For iteration towards ∞ (more precisely when "m" ≥ "n" + 2, so that ∞ is a super-attracting fixed point), we have
("d" = "m" − "n") and consequently:
For iteration towards a finite attracting cycle (that is not super-attracting) containing the point "z*" and having order "r", we have
and consequently:
For a super-attracting cycle, the formula is:
We calculate this number when the iteration stops. Note that the distance estimation is independent of the attraction of the cycle. This means that it has meaning for transcendental functions of "degree infinity" (e.g. sin("z") and tan("z")).
Besides drawing of the boundary, the distance function can be introduced as a 3rd dimension to create a solid fractal landscape.

</doc>
<doc id="56435" url="https://en.wikipedia.org/wiki?curid=56435" title="Obesity">
Obesity

Obesity is a medical condition in which excess body fat has accumulated to the extent that it may have a negative effect on health. People are generally considered obese when their body mass index (BMI), a measurement obtained by dividing a person's weight by the square of the person's height, is over , with the range defined as overweight. Some East Asian countries use lower values. Obesity increases the likelihood of various diseases, particularly heart disease, type 2 diabetes, obstructive sleep apnea, certain types of cancer, and osteoarthritis.
Obesity is most commonly caused by a combination of excessive food intake, lack of physical activity, and genetic susceptibility. A few cases are caused primarily by genes, endocrine disorders, medications, or mental illness. Evidence to support the view that obese people eat little yet gain weight due to a slow metabolism is not generally supported. On average, obese people have a greater energy expenditure than their thin counterparts due to the energy required to maintain an increased body mass.
Obesity is mostly preventable through a combination of social changes and personal choices. Changes to diet and exercising are the main treatments. Diet quality can be improved by reducing the consumption of energy-dense foods, such as those high in fat and sugars, and by increasing the intake of dietary fiber. Medications may be taken, along with a suitable diet, to reduce appetite or decrease fat absorption. If diet, exercise, and medication are not effective, a gastric balloon or surgery may be performed to reduce stomach volume or bowel length, leading to feeling full earlier or a reduced ability to absorb nutrients from food.
Obesity is a leading preventable cause of death worldwide, with increasing rates in adults and children. In 2014, 600 million adults (13%) and 42 million children under the age of five were obese. Obesity is more common in women than men. Authorities view it as one of the most serious public health problems of the 21st century. Obesity is stigmatized in much of the modern world (particularly in the Western world), though it was seen as a symbol of wealth and fertility at other times in history and still is in some parts of the world. In 2013, the American Medical Association classified obesity as a disease.
Classification.
Obesity is a medical condition in which excess body fat has accumulated to the extent that it may have an adverse effect on health. It is defined by body mass index (BMI) and further evaluated in terms of fat distribution via the waist–hip ratio and total cardiovascular risk factors. BMI is closely related to both percentage body fat and total body fat.
In children, a healthy weight varies with age and sex. Obesity in children and adolescents is defined not as an absolute number but in relation to a historical normal group, such that obesity is a BMI greater than the 95th percentile. The reference data on which these percentiles were based date from 1963 to 1994, and thus have not been affected by the recent increases in weight.
BMI is defined as the subject's weight divided by the square of their height and is calculated as follows.
BMI is usually expressed in kilograms per square metre, resulting when weight is measured in kilograms and height in metres. To convert from pounds per square inch multiply by .
The most commonly used definitions, established by the World Health Organization (WHO) in 1997 and published in 2000, provide the values listed in the table.
Some modifications to the WHO definitions have been made by particular bodies. The surgical literature breaks down "class III" obesity into further categories whose exact values are still disputed.
As Asian populations develop negative health consequences at a lower BMI than Caucasians, some nations have redefined obesity; the Japanese have defined obesity as any BMI greater than 25 kg/m2 while China uses a BMI of greater than 28 kg/m2.
Effects on health.
Excessive body weight is associated with various diseases, particularly cardiovascular diseases, diabetes mellitus type 2, obstructive sleep apnea, certain types of cancer, osteoarthritis and asthma. As a result, obesity has been found to reduce life expectancy.
Mortality.
Obesity is one of the leading preventable causes of death worldwide. Some large-scale American and European studies have found that mortality risk is lowest at a BMI of 20–25 kg/m2 in non-smokers and at 24–27 kg/m2 in current smokers, with risk increasing along with changes in either direction. In contrast, a 2013 systematic review and meta-analysis found that grade 1 obesity (BMI 30-35) was not associated with higher mortality than normal weight, and that overweight (BMI 25-30) was associated with "significantly lower" mortality than was normal weight (BMI 18.5-25). Other evidence suggests that the association of BMI and waist circumference with mortality is U- or J-shaped, while the association between waist-to-hip ratio and waist-to-height ratio with mortality is more positive. In Asians risk begins to increase between 22–25 kg/m2. A BMI above 32 kg/m2 has been associated with a doubled mortality rate among women over a 16-year period. In the United States obesity is estimated to cause 111,909 to 365,000 deaths per year, while 1 million (7.7%) of deaths in Europe are attributed to excess weight. On average, obesity reduces life expectancy by six to seven years, a BMI of 30–35 kg/m2 reduces life expectancy by two to four years, while severe obesity (BMI > 40 kg/m2) reduces life expectancy by ten years.
Morbidity.
Obesity increases the risk of many physical and mental conditions. These comorbidities are most commonly shown in metabolic syndrome, a combination of medical disorders which includes: diabetes mellitus type 2, high blood pressure, high blood cholesterol, and high triglyceride levels.
Complications are either directly caused by obesity or indirectly related through mechanisms sharing a common cause such as a poor diet or a sedentary lifestyle. The strength of the link between obesity and specific conditions varies. One of the strongest is the link with type 2 diabetes. Excess body fat underlies 64% of cases of diabetes in men and 77% of cases in women.
Health consequences fall into two broad categories: those attributable to the effects of increased fat mass (such as osteoarthritis, obstructive sleep apnea, social stigmatization) and those due to the increased number of fat cells (diabetes, cancer, cardiovascular disease, non-alcoholic fatty liver disease). Increases in body fat alter the body's response to insulin, potentially leading to insulin resistance. Increased fat also creates a proinflammatory state, and a prothrombotic state.
Survival paradox.
Although the negative health consequences of obesity in the general population are well supported by the available evidence, health outcomes in certain subgroups seem to be improved at an increased BMI, a phenomenon known as the obesity survival paradox. The paradox was first described in 1999 in overweight and obese people undergoing hemodialysis, and has subsequently been found in those with heart failure and peripheral artery disease (PAD).
In people with heart failure, those with a BMI between 30.0 and 34.9 had lower mortality than those with a normal weight. This has been attributed to the fact that people often lose weight as they become progressively more ill. Similar findings have been made in other types of heart disease. People with class I obesity and heart disease do not have greater rates of further heart problems than people of normal weight who also have heart disease. In people with greater degrees of obesity, however, the risk of further cardiovascular events is increased. Even after cardiac bypass surgery, no increase in mortality is seen in the overweight and obese. One study found that the improved survival could be explained by the more aggressive treatment obese people receive after a cardiac event. Another found that if one takes into account chronic obstructive pulmonary disease (COPD) in those with PAD, the benefit of obesity no longer exists.
Causes.
At an individual level, a combination of excessive food energy intake and a lack of physical activity is thought to explain most cases of obesity. A limited number of cases are due primarily to genetics, medical reasons, or psychiatric illness. In contrast, increasing rates of obesity at a societal level are felt to be due to an easily accessible and palatable diet, increased reliance on cars, and mechanized manufacturing.
A 2006 review identified ten other possible contributors to the recent increase of obesity: (1) insufficient sleep, (2) endocrine disruptors (environmental pollutants that interfere with lipid metabolism), (3) decreased variability in ambient temperature, (4) decreased rates of smoking, because smoking suppresses appetite, (5) increased use of medications that can cause weight gain (e.g., atypical antipsychotics), (6) proportional increases in ethnic and age groups that tend to be heavier, (7) pregnancy at a later age (which may cause susceptibility to obesity in children), (8) epigenetic risk factors passed on generationally, (9) natural selection for higher BMI, and (10) assortative mating leading to increased concentration of obesity risk factors (this would increase the number of obese people by increasing population variance in weight). While there is substantial evidence supporting the influence of these mechanisms on the increased prevalence of obesity, the evidence is still inconclusive, and the authors state that these are probably less influential than the ones discussed in the previous paragraph.
Diet.
1961
2001–03
Map of dietary energy availability per person per day in 1961 (left) and 2001–2003 (right) Calories per person per day (kilojoules per person per day)
Dietary energy supply per capita varies markedly between different regions and countries. It has also changed significantly over time. From the early 1970s to the late 1990s the average food energy available per person per day (the amount of food bought) increased in all parts of the world except Eastern Europe. The United States had the highest availability with per person in 1996. This increased further in 2003 to . During the late 1990s Europeans had per person, in the developing areas of Asia there were per person, and in sub-Saharan Africa people had per person. Total food energy consumption has been found to be related to obesity.
The widespread availability of nutritional guidelines has done little to address the problems of overeating and poor dietary choice. From 1971 to 2000, obesity rates in the United States increased from 14.5% to 30.9%. During the same period, an increase occurred in the average amount of food energy consumed. For women, the average increase was per day ( in 1971 and in 2004), while for men the average increase was per day ( in 1971 and in 2004). Most of this extra food energy came from an increase in carbohydrate consumption rather than fat consumption. The primary sources of these extra carbohydrates are sweetened beverages, which now account for almost 25 percent of daily food energy in young adults in America, and potato chips. Consumption of sweetened drinks such as soft drinks, fruit drinks, iced tea, and energy and vitamin water drinks is believed to be contributing to the rising rates of obesity and to an increased risk of metabolic syndrome and type 2 diabetes.
As societies become increasingly reliant on energy-dense, big-portions, and fast-food meals, the association between fast-food consumption and obesity becomes more concerning. In the United States consumption of fast-food meals tripled and food energy intake from these meals quadrupled between 1977 and 1995.
Agricultural policy and techniques in the United States and Europe have led to lower food prices. In the United States, subsidization of corn, soy, wheat, and rice through the U.S. farm bill has made the main sources of processed food cheap compared to fruits and vegetables. Calorie count laws and nutrition facts labels attempt to steer people toward making healthier food choices, including awareness of how much food energy is being consumed.
Obese people consistently under-report their food consumption as compared to people of normal weight. This is supported both by tests of people carried out in a calorimeter room and by direct observation.
Sedentary lifestyle.
A sedentary lifestyle plays a significant role in obesity. Worldwide there has been a large shift towards less physically demanding work, and currently at least 30% of the world's population gets insufficient exercise. This is primarily due to increasing use of mechanized transportation and a greater prevalence of labor-saving technology in the home. In children, there appear to be declines in levels of physical activity due to less walking and physical education. World trends in active leisure time physical activity are less clear. The World Health Organization indicates people worldwide are taking up less active recreational pursuits, while a study from Finland found an increase and a study from the United States found leisure-time physical activity has not changed significantly.
In both children and adults, there is an association between television viewing time and the risk of obesity. A review found 63 of 73 studies (86%) showed an increased rate of childhood obesity with increased media exposure, with rates increasing proportionally to time spent watching television.
Genetics.
Like many other medical conditions, obesity is the result of an interplay between genetic and environmental factors. Polymorphisms in various genes controlling appetite and metabolism predispose to obesity when sufficient food energy is present. As of 2006, more than 41 of these sites on the human genome have been linked to the development of obesity when a favorable environment is present. People with two copies of the FTO gene (fat mass and obesity associated gene) have been found on average to weigh 3–4 kg more and have a 1.67-fold greater risk of obesity compared with those without the risk allele. The differences in BMI between people that are due to genetics varies depending on the population examined from 6% to 85%.
Obesity is a major feature in several syndromes, such as Prader–Willi syndrome, Bardet–Biedl syndrome, Cohen syndrome, and MOMO syndrome. (The term "non-syndromic obesity" is sometimes used to exclude these conditions.) In people with early-onset severe obesity (defined by an onset before 10 years of age and body mass index over three standard deviations above normal), 7% harbor a single point DNA mutation.
Studies that have focused on inheritance patterns rather than on specific genes have found that 80% of the offspring of two obese parents were also obese, in contrast to less than 10% of the offspring of two parents who were of normal weight. Different people exposed to the same environment have different risks of obesity due to their underlying genetics.
The thrifty gene hypothesis postulates that, due to dietary scarcity during human evolution, people are prone to obesity. Their ability to take advantage of rare periods of abundance by storing energy as fat would be advantageous during times of varying food availability, and individuals with greater adipose reserves would be more likely to survive famine. This tendency to store fat, however, would be maladaptive in societies with stable food supplies. This theory has received various criticisms, and other evolutionarily-based theories such as the drifty gene hypothesis and the thrifty phenotype hypothesis have also been proposed.
Other illnesses.
Certain physical and mental illnesses and the pharmaceutical substances used to treat them can increase risk of obesity. Medical illnesses that increase obesity risk include several rare genetic syndromes (listed above) as well as some congenital or acquired conditions: hypothyroidism, Cushing's syndrome, growth hormone deficiency, and the eating disorders: binge eating disorder and night eating syndrome. However, obesity is not regarded as a psychiatric disorder, and therefore is not listed in the DSM-IVR as a psychiatric illness. The risk of overweight and obesity is higher in patients with psychiatric disorders than in persons without psychiatric disorders.
Certain medications may cause weight gain or changes in body composition; these include insulin, sulfonylureas, thiazolidinediones, atypical antipsychotics, antidepressants, steroids, certain anticonvulsants (phenytoin and valproate), pizotifen, and some forms of hormonal contraception.
Social determinants.
While genetic influences are important to understanding obesity, they cannot explain the current dramatic increase seen within specific countries or globally. Though it is accepted that energy consumption in excess of energy expenditure leads to obesity on an individual basis, the cause of the shifts in these two factors on the societal scale is much debated. There are a number of theories as to the cause but most believe it is a combination of various factors.
The correlation between social class and BMI varies globally. A review in 1989 found that in developed countries women of a high social class were less likely to be obese. No significant differences were seen among men of different social classes. In the developing world, women, men, and children from high social classes had greater rates of obesity. An update of this review carried out in 2007 found the same relationships, but they were weaker. The decrease in strength of correlation was felt to be due to the effects of globalization. Among developed countries, levels of adult obesity, and percentage of teenage children who are overweight, are correlated with income inequality. A similar relationship is seen among US states: more adults, even in higher social classes, are obese in more unequal states.
Many explanations have been put forth for associations between BMI and social class. It is thought that in developed countries, the wealthy are able to afford more nutritious food, they are under greater social pressure to remain slim, and have more opportunities along with greater expectations for physical fitness. In undeveloped countries the ability to afford food, high energy expenditure with physical labor, and cultural values favoring a larger body size are believed to contribute to the observed patterns. Attitudes toward body weight held by people in one's life may also play a role in obesity. A correlation in BMI changes over time has been found among friends, siblings, and spouses. Stress and perceived low social status appear to increase risk of obesity.
Smoking has a significant effect on an individual's weight. Those who quit smoking gain an average of 4.4 kilograms (9.7 lb) for men and 5.0 kilograms (11.0 lb) for women over ten years. However, changing rates of smoking have had little effect on the overall rates of obesity.
In the United States the number of children a person has is related to their risk of obesity. A woman's risk increases by 7% per child, while a man's risk increases by 4% per child. This could be partly explained by the fact that having dependent children decreases physical activity in Western parents.
In the developing world urbanization is playing a role in increasing rate of obesity. In China overall rates of obesity are below 5%; however, in some cities rates of obesity are greater than 20%.
Malnutrition in early life is believed to play a role in the rising rates of obesity in the developing world. Endocrine changes that occur during periods of malnutrition may promote the storage of fat once more food energy becomes available.
Consistent with cognitive epidemiological data, numerous studies confirm that obesity is associated with cognitive deficits. Whether obesity causes cognitive deficits, or vice versa is unclear at present.
Infectious agents.
The study of the effect of infectious agents on metabolism is still in its early stages. Gut flora has been shown to differ between lean and obese humans. There is an indication that gut flora in obese and lean individuals can affect the metabolic potential. This apparent alteration of the metabolic potential is believed to confer a greater capacity to harvest energy contributing to obesity. Whether these differences are the direct cause or the result of obesity has yet to be determined unequivocally.
An association between viruses and obesity has been found in humans and several different animal species. The amount that these associations may have contributed to the rising rate of obesity is yet to be determined.
Pathophysiology.
There are many possible pathophysiological mechanisms involved in the development and maintenance of obesity. This field of research had been almost unapproached until the leptin gene was discovered in 1994 by J. M. Friedman's laboratory. These investigators postulated that leptin was a satiety factor. In the ob/ob mouse, mutations in the leptin gene resulted in the obese phenotype opening the possibility of leptin therapy for human obesity. However, soon thereafter J. F. Caro's laboratory could not detect any mutations in the leptin gene in humans with obesity. On the contrary Leptin expression was increased proposing the possibility of Leptin-resistance in human obesity. Since this discovery, many other hormonal mechanisms have been elucidated that participate in the regulation of appetite and food intake, storage patterns of adipose tissue, and development of insulin resistance. Since leptin's discovery, ghrelin, insulin, orexin, PYY 3-36, cholecystokinin, adiponectin, as well as many other mediators have been studied. The adipokines are mediators produced by adipose tissue; their action is thought to modify many obesity-related diseases.
Leptin and ghrelin are considered to be complementary in their influence on appetite, with ghrelin produced by the stomach modulating short-term appetitive control (i.e. to eat when the stomach is empty and to stop when the stomach is stretched). Leptin is produced by adipose tissue to signal fat storage reserves in the body, and mediates long-term appetitive controls (i.e. to eat more when fat storages are low and less when fat storages are high). Although administration of leptin may be effective in a small subset of obese individuals who are leptin deficient, most obese individuals are thought to be leptin resistant and have been found to have high levels of leptin. This resistance is thought to explain in part why administration of leptin has not been shown to be effective in suppressing appetite in most obese people.
While leptin and ghrelin are produced peripherally, they control appetite through their actions on the central nervous system. In particular, they and other appetite-related hormones act on the hypothalamus, a region of the brain central to the regulation of food intake and energy expenditure. There are several circuits within the hypothalamus that contribute to its role in integrating appetite, the melanocortin pathway being the most well understood. The circuit begins with an area of the hypothalamus, the arcuate nucleus, that has outputs to the lateral hypothalamus (LH) and ventromedial hypothalamus (VMH), the brain's feeding and satiety centers, respectively.
The arcuate nucleus contains two distinct groups of neurons. The first group coexpresses neuropeptide Y (NPY) and agouti-related peptide (AgRP) and has stimulatory inputs to the LH and inhibitory inputs to the VMH. The second group coexpresses pro-opiomelanocortin (POMC) and cocaine- and amphetamine-regulated transcript (CART) and has stimulatory inputs to the VMH and inhibitory inputs to the LH. Consequently, NPY/AgRP neurons stimulate feeding and inhibit satiety, while POMC/CART neurons stimulate satiety and inhibit feeding. Both groups of arcuate nucleus neurons are regulated in part by leptin. Leptin inhibits the NPY/AgRP group while stimulating the POMC/CART group. Thus a deficiency in leptin signaling, either via leptin deficiency or leptin resistance, leads to overfeeding and may account for some genetic and acquired forms of obesity.
Public health.
The World Health Organization (WHO) predicts that overweight and obesity may soon replace more traditional public health concerns such as undernutrition and infectious diseases as the most significant cause of poor health. Obesity is a public health and policy problem because of its prevalence, costs, and health effects. The United States Preventive Services Task Force recommends screening for all adults followed by behavioral interventions in those who are obese. Public health efforts seek to understand and correct the environmental factors responsible for the increasing prevalence of obesity in the population. Solutions look at changing the factors that cause excess food energy consumption and inhibit physical activity. Efforts include federally reimbursed meal programs in schools, limiting direct junk food marketing to children, and decreasing access to sugar-sweetened beverages in schools. When constructing urban environments, efforts have been made to increase access to parks and to develop pedestrian routes.
Many countries and groups have published reports pertaining to obesity. In 1998, the first US Federal guidelines were published, titled "Clinical Guidelines on the Identification, Evaluation, and Treatment of Overweight and Obesity in Adults: The Evidence Report". In 2006 the Canadian Obesity Network published the "Canadian Clinical Practice Guidelines (CPG) on the Management and Prevention of Obesity in Adults and Children". This is a comprehensive evidence-based guideline to address the management and prevention of overweight and obesity in adults and children.
In 2004, the United Kingdom Royal College of Physicians, the Faculty of Public Health and the Royal College of Paediatrics and Child Health released the report "Storing up Problems", which highlighted the growing problem of obesity in the UK. The same year, the House of Commons Health Select Committee published its "most comprehensive inquiry [...] ever undertaken" into the impact of obesity on health and society in the UK and possible approaches to the problem. In 2006, the National Institute for Health and Clinical Excellence (NICE) issued a guideline on the diagnosis and management of obesity, as well as policy implications for non-healthcare organizations such as local councils. A 2007 report produced by Sir Derek Wanless for the King's Fund warned that unless further action was taken, obesity had the capacity to cripple the National Health Service financially.
Comprehensive approaches are being looked at to address the rising rates of obesity. The Obesity Policy Action (OPA) framework divides measure into 'upstream' policies, 'midstream' policies, 'downstream' policies. 'Upstream' policies look at changing society, 'midstream' policies try to alter individuals' behavior to prevent obesity, and 'downstream' policies try to treat currently afflicted people.
Management.
The main treatment for obesity consists of dieting and physical exercise. Diet programs may produce weight loss over the short term, but maintaining this weight loss is frequently difficult and often requires making exercise and a lower food energy diet a permanent part of a person's lifestyle. All types of low-carbohydrate and low-fat diets appear equally beneficial. The heart disease and diabetes risks associated with different diets also appear to be similar. Success rates of long-term weight loss maintenance with lifestyle changes are low, ranging from 2–20%. Dietary and lifestyle changes are effective in limiting excessive weight gain in pregnancy and improve outcomes for both the mother and the child. Intensive behavioral counseling is recommended in those who are both obese and have other risk factors for heart disease.
Three medications, orlistat (Xenical), lorcaserin (Belviq) and a combination of phentermine and topiramate (Qsymia) are currently available and have evidence for long term use. Weight loss with orlistat is modest, an average of 2.9 kg (6.4 lb) at 1 to 4 years. Its use is associated with high rates of gastrointestinal side effects and concerns have been raised about negative effects on the kidneys. The other two medications are available in the United States but not Europe. Lorcaserin results in an average 3.1 kg weight loss (3% of body weight) greater than placebo over a year; however, it may increase heart valve problems. A combination of phentermine and topiramate is also somewhat effective; however, it may be associated with heart problems. There is no information on how these drugs affect longer-term complications of obesity such as cardiovascular disease or death.
The most effective treatment for obesity is bariatric surgery. Surgery for severe obesity is associated with long-term weight loss, improvement in obesity related conditions, and decreased overall mortality. One study found a weight loss of between 14% and 25% (depending on the type of procedure performed) at 10 years, and a 29% reduction in all cause mortality when compared to standard weight loss measures. Complications occur in about 17% of cases and reoperation is needed in 7% of cases. Due to its cost and risks, researchers are searching for other effective yet less invasive treatments including devices that occupy space in the stomach.
Epidemiology.
In earlier historical periods obesity was rare, and achievable only by a small elite, although already recognised as a problem for health. But as prosperity increased in the Early Modern period, it affected increasingly larger groups of the population. In 1997 the WHO formally recognized obesity as a global epidemic. As of 2008 the WHO estimates that at least 500 million adults (greater than 10%) are obese, with higher rates among women than men. The rate of obesity also increases with age at least up to 50 or 60 years old and severe obesity in the United States, Australia, and Canada is increasing faster than the overall rate of obesity.
Once considered a problem only of high-income countries, obesity rates are rising worldwide and affecting both the developed and developing world. These increases have been felt most dramatically in urban settings. The only remaining region of the world where obesity is not common is sub-Saharan Africa.
History.
Etymology.
"Obesity" is from the Latin "obesitas", which means "stout, fat, or plump". "Ēsus" is the past participle of "edere" (to eat), with "ob" (over) added to it. "The Oxford English Dictionary" documents its first usage in 1611 by Randle Cotgrave.
Historical attitudes.
Ancient Greek medicine recognizes obesity as a medical disorder, and records that the Ancient Egyptians saw it in the same way. Hippocrates wrote that "Corpulence is not only a disease itself, but the harbinger of others". The Indian surgeon Sushruta (6th century BCE) related obesity to diabetes and heart disorders. He recommended physical work to help cure it and its side effects. For most of human history mankind struggled with food scarcity. Obesity has thus historically been viewed as a sign of wealth and prosperity. It was common among high officials in Europe in the Middle Ages and the Renaissance as well as in Ancient East Asian civilizations. In the 17th century, English medical author Tobias Venner is credited with being one of the first to refer to the term as a societal disease in a published English language book.
With the onset of the industrial revolution it was realized that the military and economic might of nations were dependent on both the body size and strength of their soldiers and workers. Increasing the average body mass index from what is now considered underweight to what is now the normal range played a significant role in the development of industrialized societies. Height and weight thus both increased through the 19th century in the developed world. During the 20th century, as populations reached their genetic potential for height, weight began increasing much more than height, resulting in obesity. In the 1950s increasing wealth in the developed world decreased child mortality, but as body weight increased heart and kidney disease became more common.
During this time period insurance companies realized the connection between weight and life expectancy and increased premiums for the obese.
Many cultures throughout history have viewed obesity as the result of a character flaw. The "obesus" or fat character in Greek comedy was a glutton and figure of mockery. During Christian times food was viewed as a gateway to the sins of sloth and lust. In modern Western culture, excess weight is often regarded as unattractive, and obesity is commonly associated with various negative stereotypes. People of all ages can face social stigmatization, and may be targeted by bullies or shunned by their peers.
Public perceptions in Western society regarding healthy body weight differ from those regarding the weight that is considered ideal  – and both have changed since the beginning of the 20th century. The weight that is viewed as an ideal has become lower since the 1920s. This is illustrated by the fact that the average height of Miss America pageant winners increased by 2% from 1922 to 1999, while their average weight decreased by 12%. On the other hand, people's views concerning healthy weight have changed in the opposite direction. In Britain the weight at which people considered themselves to be overweight was significantly higher in 2007 than in 1999. These changes are believed to be due to increasing rates of adiposity leading to increased acceptance of extra body fat as being normal.
Obesity is still seen as a sign of wealth and well-being in many parts of Africa. This has become particularly common since the HIV epidemic began.
The arts.
The first sculptural representations of the human body 20,000–35,000 years ago depict obese females. Some attribute the Venus figurines to the tendency to emphasize fertility while others feel they represent "fatness" in the people of the time. Corpulence is, however, absent in both Greek and Roman art, probably in keeping with their ideals regarding moderation. This continued through much of Christian European history, with only those of low socioeconomic status being depicted as obese.
During the Renaissance some of the upper class began flaunting their large size, as can be seen in portraits of Henry VIII of England and Alessandro del Borro. Rubens (1577–1640) regularly depicted full-bodied women in his pictures, from which derives the term Rubenesque. These women, however, still maintained the "hourglass" shape with its relationship to fertility. During the 19th century, views on obesity changed in the Western world. After centuries of obesity being synonymous with wealth and social status, slimness began to be seen as the desirable standard.
Society and culture.
Economic impact.
In addition to its health impacts, obesity leads to many problems including disadvantages in employment and increased business costs. These effects are felt by all levels of society from individuals, to corporations, to governments.
In 2005, the medical costs attributable to obesity in the US were an estimated $190.2 billion or 20.6% of all medical expenditures, while the cost of obesity in Canada was estimated at CA$2 billion in 1997 (2.4% of total health costs). The total annual direct cost of overweight and obesity in Australia in 2005 was A$21 billion. Overweight and obese Australians also received A$35.6 billion in government subsidies. The estimate range for annual expenditures on diet products is $40 billion to $100 billion in the US alone.
Obesity prevention programs have been found to reduce the cost of treating obesity-related disease. However, the longer people live, the more medical costs they incur. Researchers therefore conclude that reducing obesity may improve the public's health, but it is unlikely to reduce overall health spending.
Obesity can lead to social stigmatization and disadvantages in employment. When compared to their normal weight counterparts, obese workers on average have higher rates of absenteeism from work and take more disability leave, thus increasing costs for employers and decreasing productivity. A study examining Duke University employees found that people with a BMI over 40 kg/m2 filed twice as many workers' compensation claims as those whose BMI was 18.5–24.9 kg/m2. They also had more than 12 times as many lost work days. The most common injuries in this group were due to falls and lifting, thus affecting the lower extremities, wrists or hands, and backs. The Alabama State Employees' Insurance Board approved a controversial plan to charge obese workers $25 a month for health insurance that would otherwise be free unless they take steps to lose weight and improve their health. These measures started in January 2010 and apply to those state workers whose BMI exceeds 35 kg/m2 and who fail to make improvements in their health after one year.
Some research shows that obese people are less likely to be hired for a job and are less likely to be promoted. Obese people are also paid less than their non-obese counterparts for an equivalent job; obese women on average make 6% less and obese men make 3% less.
Specific industries, such as the airline, healthcare and food industries, have special concerns. Due to rising rates of obesity, airlines face higher fuel costs and pressures to increase seating width. In 2000, the extra weight of obese passengers cost airlines US$275 million. The healthcare industry has had to invest in special facilities for handling severely obese patients, including special lifting equipment and bariatric ambulances. Costs for restaurants are increased by litigation accusing them of causing obesity. In 2005 the US Congress discussed legislation to prevent civil lawsuits against the food industry in relation to obesity; however, it did not become law.
With the American Medical Association's 2013 classification of obesity as a chronic disease, it is thought that health insurance companies will more likely pay for obesity treatment, counseling and surgery, and the cost of research and development of fat treatment pills or gene therapy treatments should be more affordable if insurers help to subsidize their cost. The AMA classification is not legally binding, however, so health insurers still have the right to reject coverage for a treatment or procedure.
In 2014, The European Court of Justice ruled that morbid obesity is a disability. The Court argued that if an employee's obesity prevents him from "full and effective participation of that person in professional life on an equal basis with other workers", then it shall be considered a disability and that firing someone on such grounds is discriminatory.
Size acceptance.
The principal goal of the fat acceptance movement is to decrease discrimination against people who are overweight and obese. However, some in the movement are also attempting to challenge the established relationship between obesity and negative health outcomes.
A number of organizations exist that promote the acceptance of obesity. They have increased in prominence in the latter half of the 20th century. The US-based National Association to Advance Fat Acceptance (NAAFA) was formed in 1969 and describes itself as a civil rights organization dedicated to ending size discrimination.
The International Size Acceptance Association (ISAA) is a non-governmental organization (NGO) which was founded in 1997. It has more of a global orientation and describes its mission as promoting size acceptance and helping to end weight-based discrimination. These groups often argue for the recognition of obesity as a disability under the US Americans With Disabilities Act (ADA). The American legal system, however, has decided that the potential public health costs exceed the benefits of extending this anti-discrimination law to cover obesity.
Childhood obesity.
The healthy BMI range varies with the age and sex of the child. Obesity in children and adolescents is defined as a BMI greater than the 95th percentile. The reference data that these percentiles are based on is from 1963 to 1994 and thus has not been affected by the recent increases in rates of obesity. Childhood obesity has reached epidemic proportions in the 21st century, with rising rates in both the developed and developing world. Rates of obesity in Canadian boys have increased from 11% in the 1980s to over 30% in the 1990s, while during this same time period rates increased from 4 to 14% in Brazilian children.
As with obesity in adults, many factors contribute to the rising rates of childhood obesity. Changing diet and decreasing physical activity are believed to be the two most important causes for the recent increase in the incidence of child obesity. Because childhood obesity often persists into adulthood and is associated with numerous chronic illnesses, children who are obese are often tested for hypertension, diabetes, hyperlipidemia, and fatty liver. Treatments used in children are primarily lifestyle interventions and behavioral techniques, although efforts to increase activity in children have had little success. In the United States, medications are not FDA approved for use in this age group.
Other animals.
Obesity in pets is common in many countries. In the United States, 23–41% of dogs are overweight, and about 5.1% are obese. The rate of obesity in cats was slightly higher at 6.4%. In Australia the rate of obesity among dogs in a veterinary setting has been found to be 7.6%. The risk of obesity in dogs is related to whether or not their owners are obese; however, there is no similar correlation between cats and their owners.

</doc>
<doc id="56437" url="https://en.wikipedia.org/wiki?curid=56437" title="Infrared astronomy">
Infrared astronomy

Infrared astronomy is the branch of astronomy and astrophysics that studies astronomical objects visible in infrared (IR) radiation. The wavelength of infrared light ranges from 0.75 to 300 micrometers. Infrared falls in between visible radiation, which ranges from 380 to 750 nanometers, and submillimeter waves.
Infrared astronomy began in the 1830s, a few decades after the discovery of infrared light by William Herschel in 1800. Early progress was limited, and it was not until the early 20th century that conclusive detections of astronomical objects other than the Sun and Moon were detected in infrared light. After a number of discoveries were made in the 1950s and 1960s in radio astronomy, astronomers realized the information available outside of the visible wavelength range, and modern infrared astronomy was established.
Infrared and optical astronomy are often practiced using the same telescopes, as the same mirrors or lenses are usually effective over a wavelength range that includes both visible and infrared light. Both fields also use solid state detectors, though the specific type of solid state detectors used are different. Infrared light is absorbed at many wavelengths by water vapor in the Earth's atmosphere, so most infrared telescopes are at high elevations in dry places, above as much of the atmosphere as possible. There are also infrared observatories in space, including the Spitzer Space Telescope and the Herschel Space Observatory.
History.
The discovery of infrared radiation is attributed to William Herschel, who performed an experiment where he placed a thermometer in sunlight of different colors after it passed through a prism. He noticed that the temperature increase induced by sunlight was highest "outside" the visible spectrum, just beyond the red color. That the temperature increase was highest at infrared wavelengths was due to the spectral index of the prism rather than properties of the Sun, but the fact that there was any temperature increase at all prompted Herschel to deduce that there was invisible radiation from the Sun. He dubbed this radiation "calorific rays", and went on to show that it could be reflected, transmitted, and absorbed just like visible light.
Efforts were made starting in the 1830s and continuing through the 19th century to detect infrared radiation from other astronomical sources. Radiation from the Moon was first detected in 1873 by William Parsons, 3rd Earl of Rosse. Ernest Fox Nichols used a modified Crookes radiometer in an attempt to detect infrared radiation from Arcturus and Vega, but Nichols deemed the results inconclusive. Even so, the ratio of flux he reported for the two stars is consistent with the modern value, so George Rieke gives Nichols credit for the first detection of a star other than our own in the infrared.
The field of infrared astronomy continued to develop slowly in the early 20th century, as Seth Barnes Nicholson and Edison Pettit developed thermopile detectors capable of accurate infrared photometry and sensitive to a few hundreds of stars. The field was mostly neglected by traditional astronomers though until the 1960s, with most scientists who practiced infrared astronomy having actually been trained physicists. The success of radio astronomy during the 1950s and 1960s, combined with the improvement of infrared detector technology, prompted more astronomers to take notice, and infrared astronomy became well established as a subfield of astronomy.
Modern infrared astronomy.
Infrared radiation with wavelengths just longer than visible light, known as near-infrared, behaves in a very similar way to visible light, and can be detected using similar solid state devices. For this reason, the near infrared region of the spectrum is commonly incorporated as part of the "optical" spectrum, along with the near ultraviolet. Many optical telescopes, such as those at Keck Observatory, operate effectively in the near infrared as well as at visible wavelengths. The far-infrared extends to submillimeter wavelengths, which are observed by telescopes such as the James Clerk Maxwell Telescope at Mauna Kea Observatory.
Like all other forms of electromagnetic radiation, infrared is utilized by astronomers to study the universe. Indeed, infrared measurements taken by the 2MASS and WISE astronomical surveys have been particularly effective at unveiling previously undiscovered star clusters. Examples of such embedded star clusters are FSR 1424, FSR 1432, Camargo 394, Camargo 399, Majaess 30, and Majaess 99. Infrared telescopes, which includes most major optical telescopes as well as a few dedicated infrared telescopes, need to be chilled with liquid nitrogen and shielded from warm objects. The reason for this is that objects with temperatures of a few hundred Kelvin emit most of their thermal energy at infrared wavelengths. If infrared detectors were not kept cooled, the radiation from the detector itself would contribute noise that would dwarf the radiation from any celestial source. This is particularly important in the mid-infrared and far-infrared regions of the spectrum.
To achieve higher angular resolution, some infrared telescopes are combined to form astronomical interferometers. The effective resolution of an interferometer is set by the distance between the telescopes, rather than the size of the individual telescopes. When used together with adaptive optics, infrared interferometers, such as two 10 meter telescopes at Keck Observatory or the four 8.2 meter telescopes that make up the Very Large Telescope Interferometer, can achieve high angular resolution.
The principal limitation on infrared sensitivity from ground-based telescopes is the Earth's atmosphere. Water vapor absorbs a significant amount of infrared radiation, and the atmosphere itself emits at infrared wavelengths. For this reason, most infrared telescopes are built in very dry places at high altitude, so that they are above most of the water vapor in the atmosphere. Suitable locations on Earth include Mauna Kea Observatory at 4205 meters above sea level, the Paranal Observatory at 2635 meters in Chile and regions of high altitude ice-desert such as Dome C in Antarctic. Even at high altitudes, the transparency of the Earth's atmosphere is limited except in infrared windows, or wavelengths where the Earth's atmosphere is transparent. The main infrared windows are listed below:
As is the case for visible light telescopes, space is the ideal place for infrared telescopes. In space, images from infrared telescopes can achieve higher resolution, as they do not suffer from blurring caused by the Earth's atmosphere, and are also free from absorption caused by the Earth's atmosphere. Current infrared telescopes in space include the Herschel Space Observatory, the Spitzer Space Telescope, and the Wide-field Infrared Survey Explorer. Since putting telescopes in orbit is expensive, there are also airborne observatories, such as the Stratospheric Observatory for Infrared Astronomy and the Kuiper Airborne Observatory. These observatories place telescopes above most, but not all, of the atmosphere, which means there is absorption of infrared light from space by water vapor in the atmosphere.
Infrared technology.
One of the most common infrared detector arrays used at research telescopes is HgCdTe arrays. These operate well between 0.6 and 5 micrometre wavelengths. For longer wavelength observations or higher sensitivity other detectors may be used, including other narrow gap semiconductor detectors, low temperature bolometer arrays or photon-counting Superconducting Tunnel Junction arrays.
Special requirements for infrared astronomy include: very low dark currents to allow long integration times, associated low noise readout circuits and sometimes very high pixel counts.
Low temperature is often achieved by a coolant, which can run out. Space missions have either ended or shifted to "warm" observations when the coolant supply used up. For example, WISE ran out of coolant in October 2010,about ten months after being launched. (See also NICMOS, Spitzer Space Telescope)

</doc>
<doc id="56438" url="https://en.wikipedia.org/wiki?curid=56438" title="Akhnaten (opera)">
Akhnaten (opera)

Akhnaten is an opera in three acts based on the life and religious convictions of the pharaoh Akhenaten (Amenhotep IV), written by the American minimalist composer Philip Glass in 1983. Akhnaten had its world premiere on March 24, 1984 at the Stuttgart State Opera, under the German title "Echnaton". Paul Esswood sang the title role, German director Achim Freyer staged the opera in an abstract style with highly ritualistic movements. The American premiere was held on October 12, 1984 at the Houston Grand Opera, where Glass's opera "The Making of the Representative for Planet 8" also premiered.
According to the composer, this work is the culmination of his two other biographical operas, "Einstein on the Beach" (about Albert Einstein) and "Satyagraha" (about Mohandas Gandhi). These three people — Akhenaten, Einstein and Gandhi — were all driven by an inner vision which altered the age in which they lived, in particular Akhenaten in religion, Einstein in science, and Gandhi in politics.
The text, taken from original sources, is sung in the original languages, linked together with the commentary of a narrator in a modern language, such as English or German. Egyptian texts of the period are taken from a poem of Akhenaten himself, from the "Egyptian Book of the Dead", and from extracts of decrees and letters from the Amarna period, the seventeen-year period of Akhenaten's rule. Other portions are in Akkadian and Biblical Hebrew. Akhnaten's "Hymn to the Sun" is sung in the language of the audience.
Roles.
Small male chorus (Priests), Large opera chorus (The people of Egypt)
Music.
The orchestra's size is about the size employed for early 19th-century opera: 2 flutes (one doubling piccolo), 2 oboes (both doubling oboe d'amore), 2 clarinets, bass clarinet, 2 bassoons, 2 french horns, 2 trumpets, 2 trombones, tuba, percussion (3 players), celesta (doubling synthesizer), 12 violas, 8 celli, 6 double basses.
Since the Stuttgart State Opera house was being restored in 1984 and the orchestra pit of the Stuttgart State theater, where the premiere was to take place, was considerably smaller, Glass chose to completely leave out the violins (about 20), giving the orchestra a darker, sombre character, which fits the subject. Apart from this, this was Glass's most "conventional" opera orchestra until then (compared to "Einstein on the Beach", written for the six-piece Philip Glass Ensemble, and "Satyagraha", scored for woodwinds and strings only).
Generally speaking, for the unprepared listener the music of this opera is more accessible than that of its predecessors, the "hardcore" minimalist "Einstein" and the oratorio-like "Satyagraha". The music follows and underlines the dramatic context outlined by the story, and the harmonic and melodic language is more varied and changes more often, giving the music a more theatrical and almost "romantic" quality.
Synopsis.
The opera is divided into three acts:
Act 1: Year 1 of Akhnaten's Reign in Thebes.
"Prelude, Verse 1, Verse 2, Verse 3"
Set in the key of A minor, the strings introduce a ground bass theme, with following variations. (A passacaglia). The scribe recites funeral texts from the pyramids. 'Open are the double doors of the horizon; unlocked are its bolts.' 
"Scene 1: Funeral of Akhnaten's father Amenhotep III"
Heralded by hammering drums, Aye and a small male chorus chant a funeral hymn in Egyptian, later joined by the full chorus. The music is basically a march, based on the chords of A major and F♯ minor (with added major sixth), and grows to ecstatic intensity towards the end.
"Scene 2: The Coronation of Akhnaten"
After a lengthy orchestral introduction, during which Akhnaten appears, heralded by a solo trumpet, the High Priest, Aye, and Horemhab sing a ritual text. After that, the Narrator recites a list of royal titles bestowed upon Akhnaten, while he is crowned. After the coronation, the chorus repeats the ritual text from the beginning of the scene. Again, the main key is A minor. 
"Scene 3: The Window of Appearances"
After an introduction in A minor, dominated by tubular bells, Akhnaten sings a praise to the Creator (in Egyptian) at the window of public appearances. This is the first time he actually sings, after he has already been on stage for 20 minutes (and 40 minutes into the opera) and the effect of his countertenor voice (which in 1983 was even more rare than nowadays) is startling. He is joined by Nefertiti, who actually sings lower notes than he, and later by Queen Tye, whose soprano soars high above the intertwining voices of the royal couple.
Act 2: Years 5 to 15 in Thebes and Akhetaten.
"Scene 1: The Temple"
The scene opens again in A minor, with the High Priest and a group of priests singing a hymn to Amun, principal god of the old order, in his temple. The music becomes increasingly dramatic, as Akhnaten, together with Queen Tye and his followers, attack the temple. This scene has only wordless singing. The harmonies grow very chromatic, finally reaching A flat major and E minor. The temple roof is removed and the sun god Aten's rays invade the temple, thus ending Amun's reign and laying the foundation for the worship of the only god Aten.
"Scene 2: Akhnaten and Nefertiti"
Two solo celli introduce a "love theme". Accompanied by a solo trombone while the harmony switches to H(sus), the Narrator recites a prayer-like poem to the sun god. The strings softly take over the music in E minor, and the same poem is recited again, this time actually as a love poem from Akhnaten to Nefertiti. Then Akhnaten and Nefertiti sing the same text to each other (in Egyptian), as an intimate love duet. After a while, the trumpet associated with Akhnaten joins them as the highest voice, turning the duet into a trio.
"Scene 3: The City - Dance"
The Narrator speaks a text taken from the boundary stones of the new capital of the empire, Akhet-Aten (The Horizon of Aten), describing the construction of the city, with large, light-filled spaces. After a brass fanfare, the completion of the city is celebrated in a light-hearted dance, contrasting with the stark, ritualistic music with which this act began. (In the Stuttgart premiere, the dance actually described the construction of the city)
"Scene 4: Hymn"
What now follows is a hymn to the only god Aten, a long aria (alternating between A minor and A major) by Akhnaten, and the central piece of the opera. It is outstanding as it is the only text sung in the language of the audience, praising the sun giving life to everything. After the aria, an off-stage chorus sings Psalm 104 in Hebrew, dating some 400 years later, which has strong resemblances to Akhnaten's Hymn, thus emphasizing Akhnaten as the first founder of a monotheistic religion.
Act 3: Year 17 and the Present.
"Scene 1: The Family"
Two Oboe d'amore play the "love theme" from Act II. Akhnaten, Nefertiti and their six daughters, sing wordlessly in contemplation, they are oblivious of what happens outside of the palace. As the music switches from E minor to F minor, the Narrator reads letters from Syrian vassals, asking for help against their enemies. Since the king does not send troops, his land is being seized and plundered by their enemies. The scene focuses again on Akhnaten and his family, still oblivious to the country falling apart.
"Scene 2: The Attack and Fall of the City"
The music moves again to a vigorous F minor. Horemhab, Aye and the High Priest of Aten instigate the people (as the chorus), singing part of the vassal's letters (in their original Akkadian language) until finally the palace is attacked, the royal family killed, and the city of the sun destroyed. 
"Scene 3: The Ruins"
The music of the very beginning of the opera returns. The scribe recites an inscription on Aye's tomb, praising the death of "the heretic" and the new reign of the old gods. He then describes the restoration of Amun's temple by Akhnaten's son Tutenkhamun. The Prelude music grows stronger and the scene moves to present-day Egypt, to the ruins of Amarna, the former capital Akhet-Aton. The Narrator appears as a modern tourist guide and speaks a text from a guide book, describing the ruins. ""There is nothing left of this glorious city of temples and palaces"".
"Scene 4: Epilogue"
The ghosts of Akhnaten, Nefertiti and Queen Tye appear, singing wordlessly amongst the ruins. The funeral procession from the beginning of the opera appears on the horizon, and they join it. The music introduces a bass line from the beginning of "Einstein on the Beach", the first part of Glass' "portrait" trilogy (The second one being "Satyagraha" and the third one "Akhnaten"), thus providing a musical bracket for the whole trilogy.

</doc>
<doc id="56439" url="https://en.wikipedia.org/wiki?curid=56439" title="Jeff Bridges">
Jeff Bridges

Jeffrey Leon "Jeff" Bridges (born December 4, 1949) is an American actor, singer and producer. He comes from a prominent acting family, and appeared on the television series "Sea Hunt" (1958–60), with his father, Lloyd Bridges and brother, Beau Bridges. He won the Academy Award for Best Actor for his role as Otis "Bad" Blake in the 2009 film "Crazy Heart", and earned Academy Award nominations for his roles in "The Last Picture Show" (1971), "Thunderbolt and Lightfoot" (1974), "Starman" (1984), "The Contender" (2000) and "True Grit" (2010). His other films include "Tron" (1982), "Jagged Edge" (1985), "The Fabulous Baker Boys" (1989), "The Fisher King" (1991), "Fearless" (1993), "The Big Lebowski" (1998), "Seabiscuit" (2003), "Iron Man" (2008), "" (2010) and "The Giver" (2014).
Early life.
Jeffrey Leon Bridges was born on December 4, 1949 in Los Angeles, California. He is the son of show business parents, actor Lloyd Bridges (1913–1998) and actress and writer Dorothy Bridges (née Simpson; 1915–2009). His older brother, Beau Bridges, is also an actor. He has a younger sister, Lucinda, and had another brother, Garrett, who died of sudden infant death syndrome in 1948. His maternal grandfather was an English emigrant from Liverpool.
Bridges and his siblings were raised in the Holmby Hills section of Los Angeles. Growing up, Bridges shared a close relationship with his brother Beau, who acted as a surrogate father when their father was working. He graduated from University High School in 1967. At age 17, Jeff toured with his father in a stage production of "Anniversary Waltz". After graduating from high school, Bridges moved to New York City, where he studied acting at the Herbert Berghof Studio. Also, after turning 18, Bridges joined the United States Coast Guard Reserve, where he served for seven years.
Career.
Film.
Bridges made his first screen appearance at the age of almost two years in "The Company She Keeps" in 1951. In his youth, Bridges and brother Beau made occasional appearances on their father's show "Sea Hunt" (1958–1961) and the CBS anthology series, "The Lloyd Bridges Show" (1962–1963). In 1971 he played the lead role Mike in the TV movie "In Search of America". His first major role came in the 1971 film "The Last Picture Show", for which he garnered a nomination for the Academy Award for Best Supporting Actor. He co-starred in the 1972 critically acclaimed neo-noir boxing film "Fat City", directed by John Huston. He was nominated again for Best Supporting Actor for his performance opposite Clint Eastwood in the 1974 film "Thunderbolt and Lightfoot". In 1976, he starred as the protagonist Jack Prescott in the first remake of "King Kong", opposite Jessica Lange. This film was a commercial success, earning $90 million worldwide, more than triple its $23 million budget, and also winning an Academy Award for special effects.
One of his better-known roles was in the 1982 science fiction film "Tron", in which he played Kevin Flynn, a video game programmer (a role he reprised in late 2010 with the sequel ""). The same year (1982) he also starred in "Kiss Me Goodbye", an American romantic comedy film directed by Robert Mulligan that also starred Sally Field. He was nominated for the Academy Award for Best Actor in 1984, for playing the alien in "Starman". He was also acclaimed for his roles in the thriller "Against All Odds" (1984) and the crime drama "Jagged Edge" (1985). His role in "Fearless" (1993) is thought by some critics to be one of his best performances. One critic dubbed it a masterpiece; Pauline Kael wrote that he "may be the most natural and least self-conscious screen actor that has ever lived." In 1994, he starred as Lt. Jimmy Dove in the action film Blown Away, opposite Tommy Lee Jones and Forest Whitaker. His real life father Lloyd Bridges also featured in the film, playing the father of Bridges' character. The film managed to recoup $50 million of its $30 million budget at the box office. It was up against another explosive themed film, Speed, which had been released a few weeks before Bridges' film. In 1998, he starred as what is arguably his most famous role, The Dude, in the Coen brothers' film "The Big Lebowski". He has said that he relates to The Dude more than any of his other roles.
In 2000, he received his fourth Academy Award nomination, for his role in "The Contender". He also starred in the 2005 Terry Gilliam film "Tideland", his second with the director (the first being 1991's "The Fisher King"). He shaved his trademark mane of hair to play the role of Obadiah Stane in the 2008 Marvel comic book adaptation "Iron Man". In July 2008, at the San Diego Comic-Con International, he appeared in a teaser for "", shot as concept footage for director Joseph Kosinski; this developed into a full 3D feature release in 2010.
Bridges is one of the youngest actors ever to be nominated for an Academy Award (1972, age 22, Best Supporting Actor, "The Last Picture Show"), and one of the oldest ever to win (2010, age 60, Best Actor, "Crazy Heart"). "Crazy Heart" also won him the Golden Globe for Best Actor in a Drama, and the Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Leading Role.
Bridges received his sixth Academy Award nomination for his role in "True Grit", a collaboration with the Coen brothers in which he starred alongside Matt Damon, Josh Brolin, Barry Pepper, and Hailee Steinfeld. Both the film, and Bridges' performance as Rooster Cogburn, were critically praised. Bridges lost to Colin Firth, whom he had beaten for the Oscar in the same category the previous year.
Music.
Referring to his career as an actor and his passion for music, Bridges says, "I dug what an actor did, but it took me a while to feel it, to truly appreciate the craft and the preparation. Plus, I was still playing music a lot, and I guess I had a hard time choosing: was I an actor or a musician, or could I be both?"
Bridges studied piano at a young age, strongly encouraged by his mother. While working on the 1980 film "Heaven's Gate", he often played guitar with his co-star, singer/songwriter Kris Kristofferson, between takes. His character in "Crazy Heart", Bad Blake, was later based partly on Kristofferson. He released his debut album "Be Here Soon" on January 1, 2000. In 2005, Bridges, known as "The Dude" in the film "The Big Lebowski", showed up at a Lebowski Fest in Los Angeles singing and playing the film's theme song written by Bob Dylan, "Man in Me".
On January 15, 2010, Bridges performed the song "I Don't Know" from "Crazy Heart" on "The Tonight Show with Conan O'Brien". In the film "The Contender", in which he co-starred, Bridges recorded a version of Johnny Cash's standard "Ring of Fire" with Kim Carnes that played over the pivotal opening credits. In February 2010, he was among the nearly 80 musicians to sing on the charity-single remake of "We Are the World". On October 24, 2010, Bridges appeared at Neil Young's annual "Bridge School Benefit" concert and played a set with singer-songwriter Neko Case.
On April 19, 2011, Country Music Television announced that Bridges had signed a recording contract with Blue Note Records/EMI Music Group. He worked with producer T-Bone Burnett and released his second album, "Jeff Bridges," on August 16, 2011. On November 5, 2011, Bridges played Austin City Limits in support of this album.
In 2015, Jeff Bridges released an ambient/spoken-word album entitled "Sleeping Tapes". All proceeds from the album go directly to Bridges' charity No Kid Hungry.
Bridges plays many guitars, including the Gretsch Chet Atkins Country Gentlemen Model G6122-1959.
Other work.
Author.
In 2013, Bridges authored "The Dude and the Zen Master" with Bernie Glassman. Bridges found himself at a party with Glassman and Ram Dass and their conversation led to discussing the parallels between "The Dude" from "The Big Lebowski" and Zen Buddhism. The book was formed from what has been described as a "transcript of a five-day “hang” on a Montana ranch."
Photography.
Bridges has been an amateur photographer since high school, and began taking photographs on film sets during "Starman", at the suggestion of co-star Karen Allen. Since 1980, he began photographing on and off set shots with his favorite camera, a Widelux F8. He published many of these photographs online and published a book in 2003 entitled, "Pictures: Photographs by Jeff Bridges".
Narrator.
Bridges narrated the documentary "Lost in La Mancha" (2002), about the making of a Terry Gilliam retelling of "Don Quixote", tentatively titled "The Man Who Killed Don Quixote", which would have starred Johnny Depp as Sancho Panza and Jean Rochefort as the quixotic hero. Bridges had previously appeared in Gilliam's "The Fisher King". Bridges also narrated the documentaries National Geographic's "Lewis & Clark: Great Journey West" (2002, IMAX), Discovery Channel's "Raising the Mammoth" (2000), and ABC's "Heroes of Rock and Roll" (1979). He also voiced the character Big Z in the animated picture "Surf's Up". He also hosted VH1's "Top 100 Greatest Albums of Rock and Roll" series in 2001.
Bridges has performed TV commercial voiceover work as well, including Hyundai's 2007 "Think About It" advertising campaign as well as the Duracell advertisements in the "Trusted Everywhere" campaign.
On December 18, 2010, Bridges hosted NBC's "Saturday Night Live"; he had hosted the show before in 1983 with his brother, Beau. With the December 18, 2010 episode, Bridges beat Sigourney Weaver's record for longest gap between hosting appearances on "SNL" (Weaver had a 24-year gap between her first time hosting in 1986 and her second time hosting in 2010, while Bridges had a 27-year gap between his first appearance in 1983 and his most recent one, also in 2010).
Personal life.
Bridges married Susan Geston in 1977. They met on the film shoot of "Rancho Deluxe", which was filmed on a ranch where Geston was working as a maid. They have three daughters: Isabelle Annie (born August 6, 1981), Jessica Lily "Jessie" (born June 14, 1983), Hayley Roselouise (born October 17, 1985), and granddaughter Grace (born March 31, 2011) from Isabelle.
Bridges has studied Buddhism. He meditates for half an hour before beginning work on a film set. He has learned Transcendental Meditation.
Humanitarian efforts.
In 1984, Bridges and other entertainment industry leaders founded the End Hunger Network aimed at encouraging, stimulating and supporting action to end childhood hunger. He supports President Obama's initiative to End Childhood Hunger by 2015. In November 2010, Bridges became spokesman for the No Kid Hungry campaign of the organization Share our Strength. Its goal is to present and undertake a state-by-state strategy to end childhood hunger in the United States by 2015. Bridges also supports environmental causes and organizations such as the Amazon Conservation Team.

</doc>
<doc id="56440" url="https://en.wikipedia.org/wiki?curid=56440" title="Orbital inclination">
Orbital inclination

Orbital inclination is the minimum angle between a reference plane and the orbital plane or axis of direction of an object in orbit around another object.
Orbits.
The inclination is one of the six orbital parameters describing the shape and orientation of a celestial orbit. It is the angular distance of the orbital plane from the plane of reference (usually the primary's equator or the ecliptic), normally stated in degrees. In the Solar System, orbital inclination is usually stated with respect to Earth's orbit.
In the Solar System, the inclination of the orbit of a planet is defined as the angle between the plane of the orbit of the planet and the ecliptic. Therefore Earth's inclination is, by definition, zero. Inclination could instead be measured with respect to another plane, such as the Sun's equator or even Jupiter's orbital plane, but the ecliptic is more practical for Earth-bound observers. Most planetary orbits in the Solar System have relatively small inclinations, both in relation to each other and to the Sun's equator. On the other hand, the dwarf planets Pluto and Eris have inclinations to the ecliptic of 17 degrees and 44 degrees respectively, and the large asteroid Pallas is inclined at 34 degrees.
Natural and artificial satellites.
The inclination of orbits of natural or artificial satellites is measured relative to the equatorial plane of the body they orbit if they do so close enough. The equatorial plane is the plane perpendicular to the axis of rotation of the central body.
For impact-generated moons of terrestrial planets not too far from their star, with a large planet–moon distance, it is expected that the orbital planes of moons will tend to be aligned with the planet's orbit around the star due to tides from the star, but if the planet–moon distance is small it may be inclined. For gas giants, the orbits of moons will tend to be aligned with the giant planet's equator because these formed in circumplanetary disks.
The term "critical inclination" is often used when describing artificial satellites in orbit around Earth. This term refers to a satellite orbiting with an inclination of 63.4°. This inclination is described as critical as there is zero apogee drift for satellites in elliptical orbits at this inclination.
Exoplanets and multiple star systems.
The inclination of exoplanets or members of multiple stars is the angle of the plane of the orbit relative to the plane perpendicular to the line-of-sight from Earth to the object.
Since the word 'inclination' is used in exoplanet studies for this line-of-sight inclination then the angle between the planet's orbit and the star's rotation must use a different word and is termed the spin-orbit angle or spin-orbit alignment. In most cases the orientation of the star's rotational axis is unknown.
Because the radial-velocity method more easily finds planets with orbits closer to edge-on, most exoplanets found by this method have inclinations between 45° and 135°, although in most cases the inclination is not known. Consequently, most exoplanets found by radial velocity have true masses no more than 70% greater than their minimum masses. If the orbit is almost face-on, especially for superjovians detected by radial velocity, then those objects may actually be brown dwarfs or even red dwarfs. One particular example is HD 33636 B, which has true mass 142 MJ, corresponding to an M6V star, while its minimum mass was 9.28 MJ.
If the orbit is almost edge-on, then the planet can be seen transiting its star.
Calculation.
In astrodynamics, the inclination formula_1 can be computed from the orbital momentum vector formula_2 (or any vector perpendicular to the orbital plane) as formula_3, where formula_4 is the z-component of formula_5.
Mutual inclination of two orbits may be calculated from their inclinations to another plane using cosine rule for angles.

</doc>
<doc id="56442" url="https://en.wikipedia.org/wiki?curid=56442" title="A Dictionary of Modern English Usage">
A Dictionary of Modern English Usage

A Dictionary of Modern English Usage (1926), by Henry Watson Fowler (1858–1933), is a style guide to British English usage, pronunciation, and writing. Covering topics including plurals and literary technique, distinctions among like words (such as homonyms and synonyms), and the use of foreign terms, it became the standard for most style guides that followed. Thus, the 1926 first edition remains in print, despite the existence of the 1965 second edition (edited by Ernest Gowers, and reprinted in 1983 and 1987), and later versions. The 1996 third edition, as "The New Fowler's Modern English Usage" (with a revised third in 2004) was mostly rewritten by Robert W. Burchfield, as a usage dictionary incorporating corpus linguistics data; the 2015 fourth edition ("Fowler's Dictionary of Modern English Usage", edited by Jeremy Butterfield) follows similar principles to the third. In whatever edition, the work is informally known as Fowler’s Modern English Usage, Fowler, and Fowler’s.
Linguistic approach.
In "A Dictionary of Modern English Usage", Henry W. Fowler’s general approach encourages a direct, vigorous writing style, and opposes all artificiality, by firmly advising against convoluted sentence construction, the use of foreign words and phrases, and the use of archaisms. He opposed pedantry, and ridiculed artificial grammar rules unwarranted by natural English usage, such as bans on ending a sentence with a preposition; rules on the placement of the word "only"; and rules distinguishing between "which" and "that". He classified and condemned every cliché, in the course of which he coined and popularised the terms "battered ornament", "Wardour Street", "vogue words", and "worn-out humour", while defending useful distinctions between words whose meanings were coalescing in practice, thereby guiding the speaker and the writer away from illogical sentence construction, and the misuse of words. In the entries "Pedantic Humour" and "Polysyllabic Humour" Fowler mocked the use of arcane words (archaisms) and the use of long words.
Quotations.
Widely and often cited, "A Dictionary of Modern English Usage" is renowned for its witty passages, such as:
Editions.
Before writing "A Dictionary of Modern English Usage", Henry Fowler and his younger brother, Francis George Fowler (1871–1918), wrote and revised "The King's English" (1906), a grammar and usage guide later superseded by this book in the 1930s. Moreover, he researched the "Dictionary" assisted by Francis, who died in 1918 of tuberculosis, which he contracted in service with the British Expeditionary Force in the First World War (1914–1918). Fowler thus dedicated the "Dictionary" to his brother, Francis George:
I think of it as it should have been, with its prolixities docked, its dullnesses enlivened, its fads eliminated, its truths multiplied ... having been designed in consultation with him, it is the last fruit of a partnership that began in 1903 with our translation of Lucian.
The first edition of "A Dictionary of Modern English Usage" (1926) was much reprinted; thus, a reprint wherein the copyright page indicates 1954, as the most recent reprinting year, also notes that the 1930 and 1937 reprintings were "with corrections". The second edition, "Fowler’s Modern English Usage" (1965) was revised by Sir Ernest Gowers, who updated the text, contributed entries, and deleted articles "no longer relevant to literary fashions". For the twenty-first century, the third edition, "The New Fowler’s Modern English Usage " (1996), was revised and published as "Fowler’s Modern English Usage" (2004), the editor of which, Robert Burchfield, in the preface acknowledges that, while "Fowler’s name remains on the title-page ... his book has been largely rewritten." A fourth edition, edited by Jeremy Butterfield, was published by Oxford University Press in 2015. The substantive and editorial differences between the first and third editions are that the former is a prescriptive style guide to clear and expressive writing, while the latter is a descriptive usage guide to spoken and written English. The 2009 reprinting of the 1926 first edition contains an introduction and commentary by the linguist David Crystal. The "Pocket Fowler's Modern English Usage" edited by Robert Allen was published by OUP in 1999. It was based mainly on Burchfield's 1996 edition, abridged to 40% by omitting about half the entries and reducing others; there was also some new content. A second edition of Allen's "Pocket Fowler" was published in 2008, which OUP said "harks back to the original 1926 edition".

</doc>
<doc id="56443" url="https://en.wikipedia.org/wiki?curid=56443" title="Fowler">
Fowler

Fowler can refer to:

</doc>
<doc id="56444" url="https://en.wikipedia.org/wiki?curid=56444" title="Jeans">
Jeans

Jeans are trousers, a type of garment, typically made from denim or dungaree cloth. Often the term "jeans" refers to a particular style of pants, called "blue jeans," which were invented by Jacob W. Davis in partnership with Levi Strauss & Co. in 1871 and patented by Jacob W. Davis and Levi Strauss on May 20, 1873. Prior to the Levi Strauss patented trousers, the term "blue jeans" had been long in use for various garments (including trousers, overalls, and coats), constructed from blue colored denim. Originally designed for cowboys and miners, jeans became popular in the 1950s among teenagers, especially members of the greaser subculture. Jeans were a common fashion item in the 1960s Hippie subculture and they continued to be popular in the 1970s and 1980s youth subcultures of punk rock and heavy metal. Historic brands include Levi's, Lee, and Wrangler. In the 2010s, jeans remain a popular fashion item, and they come in various fits, including skinny, tapered, slim, straight, boot cut, cigarette bottom, narrow bottom, bell bottom, low waist, anti-fit, and flare. "Distressed" (visibly aged and worn, but still intact and functional) jeans trousers have become increasingly fashionable, making pre-sale "factory distressing" a common feature in commercially sold jeans.
In the 2010s, jeans are a very popular article of casual dress around the world. They come in many styles and colors. However, blue jeans are particularly identified with American culture, especially the Old West. As well, although jeans are mostly known as a popular fashion garment for several decades, they are still worn as protective garments by some individuals, such as cattle ranch workers and motorcycle riders, due to their high durability as compared to other common fabrics.
History.
Jean fabric.
Research on the trade of jean fabric shows that it emerged in the cities of Genoa, Italy, and Nimes, France. Gênes, the French word for Genoa, may be the origin of the word "jeans". In Nimes, weavers tried to reproduce jean but instead developed a similar twill fabric that became known as denim, from "de Nimes", meaning "from Nimes". Genoa’s jean was a fustian textile of "medium quality and of reasonable cost", very similar to cotton corduroy for which Genoa was famous, and was "used for work clothes in general". Nimes’s "denim" was coarser, considered higher quality and was used "for over garments such as smocks or overalls". Nearly all Indigo, needed for dyeing, came from indigo bush plantations in India till the late 19th century. It was replaced by indigo synthesis methods developed in Germany.
By the 17th century, jean was a crucial textile for working-class people in Northern Italy. This is seen in a series of genre paintings from around the 17th century attributed to an artist now named The Master of the Blue Jeans. The ten paintings depict impoverished scenes with lower-class figures wearing a fabric that looks like denim. The fabric would have been Genoese jean, which was cheaper. Genre painting came to prominence in late 16th century, and the low-life subject matter in all ten paintings places them among others that portray similar scenes.
Denim is not the only sturdy cotton fabric used for everything from working clothes to fashion items. There is also dungaree.
Dungaree was mentioned for the first time in the 17th century, when it was referred to as cheap, coarse thick cotton cloth, often colored blue but sometimes white, worn by impoverished people in what was then a region of Bombay, India a dockside village called Dongri. This cloth was "dungri" in Hindi. Dungri was exported to England and used for manufacturing of cheap, robust working clothes. In English, the word "dungri" became pronounced as "dungaree".
The importance of jean is also shown by the history of textile trade. Genoese sailors used jean to cover and protect their goods on the docks from the weather. During the Republic of Genoa (17th, 18th centuries), sailors exported jeans throughout Europe.
The invention of the zipper, by Whitcomb L. Judson, helped as well.
Jean became popular in the United States when Levi Strauss & Co.'s introduced blue jean overalls in 1873.
Riveted jeans.
Levi Strauss, as a young man in 1851, went from Germany to New York to join his older brothers who ran a goods store. In 1853, he moved to San Francisco to open his own dry goods business. Jacob Davis was a tailor who often bought bolts of cloth from the Levi Strauss & Co. wholesale house. In 1872, Davis wrote to Strauss asking to partner with him to patent and sell clothing reinforced with rivets. The copper rivets were to reinforce the points of stress, such as pocket corners and at the bottom of the button fly. Levi accepted Davis's offer, and the two men received US patent No. 139,121 for an "Improvement in Fastening Pocket-Openings" on May 20, 1873.
Davis and Strauss experimented with different fabrics. An early attempt was brown cotton duck, a bottom-weight fabric. Finding denim a more suitable material for work-pants, they began using it to manufacture their riveted pants. The denim used was produced by an American manufacturer, but popular legend states it was imported from Nimes, France. A popular myth is that Strauss initially sold brown canvas pants to miners, later dyed them blue, turned to using denim, and only after Davis wrote to him, added rivets.
Evolution of the garment.
The term appears first in 1795, when a Swiss banker by the name Jean-Gabriel Eynard and his brother Jacques went to Genoa and both were soon heading a flourishing commercial concern. In 1800 Massena's troops entered the town and Jean-Gabriel was entrusted with their supply. In particular he furnished them with uniforms cut from blue cloth called "bleu de Genes" whence later derives the famous garment known worldwide as "blue jeans". When Levi Strauss & Co. patented the modern, mass-produced prototype in 1873, there were two pockets in the front and one on the back with copper rivets. Later, the jeans were redesigned to today's industry standard of 5 pockets including a little watch pocket and copper rivets.
Initially, jeans were simply sturdy trousers worn by factory workers. During this period, men's jeans had the zipper down the front, whereas women's jeans had the zipper down the left side. Fewer jeans were made during World War II, but 'waist overalls' were introduced to the world by US soldiers, who sometimes wore them off duty. By the 1960s, both men's and women's jeans had the zipper down the front. Historic photographs indicate that in the decades before they became a staple of fashion, jeans generally fit quite loosely, much like a pair of bib overalls without the bib. Indeed, until 1960, Levi Strauss called its flagship product "waist overalls" rather than "jeans".
After James Dean popularized them in the movie "Rebel Without a Cause", wearing jeans became a symbol of youth rebellion during the 1950s. Because of this, they were sometimes banned in theaters, restaurants and schools.During the 1960s the wearing of jeans became more acceptable, and by the 1970s it had become general fashion in the United States for casual wear.
Michael Belluomo, editor of "Sportswear International Magazine", Oct/Nov 1987, P. 45, wrote that in 1965, Limbo, a boutique in the New York East Village, was "the first retailer to wash a new pair of jeans to get a used, worn effect, and the idea became a hit." He continued, " hired East Village artists to embellish the jeans with patches, decals, and other touches, and sold them for $200." In the early 1980s the denim industry introduced the stone-washing technique developed by GWG also known as "Great Western Garment Co." Donald Freeland of Edmonton, Alberta pioneered the method, which helped to bring denim to a larger and more versatile market. Acceptance of jeans continued through the 1980s and 1990s to the point where jeans are, in the first decade of 21st century, a wardrobe staple, with the average North American owning seven pairs. In the 2010s, jeans may be seen being worn by people of all genders and ages.
Manufacturing processes.
Dyeing.
Traditionally, jeans were dyed to a blue color using natural indigo dye. Most denim is now dyed using synthetic indigo. Approximately 20 thousand tons of indigo are produced annually for this purpose, though only a few grams of the dye are required for each pair. For other colors of denim other dyes must be used. Currently, jeans are produced in any color that can be achieved with cotton.
For more information on dyeing, refer to denim and the discussion there of using pigment dyes.
Pre-shrinking.
In 1962 Levi Strauss introduced pre-shrunk jeans, which did not shrink further after purchase, allowing the consumer to buy his or her correct size. These jeans were known as the 505 regular fit jeans. The 505 are almost identical to the 501s with the exception of the button-fly. The Levi's Corporation also introduced a slim boot-cut fit known as 517 and 527. The difference between the two is the 517s sit at the waist line and the 527s sit below the waist line. Later, Levi's would develop other styles and fits such as the loose, slim, comfort, relaxed, skinny, and a regular fit with a tapered leg.
Used look.
The used or "acid wash" look is created by means of abrading the jeans and/or treating them with chemicals, such as acryl resin, phenol, a hypochlorite, potassium permanganate, caustic soda, acids etc.
Sandblasting or abrading with sandpaper.
Consumers wanting jeans that appear worn can buy jeans that have been specially treated. To give the fabrics the worn look, sandblasting done with chemicals or by adding pumice stone to the washing process or abrading with sandpaper is often done.
Environmental and humanitarian impact.
A typical pair of blue jeans consumes 919 gallons (3479 liters) of water during its life cycle. This includes the water to irrigate the cotton crop, manufacture the jeans, and the numerous washes by the consumer.
The production of jeans with a "used look" can be more environmentally damaging than regular jeans, depending on how the waste compounds are processed. Sandblasting and treating with sandpaper has the risk of causing silicosis to the workers, and in Turkey, more than 5,000 textile workers have been stricken with this disease, and 46 people are known to have died. Some companies have announced they are banning the use of sandblasting.
Care and wear.
Despite most jeans being "pre-shrunk", they are still sensitive to slight further shrinkage and loss of color from being washed. The Levi Strauss company recommends avoiding washing jeans as much as possible. Carl Chiara, Levi Strauss director of brand and special projects, has a credo: The less you wash your jeans, the better your jeans become. These and other suggestions to avoid washing jeans where possible have encountered criticism. Cory Warren, editor of "LS&Co. Unzipped", clarifies in a response to such a criticism:
For those who prefer to refrain from washing their jeans there have been suggestions to freeze them in order to kill the germs that cause odor. However, this advice has been disputed as ineffective and replaced with the suggestion of baking them for ten minutes at 250 degrees Fahrenheit. (120 °C).
Jeans in the USSR.
In the Soviet Union, jeans were the symbol of the Western way of life. The "jeans fever" in the USSR started 1957, during the World Festival of Youth and Students. According to a 1961 Russian textile dictionary, jeans were initially referred to as a "worker's uniform" (рабочий костюм, "rabochii kostyum").
The jeans brand Rokotov and Fainberg is named after the defendants in the Rokotov–Faibishenko case, who were executed for, among other things, trafficking in jeans.
Jeans in the law.
Jeans are covered under laws regarding trousers. As well, there have been some notable legal cases involving jeans specifically:
In Rome in 1992, a 45-year-old driving instructor was accused of rape. When he picked up an 18-year-old girl for her first driving lesson, he allegedly raped her for an hour, then told her that if she was to tell anyone he would kill her. Later that night she told her parents and her parents agreed to help her press charges. While the alleged rapist was convicted and sentenced, the Italian Supreme Court overturned the conviction in 1998 because the victim wore tight jeans. It was argued that she must have necessarily had to help her attacker remove her jeans, thus making the act consensual ("because the victim wore very, very tight jeans, she had to help him remove them...and by removing the jeans...it was no longer rape but consensual sex"). The Italian Supreme Court stated in its decision "it is a fact of common experience that it is nearly impossible to slip off tight jeans even partly without the active collaboration of the person who is wearing them." This ruling sparked widespread feminist protest. The day after the decision, women in the Italian Parliament protested by wearing jeans and holding placards that read "Jeans: An Alibi for Rape." As a sign of support, the California Senate and Assembly followed suit. Soon Patricia Giggans, Executive Director of the Los Angeles Commission on Assaults Against Women, (now Peace Over Violence) made Denim Day an annual event. As of 2011 at least 20 U.S. states officially recognize Denim Day in April. Wearing jeans on this day has become an international symbol of protest against erroneous and destructive attitudes about sexual assault. As of 2008 the Italian Supreme Court has overturned their findings, and there is no longer a "denim" defense to the charge of rape.
In 2014, an Indian family court in Mumbai ruled that a husband objecting to his wife wearing a kurta and jeans and forcing her to wear a sari amounts to cruelty inflicted by the husband and can be a ground to seek divorce. The wife was thus granted a divorce on the ground of cruelty as defined under section 27(1)(d) of Special Marriage Act, 1954.
Sales trends.
Worldwide market for jeans.
North America accounts for 39% of global purchases for jeans, followed by Western Europe at 20%, Japan and Korea at 10% and the rest of the world at 31%.
United States consumers spent more than US$14 billion on jeans in 2004 and US$15 billion in 2005. US consumers bought US$13.8 billion of men's and women's jeans in the year that ended 30 April 2011, according to market-research firm NPD Group.
Jeans are losing market share to yoga pants and other activewear.
Teens are now buying more fashion gear from Nike and Lululemon over denim classics from brands like Abercrombie, according to a recent Piper Jaffray survey on teen spending. Activewear now comprises 28% of teens' apparel purchases, up from 6% in 2008. In 2014, Nike, Lululemon, Under Armour, and Adidas are the most popular brands for athletic apparel among teen consumers. It is likely that the preference for soft, knit trousers will follow this generation as they age, causing a significant shift in spending from blue jeans to athleisure apparel. Fashion retailers will need to adjust their offerings accordingly. Bloomberg reports that Levi's, which is the world's most iconic denim company, stuck to its core product (denim) instead of adapting to consumer trends. As a result, Levi's sales have dipped from over USD 7 billion to USD 4.8 billion over the years.

</doc>
<doc id="56447" url="https://en.wikipedia.org/wiki?curid=56447" title="Theo Wade Brown">
Theo Wade Brown

Theo Wade Brown (26 May 1950 - 30 April 2002) was an English carpenter, designer and engineer.
Brown was also a bon viveur, amateur musician and genuine eccentric. With his handlebar moustache and long red hair, he was an unmistakable figure.
Brown was a well-known member of the London film special effects community, and one of the core team at the Computer Film Company that won a Scientific and Technical Academy Award for developing digital film technology.
Brown later designed the Northlight film scanner for the Computer Film Company scanner division (now Filmlight), and was responsible not only for its remarkable engineering design, but also its 1920s-style marble and steel appearance—an artistic flourish that was characteristic of Brown's approach to life.
Brown suffered from bipolar disorder which led eventually to his death.
In 2010, he was posthumously awarded a Scientific and Technical Academy Award for his work at Filmlight on the Northlight scanner technology.

</doc>
<doc id="56452" url="https://en.wikipedia.org/wiki?curid=56452" title="Örnsköldsvik Municipality">
Örnsköldsvik Municipality

Örnsköldsvik Municipality ("Örnsköldsviks kommun") is one of Sweden's 290 municipalities, in Västernorrland County in northern Sweden. Its seat is in the town Örnsköldsvik. The present municipality was created in 1971 by the amalgamation of the "City of Örnsköldsvik" with seven former rural municipalities.
Geography.
Örnsköldsvik is situated near the northern end of the "High Coast", which is a UNESCO World Heritage Site and has the third longest suspension bridge in Europe, the Höga Kusten Bridge.
The city is located around 100 km south of Umeå and 550 km north of Stockholm. The area is dominated by forest, but it also contains minor areas of agriculture.
Population distribution (31 December 2005).
The municipality of Örnsköldsvik is built up from a number of parishes, within which are towns and villages. The population is distributed as follows:
Parish (town) number of citizens
Total: 54,943
Transportation.
Main road transportations are provided by the European route E4. The Örnsköldsvik Airport provides daily flights to and from the Stockholm-Arlanda Airport courtesy of Höga Kusten Flyg, and also charter flights to Turkey courtesy of Pegasus Airlines. Railway transportation will in the future be provided by high-speed railway Botniabanan, which is currently under construction. There is also a harbour, where cargo ships load and unload timber and other merchandise. In North America the town is known for its excellent hockey players, a number of whom play with the NHL.
Recreation and sports.
Due to the hilly surroundings, hiking and exploring the scenery of the High Coast is popular in the area. In the wintertime, skiing is popular. Both cross-country skiing, alpine skiing and even ski jumping is practiced almost in the downtown area. Since Örnsköldsvik is a coastal town, there are also beaches near town, as well as campsites. There's also an indoor water park called Paradisbadet, with one of the longest water slides in Europe.
Sports is also popular, the main spectator sport in town is ice hockey, with the local team Modo Hockey in Swedish Hockey League, the main league for ice hockey in Sweden. The local football teams are not quite as successful, but still pretty popular, on the men's side especially the teams Friska Viljor FC from central Örnsköldsvik and Anundsjö IF from Bredbyn outside of town, and women's Själevads IK. A couple floorball teams from town have also had some success.
Notable natives.
Örnsköldsvik is the birthplace of many world-famous ice hockey players, including Peter Forsberg, Markus Näslund, Niklas Sundström, and twins Daniel and Henrik Sedin. Samuel Påhlsson, also an ice hockey player, lived there for a long time but was born in Ånge. Many stars from hockey's previous generation, including Anders Hedberg, Thomas Gradin and Anders Kallur, were also either Örnsköldsvik natives (Hedberg) and/or played in the town for the Modo Hockey club.
Sister cities.
Örnsköldsvik's sister cities are:

</doc>
<doc id="56455" url="https://en.wikipedia.org/wiki?curid=56455" title="Antonio Stradivari">
Antonio Stradivari

Antonio Stradivari (; 1644 – 18 December 1737) was an Italian luthier and a crafter of stringed instruments such as violins, cellos, guitars, violas and harps. Stradivari is generally considered the most significant and greatest artisan in this field. The Latinized form of his surname, "Stradivarius", as well as the colloquial "Strad" are terms often used to refer to his instruments. The Hills Violin Shop estimate that Antonio produced 1,116 instruments, of which 960 were violins. It is also estimated that around 650 of these instruments survive, including 450 to 512 violins.
Biography.
Family background and early life.
Antonio Stradivari’s birthdate, presumably between 1644 and 1649, has been debated amongst historians due to the numerous inconsistencies in the evidence of the latter. The 1668 and 1678 censuses report him actually growing younger, a fact explained by the probable loss of statistics from 1647–49, when renewed belligerency between France’s Modenese and Spain’s Milanese proxies led to a flow of refugees that included Stradivari’s mother.
Stradivari's ancestry consisted of notable citizens of Cremona, dating back to at least the 12th or 13th century. The earliest mention of the family name, or a variation upon it, is in a land grant dating from 1188. The origin of the name itself has several possible explanations; some sources say it is the plural of "Stradivare", essentially meaning "toll-man" in Lombard, while others say that the form "de Strataverta" derives from "Strada averta", which, in Cremonese dialect means "open road."
Antonio's parents were Alessandro Stradivari, son of Giulio Cesare Stradivari, and Anna Moroni, daughter of Leonardo Moroni. They married on 30 August 1622, and had at least three children between 1623 and 1628: Giuseppe Giulia Cesare, Carlo Felice, and Giovanni Battista. The baptismal records of the parish of S. Prospero then stop, and it is unknown whether they had any children from 1628 to 1644. This blank in the records may be due to the family leaving Cremona in response to war, famine, and plague in the city from 1628 to 1630, or the records may have been lost due to clerical reforms imposed by Joseph II of Austria in 1788. The latter explanation is supported by the word "Cremonensis" (of Cremona) on many of Stradivari's labels, which suggests that he was born in the city instead of merely moving back there to work. Antonio was born in 1644, a fact deducible from later violins. However, there are no records or information available on his early childhood, and the first evidence of his presence in Cremona is the label of his oldest surviving violin from 1666.
Stradivari likely began an apprenticeship with Nicolò Amati between the ages of 12 and 14, although a minor debate surrounds this fact. One of the few pieces of evidence supporting this is the label of his 1666 violin, which reads, "Alumnus Nicolai Amati, faciebat anno 1666". However, Stradivari did not repeatedly put Amati's name on his labels, unlike many of his other students. Stradivari's early violins actually bear less resemblance to those of Amati than his later instruments do. M. Chanot-Chardon, a well-known French luthier, asserted that his father had a label of Stradivari's stating, "Made at the age of thirteen, in the workshop of Nicolò Amati". This label has never been found or confirmed. Amati would also have been a logical choice for Antonio's parents, as he represented an old family of violin makers in Cremona, and was far superior to most other luthiers in Italy.
An alternative theory is that Stradivari started out as a woodworker: the house he lived in from 1667 to 1680 was owned by Francesco Pescaroli, a woodcarver and inlayer. Stradivari may even have been employed to decorate some of Amati's instruments, without being a true apprentice. This theory is supported by some of Stradivari's later violins, which have elaborate decorations and purfling.
Assuming that Stradivari was a student of Amati, he would have begun his apprenticeship in 1656–58 and produced his first decent instruments in 1660, at the age of 16. His first labels were printed from 1660 to 1665, which indicates that his work had sufficient quality to be offered directly to his patrons. However, he probably stayed in Amati's workshop until about 1684, using his master's reputation as a launching point for his career.
First marriage.
Stradivari married his first wife, Francesca Ferraboschi, on 4 July 1667. Francesca was the young widow of the burgher Giacomo Capra, with whom she had two children, and who had been shot by Francesca's brother on the Piazza Garibaldi (formerly the Piazza Santa Agata) by a crossbow. He was later exiled, though allowed to return to Cremona many years later. After their marriage, Stradivari moved into a house known as the Casa del Pescatore, or the Casa Nuziale, in his wife's parish. A clue to how they would have met lies in the 1659 Easter census, which lists the Ferraboschi family four houses away from the Amati residence. The couple had a daughter, Giulia Maria, three to four months later. They remained in the house until 1680, during which time they had four more children: Catterina, Francesco, Alessandro, and Omobono Stradivari, as well as an infant son who lived for only a week. It is to be noted that an age difference of four to nine years was uncommon between wedded couples at the time.
Stradivari purchased a house now known as No. 1 Piazza Roma (formerly No. 2 Piazza San Domenico) around 1680 for the sum of 7000 lire, 2000 of which he paid at the time of the purchase. The totality of the house was paid for by 1684. . The residense was just doors away from those of several other violin making families of Cremona, including the Amatis and Guarneris. Stradivari probably worked in the loft and attic, and he stayed in this house for the rest of his life.
Stradivari's wife Francesca died on 20 May 1698, and received an elaborate funeral five days later.
Second marriage.
Stradivari married his second wife, Antonia Maria Zambelli, on 24 August 1699. The only information known about her is that she was 35 at the time of the marriage. They had five children from 1700 to 1708—Francesca Maria, Giovanni Battista Giuseppe, Giovanni Battista Martino, Giuseppe Antonio, and Paolo.
Death.
Stradivari died on 18 December 1737, aged 93. He is buried in the Church of San Domenico. The tomb was acquired 8 years prior to his death, having been bought from a Cremonese family, substituting their name for his in the tombstone.
Will.
His will, dated 1729, is one of the closest approximations we can give to how Stradivari ran his family. Counting his wife, there were eight living heirs at the time Stradivari wrote the draft. Zambelli was left with her clothing, half of her jewelry, bed linens and household items. Antonio declared she would become the responsibility of his two eldest sons. As for Annnunciata Caterina, Antonio left her jewelry, income on loans, clothing and linens. Paolo, the youngest child, was to get six finished violins as well as some household effects and cash. Three other children who had joined religious orders were left with their share of inheritance. Maria, a nun, would get an annuity, Alessandro, a priest, would get fixed income on a home mortgage loan and Giuseppe, another priest would get some income on half a share from a pastry shop. There were also annual payments to his two sons of 150 and 300 lire each, 170 lire for Annunciata as well as 100 for Francesca. To put this into perspective, six violins were valued at approximately 1000 lire, or about 150 lire each.
We are now left with two sons from Antonio’s first marriage who worked in the family shop: Omobono and Franceso. As Omobono had left the dwelling aged eighteen in search of new employment possibilities in Naples, he left Antonio to pay for much of his living expenses. In this sense, his father had never really forgiven him for leaving home. Just as Paolo, he would inherit six violins. That was all that was written on the will for him. As For Francesco, who was named his father’s successor, he would inherit the rest of his father’s belongings, the rest of the estate. This included all of the wood tools, stencils, finished violins, patterns, not to mention, his father’s reputation.
Many events in the family’s history testify to the substantial wealth Antonio generated. For example, in 1733, Stradivari bought his youngest son a partnership in a local textile firm for the large amount of 25,000 lire. In comparison, he had bought his house in 1680 for 7,000 lire. Also, allowing mild inflation, Antonio made a loan of 12,000 lire in 1714. In 1715, under unknown circumstances, Giuseppe Guarneri borrowed 1,000 lire from Stradivari and later defaulted on the loan. Giuseppe worked almost all his life in Stradivari's shadow, just as his father, the elder Giuseppe filius Andreae did.
Career.
Early career.
Stradivari likely developed his own style slowly. His violins often used slightly smaller dimensions. A notable exception to this is the 1697 "Hellier" violin, which had much larger proportions. Stradivari's early (pre-1684) violins are in strong contrast to Amati's instruments from the same time period; Stradivari's have a stronger, more masculine build, and less rounded curves, with the purfling set farther in.
By 1680, Stradivari had acquired at least a small, yet growing, reputation. In 1682, a Venetian banker ordered a complete set of instruments, which he planned to present to King James II of England. The fate of these instruments is unknown. Cosimo de' Medici bought another five years later. Amati died in 1684, an event followed by a noticeable increase in Stradivari's production. The years 1684 and 1685 also marked an important development in his style – the dimensions he used generally increased, and his instruments were more in the style of Amati's work of the 1640s and 1650s. Stradivari's instruments underwent no major change in the next five years, although in 1688 he began cutting a more distinct bevel and began outlining the heads of instruments in black, a quite original improvement.
Stradivari's early career is marked by wide experimentation, and his instruments during this period are generally considered of a lesser quality than his later work. However, the precision with which he carved the heads and inserted the purfling quickly marked him as one of the most dextrous craftsmen in the world, a prime example of this being the 1690 "Tuscan" violin. Pre-1690 instruments are sometimes termed "Amatisé" but this is not completely accurate; it is largely because Stradivari created many more instruments later on that people try to connect his early work with Amati's style.
By 1680 Stradivari moved to No. 1 Piazza Roma (formerly No. 2 Piazza San Domenico). The house was just doors away from those of several other violin making families of Cremona, including the Amatis and Guarneris. Stradivari probably worked in the loft and attic, and he stayed in this house for the rest of his life.
"Golden" period and later years.
In the early 1690s, Stradivari made a pronounced departure from this earlier style of instrument-making, changing two key elements of his instruments. First, he began to make violins with a larger pattern than previous instruments; these larger violins usually are known as "Long Strads". He also switched to using a darker, richer varnish, as opposed to a yellower varnish similar to that used by Amati. He continued to use this pattern until 1698, with few exceptions. After 1698, he abandoned the Long Strad model and returned to a slightly shorter model, which he used until his death. The period from 1700 until the 1720s is often termed the "golden period" of his production. Instruments made during this time are usually considered of a higher quality than his earlier instruments. Late-period instruments made from the late 1720s until his death in 1737 show signs of Stradivari's advancing age. These late instruments may be a bit less beautiful than the Golden Period instruments, but many nonetheless possess a fine tone. Heavier and looser craftmanship of the late Stradivari output can be seen in the 1734 'Habeneck'.
Stradivari and the Cremonese violin making school.
Influence in the 18th century.
San Matteo, the Stradivari parish, as well as San Faustino, the Amati parish, made up the center of Cremonese violin making.They exerted influence not only on one another, in terms of the shape, varnish and sound of instruments, but also on many of their contemporaries; they defined violin making standards for the next 300 years.
Even at the beginning of the 18th century, Stradivari’s influence could be seen not only in the work of Cremonese makers, but also international ones, such as Barak Norman’s, one of the first important British makers. In the 1720s Daniel Parker, a very important British luthier, produced fine violins after Stradivari’s work selling anywhere from £30,000 - £60,000 in recent auctions. Parker based his best instruments on Stradivari's` `long pattern`, having the opportunity to study one or more of the instruments. Well into the 19th century, Jean Baptiste Vuillaume, the leading French luthier of his time, also made many important copies of Strads and Guarneris.
In the 18th century, Cremonese luthiers were the suppliers and local players on the demand side. After Stradivari’s death, this drastically changed. Although the Cremonese luthiers remained the suppliers, the demand side consisted of collectors, researchers, imitators, profiteers and speculators. Many local players could no longer afford the sought out instruments and most of the purchased instruments would be hidden in private collections, put in museums, or would be simply put back in their cases, hoping that they would gain value over time. It is then that the so-called ‘fever’ for Stradivaris took off. Cozio, Tarisio and Vuillaume were the fathers of this frenzy that would extend well into the 21st century. Also, soon after Stradivari’s death, most of the other major Cremonese luthiers would die, putting an end to the golden period of Cremona’s violin making, which lasted more than 150 years, starting with the Amatis and ending with the Cerutis.
Members of the Gagliano family such as Gennaro and Nicolo made excellent copies of the instruments in the 1740s, though the only similarity to Stradivari's instruments were the execution of the form and arching as well as consistently fine and detailed varnish. Nicolo would usually use the forma B model for his cellos and as the quality of the output steadily declined within the family, the Stradivari models were almost abandoned in Naples.
Having acquired many Strads from Paolo Stradivari, Count Cozio commissioned some replicas of the instruments to Giovanni Battista Guadagnini. Although many features of Strads are present in the copies, they still remain heavily influenced by Guadagnini's workshop principles and represent well the maker's Turin period.
Vincenzo Panormo was also one of the many luthiers who based many of his violins on Strads. He learned about them in Paris around 1779 and 1789 when he worked closely with Léopold Renaudin, another one of Strad's followers. Stradivari's influence could also be seen in Spain with the outstanding work of José Contreras of Granada and Madrid. Having the privilege to be exposed to Stradivari's instruments through the Spanish court, he was experienced enough to replace the scroll of a 1717 Stradivari cello and possibly even make its back and ribs. He had a great ability to imitate the original varnish and intricacy of the instrument.
Influence in the 19th and 20th century.
The 19th century was not as eventful in comparison to the previous centuries. Some of the most important luthiers from this part of history include Rota and Chanot. This century was home to the many experimental violins from Francois Chanot and William Sidney Mount (non-Italian makers).
The 20th century was the so-called rebirth of Cremonese making, when luthiers such as Rocca, Morassi, Beltrami, Antoniazzi emerged from a seemingly uneventful and experimental period. These makers, sometimes basing their early violins on Strads, would later on make their own models and would inspire each other’s work.
Stradivari and his sons.
Even though Antonio had a very long working life, it is impossible for him to have crafted more than 1000 instruments entirely by himself, meaning that his sons, Francesco and Omobono, as well as possibly a third son, must have been working on and off in his shop. We know that having left the workshop at eighteen, Omobono made a few instruments on his own, such as the newly discovered ‘Blagrove’ and another violin dating from 1732. On his side, Francesco made very few violins independently, such as the 1742 ‘Salabue’ and ‘Oliveira’, spending his lifetime in his father’s shop. This was one of the main reasons that Francesco had a large part in Antonio’s will, and Omobono a lesser one. One of the major differences between Antonio and his sons' craftsmanship was the quality of the purfling on their instruments. Francesco and Omobono are referred to as being "startlingly poor" by John Dilworth in an online article on Tarisio.com about Stradivari’s sons (2015).
« Only a handful of instruments are reliably attributed to Francesco alone. […]are only two authentic labels known: ‘Franciscus Stradivarius Cremonensis / Filius Antonii faciebat Anno 1742’[…]. Notably it omits the A+S stamp that occurs on Antonio’s labels. Another label states ‘Sotto la Disciplina d’Antonio / Stradivari F. in Cremona 1737’. This is of course the year of his father’s death, and the phrase ‘sotto la disciplina’, although it appears in a few other instruments, may here be a particular sign of his respect.[…]»
Stradivarius instruments.
Stradivari's instruments are regarded as amongst the finest bowed stringed instruments ever created, are highly prized, and are still played by professionals today. Only one other maker, Giuseppe Guarneri del Gesù, commands a similar respect among violinists. However, neither blind listening tests nor acoustic analysis have ever demonstrated that Stradivarius instruments are better than other high-quality instruments or even reliably distinguishable from them.
Fashions in music, as in other things, have changed over the centuries, and the supremacy of Stradivari's and Guarneri's instruments is accepted only today. In the past, instruments by Nicolò Amati and Jacob Stainer were preferred for their subtle sweetness of tone.
While the usual label for a Stradivarius instrument, whether genuine or false, uses the traditional Latin inscription, after the McKinley Tariff Act of 1890, copies were also inscribed with the country of origin. Since thousands of instruments are based on Stradivari's models and bear the same name as his models, many unwary people are deceived into purchasing forged Stradivarius instruments, which can be avoided by having an instrument authenticated.
Some violinists and cellists use Stradivari instruments in their work. Yo-Yo Ma currently uses the "Davidov Stradivarius", Julian Lloyd Webber employs the "Barjansky Stradivarius", and, until his death in 2007, Mstislav Rostropovich played on the "Duport Stradivarius". The "Soil" of 1714 is owned by virtuoso Itzhak Perlman. The "Countess Polignac" is currently played by Gil Shaham. The Vienna Philharmonic uses several Stradivari instruments that were purchased by the National Bank of Austria and other sponsors: "Chaconne", 1725; "ex-Hämmerle", 1709; "ex-Smith-Quersin", 1714; "ex-Arnold Rosé", "ex-Viotti", 1718; and "ex-Halphen", 1727. Viktoria Mullova owns and plays the Jules Falk.
The London sales of "The Mendelssohn" at £902,000 ($1,776,940) in 1990 and "The Kreutzer" for £947,500 in 1998 constitute two top-selling Stradivari. A record price paid at a public auction for a Stradivari was $2,032,000 for the "Lady Tennant" at Christie's in New York, April 2005. On 16 May 2006, Christie's auctioned Stradivari's 1707 "Hammer" for a new record of US$3,544,000. On 2 April 2007, Christie's sold a Stradivari violin, the 1729 "Solomon, Ex-Lambert", for more than $2.7 million to an anonymous bidder in the auction house's fine musical instruments sale. Its price, US$2,728,000 including the Christie's commission, far outdid its estimated value: $1 million to $1.5 million. On 14 October 2010, a 1697 Stradivari violin known as "The Molitor" was sold online by Tarisio Auctions for a world-record price of $3,600,000 to renowned concert violinist Anne Akiko Meyers: at the time its price was the highest for any musical instrument sold at auction. On 21 June 2011, a 1721 Stradivari violin known as "Lady Blunt" was auctioned by Tarisio to an anonymous bidder for £9,808,000 with all proceeds going to help the victims of the Japan earthquake. This was over four times the previous auction record for a Stradivari violin. The Baron von der Leyen Strad was auctioned by Tarisio on 26 April 2012, for $2.6 million.
Publicly displayed collections of Stradivari instruments are those of the Library of Congress with three violins, a viola, and a cello, the Agency of National Estates of Spain, with a quartet of two violins, the "Spanish I and II", the "Spanish Court" cello, and the "Spanish Court" viola, exhibited in the Music Museum at the Royal Palace of Madrid (Palacio Real de Madrid]] and the Royal Academy of Music's Collections with several instruments by Antonio Stradivari, including the "Joachim" (1698), "Rutson" (1694), the "Crespi" (1699), "Viotti ex-Bruce" (1709), "Kustendyke" (1699), "Maurin" (1718) and the "Ex Back" (1666) violins, "Ex Kux" (1714), and the "Archinto" (1696) violas, the "Marquis de Corberon" (1726) and the "Markevitch" (1709) celli. The Musée de la musique in Paris displays several beautiful Stradivari instruments that formerly belonged to the Paris Conservatory.
The collection of The New Jersey Symphony Orchestra had the largest number of Stradivari in its string section, purchased in 2003 from the collection of Herbert R. Axelrod, until it recently decided to sell them off. A collection assembled by Rodman Wanamaker in the 1920s contained as many as 65 stringed instruments by such masters as Stradivari, Gofriller, Baptiste and Giuseppe Guarneri. Included was "The Swan", the last violin made by Stradivari, and soloist instrument of the great Cuban 19th-century virtuoso Joseph White. The collection, known as The Cappella, was used in concerts with the Philadelphia Orchestra and Leopold Stokowski before being dispersed after Wanamaker's death. The Vienna Philharmonic uses four violins and one cello. The Metropolitan Museum of Art has three Stradivari violins dated 1693, 1694 and 1717. The National Music Museum, in Vermillion, South Dakota, has in its collection one of two known Stradivari guitars, one of eleven known violas da gamba, later modified into a cello form, one of two known choral mandolins, and one of six Stradivari violins that still retain their original neck. In the interests of conservation, the "Messiah Stradivarius" violin—on display in the Ashmolean Museum in Oxford, England—has not been played at all in recent years.
In fiction.
There are numerous references to Stradivari violins in fiction, including:
Literature
Television
Film
Video games
References.
Notes
Sources

</doc>
<doc id="56458" url="https://en.wikipedia.org/wiki?curid=56458" title="Apraxia">
Apraxia

Apraxia is a motor disorder caused by damage to the brain (specifically the posterior parietal cortex), in which someone has difficulty with the motor planning to perform tasks or movements when asked, provided that the request or command is understood and he/she is willing to perform the task. A person with apraxia cannot move his or her lips or tongue to the right place to say sounds correctly because, even though the muscles are not weak, the message from the brain to the mouth are disrupted. The nature of the brain damage determines the severity. Apraxia is an acquired disorder of motor planning, but is not caused by incoordination, sensory loss, or failure to comprehend simple commands (which can be tested by asking the person to recognize the correct movement from a series). It is caused by damage to specific areas of the cerebrum. Apraxia should not be confused with ataxia, a lack of coordination of movements; aphasia, an inability to produce and/or comprehend language; abulia, the lack of desire to carry out an action; or allochiria, in which patients perceive stimuli to one side of the body as occurring on the other. Developmental coordination disorder is the developmental disorder of motor planning.
Types.
There are several types of apraxia including:
Each type may be tested at decreasing levels of complexity; if the person tested fails to execute the commands, you can make the movement yourself and ask that the person mimic it, or you can even give them a real object (like a toothbrush) and ask them to use it. 
Apraxia of speech.
Apraxia of speech (AOS) is a neurologic speech disorder that reflects an impaired capacity to plan or program sensorimotor commands necessary for directing movements that result in phonetically and prosodically normal speech. It occurs in both children (childhood apraxia of speech) and adults (acquired apraxia of speech) who have (prior to the onset of apraxia) acquired some level of speaking ability. AOS affects an individual's volitional speech and is typically the result of a stroke, tumor, or other known neurological illness or injury. Apraxia may be accompanied by a language disorder called aphasia.
Symptoms of AOS include inconsistent articulatory errors, groping oral movements to locate the correct articulatory position, and increasing errors with increasing word and phrase length. Individuals with apraxia of speech know what words they want to say, but their brains have difficulty coordinating the muscle movements necessary to say all the sounds in the words. Patients with apraxia find that vowels are easier to produce than consonants. Single consonants are easier than blends. As in stuttering, final consonants are easier than those in the initial position. This may occur because initial consonants are affected by anticipatory errors. Also, perhaps once a person with apraxia begins speech with the production of a vowel, production continues in a more automatic fashion. Fricatives and affricates are the most difficult phonemes for apraxics to produce. AOS often co-occurs with Oral Apraxia, which is the inability to perform volitional tasks with the oral structures not involving speech. Some of these tasks might include coughing, puckering the lips, and smiling. AOS also often co-occurs with Limb Apraxia.
Developmental verbal dyspraxia presents in children who have no evidence of difficulty with strength or range of motion of the articulators, but are unable to execute speech movements because of motor planning and coordination problems.
Causes.
Apraxia is most often due to a lesion located in the dominant (usually left) hemisphere of the brain, typically in the frontal and parietal lobes. Lesions may be due to stroke, acquired brain injuries, or neurodegenerative diseases such as Alzheimer's disease or other dementias, Parkinson's disease, or Huntington's disease. It is also possible for apraxia to be caused by lesions in other areas of the brain including the non-dominant (usually right) hemisphere.
Ideomotor apraxia is typically due to a decrease in blood flow to the dominant hemisphere of the brain and particularly the parietal and premotor areas. It is frequently seen in patients with corticobasal degeneration.
Ideational apraxia often results in functional impairments in activities of daily living (ADLs) similar to those seen with late stage dementia. More recently, it has been observed in patients with lesions in the dominant hemisphere near areas associated with aphasia; however, more research is needed on ideational apraxia due to brain lesions. The localization of lesions in areas of the frontal and temporal lobes would provide explanation for the difficulty in motor planning seen in ideational apraxia as well as its difficulty to distinguish it from certain aphasias.
Constructional apraxia is often caused by lesions of the inferior non-dominant parietal lobe, and can be caused by brain injury, illness, tumor or other condition that can result in a brain lesion.
Diagnosis.
Although qualitative and quantitative studies exist, there is little consensus on the proper method to assess for apraxia. The criticisms of past methods include failure to meet standard psychometric properties as well as research-specific designs that translate poorly to non-research use.
The Test to Measure Upper Limb Apraxia (TULIA) is one method of determining upper limb apraxia through the qualitative and quantitative assessment of gesture production. In contrast to previous publications on apraxic assessment, the reliability and validity of TULIA was thoroughly investigated. The TULIA consists of subtests for the imitation and pantomime of non-symbolic (“put your index finger on top of your nose”), intransitive (“wave goodbye”) and transitive (“show me how to use a hammer”) gestures. Discrimination (differentiating between well- and poorly performed tasks) and recognition (indicating which object corresponds to a pantomimed gesture) tasks are also often tested for a full apraxia evaluation.
However, there may not be a strong correlation between formal test results and actual performance in everyday functioning or activities of daily living (ADLs). A comprehensive assessment of apraxia should include formal testing, standardized measurements of ADLs, observation of daily routines, self-report questionnaires and targeted interviews with the patients and their relatives.
As stated above, apraxia should not be confused with aphasia, however they are frequently accompanied with each other. It has been stated that apraxia is so often accompanied by aphasia that many believe that if a person displays AOS; it should be assumed that the patient also has some level of aphasia.
Treatment.
Treatment for individuals with apraxia includes speech therapy, occupational therapy, and physical therapy.
Yet, treatments for apraxia have received little attention for several reasons, including the tendency for the condition to resolve spontaneously in acute cases. Additionally, the very nature of the automatic-voluntary dissociation of motor abilities that defines apraxia means that patients may still be able to automatically perform activities if cued to do so in daily life. Nevertheless, research shows that patients experiencing apraxia have less functional independence in their daily lives, and that evidence for the treatment of apraxia is scarce. However, a literature review of apraxia treatment to date reveals that although the field is in its early stages of treatment design, certain aspects can be included to treat apraxia. One method is through rehabilitative treatment, which has been found to positively impact apraxia, as well as activities of daily living. In this review, rehabilitative treatment consisted of 12 different contextual cues, which were used in order to teach patients how to produce the same gesture under different contextual situations. Additional studies have also recommended varying forms of gesture therapy, whereby the patient is instructed to make gestures (either using objects or symbolically meaningful and non-meaningful gestures) with progressively less cuing from the therapist. It may be necessary for patients with apraxia to use a form of alternative and augmentative communication depending on the severity of the disorder. In addition to using gestures as mentioned, patients can also use communication boards or more sophisticated electronic devices if needed. No single type of therapy or approach has been proven as the best way to treat a patient with apraxia, since each patient's case varies. However, one-on-one sessions usually work the best, with the support of family members and friends. Since everyone responds to therapy differently, some patients will make significant improvements, while others will make less progress. The overall goal for treatment of apraxia is to treat the motor plans for speech, not treating at the phoneme (sound) level.
Prognosis.
The prognosis for individuals with apraxia varies. With therapy, some patients improve significantly, while others may show very little improvement. Some individuals with apraxia may benefit from the use of a communication aid.
However, many people with apraxia are no longer able to be independent. Those with limb-kinetic and/or gait apraxia should avoid activities in which they might injure themselves or others.
Occupational therapy, physical therapy, and play therapy may be considered as other references to support patients with apraxia. These team members could be work along with the SLP to provide the best therapy for people with apraxia. However, because people with limb apraxia may have trouble directing their motor movements, occupational therapy for stroke or other brain injury can be difficult.
No drug has been shown useful for treating apraxia.

</doc>
<doc id="56461" url="https://en.wikipedia.org/wiki?curid=56461" title="Canavan disease">
Canavan disease

Canavan disease, also called Canavan-Van Bogaert-Bertrand disease is an autosomal recessive degenerative disorder that causes progressive damage to nerve cells in the brain, and is one of the most common degenerative cerebral diseases of infancy. It is caused by a deficiency of the enzyme aminoacylase 2, and is one of a group of genetic diseases referred to as a leukodystrophies. It is characterized by degeneration of myelin in the phospholipid layer insulating the axon of a neuron and is associated with a gene located on human chromosome 17.
Prevalence.
Although Canavan disease may occur in any ethnic group, it affects people of Eastern European Jewish ancestry more frequently. About 1 in 40 (2.5%) individuals of Eastern European (Ashkenazi) Jewish ancestry are carriers.
Pathophysiology.
Canavan disease is inherited in an autosomal recessive fashion. When both parents are carriers, there is a 25% chance of having an affected child. Genetic counseling and genetic testing is recommended for families with two parental carriers.
Canavan disease is caused by a defective "ASPA" gene which is responsible for the production of the enzyme aspartoacylase. Decreased aspartoacylase activity prevents the normal breakdown of "N"-acetyl aspartate, wherein the accumulation of N-acetylaspartate, or lack of its further metabolism interferes with growth of the myelin sheath of the nerve fibers of the brain. The myelin sheath is the fatty covering that surrounds nerve cells and acts as an insulator, which allows for efficient transmission of nerve impulses.
Symptoms.
Symptoms of Canavan disease, which appear in early infancy and progress rapidly, may include intellectual disability, loss of previously acquired motor skills, feeding difficulties, abnormal muscle tone (i.e., floppiness or stiffness), poor head control, and megalocephaly (abnormally enlarged head). Paralysis, blindness, or seizures may also occur.
Treatment.
There is no cure for Canavan disease, nor is there a standard course of treatment. Treatment is symptomatic and supportive. There is also an experimental treatment using lithium citrate. When a person has Canavan disease, his or her levels of N-acetyl aspartate are chronically elevated. The lithium citrate has proven in a rat genetic model of Canavan disease to be able to significantly decrease levels of N-acetyl aspartate. When tested on a human, the subject reversed during a two-week wash-out period after withdrawal of lithium.
The investigation revealed both decreased N-acetyl aspartate levels in regions of the brain tested and magnetic resonance spectroscopic values that are more characteristic of normal development and myelination. This evidence suggests that a larger controlled trial of lithium may be warranted as supportive therapy for children with Canavan disease.
In addition there are experimental trials of gene therapy, published in 2002, involving using a healthy gene to take over for the defective one that causes Canavan disease.
In human trials, the results of which were published in 2012, this method appeared to improve the life of the patient without long-term adverse effects during a 5-year follow-up.
Prognosis.
Death usually occurs before age ten, but some children with milder forms of the disease survive into their teens and twenties.
Current research.
Research involving triacetin supplementation has shown promise in a rat model. Triacetin, which can be enzymatically cleaved to form acetate, enters the brain more readily than the negatively charged acetate. The defective enzyme in Canavan disease, aspartoacylase, converts N-acetylaspartate into aspartate and acetate. Mutations in the gene for aspartoacylase prevent the breakdown of N-acetylaspartate, and reduce brain acetate availability during brain development. Acetate supplementation using Triacetin is meant to provide the missing acetate so that brain development can continue normally.
A team of researchers headed by Paola Leone are currently at the University of Medicine and Dentistry of New Jersey, in Stratford, New Jersey. The brain gene therapy is conducted at Cooper University Hospital. The procedure involves the insertion of six (6) catheters into the brain that deliver a solution containing 600 billion to 900 billion engineered virus particles. The virus, a modified version of AAV, is designed to replace the aspartoacylase enzyme. Children treated with this procedure to date have shown marked improvements, including the growth of myelin with decreased levels of the n-acetyl-aspartate toxin.
History.
Canavan disease was first described in 1931 by Myrtelle Canavan.
Greenberg v. Miami Children's Hospital Research Institute.
The discovery of the gene for Canavan disease, and subsequent events, generated considerable controversy. In 1987 the Greenbergs, a family with two children affected by Canavan disease, donated tissue samples to Reuben Matalon, a researcher at the University of Chicago who was looking for the Canavan gene. He successfully identified the gene in 1993 and developed a test for it that would enable antenatal (before birth) counseling of couples at risk of having a child with the disease. For a while, the Canavan Foundation offered free genetic testing with the test.
However, in 1997, after relocating to Florida, Matalon's employer, Miami Children's Hospital, patented the gene and started claiming royalties on the genetic test, forcing the Canavan Foundation to withdraw their testing. A subsequent lawsuit brought by the Canavan Foundation against Miami Children's Hospital, and was resolved with a sealed out-of-court settlement. The case is sometimes cited in arguments about the appropriateness of patenting genes.

</doc>
<doc id="56462" url="https://en.wikipedia.org/wiki?curid=56462" title="Carpal tunnel syndrome">
Carpal tunnel syndrome

Carpal tunnel syndrome (CTS) is a medical condition due to compression of the median nerve as it travels through the wrist at the carpal tunnel. The main symptoms are pain, numbness and tingling, in the thumb, index finger, middle finger, and the thumb side of the ring fingers. Symptoms typically start gradually and during the night. Pain may extend up the arm. Weak grip strength may occur and after a long period of time the muscles at the base of the thumb may waste away. In more than half of cases both sides are affected.
Risk factors include obesity, repetitive wrist work, pregnancy, and rheumatoid arthritis. There is tentative evidence that hypothyroidism increases the risk. It is unclear if diabetes plays a role. --> The use of birth control pills does not affect the risk. --> Types of work that are associated include computer work, work with vibrating tools, and work that requires a strong grip. Diagnosis is suspected based on sign, symptoms, and specific physical tests and may be confirmed with electrodiagnostic tests. If muscle wasting at the base of the thumb is present the diagnosis is likely.
Being physically active can decrease the risk of developing CTS. --> Symptoms can be improved by wearing a wrist splint or with corticosteroid injections. --> Taking NSAIDs or gabapentin does not appear to be useful. --> Surgery to cut the transverse carpal ligament is effective with better results at a year compared to non surgical options. --> Further splinting after surgery is not needed. --> Evidence does not support magnet therapy.
About 5% of people in the United States have carpal tunnel syndrome. It usually begins in adulthood and women are more commonly affected than men. Up to 33% of people may improve without specific treatment over approximately a year. Carpal tunnel syndrome was first fully described after World War II.
Signs and symptoms.
Some suggest that median nerve symptoms can arise from compression at the level of the thoracic outlet or the area where the median nerve passes between the two heads of the pronator teres in the forearm, although this is debated.
Numbness and paresthesias in the median nerve distribution are the hallmark neuropathic symptoms (NS) of carpal tunnel entrapment syndrome. Weakness and atrophy of the thumb muscles may occur if the condition remains untreated, because the muscles are not receiving sufficient nerve stimulation. Discomfort is usually worse at night and in the morning.
Causes.
Most cases of CTS are of unknown cause. Carpal tunnel syndrome can be associated with any condition that causes pressure on the median nerve at the wrist. Some common conditions that can lead to CTS include obesity, oral contraceptives, hypothyroidism, arthritis, diabetes, prediabetes (impaired glucose tolerance), and trauma. Carpal tunnel is also a feature of a form of Charcot-Marie-Tooth syndrome type 1 called hereditary neuropathy with liability to pressure palsies.
Other causes of this condition include intrinsic factors that exert pressure within the tunnel, and extrinsic factors (pressure exerted from outside the tunnel), which include benign tumors such as lipomas, ganglion, and vascular malformation. Carpal tunnel syndrome often is a symptom of transthyretin amyloidosis-associated polyneuropathy and prior carpal tunnel syndrome surgery is very common in individuals who later present with transthyretin amyloid-associated cardiomyopathy, suggesting that transthyretin amyloid deposition may cause carpal tunnel syndrome.
The median nerve can usually move up to 9.6 mm to allow the wrist to flex, and to a lesser extent during extension. Long-term compression of the median nerve can inhibit nerve gliding, which may lead to injury and scarring. When scarring occurs, the nerve will adhere to the tissue around it and become locked into a fixed position, so that less movement is apparent.
Normal pressure of the carpal tunnel has been defined as a range of 2–10 mm, and wrist flexion increases this pressure 8-fold, while extension increases it 10-fold. Repetitive flexion and extension in the wrist significantly increase the fluid pressure in the tunnel through thickening of the synovial tissue that lines the tendons within the carpal tunnel.
Work related.
The international debate regarding the relationship between CTS and repetitive motion in work is ongoing. The Occupational Safety and Health Administration (OSHA) has adopted rules and regulations regarding cumulative trauma disorders. Occupational risk factors of repetitive tasks, force, posture, and vibration have been cited. 
The relationship between work and CTS is controversial; in many locations, workers diagnosed with carpal tunnel syndrome are entitled to time off and compensation.
Some speculate that carpal tunnel syndrome is provoked by repetitive movement and manipulating activities and that the exposure can be cumulative. It has also been stated that symptoms are commonly exacerbated by forceful and repetitive use of the hand and wrists in industrial occupations, but it is unclear as to whether this refers to pain (which may not be due to carpal tunnel syndrome) or the more typical numbness symptoms.
A review of available scientific data by the National Institute for Occupational Safety and Health (NIOSH) indicated that job tasks that involve highly repetitive manual acts or specific wrist postures were associated with incidents of CTS, but causation was not established, and the distinction from work-related arm pains that are not carpal tunnel syndrome was not clear. It has been proposed that repetitive use of the arm can affect the biomechanics of the upper limb or cause damage to tissues. It has also been proposed that postural and spinal assessment along with ergonomic assessments should be included in the overall determination of the condition. Addressing these factors has been found to improve comfort in some studies. A 2010 survey by NIOSH showed that 2/3 of the 5 million carpal tunnel cases in the US that year were related to work. Women have more work-related carpal tunnel syndrome than men.
Speculation that CTS is work-related is based on claims such as CTS being found mostly in the working adult population, though evidence is lacking for this. For instance, in one recent representative series of a consecutive experience, most patients were older and not working. Based on the claimed increased incidence in the workplace, arm use is implicated, but the weight of evidence suggests that this is an inherent, genetic, slowly but inevitably progressive idiopathic peripheral mononeuropathy.
Genetics.
Genetics play a role.
Associated conditions.
A variety of patient factors can lead to CTS, including heredity, size of the carpal tunnel, associated local and systematic diseases, and certain habits. Non-traumatic causes generally happen over a period of time, and are not triggered by one certain event. Many of these factors are manifestations of physiologic aging.
Examples include:
Diagnosis.
There is no consensus reference standard for the diagnosis of carpal tunnel syndrome. A combination of described symptoms, clinical findings, and electrophysiological testing may be used. CTS work up is the most common referral to the electrodiagnostic lab. Historically, diagnosis has been made with the combination of a thorough history and physical examination in conjunction with the use of electrodiagnostic (EDX) testing for confirmation. Additionally, evolving technology has included the use of ultrasonography in the diagnosis of CTS. However, it is well established that physical exam provocative maneuvers lack both sensitivity and specificity. Furthermore, EDX cannot fully exclude the diagnosis of CTS due to the lack of sensitivity. A Joint report published by the American Association of Neuromuscular and Electrodiagostic Medicine (AANEM), the American Academy of Physical Medicine and Rehabilitation (AAPM&R) and the American Academy of Neurology defines practice parameters, standards and guidelines for EDX studies of CTS based on an extensive critical literature review. This joint review concluded median and sensory nerve conduction studies are valid and reproducible in a clinical laboratory setting and a clinical diagnosis of CTS can be made with a sensitivity greater than 85% and specificity greater than 95%. Given the key role of electrodiagnostic testing in the diagnosis of CTS, The American Association of Neuromuscular & Electrodiagnostic Medicine has issued evidence-based practice guidelines, both for the diagnosis of carpal tunnel syndrome.
Numbness in the distribution of the median nerve, nocturnal symptoms, thenar muscle weakness/atrophy, positive Tinel's sign at the carpal tunnel, and abnormal sensory testing such as two-point discrimination have been standardized as clinical diagnostic criteria by consensus panels of experts. Pain may also be a presenting symptom, although less common than sensory disturbances.
Electrodiagnostic testing (electromyography and nerve conduction velocity) can objectively verify the median nerve dysfunction. Normal nerve conduction studies, however, do not exclude the diagnosis of CTS. Clinical assessment by history taking and physical examination can support a diagnosis of CTS. If clinical suspicion of CTS is high, treatment should be initiated despite normal electrodiagnostic testing.
Physical exam.
The use of Phalen test, Tinel sign, Flick sign, or upper limb nerve test alone is not sufficient for diagnosis.
As a note, a patient with true carpal tunnel syndrome (entrapment of the median nerve within the carpal tunnel) will not have any sensory loss over the thenar eminence (bulge of muscles in the palm of hand and at the base of the thumb). This is because the palmar branch of the median nerve, which innervates that area of the palm, branches off of the median nerve and passes over the carpal tunnel. This feature of the median nerve can help separate carpal tunnel syndrome from thoracic outlet syndrome, or pronator teres syndrome.
Other conditions may also be misdiagnosed as carpal tunnel syndrome. Thus, if history and physical examination suggest CTS, patients will sometimes be tested electrodiagnostically with nerve conduction studies and electromyography. The goal of electrodiagnostic testing is to compare the speed of conduction in the median nerve with conduction in other nerves supplying the hand. When the median nerve is compressed, as in CTS, it will conduct more slowly than normal and more slowly than other nerves. There are many electrodiagnostic tests used to make a diagnosis of CTS, but the most sensitive, specific, and reliable test is the Combined Sensory Index (also known as Robinson index). Electrodiagnosis rests upon demonstrating impaired median nerve conduction across the carpal tunnel in context of normal conduction elsewhere. Compression results in damage to the myelin sheath and manifests as delayed latencies and slowed conduction velocities However, normal electrodiagnostic studies do not preclude the presence of carpal tunnel syndrome, as a threshold of nerve injury must be reached before study results become abnormal and cut-off values for abnormality are variable. Carpal tunnel syndrome with normal electrodiagnostic tests is very, very mild at worst.
The role of MRI or ultrasound imaging in the diagnosis of carpal tunnel syndrome is unclear. There routine use is not recommended.
Differential diagnosis.
Carpal tunnel syndrome is sometimes applied as a label to anyone with pain, numbness, swelling, and/or burning in the radial side of the hands and/or wrists. When pain is the primary symptom, carpal tunnel syndrome is unlikely to be the source of the symptoms. As a whole, the medical community is not currently embracing or accepting trigger point theories due to lack of scientific evidence supporting their effectiveness.
Pathophysiology.
The carpal tunnel is an anatomical compartment located at the base of the palm. Nine flexor tendons and the median nerve pass through the carpal tunnel that is surrounded on three sides by the carpal bones that form an arch. The median nerve provides feeling or sensation to the thumb, index finger, long finger, and half of the ring finger. At the level of the wrist, the median nerve supplies the muscles at the base of the thumb that allow it to abduct, move away from the other four fingers, as well as move out of the plane of the palm. The carpal tunnel is located at the middle third of the base of the palm, bounded by the bony prominence of the scaphoid tubercle and trapezium at the base of the thumb, and the hamate hook that can be palpated along the axis of the ring finger. From the anatomical position, the carpal tunnel is bordered on the anterior surface by the transverse carpal ligament, also known as the flexor retinaculum. The flexor retinaculum is a strong, fibrous band that attaches to the pisiform and the hamulus of the hamate. The proximal boundary is the distal wrist skin crease, and the distal boundary is approximated by a line known as Kaplan's cardinal line. This line uses surface landmarks, and is drawn between the apex of the skin fold between the thumb and index finger to the palpated hamate hook.
The median nerve can be compressed by a decrease in the size of the canal, an increase in the size of the contents (such as the swelling of lubrication tissue around the flexor tendons), or both. Since the carpal tunnel is bordered by carpal bones on one side and a ligament on the other, when the pressure builds up inside the tunnel, there is nowhere for it to escape and thus it ends up pressing up against and damaging the median nerve. Simply flexing the wrist to 90 degrees will decrease the size of the canal.
Compression of the median nerve as it runs deep to the transverse carpal ligament (TCL) causes atrophy of the thenar eminence, weakness of the flexor pollicis brevis, opponens pollicis, abductor pollicis brevis, as well as sensory loss in the digits supplied by the median nerve. The superficial sensory branch of the median nerve, which provides sensation to the base of the palm, branches proximal to the TCL and travels superficial to it. Thus, this branch spared in carpal tunnel syndrome, and there is no loss of palmar sensation.
Prevention.
Suggested healthy habits such as avoiding repetitive stress, work modification through use of ergonomic equipment (wrist rest, mouse pad), taking proper breaks, using keyboard alternatives (digital pen, voice recognition, and dictation), and have been proposed as methods to help prevent carpal tunnel syndrome. The potential role of B-vitamins in preventing or treating carpal tunnel syndrome has not been proven.
There is little or no data to support the concept that activity adjustment prevents carpal tunnel syndrome.
Stretches and isometric exercises will aid in prevention for persons at risk. Stretching before the activity and during breaks will aid in alleviating tension at the wrist. Place the hand firmly on a flat surface and gently pressing for a few seconds to stretch the wrist and fingers. An example for an isometric exercise of the wrist is done by clenching the fist tightly, releasing and fanning out fingers. None of these stretches or exercises should cause pain or discomfort.
Biological factors such as genetic predisposition and anthropometric features had significantly stronger causal association with carpal tunnel syndrome than occupational/environmental factors such as repetitive hand use and stressful manual work. This suggests that carpal tunnel syndrome might not be preventable simply by avoiding certain activities or types of work/activities.
Treatment.
Generally accepted treatments include: physiotherapy, steroids either orally or injected locally, splinting, and surgical release of the transverse carpal ligament. There is insufficient evidence for ultrasound, yoga, lasers, vitamin B6, and exercise. Change in activity may include avoiding activities that worsen symptoms.
The American Academy of Orthopedic Surgeons recommends proceeding conservatively with a course of nonsurgical therapies tried before release surgery is considered. A different treatment should be tried if the current treatment fails to resolve the symptoms within 2 to 7 weeks. Early surgery with carpal tunnel release is indicated where there is evidence of median nerve denervation or a person elects to proceed directly to surgical treatment.Recommendations may differ when carpal tunnel syndrome is found in association with the following conditions: diabetes mellitus, coexistent cervical radiculopathy, hypothyroidism, polyneuropathy, pregnancy, rheumatoid arthritis, and carpal tunnel syndrome in the workplace.
Splints.
The importance of wrist braces and splints in the carpal tunnel syndrome therapy is known, but many people are unwilling to use braces. In 1993, The American Academy of Neurology recommend a non-invasive treatment for the CTS at the beginning (except for sensitive or motor deficit or grave report at EMG/ENG): a therapy using splints was indicated for light and moderate pathology. Current recommendations generally don't suggest immobilizing braces, but instead activity modification and non-steroidal anti-inflammatory drugs as initial therapy, followed by more aggressive options or specialist referral if symptoms do not improve.
Many health professionals suggest that, for the best results, one should wear braces at night and, if possible, during the activity primarily causing stress on the wrists.
Corticosteroids.
Corticosteroid injections can be effective for temporary relief from symptoms while a person develops a long-term strategy that fits their lifestyle. The injections are done under local anæsthesia. This treatment is not appropriate for extended periods, however. In general, local steroid injections are only used until other treatment options can be identified.
Surgery.
Release of the transverse carpal ligament is known as "carpal tunnel release" surgery. It is recommended when there is static (constant, not just intermittent) numbness, muscle weakness, or atrophy, and when night-splinting or other conservative interventions no longer control intermittent symptoms. The surgery may be done with local or regional anesthesia with or without sedation, or under general anesthesia. In general, milder cases can be controlled for months to years, but severe cases are unrelenting symptomatically and are likely to result in surgical treatment. 
Surgery is more beneficial in the short term to alleviate symptoms (up to six months) than wearing an orthosis for a minimum of 6 weeks. However, surgery and wearing a brace resulted in similar symptom relief in the long term (12-18 month outcomes).
Physical therapy.
A recent evidence based guideline produced by the American Academy of Orthopedic Surgeons assigned various grades of recommendation to physiotherapy (also called physical therapy) and other nonsurgical treatments. One of the primary issues with physiotherapy is that it attempts to reverse (often) years of pathology inside the carpal tunnel. Practitioners caution that any physiotherapy such as myofascial release may take weeks of persistent application to effectively manage carpal tunnel syndrome.
Again, some claim that pro-active ways to reduce stress on the wrists, which alleviates wrist pain and strain, involve adopting a more ergonomic work and life environment. For example, some have claimed that switching from a QWERTY computer keyboard layout to a more optimised ergonomic layout such as Dvorak was commonly cited as beneficial in early CTS studies, however some meta-analyses of these studies claim that the evidence that they present is limited.
Prognosis.
Most people relieved of their carpal tunnel symptoms with conservative or surgical management find minimal residual or "nerve damage". Long-term chronic carpal tunnel syndrome (typically seen in the elderly) can result in permanent "nerve damage", i.e. irreversible numbness, muscle wasting, and weakness. Those that undergo a carpal tunnel release are nearly twice as likely as those not having surgery to develop trigger thumb in the months following the procedure.
While outcomes are generally good, certain factors can contribute to poorer results that have little to do with nerves, anatomy, or surgery type. One study showed that mental status parameters or alcohol use yields much poorer overall results of treatment.
Recurrence of carpal tunnel syndrome after successful surgery is rare. If a person has hand pain after surgery, it is most likely not caused by carpal tunnel syndrome. It may be the case that the illness of a person with hand pain after carpal tunnel release was diagnosed incorrectly, such that the carpal tunnel release has had no positive effect upon the patient's symptoms.
Epidemiology.
Carpal tunnel syndrome can affect anyone. It accounts for about 90% of all nerve compression syndromes. In the U.S., 5% of people have the effects of carpal tunnel syndrome. Caucasians have the highest risk of CTS compared with other races such as non-white South Africans. Women suffer more from CTS than men with a ratio of 3:1 between the ages of 45–60 years. Only 10% of reported cases of CTS are younger than 30 years. Increasing age is a risk factor. CTS is also common in pregnancy.
Occupational.
As of 2010, 8% of U.S. workers reported ever having carpal tunnel syndrome and 4% reported carpal tunnel syndrome in the past 12 months. Prevalence rates for carpal tunnel syndrome in the past 12 months were higher among females than among males; among workers aged 45–64 than among those aged 18–44. Overall, 67% of current carpal tunnel syndrome cases among current/recent workers were reportedly attributed to work by health professionals, indicating that the prevalence rate of work-related carpal tunnel syndrome among workers was 2%, and that there were approximately 3.1 million cases of work-related carpal tunnel syndrome among U.S. workers in 2010. Among current carpal tunnel syndrome cases attributed to specific jobs, 24% were attributed to jobs in the manufacturing industry, a proportion 2.5 times higher than the proportion of current/recent workers employed in the manufacturing industry, suggesting that jobs in this industry are associated with an increased risk of work-related carpal tunnel syndrome.
History.
The condition known as carpal tunnel syndrome had major appearances throughout the years but it was most commonly heard of in the years following World War II. Individuals who had suffered from this condition have been depicted in surgical literature for the mid-19th century. In 1854, Sir James Paget was the first to report median nerve compression at the wrist in a distal radius fracture. Following the early 20th century there were various cases of median nerve compression underneath the transverse carpal ligament. Carpal Tunnel Syndrome was most commonly noted in medical literature in the early 20th century but the first use of the term was noted 1939. Physician Dr. George S. Phalen of the Cleveland Clinic identified the pathology after working with a group of patients in the 1950s and 1960s.

</doc>
<doc id="56464" url="https://en.wikipedia.org/wiki?curid=56464" title="Joubert syndrome">
Joubert syndrome

Joubert syndrome is a rare genetic disorder that affects the cerebellum, an area of the brain that controls balance and coordination.
Diagnosis.
The disorder is characterized by absence or underdevelopment of the cerebellar vermis and a malformed brain stem (molar tooth sign). The most common features include ataxia (lack of muscle control), hyperpnea (abnormal breathing patterns), sleep apnea, abnormal eye and tongue movements, and hypotonia. Other malformations such as extra fingers and toes, cleft lip or palate, tongue abnormalities, and seizures may also occur. There may be mild or moderate intellectual disabilities. Joubert syndrome is one of the many genetic syndromes associated with syndromic retinitis pigmentosa. The syndrome was first identified by pioneering pediatric neurologist Marie Joubert in Montreal, Canada, while working at the Montreal Neurological Institute and McGill University.
Treatment.
Treatment for Joubert syndrome is symptomatic and supportive. Infant stimulation and physical, occupational, speech and hearing therapy may benefit some patients. Infants with abnormal breathing patterns should be monitored.
Prognosis.
The prognosis for individuals with Joubert syndrome varies. Some patients have a mild form with minimal motor disability and good mental development, while others may have severe motor disability and moderate mental developmental delays.
Genetics.
A number of mutations have been identified in individuals with Joubert syndrome (JBTS) which allowed for classification of the disorder into subtypes.
Ciliopathy.
Research has revealed that a number of genetic disorders, not previously thought to be related, may indeed be related as to their root cause. Joubert syndrome is one such disease. It is a member of an emerging class of diseases called ciliopathies.
The underlying cause of the ciliopathies may be a dysfunctional molecular mechanism in the primary cilia structures of the cell, organelles which are present in many cellular types throughout the human body. The cilia defects adversely affect "numerous critical developmental signaling pathways" essential to cellular development and thus offer a plausible hypothesis for the often multi-symptom nature of a large set of syndromes and diseases.
Currently recognized ciliopathies include Joubert syndrome, primary ciliary dyskinesia (also known as Kartagener Syndrome), Bardet-Biedl syndrome, polycystic kidney disease and polycystic liver disease, nephronophthisis, Alstrom syndrome, Meckel-Gruber syndrome and some forms of retinal degeneration.

</doc>
<doc id="56465" url="https://en.wikipedia.org/wiki?curid=56465" title="Cassava">
Cassava

Manihot esculenta (commonly called cassava (), Brazilian arrowroot, manioc, tapioca, and yuca) is a woody shrub native to South America of the spurge family, Euphorbiaceae. It is extensively cultivated as an annual crop in tropical and subtropical regions for its edible starchy tuberous root, a major source of carbohydrates. Though it is often called yuca in Spanish and in the United States, it differs from the yucca, an unrelated fruit-bearing shrub in the family Asparagaceae. Cassava, when dried to a powdery (or pearly) extract, is called "tapioca"; its fermented, flaky version is named "garri".
Cassava is the third largest source of food carbohydrates in the tropics, after rice and maize. Cassava is a major staple food in the developing world, providing a basic diet for over half a billion people. It is one of the most drought-tolerant crops, capable of growing on marginal soils. Nigeria is the world's largest producer of cassava, while Thailand is the largest exporter of dried cassava.
Cassava is classified as either sweet or bitter. Like other roots and tubers, both bitter and sweet varieties of cassava contain antinutritional factors and toxins, with the bitter varieties containing much larger amounts. They must be properly prepared before consumption, as improper preparation of cassava can leave enough residual cyanide to cause acute cyanide intoxication, goiters, and even ataxia or partial paralysis. The more toxic varieties of cassava are a fall-back resource (a "food security crop") in times of famine in some places. Farmers often prefer the bitter varieties because they deter pests, animals, and thieves.
Description.
The cassava root is long and tapered, with a firm, homogeneous flesh encased in a detachable rind, about 1 mm thick, rough and brown on the outside. Commercial varieties can be in diameter at the top, and around long. A woody vascular bundle runs along the root's axis. The flesh can be chalk-white or yellowish. Cassava roots are very rich in starch and contain significant amounts of calcium (50 mg/100g), phosphorus (40 mg/100g) and vitamin C (25 mg/100g). However, they are poor in protein and other nutrients. In contrast, cassava leaves are a good source of protein (rich in lysine) but deficient in the amino acid methionine and possibly tryptophan.
History.
Wild populations of "M. esculenta" subspecies "flabellifolia", shown to be the progenitor of domesticated cassava, are centered in west-central Brazil, where it was likely first domesticated more than 10,000 years BP. Forms of the modern domesticated species can also be found growing in the wild in the south of Brazil. By 4,600 BC, manioc pollen appears in the Gulf of Mexico lowlands, at the San Andrés archaeological site. The oldest direct evidence of cassava cultivation comes from a 1,400-year-old Maya site, Joya de Cerén, in El Salvador. With its high food potential, it had become a staple food of the native populations of northern South America, southern Mesoamerica, and the Caribbean by the time of the Spanish conquest. Its cultivation was continued by the colonial Portuguese and Spanish.
Cassava was a staple food for pre-Columbian peoples in the Americas and is often portrayed in indigenous art. The Moche people often depicted yuca in their ceramics.
Mass production of Casabe bread became the first Cuban industry established by the Spanish Ships departing to Europe from Cuban ports such as Havana, Santiago, Bayamo and Baracoa not only carried goods to Spain. The Spanish also needed to replenish their boats with dried meat, water, fruit and large amounts of casabe bread [http://www.sjsu.edu/faculty/watkins/havana.htm. Cuban weather was not suitable for wheat planting and casabe would not go stale as quickly as regular bread.
Cassava was introduced to Africa by Portuguese traders from Brazil in the 16th century. Maize and cassava are now important staple foods, replacing native African crops. Cassava is sometimes described as the 'bread of the tropics' but should not be confused with the tropical and equatorial bread tree "(Encephalartos)", the breadfruit "(Artocarpus altilis)" or the African breadfruit "(Treculia africana)".
Economic importance and production.
World production of cassava root was estimated to be 184 million tonnes in 2002, rising to 230 million tonnes in 2008. The majority of production in 2002 was in Africa, where 99.1 million tonnes were grown; 51.5 million tonnes were grown in Asia; and 33.2 million tonnes in Latin America and the Caribbean, specifically Jamaica. Nigeria is the world's largest producer of cassava. However, based on the statistics from the FAO of the United Nations, Thailand is the largest exporting country of dried cassava, with a total of 77% of world export in 2005. The second-largest exporting country is Vietnam, with 13.6%, followed by Indonesia (5.8%) and Costa Rica (2.1%).
In 2010, the average yield of cassava crops worldwide was 12.5 tonnes per hectare. The most productive cassava farms in the world were in India, with a nationwide average yield of 34.8 tonnes per hectare in 2010.
Cassava, yams ("Dioscorea" spp.), and sweet potatoes ("Ipomoea batatas") are important sources of food in the tropics. The cassava plant gives the third-highest yield of carbohydrates per cultivated area among crop plants, after sugarcane and sugar beets. Cassava plays a particularly important role in agriculture in developing countries, especially in sub-Saharan Africa, because it does well on poor soils and with low rainfall, and because it is a perennial that can be harvested as required. Its wide harvesting window allows it to act as a famine reserve and is invaluable in managing labor schedules. It offers flexibility to resource-poor farmers because it serves as either a subsistence or a cash crop.
No continent depends as much on root and tuber crops in feeding its population as does Africa. In the humid and subhumid areas of tropical Africa, it is either a primary staple food or a secondary costaple. In Ghana, for example, cassava and yams occupy an important position in the agricultural economy and contribute about 46% of the agricultural gross domestic product. Cassava accounts for a daily caloric intake of 30% in Ghana and is grown by nearly every farming family. The importance of cassava to many Africans is epitomised in the Ewe (a language spoken in Ghana, Togo and Benin) name for the plant, "agbeli", meaning "there is life". The price of cassava has risen significantly in the last half decade, and lower-income people have turned to other carbohydrate-rich foods, such as rice.
In Tamil Nadu, India, the National Highway 68 between Thalaivasal and Attur has many cassava processing factories alongside it, indicating a local abundance. Cassava is widely cultivated and eaten as a staple food in Andhra Pradesh and in Kerala besides being commonly cultivated and popular in Assam, where it is an important source of carbohydrates especially for natives of hilly areas.
In the subtropical region of southern China, cassava is the fifth-largest crop in term of production, after rice, sweet potato, sugar cane and maize. China is also the largest export market for cassava produced in Vietnam and Thailand. Over 60% of cassava production in China is concentrated in a single province, Guangxi, averaging over 7 million tonnes annually.
According to Food and Agriculture Organization Corporate Statistical Database (FAOSTAT) the top 20 cassava producing countries by year 2012 were as follows:
Uses.
Alcoholic beverages.
Alcoholic beverages made from cassava include Cauim and tiquira (Brazil), kasiri (Sub-Saharan Africa), Impala (Mozambique) masato (Peruvian Amazonia chicha), parakari or kari (Guyana), nihamanchi (South America) aka nijimanche (Ecuador and Peru), ö döi (chicha de yuca, Ngäbe-Bugle, Panama), sakurá (Brazil, Surinam).
Culinary.
Cassava-based dishes are widely consumed wherever the plant is cultivated; some have regional, national, or ethnic importance. Cassava must be cooked properly to detoxify it before it is eaten.
Cassava can be cooked in many ways. The root of the sweet variety has a delicate flavor and can replace potatoes. It is used in cholent in some households. It can be made into a flour that is used in breads, cakes and cookies. In Brazil, detoxified manioc is ground and cooked to a dry, often hard or crunchy meal known as "farofa" used as a condiment, toasted in butter, or eaten alone as a side dish.
Nutritional profile.
Cassava root is essentially a carbohydrate source. Its composition shows 60–65 percent moisture, 20–31 percent carbohydrate, 1–2 percent crude protein and a comparatively low content of vitamins and minerals. However, the roots are rich in calcium and vitamin C and contain a nutritionally significant quantity of thiamine, riboflavin and nicotinic acid. Cassava starch contains 70 percent amylopectin and 20 percent amylose. Cooked cassava starch has a digestibility of over 75 percent.
Cassava root is a poor source of protein. Despite the very low quantity, the quality of cassava root protein is fairly good in terms of essential amino acids. Methionine, cysteine and cystine are, however, limiting amino acids in cassava root.
Cassava is attractive as nutrition source in certain ecosystems because cassava is one of the most drought-tolerant crops, can be successfully grown on marginal soils, and gives reasonable yields where many other crops do not grow well. Cassava is well adapted within latitudes 30° north and south of the equator, at elevations between sea level and above sea level, in equatorial temperatures, with rainfalls of 50 millimeters to annually, and to poor soils with a pH ranging from acidic to alkaline. These conditions are common in certain parts of Africa and South America.
Cassava is a highly productive crop in terms of food calories produced per unit land area per unit of time, significantly higher than other staple crops. Cassava can produce food calories at rates exceeding 250,000 cal/hectare/day compared with 176,000 for rice, 110,000 for wheat, and 200,000 for maize (corn).
Cassava, like other foods, also has antinutritional and toxic factors. Of particular concern are the cyanogenic glucosides of cassava (linamarin and lotaustralin). These, on hydrolysis, release hydrocyanic acid (HCN). The presence of cyanide in cassava is of concern for human and for animal consumption. The concentration of these antinutritional and unsafe glycosides varies considerably between varieties and also with climatic and cultural conditions. Selection of cassava species to be grown, therefore, is quite important. Once harvested, bitter cassava must be treated and prepared properly prior to human or animal consumption, while sweet cassava can be used after simple boiling.
Comparison with other major staple foods.
The following table shows the nutrient content of cassava and compares it with major staple foods in a raw form. Raw forms of these staples, however, are not edible and cannot be digested. These must be sprouted, or prepared and cooked as appropriate for human consumption. In sprouted or cooked form, the relative nutritional and antinutritional contents of each of these grains is remarkably different from that of raw form of these grains reported in this table. The nutrition value for each staple food in cooked form depends on the cooking method (boiling, baking, steaming, frying, etc.).
The table shows that cassava is a good energy source, but like potato, cassava's protein and essential nutrients density is lower than other staple foods.
Biofuel.
In many countries, significant research has begun to evaluate the use of cassava as an ethanol biofuel feedstock. Under the Development Plan for Renewable Energy in the Eleventh Five-Year Plan in the People's Republic of China, the target is to increase the application of ethanol fuel by nongrain feedstock to 2 million tonnes, and that of biodiesel to 200 thousand tonnes by 2010. This will be equivalent to a substitute of 10 million tonnes of petroleum. As a result, cassava (tapioca) chips have gradually become a major source for ethanol production. On December 22, 2007, the largest cassava ethanol fuel production facility was completed in Beihai, with annual output of 200 thousand tons, which would need an average of 1.5 million tons of cassava. In November 2008, China-based Hainan Yedao Group reportedly invested $51.5m (£31.8m) in a new biofuel facility that is expected to produce a year of bioethanol from cassava plants.
Animal feed.
Cassava tubers and hay are used worldwide as animal feed. Cassava hay is harvested at a young growth stage (three to four months) when it reaches about above ground; it is then sun-dried for one to two days until it has final dry matter content of less than 85%. Cassava hay contains high protein (20–27% crude protein) and condensed tannins (1.5–4% CP). It is valued as a good roughage source for ruminants such as dairy or beef cattle, buffalo, goats, and sheep, whether by direct feeding or as a protein source in concentrate mixtures.
Laundry starch.
Manioc is also used in a number of commercially available laundry products, especially as starch for shirts and other garments. Using manioc starch diluted in water and spraying it over fabrics before ironing helps stiffen collars.
Medicinal use.
Cassava root has been promoted as a treatment for bladder and prostate cancer. However, according to the American Cancer Society, "there is no convincing scientific evidence that cassava or tapioca is effective in preventing or treating cancer".
Food use processing and toxicity.
Cassava roots, peels and leaves should not be consumed raw because they contain two cyanogenic glucosides, linamarin and lotaustralin. These are decomposed by linamarase, a naturally occurring enzyme in cassava, liberating hydrogen cyanide (HCN). Cassava varieties are often categorized as either sweet or bitter, signifying the absence or presence of toxic levels of cyanogenic glucosides, respectively. The so-called sweet (actually not bitter) cultivars can produce as little as 20 milligrams of cyanide (CN) per kilogram of fresh roots, whereas bitter ones may produce more than 50 times as much (1 g/kg). Cassavas grown during drought are especially high in these toxins. A dose of 25 mg of pure cassava cyanogenic glucoside, which contains 2.5 mg of cyanide, is sufficient to kill a rat. Excess cyanide residue from improper preparation is known to cause acute cyanide intoxication, and goiters, and has been linked to ataxia (a neurological disorder affecting the ability to walk, also known as "konzo"). It has also been linked to tropical calcific pancreatitis in humans, leading to chronic pancreatitis.
Societies that traditionally eat cassava generally understand that some processing (soaking, cooking, fermentation, etc.) is necessary to avoid getting sick.
Symptoms of acute cyanide intoxication appear four or more hours after ingesting raw or poorly processed cassava: vertigo, vomiting, and collapse. In some cases, death may result within one or two hours. It can be treated easily with an injection of thiosulfate (which makes sulfur available for the patient's body to detoxify by converting the poisonous cyanide into thiocyanate).
"Chronic, low-level cyanide exposure is associated with the development of goiter and with tropical ataxic neuropathy, a nerve-damaging disorder that renders a person unsteady and uncoordinated. Severe cyanide poisoning, particularly during famines, is associated with outbreaks of a debilitating, irreversible paralytic disorder called konzo and, in some cases, death. The incidence of konzo and tropical ataxic neuropathy can be as high as 3% in some areas."
Brief soaking (four hours) of cassava is not sufficient, but soaking for 18–24 hours can remove up to half the level of cyanide. Drying may not be sufficient, either.
For some smaller-rooted, sweet varieties, cooking is sufficient to eliminate all toxicity. The cyanide is carried away in the processing water and the amounts produced in domestic consumption are too small to have environmental impact. The larger-rooted, bitter varieties used for production of flour or starch must be processed to remove the cyanogenic glucosides. The large roots are peeled and then ground into flour, which is then soaked in water, squeezed dry several times, and toasted. The starch grains that float to the surface during the soaking process are also used in cooking. The flour is used throughout South America and the Caribbean. Industrial production of cassava flour, even at the cottage level, may generate enough cyanide and cyanogenic glycosides in the effluents to have a severe environmental impact.
A safe processing method used by the pre-Columbian people of the Americas is to mix the cassava flour with water into a thick paste and then let it stand in the shade for five hours in a thin layer spread over a basket. In that time, about 83% of the cyanogenic glycosides are broken down by the linamarase; the resulting hydrogen cyanide escapes to the atmosphere, making the flour safe for consumption the same evening.
The traditional method used in West Africa is to peel the roots and put them into water for three days to ferment. The roots then are dried or cooked. In Nigeria and several other west African countries, including Ghana, Benin, Togo, Ivory Coast, and Burkina Faso, they are usually grated and lightly fried in palm oil to preserve them. The result is a foodstuff called "gari". Fermentation is also used in other places such as Indonesia (see Tapai). The fermentation process also reduces the level of antinutrients, making the cassava a more nutritious food.
The reliance on cassava as a food source and the resulting exposure to the goitrogenic effects of thiocyanate has been responsible for the endemic goiters seen in the Akoko area of southwestern Nigeria.
People dependent on cassava risk cyanide poisoning and malnutrition diseases such as kwashiorkor and endemic goiter.
A project called "BioCassava Plus" is developing a cassava with lower cyanogen glucosides and fortified with vitamin A, iron and protein to help the nutrition of people in sub-Saharan Africa. In 2011, the director of the program said he hoped to obtain regulatory approvals by 2017.
Farming.
Harvesting.
Cassava is harvested by hand by raising the lower part of the stem and pulling the roots out of the ground, then removing them from the base of the plant. The upper parts of the stems with the leaves are plucked off before harvest. Cassava is propagated by cutting the stem into sections of approximately 15 cm, these being planted prior to the wet season.
Postharvest handling and storage.
Cassava undergoes postharvest physiological deterioration, or PPD, once the tubers are separated from the main plant. The tubers, when damaged, normally respond with a healing mechanism. However, the same mechanism, which involves coumaric acids, initiates about 15 minutes after damage, and fails to switch off in harvested tubers. It continues until the entire tuber is oxidized and blackened within two to three days after harvest, rendering it unpalatable and useless. Recent work has indicated that PPD is related to the accumulation of reactive oxygen species (ROS) initiated by cyanide release during mechanical harvesting. Based on this research, cassava shelf life was increased to up to 2 weeks by overexpressing a cyanide insensitive alternative oxidase.
PPD is one of the main obstacles currently preventing farmers from exporting cassavas abroad and generating income. Cassava can be preserved in various ways such as coating in wax or freezing.
The major cause of losses during cassava chip storage is infestation by insects. A wide range of species that feed directly on the dried chips have been reported as the cause of weight loss in the stored produce. Some loss assessment studies and estimations on dried cassava chips have been carried out in different countries. Hiranandan and Advani (1955) measured 12 - 14% post-harvest weight losses in India for chips stored for about five months. Killick (1966) estimated for Ghana that 19% of the harvest cassava roots are lost annually, and Nicol (1991) estimated a 15–20% loss of dried chips stored for eight months. Pattinson (1968) estimated for Tanzania a 12% weight loss of cassava chips stored for five months, and Hodges et al. (1985) assessed during a field survey postharvest losses of up to 19% after 3 months and up to 63% after four to five months due to the infestation of "Prostephanus truncatus" (Horn). In Togo, Stabrawa (1991) assessed postharvest weight losses of 5% after one month of storage and 15% after three months of storage due to insect infestation, and Compton (1991) assessed weight losses of about 9% for each store in the survey area in Togo. Wright et al. (1993) assessed postharvest losses of chips of about 14% after four months of storage, about 20% after seven months of storage and up to 30% when "P. truncatus" attacked the dried chips. In addition, Wright et al. (1993) estimated about 4% of the total national cassava production in Togo is lost during the chip storage. This was about equivalent to 0.05% of the GNP in 1989.
Plant breeding has resulted in cassava that is tolerant to PPD. Sánchez et al. identified four different sources of tolerance to PPD. One comes from Walker's Manihot ("M. walkerae") of southern Texas in the United States and Tamaulipas in Mexico. A second source was induced by mutagenic levels of gamma rays, which putatively silenced one of the genes involved in PPD genesis. A third source was a group of high-carotene clones. The antioxidant properties of carotenoids are postulated to protect the roots from PPD (basically an oxidative process). Finally, tolerance was also observed in a waxy-starch (amylose-free) mutant. This tolerance to PPD was thought to be cosegregated with the starch mutation, and is not a pleiotropic effect of the latter.
Pests.
In Africa, a previous issue of great significance was the cassava mealybug ("Phenacoccus manihoti") and cassava green mite ("Mononychellus tanajoa"). These pests can cause up to 80% crop loss, which is extremely detrimental to the production of subsistence farmers. These pests were rampant in the 1970s and 1980s but were brought under control following the establishment of the Biological Control Center for Africa of the IITA under the leadership of Dr. Hans Rudolf Herren. The Centre investigated biological control for cassava pests; two South American natural enemies "Apoanagyrus lopezi" (a parasitoid wasp) and "Typhlodromalus aripo" (a predatory mite) were found to effectively control the cassava mealybug and the cassava green mite, respectively.
The cassava mosaic virus causes the leaves of the cassava plant to wither, limiting the growth of the root. An outbreak of the virus in Africa in the 1920s led to a major famine. The virus is spread by the whitefly and by the transplanting of diseased plants into new fields. Sometime in the late 1980s, a mutation occurred in Uganda that made the virus even more harmful, causing the complete loss of leaves. This mutated virus has been spreading at a rate of per year, and as of 2005 may be found throughout Uganda, Rwanda, Burundi, the Democratic Republic of the Congo and the Republic of the Congo.
Recently, brown streak disease has been identified as a major threat to cassava cultivation worldwide.
A wide range of plant parasitic nematodes have been reported associated with cassava worldwide. These include "Pratylenchus brachyurus"., "Rotylenchulus reniformis", "Helicotylenchus" spp., "Scutellonema" spp. and "Meloidogyne" spp., of which "Meloidogyne incognita" and "Meloidogyne javanica" are the most widely reported and economically important. "Meloidogyne" spp. feeding produces physically damaging galls with eggs inside them. Galls later merge as the females grow and enlarge, and they interfere with water and nutrient supply. Cassava roots become tough with age and restrict the movement of the juveniles and the egg release. It is therefore possible that extensive galling can be observed even at low densities following infection. Other pest and diseases can gain entry through the physical damage caused by gall formation, leading to rots. They have not been shown to cause direct damage to the enlarged storage roots, but plants can have reduced height if there was loss of enlarged root weight.
Research on nematode pests of cassava is still in the early stages; results on the response of cassava is, therefore, not consistent, ranging from negligible to seriously damaging. Since nematodes have such a seemingly erratic distribution in cassava agricultural fields, it is not easy to clearly define the level of direct damage attributed to nematodes and thereafter quantify the success of a chosen management method.
The use of nematicides has been found to result in lower numbers of galls per feeder root compared to a control, coupled with a lower number of rots in the storage roots. The nematicide Femaniphos, when used, did not affect crop growth and yield parameter variables measured at harvest. Nematicide use in cassava is neither practical nor sustainable; currently the use of tolerant and resistant varieties is the most practical and sustainable management method.

</doc>
<doc id="56466" url="https://en.wikipedia.org/wiki?curid=56466" title="Neurofibromatosis">
Neurofibromatosis

Neurofibromatosis (NF) refers to several genetically inherited conditions that are clinically and genetically different and carry a high possibility of tumor formation. This disorder is divided into Neurofibromatosis type 1, Neurofibromatosis type 2 and Schwannomatosis.
Signs.
Neurofibromatosis (NF1) in early life may cause learning and behavior problems – about 60% of children who have NF1 have a mild form of difficulty in school. In terms of signs the individual might have are the following:
Cause.
Neurofibromatosis is an autosomal dominant disorder, which means only one copy of the affected gene is needed for the disorder to develop. Therefore, if only one parent has neurofibromatosis, his or her children have a 50% chance of developing the condition as well.The affected child could have mild NF1 even though inherited from a parent with a severe form of the disorder. The types of neurofibromatosis are:
Pathophysiology.
The pathophysiology of neurofibromatosis (type 1) consists of the NF1 gene protein. This protein is a tumor suppressor and therefore serves as a signal regulator of cell proliferation and differentiation. A dysfunction of neurofibromin can affect regulation, and cause uncontrolled cell proliferation. Schwann cells in neurofibromas have a mutation in the NF1 alleles.
Diagnosis.
The neurofibromatoses are considered as RASopathies and as members of the "neurocutaneous syndromes" ("phakomatoses"). Conditions which may be confused with NF-1 but which are not considered NF include, LEOPARD syndrome, and Legius syndrome
The diagnosis of neurofibromatosis is done via the following means:
Treatment.
Surgical removal of tumors is an option, however the risks involved should be assessed first. With regard to OPG (optic pathway gliomas), the preferred treatment is chemotherapy. However, radiotherapy isn't recommended in children who present with this disorder. It is recommended that children diagnosed with NF1 at an early age have an examination each year, which allows any potential growths or changes related to the disorder to be monitored.
Prognosis.
In most cases, symptoms of NF1 are mild, and individuals live normal and productive lives. In some cases, however, NF1 can be severely debilitating and may cause cosmetic and psychological issues. The course of NF2 varies greatly among individuals. In some cases of NF2, the damage to nearby vital structures, such as other cranial nerves and the brain stem, can be life-threatening. Most individuals with schwannomatosis have significant pain. In some extreme cases the pain will be severe and disabling.
Epidemiology.
NF1 occurs in 1 in 3000 individuals and is equally prevalent among men and women. Furthermore, it is among the most common inherited nervous system disorders. Such individuals have a 10 to 15 year reduction in life expectancy compared to the average person.

</doc>
<doc id="56469" url="https://en.wikipedia.org/wiki?curid=56469" title="Pelizaeus–Merzbacher disease">
Pelizaeus–Merzbacher disease

Pelizaeus–Merzbacher disease (PMD) is a rare central nervous system disorder in which coordination, motor abilities, and intellectual function are delayed to variable extents.
Classification.
The disease is one in a group of genetic disorders collectively known as leukodystrophies that affect growth of the myelin sheath, the fatty covering—which acts as an insulator—on nerve fibers in the CNS. PMD is generally caused by a recessive mutation of the gene on the long arm of the X-chromosome (Xq21-22) that codes for a myelin protein called proteolipid protein 1 or PLP1. The majority of disease-causing mutations result in duplications of the entire PLP1 gene. There are several forms of Pelizaeus-Merzbacher disease including, classic, connatal, transitional, and adult variants. Interestingly, deletions at the PLP1 locus (which are rarer) cause a milder form of PMD than is observed with the typical duplication mutations, which demonstrates the critical importance of gene dosage at this locus for normal CNS function. Some of the remaining cases of PMD are accounted for by mutations in the gap junction A12 ("GJA12") gene, and are now called Pelizaeus-Merzbacher-like disease (PMLD). Other cases of apparent PMD do not have mutations in either the "PLP1" or "GJA12" genes, and are presumed to be caused either by mutations in other genes, or by mutations not detected by sequencing the "PLP1" gene exons and neighboring intronic regions of the gene. Among these is a new genetic disorder (discovered in 2003, 2004) which is caused by mutation in the transporter of thyroid hormone, MCT8, also known as SLC16A2, is believed to be account for a significant fraction of the undiagnosed neurological disorders (usually resulting in hypotonic/floppy infants with delayed milestones). This genetic defect was known as Allan-Herndon-Dudley syndrome (since 1944) without knowing its actual cause. Some of the signs for this disorder are as follows: normal to slightly elevated TSH, elevated T3 and reduced T4 (ratio of T3/T4 is about double its normal value). Normal looking at birth and for the first few years, hypotonic (floppy), in particular difficulty to hold the head, possibly difficulty to thrive, possibly with delayed myelination (if so, some cases are reported with an MRI pattern similar to Pelizaeus–Merzbacher disease, known as PMD,) possibly with decreased mitochondrial enzyme activities, possibly with fluctuating lactate level. Patients have an alert face, a limited IQ, patients may never talk/walk, 50% need feeding tube, patients have a normal life span. MCT8 can be ruled out with a simple TSH/T4/T3 thyroid test.
Milder mutations of the "PLP1" gene that mainly cause leg weakness and spasticity, with little or no cerebral involvement, are classified as spastic paraplegia 2 (SPG2). The onset of Pelizaeus–Merzbacher disease is usually in early infancy. The most characteristic early signs are nystagmus (rapid, involuntary, rhythmic motion of the eyes) and hypotonia (low muscle tone). Motor abilities are delayed or never acquired, mostly depending upon the severity of the mutation. Most children with PMD learn to understand language, and usually have some speech. Other signs may include tremor, lack of coordination, involuntary movements, weakness, unsteady gait, and over time, spasticity in legs and arms. Muscle contractures (shrinkage or shortening of a muscle) often occur over time. Mental functions may deteriorate. Some patients may have convulsions and skeletal deformation, such as scoliosis, resulting from abnormal muscular stress on bones.
Diagnosis.
The diagnosis of PMD is often first suggested after identification by magnetic resonance imaging (MRI) of abnormal white matter (high T2 signal intensity, i.e. T2 lengthening) throughout the brain, which is typically evident by about 1 year of age, but more subtle abnormalities should be evident during infancy. Unless there is a family history consistent with sex-linked inheritance, the condition is often misdiagnosed as cerebral palsy. Once a "PLP1" or "GJA12" mutation is identified, prenatal diagnosis or preimplantation genetic diagnostic testing is possible.
Treatment.
There is no cure for PMD, nor is there a standard course of treatment. Treatment, which is symptomatic and supportive, may include medication for seizures and spasticity. Regular evaluations by physical medicine and rehabilitation, orthopedic, developmental and neurologic specialists should be made to ensure optimal therapy and educational resources. The prognosis for those with Pelizaeus–Merzbacher disease is highly variable, with children with the most severe form (so-called connatal) usually not surviving to adolescence, but survival into the sixth or even seventh decades is possible, especially with attentive care. Genetic counseling should be provided to the family of a child with PMD.
In December 2008, StemCells Inc., a biotech company in Palo Alto, received clearance from the U.S. Food and Drug Administration (FDA) to conduct Phase I clinical trials in PMD to assess the safety of transplanting human neural stem cells as a potential treatment for PMD. The trial was initiated in November 2009 at the University of California, San Francisco (UCSF) Children's Hospital.

</doc>
<doc id="56470" url="https://en.wikipedia.org/wiki?curid=56470" title="Leopold I of Belgium">
Leopold I of Belgium

Leopold I (, German and ; Coburg, 16 December 1790 – Laeken, 10 December 1865) was a German prince who became the first King of the Belgians following Belgian independence in 1830. He reigned between July 1831 and December 1865. He established the House of Saxe-Coburg and Gotha to which all subsequent Belgian kings have belonged.
Born into the ruling family of the small German duchy of Saxe-Coburg-Saalfeld, Leopold took a commission in the Imperial Russian Army and fought against Napoleon after French troops overran Saxe-Coburg during the Napoleonic Wars. After Napoleon's defeat, Leopold moved to the United Kingdom where he married Princess Charlotte of Wales, the only child of the Prince Regent (the future King George IV), thus situating himself as a possible future prince consort of Great Britain. Charlotte died in 1817, although Leopold continued to enjoy considerable status in England.
After the Greek War of Independence (1821–32), LeopoId was offered the position of King of Greece but turned it down, believing it to be too precarious. Instead, Leopold accepted the kingship of the newly-established Kingdom of Belgium in 1831. The Belgian government offered the position to Leopold because of his diplomatic connections with royal houses across Europe. In addition, because he was seen as a British-backed candidate, he was not affiliated to other powers, such as France, which were believed to have territorial ambitions in Belgium which might threaten the European balance of power created by the 1815 Congress of Vienna.
Leopold was crowned in Belgium on 21 July 1831, an event commemorated annually as Belgian National Day. His reign was marked by attempts by the Dutch to recapture Belgium and, later, by internal political division between liberals and Catholics. As a Protestant, Leopold was considered liberal and encouraged economic modernisation, playing an important role in encouraging the creation of Belgium's first railway in 1835 and subsequent industrialisation. As a result of the ambiguities in the Belgian Constitution, Leopold was able to slightly expand the monarch's powers during his reign. He also played an important role in stopping the spread of the Revolutions of 1848 into Belgium. He died in 1865 and was succeeded by his son, Leopold II.
Early life.
Leopold was born in Coburg in the tiny German duchy of Saxe-Coburg-Saalfeld in modern-day Bavaria on 16 December 1790. He was the youngest son of Francis, Duke of Saxe-Coburg-Saalfeld, and Countess Augusta Reuss-Ebersdorf. In 1826, Saxe-Coburg acquired the city of Gotha from the neighboring Duchy of Saxe-Gotha-Altenburg and gave up Saalfeld to Saxe-Meiningen, becoming Saxe-Coburg-Gotha.
Military career.
ln 1795, at just five years old, Leopold was given an honorary commission of the rank of colonel in the "Izmaylovsky" Regiment, part of the Imperial Guard, in the Imperial Russian Army. Seven years later, he received a promotion to the rank of Major General.
When French troops occupied the Duchy of Saxe-Coburg in 1806 during the Napoleonic Wars, Leopold went to Paris where he became part of the Imperial Court of Napoleon. Napoleon offered him the position of adjutant, but Leopold refused. Instead, he went to Russia to take up a military career in the Imperial Russian cavalry, which was at war with France at the time. He campaigned against Napoleon and distinguished himself at the Battle of Kulm at the head of his "cuirassier" division. In 1815, by the time of the final defeat of Napoleon and, aged 25, reached the rank of lieutenant general.
Marriage to Charlotte.
Leopold received British citizenship in 1815. On 2 May 1816, Leopold married Princess Charlotte of Wales at Carlton House in London. Charlotte was the only legitimate child of the Prince Regent George (later King George IV) and therefore second in line to the British throne. The same year he received an honorary commission to the rank of Field Marshal and Knight of the Order of the Garter. On 5 November 1817, Princess Charlotte gave birth to a stillborn son. She herself died the next day following complications.
Had Charlotte survived, she would have become queen of the United Kingdom on the death of her father and Leopold presumably would have assumed the role of prince consort, later taken by his nephew Prince Albert of Saxe-Coburg and Gotha. Despite Charlotte's death, the Prince Regent granted Prince Leopold the British style of "Royal Highness" by Order in Council on 6 April 1818.
From 1828 to 1829, Leopold had several-months long affair with the actress Caroline Bauer, who bore a striking resemblance to Charlotte. Caroline was a cousin of his advisor Christian Friedrich Freiherr von Stockmar. She came to England with her mother and took up residence at Longwood House, a few miles from Claremont House. But, by mid-1829, the liaison was over, and the actress and her mother returned to Berlin. Many years later, in memoirs published after her death, she declared that she and Leopold had engaged into a morganatic marriage and that he had bestowed upon her the title of Countess Montgomery. He would have broken this marriage when the possibility arose that he could become King of Greece. The son of Freiherr von Stockmar denied that these events ever happened, and indeed no records have been found of a civil or religious marriage with the actress.
Refusal of the Greek throne.
Following the Greek rebellion against the Ottoman Empire, Leopold was offered the throne of Greece. Leopold, however, declined the offer, fearing that Greece was too politically unstable to remain a viable monarchy. The position was instead accepted by Otto of Wittelsbach in May 1832.
Acceptance of the Belgian throne.
Background.
At the end of August 1830, rebels in the Southern provinces (modern-day Belgium) of the United Netherlands rose up against Dutch rule. The rising, which began in Brussels, pushed the Dutch army back, and the rebels defended themselves against a Dutch attack. International powers meeting in London agreed to support the independence of Belgium, even though the Dutch refused to recognize the new state.
In November 1830, a National Congress was established in Belgium to create a constitution for the new state. Fears of "mob rule" associated with republicanism after the French Revolution of 1789, as well as the example of the recent, liberal July Revolution in France, led the Congress to decide that Belgium would be a popular, constitutional monarchy.
Search for a monarch.
The choice of candidates for the position was one of the most controversial issues faced by the revolutionaries. The Congress refused to consider any candidate from the Dutch ruling house of Orange-Nassau. Some Orangists had hoped to offer the position to King William I or his son, William, Prince of Orange, which would bring Belgium into personal union with the Netherlands like Luxembourg. The Great Powers also worried that a candidate from another state could risk destabilizing the international balance of power and lobbied for a neutral candidate.
Eventually the Congress was able to draw up a shortlist. The three viable possibilities were felt to be Eugène de Beauharnais, a French nobleman and stepson of Napoleon; Auguste of Leuchtenberg, son of Eugene; and Louis, Duke of Nemours who was the son of the French King Louis-Philippe. All the candidates were French and the choice between them was principally between choosing the Bonapartism of Beauharnais or Leuchtenberg and supporting the July Monarchy of Louis-Philippe. Louis-Philippe realized that the choice of either of the Bonapartists could be first stage of a coup against him, but that his son would also be unacceptable to other European powers suspicious of French intentions. Nemours refused the offer. With no definitive choice in sight, Catholics and Liberals united to elect Erasme Louis Surlet de Chokier, a minor Belgian nobleman, as regent to buy more time for a definitive decision in February 1831.
Leopold of Saxe-Coburg had been proposed at an early stage, but had been dropped because of French opposition. The problems caused by the French candidates and the increased international pressure for a solution led to his reconsideration. On 22 April, he was finally approached by a Belgian delegation at Marlborough House to officially offer him the throne. Leopold, however, was reluctant to accept.
Coronation.
On 17 July 1831, Leopold travelled from Calais to Belgium, entering the country at De Panne. Travelling to Brussels, he was greeted with patriotic enthusiasm along his route. The coronation took place on 21 July on the Place Royale in Brussels. A stand had been erected on the steps of the church of Saint Jacques-sur-Coudenberg, surrounded by the names of revolutionaries fallen during the fighting in 1830. After a ceremony of resignation by the regent, Leopold, dressed in the uniform of a Belgian lieutenant-general, swore loyalty to the constitution and became king.
The coronation is generally used to mark end of the revolution and the start of the Kingdom of Belgium and is celebrated each year as the Belgian national holiday.
Reign.
Consolidation of independence.
Less than two weeks after Leopold's coronation, on 2 August, the Netherlands invaded Belgium, starting the Ten Days' Campaign. The small Belgian army was overwhelmed by the Dutch assault and was pushed back. Faced with a military crisis, Leopold appealed to the French for support. The French promised support, and the arrival of their "" in Belgium forced the Dutch to accept a diplomatic mediation and retreat back to the pre-war border. Skirmishes continued for eight years, but in 1839, the two countries signed the Treaty of London, establishing Belgium's independence.
Leopold was generally unsatisfied with the amount of power allocated to the monarch in the Constitution, and sought to extend it wherever the Constitution was ambiguous or unclear while generally avoiding involvement in routine politics.
Subsequent reign.
Leopold I's reign was also marked by an economic crisis which lasted until the late 1850s. In the aftermath of the revolution, the Dutch had closed the Scheldt to Belgian shipping, meaning that the port of Antwerp was effectively useless. The Netherlands and the Dutch colonies in particular, which had been profitable markets for Belgian manufacturers before 1830, were totally closed to Belgian goods. The period between 1845 and 1849 was particularly hard in Flanders, where harvests failed and a third of the population became dependent on poor relief, and have been described as the "worst years of Flemish history". The economic situation in Flanders also increased the internal migration to Brussels and the industrial areas of Wallonia, which continued throughout the period.
Politics in Belgium under Leopold I were polarized between liberal and Catholic political factions, though before 1847 they collaborated in "Unionist" governments. The liberals were opposed to the Church's influence in politics and society, while supporting free trade, personal liberties and secularization. The Catholics wanted religious teachings to be a fundamental basis for the state and society and opposed all attempts by the liberals to attack the Church's official privileges. Initially, these factions existed only as informal groups with which prominent politicians were generally identified. The liberals held power through much of Leopold I's reign. An official Liberal Party was formed in 1846, although a formal Catholic Party was only established in 1869. Leopold, who was himself a Protestant, tended to favor liberals and shared their desire for reform, even though he was not partisan. On his own initiative, in 1842, Leopold proposed a law which would have stopped women and children from working in some industries, but the bill was defeated. Leopold was an early supporter of railways, and Belgium's first stretch of this railway, between northern Brussels and Mechelen, was completed in 1835. When completed, it was one of the first passenger railways in continental Europe.
Revolution of 1848.
The success of economic reforms partially mitigated the effects of the economic downturn and meant that Belgium was not as badly affected as its neighbors by the Revolutions of 1848. Nevertheless, in early 1848, a large number of radical publications appeared. The most serious threat of the 1848 revolutions in Belgium was posed by Belgian émigré groups. Shortly after the revolution in France, Belgian migrant workers living in Paris were encouraged to return to Belgium to overthrow the monarchy and establish a republic. Around 6,000 armed émigrés of the "Belgian Legion" attempted to cross the Belgian frontier. The first group, travelling by train, was stopped and quickly disarmed at Quiévrain on 26 March 1848. The second group crossed the border on 29 March and headed for Brussels. They were confronted by Belgian troops at the hamlet of Risquons-Tout and, during fighting, seven émigrés were killed and most of the rest were captured. To defuse tension, Leopold theatrically offered his resignation if this was the wish of the majority of his people.
The defeat at Risquons-Tout effectively ended the revolutionary threat to Belgium, as the situation in Belgium began to recover that summer after a good harvest, and fresh elections returned a strong Liberal majority.
Role in international relations.
Because of his family connections and position at the head of a neutral and unthreatening power, Leopold was able to act as an important intermediary in European politics during his reign. As a result of this, he earned the nickname the "Nestor of Europe", after the wise mediator in Homer's "Iliad". Leopold played a particularly important role in moderating relations between the hostile Great Powers. In the later part of his reign, his role in managing relations between Great Britain and the French Empire of Napoleon III was particularly important.
Leopold was particularly known as a political marriage broker. In 1840, Leopold arranged the marriage of his niece, Queen Victoria, to his nephew, Prince Albert of Saxe-Coburg and Gotha. Even before she succeeded to the throne, Leopold had been advising Victoria by letter, and continued to influence her after her accession.
In foreign policy, Leopold's principal object was the maintenance of Belgian neutrality. Despite pressure from the Great Powers, especially over the Crimean War (1853–56), Belgium remained neutral throughout the reigns of Leopold I and II.
Second marriage and family.
In 1832, Leopold married his second wife, Louise-Marie of Orléans. Louise-Marie was the daughter of Louis Philippe I, the King of the French, enstated in 1830. Leopold and Louise-Marie had four children. The eldest, Louis Philippe, died in 1834. When their second son Leopold was born in 1835, he became crown prince (and later King Leopold II). Their third son was Philippe, the father of Belgium's third king, Albert I. Their youngest child was Charlotte, who would later marry Emperor Maximilian I of Mexico.
On 11 October 1850, Queen Louise-Marie died of tuberculosis, aged 38. Leopold also had two sons, George and Arthur, by a mistress, Arcadie Meyer (). George was born in 1849, and Arthur was born in 1852. At Leopold's request, in 1862 the two sons were created Freiherr von Eppinghoven by his nephew, Ernest II, Duke of Saxe-Coburg and Gotha; in 1863 Arcadie was also created Baronin von Eppinghoven.
Death and commemoration.
Leopold died in Laeken near Brussels on 10 December 1865, aged 74. He is buried in the Royal Vault at the Church of "Notre-Dame de Laeken", next to Louise-Marie. He was succeeded by his son, Leopold II, aged 30, who would rule until 1909.
A number of Belgian naval vessels have been named in his honour, including current frigate "Leopold I". His monogram features on the flag of the Flemish town of Leopoldsburg. He has also featured on postage stamps and commemorative coins issued since his death.
In the 2009 film "The Young Victoria", directed by Jean-Marc Vallée, Leopold was played by Thomas Kretschmann.

</doc>
