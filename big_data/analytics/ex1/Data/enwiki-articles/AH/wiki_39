<doc id="51053" url="https://en.wikipedia.org/wiki?curid=51053" title="Psychoanalytic literary criticism">
Psychoanalytic literary criticism

Psychoanalytic literary criticism is literary criticism or literary theory which, in method, concept, or form, is influenced by the tradition of psychoanalysis begun by Sigmund Freud. 
Psychoanalytic reading has been practiced since the early development of psychoanalysis itself, and has developed into a heterogeneous interpretive tradition. As Celine Surprenant writes, 'Psychoanalytic literary criticism does not constitute a unified field. However, all variants endorse, at least to a certain degree, the idea that literature [...] is fundamentally entwined with the psyche'.
Overview.
The object of psychoanalytic literary criticism, at its very simplest, can be the psychoanalysis of the author or of a particularly interesting character in a given work. The criticism is similar to psychoanalysis itself, closely following the analytic interpretive process discussed in Freud's "The Interpretation of Dreams" and other works. Critics may view the fictional characters as psychological case studies, attempting to identify such Freudian concepts as the Oedipus complex, penis envy, Freudian slips, Id, ego and superego and so on, and demonstrate how they influence the thoughts and behaviors of fictional characters. 
However, more complex variations of psychoanalytic criticism are possible. The concepts of psychoanalysis can be deployed with reference to the narrative or poetic structure itself, without requiring access to the authorial psyche (an interpretation motivated by French psychoanalyst Jacques Lacan's remark that "the unconscious is structured like a language"). Or the founding texts of psychoanalysis may themselves be treated as literature, and re-read for the light cast by their formal qualities on their theoretical content (Freud's texts frequently resemble detective stories, or the archaeological narratives of which he was so fond). 
Like all forms of literary criticism, psychoanalytic criticism can yield useful clues to the sometime baffling symbols, actions, and settings in a literary work; however, like all forms of literary criticism, it has its limits. For one thing, some critics rely on psychocriticism as a "one size fits all" approach, when other literary scholars argue that no one approach can adequately illuminate or interpret a complex work of art. As Guerin, et al. put it in "A Handbook of Critical Approaches to Literature",
The danger is that the serious student may become theory-ridden, forgetting that Freud's is not the only approach to literary criticism. To see a great work of fiction or a great poem primarily as a psychological case study is often to miss its wider significance and perhaps even the essential aesthetic experience it should provide.
Methods.
Early applications.
Freud wrote several important essays on literature, which he used to explore the psyche of authors and characters, to explain narrative mysteries, and to develop new concepts in psychoanalysis (for instance, "Delusion and Dream in Jensen's Gradiva" and his influential readings of the Oedipus myth and Shakespeare's "Hamlet" in "The Interpretation of Dreams"). The criticism has been made, however, that in his and his early followers' studies 'what calls for elucidation are not the artistic and literary works themselves, but rather the psychopathology and biography of the artist, writer or fictional characters'. Thus 'many psychoanalysts among Freud's earliest adherents did not resist the temptation to psychoanalyze poets and painters (sometimes to Freud's chagrin'). Later analysts would conclude that 'clearly one cannot psychoanalyse a writer from his text; one can only appropriate him'.
Early psychoanalytic literary criticism would often treat the text as if it were a kind of dream. This means that the text represses its real (or latent) content behind obvious (manifest) content. The process of changing from latent to manifest content is known as the dream work, and involves operations of concentration and displacement. The critic analyzes the language and symbolism of a text to reverse the process of the dream work and arrive at the underlying latent thoughts. The danger is that 'such criticism tends to be reductive, explaining away the ambiguities of works of literature by reference to established psychoanalytic doctrine; and very little of this work retains much influence today'.
Jungians.
Later readers, such as Carl Jung and another of Freud's disciples, Karen Horney, broke with Freud, and their work, especially Jung's, led to other rich branches of psychoanalytic criticism: Horney's to feminist approaches including womb envy, and Jung's to the study of archetypes and the collective unconscious. Jung's work in particular was influential as, combined with the work of anthropologists such as Claude Lévi-Strauss and Joseph Campbell, it led to the entire fields of mythocriticism and archetype analysis.
Northrop Frye considered that 'the literary critic finds Freud most suggestive for the theory of comedy, and Jung for the theory of romance'.
Form.
Waugh writes, 'The development of psychoanalytic approaches to literature proceeds from the shift of emphasis from "content" to the fabric of artistic and literary works'. Thus for example Hayden White has explored how 'Freud's descriptions tally with nineteenth-century theories of tropes, which his work somehow reinvents'.
Especially influential here has been the work of Jacques Lacan, an avid reader of literature who used literary examples as illustrations of important concepts in his work (for instance, Lacan argued with Jacques Derrida over the interpretation of Edgar Allan Poe's "The Purloined Letter"). 
'Lacan's theories have encouraged a criticism which focuses not on the author but on the linguistic processes of the text'. Within this Lacanian emphasis, 'Freud's theories become a place from which to raise questions of interpretation, rhetoric, style, and figuration'. 
However, Lacanian scholars have noted that Lacan himself was not interested in literary criticism "per se", but in how literature might illustrate a psychoanalytic method or concept.
Reader response.
According to Ousby, 'Among modern critical uses of psychoanalysis is the development of "ego psychology" in the work of Norman Holland, who concentrates on the relations between reader and text' - as with reader response criticism. Rollin writes that 'Holland's experiments in reader response theory suggest that we all read literature selectively, unconsciously projecting our own fantasies into it'.
Thus in crime fiction, for example, 'Rycroft sees the criminal as personifying the reader's unavowed hostility to the parent'.
Charles Mauron: psychocriticism.
In 1963, Charles Mauron conceived a structured method to interpret literary works via psychoanalysis. The study implied four different phases:
On Mauron's concept, the author cannot be reduced to a ratiocinating self: his own more or less traumatic biographical past, the cultural archetypes that have suffused his "soul" ironically contrast with the conscious self, The chiasmic relation between the two tales may be seen as a sane and safe acting out. A basically unconscious sexual impulse is symbolically fulfilled in a positive and socially gratifying way, a process known as Sublimation.
Anxiety of influence.
'The American critic Harold Bloom has adopted the Freudian notion of the Oedipus Complex to his study of relationships of influence between poets...and his work has also inspired a feminist variant in the work of Sandra Gilbert and Susan Gubar'.
In similar vein, Shoshana Felman has asked with respect to what she calls ""the guilt of poetry"" the question: 'Could literary history be in any way considered as a repetitive unconscious "transference" of the guilt of poetry?'.
Cultural examples.
In "", one of David Lodge's satires of academia, the naive hero Persse follows Angelica to a forum where she discourses on Romance: '"Roland Barthes has taught us the close connection between narrative and sexuality, between the pleasures of the body and the 'pleasure of the text'...Romance is a multiple orgasm." Persse listened to this stream of filth flowing from between Angelica's exquisite lips and pearly teeth with growing astonishment and burning cheeks, but no one else in the audience seemed to find anything remarkable or disturbing about her presentation'.
In A.S. Byatt's novel "Possession", the heroine/feminist scholar, while recognising that '"we live in the truth of what Freud discovered"', concedes that '"the whole of our scholarship - the whole of our thought - we question everything except the centrality of sexuality"'.

</doc>
<doc id="51054" url="https://en.wikipedia.org/wiki?curid=51054" title="American black bear">
American black bear

The American black bear ("Ursus americanus") is a medium-sized bear native to North America. It is the continent's smallest and most widely distributed bear species. Black bears are omnivores with their diets varying greatly depending on season and location. They typically live in largely forested areas, but do leave forests in search of food. Sometimes they become attracted to human communities because of the immediate availability of food. The American black bear is the world's most common bear species.
It is listed by the IUCN as a "least concern" species, due to its widespread distribution and a large global population estimated to be twice that of all other bear species combined. Along with the brown bear, it is one of only two of the eight modern bear species not considered globally threatened with extinction by the IUCN. American black bears often mark trees using their teeth and claws as a form of communication with other bears, a behavior common to many species of bears.
Taxonomy and evolution.
Despite living in North America, American black bears are not closely related to brown bears and polar bears; genetic studies reveal that they split from a common ancestor 5.05 million years ago (mya). Both American and Asian black bears are considered sister taxa, and are more closely related to each other than to other species of bear. Reportedly, the sun bear is also a relatively recent split from this lineage.
A small primitive bear called "Ursus abstrusus" is the oldest known North American fossil member of the genus "Ursus", dated to 4.95 mya. This suggests that "U. abstrusus" may be the direct ancestor of the American black bear, which evolved in North America. Although Wolverton and Lyman still consider "U. vitabilis" an "apparent precursor to modern black bears", it has also been placed within U. americanus.
The ancestors of American black bears and Asiatic black bears diverged from sun bears 4.58 mya. The American black bear then split from the Asian black bear 4.08 mya. The earliest American black bear fossils, which were located in Port Kennedy, Pennsylvania, greatly resemble the Asiatic species, though later specimens grew to sizes comparable to grizzlies. From the Holocene to present, American black bears seem to have shrunk in size, but this has been disputed because of problems with dating these fossil specimens.
The American black bear lived during the same period as short-faced bears ("Arctodus simus" and "A. pristinus") and the Florida spectacled bear ("Tremarctos floridanus"). These Tremarctine bears evolved from bears that had emigrated from Asia to North America 7–8 ma. The short-faced bears are thought to have been heavily carnivorous and the Florida spectacled bear more herbivorous, while the American black bears remained arboreal omnivores, like their Asian ancestors. The black bear's generalist behavior allowed it to exploit a wider variety of foods and has been given as a reason why, of these three genera, it alone survived climate and vegetative changes through the last ice age while the other more specialized North American predators became extinct. However, both "Arctodus" and "Tremarctos" had survived several other ice ages. After these prehistoric ursids became extinct during the last glacial period 10,000 years ago, black bears were probably the only bear present in much of North America until the migration of brown bears to the rest of the continent.
Hybrids.
American black bears are reproductively compatible with several other bear species, and have occasionally produced hybrid offspring. According to Jack Hanna's "Monkeys on the Interstate", a bear captured in Sanford, Florida, was thought to have been the offspring of an escaped female Asian black bear and a male American black bear. In 1859, a black bear and a Eurasian brown bear were bred together in the London Zoological Gardens, but the three cubs died before they reached maturity. In "The Variation of Animals and Plants under Domestication" Charles Darwin noted:
In the nine-year Report it is stated that the bears had been seen in the zoological gardens to couple freely, but previously to 1848 most had rarely conceived. In the reports published since this date three species have produced young (hybrids in one case), ...
A black bear shot in autumn 1986 in Michigan was thought by some to be a black bear/grizzly bear hybrid, due to its unusually large size and its proportionately larger braincase and skull. DNA testing was unable to determine whether it was a large black bear or grizzly.
Subspecies.
Listed alphabetically.
Native names.
The word "baribal" is used as a name for the black bear in French, Italian, German, Russian, Czech and Polish. Although the root word is popularly written as being from an unspecified Native American language, there is no evidence for this.
Distribution and population.
Historically, black bears occupied the majority of North America's forested regions. Today, they are primarily limited to sparsely settled, forested areas.
Black bears currently inhabit much of their original Canadian range, though they seldom occur in the southern farmlands of Alberta, Saskatchewan, and Manitoba; they have been extinct in Prince Edward Island since 1937. The total Canadian black bear population is between 396,000 and 476,000, based on surveys taken in the mid-1990s in seven Canadian provinces, though this estimate excludes black bear populations in New Brunswick, Northwest Territories, Nova Scotia, and Saskatchewan. All provinces indicated stable populations of black bears over the last decade.
The current range of black bears in the United States is constant throughout most of the northeast, and down in the Appalachian Mountains almost continuously from Maine to north Georgia, the northern midwest, the Rocky Mountain region, the west coast and Alaska. However it becomes increasingly fragmented or absent in other regions. Despite this, black bears in those areas seems to have expanded their range during the last decade, such as with recent sightings in Ohio, though these probably do not represent stable breeding populations yet. Surveys taken from 35 states in the early 1990s indicate that black bears are either stable or increasing, except in Idaho and New Mexico. The overall population of black bears in the United States has been estimated to range between 339,000 and 465,000, though this excludes populations from Alaska, Idaho, South Dakota, Texas, and Wyoming, whose population sizes are unknown.
As of 1993, known Mexican black bear populations existed in four areas, though knowledge on the distributions of populations outside those areas have not been updated since 1959. Mexico is the only country where the black bear is classified as "endangered".
There have been several sightings quite far away from where the black bear is normally found, such as Union County, North Carolina and western Nebraska.
Habitat.
Throughout their range, habitats preferred by American black bears have a few shared characteristics. They are often found in areas with relatively inaccessible terrain, thick understory vegetation and large quantities of edible material (especially masts). The adaptation to woodlands and thick vegetation in this species may have originally been due to the black bear having evolved alongside larger, more aggressive bear species, such as the extinct short-faced bear and the still living grizzly bear, that monopolized more open habitats and the historic presence of larger predators such as smilodon and the American lion that could have preyed on black bears. Although found in the largest numbers in wild, undisturbed areas and rural regions, black bears can adapt to surviving in some numbers in peri-urban regions as long as they contain easily accessible foods and some vegetative coverage. In most of the contiguous United States, black bears today are usually found in heavily vegetated mountainous areas, from . For bears living in the American Southwest and Mexico, habitat usually consists of stands of chaparral and pinyon juniper woods. In this region, bears occasionally move to more open areas to feed on prickly pear cactus. At least two distinct, prime habitat types are inhabited in the Southeast United States. Black bears in the southern Appalachian Mountains survive in predominantly oak-hickory and mixed mesophytic forests. In the coastal areas of the southeast (such as Florida, The Carolinas, and Louisiana), bears inhabit a mixture of flatwoods, bays, and swampy hardwood sites. In the northeast part of the range (United States and Canada), prime habitat consists of a forest canopy of hardwoods such as beech, maple, and birch, and coniferous species. Corn crops and oak-hickory mast are also common sources of food in some sections of the northeast; small, thick swampy areas provide excellent refuge cover largely in stands of white cedar. Along the Pacific coast, redwood, Sitka spruce, and hemlocks predominate as overstory cover. Within these northern forest types are early successional areas important for black bears, such as fields of brush, wet and dry meadows, high tidelands, riparian areas and a variety of mast-producing hardwood species. The spruce-fir forest dominates much of the range of the black bear in the Rockies. Important nonforested areas here are wet meadows, riparian areas, avalanche chutes, roadsides, burns, sidehill parks, and subalpine ridgetops. In areas where human development is relatively low, such as stretches of Canada and Alaska, American black bears tend to be found more regularly in lowland regions. In parts of northeastern Canada, especially Labrador, black bears have adapted exclusively to semi-open areas that are more typical habitat in North America for brown bears (likely due to the absence here of brown and polar bears as well as other large carnivore species).
Description.
Build.
The skulls of American black bears are broad, with narrow muzzles and large jaw hinges. In Virginia, the total length of adult bear skulls was found to average . Across its range, greatest skull length for the species has been reportedly measured from . Females tend to have more slender and pointed faces than males. Their claws are typically black or grayish brown. The claws are short and rounded, being thick at the base and tapering to a point. Claws from both hind and front legs are almost identical in length, though the foreclaws tend to be more sharply curved. The paws of the species are relatively sizeable, with a rear foot length of , being proportionly larger than other medium-sized bear species but much smaller than the paws of large adult brown and especially polar bears. The soles of the feet are black or brownish, and are naked, leathery and deeply wrinkled. The hind legs are relatively longer than those of Asiatic black bears. The vestigal tail is usually 4.8 inches (12 cm) long. The ears are small and rounded, and are set well back on the head.
Black bears are highly dexterous, being capable of opening screw-top jars and manipulating door latches. They also have great physical strength. They have been known to turn over flat-shaped rocks weighing by flipping them over with a single foreleg. They move in a rhythmic, sure-footed way and can run at speeds of 25–30 mph (40–50 km/h). Black bears have good eyesight, and have been proven experimentally to be able to learn visual discrimination tasks based on color faster than chimpanzees and as fast as dogs. They are also capable of rapidly learning to distinguish different shapes, such as small triangles, circles and squares.
Size.
Black bear weight tends to vary according to age, sex, health, and season. Seasonal variation in weight is very pronounced: in autumn, their pre-den weight tends to be 30% higher than in spring, when black bears emerge from their dens. Black bears on the East Coast tend to be heavier on average than those on the West Coast, although black bears follow Bergmann's rule and bears from the northwest are often slightly heavier than the bears from the southeast. Adult males typically weigh between , while females weigh 33% less at . In the state of California, studies have indicated that the average mass is in adult males and in adult females. Adult black bears in Yukon Flats National Wildlife Refuge in east-central Alaska were found to average in males and in females, whereas on Kuiu Island in southeast Alaska (where nutritious salmon are readily available) adult bears averaged an estimated . In Great Smoky Mountains National Park, adult males averaged and adult females averaged per one study. In Yellowstone National Park, a population study found that adult males averaged and adult females averaged . In New York state, the two sexes reportedly average and , respectively. Adults typically range from in head-and-body length, and in shoulder height. The typically small tail is long. Although they are the smallest species in North America, large males exceed the size of other bear species except the brown bear and polar bears. The biggest wild American black bear ever recorded was a male from New Brunswick, shot in November 1972, that weighed after it had been dressed, meaning it weighed an estimated in life, and measured long. Another notably outsized wild black bear, weighing in at in total, was the cattle-killer shot in December 1921 on the Moqui Reservation in Arizona. The record-sized bear from New Jersey was shot in Morris County December 2011 and scaled . Even larger, the most massive black bear recorded in Pennsylvania (one of six weighing over shot in the last 15 years in the state) weighed in at and was shot in November 2010 in Pike County. The North American Bear Center, located in Ely, Minnesota, is home to the world's largest captive male and female black bears. Ted, the male, weighed in the fall of 2006. Honey, the female, weighed in the fall of 2007.
Pelage.
The fur is soft, with dense underfur and long, coarse, thick guard hairs. The fur is not as shaggy or coarse as that of brown bears. American black bear skins can be distinguished from those of Asiatic black bears by the lack of a white mark on the chin and hairier footpads. Despite their name, black bears show a great deal of color variation. Individual coat colors can range from white, blond, cinnamon, or light brown to dark chocolate brown or to jet black, with many intermediate variations existing. Bluish tinged black bears occur along a portion of coastal Alaska and British Columbia. White to cream colored black bears occur in coastal islands and the adjacent mainland of south-western British Columbia. Albino specimens have also been recorded. Black coats tend to predominate in moist areas such as New England, New York, Tennessee, Michigan and western Washington. Approximately 70% of all black bears are black, though only 50% of black bears in the Rocky Mountains are black. Many black bears in Northwestern North America are cinnamon, blond or light brown in color, and thus may sometimes be mistaken for grizzly bears. Grizzly (and other types of brown) bears can be distinguished by their shoulder hump, larger size and broader, more concave skull.
In his book "The Great Bear Almanac", Gary Brown summarized the predominance of black or brown/blond specimens by location:
Behavior.
In his "Great Bear Almanac", Gary Brown lists 20 different sounds in eight different contexts. Sounds expressing aggression include growls, woofs, snorts, bellows and roars. Sounds expressing contentment include mumbles, squeaks and pants. A black bear has better eyesight and a better sense of hearing compared to humans. Their keenest sense is the sense of smell, which is about seven times greater than a dog's. American black bears tend to be territorial and non-gregarious in nature. However, at abundant food sources (i.e. spawning salmon or garbage dumps) black bears may congregate and dominance hierarchies form, with the largest, most powerful males dominating the most fruitful feeding spots. They mark their territories by rubbing their bodies against trees and clawing at the bark. Annual ranges held by mature male black bears tend to be very large but there is some variation. On Long Island off the coast of Washington, ranges average , whereas on the Ungava Peninsula in Canada ranges can average up to , with some males bears travelling as far as in times of food shortages. Black bears are excellent and strong swimmers, doing so for pleasure and to feed (largely on fish). Black bears climb trees regularly to feed, escape enemies and to hibernate. Half of bear species are habitually arboreal (the most arboreal species, the American and Asian black bears and the sun bear, being fairly closely related). Their arboreal abilities tend to decline with age. Black bears may be active at any time of the day or night, although mainly forage by night. Bears living near human habitations tend to be more extensively nocturnal and bears living near brown bears tend to be more extensively diurnal.
Reproduction and development.
Sows usually produce their first litter at the age of 3–5 years. Sows living in more developed areas tend to get pregnant at younger ages. The breeding period usually occurs in the June–July period, though it can extend to August in the species' northern range. The breeding period lasts for 2–3 months. Both sexes are promiscuous. Males try to mate with several females but large, dominant ones may violently claim a female if another mature male comes near. Sows tend to be short tempered with their mates after copulating. The fertilized eggs undergo delayed development and do not implant in the female’s womb until November. The gestation period lasts 235 days, and litters are usually born in late January to early February. Litter size is between one and six cubs; typically two or three. At birth, cubs weigh , and measure in length. They are born with fine, gray, downlike hair, and their hind quarters are underdeveloped. They typically open their eyes after 28–40 days, and begin walking after 5 weeks. Cubs are dependent on their mother's milk for 30 weeks, and will reach independence at 16–18 months. At the age of six weeks, they attain , by 8 weeks they reach and by the age of 6 months they weigh . They reach sexual maturity at the age of three years, and attain their full growth at 5 years.
Longevity and mortality.
The average lifespan in the wild is 18 years, though it is quite possible for wild specimens to survive for more than 23 years. The record age of a wild specimen was 39 years, while that in captivity was 44 years. Average annual survival rates for adult bears is variable, ranging from 86% in Florida to 73% in Virginia and North Carolina. In Minnesota, 99% of wintering adult bears were able to survive the hibernation cycle in one study. Remarkably, a study of black bears in Nevada found that the amount of annual mortality of a population of bears in wilderness areas was 0%, whereas in developed areas in the state this figure rose to 83%. Survival in subadults is generally less assured. In Alaska, only 14–17% of subadult males and 30–48% of subadult females were found in a study to survive to adulthood. Across the range, the estimated amount of cubs who survive past their first year is 60%.
With the exception of the rare confrontation with an adult brown bear or gray wolf pack, adult black bears are not usually subject to natural predation. Black bear cubs tend to be more vulnerable to predation than adults. Known predators of bear cubs have included bobcats, coyotes, cougars, wolves, brown bears and other bears of their own species. Many of these will stealthily snatch small cubs right from under the sleeping mother. There is a single record of a golden eagle snatching a yearling cub. Once out of hibernation, mother bears may be able to fight off most potential predators. Even cougars will be displaced by an angry mother bear if they are discovered stalking the cubs. Flooding of dens after birth may also occasionally kill newborn cubs. However, in current times, American black bears fatalities are overwhelmingly attributable to human activities. Seasonally, tens of thousands of black bears are hunted legally across North America, with many more being illegally poached or trapped. Auto-collisions also may claim many black bear lives annually.
Hibernation.
Black bears were once not considered true or "deep" hibernators, but because of discoveries about the metabolic changes that allow black bears to remain dormant for months without eating, drinking, urinating, or defecating, most biologists have redefined mammalian hibernation as "specialized, seasonal reduction in metabolism concurrent with scarce food and cold weather". Black bears are now considered highly efficient hibernators.
Black bears enter their dens in October and November. Prior to that time, they can put on up to of body fat to get them through the seven months during which they fast. Hibernation in black bears typically lasts 3–8 months, depending on regional climate. During this time, their heart rate drops from 40–50 beats per minute to 8 beats per minute. They spend their time in hollowed-out dens in tree cavities, under logs or rocks, in banks, caves, or culverts, and in shallow depressions. Females, however, have been shown to be pickier in their choice of dens, in comparison to males. Although naturally-made dens are occasionally used, most dens are dug out by the bear itself. A special hormone, leptin is released into the black bear's systems, to suppress appetite. Because they do not urinate or defecate during dormancy, the nitrogen waste from the bear's body is biochemically recycled back into their proteins. This also serves the purpose of preventing muscle loss, as the process uses the waste products to build muscle during the long periods of inactivity. In comparison to true hibernators, their body temperature does not drop significantly (staying around 35 degrees Celsius) and they remain somewhat alert and active. If the winter is mild enough, they may wake up and forage for food. Females also give birth in February and nurture their cubs until the snow melts. During winter, black bears consume 25–40% of their body weight. The footpads peel off while they sleep, making room for new tissue. In the most southernly areas (i.e. Florida, Mexico, the Southeastern United States) of the black bear's distribution only pregnant females and mothers with yearling cubs will enter hibernation. After emerging from their winter dens in spring, they wander their home ranges for two weeks so that their metabolism accustoms itself to the activity. In mountainous areas, they seek southerly slopes at lower elevations for forage and move to northerly and easterly slopes at higher elevations as summer progresses. Black bears use dense cover for hiding and thermal protection, as well as for bedding.
Dietary habits.
Generally, American black bears are largely crepuscular in foraging active, though may actively feed at any time. Up to 85% of the black bear's diet consists of vegetation, though they tend to dig less than brown bears, eating far fewer roots, bulbs, corms and tubers than the latter species. When initially emerging from hibernation, they will seek to feed on carrion from winter-killed animals and newborn ungulates. As the spring temperature warms, black bears seek new shoots of many plant species, especially new grasses, wetland plants and forbs. Young shoots and buds from trees and shrubs during the spring period are also especially important to black bears emerging from hibernation, as they assist in rebuilding muscle and strengthening the skeleton and are often the only digestible foods available at that time. During summer, the diet is comprised largely by fruits, especially berries and soft masts such as buds and drupes. During the autumn hyperphagia, feeding becomes pretty much the full-time task of black bears. Hard masts become the most important part of the black bear's diet in autumn and may even partially dictate the species distribution. Favored masts such as hazelnuts, oak acorns and whitebark pine nuts may be consumed by the hundreds each day by a single black bear during fall. During the fall period, American black bears may also habitually raid the nut caches of tree squirrels. Also extremely important in fall are berries such as huckleberries and buffalo berries. Black bears living in areas near human settlements or around a considerable influx of recreational human activity often come to rely on foods inadvertently provided by humans, especially during summertime. These include refuse, birdseed, agricultural products and honey from apiaries.
The majority of the black bear's animal diet consists of insects such as bees, yellow jackets, ants and their larvae. Black bears are also fond of honey, and will gnaw through trees if hives are too deeply set into the trunks for them to reach them with their paws. Once the hive is breached, black bears will scrape the honeycombs together with their paws and eat them, regardless of stings from the bees. Black bears that live in northern coastal regions (especially the Pacific coast) will fish for salmon during the night, as their black fur is easily spotted by salmon in the daytime. However, the white furred black bears of the islands of western Canada have a 30% greater success rate in catching salmon than their black furred counterparts. Other fish including suckers, trout and catfish are readily caught when possible. Although black bears do not often engage in active predation of other large animals for much of the year, the species will also regularly prey on mule and white-tailed deer fawns in spring given the opportunity. In addition they have been recorded similarly preying on elk calves in Idaho and moose calves in Alaska. 
Black bear predation on adult deer is rare but has been recorded. They may even hunt prey up to the size of adult female moose, which are considerably larger than themselves, by ambushing them. There is at least one record of a male black bear killing two bull elk over the course of six days by chasing them into deep snow banks where their movement is impeded. In Labrador, black bears are exceptionally carnivorous, living largely off of caribou, usually sickly, young or dead specimens, and rodents such as voles. This is believed to be due to a paucity of edible plant life in this sub-Arctic region and a local lack of competing large carnivores (including other bear species). Like brown bears, black bears try to use surprise to ambush their prey and target the sickly animals in herds. Once a deer fawn is captured, it is frequently torn apart alive while feeding. If able to capture a mother deer in spring, the bear frequently begins feeding on the udder of lactating females, but generally prefer meat from the viscera. Black bears often drag their prey to cover, preferring to feed in seclusion. The skin of large prey is stripped back and turned inside out with the skeleton usually left largely intact. Unlike wolves and coyotes, black bears rarely scatter the remains of their kills. Vegetation around the carcass is usually matted down by black bears and their droppings are frequently found nearby. Black bears may attempt to cover remains of larger carcasses, though they do not do so with the same frequency as cougars and grizzly bears. They will readily consume eggs and nestlings of various birds and can easily access many tree nests, even the huge nest of the bald eagle. Black bears have been reported stealing deer and other animals from human hunters.
Interspecific predatory relationships.
Over much of their range, black bears are assured scavengers that can intimidate, using their large size and considerable strength, and if necessary dominate other predators in confrontations over carcasses. However, in occasions where they encounter the Kodiak or the grizzly bears, the larger two brown sub-species dominate them. Black bears tend to escape competition from brown bears by being more active in the daytime, and living in more densely forested areas. Violent interactions resulting in the deaths of black bears have been recorded in Yellowstone National Park.
Black bears do compete with cougars over carcasses. Like brown bears, they will sometimes steal kills from cougars. One study found that both bear species visited 24% of cougar kills in Yellowstone and Glacier National Parks, usurping 10% of carcasses. Fights between the two species are rare, though they can be violent. Cougars occasionally kill adult bears, a behavior reportedly witnessed in the 19th century. There are also 19th and early 20th century records of bears killing cougar, either in defense or in territorial disputes, and occasional fights, which ended in both combatants fatally wounded.
Black bear interactions with wolves are much rarer than with brown bears, due to differences in habitat preferences. The majority of black bear encounters with wolves occur in the species′ northern range, with no interactions being recorded in Mexico. Despite the black bear being more powerful on a one to one basis, packs of wolves have been recorded to kill black bears on numerous occasions without eating them. Unlike brown bears, black bears frequently lose against wolves in disputes over kills. Wolf packs typically kill black bears when the large animals are in their hibernation cycle.
There is at least one record of a black bear killing a wolverine in a dispute over food in Yellowstone National Park. Black bears may sometimes habitually prey on American alligator nests. Sometimes, they are fought off by the female alligator but will also occasionally wound or even kill an adult alligator, though neither species are likely to confront a large adult of the other directly. Anecdotal cases of alligator predation on bears have been reported, though such cases may involve assaults on cubs.
Relationships with humans.
In folklore, mythology and culture.
Black bears feature prominently in the stories of some of America's indigenous peoples. One tale tells of how the black bear was a creation of the Great Spirit, while the grizzly was created by the Evil Spirit. In the mythology of the Haida, Tlingit, Tsimshian people of the Northwest Coast, mankind first learned to respect bears when a girl married the son of black bear Chieftain. In Kwakiutl mythology, black and brown bears became enemies when Grizzly Bear Woman killed Black Bear Woman for being lazy. Black Bear Woman's children, in turn, killed Grizzly Bear Woman's own cubs. The Navajo believed that the Big Black Bear was chief among the bears of the four directions surrounding Sun's house, and would pray to it in order to be granted its protection during raids.
Morris Michtom, the creator of the teddy bear, was inspired to make the toy when he came across a cartoon of Theodore Roosevelt refusing to shoot a black bear cub tied to a tree. Winnie the Pooh was named after Winnipeg, a female black bear cub that lived at London Zoo from 1915 until her death in 1934. A black bear cub who in the spring of 1950 was caught in the Capitan Gap fire was made into the living representative of Smokey Bear, the mascot of the United States Forest Service.
The American black bear is the mascot of The University of Maine and Baylor University, where the university houses two live black bears on campus.
Sleeping Bear Dunes is named after a Native American legend, where a female bear and her cub swam across Lake Michigan. Exhausted from their journey, the bears rested on the shoreline and fell sound asleep. Over the years, the sand covered them up, creating a huge sand dune.
Attacks on humans.
Although an adult bear is quite capable of killing a human, American black bears typically avoid confronting humans when possible. Unlike grizzly bears, which became a subject of fearsome legend among the European settlers of North America, black bears were rarely considered overly dangerous, even though they lived in areas where the pioneers had settled. Black bears rarely attack when confronted by humans, and usually limit themselves to making mock charges, emitting blowing noises and swatting the ground with their forepaws. The number of black bear attacks on humans is higher than those of the brown bear in North America, though this is largely because the black species considerably outnumbers the brown rather than greater aggressiveness. 
Compared to brown bear attacks, aggressive encounters with black bears rarely lead to serious injury. However, the majority of black bear attacks tend to be motivated by hunger rather than territoriality, and thus victims have a higher probability of surviving by fighting back rather than submitting. Unlike grizzlies, female black bears do not display the same level of protectiveness to their cubs, and seldom attack humans in their vicinity. However, occasionally, attacks by protective mothers do occur. The worst recorded fatality incident occurred in May 1978, in which a black bear killed three teenagers who were fishing in Algonquin Park in Canada. Another exceptional, spree-like attack occurred in August 1997 in Liard River Hot Springs Provincial Park in Canada, when an emaciated black bear attacked a child and mother, killing the mother as well as an adult man who tried to intervene. This bear was shot while mauling a fourth victim.
The majority of attacks happened in national parks, usually near campgrounds, where the bears had become habituated to close human proximity and food conditioned. Out of 1,028 incidents of black bears acting aggressively toward people, 107 resulted in injury, were recorded from 1964 to 1976 in the Great Smoky Mountains National Park, and occurred mainly in tourist hotspots where people regularly fed the bears handouts. In almost every case where open dumps or handouts that had previously attracted black bears were ceased, the amount of aggressive encounters with bears have decreased precipitously over time. However, in the aforementioned case of the spree attack in Liard River Hot Springs, the attacking bear was believed to have been previously almost fully dependent on a local garbage dump that had closed and was starving as a result of the loss of that food source. Attempts to relocate bears are typically unsuccessful, as black bears seem to be able to return to their home range even without familiar landscape cues.
Livestock and crop predation.
A limitation of food sources in early spring and wild berry and nut crop failures during summer months may be contributing factors to black bears regularly feeding from commercial human-based food sources. Crops are frequently eaten by these bears, especially during autumn hyperphagia when natural foods are scarce. Favored crops may include apples, oats and corns. Black bears can do extensive damage in some areas of the northwestern United States by stripping the bark from trees and feeding on the cambium. Livestock depredations by black bears occur mostly in spring. Though black bears have the capacity to (and occasionally do) hunt adult cattle and horses, they seem to prefer smaller, more easily overwhelmed prey such as sheep, goats, calves, and pigs. They normally kill by biting the neck and shoulders, though they may break the neck or back of prey with blows from the paws. Evidence of a bear attack includes claw marks and is frequently found on the neck, back, and shoulders of larger animals. Surplus killing of sheep and goats are common. Bears have been known to frighten livestock herds over cliffs, causing injuries and death to many animals; whether or not this is intentional is not known. Occasionally, pets, especially dogs, which are most prone to harass a bear, are killed by black bears. It is not recommended to use unleashed dogs as a deterrent from bear attacks. Although large, aggressive dogs sometimes cause a bear to run, if pressed, angry bears frequently turn the tables and end up chasing the dog in return. A bear in pursuit of a pet dog has the potential to threaten both canid and human lives.
Bear awareness in towns.
In an effort to help prevent conflicts with bears, many towns in British Columbia developed bear aware programs. The main premise of these programs is to teach humans to manage foods that attract bears. Keeping garbage securely stored, harvesting fruit when ripe, securing livestock behind electric fences, and storing pet food indoors are all measures promoted by bear aware programs. Revelstoke, British Columbia is a community that demonstrates the success of this approach. Before the community had an education program, an average of 27 bears were killed in Revelstoke each year; after the program began, the average mortality has dropped to just 7 bears per year. See Revelstoke Bear Aware for more information.
Hunting and exploitation.
Hunting.
Historically, black bears were hunted by both Native Americans and European settlers. Some Native American tribes, in admiration for the black bear's intelligence, would decorate the heads of bears they killed with trinkets, and place them on blankets. Tobacco smoke would be wafted into the disembodied head's nostrils by the hunter that dealt the killing blow, who would compliment the animal for its courage. The Kutchin typically hunted black bears during their hibernation cycle. Unlike the hunting of hibernating grizzlies, which was fraught with danger, black bears took longer to awaken, and was thus safer and easier. During the European colonisation of eastern North America, thousands of black bears were hunted for their meat, fat and fur. Theodore Roosevelt wrote extensively on black bear hunting in his "Hunting the Grisly and other sketches", in which he stated ""in black bear chase there is much excitement, and occasionally a slight spice of danger, just enough to render it attractive; so it has always been eagerly followed"". He wrote that black bears were difficult to hunt by stalking, due to their habitat preferences, though were easy to trap. Roosevelt described how, in the southern states, planters regularly hunted black bears on horseback with hounds. General Wade Hampton was known to have been present at 500 successful black bear hunts, two thirds of which he killed personally. He killed thirty or forty black bears with only a knife, which he would use to stab the bears between the shoulder blades while they were distracted by his hounds. Unless well trained, horses were often useless in black bear hunts, as they often bolted when the bears stood their ground. In 1799, 192,000 black bear skins were exported from Quebec. In 1822, 3,000 skins were exported from the Hudson's Bay Company. In 1992, untanned, fleshed and salted black bear hides were sold for an average of $165.
In Canada, black bears are considered as both a big game and furbearer species in all provinces save for New Brunswick and Northwest Territories, where they are only classed as a big game species. There are currently 80,822 licensed black bear hunters in all of Canada. Canadian black bear hunts take place in the fall and spring, and both male and female bears can be legally taken, though some provinces prohibit the hunting of females with cubs, or yearling specimens.
Currently, 28 of the USA's states have black bear hunting seasons. Nineteen states require a bear hunting license, with some also requiring a big game license. In eight states, only a big game license is required to hunt black bears. Overall over 481,500 black bear hunting licences are sold per year. The hunting methods and seasons vary greatly according to state, with some bear hunting seasons including fall only, spring and fall, or year-round. New Jersey, in November 2010, approved of a six-day bear-hunting season in early December 2010 to slow the growth of the black bear population. Bear-hunting had been banned in New Jersey for five years. A Fairleigh Dickinson University PublicMind poll found that 53% of New Jersey voters approved of the new season if scientists concluded black bears were leaving their usual habitats and destroying private property. Men, older voters, and those living in rural areas were more likely to approve of a bear-hunting season in New Jersey than women, younger voters, and those living in more developed parts of the state. In the western states, where there are large black populations, there are spring and year-round seasons. Approximately 18,845 black bears were killed annually in the USA between 1988–1992. Within this period, annual kills ranged from six bears in South Carolina to 2,232 in Maine.
According to Dwight Schuh in his "Bowhunter's Encyclopedia", black bears are the third most popular quarry of bowhunters, behind deer and elk.
Meat.
Black bear meat had historically been held in high esteem among North America's indigenous people and colonists. Black bears were the only bear species the Kutchin hunted for their meat, though this constituted only a small part of their diet. According to the second volume of "Frank Forester's field sports of the United States, and British provinces, of North America":
Theodore Roosevelt himself likened the flesh of young black bears to that of pork, and not as coarse or flavourless as the meat of grizzlies. The most favoured cuts of the black bear's meat are concentrated in the legs and loins. Meat from the neck, front legs and shoulders is usually ground into minced meat or used for stews and casseroles. Keeping the fat tends to give the meat a strong flavour. As black bears can have trichinellosis, cooking temperatures need to be high in order to kill the parasites.
Black bear fat was once valued as a cosmetic article that promoted hair growth and gloss. The fat most favoured for this purpose was the hard white fat found in the body's interior. As only a small portion of this fat could be harvested for this purpose, the oil was often mixed with large quantities of hog lard. However animal rights activism over the last decade has slowed the harvest of these animals; therefore the lard from black bear has not been used in recent years for the purpose of cosmetics.

</doc>
<doc id="51056" url="https://en.wikipedia.org/wiki?curid=51056" title="Lake Huron">
Lake Huron

Lake Huron () is one of the five Great Lakes of North America. Hydrologically, it comprises the easterly portion of Lake Michigan–Huron, having the same surface elevation as its westerly counterpart, to which it is connected by the , Straits of Mackinac. It is shared on the east by the Canadian province of Ontario and on the west by the state of Michigan in the United States. The name of the lake is derived from early French explorers who named it for the Huron people inhabiting the region.
The Huronian glaciation was named due to evidence collected from Lake Huron region. The northern parts of the lake include the North Channel and Georgian Bay. The main inlet is the St. Marys River and the main outlet is the St. Clair.
Geography.
By surface area, Lake Huron is the second-largest of the Great Lakes, with a surface area of 23,000 square miles (59,600 km2) making it the third-largest fresh water lake on Earth (and the fourth-largest lake, if the Caspian Sea is counted as a lake). By volume however, Lake Huron is only the third largest of the Great Lakes, being surpassed by Lake Michigan and Lake Superior. When measured at the low water datum, the lake contains a volume of 850 cubic miles (3,540 km3) and a shoreline length (including islands) of .
The surface of Lake Huron is 577 feet (176 m) above sea level. The lake's average depth is 32 fathoms 3 feet (195 ft; 59 m), while the maximum depth is 125 fathoms (750 ft; 229 m). It has a length of and a greatest breadth of .
Important cities on Lake Huron include: Goderich, Sarnia, Bay City, Alpena, Rogers City, Cheboygan, Tobermory, Sauble Beach, Saugeen Shores, St. Ignace, and Port Huron.
A large bay that protrudes northeast from Lake Huron into Ontario, Canada, is called Georgian Bay. A notable feature of the lake is Manitoulin Island, which separates the North Channel and Georgian Bay from Lake Huron's main body of water. It is the world's largest freshwater island. Major centres on Georgian Bay include Owen Sound, Wasaga Beach, Midland, Penetanguishene, Port Severn and Parry Sound.
A smaller bay that protrudes southwest from Lake Huron into the state of Michigan, U.S.A., is called Saginaw Bay.
Water levels.
Historic High Water
The lake fluctuates from month to month with the highest lake levels in October and November. The normal high-water mark is above datum ("577.5 ft or 176.0 m"). In the summer of 1986, Lakes Michigan and Huron reached their highest level at above datum. The high-water records began in February 1986 and lasted through the year, ending with January 1987. Water levels ranged from above Chart Datum.
Historic Low Water
Lake levels tend to be the lowest in winter. The normal low-water mark is below datum ("577.5 ft or 176.0 m"). In the winter of 1964, Lakes Michigan and Huron reached their lowest level at below datum. As with the high-water records, monthly low-water records were set each month from February 1964 through January 1965. During this twelve-month period, water levels ranged from below Chart Datum.
Great Lakes Circle Tour.
The Great Lakes Circle Tour is a designated scenic road system connecting all the Great Lakes and the St. Lawrence River.
Geology.
Lake Huron has the largest shore line length of any of the Great Lakes, counting its 30,000 islands.
Lake Huron is separated from Lake Michigan, which lies at the same level, by the , Straits of Mackinac, making them hydrologically the same body of water (sometimes called Lake Michigan-Huron and sometimes described as two 'lobes of the same lake'). Aggregated, Lake Huron-Michigan, at , "is technically the world's largest freshwater lake." When counted separately, Lake Superior is 22,300 mi² larger than Huron and higher. Lake Superior drains into the St. Marys River at Sault Ste. Marie which then flows southward into Lake Huron. The water then flows south to the St. Clair River, at Port Huron, Michigan, and Sarnia, Ontario.
The Great Lakes Waterway continues thence to Lake St. Clair; the Detroit River and Detroit, Michigan; into Lake Erie and thence – via Lake Ontario and the St. Lawrence River – to the Atlantic Ocean.
Like the other Great Lakes, it was formed by melting ice as the continental glaciers retreated toward the end of the last ice age. Before this, Lake Huron was a low-lying depression through which flowed the now-buried Laurentian and Huronian Rivers; the lake bed was criss-crossed by a large network of tributaries to these ancient waterways, with many of the old channels still evident on bathymetric maps.
History.
The extent of development among Eastern Woodlands Native American societies on the eve of European contact is indicated by the archaeological evidence of a town on or near Lake Huron that contained more than one hundred large structures housing a total population of between 4000 and 6000. The French, the first European visitors to the region, often referred to Lake Huron as La Mer Douce, "the fresh-water sea". In 1656, a map by French cartographer Nicolas Sanson refers to the lake as Karegnondi, a Wendat word which has been variously translated as "Freshwater Sea", "Lake of the Hurons", or simply "lake". The lake was generally labeled "Lac des Hurons" (Lake of the Huron) on most early European maps.
Storm of 1913.
On November 9, 1913, a great storm in Lake Huron sank ten ships and more than twenty were driven ashore. The storm, which raged for 16 hours, killed 235 seamen.
The Matoa had passed between Port Huron, Michigan, and Sarnia, Ontario, just after midnight. On the 9th, just after six in the morning, the Senator pushed upstream. Less than an hour later, the Manola passed through. Captain Frederick W. Light of the Manola reported that both the Canadian and the American weather stations had storm flag signals flying from their weather towers. Following behind at 7:00 a.m. that Sunday, the Regina steamed out of Sarnia into the northwest gale. The warnings now had been up for four hours. The Manola passed the Regina off Port Sanilac, up the lake. Captain Light determined that if it continued to deteriorate, he would seek shelter at Harbor Beach, Michigan, another up the lake. There, he could seek shelter behind the breakwater. Before he reached Harbor Beach, the winds turned to the northeast and the lake began to rise. It would be noon before he reached Harbor Beach and ran for shelter. The waves were so violent that the Manola touched bottom entering the harbor. With help from a tug, the Manola tied up to the break wall with eight lines. It was about 3:00 p.m. when the Manola was secured and the crew prepared to drop anchor. As they worked, the cables began to snap from wind pressure against the hull. To keep from being pushed aground, they kept their bow into the wind with the engines running half to full in turns, yet the ship still drifted before its movement was arrested. Waves breaking over the ship damaged several windows and the crew reported seeing portions of the concrete break wall peeling off as the waves struck it.
Meanwhile, fifty miles farther up the lake, the Matoa and Captain Hugh McLeod had to ride out the storm without a safe harbor. The Matoa would be found stranded on the Port Austin reef when the winds subsided. It was noon on Monday before the winds let up and not until 11:00 p.m. that night before Capt. Light determined it to be safe to continue his journey.
Modern history.
On October 26, 2010, the Karegnondi Water Authority was formed to build and manage a pipeline from the Lake to Flint.
Shipwrecks.
More than a thousand wrecks have been recorded in Lake Huron. These purportedly include the first European vessel to sail the Great Lakes, Le Griffon, built in 1679 on the eastern shore of Lake Erie, near Buffalo, New York. Robert Cavalier, Sieur de la Salle navigated across Lake Erie, up the Detroit River, Lake St. Clair and the St. Clair River out into Lake Huron. Passing the Straits of Mackinac, La Salle and the "Griffon" made landfall on Washington Island, off the tip of the Door Peninsula on the Wisconsin side of Lake Michigan. Here, La Salle filled the "Griffon" with pelts and in late November 1679 sent the "Griffon" back to the site of modern-day Buffalo, never to be seen again.
Two wrecks have been identified as the "Griffon", although neither has gained final verification as the actual wreck. Blown by a fierce storm after leaving, the "Griffon" ran aground before the storm. The people of Manitoulin Island say that the wreck in Mississagi Straits at the western tip of the island is that of the "Griffon". Meanwhile, others near Tobermory, say that the wreck on Russell Island, farther east in Georgian Bay is that of the "Griffon".
Thunder Bay.
The Thunder Bay National Marine Sanctuary and Underwater Preserve is home to 116 historically significant shipwrecks. It is the 13th National Marine Sanctuary designated by the National Oceanic and Atmospheric Administration, established in 2000. Glass-bottom boat tours depart from Alpena, Michigan, providing tourists with views of some of the famous shipwrecks in Thunder Bay.
Saginaw Bay.
Within the waters of Saginaw Bay are 185 of 1,000+ wrecks.
Matoa, a propeller freighter weighing 2,311 gross tons, was built in Cleveland in 1890, and was wrecked in 1913 on Port Austin Reef.
Georgian Bay, North Channel.
Georgian Bay, the largest bay on Lake Huron, contains 212 of the 1,000 sunken vessels in the lake.
Manola, a propeller freighter of 2,325 gross tons, was built in 1890 by the Globe Shipping Company of Cleveland, Ohio. It was operated by the Minnesota Steamship Company (Cleveland) from 1890–1901, and by the Pittsburgh Steamship Company from 1901–1918. On January 25, 1918, the Manola was sold to the U.S. Shipping Board. It was sold again in 1920 to the Canada Steamship Lines, Ltd., and renamed the Mapledawn. It became stranded on November 20, 1924, on Christian Island in Georgian Bay. Headed for Port McNichol, Ontario, it was declared a total loss after two weeks. Salvagers were able to recover approximately 75,000 bushels of barley for delivery to Midland, Ontario.
Ecology.
Lake Huron has a lake retention time of 22 years.
Like all of the Great Lakes, the ecology of Lake Huron has undergone drastic changes in the last century. The lake originally supported a native deepwater fish community dominated by lake trout, which fed on a number of deepwater ciscos as well as sculpins and other native fishes. Several invasive species, including sea lamprey, alewife and rainbow smelt, became abundant in the lake by the 1930s. The major native top predator, lake trout, were virtually extirpated from the lake by 1950 due to a combination of overfishing and the effects of sea lamprey. Several species of deepwater ciscos were also extirpated from the lake by the 1960s; the only remaining native deepwater cisco is the bloater. Nonnative Pacific salmon have been stocked in the lake since the 1960s, and lake trout have also been stocked in an attempt to rehabilitate the species, although little natural reproduction of stocked trout has been observed.
Lake Huron has suffered recently due the introduction of a variety of new invasive species, including zebra and quagga mussels, the spiny water flea, and round gobies. The deepwater demersal fish community of the lake was in a state of collapse by 2006, and a number of drastic changes have been observed in the zooplankton community of the lake. Chinook salmon catches have also been greatly reduced in recent years, and lake whitefish have become less abundant and are in poor condition. These recent changes may be attributable to the new exotic species.

</doc>
<doc id="51058" url="https://en.wikipedia.org/wiki?curid=51058" title="Feminist literary criticism">
Feminist literary criticism

Feminist literary criticism is literary criticism informed by feminist theory, or, more broadly, by the politics of feminism. It uses feminist principles and ideology to critique the language of literature. This school of thought seeks to analyze and describe the ways in which literature portrays the narrative of male domination by exploring the economic, social, political, and psychological forces embedded within literature.
Its history has been broad and varied, from classic works of nineteenth-century women authors such as George Eliot and Margaret Fuller to cutting-edge theoretical work in women's studies and gender studies by "third-wave" authors. In general, feminist literary criticism before the 1970s—in the first and second waves of feminism—was concerned with women's authorship and the representation of women's condition within literature; including the depiction of fictional female characters. In addition, feminist criticism was concerned with the exclusion of women from the literary canon. 
Lois Tyson suggests this is because the views of women authors are often not considered to be universal ones.
Since the development of more complex conceptions of gender and subjectivity and third-wave feminism, feminist literary criticism has taken a variety of new routes, namely in the tradition of the Frankfurt School's critical theory. It has considered gender in the terms of Freudian and Lacanian psychoanalysis, as part of the deconstruction of existing relations of power, and as a concrete political investment. It has been closely associated with the birth and growth of queer studies. The more traditionally central feminist concern with the representation and politics of women's lives has continued to play an active role in criticism. More specifically, modern feminist criticism deals with those issues related to the perceived intentional and unintentional patriarchal programming within key aspects of society including education, politics and the work force.
Lisa Tuttle has defined feminist theory as asking "new questions of old texts." She cites the goals of feminist criticism as: (1) To develop and uncover a female tradition of writing, (2) to interpret symbolism of women's writing so that it will not be lost or ignored by the male point of view, (3) to rediscover old texts, (4) to analyze women writers and their writings from a female perspective, (5) to resist sexism in literature, and (6) to increase awareness of the sexual politics of language and style.
Methods employed.
Feminist scholarship has developed a multitude of ways to unpack literature in order to understand its essence. Scholars under the camp known as Feminine Critique sought to divorce literary analysis away from abstract diction-based arguments and instead tailored their criticism to more “grounded” pieces of literature (plot, characters, etc.) and recognize the perceived implicit misogyny of the structure of the story itself. Others schools of thought such as gynocriticism uses a historicist approach to literature by exposing exemplary female scholarship in literature and the ways in which their relation to gender structure relayed in their portrayal of both fiction and reality in their texts.
More contemporary scholars attempt to understand the intersecting points of femininity and complicate our common assumptions about gender politics by accessing different categories of identity (race, class, sexual orientation, etc.) The ultimate goal of any of these tools is to uncover and expose patriarchal underlying tensions within novels and interrogate the ways in which our basic literary assumptions about such novels are contingent on female subordination. In this way, the accessibility of literature broadens to a far more inclusive and holistic population. Moreover, works that historically received little or no attention, given the historical constraints around female authorship in some cultures, are able to be heard in their original form and unabridged. This makes a broader collection of literature for all readers insofar as all great works of literature are given exposure without bias towards a gender influenced system.
Women have also begun to employ anti-patriarchal themes to protest the historical censorship of literature written by women. The rise of decadent feminist literature in the 1990s was meant to directly challenge the sexual politics of the patriarchy. By employing a wide range of female sexual exploration and lesbian and queer identities by those like Rita Felski and Judith Bennet, women were able attract more attention about feminist topics in literature.
History and critics.
Modern feminist literary criticism finds its roots in the 1960s second-wave feminist movements. Beginning with the interrogation of male-centric literature that portrayed women in a demeaning and oppressed model, theorist such as Mary Ellman, Kate Millet and Germaine Greer challenged past imaginations of the feminine within literary scholarship.
Elain Showalter became a leading critic in the gynocritical method with her work "A Literature of their Own" in 1977. By this time, scholars were not only interested in simply demarcating narratives of oppression but also creating a literary space for past, present and future female literary scholars to substantiate their experience in a genuine way that appreciates the aesthetic form of their works.
French scholars such as Julia Kristeva, Hélène Cixous, and Luce Irigaray introduced psychoanalytic discourses into their work by way of Sigmund Freud and Jacques Lacan as a way to truly “get to the root” of feminine anxieties within text to manifest broader societal truths about the place of women. Current feminist scholars in the field of literature include Hortense Spillers, Susan Gubar, Nancy Armstrong, Annette Kolodny and Irene Tayler who all come from a variety of backgrounds who use their own nuanced and subjective experiences to inform their understanding of feminist literature. Currently, several university scholars all employ the usage of literary feminism when critiquing texts. The mainstreaming of this school has given academia an extremely useful tool in raising questions over the gender relationships within texts.
Black literary feminist scholars began to emerge, in the post-Civil Rights era of the United States, as a response to the masculine-centric narratives of Black empowerments began to gain momentum over female voices. Although not a ”critical” text, "The Black Woman: An Anthology", edited by Cade (1970) is seen as essential to the rise of Black literary criticism and theory. It’s compilation of poems, short stories and essays gave rise to new institutionally supported forms of Black literary scholarship. The literary scholarship also included began with the perception of Black female writers being under received relative to their talent. The Combahee River Collective released what is called one of the most famous pieces in Black literary scholarship known as "A Black Feminist Statement" (1977), which sought to prove that literary feminism was an important component to black female liberation.
Hazel Carby, Barbara Christian, bell hooks, Nellie McKay, Valerie Smith, Hortense Spillers, Eleanor Traylor, Cheryl Wall and Sheryl Ann Williams all contributed heavily to the Black Feminist Scholarship during the 1980s. During that same time, Deborah E. McDowell published "New Directions for Black Feminist Criticism", which called for a more theoretical school of criticism versus the current writings, which she deemed overly practical. As time moved forward, theory began to disperse in ideology. Many deciding to shift towards the nuanced psychological factors of the Black experience and further away from broad sweeping generalizations. Others began to connect their works to the politics of lesbianism. Some decided to analyze the Black experience through their relationship to the Western world. Regardless, these scholars continue to employ a variety of methods to explore the identity of Black feminism in literature.

</doc>
<doc id="51062" url="https://en.wikipedia.org/wiki?curid=51062" title="Sewer">
Sewer

Sewer may refer to:

</doc>
<doc id="51067" url="https://en.wikipedia.org/wiki?curid=51067" title="Anomie">
Anomie

Anomie () is a "condition in which society provides little moral guidance to individuals". It is the breakdown of social bonds between an individual and the community, e.g., under unruly scenarios resulting in fragmentation of social identity and rejection of self-regulatory values. It was popularized by French sociologist Émile Durkheim in his influential book "Suicide" (1897). Durkheim never uses the term "normlessness"; rather, he describes anomie as "derangement", and "an insatiable will".
For Durkheim, anomie arises more generally from a mismatch between personal or group standards and wider social standards, or from the lack of a social ethic, which produces moral deregulation and an absence of legitimate aspirations. This is a nurtured condition:
History.
In 1893, Durkheim introduced the concept of "anomie" to describe the mismatch of collective guild labour to evolving societal needs when the guild was homogeneous in its constituency. He equated homogeneous (redundant) skills to "mechanical solidarity" whose inertia retarded adaptation. He contrasted this with the self-regulating behaviour of a division of labour based on differences in constituency, equated to "organic solidarity", whose lack of inertia made it sensitive to need changes.
Durkheim observed that the conflict between the evolved organic division of labour and the homogeneous mechanical type was such that one could not exist in the presence of the other.
When solidarity is organic, anomie is impossible. Sensitivity to mutual needs promotes evolution in the division of labour. "Producers, being near consumers, can easily reckon the extent of the needs to be satisfied. Equilibrium is established without any trouble and production regulates itself." Durkheim contrasted the condition of anomie as being the result of a malfunction of organic solidarity during the transition from mechanical solidarity: But on the contrary, if some opaque environment is interposed... relations rare, are not repeated enough... are too intermittent. Contact is no longer sufficient. The producer can no longer embrace the market at a glance, nor even in thought. He can no longer see its limits, since it is, so to speak limitless. Accordingly, production becomes unbridled and unregulated.
Durkheim's use of the term anomie was about a phenomenon of industrialization—mass-regimentation that could not adapt due to its own inertia—its resistance to change, which causes disruptive cycles of collective behavior e.g. economics, due to the necessity of a prolonged buildup of sufficient force or momentum to overcome the inertia.
Later in 1897, in his studies of suicide, Durkheim associated anomie to the influence of a lack of norms or norms that were too rigid. But such normlessness or norm-rigidity was a "symptom of anomie", caused by the lack of differential adaptation that would enable norms to evolve naturally due to self-regulation, either to develop norms where none existed or to change norms that had become rigid and obsolete.
Etymology.
The word comes from Greek ἀνομία, namely the prefix "a-" "without", and "nomos" "law". The Greeks distinguished between "nomos" (νόμος, "law"), and "arché" (ἀρχή, "starting rule, axiom, principle"). For example, a monarch is a single ruler but he or she might still be subject to, and not exempt from, the prevailing laws, i.e. "nomos". In the original city state democracy, the majority rule was an aspect of "arché" because it was a rule-based, customary system, which might or might not make laws, i.e. "nomos". Thus, the original meaning of "anomie" defined anything or anyone against or outside the law, or a condition where the current laws were not applied resulting in a state of illegitimacy or lawlessness.
The contemporary English understanding of the word "anomie" can accept greater flexibility in the word "norm", and some have used the idea of normlessness to reflect a similar situation to the idea of anarchy. But, as used by Émile Durkheim and later theorists, "anomie" is a reaction against or a retreat from the regulatory social controls of society, and is a completely separate concept from anarchy, which consists of the absence of the roles of rulers and submitted.
Social disorder.
The nineteenth century French pioneer sociologist Émile Durkheim borrowed the word from French philosopher Jean-Marie Guyau and used it in his influential book "Suicide" (1897), outlining the social (and not individual) causes of suicide, characterized by a rapid change of the standards or values of societies (often erroneously referred to as normlessness), and an associated feeling of alienation and purposelessness. He believed that "anomie" is common when the surrounding society has undergone significant changes in its economic fortunes, whether for better or for worse and, more generally, when there is a significant discrepancy between the ideological theories and values commonly professed and what was actually achievable in everyday life. This was contrary to previous theories on suicide which generally maintained that suicide was precipitated by negative events in a person's life and their subsequent depression.
In Durkheim's view, traditional religions often provided the basis for the shared values which the anomic individual lacks. Furthermore, he argued that the division of labor that had been prevalent in economic life since the Industrial Revolution led individuals to pursue egoistic ends rather than seeking the good of a larger community. Robert King Merton also adopted the idea of anomie to develop strain theory, defining it as the discrepancy between common social goals and the legitimate means to attain those goals. In other words, an individual suffering from anomie would strive to attain the common goals of a specific society yet would not be able to reach these goals legitimately because of the structural limitations in society. As a result, the individual would exhibit deviant behavior. Friedrich Hayek notably uses the word "anomie" with this meaning.
According to one academic survey, psychometric testing confirmed a link between anomie and academic dishonesty among university students, suggesting that universities needed to foster codes of ethics among students in order to curb it. In another study, anomie was seen as a "push factor" in tourism.
As an older variant, the "Webster 1913 Dictionary" reports use of the word "anomie" as meaning "disregard or violation of the law" but anomie as a social disorder is not to be confused with anarchy. Proponents of anarchism claim that anarchy does not necessarily lead to anomie and that hierarchical command actually increases lawlessness. Some anarcho-primitivists like Ted Kaczynski argue that complex societies, particularly industrial and post-industrial societies, directly cause conditions such as anomie by depriving the individual of self-determination and a relatively small reference group to relate to, such as the band, clan, or tribe.
In literature, film, and theatre.
In Albert Camus's existentialist novel "The Stranger", the bored, alienated protagonist Meursault struggles to construct an individual system of values as he responds to the disappearance of the old. He exists largely in a state of anomie, as seen from the apathy evinced in the opening lines: "" ("Today mother died. Or maybe yesterday, I don't know").
Fyodor Dostoyevsky expressed a similar concern about anomie in his novel, "The Brothers Karamazov". The Grand Inquisitor remarks that in the absence of God and immortal life, everything would be lawful. In other words, that any act becomes thinkable, that there is no moral compass, which leads to apathy and detachment.

</doc>
<doc id="51070" url="https://en.wikipedia.org/wiki?curid=51070" title="Conventional superconductor">
Conventional superconductor

Conventional superconductors are materials that display superconductivity as described by BCS theory or its extensions. This is in contrast to unconventional superconductors, which do not. Conventional superconductors can be either type-I or type-II.
Most elemental superconductors are conventional. Niobium and vanadium are type-II, while most other elemental superconductors are type-I. Critical temperatures of some elemental superconductors:
Most compound and alloy superconductors are type-II materials. The most commonly used conventional superconductor in applications is a niobium-titanium alloy - this is a type-II superconductor with a superconducting critical temperature of 11 K. The highest critical temperature so far achieved in a conventional superconductor was 39 K (-234 °C) in magnesium diboride.

</doc>
<doc id="51072" url="https://en.wikipedia.org/wiki?curid=51072" title="Natural deduction">
Natural deduction

In logic and proof theory, natural deduction is a kind of proof calculus in which logical reasoning is expressed by inference rules closely related to the "natural" way of reasoning. This contrasts with the axiomatic systems which instead use axioms as much as possible to express the logical laws of deductive reasoning.
Motivation.
Natural deduction grew out of a context of dissatisfaction with the axiomatizations of deductive reasoning common to the systems of Hilbert, Frege, and Russell (see, e.g., Hilbert system). Such axiomatizations were most famously used by Russell and Whitehead in their mathematical treatise "Principia Mathematica". Spurred on by a series of seminars in Poland in 1926 by Łukasiewicz that advocated a more natural treatment of logic, Jaśkowski made the earliest attempts at defining a more natural deduction, first in 1929 using a diagrammatic notation, and later updating his proposal in a sequence of papers in 1934 and 1935. His proposals led to different notations
such as Fitch-style calculus (or Fitch's diagrams) or Suppes' method of which e.g. Lemmon gave a variant called system L.
Natural deduction in its modern form was independently proposed by the German mathematician Gentzen in 1934, in a dissertation delivered to the faculty of mathematical sciences of the University of Göttingen. The term "natural deduction" (or rather, its German equivalent "natürliches Schließen") was coined in that paper:
Gentzen was motivated by a desire to establish the consistency of number theory. He was unable to prove the main result required for the consistency result, the cut elimination theorem — the Hauptsatz — directly for Natural Deduction. For this reason he introduced his alternative system, the sequent calculus, for which he proved the Hauptsatz both for classical and intuitionistic logic. In a series of seminars in 1961 and 1962 Prawitz gave a comprehensive summary of natural deduction calculi, and transported much of Gentzen's work with sequent calculi into the natural deduction framework. His 1965 monograph "Natural deduction: a proof-theoretical study" was to become a reference work on natural deduction, and included applications for modal and second-order logic.
In natural deduction, a proposition is deduced from a collection of premises by applying inference rules repeatedly. The system presented in this article is a minor variation of Gentzen's or Prawitz's formulation, but with a closer adherence to Martin-Löf's description of logical judgments and connectives.
Judgments and propositions.
A "judgment" is something that is knowable, that is, an object of knowledge. It is "evident" if one in fact knows it. Thus ""it is raining"" is a judgment, which is evident for the one who knows that it is actually raining; in this case one may readily find evidence for the judgment by looking outside the window or stepping out of the house. In mathematical logic however, evidence is often not as directly observable, but rather deduced from more basic evident judgments. The process of deduction is what constitutes a "proof"; in other words, a judgment is evident if one has a proof for it.
The most important judgments in logic are of the form ""A is true"". The letter "A" stands for any expression representing a "proposition"; the truth judgments thus require a more primitive judgment: ""A is a proposition"". Many other judgments have been studied; for example, ""A is false"" (see classical logic), ""A is true at time t"" (see temporal logic), ""A is necessarily true"" or ""A is possibly true"" (see modal logic), ""the program M has type τ"" (see programming languages and type theory), ""A is achievable from the available resources"" (see linear logic), and many others. To start with, we shall concern ourselves with the simplest two judgments ""A is a proposition"" and ""A is true"", abbreviated as ""A" prop" and ""A" true" respectively.
The judgment ""A" prop" defines the structure of valid proofs of "A", which in turn defines the structure of propositions. For this reason, the inference rules for this judgment are sometimes known as "formation rules". To illustrate, if we have two propositions "A" and "B" (that is, the judgments ""A" prop" and ""B" prop" are evident), then we form the compound proposition "A and B", written symbolically as "formula_1". We can write this in the form of an inference rule:
formula_2
where the parentheses are omitted to make the inference rule more succinct:
formula_3
This inference rule is "schematic": "A" and "B" can be instantiated with any expression. The general form of an inference rule is:
formula_4
where each formula_5 is a judgment and the inference rule is named "name". The judgments above the line are known as "premises", and those below the line are "conclusions". Other common logical propositions are disjunction (formula_6), negation (formula_7), implication (formula_8), and the logical constants truth (formula_9) and falsehood (formula_10). Their formation rules are below.
formula_11
Introduction and elimination.
Now we discuss the ""A" true" judgment. Inference rules that introduce a logical connective in the conclusion are known as "introduction rules". To introduce conjunctions, "i.e.", to conclude ""A and B" true" for propositions "A" and "B", one requires evidence for ""A" true" and ""B" true". As an inference rule:
formula_12
It must be understood that in such rules the objects are propositions. That is, the above rule is really an abbreviation for:
formula_13
This can also be written:
formula_14
In this form, the first premise can be satisfied by the formula_15 formation rule, giving the first two premises of the previous form. In this article we shall elide the "prop" judgments where they are understood. In the nullary case, one can derive truth from no premises.
formula_16
If the truth of a proposition can be established in more than one way, the corresponding connective has multiple introduction rules.
formula_17
Note that in the nullary case, "i.e.", for falsehood, there are "no" introduction rules. Thus one can never infer falsehood from simpler judgments.
Dual to introduction rules are "elimination rules" to describe how to de-construct information about a compound proposition into information about its constituents. Thus, from ""A ∧ B" true", we can conclude ""A" true" and ""B" true":
formula_18
As an example of the use of inference rules, consider commutativity of conjunction. If "A ∧ B" is true, then "B ∧ A" is true; This derivation can be drawn by composing inference rules in such a fashion that premises of a lower inference match the conclusion of the next higher inference.
formula_19
The inference figures we have seen so far are not sufficient to state the rules of implication introduction or disjunction elimination; for these, we need a more general notion of "hypothetical derivation".
Hypothetical derivations.
A pervasive operation in mathematical logic is "reasoning from assumptions". For example, consider the following derivation:
formula_20
This derivation does not establish the truth of "B" as such; rather, it establishes the following fact:
In logic, one says ""assuming A ∧ (B ∧ C) is true, we show that B is true""; in other words, the judgment ""B true"" depends on the assumed judgment ""A ∧ (B ∧ C) true"". This is a "hypothetical derivation", which we write as follows:
formula_21
The interpretation is: ""B true" is derivable from "A ∧ (B ∧ C) true"". Of course, in this specific example we actually know the derivation of ""B true"" from ""A ∧ (B ∧ C) true"", but in general we may not "a-priori" know the derivation. The general form of a hypothetical derivation is:
formula_22
Each hypothetical derivation has a collection of "antecedent" derivations (the "Di") written on the top line, and a "succedent" judgment ("J") written on the bottom line. Each of the premises may itself be a hypothetical derivation. (For simplicity, we treat a judgment as a premise-less derivation.)
The notion of hypothetical judgment is "internalised" as the connective of implication. The introduction and elimination rules are as follows.
formula_23
In the introduction rule, the antecedent named "u" is "discharged" in the conclusion. This is a mechanism for delimiting the "scope" of the hypothesis: its sole reason for existence is to establish ""B true""; it cannot be used for any other purpose, and in particular, it cannot be used below the introduction. As an example, consider the derivation of ""A ⊃ (B ⊃ (A ∧ B)) true"":
formula_24
This full derivation has no unsatisfied premises; however, sub-derivations "are" hypothetical. For instance, the derivation of ""B ⊃ (A ∧ B) true"" is hypothetical with antecedent ""A true"" (named "u").
With hypothetical derivations, we can now write the elimination rule for disjunction:
formula_25
In words, if "A ∨ B" is true, and we can derive "C true" both from "A true" and from "B true", then "C" is indeed true. Note that this rule does not commit to either "A true" or "B true". In the zero-ary case, "i.e." for falsehood, we obtain the following elimination rule:
formula_26
This is read as: if falsehood is true, then any proposition "C" is true.
Negation is similar to implication.
formula_27
The introduction rule discharges both the name of the hypothesis "u", and the succedent "p", "i.e.", the proposition "p" must not occur in the conclusion " A". Since these rules are schematic, the interpretation of the introduction rule is: if from ""A true"" we can derive for every proposition "p" that ""p true"", then "A" must be false, "i.e.", ""not A true"". For the elimination, if both "A" and "not A" are shown to be true, then there is a contradiction, in which case every proposition "C" is true. Because the rules for implication and negation are so similar, it should be fairly easy to see that "not A" and "A ⊃ ⊥" are equivalent, i.e., each is derivable from the other.
Consistency, completeness, and normal forms.
A theory is said to be consistent if falsehood is not provable (from no assumptions) and is complete if every theorem is provable using the inference rules of the logic. These are statements about the entire logic, and are usually tied to some notion of a model. However, there are local notions of consistency and completeness that are purely syntactic checks on the inference rules, and require no appeals to models. The first of these is local consistency, also known as local reducibility, which says that any derivation containing an introduction of a connective followed immediately by its elimination can be turned into an equivalent derivation without this detour. It is a check on the "strength" of elimination rules: they must not be so strong that they include knowledge not already contained in its premises. As an example, consider conjunctions.
Dually, local completeness says that the elimination rules are strong enough to decompose a connective into the forms suitable for its introduction rule. Again for conjunctions:
These notions correspond exactly to β-reduction (beta reduction) and η-conversion (eta conversion) in the lambda calculus, using the Curry–Howard isomorphism. By local completeness, we see that every derivation can be converted to an equivalent derivation where the principal connective is introduced. In fact, if the entire derivation obeys this ordering of eliminations followed by introductions, then it is said to be "normal". In a normal derivation all eliminations happen above introductions. In most logics, every derivation has an equivalent normal derivation, called a "normal form". The existence of normal forms is generally hard to prove using natural deduction alone, though such accounts do exist in the literature, most notably by Dag Prawitz in 1961. It is much easier to show this indirectly by means of a cut-free sequent calculus presentation.
First and higher-order extensions.
The logic of the earlier section is an example of a "single-sorted" logic, "i.e.", a logic with a single kind of object: propositions. Many extensions of this simple framework have been proposed; in this section we will extend it with a second sort of "individuals" or "terms". More precisely, we will add a new kind of judgment, ""t is a term"" (or ""t term"") where "t" is schematic. We shall fix a countable set "V" of "variables", another countable set "F" of "function symbols", and construct terms as follows:
For propositions, we consider a third countable set "P" of "predicates", and define "atomic predicates over terms" with the following formation rule:
In addition, we add a pair of "quantified" propositions: universal (∀) and existential (∃):
These quantified propositions have the following introduction and elimination rules.
In these rules, the notation ["t"/"x"] "A" stands for the substitution of "t" for every (visible) instance of "x" in "A", avoiding capture; see the article on lambda calculus for more detail about this standard operation. As before the superscripts on the name stand for the components that are discharged: the term "a" cannot occur in the conclusion of ∀I (such terms are known as "eigenvariables" or "parameters"), and the hypotheses named "u" and "v" in ∃E are localised to the second premise in a hypothetical derivation. Although the propositional logic of earlier sections was decidable, adding the quantifiers makes the logic undecidable.
So far the quantified extensions are "first-order": they distinguish propositions from the kinds of objects quantified over. Higher-order logic takes a different approach and has only a single sort of propositions. The quantifiers have as the domain of quantification the very same sort of propositions, as reflected in the formation rules:
A discussion of the introduction and elimination forms for higher-order logic is beyond the scope of this article. It is possible to be in between first-order and higher-order logics. For example, second-order logic has two kinds of propositions, one kind quantifying over terms, and the second kind quantifying over propositions of the first kind.
Different presentations of natural deduction.
Tree-like presentations.
Gentzen's discharging annotations used to internalise hypothetical judgments can be avoided by representing proofs as a tree of sequents "Γ ⊢A" instead of a tree of "A true" judgments.
Sequential presentations.
Jaśkowski's representations of natural deduction led to different notations such as Fitch-style calculus (or Fitch's diagrams) or Suppes' method, of which Lemmon gave a variant called system L. Such presentation systems, which are more accurately described as tabular, include the following.
Proofs and type-theory.
The presentation of natural deduction so far has concentrated on the nature of propositions without giving a formal definition of a "proof". To formalise the notion of proof, we alter the presentation of hypothetical derivations slightly. We label the antecedents with "proof variables" (from some countable set "V" of variables), and decorate the succedent with the actual proof. The antecedents or "hypotheses" are separated from the succedent by means of a "turnstile" (⊢). This modification sometimes goes under the name of "localised hypotheses". The following diagram summarises the change.
The collection of hypotheses will be written as Γ when their exact composition is not relevant.
To make proofs explicit, we move from the proof-less judgment ""A true"" to a judgment: "π "is a proof of (A true)"", which is written symbolically as "π : "A true"". Following the standard approach, proofs are specified with their own formation rules for the judgment "π "proof"". The simplest possible proof is the use of a labelled hypothesis; in this case the evidence is the label itself.
For brevity, we shall leave off the judgmental label "true" in the rest of this article, "i.e.", write "Γ ⊢ π : "A"". Let us re-examine some of the connectives with explicit proofs. For conjunction, we look at the introduction rule ∧I to discover the form of proofs of conjunction: they must be a pair of proofs of the two conjuncts. Thus:
The elimination rules ∧E1 and ∧E2 select either the left or the right conjunct; thus the proofs are a pair of projections — first (fst) and second (snd).
For implication, the introduction form localises or "binds" the hypothesis, written using a λ; this corresponds to the discharged label. In the rule, "Γ, "u":"A"" stands for the collection of hypotheses Γ, together with the additional hypothesis "u".
With proofs available explicitly, one can manipulate and reason about proofs. The key operation on proofs is the substitution of one proof for an assumption used in another proof. This is commonly known as a "substitution theorem", and can be proved by induction on the depth (or structure) of the second judgment.
So far the judgment "Γ ⊢ π : "A"" has had a purely logical interpretation. In type theory, the logical view is exchanged for a more computational view of objects. Propositions in the logical interpretation are now viewed as "types", and proofs as programs in the lambda calculus. Thus the interpretation of "π : "A"" is ""the program" π has type "A"". The logical connectives are also given a different reading: conjunction is viewed as product (×), implication as the function arrow (→), etc. The differences are only cosmetic, however. Type theory has a natural deduction presentation in terms of formation, introduction and elimination rules; in fact, the reader can easily reconstruct what is known as "simple type theory" from the previous sections.
The difference between logic and type theory is primarily a shift of focus from the types (propositions) to the programs (proofs). Type theory is chiefly interested in the convertibility or reducibility of programs. For every type, there are canonical programs of that type which are irreducible; these are known as "canonical forms" or "values". If every program can be reduced to a canonical form, then the type theory is said to be "normalising" (or "weakly normalising"). If the canonical form is unique, then the theory is said to be "strongly normalising". Normalisability is a rare feature of most non-trivial type theories, which is a big departure from the logical world. (Recall that almost every logical derivation has an equivalent normal derivation.) To sketch the reason: in type theories that admit recursive definitions, it is possible to write programs that never reduce to a value; such looping programs can generally be given any type. In particular, the looping program has type ⊥, although there is no logical proof of "⊥ "true"". For this reason, the "propositions as types; proofs as programs" paradigm only works in one direction, if at all: interpreting a type theory as a logic generally gives an inconsistent logic.
Like logic, type theory has many extensions and variants, including first-order and higher-order versions. An interesting branch of type theory, known as dependent type theory, allows quantifiers to range over programs themselves. These quantified types are written as Π and Σ instead of ∀ and ∃, and have the following formation rules:
These types are generalisations of the arrow and product types, respectively, as witnessed by their introduction and elimination rules.
Dependent type theory in full generality is very powerful: it is able to express almost any conceivable property of programs directly in the types of the program. This generality comes at a steep price — either typechecking is undecidable (extensional type theory), or extensional reasoning is more difficult (intensional type theory). For this reason, some dependent type theories do not allow quantification over arbitrary programs, but rather restrict to programs of a given decidable "index domain", for example integers, strings, or linear programs.
Since dependent type theories allow types to depend on programs, a natural question to ask is whether it is possible for programs to depend on types, or any other combination. There are many kinds of answers to such questions. A popular approach in type theory is to allow programs to be quantified over types, also known as "parametric polymorphism"; of this there are two main kinds: if types and programs are kept separate, then one obtains a somewhat more well-behaved system called "predicative polymorphism"; if the distinction between program and type is blurred, one obtains the type-theoretic analogue of higher-order logic, also known as "impredicative polymorphism". Various combinations of dependency and polymorphism have been considered in the literature, the most famous being the lambda cube of Henk Barendregt.
The intersection of logic and type theory is a vast and active research area. New logics are usually formalised in a general type theoretic setting, known as a logical framework. Popular modern logical frameworks such as the calculus of constructions and LF are based on higher-order dependent type theory, with various trade-offs in terms of decidability and expressive power. These logical frameworks are themselves always specified as natural deduction systems, which is a testament to the versatility of the natural deduction approach.
Classical and modal logics.
For simplicity, the logics presented so far have been intuitionistic. Classical logic extends intuitionistic logic with an additional axiom or principle of excluded middle:
This statement is not obviously either an introduction or an elimination; indeed, it involves two distinct connectives. Gentzen's original treatment of excluded middle prescribed one of the following three (equivalent) formulations, which were already present in analogous forms in the systems of Hilbert and Heyting:
(XM3 is merely XM2 expressed in terms of E.) This treatment of excluded middle, in addition to being objectionable from a purist's standpoint, introduces additional complications in the definition of normal forms.
A comparatively more satisfactory treatment of classical natural deduction in terms of introduction and elimination rules alone was first proposed by Parigot in 1992 in the form of a classical lambda calculus called λμ. The key insight of his approach was to replace a truth-centric judgment "A true" with a more classical notion, reminiscent of the sequent calculus: in localised form, instead of Γ ⊢ "A", he used Γ ⊢ Δ, with Δ a collection of propositions similar to Γ. Γ was treated as a conjunction, and Δ as a disjunction. This structure is essentially lifted directly from classical sequent calculi, but the innovation in λμ was to give a computational meaning to classical natural deduction proofs in terms of a callcc or a throw/catch mechanism seen in LISP and its descendants. (See also: first class control.)
Another important extension was for modal and other logics that need more than just the basic judgment of truth. These were first described, for the alethic modal logics S4 and S5, in a natural deduction style by Prawitz in 1965, and have since accumulated a large body of related work. To give a simple example, the modal logic S4 requires one new judgment, ""A valid"", that is categorical with respect to truth:
This categorical judgment is internalised as a unary connective ◻"A" (read ""necessarily A"") with the following introduction and elimination rules:
Note that the premise ""A valid"" has no defining rules; instead, the categorical definition of validity is used in its place. This mode becomes clearer in the localised form when the hypotheses are explicit. We write "Ω;Γ ⊢ "A true"" where Γ contains the true hypotheses as before, and Ω contains valid hypotheses. On the right there is just a single judgment ""A true""; validity is not needed here since "Ω ⊢ "A valid"" is by definition the same as "Ω;⋅ ⊢ "A true"". The introduction and elimination forms are then:
The modal hypotheses have their own version of the hypothesis rule and substitution theorem.
This framework of separating judgments into distinct collections of hypotheses, also known as "multi-zoned" or "polyadic" contexts, is very powerful and extensible; it has been applied for many different modal logics, and also for linear and other substructural logics, to give a few examples. However, relatively few systems of modal logic can be formalised directly in natural deduction. To give proof-theoretic characterisations of these systems, extensions such as labelling or systems of deep inference.
The addition of labels to formulae permits much finer control of the conditions under which rules apply, allowing the more flexible techniques of analytic tableaux to be applied, as has been done in the case of labelled deduction. Labels also allow the naming of worlds in Kripke semantics; presents an influential technique for converting frame conditions of modal logics in Kripke semantics into inference rules in a natural deduction formalisation of hybrid logic. surveys the application of many proof theories, such as Avron and Pottinger's hypersequents and Belnap's display logic to such modal logics as S5 and B.
Comparison with other foundational approaches.
Sequent calculus.
The sequent calculus is the chief alternative to natural deduction as a foundation of mathematical logic. In natural deduction the flow of information is bi-directional: elimination rules flow information downwards by deconstruction, and introduction rules flow information upwards by assembly. Thus, a natural deduction proof does not have a purely bottom-up or top-down reading, making it unsuitable for automation in proof search. To address this fact, Gentzen in 1935 proposed his sequent calculus, though he initially intended it as a technical device for clarifying the consistency of predicate logic. Kleene, in his seminal 1952 book "Introduction to Metamathematics", gave the first formulation of the sequent calculus in the modern style.
In the sequent calculus all inference rules have a purely bottom-up reading. Inference rules can apply to elements on both sides of the turnstile. (To differentiate from natural deduction, this article uses a double arrow ⇒ instead of the right tack ⊢ for sequents.) The introduction rules of natural deduction are viewed as "right rules" in the sequent calculus, and are structurally very similar. The elimination rules on the other hand turn into "left rules" in the sequent calculus. To give an example, consider disjunction; the right rules are familiar:
On the left:
Recall the ∨E rule of natural deduction in localised form:
The proposition "A ∨ B", which is the succedent of a premise in ∨E, turns into a hypothesis of the conclusion in the left rule ∨L. Thus, left rules can be seen as a sort of inverted elimination rule. This observation can be illustrated as follows:
In the sequent calculus, the left and right rules are performed in lock-step until one reaches the "initial sequent", which corresponds to the meeting point of elimination and introduction rules in natural deduction. These initial rules are superficially similar to the hypothesis rule of natural deduction, but in the sequent calculus they describe a "transposition" or a "handshake" of a left and a right proposition:
The correspondence between the sequent calculus and natural deduction is a pair of soundness and completeness theorems, which are both provable by means of an inductive argument.
It is clear by these theorems that the sequent calculus does not change the notion of truth, because the same collection of propositions remain true. Thus, one can use the same proof objects as before in sequent calculus derivations. As an example, consider the conjunctions. The right rule is virtually identical to the introduction rule
The left rule, however, performs some additional substitutions that are not performed in the corresponding elimination rules.
The kinds of proofs generated in the sequent calculus are therefore rather different from those of natural deduction. The sequent calculus produces proofs in what is known as the "β-normal η-long" form, which corresponds to a canonical representation of the normal form of the natural deduction proof. If one attempts to describe these proofs using natural deduction itself, one obtains what is called the "intercalation calculus" (first described by John Byrnes), which can be used to formally define the notion of a "normal form" for natural deduction.
The substitution theorem of natural deduction takes the form of a structural rule or structural theorem known as "cut" in the sequent calculus.
In most well behaved logics, cut is unnecessary as an inference rule, though it remains provable as a meta-theorem; the superfluousness of the cut rule is usually presented as a computational process, known as "cut elimination". This has an interesting application for natural deduction; usually it is extremely tedious to prove certain properties directly in natural deduction because of an unbounded number of cases. For example, consider showing that a given proposition is "not" provable in natural deduction. A simple inductive argument fails because of rules like ∨E or E which can introduce arbitrary propositions. However, we know that the sequent calculus is complete with respect to natural deduction, so it is enough to show this unprovability in the sequent calculus. Now, if cut is not available as an inference rule, then all sequent rules either introduce a connective on the right or the left, so the depth of a sequent derivation is fully bounded by the connectives in the final conclusion. Thus, showing unprovability is much easier, because there are only a finite number of cases to consider, and each case is composed entirely of sub-propositions of the conclusion. A simple instance of this is the "global consistency" theorem: "⋅ ⊢ ⊥ "true"" is not provable. In the sequent calculus version, this is manifestly true because there is no rule that can have "⋅ ⇒ ⊥" as a conclusion! Proof theorists often prefer to work on cut-free sequent calculus formulations because of such properties.

</doc>
<doc id="51074" url="https://en.wikipedia.org/wiki?curid=51074" title="Peter Kropotkin">
Peter Kropotkin

Prince Pyotr Alexeyevich Kropotkin (; ; December 9, 1842 – February 8, 1921) was a Russian activist, scientist, and philosopher, who advocated decentralized government and anarchism. Kropotkin was a proponent of a communist society free from central government and based on voluntary associations between workers. He wrote many books, pamphlets and articles, the most prominent being "The Conquest of Bread" and "Fields, Factories and Workshops", and his principal scientific offering, "". He also contributed the article on anarchism to the "Encyclopædia Britannica Eleventh Edition".
Biography.
Early life.
Kropotkin was born in Moscow, into the second-highest level of the Russian aristocracy. His mother was the daughter of a Cossack general. His father, Alexei Petrovich Kropotkin, was a prince in Smolensk, of the Rurik dynasty which had ruled Russia before the rise of the Romanovs. Kropotkin's father owned large tracts of land and nearly 1,200 male serfs in three provinces.
"nder the influence of republican teachings," Kropotkin dropped his princely title at the age of twelve, and "even rebuked his friends, when they so referred to him."
In 1857, at age 14, Kropotkin enrolled in the Corps of Pages at St. Petersburg. Only 150 boys – mostly children of nobility belonging to the court – were educated in this privileged corps, which combined the character of a military school endowed with special rights and of a court institution attached to the Imperial Household. Kropotkin's memoirs detail the hazing and other abuse of pages for which the Corps had become notorious.
In Moscow, Kropotkin had developed an interest in the condition of the peasantry, and this interest increased as he grew older. Although his work as a page for Tsar Alexander II made Kropotkin sceptical about the tsar's "liberal" reputation, Kropotkin was greatly pleased by the tsar's decision to emancipate the serfs in 1861. In St. Petersburg, he read widely on his own account, and gave special attention to the works of the French encyclopædists and to French history. The years 1857–1861 witnessed a growth in the intellectual forces of Russia, and Kropotkin came under the influence of the new liberal-revolutionary literature, which largely expressed his own aspirations.
In 1862, Kropotkin was promoted from the Corps of Pages to the army. The members of the corps had the prescriptive right to choose the regiment to which they would be attached. For some time, he was "aide de camp" to the governor of Transbaikalia at Chita. Later he was appointed attaché for Cossack affairs to the governor-general of East Siberia at Irkutsk.
Geographical expeditions in Siberia.
Administrative work was scarce, and in 1864 Kropotkin accepted charge of a geographical survey expedition, crossing North Manchuria from Transbaikalia to the Amur, and soon was attached to another expedition which proceeded up the Sungari River into the heart of Manchuria. The expeditions yielded valuable geographical results. The impossibility of obtaining any real administrative reforms in Siberia now induced Kropotkin to devote himself almost entirely to scientific exploration, in which he continued to be highly successful.
In 1866, Kropotkin began reading the works of the French anarchist Pierre-Joseph Proudhon, and other political thinkers such as John Stuart Mill and Alexander Herzen. These readings, along with his experiences amongst the peasantry in Siberia, led him to declare himself an anarchist by 1872.
In 1867, Kropotkin resigned his commission in the army and returned to St. Petersburg, where he entered the Saint Petersburg Imperial University to study mathematics, becoming at the same time secretary to the geography section of the Russian Geographical Society. His departure from a family tradition of military service prompted his father to disinherit him, "leaving him a 'prince' with no visible means of support." In 1871, he explored the glacial deposits of Finland and Sweden for the Society. In 1873, he published an important contribution to science, a map and paper in which he showed that the existing maps entirely misrepresented the physical features of Asia; the main structural lines were in fact from southwest to northeast, not from north to south or from east to west as had been previously supposed. During this work, he was offered the secretaryship of the Society, but he had decided that it was his duty not to work at fresh discoveries but to aid in diffusing existing knowledge among the people at large. Accordingly, he refused the offer and returned to St. Petersburg, where he joined the revolutionary party.
Activism in Switzerland and France.
Kropotkin visited Switzerland in 1872 and became a member of the International Workingmen's Association (IWA) at Geneva. It was there that he found that he did not like IWA's style of socialism. Instead, he studied the programme of the more radical Jura federation at Neuchâtel and spent time in the company of the leading members, and adopted the creed of anarchism.
On returning to Russia, Kropotkin's friend Dmitri Klements introduced him to the Circle of Tchaikovsky, a socialist/populist group that had been created in 1872. Kropotkin worked to spread revolutionary propaganda amongst peasants and workers, and acted as a bridge between the Circle and the aristocracy. Throughout this period, Kropotkin maintained his position within the Geographical Society in order to provide cover for his activities.
In 1874 Kropotkin was arrested and imprisoned in the Peter and Paul Fortress for subversive political activity, as a result of his work with the Circle of Tchaikovsky. Because of his aristocratic background, he was granted special privileges while in prison, such as being allowed to continue his geographical work in his cell. He delivered his report on the subject of the Ice Age, where he argued that it had taken place in not as distant a past as originally thought. In 1876, just before his trial, Kropotkin was moved to a low-security prison in St. Petersburg, from which he escaped with the assistance of his friends. On the night of the escape, Kropotkin and his friends celebrated by dining in one of the finest restaurants in St. Petersburg, assuming correctly that the police would not think to look for them there. After this, he boarded a boat, and headed to England. After a short stay there, he moved to Switzerland where he joined the Jura Federation. In 1877 he moved to Paris, where he helped start the socialist movement. In 1878 he returned to Switzerland where he edited the Jura Federation's revolutionary newspaper "Le Révolté", and published various revolutionary pamphlets.
In 1881, shortly after the assassination of Tsar Alexander II, he was expelled from Switzerland. After a short stay at Thonon (Savoy), he went to London where he stayed nearly a year. He attended the Anarchist Congress that met in London from July 14, 1881.
Other delegates included Marie Le Compte, Errico Malatesta, Saverio Merlino, Louise Michel, Nicholas Tchaikovsky and Émile Gautier. While respecting "complete autonomy of local groups" the congress defined propaganda actions that all could follow and agreed that propaganda by the deed was the path to social revolution. "The Radical" of July 23, 1881 reported that the congress met on July 18 at the Cleveland Hall, Fitzroy Square, with speeches by Marie Le Compte, "the transatlantic agitator", Louise Michel, and Kropotkin. Later Le Compte and Kropotkin gave talks to the Homerton Social Democratic Club and to the Stratford Radical and Dialectical Club.
Kropotkin returned to Thonon in late 1882. Soon he was arrested by the French government, tried at Lyon, and sentenced by a police-court magistrate (under a special law passed on the fall of the Paris Commune) to five years' imprisonment, on the ground that he had belonged to the IWA (1883). The French Chamber repeatedly agitated on his behalf, and he was released in 1886. He was invited to Britain by Charlotte Wilson, with whom he co-founded the Freedom Press, an anarchist newspaper which continues to this day. Kropotkin was a regular contributor. He settled near London, living at various times in Harrow – where his daughter, Alexandra, was born – Ealing and Bromley (6 Crescent Road 1886–1914). He also lived for a number of years in Brighton. While living in London, Kropotkin became friends with a number of prominent English-speaking socialists, including William Morris and George Bernard Shaw.
Return to Russia.
In 1917 after the February Revolution, Kropotkin returned to Russia again after years of exile. Upon his arrival, he was greeted by crowds of tens of thousands of people, cheering his return. He was offered the ministry of education in the provisional government, which he promptly refused, feeling that working with them would be a violation of his anarchist principles.
His enthusiasm for the changes happening in the Russian Empire turned to disappointment when the Bolsheviks seized power in the October Revolution. "This buries the revolution," he said. He thought that the Bolsheviks had shown how the revolution was not to be made; by authoritarian rather than libertarian methods. He had spoken out against authoritarian socialism in his writings (for example "The Conquest of Bread"), making the prediction that any state founded on these principles would most likely see its own breakup and the restoration of capitalism.
Death.
Kropotkin died of pneumonia on February 8, 1921, in the city of Dmitrov, and was buried at the Novodevichy Cemetery. Thousands of people marched in his funeral procession, including, with Vladimir Lenin's approval, anarchists carrying banners with anti-Bolshevik slogans. It was to become the last public demonstration of anarchists, which saw engaged speeches by Emma Goldman and Aron Baron. In 1957 the Dvorets Sovetov station of the Moscow Metro was renamed Kropotkinskaya in his honor.
Philosophy.
Critique of capitalism.
Kropotkin pointed out what he considered to be the fallacies of the economic systems of feudalism and capitalism. He believed they create poverty and artificial scarcity while promoting privilege. Instead he proposed a more decentralized economic system based on mutual aid, mutual support, and voluntary cooperation, asserting that the tendencies for this kind of organization already exist, both in evolution and in human society.
Cooperation and competition.
In 1902 Kropotkin published his book "", which provided an alternative view of animal and human survival, beyond the claims of interpersonal competition and natural hierarchy proffered at the time by some "social Darwinists" such as Francis Galton. He argued that "it was an evolutionary emphasis on cooperation instead of competition in the Darwinian sense that made for the success of species, including the human". Kropotkin explored the widespread use of cooperation as a survival mechanism in human societies - through their many stages - and amongst animals. He used many real-life examples in an attempt to show that the main factor in facilitating evolution is cooperation between individuals in free-associated societies and groups, without central control, authority, or compulsion. He did so in order to counteract the concept of fierce competition as the core of evolution, which concept provided a rationalization for the dominant political, economic, and social theories of the time and for the prevalent interpretations of Darwinism. In the last chapter, he wrote:
Kropotkin did not deny the presence of competitive urges in humans, but did not see them as the driving force of history (as did capitalists and social Darwinists). He did believe that at times seeking out conflict proved socially beneficial, but only during attempts to destroy unjust, authoritarian institutions such as the State or the Church, which he saw as stifling human creativity and freedom and impeding humans' instinctual drive towards sociality and cooperation.
Kropotkin's observations of cooperative tendencies in indigenous peoples (pre-feudal, feudal, and those remaining in modern societies) led him to conclude that not all human societies were based on competition, such as those of industrialized Europe, and that many societies exhibited cooperation among individuals and groups as the norm. He also concluded that most pre-industrial and pre-authoritarian societies (where he claimed that leadership, central government and class did not exist) actively defend against the accumulation of private property by, for example, equally distributing within the community a person's possessions when he died, or by not allowing a gift to be sold, bartered or used to create wealth (see Gift economy).
Mutual aid.
In "The Conquest of Bread", Kropotkin proposed a system of economics based on mutual exchanges made in a system of voluntary cooperation. He believed that should a society be socially, culturally, and industrially developed enough to produce all the goods and services required by it, then no obstacle, such as preferential distribution, pricing or monetary exchange will stand as an obstacle for all taking what they need from the social product. He supported the eventual abolishment of money or tokens of exchange for goods and services.
Kropotkin believed that Bakunin's collectivist economic model was simply a wage system by a different name, and thought that such a system would breed the same type of centralization and inequality as a capitalist wage system. He stated that it is impossible to determine the value of an individual's contributions to the products of social labor, and thought that anyone who was placed in a position of trying to make such determinations would wield authority over those whose wages they determined. He further developed these ideas in "Fields, Factories and Workshops".
According to Kirkpatrick Sale:
Self-sufficiency.
His focus on local production led to his view that a country should strive for self-sufficiencymanufacture its own goods and grow its own food, lessening dependence on imports. To these ends he advocated irrigation and growing under glass to boost local food production ability.

</doc>
<doc id="51078" url="https://en.wikipedia.org/wiki?curid=51078" title="Thalidomide">
Thalidomide

Thalidomide sold under the brand names Immunoprin, among others, is an immunomodulatory drug and the prototype of the thalidomide class of drugs. Today, thalidomide is used mainly as a treatment of certain cancers (multiple myeloma) and of a complication of leprosy.
Thalidomide was first marketed in 1957 in West Germany under the trade-name Contergan. The German drug company Chemie Grünenthal developed and sold the drug. Primarily prescribed as a sedative or hypnotic, thalidomide also claimed to cure "anxiety, insomnia, gastritis, and tension". Afterwards, it was used against nausea and to alleviate morning sickness in pregnant women. Thalidomide became an over-the-counter drug in West Germany on October 1, 1957. Shortly after the drug was sold in West Germany, between 5,000 and 7,000 infants were born with phocomelia (malformation of the limbs). Only 40% of these children survived. Throughout the world, about 10,000 cases were reported of infants with phocomelia due to thalidomide; only 50% of the 10,000 survived. Those subjected to thalidomide while in the womb experienced limb deficiencies in a way that the long limbs either were not developed or presented themselves as stumps. Other effects included deformed eyes and hearts, deformed alimentary and urinary tracts, blindness and deafness. The negative effects of thalidomide led to the development of more structured drug regulations and control over drug use and development.
Medical uses.
Thalidomide is used for a number of conditions including erythema nodosum leprosum, multiple myeloma (in combination with dexamethasone), and various other cancers, for some symptoms of HIV/AIDS, Crohn's disease, sarcoidosis, graft-versus-host disease, rheumatoid arthritis and a number of skin conditions that have not responded to usual treatment.
The bacterium that causes tuberculosis is related to leprosy. Thalidomide may be helpful in some cases where standard TB drugs and corticosteroids are not sufficient to resolve severe inflammation in the brain.
There is no conclusive evidence that thalidomide or lenalidomide is useful to bring about or maintain remission in Crohn's disease.
Adverse effects.
Thalidomide may cause side effects, such as polyneuropathy, fatigue, skin rash, and venous thromboembolism (VTE), or blood clots, which could lead to stroke or myocardial infarction.
Adverse effects by frequency:<br>
Very common (may affect more than 1 in 10 people):
Common (may affect up to 1 in 10 people):
Uncommon (may affect up to 1 in 100 people):
Rare (may affect up to 1 in 1,000 people):
Very rare (may affect up to 1 in 10,000 people):
† Peripheral neuropathy may be irreversible and usually results from chronic (usually a matter of months) exposure to thalidomide.
Carcinogenicity.
Animal studies did not demonstrate any carcinogenicity even when rats and mice were exposed to up to 11 times the therapeutic dose of thalidomide. Despite this there have been some concerns that it may cause secondary malignancies in patients with multiple myeloma. The FDA has issued a statement that it is investigating these concerns.
Some clinical trials have supported this claim and the major secondary malignancy that thalidomide is associated with is acute myeloid leukaemia. The MHRA of the UK and Health Canada of Canada have also issued warnings to healthcare professionals regarding the risk of secondary malignancies due to thalidomide exposure.
Contraindications.
Contraindications include:
Interactions.
There are no expected pharmacokinetic interactions between thalidomide and other medicines due to its neutral effects on p-glycoprotein and P450 cytochromes. It may interact with sedatives due to its sedative action. It may also interact with bradycardic agents due to its bradycardia-inducing effects. The risk of peripheral neuropathy may be increased by concomitant treatment with other agents known to cause peripheral neuropathy. The risk of venous thromboembolisms with thalidomide seems to be increased when patients are treated with oral contraceptives or other cytotoxic agents (including doxorubicin and melphalan) concurrently. Thalidomide may interfere with the contraceptive effects of various contraceptives and hence it is advised that women of reproductive age use at least two different means of contraception to ensure that no child will be conceived while they are receiving thalidomide.
Overdose.
Eighteen cases of overdoses have been reported to date with doses of up to 14.4 g without any reported fatalities. No specific antidote for overdoses exists and treatment is purely supportive.
Mechanism of action.
The precise mechanism of action for thalidomide is unknown, but possible mechanisms include anti-angiogenic and oxidative stress-inducing effects. It also inhibits TNF-α, IL-6, IL-10 and IL-12 production, modulates the production of IFN-γ and enhances the production of IL-2, IL-4 and IL-5 by immune cells. It increases lymphocyte count, costimulates T cells and modulates natural killer cell cytotoxicity. It also inhibits NF-κB and COX-2 activity.
In 1990, a group of researchers in Brazil noted that TNF alpha levels went up in leprosy reactional states and observed that TNF levels decreased in some patients on treatment with thalidomide, hence potentially explaining the efficacy of thalidomide in treating ENL.
The mechanism of thalidomide's teratogenic action has led to over 2000 research papers and the proposal of 15 or 16 plausible mechanisms. Angiogenesis is critical during limb development of the foetus. Thalidomide can directly inhibit angiogenesis induced by bFGF or VEGF "in vivo". Teratogenic analogs inhibit angiogenesis whereas nonteratogenic analogs do not inhibit angiogenesis. In 2009, research by other groups confirmed "conclusively that loss of newly formed blood vessels is the primary cause of thalidomide teratogenesis, and developing limbs are particularly susceptible because of their relatively immature, highly angiogenic vessel network".
Thalidomide is racemic; the individual enantiomers can racemize due to the acidic hydrogen at the chiral centre, which is the carbon of the glutarimide ring bonded to the phthalimide substituent. The racemization process can occur "in vivo" so that any plan to administer a purified single enantiomer to avoid the teratogenic effects will most likely be in vain.
Cereblon.
Several studies have now shown that the mechanism of action for thalidomide involves binding to the protein cereblon, a ubiquitin ligase substrate adapter protein, which is important in limb formation and the proliferative capacity of myeloma cells. Ubiquitin ligases function by reducing the cellular levels of proteins and thalidomide has been shown to alter the set of proteins which CRBN can degrade. This was confirmed in studies that reduced the production of cereblon in developing chick and zebrafish embryos using genetic techniques. These embryos had defects similar to those treated with thalidomide. Interestingly, mice treated with thalidomide do not display teratogenicity of their offspring as seen in humans.
History.
Thalidomide was developed by German pharmaceutical company "Chemie Grünenthal" (now "Grünenthal GmbH"). After obtaining a twenty-year patent in April 1954, "Chemie Grünenthal" started clinical trials and as early as November 1956 marketed thalidomide for the treatment of respiratory infections under the trade name "Grippex", a combination drug that contained thalidomide, quinine, vitamin C, phenacetin and acetylsalicylic-acid (aspirin).
Researchers at "Chemie Grünenthal" also found that thalidomide was a particularly effective antiemetic that had an inhibitory effect on morning sickness. Hence, on October 1, 1957, the company launched thalidomide and began aggressively marketing it under the trade name "Contergan". It was proclaimed a "wonder drug" for insomnia, coughs, colds and headaches.
During this time period, the use of medications during pregnancy was not strictly controlled, and drugs were not thoroughly tested for potential harm to the foetus. Thousands of pregnant women took the drug to relieve their symptoms. At the time of the drug's development, scientists did not believe any drug taken by a pregnant woman could pass across the placental barrier and harm the developing foetus, even though the effect of alcohol on foetal development had been documented by case studies on alcoholic mothers since at least 1957. There soon appeared reports of findings of abnormalities in children being born, traced back to the use of the drug thalidomide. In late 1959, it was noticed that peripheral neuritis developed in patients who took the drug over a period of time, and it was only after this point that thalidomide ceased to be provided over the counter.
Hence, while initially considered safe, the drug was responsible for teratogenic deformities in children born after their mothers used it during pregnancies, prior to the third trimester. In November 1961, thalidomide was taken off the market due to massive pressure from the press and public. Experts estimate that the drug thalidomide led to the death of approximately 2,000 children and serious birth defects in more than 10,000 children, about 5,000 of them in West Germany. The regulatory authorities in East Germany did not approve thalidomide. One reason for the initially unobserved side effects of the drug and the subsequent approval in West Germany was that at that time drugs did not have to be tested for teratogenic effects. They had been tested on rodents only, as was usual at the time.
In the UK, the British pharmaceutical company "The Distillers Company (Biochemicals) Ltd," a subsidiary of "Distillers Co. Ltd". (now part of Diageo plc), marketed thalidomide under the brand name "Distaval" as a remedy for morning sickness throughout the United Kingdom, Australia and New Zealand. Their advertisement claimed that "Distaval can be given with complete safety to pregnant women and nursing mothers without adverse effect on mother or child...Outstandingly safe Distaval has been prescribed for nearly three years in this country." Around the world, more and more pharmaceutical companies started to produce and market the drug under license from "Chemie Grünenthal". By the mid 1950s, 14 pharmaceutical companies were marketing thalidomide in 46 countries under 37 (some reports suggest 51) different trade names.
In the U.S., representatives from "Chemie Grünenthal" approached "Smith, Kline & French" (SKF), now GlaxoSmithKline (GSK) with a request to market and distribute the drug in North America. A memorandum rediscovered in 2010 in the archives of the U.S. Food and Drug Administration (FDA) shows that, as part of its in-licensing approach, "Smith, Kline and French" conducted animal tests and ran a clinical trial of the drug in the United States involving 875 people, including pregnant women, in 1956–57. In 1956, researchers at SKF involved in clinical trials noted that even when used in very high doses, thalidomide could not induce sleep in mice. And when administered at doses 50 to 650 times larger than that claimed by "Chemie Grünenthal" to be "sleep inducing", the researchers could still not achieve the hypnotic effect in animals that it had on humans. After completion of the trial, and based on reasons kept hidden for decades, SKF declined to commercialize the drug. Later, "Chemie Grünenthal", in 1958, reached an agreement with "William S Merrell Company" in Cincinnati, Ohio, (later Richardson-Merrell, now part of Sanofi), to market and distribute thalidomide throughout the United States.
The U.S. FDA refused to approve thalidomide for marketing and distribution. However, the drug was distributed in large quantities for testing purposes, after the American distributor and manufacturer Richardson-Merrell had applied for its approval in September 1960. The official in charge of the FDA review, Frances Oldham Kelsey, did not rely on information from the company, which did not include any test results. Richardson-Merrell was called on to perform tests and report the results. The company refused and demanded approval six times, and was refused each time. Nevertheless, a total of 17 children with thalidomide-induced malformations were born in the U.S.
In Canada, the history of the drug thalidomide dates back to April 1, 1961. There were many different forms sold, with the most common variant being Talimol. Two months after Talimol went on sale, pharmaceutical companies sent physicians letters warning about the risk of birth defects. It was not until March 2, 1962, that both drugs were banned from the Canadian market by the FDD, and soon afterward physicians were warned to destroy their supplies.
Leprosy treatment.
In 1964, Israeli physician Jacob Sheskin administered thalidomide to a patient critically ill with leprosy. The patient exhibited erythema nodosum leprosum (ENL), a painful skin condition, one of the complications of leprosy. This was attempted despite the ban on thalidomide's use, but results were favourable: the patient slept for hours and was able to get out of bed without aid upon awakening. A clinical trial studying the use of thalidomide in leprosy soon followed.
Thalidomide has been used by Brazilian physicians as the drug of choice for the treatment of severe ENL since 1965, and by 1996, at least 33 cases of thalidomide embryopathy were recorded in people born in Brazil after 1965. Since 1994, the production, dispensing, and prescription of thalidomide have been strictly controlled, requiring women to use two forms of birth control and submit to regular pregnancy tests. Despite this, cases of thalidomide embryopathy continue, with at least 100 cases identified in Brazil between 2005 and 2010. 5.8 million thalidomide pills were distributed throughout Brazil in this time period, largely to poor Brazilians in areas with poor access to healthcare, and these cases have occurred despite the controls.
In 1998 the FDA approved the drug's use in the treatment of ENL. Because of thalidomide's potential for causing birth defects, the drug may be distributed only under tightly controlled conditions. The FDA required that Celgene Corporation, which planned to market thalidomide under the brand name "Thalomid", establish a system for thalidomide education and prescribing safety (STEPS) oversight program. The conditions required under the program include limiting prescription and dispensing rights to authorized prescribers and pharmacies only, keeping a registry of all patients prescribed thalidomide, providing extensive patient education about the risks associated with the drug, and providing periodic pregnancy tests for women who take the drug.
In 2010, the World Health Organisation (WHO) stated that it did not recommend thalidomide due the difficulty of adequately controlling its use, and due to the availability of clofazimine.
Cancer treatment.
Shortly after the teratogenic properties of thalidomide were recognized in the mid-1960s, its anti-cancer potential was explored and two clinical trials were conducted in people with advanced cancer, including some people with multiple myeloma; the trials were inconclusive.
Little further work was done with thalidomide in cancer until the 1990s.
Judah Folkman pioneered studies into the role of angiogenesis (the proliferation and growth of blood vessels) in the development of cancer, and in the early 1970s had shown that solid tumors could not expand without it. In 1993 he surprised the scientific world by hypothesizing the same was true of blood cancers, and the next year he published work showing that a biomarker of angiogenesis was higher in all people with cancer, but especially high in people with blood cancers, and other evidence emerged as well. Meanwhile, a member of his lab, Robert D'Amato, was looking for angiogenesis inhibitors, and discovered in 1994 that thalidomide inhibited angiogenesis. Around that time, the wife of a man who was dying of multiple myeloma and whom standard treatments had failed, called Folkman asking him about his anti-angiogenesis ideas. Folkman convinced the patient's doctor to try thalidomide, and that doctor conducted a clinical trial of thalidomide for people with multiple myeloma in which about a third of the subjects responded to the treatment. The results of that trial were published in the New England Journal of Medicine in 1999.
After further work was done by Celgene and others, in 2006 the U.S. Food and Drug Administration granted accelerated approval for thalidomide in combination with dexamethasone for the treatment of newly diagnosed multiple myeloma patients.
Thalidomide analogs.
The exploration of the antiangiogenic and immunomodulatory activities of thalidomide has led to the study and creation of thalidomide analogs. Celgene has sponsored numerous clinical trials with analogues to thalidomide, such as lenalidomide, that are substantially more powerful and have fewer side effects — except for greater myelosuppression. In 2005, Celgene received FDA approval for lenalidomide (Revlimid) as the first commercially useful derivative. Revlimid is available only in a restricted distribution setting to avoid its use during pregnancy. Further studies are being conducted to find safer compounds with useful qualities. Another more potent analog, pomalidomide, is now FDA approved. Additionally, apremilast was approved by the FDA in March 2014. These thalidomide analogs can be used to treat different diseases, or used in a regimen to fight two conditions.
Interest turned to pomalidomide, a derivative of thalidomide marketed by Celgene. It is a very active anti-angiogenic agent and also acts as an immunomodulator. Pomalidomide was approved in February 2013 by the U.S. Food and Drug Administration (FDA) as a treatment for relapsed and refractory multiple myeloma. It received a similar approval from the European Commission in August 2013, and is expected to be marketed in Europe under the brand name Imnovid.
Society and culture.
Birth defects crisis.
In the late 1950s and early 1960s, more than 10,000 children in 46 countries were born with deformities such as phocomelia as a consequence of thalidomide use. The severity and location of the deformities depended on how many days into the pregnancy the mother was; thalidomide taken on the 20th day of pregnancy caused central brain damage, day 21 would damage the eyes, day 22 the ears and face, day 24 the arms, and leg damage would occur if taken up to day 28. Thalidomide did not damage the foetus if taken after 42 days gestation.
It is not known exactly how many worldwide victims of the drug there have been, although estimates range from 10,000 to 20,000 to 100,000. Despite the side effects, thalidomide was sold in pharmacies in Canada until 1962;
In the United Kingdom, the drug was licensed in 1958 and withdrawn in 1961. Of the approximately 2,000 babies born with defects, around half died within a few months and 466 survived to at least 2010.
In Spain, thalidomide was widely available throughout the 1970s, perhaps even into the 1980s. There were two reasons for this. First, state controls and safeguarding were poor; indeed, it was not until 2008 that the government even admitted the country had ever imported thalidomide. Second, Grünenthal failed to insist that its sister company in Madrid warn Spanish doctors, and permitted it to not warn them. The Spanish advocacy group for victims of thalidomide estimates that in 2015, there were 250–300 living victims of thalidomide in Spain.
The Australian obstetrician William McBride and the German paediatrician Widukind Lenz suspected a link between birth defects and the drug, a theory Lenz proved in 1961. McBride was later awarded a number of honors, including a medal and prize money by L'Institut de la Vie in Paris. Further animal tests were conducted by Dr George Somers, Chief Pharmacologist of Distillers Company in Britain, which showed foetal abnormalities in rabbits. Similar results were also published showing these effects in rats and other species.
In East Germany, the head of the central pharmacy control commission, Friedrich Jung, suspected an antivitaminic effect of thalidomide as derivative of glutamic acid. Meanwhile, in West Germany, it took some time before the increase in dysmelia at the end of the 1950s was connected with thalidomide. In 1958 Karl Beck, a former pediatric doctor in Bayreuth wrote an article in a local newspaper claiming a relationship between nuclear weapons testing and cases of dysmelia in children. Based on this, FDP whip Erich Mende requested an official statement from the federal government. For statistical reasons, the main data series used to research dysmelia cases started by chance at the same time as the approval date for thalidomide. After the Nazi regime with its Law for the Prevention of Hereditarily Diseased Offspring used mandatory statistical monitoring to commit various crimes, western Germany had been very reluctant to monitor congenital disorders in a similarly strict way. The parliamentary report rejected any relation with radioactivity and the abnormal increase of dysmelia. Also the DFG research project installed after the Mende request was not helpful. The project was led by pathologist Franz Büchner who ran the project to propagate his teratological theory. Büchner saw lack of healthy nutrition and behavior of the mothers as being more important than genetic reasons. Furthermore, it took a while to install a Surgeon General in Germany; the Federal Ministry of Health (Germany) was not founded until 1962, some months after thalidomide was banned from the market. In Germany approximately 2,500 thalidomide babies were born.
Several countries either restricted the drug's use or never approved it. Ingeborg Eichler, a member of the Austrian pharmaceutical admission conference, enforced thalidomide (tradename Softenon) being sold under the rules of prescription medication and as a result relatively few affected children were born in Austria and Switzerland. In the United States, pharmacologist Frances Oldham Kelsey M.D. withstood pressure from the Richardson-Merrell company and refused Food and Drug Administration (FDA) approval to market thalidomide, saying further studies were needed. This reduced the impact of thalidomide in United States patients. Although thalidomide was never approved for sale in the United States at the time, millions of tablets had been distributed to physicians during a clinical testing program. It was impossible to know how many pregnant women had been given the drug to help alleviate morning sickness or as a sedative.
Aftermath of scandal.
The numerous reports of malformations in babies brought about the awareness of the side effects of the drug on pregnant women. The birth defects caused by the drug thalidomide can range from moderate malformation to more severe forms. Possible birth defects include phocomelia, dysmelia, amelia, bone hypoplasticity, and other congenital defects affecting the ear, heart, or internal organs. Franks et al. looked at how the drug affected newborn babies, the severity of their deformities, and reviewed the drug in its early years. Webb in 1963 also reviewed the history of the drug and the different forms of birth defects it had caused. "The most common form of birth defects from thalidomide is shortened limbs, with the arms being more frequently affected. This syndrome is the presence of deformities of the long bones of the limbs resulting in shortening and other abnormalities."
Germany.
In 1968, a large criminal trial began in Germany, charging several Grünenthal officials with negligent homicide and injury. 
After Grünenthal settled with the victims in April 1970, the trial ended in December 1970 with no finding of guilt. As part of the settlement, Grünenthal paid 100 million DM into a special foundation; the German government added 320 million DM. The foundation paid victims a one-time sum of 2,500-25,000 DM (depending on severity of disability) and a monthly stipend of 100-450 DM. The monthly stipends have since been raised substantially and are now paid entirely by the government (as the foundation had run out of money). Grünenthal paid another 50 million Euros into the foundation in 2008.
On 31 August 2012, Grünenthal chief executive Harald F. Stock, PhD, who served as the Chief Executive Officer of Grünenthal GmbH from January 2009 to May 28, 2013 and was also a Member of Executive Board until May 28, 2013, apologized for the first time for producing the drug and remaining silent about the birth defects. At a ceremony, Stock unveiled a statue of a disabled child to symbolize those harmed by thalidomide and apologized for not trying to reach out to victims for over 50 years. At the time of the apology, there were 5,000 to 6,000 sufferers still alive. Victim advocates called the apology "insulting" and "too little, too late", and criticized the company for not compensating victims. They also criticized the company for their claim that no one could have known the harm the drug caused, arguing that there were plenty of red flags at the time.
United Kingdom.
In 1968, after a long campaign by "The Sunday Times", a compensation settlement for the UK victims was reached with Distillers Company (now part of Diageo), which had distributed the drug in the UK. This compensation, which is distributed by the Thalidomide Trust in the UK, was substantially increased by Diageo in 2005. The UK Government gave survivors a grant of £20 million, to be distributed through the Thalidomide Trust, in December 2009.
Australia.
Melbourne woman Lynette Rowe, who was born without limbs, is leading an Australian class action lawsuit against the drug's manufacturer, Grünenthal, which fought to have the case heard in Germany. The Supreme Court of Victoria dismissed Grünenthal's application in 2012, and the case was heard in Australia. More than a hundred Australian thalidomide survivors are involved in the class action, according to Rowe's lawyer. On 17 July 2012, Lynette Rowe was awarded an out-of-court settlement, believed to be in the millions of dollars and paving the way for class action victims to receive further compensation.
Canada.
The drug thalidomide's birth defects in children affected many people's lives, and from these events came the formation of the group called The Thalidomide Victims Association of Canada, a group of 120 Canadian survivors. Their goal was to prevent future usage of drugs that could be of potential harm to mothers and babies. The members from the thalidomide victims association were involved in the STEPS program, which aimed to prevent teratogenicity.
The effects of thalidomide increased fears regarding the safety of pharmaceutical drugs. The Society of Toxicology of Canada was formed after the effects of thalidomide were made public, focusing on toxicology as a discipline separate from pharmacology. The need for the testing and approval of the toxins in certain pharmaceutical drugs became more important after the disaster. The Society of Toxicology of Canada is responsible for the Conservation Environment Protection Act, focusing on researching the impact to human health of chemical substances. Thalidomide brought on changes in the way drugs are tested, what type of drugs are used during pregnancy, and increased the awareness of potential side effects of drugs.
United States.
For correctly denying the application despite the pressure from Richardson-Merrell, Kelsey eventually received the President's Award for Distinguished Federal Civilian Service at a 1962 ceremony with President John F. Kennedy. In September 2010, the FDA honored Kelsey with the first Kelsey award. The award, given annually to an FDA staff member, came 50 years after Kelsey, then a new medical officer at the agency, first reviewed the application from the William S. Merrell Company of Cincinnati. Cardiologist Helen B. Taussig learned of the damaging effects of the drug thalidomide on newborns and in 1967, testified before Congress on this matter after a trip to Germany where she worked with infants suffering from phocomelia(severe limb deformities). As a result of her efforts, thalidomide was banned in the United States and Europe.
Change in drug regulations.
The disaster prompted many countries to introduce tougher rules for the testing and licensing of drugs, such as the Kefauver Harris Amendment (U.S.) and Directive 65/65/EEC1 (E.U.). In the United States, the new regulations strengthened the FDA, among other ways, by requiring applicants to prove efficacy and to disclose all side-effects encountered in testing. The FDA subsequently initiated the Drug Efficacy Study Implementation to reclassify drugs already on the market.
Research.
Investigational uses include:

</doc>
<doc id="51079" url="https://en.wikipedia.org/wiki?curid=51079" title="Magnet">
Magnet

A magnet (from Greek "magnḗtis líthos", "Magnesian stone") is a material or object that produces a magnetic field. This magnetic field is invisible but is responsible for the most notable property of a magnet: a force that pulls on other ferromagnetic materials, such as iron, and attracts or repels other magnets.
A permanent magnet is an object made from a material that is magnetized and creates its own persistent magnetic field. An everyday example is a refrigerator magnet used to hold notes on a refrigerator door. Materials that can be magnetized, which are also the ones that are strongly attracted to a magnet, are called ferromagnetic (or ferrimagnetic). These include iron, nickel, cobalt, some alloys of rare earth metals, and some naturally occurring minerals such as lodestone. Although ferromagnetic (and ferrimagnetic) materials are the only ones attracted to a magnet strongly enough to be commonly considered magnetic, all other substances respond weakly to a magnetic field, by one of several other types of magnetism.
Ferromagnetic materials can be divided into magnetically "soft" materials like annealed iron, which can be magnetized but do not tend to stay magnetized, and magnetically "hard" materials, which do. Permanent magnets are made from "hard" ferromagnetic materials such as alnico and ferrite that are subjected to special processing in a powerful magnetic field during manufacture, to align their internal microcrystalline structure, making them very hard to demagnetize. To demagnetize a saturated magnet, a certain magnetic field must be applied, and this threshold depends on coercivity of the respective material. "Hard" materials have high coercivity, whereas "soft" materials have low coercivity.
An electromagnet is made from a coil of wire that acts as a magnet when an electric current passes through it but stops being a magnet when the current stops. Often, the coil is wrapped around a core of "soft" ferromagnetic material such as steel, which greatly enhances the magnetic field produced by the coil.
The overall strength of a magnet is measured by its magnetic moment or, alternatively, the total magnetic flux it produces. The local strength of magnetism in a material is measured by its magnetization.
Discovery and development.
Ancient people learned about magnetism from lodestones, which are naturally magnetized pieces of iron ore. The word "magnet" in Greek meant "stone from Magnesia", a part of ancient Greece where lodestones were found. Lodestones, suspended so they could turn, were the first magnetic compasses. The earliest known surviving descriptions of magnets and their properties are from Greece, India, and China around 2500 years ago. The properties of lodestones and their affinity for iron were written of by Pliny the Elder in his encyclopedia "Naturalis Historia".
By the 12th to 13th centuries AD, magnetic compasses were used in navigation in China, Europe, and elsewhere.
Physics.
Magnetic field.
The magnetic flux density (also called magnetic B field or just magnetic field, usually denoted B) is a vector field. The magnetic B field vector at a given point in space is specified by two properties:
In SI units, the strength of the magnetic B field is given in teslas.
Magnetic moment.
A magnet's magnetic moment (also called magnetic dipole moment and usually denoted μ) is a vector that characterizes the magnet's overall magnetic properties. For a bar magnet, the direction of the magnetic moment points from the magnet's south pole to its north pole, and the magnitude relates to how strong and how far apart these poles are. In SI units, the magnetic moment is specified in terms of A•m2 (amperes times meters squared).
A magnet both produces its own magnetic field and responds to magnetic fields. The strength of the magnetic field it produces is at any given point proportional to the magnitude of its magnetic moment. In addition, when the magnet is put into an external magnetic field, produced by a different source, it is subject to a torque tending to orient the magnetic moment parallel to the field. The amount of this torque is proportional both to the magnetic moment and the external field. A magnet may also be subject to a force driving it in one direction or another, according to the positions and orientations of the magnet and source. If the field is uniform in space, the magnet is subject to no net force, although it is subject to a torque.
A wire in the shape of a circle with area "A" and carrying current "I" is a magnet, with a magnetic moment of magnitude equal to "IA".
Magnetization.
The magnetization of a magnetized material is the local value of its magnetic moment per unit volume, usually denoted M, with units A/m. It is a vector field, rather than just a vector (like the magnetic moment), because different areas in a magnet can be magnetized with different directions and strengths (for example, because of domains, see below). A good bar magnet may have a magnetic moment of magnitude 0.1 A•m2 and a volume of 1 cm3, or 1×10−6 m3, and therefore an average magnetization magnitude is 100,000 A/m. Iron can have a magnetization of around a million amperes per meter. Such a large value explains why iron magnets are so effective at producing magnetic fields.
Modelling magnets.
Two different models exist for magnets: magnetic poles and atomic currents.
Although for many purposes it is convenient to think of a magnet as having distinct north and south magnetic poles, the concept of poles should not be taken literally: it is merely a way of referring to the two different ends of a magnet. The magnet does not have distinct north or south particles on opposing sides. If a bar magnet is broken into two pieces, in an attempt to separate the north and south poles, the result will be two bar magnets, "each" of which has both a north and south pole. However, a version of the magnetic-pole approach is used by professional magneticians to design permanent magnets.
In this approach, the divergence of the magnetization ∇•M inside a magnet and the surface normal component M•n are treated as a distribution of magnetic monopoles. This is a mathematical convenience and does not imply that there are actually monopoles in the magnet. If the magnetic-pole distribution is known, then the pole model gives the magnetic field H. Outside the magnet, the field B is proportional to H, while inside the magnetization must be added to H. An extension of this method that allows for internal magnetic charges is used in theories of ferromagnetism.
Another model is the Ampère model, where all magnetization is due to the effect of microscopic, or atomic, circular bound currents, also called Ampèrian currents, throughout the material. For a uniformly magnetized cylindrical bar magnet, the net effect of the microscopic bound currents is to make the magnet behave as if there is a macroscopic sheet of electric current flowing around the surface, with local flow direction normal to the cylinder axis. Microscopic currents in atoms inside the material are generally canceled by currents in neighboring atoms, so only the surface makes a net contribution; shaving off the outer layer of a magnet will "not" destroy its magnetic field, but will leave a new surface of uncancelled currents from the circular currents throughout the material.
The right-hand rule tells which direction the current flows.
Pole naming conventions.
The north pole of a magnet is defined as the pole that, when the magnet is freely suspended, points towards the Earth's North Magnetic Pole in the Arctic. Since opposite poles (north and south) attract, the North Magnetic Pole is actually the "south" pole of the Earth's magnetic field. As a practical matter, to tell which pole of a magnet is north and which is south, it is not necessary to use the Earth's magnetic field at all. For example, one method would be to compare it to an electromagnet, whose poles can be identified by the right-hand rule. The magnetic field lines of a magnet are considered by convention to emerge from the magnet's north pole and reenter at the south pole.
Magnetic materials.
The term "magnet" is typically reserved for objects that produce their own persistent magnetic field even in the absence of an applied magnetic field. Only certain classes of materials can do this. Most materials, however, produce a magnetic field in response to an applied magnetic field – a phenomenon known as magnetism. There are several types of magnetism, and all materials exhibit at least one of them.
The overall magnetic behavior of a material can vary widely, depending on the structure of the material, particularly on its electron configuration. Several forms of magnetic behavior have been observed in different materials, including:
There are various other types of magnetism, such as spin glass, superparamagnetism, superdiamagnetism, and metamagnetism.
Medical issues and safety.
Because human tissues have a very low level of susceptibility to static magnetic fields, there is little mainstream scientific evidence showing a health effect associated with exposure to static fields. Dynamic magnetic fields may be a different issue, however; correlations between electromagnetic radiation and cancer rates have been postulated due to demographic correlations (see Electromagnetic radiation and health).
If a ferromagnetic foreign body is present in human tissue, an external magnetic field interacting with it can pose a serious safety risk.
A different type of indirect magnetic health risk exists involving pacemakers. If a pacemaker has been embedded in a patient's chest (usually for the purpose of monitoring and regulating the heart for steady electrically induced beats), care should be taken to keep it away from magnetic fields. It is for this reason that a patient with the device installed cannot be tested with the use of a magnetic resonance imaging device.
Children sometimes swallow small magnets from toys, and this can be hazardous if two or more magnets are swallowed, as the magnets can pinch or puncture internal tissues; one death has been reported.
Magnetic imaging devices (e.g. MRIs) generate enormous magnetic fields, and therefore rooms intended to hold them exclude ferrous metals. Bringing objects made of ferrous metals (such as oxygen canisters) into such a room creates a severe safety risk, as those objects may be powerfully thrown about by the intense magnetic fields.
Magnetizing ferromagnets.
Ferromagnetic materials can be magnetized in the following ways:
Demagnetizing ferromagnets.
Magnetized ferromagnetic materials can be demagnetized (or degaussed) in the following ways:
Types of permanent magnets.
Magnetic metallic elements.
Many materials have unpaired electron spins, and the majority of these materials are paramagnetic. When the spins interact with each other in such a way that the spins align spontaneously, the materials are called ferromagnetic (what is often loosely termed as magnetic). Because of the way their regular crystalline atomic structure causes their spins to interact, some metals are ferromagnetic when found in their natural states, as ores. These include iron ore (magnetite or lodestone), cobalt and nickel, as well as the rare earth metals gadolinium and dysprosium (when at a very low temperature). Such naturally occurring ferromagnets were used in the first experiments with magnetism. Technology has since expanded the availability of magnetic materials to include various man-made products, all based, however, on naturally magnetic elements.
Composites.
Ceramic, or ferrite, magnets are made of a sintered composite of powdered iron oxide and barium/strontium carbonate ceramic. Given the low cost of the materials and manufacturing methods, inexpensive magnets (or non-magnetized ferromagnetic cores, for use in electronic components such as radio antennas, for example) of various shapes can be easily mass-produced. The resulting magnets are non-corroding but brittle and must be treated like other ceramics.
Alnico magnets are made by casting or sintering a combination of aluminium, nickel and cobalt with iron and small amounts of other elements added to enhance the properties of the magnet. Sintering offers superior mechanical characteristics, whereas casting delivers higher magnetic fields and allows for the design of intricate shapes. Alnico magnets resist corrosion and have physical properties more forgiving than ferrite, but not quite as desirable as a metal. Trade names for alloys in this family include: "Alni, Alcomax, Hycomax, Columax", and "Ticonal".
Injection-molded magnets are a composite of various types of resin and magnetic powders, allowing parts of complex shapes to be manufactured by injection molding. The physical and magnetic properties of the product depend on the raw materials, but are generally lower in magnetic strength and resemble plastics in their physical properties.
Flexible magnets are composed of a high-coercivity ferromagnetic compound (usually ferric oxide) mixed with a plastic binder. This is extruded as a sheet and passed over a line of powerful cylindrical permanent magnets. These magnets are arranged in a stack with alternating magnetic poles facing up (N, S, N, S...) on a rotating shaft. This impresses the plastic sheet with the magnetic poles in an alternating line format. No electromagnetism is used to generate the magnets. The pole-to-pole distance is on the order of 5 mm, but varies with manufacturer. These magnets are lower in magnetic strength but can be very flexible, depending on the binder used.
Rare-earth magnets.
Rare earth (lanthanoid) elements have a partially occupied "f" electron shell (which can accommodate up to 14 electrons). The spin of these electrons can be aligned, resulting in very strong magnetic fields, and therefore, these elements are used in compact high-strength magnets where their higher price is not a concern. The most common types of rare-earth magnets are samarium-cobalt and neodymium-iron-boron (NIB) magnets.
Single-molecule magnets (SMMs) and single-chain magnets (SCMs).
In the 1990s, it was discovered that certain molecules containing paramagnetic metal ions are capable of storing a magnetic moment at very low temperatures. These are very different from conventional magnets that store information at a magnetic domain level and theoretically could provide a far denser storage medium than conventional magnets. In this direction, research on monolayers of SMMs is currently under way. Very briefly, the two main attributes of an SMM are:
Most SMMs contain manganese but can also be found with vanadium, iron, nickel and cobalt clusters. More recently, it has been found that some chain systems can also display a magnetization that persists for long times at higher temperatures. These systems have been called single-chain magnets.
Nano-structured magnets.
Some nano-structured materials exhibit energy waves, called magnons, that coalesce into a common ground state in the manner of a Bose–Einstein condensate.
Rare-earth-free permanent magnets.
The United States Department of Energy has identified a need to find substitutes for rare earth metals in permanent magnet technology, and has begun funding such research. The Advanced Research Projects Agency-Energy (ARPA-E) has sponsored a Rare Earth Alternatives in Critical Technologies (REACT) program, to develop alternative materials. In 2011, ARPA-E awarded 31.6 million dollars to fund Rare-Earth Substitute projects.
Costs.
The cheapest permanent magnets, allowing for field strengths, are flexible and ceramic magnets, but these are also among the weakest types. The ferrite magnets are mainly low-cost magnets since they are made from cheap raw materials- iron oxide and Ba- or Sr-carbonate. However, a new low cost magnet- Mn-Al alloy has been developed and is now dominating the low-cost magnets field. It has a higher saturation magnetization than the ferrite magnets. It also has more favorable temperature coefficients, although it can be thermally unstable.
Neodymium-iron-boron (NIB) magnets are among the strongest. These cost more per kilogram than most other magnetic materials but, owing to their intense field, are smaller and cheaper in many applications.
Temperature.
Temperature sensitivity varies, but when a magnet is heated to a temperature known as the Curie point, it loses all of its magnetism, even after cooling below that temperature. The magnets can often be remagnetized, however.
Additionally, some magnets are brittle and can fracture at high temperatures.
The maximum usable temperature is highest for alnico magnets at over , around for ferrite and SmCo, about for NIB and lower for flexible ceramics, but the exact numbers depend on the grade of material.
Electromagnets.
An electromagnet, in its simplest form, is a wire that has been coiled into one or more loops, known as a solenoid. When electric current flows through the wire, a magnetic field is generated. It is concentrated near (and especially inside) the coil, and its field lines are very similar to those of a magnet. The orientation of this effective magnet is determined by the right hand rule. The magnetic moment and the magnetic field of the electromagnet are proportional to the number of loops of wire, to the cross-section of each loop, and to the current passing through the wire.
If the coil of wire is wrapped around a material with no special magnetic properties (e.g., cardboard), it will tend to generate a very weak field. However, if it is wrapped around a soft ferromagnetic material, such as an iron nail, then the net field produced can result in a several hundred- to thousandfold increase of field strength.
Uses for electromagnets include particle accelerators, electric motors, junkyard cranes, and magnetic resonance imaging machines. Some applications involve configurations more than a simple magnetic dipole; for example, quadrupole and sextupole magnets are used to focus particle beams.
Units and calculations.
For most engineering applications, MKS (rationalized) or SI (Système International) units are commonly used. Two other sets of units, Gaussian and CGS-EMU, are the same for magnetic properties and are commonly used in physics.
In all units, it is convenient to employ two types of magnetic field, B and H, as well as the magnetization M, defined as the magnetic moment per unit volume.
Materials that are not permanent magnets usually satisfy the relation M = "χ"H in SI, where "χ" is the (dimensionless) magnetic susceptibility. Most non-magnetic materials have a relatively small "χ" (on the order of a millionth), but soft magnets can have "χ" on the order of hundreds or thousands. For materials satisfying M = "χ"H, we can also write B = "μ"0(1 + "χ")H = "μ"0"μ"rH = "μ"H, where "μ"r = 1 + "χ" is the (dimensionless) relative permeability and μ =μ0μr is the magnetic permeability. Both hard and soft magnets have a more complex, history-dependent, behavior described by what are called hysteresis loops, which give either B vs. H or M vs. H. In CGS, M = "χ"H, but "χ"SI = 4"πχ"CGS, and μ = μr.
Caution: in part because there are not enough Roman and Greek symbols, there is no commonly agreed-upon symbol for magnetic pole strength and magnetic moment. The symbol "m" has been used for both pole strength (unit A•m, where here the upright m is for meter) and for magnetic moment (unit A•m2). The symbol "μ" has been used in some texts for magnetic permeability and in other texts for magnetic moment. We will use "μ" for magnetic permeability and "m" for magnetic moment. For pole strength, we will employ "q""m". For a bar magnet of cross-section "A" with uniform magnetization "M" along its axis, the pole strength is given by "qm" = "MA", so that "M" can be thought of as a pole strength per unit area.
Fields of a magnet.
Far away from a magnet, the magnetic field created by that magnet is almost always described (to a good approximation) by a dipole field characterized by its total magnetic moment. This is true regardless of the shape of the magnet, so long as the magnetic moment is non-zero. One characteristic of a dipole field is that the strength of the field falls off inversely with the cube of the distance from the magnet's center.
Closer to the magnet, the magnetic field becomes more complicated and more dependent on the detailed shape and magnetization of the magnet. Formally, the field can be expressed as a multipole expansion: A dipole field, plus a quadrupole field, plus an octupole field, etc.
At close range, many different fields are possible. For example, for a long, skinny bar magnet with its north pole at one end and south pole at the other, the magnetic field near either end falls off inversely with the square of the distance from that pole.
Calculating the magnetic force.
Pull force of a single magnet.
The strength of a given magnet is sometimes given in terms of its "pull force"— its ability to move (push/ pull) other objects. The pull force exerted by either an electromagnet or a permanent magnet at the "air gap" (i.e., the point in space where the magnet ends) is given by the Maxwell equation:
where
Therefore, if a magnet is acting vertically, it can lift a mass "m" in kilograms given by the simple equation:
Force between two magnetic poles.
Classically, the force between two magnetic poles is given by:
where
The pole description is useful to the engineers designing real-world magnets, but real magnets have a pole distribution more complex than a single north and south. Therefore, implementation of the pole idea is not simple. In some cases, one of the more complex formulae given below will be more useful.
Force between two nearby magnetized surfaces of area "A".
The mechanical force between two nearby magnetized surfaces can be calculated with the following equation. The equation is valid only for cases in which the effect of fringing is negligible and the volume of the air gap is much smaller than that of the magnetized material:
where:
Force between two bar magnets.
The force between two identical cylindrical bar magnets placed end to end is given by:
where:
Note that all these formulations are based on Gilbert's model, which is usable in relatively great distances. In other models (e.g., Ampère's model), a more complicated formulation is used that sometimes cannot be solved analytically. In these cases, numerical methods must be used.
Force between two cylindrical magnets.
For two cylindrical magnets with radius formula_7 and height formula_8, with their magnetic dipole aligned, the force can be well approximated (even at distances of the order of formula_8) by,
where formula_11 is the magnetization of the magnets and formula_12 is the gap between the magnets.
In disagreement to the statement in the previous section, a measurement of the magnetic flux density very close to the magnet formula_13 is related to formula_11 by the formula
The effective magnetic dipole can be written as
Where formula_17 is the volume of the magnet. For a cylinder, this is formula_18.
When formula_19, the point dipole approximation is obtained,
which matches the expression of the force between two magnetic dipoles.

</doc>
<doc id="51082" url="https://en.wikipedia.org/wiki?curid=51082" title="Richmond">
Richmond

Richmond may refer to:

</doc>
<doc id="51083" url="https://en.wikipedia.org/wiki?curid=51083" title="Mikael Agricola">
Mikael Agricola

Mikael Agricola ( ) (c. 1510 – 9 April 1557) was a clergyman who became the de facto founder of literary Finnish and a prominent proponent of the Protestant Reformation in Sweden including at the time Swedish territory Finland. He is often called the "father of literary Finnish". Agricola was consecrated as the bishop of Turku (Åbo) in 1554, without papal approval. As a result, he began a reform of the Finnish church (then a part of the Church of Sweden) along Lutheran lines. He translated the New Testament into Finnish and also produced the prayer book and hymns used in Finland's new Lutheran Church. This work set the rules of orthography that are the basis of modern Finnish spelling. His thorough work is particularly remarkable in that he accomplished it in only three years. He died suddenly while returning from a trip during which he negotiated a treaty with the Russians.
Biography.
Early life.
Michael Olaui or Mikkel Olofsson (Finnish "Mikael Olavinpoika") was born in Nyland ("Uusimaa") in the village of Torsby in Pernå ("Pernaja"), Sweden (now Finland), around the year 1510. He was named after the patron saint of Pernå's church. The exact date of his birth, like most details of his life, is unknown. His family was a quite wealthy peasant family according to the local bailiff's accounting. He had three sisters, but their names are not known. His teachers apparently recognized his aptitude for languages and his rector Bartholomeus sent him to Viborg (Fi. "Viipuri"; now Vyborg, Russia) for Latin school and some priestly training, where he attended the school of Erasmus. It is not known whether his first language was Swedish or Finnish; the first alternative is supported by the fact that Pernå was mostly a Swedish-speaking district. However, he mastered both languages like a native speaker and was possibly a bilingual child.
Studies.
When Michael studied in Viborg (Viipuri) he assumed the surname Agricola ("farmer" gv. "agriculture"); surnames based on one's father’s status and occupation were common for first-generation scholars at the time. It was probably in Viipuri where he first came in touch with the Reformation and Humanism. The Viipuri castle was ruled by a German count, Johann, who had served the king of Sweden, Gustav Vasa. The count was a supporter of the Reformation, and they already held Lutheran services.
In 1528 Agricola followed his teacher to Turku (Åbo), then the center of the Finnish side of the Swedish realm and the capital of the bishopric. There Agricola became a scribe in bishop Martinus Skytte's office. While in Turku Agricola met Martin Luther's first Finnish student Petrus Särkilahti, who eagerly spread the idea of the Reformation. Särkilahti died in 1529, and it was up to Agricola to continue Särkilahti's work. Agricola was ordained for priesthood circa 1531.
In 1536 the bishop of Turku sent Agricola to study in Wittenberg in Germany. He concentrated on the lectures of Philipp Melanchthon, who was an expert in Greek, the original language of the New Testament. In Wittenberg Agricola studied under Luther. Agricola got recommendations to Swedish King Gustav Vasa from both of the reformists. He sent two letters to Gustav, asking for a confirmation for a stipend. When the confirmation came, Agricola bought books (for example, the complete works of Aristotle). In 1537 he started translating the New Testament into Finnish.
Rector and ordinarius.
In 1539 Agricola returned to Turku and ended up as the rector of Turku (Cathedral) School. He did not like his job, calling his students "untamed animals". At the time Gustav Vasa had confiscated the property of the church when he was consolidating his power but he also drove the Reformation. In 1544 Agricola received an order from the crown to send several talented young men to Stockholm's taxing offices. For some reason, Agricola did not obey until the order was sent again the next year, with a more menacing tone. This episode probably affected their relations negatively.
In 1546 Agricola lost his home and school in the Fire of Turku. On 22 February 1548, Gustav Vasa ordered Agricola to retire from his position as a rector. At this time Agricola was already married, but history knows his wife only by her name: Pirjo Olavintytär (Bridget, "daughter of Olavi"; Birgitta Olafsdotter, Brigida Olaui). His only son, Christian Agricola (Christianus Michaelis Agricola), was born 11 December 1550, and became the bishop of Tallinn in 1584.
When an old bishop died in 1554, Gustav Vasa had Agricola consecrated as the "ordinarius" of Turku parish – for all practical purposes Bishop of Turku and by extension the first Lutheran bishop for all Finland. Agricola was not a particularly strict or dedicated reformer, although he did remove the Canon of the Mass.
Death and Commemorations.
In 1557 Agricola joined the delegation going to Russia and was in Moscow from 21 February to 24 March negotiating a peace treaty, the Treaty of Novgorod (1557). On 9 April he fell ill and died in Uusikirkko (now Polyane) village, part of the Kyrönniemi parish on the Karelian Isthmus. This day is also Elias Lönnrot's birthday and it is celebrated in Finland as the day of the Finnish language. Agricola was buried inside Viipuri's church, but the exact location of the grave is not known.
The Evangelical Lutheran Church in America remembers Bishop Agricola annually on 10 April.
Mikael Agricola Church in Helsinki is named after Agricola.
In 2007, 400 years after his death, Agricola was selected as the main motif for a commemorative coin, the €10 Mikael Agricola and Finnish language commemorative coin. This collector coin was issued to honor Agricola's life work as a contributor to the Protestant reformation in Finland and as the father of the Finnish written language. The reverse side depicts a quill to reference the writer, while the coin's obverse side contains an artistic interpretation of a human figure.
Literary achievements.
"Abckiria".
Agricola had thought about translating the New Testament in his early years of study. At the time, however, there was no standard written form of Finnish, so he started developing it. His first book, "Abckiria", which is nowadays known as the "ABC-kirja" or ABC-book, was a primer for reading and a catechism. It was first printed in 1543. The catechism was included because only very few people could afford the whole Bible at the time. The first printing contained 16 pages. 
A second printing was released in 1551 with 24 pages.
In 1966 Åke Åbergin, a librarian, discovered parts, while repairing book bindings, from an as yet unknown (likely the third) edition of the "ABC-kirja" that included the name of the printer, Amund Lauritsanpoika, and fortuitously the publishing date of 1559 (two years after the authors death) of the final as yet undiscovered 8 pages. The pages were likely the result of an imposing error and relegated to padding paper. 
"Rucouskiria".
Agricola's "Rucouskiria" (Rukouskirja - prayer book) was printed in March 1544. At the beginning of the book, Agricola wrote about many topics concerning all-round education and the Reformation's effects in Finland. The book includes four prefaces and about 700 prayers on many topics; it even has twelve different prayers instead of the usual two or three. It is the most independent work by Agricola and contains approximately 900 pages. His sources include the works of Luther, Melanchthon, and Erasmus.
New Testament translation.
Agricola's most prominent book is the first Finnish-language translation of the New Testament. The manuscript was completed in 1548. It contains 718 pages and many illustrations.
Liturgical books.
While Agricola was in Wittenberg, he translated three smaller liturgical books into Finnish. These books were printed in 1549.
"Käsikirja Castesta ia muista Christikunnan Menoista" includes forms for christening, marriage and burial, as well as speeches for the sick, mourning and dying. It is translated from Olaus Petri's corresponding work except for the christening and marriage portions, which are from Luther. It also contains minor elements translated from Caspar Huberinus' works.
"Messu eli Herran echtolinen" includes the form for a service. It is also based on Olaus Petri's work and a few Finnish manuscripts. In this book Agricola revealed his next mission: the translation of the Old Testament.
"Se meiden Herran Jesusen Christusen Pina, ylesnousemus ia tauiaisen Astumus, niste Neliest Euangelisterist coghottuon" tells about Jesus Christ's suffering. It is collected from all four gospels. This book was influenced heavily by Johannes Bugenhagen, a teacher in Wittenberg. It was mainly translated from the German version, but some parts are influenced by the Swedish version and Agricola's own translation of the New Testament.

</doc>
<doc id="51084" url="https://en.wikipedia.org/wiki?curid=51084" title="Unconventional superconductor">
Unconventional superconductor

Unconventional superconductors are materials that display superconductivity which does not conform to either the conventional BCS theory or the Nikolay Bogolyubov's theory or its extensions.
Detailed history.
The first unconventional singlet d-wave superconductor, CeCu2Si2, a type of
heavy fermion metal, was discovered in 1978 by Frank Steglich. In the early eighties, many more unconventional, heavy fermion superconductors were discovered, including UBe13, UPt3 and URu2Si2. In each of these materials, the anisotropic nature of the pairing is implicated by the power-law dependence of the nuclear magnetic resonance (NMR) relaxation rate and specific heat capacity on temperature. The presence of nodes in the superconducting gap of UPt3 was confirmed in 1986 from the polarization dependence of the ultrasound attenuation.
The first unconventional triplet superconductor, organic material (TMTSF)2PF6, was discovered by Denis Jerome and Klaus Bechgaard in 1979. Recent experimental works by Paul Chaikin's and Michael Naughton's groups as well as theoretical analysis of their data by Andrei Lebed have firmly confirmed unconventional nature of superconducting pairing in (TMTSF)2X (X=PF6, ClO4, etc.) organic materials.
High-temperature singlet d-wave superconductivity was discovered by J.G. Bednorz and K.A. Müller in 1986, who discovered that the lanthanum-based cuprate perovskite material LaBaCuO4 develops superconductivity at a critical temperature ("T"c) of approximately 35 K (-238 degrees Celsius). This is well above the highest critical temperature known at the time ("T"c = 23 K) and thus the new family of materials were called high-temperature superconductors. Bednorz and Müller received the Nobel prize in Physics for this discovery in 1987. Since then, many other high-temperature superconductors have been synthesized. As early as 1987, superconductivity above 77 K, the boiling point of nitrogen, was achieved. This is highly significant from the point of view of the technological applications of superconductivity, because liquid nitrogen is far less expensive than liquid helium, which is required to cool conventional superconductors down to their critical temperature. The current record critical temperature is about "T"c = 133 K (−140 °C) at standard pressure, and somewhat higher critical temperatures can be achieved at high pressure. Nevertheless, at present it is considered unlikely that cuprate perovskite materials will achieve room-temperature superconductivity.
On the other hand, in recent years other unconventional superconductors have been discovered. These include some that do not superconduct at high temperatures, such as the strontium ruthenate oxide compounds, but that, like the high-temperature superconductors, are unconventional in other ways (for example, the origin of the attractive force leading to the formation of Cooper pairs may be different from the one postulated in BCS theory). In addition to this, superconductors that have unusually high values of "T"c but that are not cuprate perovskites have been discovered. Some of them may be extreme examples of conventional superconductors (this is suspected of magnesium diboride, MgB2, with "T"c = 39 K). Others display more unconventional features.
In 2008 a new class (layered oxypnictide superconductors), for example LaOFeAs, were discovered that do not include copper. An oxypnictide of samarium seems to have a "T"c of about 43 K which is higher than predicted by BCS theory. Tests at up to 45 teslas suggest the upper critical field of LaFeAsO0.89F0.11 may be around 64 teslas. Some other iron-based superconductors do not contain oxygen.
History and progress.
After more than twenty years of intensive research the origin of high-temperature superconductivity is still not clear, but it seems that instead of "electron-phonon" attraction mechanisms, as in conventional superconductivity, one is dealing with genuine "electronic" mechanisms (e.g. by antiferromagnetic correlations), and instead of s-wave pairing, d-waves are substantial.
One goal of all this research is room-temperature superconductivity.
Examples.
Examples of high-"T"c cuprate superconductors include La1.85Ba0.15CuO4, and YBCO (yttrium-barium-copper-oxide), which is famous as the first material to achieve superconductivity above the boiling point of liquid nitrogen.
Process.
Perovskites are made by mixing oxides in stoichiometric quantities and then heating in a furnace at high temperatures in an oxygen-rich atmosphere.
Ongoing research.
The question of how superconductivity arises in high-temperature superconductors is one of the major unsolved problems of theoretical condensed matter physics . The mechanism that causes the electrons in these crystals to form pairs is not known.
Despite intensive research and many promising leads, an explanation has so far eluded scientists. One reason for this is that the materials in question are generally very complex, multi-layered crystals (for example, BSCCO), making theoretical modeling difficult.
Possible mechanism.
The most controversial topic in condensed matter physics has been the mechanism for high-"T"c superconductivity (HTS). There have been two representative theories on the HTS : (See also Resonating valence bond theory )
Thus, in order to solve this unsettled problem, there have been numerous experiments such as photoelectron spectroscopy, NMR, specific heat measurement, etc. Unfortunately, the results were ambiguous, where some reports supported the d symmetry for the HTS but others supported the s symmetry. This muddy situation possibly originated from the indirect nature of the experimental evidence, as well as experimental issues such as sample quality, impurity scattering, twinning, etc.
Previous studies on the symmetry of the HTS order parameter.
The symmetry of the HTS order parameter has been studied in nuclear magnetic resonance measurements and, more recently, by angle-resolved photoemission and measurements of the microwave penetration depth in a HTS crystal. NMR measurements probe the local magnetic field around an atom and hence reflect the susceptibility of the material. They have been of special interest for the HTS materials because many researchers have wondered whether spin correlations might play a role in the mechanism of the HTS.
NMR measurements of the resonance frequency on YBCO indicated that electrons in the copper oxide superconductors are paired in spin-singlet states. This indication came from the behavior of the Knight shift, the frequency shift that occurs when the internal field is different from the applied field: In a normal metal, the magnetic moments of the conduction electrons in the neighborhood of the ion being probed align with the applied field and create a larger internal field. As these metals go superconducting, electrons with oppositely directed spins couple to form singlet states. In the anisotropic HTS, perhaps NMR measurements have found that the relaxation rate for copper depends on the direction of the applied static magnetic field, with the rate being higher when the static field is parallel to one of the axes in the copper oxide plane. While this observation by some group supported the d symmetry of the HTS, other groups could not observe it.
Also, by measuring the "penetration depth", the symmetry of the HTS order parameter can be studied. The microwave penetration depth is determined by the superfluid density responsible for screening the external field. In the s wave BCS theory, because pairs can be thermally excited across the gap Δ, the change in superfluid density per unit change in temperature goes as exponential behavior, exp(-Δ/"k"B"T"). In that case, the penetration depth also varies exponentially with temperature "T". If there are nodes in the energy gap as in the "d" symmetry HTS, electron pair can more easily be broken, the superfluid density should have a stronger temperature dependence, and the penetration depth is expected to increase as a power of T at low temperatures. If the symmetry is specially "d""x"2-"y"2 then the penetration depth should vary linearly with "T" at low temperatures. This technique is increasingly being used to study superconductors and is limited in application largely by the quality of available single crystals.
Photoemission spectroscopy also could provide information on the HTS symmetry. By scattering photons off electrons in the crystal, one can sample the energy spectra of the electrons. Because the technique is sensitive to the angle of the emitted electrons one can determine the spectrum for different wave vectors on the Fermi surface. However, within the resolution of the angle-resolved photoemission spectroscopy (ARPES), researchers could not tell whether the gap goes to zero or just gets very small. Also, ARPES are sensitive only to the magnitude and not to the sign of the gap, so it could not tell if the gap goes negative at some point. This means that ARPES cannot determine whether the HTS order parameter has the "d" symmetry or not.
Junction experiment supporting the "d" symmetry.
There was a clever experimental design to overcome the muddy situation. An experiment based on flux quantization of a three-grain ring of YBa2Cu3O7 (YBCO) was proposed to test the symmetry of the order parameter in the HTS. The symmetry of the order parameter could best be probed at the junction interface as the Cooper pairs tunnel across a Josephson junction or weak link. It was expected that only for a junction of "d" symmetry superconductors there could occur a half-integer flux, that is, a spontaneous magnetization. However, even if the junction experiment is the strongest method to determine the symmetry of the HTS order parameter, there have been ambiguous results of the junction experiments.
J. R. Kirtley and C. C. Tsuei thought that the ambiguous results came from the defect inside the HTS, so that they designed the experiment where both of clean limit (no defect) and dirty limit (maximum of defects) were simultaneously considered. In the experiment, the spontaneous magnetization was clearly observed in YBCO, which absolutely supported the "d" symmetry of the order parameter in YBCO. Because YBCO is orthorhombic, it might inherently have an admixture of s symmetry. So, by tuning their technique further, they found that there was an admixture of s symmetry in YBCO within about 3%. Also, they found that there was a pure "d""x"2-"y"2 order parameter symmetry in the tetragonal Tl2Ba2CuO6.

</doc>
<doc id="51086" url="https://en.wikipedia.org/wiki?curid=51086" title="Jefferson County">
Jefferson County

Jefferson County is the name of 26 counties and one parish in the United States:
Other:

</doc>
<doc id="51089" url="https://en.wikipedia.org/wiki?curid=51089" title="919">
919

__NOTOC__
Year 919 (CMXIX) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="51090" url="https://en.wikipedia.org/wiki?curid=51090" title="918">
918

__NOTOC__
Year 918 (CMXVIII) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="51091" url="https://en.wikipedia.org/wiki?curid=51091" title="917">
917

__NOTOC__
Year 917 (CMXVII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="51092" url="https://en.wikipedia.org/wiki?curid=51092" title="916">
916

__NOTOC__
Year 916 (CMXVI) was a leap year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="51093" url="https://en.wikipedia.org/wiki?curid=51093" title="915">
915

__NOTOC__
Year 915 (CMXV) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="51094" url="https://en.wikipedia.org/wiki?curid=51094" title="914">
914

__NOTOC__
Year 914 (CMXIV) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="51096" url="https://en.wikipedia.org/wiki?curid=51096" title="912">
912

__NOTOC__
Year 912 (CMXII) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="51097" url="https://en.wikipedia.org/wiki?curid=51097" title="Kurt Weill">
Kurt Weill

Kurt Julian Weill (March 2, 1900April 3, 1950) was a German composer, active from the 1920s in his native country, and in his later years in the United States. He was a leading composer for the stage who was best known for his fruitful collaborations with Bertolt Brecht. With Brecht, he developed productions such as his best-known work "The Threepenny Opera", which included the ballad "Mack the Knife". Weill held the ideal of writing music that served a socially useful purpose. He wrote several works for the concert hall, as well as several Judaism-themed pieces. He became a United States citizen on August 27, 1943.
Personal life.
Weill was born on March 2, 1900, the third of four children to Albert Weill (1867–1950) and Emma Weill (née Ackermann; 1872–1955). He grew up in a religious Jewish family in the "Sandvorstadt", the Jewish quarter in Dessau, Germany, where his father was a cantor. At the age of twelve, Weill started taking piano lessons and made his first attempts at writing music; his earliest preserved composition was written in 1913 and is titled "Mi Addir. Jewish Wedding Song".
In 1915, Weill started taking private lessons with Albert Bing, Kapellmeister at the "Herzogliches Hoftheater zu Dessau", who taught him piano, composition, music theory, and conducting. Weill performed publicly on piano for the first time in 1915, both as an accompanist and soloist. The following years he composed numerous Lieder to the lyrics of poets such as Joseph von Eichendorff, Arno Holz, and Anna Ritter, as well as a cycle of five songs titled "Ofrahs Lieder" to a German translation of a text by Yehuda Halevi.
Weill graduated with an Abitur from the "Oberrealschule" of Dessau in 1918, and enrolled at the Berliner Hochschule für Musik at the age of 18, where he studied composition with Engelbert Humperdinck, conducting with Rudolf Krasselt, and counterpoint with Friedrich E. Koch, and also attended philosophy lectures by Max Dessoir and Ernst Cassirer. The same year, he wrote his first string quartet (in B minor).
Early work and compositions.
Weill's family experienced financial hardship in the aftermath of World War I, and in July 1919, Weill abandoned his studies and returned to Dessau, where he was employed as a répétiteur at the Friedrich-Theater under the direction of the new Kapellmeister, Hans Knappertsbusch. During this time, he composed an orchestral suite in E-flat major, a symphonic poem of Rainer Maria Rilke's "The Lay of the Love and Death of Cornet Christopher Rilke" as well as "Schilflieder", a cycle of five songs to poems by Nikolaus Lenau. In December 1919, through the help of Humperdinck, Weill was appointed as Kapellmeister at the newly founded Stadttheater in Lüdenscheid, where he directed opera, operetta, and singspiel for five months, and also composed a cello sonata and "Ninon de Lenclos", a now lost one-act operatic adaptation of a play by Ernst Hardt. From May to September 1920, Weill spent a couple of months in Leipzig, where his father had become the new director of a Jewish orphanage. Before he returned to Berlin, in September 1920, he composed "Sulamith", a choral fantasy for soprano, female choir, and orchestra.
Studies with Busoni.
Back in Berlin, Weill had an interview with Ferruccio Busoni in December 1920. After examining some of Weill's compositions, Busoni accepted him as one of five master students in composition at the Preußische Akademie der Künste in Berlin. From January 1921 to December 1923, Weill studied music composition with him and also counterpoint with Philipp Jarnach in Berlin. During his first year he composed his first symphony, "Sinfonie in einem Satz", as well as the lieder "Die Bekehrte" (Goethe) and two "Rilkelieder" for voice and piano. To support his family in Leipzig, he also worked as a pianist in a Bierkeller tavern. In spring of 1922, Weill joined the November Group's music faction. That year he composed a psalm, a divertimento for orchestra, and "Sinfonia Sacra: Fantasia, Passacaglia, and Hymnus for Orchestra". On November 18, 1922, his children's pantomime "Die Zaubernacht" ("The Magic Night") premiered at the Theater am Kurfürstendamm; it was the first public performance of any of Weill's works in the field of musical theatre.
Out of financial need, Weill taught music theory and composition to private students from 1923 to 1925. Among his students were Claudio Arrau, Maurice Abravanel, Heinz Jolles (later known as Henry Jolles), and Nikos Skalkottas. Arrau, Abravenel, and Jolles remained members of Weill's circle of friends thereafter, and Jolles's sole surviving composition predating the rise of the Nazi regime in 1933 is a fragment of a work for four pianos he and Weill wrote jointly. Weill's compositions during his last year of studies included "Quodlibet", an orchestral suite version of "Die Zaubernacht", "Frauentanz", seven medieval poems for soprano, flute, viola, clarinet, French horn, and bassoon, and "Recordare" for choir and children's choir to words from the Book of Lamentations. Further premieres that year included a performance of his "Divertimento for Orchestra" by the Berlin Philharmonic under the direction of Heinz Unger on April 10, 1923, and the Hindemith-Amar Quartet's rendering of Weill's "String Quartet", Op. 8, on June 24, 1923. In December 1923, Weill finished his studies with Busoni.
Success in the 1920s and early-1930s.
In 1922 he joined the "Novembergruppe", a group of leftist Berlin artists that included Hanns Eisler and Stefan Wolpe. In February 1924 the conductor Fritz Busch introduced him to the dramatist Georg Kaiser, with whom Weill would have a long-lasting creative partnership resulting in several one-act operas. At Kaiser's house in Grünheide, Weill first met singer/actress Lotte Lenya in the summer of 1924. The couple were married twice: in 1926 and again in 1937 (following their divorce in 1933). She took great care to support Weill's work, and after his death she took it upon herself to increase awareness of his music, forming the Kurt Weill Foundation. From November 1924 to May 1929, Weill wrote hundreds of reviews for the influential and comprehensive radio program guide "Der deutsche Rundfunk". Hans Siebert von Heister had already worked with Weill in the November Group, and offered Weill the job shortly after becoming editor-in-chief.
Although he had some success with his first mature non-stage works (such as the String Quartet, Op. 8 or the Concerto for Violin and Wind Orchestra, Op. 12), which were influenced by Gustav Mahler, Arnold Schoenberg and Igor Stravinsky, Weill tended more and more to vocal music and musical theatre. His musical theatre work and his songs were extremely popular with the wider public in Germany at the end of the 1920s and the beginning of the 1930s. Weill's music was admired by composers such as Alban Berg, Alexander von Zemlinsky, Darius Milhaud and Stravinsky, but it was also criticised by others: by Schoenberg, who later revised his opinion, and by Anton Webern.
His best-known work is "The Threepenny Opera" (1928), a reworking of John Gay's "The Beggar's Opera" written in collaboration with Bertolt Brecht. Engel directed the original production of "The Threepenny Opera" in 1928. It contains Weill's most famous song, "Mack the Knife" (""Die Moritat von Mackie Messer""). The stage success was filmed by G. W. Pabst in two language versions: "Die 3-Groschen-Oper" and "L'opéra de quat' sous". Weill and Brecht tried to stop the film adaptation through a well publicised lawsuit—which Weill won and Brecht lost. Weill's working association with Brecht, although successful, came to an end over politics in 1930. Though Weill associated with socialism, after Brecht tried to push the play even further into a left wing direction, Weill commented, according to his wife Lotte Lenya, that he was unable to "set the communist party manifesto to music."
Paris, London and New York.
Weill fled Nazi Germany in March 1933. A prominent and popular Jewish composer, Weill was officially denounced for his populist views and sympathies, and became a target of the Nazi authorities, who criticized and interfered with performances of his later stage works, such as "Rise and Fall of the City of Mahagonny" ("Aufstieg und Fall der Stadt Mahagonny", 1930), "Die Bürgschaft" (1932), and "Der Silbersee" (1933). With no option but to leave Germany, he went first to Paris, where he worked once more with Brecht (after a project with Jean Cocteau failed) on the ballet "The Seven Deadly Sins".
On April 13, 1933 his musical "The Threepenny Opera" was given its premiere on Broadway, but closed after 13 performances to mixed reviews. In 1934 he completed his Symphony No. 2, his last purely orchestral work, conducted in Amsterdam and New York by Bruno Walter, and also the music for Jacques Deval's play, "". A production of his operetta "Der Kuhhandel" ("A Kingdom for a Cow") took him to London in 1935, and later that year he went to the United States in connection with "The Eternal Road", a "Biblical Drama" by Franz Werfel that had been commissioned by members of New York's Jewish community and was premiered in 1937 at the Manhattan Opera House, running for 153 performances.
He and his wife moved to New York City on September 10, 1935, living first at the St. Moritz Hotel before moving on to an apartment at 231 East 62nd Street between Third and Second Avenues. Weill and his wife rented an old house with Paul Green during the summer of 1936 near Pine Brook Country Club in Nichols, Connecticut, the summer home of the Group Theatre, while finishing "Johnny Johnson". Some of the other artists who summered there in 1936 were; Elia Kazan, Harry Morgan, John Garfield, Lee J. Cobb, Will Geer, Clifford Odets, Howard Da Silva and Irwin Shaw.
Rather than continue to write in the same style that had characterized his European compositions, Weill made a study of American popular and stage music. His American output—though held by some to be inferior—nonetheless contains individual songs and entire shows that not only became highly respected and admired, but have been seen as seminal works in the development of the American musical. In 1939 he wrote the music for "Railroads on Parade," a musical spectacular put on at the 1939 World's Fair in New York to celebrate the American railroad industry (book by Edward Hungerford). Unique among Broadway composers of the time, Weill insisted on writing his own orchestrations (with some very few exceptions, such as the dance music in "Street Scene"). He worked with writers such as Maxwell Anderson and Ira Gershwin, and wrote a film score for Fritz Lang ("You and Me", 1938). Weill himself strove to find a new way of creating an American opera that would be both commercially and artistically successful. The most interesting attempt in this direction is "Street Scene", based on a play by Elmer Rice, with lyrics by Langston Hughes. For his work on "Street Scene" Weill was awarded the inaugural Tony Award for Best Original Score.
In the 1940s Weill lived in Downstate New York near the New Jersey border and made frequent trips both to New York City and to Hollywood for his work for theatre and film. Weill was active in political movements encouraging American entry into World War II, and after America joined the war in 1941, Weill enthusiastically collaborated in numerous artistic projects supporting the war effort both abroad and on the home front. He and Maxwell Anderson also joined the volunteer civil service by working as air raid wardens on High Tor Mountain between their homes in New City, New York and Haverstraw, New York in Rockland County. Weill became a naturalized citizen of the United States in 1943.
Weill had ideals of writing music that served a socially useful purpose. In the US, he wrote "Down in the Valley", an opera including the song of the same name and other American folk songs. He also wrote a number of songs in support of the American war effort, including the satirical "Schickelgruber" (with lyrics by Howard Dietz), ""Buddy on the Nightshift"" (with Oscar Hammerstein) and – with Brecht again as in his earlier career – the ""Ballad of the Nazi Soldier's Wife"" ("Und was bekam des Soldaten Weib?"). Intended for broadcast to Germany, the song chronicled the progress of the Nazi war machine through the gifts sent to the proud wife at home by her man at the front: furs from Oslo, a silk dress from Paris etc., until finally, from Russia, she receives her widow's veil.
Apart from "Mack the Knife" and "Pirate Jenny" from "The Threepenny Opera", his most famous songs include "Alabama Song" (from "Mahagonny"), "Surabaya Johnny" (from "Happy End"), "Speak Low" (from "One Touch of Venus"), "Lost in the Stars" (from the musical of that name), "My Ship" (from "Lady in the Dark"), and "September Song" (from "Knickerbocker Holiday").
Death.
Weill suffered a heart attack shortly after his 50th birthday and died on April 3, 1950, in New York City. He was buried in Mount Repose Cemetery in Haverstraw, New York. The text and music on his gravestone come from the song "A Bird of Passage" from "Lost in the Stars", itself adapted from a quotation from the Venerable Bede:
<poem style="margin-left: 2em;">This is the life of men on earth:
Out of darkness we come at birth
Into a lamplit room, and then –
Go forward into dark again.
An excerpt from Maxwell Anderson's eulogy for Weill read:
I wish, of course, that he had been lucky enough to have had a little more time for his work. I could wish the times in which he lived had been less troubled. But these things were as they were – and Kurt managed to make thousands of beautiful things during the short and troubled time he had...
Influence.
Sixty years after his death, Weill's music continues to be performed both in popular and classical contexts. In Weill's lifetime, his work was most associated with the voice of his wife, Lotte Lenya, but shortly after his death "Mack the Knife" was established by Louis Armstrong and Bobby Darin as a jazz standard. His music has since been recorded by many performers, ranging from Nina Simone, Frank Sinatra, The Doors, Ella Fitzgerald, David Bowie, Robbie Williams, Judy Collins, John Zorn, Dagmar Krause, Steeleye Span, The Young Gods and PJ Harvey to New York's Metropolitan Opera and the Vienna Radio Symphony Orchestra. Singers as varied as Teresa Stratas, Ute Lemper, Gisela May, Anne Sofie von Otter, Max Raabe, Heinz Karl Gruber, Dee Dee Bridgewater and Marianne Faithfull have recorded entire albums of his music.
In 1985, Hal Willner produced "", a tribute album in which Weill's songs were interpreted by a variety of artists, including Todd Rundgren, Ella Fitzgerald, Tom Waits, Lou Reed and Sting.
Amanda Palmer, singer/pianist of the 'Brechtian Punk Cabaret' duo The Dresden Dolls, has Kurt Weill's name on the front of her keyboard (a pun with the name of the instrument maker Kurzweil) as a tribute to the composer. In 1991, seminal Swiss Industrial music band The Young Gods released their album of Kurt Weill songs, "The Young Gods Play Kurt Weill". Weill was also often cited as an influence on Goldfrapp's "Felt Mountain". In 2008, Weill's songs were performed by Canadian musicians (including Sarah Slean and Mary Margaret O'Hara) in a tribute concert as part of the first annual Canwest Cabaret Festival in Toronto. In 2009 Duke Special released an EP, "Huckleberry Finn", of five songs from an unfinished musical by Kurt Weill based on the novel by Mark Twain.
Connected family.
Kurt Weill's grandmother was Jeanette Hochstetter of Liedolsheim, Germany. Weill was one of four members of the same Hochstetter family to lead distinguished careers in the fields of music and literature. His first cousin once removed was Caesar Hochstetter (born January 12, 1863 in Ladenburg, a suburb of Mannheim – his date and place of death are unknown but this was probably during The Holocaust), a composer and arranger who collaborated with Max Reger and who dedicated to him.
Caesar's younger brother was Professor (born May 12, 1873, Mannheim – died 1942, Theresienstadt concentration camp), Professor of Literature at the University of Brussels, writer and poet and friend of Wilhelm Busch. His second cousin was the childhood prodigy pianist, Lisy Fischer (born August 22, 1900, Zürich, Switzerland – died June 6, 1999, Newcastle upon Tyne, England).

</doc>
<doc id="51098" url="https://en.wikipedia.org/wiki?curid=51098" title="895">
895

__NOTOC__
Year 895 (DCCCXCV) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Music.
</onlyinclude>

</doc>
<doc id="51100" url="https://en.wikipedia.org/wiki?curid=51100" title="894">
894

__NOTOC__
Year 894 (DCCCXCIV) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="51101" url="https://en.wikipedia.org/wiki?curid=51101" title="3 BC">
3 BC

__NOTOC__
Year 3 BC was a common year starting on Wednesday or Thursday (link will display the full calendar) of the Julian calendar (the sources differ, see leap year error for further information) and a common year starting on Tuesday of the Proleptic Julian calendar. At the time, it was known as the Year of the Consulship of Lentulus and Messalla (or, less frequently, year 751 "Ab urbe condita"). The denomination 3 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Jerusalem Temple (Judean Hills)
Summer Gabriel (The Angel ) delivers A message from God ([http://www.jw.org/en/publications/bible/nwt/books/luke/1/#v42001005 Luke 1:5-25) In the Days of Herod Fortelling the birth of John the Baptist to Zechariah the Priest and Elizabeth his parents.
Roman Empire.
</onlyinclude>

</doc>
<doc id="51102" url="https://en.wikipedia.org/wiki?curid=51102" title="4 BC">
4 BC

__NOTOC__
Year 4 BC was a common year starting on Tuesday or Wednesday (link will display the full calendar) of the Julian calendar (the sources differ, see leap year error for further information) and a common year starting on Monday of the Proleptic Julian calendar. At the time, it was known as the Year of the Consulship of Sabinus and Rufus (or, less frequently, year 750 "Ab urbe condita"). The denomination 4 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Judea Province, Roman Empire.
</onlyinclude>

</doc>
<doc id="51104" url="https://en.wikipedia.org/wiki?curid=51104" title="110s BC">
110s BC


</doc>
<doc id="51105" url="https://en.wikipedia.org/wiki?curid=51105" title="951">
951

__NOTOC__
Year 951 (CMLI) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="51106" url="https://en.wikipedia.org/wiki?curid=51106" title="Francis Walsingham">
Francis Walsingham

Sir Francis Walsingham ( 1532 – 6 April 1590) was principal secretary to Queen Elizabeth I of England from 20 December 1573 until his death and is popularly remembered as her "spymaster".
Born to a well-connected family of gentry, Walsingham attended Cambridge University and travelled in continental Europe before embarking on a career in law at the age of twenty. A committed Protestant, during the reign of the Catholic Queen Mary I of England he joined other expatriates in exile in Switzerland and northern Italy until Mary's death and the accession of her Protestant half-sister, Elizabeth.
Walsingham rose from relative obscurity to become one of the small coterie who directed the Elizabethan state, overseeing foreign, domestic and religious policy. He served as English ambassador to France in the early 1570s and witnessed the St. Bartholomew's Day massacre. As principal secretary, he supported exploration, colonization, the use of England's maritime strength and the plantation of Ireland. He worked to bring Scotland and England together. Overall, his foreign policy demonstrated a new understanding of the role of England as a maritime, Protestant power in an increasingly global economy. He oversaw operations that penetrated Spanish military preparation, gathered intelligence from across Europe, disrupted a range of plots against Elizabeth and secured the execution of Mary, Queen of Scots.
Early years.
Francis Walsingham was born in or about 1532, probably at Foots Cray, near Chislehurst, Kent. His parents were William and Joyce Walsingham. William was a successful, well-connected and wealthy London lawyer who died in 1534 and Joyce was the daughter of courtier Sir Edmund Denny and the sister of Sir Anthony Denny, who was the principal gentleman of King Henry VIII's privy chamber. William Walsingham served as a member of the commission that was appointed to investigate the estates of Cardinal Thomas Wolsey in 1530, and his elder brother, Sir Edmund Walsingham, was Lieutenant of the Tower of London. After William's death, Joyce married the courtier Sir John Carey in 1538. Carey's brother William was the husband of Mary Boleyn, Anne Boleyn's elder sister. Of Francis Walsingham's five sisters, Mary married Sir Walter Mildmay, who was Chancellor of the Exchequer for over 20 years, and Elizabeth married the parliamentarian Peter Wentworth.
Francis Walsingham matriculated at King's College, Cambridge, in 1548 with many other Protestants but as an undergraduate of high social status did not sit for a degree. From 1550 or 1551, he travelled in continental Europe, returning to England by 1552 to enrol at Gray's Inn, one of the qualifying bodies for English lawyers.
Upon the death in 1553 of Henry VIII's successor, Edward VI, Edward's Catholic half-sister Mary I became queen. Many wealthy Protestants, such as John Foxe and John Cheke, fled England, and Walsingham was among them. He continued his studies in law at the universities of Basel and Padua, where he was elected to the governing body by his fellow students in 1555.
Rise to power.
Mary I died in 1558 and was succeeded by her Protestant half-sister Elizabeth I. Walsingham returned to England and through the support of one of his fellow former exiles, Francis Russell, 2nd Earl of Bedford, he was elected to Elizabeth's first parliament as the member for Bossiney, Cornwall, in 1559. At the subsequent election in 1563, he was returned for both Lyme Regis, Dorset, another constituency under Bedford's influence, and Banbury, Oxfordshire. He chose to sit for Lyme Regis. In January 1562 he married Anne, daughter of Sir George Barne, Lord Mayor of London in 1552–3, and widow of wine merchant Alexander Carleill. Anne died two years later leaving her son Christopher Carleill in Walsingham's care. In 1566, Walsingham married Ursula St. Barbe, widow of Sir Richard Worsley, and Walsingham acquired her estates of Appuldurcombe and Carisbrooke Priory on the Isle of Wight. The following year, she bore him a daughter, Frances. Walsingham's other two stepsons, Ursula's sons John and George, were killed in a gunpowder accident at Appuldurcombe in 1567.
In the following years, Walsingham became active in soliciting support for the Huguenots in France and developed a friendly and close working relationship with Nicholas Throckmorton, his predecessor as MP for Lyme Regis and a former ambassador to France. By 1569, Walsingham was working with William Cecil to counteract plots against Elizabeth. He was instrumental in the collapse of the Ridolfi plot, which hoped to replace Elizabeth with the Catholic Mary, Queen of Scots. He is credited with writing propaganda decrying a conspiratorial marriage between Mary and Thomas Howard, 4th Duke of Norfolk, and Roberto di Ridolfi, after whom the plot was named, was interrogated at Walsingham's house.
In 1570, the Queen chose Walsingham to support the Huguenots in their negotiations with Charles IX of France. Later that year, he succeeded Sir Henry Norris as English ambassador in Paris. One of his duties was to continue negotiations for a marriage between Elizabeth and Charles IX's younger brother Henry, Duke of Anjou. The marriage plan was eventually dropped on the grounds of Henry's Catholicism. A substitute match with the next youngest brother, Francis, Duke of Alençon, was proposed but Walsingham considered him ugly and "void of a good humour". Elizabeth was 20 years older than Alençon, and was concerned that the age difference would be seen as absurd. Walsingham believed that it would serve England better to seek a military alliance with France against Spanish interests. The defensive Treaty of Blois was concluded between France and England in 1572, but the treaty made no provision for a royal marriage and left the question of Elizabeth's successor open.
The Huguenots and other European Protestant interests supported the nascent revolt in the Spanish Netherlands, which were provinces of Habsburg Spain. When Catholic opposition to this course in France resulted in the death of Huguenot leader Gaspard de Coligny and the St. Bartholomew's Day massacre, Walsingham's house in Paris became a temporary sanctuary for Protestant refugees, including Philip Sidney. Ursula, who was pregnant, escaped to England with their four-year-old daughter. She gave birth to a second girl, Mary, in January 1573 while Walsingham was still in France. He returned to England in April 1573, having established himself as a competent official whom the Queen and Cecil could trust. He cultivated contacts throughout Europe, and a century later his dispatches would be published as "The Complete Ambassador".
In the December following his return, Walsingham was appointed to the Privy Council of England and was made joint principal secretary (the position which later became "Secretary of State") with Sir Thomas Smith. Smith retired in 1576, leaving Walsingham in effective control of the privy seal, though he was not formally invested as Lord Privy Seal. Walsingham acquired a Surrey county seat in Parliament from 1572 that he retained until his death, but he was not a major parliamentarian. He was knighted on 1 December 1577, and held the sinecure posts of Recorder of Colchester, "custos rotulorum" of Hampshire, and High Steward of Salisbury, Ipswich and Winchester. He was appointed Chancellor of the Order of the Garter from 22 April 1578 until succeeded by Sir Amias Paulet in June 1587, when he became Chancellor of the Duchy of Lancaster in addition to principal secretary.
Secretary of State.
The duties of the principal secretary were not defined formally, but as he handled all royal correspondence and determined the agenda of council meetings, he could wield great influence in all matters of policy and in every field of government, both foreign and domestic. During his term of office, Walsingham supported the use of England's maritime power to open new trade routes and explore the New World, and was at the heart of international affairs. He was involved directly with English policy towards Spain, the Netherlands, Scotland, Ireland and France, and embarked on several diplomatic missions to neighbouring European states.
Closely linked to the mercantile community, he actively supported trade promotion schemes and invested in the Muscovy Company and the Levant Company. He supported the attempts of John Davis and Martin Frobisher to discover the Northwest Passage and exploit the mineral resources of Labrador, and encouraged Humphrey Gilbert's exploration of Newfoundland. Gilbert's voyage was largely financed by recusant Catholics and Walsingham favoured the scheme as a potential means of removing Catholics from England by encouraging emigration to the New World. Walsingham was among the promoters of Francis Drake's profitable 1578–1581 circumnavigation of the world, correctly judging that Spanish possessions in the Pacific were vulnerable to attack. The venture was calculated to promote the Protestant interest by embarrassing and weakening the Spanish, as well as to seize Spanish treasure. The first edition of Richard Hakluyt's "Principal Navigation, Voyages and Discoveries of the English Nation" was dedicated to Walsingham.
Walsingham advocated direct intervention in the Netherlands in support of the Protestant revolt against Spain, on the grounds that although wars of conquest were unjust, wars in defence of religious liberty and freedom were not. Cecil was more circumspect and advised a policy of mediation, a policy that Elizabeth endorsed. Walsingham was sent on a special embassy to the Netherlands in 1578, to sound out a potential peace deal and gather military intelligence.
Charles IX died in 1574 and Henry, Duke of Anjou, inherited the French throne as Henry III. Between 1578 and 1581 the Queen resurrected attempts to negotiate a marriage with the Duke of Alençon, who had put himself forward as a protector of the Huguenots and a potential leader of the Dutch. Walsingham was sent to France in mid-1581 to discuss an Anglo-French alliance, but the French wanted the marriage agreed first and Walsingham was under instruction to obtain a treaty before committing to the marriage. He returned to England without an agreement. Personally, Walsingham opposed the marriage, perhaps to the point of encouraging public opposition. Alençon was a Catholic and as his elder brother, Henry III, was childless, he was heir to the French throne. Elizabeth was past the age of childbearing and had no clear successor. If she died while married to the French heir, her realms could fall under French control. By comparing the match of Elizabeth and Alençon with the match of the Protestant Henry of Navarre and the Catholic Margaret of Valois, which occurred in the week before the St. Bartholomew's Day massacre, the "most horrible spectacle" he had ever witnessed, Walsingham raised the spectre of religious riots in England in the event of the marriage proceeding. Elizabeth put up with his blunt, often unwelcome, advice, and acknowledged his strong beliefs in a letter, in which she called him "her Moor cannot change his colour".
These were years of tension in policy towards France, with Walsingham sceptical of the unpredictable Henry III and distrustful of the English ambassador in Paris, Edward Stafford. Stafford, who was compromised by his gambling debts, was in the pay of the Spanish and passed vital information to Spain. Walsingham may have been aware of Stafford's duplicity, as he fed the ambassador false information, presumably in the hope of fooling or confusing the Spanish.
The pro-English Regent of Scotland James Douglas, 4th Earl of Morton, whom Walsingham had supported, was overthrown in 1578. After the collapse of the Raid of Ruthven, another initiative to secure a pro-English government in Scotland, Walsingham reluctantly visited the Scottish court in August 1583, knowing that his diplomatic mission was unlikely to succeed. James VI dismissed Walsingham's advice on domestic policy saying he was an "absolute King" in Scotland. Walsingham replied with a discourse on the topic that "young princes were many times carried into great errors upon an opinion of the absoluteness of their royal authority and do not consider, that when they transgress the bounds and limits of the law, they leave to be kings and become tyrants." A mutual defence pact was eventually agreed in the Treaty of Berwick of 1586.
Walsingham's cousin Edward Denny fought in Ireland during the rebellion of the Earl of Desmond and was one of the English settlers granted land in Munster confiscated from Desmond. Walsingham's stepson Christopher Carleill commanded the garrisons at Coleraine and Carrickfergus. Walsingham thought Irish farmland was underdeveloped and hoped that plantation would improve the productivity of estates. Tensions between the native Irish and the English settlers had lasting effects on the history of Ireland.
Walsingham's younger daughter Mary died aged seven in July 1580; his elder daughter, Frances, married Sir Philip Sidney on 21 September 1583, despite the Queen's initial objections to the match (for unknown reasons) earlier in the year. As part of the marriage agreement, Walsingham agreed to pay £1,500 of Sidney's debts and gave his daughter and son-in-law the use of his manor at Barn Elms in Surrey. A granddaughter born in November 1585 was named Elizabeth after the Queen, who was one of two godparents along with Sidney's uncle, Robert Dudley, 1st Earl of Leicester. The following year, Sidney was killed fighting the Spanish in the Netherlands and Walsingham was faced with paying off more of Sidney's extensive debts. His widowed daughter gave birth, in a difficult delivery, to a second child shortly afterward, but the baby, a girl, was stillborn.
Espionage.
Walsingham was driven by Protestant zeal to counter Catholicism, and sanctioned the use of torture against Catholic priests and suspected conspirators. Edmund Campion was among those tortured and found guilty on the basis of extracted evidence; he was hanged, drawn and quartered at Tyburn in 1581. Walsingham could never forget the atrocities against Protestants he had witnessed in France during the Bartholomew's Day massacre and believed a similar slaughter would occur in England in the event of a Catholic resurgence. Walsingham's brother-in-law Robert Beale, who was in Paris with Walsingham at the time of the massacre, encapsulated Walsingham's view: "I think it time and more than time for us to awake out of our dead sleep, and take heed lest like mischief as has already overwhelmed the brethren and neighbours in France and Flanders embrace us which be left in such sort as we shall not be able to escape." Walsingham tracked down Catholic priests in England and supposed conspirators by employing informers, and intercepting correspondence. Walsingham's staff in England included the cryptographer Thomas Phelippes, who was an expert in deciphering letters and forgery, and Arthur Gregory, who was skilled at breaking and repairing seals without detection.
In May 1582, letters from the Spanish ambassador in England, Bernardino de Mendoza, to contacts in Scotland were found on a messenger by Sir John Forster, who forwarded them to Walsingham. The letters indicated a conspiracy among the Catholic powers to invade England and displace Elizabeth with Mary, Queen of Scots. By April 1583, Walsingham had a spy, identified as Giordano Bruno by author John Bossy, deployed in the French embassy in London. Walsingham's contact reported that Francis Throckmorton, a nephew of Walsingham's old friend Nicholas Throckmorton, had visited the ambassador, Michel de Castelnau. In November 1583, after six months of surveillance, Walsingham had Throckmorton arrested and then tortured to secure a confession—an admission of guilt that clearly implicated Mendoza. The Throckmorton plot called for an invasion of England along with a domestic uprising to liberate Mary, Queen of Scots, and depose Elizabeth. Throckmorton was executed in 1584 and Mendoza was expelled from England.
Entrapment of Mary, Queen of Scots.
After the assassination in mid-1584 of William the Silent, the leader of the Dutch revolt against Spain, English military intervention in the Low Countries was agreed in the Treaties of Nonsuch of 1585. The murder of William the Silent also reinforced fears for Queen Elizabeth's safety. Walsingham helped create the Bond of Association, the signatories of which promised to hunt down and kill anyone who conspired against Elizabeth. The Act for the Surety of the Queen's Person, passed by Parliament in March 1585, set up a legal process for trying any claimant to the throne implicated in plots against the Queen. The following month Mary, Queen of Scots, was placed in the strict custody of Sir Amias Paulet, a friend of Walsingham. At Christmas, she was moved to a moated manor house at Chartley. Walsingham instructed Paulet to open, read and pass to Mary unsealed any letters that she received, and to block any potential route for clandestine correspondence. In a successful attempt to entrap her, Walsingham arranged a single exception: a covert means for Mary's letters to be smuggled in and out of Chartley in a beer keg. Mary was misled into thinking these secret letters were secure, while in reality they were deciphered and read by Walsingham's agents. In July 1586, Anthony Babington wrote to Mary about an impending plot to free her and kill Elizabeth. Mary's reply was clearly encouraging and sanctioned Babington's plans. Walsingham had Babington and his associates rounded up; fourteen were executed in September 1586. In October, Mary was put on trial under the Act for the Surety of the Queen's Person in front of 36 commissioners, including Walsingham.
During the presentation of evidence against her, Mary broke down and pointed accusingly at Walsingham saying, "all of this is the work of Monsieur de Walsingham for my destruction", to which he replied, "God is my witness that as a private person I have done nothing unworthy of an honest man, and as Secretary of State, nothing unbefitting my duty." Mary was found guilty and the warrant for her execution was drafted, but Elizabeth hesitated to sign it, despite pressure from Walsingham. Walsingham wrote to Paulet urging him to find "some way to shorten the life" of Mary to relieve Elizabeth of the burden, to which Paulet replied indignantly, "God forbid that I should make so foul a shipwreck of my conscience, or leave so great a blot to my poor posterity, to shed blood without law or warrant." Walsingham made arrangements for Mary's execution; Elizabeth signed the warrant on 1 February 1587 and entrusted it to William Davison, who had been appointed as junior Secretary of State in late September 1586. Davison passed the warrant to Cecil and a privy council convened by Cecil without Elizabeth's knowledge agreed to carry out the sentence as soon as was practical. Within a week, Mary was beheaded. On hearing of the execution, Elizabeth claimed not to have sanctioned the action and that she had not meant Davison to part with the warrant. Davison was arrested and imprisoned in the Tower of London. Walsingham's share of Elizabeth's displeasure was small because he was absent from court, at home ill, in the weeks just before and after the execution. Davison was eventually released in October 1588, on the orders of Cecil and Walsingham.
Spanish Armada.
From 1586, Walsingham received many dispatches from his agents in mercantile communities and foreign courts detailing Spanish preparations for an invasion of England. Walsingham's recruitment of Anthony Standen, a friend of the Tuscan ambassador to Madrid, was an exceptional intelligence triumph and Standen's dispatches were deeply revealing. Walsingham worked to prepare England for a potential war with Spain, in particular by supervising the substantial rebuilding of Dover Harbour, and encouraging a more aggressive strategy. On Walsingham's instructions, the English ambassador in Turkey, William Harborne, attempted unsuccessfully to persuade the Ottoman Sultan to attack Spanish possessions in the Mediterranean in the hope of distracting Spanish forces. Walsingham supported Francis Drake's raid of Cadiz in 1587, which wrought havoc with Spanish logistics. The Spanish Armada sailed for England in July 1588. Walsingham received regular dispatches from the English naval forces, and raised his own troop of 260 men as part of the land defences. On 18 August 1588, after the dispersal of the armada, naval commander Lord Henry Seymour wrote to Walsingham, "you have fought more with your pen than many have in our English navy fought with their enemies".
In foreign intelligence, Walsingham's extensive network of "intelligencers", who passed on general news as well as secrets, spanned Europe and the Mediterranean. While foreign intelligence was a normal part of the principal secretary's activities, Walsingham brought to it flair and ambition, and large sums of his own money. He cast his net more widely than others had done previously: expanding and exploiting links across the continent as well as in Constantinople and Algiers, and building and inserting contacts among Catholic exiles. Among his spies may have been the playwright Christopher Marlowe; Marlowe was in France in the mid-1580s and was acquainted with Walsingham's kinsman Thomas Walsingham.
Death and legacy.
From 1571 onwards, Walsingham complained of ill health and often retired to his country estate for periods of recuperation. He complained of "sundry carnosities", pains in his head, stomach and back, and difficulty in passing water. Suggested diagnoses include cancer, kidney stones, urinary infection, and diabetes. He died on 6 April 1590, at his house in Seething Lane. Historian William Camden wrote that Walsingham died from "a carnosity growing "intra testium sunctas" cancer". He was buried privately in a simple ceremony at 10 pm on the following day, beside his son-in-law, in Old St Paul's Cathedral. The grave and monument were destroyed in the Great Fire of London in 1666. His name appears on a modern monument in the crypt listing the important graves lost.
In his will, dated 12 December 1589, Walsingham complained of "the greatness of my debts and the mean state shall leave my wife and heirs in", but the true state of his finances is unclear. He received grants of land from the Queen, grants for the export of cloth and leases of customs in the northern and western ports. His primary residences, apart from the court, were in Seething Lane by the Tower of London (now the site of a Victorian office building called Walsingham House), at Barn Elms in Surrey and at Odiham in Hampshire. Nothing remains of any of his houses. He spent much of his own money on espionage in the service of the Queen and the Protestant cause. In 1586, he funded a lectureship in theology at Oxford University for the Puritan John Rainolds. He had underwritten the debts of his son-in-law, Sir Philip Sidney, had pursued the Sidney estate for recompense unsuccessfully and had carried out major land transactions in his later years. After his death, his friends reflected that poor bookkeeping had left him further in the Crown's debt than was fair. In 1611, the Crown's debts to him were calculated at over £48,000, but his debts to the Crown were calculated at over £43,000 and a judge, Sir Julius Caesar, ordered both sets of debts cancelled "quid pro quo". Walsingham's surviving daughter Frances received a £300 annuity, and married the Earl of Essex. Ursula, Lady Walsingham, continued to live at Barn Elms with a staff of servants until her death in 1602.
Protestants lauded Walsingham as "a sound pillar of our commonwealth and chief patron of virtue, learning and chivalry". He was part of a Protestant intelligentsia that included Philip Sidney, Edmund Spenser and John Dee: men who promoted an expansionist and nationalist English Renaissance. Spenser included a dedicatory sonnet to Walsingham in the "Faerie Queene", likening him to Maecenas who introduced Virgil to the Emperor Augustus. After Walsingham's death, Sir John Davies composed an acrostic poem in his memory and Watson wrote an elegy, "Meliboeus", in Latin. On the other hand, Jesuit Robert Persons thought Walsingham "cruel and inhumane" in his persecution of Catholics. Catholic sources portray a ruthless, devious man driven by religious intolerance and an excessive love for intrigue. Walsingham attracts controversy still. Although he was ruthless, his opponents on the Catholic side were no less so; the treatment of prisoners and suspects by Tudor authorities was typical of European governments of the time. Walsingham's personal, as opposed to his public, character is elusive; his public papers were seized by the government while many of his private papers, which might have revealed much, were lost. The fragments that do survive demonstrate his personal interest in gardening and falconry.
In fiction.
Fictional portrayals of Walsingham tend to follow Catholic interpretations, depicting him as sinister and Machiavellian. He features in conspiracy theories surrounding the death of Christopher Marlowe, whom he predeceased. Charles Nicholl examined (and rejected) such theories in "The Reckoning: The Murder of Christopher Marlowe" (1992), which was used as a source by Anthony Burgess for his novel "A Dead Man in Deptford" (1993).
The 1998 film "Elizabeth" gives considerable, although sometimes historically inaccurate, prominence to Walsingham (portrayed by Geoffrey Rush). It fictionalizes him as irreligious and sexually ambiguous, merges chronologically distant events, and inaccurately suggests that he murdered Mary of Guise. Rush reprised the role in the 2007 sequel, "". Both Stephen Murray in the 1970 BBC series "Elizabeth R" and Patrick Malahide in the 2005 Channel Four miniseries "Elizabeth I" play him as a dour official.

</doc>
<doc id="51108" url="https://en.wikipedia.org/wiki?curid=51108" title="Poison">
Poison

In biology, poisons are substances that cause disturbances in organisms, usually by chemical reaction or other activity on the molecular scale, when an organism absorbs a sufficient quantity.
The fields of medicine (particularly veterinary) and zoology often distinguish a poison from a toxin, and from a venom. Toxins are poisons produced by organisms in nature, and venoms are toxins injected by a bite or sting (this is exclusive to animals). The difference between venom and other poisons is the delivery method. Industry, agriculture, and other sectors use poisons for reasons other than their toxicity. Pesticides are one group of substances whose toxicity is their prime purpose.
In 2013, 3.3 million cases of unintentional poisonings occurred. This resulted in 98,000 deaths worldwide, down from 120,000 deaths in 1990.
Terminology.
The term "poison" is often used colloquially to describe any harmful substance—particularly corrosive substances, carcinogens, mutagens, teratogens and harmful pollutants, and to exaggerate the dangers of chemicals. Paracelsus (1493–1541), the father of toxicology, once wrote: "Everything is poison, there is poison in everything. Only the dose makes a thing not a poison"
(see median lethal dose). The law defines "poison" more strictly. Substances not legally required to carry the label "poison" can also cause a medical condition of poisoning.
Some poisons are also toxins, which is any poison produced by animals, vegetables or bacterium, such as the bacterial proteins that cause tetanus and botulism. A distinction between the two terms is not always observed, even among scientists. The derivative forms "toxic" and "poisonous" are synonymous.
Animal poisons delivered subcutaneously (e.g., by sting or bite) are also called "venom". In normal usage, a poisonous organism is one that is harmful to consume, but a venomous organism uses venom to kill its prey or defend itself while still alive. A single organism can be both poisonous and venomous, but that is rare.
In nuclear physics, a poison is a substance that obstructs or inhibits a nuclear reaction. For an example, see nuclear poison.
Environmentally hazardous substances are not necessarily poisons, and vice versa. For example, food-industry wastewater—which may contain potato juice or milk—can be hazardous to the ecosystems of streams and rivers by consuming oxygen and causing eutrophication, but is nonhazardous to humans and not classified as a poison.
Biologically speaking, any substance, if given in large enough amounts, is poisonous and can cause death. For instance, several kilograms worth of water would constitute a lethal dose. Many substances used as medications – such as fentanyl – have an LD50 only one order of magnitude greater than the ED50. An alternative classification distinguishes between lethal substances that provide a therapeutic value and those that do not.
Poisoning.
Acute poisoning is exposure to a poison on one occasion or during a short period of time. Symptoms develop in close relation to the exposure. Absorption of a poison is necessary for systemic poisoning. In contrast, substances that destroy tissue but do not absorb, such as lye, are classified as corrosives rather than poisons. Furthermore, many common household medications are not labeled with skull and crossbones, although they can cause severe illness or even death. In the medical sense, poisoning can be caused by less dangerous substances than those legally classified as a poison.
Chronic poisoning is long-term repeated or continuous exposure to a poison where symptoms do not occur immediately or after each exposure. The patient gradually becomes ill, or becomes ill after a long latent period. Chronic poisoning most commonly occurs following exposure to poisons that bioaccumulate, or are biomagnified, such as mercury, gadolinium, and lead.
Contact or absorption of poisons can cause rapid death or impairment. Agents that act on the nervous system can paralyze in seconds or less, and include both biologically derived neurotoxins and so-called nerve gases, which may be synthesized for warfare or industry.
Inhaled or ingested cyanide, used as a method of execution in gas chambers, almost instantly starves the body of energy by inhibiting the enzymes in mitochondria that make ATP. Intravenous injection of an unnaturally high concentration of potassium chloride, such as in the execution of prisoners in parts of the United States, quickly stops the heart by eliminating the cell potential necessary for muscle contraction.
Most biocides, including pesticides, are created to act as poisons to target organisms, although acute or less observable chronic poisoning can also occur in non-target organisms (secondary poisoning), including the humans who apply the biocides and other beneficial organisms. For example, the herbicide 2,4-D imitates the action of a plant hormone, which makes its lethal toxicity specific to plants. Indeed, 2,4-D is not a poison, but classified as "harmful" (EU).
Many substances regarded as poisons are toxic only indirectly, by toxication. An example is "wood alcohol" or methanol, which is not poisonous itself, but is chemically converted to toxic formaldehyde and formic acid in the liver. Many drug molecules are made toxic in the liver, and the genetic variability of certain liver enzymes makes the toxicity of many compounds differ between individuals.
Toxicology is the study of the symptoms, mechanisms, treatment and diagnosis of biological poisoning.
Exposure to radioactive substances can produce radiation poisoning, an unrelated phenomenon.
Epidemiology.
[[Image:Poisonings world map - DALY - WHO2004.svg|thumb|Disability-adjusted life year for poisonings per 100,000 inhabitants in 2004.
In 2010, poisoning resulted in about 180,000 deaths down from 200,000 in 1990. There were approximately 727,500 emergency department visits in the United States involving poisonings—3.3% of all injury-related encounters.
Applications.
Poisonous compounds may be useful either for their toxicity, or, more often, because of another chemical property, such as specific chemical reactivity. Poisons are widely used in industry and agriculture, as chemical reagents, solvents or complexing reagents, e.g. carbon monoxide, methanol and sodium cyanide, respectively. They are less common in household use, with occasional exceptions such as ammonia and methanol. For instance, phosgene is a highly reactive nucleophile acceptor, which makes it an excellent reagent for polymerizing diols and diamines to produce polycarbonate and polyurethane plastics. For this use, millions of tons are produced annually. However, the same reactivity makes it also highly reactive towards proteins in human tissue and thus highly toxic. In fact, phosgene has been used as a chemical weapon. It can be contrasted with mustard gas, which has only been produced for chemical weapons uses, as it has no particular industrial use.
Biocides need not be poisonous to humans, because they can target metabolic pathways absent in humans, leaving only incidental toxicity. For instance, the herbicide 2,4-dichlorophenoxyacetic acid is a mimic of a plant growth hormone, which causes uncontrollable growth leading to the death of the plant. Humans and animals, lacking this hormone and its receptor, are unaffected by this, and need to ingest relatively large doses before any toxicity appears. Human toxicity is, however, hard to avoid with pesticides targeting mammals, such as rodenticides.
The risk from toxicity is also distinct from toxicity itself. For instance, the preservative thiomersal used in vaccines is toxic, but the quantity administered in a single shot is negligible.
History.
Throughout human history, intentional application of poison has been used as a method of murder, pest-control, suicide, and execution. As a method of execution, poison has been ingested, as the ancient Athenians did (see Socrates), inhaled, as with carbon monoxide or hydrogen cyanide (see gas chamber), or injected (see lethal injection). Poison's lethal effect can be combined with its allegedly magical powers; an example is the Chinese "gu" poison. Poison was also employed in gunpowder warfare. For example, the 14th-century Chinese text of the "Huolongjing" written by Jiao Yu outlined the use of a poisonous gunpowder mixture to fill cast iron grenade bombs.

</doc>
<doc id="51109" url="https://en.wikipedia.org/wiki?curid=51109" title="Charles VII, Holy Roman Emperor">
Charles VII, Holy Roman Emperor

Charles VII (6 August 1697 – 20 January 1745) was the prince-elector of Bavaria from 1726 and Holy Roman Emperor from 24 January 1742 until his death, in 1745. A member of the House of Wittelsbach, Charles was notably the only person not born of the House of Habsburg to become emperor in over three centuries (although he was descended from the Habsburg Philip I of Castile by 27 different ways).
Early life and career.
He was born in Brussels as the son of Maximilian II Emanuel, Elector of Bavaria and Theresa Kunegunda Sobieska, and the grandson of Polish King John III Sobieski.
His family was split during the War of the Spanish Succession and was for many years under house arrest in Austria. Only in 1715 was the family reunited. After attaining his majority in August 1715, he undertook an educational tour of Italy from 3 December 1715 until 24 August 1716. In 1717, with Bavarian auxiliaries, he joined the war of the Habsburgs against the Turks. 
On 5 October 1722, Charles married Maria Amalia, Archduchess of Austria, whom he had met while staying at the imperial court in Vienna. She was the younger daughter of the late Joseph I, Holy Roman Emperor and his consort Wilhelmine Amalia of Brunswick-Lüneburg. Her maternal grandfather was John Frederick, Duke of Brunswick-Lüneburg. In 1725 Charles Albert visited Versailles for the wedding of Louis XV and established firm contacts with the French court.
In 1726, when his father died, Charles Albert became Duke of Bavaria and a Prince-elector of the Holy Roman Empire. He succeeded in maintaining good relations both with his Habsburg relatives and with France, continuing his father's purposeful policies. In 1729 he instituted the knightly Order of St George. This year he also initiated to build the Rothenberg Fortress.
Holy Roman Emperor.
In continuance of the policy of his father, Charles Albert aspired to an even higher rank. As son-in-law of Joseph I, Holy Roman Emperor, Charles Albert rejected the Pragmatic Sanction of 1713 and claimed the German territories of the Habsburg dynasty after the death of emperor Charles VI in 1740. With the treaty of Nymphenburg concluded in July 1741, Charles Albert allied with France and Spain against Austria.
During the War of the Austrian Succession Charles Albert invaded Upper Austria in 1741 and planned to conquer Vienna, but his allied French troops under the Duc de Belle-Isle were redirected to Bohemia instead and Prague was conquered in November 1741. So Charles Albert was crowned King of Bohemia in Prague (19 December 1741) when the Habsburgs were not yet defeated. He was unanimously elected "King of the Romans" on 24 January 1742, also with the vote of George II, and took the title "Holy Roman Emperor" upon his coronation on 12 February 1742. His brother Klemens August of Bavaria, archbishop and elector ("Kurfürst") of Cologne, who generally sided with the Austria Habsburg-Lorraine faction in the disputes over the Habsburg succession, cast his vote for him and personally crowned him emperor at Frankfurt. Charles VII was the second Wittelsbach Emperor after Louis IV and the first Wittelsbach King of the Romans since the reign of Rupert of Germany.
Shortly after the coronation most of Charles Albert's territories were overrun by the Austrians, and Bavaria was occupied by the troops of Maria Theresa. The emperor fled Munich and resided for almost three years in the "Palais Barckhaus" in Frankfurt. Most of Bohemia was lost in December 1742 when the Austrians allowed the French under the Duc de Belle-Isle and the Duc de Broglie an honourable capitulation. Charles Albert was mocked as an emperor who neither controlled his own realm, nor was in effective control of the empire itself, though the institution of the Holy Roman Emperor had largely become symbolic in nature and powerless by that time. A popular Latin saying about him was "et Caesar et nihil", meaning "both Emperor and nothing", a word-play on "aut Caesar aut nihil", "either Emperor or nothing". Charles Albert's general Ignaz Felix, Count of Törring-Jettenbach was compared to a drum, as people "heard about him only when he was beaten". 
Charles VII tried to emphasise his government in Frankfurt with numerous acts of law, such as the grant of imperial privilege to the University of Erlangen in 1743 and the creation of several new imperial nobles. Charles Eugene, Duke of Württemberg was declared to be of full age ahead of time in 1744. Alexander Ferdinand, 3rd Prince of Thurn and Taxis served as Principal Commissioner for Charles VII at the Perpetual Imperial Diet in Frankfurt am Main and in 1744 the Thurn und Taxis dynasty were appointed hereditary Postmasters General of the Imperial Reichspost.
The new commander of the Bavarian army, Friedrich Heinrich von Seckendorff, fought Austria in a series of battles in 1743 and 1744. In 1743 his troops and their allies took Bavaria and Charles VII was able to return to Munich in April for some time. After the allied French had to retreat after defeats to the Rhine, he lost Bavaria again. The new alliance with Frederick II of Prussia during the Second Silesian War finally forced the Austrian army to leave Bavaria and to retreat back into Bohemia. In October 1744 Charles VII regained Munich. Suffering severely from gout, he returned, but died three months later. His brother Klemens August then again leaned toward Austria, and his son and successor Maximilian III Joseph made peace with Austria. With the Treaty of Füssen Austria recognized the legitimacy of Charles VII's election as Holy Roman Emperor.
Charles Albert is buried in the crypt of the Theatinerkirche in Munich.
Cultural legacy.
Charles Albert's reign was the height of the Bavarian rococo era. François de Cuvilliés was appointed chief architect of the court and constructed the Amalienburg in Munich. The Nymphenburg Palace was completed during Charles' reign: the grand circle ("Schlossrondell") of baroque mansions was intended as a starting point for a new city ("Carlstadt") but this was not achieved. For the Munich Residence, Charles Albert ordered the building of the Ancestral Gallery and the Ornate Rooms. He also ordered Cuvilliés to construct the Palais Holnstein for one of his mistresses, the Countess Holnstein. 
Among the most gifted Bavarian artists of his time were Johann Michael Fischer, Cosmas Damian Asam and Egid Quirin Asam, Johann Michael Feuchtmayer, Matthäus Günther, Johann Baptist Straub and Johann Baptist Zimmermann.
Children.
Charles and his wife Maria Amalia, Archduchess of Austria were parents of seven children:
Illegitimate children.
Charles Albert and his mistress Sophie Caroline von Ingelheim had a son:
Titles.
"Charles VII, by the grace of God elected Holy Roman Emperor, forever August, King in Germany and of Bohemia, Duke in the Upper and Lower Bavaria as well as the Upper Palatinate, Count-Palatine of the Rhine, Archduke of Austria, Prince-Elector of the Holy Roman Empire, Landgrave of Leuchtenberg, etc. etc."

</doc>
<doc id="51111" url="https://en.wikipedia.org/wiki?curid=51111" title="Pipeline transport">
Pipeline transport

Pipeline transport is the transportation of goods or material through a pipe. The best data, in 2014, gives a total of slightly less than 3.5 million km of pipeline in 120 countries of the world. The United States had 65%, Russia had 8%, and Canada had 3%, thus 75% of all pipeline was in three countries.
Pipeline and Gas Journal’s worldwide survey figures indicate that of pipelines are planned and under construction. Of these, represent projects in the planning and design phase; reflect pipelines in various stages of construction. Liquids and gases are transported in pipelines and any chemically stable substance can be sent through a pipeline. Pipelines exist for the transport of crude and refined petroleum, fuels - such as oil, natural gas and biofuels - and other fluids including sewage, slurry, water, and beer. Pipelines are useful for transporting water for drinking or irrigation over long distances when it needs to move over hills, or where canals or channels are poor choices due to considerations of evaporation, pollution, or environmental impact. Pneumatic tubes using compressed air can be used to transport solid capsules.
Oil pipelines are made from steel or plastic tubes which are usually buried. The oil is moved through the pipelines by pump stations along the pipeline. Natural gas (and similar gaseous fuels) are lightly pressurised into liquids known as Natural Gas Liquids (NGLs). Natural gas pipelines are constructed of carbon steel. Highly toxic ammonia is theoretically the most dangerous substance to be transported through long-distance pipelines, but accidents have been rare. Hydrogen pipeline transport is the transportation of hydrogen through a pipe. District heating or "teleheating" systems use a network of insulated pipes which transport heated water, pressurized hot water or sometimes steam to the customer.
Pipelines conveying flammable or explosive material, such as natural gas or oil, pose special safety concerns and there have been various accidents. Pipelines can be the target of vandalism, sabotage, or even terrorist attacks. In war, pipelines are often the target of military attacks.
Oil and natural gas.
It is uncertain when the first crude oil pipeline was built. Credit for the development of pipeline transport is disputed, with competing claims for Vladimir Shukhov and the Branobel company in the late 19th century, and the Oil Transport Association, which first constructed a wrought iron pipeline over a track from an oil field in Pennsylvania to a railroad station in Oil Creek, in the 1860s. Pipelines are generally the most economical way to transport large quantities of oil, refined oil products or natural gas over land.
Natural gas (and similar gaseous fuels) are lightly pressurized into liquids knows as Natural Gas Liquids (NGLs). Small NGL processing facilities can be located in oil fields so the butane and propane liquid under light pressure of , can be shipped by rail, truck or pipeline. Propane can be used as a fuel in oil fields to heat various facilities used by the oil drillers or equipment and trucks used in the oil patch. EG: Propane will convert from a gas to a liquid under light pressure, 100 psi, give or take depending on temperature, and is pumped into cars and trucks at less than at retail stations. Pipelines and rail cars use about double that pressure to pump at .
The distance to ship propane to markets is much shorter as thousands of NGL processing plants are located in oil fields or close by when a number of pipelines tie into each other from various relatively close fields. Many Bakken Basin oil companies in North Dakota, Montana, Manitoba and Saskatchewan gas fields separate the NGL's in the field, allowing the drillers to sell propane directly to small wholesalers, eliminating the large refinery control of product and prices for propane or butane.
The most recent major pipeline to start operating in North America, is a TransCanada natural gas line going north across the Niagara region bridges with Marcellus shale gas from Pennsylvania and others tied in methane or natural gas sources, into the Canadian province of Ontario as of the fall of 2012, supplying 16 percent of all the natural gas used in Ontario.
This new US supplied natural gas displaces the natural gas formerly shipped to Ontario from western Canada in Alberta and Manitoba, thus dropping the government regulated pipeline shipping charges because of the significantly shorter distance from gas source to consumer. Compared to shipping by railroad, pipelines have lower cost per unit and higher capacity. Pipelines are preferable to transportation by truck for a number of reasons. Employment on completed pipelines represents only "1% of that of the trucking industry."
To avoid delays and US government regulation, many small, medium and large oil producers in North Dakota have decided to run an oil pipeline north to Canada to meet up with a Canadian oil pipeline shipping oil from west to east. This allows the Bakken Basin and Three Forks oil producers to get higher negotiated prices for their oil because they will not be restricted to just one wholesale market in the US. The distance from the biggest oil patch in North Dakota, is Williston, North Dakota, only about 85 miles or 137 kilometers to the Canadian border and Manitoba. Mutual funds and joint ventures are big investors in new oil and gas pipelines. In the fall of 2012, the US began exporting propane to Europe, known as LPG, as wholesale prices there are much higher than in North America.
As more North American pipelines are built, even more exports of LNG, propane, butane, and other natural gas products will occur on all three US coasts. To give insight, North Dakota's oil production has grown to 5 times in late 2012 compared to what it was just 6 years ago creating thousands of good paying long term jobs. North Dakota oil companies are shipping huge amounts of oil by tanker rail car as they can direct the oil to the market that gives the best price but pipelines are cheaper. Rail cars can be used to avoid a congested oil pipeline to get the oil to a different pipeline in order to get the oil to market faster or to a different less busy oil refinery.
Enbridge in Canada is applying to reverse an oil pipeline going from east-to-west (Line 9) and expanding it and using it to ship western Canadian bitumen oil eastward. From a presently rated 250,000 barrels equivalent per day pipeline, it will be expanded to between one million to 1.3 million barrels per day. It will bring western oil to refineries in Ontario, Michigan, Ohio, Pennsylvania, Quebec and New York by early 2014. New Brunswick will also refine some of this western Canadian crude and export some crude and refined oil to Europe from its deep water oil ULCC loading port.
Although pipelines can be built under the sea, that process is economically and technically demanding, so the majority of oil at sea is transported by tanker ships.
The Enbridge Sandpiper pipeline is proposed to transfer fracked oil from Western North Dakota through northwestern Minnesota, where one-fifth of the world's fresh surface water lies. The pipeline will be 24-30 inches in diameter. It will carry over 300,000 barrels of oil a day with a volatility of 32.
Growth of market.
The market size for oil and gas pipeline construction experienced tremendous
growth prior to the economic downturn in 2008. The industry grew from $23 billion in 2006 to $39 billion in 2008. After faltering in 2009, demand for pipeline expansion and updating increased the following year as energy production grew. By 2012, almost 32,000 miles of North American pipeline were being planned or under construction.
Construction and operation.
Oil pipelines are made from steel or plastic tubes with inner diameter typically from . Most pipelines are typically buried at a depth of about . To protect pipes from impact, abrasion, and corrosion, a variety of methods are used. These can include wood lagging (wood slats), concrete coating, rockshield, high-density polyethylene, imported sand padding, and padding machines.
Crude oil contains varying amounts of paraffin wax and in colder climates wax buildup may occur within a pipeline. Often these pipelines are inspected and cleaned using pigging, the practice of using devices known as "pigs" to perform various maintenance operations on a pipeline. The devices are also known as "scrapers" or "Go-devils". "Smart pigs" (also known as "intelligent" or "intelligence" pigs) are used to detect anomalies in the pipe such as dents, metal loss caused by corrosion, cracking or other mechanical damage. These devices are launched from pig-launcher stations and travel through the pipeline to be received at any other station down-stream, either cleaning wax deposits and material that may have accumulated inside the line or inspecting and recording the condition of the line.
For natural gas, pipelines are constructed of carbon steel and vary in size from in diameter, depending on the type of pipeline. The gas is pressurized by compressor stations and is odorless unless mixed with a mercaptan odorant where required by a regulating authority.
Ammonia.
Highly toxic ammonia is theoretically the most dangerous substance to be transported through long-distance pipelines. However, incidents on ammonia-transporting lines are uncommon - unlike on industrial ammonia-processing equipment. A major ammonia pipeline is the Ukrainian "Transammiak" line connecting the TogliattiAzot facility in Russia to the exporting Black Sea-port of Odessa.
Alcohol fuels.
Pipelines have been used for transportation of ethanol in Brazil, and there are several ethanol pipeline projects in Brazil and the United States. The main problems related to the transport of ethanol by pipeline are its corrosive nature and tendency to absorb water and impurities in pipelines, which are not problems with oil and natural gas. Insufficient volumes and cost-effectiveness are other considerations limiting construction of ethanol pipelines.
Coal and ore.
Slurry pipelines are sometimes used to transport coal or ore from mines. The material to be transported is closely mixed with water before being introduced to the pipeline; at the far end, the material must be dried.
One example is a slurry pipeline which is planned to transport iron ore from the Minas-Rio mine (producing 26.5 million tonnes per year) to the Port of Açu in Brazil. An existing example is the Savage River Slurry pipeline in Tasmania, Australia, possibly the world's first when it was built in 1967. It includes a bridge span at above the Savage River.
Hydrogen.
Hydrogen pipeline transport is a transportation of hydrogen through a pipe as part of the hydrogen infrastructure. Hydrogen pipeline transport is used to connect the point of hydrogen production or delivery of hydrogen with the point of demand, with transport costs similar to CNG, the technology is proven. Most hydrogen is produced at the place of demand with every 50 to an industrial production facility. The 1938 Rhine-Ruhr hydrogen pipeline is still in operation. , there are of low pressure hydrogen pipelines in the US and in Europe.
Water.
Two millennia ago, the ancient Romans made use of large aqueducts to transport water from higher elevations by building the aqueducts in graduated segments that allowed gravity to push the water along until it reached its destination. Hundreds of these were built throughout Europe and elsewhere, and along with flour mills were considered the lifeline of the Roman Empire. The ancient Chinese also made use of channels and pipe systems for public works. The famous Han Dynasty court eunuch Zhang Rang (d. 189 AD) once ordered the engineer Bi Lan to construct a series of square-pallet chain pumps outside the capital city of Luoyang. These chain pumps serviced the imperial palaces and living quarters of the capital city as the water lifted by the chain pumps was brought in by a stoneware pipe system.
Pipelines are useful for transporting water for drinking or irrigation over long distances when it needs to move over hills, or where canals or channels are poor choices due to considerations of evaporation, pollution, or environmental impact.
The Goldfields Water Supply Scheme in Western Australia using 750 mm (30 inch) pipe and completed in 1903 was the largest water supply scheme of its time.
Examples of significant water pipelines in South Australia are the Morgan-Whyalla pipelne (completed 1944) and Mannum-Adelaide (completed 1955) pipelines, both part of the larger Snowy Mountains scheme.
There are two Los Angeles, California aqueducts, the "Owens Valley aqueduct" (completed 1913) and the "Second Los Angeles Aqueduct" (completed 1970) which also include extensive use of pipelines.
The Great Manmade River of Libya supplies of water each day to Tripoli, Benghazi, Sirte, and several other cities in Libya. The pipeline is over long, and is connected to wells tapping an aquifer over underground.
Other systems.
District heating.
[Dü StPö mit Kraftwerk Dürnrohr.jpg|thumb|200px|District heating pipeline in Austria with a length of 31 km 
District heating or "teleheating" systems consist of a network of insulated feed and return pipes which transport heated water, pressurized hot water or sometimes steam to the customer. While steam is hottest and may be used in industrial processes due to its higher temperature, it is less efficient to produce and transport due to greater heat losses. Heat transfer oils are generally not used for economic and ecological reasons. The typical annual loss of thermal energy through distribution is around 10%, as seen in Norway's district heating network.
District heating pipelines are normally installed underground, with some exceptions. Within the system, heat storage may be installed to even out peak load demands. Heat is transferred into the central heating of the dwellings through heat exchangers at heat substations, without mixing of the fluids in either system.
Beer.
Bars in the Veltins-Arena, a major football ground in Gelsenkirchen, Germany, are interconnected by a long beer pipeline. In Randers city in Denmark, the so-called Thor Beer pipeline was operated. Originally, copper pipes ran directly from the brewery, but when the brewery moved out of the city in the 1990s, Thor Beer replaced it with a giant tank.
A beer pipeline has been proposed for construction in Bruges, Belgium to reduce truck traffic on the city streets.
Brine.
The village of Hallstatt in Austria, which is known for its long history of salt mining, claims to contain "the oldest industrial pipeline in the world", dating back to 1595. It was constructed from 13,000 hollowed-out tree trunks to transport brine from Hallstatt to Ebensee.
Milk.
Between 1978 and 1994, a 15 km milk pipeline ran between the Dutch island of Ameland and Holwerd on the mainland, of which 8 km beneath the Wadden Sea. Every day, 30.000 litres of milk produced on the island were transported to be processed on the mainland. In 1994, the milk transport was abandoned.
Marine pipelines.
In places, a pipeline may have to cross water expanses, such as small seas, straits and rivers. In many instances, they lie entirely on the seabed. These pipelines are referred to as "marine" pipelines (also, "submarine" or "offshore" pipelines). They are used primarily to carry oil or gas, but transportation of water is also important. In offshore projects, a distinction is made between a "flowline" and a pipeline. The former is an "intrafield" pipeline, in the sense that it is used to connect subsea wellheads, manifolds and the platform "within" a particular development field. The latter, sometimes referred to as an "export pipeline", is used to bring the resource to shore. The construction and maintenance of marine pipelines imply logistical challenges that are different from those onland, mainly because of wave and current dynamics, along with other geohazards.
Functions.
In general, pipelines can be classified in three categories depending on purpose:
Development and planning.
When a pipeline is built, the construction project not only covers the civil engineering work to lay the pipeline and build the pump/compressor stations, it also has to cover all the work related to the installation of the field devices that will support remote operation.
The pipeline is routed along what is known as a "right of way". Pipelines are generally developed and built using the following stages:
Russia has "Pipeline Troops" as part of the Rear Services, who are trained to build and repair pipelines. Russia is the only country to have Pipeline Troops.
Operation.
Field devices are instrumentation, data gathering units and communication systems. The field Instrumentation includes flow, pressure and temperature gauges/transmitters, and other devices to measure the relevant data required. These instruments are installed along the pipeline on some specific locations, such as injection or delivery stations, pump stations (liquid pipelines) or compressor stations (gas pipelines), and block valve stations.
The information measured by these field instruments is then gathered in local Remote Terminal Units (RTU) that transfer the field data to a central location in real time using communication systems, such as satellite channels, microwave links, or cellular phone connections.
Pipelines are controlled and operated remotely, from what is usually known as the "Main Control Room". In this center, all the data related to field measurement is consolidated in one central database. The data is received from multiple RTUs along the pipeline. It is common to find RTUs installed at every station along the pipeline. 
The SCADA system at the Main Control Room receives all the field data and presents it to the pipeline operator through a set of screens or Human Machine Interface, showing the operational conditions of the pipeline. The operator can monitor the hydraulic conditions of the line, as well as send operational commands (open/close valves, turn on/off compressors or pumps, change setpoints, etc.) through the SCADA system to the field.
To optimize and secure the operation of these assets, some pipeline companies are using what is called "Advanced Pipeline Applications", which are software tools installed on top of the SCADA system, that provide extended functionality to perform leak detection, leak location, batch tracking (liquid lines), pig tracking, composition tracking, predictive modeling, look ahead modeling, operator training and
Technology.
Components.
Pipeline networks are composed of several pieces of equipment that operate together to move products from location to location. The main elements of a pipeline system are:
Leak detection systems.
Since oil and gas pipelines are an important asset of the economic development of almost any country, it has been required either by government regulations or internal policies to ensure the safety of the assets, and the population and environment where these pipelines run.
Pipeline companies face government regulation, environmental constraints and social situations. Government regulations may define minimum staff to run the operation, operator training requirements, pipeline facilities, technology and applications required to ensure operational safety. For example, in the State of Washington it is mandatory for pipeline operators to be able to detect and locate leaks of 8 percent of maximum flow within fifteen minutes or less. Social factors also affect the operation of pipelines. In third world countries, product theft is a problem for pipeline companies. It is common to find unauthorized extractions in the middle of the pipeline. In this case, the detection levels should be under two percent of maximum flow, with a high expectation for location accuracy.
Various technologies and strategies have been implemented for monitoring pipelines, from physically walking the lines to satellite surveillance. The most common technology to protect pipelines from occasional leaks is Computational Pipeline Monitoring or CPM. CPM takes information from the field related to pressures, flows, and temperatures to estimate the hydraulic behavior of the product being transported. Once the estimation is completed, the results are compared to other field references to detect the presence of an anomaly or unexpected situation, which may be related to a leak.
The American Petroleum Institute has published several articles related to the performance of CPM in liquids pipelines. The API Publications are:
Where a pipeline containing passes under a road or railway, it is usually enclosed in a protective casing. This casing is vented to the atmosphere to prevent the build-up of flammable gases or corrosive substances, and to allow the air inside the casing to be sampled to detect leaks. The "casing vent", a pipe protruding from the ground, often doubles as a warning marker called a "casing vent marker".
Implementation.
As a rule pipelines for all uses are laid in most cases underground. However, in some cases it is necessary to cross a valley or a river on a pipeline bridge. Pipelines for centralized heating systems are often laid on the ground or overhead. Pipelines for petroleum running through permafrost areas as Trans-Alaska-Pipeline are often run overhead in order to avoid melting the frozen ground by hot petroleum which would result in sinking the pipeline in the ground.
Maintenance.
Maintenance of pipelines includes checking cathodic protection levels for the proper range, surveillance for construction, erosion, or leaks by foot, land vehicle, boat, or air, and running cleaning pigs, when there is anything carried in the pipeline that is corrosive.
US pipeline maintenance rules are covered in Code of Federal Regulations(CFR) sections, 49 CFR 192 for natural gas pipelines, and 49 CFR 195 for petroleum liquid pipelines.
Regulation.
In the US, onshore and offshore pipelines used to transport oil and gas are regulated by the Pipeline and Hazardous Materials Safety Administration (PHMSA). Certain offshore pipelines used to produce oil and gas are regulated by the Minerals Management Service (MMS). In Canada, pipelines are regulated by either the provincial regulators or, if they cross provincial boundaries or the Canada/US border, by the National Energy Board (NEB).
Government regulations in Canada and the United States require that buried fuel pipelines must be protected from corrosion. Often, the most economical method of corrosion control is by use of pipeline coating in conjunction with cathodic protection and technology to monitor the pipeline. Above ground, cathodic protection is not an option. The coating is the only external protection.
Pipelines and geopolitics.
Pipelines for major energy resources (petroleum and natural gas) are not merely an element of trade. They connect to issues of geopolitics and international security as well, and the construction, placement, and control of oil and gas pipelines often figure prominently in state interests and actions. A notable example of pipeline politics occurred at the beginning of the year 2009, wherein a dispute between Russia and Ukraine ostensibly over pricing led to a major political crisis. Russian state-owned gas company Gazprom cut off natural gas supplies to Ukraine after talks between it and the Ukrainian government fell through. In addition to cutting off supplies to Ukraine, Russian gas flowing through Ukraine—which included nearly all supplies to Southeastern Europe and some supplies to Central and Western Europe—was cut off, creating a major crisis in several countries heavily dependent on Russian gas as fuel. Russia was accused of using the dispute as leverage in its attempt to keep other powers, and particularly the European Union, from interfering in its "near abroad".
Oil and gas pipelines also figure prominently in the politics of Central Asia and the Caucasus.
Hazard identification.
Because the solvent fraction of dilbit typically comprises volatile aromatics like naptha and benzene, reasonably rapid carrier vaporization can be expected to follow an above-ground spill—ostensibly enabling timely intervention by leaving only a viscous residue that is slow to migrate. Effective protocols to minimize exposure to petrochemical vapours are well-established, and oil spilled from the pipeline would be unlikely to reach the aquifer unless incomplete remediation were followed by the introduction of another carrier (e.g. a series of torrential downpours).
The Keystone XL extension is designed to be buried under four feet of soil, which will hinder post-spill vaporization of the carrier fraction. Diluent and bitumen will migrate at different rates, depending on the temperature- and composition of the surrounding soils, but separation will take place more slowly as the aromatics diffuse through sediment rather than through air.
The introduction of benzene and other volatile organic compounds (collectively BTEX) to the subterranean environment compounds the threat posed by a pipeline leak. Particularly if followed by rain, a pipeline breach would result in BTEX dissolution and equilibration of benzene in water, followed by percolation of the admixture into the aquifer. Benzene can cause many health problems and is carcinogenic with EPA Maximum Contaminant Level (MCL) set at 5 μg/L for potable water. Although it is not well studied, single benzene exposure events have been linked to acute carcinogenesis. Additionally, the exposure of livestock, mainly cattle, to benzene has been shown to cause many health issues, such as neurotoxicity, fetal damage and fatal poisoning.
The entire surface of an above-ground pipeline can be directly examined for material breach. Pooled petroleum is unambiguous, readily spotted, and indicates the location of required repairs. Because the effectiveness of remote inspection is limited by the cost of monitoring equipment, gaps between sensors, and data that requires interpretation, leaks in buried pipe are more likely to go undetected
Pipeline developers do not always prioritize effective surveillance against leaks. Buried pipes draw fewer complaints. They are insulated from extremes in ambient temperature, they are shielded from ultraviolet rays, and they are less exposed to photodegradation. Buried pipes are isolated from airborne debris, electrical storms, tornadoes, hurricanes, hail, and acid rain. They are protected from nesting birds, rutting mammals, and wayward buckshot. Buried pipe is less vulnerable to accident damage (e.g. automobile collisions) and less accessible to vandals, saboteurs, and terrorists.
Exposure.
Previous work has shown that a 'worst-case exposure scenario' can be limited to a specific set of conditions. Based on the advanced detection methods and pipeline shut-off SOP developed by TransCanada, the risk of a substantive or large release over a short period of time contaminating groundwater with benzene is unlikely. Detection, shutoff, and remediation procedures would limit the dissolution and transport of benzene. Therefore, the exposure of benzene would be limited to leaks that are below the limit of detection and go unnoticed for extended periods of time. Leak detection is monitored through a SCADA system that assesses pressure and volume flow every 5 seconds. A pinhole leak that releases small quantities that cannot be detected by the SCADA system (<1.5% flow) could accumulate into a substantive spill. Detection of pinhole leaks would come from a visual or olfactory inspection, aerial surveying, or mass-balance inconsistencies. It is assumed that pinhole leaks are discovered within the 14 day inspection interval, however snow cover and location (e.g. remote, deep) could delay detection. Benzene typically makes up 0.1 – 1.0% of oil and will have varying degrees of volatility and dissolution based on environmental factors.
Even with pipeline leak volumes within SCADA detection limits, sometimes pipeline leaks are misinterpreted by pipeline operators to be pump malfunctions, or other problems. The Enbridge Line 6B crude oil pipeline failure in Marshall, Michigan on July 25, 2010 was thought by operators in Edmonton to be from column separation of the dilbit in that pipeline. The leak in wetlands along the Kalamazoo River was only confirmed 17 hours after it happened by a local gas company employee in Michigan.
Spill frequency-volume.
Although the Pipeline and Hazardous Materials Safety Administration (PHMSA) has standard baseline incident frequencies to estimate the number of spills, TransCanada altered these assumptions based on improved pipeline design, operation, and safety. Whether these adjustments are justified is debatable as these assumptions resulted in a nearly 10-fold decrease in spill estimates. Given that the pipeline crosses 247 miles of the Ogallala Aquifer, or 14.5% of the entire pipeline length, and the 50-year life of the entire pipeline is expected to have between 11 – 91 spills, approximately 1.6 – 13.2 spills can be expected to occur over the aquifer. An estimate of 13.2 spills over the aquifer, each lasting 14 days, results in 184 days of potential exposure over the 50 year lifetime of the pipeline.
In the reduced scope ‘worst case exposure scenario,’ the volume of a pinhole leak at 1.5% of max flow-rate for 14 days has been estimated at 189,000 barrels or 7.9 million gallons of oil. According to PHMSA’s incident database, only 0.5% of all spills in the last 10 years were >10,000 barrels.
Benzene fate and transport.
Benzene is considered a light aromatic hydrocarbon with high solubility and high volatility. It is unclear how temperature and depth would impact the volatility of benzene, so assumptions have been made that benzene in oil (1% weight by volume) would not volatilize before equilibrating with water.
Using the octanol-water partition coefficient and a 100-year precipitation event for the area, a worst-case estimate of 75 mg/L of benzene is anticipated to flow toward the aquifer. The actual movement of the plume through groundwater systems is not well described, although one estimate is that up to 4.9 billion gallons of water in the Ogallala Aquifer could become contaminated with benzene at concentrations above the MCL. The Final Environmental Impact Statement from the State Department does not include a quantitative analysis because it assumed that most benzene will volatilize.
Previous dilbit spill remediation difficulties.
One of the major concerns about dilbit is the difficulty in cleaning it up. Enbridge's Line 6B, a 30-inch crude oil pipeline, ruptured in Marshall, Michigan on July 25, 2010, mentioned above, spilled at least 843,000 gallons of dilbit. After detection of the leak, booms and vacuum trucks were deployed. Heavy rains caused the river to overtop existing dams, and carried dilbit 30 miles downstream before the spill was contained. Remediation work collected over 1.1 million gallons of oil and almost 200,000 cubic yards of oil-contaminated sediment and debris from the Kalamazoo River system. However, oil was still being found in affected waters in October 2012.
Dangers.
Accidents.
Pipelines conveying flammable or explosive material, such as natural gas or oil, pose special safety concerns.
As targets.
Pipelines can be the target of vandalism, sabotage, or even terrorist attacks. In war, pipelines are often the target of military attacks, as destruction of pipelines can seriously disrupt enemy logistics.

</doc>
<doc id="51112" url="https://en.wikipedia.org/wiki?curid=51112" title="William Cecil, 1st Baron Burghley">
William Cecil, 1st Baron Burghley

William Cecil, 1st Baron Burghley (sometimes spelt Burleigh) (13 September 1520 – 4 August 1598) was an English statesman, the chief advisor of Queen Elizabeth I for most of her reign, twice Secretary of State (1550–1553 and 1558–1572) and Lord High Treasurer from 1572. Albert Pollard says, "From 1558 for forty years the biography of Cecil is almost indistinguishable from that of Elizabeth and from the history of England."
Burghley set as the main goal of English policy the creation of a united and Protestant British Isles. His methods were to complete the control of Ireland, and to forge an alliance with Scotland. Protection from invasion required a powerful Royal Navy. While he was not fully successful, his successors agreed with his goals. Derek Wilson (2013) says, "Few politicians were more subtle or unscrupulous than William Cecil." He was the founder of the Cecil dynasty which has produced many politicians including two Prime Ministers.
Early life.
Cecil was born in Bourne, Lincolnshire, in 1520, the son of Richard Cecil, owner of the Burghley estate (near Stamford, Lincolnshire), and his wife, Jane Heckington. 
Pedigrees, elaborated by Cecil himself with the help of William Camden the antiquary, associated him with the Welsh Cecils or Sitsylts of Allt-Yr-Ynys, Walterstone, on the border of Herefordshire and Monmouthshire, and traced his descent from an Owen of the time of King Harold and a Sitsyllt of the reign of William Rufus. Sitsylt is the original Welsh spelling of the anglicised Cecil. There is now no doubt that the family was from the Welsh Marches and Lord Burghley himself acknowledged this in his family pedigree painted at Theobalds. The family had connections with Dore Abbey. However, the move to Stamford provides information concerning the Lord Treasurer's grandfather, David; he, according to Burghley's enemies, kept the best inn in Stamford. David somehow secured the favour of the first Tudor king, Henry VII, to whom he seems to have been Yeoman of the Guard. He was Sergeant-of-Arms to Henry VIII in 1526, Sheriff of Northamptonshire in 1532, and a Justice of the Peace for Rutland. His eldest son, Richard, Yeoman of the Wardrobe (died 1554), married Jane, daughter of William Heckington of Bourne, and was father of three daughters and the future Lord Burghley.
William, the only son, was put to school first at The King's School, Grantham, and then Stamford School, which he later saved and endowed. In May 1535, at the age of fourteen, he went to St John's College, Cambridge, where he was brought into contact with the foremost scholars of the time, Roger Ascham and John Cheke, and acquired an unusual knowledge of Greek. He also acquired the affections of Cheke's sister, Mary, and was in 1541 removed by his father to Gray's Inn, without having taken a degree, as was common at the time for those not intending to enter the Church. The precaution proved useless and four months later Cecil committed one of the rare rash acts of his life in marrying Mary Cheke. The only child of this marriage, Thomas, the future Earl of Exeter, was born in May 1542, and in February 1543 Cecil's first wife died. Three years later, on 21 December 1546 he married Mildred Cooke, who was ranked by Ascham with Lady Jane Grey as one of the two most learned ladies in the kingdom, (aside from another of Ascham's pupils, Elizabeth Tudor, who was later Elizabeth I) and whose sister, Anne, was the wife of Sir Nicholas (and later the mother of Sir Francis) Bacon.
Early career.
William Cecil's early career was spent in the service of the Duke of Somerset (a brother of the late queen, Jane Seymour), who was Lord Protector during the early years of the reign of his nephew, the young Edward VI. Cecil accompanied Somerset on his Pinkie campaign of 1547 (part of the "Rough Wooing"), being one of the two Judges of the Marshalsea. The other was William Patten, who states that both he and Cecil began to write independent accounts of the campaign, and that Cecil generously contributed his notes for Patten's narrative of the "Expedition into Scotland".
Cecil, according to his autobiographical notes, sat in Parliament in 1543; but his name does not occur in the imperfect parliamentary returns until 1547, when he was elected for the family borough of Stamford.
In 1548, he is described as the Protector's Master of Requests, which apparently means that he was clerk or registrar of the court of requests which the Protector, possibly at Hugh Latimer's instigation, illegally set up in Somerset House to hear poor men's complaints. He also seems to have acted as private secretary to the Protector, and was in some danger at the time of the Protector's fall in October 1549. The lords opposed to Somerset ordered his detention on 10 October, and in November he was in the Tower of London.
Cecil ingratiated himself with Warwick, and after less than three months he was out of the Tower. On 5 September 1550 Cecil was sworn in as one of King Edward's two Secretaries of State. In April 1551, Cecil became Chancellor of the Order of the Garter. But service under Warwick (by now the Duke of Northumberland) carried some risk, and decades later in his diary, Cecil recorded his release in the phrase ""ex misero aulico factus liber et mei juris"" ("I was freed from this miserable court").
To protect the Protestant government from the accession of a Catholic queen, Northumberland forced King Edward's lawyers to create an instrument setting aside the Third Succession Act on 15 June 1553. (The document, which Edward titled "My Devise for the Succession", barred both Elizabeth and Mary, the remaining children of Henry VIII, from the throne, in favour of Lady Jane Grey.) Cecil resisted for a while, in a letter to his wife, he wrote: "Seeing great perils threatened upon us by the likeness of the time, I do make choice to avoid the perils of God's displeasure." But at Edward's royal command he signed it. He signed not only the "devise", but also the bond among the conspirators and the letters from the council to Mary Tudor of 9 June 1553.
Years afterwards, he pretended that he had only signed the devise as a witness, but in his apology to Queen Mary I, he did not venture to allege so flimsy an excuse; he preferred to lay stress on the extent to which he succeeded in shifting the responsibility on to the shoulders of his brother-in-law, Sir John Cheke, and other friends, and on his intrigues to frustrate the Queen to whom he had sworn allegiance.
There is no doubt that Cecil saw which way the wind was blowing, and disliked Northumberland's scheme; but he had not the courage to resist the duke to his face. As soon, however, as the duke had set out to meet Mary, Cecil became the most active intriguer against him, and to these efforts, of which he laid a full account before Queen Mary, he mainly owed his immunity. He had, moreover, had no part in the divorce of Catherine of Aragon or in the humiliation of Mary during Henry's reign, and he made no scruple about conforming to the Catholic reaction. He went to Mass, confessed, and in no particular official capacity went to meet Cardinal Pole on his return to England in December 1554, again accompanying him to Calais in May 1555.
He was elected to Parliament as knight of the shire for Lincolnshire in 1553 (probably), 1555 and 1559 and for Northamptonshire in 1563.
It was rumoured in December 1554 that Cecil would succeed Sir William Petre as Secretary of State, an office which, with his chancellorship of the Garter, he had lost on Mary's accession to the throne. Probably the Queen had more to do with this rumour than Cecil, though he is said to have opposed, in the parliament of 1555 (in which he represented Lincolnshire), a bill for the confiscation of the estates of the Protestant refugees. But the story, even as told by his biographer, does not represent Cecil's conduct as having been very courageous; and it is more revealing that he found no seat in the parliament of 1558, for which Mary had directed the return of "discreet and good Catholic members".
Reign of Elizabeth.
The Duke of Northumberland had employed Cecil in the administration of the lands of Princess Elizabeth. Before Mary died he was a member of the "old flock of Hatfield", and from the first, the new Queen relied on Cecil. She appointed him Secretary of State. His tight control over the finances of the Crown, leadership of the Privy Council, and the creation of a highly capable intelligence service under the direction of Francis Walsingham made him the most important minister for the majority of Elizabeth's reign.
Foreign policy.
Dawson argues that Cecil's long-term goal was a united and Protestant British Isles, an objective to be achieved by completing the conquest of Ireland and by creating an Anglo-Scottish alliance. With the land border with Scotland safe, the main burden of defence would fall upon the Royal Navy, Cecil proposed to strengthen and revitalise the Navy, making it the centerpiece of English power. He did obtain a firm Anglo-Scottish alliance reflecting the common religion and shared interests of the two countries, as well as an agreement that offered the prospect of a successful conquest of Ireland. However, his strategy ultimately failed. His idea that England's safety required a united British Isles became an axiom of English policy by the 17th century.
Though a Protestant, Cecil was not a religious purist; he aided the Protestant Huguenots and Dutch just enough to keep them going in the struggles which warded danger from England's shores. But Cecil never developed that passionate aversion from decided measures which became a second nature to Elizabeth. His intervention in Scotland in 1559–60 showed that he could strike hard when necessary; and his action over the execution of Mary, Queen of Scots, proved that he was willing to take on responsibilities from which the Queen shrank. 
Generally he was in favour of more decided intervention on behalf of continental Protestants than Elizabeth would have liked, but it is not always easy to ascertain the advice he gave. He left endless memoranda lucidly (nevertheless sometimes bordering on the ridiculous) setting forth the pros and cons of every course of action; but there are few indications of the line which he actually recommended when it came to a decision. How far he was personally responsible for the Anglican Settlement, the Poor Laws, and the foreign policy of the reign, remains to a large extent a matter of conjecture. However, it is most likely that Cecil's views carried the day in the politics of Elizabethan England. The historian Hilaire Belloc contends that Cecil was the "de facto" ruler of England during his tenure as Secretary; pointing out that in instances where his and Elizabeth's wills diverged, it was Cecil's will that was imposed.
Leimon and Parker argue that Burghley was the principal protector of Edward Stafford, the English ambassador to Paris and a paid spy who helped the Spanish at the time of the Spanish Armada. However, they do not claim Burghley knew of Stafford's treason.
Domestic politics.
Cecil's share in the Religious Settlement of 1559 was considerable, and it coincided fairly with his own Anglican religious views. Like the mass of the nation, he grew more Protestant as time wore on; he was happier to persecute Catholics than Puritans; and he had no love for ecclesiastical jurisdiction. His prosecution of the English Catholics made him a recurring character in the "evil counsellor polemics", written by Catholic exiles across the channel. In these pamphlets, polemicists painted a black picture of Burghley as a corrupting influence over the queen. "The Queen will listen to none but unto him", exiled Catholic intelligencer Richard Verstegan wrote, "and somtymes, she is faine to come to his bedsyde to entreat him in some-things." He warmly remonstrated with John Whitgift, the Anglican Archbishop of Canterbury, over his persecuting Articles of 1583. The finest encomium was passed on him by the queen herself, when she said, "This judgment I have of you, that you will not be corrupted with any manner of gifts, and that you will be faithful to the state."
In Parliament.
He represented Lincolnshire in the Parliament of 1555 and 1559, and Northamptonshire in that of 1563, and he took an active part in the proceedings of the House of Commons until his elevation to the peerage; but there seems no good evidence for the story that he was proposed as Speaker in 1563. In January 1561, he was given the lucrative office of Master of the Court of Wards and Liveries in succession to Sir Thomas Parry. As Master of the Court of Wards, Burghley supervised the raising and education of wealthy, aristocratic boys whose fathers had died before they reached maturity. These included Edward de Vere, 17th Earl of Oxford, Henry Wriothesley, 3rd Earl of Southampton, and Roger Manners, 5th Earl of Rutland. He is widely credited with reforming an institution notorious for its corruption, but the extent of his reforms has been disputed by some scholars.
In February 1559, he was elected Chancellor of Cambridge University in succession to Cardinal Pole; he was created M.A. of that university on the occasion of Elizabeth's visit in 1564, and M.A. of Oxford on a similar occasion in 1566. He was the first Chancellor of Trinity College, Dublin, between 1592 and 1598.
On 25 February 1571, Queen Elizabeth elevated him as Baron Burghley. The fact that Burghley continued to act as Secretary of State after his elevation illustrates the growing importance of that office, which under his son became a secretary of the ship of state. In 1572 Burghley privately admonished the queen for her "doubtful dealing with the Queen of Scots." He made a strong attack on everything he thought Elizabeth had done wrong as queen. In his view, Mary had to be executed because her life was a rallying cause for the Catholics and played into the hands of the Spanish and of the pope, who excommunicated Elizabeth in 1570 and sent in Jesuits to organise a Catholic underground. By 1585–6 these missionaries had set up a secret, but highly effective, underground system for the transport and support of priests arriving from the Continent. Elizabeth's indecision was maddening; finally in 1587 Elizabeth had Mary executed.
Treasurer.
In 1572, Lord Winchester, who had been Lord High Treasurer under Edward, Mary and Elizabeth, died. His vacant post was offered to Robert Dudley, 1st Earl of Leicester, who declined it and proposed Burghley, stating that the latter was the more suitable candidate because of his greater "learning and knowledge". The new Lord Treasurer's hold over the queen strengthened with the years.
Burghley and Theobalds.
Burghley House near the town of Stamford was built for Cecil between 1555 and 1587 and modelled on the privy lodgings of Richmond Palace. It was subsequently the residence of his descendants, the Earls and Marquesses of Exeter. The house is one of the principal examples of 16th-century Elizabethan architecture.
A new Theobalds House just off the main road north from London to Ware, was built between 1564 and 1585 to the order of Burghley. The Queen visited eight times between 1572 and 1596.
Death.
Descendants.
His elder son, Sir Thomas Cecil, who inherited the Barony of Burghley on his death, was later created Earl of Exeter. His younger son, Sir Robert Cecil (later created Baron Cecil, Viscount Cranborne and finally Earl of Salisbury), inherited his political mantle, taking on the role of chief minister and arranging a smooth transfer of power to the Stuart administration under King James I. His daughter Anne became the first wife of Edward de Vere, 17th Earl of Oxford, in 1571; she served as a Maid of Honour to Queen Elizabeth before her marriage.
Burghley's descendants include the Marquesses of Exeter, descended from his elder son Thomas; and the Marquesses of Salisbury, descended from his younger son Robert. One of the latter branch, Robert Cecil, 3rd Marquess of Salisbury (1830–1903), served three times as Prime Minister under Queen Victoria and Edward VII.
Private life.
In contrast to his public unscrupulousness, Burghley's private life was upright; he was a faithful husband, a careful father and a dutiful master. A book-lover and antiquarian, he made a special hobby of heraldry and genealogy. It was the conscious and unconscious aim of the age to reconstruct a new landed aristocracy on the ruins of the old, Catholic order. As such, Burghley was a great builder, planter and patron. All the arts of architecture and horticulture were lavished on Burghley House and Theobalds, which his son exchanged for Hatfield.
Public conduct.
His public conduct does not present itself in quite so amiable a light. As the marquess of Winchester said of himself, he was sprung from the willow rather than the oak, and he was not the man to suffer for convictions. The interest of the state was the supreme consideration, and to it he had no hesitation in sacrificing individual consciences. He frankly disbelieved in toleration; "that state," he said, "could never be in safety where there was a toleration of two religions. For there is no enmity so great as that for religion; and therefore they that differ in the service of their God can never agree in the service of their country." With a maxim such as this, it was easy for him to maintain that Elizabeth's coercive measures were political and not religious. To say that he was Machiavellian is meaningless, for every statesman is so more or less; especially in the 16th century men preferred efficiency to principle. On the other hand, principles are valueless without law and order; and Burghley's craft and subtlety prepared a security in which principles might find some scope.
Nicholas White.
The most prolonged of Cecil's surviving personal correspondences is with an Irish judge, Nicholas White, lasting from 1566 until 1590; it is contained in the "State Papers Ireland 63" and "Lansdowne MS. 102", but receives hardly a mention in the literature on Cecil.
White had been a tutor to Cecil's children during his student days in London, and the correspondence suggests that he was held in lasting affection by the family. In the end, White fell into a Dublin controversy over the confessions of an intriguing priest, which threatened the authority of the Queen's deputised government in Ireland; out of caution Cecil withdrew his longstanding protection and the judge was imprisoned in London and died soon after.
White's most remarked-upon service for Cecil is his report on his visit with Mary, Queen of Scots, in 1569, during the early years of her imprisonment. He may have published an English translation of the "Argonautica" in the 1560s but no copy has survived.
In popular culture.
Cecil has been a character in many works of fiction and documentary essay concerned with Elizabeth I's reign. Richard Attenborough depicted him in the film "Elizabeth". He was played by Ben Webster in the 1935 film "Drake of England". He was a prominent supporting character in the 1937 film "Fire Over England", starring Laurence Olivier, Vivien Leigh, and Flora Robson; Burghley (spelled Burleigh in the film) was played by Morton Selten. He also appears in the television mini-series Elizabeth I with Helen Mirren, played by Ian McDiarmid; was portrayed by Ronald Hines in the 1971 TV series "Elizabeth R"; and by Ian Hart in the 2005 miniseries "The Virgin Queen". He is portrayed by David Thewlis in Roland Emmerich's "Anonymous".
Cecil appears as a character in the novels "I, Elizabeth" by Rosalind Miles, "The Virgin's Lover" and "The Other Queen" by Philippa Gregory, and is a prominent secondary character in several books by Bertrice Small. He also appears prominently in the alternative history "Ruled Britannia", by Harry Turtledove, in which he and his son Sir Robert Cecil are conspirators and patrons of William Shakespeare in an attempt to restore Elizabeth to power after a successful Spanish invasion and conquest of England. In addition, he is portrayed as a young man in "Lamentation" by C. J. Sansom.
Cecil is also portrayed by Ben Willbond in the BAFTA award winning children's comedy television series "Horrible Histories".

</doc>
<doc id="51113" url="https://en.wikipedia.org/wiki?curid=51113" title="Clemens August of Bavaria">
Clemens August of Bavaria

Clemens August of Bavaria () (17 August 1700 – 6 February 1761) was a member of the Wittelsbach dynasty of Bavaria and Archbishop-Elector of Cologne.
Biography.
Clemens August (Clementus Augustus) was born in Brussels, the son of Elector Maximilian II Emanuel of Bavaria and Theresa Kunegunda Sobieska and the grandson of King John III Sobieski of Poland. His family was split during the War of the Spanish Succession and was for many years under house arrest in Austria; only in 1715 did the family become re-united.
His uncle Joseph Clemens, Elector and Archbishop of Cologne, saw to it that Clemens August received several appointments in Altötting, the Diocese of Regensburg, and at the Prince-Provostry of Berchtesgaden, and he soon received papal confirmation as Bishop of Regensburg, and later of Cologne.
As Archbishop of Cologne, he was one of the Electors, a Prince-Bishop of Münster, Hildesheim, and Osnabrück, and a Grand Master of the Teutonic Order.
Clemens August, who mostly sided with the Austrian Habsburg-Lorraine side during the War of the Austrian Succession, personally crowned his brother Charles VII emperor at Frankfurt in 1742. After Charles's death in 1745, Clemens August then again leaned toward Austria. Over time, Clemens August changed more frequently the alliances, as of Allied of Austria or France, also under the influence of his frequently changing First Ministers and high donations.
He died in Festung Ehrenbreitstein in 1761. In March 1761, shortly after his death, Pope Clement XIII rejected the succession of Clemens August's brother Cardinal John Theodore of Bavaria as Archbishop and Prince-Elector of Cologne since the pope entertained some doubt on John Theodore's "moral conduct". This was the end of the reign of the Wittelsbach in Cologne after 178 years of continuous rule. In his will, Clemens August donated only to his successor as Elector and the court chamber of the Electorate of Cologne, but not the Elector of Bavaria. His nephew Maximilian III. Joseph then tried to challenge the will before the Supreme Court of Appeal, however, this failed on 23 January 1767.
Cultural legacy.
Clemens August patronised the arts; among others he ordered to build the palaces of Augustusburg and Falkenlust in Brühl, North Rhine-Westphalia, listed on the UNESCO cultural world heritage list, and the church of St Michael in Berg am Laim in Munich.
Illegitimate children.
Clemens August and his mistress Mechthild Brion had a daughter:

</doc>
<doc id="51114" url="https://en.wikipedia.org/wiki?curid=51114" title="Transport economics">
Transport economics

Transport economics is a branch of economics founded in 1959 by American economist John R. Meyer that deals with the allocation of resources within the transport sector. It has strong links to civil engineering. Transport economics differs from some other branches of economics in that the assumption of a spaceless, instantaneous economy does not hold. People and goods flow over networks at certain speeds. Demands peak. Advance ticket purchase is often induced by lower fares. The networks themselves may or may not be competitive. A single trip (the final good, in the consumer's eyes) may require the bundling of services provided by several firms, agencies and modes.
Although transport systems follow the same supply and demand theory as other industries, the complications of network effects and choices between dissimilar goods (e.g. car and bus travel) make estimating the demand for transportation facilities difficult. The development of models to estimate the likely choices between the such goods involved in transport decisions (discrete choice models) led to the development of an important branch of econometrics, as well as a Nobel Prize for Daniel McFadden.
In transport, demand can be measured in number of journeys made or in total distance traveled across all journeys (e.g. passenger-kilometers for public transport or vehicle-kilometers of travel (VKT) for private transport). Supply is considered to be a measure of capacity. The price of the good (travel) is measured using the generalised cost of travel, which includes both money and time expenditure.
The effect of increases in supply (i.e. capacity) are of particular interest in transport economics (see induced demand), as the potential environmental consequences are significant (see "externalities" below).
Externalities.
In addition to providing benefits to their users, transport networks impose both positive and negative externalities on non-users. The consideration of these externalities - particularly the negative ones - is a part of transport economics.
Positive externalities of transport networks may include the ability to provide emergency services, increases in land value, and agglomeration benefits. Negative externalities are wide-ranging and may include local air pollution, noise pollution, light pollution, safety hazards, community severance and congestion. The contribution of transport systems to potentially hazardous climate change is a significant negative externality which is difficult to evaluate quantitatively, making it difficult (but not impossible) to include in transport economics-based research and analysis.
Congestion is considered a negative externality by economists. An externality occurs when a transaction causes costs or benefits to third party, often, although not necessarily, from the use of a public good. For example, manufacturing or transportation cause air pollution imposing costs on others when making use of public air.
Traffic congestion.
Traffic congestion is a negative externality caused by various factors. A 2005 American study stated that there are seven root causes of congestion, and gives the following summary of their contributions: bottlenecks 40%, traffic incidents 25%, bad weather 15%, work zones 10%, poor signal timing 5%, and special events/other 5%. Within the transport economics community, congestion pricing is considered to be an appropriate mechanism to deal with this problem (i.e. to internalise the externality) by allocating scarce roadway capacity to users. Capacity expansion is also a potential mechanism to deal with traffic congestion, but is often undesirable (particularly in urban areas) and sometimes has questionable benefits (see induced demand). William Vickrey, winner of the 1996 Nobel Prize for his work on "moral hazard", is considered one of the fathers of congestion pricing, as he first proposed it for the New York City Subway in 1952.
In the road transportation arena these theories were extended by Maurice Allais, a fellow Nobel prize winner "for his pioneering contributions to the theory of markets and efficient utilization of resources", Gabriel Roth who was instrumental in the first designs and upon whose World Bank recommendation the first system was put in place in Singapore. Reuben Smeed, the deputy director of the Transport and Road Research Laboratory was also a pioneer in this field, and his ideas were presented to the British government in what is known as the Smeed Report.
Congestion is not limited to road networks; the negative externality imposed by congestion is also important in busy public transport networks as well as crowded pedestrian areas, e.g. on the London Underground on a weekday or any urban train station, at peak times. There is the classical excess in demand compared to supply. This is because at peak times there is a large demand for trains, since people want to go home (i.e., a derived demand). However, space on the platforms and on the trains is limited and small compared to the demand for it. As a result, there are crowds of people outside the train doors and in the train station corridors. This increases delays for commuters, which can often cause a rise in stress or other problems.
Congestion pricing.
Congestion pricing is an efficiency pricing strategy that requires the users to pay more for that public good, thus increasing the welfare gain or net benefit for society. Congestion pricing is one of a number of alternative demand side (as opposed to supply side) strategies offered by economists to address congestion. Congestion pricing was first implemented in Singapore in 1975, together with a comprehensive package of road pricing measures, stringent car ownership rules and improvements in mass transit. Thanks to technological advances in electronic toll collection, Singapore upgraded its system in 1998 (see Singapore's Electronic Road Pricing). Similar pricing schemes were implemented in Rome in 2001, as an upgrade to the manual zone control system implemented in 1998;
London in 2003 and extended in 2007 (see London congestion charge); Stockholm in 2006, as seven-month trial, and then on a permanent basis since August 2007 (see Stockholm congestion tax).
Pollution Pricing.
Since January 2008, Milan introduced a traffic charge scheme as a one-year trial, called Ecopass, that exempts higher emission standard vehicles (Euro IV) and other alternative fuel vehicles Later during the year the Ecopass was extended until December 31, 2009.
Even the transport economists who advocate congestion pricing have anticipated several practical limitations, concerns and controversial issues regarding the actual implementation of this policy. As summarized by Cervero: ""True social-cost pricing of metropolitan travel has proven to be a theoretical ideal that so far has eluded real-world implementation. The primary obstacle is that except for professors of transportation economics and a cadre of vocal environmentalists, few people are in favor of considerably higher charges for peak-period travel. Middle-class motorists often complain they already pay too much in gasoline taxes and registration fees to drive their cars, and that to pay more during congested periods would add insult to injury. In the United States, few politicians are willing to champion the cause of congestion pricing in fear of reprisal from their constituents... Critics also argue that charging more to drive is elitist policy, pricing the poor off of roads so that the wealthy can moveabout unencumbered. It is for all these reasons that peak-periord pricing remains a pipe dream in the minds of many.""
Road space rationing.
Transport economists consider road space rationing an alternative to congestion pricing, but road space rationing is considered more equitable, as the restrictions force all drivers to reduce auto travel, while congestion pricing restrains less those who can afford paying the congestion charge. Nevertheless, high-income users can avoid the restrictions by owning a second car. Moreover, congestion pricing (unlike rationing) acts "to allocate a scarce resource to its most valuable use, as evinced by users' willingness to pay for the resource". While some "opponents of congestion pricing fear that tolled roads will be used only by people with high income. But preliminary evidence suggests that the new toll lanes in California are used by people of all income groups. The ability to get somewhere fast and reliably is valued in a variety of circumstances. Not everyone will need or want to incur a toll on a daily basis, but on occasions when getting somewhere quickly is necessary, the option of paying to save time is valuable to people at all income levels." Road space rationing based on license numbers has been implemented in cities such as Athens (1982), México City (1989), São Paulo (1997), Santiago, Chile, Bogotá, Colombia, La Paz (2003), Bolivia, and San José (2005), Costa Rica.
Tradable mobility credits.
A more acceptable policy on automobile travel restrictions, proposed by transport economists to avoid inequality and revenue allocation issues, is to implement a rationing of peak period travel but through revenue-neutral credit-based congestion pricing. This concept is similar to the existing system of emissions trading of carbon credits, proposed by the Kyoto Protocol to curb greenhouse emissions. Metropolitan area or city residents, or the taxpayers, will have the option to use the local government-issued mobility rights or congestion credits for themselves, or to trade or sell them to anyone willing to continue traveling by automobile beyond the personal quota. This trading system will allow direct benefits to be accrued by those users shifting to public transportation or by those reducing their peak-hour travel rather than the government.
Funding and financing.
Methods of funding and financing transport network maintenance, improvement and expansion are debated extensively and form part of the transport economics field.
Funding issues relate to the ways in which money is raised for the supply of transport capacity. Taxation and user fees are the main methods of fund-raising. Taxation may be general (e.g. income tax), local (e.g. sales tax or land value tax) or variable (e.g. fuel tax), and user fees may be tolls, congestion charges or fares). The method of funding often attracts strong political and public debate.
Financing issues relate to the way in which these funds are used to pay for the supply of transport. Loans, bonds, public–private partnerships and concessions are all methods of financing transport investment.
Regulation and competition.
Regulation of the supply of transport capacity relates to both safety regulation and economic regulation. Transport economics considers issues of the economic regulation of the supply of transport, particularly in relation to whether transport services and networks are provided by the public sector (i.e. socially), by the private sector (i.e. competitively) or using a mixture of both.
Transport networks and services can take on any combination of regulated/deregulated and public/private provision. For example, bus services in the UK outside London are provided by both the public and private sectors in a deregulated economic environment (where no-one specifies which services are to be provided, so the provision of services is influenced by the market), whereas bus services within London are provided by the private sector in a regulated economic environment (where the public sector specifies the services to be provided and the private sector competes for the right to supply those services - i.e. franchising).
The regulation of public transport is often designed to achieve some social, geographic and temporal equity as market forces might otherwise lead to services being limited to the most popular travel times along the most densely settled corridors of development. National, regional or municipal taxes are often deployed to provide a network that is socially acceptable (e.g. extending timetables through the daytime, weekend, holiday or evening periods and intensifying the mesh of routes beyond that which a lightly regulated market would probably provide).
Franchising may be used to create a supply of transport that balances the free-market supply outcome and the most socially desirable supply outcome.
Project appraisal and evaluation.
The most sophisticated methods of project appraisal and evaluation have been developed and applied in the transport sector. It should be noted that the terms 'appraisal' and 'evaluation' are often confused in relation to the assessment of projects. Appraisal refers to "ex ante" (before the event) assessment and evaluation refers to "ex post" (after the event) assessment.
Appraisal.
The appraisal of changes in the transport network is one of the most important applications of transport economics. In order to make an assessment of whether any given transport project should be carried out, transport economics can be used to compare the costs of the project with its benefits (both social and financial). Such an assessment is known as a cost-benefit analysis, and is usually a fundamental piece of information for decision-makers, as it places a value on the net benefits (or disbenefits) of schemes and generates a ratio of benefits to costs which may be used to prioritise projects when funding is constrained.
A primary difficulty in project appraisal is the valuation of time. Travel time savings are often cited as a key benefit of transport projects, but people in different occupations, carrying out different activities and in different social classes value time differently.
Appraising projects on the basis of their supposed reductions in travel times has come under scrutiny in recent years with the recognition that improvements in capacity generate trips that would not have been made (induced demand), partially eroding the benefits of reduced travel times. Therefore, an alternative method of appraisal is to measure changes in land value and consumer benefits from a transport project rather than the measuring benefits accruing to travellers themselves. However, this method of analysis is much more difficult to carry out.
Another problem is that many transport projects have impacts that cannot be expressed in monetary terms, such as impacts on, for example, local air quality, biodiversity and community severance. Whilst these impacts can be included in a detailed environmental impact assessment, a key issue has been how to present these assessments alongside estimates of those costs and benefits that can be expressed in monetary terms. Recent developments in transport appraisal practice in some European countries have seen the application of multi-criteria decision analysis based decision support tools. These build on existing cost-benefit analysis and environmental impact assessment techniques and help decision makers weigh up the monetary and non-monetary impacts of transport projects. In the UK, one such application, the New Approach to Appraisal has become a cornerstone of UK transport appraisal.
Evaluation.
The evaluation of projects enables decision makers to understand whether the benefits and costs that were estimated in the appraisal materialised. Successful project evaluation requires that the necessary data to carry out the evaluation is specified in advance of carrying out the appraisal.
The appraisal and evaluation of projects form stages within a broader policy making cycle that includes:
Social effects on poverty.
Those with low income living in cities face a problem called “poverty transportation.” The problem arises because many of the entry level jobs which are sought out by those with little education are typically located in suburban areas. Those jobs are also not very accessible by public transportation because the transportation was often designed to move people around cities, which becomes a problem when the jobs are no longer located in the cities. Those who cannot afford cars inevitably suffer the worst, because they have no choice but to rely on public transport. The problem is illustrated by an estimation that 70% of entry level jobs are located in the suburbs, while only 32% of those jobs are within a quarter mile of public transportation. More difficult (or more expensive) access to jobs and other goods & services can act as a ghetto tax.
As a result of the transportation systems in use, but not adequately meeting the needs of those who rely on them, they tend to generate low revenue. And with minimal revenue or funding the transportation systems are forced to decrease service and increase fares, which causes those in poverty to face more inequality. Further those who live in cities with no public transportation become even more excluded from education and work. In places with no public transport a car is the only viable option and that creates unnecessary strain on the roads and environment.
Since automobile use tends to be greater than public transportation use, it also becomes the norm for people to work towards car ownership. Private car ownership has led to a large allocation of resources towards road and bridge maintenance. But underfunding of public transportation prevents everyone who needs transportation from having access to it. And those who can choose between public transportation and private transportation will choose private transportation rather than face the inconveniences of public transportation. The lack of customers willing to use public transport creates a cycle that ultimately never leads to the transportation systems making significant progress. Another reason for low private vehicle ownership among welfare recipients are the established asset limitations. In the U.S. the asset limit is $1000 per vehicle. This forces welfare recipients to purchase old and sub standard vehicles in order not to lose their welfare funding.
There are a number of ways in which public transportation could be improved and for it to become a better and more enticing option for other people who do not necessarily depend on it. Some of these include creating networks of overlapping routes even among different operators to give people more choice in where and how they want to go somewhere. The system should also function as a whole, to prevent drivers from dangerously racing along routes to increase profit. Providing incentives to use public transportation can also be beneficial, as ridership increases the transportation systems can appropriately respond by increasing the frequency along those transportation routes. Even creating bus only lanes or priority lanes at intersections could improve service and speed.
Experiments done in Africa (Uganda and Tanzania) and Sri Lanka on hundreds of households have shown that a bicycle can increase the income of a poor family by as much as 35%]. Transport, if analyzed for the cost-benefit analysis for rural poverty alleviation, has given one of the best returns in this regard. For example, road investments in India were a staggering 3–10 times more effective than almost all other investments and subsidies in rural economy in the decade of the 1990s. What a road does at a macro level to increase transport, the bicycle supports at the micro level. Bicycle, in that sense, can be one of the best means to eradicate the poverty in poor nations.
Car taxation.
Car taxation is an instrument to influence the purchase decisions of consumers. Taxes can be differentiated to support the market introduction of fuel efficient and low carbon dioxide (CO2) emitting cars.
The European Union Commission has made a proposal for a Council Directive on passenger car taxation which is currently before the Council and Parliament.
The Commission encourages again Member States to adopt this proposal as soon as possible and to adapt their car taxation policies so as to promote the purchase of fuel efficient cars throughout the EU and help manufacturers respect the upcoming fuel efficiency framework, thus contributing their share to reducing the CO2 emissions of cars. Taxes differentiated over the whole range of cars on the market, so as to gradually induce a switch towards less emitting cars, would be an efficient way to reduce compliance costs for manufacturers.
Tax rates on acquisition.
In 2011, for a brand new VW Golf Trendline (80 PS, 5G 2T) the taxation rate (all inclusive, i.e. VAT+registration tax+any other taxes) on acquisition was as follows:

</doc>
<doc id="51115" url="https://en.wikipedia.org/wiki?curid=51115" title="Alienation">
Alienation

Alienation may refer to:

</doc>
<doc id="51117" url="https://en.wikipedia.org/wiki?curid=51117" title="Meissner effect">
Meissner effect

The Meissner effect is the expulsion of a magnetic field from a superconductor during its transition to the superconducting state. The German physicists Meissner] and Robert Ochsenfeld discovered this phenomenon in 1933 by measuring the magnetic field distribution outside superconducting tin and lead samples. The samples, in the presence of an applied magnetic field, were cooled below their superconducting transition temperature. Below the transition temperature the samples cancelled nearly all interior magnetic fields. They detected this effect only indirectly because the magnetic flux is conserved by a superconductor: when the interior field decreases, the exterior field increases. The experiment demonstrated for the first time that superconductors were more than just perfect conductors and provided a uniquely defining property of the superconducting state.
A superconductor with little or no magnetic field within it is said to be in the Meissner state. The Meissner state breaks down when the applied magnetic field is too large. Superconductors can be divided into two classes according to how this breakdown occurs. In Type I superconductors, superconductivity is abruptly destroyed when the strength of the applied field rises above a critical value "Hc". Depending on the geometry of the sample, one may obtain an intermediate state consisting of a baroque pattern of regions of normal material carrying a magnetic field mixed with regions of superconducting material containing no field. In Type II superconductors, raising the applied field past a critical value "H""c"1 leads to a mixed state (also known as the vortex state) in which an increasing amount of magnetic flux penetrates the material, but there remains no resistance to the flow of electric current as long as the current is not too large. At a second critical field strength "H""c"2, superconductivity is destroyed. The mixed state is actually caused by vortices in the electronic superfluid, sometimes called fluxons because the flux carried by these vortices is quantized. Most pure elemental superconductors, except niobium and carbon nanotubes, are Type I, while almost all impure and compound superconductors are Type II.
Explanation.
The Meissner effect was given a phenomenological explanation by the brothers Fritz and Heinz London, who showed that the electromagnetic free energy in a superconductor is minimized provided
where H is the magnetic field and λ is the London penetration depth.
This equation, which is known as the London equation, predicts that the magnetic field in a superconductor decays exponentially from whatever value it possesses at the surface.
In a weak applied field, a superconductor "expels" nearly all magnetic flux. It does this by setting up electric currents near its surface. The magnetic field of these surface currents cancels the applied magnetic field within the bulk of the superconductor. As the field expulsion, or cancellation, does not change with time, the currents producing this effect (called persistent currents) do not decay with time. Therefore, the conductivity can be thought of as infinite: a superconductor.
Near the surface, within the London penetration depth, the magnetic field is not completely cancelled. Each superconducting material has its own characteristic penetration depth.
Any perfect conductor will prevent any change to magnetic flux passing through its surface due to ordinary electromagnetic induction at zero resistance. The Meissner effect is distinct from this: when an ordinary conductor is cooled so that it makes the transition to a superconducting state in the presence of a constant applied magnetic field, the magnetic flux is expelled during the transition. This effect cannot be explained by infinite conductivity alone. Its explanation is more complex and was first given in the London equations by the brothers Fritz and Heinz London. It should thus be noted that the placement and subsequent levitation of a magnet above an already superconducting material does not demonstrate the Meissner effect, while an initially stationary magnet later being repelled by a superconductor as it is cooled through its critical temperature does.
Perfect diamagnetism.
Superconductors in the Meissner state exhibit perfect diamagnetism, or superdiamagnetism, meaning that the total magnetic field is very close to zero deep inside them (many penetration depths from the surface). This means that their magnetic susceptibility, formula_2 = −1. Diamagnetics are defined by the generation of a spontaneous magnetization of a material which directly opposes the direction of an applied field. However, the fundamental origins of diamagnetism in superconductors and normal materials are very different. In normal materials diamagnetism arises as a direct result of the orbital spin of electrons about the nuclei of an atom induced electromagnetically by the application of an applied field. In superconductors the illusion of perfect diamagnetism arises from persistent screening currents which flow to oppose the applied field (the Meissner effect); not solely the orbital spin.
Consequences.
The discovery of the Meissner effect led to the phenomenological theory of superconductivity by Fritz and Heinz London in 1935. This theory explained resistanceless transport and the Meissner effect, and allowed the first theoretical predictions for superconductivity to be made. However, this theory only explained experimental observations—it did not allow the microscopic origins of the superconducting properties to be identified. This was done successfully by the BCS theory in 1957, from which the penetration depth and the Meissner effect result. However, some physicists argue that BCS theory does not explain the Meissner effect.
Paradigm for the Higgs mechanism.
The Meissner effect of superconductivity serves as an important paradigm for the generation mechanism of a mass "M" (i.e. a reciprocal "range", formula_3 where "h" is Planck constant and "c" is speed of light) for a gauge field. In fact, this analogy is an abelian example for the Higgs mechanism, through which in high-energy physics the masses of the electroweak gauge particles, and are generated. The length formula_4 is identical with the London penetration depth in the theory of superconductivity.

</doc>
<doc id="51119" url="https://en.wikipedia.org/wiki?curid=51119" title="Literary theory">
Literary theory

Literary theory in a strict sense is the systematic study of the nature of literature and of the methods for analyzing literature. However, literary scholarship since the 19th century often includes—in addition to, or even instead of literary theory in the strict sense—considerations of intellectual history, moral philosophy, social prophecy, and other interdisciplinary themes which are of relevance to the way humans interpret meaning. In humanities in modern academia, the latter style of scholarship is an outgrowth of critical theory and is often called simply "theory." As a consequence, the word "theory" has become an umbrella term for a variety of scholarly approaches to reading texts. Many of these approaches are informed by various strands of Continental philosophy and sociology.
History.
The practice of literary theory became a profession in the 20th century, but it has historical roots that run as far back as ancient Greece (Aristotle's "Poetics" is an often cited early example), ancient India (Bharata Muni's "Natya Shastra"), ancient Rome (Longinus's "On the Sublime") and medieval Iraq (Al-Jahiz's "al-Bayan wa-'l-tabyin" and "al-Hayawan", and ibn al-Mu'tazz's "Kitab al-Badi"), and the aesthetic theories of philosophers from ancient philosophy through the 18th and 19th centuries are important influences on current literary study. The theory and criticism of literature are, of course, also closely tied to the history of literature.
The modern sense of "literary theory," however, dates only to approximately the 1950s, when the structuralist linguistics of Ferdinand de Saussure began strongly to influence English language literary criticism. The New Critics and various European-influenced formalists (particularly the Russian Formalists) had described some of their more abstract efforts as "theoretical" as well. But it was not until the broad impact of structuralism began to be felt in the English-speaking academic world that "literary theory" was thought of as a unified domain.
In the academic world of the United Kingdom and the United States, literary theory was at its most popular from the late 1960s (when its influence was beginning to spread outward from elite universities like Johns Hopkins, Yale, and Cornell) through the 1980s (by which time it was taught nearly everywhere in some form). During this span of time, literary theory was perceived as academically cutting-edge, and most university literature departments sought to teach and study theory and incorporate it into their curricula. Because of its meteoric rise in popularity and the difficult language of its key texts, theory was also often criticized as faddish or trendy obscurantism (and many academic satire novels of the period, such as those by David Lodge, feature theory prominently). Some scholars, both theoretical and anti-theoretical, refer to the 1970s and 1980s debates on the academic merits of theory as "the theory wars."
By the early 1990s, the popularity of "theory" as a subject of interest by itself was declining slightly (along with job openings for pure "theorists") even as the texts of literary theory were incorporated into the study of almost all literature. By 2010, the controversy over the use of theory in literary studies had quieted down, and discussions on the topic within literary and cultural studies tend now to be considerably milder and less lively. However, some scholars like Mark Bauerlein continue to argue that less capable theorists have abandoned proven methods of epistemology, resulting in persistent lapses in learning, research, and evaluation. Some scholars draw do draw heavily on theory in their work, while others only mention it in passing or not at all; but it is an acknowledged, important part of the study of literature.
About.
One of the fundamental questions of literary theory is "what is literature?" – although many contemporary theorists and literary scholars believe either that "literature" cannot be defined or that it can refer to any use of language. Specific theories are distinguished not only by their methods and conclusions, but even by how they define a "text".
The principles and methods of literary theory apply to non-fiction, popular fiction, film, historical documents, law, advertising, etc., and in the related field of cultural studies. Some scholars within cultural studies treat cultural events, like fashion or football riots, as "texts" to be interpreted. By this measure, literary theory can be thought of as the general theory of interpretation.
Since theorists of literature often draw on a very heterogeneous tradition of Continental philosophy and the philosophy of language, any classification of their approaches is only an approximation. There are many types of literary theory, which take different approaches to texts. Even among those listed below, combine methods from more than one of these approaches (for instance, the deconstructive approach of Paul de Man drew on a long tradition of close reading pioneered by the New Critics, and de Man was trained in the European hermeneutic tradition).
Broad schools of theory that have historically been important include historical and biographical criticism, New Criticism, formalism, Russian formalism, and structuralism, post-structuralism, Marxism, feminism and French feminism, post-colonialism, new historicism, deconstruction, reader-response criticism, and psychoanalytic criticism.
Differences among schools.
The different interpretive and epistemological perspectives of different schools of theory often arise from, and so give support to, different moral and political commitments. For instance, the work of the New Critics often contained an implicit moral dimension, and sometimes even a religious one: a New Critic might read a poem by T. S. Eliot or Gerard Manley Hopkins for its degree of honesty in expressing the torment and contradiction of a serious search for belief in the modern world. Meanwhile, a Marxist critic might find such judgments merely ideological rather than critical; the Marxist would say that the New Critical reading did not keep enough critical distance from the poem's religious stance to be able to understand it. Or a post-structuralist critic might simply avoid the issue by understanding the religious meaning of a poem as an allegory of meaning, treating the poem's references to "God" by discussing their referential nature rather than what they refer to. A critic using Darwinian literary studies might use arguments from the evolutionary psychology of religion.
Such a disagreement cannot be easily resolved, because it is inherent in the radically different terms and goals (that is, the theories) of the critics. Their theories of reading derive from vastly different intellectual traditions: the New Critic bases his work on an East-Coast American scholarly and religious tradition, while the Marxist derives his thought from a body of critical social and economic thought, the post-structuralist's work emerges from twentieth-century Continental philosophy of language, and the Darwinian from the modern evolutionary synthesis. To expect such different approaches to have much in common would be naïve; so calling them all "theories of literature" without acknowledging their heterogeneity is itself a reduction of their differences.
In the late 1950s, the Canadian literary critic Northrop Frye attempted to establish an approach for reconciling historical criticism and New Criticism while addressing concerns of early reader-response and numerous psychological and social approaches. His approach, laid out in his "Anatomy of Criticism", was explicitly structuralist, relying on the assumption of an intertextual "order of words" and universality of certain structural types. His approach held sway in English literature programs for several decades but lost favor during the ascendance of post-structuralism.
For some theories of literature (especially certain kinds of formalism), the distinction between "literary" and other sorts of texts is of paramount importance. Other schools (particularly post-structuralism in its various forms: new historicism, deconstruction, some strains of Marxism and feminism) have sought to break down distinctions between the two and have applied the tools of textual interpretation to a wide range of "texts", including film, non-fiction, historical writing, and even cultural events.
Bakhtin argued that the "utter inadequacy" of literary theory is evident when it is forced to deal with the novel; while other genres are fairly stabilized, the novel is still developing.
Another crucial distinction among the various theories of literary interpretation is intentionality, the amount of weight given to the author's own opinions about and intentions for a work. For most pre-20th century approaches, the author's intentions are a guiding factor and an important determiner of the "correct" interpretation of texts. The New Criticism was the first school to disavow the role of the author in interpreting texts, preferring to focus on "the text itself" in a close reading. In fact, as much contention as there is between formalism and later schools, they share the tenet that the author's interpretation of a work is no more inherently meaningful than any other.
Schools of literary theory.
Listed below are some of the most commonly identified schools of literary theory, along with their major authors. In many cases, such as those of the historian and philosopher Michel Foucault and the anthropologist Claude Lévi-Strauss, the authors were not primarily literary critics, but their work has been broadly influential in literary theory.
The concept of emergence has been applied to the theory of literature and art, history, linguistics, cognitive sciences, etc. by the teachings of Jean-Marie Grassin et the University of Limoges (v. esp.: J. Fontanille, B. Westphal, J. Vion-Dury, éds. L'Émergence—Poétique de l'Émergence, en réponse aux travaux de Jean-Marie Grassin, Bern, Berlin, etc., 2011; and: the article "Emergence" in the "International Dictionary of Literary Terms (DITL)").

</doc>
<doc id="51123" url="https://en.wikipedia.org/wiki?curid=51123" title="Literary criticism">
Literary criticism

Literary criticism is the study, evaluation, and interpretation of literature. Modern literary criticism is often influenced by literary theory, which is the philosophical discussion of literature's goals and methods. Though the two activities are closely related, literary critics are not always, and have not always been, theorists.
Whether or not literary criticism should be considered a separate field of inquiry from literary theory, or conversely from book reviewing, is a matter of some controversy. For example, the "Johns Hopkins Guide to Literary Theory and Criticism" draws no distinction between literary theory and literary criticism, and almost always uses the terms together to describe the same concept. Some critics consider literary criticism a practical application of literary theory, because criticism always deals directly with particular literary works, while theory may be more general or abstract.
Literary criticism is often published in essay or book form. Academic literary critics teach in literature departments and publish in academic journals, and more popular critics publish their reviews in broadly circulating periodicals such as the "Times Literary Supplement", the "New York Times Book Review", the "New York Review of Books", the "London Review of Books", "The Nation", and "The New Yorker".
History.
Aristotle's "Poetics" clearly defines aspects of literature and introduces many literary terms still used today.
Classical and medieval criticism.
Literary criticism has probably existed for as long as literature. In the 4th century BC Aristotle wrote the "Poetics", a typology and description of literary forms with many specific criticisms of contemporary works of art. "Poetics" developed for the first time the concepts of mimesis and catharsis, which are still crucial in literary study. Plato's attacks on poetry as imitative, secondary, and false were formative as well. Around the same time, Bharata Muni, in his "Natya Shastra", wrote literary criticism on ancient Indian literature and Sanskrit drama.
Later classical and medieval criticism often focused on religious texts, and the several long religious traditions of hermeneutics and textual exegesis have had a profound influence on the study of secular texts. This was particularly the case for the literary traditions of the three Abrahamic religions: Jewish literature, Christian literature and Islamic literature.
Literary criticism was also employed in other forms of medieval Arabic literature and Arabic poetry from the 9th century, notably by Al-Jahiz in his "al-Bayan wa-'l-tabyin" and "al-Hayawan", and by Abdullah ibn al-Mu'tazz in his "Kitab al-Badi".
Renaissance criticism.
The literary criticism of the Renaissance developed classical ideas of unity of form and content into literary neoclassicism, proclaiming literature as central to culture, entrusting the poet and the author with preservation of a long literary tradition. The birth of Renaissance criticism was in 1498, with the recovery of classic texts, most notably, Giorgio Valla's Latin translation of Aristotle's "Poetics". The work of Aristotle, especially "Poetics", was the most important influence upon literary criticism until the late eighteenth century. Lodovico Castelvetro was one of the most influential Renaissance critics who wrote commentaries on Aristotle's "Poetics" in 1570.
19th-century Romantic criticism.
The British Romantic movement of the early nineteenth century introduced new aesthetic ideas to literary study, including the idea that the object of literature need not always be beautiful, noble, or perfect, but that literature itself could elevate a common subject to the level of the sublime. German Romanticism, which followed closely after the late development of German classicism, emphasized an aesthetic of fragmentation that can appear startlingly modern to the reader of English literature, and valued "Witz" – that is, "wit" or "humor" of a certain sort – more highly than the serious Anglophone Romanticism. The late nineteenth century brought renown to authors known more for critical writing than for their own literary work, such as Matthew Arnold.
The New Criticism.
However important all of these aesthetic movements were as antecedents, current ideas about literary criticism derive almost entirely from the new direction taken in the early twentieth century. Early in the century the school of criticism known as Russian Formalism, and slightly later the New Criticism in Britain and in the United States, came to dominate the study and discussion of literature, in the English-speaking world. Both schools emphasized the close reading of texts, elevating it far above generalizing discussion and speculation about either authorial intention (to say nothing of the author's psychology or biography, which became almost taboo subjects) or reader response. This emphasis on form and precise attention to "the words themselves" has persisted, after the decline of these critical doctrines themselves.
Theory.
In 1957 Northrop Frye published the influential "Anatomy of Criticism". In his works Frye noted that some critics tend to embrace an ideology, and to judge literary pieces on the basis of their adherence to such ideology. This has been a highly influential viewpoint among modern conservative thinkers. E. Michael Jones, for example, argues in his "Degenerate Moderns" that Stanley Fish was influenced by his adulterous affairs to reject classic literature that condemned adultery.
In the British and American literary establishment, the New Criticism was more or less dominant until the late 1960s. Around that time Anglo-American university literature departments began to witness a rise of a more explicitly philosophical literary theory, influenced by structuralism, then post-structuralism, and other kinds of Continental philosophy. It continued until the mid-1980s, when interest in "theory" peaked. Many later critics, though undoubtedly still influenced by theoretical work, have been comfortable simply interpreting literature rather than writing explicitly about methodology and philosophical presumptions.
History of the book.
Related to other forms of literary criticism, the history of the book is a field of interdisciplinary inquiry drawing on the methods of bibliography, cultural history, history of literature, and media theory. Principally concerned with the production, circulation, and reception of texts and their material forms, book history seeks to connect forms of textuality with their material aspects.
Among the issues within the history of literature with which book history can be seen to intersect are: the development of authorship as a profession, the formation of reading audiences, the constraints of censorship and copyright, and the economics of literary form.
Current state.
Today, interest in literary theory and continental philosophy coexists in university literature departments with a more conservative literary criticism of which the New Critics would probably have approved. Disagreements over the goals and methods of literary criticism, which characterized both sides taken by critics during the "rise" of theory, have declined. Many critics feel that they now have a great plurality of methods and approaches from which to choose.
Some critics work largely with theoretical texts, while others read traditional literature; interest in the literary canon is still great, but many critics are also interested in minority and women's literatures, while some critics influenced by cultural studies read popular texts like comic books or pulp/genre fiction. Ecocritics have drawn connections between literature and the natural sciences. Darwinian literary studies studies literature in the context of evolutionary influences on human nature. Many literary critics also work in film criticism or media studies. Some write intellectual history; others bring the results and methods of social history to bear on reading literature.
Value of academic criticism.
The value of extensive literary analysis has been questioned by several prominent artists. Vladimir Nabokov once wrote that good readers do not read books, and particularly those which are considered to be literary masterpieces, "for the academic purpose of indulging in generalizations". At a 1986 Copenhagen conference of James Joyce scholars, Stephen J. Joyce (the modernist writer's grandson) said, "If my grandfather was here, he would have died laughing ... "Dubliners" and "A Portrait of the Artist as a Young Man" can be picked up, read, and enjoyed by virtually anybody without scholarly guides, theories, and intricate explanations, as can "Ulysses", if you forget about all the hue and cry." He later questioned whether anything has been added to the legacy of Joyce's art by the 261 books of literary criticism stored in the Library of Congress.
Key texts.
The 20th century.
"Poetry, Revisionism, Repression"

</doc>
<doc id="51124" url="https://en.wikipedia.org/wiki?curid=51124" title="Pangolin">
Pangolin

Pangolins (also referred to as scaly anteaters or trenggiling) are mammals of the order Pholidota. The one extant family, Manidae, has three genera: "Manis", which comprises four species living in Asia, "Phataginus", which comprises two species living in Africa, and "Smutsia", which comprises two species also living in Africa. These species range in size from . A number of extinct pangolin species are also known. The name pangolin comes from the Malay word "pengguling", meaning "something that rolls up". It is found in tropical regions throughout Africa and Asia.
Pangolins have large, protective keratin scales covering their skin; they are the only known mammals with this adaptation. They live in hollow trees or burrows, depending on the species. Pangolins are nocturnal, and their diet consists of mainly ants and termites which they capture using their long, specially adapted tongues. They tend to be solitary animals, meeting only to mate and produce a litter of one to three offspring which are raised for about two years. Pangolins are threatened by hunting (for their meat and armor) and heavy deforestation of their natural habitats, and are the most trafficked mammal in the world. Of the eight species of pangolin, four species ("Phataginus tetradactyla", "P. tricuspis", "Smutsia gigantea", and "S. temminckii") are listed as vulnerable, two species ("Manis crassicaudata" and "M. cullonensis") are listed as endangered, and two species ("M. pentadactyla" and "M. javanica") are listed as critically endangered on the IUCN Red List of Threatened Species.
Description.
The physical appearance of a pangolin is marked by large, hardened, overlapping plate-like scales. The scales, which are soft on newborn pangolins but harden as the animal matures, are made of keratin, the same material of which human fingernails and tetrapod claws are made. The pangolin's scaled body is comparable to a pine cone or globe artichoke. It can curl up into a ball when threatened, with its overlapping scales acting as armour and its face tucked under its tail. The scales are sharp, providing extra defense. The front claws are so long they are unsuited for walking, so the animal walks with its fore paws curled over to protect them.
Pangolins can also emit a noxious-smelling chemical from glands near the anus, similar to the spray of a skunk. They have short legs, with sharp claws which they use for burrowing into termite and ant mounds, as well as climbing.
The size of pangolins varies by species, ranging from . Females are generally smaller than males.
The tongues of pangolins are extremely elongated and extend into the abdominal cavity. Like those of the giant anteater and the tube-lipped nectar bat, they are not attached to their hyoid bone and extend past their pharynx deep into the thorax. This extension lies between the sternum and the trachea. Large pangolins can extend their tongues as much as , with a diameter of only .
Behavior.
Most pangolins are nocturnal animals that use their well-developed sense of smell to find insects. The long-tailed pangolin is also active by day, while other species of pangolins spend most of the daytime sleeping, curled up into a ball.
Arboreal pangolins live in hollow trees, whereas the ground dwelling species dig tunnels underground, to a depth of . Pangolins are also good swimmers.
Diet.
Pangolins are insectivorous. Most of their diet consists of various species of ants and termites and may be supplemented by other insects, especially larvae. They are somewhat particular and tend to consume only one or two species of insects, even when many species are available to them. A pangolin will consume an average of of insects per day.
Pangolins have a very poor sense of vision, and therefore rely heavily on smell and hearing. After locating their prey, they tear open the anthills or termite mounds with their powerful front claws. Their front claws are so large that their front feet are not useful for walking. The animal uses its long tail to counterbalance its torso as it walks on its two hind legs. After tearing open the ant or termite mound, it uses its long tongue to probe inside the insect tunnels and retrieve its prey. They have glands in their chests to lubricate the tongue with sticky, ant-catching saliva. The tongue extends all the way into a cavity of the abdomen and is longer than the pangolin's entire body length. Pangolins lack teeth and, therefore, the ability to chew, however, they ingest small stones while foraging, which accumulate in the muscular stomach and help to grind up ants.
Some species, such as the tree pangolin, use their strong, prehensile tails to hang from tree branches and strip away bark from the trunk, exposing insect nests inside.
Reproduction.
Pangolins are solitary and meet only to mate. Males are larger than females, weighing up to 50% more. While there is no defined mating season, they typically mate once each year, usually during the summer or autumn months. Rather than the males seeking out the females, males mark their location with urine or feces and the females will find them. If there is competition over a female, the males will use their tails as clubs to fight for the opportunity to mate with her.
Gestation lasts for approximately 120–150 days. African pangolin females usually give birth to a single offspring at a time, but the Asiatic species may give birth from one to three. Weight at birth is and the average length is . At the time of birth, the scales are soft and white. After several days, they harden and darken to resemble those of an adult pangolin. During the vulnerable stage, the mother stays with her offspring in the burrow, nursing it, and will wrap her body around it if she senses danger. The young cling to the mother's tail as she moves about, although in burrowing species, they remain in the burrow for the first two to four weeks of life. At one month, they first leave the burrow riding on the mother's back. Weaning takes place at approximately three months of age, at which stage the young begin to eat insects in addition to nursing. At two years of age, the offspring are sexually mature and are abandoned by the mother.
Threats.
Pangolins are hunted and eaten in many parts of Africa and are one of the more popular types of bush meat. They are also in great demand in Southern China and Vietnam because their meat is considered a delicacy and some believe that pangolin scales have medicinal qualities. This, coupled with deforestation, has led to a large decrease in the numbers of giant pangolins. In November 2010, pangolins were added to the Zoological Society of London's list of genetically distinct and endangered mammals. All eight species of pangolin are classified by the IUCN as threatened to extinction, while two are classified as critically endangered.
Though pangolins are protected by an international ban on their trade, populations have suffered from illegal trafficking due to unfounded beliefs in East Asia that their ground-up scales can stimulate lactation or cure cancer or asthma. In the past decade there have been numerous seizures of illegally trafficked pangolin and pangolin meat in Asia. In one such incident during 2013, 10,000 kilograms of pangolin meat was seized from a Chinese vessel that ran aground in the Philippines.
Conservation.
As a result of increasing threats to pangolins, mainly in the form of illegal, international trade in pangolin skin, scales, and meat, these species have received increasing conservation attention in recent years. For example, in 2014, the IUCN (International Union for the Conservation of Nature) re-categorised all eight species of pangolin on its Red List of Threatened Species, and each species is now threatened with extinction. Also, the IUCN SSC Pangolin Specialist Group launched a global action plan to conserve pangolins, dubbed 'Scaling up Pangolin Conservation' in July 2014.
Taxonomy.
Pangolins were formerly classified with various other orders, for example Xenarthra, which includes the ordinary anteaters, sloths, and the similar-looking armadillos. Newer genetic evidence, however, indicates their closest living relatives are the Carnivora with which they form the clade Ferae. Some palaeontologists placed Ernanodonta in a separate suborder of Cimolesta near Pholidota, have classified the pangolins in the order Cimolesta, together with several extinct groups indicated (†) below, though this idea has fallen out of favor since cimolestids have been determined to have not been placental mammals.
Until recently, all species of pangolin had been attributed to the genus "Manis". Recent research has supported the splitting of pangolins into three genera: "Manis", "Phataginus", and "Smutsia".

</doc>
<doc id="51126" url="https://en.wikipedia.org/wiki?curid=51126" title="Pierrot">
Pierrot

Pierrot () is a stock character of pantomime and Commedia dell'Arte whose origins are in the late seventeenth-century Italian troupe of players performing in Paris and known as the Comédie-Italienne; the name is a hypocorism of "Pierre" (Peter), via the suffix "-ot." His character in contemporary popular culture—in poetry, fiction, the visual arts, as well as works for the stage, screen, and concert hall—is that of the sad clown, pining for love of Columbine, who usually breaks his heart and leaves him for Harlequin. Performing unmasked, with a whitened face, he wears a loose white blouse with large buttons and wide white pantaloons. Sometimes he appears with a frilled collaret and a hat, usually with a close-fitting crown and wide round brim, more rarely with a conical shape like a dunce's cap. But most frequently, since his reincarnation under Jean-Gaspard Deburau, he wears neither collar nor hat, only a black skullcap. The defining characteristic of Pierrot is his naïveté: he is seen as a fool, often the butt of pranks, yet nonetheless trusting.
It was a generally buffoonish Pierrot that held the European stage for the first two centuries of his history. And yet early signs of a respectful, even sympathetic attitude toward the character appeared in the plays of Jean-François Regnard and in the paintings of Antoine Watteau, an attitude that would deepen in the nineteenth century, after the Romantics claimed the figure as their own. For Jules Janin and Théophile Gautier, Pierrot was not a fool but an avatar of the post-Revolutionary People, struggling, sometimes tragically, to secure a place in the bourgeois world. And subsequent artistic/cultural movements found him equally amenable to their cause: the Decadents turned him, like themselves, into a disillusioned disciple of Schopenhauer, a foe of Woman and of callow idealism; the Symbolists saw him as a lonely fellow-sufferer, crucified upon the rood of soulful sensitivity, his only friend the distant moon; the Modernists converted him into a Whistlerian subject for canvases devoted to form and color and line. In short, Pierrot became an alter-ego of the artist, specifically of the famously alienated artist of the nineteenth and early twentieth centuries. His physical insularity; his poignant lapses into mutism, the legacy of the great mime Deburau; his white face and costume, suggesting not only innocence but the pallor of the dead; his often frustrated pursuit of Columbine, coupled with his never-to-be-vanquished unworldly naïveté—all conspired to lift him out of the circumscribed world of the Commedia dell'Arte and into the larger realm of myth. Much of that mythic quality ("I'm Pierrot," said David Bowie: "I'm Everyman") still adheres to the "sad clown" of the postmodern era.
Origins: seventeenth century.
He is sometimes said to be a French variant of the sixteenth-century Italian Pedrolino, but the two types have little but their names ("Little Pete") and social stations in common. Both are comic servants, but Pedrolino, as a so-called first "zanni", often acts with cunning and daring, an engine of the plot in the scenarios where he appears. Pierrot, on the other hand, as a "second" "zanni", is a static character in his earliest incarnations, "standing on the periphery of the action", dispensing advice that seems to him sage, and courting—unsuccessfully—his master's young daughter, Columbine, with bashfulness and indecision.
His origins among the Italian players in France are most unambiguously traced to Molière's character, the lovelorn peasant Pierrot, in "Don Juan, or The Stone Guest" (1665). In 1673, probably inspired by Molière's success, the Comédie-Italienne made its own contribution to the Don Juan legend with an "Addendum to "The Stone Guest"", which included Molière's Pierrot. Thereafter the character—sometimes a peasant, but more often now an Italianate "second" "zanni"—appeared fairly regularly in the Italians’ offerings, his role always taken by one Giuseppe Giaratone (or Geratoni), until the troupe was banished by royal decree in 1697.
Among the French dramatists who wrote for the Italians and who gave Pierrot life on their stage were Jean Palaprat, Claude-Ignace Brugière de Barante, Antoine Houdar de la Motte, and the most sensitive of his early interpreters, Jean-François Regnard. He acquires there a very distinctive personality. He seems an anomaly among the busy social creatures that surround him; he is isolated, out of touch. Columbine laughs at his advances; his masters who are in pursuit of pretty young wives brush off his warnings to act their age. His is a solitary voice, and his estrangement, however comic, bears the pathos of the portraits—Watteau's chief among them—that we will encounter in the centuries to come.
Eighteenth century.
France.
An Italian company was called back to Paris in 1716, and Pierrot was reincarnated by the actors Pierre-François Biancolelli (son of the Harlequin of the banished troupe of players) and, after Biancolelli abandoned the role, the celebrated Fabio Sticotti (1676–1741) and his son Antoine-Jean (1715–1772). But the character seems to have been regarded as unimportant by this company, since he appears infrequently in its new plays.
His real life in the theater in the eighteenth century is to be found on the lesser stages of the capital, at its two great fairs, the Foires Saint-Germain and Saint-Laurent. There he appeared in the marionette theaters and in the motley entertainments—featuring song, dance, audience participation, and acrobatics—that were calculated to draw a crowd while sidestepping the regulations that ensured the Théâtre-Français a monopoly on "regular" dramas in Paris. Sometimes he spoke gibberish (in the so-called "pièces à la muette"); sometimes the audience itself sang his lines, inscribed on placards held aloft by hovering Cupids (in the "pièces à écriteau"). The result, far from "regular" drama, tended to put a strain on his character, and, as a consequence, the early Pierrot of the fairgrounds is a much less nuanced and rounded type than we find in the older repertoire. This holds true even when sophisticated playwrights, such as Alain-René Lesage and his collaborators, Dorneval and Fuzelier, began (around 1712) to contribute more "regular" plays to the Foires.
The broad satirical streak in Lesage often rendered him indifferent to Pierrot's character, and consequently, as the critic Vincent Barberet observes, "Pierrot is assigned the most diverse roles . . . and sometimes the most opposed to his personality. Besides making him a valet, a roasting specialist, a chef, a hash-house cook, an adventurer, just as frequently dresses him up as someone else." In not a few of the early Foire plays, Pierrot's character is therefore "quite badly defined." (For a typical farce by Lesage during these years, see his Harlequin, King of Serendib of 1713.) In the main, Pierrot's inaugural years at the Foires were rather degenerate ones.
An important factor that probably hastened his degeneration was the multiplicity of his fairground interpreters. Not only actors but also acrobats and dancers were quick to seize on his role, inadvertently reducing Pierrot to a generic type. The extent of that degeneration may be gauged by the fact that Pierrot came to be confused, apparently because of his manner and costume, with that much coarser character Gilles, as a famous portrait by Antoine Watteau attests (note title of image at right).
But in the 1720s, Pierrot at last came into his own. Antoine Galland's final volume of The "Thousand and One Nights" had appeared in 1717, and in the plots of these tales Lesage and his collaborators found inspiration, both exotic and (more importantly) coherent, for new plays. In "Achmet and Almanzine" (1728) by Lesage and Dorneval, for example, we are introduced not only to the royal society of far-off Astrakhan but also to a familiar and well-drawn servant of old—the headstrong and bungling Pierrot. It was also in the 1720s that Alexis Piron loaned his talents to the Foires, and in plays like "Trophonius's Cave" (1722) and "The Golden Ass" (1725), we meet the same engaging Pierrot of Giaratone's creation. The accomplished comic actor Jean-Baptiste Hamoche, who had worked at the Foires from 1712 to 1718, reappeared in Pierrot's role in 1721, and from that year until 1732 he "obtained, thanks to the naturalness and truth of his acting, great applause and became the favorite actor of the public." But Pierrot's triumph was short-lived. "The retirement of Hamoche in 1733", writes Barberet, "was fatal to Pierrot. After this date, we hardly ever see him appear again except in old plays."
But as he seemed to expire on the theatrical scene, he found new life in the visual arts. He, along with his fellow Commedia masks, was beginning to be "poeticized" in the early 1700s: he was being made the subject, not only of poignant folksong ("Au clair de la lune", sometimes attributed to Lully), but also of the more ambitious art of Claude Gillot ("Master André's Tomb" 1717), of Gillot's students Watteau ("Italian Actors" 1719) and Nicolas Lancret ("Italian Actors near a Fountain" 1719), of Jean-Baptiste Oudry ("Italian Actors in a Park" 1725), and of Jean-Honoré Fragonard ("A Boy as Pierrot" [1776–1780]). This development will accelerate in the next century.
England.
Before turning to that century, however, we should note that it was in this, the eighteenth, that Pierrot began to be naturalized in other countries. As early as 1673, just months after Pierrot had made his debut in the "Addendum to "The Stone Guest"", Scaramouche Tiberio Fiorilli and a troupe assembled from the Comédie-Italienne entertained Londoners with selections from their Parisian repertoire. And in 1717, Pierrot's name first appears in an English entertainment: a pantomime by John Rich entitled "The Jealous Doctor; or, The Intriguing Dame", in which the role was undertaken by a certain Mr. Griffin. Thereafter, until the end of the century, Pierrot appeared fairly regularly in English pantomimes (which were originally mute harlequinades but later evolved into the Christmas pantomimes of today; in the nineteenth century, the harlequinade was presented as a "play within a play" during the pantomime), finding his most notable interpreter in Carlo Delpini (1740–1828). His role was uncomplicated: Delpini, according to the popular theater historian, M. Willson Disher, "kept strictly to the idea of a creature so stupid as to think that if he raised his leg level with his shoulder he could use it as a gun." So conceived, Pierrot was easily and naturally displaced by the native English Clown when the latter found a suitably brilliant interpreter. It did so in 1800, when "Joey" Grimaldi made his celebrated debut in the role.
Denmark.
A more long-lasting development occurred in Denmark. In that same year, 1800, a troupe of Italian players led by Pasquale Casorti began giving performances in Dyrehavsbakken, then a well-known site for entertainers, hawkers, and inn-keepers. Casorti's son, Giuseppe (1749–1826), had undoubtedly been impressed by the Pierrots they had seen while touring France in the late eighteenth century, for he assumed the role and began appearing as Pierrot in his own pantomimes, which now had a formulaic structure (Cassander, father of Columbine, and Pierrot, his dim-witted servant, undertake a mad pursuit of Columbine and her rogue lover, Harlequin). The formula has proven enduring: Pierrot is still a fixture at Bakken, the oldest amusement park in the world, where he plays the nitwit talking to and entertaining children, and at nearby Tivoli Gardens, the second oldest, where the Harlequin and Columbine act is performed as a pantomime and ballet. Pierrot—as "Pjerrot", with his boat-like hat and scarlet grin—remains one of the parks’ chief attractions.
Germany.
Ludwig Tieck's "The Topsy-Turvy World" (1798) is an early—and highly successful—example of the introduction of the Commedia dell'Arte characters into parodic metatheater. (Pierrot is a member of the audience watching the play.)
Spain.
The penetration of Pierrot and his companions of the Commedia into Spain is documented in a painting by Goya, "Itinerant Actors" (1793). It foreshadows the work of such Spanish successors as Picasso and Fernand Pelez, who also showed strong sympathy with the lives of traveling saltimbancos.
Nineteenth century.
Pantomime of Deburau at the Théâtre des Funambules.
When, in 1762, a great fire destroyed the Foire Saint-Germain and the new Comédie-Italienne claimed the fairs’ stage-offerings (now known collectively as the Opéra-Comique) as their own, new enterprises began to attract the Parisian public, as little theaters—all but one now defunct— sprang up along the Boulevard du Temple. One of these was the Théâtre des Funambules, licensed in its early years to present only mimed and acrobatic acts. This will be the home, beginning in 1816, of Jean-Gaspard Deburau (1796–1846), the most famous Pierrot in the history of the theater, immortalized by Jean-Louis Barrault in Marcel Carné's film "Children of Paradise" (1945).
Adopting the stage-name "Baptiste", Deburau played Pierrot, from about 1819, in a number of types of comic pantomime—rustic, melodramatic, "realistic", and fantastic. He was often the servant of the heavy father (usually Cassander), his mute acting a compound of placid grace and cunning malice. His style, according to Louis Péricaud, the chronicler of the Funambules, formed "an enormous contrast with the exhuberance, the superabundance of gestures, of leaps, that ... his predecessors had employed." He altered the costume: freeing his long neck for comic effects, he dispensed with the frilled collaret; he substituted a skullcap for a hat, thereby keeping his expressive face unshadowed; and he greatly increased the amplitude of both blouse and trousers. Most importantly, the character of his Pierrot, as it evolved gradually through the 1820s, eventually parted company almost completely with the crude Pierrots—timid, sexless, lazy, and greedy—of the earlier pantomime.
With him the poet and journalist Théophile Gautier after Deburau's death, the role of Pierrot was widened, enlarged. It ended by occupying the entire piece, and, be it said with all the respect due to the memory of the most perfect actor who ever lived, by departing entirely from its origin and being denaturalized. Pierrot, under the flour and blouse of the illustrious Bohemian, assumed the airs of a master and an aplomb unsuited to his character; he gave kicks and no longer received them; Harlequin now scarcely dared brush his shoulders with his bat; Cassander would think twice before boxing his ears.
Deburau seems to have had a predilection for "realistic" pantomime—a predilection that, as we will see, led eventually to calls for Pierrot's expulsion from it. But the pantomime that had the greatest appeal to his public was the ""pantomime-arlequinade-féerie"", sometimes "in the English style" (i.e., with a prologue in which characters were transformed into the Commedia types). The action unfolded in fairy-land, peopled with good and bad spirits who both advanced and impeded the plot, which was interlarded with comically violent (and often scabrous) mayhem. As in the Bakken pantomimes, that plot hinged upon Cassander's pursuit of Harlequin and Columbine—but it was complicated, in Baptiste's interpretation, by a clever and ambiguous Pierrot. Baptiste's Pierrot was both a fool and no fool; he was Cassandre's valet but no one's servant. He was an embodiment of comic contrasts, showing
imperturbable sang-froid the words are Gautier's, artful foolishness and foolish finesse, brazen and naïve gluttony, blustering cowardice, skeptical credulity, scornful servility, preoccupied insouciance, indolent activity, and all those surprising contrasts that must be expressed by a wink of the eye, by a puckering of the mouth, by a knitting of the brow, by a fleeting gesture.
As the Gautier citations suggest, Deburau early—about 1828—caught the attention of the Romantics, and soon he was being celebrated in the reviews of Charles Nodier (Gautier's praise would follow), in an article by Charles Baudelaire on "The Essence of Laughter" (1855), and in the poetry of Théodore de Banville. A pantomime produced at the Funambules in 1828, "The Gold Dream, or Harlequin and the Miser", was widely thought to be the work of Nodier, and both Gautier and Banville wrote Pierrot playlets that were eventually produced on other stages—"Posthumous Pierrot" (1847) and "The Kiss" (1887), respectively.
"Shakespeare at the Funambules" and aftermath.
In 1842, Deburau was inadvertently responsible for translating Pierrot into the realm of tragic myth, heralding the isolated and doomed figure—often the "fin-de-siècle" artist's alter-ego—of Decadent, Symbolist, and early Modernist art and literature. In that year, Gautier, drawing upon Deburau's newly acquired audacity as a Pierrot, as well as upon the Romantics’ store of Shakespearean plots and of Don-Juanesque legend, published a "review" of a pantomime he claimed to have seen at the Funambules.
He entitled it "Shakespeare at the Funambules", and in it he summarized and analyzed an unnamed pantomime of unusually somber events: Pierrot murders an old-clothes man for garments to court a duchess, then is skewered in turn by the sword with which he stabbed the peddler when the latter's ghost lures him into a dance at his wedding. The pantomime under "review" was a fabrication (though it inspired a hack to turn it into an actual pantomime, "The Ol’ Clo's Man" , in which Deburau probably appeared—and also inspired Barrault's wonderful recreation of it in "Children of Paradise"). But it importantly marked a turning-point in Pierrot's career: henceforth Pierrot could bear comparisons with the serious over-reachers of high literature, like Don Juan or Macbeth; he could be a victim—even unto death—of his own cruelty and daring.
When Gustave Courbet drew a crayon illustration for "The Black Arm" (1856), a pantomime by Fernand Desnoyers written for another mime, Paul Legrand (see next section), the Pierrot who quakes with fear as a black arm snakes up from the ground before him is clearly a child of the Pierrot in "The Ol’ Clo's Man". So, too, are Honoré Daumier's Pierrots: creatures often suffering a harrowing anguish. In 1860, Deburau was directly credited with inspiring such anguish, when, in a novella called "Pierrot" by Henri Rivière, the mime-protagonist blames his real-life murder of a treacherous Harlequin on Baptiste's "sinister" cruelties. Among the most celebrated of pantomimes in the latter part of the century would appear sensitive moon-mad souls duped into criminality—usually by love of a fickle Columbine—and so inevitably marked for destruction (Paul Margueritte's "Pierrot, Murderer of His Wife" the mime Séverin's "Poor Pierrot" [1891; Catulle Mendès’ "Ol’ Clo's Man" , modeled on Gautier's "review").
Pantomime after Baptiste: Charles Deburau, Paul Legrand, and their successors.
Deburau's son, Jean-Charles (or, as he preferred, "Charles" [1829–1873]), assumed Pierrot's blouse the year after his father's death, and he was praised for bringing Baptiste's agility to the role. (Nadar's photographs of him in various poses are some of the best to come out of his studio—if not some of the best of the era.)
But the most important Pierrot of mid-century was Charles-Dominique-Martin Legrand, known as Paul Legrand (1816–1898; see photo at top of page). In 1839, Legrand made his debut at the Funambules as the lover Leander in the pantomimes, and when he began appearing as Pierrot, in 1845, he brought a new sensibility to the character. A mime whose talents were dramatic rather than acrobatic, Legrand helped steer the pantomime away from the old fabulous and knockabout world of fairy-land and into the realm of sentimental—often tearful—realism. In this he was abetted by the novelist and journalist Champfleury, who set himself the task, in the 1840s, of writing "realistic" pantomimes. Among the works he produced were "Marquis Pierrot" (1847), which offers a plausible explanation for Pierrot's powdered face (he begins working-life as a miller's assistant), and the "Pantomime of the Attorney" (1865), which casts Pierrot in the prosaic role of an attorney's clerk.
Legrand left the Funambules in 1853 for what was to become his chief venue, the Folies-Nouvelles, which attracted the fashionable and artistic set, unlike the Funambules’ working-class children of paradise. Such an audience was not averse to pantomimic experiment, and at mid-century "experiment" very often meant Realism. (The pre-"Bovary" Gustave Flaubert wrote a pantomime for the Folies-Nouvelles, "Pierrot in the Seraglio" , which was never produced.) Legrand often appeared in realistic costume, his chalky face his only concession to tradition, leading some advocates of pantomime, like Gautier, to lament that he was betraying the character of the type.
But it was the Pierrot as conceived by Legrand that had the greatest influence on future mimes. Charles himself eventually capitulated: it was he who played the Pierrot of Champfleury's "Pantomime of the Attorney". Like Legrand, Charles's student, the Marseilles mime Louis Rouffe (1849–1885), rarely performed in Pierrot's costume, earning him the epithet ""l'Homme Blanc"" ("The White Man"). His successor Séverin (1863–1930) played Pierrot sentimentally, as a doom-laden soul, a figure far removed from the conception of Deburau "père". And one of the last great mimes of the century, Georges Wague (1875–1965), though he began his career in Pierrot's costume, ultimately dismissed Baptiste's work as puerile and embryonic, averring that it was time for Pierrot's demise in order to make way for "characters less conventional, more human." Marcel Marceau's Bip seems a natural, if deliberate, outgrowth of these developments, walking, as he does, a concessionary line between the early fantastic domain of Deburau's Pierrot and the so-called realistic world.
Pantomime and late nineteenth-century art.
France.
In the 1880s and 1890s, the pantomime reached a kind of apogee, and Pierrot became ubiquitous. Moreover, he acquired a counterpart, Pierrette, who rivaled Columbine for his affections. (She seems to have been especially endearing to Xavier Privas, hailed in 1899 as the "prince of songwriters": several of his songs ["Pierrette Is Dead", "Pierrette's Christmas"] are devoted to her fortunes.) A Cercle Funambulesque was founded in 1888, and Pierrot (sometimes played by female mimes, such as Félicia Mallet) dominated its productions until its demise in 1898. Sarah Bernhardt even donned Pierrot's blouse for Jean Richepin's "Pierrot the Murderer" (1883).
But French mimes and actors were not the only figures responsible for Pierrot's ubiquity: the English Hanlon brothers (sometimes called the Hanlon-Lees), gymnasts and acrobats who had been schooled in the 1860s in pantomimes from Baptiste's repertoire, traveled (and dazzled) the world well into the twentieth century with their pantomimic sketches and extravaganzas featuring riotously nightmarish Pierrots. The Naturalists—Émile Zola especially, who wrote glowingly of them—were captivated by their art. Edmond de Goncourt modeled his acrobat-mimes in his "The Zemganno Brothers" (1879) upon them; J.-K. Huysmans (whose "Against Nature" would become Dorian Gray's bible) and his friend Léon Hennique wrote their pantomime "Pierrot the Skeptic" (1881) after seeing them perform at the Folies Bergère. (And, in turn, Jules Laforgue wrote his pantomime "Pierrot the Cut-Up" ["Pierrot fumiste", 1882 after reading the scenario by Huysmans and Hennique.) It was in part through the enthusiasm that they excited, coupled with the Impressionists’ taste for popular entertainment, like the circus and the music-hall, as well as the new bohemianism that then reigned in artistic quarters like Montmartre (and which was celebrated by such denizens as Adolphe Willette, whose cartoons and canvases are crowded with Pierrots)—it was through all this that Pierrot achieved almost unprecedented currency and visibility towards the end of the century.
He invaded the visual arts—not only in the work of Willette, but also in the illustrations and posters of Jules Chéret; in the engravings of Odilon Redon ("The Swamp Flower: A Sad Human Head" and in the canvases of Georges Seurat ("Pierrot with a White Pipe [Aman-Jean" "The Painter Aman-Jean as Pierrot" [1883), Léon Comerre ("Pierrot" Henri Rousseau ("A Carnival Night" [1886), Paul Cézanne ("Mardi gras and Harlequin" Fernand Pelez ("Grimaces and Miseries" a.k.a. "The Saltimbanques" [1888), Pablo Picasso ("Pierrot and Columbine" Guillaume Seignac ("Pierrot's Embrace" [1900), and Édouard Vuillard ("The Black Pierrot" 1890). The mime "Tombre" of Jean Richepin's novel "Nice People" ("Braves Gens" turned him into a pathetic and alcoholic "phantom"; Paul Verlaine imagined him as a gormandizing naïf in "Pantomime" (1869), then, like Tombre, as a lightning-lit specter in "Pierrot" (1868, pub. 1882). Laforgue put three of the "complaints" of his first published volume of poems (1885) into "Lord" Pierrot's mouth—and dedicated his next book, "The Imitation of Our Lady the Moon" (1886), completely to Pierrot and his world. (Pierrots were legion among the minor, now-forgotten poets: for samples, see Willette's journal "The Pierrot", which appeared between 1888 and 1889, then again in 1891.) In the realm of song, Claude Debussy set both Verlaine's "Pantomime" and Banville's "Pierrot" (1842) to music in 1881 (not published until 1926)—the only precedents among works by major composers being the "Pierrot" section of Telemann's "Burlesque Overture" (1717–22), Mozart's 1783 "Masquerade" (in which Mozart himself took the role of Harlequin and his brother-in-law, Joseph Lange, that of Pierrot), and the "Pierrot" section of Robert Schumann's "Carnival" (1835). Even the embryonic art of the motion picture turned to Pierrot before the century was out: he appeared, not only in early celluloid shorts (Georges Méliès's "The Nightmare" [1896, "The Magician" Alice Guy's "Arrival of Pierrette and Pierrot" [1900, "Pierrette's Amorous Adventures" Ambroise-François Parnaland's "Pierrot's Big Head/Pierrot's Tongue" [1900, "Pierrot-Drinker" ), but also in Emile Reynaud's Praxinoscope production of "Poor Pierrot" (1892), the first animated movie and the first hand-colored one.
Belgium.
Thus far the discussion has focused on the French "pierrotistes", but Pierrot's popularity was by no means confined to France. Wherever "decadence" had taken hold, there he could be found. In Belgium, where the Decadents and Symbolists were as numerous as their French counterparts, Félicien Rops depicted a grinning Pierrot who is witness to an unromantic backstage scene ("Blowing Cupid's Nose" and James Ensor painted Pierrots (and other masks) obsessively, sometimes rendering them prostrate in the ghastly light of dawn ("The Strange Masks" [1892), sometimes isolating Pierrot in their midst, his head drooping in despondency ("Pierrot's Despair" sometimes augmenting his company with a smiling, stein-hefting skeleton ("Pierrot and Skeleton in Yellow" [1893). Their countryman the poet Albert Giraud also identified intensely with the "zanni": the fifty rondels of his "Pierrot lunaire" ("Moonstruck Pierrot" ) would inspire several generations of composers (see Pierrot lunaire below), and his verse-play "Pierrot-Narcissus" (1887) offered a definitive portrait of the solipsistic poet-dreamer. The title of choreographer Joseph Hansen's 1884 ballet, "Macabre Pierrot", created in collaboration with the poet Théo Hannon, summed up one of the chief strands of the character's persona for many artists of the era.
England.
In the England of the Aesthetic Movement, Aubrey Beardsley's drawings attested profound kinship with the figure; Olive Custance (who would marry Oscar Wilde's lover, Lord Alfred Douglas) published the poem "Pierrot" in 1897; and Ernest Dowson wrote the verse-play "Pierrot of the Minute" (1897, illustrated by Beardsley), to which the composer Sir Granville Bantock would later contribute an orchestral prologue (1908). One of the gadflies of Aestheticism, W. S. Gilbert, introduced Harlequin and Pierrot as love-struck twin brothers into "Eyes and No Eyes, or The Art of Seeing" (1875), for which Thomas German Reed wrote the music. And he ensured that neither character, contrary to many an Aesthetic Pierrot, would be amorously disappointed.
In a more bourgeois vein, Ethel Wright painted "Bonjour, Pierrot!" (a greeting to a dour clown sitting disconsolate with his dog) in 1893. And the Pierrot of popular taste also spawned a uniquely English entertainment. In 1891, the singer and banjoist Clifford Essex returned from France enamored of the Pierrots he had seen there and resolved to create a troupe of English Pierrot entertainers. Thus were born the seaside Pierrots (in conical hats and sometimes black or colored costume) who, as late as the 1950s, sang, danced, juggled, and joked on the piers of Brighton and Margate and Blackpool. Obviously inspired by these troupes were the Will Morris Pierrots, named after their Birmingham founder. They originated in the Smethwick area in the late 1890s and played to large audiences in many parks, theaters, and pubs in the Midlands. It was doubtless these popular entertainers who inspired the academic Walter Westley Russell to commit "The Pierrots" (c. 1900) to canvas.
"Pierrot and Pierrette" (1896) was a specimen of early English film from the director Birt Acres. For an account of the English mime troupe The Hanlon Brothers, see France above.
Germany.
In Germany, Frank Wedekind introduced the "femme-fatale" of his first "Lulu" play, "Earth Spirit" (1895), in a Pierrot costume; and when the Austrian composer Alban Berg drew upon the play for his opera "Lulu" (unfinished; first perf. 1937), he retained the scene of Lulu's meretricious pierroting. In a similarly (and paradoxically) revealing spirit, the painter Paul Hoecker put cheeky young men into Pierrot costumes to ape their complacent burgher elders, smoking their pipes ("Pierrots with Pipes" 1900) and swilling their champagne ("Waiting Woman" 1895). (See also Pierrot lunaire below.)
Italy.
Canio's Pagliaccio in the famous opera (1892) by Leoncavallo is close enough to a Pierrot to deserve a mention here. Much less well-known is the musical "mimodrama" of Vittorio Monti, "Noël de Pierrot" a.k.a. "A Clown's Christmas" (1900), its score set to a pantomime by Fernand Beissier, one of the founders of the Cercle Funambulesque. (Monti would go on to claim his rightful fame by celebrating another spiritual outsider, much akin to Pierrot—the Gypsy. His "Csárdás" 1904, like "Pagliacci", has found a secure place in the standard musical repertoire.)
North America.
Pierrot and his fellow masks were late in coming to America, which, unlike England, Russia, and the countries of continental Europe, had had no early exposure to Commedia dell'Arte. The Hanlon-Lees made their first U.S. appearance in 1858, and their subsequent tours, well into the twentieth century, of scores of cities throughout the country accustomed their audiences to their fantastic, acrobatic Pierrots. But the Pierrot that would leave the deepest imprint upon the American imagination was that of the French and English Decadents, a creature who quickly found his home in the so-called little magazines of the 1890s (as well as in the poster-art that they spawned). One of the earliest and most influential of these in America, "The Chap-Book" (1894–98), which featured a story about Pierrot by the aesthete Percival Pollard in its second number, was soon host to Beardsley-inspired Pierrots drawn by E.B. Bird and Frank Hazenplug. (The Canadian poet Bliss Carman should also be mentioned for his contribution to Pierrot's dissemination in mass-market publications like "Harper's".) Like most things associated with the Decadence, such exotica discombobulated the mainstream American public, which regarded the little magazines in general as "freak periodicals" and declared, through one of its mouthpieces, "Munsey's Magazine", that "each new representative of the species is, if possible, more preposterous than the last."
The fin-de-siècle world in which this Pierrot resided was clearly at odds with the reigning American Realist and Naturalist aesthetic (though such figures as Ambrose Bierce and John LaFarge were mounting serious challenges to it). It is in fact jarring to find the champion of American prose Realism, William Dean Howells, introducing "Pastels in Prose" (1890), a volume of French prose-poems translated by Stuart Merrill and containing a Paul Margueritte pantomime, "The Death of Pierrot", with words of warm praise (and even congratulations to each poet for failing “to saddle his reader with a moral”). So uncustomary was the French Aesthetic viewpoint that, when Pierrot made an appearance in an eponymous pantomime (1893) by Alfred Thompson, set to music by the American composer Laura Sedgwick Collins, "The New York Times" covered it as an event, even though it was only a student production. It was found to be “pleasing” because, in part, it was “odd”. Not until the first decade of the next century, when the great (and popular) fantasist Maxfield Parrish worked his magic on the figure, would Pierrot be comfortably naturalized in America.
Central and South America.
Inspired by the French Symbolists, especially Verlaine, Rubén Darío, the Nicaraguan poet widely acknowledged as the founder of Spanish-American literary Modernism ("modernismo"), placed Pierrot ("sad poet and dreamer") in opposition to Columbine ("fatal woman", the arch-materialistic "lover of rich silk garments, golden jewelry, pearls and diamonds") in his 1898 prose-poem "The Eternal Adventure of Pierrot and Columbine".
Russia.
In the last year of the century, Pierrot appeared in a Russian ballet, "Harlequin's Millions" a.k.a. "Harlequinade" (1900), its libretto and choreography by Marius Petipa, its music by Riccardo Drigo, its dancers the members of St. Petersburg's Imperial Ballet. It would set the stage for the later and greater triumphs of Pierrot in the productions of the Ballets Russes.
19th-century legacy.
The Pierrot bequeathed to the twentieth century had acquired a rich and wide range of personae. He was the naïve butt of practical jokes and amorous scheming (Gautier); the prankish but innocent waif (Banville, Verlaine, Willette); the narcissistic dreamer clutching at the moon, which could symbolize many things, from spiritual perfection to death (Giraud, Laforgue, Willette, Dowson); the frail, neurasthenic, often doom-ridden soul (Richepin, Beardsley); the clumsy, though ardent, lover, who wins Columbine's heart, or murders her in frustration (Margueritte); the cynical and misogynous dandy, sometimes dressed in black (Huysmans/Hennique, Laforgue); the Christ-like victim of the martyrdom that is Art (Giraud, Willette, Ensor); the androgynous and unholy creature of corruption (Richepin, Wedekind); the madcap master of chaos (the Hanlon-Lees); the purveyor of hearty and wholesome fun (the English pier Pierrots)—and various combinations of these. Like the earlier masks of Commedia dell’Arte, Pierrot now knew no national boundaries. Thanks to the international gregariousness of Modernism, he would soon be found everywhere.
Pierrot and Modernism.
Pierrot played a seminal role in the emergence of Modernism in the arts. He was a key figure in every art-form except architecture. With respect to poetry, T. S. Eliot's "breakthrough work", "The Love Song of J. Alfred Prufrock" (1915), owed its existence to the poems of Jules Laforgue, whose ""ton 'pierrot'"" informed all of Eliot's early poetry. (Laforgue, he said, "was the first to teach me how to speak, to teach me the poetic possibilities of my own idiom of speech.") Prufrock is a Pierrot transplanted to America. As for fiction, William Faulkner began his career as a chronicler of Pierrot's amorous disappointments and existential anguish in such little-known works as his play "The Marionettes" (1920) and the verses of his "Vision in Spring" (1921)—works that were an early and revealing declaration of the novelist's "fragmented state". (Some critics have argued that Pierrot stands behind the semi-autobiographical Nick Adams of Faulkner's fellow-Nobel laureate Ernest Hemingway, and another contends that James Joyce's Stephen Dedalus, again an avatar of his own creator, also shares the same parentage.) As far as music is concerned, it would be difficult to find a historian of Modernism who does not place Arnold Schoenberg's 1912 song-cycle "Pierrot lunaire" at the very pinnacle of High-Modernist achievement. And in ballet, Igor Stravinsky's Petrushka (1911), in which the traditionally Pulcinella-like clown wears the heart of Pierrot, is often argued to have attained the same stature. Students of Modernist painting and sculpture are familiar with Pierrot (in many different attitudes, from the ineffably sad to the ebulliently impudent) through the masterworks of his acolytes, including Pablo Picasso, Juan Gris, Georges Rouault, Salvador Dalí, Max Beckmann, August Macke, Paul Klee, Jacques Lipchitz—the list is very long (see Visual arts below). As for the drama, Pierrot was a regular fixture in the plays of the Little Theatre Movement (Edna St. Vincent Millay's "Aria da Capo" Robert Emmons Rogers' "Behind a Watteau Picture" [1918, Blanche Jennings Thompson's "The Dream Maker" ), which nourished the careers of such important Modernists as Eugene O'Neill, Susan Glaspell, and others. Finally, in film, the most beloved of its early comic heroes was the Little Tramp of Charlie Chaplin, who conceived the character, in Chaplin's words, as "a sort of Pierrot".
As the diverse incarnations of the 19th-century Pierrot would predict, the hallmarks of the Modernist Pierrot are his ambiguity and complexity. One of his earliest appearances was in Alexander Blok's "The Puppet Show" (1906), called by one theater-historian "the greatest example of the harlequinade in Russia". Vsevolod Meyerhold, who both directed the first production and took on the role, dramatically emphasized the multifacetedness of the character: according to one spectator, Meyerhold’s Pierrot was "nothing like those familiar, falsely sugary, whining Pierrots. Everything about him is sharply angular; in a hushed voice he whispers strange words of sadness; somehow he contrives to be caustic, heart-rending, gentle: all these things yet at the same time impudent." In her own notes to "Aria da Capo", Edna St. Vincent Millay makes it clear that her Pierrot is not to be played as a cardboard stock type:Pierrot sees clearly into existing evils and is rendered gaily cynical by them; he is both too indolent and too indifferent to do anything about it. Yet in several lines of the play his actual unhappiness is seen,—for instance, "Moon's just a word to swear by", in which he expresses his conviction that all beauty and romance are fled from the world. At the end of the play the line, "Yes, and yet I dare say he is just as dead", must not be said flippantly or cynically, but slowly and with much philosophic concentration on the thought.Even Chaplin's Little Tramp, conceived broadly as a comic and sentimental type, exhibits a wide range of aspirations and behaviors. "You know," Chaplin alleges to have told Mack Sennett, after first having assumed the character,this fellow is many-sided, a tramp, a gentleman, a poet, a dreamer, a lonely fellow, always hopeful of romance and adventure. He would have you believe he is a scientist, a musician, a duke, a polo player. However, he is not above picking up cigarette butts or robbing a baby of its candy. And, of course, if the occasion warrants it, he will kick a lady in the rear—but only in extreme anger!
Early 20th century (1901-1950): notable works.
In this section, with the exception of productions by the Ballets Russes (which will be listed alphabetically by title) and of musical settings of Pierrot lunaire (which will be discussed under a separate heading), all works are identified by artist; all artists are grouped by nationality, then listed alphabetically. Multiple works by artists are listed chronologically.
Late twentieth/early twenty-first centuries (1951- ): notable works.
In the latter half of the twentieth century, Pierrot continued to appear in the art of the Modernists—or at least of the long-lived among them: Chagall, Ernst, Goleminov, Hopper, Miró, Picasso—as well as in the work of their younger followers, such as Gerard Dillon, Indrek Hirv, and Roger Redgate. And when film arrived at a pinnacle of auteurism in the 1950s and '60s, aligning it with the earlier Modernist aesthetic, some of its most celebrated directors—Bergman, Fellini, Godard—turned naturally to Pierrot.
But Pierrot's most prominent place in the late twentieth century, as well as in the early twenty-first, has been in popular, not High Modernist, art. As the entries below tend to testify, Pierrot is most visible (as in the eighteenth century) in unapologetically popular genres—in circus acts and street-mime sketches, TV programs and Japanese "anime", comic books and graphic novels, children's books and "young adult" fiction (especially fantasy and, in particular, vampire fiction), Hollywood films, and pop and rock music. He generally assumes one of three avatars: the sweet and innocent child (as in the children's books), the poignantly lovelorn and ineffectual being (as, notably, in the Jerry Cornelius novels of Michael Moorcock), or the somewhat sinister and depraved outsider (as in David Bowie's various experiments, or Rachel Caine's vampire novels, or the S&M lyrics of the English rock group Placebo).
The format of the lists that follow is the same as that of the previous section, except for the Western pop-music singers and groups. These are listed alphabetically by first name, not last (e.g., "Stevie Wonder", not "Wonder, Stevie").
"Pierrot lunaire".
The fifty poems that were published by Albert Giraud (born Emile Albert Kayenbergh) as "Pierrot lunaire: Rondels bergamasques" in 1884 quickly attracted composers to set them to music, especially after they were translated, somewhat freely, into German (1892) by the poet and dramatist Otto Erich Hartleben. The best known and most important of these settings is the atonal song-cycle derived from twenty-one of the poems (in Hartleben's translation) by Arnold Schoenberg in 1912, i.e., his Opus 21: "Dreimal sieben Gedichte aus Albert Girauds" Pierrot lunaire ("Thrice-Seven Poems from Albert Giraud's" Pierrot lunaire—Schoenberg was numerologically superstitious). The impact of this work on the musical world has proven to be virtually immeasurable. It has led, among other things, to ensemble groups' appropriating Pierrot's name, such as the English Pierrot Players (1967–70), and to a number of projects—such as the Schoenberg Institute's of 1987 and the composer Roger Marsh's of 2001-2002—that have been devised to pay homage to Schoenberg and, at the same time, to extend his avant-garde reach, thereby bringing both Hartleben's and Giraud's complete cycles to full musical fruition.
But the loony Pierrot behind those cycles has invaded worlds well beyond those of composers, singers, and ensemble-performers. Theatrical groups such as the Opera Quotannis have brought Pierrot's Passion to the dramatic stage; dancers such as Glen Tetley have choreographed it; poets such as Wayne Koestenbaum have derived original inspiration from it. It has been translated into still more distant media by painters, such as Paul Klee; fiction-writers, such as Helen Stevenson; filmmakers, such as Bruce LaBruce; and graphic-novelists, such as Antoine Dodé. A passionately sinister Pierrot Lunaire has even shadowed DC Comics' Batman. The inextinguishable vibrancy of Giraud's creation is aptly honored in the title of a song by the British rock-group The Soft Machine: "Thank You Pierrot Lunaire" (1969).
Carnival and Pierrot Grenade.
Pierrot, usually in the company of Pierrette or Columbine, appears among the revelers at many carnivals of the world, most notably at the festivities of Uruguay. His name suggests kinship with the Pierrot Grenade of Trinidad and Tobago Carnival, but the latter seems to have no connection with the French clown. Pierrot Grenade is apparently descended from an earlier creature indeed called "Pierrot"—but this name seems to be an outsider's "correction" of the regional "Pay-wo" or "Pié-wo", probably a corruption of "Pay-roi" or "country king," which describes the stature to which the figure aspired. This "Pierrot"—extinct by the mid-twentieth century—was richly garbed, proud of his mastery of English history and literature (Shakespeare especially), and fiercely pugnacious when encountering his likes. Pierrot Grenade, on the other hand, whose name suggests descent from the humble island of Grenada (and who seems to have evolved as a hick cousin of his namesake), dresses in ragged strips of colored cloth, sometimes adorned with cheap trinkets; he has little truck with English culture, but displays his talents (when not singing and dancing) in speechifying upon issues of the day and spelling long words in ingenious ways. A feeble fighter, he spars mainly with his tongue—formerly in Creole or French Patois, when those dialects were common currency—as he circulates through the crowds. Around the mid-twentieth century, he traveled about in pairs or larger groups, contending for supremacy among his companions, but by the dawn of the twenty-first century, he had become rather solitary, a vestige of his former gregarious self.

</doc>
<doc id="51128" url="https://en.wikipedia.org/wiki?curid=51128" title="James White (author)">
James White (author)

James White (7 April 1928 – 23 August 1999) was a Northern Irish author of science fiction novellas, short stories and novels. He was born in Belfast and returned there after spending some early years in Canada. After a few years working in the clothing industry, he worked at Short Brothers Ltd., an aircraft company based in Belfast, from 1965 until taking early retirement in 1984 as a result of diabetes. White married Margaret Sarah Martin, another science fiction fan, in 1955 and the couple had three children. He died of a stroke.
He became a fan of science fiction in 1941 and co-wrote two fan magazines, from 1948 to 1953 and 1952 to 1965. Encouraged by other fans, White began publishing short stories in 1953, and his first novel was published in 1957. His best-known novels were the twelve of the Sector General series, the first published in 1962 and the last after his death. White also published nine other novels, two of which were nominated for major awards, unsuccessfully.
White abhorred violence, and medical and other emergencies were the sources of dramatic tension in his stories. Some critics regarded him as a second-rank writer, who occasionally produced first-rank works, and felt his plots and writing could be formulaic. However, the "Sector General" series is regarded as defining the genre of medical science fiction, and as introducing a memorable crew of aliens. Although missing winning the most prestigious honours four times, White gained other awards for specific works and for contributions to science fiction. He was also Guest-of-Honour of several conventions.
Biography.
James White was born in Belfast, Northern Ireland, on 7 April 1928, and spent part of his early life in Canada. He was educated in Belfast at St. John's Primary School (1935–1941) and St. Joseph's Technical Secondary School (1942–1943). As a teenager he lived with foster parents. He wanted to study medicine but financial circumstances prevented this. Between 1943 and 1965 he worked for several Belfast tailoring firms and then as assistant manager of a Co-op department store. He married Margaret ("Peggy") Sarah Martin, another science fiction fan, in 1955 and the couple had three children: daughter Patricia, and sons Martin and Peter. White later worked for the aeroplane builders Short Brothers Ltd. as a technical clerk (1965–1966), publicity assistant (1966–1968), and publicity officer (1968–1984).
He became a science fiction fan in 1941, attracted particularly by the works of E. E. "Doc" Smith, which featured good aliens as well as evil ones, and of Robert A. Heinlein, many of whose stories concern ordinary people. In 1947 he met another Irish fan, Walter A. ("Walt") Willis (1919–1999), and the two helped to produce the fan magazines "Slant" (1948–1953) and "Hyphen" (1952–1965), which featured stories and articles by noted authors including John Brunner, A. Bertram Chandler, and Bob Shaw. In 2004 both White and Willis were nominated for the retrospective Hugo Award for Best Fan Writer of 1953, although neither won. -->White said that he started writing stories because the "Slant" team felt that "Astounding Science Fiction" was too dominated by prophesies of nuclear doom, and his friends dared him to write the kind of story that they all liked to read. He said that getting published was fairly easy during the 1950s, as the World War II restrictions on paper were ended, and there were at least 12 science magazines in Britain and about 40 in the United States. His first published short story, "Assisted Passage", a parody of 1950s Anglo-Australian emigration policies, appeared in the January 1953 edition of the magazine "New Worlds". Further stories appeared in "New Worlds" during the next few years, but White's attempt to access the more lucrative American market by submitting stories to "Astounding Science Fiction" stalled after the publication of "The Scavengers". White later said that his optimism about inter-species relations was unpalatable to "Astounding"'s xenophobic editor, John W. Campbell. As a result, White's work was little-known outside the UK until the 1960s.
In 1957, Ace Books published White's first novel, "The Secret Visitors", which included locations in Northern Ireland. The book had previously been serialised in "New Worlds" with the title "Tourist Planet". Ace Books' science fiction editor, Donald A. Wollheim, thought the original ending was too tame and suggested that White should insert an all-out space battle just after the climactic courtroom scene. In November the same year "New Worlds" published White's novelette "Sector General", and editor John ("Ted") Carnell requested more stories set in the same universe, founding the series for which White is known best. White gained "a steady following" for his "scientifically accurate" stories, which were notable examples of hard science fiction in "New Worlds", despite the magazine's promotion of literary "New Wave" science fiction during the 1960s.
White kept his job with Short Brothers and wrote in the evenings, as his stories did not make enough money for him to become a full-time author. In 1980 he taught a literature course at a Belfast branch of the Workers Educational Association.
When diabetes had severely impaired his eyesight, he took early retirement in 1984 and relocated to the north Antrim resort town of Portstewart, where he continued to write. For many years he was a Council Member of the British Science Fiction Association and, with Harry Harrison and Anne McCaffrey, a Patron of the Irish Science Fiction Association.
White was also a strong pacifist. He died of a stroke on 23 August 1999, while his novels "Double Contact" and "" were being prepared for publication. His wife Peggy, son Martin, and daughter Patricia survived him.
Published works.
Sector General.
The Sector General series consists of 12 books published originally between 1962 ("Hospital Station") and 1999 ("Double Contact"). Additional short stories set in the Sector General Universe ("Countercharm", "Tableau", "Occupation: Warrior", and "Custom Fitting") appear in other collections by White.
Sector General is a gigantic multi-species hospital space station founded as a peace-making project by two heroes from opposite sides of humanity's only full interstellar war. The hospital accommodates patients and staff from dozens of species, with different environmental requirements, behaviours and ailments. Initially most of the stories concern the career of Doctor Conway, who rises from junior surgeon to Diagnostician. In the fourth book the Galactic Federation decides that the emergency service which the hospital offers to victims of space accidents and planetary catastrophes is the most effective means of making peaceful contact with new spacefaring species, which allows the series to expand its range of plots, characters and settings. The seventh and later books each have a different and usually alien viewpoint character, which gave them "considerable new pep". They also expand the range of issues beyond purely medical, and in Mike Resnick's opinion treat issues such as guilt and forgiveness better than most science fiction.
The series defined the subgenre of multi-species medical stories, and was "the first explicitly pacifist space opera" series, when much of contemporary space opera from the USA was notably military.
Other novels.
"Second Ending" (1961), which White described as "about the last man on Earth" but with "an upbeat ending", was short-listed for a Hugo Award. 
"The Escape Orbit" (1964; title "Open Prison" in the UK), which was short-listed for a Nebula Award, chronicles the efforts of human prisoners of war to survive after being dumped on a hostile planet without tools or weapons. 
"All Judgement Fled" (1968), which won the 1979 Europa prize, was described by Mike Resnick as his favourite among White's novels and as ""Rendezvous with Rama" done right."
White's other novels not part of the Sector General series are:
Collections and short stories.
The title story of White's collection "Deadly Litter" (1964) anticipated the dangers of space debris although there had been only a few orbital missions. "The White Papers" was produced by NESFA (New England Science Fiction Association) to commemorate White's being the Guest-of-Honour at the 1996 Worldcon, and includes short stories and fan magazine articles by White, plus sections of Gary Louie's guide to the Sector General series. Among the stories, "Custom Fitting" (1976) was short-listed for a Hugo Award, and "Sanctuary" (1988) won an Analog Analytical Laboratory Award. His short story "Un-Birthday Boy", published in the magazine Analog in 1996 but not in a collection or anthology, was short-listed for a Hugo Award.
Other collections include:
Critical appraisal.
Paul Kincaid described White as a second-rank writer who occasionally produced first-rank works, and attracted a devoted but not wide audience. Kincaid noted that his plots were often formulaic and his writing employed a predictable set of techniques and mannerisms, along with a "studied quietness." On the other hand, John Clute wrote that "in the depiction of goodness may lie the real genius of James White," Mike Resnick described the Sector General series' characters as "the most memorable crew of aliens ever created," and Graham Andrews wrote that White's aliens are really alien, not just human minds with exotic biologies. Michael Ashley commented that the setting of the television series "" is reminiscent of Sector General, and Mark Leeper noted similarities between Sector General's setting and that of television's "Babylon 5". Chris Aylott wrote that White's plot construction and writing, including occasionally clumsy exposition, are typical of the Golden Age of science fiction in the 1930s, '40s, and '50s.
Algis Budrys concluded his review of "The Watch Below" with "... this is very nice writing when considered simply as prose and as an attempt to involve the reader's emotions." However, when reviewing "All Judgment Fled" he wrote, "I suspect that he generates so much tension within himself while writing a book that he literally cannot bear to come to grips with crucial scenes."
White said of his approach to producing stories, "Of course, the plot idea must come first – but the characters soon take over," and compared it to using a compass rather than a map. He explained that he was drawn to medical themes by two factors: they offered opportunities for dramatic tension without war; and he had wanted to become a doctor, but had to go to work instead. His avoidance of violent themes is as strong in his non-medical stories as in the Sector General series.
None of White's works won Hugo or Nebula Awards, although four were short-listed. However, he won a Europa Prize in 1979, an "Analog" Analytical Laboratory Award in 1988 and a Science Fiction Chronicle Reader Award in 1996. In 1998, White received the NESFA (New England Science Fiction Association) Edward E. Smith Memorial Award ("Skylark Award") for contributions to science fiction, named after a story by one of his inspirations, E. E. "Doc" Smith, and appreciated this so much that he donated his complete collection of "Slant" magazines to NESFA. The next year he was inducted into the European Science Fiction Society's Hall of Fame. White was Guest-of-Honour at many conventions including: the 1971 and 1985 Novacons in the United Kingdom; three Beneluxcons (Belgium, Netherlands and Luxembourg); the 1998 Octocon (Ireland); a Nicon (Northern Ireland); and the 1996 Worldcon.
Since 2000 the James White Award has been presented for the best short story by a non-professional writer. The judges are professional authors and editors, and have included Mike Resnick, Orson Scott Card, Lois McMaster Bujold, Peter F. Hamilton, Christopher Priest and Robert Sheckley.

</doc>
<doc id="51129" url="https://en.wikipedia.org/wiki?curid=51129" title="Nash embedding theorem">
Nash embedding theorem

The Nash embedding theorems (or imbedding theorems), named after John Forbes Nash, state that every Riemannian manifold can be isometrically embedded into some Euclidean space. Isometric means preserving the length of every path. For instance, bending without stretching or tearing a page of paper gives an isometric embedding of the page into Euclidean space because curves drawn on the page retain the same arclength however the page is bent.
The first theorem is for continuously differentiable ("C"1) embeddings and the second for analytic embeddings or embeddings that are smooth of class "Ck", 3 ≤ "k" ≤ ∞. These two theorems are very different from each other; the first one has a very simple proof and leads to some very counterintuitive conclusions, while the proof of the second one is very technical but the result is not that surprising.
The "C"1 theorem was published in 1954, the "Ck"-theorem in 1956. The real analytic theorem was first treated by Nash in 1966; his argument was simplified considerably by . (A local version of this result was proved by Élie Cartan and Maurice Janet in the 1920s.) In the real analytic case, the smoothing operators (see below) in the Nash inverse function argument can be replaced by Cauchy estimates. Nash's proof of the "Ck"- case was later extrapolated into the h-principle and Nash–Moser implicit function theorem. A simplified proof of the second Nash embedding theorem was obtained by who reduced the set of nonlinear partial differential equations to an elliptic system, to which the contraction mapping theorem could be applied.
Nash–Kuiper theorem ("C"1 embedding theorem).
Theorem. Let ("M","g") be a Riemannian manifold and ƒ: "Mm" → R"n" a short "C"∞-embedding (or immersion) into Euclidean space R"n", where "n" ≥ "m"+1. Then for arbitrary ε > 0 there is an embedding (or immersion) ƒε: "Mm" → R"n" which is
In particular, as follows from the Whitney embedding theorem, any "m"-dimensional Riemannian manifold admits an isometric "C"1-embedding into an "arbitrarily small neighborhood" in 2"m"-dimensional Euclidean space.
The theorem was originally proved by John Nash with the condition "n" ≥ "m"+2 instead of "n" ≥ "m"+1 and generalized by Nicolaas Kuiper, by a relatively easy trick.
The theorem has many counterintuitive implications. For example, it follows that any closed oriented Riemannian surface can be "C"1 isometrically embedded into an arbitrarily small ε-ball in Euclidean 3-space (for small formula_1 there is no such "C"2-embedding since from the formula for the Gauss curvature an extremal point of such an embedding would have curvature ≥ ε−2). And, there exist "C"1 isometric embeddings of the hyperbolic plane in R3.
"C""k" embedding theorem.
The technical statement appearing in Nash's original paper is as follows: if "M" is a given "m"-dimensional Riemannian manifold (analytic or of class "Ck", 3 ≤ "k" ≤ ∞), then there exists a number "n" (with "n" ≤ "m"(3"m"+11)/2 if "M" is a compact manifold, or "n" ≤ "m"("m"+1)(3"m"+11)/2 if "M" is a non-compact manifold) and an injective map ƒ: "M" → R"n" (also analytic or of class "Ck") such that for every point "p" of "M", the derivative dƒ"p" is a linear map from the tangent space "TpM" to R"n" which is compatible with the given inner product on "TpM" and the standard dot product of R"n" in the following sense:
for all vectors "u", "v" in "TpM". This is an undetermined system of partial differential equations (PDEs).
In a later conversation with Robert M. Solovay, Nash mentioned of a fault in the original argument in deriving the sufficing value of the dimension of the embedding space for the case of non-compact manifolds.
The Nash embedding theorem is a global theorem in the sense that the whole manifold is embedded into R"n". A local embedding theorem is much simpler and can be proved using the implicit function theorem of advanced calculus in a coordinate neighborhood of the manifold. The proof of the global embedding theorem relies on Nash's far-reaching generalization of the implicit function theorem, the Nash–Moser theorem and Newton's method with postconditioning. The basic idea of Nash's solution of the embedding problem is the use of Newton's method to prove the existence of a solution to the above system of PDEs. The standard Newton's method fails to converge when applied to the system; Nash uses smoothing operators defined by convolution to make the Newton iteration converge: this is Newton's method with postconditioning. The fact that this technique furnishes a solution is in itself an existence theorem and of independent interest. There is also an older method called Kantorovich iteration that uses Newton's method directly (without the introduction of smoothing operators).

</doc>
<doc id="51130" url="https://en.wikipedia.org/wiki?curid=51130" title="College of Sorbonne">
College of Sorbonne

The College of Sorbonne () was a theological college of the University of Paris, founded in 1253 by Robert de Sorbon (1201–1274), after whom it was named. With the rest of the Paris colleges, it was suppressed during the French Revolution. It was restored in 1808 but finally closed in 1882. In recent times it came to refer to the group of academic faculties of the University of Paris, as opposed to the professional faculties of law and medicine. It is also used to refer to the main building of the University of Paris in the 5th arrondissement of Paris, which houses several faculties created when the University was divided up into thirteen autonomous universities in 1970.
Robert de Sorbon was the son of peasants from the village of Sorbon in the Ardennes, who had become a master of theology, a "chanoine" of the Cathedral of Notre Dame de Paris, and the confessor and chaplain of King Louis IX (Saint Louis). At the time that he founded his college, the University of Paris had already been in existence for half a century, and already had thousands of students. Obtaining a higher degree in theology could take as long as twenty years, and therefore required considerable financial support. Students who belonged to the religious orders of the Franciscans and Dominicans, or from the large monasteries of Cluny or Citeaux, received housing and board from their religious orders, but independent students did not. Sorbon founded his college to provide housing and board for poorer students of theology who did not have such support.
Sorbon purchased several houses on Rue Coupe-Gueule (now Rue de la Sorbonne) and made them into lodging for students. The college opened in 1257 with about twenty students, called "socii". As the college grew, Sorbon provided a library containing over a thousand volumes by 1292, the largest in the university, and a chapel. 
The Sorbonne became the most distinguished theological institution in France, and its doctors were frequently called upon to render opinions on important ecclesiastical and theological issues. In 1470, the Sorbonne had one of the first printing presses in France. It was particularly active in the effort to suppress heresy and the spread of Protestant doctrines. Its students included Cardinal Richelieu, who studied there from 1606 to 1607. Richelieu became Proviseur, or administrator of the college on 29 August 1622. Between 1635 and 1642, Richelieu renovated the Sorbonne; he consolidated the Sorbonne with two smaller colleges, and built a complex of new buildings, including a domed chapel, around a large courtyard. Richelieu left a large part of his fortune and his library to the Sorbonne, and he was buried in the chapel. Only the chapel remains of the Richelieu era buildings.
The Sorbonne was closed to students in 1791 during the French Revolution. For a brief time, under Robespierre, the chapel became a Temple of Reason. Napoleon turned the college buildings into studios for artists. In 1822, it became the home of the faculties of letters, sciences and theology of the University of Paris.
In 1885, as part of the Third Republic policy of separation of church and state, the theology faculty was officially closed. The old buildings of the Sorbonne, with the exception of the chapel, were demolished and the new Sorbonne building, designed by Henri Paul Nénot, opened in 1889, the centenary of the French Revolution. It contained a large amphitheater, reception halls and meeting rooms, the offices of the rector of the University of Paris, and the faculties of arts and sciences. The chapel was no longer used for religious services, but only for official ceremonies and exhibitions.
In 1971, as a result of the riots of demonstrations of May 1968, the University of Paris was broken up into thirteen independent faculties. The New Sorbonne building became the home of the Universities of Paris I, II, III, IV, V, the "École Nationale des Chartes", and the "École pratique des hautes études".
Foundation.
Robert de Sorbon was a native of Le Réthelois, a distinguished professor and famous preacher who lived from 1201 till 1274. Sorbon found that there was a defect in the primitive organization of the University of Paris. The two principal mendicant orders—the Dominicans and the Franciscans—each had colleges at Paris where they delivered lectures which extern students could attend without fee.
Robert de Sorbon decided that the university should also provide free instruction, so that it could compete with the religious orders. Further, he believed the society of professors should follow the practices of the cenobitic life, except in vows. His important work was made possible by the high esteem in which de Sorbon was held at Paris, together with his intellectual brilliance, great generosity, and the assistance of his friends. The foundation dates from 1257 or the beginning of 1258. Guillaume de Saint-Amour, Gérard d'Abbeville, Henry of Ghent, Guillaume des Grez, Odo or Eudes of Douai, Chrétien de Beauvais, Gérard de Reims, Nicolas de Bar were among the most illustrious scholars connected either with the first chairs in the Sorbonne, or with the first association that constituted it. These savants were already attached to the university staff.
Organization.
The constitution of the society as conceived by De Sorbon was simple: an administrator ("provisor"), associates ("socii"), and guests ("hospites"). The provisor was the head; nothing could be done without consulting him; he installed the members selected by the society, and confirmed the statutes drawn up by it; he had to provide for everything.
The associates formed the body of the society. To be admitted to it, the candidate was required to have taught a course of philosophy. There were two kinds of associates, the "bursaires" and the "pensionnaires". The latter paid forty (Paris) pounds a year; the former were provided for by the house. The burse could be granted only to persons not having an income of forty (Paris) pounds. There was a "primus inter pares", the prior, who presided over all internal affairs of the house.
Doctors and bachelors were alike eligible, but, owing to the number of the latter, the custom rapidly grew up of selecting only bachelors. Other persons were candidates for admission to the society rather than members of it. From the material and intellectual point of view, they enjoyed the same privileges as the members: board, lodging, books, spiritual and scholastic exercises but they had no votes. When they had fulfilled the condition of teaching philosophy, they were admissible as members. The course of studies lasted ten years, during which time their burses continued; but if, at the end of ten years, they had not given proof of their ability, either as teachers or as preachers, they had to give up their burse.
History.
The ordinary lectures were public, and consequently were attended by students who belonged to neither of the divisions of the society. The doctors and bachelors were authorized to give shelter to other poor pupils. Besides the work of the classroom, there was the duty of preaching or labouring in the parishes. In preparation for this, the associates, on certain days, had to deliver sermons or conferences ("collationes") to the community. The purely spiritual side was not forgotten. Conferences, usually delivered by the prior, on this important part of the Christian and priestly life were given especially to the interns.
For twenty years the ability of the administrator, or provisor, corresponded to the foreseeing devotedness of the founder. This stretch of time showed the effectiveness of the administrative measures which De Sorbon had adopted. He had written down the rules in thirty-eight articles. This rule was directed towards the maintenance of common life, from silence in the refectory, to simplicity of authorized dress. As circumstances permitted, about 1271 De Sorbon added a literary college: this was the Collège de Calvi or the "little Sorbonne".
The constitution which Robert de Sorbon gave to his college lasted for centuries. If Claude Héméré (1574–1650, librarian of the Sorbonne) saw in the project the conception of a powerful intellect, "Hoc primus in lycaeo Parisiensi vidit Robertus", its realization became a model college for others. The expression "Pauvres maîtres et étudiants en théologie" seems to emphasize the two primary characteristics of the society: equality in poverty, an equality so perfect between masters and pupils that it designated them by a common name; the poverty of the pupils, since most of them were bursaires; the poverty of the masters, since, content with what was strictly necessary, they renounced all other professional remuneration. This equality was always maintained with scrupulous care; the Sorbon repeated as an axiom, "Omnes nos sumus socii et aequales", and referred to the college as "pauperem nostram Sorbonem".
From the outset the college enjoyed the favour of the Holy See. Pope Alexander IV (1259) urged the French bishops to support it, Urban IV (1262) recommended it to the goodwill of the whole Christian world, and Clement IV (1268) granted it papal approbation. Wealthy benefactors provided it with ample endowment. A high standard of scholarship was maintained and the severity of the "actus Sorbonnicus", or examination for degrees, including the defence of the "thesis Robertina", became proverbial. The professorial corps was highly respected. From all parts of Europe, theological and political questions were sent to it for solution.
In 1470 the Sorbonne introduced the art of printing into France by calling to Paris three of Gutenberg's associates, Gering, Friburger, and Crantz. Among its principal patrons and benefactors was Cardinal Richelieu, who held for a time the office of provisor and who, in 1635, laid the cornerstone of an edifice to be built at his expense for the use of the college. He was buried in the church of the Sorbonne, where his tomb is still preserved.
The doctors of the college were loyal defenders of the Catholic faith against the inroads of Protestantism and the Enlightenment. As other teachers of theology in the university became members of the Sorbonne, by the beginning of the sixteenth century, its staff was practically identical with the university faculty. De Sorbon had created a library. It expanded rapidly, due to numerous gifts.
On the other hand, the professors gave their support to Gallicanism and obliged their members to subscribe to the "four articles". This attitude naturally weakened the prestige of the Sorbonne as a theological school. Ecclesiastical students had to seek their education in the seminaries. The Sorbonne itself was suppressed by decree of 5 April 1792, after the French Revolution.
Napoleon restored it in 1808 as the theological faculty of the newly organized university. It did not, however, regain its former standing or influence, though it continued in existence until 1882, when it was finally suppressed. In 1884 the construction of the present building was begun and it was completed in 1889. At the beginning of the 20th century, it was occupied by the various departments of letters and science which formed the "École des Hautes Etudes".

</doc>
<doc id="51134" url="https://en.wikipedia.org/wiki?curid=51134" title="Leonardo Bruni">
Leonardo Bruni

Leonardo Bruni (or "Leonardo Aretino") (c. 1370 – March 9, 1444) was an Italian humanist, historian and statesman, often recognized as the most important humanist historian of the early Renaissance. He has been called the first modern historian. He was the earliest person to write using the three-period view of history: Antiquity, Middle Ages, and Modern. The dates Bruni used to define the periods are not exactly what modern historians use today, but he laid the conceptual groundwork for a tripartite division of history.
Biography.
Leonardo Bruni was born in Arezzo, Tuscany circa 1370. Bruni was the pupil of political and cultural leader Coluccio Salutati, whom he succeeded as chancellor of Florence, and under whose tutelage he developed his ideation of civic humanism. He also served as apostolic secretary to four popes (1405-1414). Bruni's years as chancellor—1410 to 1411 and again from 1427 to his death in 1444—were plagued by warfare. Though he occupied one of the highest political offices, Bruni was relatively powerless compared to the Albizzi and Medici families. Historian Arthur Field has identified Bruni as an apparent plotter against Cosimo de' Medici in 1437 (see below). Bruni died in 1444 in Florence and was succeeded in office by Carlo Marsuppini.
Significance.
Bruni's most notable work is "Historiarum Florentini populi libri XII" (History of the Florentine People, 12 Books), which has been called the first modern history book. While it probably was not Bruni's intention to secularize history, the three period view of history is unquestionably secular and for that Bruni has been called the first modern historian. The foundation of Bruni's conception can be found with Petrarch, who distinguished the classical period from later cultural decline, or "tenebrae" (literally "darkness"). Bruni argued that Italy had revived in recent centuries and could therefore be described as entering a new age.
One of Bruni's most famous works is "New Cicero", a biography of the Roman statesman Cicero. He was also the author of biographies in Italian of Dante and Petrarch. It was Bruni who used the phrase "studia humanitatis", meaning the study of human endeavors, as distinct from those of theology and metaphysics, which is where the term humanists comes from.
As a humanist Bruni was essential in translating into Latin many works of Greek philosophy and history, such as Aristotle and Procopius. Bruni's translations of Aristotle's "Politics" and "Nicomachean Ethics", as well as the pseudo-Aristotelean "Economics", were widely distributed in manuscript and in print. His use of Aelius Aristides' "Panathenicus (Panegyric to Athens)" to buttress his republican theses in the "Panegyric to the City of Florence" (c. 1401) was instrumental in bringing the Greek historian to the attention of Renaissance political philosophers (see Hans Baron's "The Crisis of the Early Italian Renaissance" for details). He also wrote a short treatise in Greek on the Florentine constitution.
Bruni died in Florence in 1444, and is buried in a wall tomb by Bernardo Rossellino in the Basilica of Santa Croce, Florence.

</doc>
<doc id="51135" url="https://en.wikipedia.org/wiki?curid=51135" title="Portland Institute for Contemporary Art">
Portland Institute for Contemporary Art

The Portland Institute for Contemporary Art (PICA) is a contemporary performance and visual arts organization in Portland in the U.S. state of Oregon. It sponsors the annual Time-Based Art Festival (TBA Festival) each September.
History.
PICA was founded in 1996 by Kristy Edmunds, formerly the Director of the Portland Art Museum's "Art on the Edge" program. Edmunds left PICA in 2005 to become art director for the Melbourne International Arts Festival. The gallery was housed at Boora Architects from its founding until about 2001, and then moved to the headquarters of Wieden + Kennedy in Northwest Portland. PICA remained at Wieden + Kennedy, where they received discounted rent, until 2012 when they moved to Downtown Portland on Tenth Avenue. The new space had of space after $300,000 in renovations.

</doc>
<doc id="51137" url="https://en.wikipedia.org/wiki?curid=51137" title="SoftICE">
SoftICE

SoftICE is a kernel mode debugger for Microsoft Windows up to Windows XP. Crucially, it is designed to run underneath Windows such that the operating system is unaware of its presence. Unlike an application debugger, SoftICE is capable of suspending all operations in Windows when instructed. For driver debugging this is critical due to how hardware is accessed and the kernel of the operating system functions. Because of its low-level capabilities, SoftICE is also popular as a software cracking tool.
Microsoft offers two kernel-mode debuggers, WinDbg and KD, for no charge. However, the full capabilities of WinDbg and KD are available only when two interlinked computers are used. SoftICE therefore is an exceptionally useful tool for difficult driver related development. The last released version was for Windows XP. 
Older versions exist for DOS and compatible operating systems. SoftICE was originally produced by a company called NuMega, and was subsequently acquired by Compuware in 1997, which in turn sold the property to Micro Focus in 2009. Currently, Micro Focus owns the source code and patents, but is not actively maintaining SoftICE.
Naming.
"Soft" refers to software, and the "ICE" part of the name is an allusion to in-circuit emulator.
History.
The original SoftICE for DOS was written in 1987 by NuMega founders Frank Grossman and Jim Moskun. The program, written in 80386 assembly language, played the role of an operating system and ran software in virtual 8086 mode. It sold for $386.
SoftICE/W (for Windows) was developed in the 1990s, and was instrumental in the Writing of "Undocumented Windows", by Andrew Schulman, David Maxey and Matt Pietrek. SoftICE/W was derived from an earlier, lesser known product, SoftICE for Netware (32-bit protected mode). One of the key advantages it had over Microsoft's debuggers is that it enabled single machine debugging, rather than requiring a second machine to be connected over a serial port. 
The principal developers of SoftICE were Dom Basile ('Mr. SoftICE'), Tom Guinther (Kitchen Sink, Symbol Engine), Gerald Ryckman (Video Drivers and Kitchen Sink), Ray Hsu (Video Drivers W95), and Dan Babcock (SoftICE/NT 3.1/3.5: Universal Video Driver, Symbol Engine), with contributions by a variety of NuMega developers including Frank Grossman, Jim Moskun and Matt Pietrek.
In 1998 the codebase for SoftICE/95 was ported to run on the Windows NT platform.
Newer versions of SoftICE patch deep into Microsoft Windows. As such, old versions of SoftICE are rarely compatible with new versions of Windows. Compuware therefore offered SoftICE as a subscription so that it could be kept up to date and in sync with the latest Microsoft Windows version.
It used to be offered as part of Compuware's DriverStudio package but was discontinued in April 2006.
Termination.
As of April 3, 2006 the DriverStudio product family has been discontinued because of "a variety of technical and business issues as well as general market conditions". Maintenance support was offered until March 31, 2007.
Anti-SoftICE measures.
Software vendors have put in place a wide range of countermeasures to protect themselves from people employing SoftICE as a tool to analyse software.
For example, here is code some vendors used to detect the presence of SoftICE running in the same machine as an early countermeasure:
More and better such measures have evolved since. While most of them can only deter the less experienced and determined hackers, SoftICE is no longer a tool of choice for someone new to analysing software.
Today vendor's defenses are based on more sophisticated packers/protectors, e.g. Themida, Armadillo or ASProtect which pack the program code and tamper with entry point addresses so it is hard to find the program's original entry point (OEP). That is also true for the program's import address table (IAT). However tools for hiding SoftICE are also available, such as IceStealth and IceExt for Windows NT, or Icedump and IcePatch for Windows 9x.
Alternatives.
A commercial kernel-level debugger called Syser claims to continue where SoftICE left off.
A shareware but free to use OllyDbg is a 32-bit assembler-level debugger from Oleh Yuschuk. However, it can only be used for user-mode debugging.
An open source kernel debugger similar to SoftICE named "Rasta Ring 0 Debugger" (RR0D) is available. It provides low-level debugging for Microsoft Windows, Linux, OpenBSD, NetBSD, and FreeBSD. This project does not seem to be actively maintained. , the last change in its GitHub source code repository occurred in December 2008.
LinICE is another kernel-level debugger with a SoftICE look and feel. , it also has not been updated for several years.
HyperDBG is a kernel-level debugger leveraging hardware-assisted virtualization. , it was last updated in May 2010.
A debugger called BugChecker is a 32-bit single-host kernel debugger for Windows 2000 and XP, developed and made available as open source for educational purposes. BugChecker allows users to trace into both user and kernel code, both on uniprocessor and multiprocessor versions of Windows 2000 and XP.

</doc>
<doc id="51138" url="https://en.wikipedia.org/wiki?curid=51138" title="Mail">
Mail

The mail or post is a system for physically transporting documents and other small packages, as well as a term for the postcards, letters, and parcels themselves. A postal service can be private or public, though many governments place restrictions on private systems. Since the mid-19th century national postal systems have generally been established as government monopolies with a fee on the article prepaid. Proof of payment is often in the form of adhesive postage stamps, but postage meters are also used for bulk mailing. Modern private postal systems are typically distinguished from national postal agencies by the names "courier" or "delivery service".
Postal authorities often have functions other than transporting letters. In some countries, a postal, telegraph and telephone (PTT) service oversees the postal system, as well as hasa authority over telephone and telegraph systems. Some countries' postal systems allow for savings accounts and handle applications for passports. The Universal Postal Union (UPU), established in 1874, includes 192 member countries and sets the rules for international mail exchanges.
Etymology.
The word "mail" comes from the Medieval English word "male", referring to a travelling bag or pack. It was spelled that way until the 17th century, and is distinct from the word male. The French have a similar word, "malle" for a trunk or large box, and "mála" is the Irish term for a bag. In the 17th century, the word "mail" began to appear as a reference for a bag that contained letters: "bag full of letter" (1654). Over the next hundred years the word "mail" began to be applied strictly to the letters themselves, and the sack as the "mailbag". In the 19th century the British usually referred to "mail" as being letters that were being sent abroad (i.e. on a ship), and "post" as letters that were for localized delivery; in the UK the Royal Mail delivers the "post", while in the USA the US Postal Service delivers the "mail". The term "email" (short for ""e"lectronic "mail"") first appeared in the 1970s. The term "snail-mail" is a retronym to distinguish it from the quicker email. Various dates have been given for its first use.
"Post" is derived from Medieval French "poste", which ultimately stems from the past participle of the Latin verb "ponere" ("to lay down or place") and the city of Post in Western Iran where Cyrus the Great commissioned the building of the first roads expressly for the purpose of delivering mail across the Persian Empire.
History.
The practice of communication by written documents carried by an intermediary from one person or place to another almost certainly dates back nearly to the invention of writing. However, development of formal postal systems occurred much later. The first documented use of an organized courier service for the diffusion of written documents is in Egypt, where Pharaohs used couriers for the diffusion of their decrees in the territory of the State (2400 BC). The earliest surviving piece of mail is also Egyptian, dating to 255 BC.
Persia.
The first credible claim for the development of a real postal system comes from Ancient Persia, but the point of invention remains in question. The best documented claim (Xenophon) attributes the invention to the Persian King Cyrus the Great (550 BC), who mandated that every province in his kingdom would organize reception and delivery of post to each of its citizens. He also negotiated with neighbouring countries to do the same and had roads built from the city of Post in Western Iran all the way up to the city of Hakha in the East. Other writers credit his successor Darius I of Persia (521 BC). Other sources claim much earlier dates for an Assyrian postal system, with credit given to Hammurabi (1700 BC) and Sargon II (722 BC). Mail may not have been the primary mission of this postal service, however. The role of the system as an intelligence gathering apparatus is well documented, and the service was (later) called "angariae", a term that in time came to indicate a tax system. The Old Testament (Esther, VIII) makes mention of this system: Ahasuerus, king of Medes, used couriers for communicating his decisions.
The Persian system worked on stations (called Chapar-Khaneh), where the message carrier (called Chapar) would ride to the next post, whereupon he would swap his horse with a fresh one, for maximum performance and delivery speed. Herodotus described the system in this way: ""It is said that as many days as there are in the whole journey, so many are the men and horses that stand along the road, each horse and man at the interval of a day's journey; and these are stayed neither by snow nor rain nor heat nor darkness from accomplishing their appointed course with all speed"". The verse prominently features on New York's James Farley Post Office, although it has been slightly rephrased to "Neither snow nor rain nor heat nor gloom of night stays these couriers from the swift completion of their appointed rounds".
India.
The economic growth and political stability under the Mauryan empire (322–185 BC) saw the development of impressive civil infrastructure in ancient India. The Mauryans developed early Indian mail service as well as public wells, rest houses, and other facilities for the common public. Common chariots called "Dagana" were sometimes used as mail chariots in ancient India. Couriers were used militarily by kings and local rulers to deliver information through runners and other carriers. The postmaster, the head of the intelligence service, was responsible for ensuring the maintenance of the courier system. Couriers were also used to deliver personal letters.
In South India, the Wodeyar dynasty (1399—1947) of the Kingdom of Mysore used mail service for espionage purposes thereby acquiring knowledge related to matters that took place at great distances.
By the end of the 18th century, the postal system in India had reached impressive levels of efficiency. According to British national Thomas Broughton, the Maharaja of Jodhpur sent daily offerings of fresh flowers from his capital to Nathadvara (a distance of 320 km), and they arrived in time for the first religious Darshan at sunrise. Later this system underwent complete modernization when the British Raj established its full control over India. The Post Office Act XVII of 1837 provided that the Governor-General of India in Council had the exclusive right of conveying letters by post for hire within the territories of the East India Company. The mails were available to certain officials without charge, which became a controversial privilege as the years passed. On this basis the Indian Post Office was established on October 1, 1837.
China.
Chinese sources often claim mail or postal systems dating back to the Xia or Shang dynasties, which would make their service the oldest in the world. The earliest credible system of couriers was initiated by the Han Dynasty (206 BC–AD 220), who had relay stations every 30 li along major routes.
The Tang dynasty recorded 1,639 posthouses, including maritime offices, employing around 20,000 people. The system was administered by the Ministry of War and private correspondence was forbidden from the network. The Ming network had 1,936 posthouses every 60 li along major routes, with fresh horses available every 10 li between them. The postal network was a major part of the corruption in the later part of the dynasty. The Qing, prior to the foreign occupation and reorganization of the Imperial Mail, operated 1,785 posthouses throughout their lands.
Rome.
The first well-documented postal service was that of Rome. Organized at the time of Augustus Caesar (62 BC–AD 14), the service was called "cursus publicus" and was provided with light carriages ("rhedæ") pulled by fast horses. By the time of Diocletian, a parallel service was established with two-wheeled carts ("birolæ") pulled by oxen. This service was reserved for government correspondence. Yet another service for citizens was later added.
Mongol Empire.
Genghis Khan installed an empire-wide messenger and postal station system named "Örtöö" within the Mongol Empire. During the Yuan Dynasty under Kublai Khan, this system also covered the territory of China. Postal stations were used not only for the transmission and delivery of official mail but were also available for traveling officials, military men, and foreign dignitaries. These stations aided and facilitated the transport of foreign and domestic tribute specifically and the conduct of trade in general.
By the end of Kublai Khan's rule, there were more than 1400 postal stations in China alone, which in turn had at their disposal about 50,000 horses, 1,400 oxen, 6,700 mules, 400 carts, 6,000 boats, more than 200 dogs, and 1,150 sheep.
The stations were apart and had reliable attendants working for the mail service. Foreign observers, such as Marco Polo, have attested to the efficiency of this early postal system.
Other systems.
Another important postal service was created in the Islamic world by the "caliph" Mu'awiyya; the service was called "barid", for the name of the towers built to protect the roads by which couriers traveled.
Well before the Middle Ages and during them, homing pigeons were used for pigeon post, taking advantage of a singular quality of this bird, which when taken far from its nest is able to find its way home due to a particularly developed sense of orientation. Messages were then tied around the legs of the pigeon, which was freed and could reach its original nest.
Mail has been transported by quite a few other methods throughout history, including dogsled, ski, balloon, rocket, mule, pneumatic tubes, and even submarine.
Charlemagne extended to the whole territory of his empire the system used by Franks in northern Gaul and connected this service with that of "missi dominici".
Many religious orders had a private mail service. Notably, the Cistercians had one which connected more than 6,000 abbeys, monasteries, and churches. The best organization, however, was created by the Knights Templar. The newly instituted universities also had their private services, starting from Bologna (1158).
Widespread illiteracy was accommodated through the service of scribes. Illiterates who needed to communicate dictated their messages to a scribe, another profession now quite generally disappeared.
In 1505, Holy Roman Emperor Maximilian I established a postal system in the Empire, appointing Franz von Taxis to run it. The Thurn und Taxis family, then known as Tassis, had operated postal services between Italian city states from 1290 onward. Following the abolition of the Empire in 1806, the Thurn-und-Taxis Post system continued as a private organisation into the postage stamp era before being absorbed into the postal system of the new German Empire after 1871.
Postal reforms.
In the United Kingdom, prior to 1840 the postal system was expensive, confusing and seen as corrupt. Letters were paid for by the recipient rather than the sender, and were charged according to the distance the letter had travelled and the number of sheets of paper it contained. Sir Rowland Hill reformed the postal system based on the concepts of penny postage and pre payment. In his proposal Hill also called for official pre-printed envelopes and adhesive postage stamps as alternative ways of getting the sender to pay for the postage, at a time when prepayment was optional, which led to the invention of the postage stamp, the Penny Black.
Modern transportation and technology.
The postal system was important in the development of modern transportation. Railroads carried railway post offices. During the 20th century, air mail became the transport of choice for inter-continental mail. Postmen started to utilize mail trucks. The handling of mail became increasingly automated.
The Internet came to change the conditions for physical mail. Email (and in recent years social networking sites) became a fierce competitor to physical mail systems, but online auctions and Internet shopping opened new business opportunities as people often get items bought online through the mail.
Modern mail.
Modern mail is organized by national and privatized services, which are reciprocally interconnected by international regulations, organizations and international agreements. Paper letters and parcels can be sent to almost any country in the world relatively easily and cheaply. The Internet has made the process of sending letter-like messages nearly instantaneous, and in many cases and situations correspondents use electronic mail where previously they would have used letters. The volume of paper mail sent through the US Postal Service has declined by more than 15% since its peak at 213 billion pieces per annum in 2006.
Organization.
Some countries have organized their mail services as public limited liability corporations without a legal monopoly.
The worldwide postal system comprising the individual national postal systems of the world's self-governing states is co-ordinated by the Universal Postal Union, which among other things sets international postage rates, defines standards for postage stamps and operates the system of International Reply Coupons.
In most countries a system of codes has been created (referred to as "ZIP codes" in the United States, "postcodes" in the United Kingdom and Australia, and "postal codes" in most other countries), in order to facilitate the automation of operations. This also includes placing additional marks on the address portion of the letter or mailed object, called "bar coding." Bar coding of mail for delivery is usually expressed either by a series of vertical bars, usually called POSTNET coding, or a block of dots as a two-dimensional barcode. The "block of dots" method allows for the encoding of proof of payment of postage, exact routing for delivery, and other features.
The ordinary mail service was improved in the 20th century with the use of planes for a quicker delivery. The world's first scheduled airmail post service took place in the United Kingdom between the London suburbs of Hendon and Windsor, Berkshire, on 9 September 1911. Some methods of airmail proved ineffective, however, including the United States Postal Service's experiment with rocket mail.
Receipt services were made available in order to grant the sender a confirmation of effective delivery.
Payment.
Worldwide the most common method of prepaying postage is by buying an adhesive postage stamp to be applied to the envelope before mailing; a much less common method is to use a postage-prepaid envelope. Franking is a method of creating postage-prepaid envelopes under licence using a special machine. They are used by companies with large mail programs, such as banks and direct mail companies.
In 1998, the U.S. Postal Service authorised the first tests of a secure system of sending digital franks via the Internet to be printed out on a PC printer, obviating the necessity to license a dedicated franking machine and allowing companies with smaller mail programs to make use of the option; this was later expanded to test the use of personalised postage. The service provided by the U.S. Postal Service in 2003 allows the franks to be printed out on special adhesive-backed labels.
In 2004 the Royal Mail in the United Kingdom introduced its "SmartStamp" Internet-based system, allowing printing on ordinary adhesive labels or envelopes. Similar systems are being considered by postal administrations around the world.
When the pre-paid envelope or package is accepted into the mail by an agent of the postal service, the agent usually indicates by means of a cancellation that it is no longer valid for pre-payment of postage. The exceptions are when the agent forgets or neglects to cancel the mailpiece, for stamps that are pre-cancelled and thus do not require cancellation and for, in most cases, metered mail. (The "personalised stamps" authorized by the USPS and manufactured by Zazzle and other companies are in fact a form of meter label and thus do not need to be cancelled.)
Privacy and censorship.
Documents should generally not be read by anyone other than the addressee; for example, in the United States of America it is a violation of federal law for anyone other than the addressee and the government to open mail. There are exceptions however: executives often assign secretaries or assistants the task of handling their mail; and postcards do not require opening and can be read by anyone. For mail contained within an envelope, there are legal provisions in some jurisdictions allowing the recording of identities of sender and recipient.
The privacy of correspondence is guaranteed by the constitutions of Mexico and Brazil, and is alluded to in the European Convention on Human Rights and the Universal Declaration of Human Rights. The control of the contents inside private citizens' mail is censorship and concerns social, political, and legal aspects of civil rights. International mail and packages are subject to customs control, with the mail and packages are often surveyed and their contents sometimes are edited out (or even in).
There have been cases over the millennia of governments opening and copying or photographing the contents of private mail. Subject to the laws in the relevant jurisdiction, correspondence may be openly or covertly opened, or the contents determined via some other method, by the police or other authorities in some cases relating to a suspected criminal conspiracy, although black chambers (largely in the past, though there is apparently some continuance of their use today) opened and open letters extralegally.
The mail service may be allowed to open the mail if neither addressee nor sender can be located, in order to attempt to locate either. Mail service may also open the mail to inspect if it contains materials that are hazardous to transport or violates local laws.
While in most cases mail censorship is exceptional, military mail to and from soldiers on active deployment is often subject to surveillance. In active fighting, censorship may be especially strict to hide tactical secrets, prevent low morale from bad news, etc.
Rise of electronic correspondence.
Modern alternatives, such as the telegraph, telephone, telex, facsimile, and email, have reduced the attractiveness of paper mail for many applications. These modern alternatives have some advantages: in addition to their speed, they may be more secure, e.g., because the general public can not learn the address of the sender or recipient from the envelope, and occasionally traditional items of mail may fail to arrive, e.g. due to vandalism to mailboxes, unfriendly pets, and adverse weather conditions. Mail carriers due to perceived hazards or inconveniences, may refuse, officially or otherwise, to deliver mail to a particular address (for instance, if there is no clear path to the door or mailbox). On the other hand, traditional mail avoids the possibility of computer malfunctions and malware, and the recipient does not need to print it out if he wishes to have a paper copy, though he would need to scan it if he wishes to have a digital copy.
Physical mail is still widely used in business and personal communications for such reasons as legal requirements for signatures, requirements of etiquette, and the requirement to enclose small physical objects.
Since the advent of email, which is almost always much faster, the postal system has come to be referred to in Internet slang by the retronym "snail mail". Occasionally, the term "white mail" or "the PaperNet" has also been used as a neutral term for postal mail.
Mainly during the 20th century, experimentation with hybrid mail has combined electronic and paper delivery. Electronic mechanisms include telegram, telex, "facsimile" (fax), email, and short message service (SMS). There have been methods which have combined mail and some of these newer methods, such as INTELPOST, which combined facsimile transmission with overnight delivery. These vehicles commonly use a mechanical or electro-mechanical standardised writing (typing), that on the one hand makes for more efficient communication, while on the other hand makes impossible characteristics and practices that traditionally were in conventional mail, such as calligraphy.
This epoch is undoubtedly mainly dominated by mechanical writing, with a general use of no more of half a dozen standard typographic fonts from standard keyboards. However, the increased use of typewritten or computer-printed letters for personal communication and the advent of email have sparked renewed interest in calligraphy, as a letter has become more of a "special event". Long before e-mail and computer-printed letters, however, decorated envelopes, rubber stamps and artistamps formed part of the medium of mail art.
In the 2000s (decade) with the advent of eBay and other online auction sites and online stores, postal services in industrialized nations have seen a major shift to item shipping. This has been seen as a boost to the system's usage in the wake of lower paper mail volume due to the accessibility of e-mail.
Online post offices have emerged to give recipients a means of receiving traditional correspondence mail in a scanned electronic format.
Collecting.
Postage stamps are also object of a particular form of collecting. Stamp collecting as been a very popular hobby. In some cases, when demand greatly exceeds supply, their commercial value on this specific market may become enormously greater than face value, even after use. For some postal services the sale of stamps to collectors who will never use them is a significant source of revenue; for example, stamps from Tokelau, South Georgia & South Sandwich Islands, Tristan da Cunha, Niuafo´ou and many others. Stamp collecting is commonly known as philately, although strictly the latter term refers to the study of stamps.
Another form of collecting regards postcards, a document written on a single robust sheet of paper, usually decorated with photographic pictures or artistic drawings on one of the sides, and short messages on a small part of the other side, that also contained the space for the address. In strict philatelic usage, the postcard is to be distinguished from the postal card, which has a pre-printed postage on the card. The fact that this communication is visible by other than the receiver often causes the messages to be written in jargon.
Letters are often studied as an example of literature, and also in biography in the case of a famous person. A portion of the New Testament of the Bible is composed of the Apostle Paul's epistles to Christian congregations in various parts of the Roman Empire. See below for a list of famous letters.
A style of writing, called "epistolary," tells a fictional story in the form of the correspondence between two or more characters.
A makeshift mail method after stranding on a deserted island is a message in a bottle.
Deregulation.
Numerous countries, including Sweden (1 January 1993), New Zealand (1998 and 2003), Germany (2005 and 2007) and Argentina have opened up the postal services market to new entrants. In the case of New Zealand Post Limited, this included (from 2003) its right to be the sole New Zealand postal administration member of the Universal Postal Union, thus the ending of its monopoly on stamps bearing the name New Zealand.
Types of mail.
Letters.
Letter-sized mail constitutes the bulk of the contents sent through most postal services. These are usually documents printed on A4 (210×297 mm), Letter-sized (8.5×11 inches), or smaller paper and placed in envelopes.
Handwritten correspondence, while once a major means of communications between distant people, is now used less frequently due to the advent of more immediate means of communication, such as the telephone or e-mail. Traditional letters, however, are often considered to harken back to a "simpler time" and are still used when someone wishes to be deliberate and thoughtful about his or her communication. An example would be a letter of sympathy to a bereaved person.
Bills and invoices are often sent through the mail, like regular billing correspondence from utility companies and other service providers. These letters often contain a self-addressed envelope that allows the receiver to remit payment back to the company easily. While still very common, many people now opt to use online bill payment services, which eliminate the need to receive bills through the mail. Paperwork for the confirmation of large financial transactions is often sent through the mail. Many tax documents are as well.
New credit cards and their corresponding personal identification numbers are sent to their owners through the mail. The card and number are usually mailed separately several days or weeks apart for security reasons.
Bulk mail is mail that is prepared for bulk mailing, often by presorting, and processing at reduced rates. It is often used in direct marketing and other advertising mail, although it has other uses as well. The senders of these messages sometimes purchase lists of addresses (which are sometimes targeted towards certain demographics) and then send letters advertising their product or service to all recipients. Other times, commercial solicitations are sent by local companies advertising local products, like a restaurant delivery service advertising to their delivery area or a retail store sending their weekly advertising circular to a general area. Bulk mail is also often sent to companies' existing subscriber bases, advertising new products or services.
First-class.
First-class mail in the US includes postcards, letters, large envelopes (flats), and small packages, providing each piece weighs 13 ounces or less. Delivery is given priority over second-class (newspapers and magazines), third class (bulk advertisements), and fourth-class mail (books and media packages). First-class mail prices are based on both the shape and weight of the item being mailed. Pieces over 13 ounces can be sent as Priority Mail. As of 2011 42% of first-class mail arrived the next day, 27% in two days, and 31% in three. The USPS expected that changes to the service in 2012 would cause about 51% to arrive in two days and most of the rest in three.
In the UK, First Class letters are simply a priority option over Second Class, at a slightly higher cost. Royal Mail aims (but does not guarantee) to deliver all First Class letters the day after postage.
Registered and recorded mail.
Registered mail allows the location and in particular the correct delivery of a letter to be tracked. It is usually considerably more expensive than regular mail, and is typically used for valuable items. Registered mail is constantly tracked through the system.
Recorded mail is handled just like ordinary mail with the exception that it has to be signed for on receipt. This is useful for legal documents where proof of delivery is required.
In the United Kingdom recorded delivery mail (branded as "signed for" by the Royal Mail) is covered by The Recorded Delivery Services Act 1962. Under this legislation any document which its relevant law requires service by registered post can also be lawfully served by recorded delivery. This act states that any recorded delivery item is deemed to have been delivered at the instant it is posted if; (a) the item is delivered and signed for at the delivery address or handed over and signed for the at local sorting office (see (c)); (b) delivery is refused by any person occupying the address or (c) if the item is not collected from the sorting office within seven days following a non delivery because there is no reply to the postman and he leaves a collection card. The sorting office will return the item to the sender after the seventh day. The sender should retain the item unopened as proof that the item has been delivered (at least in law if not in fact). Although much case law has attempted to undermine the provisions of the Act, it has done little but reinforce the point.
Repositionable notes.
The United States Postal Service introduced a test allowing "repositionable notes" (for example, 3M's Post-it notes) to be attached to the outside of envelopes and bulk mailings, afterwards extending the test for an unspecified period.
Postal cards and postcards.
Postal cards and postcards are small message cards which are sent by mail unenveloped; the distinction often, though not invariably and reliably, drawn between them is that "postal cards" are issued by the postal authority or entity with the "postal indicia" (or "stamp") preprinted on them, while postcards are privately issued and require affixing an adhesive stamp (though there have been some cases of a postal authority's issuing non-stamped postcards). Postcards are often printed to promote tourism, with pictures of resorts, tourist attractions or humorous messages on the front and allowing for a short message from the sender to be written on the back. The postage required for postcards is generally less than postage required for standard letters; however, certain technicalities such as their being oversized or having cut-outs, may result in payment of the first-class rate being required.
Postcards are also used by magazines for new subscriptions. Inside many magazines are postage-paid subscription cards that a reader can fill out and mail back to the publishing company to be billed for a subscription to the magazine. In this fashion, magazines also use postcards for other purposes, including reader surveys, contests or information requests.
Postcards are sometimes sent by charities to their members with a message to be signed and sent to a politician (e.g. to promote fair trade or third world debt cancellation).
Other mail services.
Larger envelopes are also sent through the mail. These are often composed of a stronger material than standard envelopes and are often used by businesses to transport documents that may not be folded or damaged, such as legal documents and contracts. Due to their size, larger envelopes are sometimes charged additional postage.
Packages are often sent through some postal services, usually requiring additional postage than an average letter or postcard. Many postal services have limitations as to what a package may or may not contain, usually placing limits or bans on perishable, hazardous or flammable materials. Some hazardous materials in limited quantities may be shipped with appropriate markings and packaging, like an ORM-D label. Additionally, as a result of terrorism concerns, the U.S. Postal Service subjects their packages to numerous security tests, often scanning or x-raying packages for materials that might be found in biological materials or mail bombs.
Newspapers and magazines are also sent through postal services. Many magazines are simply placed in the mail normally (but in the U.S., they are printed with a special bar code that acts as pre-paid postage - see POSTNET), but many are now shipped in shrinkwrap to protect the loose contents of the magazine. During the second half of the 19th century and the first half of the 20th century, newspapers and magazines were normally posted using wrappers with a stamp imprint.
Hybrid mail, sometimes referred to as L-mail, is the electronic lodgement of mail from the mail generator’s computer directly to a Postal Service provider. The Postal Service provider is then able to use electronic means to have the mail piece sorted, routed and physically produced at a site closest to the delivery point. It is a type of mail growing in popularity with some Post Office operations and individual businesses venturing into this market. In some countries, these services are available to print and deliver emails to those who are unable to receive email, such as the elderly or infirm. Services provided by Hybrid mail providers are closely related to that of mail forwarding service providers.
See also.
Components of a postal system:

</doc>
<doc id="51142" url="https://en.wikipedia.org/wiki?curid=51142" title="William Riker">
William Riker

William Thomas "Will" Riker, played by Jonathan Frakes, is a fictional character in the "Star Trek" universe appearing primarily as a main character in '. Throughout the series and the series of films, he is the "Enterprise" first officer, and briefly captain, until he accepts command of the USS "Titan" at the end of '.
Casting.
Frakes went to seven auditions over six weeks before being cast as Riker. Frakes stated: "I started with the cattle call, then the casting director, the producer, then other directors, to Gene Roddenberry, and then through the Paramount execs, including the vice-president himself and the heads of television."
Depiction.
For the first two seasons, Riker is portrayed as a bold, confident and sometimes arrogant, ambitious young officer; however, over time Riker's character becomes more reserved, as experience teaches him the wisdom of a patient, careful approach. He becomes comfortable on the "Enterprise", repeatedly turning down offers of his own command, and he learns to cherish the company of his fellow officers. Nonetheless, Riker retains a willingness to occasionally disregard the chain of command. Riker is usually referred to as "Will", although in early first-season episodes of TNG he is sometimes called "Bill" by Deanna Troi. He is also usually (and informally) called "Number One" by Captain Picard, because of his position as first officer on the "Enterprise".
Riker's background is first explored in the second-season episode "The Icarus Factor". In the episode, Riker's estranged father, Kyle, visits the "Enterprise" to offer his son the command of the USS "Aries", which Riker refuses. We learn that Riker grew up in Valdez, Alaska on Earth; that his mother, Elizabeth (Betty), died when he was two years old; and that he was raised by his father until the age of 15, when he left home. In the episode, Riker had not spoken with his father for 15 years, but they manage to partially mend their relationship over a game of martial-arts sparring called Anbo-jitsu. In the episode "Lower Decks" a waiter at Ten Forward mistakenly states that Riker is Canadian. According to the "Voyager" episode "Death Wish" (which Riker made a guest appearance in), Riker's distant ancestors also lived in the United States: during the American Civil War, his ancestor Colonel Thaddeus Riker fought on the Union side, as an officer in the 102nd New York Infantry Regiment during the Atlanta Campaign.
In the two-part episode "" Riker takes command of the "Enterprise", assuming the rank of captain through a field promotion and orchestrates Picard's rescue. This episode also explores the idea of Riker being unwilling to take chances since he had grown comfortable in his role as First Officer aboard the Enterprise. By the end of the episode, when he orders the Enterprise to fire on former Captain Picard, now Locutus of Borg, Riker has grown into a more confident leader. The sixth-season episode "" reveals that Will Riker was duplicated long ago by a transporter malfunction. The "second" Riker takes the name "Thomas", which is revealed to be William Riker's middle name. In the seventh-season episode "", Riker must confront his former commanding officer, Admiral Erik Pressman, over a cover-up related to the destruction of the USS "Pegasus".
Before the beginning of the series, Riker was involved in a romantic relationship with Counselor Troi on her home planet Betazed. They often refer to each other as "imzadi", a Betazoid term of endearment meaning "beloved". The novel "Imzadi" takes place before the beginning of the series and explores the history of the relationship between the two characters. The two characters are close friends throughout the series, but their relationship does not resume until "", the third "Star Trek" film set in the "Next Generation" era, although Thomas Riker, the duplicate created by a transporter malfunction, attempts to respark their relationship in "Second Chances". The following movie, "Star Trek Nemesis", begins with their wedding on board the "Enterprise"-E. At the start of the film, Riker finally accepts a promotion to Captain and an offer to command the USS "Titan"; during the movie's final scenes he bids Picard, and the "Enterprise", farewell.
Riker was originally scripted as a much more serious, by-the-book officer—by the middle episodes of the first season, however, it was felt that he was too "official", and his character was toned down and became more of a ladies' man. Although Riker was clean-shaven for the first season, he grew a beard at the start of the second season that later would become something of a trademark. Frakes had grown a beard between seasons, and Gene Roddenberry asked him to keep it, because he thought it made Riker look more nautical. 
Guest appearances.
Frakes appeared in dual roles in "Second Chances", a TNG episode in which it was established that Riker had a "twin" created years earlier by a transporter malfunction. Frakes appeared as the twin, Thomas Riker, in the ' episode "Defiant", in which he impersonates the other Riker to commandeer the starship "Defiant" as a member of the Maquis. The following year he guest-starred as Commander Riker along with Q in the ' episode "". Frakes reprised his role of Commander Riker in the 2005 "" series finale, "These Are the Voyages...". Frakes also played Riker in an advert for Boole & Babbage.
Background.
The following actors also auditioned for the role of William Riker; they have all appeared at least once on "Star Trek: TNG" or a Star Trek series that followed it:

</doc>
