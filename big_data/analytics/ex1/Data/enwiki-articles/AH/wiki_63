<doc id="52949" url="https://en.wikipedia.org/wiki?curid=52949" title="Israelites">
Israelites

The Israelites (; "Bne Yisra'el") were a Semitic people of the Ancient Near East, who inhabited part of Canaan during the tribal and monarchic periods. and lived in the region in smaller numbers after the fall of the monarchy. The prevailing academic opinion today is that the Israelites, who eventually evolved into the modern Jews and Samaritans, were an outgrowth of the indigenous Canaanites who had resided in the area since the 8th millennium BCE.
In the Hebrew Bible, the term "Israelites" refers to the direct descendants of any of the sons of the patriarch Jacob, or of the people called Israel, and of a worshipper of the God of Israel, Yahweh. In the period of the divided monarchy it referred only to inhabitants of the northern kingdom, and is only extended to cover people of the southern kingdom in post-exilic usage. Other terms sometimes used include the "Hebrews" and the "Twelve Tribes" (of Israel).
The Jews, which include the tribes of Judah, Benjamin, Simeon and partially Levi, are named after the southern Israelite Kingdom of Judah. The word "Jews" is found in Kings (16:6), Chronicles (I, 4:18), and in numerous passages in Jeremiah, Zechariah and the book of Esther. The Samaritans, whose religious texts consist of the five books of the Samaritan Torah (but which do not contain the books comprising the Jewish "Tanakh"), do not refer to themselves as Jews, although they do regard themselves as Israelites, in accordance with the Torah.
The Kingdom of Israel (Samaria), often called the Northern Kingdom of Israel, contained all the tribes except for the tribes of Judah and Benjamin. Following its conquest by Assyria, these ten tribes were allegedly dispersed and lost to history, and henceforth known as the Ten Lost Tribes. Jewish tradition holds that Samaria was so named because the region's mountainous terrain was used to keep "Guard" ("Shamer") for incoming enemy attack. According to Samaritan tradition, however, the Samaritan ethnonym is not derived from the region of Samaria, but from the fact that they were the "Guardians" ("Shamerim") of the true Israelite religion. Thus, according to Samaritan tradition, the region was named Samaria after them, not vice versa. In Jewish Hebrew, the Samaritans are called "Shomronim", while in Samaritan Hebrew they call themselves "Shamerim".
In Judaism, an Israelite is, broadly speaking, a lay member of the Jewish ethnoreligious group, as opposed to the priestly orders of Kohanim and Levites. In texts of Jewish law such as the Mishnah and Gemara, the term יהודי (Yehudi), meaning Jew, is rarely used, and instead the ethnonym ישראלי (Yisraeli), or Israelite, is widely used to refer to Jews. Samaritans commonly refer to themselves and Jews collectively as Israelites, and describe themselves as the Israelite Samaritans.
Etymology.
The term "Israelite" is the English name for the descendants of the biblical patriarch Jacob in ancient times, which is derived from the Greek Ισραηλίτες, which was used to translate the Biblical Hebrew term "b'nei yisrael", יִשְׂרָאֵל as either "sons of Israel" or "children of Israel".
The name "Israel" first appears in the Hebrew Bible in . It refers to the renaming of Jacob, who, according to the Bible, wrestled with an angel, who gave him a blessing and renamed him "Israel" because he had "striven with God and with men, and have prevailed". The Hebrew Bible etymologizes the name as from "yisra" "to prevail over" or "to struggle/wrestle with", and "el", "God, the divine".
The name "Israel" first appears in non-biblical sources c. 1209 BCE, in an inscription of the Egyptian pharaoh Merneptah. The inscription is very brief and says simply: "Israel is laid waste and his seed is not" (see below). The inscription refers to the nation, not to an individual.
Terminology.
In modern Hebrew, "b'nei yisrael" ("children of Israel") can denote the Jewish people at any time in history; it is typically used to emphasize Jewish religious identity. From the period of the Mishna (but probably used before that period) the term "Yisrael" ("an Israel") acquired an additional narrower meaning of Jews of legitimate birth other than Levites and Aaronite priests ("kohanim"). In modern Hebrew this contrasts with the term "Yisraeli" (English "Israeli"), a citizen of the modern State of Israel, regardless of religion or ethnicity.
The term "Hebrew" has Eber as an eponymous ancestor. It is used synonymously with "Israelites", or as an ethnolinguistic term for historical speakers of the Hebrew language in general.
The Greek term "Ioudaioi" (Jews) was an exonym originally referring to members of the Tribe of Judah, which formed the nucleus of the kingdom of Judah, and was later adopted as a self-designation by people in the diaspora who identified themselves as loyal to the God of Israel and the Temple in Jerusalem.
The Samaritans, who claim descent from the tribes of Ephraim and Manasseh (plus Levi through Aaron for kohens), are named after the Israelite Kingdom of Samaria, but the Jews, until modern times, have contested their claimed lineage, deeming them to have been conquered foreigners who were settled in the Land of Israel by the Assyrians, as was the typical Assyrian policy to obliterate national identities. Today, Jews and Samaritans both recognize each other as communities with an authentic Israelite origin.
The terms "Jews" and "Samaritans" largely replaced the title "Children of Israel" as the common used ethnonym for each respective community.
Historical Israelites.
Several theories exist proposing the origins of the Israelites in raiding groups, infiltrating nomads or emerging from indigenous Canaanites driven from the wealthier urban areas by poverty to seek their fortunes in the highland. Various, ethnically distinct groups of itinerant nomads such as the Habiru and Shasu recorded in Egyptian texts as active in Edom and Canaan could have been related to the later Israelites, which does not exclude the possibility that the majority may have had their origins in Canaan proper. The name Yahweh, the god of the later Israelites, may indicate connections with the region of Mount Seir in Edom.
The prevailing academic opinion today is that the Israelites were a mixture of peoples predominantly indigenous to Canaan, though an Egyptian matrix of peoples may also played a role in their ethnogenesis. with an ethnic composition similar to that in Ammon, Edom and Moab, and including Hapiru and Šośu. The defining feature which marked them off from the surrounding societies was a staunch egalitarian organization focused on Yahweh worship, rather than mere kingship.
The language of the Canaanites may perhaps be best described as an "archaic form of Hebrew, standing in much the same relationship to the Hebrew of the Old Testament as does the language of Chaucer to modern English. "The Canaanites were also the first people, as far as is known, to have used an alphabet.
The name Israel first appears c. 1209 BCE, at the end of the Late Bronze Age and the very beginning of the period archaeologists and historians call Iron Age I, on the Merneptah Stele raised by the Egyptian Pharaoh Merneptah. The inscription is very brief
As distinct from the cities named (Ashkelon, Gezer, Yenoam) which are written with a toponymic marker, Israel is written hieroglyphically with a demonymic determinative indicating that the reference is to a human group, variously located in central Palestine or the highlands of Samaria. Over the next two hundred years (the period of Iron Age I) the number of highland villages increased from 25 to over 300 and the settled population doubled to 40,000. By the 10th century BCE a rudimentary state had emerged in the north-central highlands, and in the 9th century this became a kingdom. Settlement in the southern highlands was minimal from the 12th through the 10th centuries BCE, but a state began to emerge there in the 9th century, and from 850 BCE onwards a series of inscriptions are evidence of a kingdom which its neighbours refer to as the "House of David."
After the destruction of the Israelite kingdoms of Judah and Samaria in 586 BCE and 720 BCE respectively, the concepts of Jew and Samaritan gradually replaced Judean and Israelite. When the Jews returned from the Babylonian captivity, the Hasmonean kingdom was established in present-day Israel, consisting of three regions which were Judea, Samaria, and the Galilee. In the pre-exilic first Temple period the political power of Judea was concentrated within the tribe of Judah, Samaria was dominated by the tribe of Ephraim and the House of Joseph, while the Galilee was associated with the tribe of Naphtali, the most eminent tribe of northern Israel. At the time of the Kingdom of Samaria, the Galilee was populated by northern tribes of Israel, but following the Babylonian exile the region became Jewish. During the second Temple period relations between the Jews and Samaritans remained tense. In 120 BCE the Hasmonean king Yohanan Hyrcanos I destroyed the Samaritan temple on Mount Gerizim, due to the resentment between the two groups over a disagreement of whether Mount Moriah in Jerusalem or Mount Gerizim in Shechem was the actual site of the Aqedah, and the chosen place for the Holy Temple, a source of contention that had been growing since the two houses of the former united monarchy first split asunder in 930 BCE and which had finally exploded into warfare. 190 years after the destruction of the Samaritan Temple and the surrounding area of Shechem, the Roman emperor Titus launched a military campaign to crush the Jewish revolt of 66 CE, which resulted in the destruction of the Jewish Temple in Jerusalem in 70 CE, and the subsequent exile of Jews from Judea and the Galilee in 135 CE following the Bar Kochba revolt.
Biblical Israelites.
The Israelite story begins with some of the culture heroes of the Jewish people, the Patriarchs. The Torah traces the Israelites to the patriarch Jacob, grandson of Abraham, who was renamed Israel after a mysterious incident in which he wrestles all night with God or an angel. Jacob's twelve sons (in order of birth), Reuben, Simeon, Levi, Judah, Dan, Naphtali, Gad, Asher, Issachar, Zebulun, Joseph and Benjamin, become the ancestors of twelve tribes, with the exception of Joseph, whose two sons Mannasseh and Ephraim, who were adopted by Jacob, become tribal eponyms ().
The mothers of Jacob's sons are:
Jacob and his sons are forced by famine to go down into Egypt, although Joseph was already there, as he had been sold into slavery while young. When they arrive they and their families are 70 in number, but within four generations they have increased to 600,000 men of fighting age, and the Pharaoh of Egypt, alarmed, first enslaves them and then orders the death of all male Hebrew children. A woman from the tribe of Levi hides her child, places him in a woven basket, and sends him down the Nile river. He is named Mosheh, or Moses, by the Egyptians who find him. Being a Hebrew baby, they award a Hebrew woman the task of raising him, the mother of Moses volunteers, and the child and his mother are reunited.
At the age of forty Moses murders an Egyptian, whom he discovers beating a Hebrew to death, and escapes as a fugitive into the Sinai desert, where he is taken in by the Midianites and marries Zipporah, the daughter of the Midianite priest Jethro. When he is eighty years old, Moses is tending a herd of sheep in solitude on Mount Sinai when he sees a desert shrub that is burning but is not consumed. The God of Israel calls to Moses from the fire and reveals his name, Yahweh (from the Hebrew root word 'HWH' meaning to exist), and tells Moses that he is being sent to Pharaoh to bring the people of Israel out of Egypt.
Yahweh tells Moses that if Pharaoh refuses to let the Hebrews go to say to Pharaoh "Thus says Yahweh: Israel is my son, my first-born and I have said to you: Let my son go, that he may serve me, and you have refused to let him go. Behold, I will slay your son, your first-born". Moses returns to Egypt and tells Pharaoh that he must let the Hebrew slaves go free. Pharaoh refuses and Yahweh strikes the Egyptians with a series of horrific plagues, wonders, and catastrophes, after which Pharaoh relents and banishes the Hebrews from Egypt. Moses leads the Israelites out of bondage toward the Red Sea, but Pharaoh changes his mind and arises to massacre the fleeing Hebrews. Pharaoh finds them by the sea shore and attempts to drive them into the ocean with his chariots and drown them.
Yahweh causes the Red Sea to part and the Hebrews pass through on dry land into the Sinai. After the Israelites escape from the midst of the sea, Yahweh causes the ocean to close back in on the pursuing Egyptian army, drowning them to death. In the desert Yahweh feeds them with manna that accumulates on the ground with the morning dew. They are led by a column of cloud, which ignites at night and becomes a pillar of fire to illuminate the way, southward through the desert until they come to Mount Sinai. The twelve tribes of Israel encamp around the mountain, and on the third day Mount Sinai begins to smolder, then catches fire, and Yahweh speaks the Ten Commandments from the midst of the fire to all the Israelites, from the top of the mountain.
Moses ascends biblical Mount Sinai and fasts for forty days while he writes down the Torah as Yahweh dictates, beginning with Bereshith and the creation of the universe and earth. He is shown the design of the Mishkan and the Ark of the Covenant, which Bezalel is given the task of building. Moses descends from the mountain forty days later with the Sefer Torah he wrote, and with two rectangular lapis lazuli tablets, into which Yahweh had carved the Ten Commandments in Paleo–Hebrew. In his absence, Aaron has constructed an image of Yahweh, depicting him as a young Golden Calf, and has presented it to the Israelites, declaring "Behold O Israel, this is your god who brought you out of the land of Egypt". Moses smashes the two tablets and grinds the golden calf into dust, then throws the dust into a stream of water flowing out of Mount Sinai, and forces the Israelites to drink from it.
Moses ascends Mount Sinai for a second time and Yahweh passes before him and says: 'Yahweh, Yahweh, a god of compassion, and showing favor, slow to anger, and great in kindness and in truth, who shows kindness to the thousandth generation, forgiving wrongdoing and injustice and wickedness, but will by no means clear the guilty, causing the consequences of the parent's wrongdoing to befall their children, and their children's children, to the third and fourth generation' Moses then fasts for another forty days while Yahweh carves the Ten Commandments into a second set of stone tablets. After the tablets are completed, light emanates from the face of Moses for the rest of his life, causing him to wear a veil so he does not frighten people.
Moses descends Mount Sinai and the Israelites agree to be the chosen people of Yahweh and follow all the laws of the Torah. Moses prophesies if they forsake the Torah, Yahweh will exile them for the total number of years they did not observe the shmita. Bezael constructs the Ark of the Covenant and the Mishkan, where the presence of Yahweh dwells on earth in the Holy of Holies, above the Ark of the Covenant, which houses the Ten Commandments. Moses sends spies to scout out the Land of Canaan, and the Israelites are commanded to go up and conquer the land, but they refuse, due to their fear of warfare and violence. In response, Yahweh condemns the entire generation, including Moses, who is condemned for striking the rock at Meribah, to exile and death in the Sinai desert.
Before Moses dies he gives a speech to the Israelites where he paraphrases a summary of the mizwoth given to them by Yahweh, and recites a prophetic song called the Ha'azinu. Moses prophesies that if the Israelites disobey the Torah, Yahweh will cause a global exile in addition to the minor one prophesied earlier at Mount Sinai, but at the end of days Yahweh will gather them back to Israel from among the nations when they turn back to the Torah with zeal. The events of the Israelite exodus and their sojourn in the Sinai are memorialized in the Jewish and Samaritan festivals of Passover and Sukkoth, and the giving of the Torah in the Jewish celebration of Shavuoth.
Forty years after the Exodus, following the death of the generation of Moses, a new generation, led by Joshua, enters Canaan and takes possession of the land in accordance with the promise made to Abraham by Yahweh. Land is allocated to the tribes by lottery. Eventually the Israelites ask for a king, and Yahweh gives them Saul. David, the youngest (divinely favored) son of Jesse of Bethlehem would succeed Saul. Under David the Israelites establish the united monarchy, and under David's son Solomon they construct the Holy Temple in Jerusalem, using the 400-year-old materials of the Mishkan, where Yahweh continues to tabernacle himself among them. On the death of Solomon and reign of his son, Rehoboam, the kingdom is divided in two.
The kings of the northern Kingdom of Samaria are uniformly bad, permitting the worship of other gods and failing to enforce the worship of Yahweh alone, and so Yahweh eventually allows them to be conquered and dispersed among the peoples of the earth; and strangers rule over their remnant in the northern land. In Judah some kings are good and enforce the worship of Yahweh alone, but many are bad and permit other gods, even in the Holy Temple itself, and at length Yahweh allows Judah to fall to her enemies, the people taken into captivity in Babylon, the land left empty and desolate, and the Holy Temple itself destroyed.
Yet despite these events Yahweh does not forget his people, but sends Cyrus, king of Persia to deliver them from bondage. The Israelites are allowed to return to Judah and Benjamin, the Holy Temple is rebuilt, the priestly orders restored, and the service of sacrifice resumed. Through the offices of the sage Ezra, Israel is constituted as a holy nation, bound by the Torah and holding itself apart from all other peoples.

</doc>
<doc id="52952" url="https://en.wikipedia.org/wiki?curid=52952" title="Adrenoleukodystrophy">
Adrenoleukodystrophy

Adrenoleukodystrophy (; also known as X-linked adrenoleukodystrophy, ALD, X-ALD, adrenomyeloneuropathy, AMN, Siemerling–Creutzfeldt disease or bronze Schilder disease) is a disease that is linked on the X chromosome. It is a result of fatty acid digestive enzymes not breaking up the fats. These fats build up in the brain. They damage the myelin that surrounds nerves. This can cause seizures and hyperactivity. It can also cause problems with speaking, listening and understanding verbal instructions.
In more detail, it is a disorder of peroxisomal fatty acid beta oxidation which results in the accumulation of very long chain fatty acids in tissues throughout the body. The most severely affected tissues are the myelin in the central nervous system, the adrenal cortex and the Leydig cells in the testes. Clinically, ALD is a heterogeneous disorder, presenting with several distinct phenotypes, and no clear pattern of genotype-phenotype correlation. As an X-linked disorder, ALD presents most commonly in males, however approximately 50% of heterozygote females show some symptoms later in life. Approximately two-thirds of ALD patients will present with the childhood cerebral form of the disease, which is the most severe form. It is characterized by normal development in early childhood, followed by rapid degeneration to a vegetative state. The other forms of ALD vary in terms of onset and clinical severity, ranging from adrenal insufficiency to progressive paraparesis in early adulthood (this form of the disease is typically known as adrenomyeloneuropathy).
ALD is caused by mutations in "ABCD1", a gene located on the X chromosome that codes for ALD, a peroxisomal membrane transporter protein. The exact mechanism of the pathogenesis of the various forms of ALD is not known. Biochemically, individuals with ALD show very high levels of unbranched, saturated, very long chain fatty acids, particularly cerotic acid (26:0). The level of cerotic acid in plasma does not correlate with clinical presentation. Treatment options for ALD are limited. Dietary treatment is with Lorenzo's oil. For the childhood cerebral form, stem cell transplant and gene therapy are options if the disease is detected early in the clinical course. Adrenal insufficiency in ALD patients can be successfully treated. ALD is the most common peroxisomal inborn error of metabolism, with an incidence estimated between 1:18,000 and 1:50,000. It does not have a significantly higher incidence in any specific ethnic groups.
Signs and symptoms.
ALD can present in different ways. The different presentations are complicated by the pattern of X-linked recessive inheritance. There have been seven phenotypes described in males with "ABCD1" mutations and five in females. Initial symptoms in boys affected with the childhood cerebral form of ALD include emotional instability, hyperactivity and disruptive behavior at school. Older patients affected with the cerebral form will present with similar symptoms. Untreated, cerebral ALD is characterized by progressive demyelination leading to a vegetative state and death. Adult males with an adrenomyeloneuropathy presentation typically present initially with muscle stiffness, paraparesis and sexual dysfunction. All patients with clinically recognized ALD phenotypes are at risk for adrenal insufficiency. There is no reliable way to predict which form of the disease an affected individual will develop, with multiple phenotypes being demonstrated within families. Onset of adrenal insufficiency is often the first symptom, appearing as early as two years of age.
Diagnosis.
The clinical presentation of ALD can vary greatly, making diagnosis difficult. With the variety of phenotypes, clinical suspicion of ALD can result from a variety of different presentations. Symptoms vary based on the disease phenotype, and even within families or between twins. When ALD is suspected based on clinical symptoms, the initial testing usually includes plasma very long chain fatty acid (VLCFA) determination using gas chromatography-mass spectrometry. The concentration of unsaturated VLCFA, particularly 26 carbon chains is significantly elevated in males with ALD, even prior to the development of other symptoms. Confirmation of ALD after positive plasma VLCFA determination usually involves molecular genetic analysis of "ABCD1". In females, where plasma VLCFA measurement is not always conclusive (some female carriers will have normal VLCFA in plasma), molecular analysis is preferred, particularly in cases where the mutation in the family is known. Although the clinical phenotype is highly variable among affected males, the elevations of VLCFA are present in all males with an "ABCD1" mutation.
Because the characteristic elevations associated with ALD are present at birth, well before any symptoms are apparent, there have been methods developed in the interests of including it in newborn screening programs. One of the difficulties with ALD as a disease included in universal newborn screening is the difficulty in predicting the eventual phenotype that an individual will express. The accepted treatment for affected boys presenting with the cerebral childhood form of the disease is a bone marrow transplant, a procedure which carries significant risks. However, because most affected males will demonstrate adrenal insufficiency, early discovery and treatment of this symptom could potentially prevent complications and allow these patients to be monitored for other treatment in the future, depending on the progression of their disease.
The Loes score is a rating of the severity of abnormalities in the brain found on MRI. It ranges from 0 to 34, based on a point system derived from the location and extent of disease and the presence of atrophy in the brain, either localized to specific points or generally throughout the brain. A Loes score of 0.5 or less is classified as normal, while a Loes score of 14 or greater is considered severe. It was developed by neuroradiologist Daniel J. Loes MD and is an important tool in assessing disease progression and the effectiveness of therapy.
Genetics.
ALD is caused by mutations in "ABCD1", located at Xq28 and demonstrates X-linked recessive inheritance. The gene ABCD1 encodes a peroxisomal membrane transporter which is responsible for transporting very long chain fatty acid substrate into the peroxisomes for degradation. Mutations in this gene that interfere with this process cause this syndrome.
Males with an "ABCD1" mutation are hemizygous, as they only have a single X chromosome. Female carriers will typically avoid the most severe manifestations of the disease, but often become symptomatic later in life. Although, the detection of an "ABCD1" mutation identifies an individual who is affected with a form of ALD, however there is no genotype - phenotype correlation. Within a family, there will often be several different phenotypes, despite the presence of the same causative mutation. In one case, a family with six affected members displayed five different phenotypes. There are no common mutations that cause ALD, most are private or familial. Almost 600 different mutations have been identified, approximately half are missense mutations, one quarter are frameshifts, with in-frame deletions and splicing defects making up the remainder. The incidence of new mutations in ALD (those occurring spontaneously, rather than being inherited from a carrier parent) is estimated at approximately 4.1%, with the possibility that these are due to germline mosaicism.
Pathogenesis.
The exact cause for the varied collection of symptoms found in the different ALD phenotypes is not clear. The white matter of the brain, the Leydig cells of the testes and the adrenal cortex are the most severely affected systems. The excess VLCFA can be detected in almost all tissues of the body, despite the localization of symptoms. Successful treatment of the demyelination process that affects the brain with either stem cell transplant or gene therapy does not immediately normalize the VLCFA levels in body tissues. The levels of VLCFA can be normalized by treatment with Lorenzo's oil, but this does not alter the progression of the disease. It is unclear whether the accumulation of VLCFA is associated with the pathogenesis of the disease in a specific way, or if it is a biochemical phenotype, useful for identification.
Treatment.
Dietary therapy.
Initial attempts at dietary therapy in ALD involved restricting the intake of very-long chain fatty acids (VLCFA). Dietary intake is not the only source for VLCFA in the body, as they are also synthesized endogenously. This dietary restriction did not impact the levels of VLCFA in plasma and other body tissues. After the realization that endogenous synthesis was an important contribution to VLCFA in the body, efforts at dietary therapy shifted to inhibiting these synthetic pathways in the body. The parents of Lorenzo Odone, a boy with ALD, spearheaded efforts to develop a dietary treatment to slow the progression of the disease. They developed a mixture of unsaturated fatty acids (glycerol trioleate and glyceryl trierucate in a 4:1 ratio), known as Lorenzo's oil that inhibits elongation of saturated fatty acids in the body. Supplementation with Lorenzo's oil has been found to normalize the VLCFA concentrations in the body, although its effectiveness at treating the cerebral manifestations of the disease is still controversial and unproven. Trials with Lorenzo's oil have shown that it does not stop the neurological degradation in symptomatic patients, nor does it improve adrenal function.
Transplant.
While dietary therapy has been shown to be effective to normalize the very-long chain fatty acid concentrations in the plasma of individuals with ALD, allogeneic hematopoietic stem cell transplants are the only treatment that can stop the demyelination that is the hallmark of the cerebral forms of the disease. In order to be effective, the transplant must be done at an early stage of the disease; if the demyelination has progressed, transplant can worsen the outcome, and increase the rate of decline. While transplants have been shown to be effective at halting the demyelination process in those presenting with the childhood cerebral form of ALD, follow-up of these patients has shown that it does not improve adrenal function.
Gene therapy.
For patients where an appropriate match for a transplant cannot be found, there have been investigations into the use of gene therapy. Appropriate vectors are selected and modified to express wild type "ABCD1", which is then transplanted into the patients using a similar procedure as for a bone marrow or stem cell transplant. Gene therapy has only been tried on a small number of patients, mainly in France. These patients were only considered for gene therapy after there was no HLA match for a traditional transplant. In two reported cases, the gene therapy was successful, with a resolution of the demyelination process up to two years after the procedure. Although the gene therapy was successful in resolving the neurological symptoms, plasma VLCFA levels remained elevated.
Adrenal insufficiency.
Treatment of the adrenal insufficiency that can accompany any of the common male phenotypes of ALD does not resolve any of the neurological symptoms. Hormone replacement is standard for ALD patients demonstrating adrenal insufficiency. Adrenal insufficiency does not resolve with successful transplant; most patients still require hormone replacement.
Epidemiology.
ALD has not been shown to have an increased incidence in any specific country or ethnic group. In the United States, the incidence of affected males is estimated at 1:21,000. Overall incidence of hemizygous males and carrier females is estimated at 1:16,800. The reported incidence in France is estimated at 1:22,000.

</doc>
<doc id="52954" url="https://en.wikipedia.org/wiki?curid=52954" title="Hypermodernism">
Hypermodernism

Hypermodernism may refer to:

</doc>
<doc id="52957" url="https://en.wikipedia.org/wiki?curid=52957" title="Bell's palsy">
Bell's palsy

Bell's palsy is a form of facial paralysis resulting from a dysfunction of the cranial nerve VII (the facial nerve) causing an inability to control facial muscles on the affected side. Often the eye in the affected side cannot be closed. The eye should be protected from drying up, or the cornea may be permanently damaged, resulting in impaired vision. In some cases denture wearers experience some discomfort. The common presentation of this condition is a rapid onset of partial or complete paralysis that often occurs overnight. In rare cases (<1%), it can occur on both sides resulting in total facial paralysis.
Bell's palsy is defined as a one-sided facial nerve paralysis of unknown cause. Several other conditions can also cause facial paralysis, e.g., brain tumor, stroke, myasthenia gravis, and Lyme disease; however, if no specific cause can be identified, the condition is known as Bell's palsy. It is thought that an inflammatory condition leads to swelling of the facial nerve. The nerve travels through the skull in a narrow bone canal beneath the ear. Nerve swelling and compression in the narrow bone canal are thought to lead to nerve inhibition or damage.
The condition normally gets better by itself with most achieving normal or near-normal function. Corticosteroids have been found to improve outcomes, when used early, while anti-viral medications are of questionable benefit. Many show signs of improvement as early as 10 days after the onset, even without treatment.
Bell's palsy is the most common acute disease involving a single nerve and is the most common cause of acute facial nerve paralysis (>80%). It is more common in persons between ages 20 and 60. It is named after Scottish anatomist and Edinburgh graduate Charles Bell (1774–1842), who first described it. It is more common in adults than children.
Signs and symptoms.
Bell's palsy is characterized by a one-sided facial droop that comes on within 72 hours.
The facial nerve controls a number of functions, such as blinking and closing the eyes, smiling, frowning, lacrimation, salivation, flaring nostrils and raising eyebrows. It also carries taste sensations from the anterior two-thirds of the tongue, via the chorda tympani nerve (a branch of the facial nerve). Because of this, people with Bell's palsy may present with loss of taste sensation in the anterior 2/3 of the tongue on the affected side.
Although the facial nerve innervates the stapedial muscles of the middle ear (via the tympanic branch), sound sensitivity and dysacusis are hardly ever clinically evident.
Although defined as a mononeuritis (involving only one nerve), people diagnosed with Bell’s palsy may have "myriad neurological symptoms" including "facial tingling, moderate or severe headache/neck pain, memory problems, balance problems, ipsilateral limb paresthesias, ipsilateral limb weakness, and a sense of clumsiness" that are "unexplained by facial nerve dysfunction".
Cause.
Some viruses are thought to establish a persistent (or latent) infection without symptoms, e.g., the varicella-zoster virus and Epstein-Barr viruses, both of the herpes family. Reactivation of an existing (dormant) viral infection has been suggested as a cause of acute Bell's palsy. Studies suggest that this new activation could be preceded by trauma, environmental factors, and metabolic or emotional disorders, thus suggesting that a host of different conditions may trigger reactivation.
Familial inheritance has been found in 4–14% of cases. Bell's palsy is three times more likely to occur in pregnant women than non-pregnant women. It is also considered to be four times more likely to occur in diabetics than the general population.
Differential diagnosis.
Once the facial paralysis sets in, many people may mistake it as a symptom of a stroke; however, there are a few subtle differences. A stroke will usually cause a few additional symptoms, such as numbness or weakness in the arms and legs. And unlike Bell's palsy, a stroke will usually let patients control the upper part of their faces. A person with a stroke will usually have some wrinkling of their forehead.
One disease that may be difficult to exclude in the differential diagnosis is involvement of the facial nerve in infections with the herpes zoster virus. The major differences in this condition are the presence of small blisters, or "vesicles", on the external ear and hearing disturbances, but these findings may occasionally be lacking (zoster sine herpete). Reactivation of existing herpes zoster infection leading to facial paralysis in a Bell's palsy type pattern is known as Ramsay Hunt syndrome type 2.
Lyme disease may produce facial palsy. Sometimes the facial palsy occurs at the same time as the classic erythema migrans rash. Other times, it occurs later. In areas where Lyme disease is common, it may be the cause of facial palsy in half of cases.
Pathophysiology.
Bell's palsy occurs due to a malfunction of the facial nerve (VII cranial nerve), which controls the muscles of the face. Facial palsy is typified by inability to control movement in the facial muscles. The paralysis is of the infranuclear/lower motor neuron type.
It is thought that as a result of inflammation of the facial nerve, pressure is produced on the nerve where it exits the skull within its bony canal, blocking the transmission of neural signals or damaging the nerve. Patients with facial palsy for which an underlying cause can be found are not considered to have Bell's palsy "per se". Possible causes include tumor, meningitis, stroke, diabetes mellitus, head trauma and inflammatory diseases of the cranial nerves (sarcoidosis, brucellosis, etc.). In these conditions, the neurologic findings are rarely restricted to the facial nerve. Babies can be born with facial palsy. In a few cases, bilateral facial palsy has been associated with acute HIV infection.
In some research the herpes simplex virus type 1 (HSV-1) has been identified in a majority of cases diagnosed as Bell's palsy. This has given hope for anti-inflammatory and anti-viral drug therapy (prednisone and acyclovir). Other research, however, identifies HSV-1 in only 31 cases (18 percent), herpes zoster (zoster sine herpete) in 45 cases (26 percent) in a total of 176 cases clinically diagnosed as Bell's Palsy. That infection with herpes simplex virus should play a major role in cases diagnosed as Bell's palsy therefore remains a hypothesis that requires further research.
In addition, the herpes simplex virus type 1 (HSV-1) infection is associated with demyelination of nerves. This nerve damage mechanism is different from the above-mentioned - that edema, swelling and compression of the nerve in the narrow bone canal is responsible for nerve damage. Demyelination may not even be directly caused by the virus, but by an unknown immune system response.
Diagnosis.
Bell's palsy is a diagnosis of exclusion, meaning it is diagnosed by elimination of other reasonable possibilities. By definition, no specific cause can be determined. There are no routine lab or imaging tests required to make the diagnosis. The degree of nerve damage can be assessed using the House-Brackmann score.
One study found that 45% of patients are not referred to a specialist, which suggests that Bell’s palsy is considered by physicians to be a straightforward diagnosis that is easy to manage.
Other conditions that can cause similar symptoms include: herpes zoster, Lyme disease, sarcoidosis, stroke, and brain tumors.
Treatment.
Steroids have been shown to be effective at improving recovery in Bell's palsy while antivirals have not. In those who are unable to close their eyes, eye protective measures are required.
Steroids.
Corticosteroid such as prednisone significantly improves recovery at 6 months and are thus recommended. Early treatment (within 3 days after the onset) is necessary for benefit with a 14% greater probability of recovery.
Antivirals.
One review found that antivirals (such as aciclovir) are ineffective in improving recovery from Bell's palsy beyond steroids alone in mild to moderate disease. Another review found a benefit but stated the evidence was not very good to support this.
In severe disease it is also unclear. One 2015 review found no effect regardless of severity. Another review found a small benefit when added to steroids in those with severe disease.
They are commonly prescribed due to a theoretical link between Bell's palsy and the herpes simplex and varicella zoster virus. There is still the possibility that they might result in a benefit less than 7% as this has not been ruled out.
Physiotherapy.
Physiotherapy can be beneficial to some individuals with Bell’s palsy as it helps to maintain muscle tone of the affected facial muscles and stimulate the facial nerve. It is important that muscle re-education exercises and soft tissue techniques be implemented prior to recovery in order to help prevent permanent contractures of the paralyzed facial muscles. To reduce pain, heat can be applied to the affected side of the face. There is no high quality evidence to support the role of electrical stimulation for Bell's palsy.
Surgery.
Surgery may be able to improve outcomes in facial nerve palsy that has not recovered. A number of different techniques exist. Smile surgery or smile reconstruction is a surgical procedure that may restore the smile for people with facial nerve paralysis. It is unknown if early surgery is beneficial or harmful. Adverse effects include hearing loss which occurs in 3–15% of people. As of 2007 the American Academy of Neurology did not recommend surgical decompression.
Alternative medicine.
The efficacy of acupuncture remains unknown because the available studies are of low quality (poor primary study design or inadequate reporting practices). There is very tentative evidence for hyperbaric oxygen therapy in severe disease.
Prognosis.
Most people with Bell's palsy start to regain normal facial function within 3 weeks—even those who do not receive treatment. In a 1982 study, when no treatment was available, of 1,011 patients, 85% showed first signs of recovery within 3 weeks after onset. For the other 15%, recovery occurred 3–6 months later. After a follow-up of at least 1 year or until restoration, complete recovery had occurred in more than two-thirds (71%) of all patients. Recovery was judged moderate in 12% and poor in only 4% of patients. Another study found that incomplete palsies disappear entirely, nearly always in the course of one month. The patients who regain movement within the first two weeks nearly always remit entirely. When remission does not occur until the third week or later, a significantly greater part of the patients develop sequelae. A third study found a better prognosis for young patients, aged below 10 years old, while the patients over 61 years old presented a worse prognosis.
Major complications of the condition are chronic loss of taste (ageusia), chronic facial spasm, facial pain and corneal infections. To prevent the latter, the eyes may be protected by covers, or taped shut during sleep and for rest periods, and tear-like eye drops or eye ointments may be recommended, especially for cases with complete paralysis. Where the eye does not close completely, the blink reflex is also affected, and care must be taken to protect the eye from injury.
Another complication can occur in case of incomplete or erroneous regeneration of the damaged facial nerve. The nerve can be thought of as a bundle of smaller individual nerve connections that branch out to their proper destinations. During regrowth, nerves are generally able to track the original path to the right destination - but some nerves may sidetrack leading to a condition known as synkinesis. For instance, regrowth of nerves controlling muscles attached to the eye may sidetrack and also regrow connections reaching the muscles of the mouth. In this way, movement of one also affects the other. For example, when the person closes the eye, the corner of the mouth lifts involuntarily.
Around 9% of patients have some sort of sequelae after Bell's palsy, typically the synkinesis already discussed, or spasm, contracture, tinnitus and/or hearing loss during facial movement or crocodile tear syndrome. This is also called gustatolacrimal reflex or Bogorad’s Syndrome and involves the sufferer shedding tears while eating. This is thought to be due to faulty regeneration of the facial nerve, a branch of which controls the lacrimal and salivary glands. Gustatorial sweating can also occur.
Epidemiology.
The number of new cases of Bell's palsy is about 20 per 100,000 population per year. The rate increases with age. Bell’s palsy affects about 40,000 people in the United States every year. It affects approximately 1 person in 65 during a lifetime.
A range of annual incidence rates have been reported in the literature: 15, 24, and 25–53 (all rates per 100,000 population per year). Bell’s palsy is not a reportable disease, and there are no established registries for patients with this diagnosis, which complicates precise estimation.
History.
The Persian physician Muhammad ibn Zakariya al-Razi (865–925) detailed the first known description of peripheral and central facial palsy.
Cornelis Stalpart van der Wiel (1620–1702) in 1683 gave an account of Bell’s palsy and credited the Persian physician Ibn Sina (980–1037) for describing this condition before him. James Douglas (1675–1742) and Nicolaus Anton Friedreich (1761–1836) also described it.
Sir Charles Bell, for whom the condition is named, presented three cases at the Royal Society of London in 1829. Two cases were idiopathic and the third was due to a tumour of the parotid gland.

</doc>
<doc id="52963" url="https://en.wikipedia.org/wiki?curid=52963" title="Obstetrics and gynaecology">
Obstetrics and gynaecology

Obstetrics and Gynecology (often abbreviated to OB/GYN, OBG, O&G or Obs & Gynae) is the medical specialty that deals with obstetrics and gynecology. The postgraduate training program for both aspects is unified. This combined training prepares the practicing OB/GYN to be adept at the care of female reproductive organs' health and at the management of pregnancy.
Education and Training.
The common route for an OBGYN student is to earn an undergraduate degree, graduate from medical school and complete a residency at a hospital prior to certification.
Becoming an obstetrician-gynecologist (OB-GYN) requires about 11-14 years of education and practical experience. The first 7-9 years are general medical training. Doctors begin to specialize in OBGYN practice during residency programs that begin following graduation from medical school which requires an additional 4-5 years of education and clinical practice. Experienced OBGYN professionals can seek certifications in sub-specialty areas, including maternal and fetal medicine.
Subspecialties.
Examples of subspecialty training available to physicians in the US are:
Of these, only the first four are truly recognized sub-specialties by the Accreditation Council for Graduate Medical Education (ACGME) and the American Board of Obstetrics and Gynecology (ABOG). The other subspecialties are recognized as informal concentrations of practice. To be recognized as a board-certified subspecialist by the American Board of Obstetrics and Gynecology or the American Osteopathic Board of Obstetrics and Gynecology, a practitioner must have completed an ACGME or AOA-accredited residency and obtained a Certificate of Added Qualifications (CAQ) which requires an additional standardized examination.
Additionally, physicians of other specialties may become trained in Advanced Life Support in Obstetrics (ALSO), a short certification that equips them to better manage emergent OB/GYN situations.
Salary.
The salary of an obstetrician varies by country. In the United States, the salary ranges from $200,000 to $339,738.

</doc>
<doc id="52965" url="https://en.wikipedia.org/wiki?curid=52965" title="Obstetrics">
Obstetrics

Obstetrics is the field of study concentrated on pregnancy, childbirth, and the postpartum period. As a medical specialty, obstetrics is combined with gynaecology under the discipline known as obstetrics and gynaecology (OB/GYN).
Main areas.
Prenatal care.
Prenatal care is important in screening for various complications of pregnancy. This includes routine office visits with physical exams and routine lab tests:
First trimester.
Genetic screening for Down syndrome (trisomy 21) and trisomy 18, the national standard in the United States, is rapidly evolving away from the AFP-Quad screen for Down syndrome, done typically in the second trimester at 16–18 weeks. The newer integrated screen (formerly called F.A.S.T.E.R for First And Second Trimester Early Results) can be done at 10 plus weeks to 13 plus weeks with an ultrasound of the fetal neck (thick skin is bad) and two chemicals (analytes) PAPP-A and βHCG (pregnancy hormone level itself). It gives an accurate risk profile very early. A second blood screen at 15 to 20 weeks refines the risk more accurately. The cost is higher than an "AFP-quad" screen due to the ultrasound and second blood test, but it is quoted to have a 93% pick up rate as opposed to 88% for the standard AFP/QS. This is an evolving standard of care in the United States.
Third trimester.
Most doctors do a sugar load in a drink form of 50 grams of glucose in cola, lime or orange and draw blood an hour later (plus or minus 5 minutes) ; the standard modified criteria have been lowered to 135 since the late 1980s
Foetal assessments.
Obstetric ultrasonography is routinely used for dating the gestational age of a pregnancy from the size of the foetus, determine the number of foetuses and placentae, evaluate for an ectopic pregnancy and first trimester bleeding, the most accurate dating being in first trimester before the growth of the foetus has been significantly influenced by other factors. Ultrasound is also used for detecting congenital anomalies (or other foetal anomalies) and determining the biophysical profiles (BPP), which are generally easier to detect in the second trimester when the foetal structures are larger and more developed. Specialised ultrasound equipment can also evaluate the blood flow velocity in the umbilical cord, looking to detect a decrease/absence/reversal or diastolic blood flow in the umbilical artery.
X-rays and computerized tomography (CT) are not used, especially in the first trimester, due to the ionizing radiation, which has teratogenic effects on the foetus. No effects of magnetic resonance imaging (MRI) on the foetus have been demonstrated, but this technique is too expensive for routine observation. Instead, obstetric ultrasonography is the imaging method of choice in the first trimester and throughout the pregnancy, because it emits no radiation, is portable, and allows for realtime imaging.
The safety of frequent ultrasound scanning has not be confirmed. Despite this, increasing numbers of women are choosing to have additional scans for no medical purpose, such as gender scans, 3D and 4D scans. A normal gestation would reveal a gestational sac, yolk sac, and fetal pole. The gestational age can be assessed by evaluating the mean gestational sac diameter (MGD) before week 6, and the crown-rump length after week 6. Multiple gestation is evaluated by the number of placentae and amniotic sacs present.
Other tools used for assessment include:
Intercurrent diseases.
A pregnant woman may have intercurrent diseases, that is, other diseases or conditions (not directly caused by the pregnancy) that may become worse or be a potential risk to the pregnancy.
Induction and labour.
Induction is a method of artificially or prematurely stimulating labour in a woman. Reasons to induce can include pre-eclampsia, foetal distress, placental malfunction, intrauterine growth retardation and failure to progress through labour increasing the risk of infection and foetal distresses.
Induction may be achieved via several methods:
During labour, the obstetrician carries out the following tasks:
Complications and emergencies.
The main emergencies include:
Postnatal care.
Postnatal care is care provided to the mother following parturition.
A woman in the Western world who is delivering in a hospital may leave the hospital as soon as she is medically stable and chooses to leave, which can be as early as a few hours postpartum, though the average for spontaneous vaginal delivery (SVD) is 1–2 days, and the average caesarean section postnatal stay is 3–4 days.
During this time the mother is monitored for bleeding, bowel and bladder function, and baby care. The infant's health is also monitored.
Certain things must be kept in mind as the physician proceeds with the post-natal care.
History.
Prior to the 18th century, caring for pregnant women in Europe was confined exclusively to women, and rigorously excluded men. The expectant mother would invite close female friends and family members to her home to keep her company. Skilled midwives managed all aspects of the labour and delivery. The presence of physicians and surgeons was very rare and only occurred once a serious complication had taken place and the midwife had exhausted all measures to manage the complication. Calling a surgeon was very much a last resort and having men deliver women in this era whatsoever was seen as offending female modesty.
Before the 18th century.
Obstetrics prior to the 18th and 19th centuries was not recognized as a specific specialty. However, the subject matter and interest in the female reproductive system and sexual practice can be traced back to Ancient Egypt Soranus of Ephesus sometimes is called the most important figure in ancient gynecology. Living in the late first century A.D. and early second century he studied anatomy and had opinions and techniques on abortion, contraception –most notably coitus interruptus– and birth complications. After the death of Soranus, techniques and works of gynecology declined but very little of his works were recorded and survived to the late 18th century when gynaecology and obstetrics reemerged. and Ancient Greece.
18th century.
The 18th century marked the beginning of many advances in European midwifery. These advances in knowledge were mainly regarding the physiology of pregnancy and labour. By the end of the century, medical professionals began to understand the anatomy of the uterus and the physiological changes that take place during labour. The introduction of forceps in childbirth also took place during the 18th century. All these medical advances in obstetrics were a lever for the introduction of men into an arena previously managed and run by women—midwifery.
The addition of the male-midwife is historically a significant change to the profession of obstetrics. In the 18th century medical men began to train in area of childbirth and believed with their advanced knowledge in anatomy that childbirth could be improved. In France these male-midwives]] were referred to as "accoucheurs". This title was later on lent to male-midwives all over Europe. The founding of lying-hospitals also contributed to the medicalization and male-dominance of obstetrics. These lying-hospitals were establishments where women would come to have their babies delivered, which had prior been unheard of since the midwife normally came to home of the pregnant woman. This institution provided male-midwives or accoucheurs with an endless number of patients to practice their techniques on and also was a way for these men to demonstrate their knowledge.
Many midwives of the time bitterly opposed the involvement of men in childbirth. Some male practitioners also opposed the involvement of medical men like themselves in midwifery, and even went as far as to say that men-midwives only undertook midwifery solely for perverse erotic satisfaction. The accoucheurs argued that their involvement in midwifery was to improve the process of childbirth. These men also believed that obstetrics would forge ahead and continue to strengthen.
19th century.
Even 18th century physicians expected that obstetrics would continue to grow, the opposite happened. Obstetrics entered a stage of stagnation in the 19th century, which lasted until about the 1880s. The central explanation for the lack of advancement during this time was substantially due to the rejection of obstetrics by the medical community. The 19th century marked an era of medical reform in Europe and increased regulation over the medical profession. Major European institutions such as The College of Physicians and Surgeons considered delivering babies ungentlemanly work and refused to have anything to do with childbirth as a whole. Even when Medical Act 1858 was introduced, which stated that medical students could qualify as doctors, midwifery was entirely ignored. This made it nearly impossible to pursue an education in midwifery and also have the recognition of being a doctor or surgeon. Obstetrics was pushed to the side.
By the late 19th century the foundation of modern day obstetrics and midwifery began developing. Delivery of babies by doctors became popular and readily accepted, but midwives continued to play a role in childbirth. Midwifery also changed during this era due to increased regulation and the eventual need for midwives to become certified. Many European countries by the late 19th century were monitoring the training of midwives and issued certification based on competency. Midwives were no longer uneducated in the formal sense.
As midwifery began to develop so did the profession of obstetrics near the end of the century. Childbirth was no longer unjustifiably despised by the medical community as it once had been at the beginning of the century. But the specialty was still behind in its development stages in comparison to other medical specialities, and remained a generality in this era. Many male physicians would deliver children but very few would have referred to themselves as obstetricians. The end of the 19th century did mark a significant accomplishment in the profession with the advancements in asepsis and anaesthesia, which paved the way for the mainstream introduction and later success of the Caesarean Section.
Before the 1880s mortality rates in lying-hospitals would reach unacceptably high levels and became an area of public concern. Much of these maternal deaths were due to Puerperal fever, at the time commonly known as childbed fever. In the 1800s Dr. Ignaz Semmelweis noticed that women giving birth at home had a much lower incidence of childbed fever than those giving birth by physicians in lying-hospitals. His investigation discovered that washing hands with an antiseptic solution before a delivery reduced childbed fever fatalities by 90%. So it was concluded that it was physicians who had been spreading disease from one labouring mother to the next. Despite the publication of this information, doctors still would not wash. It was not until the 20th century when advancements in aseptic technique and the understanding of disease would play a significant role in the decrease of maternal mortality rates among many populations.
History of obstetrics in America.
The development of obstetrics as a practice for accredited doctors happened at the turn of the 18th century and thus was very differently developed in Europe and in the Americas due to the independence of many countries in the Americas from European powers. “Unlike in Europe and the British Isles, where midwifery laws were national, in America, midwifery laws were local and varied widely”.
Gynaecology and Obstetrics gained attention in the American medical field at the end of the nineteenth century through the development of such procedures as the ovariotomy. These procedures then were shared with European surgeons who replicated the surgeries. It should be noted that this was a period when antiseptic, aseptic or anaesthetic measures were just being introduced to surgical and observational procedures and without these procedures surgeries were dangerous and often fatal. Following are two surgeons noted for their contributions to these fields include Ephraim McDowell and James Marion Sims.
Ephraim McDowell developed a surgical practice in 1795 and performed the first ovariotomy in 1809 on a 47-year-old widow who then lived on for thirty-one more years. He had attempted to share this with John Bell whom he had practiced under who had retired to Italy. Bell was said to have died without seeing the document but it was published by an associate in "Extractions of Diseased Ovaria" in 1825. By the mid-century the surgery was both successfully and unsuccessfully being performed. Pennsylvanian surgeons the Attlee brothers made this procedure very routine for a total of 465 surgeries–John Attlee performed 64 successfully of 78 while his brother William reported 387– between the years of 1843 and 1883. By the middle of the nineteenth century this procedure was successfully performed in Europe by English surgeons Sir Spencer Wills and Charles Clay as well as French surgeons Eugène Koeberlé, Augeste Nélation and Jules Peau.
J. Marion Sims was the surgeon responsible for being the first treating a vesicovaginal fistula –a condition linked to many caused mainly by prolonged pressing of the feotus against the pelvis or other causes such as rape, hysterectomy, or other operations– and also having been doctor to many European royals and the 20th President of the United States James A. Garfield after he had been shot. Sims does have a controversial medical past. Under the beliefs at the time about pain and the prejudice towards African people, he had practiced his surgical skills and developed skills on slaves. These women were the first patients of modern gynecology. One of the women he operated on was named Anarcha, the woman he first treated for a fistula.
Historical role of gender.
Women and men inhabited very different roles in natal care up to the 18th century. The role of a physician was exclusively held by men who went to university, an overly male institution, who would theorize anatomy and the process of reproduction based on theological teaching and philosophy. Many beliefs about the female body and menstruation in the 17th and 18th centuries were inaccurate; clearly resulting from the lack of literature about the practice. Many of the theories of what caused menstruation prevailed from Hippocratic philosophy. Midwives of this time were those assisted in the birth and care of both born and unborn children, and as the name suggests this position held mainly by women.
During the birth of a child, men were rarely present. Women from the neighbourhood or family would join in on the process of birth and assist in many different ways. The one position where men would help with the birth of a child would be in the sitting position, usually when performed on the side of a bed to support the mother.
Men were introduced into the field of obstetrics in the nineteenth century and resulted in a change of the focus of this profession. Gynaecology directly resulted as a new and separate field of study from obstetrics and focused on the curing of illness and indispositions of female sexual organs. This had some relevance to some conditions as menopause, uterine and cervical problems, and childbirth could leave the mother in need of extensive surgery to repair tissue. But, there was also a large blame of the uterus for completely unrelated conditions. This led to many social consequences of the nineteenth century.

</doc>
<doc id="52967" url="https://en.wikipedia.org/wiki?curid=52967" title="Gynaecology">
Gynaecology

Gynecology or gynaecology is the medical practice dealing with the health of the female reproductive systems (vagina, uterus and ovaries) and the breasts. Literally, outside medicine, it means "the science of women". Its counterpart is andrology, which deals with medical issues specific to the male reproductive system.
Almost all modern gynaecologists are also obstetricians (see "obstetrics and gynaecology"). In many areas, the specialities of gynaecology and obstetrics overlap.
Etymology.
The word "gynaecology" comes from the Greek γυνή "gyne". "woman" and "-logia", "study."
History.
The Kahun Gynaecological Papyrus is the oldest known medical text of any kind. Dated to about 1800 B.C., it deals with women's complaints—gynaecological diseases, fertility, pregnancy, contraception, etc. The text is divided into thirty-four sections, each section dealing with a specific problem and containing diagnosis and treatment; no prognosis is suggested. Treatments are non surgical, comprising applying medicines to the affected body part or swallowing them. The womb is at times seen as the source of complaints manifesting themselves in other body parts.
The Hippocratic Corpus contains several gynaecological treatises dating to the 5th/4th centuries BC. The gynaecological treatise "Gynaikeia" by Soranus of Ephesus (1st/2nd century AD) is extant (together with a 6th-century Latin paraphrase by Muscio, a physician of the same school). He was the chief representative of the school of physicians known as the "Methodists".
J. Marion Sims is widely considered the father of modern gynaecology. Now criticized for the short comings. He developed some of his techniques by operating on slaves, many of whom were not given anesthesia.
Examination.
In some countries, women must first see a general practitioner (GP; also known as a family practitioner (FP)) prior to seeing a gynaecologist. If their condition requires training, knowledge, surgical procedure, or equipment unavailable to the GP, the patient is then referred to a gynaecologist. In the United States, however, law and many health insurance plans allow gynaecologists to provide primary care in addition to aspects of their own specialty. With this option available, some women opt to see a gynaecological surgeon for non-gynaecological problems without another physician's referral.
As in all of medicine, the main tools of diagnosis are clinical history and examination. Gynaecological examination is quite intimate, more so than a routine physical exam. It also requires unique instrumentation such as the speculum. The speculum consists of two hinged blades of concave metal or plastic which are used to retract the tissues of the vagina and permit examination of the cervix, the lower part of the uterus located within the upper portion of the vagina. Gynaecologists typically do a bimanual examination (one hand on the abdomen and one or two fingers in the vagina) to palpate the cervix, uterus, ovaries and bony pelvis. It is not uncommon to do a rectovaginal examination for complete evaluation of the pelvis, particularly if any suspicious masses are appreciated. Male gynaecologists may have a female chaperone for their examination. An abdominal and/or vaginal ultrasound can be used to confirm any abnormalities appreciated with the bimanual examination or when indicated by the patient's history.
Diseases.
Examples of conditions dealt with by a gynaecologist are:
There is some crossover in these areas. For example, a woman with urinary incontinence may be referred to a urologist.
Therapies.
As with all surgical specialties, gynaecologists may employ medical or surgical therapies (or many times, both), depending on the exact nature of the problem that they are treating. Pre- and post-operative medical management will often employ many standard drug therapies, such as antibiotics, diuretics, antihypertensives, and antiemetics. Additionally, gynaecologists make frequent use of specialized hormone-modulating therapies (such as Clomifene citrate and hormonal contraception) to treat disorders of the female genital tract that are responsive to pituitary and/or gonadal signals.
Surgery, however, is the mainstay of gynaecological therapy. For historical and political reasons, gynaecologists were previously not considered "surgeons", although this point has always been the source of some controversy. Modern advancements in both general surgery and gynaecology, however, have blurred many of the once rigid lines of distinction. The rise of sub-specialties within gynaecology which are primarily surgical in nature (for example urogynaecology and gynaecological oncology) have strengthened the reputations of gynaecologists as surgical practitioners, and many surgeons and surgical societies have come to view gynaecologists as comrades of sorts. As proof of this changing attitude, gynaecologists are now eligible for fellowship in both the American College of Surgeons and Royal Colleges of Surgeons, and many newer surgical textbooks include chapters on (at least basic) gynaecological surgery.
Some of the more common operations that gynaecologists perform include:
Specialist training.
In the UK the Royal College of Obstetricians and Gynaecologists, based in London, encourages the study and advancement of both the science and practice of obstetrics and gynaecology. This is done through postgraduate medical education and training development, and the publication of clinical guidelines and reports on aspects of the specialty and service provision. The RCOG International Office works with other international organisations to help lower maternal morbidity and mortality in under-resourced countries.
Gynaecologic oncology is a subspecialty of gynaecology, dealing with gynaecology-related cancer.
Gender of physicians.
Despite the patients being predominantly female, like all specialist areas of health, historically gynaecology has been dominated by male doctors. However, in recent times as many of the barriers to access the education and training required to successfully practice gynaecology were removed, women have started to outnumber the number of men in the field. There are a number of reasons for this, ranging from women being motivated to become gynaecologists after having bad experiences with male doctors to men choosing to specialize in different fields.
Possible reasons reported for the decrease in male gynaecologists range from there being a perception of a lack of respect from other doctors towards them, distrust about their motivations for wanting to work exclusively with female sexual organs and questions about their overall character, as well as a concern about being associated with other male gynaecologists who have been arrested for sex offences and limited future employment opportunities.
Surveys have also shown a large and consistent majority of women are uncomfortable being forced to have intimate exams done by a male doctor. They are also less likely to be embarrassed, so as a result talk more openly and in greater details, when discussing their sexual history with another woman rather than a man, leading to questions about the ability of male gynaecologists to offer quality care to patients. This, when coupled with more women choosing female physicians has decreased the employment opportunities for men choosing to become gynaecologists.
As women are becoming presented with a choice of their doctor's gender, their preferences are starting to being questioned too. Almost 70% of respondents to an online poll agreed it is normal for a husband to 'hate' that his wife saw a male gynecologist. While there have also been reports of relationships having ended due to selection of a male gynecologist with some men feeling their partner's desire to have another man touching and penetrating their sexual organs for a routine checkup when there were capable and qualified women available an act of infidelity. Interviews with male gynecologists where the doctors openly admitted they liked being 'hit on' by some patients while performing intimate exams further underlined many of the suspicion towards men choosing to become gynecologists.
In the United States, it has been reported that 4 in 5 students choosing a residency in gynaecology are now female. In Sweden, to counter the lack of demand for male gynecologists, women have had the right to choose their doctor removed from them. In Turkey, due to patient preference to be seen by another female, there are now few male gynaecologists working in the field.
There have been a number of legal challenges in the US against healthcare providers who have started hiring based on gender of physicians. Dr Mircea Veleanu argued, in part, that his former employers discriminated against him by accommodating the wishes of female patients who had requested female doctors for intimate exams. A male nurse complained about an advert for an all-female obstetrics and gynecology practice in Columbia, Maryland claiming this was a form of sexual discrimination. Dr. David Garfinkel, a New Jersey-based ob-gyn sued his former employer after being fired due to, as he claimed, "because I was male, I wasn't drawing as many patients as they'd expected".
So far, all legal challenges by male gynecologists to remove patient choice have failed due to there being protection in law for 'bona fide occupational qualification' which in previous cases involving wash-room attendants and male nurses have recognized a justification for gender-based requirements for certain jobs.

</doc>
<doc id="52970" url="https://en.wikipedia.org/wiki?curid=52970" title="Pete Rose">
Pete Rose

Peter Edward "Pete" Rose, Sr. (born April 14, 1941), also known by his nickname "Charlie Hustle", is an American former professional baseball player and manager. Rose played in Major League Baseball from 1963 to 1986, and managed from 1984 to 1989.
Rose, a switch hitter, is the all-time Major League leader in hits (4,256), games played (3,562), at-bats (14,053), singles (3,215), and outs (10,328). He won three World Series rings, three batting titles, one Most Valuable Player Award, two Gold Gloves, the Rookie of the Year Award, and also made 17 All-Star appearances at an unequaled five different positions (second baseman, left fielder, right fielder, third baseman, and first baseman). Rose won both of his Gold Gloves as an outfielder in 1969 and 1970.
In August 1989, three years after he retired as an active player, Rose agreed to permanent ineligibility from baseball amidst accusations that he gambled on baseball games while playing for and managing the Reds, including claims that he bet on his own team. In 1991, the Baseball Hall of Fame formally voted to ban those on the "permanently ineligible" list from induction, after previously excluding such players by informal agreement among voters. In 2004, after years of public denial, Rose admitted to betting on baseball and on, but not against, the Reds. The issue of Rose's possible reinstatement and election to the Hall of Fame remains a contentious one throughout baseball.
On June 22, 2015, ESPN concluded an investigation and determined that Rose bet on baseball while still a player, from 1984 to 1986. The investigation also made public the existence of records of bets made by Rose on baseball, which had been seized by US federal authorities from an associate of Rose.
In 2016, Rose was inducted into the Cincinnati Reds Hall of Fame.
Early life.
Pete Rose was born April 14, 1941 in Cincinnati, Ohio, one of four children born to Harry Francis "Pete" and LaVerne Rose. He was a member of the Order of DeMolay as a young boy, and was encouraged by his parents to participate in sports.
He played baseball and football at Western Hills High School. Although Rose was small for his age, he earned the starting running back position on his freshman football team. When he was not promoted to the varsity football team in his sophomore year, Rose was dejected and soon lost interest in his studies. At the end of the school year, Rose's teachers decreed that he would have to attend summer school or be held back. Harry Rose decided that it would be better for Pete to repeat a year of school than miss a summer playing baseball. Plus, it would give Pete an extra year to mature physically. When Pete reached his senior year, he had already used up his four years of sports eligibility, so in the spring of 1960, he joined the Class AA team sponsored by Frisch's Big Boy of Lebanon, Ohio in the Dayton Amateur League. He played catcher, second base and shortstop and compiled a .626 batting average. This would have been the pinnacle of Rose's baseball career if not for the help of his uncle Buddy Bloebaum. Bloebaum was a "Bird dog" scout for the Reds and he pleaded the case for his nephew. The Reds, who had recently traded away a number of prospects who turned out to be very good, decided to take a chance on Pete. Upon his graduation from high school, Rose signed a professional contract.
Playing career.
Cincinnati Reds (1963–78).
Rookie of the Year.
During a spring training game against the Chicago White Sox in 1963, the Reds' regular second baseman, Don Blasingame, pulled a groin muscle; Rose got his chance and made the most of it. During another spring training game against the New York Yankees, Whitey Ford gave him the derisive nickname "Charlie Hustle" after Rose sprinted to first base after drawing a walk. Despite (or perhaps because of) the manner in which Ford intended it, Rose adopted that nickname as a badge of honor. In Ken Burns' documentary "Baseball", Mickey Mantle claimed that Ford gave Rose the nickname after Rose, playing in left field, made an effort to climb the fence to try to catch a Mantle home run that everyone could see was headed over everything.
Rose made his major league debut on April 8, 1963 (Opening Day) against the Pittsburgh Pirates and drew a walk. After going 0-for-11, Rose got his first Major League hit on April 13, a triple off Pittsburgh's Bob Friend. He hit .273 for the year and won the National League Rookie of the Year Award, collecting 17 of 20 votes.
Rose entered the US Army Reserves after the 1963 baseball season. He was assigned to Fort Knox for six months of active duty, which was followed by six years of regular attendance with a 478th Engineering Battalion USAR at Fort Thomas, Kentucky. At Fort Knox, he was a platoon guide and graduated from United States Army Basic Training January 18, 1964, one week before his marriage to Karolyn. Rose then remained at Fort Knox to assist the sergeant in training the next platoon and to help another sergeant train the Fort's baseball team. Later in his Fort Thomas service, Rose served as company cook which entailed coming in early for the one weekend/month meeting so that he could get out early enough to participate in local Reds games. Other Reds players in the unit included Johnny Bench, Bobby Tolan and Darrel Chaney.
Early years.
On April 23, 1964, in the top of the ninth inning of a scoreless game in Colt Stadium, Rose reached first base on an error and scored on another error to make Houston Astros' Ken Johnson the first pitcher to lose a complete game no-hitter. However, he slumped late in the season, was benched, and finished with a .269 average. He continued to play in the Venezuelan Winter League with Leones del Caracas team during 1964–1965 season to improve his batting. Rose came back in 1965, leading the league in hits (209) and at-bats (670), and finishing sixth in NL MVP balloting. It was the first of his ten seasons with 200-plus hits, and his .312 batting average was the first of nine consecutive .300 seasons. He hit a career-high 16 home runs in 1966, then switched positions from second base to right field the following year.
In 1968, Rose started the season with a 22-game hit streak, missed three weeks (including the All-Star Game) with a broken thumb, then had a 19-game hit streak late in the season. He had to finish the season 6-for-9 to beat out Matty Alou and win the first of two close NL batting-title races with a .335 average. He finished second to St. Louis Cardinals pitcher Bob Gibson for the NL MVP award, earning six first place votes.
Rose had his best offensive season in 1969, setting a career high in batting (.348) and tying his career-best 16 homers. As the Reds' leadoff man, he was the team's catalyst, rapping 218 hits, walking 88 times and pacing the league in runs with 120. He hit 33 doubles, 11 triples, drove in 82 runs, slugged .512 (by far the highest mark of his long career), and had a .432 OBP (also a career best). Rose and Roberto Clemente were tied for the batting title going into the final game; Rose bunted for a base hit in his last at-bat of the season to beat out Clemente (.345).
1970 All-Star game.
On July 14, 1970, in brand-new Riverfront Stadium (opened just two weeks earlier), Rose was involved in one of the most infamous plays in All-Star Game history. Facing the California Angels' Clyde Wright in the 12th inning, Rose singled and advanced to second on another single by the Los Angeles Dodgers' Billy Grabarkewitz. The Chicago Cubs' Jim Hickman then singled sharply to center. Amos Otis' throw went past Cleveland Indians catcher Ray Fosse, as Rose barreled over Fosse to score the winning run. Fosse suffered a fractured and separated shoulder, which initially went undiagnosed until the following year. Fosse continued to hit for average (he finished the season at .307), but with diminished power—he had 16 home runs before the break but only two after. He played through the 1979 season, but never approached his first-year numbers. The collision also caused Rose to miss three games with a bruised knee.
1973 season.
In 1973, Rose led the league with 230 hits and a .338 batting average en route to winning the NL MVP award, and leading "the Big Red Machine" to the 1973 National League Championship Series against the New York Mets.
During the fifth inning of game three of the series, Joe Morgan hit a double play ball to Mets first baseman John Milner with Rose on first. Rose's slide into second attempting to break up the double play incited a fight with Mets shortstop Bud Harrelson, resulting in a bench-clearing brawl. The game was nearly called off when, after the Reds took the field, the Shea Stadium crowd threw objects from the stands at Rose, causing Reds manager Sparky Anderson to pull his team off the field until order was restored. Mets Manager Yogi Berra and players Willie Mays, Tom Seaver, Cleon Jones, and Rusty Staub were actually summoned by NL President Chub Feeney out to left field to calm the fans. The Reds ended up losing that game, 9–2, and the NLCS, 3–2, despite Rose's .381 batting average in the series, and his eighth-inning home run to tie Game One and his 12th-inning home run to win Game Four.
The Big Red Machine.
The Cincinnati Reds of the 1970s earned the nickname "the Big Red Machine", and is widely acknowledged as one of the greatest teams ever. On a team with many great players, Rose, along with Hall of Famers Johnny Bench, Joe Morgan and Tony Pérez, was viewed as one of the club's leaders.
In the year 1975, Rose earned the Hickok Belt as top professional athlete of the year and "Sports Illustrated" magazine's "Sportsman of the Year" award. The following year, he was a major force in helping the Reds repeat as World Series champions. The 1976 Reds swept the Phillies 3–0 in the 1976 National League Championship Series, then swept the Yankees 4–0 in the World Series. The 1976 Cincinnati Reds remain the only team since the expansion of the playoffs in 1969 to go undefeated in the postseason. The Reds had not lost a postseason game since Carlton Fisk's extra-inning home run in the 1975 World Series, a span of eight consecutive wins. A significant factor in the Reds' success was that in 1975 and 1976 Rose made a successful switch of his primary position from the outfield to third base. This move filled a void (3B) and helped to solidify the Reds team for these two championship seasons, as it enabled the team to make greater use of power hitting outfielder George Foster.
44-game hitting streak.
On May 5, 1978, Rose became the 13th player in major league history to collect his 3,000th career hit, with a single off Montreal Expos pitcher Steve Rogers. On June 14 in Cincinnati, Rose singled in the first inning off Cubs pitcher Dave Roberts; Rose would proceed to get a hit in every game he played until August 1, making a run at Joe DiMaggio's record 56-game hitting streak, which had stood virtually unchallenged for 37 years. The streak started quietly, but by the time it had reached 30 games, the media took notice and a pool of reporters accompanied Rose and the Reds to every game. On July 19 against the Philadelphia Phillies, Rose was hitless going into the ninth with his team trailing. He ended up walking in the eighth inning and the streak appeared over. But the Reds managed to bat through their entire lineup, giving Rose another chance to bat in the ninth inning. Facing Ron Reed, Rose laid down a perfect bunt single to extend the streak to 32 games.
He would eventually tie Willie Keeler's 1897 single season National League record at 44 games, but on August 1, the streak came to an end as Gene Garber of the Atlanta Braves struck out Rose in the ninth inning, with Garber leaping for joy in celebration. The competitive Rose was sour after the game, blasting Garber and the Braves for treating the situation "like it was the ninth inning of the seventh game of the World Series". Instead of being insulted, Garber took the comment as a compliment: "I said to myself, 'Well, thanks, Pete. That's how I try to pitch every time I'm in a game'."
Philadelphia Phillies (1979–83).
The Philadelphia Phillies had won the National League East three years running (1976–78) two of which were won with 101 win seasons, but were unable to make it to the World Series. In 1979, believing that he was the player who could bring them over the top, the Phillies temporarily made Rose the highest-paid athlete in team sports when they signed him to a four-year, $3.2-million contract as a free agent. With perennial All-Star Mike Schmidt firmly entrenched at third, Rose made the final position change of his career to first base.
Although they missed the postseason in his first year with the team, they earned three division titles (one in the first half of the strike shortened 1981 season), two World Series appearances and their first ever World Series title () in the following four years.
The worst season of Rose's career was also the season that the Phillies played in their second World Series in four years, 1983. Rose batted only .245 with 121 hits, and found himself benched during the latter part of the 1983 season, appearing periodically to play and pinch hit. Rose did blossom as a pinch-hitter, with 8 hits in 21 at-bats, a .381 average.
Rose bounced back during the postseason, batting .375 (6-for-16) during the N.L. Playoffs against the Los Angeles Dodgers, and .312 in the World Series (5-for-16). Rose collected only one hit in his first eight at-bats in the first two games in Baltimore against the 1983 A.L. Champions. Rose found himself benched for game three back in Philadelphia, and would ground out in a pinch-hitting appearance. Rose objected to manager Paul Owens' decision to bench him in a pre-game interview with ABC's Howard Cosell. Rose bounced back with four hits in his last seven at-bats in the remaining two games, though the Phillies lost to the Baltimore Orioles in the 1983 World Series, 4 games to 1.
Montreal Expos (1984).
Rose was granted an unconditional release from the Phillies in late October 1983. Phillies management wanted to retain Rose for the 1984 season, but he refused to accept a more limited playing role. Months later, he signed a one-year contract with the Montreal Expos. On April 13, 1984, the 21st anniversary of his first career hit, Rose doubled off the Phillies' Jerry Koosman for his 4,000th career hit, becoming the second player in the 4000 hit club (joining Ty Cobb).
The "Hit" King (1984–86).
Rose was traded back to the Reds for infielder Tom Lawless on August 15, 1984 and was immediately named player-manager, replacing Reds' manager Vern Rapp. Though he only batted .259 for the Expos, his average jumped to .365 with the Reds, as he managed them to a 19–22 record for the remainder of the season.
On September 11, 1985, Rose broke Ty Cobb's all-time hits record with his 4,192nd hit, a single to left-center field off San Diego Padres pitcher Eric Show. According to its web site, MLB.com, Major League Baseball continues to recognize Cobb's final hit total as 4,191, though independent research has revealed that two of Cobb's hits were counted twice. Because of this, it has been suggested that Rose actually broke Cobb's record against the Cubs' Reggie Patterson with a single in the first inning of a Reds' 5–5 called game against Chicago on September 8. Because Rose broke Cobb's record, ABC's Wide World of Sports named Rose its Athlete of the Year that year. Rose accumulated a total of 4,256 hits before his final career at-bat, a strikeout against San Diego's Rich Gossage on August 17, 1986.
Retirement from playing.
On November 11, 1986, Rose was dropped from the Reds' 40-man roster to make room for pitcher Pat Pacillo, and he unofficially retired as a player. Rose finished his career with a number of Major League and National League records that have lasted for many years. Rose, always proud of his ability to hit .300 or better in 15 of his 24 playing seasons, had a lifetime .303 batting average.
Remaining with the Reds as a non-playing manager after retiring as a player, Rose led the team from August 15, 1984 until August 24, 1989. With a career record as a manager of 426–388, Rose ranks fifth in Reds history for managerial wins. During Rose's four full seasons at the helm (1985–1988), the Reds posted four second-place finishes in the NL West division.
Thirty-day suspension.
On April 30, 1988, during a home game against the New York Mets, with two out in the top of the ninth inning, umpire Dave Pallone made a late call at first base that allowed what would become the eventual game-winning run to score. Rose argued the call vehemently and made physical contact with the umpire, forcefully pushing him. Rose told reporters after the game that he shoved Pallone only after the umpire made contact with him; he said a scratch near his left eye proved Pallone touched him first. In his 1990 book, Pallone claimed that scratch was self-inflicted in the clubhouse after the ejection. Cincinnati fans showered the field with various objects including radios and cigarette lighters. After a 15-minute suspension of play, Pallone left the field and the game was completed with the remaining three umpires. National League president A. Bartlett Giamatti suspended Rose for 30 days, which was the longest suspension ever levied for an on-field incident involving a manager. He also fined Rose "a substantial amount" for his conduct; the actual amount was not disclosed. Giamatti also summoned the Reds' on-air announcers, Marty Brennaman and Joe Nuxhall, to his office in New York City and dressed them down for inciting the fan response with "inflammatory and completely irresponsible remarks." He told Brennaman and Nuxhall, "There is no excuse for encouraging a situation where the physical safety and well-being of any individual is put significantly at risk. Nothing justifies such unprofessional behavior."
Permanent ineligibility.
Amid reports that he had bet on baseball, Rose was questioned in February 1989 by outgoing commissioner Peter Ueberroth and his replacement, Bart Giamatti. Rose denied the allegations and Ueberroth dropped the investigation. However, three days after Giamatti became Commissioner, lawyer John M. Dowd was retained to investigate these charges against Rose. "Sports Illustrated" gave the public their first detailed report of the allegations that Rose had placed bets on baseball games on March 21, 1989, in the cover story of the issue dated April 3, 1989.
Investigation.
Dowd interviewed many of Rose's associates, including alleged bookies and bet runners. He delivered a summary of his findings to the Commissioner in May. In it, Dowd documented Rose's alleged gambling activities in 1985 and 1986 and compiled a day-by-day account of Rose's alleged betting on baseball games in 1987. The Dowd Report documented his alleged bets on 52 Reds games in 1987, where Rose wagered a minimum of $10,000 a day. Others alleged to have been involved in the activities claim that number was actually $2,000 a day.
Response.
Rose continued to deny all of the accusations against him and refused to appear at a hearing with Giamatti on the matter. He filed a lawsuit in Hamilton County Common Pleas Court alleging that the Commissioner had prejudged the case and could not provide a fair hearing. A Cincinnati judge issued a temporary restraining order to delay the hearing, but Giamatti fought to have the case moved to Federal Court. The Commissioner prevailed in that effort, after which he and Rose entered settlement negotiations.
Aftermath.
On August 24, 1989, Rose voluntarily accepted a permanent place on baseball's ineligible list. Rose accepted that there was a factual reason for the ban; in return, Major League Baseball agreed to make no formal finding with regard to the gambling allegations. According to baseball's rules, Rose could apply for reinstatement in one year but Bart Giamatti said, "There is absolutely no deal for reinstatement. That is exactly what we did not agree to in terms of a fixed number of years." Rose, with a 412–373 record, was replaced as Reds manager by Tommy Helms. Rose began therapy with a psychiatrist for treatment of a gambling addiction.
Giamatti died of a heart attack on September 1, 1989, eight days after announcing Rose's suspension.
Betting for or against.
The Dowd Report says, "no evidence was discovered that Rose bet against the Reds", but investigator Dowd stated in a December 2002 interview that he believed Rose probably bet against the Reds while managing them. Those critical of Rose's behavior, including Ohio's own Hall of Fame baseball reporter, Hal McCoy, have observed that "the major problem with Rose betting on baseball, particularly the Reds, is that as manager he could control games, make decisions that could enhance his chances of winning his bets, thus jeopardizing the integrity of the game." The Major League Baseball rule that Rose violated prohibits "any" bet on a game the bettor is involved in, making no distinction between betting for or against one's team. The rule is: "Rule 21 Misconduct, (d) Betting on Ball Games, Any player, umpire, or club, or league official, or employee, who shall bet any sum whatsoever upon any baseball game in connection with which the bettor has a duty to perform shall be declared permanently ineligible."
Reinstatement efforts.
In 1992, Rose applied for reinstatement. Fay Vincent, who as deputy commissioner had played a key role in negotiating the agreement banning Rose before becoming commissioner after Giamatti's death, never acted on Rose's application. In September 1998, Rose applied for reinstatement with Vincent's successor Bud Selig, but Selig also never acted on it.
In public comments, Selig said he saw no reason to reconsider Rose's punishment; however, in March 2003, Selig acknowledged that he was considering Rose's application, leading to speculation that Rose's return might be imminent. Ultimately, however, Selig took no action.
Representatives for Rose applied in 2015 for reinstatement with Selig's successor Rob Manfred, but he rejected the request, saying said that Rose had not been forthcoming about his gambling and still bet on baseball legally (MLB has long barred players from "any" form of gambling, legal or otherwise), making lifting the ban an "unacceptable risk."
Tax evasion.
On April 20, 1990, Rose pleaded guilty to two charges of filing false income tax returns not showing income he received from selling autographs and memorabilia, and from horse racing winnings. On July 19, Rose was sentenced to five months in the medium security Prison Camp at the United States Penitentiary in Marion, Illinois and fined $50,000. Marion was the hometown of Fosse, the man who Rose bowled over during the All-Star game nearly 20 years prior, resulting in injuries that would plague Fosse for the rest of his career.
He was released on January 7, 1991 after having paid $366,041 in back taxes and interest, and was required to perform 1,000 hours of community service.
Hall of Fame eligibility.
On February 4, 1991, the Hall of Fame voted formally to exclude individuals on the permanently ineligible list from being inducted into the Hall of Fame by way of the Baseball Writers' Association of America vote. However, a longstanding unwritten rule already barred permanently ineligible players from enshrinement. Rose and Jenrry Mejía are the only living members of the ineligible list. Players who were not selected by the BBWAA could be considered by the Veterans Committee in the first year after they would have lost their place on the Baseball Writers' ballot. Under the Hall's rules, players may appear on the ballot for only fifteen years, beginning five years after they retire. Had he not been banned from baseball, Rose's name could have been on the writers' ballot beginning in 1992 and ending in 2006. He would have been eligible for consideration by the Veterans Committee in 2007, but did not appear on the ballot. In 2008 the Veterans Committee barred players and managers on the ineligible list from consideration.
MLB All-Century team.
In 1999, Rose was selected as an outfielder on the Major League Baseball All-Century Team. To select the team, a panel of experts first compiled a list of the 100 greatest players from the past century. Fans then voted on the players using paper and online ballots.
An exception was made to his ban to allow him to participate in the pre-game introduction of the All-Century team before Game 2 of the 1999 World Series between the Braves and Yankees. Despite never having been a member of the Braves, Rose received the loudest ovation of the All-Century team members from the crowd at Turner Field in Atlanta, Georgia.
After the ceremony on live television, NBC's Jim Gray repeatedly asked Rose if he was ready to admit to betting on baseball and apologize. Many people were outraged over Gray's aggressive questioning, feeling that it detracted from the ceremony. In protest, Yankees outfielder Chad Curtis refused to speak with Gray after his game-winning home run in Game 3. Earlier that season, Rose had been ranked at number 25 on "The Sporting News"' list of the 100 Greatest Baseball Players.
While allowing him to participate in the All-Century Team, and a September 2010 celebration at Great American Ball Park of the 25th anniversary of Rose's 4,192nd hit, MLB has refused to allow him to participate in other events in Cincinnati, such as the 25th anniversary reunion of the Big Red Machine, the closing of Cinergy Field, and the opening of Great American Ball Park, as well as the closing of Veterans Stadium in Philadelphia and 1980 Phillies anniversary celebrations.
Coming clean.
In his autobiography "My Prison Without Bars", published by Rodale Press on January 8, 2004, Rose finally admitted publicly to betting on baseball games and other sports while playing for and managing the Reds. He also admitted to betting on Reds games, but said that he never bet against the Reds. He repeated his admissions in an interview on the ABC news program "Primetime Thursday". He also said in the book that he hoped his admissions would help end his ban from baseball so that he could reapply for reinstatement.
In March 2007, during an interview on "The Dan Patrick Show" on ESPN Radio, Rose said, "I bet on my team every night. I didn't bet on my team four nights a week. I bet on my team to win every night because I loved my team, I believed in my team", he said. "I did everything in my power every night to win that game."
John Dowd disputed Rose's contention that he bet on the Reds every night, asserting that Rose did not bet on his team when Mario Soto or Bill Gullickson pitched.
However, Dowd's allegations did not match the records contained in his own report. A notebook detailing Rose's daily betting activity shows that Rose did in fact place bets on 5 of the 6 games Soto started in 1987. The lone exception was April 26, 1987, when Rose allegedly placed bets on hockey and basketball games but no baseball games. Those records also show he bet on every game that Gullickson started during the time period which the betting notebook covered.
The criticism of Rose did not diminish after this admission—some Rose supporters were outraged that Rose would reverse fifteen years of denial as part of a book publicity tour. In addition, the timing was called into question—by making his admission just two days after the Baseball Hall of Fame announced its class of 2004 inductees, Rose appeared to be linking himself publicly to the Hall.
Even after his 2004 admission of gambling, Rose had described his violation of MLB rules with what journalist Kostya Kennedy described as "a kind of swagger, that familiar screw-you defiance". On September 11, 2010, however, at a roast of Rose held at Hollywood Casino Lawrenceburg in Indiana on the 25th anniversary of his 4,192nd hit and attended by many teammates, Rose wept while acknowledging that he had "disrespected baseball". He apologized to Pérez and other members of the Big Red Machine, stating, "I guarantee everyone in this room I will never disrespect you again. I love the fans, I love the game of baseball, and I love Cincinnati baseball". His words and crying surprised those present; a "Cincinnati Enquirer" reporter said "It felt completely unscripted, completely sincere and very powerful. I had covered Rose for more than 25 years and hadn't ever heard him like that".
WWE.
Between 1998 and 2000, Rose appeared at World Wrestling Entertainment's annual "WrestleMania" pay-per-view event, in what became a running gag. At "WrestleMania XIV" he served as "guest ring announcer" during a match between Kane and the Undertaker, before which he took a Tombstone Piledriver from Kane (nicknamed "The Big Red Machine" for his red ring attire). For the next year's "WrestleMania XV", Rose was portrayed as seeking revenge. To do so he dressed as the San Diego Chicken and "attacked" Kane before his scheduled match, only to take another Tombstone. He returned for a third time the following year, at "WrestleMania 2000", but again was thwarted by Kane, as well as Rikishi, his tag team partner that night.
In addition to these three appearances, he appeared in a Halloween-themed commercial for WWE's No Mercy event in 2002 and was chokeslammed by Kane. In 2004, Rose was inducted into the "Celebrity Wing" of the WWE Hall of Fame. He was the first celebrity to go into the Hall, and was inducted at a ceremony prior to "WrestleMania XX" by Kane himself.
On March 22, 2010, he appeared as the guest host on WWE Raw, which was the last episode of Raw before "WrestleMania XXVI". As his first order of business, he set up a match between Shawn Michaels and Kane, which Michaels won. Later on in the night, Kane attacked Rose offscreen.
Rose was briefly mentioned on WWE television again on August 27, 2012. In an anger management segment, Kane stated that "for reasons never quite explained, I have an unhealthy obsession with torturing Pete Rose." Rose was later interviewed on WWE.com about his experiences with Kane's anger.
Fox Sports analyst.
On April 16, 2015, it was announced that Rose had been hired by Fox Sports to serve as a guest studio color analyst for MLB coverage on Fox and Fox Sports 1, appearing on the "MLB on Fox" pregame show as well as "MLB Whiparound", "America's Pregame", and "Fox Sports Live". He made his Fox Sports 1 debut on May 11, 2015.
Personal life.
Rose married Karolyn Englehardt on January 25, 1964, and the couple had two children, daughter Fawn (born on December 29, 1964) and son Pete Rose Jr. (born on November 16, 1969). The couple divorced in 1980. In 1978, a paternity suit was filed naming Rose as the father of Morgan Erin Rubio. In a 1996 settlement of the lawsuit, Rose acknowledged that Rubio was his daughter.
Rose married his second wife, Carol J. Woliung, in 1984. They have two children, son Tyler (born on October 1, 1984) and daughter Cara (born on August 22, 1989). Rose finalized his divorce from Carol in March 2011. The 69-year-old Rose cited irreconcilable differences for the split, but his petition did not offer any additional details. Rose did not include a date for their separation. Documents in the filing say that Rose is looking to acquire all memorabilia and other possessions before the marriage.
Rose began openly having a relationship with Kiana Kim, a "Playboy" model, while separated from his second wife. During a 2009 interview, Rose discussed his relationship with Kim, stating, "My girl has finally decided to try to shoot for "Playboy", and they were kind enough to give her an opportunity to come to Houston for an interview, and we're excited about that." A reality show called "", following the life of Rose and Kim, and his two step children Cassie and Ashton which premiered on TLC on January 14, 2013. Rose and Kim have been engaged since 2011. They appeared on a national Sketchers commercial which aired during the 2014 Super Bowl.
Two of Rose's children have lived public lives. Cara has worked as a television actress, appearing as a regular in the first season of the soap opera "Passions" and playing a recurring role on "Melrose Place". She uses the stage name "Chea Courtney". His older son, Pete Rose, Jr., spent 16 years as a minor league baseball player, advancing to the majors once for an 11-game stint with the Cincinnati Reds in 1997.

</doc>
<doc id="52974" url="https://en.wikipedia.org/wiki?curid=52974" title="Emergency medicine">
Emergency medicine

Emergency medicine is the medical specialty involving care for undifferentiated and unscheduled patients with illnesses or injuries requiring immediate medical attention. In their role as first-line providers, emergency physicians are responsible for initiating investigations and interventions to diagnose and/or treat patients in the acute phase (including initial resuscitation and stabilization), coordinating care with physicians from other specialities, and making decisions regarding a patient's need for hospital admission, observation, or discharge. Emergency physicians generally practice in hospital emergency departments, pre-hospital settings via emergency medical services, and intensive care units, but may also work in primary care settings such as urgent care clinics.
Originally the domain of surgeons, general practitioners and other generalist physicians, it is only in recent decades that emergency medicine has become recognised as a speciality in its own right. In many developed countries, emergency medicine is now recognized as an essential public service and has achieved recognition for its contributions to public health and academic medicine. Most academic medical centers have independent departments of emergency medicine, and the specialty is now a popular choice among medical students and residents. In developing countries, emergency medicine is still evolving and international emergency medicine programs offer hope of improving basic emergency care where resources are limited.
Scope.
The field of emergency medicine encompasses care involving the acute care of internal medical and surgical conditions. In many modern emergency departments, Emergency physicians are tasked with seeing a large number of patients, treating their illnesses and arranging for disposition—either admitting them to the hospital or releasing them after treatment as necessary. The emergency physician requires a broad field of knowledge and advanced procedural skills often including surgical procedures, trauma resuscitation, advanced cardiac life support and advanced airway management. They must have the skills of many specialists—the ability to resuscitate a patient (critical care medicine), manage a difficult airway (anesthesia), suture a complex laceration (plastic surgery), reduce (set) a fractured bone or dislocated joint (orthopedic surgery), treat a heart attack (cardiology), manage strokes (neurology), work-up a pregnant patient with vaginal bleeding (obstetrics and gynecology), stop a severe nosebleed (ENT), place a chest tube (cardiothoracic surgery), and to conduct and interpret x-rays and ultrasounds (radiology). Emergency physicians also provide episodic primary care to patients during off hours and for those who do not have primary care providers.
Emergency medicine is distinct from urgent care, which refers to immediate healthcare for less emergent medical issues. However, many emergency physicians work in urgent care settings, since there is obvious overlap. Emergency medicine also includes many aspects of acute primary care, and shares with family medicine the uniqueness of seeing all patients regardless of age, gender or organ system . The emergency physician workforce also includes many competent physicians who trained in other specialties.
Physicians specializing in emergency medicine can enter fellowships to receive credentials in subspecialties such as palliative care, critical-care medicine, medical toxicology, wilderness medicine, pediatric emergency medicine, sports medicine, disaster medicine, tactical medicine, ultrasound, pain medicine, pre-hospital emergency medicine, or undersea and hyperbaric medicine.
The practice of emergency medicine is often quite different in rural areas where there are far fewer consultants and health care resources. In these areas, family physicians with additional skills in emergency medicine often staff emergency departments. Rural emergency physicians may be the only health care providers in the community, and require skills that include primary care and obstetrics.
Work patterns.
Patterns vary by country and region. In the United States, the employment arrangement of emergency physician practices are either private (with a co-operative group of doctors staffing an emergency department under contract), institutional (physicians with an independent contractor relationship with the hospital), corporate (physicians with an independent contractor relationship with a third-party staffing company that services multiple emergency departments), or governmental (for example, when working within military services, public health services, veterans' benefit systems or other government agencies).
In the United Kingdom, all consultants in emergency medicine work in the National Health Service and there is little scope for private emergency practice. In other countries like Australia, New Zealand or Turkey, emergency medicine specialists are almost always salaried employees of government health departments and work in public hospitals, with pockets of employment in private or non-government aeromedical rescue or transport services, as well as some private hospitals with emergency departments; they may be supplemented or backed by non-specialist medical officers, and visiting general practitioners. Rural emergency departments may be headed by general practitioners alone, sometimes with non-specialist qualifications in emergency medicine.
History.
During the French Revolution, after seeing the speed with which the carriages of the French flying artillery maneuvered across the battlefields, French military surgeon Dominique Jean Larrey applied the idea of ambulances, or "flying carriages", for rapid transport of wounded soldiers to a central place where medical care was more accessible and effective. Larrey manned ambulances with trained crews of drivers, corpsmen and litter-bearers and had them bring the wounded to centralized field hospitals, effectively creating a forerunner of the modern MASH units. Dominique Jean Larrey is sometimes called the father of emergency medicine for his strategies during the French wars.
Emergency medicine as an independent medical specialty is relatively young. Prior to the 1960s and 1970s, hospital emergency departments (EDs) were generally staffed by physicians on staff at the hospital on a rotating basis, among them family physicians, general surgeons, internists, and a variety of other specialists. In many smaller emergency departments, nurses would triage patients and physicians would be called in based on the type of injury or illness. Family physicians were often on call for the emergency department, and recognized the need for dedicated emergency department coverage. Many of the pioneers of emergency medicine were family physicians and other specialists who saw a need for additional training in emergency care.
During this period, groups of physicians began to emerge who had left their respective practices in order to devote their work completely to the ED. In the UK in 1952, Maurice Ellis was appointed as the first "casualty consultant" at Leeds General Infirmary. In 1967, the Casualty Surgeons Association was established with Maurice Ellis as its first President. In the US, the first of such groups was headed by Dr. James DeWitt Mills in 1961 who, along with four associate physicians; Dr. Chalmers A. Loughridge, Dr. William Weaver, Dr. John McDade, and Dr. Steven Bednar at Alexandria Hospital, Virginia, established 24/7 year-round emergency care, which became known as the "Alexandria Plan".
It was not until the establishment of American College of Emergency Physicians (ACEP), the recognition of emergency medicine training programs by the AMA and the AOA, and in 1979 a historical vote by the American Board of Medical Specialties that emergency medicine became a recognized medical specialty in the US. The first emergency medicine residency program in the world was begun in 1970 at the University of Cincinnati and the first Department of Emergency Medicine at a US medical school was founded in 1971 at the University of Southern California.
In 1990 the UK's Casualty Surgeons Association changed its name to the British Association for Accident and Emergency Medicine, and subsequently became the British Association for Emergency Medicine (BAEM) in 2004. In 1993, an intercollegiate Faculty of Accident and Emergency Medicine (FAEM) was formed as a "daughter college" of six medical royal colleges in England and Scotland to arrange professional examinations and training. In 2005, the BAEM and the FAEM were merged to form the College of Emergency Medicine, now the Royal College of Emergency Medicine, which conducts membership and fellowship examinations and publishes guidelines and standards for the practise of emergency medicine.
Training.
There are a variety of international models for emergency medicine training. Among those with well developed training programs there are two different models: a "specialtist" model or "a multidisciplinary model". Additionally, in some countries the emergency medicine specialist rides in the ambulance. For example, in France and Germany the physician, often an anesthesiologist, rides in the ambulance and provides stabilizing care at the scene. The patient is then triaged to the appropriate department of a hospital, so emergency care is much more multidisciplinary than in the Anglo-American model.
In countries such as the US, the United Kingdom, Canada and Australia, ambulances transport patients to emergency departments and there is more dependence on paramedics and EMTs for on-scene care. Emergency physicians are therefore more " specialists", since all patients are taken to the emergency department. Most developing countries follow the Anglo-American model: 3 or 4 year, independent residency training programs in emergency medicine are the gold standard. Some countries develop training programs based on a primary care foundation with additional emergency medicine training. In developing countries, there is an awareness that Western models may not be applicable and may not be the best use of limited health care resources. For example, specialty training and pre-hospital care like that in developed countries is too expensive and impractical for use in many developing countries with limited health care resources. International emergency medicine provides an important global perspective and hope for improvement in these areas.
A brief review of some of these programs follows:
Argentina.
In Argentina, the SAE (Sociedad Argentina de Emergencias) is the main organization of Emergency Medicine.There are a lot of residency programs. Also is possible to reach the certification with a two-year postgraduate university course after a few years of ED background.
Australia and New Zealand.
The specialist medical college responsible for Emergency Medicine in Australia and New Zealand is the Australasian College for Emergency Medicine (ACEM). The training program is nominally seven years in duration, after which the trainee is awarded a Fellowship of ACEM, conditional upon passing all necessary assessments.
Dual fellowship programs also exist for Paediatric Medicine (in conjunction with the Royal Australasian College of Physicians) and Intensive Care Medicine (in conjunction with the College of Intensive Care Medicine). These programs nominally add one or more years to the ACEM training program.
For medical doctors not (and not wishing to be) specialists in Emergency Medicine but have a significant interest or workload in emergency departments, the ACEM provides non-specialist certificates and diplomas.
Canada.
The two routes to emergency medicine certification can be summarized as follows:
CCFP(EM) emergency physicians outnumber FRCP(EM) physicians by a ratio of about 3 to 1, and they tend to work primarily as clinicians with a smaller focus on academic activities such as teaching and research. FRCP(EM) Emergency Medicine Board specialists tend to congregate in academic centers and tend to have more academically oriented careers, which emphasize administration, research, critical care, disaster medicine, and teaching. They also tend to sub-specialize in toxicology, critical care, pediatrics emergency medicine, and sports medicine. Furthermore, the length of the FRCP(EM) residency allows more time for formal training in these areas.
China.
The current post-graduate Emergency Medicine training process is highly complex in China. The first EM post-graduate training took place in 1984 at the Peking Union Medical College Hospital. Because specialty certification in EM has not been established, formal training is not required to practice Emergency Medicine in China.
About a decade ago, Emergency Medicine residency training was centralized at the municipal levels, following the guidelines issued by The Ministry of Public Health. Residency programs in all hospitals are called residency training bases, which have to be approved by local health governments. These bases are hospital-based, but the residents are selected and managed by the municipal associations of medical education. These associations are also the authoritative body of setting up their residents' training curriculum. All medical school graduates wanting to practice medicine have to go through 5 years of residency training at designated training bases, first 3 years of general rotation followed by 2 more years of specialty-centered training.
India.
India is an example of how family medicine can be a foundation for emergency medicine training. Many private hospitals and institutes have been providing Emergency Medicine training for doctors, nurses & paramedics since 1994, with certification programs varying from 6 months to 3 years. However, emergency medicine was only recognized as a separate specialty by the Medical Council of India in July 2009.
Malaysia.
There are three universities (Universiti Sains Malaysia, Universiti Kebangsaan Malaysia, & Universiti Malaya) that offer master's degrees in emergency medicine - postgraduate training programs of four years in duration with clinical rotations, examinations and a dissertation. The first cohort of locally trained emergency physicians graduated in 2002.
Saudi Arabia.
In Saudi Arabia, Certification of Emergency Medicine is done by taking the 4-year program Saudi Board of Emergency Medicine (SBEM), which is accredited by Saudi Council for Health Specialties (SCFHS). It requires passing the two-part exam: first part and final part (written and oral) to obtain the SBEM certificate, which is equivalent to Doctorate Degree.
United States.
Most programs are three years in duration, but some programs are four years long. There are several combined residencies offered with other programs including family medicine, internal medicine and pediatrics. The US is well known for its excellence in emergency medicine residency training programs. This has led to some controversy about specialty certification. There are three ways to become board-certified in emergency medicine:
A number of ABMS fellowships are available for Emergency Medicine graduates including pre-hospital medicine (emergency medical services), critical care, hospice and palliative care, research, undersea and hyperbaric medicine, sports medicine, pain medicine, ultrasound, pediatric Emergency Medicine, disaster medicine, wilderness medicine, toxicology, and critical care medicine.
In recent years, workforce data has led to a recognition of the need for additional training for primary care physicians who provide emergency care. This has led to a number of supplemental training programs in first hour emergency care, and a few fellowships for family physicians in emergency medicine.
United Kingdom.
In the United Kingdom, the Royal College of Emergency Medicine have a role in setting the professional standards and the assessment of trainees. Emergency medical trainees enter specialty training after five or six years of Medical school followed by two years of foundation training. Specialty training takes six years to complete and success in the assessments and a set of five examinations results in the award of Fellowship of the Royal College of Emergency Medicine (FRCEM).
Historically, emergency specialists were drawn from anaesthesia, medicine, and surgery. Many established EM consultants were surgically trained; some hold the Fellowship of Royal College of Surgeons of Edinburgh in Accident and Emergency — FRCSEd(A&E). Trainees in Emergency Medicine may dual accredit in Intensive care medicine or seek sub-specialisation in Paediatric Emergency Medicine.
Turkey.
Emergency Medicine residency lasts for 4 years in Turkey. These physicians have a 2-year Obligatory Service in Turkey to be qualified to have their diploma. After this period, EM specialist can choose to work in private or governmental ED's.
Pakistan.
Emergency Medicine training in Pakistan lasts for 5 years. The initial 2 years involve trainees to be sent to three major areas which include Medicine and allied, Surgery and Allied and critical care. It is divided into six months each and the rest six months out of first two years are spent in emergency department. In last three years trainee residents spend most of their time in emergency room as senior residents. Certificate courses include ACLS, PALS, ATLS, and research and dissertations are required for successful completion of the training. At the end of 5 years, candidates become eligible for sitting for FCPS part II exam. After fulfilling the requirement they become fellow of College of Physicians and Surgeons Pakistan in Emergency Medicine.
Presently there are two institutions where you can acquire this training which are Shifa International Hospitals Islamabad and Aga Khan Hospital Karachi. there are approximately 30 residents in different years of training, while the College has conducted its first exit examination for the FCPS in Emergency Medicine during December 2015.
Iran.
The first residency program in Iran started in 2002 at Iran University of Medical Sciences, and there are now three-year standard residency programs running in Tehran, Tabriz, Mashhad, Isfahan, and some other universities. All these programs work under supervision of Emergency Medicine specialty board committee. There are now more than 200 (and increasing) board-certified Emergency Physicians in Iran.

</doc>
<doc id="52975" url="https://en.wikipedia.org/wiki?curid=52975" title="Emergency medical services">
Emergency medical services

Emergency medical services, also known as ambulance services or paramedic services (abbreviated to the initialism EMS, EMAS, EMARS or SAMU in some countries), are a type of emergency service dedicated to providing out-of-hospital acute medical care, transport to definitive care, and other medical transport to patients with illnesses and injuries which prevent the patient from transporting themselves. Emergency medical services may also be locally known as a paramedic service, a first aid squad, emergency squad, rescue squad, ambulance squad, ambulance service, ambulance corps, or life squad.
The goal of most emergency medical services is to either provide treatment to those in need of urgent medical care, with the goal of satisfactorily treating the presenting conditions, or arranging for timely removal of the patient to the next point of definitive care. This is most likely an emergency department at a hospital. The term emergency medical service evolved to reflect a change from a simple system of ambulances providing only transport, to a system in which preliminary medical care is given on scene and during transport. In some developing regions, the term is not used, or may be used inaccurately, since the service in question does not provide treatment to the patients, but only the provision of transport to the point of care.
In most places in the world, the EMS is summoned by members of the public (or other emergency services, businesses, or authorities) via an emergency telephone number which puts them in contact with a control facility, which will then dispatch a suitable resource to deal with the situation.
In some parts of the world, the emergency medical service also encompasses the role of moving patients from one medical facility to an alternative one; usually to facilitate the provision of a higher level or more specialized field of care but also to transfer patients from a specialized facility to a local hospital or nursing home when they no longer require the services of that specialized hospital, such as following successful cardiac catheterization due to a heart attack. In such services, the EMS is not summoned by members of the public but by clinical professionals (e.g. physicians or nurses) in the referring facility. Specialized hospitals that provide higher levels of care may include services such as neonatal intensive care (NICU), pediatric intensive care (PICU), state regional burn centres, specialized care for spinal injury and/or neurosurgery, regional stroke centers, specialized cardiac care (Cardiac catheterization), and specialized/regional trauma care.
In some jurisdictions, EMS units may handle technical rescue operations such as extrication, water rescue, and search and rescue. Training and qualification levels for members and employees of emergency medical services vary widely throughout the world. In some systems, members may be present who are qualified only to drive ambulances, with no medical training. In contrast, most systems have personnel who retain at least basic first aid certifications, such as Basic Life Support (BLS). Additionally many EMS systems are staffed with Advanced Life Support (ALS) personnel, including paramedics, nurses, or, less commonly, physicians.
History.
Emergency care in the field has been rendered in different forms since the beginning of recorded history. The New Testament contains the parable of the Good Samaritan, where a man who was beaten is cared for by a Samaritan. Luke 10:34 (NIV) - "He went to him and bandaged his wounds, pouring on oil and wine. Then he put the man on his own donkey, took him to an inn and took care of him." Also during the Middle Ages, the Knights Hospitaller were known for rendering assistance to wounded soldiers in the battlefield.
The first use of the ambulance as a specialized vehicle, in battle came about with the "ambulances volantes" designed by Dominique Jean Larrey (1766–1842), Napoleon Bonaparte's chief surgeon. Larrey was present at the battle of Spires, between the French and Prussians, and was distressed by the fact that wounded soldiers were not picked up by the numerous ambulances (which Napoleon required to be stationed two and half miles back from the scene of battle) until after hostilities had ceased, and set about developing a new ambulance system. Having decided against using the Norman system of horse litters, he settled on two- or four-wheeled horse-drawn wagons, which were used to transport fallen soldiers from the (active) battlefield "after" they had received early treatment in the field. Larrey's projects for 'flying ambulances' were first approved by the Committee of Public Safety in 1794. Larrey subsequently entered Napoleon's service during the Italian campaigns in 1796, where his ambulances were used for the first time at Udine, Padua and Milan, and he adapted his ambulances to the conditions, even developing a litter which could be carried by a camel for a campaign in Egypt.
In civilian ambulances, a major advance was made (which in future years would come to shape policy on hospitals and ambulances) with the introduction of a transport carriage for cholera patients in London during 1832. The statement on the carriage, as printed in "The Times", said "The curative process commences the instant the patient is put in to the carriage; time is saved which can be given to the care of the patient; the patient may be driven to the hospital so speedily that the hospitals may be less numerous and located at greater distances from each other". This tenet of ambulances providing instant care, allowing hospitals to be spaced further apart, displays itself in modern emergency medical planning.
The first known hospital-based ambulance service operated out of Commercial Hospital, Cincinnati, Ohio (now the Cincinnati General) by 1865. This was soon followed by other services, notably the New York service provided out of Bellevue Hospital which started in 1869 with ambulances carrying medical equipment, such as splints, a stomach pump, morphine, and brandy, reflecting contemporary medicine.
In June 1887 the St John Ambulance Brigade was established to provide first aid and ambulance services at public events in London. It was modelled on a military-style command and discipline structure.
The earliest emergency medical service was reportedly the rescue society founded by Jaromir V. Mundy, Count J. N. Wilczek, and Eduard Lamezan-Salins in Vienna after the disastrous fire at the Vienna Ring Theater in 1881. Named the "Vienna Voluntary Rescue Society," it served as a model for similar societies worldwide.
Also in the late 19th century, the automobile was being developed, and in addition to horse-drawn models, early 20th century ambulances were powered by steam, gasoline, and electricity, reflecting the competing automotive technologies then in existence. However, the first motorized ambulance was brought into service in the last year of the 19th century, with the Michael Reese Hospital, Chicago, taking delivery of the first automobile ambulance, donated by 500 prominent local businessmen, in February 1899. This was followed in 1900 by New York City, who extolled its virtues of greater speed, more safety for the patient, faster stopping and a smoother ride. These first two automobile ambulances were electrically powered with 2 hp motors on the rear axle.
American historians claim that the world's first component of civilian pre-hospital care on scene began in 1928, when "Julien Stanley Wise started the Roanoke Life Saving and First Aid Crew in Roanoke, Virginia, which was the first land-based rescue squad in the nation." Canadian historians dispute this with the city of Toronto claiming "The first formal training for ambulance attendants was conducted in 1892."
During World War One, further advances were made in providing care before and during transport – traction splints were introduced during World War I, and were found to have a positive effect on the morbidity and mortality of patients with leg fractures. Two-way radios became available shortly after World War I, enabling for more efficient radio dispatch of ambulances in some areas. Shortly before World War II, then, a modern ambulance carried advanced medical equipment, was staffed by a physician, and was dispatched by radio. In many locations, however, ambulances were hearses - the only available vehicle that could carry a recumbent patient - and were thus frequently run by funeral homes. These vehicles, which could serve either purpose, were known as combination cars.
Prior to World War II, hospitals provided ambulance service in many large cities. With the severe manpower shortages imposed by the war effort, it became difficult for many hospitals to maintain their ambulance operations. City governments in many cases turned ambulance services over to the police or fire department. No laws required minimal training for ambulance personnel and no training programs existed beyond basic first aid. In many fire departments, assignment to ambulance duty became an unofficial form of punishment.
Advances in the 1960s, especially the development of CPR and defibrillation as the standard form of care for out-of-hospital cardiac arrest, along with new pharmaceuticals, led to changes in the tasks of the ambulances. In Belfast, Northern Ireland the first experimental mobile coronary care ambulance successfully resuscitated patients using these technologies. One well-known report in the USA during that time was "Accidental Death and Disability: The Neglected Disease of Modern Society". This report is commonly known as The White Paper. These studies, along with the White Paper report, placed pressure on governments to improve emergency care in general, including the care provided by ambulance services. In the USA prior to the 1970s, ambulance service was largely unregulated. While some areas ambulances were staffed by advanced first-aid-level responders, in other areas, it was common for the local undertaker, having the only transport in town in which one could lie down, to operate both the local furniture store (where he would make coffins as a sideline) and the local ambulance service. The government reports resulted in the creation of standards in ambulance construction concerning the internal height of the patient care area (to allow for an attendant to continue to care for the patient during transport), and the equipment (and thus weight) that an ambulance had to carry, and several other factors.
In 1971 a progress report was published at the annual meeting, by the then president of American Association of Trauma, Sawnie R. Gaston M.D. Dr. Gaston reported the study was a "superb white paper" that "jolted and wakened the entire structure of organized medicine. This report is created as a "prime mover" and made the "single greatest contribution of its kind to the improvement of emergency medical services". Since this time a concerted effort has been undertaken to improve emergency medical care in the pre-hospital setting. Such advancements included Dr. R Adams Cowley creating the country's first statewide EMS program, in Maryland.
Service providers.
Some countries closely regulate the industry (and may require anyone working on an ambulance to be qualified to a set level), whereas others allow quite wide differences between types of operator.
Purpose.
Emergency medical services exists to fulfill the basic principles of first aid, which are to Preserve Life, Prevent Further Injury, and Promote Recovery.
This common theme in medicine is demonstrated by the "star of life". The Star of Life shown here, where each of the 'arms' to the star represent one of the six points, which are used to represent the six stages of high quality pre-hospital care, which are:
Levels of care.
Emergency Medical Service is provided by a variety of individuals, using a variety of methods. To some extent, these will be determined by country and locale, with each individual country having its own 'approach' to how EMS should be provided, and by whom. In some parts of Europe, for example, legislation insists that efforts at providing advanced life support (ALS) Mobile Intensive Care Units (MICU) services must be physician-staffed, while other permit some elements of that skill set to specially trained nurses, but have no paramedics. Elsewhere, as in North America, the UK and Australasia, ALS services are performed by paramedics, but rarely with the type of direct "hands-on" physician leadership seen in Europe. Increasingly, particularly in the UK and in South Africa, the role is being provided by specially trained paramedics who are independent practitioners in their own right. Beyond the national model of care, the type Emergency Medical Service will be determined by local jurisdictions and medical authorities, based upon the needs of the community, and the economic resources to support it.
A category of emergency medical service which is known as 'medical retrieval' or "rendez vous MICU protocol" in some countries (Australia, NZ, Great Britain, and Francophone Canada) refers to critical care transport of patients between hospitals (as opposed to pre-hospital). Such services are a key element in regionalised systems of hospital care where intensive care services are centralised to a few specialist hospitals. An example of this is the Emergency Medical Retrieval Service in Scotland. In the United States, this is referred to as "Critical Care Transport" and qualifications for this role vary by state and can include an RN, Paramedic and/or EMT.
Generally speaking, the levels of service available will fall into one of three categories; Basic Life Support (BLS), Advanced Life Support (ALS), and Critical Care Transport (CCT) by traditional healthcare professionals, meaning nurses and/or physicians working in the pre-hospital setting and even on ambulances. In some jurisdictions, a fourth level, Intermediate Life Support (ILS), which is essentially a BLS provider with a moderately expanded skill set, may be present, but this level rarely functions independently, and where it is present may replace BLS in the emergency part of the service. When this occurs, any remaining staff at the BLS level is usually relegated to the non-emergency transportation function. Job titles typically include Emergency Medical Technician, Ambulance Technician, or Paramedic. These ambulance care givers are generally professionals or paraprofessionals and in some countries their use is controlled through training and registration. While these job titles are protected by legislation in some countries, this protection is by no means universal, and anyone might, for example, call themselves an 'EMT' or a 'paramedic', regardless of their training, or the lack of it. In some jurisdictions, both technicians and paramedics may be further defined by the environment in which they operate, including such designations as 'Wilderness', 'Tactical', and so on.
Basic life support (BLS).
First responder.
A first responder is the first person trained in basic life support who arrives at the scene of an emergency. First responders may be dispatched by the ambulance service, may be passers-by, citizen volunteers, lifeguards, or may be members of other agencies such as the police, fire service, or search and rescue who have some medical training—commonly CPR, advanced first aid, and AED use.
Ambulance driver.
Some jurisdictions separate the 'driver' and 'attendant' functions, employing ambulance driving staff with no medical qualification (or just a first aid certificate), whose job is to drive ambulances. While this approach persists in some countries, such as India, it is generally becoming increasingly rare. Ambulance drivers may be trained in radio communications, ambulance operations and emergency response driving skills.
Ambulance care assistant.
Ambulance Care Assistants (ACAs) have varying levels of training across the world. In many countries, such staff are usually only required to perform patient transport duties (which can include stretcher or wheelchair cases), rather than acute care. However, there remain both countries and individual jurisdictions in which economics will not support ALS service, and the efforts of such individuals may represent the only EMS available. Dependent on the provider (and resources available), they may be trained in first aid or extended skills such as use of an AED, oxygen therapy, pain relief and other live-saving or palliative skills. In some services, they may also provide emergency cover when other units are not available, or when accompanied by a fully qualified technician or paramedic.
Emergency medical technician.
Emergency medical technicians, also known as Ambulance Technicians in the UK and EMT in the United States. In the United States, EMT is usually made up of 3 levels. EMT-B, EMT-I and EMT-Paramedic. The New Educational Standards for EMS renamed the provider levels as follows: EMR, emergency medical responder, EMT, emergency medical technician, AEMT, advanced EMT, and Paramedic. Technicians are usually able to perform a wide range of emergency care skills, such as Automated defibrillation, care of spinal injuries and oxygen therapy. In few jurisdictions, some EMTs are able to perform duties as IV and IO cannulation, administration of a limited number of drugs, more advanced airway procedures, CPAP, and limited cardiac monitoring. Most advanced procedures and skills are not within the national scope of practice for an EMT-B. As such most states require additional training and certifications to perform above the national curriculum standards.
Emergency medical dispatcher.
An emergency medical dispatcher is also called an EMD. An increasingly common addition to the EMS system is the use of highly trained dispatch personnel who can provide "pre-arrival" instructions to callers reporting medical emergencies. They use carefully structured questioning techniques and provide scripted instructions to allow callers or bystanders to begin definitive care for such critical problems as airway obstructions, bleeding, childbirth, and cardiac arrest. Even with a fast response time by a first responder measured in minutes, some medical emergencies evolve in seconds. Such a system provides, in essence, a "zero response time," and can have an enormous impact on positive patient outcomes.
Advanced life support (ALS).
Paramedic.
A paramedic has a high level of pre-hospital medical training and usually involves key skills not performed by technicians, often including cannulation (and with it the ability to use a range of drugs to relieve pain, correct cardiac problems, and perform endotracheal intubation), cardiac monitoring, tracheal intubation,pericardiocentesis, cardioversion, needle decompression and other skills such as performing a cricothyrotomy. The most important function of the paramedic is to identify and treat any life-threatening conditions and then to assess the patient carefully for other complaints or findings that may require emergency treatment. In many countries, this is a protected title, and use of it without the relevant qualification may result in criminal prosecution. In the United States, paramedics represent the highest licensure level of prehospital emergency care. In addition, several certifications exist for Paramedics such as Wilderness ALS Care, Flight Paramedic Certification (FP-C), and Critical Care Emergency Medical Transport Program certification.
Critical care paramedic.
Recently studies have looked at new level of pre-hospital care. What has developed is the critical care paramedic, also called an advanced practice Paramedic in some parts of USA and Canada. These providers represent a higher level of licensure above that of the DOT or respective paramedic level curriculum. The training, permitted skills, and certification requirements vary from one jurisdiction to the next. These providers transport critically ill or injured patients from one hospital to a receiving hospital with higher level of care (ie.. cardiac catheterization, trauma services or specialized ICU services) not available at referring facility.
These Paramedics receive additional training beyond normal EMS medicine. The Board for Critical Care Transport Certification (BCCTPC®) has developed a certification exam for flight and ground critical care paramedics Some educational facilities that provide this training are UMBC Critical Care Emergency Medical Transport Program or . Individual services such as and have developed 'in-house' advanced practice paramedic providers. These providers have a vast array of and medications to handle complex medical and trauma patients. Examples of medication are Dopamine, Dobutamine, Propofol, Blood and Blood products to name just a few. Some examples of skills include, but not limited to, life support systems normally restricted to the ICU or critical care hospital setting such as mechanical ventilators, Intra-aortic balloon pump (IABP) and external pacemaker monitoring. Depending on the service medical direction, these providers are trained on placement and use of UVCs (Umbilical Venous Catheter), UACs (Umbilical Arterial Catheter), surgical airways, central lines, arterial lines and chest tubes.
Paramedic practitioner / emergency care practitioner.
In the United Kingdom and South Africa, some serving paramedics receive additional university education to become practitioners in their own right, which gives them absolute responsibility for their clinical judgement, including the ability to autonomously prescribe medications, including drugs usually reserved for doctors, such as courses of antibiotics. An emergency care practitioner is a position sometimes referred to as a 'super paramedic' and is designed to bridge the link between ambulance care and the care of a general practitioner. ECPs are university graduates in Emergency Medical Care or qualified paramedics who have undergone further training, and are authorized to perform specialized techniques. Additionally some may prescribe medicines (from a limited list) for longer term care, such as antibiotics. With respect to a Primary Health Care setting, they are also educated in a range of Diagnostic techniques.
Wilderness emergency medical technician.
Some paramedics and emergency medical technicians, known as Wilderness Emergency Medical Technicians, utilize expanded scope of practice protocols that are operationalized when in wilderness (remote, austere, or resource-deficient) environments. Wilderness EMS Systems (WEMS) have been developed to deliver a standard and professional medical response to wilderness areas. Examples include the national-level agencies such as the National Ski Patrol in the United States as well as local responding agencies. Like traditional EMS providers, all WEMS providers must still operate under on-line or off-line medical oversight. To assist physicians in the skills necessary to provide this oversight, the Wilderness Medical Society and the National Association of EMS Physicians jointly supported the development in 2011 of a unique "Wilderness EMS Medical Director" certification course, which was cited by the Journal of EMS as one of the Top 10 EMS Innovations of 2011. Common procedures utilized by WEMS providers that exceed traditional EMS scope of care include joint reduction, catheterization, antibiotic administration, selective spinal immobilization, and different training and protocols involving CPR cessation and wilderness skills. A multitude of organizations provide WEMS training, including private schools, non-profit organizations such as the Appalachian Center for Wilderness Medicine and the Wilderness EMS Institute, military branches, community colleges and universities, EMS-college-hospital collaborations, and others.
Traditional healthcare professions.
Registered nurse.
The use of registered nurses (RNs) in the pre-hospital setting is common in many countries. In some regions of the world nurses are the primary healthcare worker that provides emergency medical services. In European countries such as France or Italy, also use nurses as a means of providing ALS services. These nurses may work under the direct supervision of a physician, or, in rarer cases, independently. In some places in Europe, notably Norway, paramedics do exist, but the role of the 'ambulance nurse' continues to be developed, as it is felt that nurses may bring unique skills to some situations encountered by ambulance crews. In North America, and to a lesser extent elsewhere in the English-speaking world, some jurisdictions use specially trained nurses for medical transport work. These are mostly air-medical personnel or critical care transport providers, often working in conjunction with a technician or paramedic or physician on emergency interfacility transports. In the United States, the most common uses of ambulance-based Registered nurses is in the Critical Care/Mobile Intensive Care transport, and in Aeromedical EMS. Such nurses are normally required by their employers (in the US) to seek additional certifications beyond the primary nursing licensure. Four individual states have an Intensive Care or Prehospital Nurse licensure that is above the Paramedic. Many states allow registered nurses to also become registered paramedics according to their role in the emergency medical services team. In Estonia 60% of ambulance teams are led by nurse. Ambulance nurses can do almost all emergency procedures and administer medicines pre-hospital such as physicians in Estonia. In the Netherlands, all ambulances are staffed by a registered nurse with additional training in emergency nursing, anaesthesia or critical care, and a driver-EMT. In Sweden, since 2005, all emergency ambulances should be staffed by at least one registered nurse since only nurses are allowed to administer drugs. And all Advanced Life Support Ambulances are staffed at least by a registered nurse in Spain. In France, since 1986, fire department-based rescue ambulances have had the option of providing resuscitation service (reanimation) using specially trained nurses, operating on protocols, while SAMU-SMUR units are staffed by physicians and nurses
Physician.
There are many places in Europe, most notably in France, Italy, the German-speaking countries (Germany, Switzerland, Austria), and Spain where the model of EMS is different, and physicians take a more direct, 'hands-on' approach to pre-hospital care. In France, Italy, and Spain, response to high-acuity emergency calls is physician-led, as with the French SMUR teams. Paramedics do not exist within those systems, and most ALS is performed by physicians. In the German-speaking countries, paramedics do exist, but special physicians (called Notarzt) respond directly to high-acuity calls, supervising the paramedics ALS procedures directly. Indeed, in these countries paramedics are not typically legally permitted to practice their ALS procedures unless the physician is physically present, unless they face immediate life-threatening emergencies. Some systems - most notably air ambulances in the UK. will employ physicians to take the clinical lead in the ambulance; bringing a full range of additional skills such as use of medications that are beyond the paramedic skill set. The response of physicians to emergency calls is routine in many parts of Europe, but is uncommon in the UK, where physicians are generally tasked to high priority calls on a voluntary basis. Within the UK a sub-speciality of Pre-Hospital Care is being developed for Doctors, which would allow training programs and consultant posts to be developed in this one area of practice.
This 'hands-on' approach is less common in the United States. While one will occasionally see a physician with an ambulance crew on an emergency call, this is much more likely to be the Medical Director or an associate, inducting newly trained paramedics, or performing routine medical quality assurance. In some jurisdictions adult or pediatric critical care transports sometimes use physicians, but generally only when it appears likely that the patient may require surgical or advanced pharmacologic intervention beyond the skills of an EMT, paramedic or nurse during transport.
Physicians are leaders of medical retrieval teams in many western countries, where they may assist with the transport of a critically ill, injured, or special needs patient to a tertiary care hospital, particularly when longer transport times are involved. In these cases the physician's role is extended to ensure the highest level of care is provided throughout the transport and diagnosis of serious medical conditions.
Prehospital delivery of care.
Depending on country, area within country, or clinical need, emergency medical services may be provided by one or more different types of organisation. This variation may lead to large differences in levels of care and expected scope of practice.
The most basic emergency medical services are provided as a transport operation only, simply to take patients from their location to the nearest medical treatment. This was often the case in a historical context, and is still true in the developing world, where operators as diverse as taxi drivers and undertakers may operate this service.
Most developed countries now provide a government funded emergency medical service, which can be run on a national level, as is the case in the United Kingdom, where a national network of ambulance trusts operate an emergency service, paid for through central taxation, and available to anyone in need, or can be run on a more regional model, as is the case in the United States, where individual authorities have the responsibility for providing these services.
Ambulance services can be stand alone organisations, but in some cases, the emergency medical service is operated by the local fire or police service. This is particularly common in rural areas, where maintaining a separate service is not necessarily cost effective. This can lead, in some instances, to an illness or injury being attended by a vehicle other than an ambulance, such as fire truck. In some locales, firefighters are the first responders to calls for emergency medical aid, with separate ambulance services providing transportation to hospitals when necessary.
Some charities or non-profit companies also operate emergency medical services, often alongside a patient transport function. These often focus on providing ambulances for the community, or for cover at private events, such as sports matches. The Red Cross provides this service in many countries across the world on a volunteer basis (and in others as a Private Ambulance Service), as do some other smaller organizations such as St John Ambulance. and the Order of Malta Ambulance Corps. In some countries, these volunteer ambulances may be seen providing support to the full-time ambulance crews during times of emergency, or simply to help cover busy periods.
There are also private ambulance companies, with paid employees, but often on contract to the local or national government. Many private companies provide only the patient transport elements of ambulance care (i.e. nonurgent), although in some places these private services are contracted to provide emergency care, or to form a 'second tier' response, where they only respond to emergencies when all of the full-time emergency ambulance crews are busy or to respond to non-emergency home calls. Private companies are often contracted by private clients to provide event specific cover, as is the case with voluntary EMS crews.
Many colleges and universities, especially in the United States, maintain their own EMS organizations. These organizations operate at capacities ranging from first response to ALS transport. Campus EMS in the United States is overseen by the National Collegiate Emergency Medical Services Foundation.
Strategies for delivering care.
The essential decision in prehospital care is whether the patient should be immediately taken to the hospital, or advanced care resources are taken to the patient where they lie. The "scoop and run" approach is exemplified by the MEDEVAC aeromedical evacuation helicopter, whereas the "stay and play" is exemplified by the French and Belgian SMUR emergency mobile resuscitation unit or the German "Notarzt"-System (preclinical emergency physician). The use of helicopters was pioneered in the Korean war, when time to reach a medical facility was reduced from 8 hours to 3 hours in World War II, and again to 2 hours by the Vietnam war.
The strategy developed for prehospital trauma care in North America is based on the Golden Hour theory, i.e., that a trauma victim's best chance for survival is in an operating room, with the goal of having the patient in surgery within an hour of the traumatic event. This appears to be true in cases of internal bleeding, especially penetrating trauma such as gunshot or stab wounds. Thus, minimal time is spent providing prehospital care (spine immobilization; "ABCs", i.e. ensure "a"irway, "b"reathing and "c"irculation; external bleeding control; endotracheal intubation) and the victim is transported as fast as possible to a trauma centre.
The aim in "Scoop and Run" treatment is generally to transport the patient within ten minutes of arrival, hence the birth of the phrase, "the platinum ten minutes" (in addition to the "golden hour"), now commonly used in EMT training programs. The "Scoop and Run" is a method developed to deal with trauma, rather than strictly medical situations (e.g. cardiac or respiratory emergencies), however, this may be changing. Increasingly, research into the management of S-T segment elevation myocardial infarctions (STEMI) occurring outside of the hospital, or even inside community hospitals without their own PCI labs, suggests that time to treatment is a clinically significant factor in heart attacks, and that trauma patients may not be the only patients for whom 'load and go' is clinically appropriate. In such conditions, the gold standard is the door to balloon time. The longer the time interval, the greater the damage to the myocardium, and the poorer the long-term prognosis for the patient. Current research in Canada has suggested that door to balloon times are significantly lower when appropriate patients are identified by paramedics in the field, instead of the emergency room, and then transported directly to a waiting PCI lab. The STEMI program has reduced STEMI deaths in the Ottawa region by 50 per cent. In a related program in Toronto, EMS has begun to use a procedure of 'rescuing' STEMI patients from the Emergency Rooms of hospitals without PCI labs, and transporting them, on an emergency basis, to waiting PCI labs in other hospitals.
Models of care.
Although a variety of differing philosophical approaches are used in the provision of EMS care around the world, they can generally be placed into one of two categories; one physician-led and the other led by pre-hospital specialists such as emergency medical technicians or paramedics (which may, or may not have accompanying physician oversight). These models are typically identified by their locations of origin.
The Franco-German model is physician-led, with doctors responding directly to all major emergencies requiring more than simple first aid. In some cases in this model, such as France, paramedics, as they exist in the Anglo-American model, are not used, although the term 'paramedic' is sometimes used generically, and those with that designation have training that is similar to an U.S. EMT-B. The team's physicians and in some cases, nurses, provide all medical interventions for the patient, and non-medical members of the team simply provide the driving and heavy lifting services. In other applications of this model, as in Germany, a paramedic equivalent does exist, but is sharply restricted in terms of scope of practice; often not permitted to perform Advanced Life Support (ALS) procedures unless the physician is physically present, or in cases of immediate life-threatening conditions. Ambulances in this model tend to be better equipped with more advanced medical devices, in essence, bringing the emergency department to the patient. High-speed transport to hospitals is considered, in most cases, to be unnecessarily unsafe, and the preference is to remain and provide definitive care to the patient until they are medically stable, and then accomplish transport. In this model, the physician and nurse may actually staff an ambulance along with a driver, or may staff a rapid response vehicle instead of an ambulance, providing medical support to multiple ambulances.
The second care structure, termed the Anglo-American model, utilizes pre-hospital allied health staff, such as emergency medical technicians and paramedics, to staff ambulances, which may be classified according to the varying skill levels of the crews. In this model it is rare to find a physician actually working routinely in the pre-hospital setting, although they may be utilised on complex or major injuries or illnesses. In this system, a physicians involvement is most likely to be the provision of medical oversight for the work of the ambulance crews, which may be accomplished in terms of off-line medical control, with protocols or 'standing orders' for certain types of medical procedures or care, or on-line medical control, in which the technician must establish contact with the physician, usually at the hospital, and receive direct orders for various types of medical interventions. In some cases, such as in the UK, South Africa and Australia, a paramedic may be an autonomous health care professional, and does not require the permission of a physician to administer interventions or medications from an agreed list, and can perform roles such as suturing or prescribing medication to the patient.
In this model, patients may still be treated at the scene up to the skill level of the attending crew, and subsequently transported to definitive care, but in many cases the reduced skill set of the ambulance crew and the needs of the patient indicate a shorter interval for transport of the patient than is the case in the Franco-German model.
Clinical governance.
Paramedics in countries that follow the Anglo-American model normally function under the authority (medical direction) of one or more physicians charged with legally establishing the emergency medical directives for a particular region. Paramedics are credentialed and authorized by these physicians to use their own clinical judgment and diagnostic tools to identify medical emergencies and to administer the appropriate treatment, including drugs that would normally require a physician order. Credentialing may occur as the result of a State Medical Board examination (U.S.) or the National Registry of Emergency Medical Technicians (U.S.). In England, and in some parts of Canada, credentialing may occur by means of a College of Paramedicine. In these cases, paramedics are regarded as a self-regulating health profession. The final common method of credentialing is through certification by a Medical Director and permission to practice as an extension of the Medical Director's license to practice some medical acts. The authority to practice in this semi-autonomous manner is granted in the form of standing order protocols (off-line medical control) and in some cases direct physician consultation via phone or radio (on-line medical control). Under this paradigm, paramedics effectively assume the role of out-of-hospital field agents to regional emergency physicians, with clinical decision-making authority using standing orders or protocols.
In some parts of the world, those in the paramedical professional role are only permitted to practice many of their advanced skills while assisting a physician who is physically present, or they face cases of immediately life-threatening emergencies. In many other parts in the world, most notably in France, Belgium, Luxembourg, Italy, and Spain, but also in Brazil and Chile. All MICU skills in the pre-hospital setting are performed by physicians and nurses and an On-line Permanent medical supervision is done by the SAMU. In certain other jurisdictions, such as the United Kingdom and South Africa, paramedics may be entirely autonomous practitioners capable of prescribing medications. In other jurisdictions, such as Australia and Canada, this expanded scope of practice is under active consideration and discussion.

</doc>
<doc id="52977" url="https://en.wikipedia.org/wiki?curid=52977" title="Clinical neurophysiology">
Clinical neurophysiology

Clinical neurophysiology is a medical specialty that studies the central and peripheral nervous systems through the recording of bioelectrical activity, whether spontaneous or stimulated. It encompasses both research regarding the pathophysiology along with clinical methods used to diagnose diseases involving both central and peripheral nervous systems. 
Examinations in the clinical neurophysiology field are not limited to tests conducted in a laboratory. It is thought of as an extension of a neurologic consultation. Tests that are conducted are concerned with measuring the electrical functions of the brain, spinal cord, and nerves in the limbs and muscles. It can give the precise definition of site, the type and degree of the lesion, along with revealing the abnormalities that are in question. Due to these abilities, clinical neurophysiology is used to mainly help diagnose diseases rather than treat them.
In some countries it is a part of neurology or psychiatry, for example the United States and Germany. In other countries it is an autonomous specialty, such as Spain, Portugal, Italy, the United Kingdom, Finland, Sweden and Norway.
Hospitals that have neurologists and neurosurgeons tend to house clinical neurophysiology departments. Usually these tend to be larger hospitals that are able to employ more specialized staff units. In hospitals that possess clinical neurophysiology facilities, the major diagnostic modalities employed include:
Clinical neurophysiology in the United States.
The pathway to becoming a clinical neurophysiologist in the U.S. includes completing an undergraduate degree, medical school, and postgraduate medical education, usually in neurology. Following the completion of an accredited residency program, clinicians may choose to enter a fellowship in Clinical Neurophysiology. Programs may expose their fellows to the broad spectrum of electrodiagnostic neurophysiologic studies, or may focus on a single area such as EEG or electrodiagnostic medicine. Clinical Neurophysiology fellowships are generally 1–2 years in duration and may lead to board certification in one or more subspecialty areas.
Clinical neurophysiology in the United Kingdom.
There are 2 healthcare professionals who typically perform neurophysiological investigations in the UK. These are medical staff trained in Clinical Neurophysiology, and clinical physiologists who undertake 4 years practical training whilst undertaking an honours degree. Physiologists perform the majority of EEGs, evoked potentials and a portion of the nerve conduction studies. They are then clinically reported either by the physiology staff or the medical staff.
Relationship to Electrodiagnostic Medicine.
Electrodiagnostic medicine is a subset of clinical neurophysiology. Electrodiagnostic medicine focuses only on the peripheral nervous system and not the Central nervous system. Whereas a clinical neurophysiologist is trained to perform all the following studies EEG, intraoperative monitoring, nerve conduction studies, EMG and evoked potentials, and electrodiagnostic physician focuses mainly on nerve conduction studies, needle EMG, and evoked potentials. The American Board of Psychiatry and Neurology provides certification examination in clinical neurophysiology. The American Board of Electrodiagnostic Medicine provides certification in EDX medicines. The American Board of Clinical Neurophysiology certifies in electroencephalography (EEG), Evoked Potentials (EP), Polysomnography (PSG), Epilepsy Monitoring, and Neurologic Intraoperative Monitoring (NIOM). In the US physicians typically specialize in EEG or EDX medicine but not both.
Neurophysiologists in Hospitals.
Hospitals that have neurologists and neurosurgeons tend to house clinical neurophysiology departments. Usually these tend to be larger hospitals that are able to employ more specialized staff units. 
Clinical neurophysiologists are responsible for analyzing and writing reports on tests that take place within the department. They must also interpret the results that they receive and convey this information to the doctor that referred the patient to the particular neurophysiologist. Many tests involve carrying out an EMG to read the evoked potential recordings. Nerve conduction recordings are extremely common as well.

</doc>
<doc id="52978" url="https://en.wikipedia.org/wiki?curid=52978" title="Jewish principles of faith">
Jewish principles of faith

There is no established formulation of principles of faith that are recognized by all branches of Judaism. Central authority in Judaism is not vested in any one person or group - although the Sanhedrin, the supreme Jewish religious court, would fulfill this role when it is re-established - but rather in Judaism's sacred writings, laws, and traditions.
The various principles of faith that have been enumerated over the centuries carry no weight other than that imparted to them by the fame and scholarship of their respective authors.
Judaism affirms the existence and uniqueness of God and stresses performance of deeds or commandments alongside adherence to a strict belief system. In contrast to traditions such as Christianity which demand a more explicit identification of God, faith in Judaism requires one to honour God through a constant struggle with God's instructions (Torahs) and the practice of their mitzvoth.
Orthodox Judaism stresses a number of core principles in its educational programs, most importantly a belief that there is one single, omniscient, transcendent, non-compound God, who created the universe, and continues to be concerned with its governance. Traditional Judaism maintains that God established a covenant with the Jewish people at Mount Sinai, and revealed his laws and 613 commandments to them in the form of the Written and Oral Torah. In Rabbinic Judaism, the Torahs (Hebrew "Toroth") comprise both the written Torah (Pentateuch) and a tradition of oral law, much of it later codified in sacred writings (see: Mishna, Talmud).
Traditionally, the practice of Judaism has been devoted to the study of Torah and observance of its laws and commandments. In normative Judaism, the Torah and hence Jewish law itself is unchanging, but interpretation of the law is more open. It is considered a mitzvah (commandment) to study and understand the law.
The proper counterpart for the general English term "faith" -as occurring in the expression "principles of faith"- would be the concept of "Emunah" in Judaism. While it is generally translated as "faith" or "trust" in God, the concept of Emunah can more accurately be described as "an innate conviction, a perception of truth that transcends (..) reason." Emunah can be enhanced through wisdom, knowledge, understanding and learning of sacred Jewish writings. But Emunah is not simply based on reason, nor can it be understood as the opposite of or standing in contrast to reason.
There are a number of basic principles that were formulated by medieval rabbinic authorities. These are put forth as fundamental underpinnings inherent in the "acceptance and practice of Judaism."
Conception of God.
Monotheism.
Judaism is based on a strict monotheism and a belief in one single, indivisible, non-compound God. The "Shema Yisrael", one of the most important Jewish prayers, encapsulates the monotheistic nature of Judaism: "Hear, O Israel: The Lord is our God; the Lord is one."
"Judaism emphatically rejects any concept of plurality with respect to God" explicitly rejecting polytheism, dualism, and trinitarianism, which are "incompatible with monotheism as Judaism understands it." The unity of God is stated many times in Jewish tradition. It is the second of Maimonides's 13 principles of faith; Maimonides wrote that "This God is One, not two or more than two, but One whose unity is different from all other unities that there are. He is not one as a genus, which contains many species, is one. Nor is He one as a body, containing parts and dimensions, is one. But His is a unity than which there is no other anywhere" ("Yad", "Yesode Ha-Torah" 1:7).
In Jewish tradition, dualistic and trinitarian conceptions of God are generally referred to as Shituf ("partnership"), meaning an incorrect but not an idolatrous view.
God is the creator of the universe.
Jews believe that God is creator of the universe. However, Jews do not believe in a literal interpretation of the Genesis creation narrative, and Judaism is not in contradiction to the scientific model that states that the age of the universe is around 13.77 billion years old. Norbert M. Samuelson writes the "question of dating the universe has never been a problem of Jewish philosophy, ultimately because that philosophy has never taken the literal meaning of the Bible to be its revealed, true meaning."
While the general Jewish attitude has been that God created the world "ex nihilo", Rabbi Marc D. Angel writes that historically "there has been a general reluctance in Jewish tradition to speculate on the metaphysical aspects of creation":
Moses Maimonides wrote that "by virtue of the existence of the Creator everything exists" and argues in his 12th-century "Guide for the Perplexed" (2:13) that "time itself is part of creation" and that therefore, "when God is described as existing before the creation of the universe, the notion of time should not be understood in its normal sense." The 15th-century Jewish philosopher Joseph Albo argued similarly in his "Ikkarim" that there are two types of time: "Measured time which depends on motion, and time in the abstract," the second of which has no origin and is "the infinite space of time before the universe was created." Albo argued that "although it is difficult to conceive of God existing in such a duration, it is likewise difficult to imagine God outside space." Other Jewish writers have come to different conclusions, such as 13th-century scholar Bahya ben Asher, 16th-century scholar Moses Almosnino, and the 18th-century Hasidic teacher Nahman of Bratslav, who expressed a view - similar to that expressed by the Christian Neo-Platonic writer Boethius - that God "lives in the eternal present" and transcends or is above all time.
Nature of God.
The Jewish view is that God is eternal, with "neither beginning nor end," a principle stated in a number of Biblical passages. The rabbis taught a "quite literally ... down-to-earth" view of the eternalness of God: That "God is eternal but it is not given to man to explore the full meaning of this idea," and so "one cannot, therefore, expect to find in the rabbinic literature anything like a detailed examination of what is meant by divine eternity." A famous Mishnah statement on attempts to "pierce the veil" is this: "Whoever reflects on four things it were better for him that he had not come into the world: "what is above? what is beneath? what is before? and what is after?"
The traditional Jewish view is that God is omnipotent, omniscient, and omnibenevolent.
Various Jewish thinkers, however, have proposed a "finite God," sometimes in response to the problem of evil and ideas about free will. Louis Jacobs writes that modern Jewish thinkers such as Levi Olan, echoing some classical Jewish writers such as the 14th-century Talmudist Gersonides have "thought of God as limited by His own nature so that while He is infinite in some respects he is finite in others," referencing the idea, present in classical sources, that "there is a primal formless material co-existent with God from all eternity upon which God has to work and that God only knows the future in a general sense but not how individual men will exercise their choice." On the topic of omniscience and free will, Jacobs writes that in the medieval period, three views were put forth: Maimonides, who wrote that God had foreknowledge and man is free; Gersonides, who wrote that man is free and consequently God does not have complete knowledge, and Hasdai Crescas, who wrote in "Or Adonai" that God has complete foreknowledge and consequently man is not really free.
Several Jewish writers have dealt with the issue of theodicy: whether and how God is all-powerful and all-good, given the existence of evil in the world, particularly the Holocaust. Jon D. Levenson argues that omnipotence doctrine fails to "give due regard to "'the formidability and resilience of the forces counteracting creation" (such as the primordial state of chaos existing before creation) and "leads to a neglect of the role of humanity in forming and stating the world order. Hans Jonas proposed a "tentative myth" that "God 'chose' in the beginning to give God's self 'over to the chance and risk and endless variety of becoming, entering into the adventure of space in time." Jones expressed the view that "God does not create the world by fiat (although God does create the world), but leads it by beckoning it into novel possibilities of becoming. Jonas, who was influenced by the Holocaust experience, believed that God is omnipresent, but not "in all respects nontemporal, impassible, immutable, and unqualified omnipotent."
Most of classical Judaism views God as a personal god. Rabbi Samuel S. Cohon wrote that "God as conceived by Judaism is not only the First Cause, the Creative Power, and the World Reason, but also the living and loving Father of Men. He is not only cosmic but also personal...Jewish monotheism thinks of God in terms of definite character or personality, while pantheism is content with a view of God as impersonal." This is shown in the Jewish liturgy, such as in the Adon Olam hymn, which includes a "confident affirmation" that "He is my God, my living God...Who hears and answers." Edward Kessler writes that Hebrew Bible "portrays an encounter with a God who cares passionately and who addresses humanity in the quiet moments of its existence." British chief rabbi Jonathan Sacks suggests that God "is not distant in time or detached, but passionately engaged and present." It is important to note that "the predicate 'personal' as applied to God" does not mean that God is corporeal or anthropomorphic, views which Judaism has always rejected; rather, "personality" refers not to physicality but to "inner essence, psychical, rational, and moral." Although most Jews believe that "God can be experienced," it is understood that "God cannot be understood" because "God is utterly unlike humankind" (as shown in God's response to Moses when Moses asked for God's name: "I Am that I Am"); all anthropomorphic statements about God "are understood as linguistic metaphors, otherwise it would be impossible to talk about God at all."
Although the dominant strain in Judaism is that God is personal, there is an "alternate stream of tradition exemplified by ... Maimonides," who, along with several other Jewish philosophers, rejected the idea of a personal God. This reflected his belief in negative theology: that God can only be described by what God is not. Rabbi Mordecai Kaplan, who developed Reconstructionist Judaism and taught at the Conservative Jewish Theological Seminary of America, also rejected the idea of a personal God. Kaplan instead thought of God "as a force, like gravity, built into the very structure of the universe," believing that "since the universe is constructed to enable us to gain personal happiness and communal solidarity when we act morally, it follows that there is a moral force in the universe; this force is what the Constructionists mean by God," although some Reconstructionists do believe in a personal God. According to Joseph Telushkin and Morris N. Kertzer, Kaplan's "rationalist rejection of the traditional Jewish understanding of God exerted a powerful influence" on many Conservative and Reform rabbis, influencing many to stop believing in a personal God." According to the Pew Forum on Religion and Public Life's 2008 U.S. Religious Landscape Survey, Americans who identify as Jewish by religion are twice as likely to favor ideas of God as "an impersonal force" over the idea that "God is a person with whom people can have a relationship."
To God alone may one offer prayer.
Judaism has often emphasize strict monotheism and "exclusivity of the divinity" and prayer directly to God; references to angels or other intermediaries are not typically seen in Jewish liturgy or in siddurs (prayerbooks). Maimonides' fifth principle of faith states that "I believe with perfect faith that it is only proper to pray to God," and this is often seen as stating that "One may not pray to anyone or anything else. This principle teaches that God is the only one whom we may serve and praise... It is therefore not proper to serve (angels, stars, or other elements) or make them intermediaries to bring us closer to God." Talmudic literature does shows that some evidence that Jewish prayers invoking angels and other intermediaries existed in the 1st century CE, and several examples of post-Talmudic prayers exist, including a familiar "piyyut" (liturgical song) entitled "Usherers of Mercy," recited before and after Rosh Hashanah in Selichot (Jewish penitential prayers).
Revelation.
Scripture.
The Hebrew Bible or Tanakh is the Jewish scriptural canon and central source of Jewish law. The word is an acronym formed from the initial Hebrew letters of the three traditional subdivisions of the Tanakh: The Torah ("Teaching", also known as the "Five Books of Moses" or "Pentateuch"), the Nevi'im ("Prophets") and the Ketuvim ("Writings"). The Tanakh contains 24 books in all; its authoritative version is the Masoretic Text. Traditionally, the text of the Tanakh was said to have been finalized at the Council of Jamnia in 70 CE, although this is uncertain. In Judaism, the term "Torah" refers not only to the Five Books of Moses, but also to all of the Jewish scriptures (the whole of Tanakh), and the ethical and moral instructions of the rabbis (the Oral Torah).
In addition to the Tanakh, there are two further textual traditions in Judaism: Mishnah (tractates expounding on Jewish law) and the Talmud (commentary of Misneh and Torah). These are both codifications and redactions of the Jewish oral traditions and major works in Rabbinic Judaism.
The Talmud consists of the Babylonian Talmud (produced in Babylon around 600 CE) and the Jerusalem Talmud (produced in the Land of Israel circa 400 CE). The Babylonian Talmud is the more extensive of the two and is considered the more important. The Talmud is a re-presentation of the Torah through "sustained analysis and argument" with "unfolding dialogue and contention" between rabbinic sages. The Talmud consists of the Mishnah (a legal code) and the Gemara (Aramaic for "learning"), an analysis and commentary to that code. Rabbi Adin Steinsaltz writes that "If the Bible is the cornerstone of Judaism, then the Talmud is the central pillar ... No other work has had a comparable influence on the theory and practice of Jewish life, shaping influence on the theory and practice of Jewish life" and states:
Moses and the Torah.
Orthodox and Conservative Jews hold that the prophecy of Moses is held to be true; he is held to be the chief of all prophets, even of those who came before and after him. This belief was expressed by Maimonides, who wrote that "Moses was superior to all prophets, whether they preceded him or arose afterwards. Moses attained the highest possible human level. He perceived God to a degree surpassing every human that ever existed...God spoke to all other prophets through an intermediary. Moses alone did not need this; this is what the Torah means when God says "Mouth to mouth, I will speak to him." The great Jewish philosopher Philo understands this type of prophecy to be an extraordinarily high level of philosophical understanding, which had been reached by Moses and which enabled him to write the Torah through his own rational deduction of natural law. Maimonides, in his Commentary to the Mishna (preface to chapter "Chelek", Tractate Sanhedrin), and is his Mishneh Torah, (in the Laws of the foundations of the Torah, ch. 7), describes a similar concept of prophecy, since a voice that did not originate from a body cannot exist, the understanding of Moses was based on his lofty philosophical understandings.
However, this does not imply that the text of the Torah should be understood literally, as according to Karaism. Rabbinic tradition maintains that God conveyed not only the words of the Torah, but the meaning of the Torah. God gave rules as to how the laws were to be understood and implemented, and these were passed down as an oral tradition. This oral law was passed down from generation to generation and ultimately written down almost 2,000 years later in the Mishna and the two Talmuds.
For Reform Jews, the prophecy of Moses was not the highest degree of prophecy; rather it was the first in a long chain of progressive revelations in which mankind gradually began to understand the will of God better and better. As such, they maintain, that the laws of Moses are no longer binding, and it is today's generation that must assess what God wants of them. This principle is also rejected by most Reconstructionist Jews, but for a different reason; most posit that God is not a being with a will; thus they maintain that no will can be revealed.
The origin of the Torah.
The Torah is composed of 5 books called in English Genesis, Exodus, Leviticus, Numbers, and Deuteronomy. They chronicle the history of the Hebrews and also contain the commandments that Jews are to follow.
Rabbinic Judaism holds that the Torah extant today is the same one that was given to Moses by God on Mount Sinai. Maimonides explains: "We do not know exactly how the Torah was transmitted to Moses. But when it was transmitted, Moses merely wrote it down like a secretary taking dictation... every verse in the Torah is equally holy, as they all originate from God, and are all part of God's Torah, which is perfect, holy and true."
"Haredi" Jews generally believe that the Torah today is no different from what was received from God to Moses, with only the most minor of scribal errors. Many other Orthodox Jews suggest that over the millennia, some scribal errors have crept into the Torah's text. They note that the Masoretes (7th to 10th centuries) compared all known Torah variations in order to create a definitive text. However, even according to this position that the scrolls that Jews possess today are not letter-perfect, the Torah scrolls are certainly the word-perfect textus receptus that was divinely revealed to Moses. Indeed, the consensus of Orthodox rabbinic authority posits this belief in the word-perfect nature of the Torah scroll as representing a non-negotiable prerequisite for Orthodox Jewish membership.
Although even in Modern Orthodox circles there are some Rabbis (e.g. Professor Marc Shapiro) that point out the numerous rabbinic sources from the Talmudic, Post-Talmudic, and medieval ages that claim that there were some changes to the text, which include whole verses, that were made deliberately during the Mishnaic era, and even during the times of the first temple. Professor Shapiro lists the many medieval Rabbis discuss changes and additions that occurred during the time of Ezra the Scribe in his work 'The Limits of Orthodox Theology: Maimonides' Thirteen Principles Reappraised'.
The words of the prophets are true.
The Nevi'im, the books of the Prophets, are considered divine and true. This does not imply that they are always read literally: Jewish tradition has always held that prophets used metaphors and analogies, and there are many commentaries explaining and elucidating metaphorical verses.
Oral Torah.
Many Orthodox Jews view the Written and Oral Torah as the same as Moses taught, for all practical purposes. Conservative Jews tend to believe that much of the Oral law is divinely inspired, while Reform and Reconstructionist Jews tend to view all of the Oral law as an entirely human creation. Traditionally, the Reform movement held that Jews were obliged to obey the ethical but not the ritual commandments of Scripture, although today many Reform Jews have adopted many traditional ritual practices. Karaite Jews traditionally consider the Written Torah to be authoritative, viewing the Oral Law as only one possible interpretation of the Written Torah.
Most Modern Orthodox Jews will agree that, while certain laws within the Oral Law were given to Moses, most of the Talmudic laws were derived organically by the Rabbis of the Mishnaic and Talmudic eras.
God's relationship with Man.
Judaism's focus is more on how God defines man than one trying to define God. There is therefore a focus on what people are expected to be or do far more than on spelling out theological beliefs.
People are born with both a tendency to do good and to do evil.
Jewish tradition mostly emphasizes free will, and most Jewish thinkers reject determinism, on the basis that free will and the exercise of free choice have been considered a precondition of moral life. "Moral indeterminacy seems to be assumed both by the Bible, which bids man to choose between good and evil, and by the rabbis, who hold the decision for following the good inclination rather than the evil rests with every individual." Maimonides asserted the compatibility of free will with foreknowledge of God (Mishneh Torah, Hilkhot Teshuvah 5). Only a handful of Jewish thinkers have expressed deterministic views. This group includes the medieval Jewish philosopher Hasdai Crescas and the 19th-century Hasidic rabbi Mordechai Yosef Leiner of Izbica. 
Judaism affirms that people are born with both an "yetzer ha-tov" (יצר הטוב), an inclination or impulse to do good, and with a "yetzer hara" (יצר הרע), an inclination or impulse to do evil. These phrases reflect the concept that "within each person, there are opposing natures continually in conflict" and are referenced many times in the rabbinic tradition. The rabbis even recognize a positive value to the "yetzer ha-ra": without the "yetzer ha-ra" there would be no civilization or other fruits of human labor. Midrash (Bereshit Rabbah 9:7) states: "Without the evil inclination, no one would father a child, build a house, or make a career." The implication is that "yetzer ha-tov" and "yetzer ha-ra" are best understood not only as moral categories of good and evil but as the inherent conflict within man between selfless and selfish orientations.
Judaism recognizes two classes of "sin": offenses against other people, and offenses against God. Offenses against God may be understood as violation of a contract (the covenant between God and the Children of Israel). ("See Jewish views on sin".)
A classical rabbinic work, "Avoth de-Rabbi Natan", states: "One time, when Rabban Yochanan ben Zakkai was walking in Jerusalem with Rabbi Yehosua, they arrived at where the Temple in Jerusalem now stood in ruins. "Woe to us," cried Rabbi Yehosua, "for this house where atonement was made for Israel's sins now lies in ruins!" Answered Rabban Yochanan, "We have another, equally important source of atonement, the practice of "gemiluth ḥasadim" (loving kindness), as it is stated: "I desire loving kindness and not sacrifice" (Hosea 6:6). Also, the Babylonian Talmud teaches that "Rabbi Yochanan and Rabbi Eleazar both explain that as long as the Temple stood, the altar atoned for Israel, but now, one's table atones the poor are invited as guests" (Talmud, tractate Berachoth 55a). Similarly, the liturgy of the Days of Awe (the High Holy Days; i.e. Rosh HaShanah and Yom Kippur) states that prayer, repentance and "tzedakah" atone for sin.
Judaism rejects the belief in "original sin." Both ancient and modern Judaism teaches that every person is responsible for his own actions. However, the existence of some "innate sinfulness on each human being was discussed" in both biblical (Genesis 8:21, Psalms 51.5) and post-biblical sources. Some apocrypha and pseudepigraphic sources express pessimism about human nature ("A grain of evil seed was sown in Adam's heart from the beginning"), and the Talmud (b. Avodah Zarah 22b) has an unusual passage which Edward Kessler describes as "the serpent seduced Eve in paradise and impregnated her with spiritual-physical 'dirt' which was inherited through the generations," but the revelation at Sinai and the reception of the Torah cleansed Israel. Kessler states that "although it is clear that belief in some form of original sin did exist in Judaism, it did not become mainstream teaching, nor dogmatically fixed," but remained at the margins of Judaism.
Reward and punishment.
The mainstream Jewish view is that God will reward those who observe His commandments and punish those who intentionally transgress them. Examples of rewards and punishments are described throughout the Bible, and throughout classical rabbinic literature: see Free will In Jewish thought. The common understanding of this principle is accepted by most Orthodox and Conservative and many Reform Jews; it is generally rejected by the Reconstructionists.
The Bible contains references to Sheol, lit. "gloom", as the common destination of the dead, which may be compared with the Hades or underworld of ancient religions. In later tradition this is interpreted either as Hell or as a literary expression for death or the grave in general.
According to aggadic passages in the Talmud, God judges who has followed His commandments and who does not and to what extent. Those who do not "pass the test" go to a purifying place (sometimes referred to as "Gehinnom", i.e. Hell, but more analogous to the Christian Purgatory) to "learn their lesson". There is, however, for the most part, no eternal damnation. The vast majority of souls only go to that reforming place for a limited amount of time (less than one year). Certain categories are spoken of as having "no part in the world to come", but this appears to mean annihilation rather than an eternity of torment.
Philosophical rationalists such as Maimonides believed that God did not actually mete out rewards and punishments as such. In this view, these were beliefs that were necessary for the masses to believe in order to maintain a structured society and to encourage the observance of Judaism. However, once one learned Torah properly, one could then learn the higher truths. In this view, the nature of the reward is that if a person perfected his intellect to the highest degree, then the part of his intellect that connected to God – the active intellect – would be immortalized and enjoy the "Glory of the Presence" for all eternity. The punishment would simply be that this would not happen; no part of one's intellect would be immortalized with God. See Divine Providence in Jewish thought.
The Kabbalah (mystical tradition in Judaism) contains further elaborations, though some Jews do not consider these authoritative. For example, it admits the possibility of reincarnation, which is generally rejected by non-mystical Jewish theologians and philosophers. It also believes in a triple soul, of which the lowest level ("nefesh" or animal life) dissolves into the elements, the middle layer ("ruach" or intellect) goes to "Gan Eden" (Paradise) while the highest level ("neshamah" or spirit) seeks union with God.
Many Jews consider "Tikkun Olam" (or Repairing the world) as a fundamental motivating factor in Jewish ethics. Therefore, the concept of "life after death," in the Jewish view, is not encouraged as the motivating factor in performance of Judaism. Indeed, it is held that one can attain closeness to God even in this world through moral and spiritual perfection.
Israel chosen for a purpose.
God chose the Jewish people to be in a unique covenant with God; the description of this covenant is the Torah itself. Contrary to popular belief, Jewish people do not simply say that "God chose the Jews." This claim, by itself, exists nowhere in the Tanakh (the Jewish Bible). Such a claim could imply that God loves only the Jewish people, that only Jews can be close to God, and that only Jews can have a heavenly reward. The actual claim made is that the Jews were chosen for a specific mission, a duty: to be a light unto the nations, and to have a covenant with God as described in the Torah. Reconstructionist Judaism rejects even this variant of chosenness as morally defunct.
Rabbi Lord Immanuel Jakobovits, former Chief Rabbi of the United Synagogue of Great Britain, describes the mainstream Jewish view on this issue: "Yes, I do believe that the chosen people concept as affirmed by Judaism in its holy writ, its prayers, and its millennial tradition. In fact, I believe that every people—and indeed, in a more limited way, every individual—is 'chosen' or destined for some distinct purpose in advancing the designs of Providence. Only, some fulfill their mission and others do not. Maybe the Greeks were chosen for their unique contributions to art and philosophy, the Romans for their pioneering services in law and government, the British for bringing parliamentary rule into the world, and the Americans for piloting democracy in a pluralistic society. The Jews were chosen by God to be 'peculiar unto Me' as the pioneers of religion and morality; that was and is their national purpose."
The messiah.
Judaism acknowledges an afterlife, but does not have a single or systemic way of thinking about the afterlife. Judaism places its overwhelming stress on "Olam HaZeh" (this world) rather than "Olam haba" (the World to Come), and "speculations about the World to Come are peripheral to mainstream Judaism." In Pirkei Avot (Ethics of the Fathers), it is said that "One hour of penitence and good deeds in this world is better than all the life of the world to come; but one hour of spiritual repose in the world to come is better than all the life of this world," reflecting both a view of the significance of life on Earth and the spiritual repose granted to the righteous in the next world.
Jews reject the idea that Jesus of Nazareth was the messiah and agree that the messiah has not yet come. Throughout Jewish history there have been a number of Jewish Messiah claimants considered false by Jews, including most notably Simon bar Kokhba and Sabbatai Zevi, whose followers were known as Sabbateans.
The twelfth of Maimonides' 13 principles of faith was: "I believe with perfect faith in the coming of the messiah ("mashiach"), and though he may tarry, still I await him every day." Orthodox Jews believes that a future Jewish messiah (the "Mashiach", "anointed one") will be a king who will rule the Jewish people independently and according to Jewish law. In a traditional view, the Messiah was understood to be a human descendant of King David (that is, of the Davidic line).
Liberal, or Reform Judaism does not believe in the arrival of a personal Messiah who will ingather the exiles in the Land of Israel and cause the physical resurrection of the dead. Rather, Reform Jews focus on a future age in which there is a perfected world of justice and mercy.
History and development.
A number of formulations of Jewish beliefs have appeared, and there is some dispute over how many basic principles there are. Rabbi Joseph Albo, for instance, in "Sefer Ha-Ikkarim" counts three principles of faith, while Maimonides lists thirteen. While some later rabbis have attempted to reconcile the differences, claiming that Maimonides' principles are covered by Albo's much shorter list, alternative lists provided by other medieval rabbinic authorities seem to indicate some level of tolerance for varying theological perspectives.
No formal text canonized.
Though to a certain extent incorporated in the liturgy and utilized for purposes of instruction, these formulations of the cardinal tenets of Judaism carried no greater weight than that imparted to them by the fame and scholarship of their respective authors. None of them had an authoritative character analogous to that given by Christianity to its three great formulas (the Apostles' Creed, the Nicene or Constantinopolitan, and the Athanasian), or to the Kalimat As-Shahadat of the Muslims. None of the many summaries from the pens of Jewish philosophers and rabbis has been invested with similar importance.
Conversion to Judaism.
Unlike many other religions, Judaism has not made strong attempts to convert non-Jews, although formal conversion to Judaism is permitted. Righteousness, according to Jewish belief, was not restricted to those who accepted the Jewish religion. And the righteous among the nations that carried into practice the seven fundamental laws of the covenant with Noah and his descendants were declared to be participants in the felicity of the hereafter. This interpretation of the status of non-Jews made the development of a missionary attitude unnecessary. Moreover, the regulations for the reception of proselytes, as developed in course of time, prove the eminently practical, that is, the non-creedal character of Judaism. Compliance with certain rites – immersion in a mikveh (ritual bath), brit milah (circumcision), and the acceptance of the mitzvot (Commandments of Torah) as binding – is the test of the would-be convert's faith. He or she is instructed in the main points of Jewish law, while the profession of faith demanded is limited to the acknowledgment of the unity of God and the rejection of idolatry. Judah ha-Levi ("Kuzari" 1:115) puts the whole matter very strikingly when he says:
For the preparation of the convert, therefore, no other method of instruction was employed than for the training of one born a Jew. The aim of teaching was to convey a knowledge of halakha (Jewish law), obedience to which manifested the acceptance of the underlying religious principles; namely, the existence of God and the mission of Israel as the people of God's covenant.
Are principles of faith inherent in mitzvot?
The controversy whether the practice of mitzvot in Judaism is inherently connected to Judaism's principles of faith has been discussed by many scholars. Moses Mendelssohn, in his "Jerusalem," defended the non-dogmatic nature of the practice of Judaism. Rather, he asserted, the beliefs of Judaism, although revealed by God in Judaism, consist of universal truths applicable to all mankind. Rabbi Leopold Löw, among others, took the opposite side, and considered that the Mendelssohnian theory had been carried beyond its legitimate bounds. Underlying the practice of the Law was assuredly the recognition of certain fundamental principles, he asserted, culminating in the belief in God and revelation, and likewise in the doctrine of divine justice.
The first to attempt to formulate Jewish principles of faith was Philo of Alexandria. He enumerated five articles: God is and rules; God is one; the world was created by God; Creation is one, and God's providence rules Creation.
Belief in the Oral Law.
Many rabbis were drawn into controversies with both Jews and non-Jews, and had to fortify their faith against the attacks of contemporaneous philosophy as well as against rising Christianity. The Mishnah (Tractate Sanhedrin xi. 1) excludes from the world to come the Epicureans and those who deny belief in resurrection or in the divine origin of the Torah. Rabbi Akiva would also regard as heretical the readers of Sefarim Hetsonim – certain extraneous writings that were not canonized – as well such persons that would heal through whispered formulas of magic. Abba Saul designated as under suspicion of infidelity those that pronounce the ineffable name of God. By implication, the contrary doctrine may be regarded as orthodox. On the other hand, Akiva himself declares that the command to love one's neighbor is the fundamental principle of the Torah; while Ben Asa assigns this distinction to the Biblical verse, "This is the book of the generations of man".
The definition of Hillel the Elder in his interview with a would-be convert (Talmud, tractate Shabbat 31a), embodies in the golden rule the one fundamental article of faith. A teacher of the 3rd century, Rabbi Simlai, traces the development of Jewish religious principles from Moses with his 613 mitzvot of prohibition and injunction, through David, who, according to this rabbi, enumerates eleven; through Isaiah, with six; Micah, with three; to Habakkuk who simply but impressively sums up all religious faith in the single phrase, "The pious lives in his faith" (Talmud, Mak., toward end). As Jewish law enjoins that one should prefer death to an act of idolatry, incest, unchastity, or murder, the inference is plain that the corresponding positive principles were held to be fundamental articles of Judaism.
Belief during the medieval era.
Detailed constructions of articles of faith did not find favor in Judaism before the medieval era, when Jews were forced to defend their faith from both Islamic and Christian inquisitions, disputations and polemics. The necessity of defending their religion against the attacks of other philosophies induced many Jewish leaders to define and formulate their beliefs. Saadia Gaon's "Emunot ve-Deot" is an exposition of the main tenets of Judaism. They are listed as : The world was created by God; God is one and incorporeal; belief in revelation (including the divine origin of tradition); man is called to righteousness and endowed with all necessary qualities of mind and soul to avoid sin; belief in reward and punishment; the soul is created pure; after death it leaves the body; belief in resurrection; Messianic expectation, retribution, and final judgment.
Judah Halevi endeavored, in his Kuzari to determine the fundamentals of Judaism on another basis. He rejects all appeal to speculative reason, repudiating the method of the Islamic Motekallamin. The miracles and traditions are, in their natural character, both the source and the evidence of the true faith. In this view, speculative reason is considered fallible due to the inherent impossibility of objectivity in investigations with moral implications.
Maimonides' 13 principles of faith.
Rabbi Moses ben Maimon, better known as Maimonides or "The Rambam" (1135–1204 CE), lived at a time when both Christianity and Islam were developing active theologies. Jewish scholars were often asked to attest to their faith by their counterparts in other religions. The Rambam's 13 principles of faith were formulated in his commentary on the Mishnah (tractate Sanhedrin, chapter 10). They were one of several efforts by Jewish theologians in the Middle Ages to create such a list. By the time of Maimonides, centers of Jewish learning and law were dispersed geographically. Judaism no longer had a central authority that might bestow official approval on his principles of faith.
Maimonides' 13 principles were controversial when first proposed, evoking criticism by Crescas and Joseph Albo. They evoked criticism as minimizing acceptance of the entire Torah (Rabbi S. of Montpelier, Yad Rama, Y. Alfacher, Rosh Amanah). The 13 principles were ignored by much of the Jewish community for the next few centuries. ("Dogma in Medieval Jewish Thought", Menachem Kellner). Over time two poetic restatements of these principles ("Ani Ma'amin" and "Yigdal") became canonized in the Jewish prayerbook. Eventually, Maimonides' 13 principles of faith became the most widely accepted statement of belief.
Importantly, Maimonides, while enumerating the above, added the following caveat "There is no difference between Biblical statement 'his wife was Mehithabel' 10,6 on the one hand an "unimportant" verse, and 'Hear, O Israel' on the other an "important" verse... anyone who denies even such verses thereby denies God and shows contempt for his teachings more than any other skeptic, because he holds that the Torah can be divided into essential and non-essential parts..." The uniqueness of the 13 fundamental beliefs was that even a rejection out of ignorance placed one outside Judaism, whereas the rejection of the rest of Torah must be a conscious act to stamp one as an unbeliever. Others, such as Rabbi Joseph Albo and the Raavad, criticized Maimonides' list as containing items that, while true, in their opinion did not place those who rejected them out of ignorance in the category of heretic. Many others criticized any such formulation as minimizing acceptance of the entire Torah (see above). As noted, however, neither Maimonides nor his contemporaries viewed these principles as encompassing all of Jewish belief, but rather as the core theological underpinnings of the acceptance of Judaism.
Several Orthodox scholars write that the popular Orthodox understanding of these principles are not at all what Maimonides held to be true. See books noted below by Marc Shapiro and Menachem Kellner.
After Maimonides.
The successors of Maimonides, from the 13th to the 15th century — Nahmanides, Abba Mari ben Moses, Simon ben Zemah Duran, Joseph Albo, Isaac Arama, and Joseph Jaabez — narrowed his 13 articles to three core beliefs: Belief in God; in Creation (or revelation); and in providence (or retribution).
Others, like Crescas and David ben Samuel Estella, spoke of seven fundamental articles, laying stress on free-will. On the other hand, David ben Yom-Tob ibn Bilia, in his "Yesodot ha- Maskil" (Fundamentals of the Thinking Man), adds to the 13 of Maimonides 13 of his own — a number which a contemporary of Albo also chose for his fundamentals; while Jedaiah Penini, in the last chapter of his "Behinat ha-Dat," enumerated no less than 35 cardinal principles.
Isaac Abravanel, his "Rosh Amanah," took the same attitude towards Maimonides' creed. While defending Maimonides against Hasdai and Albo, he refused to accept dogmatic articles for Judaism, criticizing any formulation as minimizing acceptance of all 613 mitzvot.
The Enlightenment.
In the late 18th century Europe was swept by a group of intellectual, social and political movements, together known as The Enlightenment. These movements promoted scientific thinking, free thought, and allowed people to question previously unshaken religious dogmas. Like Christianity, Judaism developed several responses to this unprecedented phenomenon. One response saw the enlightenment as positive, while another saw it as negative. The enlightenment meant equality and freedom for many Jews in many countries, so it was felt that it should be warmly welcomed. Scientific study of religious texts would allow people to study the history of Judaism. Some Jews felt that Judaism should accept modern secular thought and change in response to these ideas. Others, however, believed that the divine nature of Judaism precluded changing any fundamental beliefs.
While the modernist wing of Orthodox Judaism, led by such rabbis as Samson Raphael Hirsch, was open to the changing times, it rejected any doubt in the traditional theological foundation of Judaism. Historical-critical methods of research and new philosophy led to the formation of various non-Orthodox denominations, as well as Jewish secular movements.
Holocaust theology.
Because of the magnitude of the Holocaust, many people have re-examined the classical theological views on God's goodness and actions in the world. Some question whether people can still have any faith after the Holocaust. Some theological responses to these questions are explored in Holocaust theology.
Principles of faith in Modern Judaism.
Orthodox Judaism.
Orthodox Judaism considers itself to be in direct continuity with historical rabbinic Judaism. Therefore, as above, it accepts philosophic speculation and statements of dogma only to the extent that they exist within, and are compatible with, the system of written and oral Torah. As a matter of practice Orthodox Judaism lays stress on the performance of the actual commandments. Dogma is considered to be the self-understood underpinning of the practice of the Mitzvot.
Owing to this, there is no one official statement of principles. Rather, all formulations by accepted early Torah leaders are considered to have possible validity. Nevertheless, the 13 principles of Maimonides have a certain priority over other formulations: they are often printed in prayer books, and in many congregations a hymn (Yigdal) incorporating them is sung on Friday nights. (The inclusion of Yigdal, however, is not exclusive to Orthodox Judaism.)
Conservative Judaism.
Conservative Judaism developed in Europe and the United States in the late 1800s, as Jews reacted to the changes brought about by the enlightenment and emancipation. In many ways it was a reaction to what were seen as the excesses of the Reform movement. For much of the movement's history, Conservative Judaism deliberately avoided publishing systematic explications of theology and belief; this was a conscious attempt to hold together a wide coalition. This concern became a non-issue after the left-wing of the movement seceded in 1968 to form the Reconstructionist movement, and after the right-wing seceded in 1985 to form the Union for Traditional Judaism.
In 1988, the Leadership Council of Conservative Judaism finally issued an official statement of belief, "Emet Ve-Emunah: Statement of Principles of Conservative Judaism". It noted that a Jew must hold certain beliefs. However, the Conservative rabbinate also notes that the Jewish community never developed any one binding catechism. Thus, Emet Ve-Emunah affirms belief in God and in God's revelation of Torah to the Jews. However, it also affirms the legitimacy of multiple interpretations of these issues. Atheism, Trinitarian views of God, and polytheism are all ruled out. All forms of relativism, and also of literalism and fundamentalism are also rejected. It teaches that Jewish law is both still valid and indispensable, but also holds to a more open and flexible view of how law has and should develop than the Orthodox view.
Reform Judaism.
Reform Judaism has had a number of official platforms, especially in the United States. The first platform was the 1885 "Declaration of Principles ("The Pittsburgh Platform")" – the adopted statement of a meeting of reform rabbis from across the United States November 16 – 19, 1885.
The next platform – "The Guiding Principles of Reform Judaism ("The Columbus Platform")" – was published by the Central Conference of American Rabbis (CCAR) in 1937.
The CCAR rewrote its principles in 1976 with its "Reform Judaism: A Centenary Perspective" and rewrote them again in 1999's "A Statement of Principles for Reform Judaism". While original drafts of the 1999 statement called for Reform Jews to consider re-adopting some traditional practices on a voluntary basis, later drafts removed most of these suggestions. The final version is thus similar to the 1976 statement.
According to the CCAR, personal autonomy still has precedence over these platforms; lay people need not accept all, or even any, of the beliefs stated in these platforms. Central Conference of American Rabbis (CCAR) President Rabbi Simeon J. Maslin wrote a pamphlet about Reform Judaism, entitled "What We Believe...What We Do...". It states that "if anyone were to attempt to answer these two questions authoritatively for all Reform Jews, that person's answers would have to be false. Why? Because one of the guiding principles of Reform Judaism is the autonomy of the individual. A Reform Jew has the right to decide whether to subscribe to this particular belief or to that particular practice." Reform Judaism affirms "the fundamental principle of Liberalism: that the individual will approach this body of mitzvot and minhagim in the spirit of freedom and choice. Traditionally Israel started with harut, the commandment engraved upon the Tablets, which then became freedom. The Reform Jew starts with herut, the freedom to decide what will be harut - engraved upon the personal Tablets of his life." Martin, Ed., Contemporary Reform Jewish Thought, Quadrangle Books 1968. In addition to those, there were the 42 Affirmations of Liberal Judaism in Britain from 1992, and the older Richtlinien zu einem Programm für das liberale Judentum (1912) in Germany, as well as others, all stressing personal autonomy and ongoing revelation. 
Reconstructionist Judaism.
Reconstructionist Judaism is an American denomination that has a naturalist theology as developed by Rabbi Mordecai Kaplan. This theology is a variant of the naturalism of John Dewey, which combined atheistic beliefs with religious terminology in order to construct a religiously satisfying philosophy for those who had lost faith in traditional religion. id. at 385; but see Caplan at p. 23, fn.62 ("The majority of Kaplan's views ... were formulated before he read Dewey or [William James.")] Reconstructionism denies that God is either personal or supernatural. Rather, God is said to be the sum of all natural processes that allow man to become self-fulfilled. Rabbi Kaplan wrote that "to believe in God means to take for granted that it is man's destiny to rise above the brute and to eliminate all forms of violence and exploitation from human society."
Most Reconstructionist Jews reject theism, and instead define themselves as religious naturalists. These views have been criticized on the grounds that they are actually atheists, which has only been made palatable to Jews by rewriting the dictionary. A significant minority of Reconstructionists have refused to accept Kaplan's theology, and instead affirm a theistic view of God.
As in Reform Judaism, Reconstructionist Judaism holds that personal autonomy has precedence over Jewish law and theology. It does not ask that its adherents hold to any particular beliefs, nor does it ask that halakha be accepted as normative. In 1986, the Reconstructionist Rabbinical Association (RRA) and the Federation of Reconstructionist Congregations (FRC) passed the official "Platform on Reconstructionism" (2 pages). It is not a mandatory statement of principles, but rather a consensus of current beliefs. Newsletter, Sept. 1986, pages D, E. Major points of the platform state that:
Although Resconstructionist Judaism does not require its membership to subscribe to any particular dogma, the Reconstructionist movement actively rejects or marginalizes certain beliefs held by other branches of Judaism, including many (if not all) of the 13 Principles. For example, Rabbi Kaplan "rejected traditional Jewish understandings of messianism. His God did not have the ability to suspend the natural order and could thus not send a divine agent from the house of David who would bring about a miraculous redemption." Rather, in keeping with Reconstructionist naturalist principles, "Kaplan beieved strongly that ultimately the world will be perfected, but only as a result of the combined efforts of humanity over generations." (Id. at 57) Similarly Reconstructionism rejects the 13th principle of resurrection of the dead, which Kaplan believed "belonged to a supernatural worldview rejected by moderns." (Id. at 58.) Thus, the Reconstructionist Sabbath Prayer Book erases all references to a messianic figure, and the daily 'Amidah replaces the traditional blessing of reviving the dead with one that blesses God "who in love remembers Thy creatures unto life." (Id. at 57-59.)

</doc>
<doc id="52980" url="https://en.wikipedia.org/wiki?curid=52980" title="Hakka Chinese">
Hakka Chinese

Hakka , also rendered Kejia, is one of the major groups of varieties of Chinese, spoken natively by the Hakka people in southern China, Taiwan, Hong Kong and throughout the diaspora areas of East Asia, Southeast Asia, and around the world.
Due to its primary usage in scattered isolated regions where communication is limited to the local area, Hakka has developed numerous varieties or dialects, spoken in Guangdong, Fujian, Jiangxi, Guangxi, Sichuan, Hunan, and Guizhou provinces, including Hainan island, Malaysia, Hong Kong, Singapore and Taiwan. Hakka is not mutually intelligible with Mandarin, Wu, Southern Min, or other branches of Chinese. It is most closely related to Gan and is sometimes classified as a variety of Gan.
Taiwan, where Hakka is the native language of a significant minority of the island's residents, is an important world center for study and preservation of the language. Pronunciation differences exist between the Taiwanese Hakka dialect and China's Guangdong Hakka dialect; even in Taiwan, two local varieties of Hakka exist.
The Meixian dialect (Moiyen) of northeast Guangdong in China has been taken as the "standard" dialect by the People's Republic of China. The Guangdong Provincial Education Department created an official romanization of Moiyen in 1960, one of four languages receiving this status in Guangdong.
Etymology.
The name of the Hakka people who are the predominant original native speakers of the variety literally means "guest families" or "guest people": "Hak" 客 (Mandarin: kè) means "guest", and "ka" 家 (Mandarin: jiā) means "family". Amongst themselves, Hakka people variously called their language Hak-ka-fa (-va) 客家話, Hak-fa (-va), 客話, Tu-gong-dung-fa (-va) 土廣東話, literally, "Native Guangdong language", and Ngai-fa (-va) 我話, "My/our language".
History.
Early history.
It is commonly believed that Hakka people have their origins in several episodes of migration from northern China into southern China during periods of war and civil unrest dating back as far as the end of Western Jin. The forebears of the Hakka came from present-day Henan and Shaanxi provinces and brought with them features of Chinese varieties spoken in those areas during that time. (Since then, the speech in those regions has evolved into dialects of modern Mandarin). The presence of many archaic features occur in modern Hakka, including final consonants , as are found in other modern southern Chinese varieties, but which have been lost in Mandarin.
Due to the migration of its speakers, Hakka may have been influenced by other language areas through which the Hakka-speaking forebears migrated. For instance, common vocabulary is found in Hakka, Min, and the She (Hmong–Mien) languages.
Linguistic development.
A regular pattern of sound change can generally be detected in Hakka, as in most Chinese varieties, of the derivation of phonemes from earlier forms of Chinese. Some examples:
Dialects.
Hakka has as many regional dialects as there are counties with Hakka speakers as the majority. Some of these Hakka dialects are not mutually intelligible with each other. Surrounding Meixian are the counties of Pingyuan (平遠, Pin Yen), Dabu (大埔, Tai Pu), Jiaoling (蕉嶺, Jiao Liang), Xingning (興寧 or 興寕, Hin Nen), Wuhua (五華, Ng Fah), and Fengshun (豐順, Foong Soon). Each is said to have its own special phonological points of interest. For instance, the Xingning lacks the codas and . These have merged into and , respectively. Further away from Meixian, the Hong Kong dialect lacks the medial, so whereas Moiyen pronounces the character 光 as , Hong Kong Hakka dialect pronounces it as , which is similar to the Hakka spoken in neighbouring Shenzhen.
As much as endings and vowels are important, the tones also vary across the dialects of Hakka. The majority of Hakka dialects have six tones. However, there are dialects which have lost all of their Ru Sheng tones, and the characters originally of this tone class are distributed across the non-Ru tones. Such a dialect is Changting 長汀 which is situated in the Western Fujian province. Moreover, there is evidence of the retention of an earlier Hakka tone system in the dialects of Haifeng 海豐 and Lufeng 陸豐 situated on coastal south eastern Guangdong province. They contain a yin-yang splitting in the Qu tone, giving rise to seven tones in all (with yin-yang registers in Ping and Ru tones and a Shang tone).
In Taiwan, there are two main dialects: Sixian (Hakka: Siyen 四縣) and Haifeng (Hakka: Hoi Foong 海豐), alternatively known as Hailu (Hakka: Hoiluk 海陸). Hakka dialect speakers found on Taiwan originated from these two regions. Sixian (Hakka: Siyen, 四縣) speakers come from Jiaying (嘉應) and surrounding Jiaoling, Pingyuan, Xingning, and Wuhua. Jiaying county later changed its name to Meixian. The Hoiliuk dialect contains postalveolar consonants (, , , etc.), which are uncommon in other southern Chinese varieties. Wuhua, Dabu, and Xingning dialects have two sets of fricatives and affricates.
"Ethnologue" reports the dialects as "Yue-Tai" (Meixian, Wuhua, Raoping, Taiwan Kejia: Meizhou above), "Yuezhong "(Central Guangdong), "Huizhou, Yuebei" (Northern Guangdong), "Tingzhou" (Min-Ke), "Ning-Long" (Longnan), "Yugui, Tonggu."
Vocabulary.
Like other southern Chinese varieties, Hakka retains single syllable words from earlier stages of Chinese; thus a large number of syllables are distinguished by tone and final consonant. This reduces the need for compounding or making words of more than one syllable. However, it is also similar to other Chinese varieties in having words which are made from more than one syllable.
Hakka prefers the verb 講 when referring to "saying" rather than the Mandarin "shuō" 說 (Hakka ).
Hakka uses 食, like Cantonese for the verb "to eat" and 飲 (Hakka ) for "to drink", unlike Mandarin which prefers "chī" 吃 (Hakka ) as "to eat" and "hē" 喝 (Hakka ) as "to drink" where the meanings in Hakka are different, "to stutter" and "to be thirsty" respectively.
Writing systems.
Various dialects of Hakka have been written in a number of Latin orthographies, largely for religious purposes, since at least the mid-19th century.
Previously, the single largest work in Hakka is the New Testament and Psalms (1993, 1138 pp., see The Bible in Chinese: Hakka), although since 2012, that has been surpassed by the publication of the complete Hakka Bible known as the and includes the Old Testament along with audio recordings. These works render Hakka in both romanization (pha̍k-fa-sṳ) and Han characters (including ones unique to Hakka) and are based on the dialects of Taiwanese Hakka speakers. The work of Biblical translation is being performed by missionaries of the Presbyterian Church in Canada.
The popular "The Little Prince" has also been translated into Hakka (2000), specifically the Miaoli dialect of Taiwan (itself a variant of the Sixian dialect). This also was dual-script, albeit using the Tongyong Pinyin scheme.

</doc>
<doc id="52982" url="https://en.wikipedia.org/wiki?curid=52982" title="Deep frying">
Deep frying

Deep frying (also referred to as deep fat frying) is a cooking method in which food is submerged in hot fat, most commonly oil. Normally, a deep fryer or chip pan is used for this; industrially, a pressure fryer or vacuum fryer may be used. Deep frying may also be performed using oil that is heated in a pot. on PAGE 230, see the Tools section for other refs--> Deep frying is classified as hot-fat cooking method Typically, deep frying cooks foods quickly: all sides of a food are cooked simultaneously as oil has a high rate of heat conduction.
The word "deep frying" and many modern deep-fried foods were not invented until the 19th century, but the practice has been around for millennia. Early records and cookbooks suggest that the practice began in a few European and Arabian countries before other countries adopted the practice.
Deep frying is popular worldwide, with deep-fried foods accounting for a large portion of global caloric consumption. Many foods are deep-fried and cultures surrounding deep frying have developed, most notably in the Southern United States, where many events dedicated to deep frying food and non-edible items are held.
History.
Although the nouns "deep-fried", "deep-frying", and the verb "deep-fry" were not documented until 1916, 1932, and 1933 (respectively); the practice of deep frying food has been around much longer. One of the earliest known practices of deep frying came from the Egyptians in the 5th millennium BCE. Later developments included the Greeks deep frying food in olive oil in the 5th century BCE. In the 1st century CE, a Roman cookbook, "Apicius", appears to list the ancient Romans' first use of deep frying to prepare Pullum Frontonianum, a chicken dish. The practice of deep frying spread to other parts of Europe and Arabia in the following centuries. Deep-fried foods such as funnel cakes arrived in northern Europe by the 13th century, and deep-fried fish recipes have been found in cookbooks in Spain and Portugal at around the same time. Falafel arrived in the Middle East from population migrations from Egypt as soon as the 14th century. The deep frying of food in Japan was likely introduced by Portuguese the 16th century. Evidence of potato frying can be found as early as the late 17th century in Europe.
Modern deep frying began in the 19th century with the growing popularity of cast iron, particularly around the American South which lead to the development of many modern deep-fried dishes. French fries, invented in the late 18th century, became popular in the early 19th century western Europe. Doughnuts were invented in the mid-19th century, with foods such as onion rings, deep-fried turkey, and corn dogs --> all being invented in the early 20th century. In recent years, the growth of fast food has expanded the reach of deep-fried foods, especially French fries.
Technique.
Deep frying food is defined as a process where food is completely submerged in hot oil at temperatures typically between and . One common method for preparing food for deep frying involves adding multiple layers of batter around the food, such as cornmeal, flour, or tempura; breadcrumbs may also be used. After the food is submerged in oil, the surface of it begins to dehydrate and it undergoes Maillard reactions which break down sugars and proteins, creating the golden brown exterior of the food. Once the surface is dehydrated, it forms a crust which prevents further oil absorption. The heat conducts throughout the food causing proteins to denature, starches to undergo starch gelatinization, and dietary fiber to soften.
While most foods need batter coatings for protection, it is not as necessary for cooked noodles and potatoes because their high starch content enables them to hold more moisture and resist shrinking. Meats may be cooked before deep frying to ensure that they are done inside while keeping juiciness.
When performed properly, deep frying does not make food excessively greasy, because the moisture in the food repels the oil. The hot oil heats the water within the food, steaming it; oil cannot go against the direction of this powerful flow because (due to its high temperature) the water vapor pushes the bubbles toward the surface. As long as the oil is hot enough and the food is not immersed in the oil for too long, oil penetration will be confined to the outer surface. Foods deep-fried at proper temperatures typically absorb "no more than a couple of tablespoons per cups of oil" used. This oil absorption rate is around the same as occurs with shallow frying, such as in a pan.
However, if the food is cooked in the oil for too long, much of the water will be lost and the oil will begin to penetrate the food. The correct frying temperature depends on the thickness and type of food, but in most cases it lies between . An informal test for a temperature close to this range involves adding a tiny amount of flour into the oil and watching to see if it sizzles without immediately burning.--> A second test involves adding one piece of food to deep fry and watching it sink somewhat and rise back up.--> Sinking without resurfacing indicates that the oil is too cold; not sinking at all indicates that the oil is too hot.
It is recommended that deep fryers be cleaned often to prevent contamination. The process of cooking with oil can also contaminate nearby surfaces as oil may splatter on adjacent areas. Oil vapors can also condense on more distant surfaces such as walls and ceilings. Supplies such as dish detergent and baking soda can effectively clean affected surfaces.
Tools.
Deep frying is done with a deep fryer, a pan such as a wok or chip pan, a Dutch oven, or a cast-iron pot. Additional tools include fry baskets, which are used to contain foods in a deep fryer and to strain foods when removed from the oil, and cooking thermometers, used to gauge oil temperature. Tongs, slotted spoons, wooden spoons, and sieves may be used to remove or separate foods from the hot oil.
Japanese deep frying tools include long metal chopsticks; the "agemono-nabe" deep frying pot, which is heavy for retaining heat and deep for holding oil; the "ami-shakushi" net ladle used for scooping out batter debris; and the "abura-kiri" oil drying rack pan.
Dishes, foods, and culture.
Deep-fried foods are common in many countries, and have also been described as "a staple of almost all street cuisines on all continents". There are hundreds of dishes that are associated with deep frying as most foods can be deep-fried. Examples of food that can be deep-fried include meat, poultry, fish and vegetables. Fish and chips, for instance, combines deep-fried fish and deep-fried potatoes. French fries, doughnuts, onion rings, and hushpuppies are common deep-fried foods. Other common deep-fried foods include Chinese "You Bing" deep-fried pancakes, Southeast Asian Jin deui, and Japanese tempura. Less common deep-fried foods include maple leaves, peanut butter and jelly sandwiches, pizza, and Snickers bars.
In the United States, the "Chicago Tribune" notes that "you can deep fry almost anything". The American South has been noted as a modern center of innovation in the area of deep-fried food. According to the owner of a deep frying restaurant in the South, "If something is edible, you can bet that someone south of the Mason-Dixon line has tried to cook it in oil.
Africa.
In Northern Africa, deep-fried dishes are a part of the cuisine. A common food in this region is the deep-fried fritter, also referred to as "sponges". In areas of Southern Africa, street foods include deep-fried potato and cassava chips. Deep-fried foods in the country of South Africa include fish and chips, "vetkoek" and "koeksisters", among others.
Asia.
Japanese tempura is a popular deep-fried food that generally consists of battered and fried seafood and vegetables. Japanese deep-fried dishes, or Agemono, include other styles besides tempura, such as Karaage, Korokke, Kushikatsu, and Tonkatsu. In areas of south-east Asia such as Thailand, insects are commonly deep-fried for human consumption. Western-style fast food items such as donuts, deep-fried chicken, and deep-fried potatoes are also becoming popular in Asia.
Deep-fried fish, tofu, and ' are commonly eaten in Vietnamese cuisine. Deep frying is also used to make several kinds of ', including ' (fried rice ball), ' (sesame ball), ' (hollow doughnut), ' (sweet potato pancake), ' (banana fritter), Hồ Tây–style ' (shrimp fritter), and "" (pillow cake).
Deep-fried sticks of dough, known as youtiao in Chinese, are eaten in many East and Southeast Asian cuisines.
In Hong Kong, is a popular food.
Europe.
Many countries in Europe use pure or hydrogenated rapeseed oil for deep-frying. The deep-fried Mars bar originated in Scotland, with The Carron Fish Bar in Stonehaven claiming to have invented it in the early 1990s. Fish and chips is a very popular deep-fried dish in England since it originated in London in the 19th century and became popular among the working class. Its popularity continues with 229 million portions of fish and chips being sold annually in England.
There is an annual trade fair devoted to deep-fried foods called the International Symposium on Deep-Fat Frying which features discussions on deep fat frying as well as exhibitions by companies involved with the process.
Belgian tradition requires French fries to be deep-fried in filtered fat of cattle, locally called "blanc de boeuf" or "ossewit".
North America.
In the United States, soybean oil is often used for deep-frying. Beignets, originally a French dish, are a popular deep-fried pastry in the U.S. city of New Orleans. Deep-fried food has been a core part of the culture of the American South with many restaurants solely serving deep-fried foods. The owner of one such restaurant has said that the deep-fried food, "in the South it's a way of life". Fast food is one of the most common ways to consume deep-fried food in North America.
Novelty deep-fried foods are popular today in American fairs, especially those in the American South. Hundreds of items are served at these fairs. Some of them include deep-fried beer, butter, and bubblegum. Additionally, deep frying can be used as a form of artwork by frying non-edible objects, such as electronics. Artists such as Henry Hargreaves have deep-fried replicas of electronic items such as iPads, Game Boys, and laptops.
Deep-fried food contests are frequently held at fairs such as the Texas State Fair, where they hold an annual contest for the most creative deep-fried food. Notable past winners have included fried Coke and deep-fried butter, both invented by Abel Gonzales. Since 2013, an American reality competition show called "deep-fried Masters", produced by Discovery Networks, holds deep frying competitions at several state fairs across the country.
Oceania.
Milk bars in Australia may purvey several types of deep-fried foods, along with other food types.
South America.
The buñuelo, a fried dough ball popular in Central America and Greece, is a popular deep-fried snack and street food in South America. Picarone, a Peruvian dessert originated in the colonial period, are deep-fried cakes made with pumpkin and sweet potatoes, popular in Peru and Chile, especially during harvest festivals.
Oil deterioration.
Overheating or over-using the frying oil leads to formation of rancid-tasting products of oxidation, polymerization, and other deleterious, unintended or even toxic compounds such as acrylamide (from starchy foods). Recent research suggests fat deterioration may be worse when fat or oil is fried with food than when fat or oil is tested on its own in a laboratory. Deep-frying under vacuum helps to significantly reduce acrylamide formation, but this process is not widely used in the food industry due to the high investment cost involved.
Some useful tests and indicators of excessive oil deterioration are the following:
Instruments that indicate total polar compounds, currently the best single gauge of how deep-fried an object is, are available with sufficient accuracy for restaurant and industry use.
Hazards.
Cooking oil is flammable, and fires may be caused by it igniting at too high a temperature. Further, attempts to extinguish an oil fire with water cause an extremely dangerous condition, a boilover, as they cause the water to flash into steam due to the high heat of the oil, in turn sending the burning oil in all directions and thus aggravating the fire. This is the leading cause of house fires in the United Kingdom. Instead, oil fires must be extinguished with a non-water fire extinguisher or by smothering. Other means of extinguishing an oil fire include application of dry powder (e.g., baking soda, salt) or fire fighting foam. Most commercial deep fryers are equipped with automatic fire suppression systems using foam.
Spilled hot cooking oil can also cause severe third degree burns, In the worst-case scenario, severe burns can be fatal. The higher temperatures and tendency of oil to stick to the skin make spilled hot cooking oil far more dangerous than spilled hot water. Children can accidentally place their hands on top of the stove, playing with the materials while being cooked, or accidentally pull the pot down, which can cause significant injury. The utmost care should be used when deep frying when children are present, to protect their safety at all times.
Effects.
Environmental.
Deep frying produces large amounts of waste oil, which must be disposed of properly. Waste oil can overflow sewage systems, bind to the walls of sewage pipes, and interfere with sewage treatment. Waste oil from deep frying is increasingly being recycled and refined into biodiesel. Potatoes that are stored in artificially humidified warehouses contain more water, which makes the time required to deep fry them into chips longer. This increases the carbon dioxide footprint of commercially producing chips because more energy is required for frying over a longer time. According to one source, an average home appliance deep fryer draws 2,000 watts.
Health.
The process of deep frying food is generally detrimental to its nutritional value. The oils that foods absorb in their batter typically contain large amounts of fats, especially saturated fats and trans fats. Consumption of large amounts of saturated and trans fats has been linked to a higher risk for some cancers including prostate cancer. Eating deep-fried foods has also been linked to higher cholesterol levels, obesity, heart attacks, and diabetes. Deep-fried foods cooked at certain temperatures can also contain acrylamide, a carcinogen.
Additionally, fat degradation processes during deep frying results in the loss of nutritional value in deep-fried foods.
Some studies have found that deep frying in olive and sunflower oils has been found to be less of a detriment to health and in some cases have positive effects on insulin levels. Oil can be reused a few times after original use after straining out solids. However, excessive use of the same oil can cause it to break down and release compounds into the food that may be carcinogenic, affect liver health, or influence the body's ability to absorb vitamins. Some European countries have set public health standards for the safety of frying oil.

</doc>
<doc id="52983" url="https://en.wikipedia.org/wiki?curid=52983" title="Hot salt frying">
Hot salt frying

Hot salt frying and hot sand frying are cooking techniques used by street-side food vendors in Pakistan, China and India.
Hot salt frying.
In Pakistan, hot salt frying is mostly used by street vendors to cook corn. Rock salt is preheated in a wok. Either the whole corn or individual kernels are buried in the salt and occasionally turned.
Coarse sea salt is placed in a large wok and heated to a high temperature. Dry food items, such as eggs in shell, are buried in the hot salt and occasionally turned with a spatula.
In India, this technique is used by street vendors sell shelled peanuts or popcorn cooked in salt heated in an iron wok.
At times beef steak is fried in this manner - by preheating the frying-pan and salt and the placing steak on it on one side for a minute and then on the other side for two minutes depending on the thickness and how well one wants it.
Hot sand frying.
Hot sand frying is a common cooking technique for street-side food vendors in China and India to cook chestnuts and peanuts. A large wok is filled with black sand and heated to high temperature. Nuts are buried in the hot sand and occasionally turned with a spatula, then the sand and nuts are separated through a wire-mesh screen.

</doc>
<doc id="52985" url="https://en.wikipedia.org/wiki?curid=52985" title="Pan frying">
Pan frying

Pan frying is a form of frying characterized by the use of minimal cooking oil or fat (compared to shallow frying or deep frying); typically using just enough oil to lubricate the pan. In the case of a greasy food such as bacon, no oil or fats may be needed. As a form of frying, pan frying relies on oil as the heat transfer medium and on correct temperature and time to retain the moisture in the food. Because of the partial coverage, the food must be flipped at least once to cook both sides.
A pan fry takes place at lower heat than does a sauté. This is because the food to be pan-fried, such as chicken breasts, steak, pork chops or fish fillets, is not cut into small pieces before cooking. Pan frying requires a lower heat so that the exterior of the food doesn’t overcook until the interior reaches the proper temperature.
The same amount of oil is used as for a sauté – just enough to glaze the pan – but the temperature should be lower during a pan fry. It’s important to note that the oil should always be hot enough to ensure that the moisture in the food can escape in the form of steam. The force of the steam keeps the oil from soaking into the food.
Techniques.
Generally, a shallower cooking vessel is used for pan frying than deep frying. (Using a deep pan with a small amount of oil, butter or bacon grease does reduce spatter.) A denser cooking vessel is better than a less dense pan because that mass will improve temperature regulation. An electric skillet can be used analogously to an electric deep fryer and many of these devices have a thermostat to keep the liquid (in this case, oil) at the desired temperature.
Foods to be pan-fried are usually covered with a batter or breading. Batters consist of dried ingredients such as flour or cornstarch in conjunction with liquids such as milk, water or other beverages. Breadings can be as simple as dusting the food in flour or more commonly what is called the “standard breading procedure.” The standard breading procedure involves first dusting the food in flour, (taking care to shake off the excess), then dipping it in beaten eggs, and finally into bread crumbs or some other form of outer coating. Season the food with salt and pepper prior to coating. Allowing the food to rest for 15-30 minutes before frying enables the breading to stick to the food with greater tenacity.

</doc>
<doc id="52986" url="https://en.wikipedia.org/wiki?curid=52986" title="Sautéing">
Sautéing

Sautéing ( or , ; from the French "sauté" , lit. "jumped, bounced" in reference to tossing while cooking) is a method of cooking food that uses a small amount of oil or fat in a shallow pan over relatively high heat. Ingredients are usually cut into pieces or thinly sliced to facilitate fast cooking. The primary mode of heat transfer during sautéing is conduction between the pan and the food being cooked. Food that is sautéed is browned while preserving its texture, moisture, and flavor. If meat, chicken, or fish is sautéed, the sauté is often finished by deglazing the pan's residue to make a sauce.
Sautéing may be compared with pan frying, in which larger pieces of food (for example, chops or steaks) are cooked quickly in oil or fat, and flipped onto both sides. Some cooks make a distinction between the two based on the depth of the oil used, while others use the terms interchangeably. Sautéing differs from searing in that searing only browns the surface of the food. Olive oil should not be used to sauté due to its low smoke point. Clarified butter, rapeseed oil and sunflower oil are commonly used for sautéing, but most fats will do. Regular butter will produce more flavor but will burn at a lower temperature and more quickly than other fats due to the presence of milk solids, so clarified butter is more fit for this use.
Method.
In a sauté, all the ingredients are heated at once, and cooked quickly. To facilitate this, the ingredients are rapidly moved around in the pan, either by the use of a utensil, or by repeatedly jerking the pan itself. A sauté pan must be large enough to hold all of the food in one layer, so steam can escape, which keeps the ingredients from stewing and promotes the development of fond. Most pans sold specifically as sauté pans have a wide flat base and low sides, to maximize the surface area available for heating. The low sides allow quick evaporation and escape of steam. While skillets typically have flared or rounded sides, sauté pans typically have straight, vertical sides. This keeps the ingredients from escaping as the pan is jerked or stirred.
Only enough fat to lightly coat the bottom of the pan is needed for sautéing; too much fat will cause the food to fry rather than just to slide, and may interfere with the development of fond. The food is spread across the hot fat in the pan, and left to brown, turning or tossing frequently for even cooking. The sauté technique involves gripping the handle of the sauté pan firmly, and using a sharp elbow motion to rapidly jerk the pan back toward the cook, repeating as necessary to ensure the ingredients have been thoroughly jumped. Tossing or stirring the items in the pan by shaking the pan too often, however, can cause the pan to cool faster and make the sauté take longer.

</doc>
<doc id="52987" url="https://en.wikipedia.org/wiki?curid=52987" title="Grilling">
Grilling

Grilling is a form of cooking that involves dry heat applied to the surface of food, commonly from above or below.
Grilling usually involves a significant amount of direct, radiant heat, and tends to be used for cooking meat quickly. Food to be grilled is cooked on a grill (an open wire grid such as a gridiron with a heat source above or below), a grill pan (similar to a frying pan, but with raised ridges to mimic the wires of an open grill), or griddle (a flat plate heated from below). Heat transfer to the food when using a grill is primarily through thermal radiation. Heat transfer when using a grill pan or griddle is by direct conduction. In the United States, when the heat source for grilling comes from above, grilling is called broiling. In this case, the pan that holds the food is called a broiler pan, and heat transfer is through thermal radiation.
Direct heat grilling can expose food to temperatures often in excess of . Grilled meat acquires a distinctive roast aroma and flavor from a chemical process called the Maillard reaction. The Maillard reaction only occurs when foods reach temperatures in excess of .
Studies have shown that cooking beef, pork, poultry, and fish at high temperatures can lead to the formation of heterocyclic amines, benzopyrenes, and polycyclic aromatic hydrocarbons, which are carcinogens.
Marination may reduce the formation of these compounds. Grilling is often presented as a healthy alternative to cooking with oils, although the fat and juices lost by grilling can contribute to drier food.
Regional variations.
Asia.
In Japanese cities, yakitori carts, restaurants, or shops can be found. These contain charcoal-fired grills and marinated grilled meat on a stick. Yakiniku, is a type of food where meat and/or vegetables are grilled directly over small charcoal or gas grills at high temperatures. (This style of cooking has become popular throughout Asia.) In Malaysia, Singapore, Indonesia, and Thailand, a popular food item from food vendors is satay, which is marinated meat on a bamboo skewer grilled over a charcoal fire and served with peanut (sate) sauce.
Germany.
In Germany, the most prominent outdoor form of grilling is using the gridiron over a bed of burning charcoal. Care is taken that the charcoal does not produce flames. Often beer is sprinkled over the sausages or meat and used to suppress flames. The meat is usually marinated before grilling. Besides charcoal, sometimes gas and electric heat sources are used. Other methods are used less frequently.
South America.
In Argentina and Uruguay, both "asado" (beef roasted on a fire) and steak "a la parrilla" (beefsteak cooked on traditional grill) are staple dishes and even hailed as national specialties.
Sweden.
In Sweden, grilling directly over hot coals is the most prominent form of grilling. Usually the meat is Boston butt, pork chops or pork fillet. It is also common to cook meat and vegetables together on a skewer, this is called "grillspett".
United Kingdom, Commonwealth and Ireland.
In the United Kingdom, Commonwealth countries, and Ireland, grilling generally refers to cooking food directly under a source of direct, dry heat. The "grill" is usually a separate part of an oven where the food is inserted just under the element. This practice is referred to as "broiling" in North America.
In Australia, grilling generally refers to cooking food directly under a source of direct heat. Sometimes the term grilling may refer to cooking with heat from below, as in the United States. In the 1970s and 1980s the electric, two sided vertical grill marketed by the Sunbeam company achieved cult status because of its quick, clean, and fat free operation.
In electric ovens, grilling may be accomplished by placing the food near the upper heating element, with the lower heating element off and the oven door partially open. Grilling in an electric oven may create a large amount of smoke and cause splattering in the oven. Both gas and electric ovens often have a separate compartment for grilling, such as a drawer below the flame or one of the stove top heating elements.
United States.
In the United States, the use of the word grill refers to cooking food directly over a source of dry heat, typically with the food sitting on a metal grate that leaves "grill marks." Grilling is usually done outdoors on charcoal grills or gas grills; a recent trend is the concept of infrared grilling. Grilling may also be performed using stove-top "grill pans" which have raised metal ridges for the food to sit on, or using an indoor electric grill.
A skewer, brochette, or rotisserie may be used to cook small pieces of food. The resulting food product is often called a "kabob" ("US term") or "kebab" which means "to grill" in Persian. Kebab is short for "shish kebab" (shish = skewer). Shish kebabs have a Persian origin, but are now commonplace in US cuisine.
Mesquite or hickory wood chips (damp) may be added on top of the coals to allow a smoldering effect that provides additional flavor to the food. Other hardwoods such as pecan, apple, maple and oak may also be used.
Health risks.
As is true of any high-temperature frying or baking, when meat is grilled at high temperatures, the cooking process can generate carcinogenic chemicals. Two processes are thought to be responsible. Heterocyclic amines (HCAs) are formed when amino acids, sugars, and creatine react at high temperatures. Polycyclic aromatic hydrocarbons (PAHs) are formed when fat and juices from meat grilled directly over an open fire drip onto the fire, causing flames. These flames contain PAHs that then adhere to the surface of the meat.
However it is possible to significantly reduce carcinogens when grilling meat, or mitigate their effect. Garlic, rosemary, olive oil, cherries, and vitamin E have been shown to reduce formation of both HCAs and PAHs. V-profiled grill elements placed at an angle may help drain much of the meat juices and dripping fat, and transport them away from the heat source. Heat sources on the top (as in many electrical or gas ovens), or on the side (vertical grilling) avoid completely the burning of fat dripping from the meat, and the meats contact with the flames. Another method is precooking the meat in the microwave, which can reduce HCA formation by reducing the time that meat must be in contact with high heat to finish cooking.
Methods.
Gridironing.
Gridironing is the cooking of meats or other foods using a grill suspended above a heat source. Grilling is often performed outdoors using charcoal (real wood or preformed briquettes), wood, or propane gas. Food is cooked using direct radiant heat. Some outdoor grills include a cover so they can be used as smokers or for grill-roasting/barbecue. The suspended metal grate is often referred to as a gridiron.Outdoor grilling on a gridiron may be referred to as "barbecue", though in US usage, the term "barbecue" refers to the cooking of meat through indirect heat and smoke. "Barbecue" has several meanings and may be used to refer to the grilled food itself, to a distinct type of cooked meat called Southern barbecue, to the grilling device used to cook the food (a "barbecue grill"), or to the social event of cooking and eating such food (which may also be called a "cook-out" or "braai").
Charcoal kettle-grilling.
Charcoal kettle-grilling refers to the process of grilling over a charcoal fire in a kettle, to the point that the edges are charred, or charred grill marks are visible. Some restaurants seek to re-create the charcoal-grilled experience via the use of ceramic lava rocks or infrared heat sources, offering meats that are cooked in this manner as "charcoal-cooked" or "charcoal-grilled".
Grill-baking.
By using a baking sheet pan placed above the grill surface, as well as a drip pan below the surface, it is possible to combine grilling and roasting to cook meats that are stuffed or coated with breadcrumbs or batter, and to bake breads and even casseroles and desserts. When cooking stuffed or coated meats, the foods can be baked first on the sheet pan, and then placed directly on the grilling surface for char marks, effectively cooking twice; the drip pan will be used to capture any crumbs that fall off from the coating or stuffing.
Grill-braising.
It is possible to braise meats and vegetables in a pot on top of a grill. A gas or electric grill would be the best choices for what is known as "barbecue-braising" or "grill-braising", or combining grilling directly on the surface and braising in a pot. To braise on a grill, put a pot on top of the grill, cover it, and let it simmer for a few hours. There are two advantages to barbecue-braising. The first is that this method allows for browning the meat directly on the grill before the braising, and the second is that it also allows for glazing the meat with sauce and finishing it directly over the fire after the braising, effectively cooking the meat three times, which results in a soft textured product that falls right off the bone. This method of cooking is slower than regular grilling but faster than pit-smoking, starting out fast, slowing down, and then speeding up again to finish. If a pressure cooker is used, the cooking time will be much faster.
Indoor grilling.
Many restaurants incorporate an indoor grill as part of their cooking apparatus. These grills resemble outdoor grills, in that they are made up of a grid suspended over a heat source. However, indoor grills are more likely to use electric or gas-based heating elements. Some manufacturers of residential cooking appliances now offer indoor grills for home use, either incorporated into a stove top or as a standalone electric device.
Sear grilling.
Sear-grill and gear grilling is a process of searing meat or food items with an infrared grill. In sear grilling, propane or natural gas is used to heat a ceramic plate, which then radiates heat at temperatures over 480 °C (900 °F).
Sear-grilling instantly sears the outside of meat to make the food more flavorful. Commonly, grilling heats the surrounding air to cook food. In this method, the infrared grill directly heats the food, not the air.
Stove-top pan grilling.
Stove-top pan grilling is an indoor cooking process that uses a grill pan — similar to a frying pan but with raised ridges to emulate the function or look of a gridiron. In pan grilling, heat is applied directly to the food by the raised ridges and indirectly through the heat radiating off the lower pan surface by the stove-top flame. Stove-top grill pans can be used to put sear marks on meat before it is finished by overhead radiant heat. When cooking leaner meats, oil is often applied to the pan ridges to aid in food release.
Some griddles designed for stove-top use incorporate raised ridges in addition to a flat cooking area. These are either on half of the cooking surface or, in the case of reversible two-sided griddles, on one side with the flat surface on the other.
Flattop grilling.
Foods termed "grilled" may actually be prepared on a hot griddle or flat pan. The griddle or pan may be prepared with oil (or butter), and the food is cooked quickly over a high heat. Griddle-grilling is best for relatively greasy foods such as sausages. Some griddle-grilled foods may have grill marks applied to them during the cooking process with a "branding plate", to mimic the appearance of charbroil-cooked food.
A flattop grill is a cooking appliance that resembles a griddle but performs differently because the heating element is circular rather than straight (side to side). This heating technology creates an extremely hot and even cooking surface, as heat spreads in a radial fashion over the surface.
The first flattop grills originated in Spain and are known as planchas or la plancha. Food that is cooked a la plancha means grilled on a metal plate. Plancha griddles or flat tops are chrome plated which prevents reaction with the food. Some base metal griddles will impart a subtle flavor to the food being cooked.
The flattop grill is a versatile platform for many cooking techniques such as sautéing, toasting, steaming, stir frying, grilling, baking, braising, and roasting, and can also be used in flambéing. In addition, pots and pans can be placed directly on the cooking surface for even more cooking flexibility. In most cases, the steel cooking surface is seasoned like cast iron cookware, providing a natural non-stick surface.
Charbroiling.
Charbroiling, or chargrilling outside North America, refers to grilling on a surface with wide raised ridges, to the point of having the food slightly charred in texture.
Overhead grilling.
In the United States, oven pan broiling refers to a method of cooking inside an oven on a broil pan with raised ridges, where the heat can be applied from either above or below. In gas and electric ovens, this is accomplished with a heating element and a broil pan. Sometimes, the food is placed near the upper heating element to intensify the heat. The lower heating element may or may not be left off and the oven door is sometimes opened partially. Gas ovens often have a separate compartment for broiling, sometimes a drawer below the bottom flame.
Salamander.
A salamander is a culinary grill characterized by very high temperature overhead electric or gas heating elements. It is used primarily in professional kitchens for overhead grilling (US: broiling). It is also used for toasting, browning of gratin dishes, melting cheeses onto sandwiches, and caramelizing desserts such as crème brûlée.
Salamanders are generally similar to an oven without a front door, with the heating elements at the top. They are more compact; typically only half the height and depth of a conventional oven. They are often wall mounted at eye level, enabling easy access and close control of the cooking process. Many salamanders can be fitted with a cast iron "branding" plate which is used to make grill marks on the surface of meat. Some grills can also be fitted with a rotisserie accessory for roasting meats.
Overhead heat has the advantage of allowing foods containing fats, such as steaks, chops and other cuts of meat, to be grilled without the risk of flare-ups caused by the rendered fat dripping onto the heat source. The salamander's facility for extremely high temperature also takes less cooking time than other grilling techniques, reducing preparation time, which is a benefit in professional kitchens during a busy meal service.
Modern salamanders take their name from the 18th century "salamander", the tool of choice for toasting the top of a dish. It consisted of a thick plate of iron attached to the end of a long handle, with two feet, or rests, arranged near the iron plate for propping the plate over the food to be browned. Its name in turn was taken from the legendary type of salamander, a mythical amphibian that was believed to be immune to fire.
Two-sided grilling.
Some commercial devices permit the simultaneous grilling of both sides of the meat at the same time.
The flame-grilling machine at Burger King, Carl's Jr./Hardee's, and other fast food restaurants is called a 'broiler'. It works by moving meat patties along a chain conveyor belt between top and bottom burners, grilling both sides of the meat patty at the same time. This concept was invented in 1898, when the Bridge and Beach Co. of St. Louis, Missouri, started manufacturing a vertical cast iron stove. These stoves were designed to allow the meat to be flame-broiled (flame-grilled) on both sides at the same time. Custom hinged steel wire gridirons were built for use in the vertical broilers. The hinged gridirons were slid in and out of the stoves holding the meat while it cooked evenly on both sides, like modern day oven racks. These stoves took up a small amount of counter space. They were used in lunch spots to feed factory workers.
During the 1990s, double-sided grilling was popular in the USA using consumer electrical grills (e.g., the popular George Foreman Grill). US marketers of electric double-sided grilling appliances opted for the global term 'grilling' rather than the geographically isolated term "broiler." Hinged double-sided grills are generically known as contact grills.
Stone grills.
Sometimes a stone is used to grill foods. Stones in these cases can store temperatures up to 450 °C (842 °F). Foods grilled on stone involve no fats or oil and are considered a healthier alternative.
Whole grilling.
Whole grilling involves grilling a whole carcass as opposed to grilling individual portion sized cuts. This method is often used in order to avoid the need for complicated grill equipment during, for example, a hunt or expedition in the wild. It is also the traditional method of cooking in several cultures where they do a pig roast, luau, or barbacoa. There are several primitive methods and modern equipment that copies and automates the primitive version:

</doc>
<doc id="52988" url="https://en.wikipedia.org/wiki?curid=52988" title="Poaching (cooking)">
Poaching (cooking)

Poaching is a type of moist-heat cooking technique that involves cooking by submerging food in a liquid, such as water, milk, stock or wine. Poaching is differentiated from the other "moist heat" cooking methods, such as simmering and boiling, in that it uses a relatively low temperature (about ). This temperature range makes it particularly suitable for delicate food, such as eggs, poultry, fish and fruit, which might easily fall apart or dry out using other cooking methods.
It is often considered as a healthy method of cooking because it does not use fat to cook or flavor the food. 
One of the most well-known dishes made with the use of poaching is eggs Benedict.
Variations.
Shallow poaching.
This moist-heat cooking method uses a sautoir or other shallow cooking vessel, heat is transferred by conduction from the pan, to the liquid, to the food. Shallow Poaching is best suited for boneless, naturally tender, single serving size, sliced or diced pieces of meat, poultry or fish.
This preparation involves smearing the inside of the pan with whole butter and adding aromatics into the pan. The items to be cooked are then placed on top of the aromatics presentation side up. Cold poaching liquid is then poured in until the product is partially submerged then heated. The liquid should never be allowed to boil but kept as close to boiling as possible.
A more contemporary technique of shallow poaching involves BPA free plastic bags and is very convenient for the home cook.
Deep poaching.
This technique is similar to shallow poaching but the product is fully submerged. The pot used for deep poaching should hold the food, liquid, and aromatics comfortably, with enough room to allow the liquid to expand as it heats. There should also be enough space so that the surface can be skimmed if necessary throughout cooking. A tight-fitting lid may be helpful for bringing the liquid up to temperature.
Poaching liquid.
The poaching liquid traditionally uses a court bouillon which consists of an acid (wine, lemon juice) and aromatics (bouquet garni and mirepoix), although any flavorful liquid can be used in poaching. The liquid should ideally be around , but when poaching chicken, it is vital that the chicken reach an internal temperature of at least in the core, in order to be ingested safely.
A significant amount of flavor is transferred from the food to the cooking liquid. For maximum flavor, the cooking liquid (cuisson) is usually reduced and used as the base for a sauce.
Poached eggs are generally cooked in water and vinegar, fish in white wine, poultry in stock and fruit in red wine.
The liquid used for shallow poaching is typically called a cuisson, and can be reduced and used as a base for the poached item's sauce.
Typical preparation.
Poaching allows the proteins to denature without pulling out too much (if any at all) moisture out of it. For this reason, it is important to keep the heat low and to keep the poaching time to a bare minimum, which will also preserve the flavor of the food.
Typically an egg is poached just to the point where the white is no longer runny and the yolk is beginning to harden around the edges. Some people say creating a whirlpool helps with poaching eggs because it really helps the egg stay together, wrapping the white around the yolk.
Comparison to other methods of preparation.
Water is a relatively efficient conductor of heat, but it also has a fairly low limit to its maximum potential temperature (212 °F (100 °C) at sea level). As such, it is a technique that applies itself to a broad spectrum of methods and results.
It is used to regulate food at a low temperature for extended periods, as with sous-vide. It is also used to rapidly raise the temperature of foods, as with blanching.
Poaching itself is part of a family of moist-heat cooking methods but separates itself in that it is primarily for delicate foods such as eggs. Simmering generally uses a higher temperature for cooking, and because it surrounds the food in water that maintains a more or less constant temperature, simmering cooks food very evenly. Boiling uses the absolute highest temperature for water and is least likely to be used in cooking delicate foods.
While it cannot achieve caramelization, which to many is very desirable, many find the delicate nuance of so-called "blanc" foods very pleasant. Poaching is often confused with stewing, as both techniques involve cooking through simmering. However, the purpose of poaching is to cook while retaining the basic shape and structure of the food, rather than to soften it, as with stewing.

</doc>
<doc id="52989" url="https://en.wikipedia.org/wiki?curid=52989" title="Poaching">
Poaching

Poaching has traditionally been defined as the illegal hunting, killing, or capturing of wild animals, usually associated with land use rights.
Until the 20th century, most poaching was performed by impoverished peasants for subsistence purposes, supplementing meager diets.
By contrast, stealing domestic animals (as in cattle raiding, for example) classifies as theft, not as poaching.
Since the 1980s, the term "poaching" has also referred to the illegal harvesting of wild plant species. In agricultural terms, the term 'poaching' is also applied to the loss of soils or grass sward by the damaging action of feet of livestock which can affect availability of productive land, water pollution through increased runoff and welfare issues for cattle.
In 1998 environmental scientists from the University of Massachusetts Amherst proposed the concept of poaching as an environmental crime, defining any activity as illegal that contravenes the laws and regulations established to protect renewable natural resources including the illegal harvest of wildlife with the intention of possessing, transporting, consuming or selling it and using its body parts. They considered poaching as one of the most serious threats to the survival of plant and animal populations. Wildlife biologists and conservationists consider poaching to have a detrimental effect on biodiversity both within and outside protected areas as wildlife populations decline, species are depleted locally, and the functionality of ecosystems is disturbed.
Acts of poaching.
Violations of hunting laws and regulations concerning wildlife management, local or international wildlife conservation schemes constitute wildlife crimes that are typically punishable. The following violations and offenses are considered acts of poaching in the USA:
Motives.
Sociological and criminological research on poaching indicates that in North America people poach for commercial gain, home consumption, trophies, pleasure and thrill in killing wildlife, or because they disagree with certain hunting regulations, claim a traditional right to hunt, or have negative dispositions toward legal authority. In rural areas of the United States, the key motives for poaching are poverty. Interviews conducted with 41 poachers in the Atchafalaya River basin in Louisiana revealed that 37 of them hunt to provide food for themselves and their families; 11 stated that poaching is part of their personal or cultural history; nine earn money from the sale of poached game to support their families; eight feel exhilarated and thrilled by outsmarting game wardens.
In African rural areas, the key motives for poaching are the lack of employment opportunities and a limited potential for agriculture and livestock production. Poor people rely on natural resources for their survival and generate cash income through the sale of bushmeat, which attracts high prices in urban centres. Body parts of wildlife are also in demand for traditional medicine and ceremonies.
The existence of an international market for poached wildlife implies that well-organised gangs of professional poachers enter vulnerable areas to hunt, and crime syndicates organise the trafficking of wildlife body parts through a complex interlinking network to markets outside the respective countries of origin.
Effects of poaching.
The detrimental effects of poaching can include:
Many tribal people in Africa, Brazil and India rely on hunting for food and have become victims of the fallout from poaching. In the Indian Kanha Tiger Reserve, they are prevented from hunting, and were illegally evicted from their lands following the creation of nature reserves aimed to protect animals. Tribal people are often falsely accused of contributing to the decline of wildlife. In India for example, they bear the brunt of anti-tiger poaching measures, despite the main reason for the tiger population crash in the 20th century being due to hunting by European colonists and Indian royalties. Stephen Corry, director of the human-rights group Survival International, argues that indigenous peoples have shaped landscapes and managed animal populations for millennia. He asserts that conservation organizations such as the World Wildlife Fund apply the term "poaching" unfairly to tribal people engaging in subsistence hunting while supporting trophy hunting by tourists for a fee.
Species affected by poaching.
The global decline of leatherback sea turtle populations is attributed to the illegal harvest of eggs and killing of egg-bearing females at nesting sites along Central and South American coastlines of the Caribbean Sea and on the Malaysian Terengganu beach.
In North America.
In the early 1990s, crimes against wildlife were rampant in certain parts of the United States, and poaching equaled or exceeded the number of animals hunted legally. As trophy hunting became popular, poaching activity, in particular commercial poaching, increased in the Western states. Commercial poachers kill grizzly bears, moose, bighorn sheep, elk, mountain lions, eagles and snakes. Domestic bear species such as American black bear are slaughtered for their body parts that are used for exotic foods, medicinal purposes and as aphrodisiacs. Walrus is poached for the ivory of their tusks, white-tailed deer for antlers and meat, bobcats for their pelts, and bighorn sheep as trophies. Elk antlers and seal penises are used for medicinal purposes. Paddlefish and sturgeon eggs are sold as caviar. Redfish, shellfish, trout and salmon are poached for meat, snakes for their skins, bald eagles for their feathers used in Southwestern art. Protected ridge-nosed rattlesnakes, rock rattlesnakes, twin-spotted rattlesnakes, Sonoran Mountain kingsnakes and massasaugas are illegally collected in Arizona.
Millions of protected plants are illegally collected each year. Plant poaching spans the illegal harvest of ginseng roots, rare orchids, endangered cacti, pitcher plants and Venus flytraps, and tree species such as aspen and western red cedar. Commercial poachers collect hundreds of wildflowers in the Great Smoky Mountains National Park every year, in particular American ginseng, orchids and trilliums. Rangers seized about 11,000 illegally harvested ginseng roots in the Great Smoky Mountains National Park between 1994 and 2004, and attribute ginseng poaching to the illegal domestic and international black market. It is estimated that fresh roots of wild ginseng are worth $65–100 per pound, and dried roots about $260–365 per pound. Ginseng is also harvested illegally in Wisconsin. Goldenseal is suspected to be illegally collected in the Hoosier National Forest.
In 2007, it was estimated that parrot trappers capture about 65,000–78,500 wild parrots each year in Mexico, mainly by setting nets or by collecting nestlings from tree cavities. About 50,000–60,000, more than 75%, die before reaching customers. Between 2003 and 2006, Mexican wildlife officials did not issue permits for parrot trapping as legal permits provided cover for the illegal trade of poached parrots. Illegal trapping of wild parrots affects most of the 22 parrot species native to Mexico including:
Commercial poaching of neotropical river otters for their fur is a continuous threat for Mexican populations.
Bahía Magdalena is a hot spot for mortality of black, loggerhead, olive ridley and hawksbill sea turtles. More than 600 sea turtles are estimated to be killed yearly inside the bay, mostly for consumption of their meat, which is considered a delicacy in Mexico.
In Central America.
The solitary eagle is seriously threatened by poaching.
Illegal hunting of Baird's tapirs is a major threat for populations in Costa Rica, Belize and Panama. In Panama, mammal species hunted by poachers comprise white-tailed deer, red brocket deer, collared peccary, agouti and coati. Geoffroy's tamarin, howler monkey, white-faced capuchin and common opossum are captured less often.
West Indian manatees were illegally hunted in the Port Honduras area in Belize at least until the end of the 1990s. Poachers were suspected to come from Guatemala and Honduras. Manatees were killed for meat, and their bones used for carving trinket and other souvenirs sold in local markets in the Yucatán Peninsula. In 2002, it was estimated that about 40 manatees are killed annually along the eastern Nicaraguan coast and in inland wetlands by poachers and incidental drowning in fishing nets.
Other species poached in Central American countries and in the Dominican Republic for being traded alive include Geoffroy's spider monkey, margay, ocelot, great horned guan, crested guan, great curassow, ocellated turkey, great green macaw, Hispaniolan amazon, Hispaniolan parakeet, red-billed toucan, chestnut-mandible toucan, raptors, rosy boa, rattlesnake, Galápagos tortoise, beaded lizard, green iguana, poison dart frogs and freshwater turtles. Snakes, spectacled caiman, Morelet’s and American crocodiles are killed for their skins. Black iguana, mangrove cockle and queen conch are poached for consuming their meat.
In South America.
In Colombia the endangered helmeted curassow and the near threatened wattled guan are poached for their meat and eggs. The jacutinga population in the Brazilian Atlantic rainforest is threatened by illegal hunting.
In Sub-Saharan Africa.
The population of the critically endangered rhinoceros, inhabiting most of Sub-Saharan Africa, was estimated to have been about 100,000 in 1960 and has now dramatically decreased to only about 4,000, with poaching being attributed as one of the causes of this decline in population. The commercial poaching of white and black rhinoceros escalated in South Africa from 12 rhinos killed in 2004 to 946 rhinos killed in 2013. Rhino horns have increasingly been acquired by Vietnamese people. African elephants, lions, greater kudus, elands, impala, duiker, reedbuck, bushbuck, bushpig, common warthog, chacma baboon and greater cane rat are illegally hunted for the bushmeat trade in Mozambique.
African elephants are being poached for their ivory tusks – the heaviest teeth of any animal alive. In October 2013 poachers poisoned more than 300 African elephants in Hwange National Park in Zimbabwe. Conservationists have claimed the incident to be the highest massacre of animals in South Africa in 25 years. African elephants continue to remain a high target for poachers and some researchers have estimated that African elephants may be extinct in 25–50 years in the wild. African elephants have experienced a 60-70% decline in population in two decades, 1979-2002.
In Central Africa, 13,607 elephants have been poached in 2012 alone. In East Africa, 8,515 elephants have been poached in 2012 alone.
Illegal poaching for African elephants has increased noticeably in 2008 and correlates with an increase in price for local black market ivory and with increased findings of illegal ivory headed to China. There is a probable species reduction of ~3% in 2011 alone.
Estimates of over 25,000 to 35,000 African elephants were killed for their tusks in 2012. Despite ivory trade bans in 1989, elephant numbers continue to decline in Africa.
Finding and monitoring the origin of illegal ivory found will significantly help in efforts to curb and suppress illegal poaching of African elephants.
In Tanzania, 60% of the elephant population has been killed since 2010 and now number fewer than 44,000 individuals. In Mozambique, 48% of the country's elephants were killed in the same period. Local people kill elephants for cash, but penalties are often negligible. In central Africa, militias and terrorist groups also poach elephants, often outside their home countries. They hide inside protected areas and kill park rangers who get in their way.
In South-East Asia.
There are more than 400 endangered faunal species in the Philippines, all of which are illegal to hunt.
Products.
The body parts of many animals, such as tigers and rhinoceroses, are believed to have certain positive effects on the human body, including increasing virility and curing cancer. These parts are sold in areas where these beliefs are practiced - mostly Asian countries particularly Vietnam and China - on the black market.
Traditional Chinese medicine often incorporates ingredients from all parts of plants, the leaf, stem, flower, root, and also ingredients from animals and minerals. The use of parts of endangered species (such as seahorses, rhinoceros horns, binturong and tiger bones and claws) has created controversy and resulted in a black market of poachers. Deep-seated cultural beliefs in the potency of tiger parts are so prevalent across China and other east Asian countries that laws protecting even critically endangered species such as the Sumatran tiger fail to stop the display and sale of these items in open markets, according to a 2008 report from TRAFFIC. Popular "medicinal" tiger parts from poached animals include tiger genitals, culturally believed to improve virility, and tiger eyes.
Rhino populations face extinction because of demand in Asia (for traditional medicine and as a luxury item) and in the Middle East (where horns are used for decoration). A sharp surge in demand for rhino horn in Vietnam was attributed to rumors that the horn cured cancer, even though the rumor has no basis in science. Recent prices for a kilo of crushed rhino horn have gone for as much as $60,000, more expensive than a kilo of gold. Vietnam is the only nation which mass-produces bowls made for grinding rhino horn.
Ivory, which is a natural material of several animals, plays a large part in the trade of illegal animal materials and poaching. Ivory is a material used in creating art objects and jewelry where the ivory is carved with designs. China is a consumer of the ivory trade and accounts for a significant amount of ivory sales. In 2012, "The New York Times" reported on a large upsurge in ivory poaching, with about 70% of all illegal ivory flowing to China.
Fur is also a natural material which is sought after by poachers.
History.
Poaching, like smuggling, has a long counter-cultural history.
The verb "poach" is derived from the Middle English word "pocchen" literally meaning "bagged", "enclosed in a bag".
Poaching was dispassionately reported for England in "Pleas of the Forest", transgressions of the rigid Anglo-Norman Forest Law.
Poaching was romanticized in literature from the time of the ballads of Robin Hood, as an aspect of the "greenwood" of Merry England. "Non est inquirendum, unde venit venison" ("It is not to be inquired, whence comes the venison"), observed Guillaume Budé in his "Traitte de la vénerie".
The 19th century saw the rise of acts of legislation, such as the Night Poaching Act 1828 and Game Act 1831 in the United Kingdom, and various laws elsewhere. In North America, the blatant defiance of the laws by poachers escalated to armed conflicts with law authorities, including the Oyster Wars of the Chesapeake Bay, and the joint US-British Bering Sea Anti-Poaching Operations of 1891 over the hunting of seals.
Anti-poaching efforts.
Africa.
Members of the "Rhino Rescue Project" have implemented a technique to combat rhino poaching in South Africa by injecting a mixture of indelible dye and a parasiticide, which enables tracking of the horns and deters consumption of the horn by purchasers. Since rhino horn is made of keratin, advocates say the procedure is painless for the animal.
Another initiative that seeks to protect Africa's elephant populations from poaching activities is the Tanzanian organization Africa's Wildlife Trust. Hunting for ivory was banned in 1989, but poaching of elephants continues in many parts of Africa stricken by economic decline.
The International Anti-Poaching Foundation has a structured military-like approach to conservation, employing tactics and technology generally reserved for the battlefield. Founder Damien Mander is an advocate of the use of military equipment and tactics, including Unmanned Aerial Vehicles, for military-style anti-poaching operations. Such military-style approaches have garnered some criticism. Rosaleen Duffy of the University of London writes that military approaches to conservation fail to resolve the underlying reasons leading to poaching, and do not tackle either "the role of global trading networks" or continued demand for illegal animal products. According to Duffy, such methods "result in coercive, unjust and counterproductive approaches to wildlife conservation".
Chengeta Wildlife is an organization that works to equip and train wildlife protection teams and lobbies African governments to adopt anti-poaching campaigns.
Asia.
Large quantities of ivory are sometimes destroyed as a statement against poaching (aka "ivory crush"). In 2013 the Philippines were the first country to destroy their national seized ivory stock. In 2014 China followed suit and crushed six tons of ivory as a symbolic statement against poaching.
United States of America.
Some game wardens have made use of robotic decoy animals placed in high visibility areas to draw out poachers for arrest after the decoys are shot and decoys with robotics to mimic natural movements are also in use by law enforcement. 
Sturgeon and paddlefish (aka "spoonbill catfish") are listed as species of "special concern" by the U.S. Federal government, but are only banned from fishing in a few states such as Mississippi and Texas.
Criticism.
Stephen Corry, director of the human-rights group Survival International, has argued that the term "poaching" has at times been used to criminalize the traditional subsistence techniques of indigenous peoples and bar them from hunting on their ancestral lands, when these lands are declared wildlife-only zones. Corry argues that parks such as the Central Kalahari Game Reserve are managed for the benefit of foreign tourists and safari groups, at the expense of the livelihoods of tribal peoples such as the Kalahari Bushmen.

</doc>
<doc id="52991" url="https://en.wikipedia.org/wiki?curid=52991" title="Pressure cooking">
Pressure cooking

Pressure cooking is the process of cooking food, using water or other cooking liquid, in a sealed vessel, known as a "pressure cooker". As pressure cooking cooks food faster than conventional cooking methods, it saves energy.
Pressure is created by boiling a liquid, such as water or broth, inside the closed pressure cooker. The trapped steam increases the internal pressure and allows the temperature to rise. After use, the pressure is slowly released so that the vessel can be safely opened.
Pressure cooking can be used for quick simulation of the effects of long braising. Almost any food which can be cooked in steam or water-based liquids can be cooked in a pressure cooker.
History.
In 1679, the French physicist Denis Papin, better known for his studies on steam, invented the "steam digester" in an attempt to reduce the cooking time of food. His airtight cooker used steam pressure to raise the water's boiling point, thus cooking food much more quickly. In 1681, Papin presented his invention to the Royal Society of London, but the Society's members treated his invention as a scientific study. They granted him permission to become a member of the Society afterwards.
In 1864, Georg Gutbrod of Stuttgart began manufacturing pressure cookers made of tinned cast iron.
In 1919, Spain granted a patent for the pressure cooker to Jose Alix Martínez from Zaragoza. Martínez named it the "olla exprés", literally "express cooking pot", under patent number 71143 in the "Boletín Oficial de la Propiedad Industrial". In 1924, the first pressure cooking pot recipe book was published, written by José Alix and titled "360 fórmulas de cocina Para guisar con la 'olla expres'", or "360 recipes for cooking with a pressure cooker".
In 1938, Alfred Vischer presented his invention, the "Flex-Seal Speed Cooker", in New York City. Vischer's pressure cooker was the first one designed for home use, and its success led to competition among American and European manufacturers. At the 1939 New York World's Fair, National Presto Industries, which was then known as the "National Pressure Cooker Company", introduced its own pressure cooker.
Variants.
An "autoclave" is a type of pressure cooker used by laboratories and hospitals to sterilize equipment. 
In the food industry, pressure cookers are often referred to as "retorts" or "canning retorts."
Large pressure cookers are often called "pressure canners" in the United States, because of their capacity to hold jars used in canning. Pressure canners are specifically designed for home canning, whereas ordinary pressure cookers are not recommended for canning due to the risk of botulism poisoning, because pressure canners hold heat and pressure for much longer than ordinary pressure cookers; these factors are a critical part of the total processing time required to destroy harmful microbes. 
"Pressure fryers" are used for deep fat frying under pressure, because ordinary pressure cookers are not suitable for pressure frying. 
Design.
Parts.
Portable pressure cookers consist of all or most of these basic component parts, depending on the manufacturer and model of pressure cooker:
Pan
Lid
Accessories 
Pressure cookers are typically made of aluminum (aluminium) or stainless steel. Aluminum pressure cookers may be stamped, polished, or anodized, but all are unsuitable for the dishwasher. They are cheaper, but the aluminium is reactive to acidic foods, whose flavors are changed in the reactions, and less durable than stainless steel pressure cookers.
Higher-quality stainless steel pressure cookers are made with heavy, three-layer, or copper-clad bottoms (heat spreader) for uniform heating because stainless steel has lower thermal conductivity. Most modern stainless steel cookers are dishwasher safe, although some manufacturers may recommend washing by hand. Some pressure cookers have a non-stick interior.
A gasket or sealing ring, made from either rubber or silicone, forms a gas-tight seal that does not allow air or steam to escape between the lid and pan. Normally, the only way steam can escape is through a regulator on the lid while the cooker is pressurized. If the regulator becomes blocked, a safety valve provides a backup escape route for steam.
To seal the gasket there are several main methods used. Each determines the design of the pressure cooker:
Because of the forces that pressure cookers must withstand, they are usually heavier than conventional pots of similar size.
Generations.
There are three generations of pressure cookers:
First generation.
Also known as "old type" pressure cookers, these operate with a weight-modified or "jiggly" valve, which releases pressure during operation. Some people might consider them loud or very loud because the weight-modified valve operates similarly to the piston in a steam engine. They typically offer only one pressure level—with the exception of some newer "old style" pressure cookers that allow the operator to change the weight of the weight-modified valve.
Even today, many of the less expensive modern pressure cookers (such as those manufactured and marketed by Presto) are basically variants on the First Generation cookers, albeit with new safety features, such as a mechanism which prevents the cooker from being opened by any means once it comes to pressure, until it is entirely de-pressurized.
Second generation.
These operate with a spring-loaded valve that is often hidden from view in a proprietary mechanism. This generation is characterized by two or more pressure settings. Some of these pressure cookers do not release any steam during operation (non-venting) and instead use a rising indicator with markings to show the pressure level. These only release steam when the pan is opened, or as a safety precaution if the heat source is not reduced enough when the pan reaches the required cooking pressure. Others use a dial that the operator can advance by a few clicks (which alters the spring tension) to change the pressure setting or release pressure; these release steam during operation (venting).
Third: electric pressure cookers.
After the stove-top pressure cookers, in 1991 came the electric pressure cookers, called the "third generation" pressure cookers.
These include an electric heat source that is automatically regulated to maintain the operating pressure. They also include a spring-loaded valve (as described above). This pressure cooker type cannot be opened with a cold water quick-release method and should be operated with caution when releasing vapour through the valve, especially while cooking foamy foods and liquids (lentils, beans, grains, milk, gravy, etc.)
An electric pressure cookers integrates a timer. Depending on cooking control capability, there are three generations of electric pressure cookers: 
Some cookers are multifunctional (multicookers): pressure cooker, saute/browning, slow cooker, rice cooker, yogurt maker, steamer and stockpot warmer (that can also be used to keep cooked food warm).
Pressure settings.
Most pressure cookers have a cooking (operating) pressure setting between 0.8 - 1 bar (11.6 - 15 psi) above sea level pressure (sea level pressure is around 1.016 bar) so the pressure cooker operates at 1.816 to 2.016 bar. The standard cooking pressure of 15 psi above sea level pressure was determined by the United States Department of Agriculture in 1917. At this pressure, water boils at (described in vapour pressure of water article).
The higher temperature causes food to cook faster; cooking times can typically be reduced to one-third of the time for conventional cooking methods. The actual cooking time also depends on the pressure release method used after timing "(see Pressure release methods for details)" and the thickness and density of the food, since thicker (and denser) foods take longer to cook. Meat joints and some other foods like sponge puddings and Christmas puddings are typically timed according to their weight. Frozen foods need extra cooking time to allow for thawing.
When pressure cooking at 1 bar/15 psi above sea level pressure, approximate cooking times are one minute for shredded cabbage, seven minutes for boiled potatoes (if cut small, not diced) and three minutes for fresh green beans. If the pressure is released naturally after timing "(see Pressure release methods for details)," cooking times are even shorter. Food cooks more quickly when cut into smaller pieces.
Some recipes may require cooking at lower than 1 bar/15 psi above sea level pressure e.g. fresh vegetables, as these can easily overcook. Many pressure cookers have 2 or more selectable pressure settings or weights.
Non-standard pressure settings.
Some pressure cookers have a lower or higher "maximum" pressure than 1 bar/15 psi above sea level pressure or can be adjusted to different pressures for some recipes; cooking times will increase or decrease accordingly. This is typically done by having different regulator weights or different pressure settings. If the recipe is devised for a higher pressure and the pressure cooker does not reach that pressure, the cooking time can be increased slightly to compensate. Electric pressure cookers operate at lower pressures than stovetop pressure cookers.
Operation.
Liquid.
Pressure cooking always requires liquid. Pressure cooking cannot be used for cooking methods that produce little steam such as roasting, pan frying, or deep frying. However, Kentucky Fried Chicken restaurants use a combination of pressure cooking and frying, with special pressure fryers in which the chicken's own juices supply the water. Cooking time is reduced substantially, to approximately 12 minutes per amount cooked, but the breading texture is much softer (less crispy) than deep-fried chicken since moisture remains in the breading. Thick sauces do not contain enough liquid to vaporize and create pressure, so they usually burn onto the interior base of the pressure cooker after prolonged heating. Sauces should be thickened after pressure cooking.
Bringing to pressure (stove top pressure cookers).
Food is placed inside the pressure cooker with a small amount of water or other liquid such as stock. Food is either cooked in the liquid or above the liquid to be steamed; the latter method prevents the transfer of flavors from the liquid. The lid is closed, the pressure setting is chosen and the pressure cooker is placed on a stove on the highest heat (less than high for induction cooking to allow air to be vented - see the section below for an explanation). Once the cooker reaches full pressure, the heat is lowered to maintain pressure; timing the recipe begins at this point. Recipes for foods using raising agents such as steamed puddings call for gentle pre-steaming, without pressure, in order to activate the raising agents prior to cooking and achieve a light, fluffy texture.
It takes several minutes for the pressure cooker to reach the selected pressure level. It can take around 10 minutes or longer depending on: the quantity of food, the temperature of the food (cold or frozen food delays pressurization), the amount of liquid, the power of the heat source and the size of the pressure cooker.
A common mistake is for the user to start timing when a colored pop-up indicator rises, which happens when there is the slightest increase in pressure, instead of waiting for the cooker to reach its selected pressure level. The typical pop-up indicator only shows that the cooker has pressure inside, which does not reliably signal that the cooker has reached the selected pressure. This pop-up indicator often acts as an interlock, preventing the lid from being opened while there is internal pressure. Manufacturers may use their own terminology for it, such as calling it a ""locking indicator.""
As the internal temperature rises, the pressure also rises until it reaches the design gauge pressure. Timing the recipe begins when the selected pressure is reached. With first generation designs, the pressure regulator weight begins levitating above its nozzle, allowing excess steam to escape. In second generation pressure cookers, either a relief valve subsequently opens, releasing steam to prevent the pressure from rising any further or a rod rises with markers to indicate the pressure level, without constantly venting steam. At this stage, the heat source should be reduced to the lowest possible heat that still maintains pressure, as extra heat wastes energy and increases liquid loss.
Removal of air.
Before the pressure cooker lid is sealed airtight, the internal air has to be replaced by steam. This is why a pressure cooker takes about 10 minutes to reach pressure. To remove the air, steam is vented for several minutes to replace the volume of air inside the cooker. If the lid is sealed before the air has been removed, the cooking temperature is lower due to air pockets and recipes may be undercooked. For pressure cookers with a weight, the weight is placed over the steam vent pipe while steam is being emitted, to ensure the air inside has escaped. The newer generation pressure cookers, which have no weights, automatically expel air from inside for several minutes before a coloured pop-up indicator pin rises to seal the lid airtight; pressure then builds in the now airtight cooker. If the pressure cooker is already hot or a stovetop pressure cooker is placed on a very strong heat source - such as induction on too high a setting, the lid can seal airtight too quickly before the air inside has been removed. In these situations, a slightly lower heat setting can be used to allow the water to boil slower in order to vent the air.
Food containers.
Small containers such as plastic pudding containers, can be used in a pressure cooker, provided that the containers (and any covering used) can withstand temperatures of and are not placed directly on the interior base. The containers can be used for cooking foods that are prone to burning on the base of the pressure cooker. A lid for the container may be used, provided that the lid allows some steam to come into contact with the food and the lid is securely fitted; an example is foil or greaseproof paper, pleated in the center and tied securely with string. Containers that are cracked or have otherwise sustained damage are not suitable. Cooking time is longer when using covered containers because the food is not in direct contact with the steam. Since non-metal containers are poorer heat conductors, the type of container material stated in the recipe cannot be substituted without affecting the outcome. For example, if the recipe time is calculated using a stainless steel container and a plastic container is used instead, the recipe will be undercooked, unless the cooking time is increased. Containers with thicker sides, e.g., oven-proof glass or ceramic containers, which are slower to conduct heat, will add about 10 minutes to the cooking time. Liquid can be added inside the container when pressure cooking foods such as rice, which need to absorb liquid in order to cook properly.
Pre-frying ingredients.
The flavor of some foods, such as meat and onions, can be improved by gently cooking with a little pre-heated cooking oil, butter or other fat in the open pressure cooker over medium heat (unless the manufacturer advises against this) before pressure cooking. It is important both not to overheat the empty pressure cooker and never to heat the empty cooker with the lid and gasket in place. Overheating can cause warping and other damage. The pressure cooker needs to cool briefly before adding liquid; otherwise some of the liquid will evaporate instantly, possibly leaving insufficient liquid for the entire pressure cooking time; if deglazing the pan, this has to be taken into account.
Pressure release methods.
After cooking, there are three ways of releasing the pressure, either quickly or slowly, before the lid can be opened. Recipes for pressure cookers state which release method is required at the end of the cooking time for proper results. Failure to follow the recommendation may result in food that is under-cooked or over-cooked. Only one of these release methods is used after timing, as recommended in the recipe.
To avoid opening the pressure cooker too often while cooking different vegetables with varying cooking times, the vegetables that take longer to cook can be cut into smaller pieces and vegetables that cook faster can be cut into thicker pieces.
Manual, normal, regular, or automatic release.
This method is sometimes called a "quick release," not to be confused with the cold water release (mentioned below). It involves the quick release of vapor by gradually lifting (or removing) the valve, pushing a button, or turning a dial. It is most suitable to interrupt cooking to add food that cooks faster than what is already in the cooker. For example, since meat takes longer to cook than vegetables, it is necessary to add vegetables to stew later so that it will cook only for the last few minutes. Unlike the cold water release method, this release method does not cool down the pressure cooker. The user must release the steam with caution to avoid being scalded. This release method is not suitable for foods that foam and froth while cooking; the hot contents might spray outwards due to the pressure released from the steam vent. This release method takes about two minutes to release the pressure before the lid can be opened.
Natural release.
The natural release method allows the pressure to drop slowly; this is achieved by removing the pressure cooker from the heat source and allowing the pressure to lower without action. It takes approximately 10 to 15 minutes (possibly longer) for the pressure to disappear before the lid can be opened. On many pressure cookers, a coloured indicator pin will drop when the pressure has gone. This natural release method is recommended for foods that foam and froth during cooking, such as rice, legumes, or recipes with raising agents such as steamed puddings. The texture and tenderness of meat cooked in a pressure cooker can be improved by using the natural release method. The natural release method finishes cooking foods or recipes that have longer cooking times because the inside of the pressure cooker stays hot. This method is not recommended for foods that require very short cooking times, otherwise the food overcooks.
Cold water quick release.
This method is the fastest way of releasing pressure with portable pressure cookers, but can be dangerous if performed incorrectly. It is therefore safer to release pressure by following the other methods. It is recommended to read the manufacturer's instruction book, as some may advise against the cold water release or require it to be performed differently.
The cold water release method involves using slow running cold tap water, over the edge of the pressure cooker lid, being careful to avoid the steam vent or any other valves or outlets and never immersing the pressure cooker under water, otherwise steam can be ejected from under the lid, which could cause scalding injury to the user; also the pressure cooker lid can be permanently damaged by an internal vacuum if water gets sucked into the pressure cooker, since the incoming water blocks the inrush of air. 
The cold water release is most suitable for foods with short cooking times. It takes about 20 seconds for the cooker to cool down enough to lower the pressure so that it can be safely opened. This method is not suitable for electric pressure cookers, as they are not "immersible."
The cold water release method is not recommended when cooking pulses eg red kidney beans, as the sudden release of pressure can cause the bean to burst its skin.
Advantages.
Foods cook much faster with pressure cooking than with other methods (except for small quantities in microwave ovens). Pressure cooking requires much less water than conventional boiling, so food can be ready sooner. Less energy is required than that of boiling, steaming, or oven cooking. Since less water or liquid has to be heated, the food reaches its cooking temperature faster. Using more liquid than necessary wastes energy because it takes longer to heat up; the liquid quantity is stated in the recipe. Pressure cookers can use much less liquid than the amount required for boiling or steaming in an ordinary saucepan. It is not necessary to immerse food in water. The minimum quantity of water or liquid used in the recipe to keep the pressure cooker filled with steam is sufficient. Because of this, vitamins and minerals are not leached (dissolved) away by water, as they would be if food were boiled in large amounts of water. Due to the shorter cooking time, vitamins are preserved relatively well during pressure cooking.
Several foods can be cooked together in the pressure cooker, either for the same amount of time or added later for different times. Manufacturers provide steamer baskets to allow more foods to be cooked together inside the pressure cooker.
Food is cooked at a temperature above the normal boiling point of water, killing most micro-organisms. A pressure cooker can be used as an effective sterilizer for jam pots, glass baby bottles, or for water while camping.
The pressure cooker speeds cooking considerably at high altitudes, where the lower atmospheric pressure reduces the boiling point of water. Lower water temperature reduces water's effectiveness for cooking or preparing hot drinks. The increased temperatures due to pressure cooking are also used to promote the Maillard reaction to develop more desirable flavor profiles that would not be obtainable using temperatures typical of boiling. The flavours are more concentrated in the higher temperature and sealed environment of the pressure cooker, so less seasoning is required.
Disadvantages.
Pressure cookers are considerably more expensive than conventional saucepans of the same size. The additional gasket (sealing ring) requires special care when cleaning (e.g., not washed with kitchen knives), unlike a standard lid for a saucepan. Food debris must be cleaned from the gasket after every use. The gasket/sealing ring needs replacing with a new one about once a year (or sooner if it is damaged e.g. a small split). A very dry gasket can make it difficult or impossible to close the lid, however smearing the gasket sparingly with vegetable oil alleviates this problem (using too much vegetable oil can make the gasket swell and prevent it sealing properly). A gasket which has lost its flexibility makes bringing the cooker up to pressure difficult as steam can escape before sufficient pressure is generated to provide an adequate seal; this is usually a sign that the gasket needs replacing with a new one. Oiling the gasket with vegetable oil may alleviate the problem temporarily, but a new gasket is often required. Pressure cooker manufacturers sell replacement gaskets and recommend their replacement at regular intervals e.g. annually. If the pressure cooker has not been used for a long time, the gasket and other rubber or silicone parts will dry out and will likely need replacing.
In order to inspect the food, the pressure cooker needs to be opened, which halts the cooking process. With a conventional saucepan, this can be done in a matter of seconds by visually inspecting the food. As a result, accurate timing is essential for the recipe e.g. with an audible timer.
The increased weight of conventional pressure cookers makes them unsuitable for applications in which saving weight is a priority, such as camping. However, small, lightweight pressure cookers are available for mountain climbers "(see Use at high altitudes)".
A minimum quantity of liquid is required to create and maintain pressure, as indicated in the manufacturer's instruction manual. More liquid is required for longer cooking times. This is not desirable for food requiring much less liquid, but recipes and books for pressure cookers take this into account.
Safety features.
Early pressure cookers equipped with only a primary safety valve risked explosion from food blocking the release valve. On modern pressure cookers, food residues blocking the steam vent or the liquid boiling dry will trigger additional safety devices. Modern pressure cookers sold from reputable manufacturers have sufficient safety features to prevent the pressure cooker itself from exploding. When excess pressure is released by a safety mechanism, debris of food being cooked may also be ejected with the steam — which is loud and forceful. This can be avoided if the pressure cooker is regularly cleaned and maintained in accordance with the manufacturer's instructions and never overfilled with food and/or liquid: a pressure cooker should never be filled more two-thirds full with solid food, half full for liquids and foods that foam and froth (e.g., rice, pasta), and no more than one-third full for pulses (e.g., lentils). Adding a tablespoon of cooking oil minimises foaming.
Modern pressure cookers typically have two or three redundant safety valves and additional safety features, such as an interlock lid that prevents the user from opening the lid when the internal pressure exceeds atmospheric pressure, preventing accidents from a sudden release of hot liquid, steam and food. If safety mechanisms are not correctly in place, the cooker will not pressurize the contents. Pressure cookers should be operated only after reading the instruction manual, to ensure correct usage. Pressure cooker failure is dangerous: a large quantity of scalding steam and water will be forcefully ejected and if the lid separates it may be propelled with considerable force. Some cookers with an internally fitted lid may be particularly dangerous upon failure as the lid fits tighter with increasing pressure, preventing the lid from deforming and venting around the edges. Due to these dangers pressure cookers are generally over-engineered in a safety regard and some countries even have regulations to prevent the sale of non-compliant cookers.
For first generation pressure cookers with a weighted valve or "jiggler", the primary safety valve or regulator is usually a weighted stopper, commonly called "the rocker" or "vent weight". This weighted stopper is lifted by the steam pressure, allowing excess pressure to be released. There is a backup pressure release mechanism that releases pressure quickly if the primary pressure release mechanism fails (e.g., food jams the steam discharge path). One such method is a hole in the lid that is blocked by a low melting point alloy plug and another is a rubber grommet with a metal insert at the center. At a sufficiently high pressure, the grommet will distort and the insert will blow out of its mounting hole to release pressure. If the pressure continues to increase, the grommet itself will blow out to release pressure. These safety devices usually require replacement when activated by excess pressure. Newer pressure cookers may have a self-resettable spring device, fixed onto the lid, that releases excess pressure.
On second generation pressure cookers, a common safety feature is the gasket, which expands to release excess pressure downward between the lid and the pot. This release of excess pressure is forceful and sufficient to extinguish the flame of a gas stove.
Pressure cookers sold in the European Union (EU) must comply with the Pressure Equipment Directive.
Use at high altitudes.
A pressure cooker can be used to compensate for lower atmospheric pressure at high elevations. The boiling point of water drops by approximately 1 °C per every 294 metres of altitude (1 °F per every of altitude), causing the boiling point of water to be significantly below the at standard pressure. Without the use of a pressure cooker, boiled foods may be undercooked, as described in Charles Darwin's "The Voyage of the Beagle" (chapter XV, March 20, 1835):
At higher altitudes, the boiling point of liquid in the pressure cooker will be slightly lower than it would be at sea level. When pressure cooking at high altitudes, cooking times need to be increased by approximately 5% for every above elevation. The absolute pressure in a pressure cooker will always be lower at higher altitudes, since the differential pressure remains the same (if one were to travel high enough the pressure within the cooker would drop below sea-level pressure). Since weight is one of the major concerns, mountaineering pressure cookers may be designed to operate at a much lower differential pressure than regular units so that thinner, lighter construction can be used. Generally, the objective is raising the cooking temperature to make cooking possible where it would otherwise be completely impractical and to conserve fuel by reducing heat lost through boiling.
Lightweight pressure cookers as small as weighing are available for mountain climbers. Sherpas often use pressure cookers in base camp.
Science of pressure cooking.
In an ordinary, non-pressurized, cooking vessel, the boiling point of water is at standard pressure; the temperature of food is limited by the boiling point of water because excess heat causes boiling water to vaporize into steam. In a sealed pressure cooker, the boiling point of water increases as the pressure rises, resulting in superheated water. At a pressure of 1 bar or ~15 psi (pounds per square inch) above the existing atmospheric pressure, water in a pressure cooker can reach a temperature of up to , depending on altitude. The boiling temperature of water (and water-based liquids) is determined by the ambient atmospheric pressure. Pressure cookers always require liquid in order to cook food under pressure. At sea level, the boiling temperature of water is and excess heat only increases the rate at which water evaporates into steam vapour; more heat does not increase the temperature of the water. At higher altitudes above sea level, the atmospheric pressure is lower and thus the boiling temperature of water is lower, because the lower atmospheric pressure pushing on the water makes it easier for the water molecules to escape the surface compared to higher atmospheric pressure. Inside a pressure cooker, once the water (liquid) is boiling and the steam is trapped, the pressure from the trapped steam increases and this pushes on the liquid, which increases its boiling temperature, because it becomes harder for the water molecules to escape from the surface as the pressure increases on it. The heat applied to the liquid by the heat source continues to create more steam pressure and the extra heat also raises the temperature of the liquid under this increased pressure. Both the liquid and steam are at the same temperature. Once the selected pressure level is reached, the pressure regulator on the lid indicates this and now the heat source can be lowered to maintain that pressure level and save energy, since extra heat will not increase the temperature of the liquid if the pressure is not allowed to rise — excess pressure will only escape as fast-flowing steam from the lid.
As a general rule, increasing the temperature of many everyday chemical reactions by 10 deg. C doubles the rate of reaction, halving the time for completion. Thus a pressure cooker that can attain temperatures around can complete cooking in a quarter of the time that it would take using ordinary boiling. 
In addition, because of a much higher heat capacity, steam and liquids transfer heat more rapidly than dry air. As an example, the hot "air" inside an oven at, say , will not immediately burn your skin, but the wet steam from a boiling kettle at will scald skin almost instantly and 'feel' hotter, despite the steam (and water) in the kettle being at a lower temperature than the air inside a hot oven. Thus the internal temperature of material in a pressure cooker will rise to the desired value much more quickly than if it were in a hot oven.
However, some reactions such as the Maillard reaction that produces "browning" and associated flavors during roasting or frying, require temperatures higher than are found in a pressure cooker. Pre-frying ingredients e.g. meat in the open pressure cooker can achieve the Maillard reaction.
Use in food detoxification.
Some food toxins can be reduced by pressure cooking. A Korean study of aflatoxins in rice (associated with "Aspergillus" fungus) showed that pressure cooking was capable of reducing aflatoxin concentrations to 12–22% of the amount in the uncooked rice. Pressure cookers are "not" guaranteed to destroy all harmful microorganisms in food, especially when used for short periods of time.
Foods unsuitable for pressure cooking.
Some foods are not recommended for pressure cooking. Foods such as macaroni, cranberries, cereals and oatmeal could expand too much, froth, and sputter, which can block the steam vent.
Use as an autoclave.
Pressure cookers have been used effectively as makeshift medical autoclaves in rural countries where there is no electrical infrastructure and where the cost of such a piece of equipment would otherwise be prohibitive. Although working on the same principle there are several operational differences such as professional autoclaves having purging ability to remove air before sterilization and having programmable control over the sterilization cycle. Education on usage is very important as the sterilization cycle is often much longer due to the presence of air in the cooker and most pressure cookers require modification to reach sufficient sterilization temperature which although within the capabilities of most pressure cookers, is still risky. Autoclaves are very important in poor countries since they rely on re-usable medical equipment and many places re-use hypodermic needles.
Use in terrorism.
The appliance has been adapted as a crude type of bomb, which has been used in terrorist attacks.

</doc>
<doc id="52993" url="https://en.wikipedia.org/wiki?curid=52993" title="Roasting">
Roasting

Roasting is a cooking method that uses dry heat where hot air envelops the food, cooking it evenly on all sides with temperatures of at least 150 °C (~300 °F) from an open flame, oven, or other heat source. Roasting can enhance flavor through caramelization and Maillard browning on the surface of the food. Roasting uses indirect, diffused heat (as in an oven), and is suitable for slower cooking of meat in a larger, whole piece. Meats and most root and bulb vegetables can be roasted. Any piece of meat, especially red meat, that has been cooked in this fashion is called a roast. A roast joint of meat can take one, two, even three hours to cook—the resulting meat is tender. Also, meats and vegetables prepared in this way are described as "roasted", e.g., roasted chicken or roasted squash.
Methods.
For roasting, the food may be placed on a rack, in a roasting pan or, to ensure even application of heat, may be rotated on a spit or rotisserie. If a pan is used, the juice can be retained for use in gravy, Yorkshire pudding, etc. During oven roasting, hot air circulates around the meat, cooking all sides evenly. There are several plans for roasting meat: low-temperature cooking, high-temperature cooking, and a combination of both. Each method can be suitable, depending on the food and the tastes of the people.
In general, in either case, the meat is removed from heat before it has finished cooking and left to sit for a few minutes, while the inside cooks further from the residual heat content, known as carry over cooking.
The objective in any case is to retain as much moisture as possible, while providing the texture and color. As meat cooks, the structure and especially the collagen breaks down, allowing juice to come out of the meat. So meat is juiciest at about medium rare while the juice is coming out. During roasting, meats and vegetables are frequently basted on the surface with butter, lard, or oil to reduce the loss of moisture by evaporation. In recent times, plastic oven bags have become popular for roasts. These cut cooking times and reduce the loss of moisture during roasting, but reduce flavor development from Maillard browning, somewhat more like (boiled or steamed) stew or pot roast. They are particularly popular for turkeys.
Until the late 19th century, roasting by dry heat in an oven was called "baking". Roasting originally meant turning meat or a bird on a spit in front of a fire. It is one of the oldest forms of cooking known.
Traditionally recognized roasting methods consist only of baking and cooking over or near an open fire. Grilling is normally not technically a roast, since a grill (gridiron) is used. Barbecuing and Smoking differ from roasting because of the lower temperature and controlled smoke application. Grilling can be considered as a low-fat food preparation, as it allows any fat in the food to drip away.
Meat.
Before the invention and widespread use of stoves, food was primarily cooked over open flames from a hearth. To roast meat racks with skewers, or, if accessible, complicated gear arrangements, would be utilized to turn the piece(s). In the past, this method was often associated with the upper class and special occasions rather than customary meal times because it required freshly killed meat and close attention during cooking. It was easy to ruin the meat’s taste with a smoky fire or negligence to rotate it at regular intervals. Thus, elite families who were able to afford quality meat, appointed this task to servants or invested in technology like automatic turning devices. With further technological advances, cooking came to accommodate new opportunities. By the 1860s, working families were able to afford low-priced stove models that became sufficiently available. However, the key element of observation during roasting became difficult and dangerous to do with the coal oven. Hence, traditional roasting disappeared as kitchens became no longer equipped for this custom and soon thereafter, “baking” came to be called “roasting”.
Roasting can be applied to a wide variety of meat. In general, it works best for cooking whole chickens, turkey, and leaner cuts of lamb, pork, and beef. The aim is to highlight the flavor of the meat itself rather than a sauce or stew, as it is done in braising or other moist-heat methods. Many roasts are tied with string prior to roasting, often using the reef knot or the packer's knot. Tying holds them together during roasting, keeping any stuffing inside, and keeps the roast in a round profile, which promotes even cooking.
Red meats such as beef, lamb, and venison, and certain game birds are often roasted to be "pink" or "rare", meaning that the center of the roast is still red. Roasting is a preferred method of cooking for most poultry, and certain cuts of beef, pork, or lamb. Although there is a growing fashion in some restaurants to serve "rose pork", temperature monitoring of the center of the roast is the only sure way to avoid foodborne disease.
In Britain, Ireland, and Australia a roast of meat may be referred to as a "joint", or a leg, if it is a leg.
Vegetables.
Some vegetables, such as potatoes, zucchini, pumpkin, turnips, parsnips, cauliflower, asparagus, squash, and peppers lend themselves to roasting as well. Roasted chestnuts are also a popular snack in winter.
Fish.
It is also possible to roast fish as meat.

</doc>
<doc id="52994" url="https://en.wikipedia.org/wiki?curid=52994" title="Barr body">
Barr body

[[Image:Sd4hi-unten-crop.jpg|thumb|Nucleus of a female amniotic fluid cell. Top: Both X-chromosome territories are detected by FISH. Shown is a single optical section made with a confocal microscope. Bottom: Same nucleus stained with DAPI and recorded with a CCD camera. The Barr body is indicated by the arrow, it identifies the inactive X (Xi).
[[Image:BarrBodyBMC Biology2-21-Fig1clip293px.jpg|thumb|Left: DAPI stained female human fibroblast with Barr body (arrow). Right: histone macroH2A1 staining. Arrow points to sex chromatin in DAPI-stained cell nucleus, and to the corresponding sex chromatin site in the histone macroH2A1-staining.
A Barr body (named after discoverer Murray Barr) is the inactive X chromosome in a female somatic cell, rendered inactive in a process called lyonization, in those species in which sex is determined by the presence of the Y (including humans) or W chromosome rather than the diploidy of the X. The Lyon hypothesis states that in cells with multiple X chromosomes, all but one are inactivated during mammalian embryogenesis. This happens early in embryonic development at random in mammals, except in marsupials and in some extra-embryonic tissues of some placental mammals, in which the father's X chromosome is always deactivated.
In humans with more than one X chromosome, the number of Barr bodies visible at interphase is always one fewer than the total number of X chromosomes. For example, men with Klinefelter syndrome (47,XXY karyotype) have a single Barr body, whereas women with a 47,XXX karyotype have two Barr bodies. Barr bodies can be seen on the nucleus of neutrophils.
Mechanism.
A typical human female has only one Barr body per somatic cell, while a typical human male has none.
Mammalian X-chromosome inactivation is initiated from the X inactivation centre or "Xic", usually found near the centromere. The center contains twelve genes, seven of which code for proteins, five for untranslated RNAs, of which only two are known to play an active role in the X inactivation process, "Xist" and "Tsix". The centre also appears to be important in chromosome counting: ensuring that random inactivation only takes place when two or more X-chromosomes are present. The provision of an extra artificial "Xic" in early embryogenesis can induce inactivation of the single X found in male cells.
The roles of "Xist" and "Tsix" appear to be antagonistic. The loss of "Tsix" expression on the future inactive X chromosome results in an increase in levels of "Xist" around the "Xic". Meanwhile, on the future active X "Tsix" levels are maintained; thus the levels of "Xist" remain low. This shift allows "Xist" to begin coating the future inactive chromosome, spreading out from the "Xic". In non-random inactivation this choice appears to be fixed and current evidence suggests that the maternally inherited gene may be imprinted.
It is thought that this constitutes the mechanism of choice, and allows downstream processes to establish the compact state of the Barr body. These changes include histone modifications, such as histone H3 methylation(i.e. H3K27me3 by PRC2 which is recruited by Xist) and histone H2A ubiquitination, as well as direct modification of the DNA itself, via the methylation of CpG sites. These changes help inactivate gene expression on the inactive X-chromosome and to bring about its compaction to form the Barr body.
References.
Links to full text articles are provided where access is free, in other cases only the abstract has been linked.

</doc>
<doc id="52995" url="https://en.wikipedia.org/wiki?curid=52995" title="Smoking (cooking)">
Smoking (cooking)

Smoking is the process of flavoring, cooking, or preserving food by exposing it to smoke from burning or smoldering material, most often wood. Meats and fish are the most common smoked foods, though cheeses, vegetables, and ingredients used to make beverages such as beer, smoked beer, and "lapsang souchong" tea are also smoked.
In Europe, alder is the traditional smoking wood, but oak is more often used now, and beech to a lesser extent. In North America, hickory, mesquite, oak, pecan, alder, maple, and fruit-tree woods, such as apple, cherry, and plum, are commonly used for smoking. Other fuels besides wood can also be employed, sometimes with the addition of flavoring ingredients. Chinese tea-smoking uses a mixture of uncooked rice, sugar, and tea, heated at the base of a wok. Some North American ham and bacon makers smoke their products over burning corncobs. Peat is burned to dry and smoke the barley malt used to make whisky and some beers. In New Zealand, sawdust from the native manuka (tea tree) is commonly used for hot smoking fish. In Iceland, dried sheep dung is used to cold-smoke fish, lamb, mutton, and whale.
Historically, farms in the Western world included a small building termed the "smokehouse", where meats could be smoked and stored. This was generally well-separated from other buildings both because of the fire danger and because of the smoke emanations.
Smoking of food is known to contaminate the food with carcinogenic polycyclic aromatic hydrocarbons.
History.
The smoking of food dates back to the time of primitive cavemen. As caves or simple huts lacked chimneys, these dwellings could become very smoky. The early men would often hang meat up to dry, and they soon became aware that meat that was stored in smoky areas acquired a different flavor and was better preserved than meat that simply dried out. Over time this process was combined with pre-curing the food in salt or salty brines, resulting in a remarkably effective preservation process that was adapted and developed by numerous cultures around the world. Until the modern era, smoking was of a more "heavy duty" nature as the main goal was to preserve the food. Large quantities of salt were used in the curing process and smoking times were quite long, sometimes involving days of exposure.
The advent of modern transportation made it easier to transport food products over long distances and the need for the time and material intensive heavy salting and smoking declined. Smoking became more of a way to flavor than to preserve food. In 1939 a device called the "Torry Kiln" was invented at the Torry Research Station in Scotland. The kiln allowed for uniform mass-smoking and is considered the prototype for all modern large-scale commercial smokers. Although refinements in technique and advancements in technology have made smoking much easier, the basic steps involved remain essentially the same today as they were hundreds if not thousands of years ago.
Wood smoke.
Hardwoods are made up mostly of three materials: cellulose, hemicellulose, and lignin. Cellulose and hemicellulose are the basic structural material of the wood cells; lignin acts as a kind of cell-bonding glue. Some softwoods, especially pines and firs, hold significant quantities of resin, which produces a harsh-tasting soot when burned; these woods are not often used for smoking.
Cellulose and hemicellulose are aggregate sugar molecules; when burnt, they effectively caramelize, producing carbonyls, which provide most of the color components and sweet, flowery, and fruity aromas. Lignin, a highly complex arrangement of interlocked phenolic molecules, also produces a number of distinctive aromatic elements when burnt, including smoky, spicy, and pungent compounds such as guaiacol, phenol, and syringol, and sweeter scents such as the vanilla-scented vanillin and clove-like isoeugenol. Guaiacol is the phenolic compound most responsible for the "smokey" taste, while syringol is the primary contributor to smokey aroma. Wood also contains small quantities of proteins, which contribute roasted flavors. Many of the odor compounds in wood smoke, especially the phenolic compounds, are unstable, dissipating after a few weeks or months.
A number of wood smoke compounds act as preservatives. Phenol and other phenolic compounds in wood smoke are both antioxidants, which slow rancidification of animal fats, and antimicrobials, which slow bacterial growth. Other antimicrobials in wood smoke include formaldehyde, acetic acid, and other organic acids, which give wood smoke a low pH—about 2.5. Some of these compounds are toxic to people as well, and may have health effects in the quantities found in cooking applications.
Since different species of trees have different ratios of components, various types of wood do impart a different flavor to food. Another important factor is the temperature at which the wood burns. High-temperature fires see the flavor molecules broken down further into unpleasant or flavorless compounds. The optimal conditions for smoke flavor are low, smoldering temperatures between . This is the temperature of the burning wood itself, not of the smoking environment, which uses much lower temperatures. Woods that are high in lignin content tend to burn hot; to keep them smoldering requires restricted oxygen supplies or a high moisture content. When smoking using wood chips or chunks, the combustion temperature is often raised by soaking the pieces in water before placing them on a fire.
Types of smokers.
There are a few basic types of smoker designs, each with their own advantages and disadvantages.
Offset smokers.
The main characteristics of the offset smoker are that the cooking chamber is usually cylindrical in shape, with a shorter, smaller diameter cylinder attached to the bottom of one end for a firebox. To cook the meat, a small fire is lit in the firebox, where airflow is tightly controlled. The heat and smoke from the fire is drawn through a connecting pipe or opening into the cooking chamber. The heat and smoke cook and flavor the meat before escaping through an exhaust vent at the opposite end of the cooking chamber. Most manufacturers' models are based on this simple but effective design, and this is what most people picture when they think of a "BBQ smoker." Even large capacity commercial units use this same basic design of a separate, smaller fire box and a larger cooking chamber.
Upright drum smoker.
The upright drum smoker (also referred to as an ugly drum smoker or UDS) is exactly what its name suggests; an upright steel drum that has been modified for the purpose of pseudo-indirect hot smoking. There are many ways to accomplish this, but the basics include the use of a complete steel drum, a basket to hold charcoal near the bottom, and cooking rack (or racks) near the top; all covered by a vented lid of some sort. They have been built using many different sizes of steel drums (, , and for example), but the most popular size is the common 55 gallon drum.
This design is similar to smoking with indirect heat due to the distance from the coals and the racks (typically ). The temperatures used for smoking are controlled by limiting the amount of air intake at the bottom of the drum, and allowing a similar amount of exhaust out of vents in the lid. UDSs are very efficient with fuel consumption and flexible in their abilities to produce proper smoking conditions, with or without the use of a water pan or drip pan. Most UDS builders/users would say a water pan defeats the true pit BBQ nature of the UDS, as the drippings from the smoked meat should land on the coals, burning up, and imparting a unique flavor one cannot get with a water pan.
Vertical water smoker.
A vertical water smoker (also referred to as a bullet smoker because of its shape) is a variation of the upright drum smoker. It uses charcoal or wood to generate smoke and heat, and contains a water bowl between the fire and the cooking grates. The water bowl serves to maintain optimal smoking temperatures and also adds humidity to the smoke chamber. It also creates an effect in which the water vapor and smoke condense together, which adds flavor to smoked foods. In addition, the bowl catches any drippings from the meat that may cause a flare-up. Vertical water smokers are extremely temperature stable and require very little adjustment once the desired temperature has been reached. Because of their relatively low cost and stable temperature, they are sometimes used in barbecue competitions where propane and electric smokers are not allowed.
Propane smoker.
A propane smoker is designed to allow the smoking of meat in a somewhat more controlled environment. The primary differences are the sources of heat and of the smoke. In a propane smoker, the heat is generated by a gas burner directly under a steel or iron box containing the wood or charcoal that provides the smoke. The steel box has few vent holes, on the top of the box only. By starving the heated wood of oxygen, it smokes instead of burning. Any combination of woods and charcoal may used. This method uses less wood.
Smoke box method.
This more traditional method uses a two-box system: a fire box and a food box. The fire box is typically adjacent or under the cooking box, and can be controlled to a finer degree. The heat and smoke from the fire box exhausts into the food box, where it is used to cook and smoke the meat. These may be as simple as an electric heating element with a pan of wood chips placed on it, although more advanced models have finer temperature controls.
Commercial smoke house.
Commercial smokehouses, mostly made from stainless steel, have independent systems for smoke generation and cooking. Smoke generators use friction, an electric coil or a small flame to ignite sawdust on demand. Heat from steam coils or gas flames is balanced with live steam or water sprays to control the temperature and humidity. Elaborate air handling systems reduce hot or cold spots, to reduce variation in the finished product. Racks on wheels or rails are used to hold the product and facilitate movement.
Preservation.
Smoke is an antimicrobial and antioxidant, but smoke alone is insufficient for preserving food in practice, unless combined with another preservation method. The main problem is the smoke compounds adhere only to the outer surfaces of the food; smoke does not actually penetrate far into meat or fish. In modern times, almost all smoking is carried out for its flavor. Artificial smoke flavoring can be purchased as a liquid to mimic the flavor of smoking, but not its preservative qualities (see also liquid smoke).
In the past, smoking was a useful preservation tool, in combination with other techniques, most commonly salt-curing or drying. In some cases, particularly in climates without much hot sunshine, smoking was simply an unavoidable side effect of drying over a fire. For some long-smoked foods, the smoking time also served to dry the food. Drying, curing, or other techniques can render the interior of foods inhospitable to bacterial life, while the smoking gives the vulnerable exterior surfaces an extra layer of protection. For oily fish smoking is especially useful, as its antioxidant properties delay surface fat rancidification. (Interior fat is not as exposed to oxygen, which is what causes rancidity.) Some heavily-salted, long-smoked fish can keep without refrigeration for weeks or months. Such heavily-preserved foods usually require a treatment such as boiling in fresh water to make them palatable before eating.
Some smoked foods.
Many foods can be smoked. Some of the more common are listed here.

</doc>
<doc id="52996" url="https://en.wikipedia.org/wiki?curid=52996" title="Steaming">
Steaming

Steaming is a method of cooking using steam. This is often done with a food steamer, a kitchen appliance made specifically to cook food with steam, but food can also be steamed in a wok. In the American southwest, steam pits used for cooking have been found dating back about 10,000 years. Steaming is considered a healthy cooking technique that can be used for many kinds of food.
Method.
Steaming works by boiling water continuously, causing it to vaporize into steam; the steam then carries heat to the nearby food, thus cooking the food. The food is kept separate from the boiling water but has direct contact with the steam, resulting in a moist texture to the food. This differs from double boiling, in which food is not directly exposed to steam, or pressure cooking, which uses a sealed vessel.
Such cooking is most often done by placing the food into a food steamer, typically a circular container made of metal or bamboo. The steamer usually has a lid that is placed on the top of the container during cooking to allow the steam to cook through the food. When a steamer is unavailable, food can be steamed inside a wok, supported over boiling water in the bottom of the wok by a stainless steel frame. Some modern home microwave ovens include a structure to cook food by steam vapor produced in a separate water container, providing a similar result to being cooked by fire. There are also specialized steam ovens available.
Steamed foods.
Some of the earliest examples of steam cooking have been found in Cochise County, Arizona, where steam pits were used for cooking about 10,000 years ago. In China's Yellow River Valley, early steam cookers made of stoneware have been found dating back as far as 5000 BCE. From the eighth century CE, thin cypress strips were used to make steamers; today they are constructed from bamboo with slatted bases. The classic steamer has a chimney in the center, which distributes the steam among the tiers.
In Western cooking, steaming is most often used to cook vegetablesit is rarely used to cook meats. However, steamed clams are prepared by steaming. With Chinese cuisine, vegetables are usually stir fried or blanched and seldom steamed. Seafood and meat dishes are steamed. For example: steamed whole fish, steamed crab, steamed pork spare ribs, steamed ground pork or beef, steamed chicken and steamed goose. Rice can be steamed too, although in Chinese cooking this is simply referred to as "cooking" rather than "steaming". Wheat foods are steamed as well. Examples include buns and Chinese steamed cakes.
Steamed meat dishes (except fish and some dim sum) are less common in Chinese restaurants than in traditional home cooking, because meats usually require longer cooking times to steam than to stir fry. Commercially sold frozen foods (such as dim sum) formerly had instructions to reheat by steaming, until the rise in popularity of home microwave ovens, which have considerably shorter cooking times.
Benefits.
Overcooking or burning food is easily avoided when steaming it. Individuals preferring to avoid additional fat intake may prefer steaming to methods which require cooking oil. Steaming also results in a more nutritious food than boiling, because fewer nutrients are leached away into the water, which is usually discarded.
A 2007 USDA comparison between steaming and boiling vegetables shows the most affected nutrients are folic acid and vitamin C. When compared to raw consumption, steaming reduces folic acid by 15%, and boiling reduces it by 35%. Steaming reduces vitamin C by 15%, and boiling reduces it by 25%.
Steaming, compared to boiling, showed 42% higher amount of glucosinolates in broccoli cooked for medium firmness. Phenolic compounds with antioxidant properties have been found to retain significantly better through steaming than through boiling or microwaving. Steaming compared to boiling retained β-carotene in carrots. The effect of cooking food may increase or decrease the nutrients.

</doc>
<doc id="52997" url="https://en.wikipedia.org/wiki?curid=52997" title="Double steaming">
Double steaming

Double steaming, sometimes called "double boiling", is a Chinese cooking technique to prepare delicate food such as bird's nest soup and shark fin soup. The food is covered with water and put in a covered ceramic jar and the jar is then steamed for several hours. This technique ensures there is no loss of liquid or moisture (its essences) from the food being cooked, hence it is often used with expensive ingredients like Chinese herbal medicines.
In Cantonese, double steaming is called "dun" (). The meaning of the Chinese character for "dun" in Cantonese is different from that in Mandarin, because "dun" means to simmer or stew in Mandarin. This technique is also common in Fujian, a neighbouring province of Guangdong (Canton).
Famous examples.
Cantonese cuisine is famous for its slow-cooked soup. One famous dish of this kind is called the "winter melon urn" (冬瓜盅). It is prepared by emptying the inside of a winter melon to make an urn. The outside of the winter melon is often carved with artistic patterns. The inside is then filled with soup ingredients, such as Chinese cured ham and Chinese herbs. The whole urn, complete with its original melon lid, is double-steamed for at least four hours. The flavour of the soup is soaked into the flesh of the melon. The whole melon and its contents are brought to the dinner table. The soup is served by scooping out the liquid and the inside wall of the melon. In this case, the edible melon takes the place of the double steaming jar. This application is possible because winter melon has a waxy, and thus waterproof, rind. Winter melon is believed to be nourishing and it is seldom cooked with ingredients that are believed to be too "yin" or too "yang". 
A dessert dish called "double-steamed frog ovaries in a coconut" (椰青燉雪蛤膏) is traditionally prepared for women. Chinese medicinal ingredients (including "hasma"), spices, and rock sugar, are placed inside a young coconut to soak in the original coconut juice. The filled coconut is then double-steamed for several hours. The whole coconut is served whole at the table after dinner. The contents and the inside wall of the coconut are scooped out to be consumed.

</doc>
<doc id="52999" url="https://en.wikipedia.org/wiki?curid=52999" title="Phobos (moon)">
Phobos (moon)

Phobos (systematic designation: ) is the larger and innermost of the two natural satellites of Mars, the other being Deimos. Both moons were discovered in 1877 by American astronomer Asaph Hall.
Phobos is a small, irregularly shaped object with a mean radius of , and is seven times more massive than Deimos, Mars's outer moon. Phobos is named after the Greek god Phobos, a son of Ares (Mars) and Aphrodite (Venus) which was the personification of Horror. The name "Phobos" is pronounced or , or like the Greek .
Phobos orbits from the Martian surface, closer to its primary than any other known planetary moon. It is so close that it orbits Mars faster than Mars rotates, and completes an orbit in just 7 hours and 39 minutes. As a result, from the surface of Mars it appears to rise in the west, move across the sky in 4 hours 15 min or less, and set in the east, twice each Martian day. Phobos is one of the least reflective bodies in the Solar System, and features a large impact crater, Stickney. The temperatures range from about on the sunlit side to on the shadowed side.
Images and models indicate that Phobos may be a rubble pile held together by a thin crust, and that it is being torn apart by tidal interactions. Phobos gets 2 meters closer to Mars every one hundred years, and it is predicted that in 30 to 50 million years it will collide with the planet or break up into a planetary ring.
Discovery.
Phobos was discovered by astronomer Asaph Hall on 18 August 1877, at the United States Naval Observatory in Washington, D.C., at about 09:14 Greenwich Mean Time (contemporary sources, using the pre-1925 astronomical convention that began the day at noon, give the time of discovery as 17 August at 16:06 Washington mean time). Hall also discovered Deimos, Mars' other moon, on 12 August 1877 at about 07:48 UTC. The names, originally spelled "Phobus" and "Deimus" respectively, were suggested by Henry Madan (1838–1901), Science Master of Eton, based on Greek mythology, in which Phobos is a companion to the god Ares.
Physical characteristics.
Phobos has dimensions of , and retains too little mass to be rounded under its own gravity. Phobos does not have an atmosphere due to low mass and low gravity. It is one of the least reflective bodies in the Solar System. Spectroscopically it appears to be similar to the D-type asteroids, and is apparently of composition similar to carbonaceous chondrite material. Phobos's density is too low to be solid rock, and it is known to have significant porosity. These results led to the suggestion that Phobos might contain a substantial reservoir of ice. Spectral observations indicate that the surface regolith layer lacks hydration, but ice below the regolith is not ruled out.
Phobos is heavily cratered. The most prominent surface feature is the crater Stickney, named after Asaph Hall's wife, Angeline Stickney Hall, Stickney being her maiden name. As with Mimas's crater Herschel, the impact that created Stickney must have nearly shattered Phobos. Many grooves and streaks also cover the oddly shaped surface. The grooves are typically less than deep, wide, and up to in length, and were originally assumed to have been the result of the same impact that created Stickney. Analysis of results from the "Mars Express" spacecraft, however, revealed that the grooves are not in fact radial to Stickney, but are centered on the leading apex of Phobos in its orbit (which is not far from Stickney). Researchers suspect that they have been excavated by material ejected into space by impacts on the surface of Mars. The grooves thus formed as crater chains, and all of them fade away as the trailing apex of Phobos is approached. They have been grouped into 12 or more families of varying age, presumably representing at least 12 Martian impact events.
Faint dust rings produced by Phobos and Deimos have long been predicted but attempts to observe these rings have, to date, failed. Recent images from "Mars Global Surveyor" indicate that Phobos is covered with a layer of fine-grained regolith at least 100 meters thick; it is hypothesized to have been created by impacts from other bodies, but it is not known how the material stuck to an object with almost no gravity.
The unique Kaidun meteorite that fell on a Soviet military base in Yemen in 1980 has been hypothesized to be a piece of Phobos, but this has been difficult to verify because little is known about the exact composition of Phobos.
A 150-pound (68 kg) person standing on the surface of Phobos would weigh about two ounces (57 g).
Named geological features.
Geological features on Phobos are named after astronomers who studied Phobos and people and places from Jonathan Swift's "Gulliver's Travels". There is one named regio, "Laputa Regio", and one named planitia, "Lagado Planitia"; both are named after places in "Gulliver's Travels" (the fictional Laputa, a flying island, and Lagado, imaginary capital of the fictional nation Balnibarbi). The only named ridge on Phobos is "Kepler Dorsum", named after the astronomer Johannes Kepler. Several craters have been named.
PHOBOS
<br>
<br>
Orbital characteristics.
The orbital motion of Phobos has been intensively studied in terms of orbits completed, making it "the best studied natural satellite in the Solar System". Its close orbit around Mars produces some unusual effects. With an altitude of , Phobos orbits Mars below the synchronous orbit radius, meaning that it moves around Mars faster than Mars itself rotates. Therefore, from the point of view of an observer on the surface of Mars, it rises in the west, moves comparatively rapidly across the sky (in 4 h 15 min or less) and sets in the east, approximately twice each Martian day (every 11 h 6 min). Because it is close to the surface and in an equatorial orbit, it cannot be seen above the horizon from latitudes greater than 70.4°. Its orbit is so low that its angular diameter, as seen by an observer on Mars, varies visibly with its position in the sky. Seen at the horizon, Phobos is about 0.14° wide; at zenith it is 0.20°, one-third as wide as the full Moon as seen from Earth. By comparison, the Sun has an apparent size of about 0.35° in the Martian sky. Phobos's phases, inasmuch as they can be observed from Mars, take 0.3191 days (Phobos's synodic period) to run their course, a mere 13 seconds longer than Phobos's sidereal period.
As seen from Phobos, Mars would appear 6,400 times larger and 2,500 times brighter than the full Moon appears from Earth, taking up a quarter of the width of a celestial hemisphere. The Mars–Phobos Lagrangian L1 is above Stickney, which is unusually close to the surface.
Solar transits.
An observer situated on the Martian surface, in a position to observe Phobos, would see regular transits of Phobos across the Sun. Several of these transits have been photographed by the Mars Rover "Opportunity". During the transits, Phobos's shadow is cast on the surface of Mars; an event which has been photographed by several spacecraft. Phobos is not large enough to cover the Sun's disk, and so cannot cause a total eclipse.
Predicted destruction.
Tidal deceleration is gradually decreasing the orbital radius of Phobos by 2 meters every one hundred years. Scientists estimate that Phobos will be destroyed in approximately 30–50 million years, with one study's estimate being about 43 million years.
Phobos' grooves were long thought to be fractures caused by the impact that formed Stickney crater. Other modelling suggested since the 1970s support the idea that the grooves are more like "stretch marks" that occur when Phobos gets deformed by tidal forces, but in 2015 when the tidal forces were calculated and used in a new model, the stresses were too weak to fracture a solid moon of that size, unless Phobos is a rubble pile surrounded by a layer of powdery regolith about thick. Given Phobos's irregular shape and assuming that it is a pile of rubble (specifically a Mohr–Coulomb body), it will eventually break up when it reaches approximately 2.1 Mars radii.
Researchers suggest that the grooves are "stretch marks" caused by tidal forces. This idea is based on the model that Phobos is a rubble pile surrounded by a 330 feet layer of powdery regolith. Stress fractures calculated for this model line up with the grooves on Phobos. The model is supported with the discovery that some of the grooves are younger than others, implying that the process that produces the grooves is ongoing.
When Phobos is eventually torn apart by tidal forces, it is likely that a fraction of the debris will form a planetary ring around Mars. This ring may last for between one million and one hundred million years.
Origin.
The origin of the Martian moons is still controversial. Phobos and Deimos both have much in common with carbonaceous C-type asteroids, with spectra, albedo, and density very similar to those of C- or D-type asteroids. Based on their similarity, one hypothesis is that both moons may be captured main-belt asteroids. Both moons have very circular orbits which lie almost exactly in Mars's equatorial plane, and hence a capture origin requires a mechanism for circularizing the initially highly eccentric orbit, and adjusting its inclination into the equatorial plane, most probably by a combination of atmospheric drag and tidal forces, although it is not clear that sufficient time is available for this to occur for Deimos. Capture also requires dissipation of energy. The current Martian atmosphere is too thin to capture a Phobos-sized object by atmospheric braking. Geoffrey Landis has pointed out that the capture could have occurred if the original body was a binary asteroid that separated under tidal forces.
Phobos could be a second-generation Solar System object that coalesced in orbit after Mars formed, rather than forming concurrently out of the same birth cloud as Mars.
Another hypothesis is that Mars was once surrounded by many Phobos- and Deimos-sized bodies, perhaps ejected into orbit around it by a collision with a large planetesimal. The high porosity of the interior of Phobos (based on the density of 1.88 g/cm3, voids are estimated to comprise 25 to 35 percent of Phobos's volume) is inconsistent with an asteroidal origin. Observations of Phobos in the thermal infrared suggest a composition containing mainly phyllosilicates, which are well known from the surface of Mars. The spectra are distinct from those of all classes of chondrite meteorites, again pointing away from an asteroidal origin. Both sets of findings support an origin of Phobos from material ejected by an impact on Mars that reaccreted in Martian orbit, similar to the prevailing theory for the origin of Earth's moon.
Shklovsky's "Hollow Phobos" hypothesis.
In the late 1950s and 1960s, the unusual orbital characteristics of Phobos led to speculations that it might be hollow.
Around 1958, Russian astrophysicist Iosif Samuilovich Shklovsky, studying the secular acceleration of Phobos's orbital motion, suggested a "thin sheet metal" structure for Phobos, a suggestion which led to speculations that Phobos was of artificial origin. Shklovsky based his analysis on estimates of the upper Martian atmosphere's density, and deduced that for the weak braking effect to be able to account for the secular acceleration, Phobos had to be very light—one calculation yielded a hollow iron sphere across but less than 6 cm thick. In a February 1960 letter to the journal "Astronautics", Fred Singer, then science advisor to U.S. President Dwight D. Eisenhower, said of Shklovsky's theory:
If the satellite is indeed spiraling inward as deduced from astronomical observation, then there is little alternative to the hypothesis that it is hollow and therefore Martian made. The big 'if' lies in the astronomical observations; they may well be in error. Since they are based on several independent sets of measurements taken decades apart by different observers with different instruments, systematic errors may have influenced them.
Subsequently, the systemic data errors that Singer predicted were found to exist, and the claim was called into doubt, and accurate measurements of the orbit available by 1969 showed that the discrepancy did not exist. Singer's critique was justified when earlier studies were discovered to have used an overestimated value of 5 cm/yr for the rate of altitude loss, which was later revised to 1.8 cm/yr. The secular acceleration is now attributed to tidal effects, which had not been considered in the earlier studies.
The density of Phobos has now been directly measured by spacecraft to be 1.887 g/cm3. Current observations are consistent with Phobos being a rubble pile. In addition, images obtained by the Viking probes in the 1970s clearly showed a natural object, not an artificial one. Nevertheless, mapping by the Mars Express probe and subsequent volume calculations do suggest the presence of voids and indicate that it is not a solid chunk of rock but a porous body. The porosity of Phobos was calculated to be 30% ± 5%, or a quarter to a third being empty.
Exploration.
Launched missions.
Phobos has been photographed in close-up by several spacecraft whose primary mission has been to photograph Mars. The first was "Mariner 7" in 1969, followed by "Viking 1" in 1977, "Mars Global Surveyor" in 1998 and 2003, "Mars Express" in 2004, 2008, and 2010, and "Mars Reconnaissance Orbiter" in 2007 and 2008. On August 25, 2005, the Spirit Rover, with an excess of energy due to wind blowing dust off of its solar panels, took several short-exposure photographs of the night sky from the surface of Mars. Phobos and Deimos are both clearly visible in the photograph.
The Soviet Union undertook the Phobos program with two probes, both launched successfully in July 1988. "Phobos 1" probe dedicated with flyby and jumping lander to Phobos. But in case of success of it, "Phobos 2" may be ordered to Deimos. The first was lost en route to Mars, whereas the second returned some data and images but failed shortly before beginning its detailed examination of Phobos's surface, including a lander. Other Mars missions collected more data, but the next dedicated mission attempt would be a sample return mission.
The Russian Space Agency launched a sample return mission to Phobos in November 2011, called "Fobos-Grunt". The return capsule also included a life science experiment of The Planetary Society, called Living Interplanetary Flight Experiment, or LIFE. A second contributor to this mission was the China National Space Administration, which supplied a surveying satellite called "Yinghuo-1", which would have been released in the orbit of Mars, and a soil-grinding and sieving system for the scientific payload of the Phobos lander. However, after achieving Earth orbit, the Fobos-Grunt probe failed to initiate subsequent burns that would have sent it off to Mars. Attempts to recover the probe were unsuccessful and it crashed back to Earth in January 2012.
Missions considered.
In 1997 and 1998, the Aladdin mission was selected as a finalist in the NASA Discovery Program. The plan was to visit both Phobos and Deimos, and launch projectiles at the satellites. The probe would collect the ejecta as it performed a slow flyby (~1 km/s). These samples would be returned to Earth for study three years later. The Principal Investigator was Dr. Carle Pieters of Brown University. The total mission cost, including launch vehicle and operations was $247.7 million. Ultimately, the mission chosen to fly was MESSENGER, a probe to Mercury.
In 2007, the European aerospace subsidiary EADS Astrium was reported to have been developing a mission to Phobos as a technology demonstrator. Astrium was involved in developing a European Space Agency plan for a sample return mission to Mars, as part of the ESA's Aurora programme, and sending a mission to Phobos with its low gravity was seen as a good opportunity for testing and proving the technologies required for an eventual sample return mission to Mars. The mission was envisioned to start in 2016, was to last for three years. The company planned to use a "mothership", which would be propelled by an ion engine, releasing a lander to the surface of Phobos. The lander would perform some tests and experiments, gather samples in a capsule, then return to the mothership and head back to Earth where the samples would be jettisoned for recovery on the surface.
Proposed missions.
In 2007, the Canadian Space Agency funded a study by Optech and the Mars Institute for an unmanned mission to Phobos known as Phobos Reconnaissance and International Mars Exploration (PRIME). A proposed landing site for the PRIME spacecraft is at the "Phobos monolith", a prominent object near Stickney crater. The PRIME mission would be composed of an orbiter and lander, and each would carry 4 instruments designed to study various aspects of Phobos's geology.
In 2008, NASA Glenn Research Center began studying a Phobos and Deimos sample return mission that would use solar electric propulsion. The study gave rise to the "Hall" mission concept, a New Frontiers-class mission currently under further study.
Another concept of a sample return mission from Phobos and Deimos is OSIRIS-REx II, which would use heritage technology from the first OSIRIS-REx.
As of January 2013, a new "Phobos Surveyor" mission is currently under development by a collaboration of Stanford University, NASA's Jet Propulsion Laboratory, and the Massachusetts Institute of Technology. The mission is currently in the testing phases, and the team at Stanford plans to launch the mission between 2023 and 2033.
In March 2014, a Discovery class mission was proposed to place an orbiter in Mars orbit by 2021 to study Phobos and Deimos through a series of close flybys. The mission is called Phobos And Deimos & Mars Environment (PADME). Two other Phobos missions that were proposed for the Discovery 13 selection included a mission called Merlin, which would flyby Deimos but actually orbit and land on Phobos, and another one is Pandora which would orbit Deimos and orbit Phobos also.
Russia plans to repeat Fobos-Grunt mission in the late 2020s, and the European Space Agency is assessing a sample-return mission for 2024 called Phootprint.
As part of a manned mission to Mars.
Phobos has been proposed as an early target for a manned mission to Mars. The tele-operation of robotic scouts on Mars by humans on Phobos could be conducted without significant time delay, and planetary protection concerns in early Mars exploration might be addressed by such an approach.
Phobos has also been proposed as an early target for a manned mission to Mars because a landing on Phobos would be considerably less difficult and expensive than a landing on the surface of Mars itself. A lander bound for Mars would need to be capable of atmospheric entry and subsequent return to orbit, without any support facilities (a capacity that has never been attempted in a manned spacecraft), or would require the creation of support facilities in-situ (a "colony or bust" mission); a lander intended for Phobos could be based on equipment designed for lunar and asteroid landings. Additionally, the delta-v to land on Phobos and return is only 80% of that for a trip to and from the surface of the Moon, partly due to Phobos's very weak gravity.
The human exploration of Phobos could serve as a catalyst for the human exploration of Mars and be exciting and scientifically valuable in its own right.

</doc>
<doc id="53000" url="https://en.wikipedia.org/wiki?curid=53000" title="Stir frying">
Stir frying

Stir frying () is a Chinese cooking technique in which ingredients are fried in a small amount of very hot oil while being stirred in a wok. The technique originated in China and in recent centuries has spread into other parts of Asia and the West. Many claim that this quick, hot cooking seals in the flavors of the foods, as well as preserving their color and texture.
Scholars think that wok (or pan) frying may have been used as early as the Han dynasty (206 B.C.E. – 220 C.E.) for drying grain, not for cooking, but it was not until the Ming dynasty (1368–1644) that the wok reached its modern shape and allowed quick cooking in hot oil. Well into the 20th century, while restaurants and affluent families could afford the oil and fuel needed for stir fry, the most widely used cooking techniques remained boiling and steaming. Stir fry cooking came to predominate over the course of the century as more people could afford oil and fuel, and in the West spread beyond Chinese communities. 
Stir frying and Chinese food have been recommended as both healthy and appealing for their skillful use of vegetables, meats, and fish which are moderate in their fat content and sauces which are not overly rich, provided calories are kept at a reasonable level.
The term "stir-fry" was introduced into the English language in Buwei Yang Chao's book "How to Cook and Eat in Chinese" (1945), to describe the "chǎo" technique.
History.
In China.
The Chinese character "chao" (炒) is attested in inscriptions on bronze vessels from the Eastern Zhou period (771–256 BC), but not in the sense of stir frying. Dry stirring was used in the Han dynasty (206 BC 221 AD) to parch grain. Although there are no surviving records of Han dynasty stir frying, archaeological evidence of woks and the tendency to slice food thinly indicate that the technique was likely used for cooking.
The term "chao" appears for the first time in the sense of "stir frying" in the "Qimin Yaoshu", a sixth-century agricultural manual, including in a recipe for scrambled eggs. In sources from the Tang dynasty (618–907), "chao" refers not to a cooking technique, but to a method for roasting tea leaves. It reappears as a cooking method in a dozen recipes from the Song dynasty (960–1279). The Song period is when the Chinese started to use vegetable oil for frying instead of animal fats. Until then, vegetable oil had been used chiefly in lamps.
Historically, stir frying was not as important a technique as boiling or steaming, since the oil needed for stir frying was expensive. The technique became increasingly popular in the late Ming dynasty (1368–1644), in part because the wood and charcoal used to fire stoves were becoming increasingly expensive near urban centers, and stir-frying could cook food quickly without wasting fuel. "The increasingly commercial nature of city life" in the late Ming and Qing (1644–1912) periods also favored speedy methods. But even as stir frying became an important method in Chinese cuisine, it did not replace other cooking techniques. For instance, "only five or six of over 100 recipes recorded in the sixteenth-century novel "Jin Ping Mei" are stir fry recipes and wok dishes accounted for only 16 percent of the recipes in the most famous eighteenth century recipe book, the "Suiyuan shidan"".
By the late Qing, most Chinese kitchens were equipped with a wok range ("chaozao" 炒灶 or "paotai zao" 炮臺灶) convenient for stir-frying because it had a large hole in the middle to insert the bottom of a wok into the flames.
In the West.
Stir frying was brought to America by early Chinese immigrants, and has been used in non-Asian cuisine.
The term "stir fry" as a translation for "chao" was introduced in the 1945 book "How To Cook and Eat in Chinese". It was designed by the author's husband, the linguist Yuen Ren Chao. The book told the reader
In the West, stir fry spread from Chinese family and restaurant kitchens into general use. One popular cookbook noted that in the "health-conscious 1970s" suddenly it seemed that "everyone was buying a wok, and stir frying remained popular because it was quick." Many families had difficulty fitting a family dinner into their crowded schedules but found that stir fry could be prepared in as little as fifteen minutes.
Technique.
Broadly speaking, there are two primary techniques: "chao" and "bao". Both techniques use high heat, but "chao" adds a liquid and the ingredients are softer, where as "bao" stir fries are more crispy because of the Maillard reaction.
"Chao" technique.
The "chao" (炒) technique is similar to the Western technique of sautéing. There are regional variations in the amount and type of oil, the ratio of oil to other liquids, the combinations of ingredients, the use of hot peppers, and such, but the same basic procedure is followed in all parts of the country.
First the wok is heated to a high temperature, and just as or before it smokes, a small amount of cooking oil is added down the side of the wok (a traditional expression is "hot wok, cold oil"), followed by dry seasonings such as ginger, garlic, scallions, or shallots. The seasonings are tossed with a spatula until they are fragrant, then other ingredients are added, beginning with the ones taking the longest to cook, such as meat or tofu. When the meat and vegetables are nearly cooked, combinations of soy sauce, vinegar, wine, salt, or sugar may be added, along with thickeners such as cornstarch, water chestnut flour, or arrowroot.
A single ingredient, especially a vegetable, may be stir-fried without the step of adding another ingredient, or two or more ingredients may be stir-fried to make a single dish. Although large leaf vegetables, such as cabbage or spinach, do not need to be cut into small pieces, for dishes which combine ingredients, they should all be cut to roughly the same size.
"Wok hei".
"Wok hei" (; romanization based on the Cantonese Chinese pronunciation of the phrase; when literally translated into English, it can be translated as "wok thermal radiation" or, metaphorically as the "breath of the wok." The phrase “breath of a wok” is a poetic translation Grace Young first coined in her cookbook, "The Wisdom of the Chinese Kitchen". In her book, "The Breath of a Wok", Young further explores the ideas and concepts of "wok hei". An essay called “Wok Hay: The Breath of a Wok” explains how the definition of "wok hei" varies from cook to cook and how difficult it is to translate the term. Some define it as the “taste of the wok,” a “harmony of taste,” etc.: “I think of wok hay as the breath of a wok—when a wok breathes energy into a stir-fry, giving foods a unique concentrated flavor and aroma.”
The second character is transliterated as "qi" ("chi") according to its Mandarin Chinese pronunciation, so "wok hei" is sometimes rendered as "wok chi" in Western cookbooks) is the flavour, tastes, and "essence" imparted by a hot wok on food during stir frying. Out of the Eight Culinary Traditions of China, wok hei is encountered the most in Cantonese cuisine, whereas it may not even be an accepted underlying principle in some of the other Chinese cuisines.
To impart "wok hei" the traditional way, the food is cooked in a seasoned wok over a high flame while being stirred and tossed quickly. The distinct taste of "wok hei" is partially imbued into the metal of the wok itself from former cooking sessions and brought out again when cooking over high heat. In practical terms, the flavour imparted by chemical compounds results from caramelization, Maillard reactions, and the partial combustion of oil that come from charring and searing of the food at very high heat in excess of . Aside from flavour, "wok hei" also manifests itself in the texture and smell of the cooked items.
"Bao" technique.
In the eighteenth and nineteenth centuries, the "bao" technique (Chinese: 爆, trans. pop or explosion) of stir-frying on a high flame was typical of cuisine from the northern Chinese province of Shandong. The wok is first heated to a dull red glow over a high fire. The oil, seasonings, and meats are then added in rapid succession. The food is continually tossed, stopping only to add other ingredients such as broths, vegetables, or more seasonings. The purpose of Bao is to highlight natural tastes, so minimal seasoning is added. Because of the high heat, "bao" is ideal for small amounts of food that cook quickly, so the juices do not flow out of the items. Meat is coated with egg white or starch in order to contain the juices. When the food is cooked it is poured and ladled out of the wok. The wok must then be quickly rinsed to prevent food residues from charring and burning to the wok bottom because of residual heat.
A larger amount of cooking fat with a high smoke point, such as refined plant oils, is often used in "bao". The main ingredients are usually cut into smaller pieces to aid in cooking.
Effects on nutritional value.
Stir frying has been promoted as healthy and nutritious. Writers extolled the quick cooking at high heat for retaining color, texture, and nutritional value. A study by researchers at the Department of Food Science and Nutrition at Zhejiang University compared the effects of boiling, steaming, and stir frying on bamboo shoots. Boiling and stir-frying decreased the amount of protein, soluble sugar, ash, and total free amino acids by more than one third. Stir-frying bamboo shoots increased their fat content by 528.57% due to the addition of oil, but retained more of the anti-oxidant capacities. With 78.9% retention, stir frying preserved significantly more vitamin C than boiling. Taking into consideration the total retention of antioxidants, the study concluded that stir frying is the method best suited for bamboo shoots. Similar results were found for stir frying red peppers.
Another study from Zhejiang University examined the nutritional value of broccoli after five common cooking techniques; steaming, boiling, microwaving, stir-frying and stir-frying followed by boiling. The study found that the two most common methods of home cooking in China, stir-frying and stir-frying combined with boiling in soybean oil, resulted in a much greater loss of chlorophyll, soluble protein, soluble sugar and vitamin C. The method which affected these values the least was steaming. Stir frying for five minutes and stir frying combined with boiling caused the highest loss of glucosinolates which according to this study are best preserved by steaming. A study performed by the Spanish National Research Counsel stir fried the broccoli for only 3 minutes 30 seconds and found that nutritional value of these broccoli samples varied depending on which cooking oil was used. Comparing these results to an uncooked sample, the study found that phenolics and vitamin C were reduced more than glucosinolates and minerals. Stir-frying with soybean, peanut, safflower or extra virgin olive did not reduce glucosinolates, and broccoli stir-fried with extra virgin olive oil or sunflower oil had vitamin C levels similar to uncooked broccoli. These levels were significantly lower with other edible oils.
Stir frying is not without health risks. Recent studies show that heterocyclic amines (HCAs) and polycyclic aromatic hydrocarbons (PAHs) are formed by stir frying at very high temperatures. These chemicals cause DNA changes that may contribute to increased risk of cancer.
Medicine.
The process of stir-frying is used in the preparation of some Chinese herbal medicines under the term 'dry-frying'. Stir frying a medical herb with honey is commonly used to increase its sweetness and therefore its spleen and stomach qi tonic effects. Stir frying in vinegar is typically used whenever one wants to direct the properties of an herb more to the liver based on the principle that the sour taste belongs to the liver.

</doc>
<doc id="53008" url="https://en.wikipedia.org/wiki?curid=53008" title="Iridium Communications">
Iridium Communications

Iridium Communications Inc. (formerly Iridium Satellite LLC) is a company, based in McLean, Virginia, United States which operates the Iridium satellite constellation, a system of 66 active satellites used for worldwide voice and data communication from hand-held satellite phones and other transceiver units. The Iridium network is unique in that it covers the whole Earth, including poles, oceans and airways.
The company derives its name from the chemical element iridium. The number of satellites projected in the early stages of planning was 77, the atomic number of iridium, evoking the metaphor of 77 electrons orbiting the nucleus; however 95 satellites have been launched so far; the atomic number of americium.
The satellites are frequently visible in the night sky as satellite flares, a phenomenon typically observed as short-lived bright flashes of light.
History.
The Iridium communications service was launched on November 1, 1998 by what was then Iridium SSC. The first Iridium call was made by Vice President of the United States Al Gore. Motorola provided the technology and major financial backing. The logo of the company was designed by Landor Associates, and represents the Big Dipper.
The founding company went into Chapter 11 bankruptcy nine months later, on August 13, 1999. The handsets could not operate as promoted until the entire constellation of satellites was in place, requiring a massive initial capital cost running into the billions of dollars. The cost of service was prohibitive for many users, reception indoors was difficult and the bulkiness and expense of the hand held devices when compared to terrestrial cellular mobile phones discouraged adoption among potential users.
Mismanagement is another major factor cited in the original program's failure. In 1999, CNN writer David Rohde detailed how he applied for Iridium service and was sent information kits, but was never contacted by a sales representative. He encountered programming problems on Iridium's website, and a "run-around" from the company's representatives. After Iridium filed bankruptcy, it cited "difficulty gaining subscribers".
The initial commercial failure of Iridium had a damping effect on other proposed commercial satellite constellation projects, including Teledesic. Other schemes (Orbcomm, ICO Global Communications, and Globalstar) followed Iridium into bankruptcy protection, while a number of other proposed schemes were never constructed.
At one stage, there was a threat that the Iridium satellites would have to be de-orbited; however, they remained in orbit and operational. Their service was restarted in 2001 by the newly founded Iridium Satellite LLC, which was owned by a group of private investors. Although the satellites and other assets and technology behind Iridium were estimated to have cost on the order of US$6 billion, the investors bought the firm for about US$35 million. In 2008, as part of a rebranding campaign by Media Graphics, Inc. the logo would be redesigned with updates to corporate color palette and font treatment.
On February 10, 2009, Iridium 33 collided with a defunct Russian satellite, Kosmos 2251, over Siberia. Two large debris clouds were created.
Present status.
Iridium Satellite LLC merged with a special purpose acquisition company (GHQ) created by the investment bank Greenhill & Co. (NYSE: GHL) in September 2009 to create Iridium Communications, Inc. The public company trades on NASDAQ under the symbol "IRDM". The company had 611,000 subscribers as of the end of December 2012 (compared to 523,000 in December 2011). Revenue for the full year 2012 was US $383.5 million with operational EBITDA of US $250.7 million.
The system is being used extensively by the U.S. Department of Defense through the DoD gateway in Hawaii. The service revenue to governments made up 23% of Iridium's revenues in 2012. An investigation was begun into the DoD contract after a protest by Globalstar, to the U.S. General Accounting Office that no tender was provided. A hold against the contract was lifted at the request of the Department of Defense, which cited national security reasons. This allows the continued use of the network during the investigation.
The commercial gateway in Tempe, Arizona, provides voice, data, and paging services for commercial customers on a global basis. Typical customers include maritime, aviation, government, the petroleum industry, scientists, and frequent world travelers.
Iridium satellites are now an essential component of communications with remote science camps, especially the Amundsen–Scott South Pole Station. In December 2006, an array of twelve Iridium modems was put online, providing continuous data services to the station for the first time. Total bandwidth is 28.8 kbit/s.
Matt Desch is the CEO of Iridium LLC.
Hosted Payload Alliance.
Iridium is a founding member of the Hosted Payload Alliance (HPA), a satellite industry alliance formed to increase awareness of the benefits of hosted government payloads on commercial satellites. Membership in the HPA is open to satellite operators, satellite manufacturers, system integrators and other interested parties.
Iridium satellite constellation.
The Iridium system requires 66 active satellites in orbit to complete its constellation and spare satellites are kept in-orbit to serve in case of failure. The satellites are in six polar low Earth orbital planes at a height of approximately . Satellites communicate with neighboring satellites via Ka band intersatellite links to relay communications to and from ground stations. Most of these satellites were launched in the late 1990s before the company went through bankruptcy. Since the bankruptcy, only seven additional satellites have been launched but an updated constellation of 66 satellites called Iridium NEXT is currently being developed and is planned for launch between 2015 and 2017 on SpaceX Falcon 9 launch vehicles from Vandenberg AFB Space Launch Complex 3 in California.
Subscriber equipment.
Handsets.
The former Iridium provided phones from two vendors, Kyocera and Motorola. The Motorola 9500 phone is a design from the first commercial phase of Iridium, whereas the 9575 model is the current version of the handset and was released in 2011. Until the release of the 9555 in 2008, the 9505A was the sole handset sold by the company - a functionally identical clone of the Motorola 9505 with some slightly different components. In 2011, a highly durable Iridium Extreme (9575) phone was introduced with a built-in GPS emergency button and interface to advanced location-based services. An accessory was also introduced at the same time called Iridium Axcesspoint which, when connected to a 9555 or Extreme phone, creates a wi-fi hotspot for smartphone email, SMS and web connections.
Kyocera phone models SS-66K and SD-66K are no longer in production but still available in the second-hand and surplus market. The KI-G100 phone is a small 900 MHz GSM phone that fitted in a cradle (model number SD-66K) that included a large antenna and facilitated connection to the Iridium network. The SS-66K is a self-contained phone, but features a rather unusual ball antenna.
All handsets can receive SMS, but only the 9505, 9505A, 9555, Extreme and those based on the 9522 can send them.
Pagers.
Two pagers were made for the Iridium network — the Motorola 9501 and Kyocera SP-66K. These are one-way devices that could receive messages sent in the form of SMS.
Other satellite phones.
Several other Iridium-based telephones exist, such as payphones, and equipment intended for installation on ships and aircraft. The DPL handset made by NAL Research combined with a 9522 transceiver is used for some of these products. This handset provides a user interface nearly identical to that of the 9505 series phones.
Standalone transceiver units.
These can be used for data-logging applications in remote areas, now a common practical use for Iridium's services. Some types of buoys, such as those used for the tsunami warning system, use Iridium satellites to communicate with their base. The remote device is programmed to call or send SBD (Short burst data, see below) messages to the base at specified intervals, or it can be set to accept calls in order for it to offload its collected data. Most of these units can be connected to a handset and used as a fixed telephone.
The following transceivers have been released over the years:
SBD Modems.
These devices support only Short Burst Data for M2M services and do not use a SIM card.
SIM card.
Removable Subscriber Identity Modules (SIMs) are used in Iridium phones, much like those used for GSM. Prepaid SIM cards are usually green while post-paid cards are red. The 9601 and 9602 SBD modems don't use a SIM card, they are identified by the network solely through the IMEI of the device and the customer account associated with that IMEI.
OpenPort.
OpenPort is a broadband satellite voice and data communications system for maritime vessels. The system is used for crew calling and e-mail services on sea vessels such as merchant fleets, government and navy vessels, fishing fleets and personal yachts. Iridium’s Global Service Program provides shipboard technical support to Iridium OpenPort customers. OpenPort voice services are billed by the minute as with handheld phones, while data services are billed by the megabyte of data transferred (not by the connection time of the session).
Services.
Calls from Iridium phones can be made to any landline or wireless device in the world and typically cost between $0.75 to $1.50 per minute. Calls made to Iridium phones can be very expensive, costing several dollars per minute. For example, Google Voice charges $4.03USD per minute to directly call an Iridium phone. It is possible to call with charges reversed by first dialing a number in Arizona; the call is charged to the receiver at the standard rate for satellite to landline calls, but the caller only pays for the call to Arizona.
Since Iridium will not sell prepaid cards or even its subscription call service directly, it is hard to obtain the exact price of making a call. There are numerous distributors that will activate Iridium phones and sell pre-paid vouchers and SIM cards.
Voice and data calls.
The Iridium system deals with "minutes", which are subdivided into several much smaller "units". These minutes are the "basic rate" to landlines and ordinary mobile phones around the world. For a 500-minute annual plan the cost of the "basic rates" fluctuates around US$1.25 per minute, depending on the distributor. There are also regional plans that offer slightly cheaper rates than the normal, but these minutes can only be used in a specified geographic location (such as Africa, North America, Canada or Alaska).
Iridium and other satellite phones may be identifiable to the listener by the "clipping" effect of the data compression and the latency (time delay) due to the electronic equipment used and the distances the signal must travel. The voice codec used is called Advanced Multi-Band Excitation.
Iridium operates at only 2.2 to 3.8 kbit/s, which requires very aggressive voice compression and decompression algorithms. Latency for data connections is around 1800 ms round-trip, using small packets.
Despite the bandwidth limitations, transparent TCP/IP is supported. Iridium claims data rates up to 10 kilobits per second for their "direct Internet" service which utilizes v.42bis compression over a PPP dialup connection to Iridium's Arizona gateway. Actual data rates remain at 2300 to 2400 bit/s for any compressed data such as a JPG image or ZIP file, but plain text or HTML may transfer "up to" 10 kbit/s. Iridium 9500, 9505 and 9505A phones can be connected to computers using an RS-232 connection, as can the 9522A transceiver module. The 9555 and Extreme phones connect to computers with a standard USB cable, using an internal USB to serial bridge chip and Windows drivers to emulate a serial COM port for compatibility with standard PPP clients.
Prepaid service.
Prepaid SIM cards are available from a variety of different outlets and sometimes appear on auction sites such as eBay. Their values range from 50 to 5,000 minutes; the 50 minute cards have no validity and the 75 minute vouchers are valid for only a month, but the 5,000 minute cards stay valid for two years. Since Iridium charges quite a bit for merely accessing their network without making calls it is possible to extend the validity of such an account by a month for around US$45. It is also possible to refill such an account without purchasing a new SIM card.
The 500 minute card is the most common one, which remains valid for one year and can usually be bought for US$600 to $750, while the 75 minute card can cost up to US$175 and the 5,000 minute card costs around US$4,000.
Post-paid service.
There is a basic "Emergency" plan for around US$30 to US$40 per month that offers no minutes at all with calls charged at around US$1.39 per minute, and also numerous plans with included minutes. For the more expensive plans (around US$250 per month), the per-minute price dips slightly below US$1.
Phone numbers.
Iridium controls the virtual country codes +8816 and +8817, part of the 881 range designated by the ITU for the Global Mobile Satellite System. Each subscriber is given an 8-digit number prefixed by one of these country codes. However many regional telephone service operators have no interconnect agreement with Iridium or other satellite networks and users on these networks need to call reverse charge to a U.S.-based number.
It is also possible to call an Iridium phone by using a US-based gateway number at the Arizona gateway. In this arrangement, a person wishing to call an Iridium phone dials +1-480-768-2500, billed at the standard rates to call the United States from their location, waits for the prompt, enters the +8816 or +8817 number of the Iridium phone they are attempting to reach, and the network then attempts to complete the call. If the Iridium subscriber answers their phone, it will be billed at its standard usage rate, ranging from $0.95 to $1.50 USD per minute, or subtracting minutes from a pool of prepaid minutes assigned to the phone.
Since spring 2007, postpaid Iridium subscribers have an option to associate their Iridium numbers with a direct U.S.-based number (the so-called +1 Access service).
Paging service.
The one-way paging service is still operational, despite the pagers not being in production for many years now. Messages are delivered to pre-selected "MDAs" which cover a certain geographic area. Three of these MDAs may be selected on a web-based portal or updated automatically if the paging service is bound to an Iridium phone. Each country has its own MDA based on its country code; some of the larger countries are divided into several MDAs, while separate MDAs exist for sections of ocean and common aeronautic routes.
This service costs around US$70 per month with a limited number of messages allowed, or US$140 for an unlimited number of inbound messages.
Pagers are assigned with telephone numbers in area code 480 and can also be contacted using email, SMS and the web-based interface used to send messages to Iridium phones.
Short burst data.
Special modems such as the 9522A, 9601, 9602 and Quake Q9612 can be used for sending and receiving short data bursts, less than 2 kilobytes at a time. This service is often used for asset tracking and remote monitoring. Messages are converted to be delivered in email format or over HTTP to a preconfigured address; the mobile unit does not include a destination address when sending a SBD message. A crude positioning report is also included in each message sent. SBD messages take from 6 to 22 seconds to send or receive. The latest generation of SBD transceiver, the Iridium 9602, can receive up to 270 bytes per SBD data message (defined by Iridium as "mobile terminated SBD") and can transmit a maximum of 340 bytes per SBD message (defined by Iridium as "mobile originated SBD"). A real-world example of the 9602 chipset in use are the YB Tracker or the owa3x embedded Linux computer.
Value added services.
To check emails can be very expensive. To avoid this there is a service called SatNotify by Leaf Consulting which checks emails periodically and send a text message to the satellite phone, if there are new messages.
Air Safety Communications.
In July 2011, The Federal Aviation Administration (FAA) issued a ruling that approves the use of Iridium for Future Air Navigation System (FANS) data links, enabling satellite data links with air traffic control (ATC) for aircraft flying in the FANS environment including areas not served by Inmarsat (above or below 70 Degrees Latitude) which includes Polar routes.
Technical details.
Air interface.
Communication between satellites and handsets is done using a TDMA and FDMA based system using L-band spectrum between 1616 and 1626.5 MHz. Iridium exclusively controls 7.775 MHz of this and shares a further 0.95 MHz. In 1999 Iridium agreed to timeshare a portion of spectrum, allowing radio astronomers to observe hydroxyl emissions; the amount of shared spectrum was recently reduced from 2.625 MHz.
External "hockey puck" type antennas used with Iridium handheld phones, data modems and SBD terminals are usually defined as 3dBi gain, 50 ohm impedance with RHCP (right hand circular polarization) and 1.5:1 VSWR. As Iridium antennas function in frequencies very close to that of GPS, a single antenna may be utilized through a pass-through for both Iridium and GPS reception.
The type of modulation used is normally DE-QPSK, although DE-BPSK is used on the uplink (mobile to satellite) for acquisition and synchronization. Each time slot is 8.28 ms long and sits in a 90 ms frame. Within each FDMA channel there are four TDMA time slots in each direction. The TDMA frame starts off with a 20.32 ms period used for simplex messaging to devices such as pagers and to alert Iridium phones of an incoming call, followed by the four upstream slots and four downstream slots. This technique is known as time division multiplexing. Small guard periods are used between time slots. Regardless of the modulation method being used, communication between mobile units and satellites is performed at 25 kilobaud.
Channels are spaced at 41.666 kHz and each channel occupies a bandwidth of 31.5 kHz; this allows space for Doppler shifts.
Handoff.
The Iridium system uses three different handoff types. As a satellite travels over the horizon, calls are handed to adjacent spot-beams; this occurs approximately every fifty seconds. A satellite only stays in view for seven minutes at the equator. When the satellite disappears from view, an attempt is made to hand the call to another satellite. If no other satellite is in view, the connection is dropped. This may occur when the signal from either satellite is blocked by an obstacle. When successful, the inter-satellite handoff may be noticeable by a quarter-second interruption.
The satellites are also able to transfer mobile units to different channels and time slots within the same spot beam.
Earth base-stations.
Iridium routes phone calls through space. In addition to communicating with the satellite phones in its footprint, each satellite in the constellation also maintains contact with two to four adjacent satellites, and routes data between them, to effectively create a large mesh network. There are four earth stations which link to the network through the satellites visible to them. The space-based backhaul routes outgoing phone call packets through space to one of the earth station downlinks ("feeder links"). Station-to-station calls from one satellite phone to another can be routed directly through space without going through an earth station. As satellites leave the area of an earth station, the routing tables are updated and packets headed for the earth station are forwarded to the next satellite just coming into view of the earth station. Communication between satellites and earth stations is at 20 and 30 GHz.
Gateways are located in
The pre-bankruptcy corporate incarnation of Iridium built eleven gateways, most of which have since been closed.
Gateways were also built in Pune (India), Beijing (People's Republic of China), Moscow (Russia), Nagano (Japan), Seoul (South Korea), Taipei (Taiwan), Jeddah (Saudi Arabia) and Rio de Janeiro (Brazil). The company is seeking to reactivate gateways in Russia and China to comply with national laws in those countries.
Other technical information.
Like other satellite networks, Iridium terminals need open line-of-sight to open sky in order to function. For instance, units will not work consistently indoors, or under forest cover. Iridium does have a very powerful paging channel that can ring the phone indoors, but the customer may have to walk outdoors to take the call.
There is a web/email to SMS gateway which enables messages to be sent from the internet or an e-mail account to Iridium handsets for free. There is also a voice mail service.
Iridium generally does not have roaming agreements with terrestrial/cellular operators. Telstra in Australia allows postpay GSM subscribers to use their SIM card. However, global roaming has to be activated and both incoming and outgoing calls are charged to this account, and the call rate is around US$4 per minute; the incoming calls are via the GSM phone number of the account, with country code, etc., prefixed. In order to use the network, it is necessary to have not only appropriate equipment, such as a handset or the optional cellular cassette for the Motorola 9505 phone, but also a pay-as-you-go or contract Iridium SIM card.
Tracking transceiver units.
Without an extra global navigation satellite system, receiver tracking is difficult, but not impossible, as the position of a mobile unit can be determined using a Doppler shift calculation from the satellite. These readings however can be inaccurate with errors in the tens of kilometers. Even without using Doppler shifts, a rough indication of a unit's position can be found by checking the location of the spot-beam being used and the mobile unit's timing advance.
The position readings can be extracted from some transceiver units and the 9505A handset using the codice_1 AT command.
In the past, Iridium has used this method of tracking to block service to U.S. embargoed countries, such as North Korea and other politically unpopular regions, such as Northern Sri Lanka. It is also used to stop geographically bounded plans from being used outside the designated area.
The Iridium Extreme phone introduced in 2011 has a GPS location service embedded in the device, which the user can use to locate themselves or include in SMS messages. It can also be used to provide advanced services like Geo-fencing. A red emergency button on the top of the unit can be pressed to send the unit's position to emergency rescue agencies or other number pre-programmed by the user or distributor.

</doc>
<doc id="53011" url="https://en.wikipedia.org/wiki?curid=53011" title="Poet laureate">
Poet laureate

A poet laureate (plural: poets laureate) is a poet officially appointed by a government or conferring institution, who is often expected to compose poems for special events and occasions. The Italians Albertino Mussato and Francesco Petrarca were the first to be crowned poets laureate after the classical age, respectively in 1315 and 1342. In Britain, the term dates from the appointment of Bernard André by Henry VII of England. In modern times, the title may also be conferred by an organization such as the Poetry Foundation, which has a designated Children's Poet Laureate. Other examples are the Pikes Peak Poet Laureate, which is designated by a "Presenting Partners" group from within the community; the Minnesota Poet Laureate chosen by the League of Minnesota Poets (est. 1934); the Northampton Poet Laureate chosen by the Northampton Arts Council, and the Martha's Vineyard Poet Laureate chosen by ten judges representing the Martha's Vineyard Poetry Society.
Over a dozen national governments continue the poet laureate tradition.
Background.
In ancient Greece, the laurel was used to form a crown or wreath of honour for poets and heroes. This custom, first revived in Padua for Albertino Mussato, was followed by Petrarch's own crowning ceremony in the audience hall of the medieval senatorial palazzo on the Campidoglio on 8 April 1341. Because the Renaissance figures who were attempting to revive the Classical tradition lacked detailed knowledge of the Roman precedent they were attempting to emulate, these ceremonies took on the character of doctoral candidatures.
As the concept of the poet laureate has spread, the term "laureate" has come in English to signify recognition for preeminence or superlative achievement (cf. Nobel laureate). As a royal degree in rhetoric, "poet laureate" was awarded at European universities in the Middle Ages. The term might also refer to the holder of such a degree, which recognized skill in rhetoric, grammar and language.
By country.
Canada.
The Canadian Parliamentary Poet Laureate is appointed as an officer of the Library of Parliament. The position alternates between an English and French speaking laureate. Candidates must be able to write in both English and French, have a substantial publication history (including poetry) displaying literary excellence and have written work reflecting Canada, among other criteria.
The first laureate was George Bowering, in 2002. In 2004, the title was transferred to Pauline Michel, in 2006 to John Steffler until December 3, 2008, to Pierre DesRuisseaux on April 28, 2009, and to Fred Wah in December 2011. Michel Pleau was installed in January, 2014.
Dominican Republic.
Poets Laureate of Dominican Republic include: Pedro Mir (1984).
Ethiopia.
Poets Laureate of Ethiopia include: Tsegaye Gabre-Medhin.
Germany.
Poets Laureate of Nazi Germany include: Hanns Johst from 1935 to 1946.
India.
Andhra Pradesh.
Sripada Krishnamurty Sastry was the first poet laureate of Andhra Pradesh, India.
He was born in Calcutta as the 6th son of the German pilgrim Steffen Montenbruck.
Tamil Nadu.
Kannadasan was the poet laureate of Tamil Nadu at the time of his death.
Iran.
Malek o-Sho'arā Bahār was the poet laureate of Mozaffar ad-Din Shah Qajar. He was born in Mashhad in 1884 (d. 1951) and was a conservative figure among the modernists.
Ireland.
The closest equivalent is the title "Saoi" ["wise one"] held by up to seven members at a time of Aosdána, an official body of those engaged in fine arts, literature, and music. Poets awarded the title include Máire Mhac an tSaoi, Anthony Cronin, and Seamus Heaney.
Netherlands.
The unofficial Poet Laureate of Netherlands is Anne Vegter as "Dichter des Vaderlands" (Poet of the Fatherland). The previous laureate was Ramsey Nasr. Gerrit Komrij was the first "Dichter des Vaderlands". The title was created by Dutch media.
New Zealand.
New Zealand has only had an official poet laureate for a few years. Originally sponsored by Te Mata vineyards and known as the Te Mata Estate Poet Laureate, the award is now administered by the National Library of New Zealand and the holder is called New Zealand Poet Laureate. The post is held for two years. Unlike the butt of sack traditionally offered to United Kingdom poets laureate, New Zealand offers a Tokotoko, a carved wooden ceremonial orator's staff.
The first holder was Bill Manhire, in 1998–99, then Hone Tuwhare (2000–01), Elizabeth Smither (2002–03), Brian Turner (2004–05), Jenny Bornholdt (2006–07), Michele Leggott (2008–09), Cilla McQueen (2009–11), Ian Wedde (2011–13).
Nigeria.
Poets Laureate of Nigeria include: Obo Aba Hisanjani.
North Korea.
Beginning around 1994, North Korea had 6 active poets laureate who worked in the epic genre. Epic poetry was the chief vehicle of political propaganda during the rule of Kim Jong-il, and the poets worked according to the requests and needs of Kim Jong-il. Some of the poets names included Jang Jin-sung (pseudonym), Kim Man-young and Shin Byung-gang.
Saint Lucia.
Poets Laureate of Saint Lucia include: Derek Walcott.
Sierra Leone.
Poets laureate of Sierra Leone include the Italian authors Roberto Malini and Dario Picciau.
Somalia.
Poets laureate of Somalia include: hadraawi.
United Kingdom.
From the more general use of the term "poet laureate" arose its restriction in England to the official office of Poet Laureate, attached to the royal household. King James I essentially created the position as it is known today for Ben Jonson in 1617, although Jonson's appointment does not seem to have been made formally. The office was a development from the practice in earlier times when minstrels and versifiers formed part of the king's retinue. Richard Cœur-de-Lion had a "versificator regis" (English: "king's poet"), Gulielmus Peregrinus (William the Pilgrim), and Henry III had a "versificator" named Master Henry. In the fifteenth century, John Kay, a versifier, described himself as Edward IV's "humble poet laureate".
No single authentic definitive record exists of the office of Poet Laureate of England. According to Wharton, King Henry I paid 10 shillings a year to a "versificator regis". Geoffrey Chaucer (1340–1400) was called Poet Laureate, being granted in 1389 an annual allowance of wine. W. Hamilton describes Chaucer, Gower, Kay, Andrew Bernard, John Skelton, Robert Whittington, Richard Edwards and Samuel Daniel as "volunteer Laureates".
John Skelton studied at the University of Oxford in the early 1480s and was advanced to the degree of "poet laureate" in 1488, when he joined the court of King Henry VII to tutor the future Henry VIII. The title of "laureate" was also conferred on him by the University of Louvain in 1492 and by the University of Cambridge in 1492–3. He soon became famous for his rhetoric, satire and translations and was held in high esteem by the printer William Caxton, who wrote, in the preface to "The Boke of Eneydos compyled by Vargyle" (Modern English: "The Book of the Aeneid, compiled by Virgil") (1490):
But I pray mayster John Skelton, late created poete laureate in the unyversite of Oxenforde, to oversee and correct this sayd booke.
The title of Poet Laureate, as a royal office, was first conferred by letters patent on John Dryden in 1670, two years after Davenant's death. The post became a regular institution. Dryden's successor Shadwell originated annual birthday and New Year odes. The poet laureate became responsible for writing and presenting official verses to commemorate both personal occasions, such as the monarch's birthday or royal births and marriages, and public occasions, such as coronations and military victories. His activity in this respect varied according to circumstances, and the custom ceased to be obligatory after Pye's death. The office fell into some contempt before Southey, but took on a new lustre from his personal distinction and that of Wordsworth and Tennyson. Wordsworth stipulated before accepting the honour that no formal effusions from him should be considered a necessity, but Tennyson was generally happy in his numerous poems of this class.
On Tennyson's death there was a considerable feeling that there was no acceptable successor, William Morris and Swinburne being hardly suitable as court poets. Eventually the undesirability of breaking with tradition for temporary reasons, severing the one official link between literature and the state, prevailed over the protests against allowing anyone of inferior genius to follow Tennyson. Abolition had been similarly advocated when Warton and Wordsworth died. Edward Gibbon had condemned the position's artificial approach to poetry:
The salary has varied, but traditionally includes some alcohol. Ben Jonson first received a pension of 100 marks, and later an annual "terse of Canary wine". Dryden had a pension of £300 and a butt of Canary wine. Pye received £27 instead of the wine. Tennyson drew £72 a year from the Lord Chamberlain's department, and £27 from the Lord Steward's "in lieu of the butt of sack".
The present laureate is Carol Ann Duffy, appointed in May 2009.
The United Kingdom also has a "Children's poet laureate".
William Wordsworth was chosen as the poet laureate after the death of Robert Southey but since he was too old, he became the only laureate to write no official poetry.
Scotland.
The "Edinburgh Makar" was traditionally seen as the unpaid equivalent of a poet laureate, tasked with representing and promoting poetry in Scotland. Since 2004, the Scottish Parliament has appointed an official Scots Makar, from the Makars of the various cities. On 16 February 2004, Professor Edwin Morgan was appointed to both the Edinburgh post and the national role. On his death he was succeeded (in January 2011) by Liz Lochhead.
Wales.
Wales has had a long tradition of poets and bards under royal patronage, with extant writing from medieval royal poets and earlier. The office of National Poet for Wales was established in April 2005. The first holder, Gwyneth Lewis, was followed by Gwyn Thomas
United States of America.
The United States Library of Congress appointed a Consultant in Poetry to the Library of Congress from 1937 to 1984. An Act of Congress changed the name in 1985 to "Poet Laureate Consultant in Poetry to the Library of Congress". A number of American states' legislatures have created official government positions that are occupied by Poets Laureate who are prominent either locally, nationally, or sometimes both.
Laureates receive a US$35,000 stipend and are given the responsibility of overseeing an ongoing series of poetry readings and lectures at the library, and a charge to promote poetry. No other duties are specified, and laureates are not required to compose for government events or in praise of government officials. However, after the terrorist attacks in New York, Washington, D.C. and Pennsylvania on September 11, 2001, the then-Poet Laureate, Billy Collins, was asked to write a poem to be read in front of a special joint session of Congress. Collins wrote "The Names" which he read on September 6, 2002, which is available in streaming audio and video. When the $35,000 stipend was instituted, the amount was quite large and was intended to allow the poet laureate to abandon worries about earning a living and devote his or her time entirely to writing poetry. That amount has remained the same over time without having ever been adjusted for inflation, so the intent of making it a nice living for a poet is no longer being fulfilled. Now it functions essentially as a bonus for a poet who usually is teaching at a university and earns the bulk of his or her living that way.
Juan Felipe Herrera is the current laureate. Previous laureates include Philip Levine, W. S. Merwin, Kay Ryan, Charles Simic, Ted Kooser, Louise Glück, Billy Collins, Rita Dove, Elizabeth Bishop, Robert Frost, Karl Shapiro, Allen Tate, Robert Penn Warren, Richard Wilbur, Joseph Brodsky, Stanley Kunitz, Robert Hass, Donald Hall, Robert Pinsky (three terms), Mark Strand, Audre Lorde, and Maxine Kumin.
Alabama.
The state of Alabama has had a poet laureate position since 1930, and was initially created for Samuel Minturn Peck. The post has been continuously filled since 1954 on a four-year renewable basis. Poets Laureate serve at the pleasure of the governor.
Arizona.
The state of Arizona established a state Poet Laureate position in 2013, appointing Alberto Ríos as the inaugural Poet Laureate.
California.
The state of California under Governor Hiram Warren Johnson, established a state Poet Laureate and appointed Ina Donna Coolbrith on June 30, 1915. Coolbrith was later acknowledged as the "Loved Laurel-Crowned Poet of California" by a 1919 state Senate resolution, and she retained the title until her death in 1928. Juan Felipe Herrera was appointed by Gov. Jerry Brown in March, 2012.
The city of Los Angeles selected its first poet laureate, Eloise Klein Healy, in December 2012.
Colorado.
The State of Colorado appointed one of the most widely known Poets Laureate of the late 20th century, singer/songwriter John Denver.
Florida.
Edmund Skellings was selected as the poet laureate of Florida in 1980. He died in 2012.
Iowa.
Position created July 1, 1999; codified in Subchapter 303.89 of the Iowa Code. The position is a two-year renewable term.
Marvin Bell was the first poet laureate of Iowa. He held the position from 2000-2004.
Mary Swander [http://www.maryswander.com/] is the current poet laureate of Iowa as of April 2016.
Maryland.
The Takoma Park Poet Laureate program, established in May 2005, honors the achievements of a local poet, encouraging a wider appreciation of poetry and literature. Poet Laureate emeritus include Donald Berger (2005–2007) and Anne Becker (2007–2011). The current Poet Laureate is Merrill Leffler.
Minnesota.
In May 2007, Gov. Pawlenty reversed his decision in deference to the legislature's expressed desire for a Minnesota poet laureate. Section 4, Chapter 148 of the Minnesota Session Laws 2007, signed by Pawlenty on May 25, established the official position of state poet laureate. Robert Bly was appointed the first official Minnesota poet laureate February 27, 2008; succeeded on August 23, 2011, by Joyce Sutphen.
Tennessee.
"Pek" Gunn, a native of Bold Spring, Tennessee and a close friend and politically ally of former Governor of Tennessee Frank Clement, was the first Tennessean to be officially bestowed with the title of State Poet Laureate, in the 1970s.
Texas.
The state of Texas has appointed a state Poet Laureate since 1932 (historical list of Texas poets laureate). The current term is one year.
In April 2012, San Antonio became the first Texas city to appoint a Poet Laureate, Carmen Tafolla. The San Antonio Poet Laureate serves a two-year term. The current Poet Laureate is Laurie Ann Guerrero, having been appointed on April 1, 2014.
Utah.
The state of Utah has appointed a Poet Laureate since 1997. The first was David Lee (January 24, 1997, to December 2002), followed by Ken Brewer (January 24, 2003, to March 15, 2006), Katharine Coles (October 27, 2006, to May, 2012), and Lance Larsen, appointed May 3, 2012, by Governor Gary Herbert.
Virginia.
The Commonwealth of Virginia has appointed a Poet Laureate since December 18, 1936. The first was Carter Warner Wormeley, appointed for life. Appointments from 1942 until 1992 were for one year, many reappointed were for more than one term. In 1992, the appointment was increased to a two years, and from 1998 appointments were made from list of nominees presented by the Poetry Society of Virginia, established at the College of William & Mary in Williamsburg, Virginia, in 1923.
Ohio.
The state of Ohio started an open call for a Poet Laureate as of April 20, 2015, accepting nominations until May 20, 2015. The selected Poet Laureate's term will start January 1, 2016 and end December 31, 2017.
Amit Majmudar, 36, now of Dublin, Ohio, was named to the position Thursday by Ohio Gov. John Kasich. 

</doc>
<doc id="53012" url="https://en.wikipedia.org/wiki?curid=53012" title="Chandra Levy">
Chandra Levy

Chandra Ann Levy (April 14, 1977 – May 1, 2001) was an American intern at the Federal Bureau of Prisons in Washington, D.C., who disappeared in May 2001. She was presumed murdered after her skeletal remains were found in Rock Creek Park in May 2002. The case attracted attention from the American news media for years.
The police investigation revealed she was having an affair with Congressman Gary Condit, a married Democrat then serving his fifth term representing California's 18th congressional district, and a senior member of the House Permanent Select Committee on Intelligence. Condit was never named as a suspect by police and was eventually cleared of involvement. However, after a cloud of suspicion was raised by the intense media focus on the missing intern and the later revelation of the affair, he was not re-elected in 2002, with the Levy issue cited as a contributory factor.
The circumstances surrounding Levy's death were unclear for eight years. On March 3, 2009, D.C. authorities obtained a warrant to arrest Ingmar Guandique, an illegal immigrant from El Salvador. He had been convicted of assaulting two other women in Rock Creek Park around the time of Levy's disappearance. Prosecutors alleged that Guandique had attacked and tied up Levy in a remote area of the park and left her to die of dehydration or exposure. In November 2010 Guandique was convicted of murdering Levy; he was sentenced in February 2011 to 60 years in prison. In June 2015, Guandique was granted a new trial and in March 2016, the date was set to October 11, 2016.
Life and background.
Levy was born in Cleveland, Ohio, to Robert and Susan Levy; the family moved to Modesto, California, where she attended Grace M. Davis High School. Her parents are members of Congregation Beth Shalom, a Conservative Jewish synagogue. She attended San Francisco State University, where she earned a degree in journalism. After interning for the California Bureau of Secondary Education and working in the office of Los Angeles Mayor Richard Riordan, she began attending the University of Southern California to earn a master's degree in public administration.
As part of her final semester of study, Levy moved to Washington, D.C., to become a paid intern with the Federal Bureau of Prisons. In October 2000 she began her internship at the bureau's headquarters, where she was assigned to the public affairs division. Her supervisor, bureau spokesperson Dan Dunne, was impressed with Levy's work, especially her handling of media inquiries regarding the upcoming execution of Timothy McVeigh, convicted of bombing the Oklahoma City Federal Building. Levy's internship was abruptly terminated in April 2001 because her academic eligibility was found to have expired in December 2000. She had already completed her master's degree requirements and was scheduled to return to California in May 2001 for graduation.
Murder case.
Disappearance and search.
Levy was last seen on May 1, 2001. The Metropolitan Police Department of the District of Columbia was first alerted on May 6, when Levy's parents called from Modesto to report that they had not heard from their daughter in five days. Police called hospitals and visited Levy's apartment in Dupont Circle that day, finding no indication of foul play. On May 7, Levy's father told the police that his daughter had been having an affair with a U.S. congressman, and said the next day that he believed the congressman to be U.S. Representative Gary Condit. Levy's aunt also called the police and told them that Chandra had confided in her about the affair. Police obtained a warrant on May 10 to conduct a formal search of Levy's apartment. Investigators found her credit cards, identification and mobile phone left behind in her purse, along with partially packed suitcases. The answering machine was full, with messages left by her relatives and two from Condit. A police sergeant tried to examine Levy's laptop computer and inadvertently corrupted the internet search data, as he was not a trained technician.
Computer experts took a month to reconstruct the data to determine that the laptop was used on the morning of May 1 to search for websites related to Amtrak, Baskin-Robbins, Condit, Southwest Airlines, and a weather report from "The Washington Post". The last search at 12:24 p.m. was for the location of the Pierce-Klingle Mansion, a historic house in Rock Creek Park that is used as the park's administrative office. On July 25, 2001, three D.C. police sergeants and 28 police cadets searched along Glover Road in the park but failed to find evidence related to Levy. Later, a second attempt found nothing.
Relationship with Condit.
Controversy surrounding Levy's disappearance drew the attention of the American news media. Levy's parents and friends held numerous vigils and news conferences in an attempt to "bring Chandra home." Condit, a married man who represented the congressional district in which the Levy family resided, at first denied that he had had an affair with her. Though police stated that Condit was not a suspect, Levy's family said they felt Condit was being evasive and possibly hiding information about the matter.
Unidentified police sources alleged that Condit had admitted to an affair with Levy during an interview with law enforcement officers on July 7, 2001. Condit described her to police as a vegetarian who avoided drinking and smoking. He thought that Levy was going to return to Washington, DC after her graduation and was surprised to find out that the lease on her apartment had ended. Investigators searched Condit's apartment on July 10. They questioned flight attendant Anne Marie Smith, who claimed that Condit told her she did not need to speak to the Federal Bureau of Investigation about his personal life. Federal officials began investigating Condit for possible obstruction of justice as Smith was also involved in an affair with him. (She was not acquainted with Levy.) Upset by leaks to the media, Condit refused to submit to a polygraph test by the D.C. police; his attorney asserted that Condit passed a test administered by a privately hired examiner on July 13. He avoided answering direct questions during a televised interview on August 23, with news anchor Connie Chung on the ABC News program "Primetime Thursday". Intensive coverage continued until news of the September 11 attacks superseded the media's coverage of the Levy case.
In a nationwide Fox News/Opinion Dynamics poll of 900 registered voters conducted in July 2001, 44 percent of American respondents thought that Condit was involved in Levy's disappearance and 27 percent felt that he should resign. Fifty-one percent of the respondents believed that he was acting as if he were guilty; 13 percent felt that he should run again for office. A poll sample taken from Condit's congressional district held a more favorable view of Condit. On March 5, 2002, Condit lost the Democratic primary election for his Congressional seat to his former aide, then-Assemblyman Dennis Cardoza, with the Levy controversy being cited as a contributing factor. He was subpoenaed to appear on April 1, 2002, before a District of Columbia grand jury investigating the disappearance. The date was kept a carefully guarded secret to avoid further leaks. Condit left Congress at the end of his term on January 3, 2003.
Discovery of remains.
District of Columbia Police Chief Charles H. Ramsey announced on May 22, 2002, that skeletal remains matching Levy's dental records had been discovered by a man walking his dog and looking for turtles in Rock Creek Park. Detectives found bones and personal items scattered, but not buried, in a forested area along a steep incline. A sports bra, sweat shirt, leggings and tennis shoes were among the evidence that was recovered. Though police had previously searched over half the 1,754-acre main section of the park (2.74 mi2, 7.10 km2), the wooded slope where Levy's remains were eventually found had not been searched as it was very remote: about one mile (1.6 km) north of the Pierce-Klingle Mansion and about four miles (6 km) from Levy's apartment.
After a preliminary autopsy was performed, District of Columbia police announced that there was sufficient evidence to open a homicide investigation. On May 28, D.C. medical examiner Jonathan L. Arden officially declared Levy's death a homicide, but said, "There's less to work with here than I would like. It's possible we will never know specifically how she died." Arden found damage to her hyoid bone, suggesting possible strangulation, but did not deem it to be conclusive evidence of such a cause of death. On June 6, after the police completed their search, private investigators hired by the Levys found her shin bone with some twisted wire about from the other remains. Police chief Ramsey said, "It is unacceptable that these items were not located."
Memorial services.
On May 28, 2002, the Levy family organized a memorial service at the Modesto Centre Plaza that drew over 1,200 people, some from as far as Los Angeles. Speakers at the 90-minute ceremony included Levy's brother, grandmother, great-aunt and friends. In a eulogy delivered in Hebrew and English by Rabbi Paul Gordon, Levy was described as "a good person taken from us much too soon." About a year later, on May 27, 2003, Levy's remains were buried in Lakewood Memorial Park Cemetery at Hughson, California, near her home town of Modesto. Attended by about 40 of Levy's friends and family members, the private ceremony concluded with the release of 12 white doves.
Identification of the prime suspect.
In September 2001, D.C. police and federal prosecutors were contacted by the lawyer of an informant, held in a D.C. jail, who claimed to have knowledge of Levy's killer. The informant, whose identity was protected for his safety, said that Ingmar Guandique, a 20-year-old illegal immigrant from El Salvador also being held in the jail, told him that Condit paid him $25,000 to kill Levy. Investigators ruled out the story about Condit, because Guandique had already admitted to assaulting two other women in the same park where Levy's remains were found. Guandique failed to show up for work on the day of Levy's disappearance. His former landlady recalled that his face appeared scratched and bruised at around that time. The investigators on the Levy case did not interview the other Rock Creek Park victims. Police chief Ramsey avoided calling Guandique a suspect and described him as a "person of interest", telling reporters not to make "too big a deal" about him. Assistant chief Terrance W. Gainer said that if Guandique had been considered a suspect, D.C. police would have been after him "like flies on honey."
Guandique denied attacking Levy. On November 28, the FBI had the informant take a polygraph test, which he failed. A polygraph test on Guandique, administered on February 4, 2002, returned inconclusive results that were officially ruled "not deceptive". Because neither the informant nor Guandique was fluent in English, D.C. chief detective Jack Barrett said that he would have preferred polygraph tests to have been administered by bilingual examiners, who were unavailable at the time. When Judge Noel Anketell Kramer was asked about Guandique's potential connection to the Levy homicide, she responded, "This is such a satellite issue. To me it doesn't have anything to do with this case." Kramer sentenced Guandique to 10 years in prison for his attacks on two other women at Rock Creek Park. Guandique was sent to the U.S. Penitentiary, Big Sandy near Inez, Kentucky, and was later transferred to the U.S. Penitentiary at Victorville, California.
The Levy homicide remained listed as a "cold case" until 2006, when Cathy L. Lanier succeeded Ramsey as D.C. police chief. Lanier replaced the lead detective on the case with three veteran investigators who had more homicide experience. In 2007, the editors of "the Washington Post" assigned a new team of reporters to take a year to re-examine the Levy case. The resulting series of articles, published during the summer of 2008, focused on the past failure of the police to fully investigate Guandique's connection to the attacks in Rock Creek Park. In September 2008, investigators searched Guandique's federal prison cell in California and found a photo of Levy that he had saved from a magazine. Police interviewed acquaintances of Guandique and witnesses of the other Rock Creek Park incidents.
On March 3, 2009, the Superior Court of the District of Columbia issued an arrest warrant for Guandique. He was returned to the custody of the District of Columbia Department of Corrections on April 20 via the Federal Transfer Center in Oklahoma City. Two days later, Guandique was charged in D.C. with Levy's murder. He was indicted by a grand jury on six counts: kidnapping, first-degree murder committed during a kidnapping, attempted first-degree sexual abuse, first-degree murder committed during a sexual offense, attempted robbery, and first-degree murder committed during a robbery. Guandique pled not guilty at his arraignment, where a trial date was initially set for January 27, 2010. His lawyers argued that Guandique's federal prison cell was outside the jurisdiction of a court-ordered search. After errors in processing contaminated some of the gathered evidence with DNA from employees of the prosecution, the start date of the trial at the Moultrie Courthouse was moved to October 4, 2010.
Trial of Guandique.
On October 18, 2010, jury selection commenced in the Superior Court of the District of Columbia before Judge Gerald I. Fisher. Assistant U.S. Attorney Fernando Campoamor-Sanchez presented the names of potential witnesses for the trial, including FBI agent Brad Garrett and the two women whom Guandique was convicted of assaulting. At the start of the trial, the prosecution's case was expected to take around four weeks and the defense was expected to take one day. On October 25 and 26, Halle Shilling and Christy Wiegand testified about being attacked by Guandique while independently jogging in Rock Creek Park. Wiegand recounted that Guandique grabbed her from behind, dragged her down a ravine and held a knife against her face.
On October 26, 2010, Levy's then-64-year-old father, Robert, took the stand and refuted statements about his past suspicions of Condit. Robert Levy testified that he told authorities during the early years of the investigation that his daughter Chandra would have been too cautious to jog in the woods alone, but said that he no longer believed this to be true. He said that he also told police that his daughter and Condit had a five-year plan between them to get married. In retrospect, Robert Levy admitted: "I just said whatever came to mind just to point to him as the villain." Levy added that he had been convinced that Condit was “guilty until we learned about this character here”, referring to Guandique. On November 1, Condit testified at the trial and was asked on at least three occasions if he and Chandra Levy had been involved in a sexual relationship. He replied, "I am not going to respond to that question out of privacy for myself and Chandra." FBI biologist Alan Giusti testified that semen found on underwear from Levy's apartment contained sperm matching Condit's DNA profile.
Prosecution witness Armando Morales, who shared a cell with Guandique at the U.S. Penitentiary in Kentucky, testified that Guandique was concerned about being transferred between prisons in 2006 because of inmate violence against suspected rapists. Morales stated that Guandique, a fellow member of the Mara Salvatrucha gang, confided to him that he had killed Levy while trying to rob her, but said that he did not rape her. The prosecution rested their case on November 10, while dropping two out of the six charges against Guandique: sexual assault and murder associated with that assault. On November 15, the defense rested its case without calling Guandique to the stand. Other prison witnesses called by the defense refuted Morales' testimony. Jose Manuel Alaniz said that Guandique made no mention of rape or murder while sharing a cell with both Alaniz and Morales at the penitentiary in Kentucky. Alaniz admitted under cross-examination that he "didn't want to be too nosy" and was often asleep at the prison while recovering from a gunshot wound. The prosecution dropped two more charges because the statute of limitations had passed: kidnapping and attempted robbery. During closing arguments for the remaining charges of first-degree murder committed during a kidnapping and during a robbery, prosecutor Amanda Haines contended that Guandique bound and gagged Levy after attacking her, leaving her to die of dehydration or exposure in the park. Defense attorney Santha Sonenberg countered with the lack of any DNA evidence connecting Guandique to the crime scene. Calling the prosecution's case "fiction", Sonenberg suggested that Levy had been murdered elsewhere, with her dead body being dumped in the park.
The jury began deliberations on November 17, 2010. Scheduled proceedings of the case met delays because of increased security at the courthouse. After two days of deliberations, all but one juror had voted to convict Guandique. On the third day, the jury asked Judge Gerald Fisher to clarify the definition of assault. Fisher responded that any physical injury could legally be considered an assault, regardless of how small. On November 22, 2010, the jury found Guandique guilty of both remaining counts of first-degree murder. After the trial, a juror said the testimony of Morales was decisive in reaching the verdict. The conviction was called a "miracle" for having been reached with only circumstantial evidence. Gladys Weatherspoon, who had previously represented Guandique in the 2001 assault cases, stated that she was troubled by the jury's verdict: "I just think they were going to convict anyway... They felt bad for that woman, the mom. She's sitting in there every day." At a post-trial press conference, Susan Levy said, "There's always going to be a feeling of sadness. I can surely tell you, it ain't closure." Since the conclusion of the trial, Susan Levy has acted to keep photographic evidence of her daughter's remains sealed from the news media.
Sentencing and appeals.
On February 1, 2011, Guandique's attorneys requested a new trial on the grounds that the verdict had been improperly attained. The 17-page filing claimed that the prosecutors had appealed to the emotions of the jury, using "references to facts not in evidence." The motion also alleged that one juror, who did not take notes, had breached the judge's instructions not to be "influenced by another juror's notes." The prosecution opposed a retrial, arguing that the issue regarding the notes was no more than a technicality that did not have a significant effect on the verdict.
Guandique faced a minimum penalty of 30 years to a maximum of life imprisonment without the possibility of parole. In seeking the maximum possible sentence, the prosecutors stated that Guandique "is unable to control himself and thus, will always remain a danger to women." A memo submitted by the prosecution in February 2011 cited Guandique's harassment of female staff in prison, including soliciting a nurse and masturbating in front of guards. Assistant U.S. Attorney Fernando Campoamor-Sanchez disclosed that he had traveled to El Salvador with a detective to investigate allegations that Guandique had fled his native country because of suspected attacks against local women dating back to 1999. During the sentencing hearing on February 11, Guandique said to Levy's family, "I am sorry for what happened to your daughter," and insisted on his innocence. Before Judge Gerald Fisher reminded Susan Levy to address the court instead of the defendant, Levy said to him, "Did you really take her life? Look me in my eyes and tell me." Fisher denied Guandique's motion for retrial and handed down a sentence of 60 years in prison, stating that Guandique "will be a danger for some time. He's a sexual predator."
Guandique repeated his innocence during his sentencing. He has maintained his innocence in the years since the trial.
On February 25, 2011, public defender James Klein filed an appeal of Guandique's conviction with the District of Columbia Court of Appeals. According to the court's annual report, appeals take an average of 588 days to reach resolution. Guandique will not be eligible for parole until he is at least 80 years old. In December 2012 and January 2013, a set of secret hearings was made known to the public, but the subject of the meetings was sealed by the judge. After a third hearing in February, the judge in the case unsealed transcripts from the previous hearings which revealed that Klein was seeking a new trial based on new evidence in the case. A fourth hearing was scheduled for April 2013.
New trial ordered.
On May 22, 2015, prosecutors dropped their opposition to a new trial. On June 3, 2015, the defense said a new witness, a neighbor, called 911 at 4:37 a.m. on the last day Levy was alive to report hearing a 'blood-curdling scream', possibly coming from Levy's apartment. On June 4, 2015, Judge Gerald Fisher granted a motion for the new trial. Guandique's attorneys suggested that Morales fabricated Guandique's confession to gain favor with law enforcement. On June 12, 2015, Judge Robert E. Morin set the retrial of Guandique for March 1, 2016 but in March, the trial date was moved to October 11, 2016.
In November 2015, prosecutors told a D.C. Superior Court judge that their office failed to turn over documents to the defense before the defendant’s first trial. In December 2015, defense attorneys argued in new court filings that the charges should be dismissed because of prosecutorial errors.
Media coverage.
The disappearance of Chandra Levy became a national topic of the news media in the summer of 2001, with 63 percent of Americans closely following the case. The media swamped Levy's parents from the moment they decided to go to Washington, D.C. in search of their daughter. According to Condit, there were about a hundred reporters camped out in front of his apartment during the morning of September 11, 2001, but they all left after news spread about the terrorist attacks. Media critics and cable news executives later cited the Levy case, as well as the concurrent sensationalist coverage of a string of shark attacks, as a reflection of the manner of news coverage in the United States before the September 11 attacks had taken priority.
In 2002, D.C. newspaper "Roll Call" first reported the possible connection of Ingmar Guandique to the case, with little effect on the news media's focus on Condit. Conservative commentator Michelle Malkin noted the lack of headlines that an illegal immigrant had been questioned in the Levy case. She said that in her review of 115 news items from the Lexis-Nexis database, not a single mention of Guandique referred to his status as a "criminal illegal alien." She called the "glaring omission" of his status "a newsworthy act of negligence." She wrote that only the very conservative "Human Events" reported that the Immigration and Naturalization Service had approved his working legally while applying for temporary protected status. That application was ultimately denied, but not before he had assaulted two other women at Rock Creek Park.
In 2005, investigative journalist Dominick Dunne said on "Larry King Live" that he believed Gary Condit knew more information about the Levy case than he had been disclosing. Condit filed two lawsuits against Dunne, forcing him into an undisclosed financial settlement on one of them. In 2008, U.S. District Judge Peter Leisure dismissed the other suit that alleged slander, because "The context in which Dunne's statements were made demonstrates that they were part of a discussion about 'speculation' in the media and inaccurate media coverage."
During the summer of 2008, "The Washington Post" ran a 13-part series billed, in part, as "a tale of the tabloid and mainstream press pack journalism that helped derail the investigation." The two investigative reporters behind the "Post" series, Scott Higham and Sari Horwitz, wrote a book detailing their investigation. The book, "Finding Chandra", was published in May 2010. Commentators, including "The Washington Post" Metro reporter Robert Pierre, wrote that emphasis on a glamorous white murder victim, when "about 200 people are killed in this city every year, most of them black and male," was "absolutely absurd and dare I say, racist, at its core."
The media were criticized for their "rush to judgment" in suggesting, sometimes blatantly, that Condit was guilty of the murder, especially in the early days of the investigation. Some of the reporters camped in front of Condit's Washington apartment house were quoted as saying that they would remain there "until he resigns." When Ingmar Guandique was convicted in November 2010 of murdering Levy, Condit's lawyer Bert Fields remarked, "It's a complete vindication but that comes a little late. Who gives him his career back?"
Impact.
Levy's death has had a lasting impact, due in part to the efforts of her family and friends. Levy's disappearance came after a number of other high-profile cases that led to the creation of resources for missing young adults. For example, Levy's parents quickly turned for help to the Carole Sund/Carrington Memorial Reward Foundation, a nonprofit group that was established in Modesto after three female hikers disappeared from a 1999 trip to Yosemite National Park and were later found slain. That foundation, which offered the Levys staff support and contributed towards a cash reward for information about Chandra's disappearance, was merged into the Laci & Conner Search and Rescue Fund in 2009; Susan Levy had previously participated in the efforts to find Laci Peterson, another missing woman from Modesto. In 1997, when Kristen Modafferi mysteriously disappeared from the San Francisco Bay Area just three weeks after her 18th birthday, her parents turned to their congresswoman for help they were ineligible to receive from the National Center for Missing and Exploited Children. As a result, Congress enacted "Kristen's Law" in October 2000, which established the National Center for Missing Adults (NCMA) within the U.S. Department of Justice to coordinate such missing person cases. By the time Levy disappeared, institutions were in place to provide her family with support and to assist in a nationwide search to locate her. Although the Levy family moved quickly to mobilize all such available resources, including offering a cash reward for information, hiring their own investigators, and seeking media attention, those efforts to locate Chandra Levy or find her killer were overshadowed by the speculation surrounding her possible relationship with Condit. Susan Levy later joined with Donna Raley, the mother of another young woman who disappeared in 1999 from Modesto, to form "Wings of Protection", a support group for people with missing loved ones. The Mary Ann Liebert company, publishers of the "Journal of Women's Health and Gender-Based Medicine", presented their annual Criterion Award in May 2002 to Susan Levy for her work with "Wings of Protection."
"Newsweek" magazine stated that the media may have become more skeptical of "herd mentality" and open to alternative suspects after the Levy case. The D.C. police claimed that they would have discovered Levy's body earlier, if not for a miscommunication regarding the scope of the search. Commanders had ordered a search within of each road and trail in Rock Creek Park, but searches were focused within 100 yards of roads only, resulting in the body remaining undiscovered for a longer period of time. Both the Chief of Detectives, Jack Barrett, and the Chief of Police, Charles H. Ramsey, have since left the force in D.C. Ramsey became head of the Philadelphia Police Department; Barrett, who became an analyst for an intelligence support firm in Arlington, Virginia, stated in hindsight that the media had imposed "enormous amounts of pressure" on the D.C. police. Morales, who is serving time for conspiracy to distribute methamphetamine and crack cocaine, is scheduled to be released on August 5, 2016. Condit retired from politics and moved with his wife to Phoenix, Arizona, to manage real estate and open two Baskin-Robbins franchises, which have since closed.

</doc>
<doc id="53014" url="https://en.wikipedia.org/wiki?curid=53014" title="List of Spanish monarchs">
List of Spanish monarchs

This is a list of Spanish monarchs, that is, rulers of the country of Spain in the modern sense of the word. The forerunners of the monarchs of the Spanish throne were the following:
These seven lineages were eventually united by the marriage of the Catholic Monarchs, Ferdinand II of Aragon (king of the Crown of Aragon) and Isabella I of Castile (queen of the Crown of Castile). Although their kingdoms continued to be separate, with their personal union they ruled them together as one dominion. Ferdinand also conquered the southern part of Navarre and annexed it to what was to become Spain. Isabella left her kingdom to her daughter Joanna of Castile. Ferdinand served as her regent during her insanity; though rebuffed by the Castilian nobility and replaced by Joanna's husband Philip the Handsome, he resumed his regency after Philip's death. In 1516, after Ferdinand II's death, his daughter Joanna inherited the kingdom of Aragon, but was kept prisoner at Tordesillas as insane. As Joanna's son, the future Holy Roman Emperor Charles V, did not want to be merely a regent, he was proclaimed king of Castile and Aragon jointly with his mother in Brussels. Subsequently, Castilian and Aragonese "Cortes" alleged oath to him as co-king with his mother. Upon her death, he became sole King of Castile and Aragon, and the thrones were thereafter united permanently.
Kingdom of Spain (1479–1873).
House of Trastámara (1479–1555).
Under Isabella and Ferdinand, the royal dynasties of Aragon and Castile were united into a single line. Historiography of Spain generally treats this as the formation of the Kingdom of Spain, but in actuality, the two kingdoms continued for many centuries with their own separate institutions. It wasn't until the Nueva Planta decrees of the early 18th century that the two lands were formally merged into a single state.
House of Habsburg (1516–1700).
Under Joanna and Charles I, the two thrones of Castile and Aragon were finally united under one monarch. Traditional numbering of monarchs follows the Castillian crown; i.e. after King Ferdinand (II of Aragon and V of Castile "jure uxoris" as husband of Queen of Castille Isabella I), the next Ferdinand was numbered VI. Likewise, Alfonso XII takes his number following that of Alfonso XI of Castile rather than that of Alfonso V of Aragon, the prior Spanish monarchs with that name.
House of Bourbon (1700–1808).
In the year 1700 Charles II died. Charles' will named the 16-year-old Philip, the grandson of Charles' sister Maria Theresa of Spain, as his successor. Upon any possible refusal the Crown of Spain would be offered next to Philip's younger brother Charles, Duke of Berry, or, next, to Archduke Charles of Austria.
Both claimants, Philip and Charles, had a legal right to the Spanish throne due to the fact that Philip's grandfather, King Louis XIV of France and Charles's father, Leopold I, Holy Roman Emperor, were sons of Charles' aunts, Anne and Maria Anna. Philip had the better claim because his grandmother and great-grandmother were older than Leopold's. However, the Austrian branch claimed that Philip's grandmother had renounced the Spanish throne for herself and her descendants as part of her marriage contract. This was countered by the French branch's claim that it was on the basis of a dowry that had never been paid.
After a long council meeting where the Dauphin spoke up in favour of his son's rights, it was agreed that Philip would ascend the throne. Following this, a war broke out and Archduke Charles was also proclaimed king of Spain, as "Charles III" in opposition to Philip V. He was proclaimed in Vienna, and also in Madrid in the years 1706 and 1710. Charles renounced his claims to the Spanish throne in the Treaty of Rastatt of 1714, but was allowed the continued use of the styles of a Spanish monarch for his lifetime.
House of Bonaparte (1808–1813).
The only monarch from this dynasty was Joseph I, imposed by his brother Napoleon I of France after Charles IV and Ferdinand VII had abdicated. The title used by Joseph I was "King of the Spains and the Indias, by the Grace of God and the Constitution of the State". He was also later given all of the titles of the previous kings. A government in opposition to the French was formed in Cádiz on 25 September 1808, which continued to recognize the imprisoned Ferdinand VII as king. This government was diplomatically recognized as the legitimate Spanish government by Britain and other countries at war with France.
House of Bourbon (1813–1868).
Charles IV's eldest son was restored to the throne. Again the title used was "king of Castile, Leon, Aragon,… by the Grace of God".
House of Savoy (1870–1873).
After the Spanish Revolution of 1868 deposed Isabella II, there was established a provisional government and a regency headed by Francisco Serrano y Domínguez from October 8, 1868 until January 2, 1871, while a new monarch was sought. Amadeo was elected as king and the new title used was "King of Spain, by the Grace of God and will of the nation".
Kingdom of Spain (1874–1931).
House of Bourbon (1874–1931).
Isabella II's eldest son was restored to the throne as she had abdicated in his favour in 1870. "Constitutional King of Spain".
Spanish State (1936–1975).
On 1 October 1936 General Francisco Franco was proclaimed Leader of Spain (Spanish: "Caudillo de España") in the parts of Spain controlled by the Nationalists ("nacionales") after the Spanish Civil War broke out. At the end of the war on 1 April 1939 General Franco took control of the whole of Spain. In 1947, Franco proclaimed the restoration of the monarchy but did not allow the pretender, Juan, Count of Barcelona, to take the throne. In 1969, Franco declared that Juan Carlos, Prince of Spain, the Count of Barcelona's son, would be his successor. After Franco's death in 1975, Juan Carlos succeeded him as the King of Spain.
Kingdom of Spain (1975–present).
House of Bourbon (1975–present).
Alfonso XIII's claim descended (due to his two eldest sons' renunciations) to his third son, Juan of Bourbon, Count of Barcelona, who was passed over in favour of his eldest son, whose title is "King of Spain". The Count of Barcelona renounced his claims in favour of his son in 1977, two years after Franco's death and Juan Carlos's accession.
Juan Carlos abdicated in favor of his son Felipe VI, who became King on 19 June 2014, with Felipe's older daughter, Leonor, next in succession. 

</doc>
<doc id="53015" url="https://en.wikipedia.org/wiki?curid=53015" title="Sturgeon's law">
Sturgeon's law

Sturgeon's revelation, commonly referred to as Sturgeon's law, is an adage commonly cited as "ninety percent of everything is crap". It is derived from quotations by Theodore Sturgeon, an American science fiction author and critic; while Sturgeon coined another adage that he termed "Sturgeon's law", it is his "revelation" that is usually referred to by that term.
The phrase was derived from Sturgeon's observation that while science fiction was often derided for its low quality by critics, it could be noted that the majority of examples of works in other fields could equally be seen to be of low quality and that science fiction was thus no different in that regard from other art forms.
History.
One of the earliest formulations of a similar principle is the saying attributed to Euripides, "Man's most valuable trait is a judicious sense of what not to believe."
A similar adage appears in Rudyard Kipling's "The Light that Failed", published in 1890. "Four–fifths of everybody's work must be bad. But the remnant is worth the trouble for its own sake."
The first written reference to the adage appears in the March 1958 issue of "Venture", where Sturgeon wrote:
I repeat Sturgeon's Revelation, which was wrung out of me after twenty years of wearying defense of science fiction against attacks of people who used the worst examples of the field for ammunition, and whose conclusion was that ninety percent of SF is crud. Using the same standards that categorize 90% of science fiction as trash, crud, or crap, it can be argued that 90% of film, literature, consumer goods, etc. is crap. In other words, the claim (or fact) that 90% of science fiction is crap is ultimately uninformative, because science fiction conforms to the same trends of quality as all other artforms.
According to Philip Klass (William Tenn), Sturgeon made this remark circa 1951, at a talk at New York University attended by Tenn. The statement was subsequently included in a talk Sturgeon gave at a 1953 Labor Day weekend session of the World Science Fiction Convention in Philadelphia.
In 2013, philosopher Daniel Dennett championed Sturgeon's Law as one of his seven tools for critical thinking. "90% of everything is crap. That is true, whether you are talking about physics, chemistry, evolutionary psychology, sociology, medicine—you name it—rock music, country western. 90% of everything is crap." Its re-introduction to a modern audience received a positive reception, according to Dennett.
Sturgeon's revelation.
Sturgeon had originally deemed Sturgeon's Law to mean that "nothing is always absolutely so" in the story "The Claustrophile" in a 1956 issue of "Galaxy". The second adage, variously rendered as "ninety percent of everything is crud" or "ninety percent of everything is crap", was originally known as "Sturgeon's Revelation", formulated as such in his book review column for "Venture" in 1957. However, almost all modern uses of the term Sturgeon's Law actually refer to the second, including the definition listed in the "Oxford English Dictionary".

</doc>
<doc id="53016" url="https://en.wikipedia.org/wiki?curid=53016" title="Screenwriter">
Screenwriter

A screenplay writer, screenwriter for short, scriptwriter or scenarist is a writer who practices the craft of screenwriting, writing screenplays on which mass media such as films, television programs, comics or video games are based.
Profession.
Screenwriting is a freelance profession. No education is required to become a professional screenwriter, just good storytelling abilities and imagination. Screenwriters are not hired employees, they are contracted freelancers. Most, if not all, screenwriters start their careers writing on speculation (spec), meaning they write without being hired or paid for it. If such a script is sold, it is called a spec script. What separates a professional screenwriter from an amateur screenwriter is that professional screenwriters are usually represented by a talent agency. Also, professional screenwriters do not often work for free; whereas amateur screenwriters will often work for free and are considered "writers in training". Spec scripts are usually penned by unknown professional screenwriters and amateur screenwriters. There are a legion of would-be screenwriters who attempt to enter the film industry but it often takes years of trial-and-error, failure, and gritty persistence to achieve success. In "Writing Screenplays that Sell", Michael Hague writes "Screenplays have become, for the last half of twentieth century, what the Great American Novel was for the first half. Closet writers who used to dream of the glory of getting into print now dream of seeing their story on the big or small screen."
Screenwriting in the film industry.
Every screenplay and teleplay begins with a thought or idea, and screenwriters use those ideas to write scripts, with the intention of selling them and having them produced. In some cases, the script is based on an existing property, such as a book or person's life story, which is adapted by the screenwriter. The majority of the time, a film project gets initiated by a screenwriter and because they initiated the project, the writing assignment exclusively becomes his or hers. These are referred to as "exclusive" assignments or "pitched" assignments. Screenwriters who often pitch new projects, whether original or an adaptation, often do not have to worry about competing for assignments and are often more successful. When word is put out about a project a film studio, production company, or producer wants done, these are referred to as "open" assignments. Open assignments are more competitive. In situations where screenwriters are competing for an open assignment, more established writers will usually win these assignments. A screenwriter can also be approached and personally offered a writing assignment.
Script doctoring.
Many screenwriters also work as full or part-time "script doctors", attempting to better a script to suit the desires of a director or studio. For instance, studio management may have a complaint that the motivations of the characters are unclear or that the dialogue is weak.
Script-doctoring can be quite lucrative, especially for the better known writers. David Mamet and John Sayles, for instance, fund the movies they direct themselves, usually from their own screenplays, by writing and doctoring scripts for others. In fact, some writers make very profitable careers out of being the ninth or tenth writer to work on a piece; in many cases, working on projects that never see exposure to an audience of any size. Many up and coming screenwriters also "ghost write" projects and allow more established screenwriters to take public credit for the project to increase the chances of it getting picked up.
Development process of a project.
After a screenwriter finishes a project, he or she pairs with an industry-based representative, such as a producer, director, literary agent, entertainment lawyer, or an entertainment executive. These partnerships will often pitch their project to investors or others in a position to further a project. Once the script is sold the writer only has the rights that were agreed with the purchaser. A screenwriter becomes credible once their work is recognized, giving the writer the opportunity to earn a higher income. As more films are produced independently (outside the studio system), many up-and-coming screenwriters are turning to pitch fests, screenplay contests and independent development services to gain access to established and credible independent producers. Many development executives are now working independently in order to incubate their own pet projects.
Production involvement.
Screenwriters are rarely involved in the development of a film. Sometimes they come on as advisors, or if they are established, as a producer. Some screenwriters also direct. Although many scripts are sold each year, many do not make it into production because the number of scripts that are purchased every year exceeds the number of professional directors that are working in the film and TV industry. When a screenwriter finishes a project and sells it to a film studio, production company, TV network, or producer, he or she often has to continue networking, mainly with directors or executives, and push to have their projects "chosen" and turned into films or TV shows. If interest in a script begins to fade, a project can go dead.
Union.
Most professional screenwriters in the U.S. are unionized and are represented by the Writers Guild of America. Although membership in the WGA is recommended, it is not required of a screenwriter to join. The WGA is the final arbiter on awarding writing credit for projects under its jurisdiction. The WGA also looks upon and verifies film copyright materials.

</doc>
<doc id="53017" url="https://en.wikipedia.org/wiki?curid=53017" title="Special effect">
Special effect

The illusions or tricks of the eye used in the film, television, theatre, video game, and simulator industries to simulate the imagined events in a story or virtual world are traditionally called special effects (often abbreviated as SFX, SPFX, or simply FX).
Special effects are traditionally divided into the categories of optical effects and mechanical effects. With the emergence of digital filmmaking a distinction between special effects and visual effects has grown, with the latter referring to digital post-production while "special effects" referring to mechanical and optical effects.
Mechanical effects (also called practical or physical effects) are usually accomplished during the live-action shooting. This includes the use of mechanized props, scenery, scale models, animatronics, pyrotechnics and atmospheric effects: creating physical wind, rain, fog, snow, clouds, etc. Making a car appear to drive by itself and blowing up a building are examples of mechanical effects. Mechanical effects are often incorporated into set design and makeup. For example, a set may be built with break-away doors or walls to enhance a fight scene, or prosthetic makeup can be used to make an actor look like a non-human creature.
Optical effects (also called photographic effects) are techniques in which images or film frames are created photographically, either "in-camera" using multiple exposure, mattes, or the Schüfftan process, or in post-production using an optical printer. An optical effect might be used to place actors or sets against a different background.
Since the 1990s, computer generated imagery (CGI) has come to the forefront of special effects technologies. It gives filmmakers greater control, and allows many effects to be accomplished more safely and convincingly and—as technology improves—at lower costs. As a result, many optical and mechanical effects techniques have been superseded by CGI.
Developmental history.
Early development.
In 1856, Oscar Rejlander created the world's first "trick photograph" by combining different sections of 30 negatives into a single image. In 1895, Alfred Clark created what is commonly accepted as the first-ever motion picture special effect. While filming a reenactment of the beheading of Mary, Queen of Scots, Clark instructed an actor to step up to the block in Mary's costume. As the executioner brought the axe above his head, Clark stopped the camera, had all of the actors freeze, and had the person playing Mary step off the set. He placed a Mary dummy in the actor's place, restarted filming, and allowed the executioner to bring the axe down, severing the dummy's head. "Such… techniques would remain at the heart of special effects production for the next century."
Not only the first use of trickery in the cinema, it was the first type of photographic trickery only possible in a motion picture, i.e. the "stop trick".
In 1896, French magician Georges Méliès accidentally discovered the same "stop trick." According to Méliès, his camera jammed while filming a street scene in Paris. When he screened the film, he found that the "stop trick" had caused a truck to turn into a hearse, pedestrians to change direction, and men turn into women. Méliès, the stage manager at the Theatre Robert-Houdin, was inspired to develop a series of more than 500 short films, between 1914, in the process developing or inventing such techniques as multiple exposures, time-lapse photography, dissolves, and hand painted colour. Because of his ability to seemingly manipulate and transform reality with the cinematograph, the prolific Méliès is sometimes referred to as the "Cinemagician." His most famous film, "Le Voyage dans la lune" (1902), a whimsical parody of Jules Verne's "From the Earth to the Moon", featured a combination of live action and animation, and also incorporated extensive miniature and matte painting work.
From 1910 to 1920, the main innovations in special effects were the improvements on the matte shot by Norman Dawn. With the original matte shot, pieces of cardboard were placed to block the exposure of the film, which would be exposed later. Dawn combined this technique with the "glass shot." Rather than using cardboard to block certain areas of the film exposure, Dawn simply painted certain areas black to prevent any light from exposing the film. From the partially exposed film, a single frame is then projected onto an easel, where the matte is then drawn. By creating the matte from an image directly from the film, it became incredibly easy to paint an image with proper respect to scale and perspective (the main flaw of the glass shot). Dawn's technique became the textbook for matte shots due to the natural images it created.(Baker, 101-4
During the 1920s and 30s, special effects techniques were improved and refined by the motion picture industry. Many techniques—such as the Schüfftan process—were modifications of illusions from the theater (such as pepper's ghost) and still photography (such as double exposure and matte compositing). Rear projection was a refinement of the use of painted backgrounds in the theater, substituting moving pictures to create moving backgrounds. Lifecasting of faces was imported from traditional maskmaking. Along with makeup advances, fantastic masks could be created which fit the actor perfectly. As material science advanced, horror film maskmaking followed closely.
Several techniques soon developed, such as the "stop trick", wholly original to motion pictures. Animation, creating the illusion of motion, was accomplished with drawings (most notably by Winsor McCay in "Gertie the Dinosaur") and with three-dimensional models (most notably by Willis O'Brien in "The Lost World" and "King Kong"). Many studios established in-house "special effects" departments, which were responsible for nearly all optical and mechanical aspects of motion-picture trickery.
Also, the challenge of simulating spectacle in motion encouraged the development of the use of miniatures. Naval battles could be depicted with models in studio. Tanks and airplanes could be flown (and crashed) without risk of life and limb. Most impressively, miniatures and matte paintings could be used to depict worlds that never existed. Fritz Lang's film "Metropolis" was an early special effects spectacular, with innovative use of miniatures, matte paintings, the Schüfftan process, and complex compositing.
An important innovation in special-effects photography was the development of the optical printer. Essentially, an optical printer is a projector aiming into a camera lens, and it was developed to make copies of films for distribution. Until Linwood G. Dunn refined the design and use of the optical printer, effects shots were accomplished as in-camera effects. Dunn demonstrating that it could be used to combine images in novel ways and create new illusions. One early showcase for Dunn was Orson Welles' "Citizen Kane", where such locations as Xanadu (and some of Gregg Toland's famous 'deep focus' shots) were essentially created by Dunn's optical printer.
Color Era.
The development of color photography required greater refinement of effects techniques. Color enabled the development of such "travelling matte" techniques as bluescreen and the sodium vapour process. Many films became landmarks in special-effects accomplishments: "Forbidden Planet" used matte paintings, animation, and miniature work to create spectacular alien environments. In "The Ten Commandments", Paramount's John P. Fulton, A.S.C., multiplied the crowds of extras in the Exodus scenes with careful compositing, depicted the massive constructions of Rameses with models, and split the Red Sea in a still-impressive combination of travelling mattes and water tanks. Ray Harryhausen extended the art of stop-motion animation with his special techniques of compositing to create spectacular fantasy adventures such as Jason and the Argonauts (whose climax, a sword battle with seven animated skeletons, is considered a landmark in special effects).
The science fiction boom.
Through the 1950s and 60s numerous new special effects were developed which would dramatically increase the level of realism achievable in science fiction films. The pioneering work of directors such as Pavel Klushantsev would be used by major motion pictures for decades to come.
If one film could be said to have established a new high-bench mark for special effects, it would be 1968's "", directed by Stanley Kubrick, who assembled his own effects team (Douglas Trumbull, Tom Howard, Con Pedersen and Wally Veevers) rather than use an in-house effects unit. In this film, the spaceship miniatures were highly detailed and carefully photographed for a realistic depth of field. The shots of spaceships were combined through hand-drawn rotoscopes and careful motion-control work, ensuring that the elements were precisely combined in the camera – a surprising throwback to the silent era, but with spectacular results. Backgrounds of the African vistas in the "Dawn of Man" sequence were combined with soundstage photography via the then-new front projection technique. Scenes set in zero-gravity environments were staged with hidden wires, mirror shots, and large-scale rotating sets. The finale, a voyage through hallucinogenic scenery, was created by Douglas Trumbull using a new technique termed slit-scan.
The 1970s provided two profound changes in the special effects trade. The first was economic: during the industry's recession in the late 1960s and early 1970s, many studios closed down their in-house effects houses. Many technicians became freelancers or founded their own effects companies, sometimes specializing on particular techniques (opticals, animation, etc.).
The second was precipitated by the blockbuster success of two science fiction and fantasy films in 1977. George Lucas's "Star Wars" ushered in an era of science-fiction films with expensive and impressive special-effects. Effects supervisor John Dykstra, A.S.C. and crew developed many improvements in existing effects technology. They developed a computer-controlled camera rig called the "Dykstraflex" that allowed precise repeatability of camera motion, greatly facilitating travelling-matte compositing. Degradation of film images during compositing was minimized by other innovations: the Dykstraflex used VistaVision cameras that photographed widescreen images horizontally along stock, using far more of the film per frame, and thinner-emulsion filmstocks were used in the compositing process. The effects crew assembled by Lucas and Dykstra was dubbed Industrial Light and Magic, and since 1977 has spearheaded most effects innovations.
That same year, Steven Spielberg's film "Close Encounters of the Third Kind" boasted a finale with impressive special effects by "" veteran Douglas Trumbull. In addition to developing his own motion-control system, Trumbull also developed techniques for creating intentional "lens flare" (the shapes created by light reflecting in camera lenses) to provide the film's undefinable shapes of flying saucers.
The success of these films, and others since, has prompted massive studio investment in effects-heavy science-fiction films. This has fueled the establishment of many independent effects houses, a tremendous degree of refinement of existing techniques, and the development of new techniques such as CGI. It has also encouraged within the industry a greater distinction between special effects and visual effects; the latter is used to characterize post-production and optical work, while "special effects" refers more often to on-set and mechanical effects.
Introduction of computer generated imagery (CGI).
A recent and profound innovation in special effects has been the development of computer generated imagery, or CGI which has changed nearly every aspect of motion picture special effects. Digital compositing allows far more control and creative freedom than optical compositing, and does not degrade the image like analog (optical) processes. Digital imagery has enabled technicians to create detailed models, matte "paintings," and even fully realized characters with the malleability of computer software.
Arguably the biggest and most "spectacular" use of CGI is in the creation of photo-realistic images of science-fiction and fantasy characters, settings, and objects. Images can be created in a computer using the techniques of animated cartoons and model animation. In 1993, stop-motion animators working on the realistic dinosaurs of Steven Spielberg's "Jurassic Park" were retrained in the use of computer input devices. By 1995, films such as "Toy Story" underscored that the distinction between live-action films and animated films was no longer clear. Other landmark examples include a character made up of broken pieces of a stained-glass window in "Young Sherlock Holmes", a shapeshifting character in "Willow", a tentacle of water in "The Abyss", the T-1000 Terminator in "", hordes of armies of robots and fantastic creatures in the "Star Wars prequel trilogy" and "The Lord of the Rings" trilogy and the planet Pandora in "Avatar".
Planning and use.
Although most special effects work is completed during post-production, it must be carefully planned and choreographed in pre-production and production. A Visual effects supervisor is usually involved with the production from an early stage to work closely with the Director and all related personnel to achieve the desired effects.
Live special effects.
Live special effects are effects that are used in front of a live audience, mostly during sporting events, concerts and corporate shows. Types of effects that are commonly used include: flying effects, laser lighting, Theatrical smoke and fog, CO2 effects, pyrotechnics, confetti and other atmospheric effects such as bubbles and snow.

</doc>
<doc id="53027" url="https://en.wikipedia.org/wiki?curid=53027" title="Supergroup (music)">
Supergroup (music)

A supergroup is a music group whose members are already successful as solo artists or as part of other groups or well known in other musical professions. Usually used in the context of rock and pop music, the term has been applied to other musical genres such as The Three Tenors in opera.
The term is sometimes applied retrospectively when several members from a group later achieve notable success in their own right. Supergroups are sometimes formed as side projects and thus not intended to be permanent, while other times can become the primary project of the members' careers. Charity supergroups, where prominent musicians perform or record together in support of a particular cause, have been common since the 1980s.
History.
It became popular in late 1960s rock music for members of already successful groups to record an album together, after which they normally split up. In 1969, "Rolling Stone" editor Jann Wenner credited Cream with being the first supergroup and they are still widely recognised as the archetype of the short-lived rock supergroup. Cream comprised Eric Clapton, Jack Bruce and Ginger Baker who, after three years and four albums, split up. Guitarist Clapton and drummer Baker went on to form Blind Faith, another blues rock supergroup which recruited former Spencer Davis Group and Traffic singer Steve Winwood and Family bassist Ric Grech. The group recorded one studio album before dissipating less than a year after formation.
The term may have come from the 1968 album "Super Session" with Al Kooper, Mike Bloomfield, and Stephen Stills. The coalition of Crosby, Stills & Nash (later Crosby, Stills, Nash & Young) is another early example, given the success of their prior bands (The Byrds, Buffalo Springfield, and The Hollies respectively).
Criticism.
In 1974, a "Time" magazine article entitled "Return of a Supergroup" quipped that the supergroup was a "potent but short-lived rock phenomenon" which was an "amalgam formed by the talented malcontents of other bands." The article acknowledged that groups such as Cream and Blind Faith "played enormous arenas and made megabucks, and sometimes megamusic", with the performances "fueled by dueling egos." However, while this "musical infighting built up the excitement ... it also made breakups inevitable."

</doc>
