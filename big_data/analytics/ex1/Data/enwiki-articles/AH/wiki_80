<doc id="54184" url="https://en.wikipedia.org/wiki?curid=54184" title="Pudelpointer">
Pudelpointer

The Pudelpointer is a versatile hunting dog breed from Germany. It is a pointing breed that came from a cross between the German hunting poodle (pudel) and the English Pointer.
Appearance.
The breed weighs between , stands at the shoulder, and comes in liver, chestnut, and occasionally black coats. The ideal coat is harsh, wiry, and dense. The dogs shed very little.
History.
In 1881, a German breeder, Baron von Zedlitz, worked on producing his ideal tracking, pointing, and retrieving gun dog, suitable for work on both land and water. From seven specific Poodles and nearly 100 different pointers, he developed the Pudelpointer. The original sire was Tell, an English Pointer belonging to Kaiser Frederick III and the original dam was a German hunting pudel named Molly who was owned by Hegewald, an author known for works on hunting dogs.
The goal was to produce a dog that was willing and easy to train, intelligent, and loved water and retrieving, like the poodle, and add to that a great desire to hunt, a strong pointing instinct, and an excellent nose, like in the English Pointer, as well as being an excellent companion in the home.
The Poodle breed had much stronger genes, and so many more Pointers were used to achieve the balanced hunting dog that was desired. A mix of 11 Pudels and 80 Pointers were used during the first 30 years to achieve the desired traits and results.
The breed was introduced to North America in 1956 by Bodo Winterhelt, who to this day, remains very involved in maintaining the breed standard. His Winterhelle Kennel was the foundation of the breed in North America. In 1977 Winterhelt founded the Pudelpointer Club of North America in Canada.
In Germany as well as North America, its performance standards are its most important trait. Before being approved for breeding, dogs and bitches must pass Hunt Test with minimum scores of their performance tests of its field, tracking, and water skills set by the various breed clubs. These clubs are the Verein Pudelpointer in Germany and the following clubs in North America: NAPPA, PCNA and VPP-GNA). The North American Versatile Hunting Dog Association (NAVHDA) also tests pudelpointers and other breeds of versatile hunting dogs. 
The pudelpointer has never become a popularized breed in the United States in part because breeders have actively avoided recognition by the American Kennel Club. Breeders believe that AKC recognition would place too much emphasis on form over function, possibly splitting the breed into a show breed and separate working class.

</doc>
<doc id="54188" url="https://en.wikipedia.org/wiki?curid=54188" title="Libero Liberati">
Libero Liberati

Libero Liberati (20 September 1926 – 5 March 1962) was an Italian motorcycle racer and the 1957 500cc Grand Prix World Champion.
Liberati was born in Terni. He became famous in his country, winning the Italian championship in 1948. Two years later Moto Guzzi called him to race in the 500cc World Championship, where he took part in a single race. The same happened the following year with Gilera. Liberati scored his first points in the World Championship in 1953, and his first race victory came in 1956 in the 350cc class.
In 1957, Liberati won the 500cc World Championship, scoring a total of four victories. He also won a race in the 350cc class. However, at the end of the season, a dispute with the Gilera factory left him without a ride. Two years later Moto Morini gave him the opportunity to race again, this time in the 250cc class.
Motorcycle Grand Prix results.
Points system from 1950 to 1968:

</doc>
<doc id="54189" url="https://en.wikipedia.org/wiki?curid=54189" title="Surrealist automatism">
Surrealist automatism

Automatism has taken on many forms: the automatic writing and drawing initially (and still to this day) explored by the surrealists can be compared to similar or parallel phenomena, such as the non-idiomatic improvisation.
Surrealist automatism is different from mediumistic automatism, from which the term was inspired. Ghosts, spirits or the like are not purported to be the source of surrealist automatic messages.
Origins.
"Pure psychic automatism" was how André Breton defined surrealism, and while the definition has proved capable of significant expansion, automatism remains of prime importance in the movement.
In 1919 Breton and Philippe Soupault wrote the first automatic book, "Les Champs Magnétiques", while "The Automatic Message" (1933) was one of Breton's significant theoretical works about automatism.
The notion of automatism is also rooted in the artistic movement of the same name founded by Montreal artist Paul-Emile Borduas in 1942; himself influenced by the Dadaist movement as well as André Breton. He, as well as a dozen other artists from Quebec's artistic scene, very much under restrictive and authoritarian rule in that period, signed the "Global Refusal" manifesto, in which the artists called upon North American society (specifically in the culturally unique environment of Quebec), to take notice and act upon the societal evolution projected by these new cultural paradigms opened by the Automatist movement as well as other influences in the 1940s.
Surautomatism.
Some Romanian surrealists invented a number of surrealist techniques (such as cubomania, entoptic graphomania, and the movement of liquid down a vertical surface) that purported to take automatism to an absurd point, and the name given, "surautomatism", implies that the methods "go beyond" automatism, but this position is controversial.
Automatic drawing.
Automatic drawing (distinguished from drawn expression of mediums) was developed by the surrealists, as a means of expressing the subconscious. In automatic drawing, the hand is allowed to move 'randomly' across the paper. In applying chance and accident to mark-making, drawing is to a large extent freed of rational control. Hence the drawing produced may be attributed in part to the subconscious and may reveal something of the psyche, which would otherwise be repressed. Examples of automatic drawing were produced by mediums and practitioners of the psychic arts. It was thought by some Spiritualists to be a spirit control that was producing the drawing while physically taking control of the medium's body.
Automatic drawing was pioneered by André Masson. Artists who practised automatic drawing include Joan Miró, Salvador Dalí, Jean Arp and André Breton. The technique was transferred to painting (as seen in Miró's paintings which often started out as automatic drawings), and has been adapted to other media; there have even been automatic "drawings" in computer graphics. Pablo Picasso was also thought to have expressed a type of automatic drawing in his later work, and particularly in his etchings and lithographic suites of the 1960s.
Most of the surrealists' automatic drawings were illusionistic, or more precisely, they developed into such drawings when representational forms seemed to suggest themselves. In the 1940s and 1950s the French-Canadian group called Les Automatistes pursued creative work (chiefly painting) based on surrealist principles. They abandoned any trace of representation in their use of automatic drawing. This is perhaps a more pure form of automatic drawing since it can be almost entirely involuntary - to develop a representational form requires the conscious mind to take over the process of drawing, unless it is entirely accidental and thus incidental. These artists, led by Paul-Emile Borduas, sought to proclaim an entity of universal values and ethics proclaimed in their manifesto "Refus Global".
As alluded to above, surrealist artists often found that their use of 'automatic drawing' was not entirely automatic, rather it involved some form of conscious intervention to make the image or painting visually acceptable or comprehensible, "...Masson admitted that his 'automatic' imagery involved a two-fold process of unconscious and conscious activity..."
Contemporary techniques.
The computer, like the typewriter, can be used to produce automatic writing and automatic poetry. The practice of automatic drawing, originally performed with pencil or pen and paper, has also been adapted to mouse and monitor, and other automatic methods have also been either adapted from non-digital media, or invented specifically for the computer. For instance, filters have been automatically run in some bitmap editor programs such as Photoshop and GIMP, and computer-controlled brushes have been used to "simulate" automatism.
Grandview — a software application created in 2011 for the Mac — displays one word at a time across the entire screen as a user types, facilitating automatic writing.

</doc>
<doc id="54193" url="https://en.wikipedia.org/wiki?curid=54193" title="Belgian euro coins">
Belgian euro coins

Belgian euro coins feature only a single design for all eight coins: the portrait or effigy of the incumbent King of the Belgians. Previously, all Belgian euros depicted King Albert II of the Belgians and his royal monogram. Current coins depict King Philippe. Also part of the design by Jan Alfons Keustermans are the 12 stars of the EU and the year of imprint.
Belgian euro design.
For images of the common side and a detailed description of the coins, see euro coins.
In Belgium, the euro was introduced in 2002. However, the first sets of coins were minted, as preparation, in 1999. Hence the first euro coins of Belgium are marked 1999, not 2002.
Reign of Albert II.
First series (1999–2007).
Belgian euro coins dated 1999–2007 have the portrait of King Albert II.
Second series (2008).
In order to conform to the common guidelines on the design of national faces of coins, Belgium updated the design of the Belgian national face of euro coins to be produced from 2008. Coins from previous years featuring the old Belgian national face remain valid.
The changes are:
As from 2007, the Belgian euro coins also adopted the new common map like the rest of the eurozone countries. A proportion of the Belgian 2 euro coins -common part, the map looks smooth, whereas, the same map on the euros coming from other eurozone countries is dotted.
Belgium is the second state in the EMU, after Finland, to, from 2008 on, change the design of their standard circulation euro coins in accordance with recommendations defined by the Economic and Financial Affairs Council of the European Union.
Amendment (2009-2013).
The 2008 portrait did not comply with previous decisions by the ECOFIN in 2005 and 2008. Therefore, an amendment was made, which reverted to the portrait of Albert II found in the 2002 series. Mint marks, year and stars remain the same. Some collectors consider this as a third series but since unlike all series it was not published in the official journal of the European Union, it is actually an amendment and not a new series.
Reign of Philippe.
Third series (2014-present).
Following the coronation of King Philippe after the abdication of Albert II, new distinctive sides were added depicting the new monarch.
Coins with the new obverse were struck from 4 February 2014. The obverses were designed by Luc Luycx.
Circulating Mintage quantities.
The following table shows the mintage quantity for all Belgian euro coins, per denomination, per year (the numbers are represented in millions).
Belgian proof set.
Each year the Royal Belgian Mint issues a limited edition of its euro coins in proof quality.
Other commemorative coins (collectors' coins).
Belgium has a good collection of euro commemorative coins, solely in silver and gold. Their face values range from 10 euros to 100 euros. This is mainly done as a legacy of old national practice of minting gold and silver coins. These coins are not really intended to be used as means of payment, so generally they do not circulate.

</doc>
<doc id="54195" url="https://en.wikipedia.org/wiki?curid=54195" title="Stingray">
Stingray

Stingrays" are a group of rays, which are cartilaginous fish related to sharks. They are classified in the suborder Myliobatoidei"' of the order Myliobatiformes and consist of eight families: Hexatrygonidae (sixgill stingray), Plesiobatidae (deep water stingray), Urolophidae (stingarees), Urotrygonidae (round rays), Dasyatidae (whiptail stingrays), Potamotrygonidae (river stingrays), Gymnuridae (butterfly rays), and Myliobatidae (eagle rays).
Most stingrays have one or more barbed stingers (modified from dermal denticles) on the tail, which are used exclusively in self-defense. The stinger may reach a length of approximately , and its underside has two grooves with venom glands. The stinger is covered with a thin layer of skin, the integumentary sheath, in which the venom is concentrated. A few members of the suborder, such as the manta and porcupine rays, do not have stingers.
Stingrays are common in coastal tropical and subtropical marine waters throughout the world. Some species, such as "Dasyatis thetidis", are found in warmer temperate oceans, and others, such as "Plesiobatis daviesi", are found in the deep ocean. The river stingrays, and a number of whiptail stingrays (such as the Niger stingray), are restricted to fresh water. Most myliobatoids are demersal (inhabiting the next-to-lowest zone in the water column); but some, such as the pelagic stingray and the eagle rays, are pelagic.
While most stingrays are relatively widespread and not currently threatened, for several species (for example "Taeniura meyeni", "D. colarensis", "D. garouaensis", and "D. laosensis"), conservation status is more problematic, leading to their being listed as vulnerable or endangered by IUCN. The status of several other species are poorly known, leading to their being listed as Data Deficient.
Behavior.
The flattened bodies of stingrays allow them to effectively conceal themselves in their environment. Stingrays do this by agitating the sand and hiding beneath it. Because their eyes are on top of their bodies and their mouths on the undersides, stingrays cannot see their prey; instead, they use smell and electroreceptors (ampullae of Lorenzini) similar to those of sharks. Stingrays feed primarily on molluscs, crustaceans, and occasionally on small fish. Some stingrays' mouths contain two powerful, shell-crushing plates, while other species only have sucking mouthparts. Stingrays settle on the bottom while feeding, often leaving only their eyes and tail visible. Coral reefs are favorite feeding grounds and are usually shared with sharks during high tide.
Reproduction.
When a male is courting a female, he will follow her closely, biting at her pectoral disc. He then places one of his two claspers into her valve.
Stingrays are ovoviviparous, bearing live young in "litters" of 5 to 13. The female holds the embryos in the womb without a placenta. Instead, the embryos absorb nutrients from a yolk sac, and after the sac is depleted, the mother provides uterine "milk".
At the Sea Life London Aquarium, two female stingrays have delivered seven baby stingrays, although the mothers have not been near a male for two years. "Rays have been known to store sperm and not give birth until they decide the timing is right".
Diet.
A stingray's diet includes small fish, snails, clams, and shrimp, and some other small sea creatures.
Stingray injuries.
Stingrays do not aggressively attack humans, though stings do normally occur if a ray is accidentally stepped on. To avoid stepping on a stingray in shallow water, the water should be waded through with a shuffle. Alternatively, before wading, stones can be thrown into the water to scare stingrays away. Contact with the stinger causes local trauma (from the cut itself), pain, swelling, muscle cramps from the venom, and later may result in infection from bacteria or fungus. The injury is very painful, but seldom life-threatening unless the stinger pierces a vital area. The barb usually breaks off in the wound, and surgery may be required to remove the fragments.
Fatal stings are very rare, but can happen, most famously in the death of Steve Irwin in 2006, in which the stinger penetrated the thoracic wall, causing massive trauma.
As food.
Rays are edible, and may be caught as food using fishing lines or spears. Stingray recipes abound throughout the world, with dried forms of the wings being most common. For example, in Malaysia and Singapore, stingray is commonly grilled over charcoal, then served with spicy "sambal" sauce, or soysauce. Generally, the most prized parts of the stingray are the wings (flaps is the proper terminology), the "cheek" (the area surrounding the eyes), and the liver. The rest of the ray is considered too rubbery to have any culinary uses.
While not independently valuable as a food source, the stingray's capacity to damage shell fishing grounds can lead to bounties being placed on their removal.
Ecotourism.
Stingrays are usually very docile and curious, their usual reaction being to flee any disturbance, but they will sometimes brush their fins past any new object they encounter. Nevertheless, certain larger species may be more aggressive and should be approached with caution, as the stingray's defensive reflex (use of its poisoned stinger) may result in serious injury or death.
Stingrays are not normally visible to swimmers, but divers and snorkelers may find them in shallow, sandy waters, more so when the water is warm. In the Cayman Islands several dive sites called Stingray City, Grand Cayman, allow divers and snorkelers to swim with large southern stingrays ("D. americana") and feed them by hand. A "Stingray City" in the sea surrounding the Caribbean island of Antigua consists of a large, shallow reserve where the rays live, and snorkeling is possible, since the rays are used to the presence of humans.
In Belize, off the island of Ambergris Caye, there is a popular marine sanctuary, Hol Chan, where divers and snorkelers often gather to watch stingrays and nurse sharks drawn to the area by tour operators who feed the animals.
Many Tahitian island resorts regularly offer guests the chance to "feed the stingrays and sharks". This consists of taking a boat to the outer lagoon reefs, then standing in waist-high water while habituated stingrays swarm around, pressing right up against tourists seeking food from their hands or that being tossed into the water. The boat owners also "call in" sharks, which, when they arrive from the ocean, swoop through the shallow water above the reef and snatch food offered to them.
Other uses.
The skin of the ray is used as an under layer for the cord or leather wrap (known as "ito" in Japanese) on Japanese swords due to its hard, rough, skin texture that keeps the braided wrap from sliding on the handle during use. They are also used to make exotic shoes, boots, belts, wallets, jackets, and cellphone cases.
Several ethnological sections in museums, such as the British Museum, display arrowheads and spearheads made of stingray stingers, used in Micronesia and elsewhere. Henry de Monfreid stated in his books that before World War II, in the Horn of Africa, whips were made from the tail of big stingrays, and these devices inflicted cruel cuts, so in Aden the British forbade their use on women and slaves. In former Spanish colonies, a stingray is called "raya látigo" ("whip ray").
Monfreid also wrote in several places about men of his crew suffering stingray wounds while standing and wading into Red Sea shallows to load or unload smuggled wares: he wrote that to "save the man's life", searing the wound with a red-hot iron was necessary.
Fossils.
Although stingray teeth are rare on sea bottoms compared to the similar shark teeth, scuba divers searching for the latter do encounter the teeth of stingrays. Permineralized stingray teeth have been found in sedimentary deposits around the world, including fossiliferous outcrops in Morocco.

</doc>
<doc id="54199" url="https://en.wikipedia.org/wiki?curid=54199" title="German euro coins">
German euro coins

German euro coins have three separate designs for the three series of coins. The 1-cent, 2-cent and 5-cent coins were designed by Rolf Lederbogen, the design for the 10-cent, 20-cent and 50-cent coins is by Reinhard Heinsdorff and the 1 and 2 euro coins were done by Heinz Hoyer and Sneschana Russewa-Hoyer. Featured in all designs are the 12 stars of the EU and the year of imprint.
In addition to the year, the German coins also feature a small letter as a mint mark indicating the particular mint that minted the coin.
The letters were assigned to the mints as they opened. The mints in Hannover/Vienna (B), Frankfurt am Main (C), Dresden/Muldenhütte (E), and Darmstadt (H) have since been closed; the last, Muldenhütte, in 1953.
German euro design.
For images of the common side and a detailed description of the coins, see euro coins.
Circulating Mintage quantities.
The following table shows the mintage quantity for all German euro coins, per denomination, per year (the numbers are represented in millions).
€2 commemorative coins.
German Bundesländer series.
Germany started the commemorative coin series "" (The 16 States of the Federal Republic of Germany) in 2006, which will continue until 2021. The year in which the coin for a specific state is issued coincides with that state's Presidency of the "Bundesrat". The coins issued are:
The other five coins will be issued in the following years; note that some designs are not yet finalised and still subject to change. Originally, the designs for the following states were different:
The series is similar to the United States' 50 State Quarters series, which saw fifty coins issued for its fifty constituent states, five per year between 1999 and 2008. A separate program saw six coins issued in 2009 for the District of Columbia and five territories of the United States.
Others.
As of 2016, Germany have issued six other €2 commemorative coins in addition to those of the "Bundesländer" series:

</doc>
<doc id="54201" url="https://en.wikipedia.org/wiki?curid=54201" title="Sodium dodecyl sulfate">
Sodium dodecyl sulfate

Sodium dodecyl sulfate, synonymously sodium lauryl sulfate (or "laurilsulfate"; SDS or SLS, respectively), is a synthetic organic compound with the formula CH3(CH2)11SO4Na. It is an anionic surfactant used in many cleaning and hygiene products. The sodium salt is of an organosulfate class of organics. It consists of a 12-carbon tail attached to a sulfate group, i.e., it is the sodium salt of "dodecyl hydrogen sulfate," the ester of dodecyl alcohol and sulfuric acid. Its hydrocarbon tail combined with a polar "headgroup" give the compound amphiphilic properties and so make it useful as a detergent. Also derived as a component of mixtures produced from inexpensive coconut and palm oils, SDS is a common component of many domestic cleaning, personal hygiene and cosmetic, pharmaceutical, and food products, as well as of industrial and commercial cleaning and product formulations.
Structure and properties.
Structure.
SDS is in the family of organosulfate compounds, and has the formula, CH3(CH2)11SO4Na; that is, it is the sodium salt of a 12-carbon alcohol that has been esterified to sulfuric acid. An alternative description is that it is an alkyl group with a pendant, terminal sulfate group attached. As a result of its hydrocarbon tail, and its anionic "head group", it has amphiphilic properties that allow it to form micelles, and so act as a detergent.
Physicochemical properties.
The critical micelle concentration (CMC) in pure water at 25 °C is 8.2 mM, and the aggregation number at this concentration is usually considered to be about 62. The micelle ionization fraction (α) is around 0.3 (or 30%).
Production.
SDS is synthesized by treating lauryl alcohol with sulfur trioxide gas, oleum, or chlorosulfuric acid to produce hydrogen lauryl sulfate. The resulting product is then neutralized through the addition of sodium hydroxide or sodium carbonate. Lauryl alcohol can be used in pure form or may be derived from either coconut or palm kernel oil by hydrolysis (which liberates their fatty acids), followed by hydrogenation. When produced from these sources, commercial samples of these "SDS" products are actually not pure SDS, rather a mixture of various sodium alkyl sulfates with SDS being the main component. For instance, SDS is a component, along with other chain-length amphiphiles, when produced from coconut oil, and is known as sodium coco sulfate (SCS). SDS is available commercially in powder, pellet, and other forms (each differing in rates of dissolution), as well as in aqueous solutions of varying concentrations.
Applications.
Cleaning and hygiene.
SDS is mainly used in detergents for laundry with many cleaning applications. It is a highly effective surfactant and is used in any task requiring the removal of oily stains and residues; for example, it is found in higher concentrations with industrial products including engine degreasers, floor cleaners, and car wash soaps.
In lower concentrations, it is found in toothpastes, shampoos, shaving creams, and bubble bath formulations, for its ability to create a foam (lather), for its surfactant properties, and in part for its thickening effect.
Food additive.
Sodium dodecyl sulfate, appearing as its synonym "sodium laurel sulfate" (SLS), is considered as a generally recognized as safe (GRAS) ingredient, for food use according to the guidelines published in 21 CFR 172.822. It is used as an emulsifying agent and whipping aid. SLS is reported to temporarily diminish perception of sweetness.
Laboratory applications.
Principle applications.
Sodium lauryl sulfate, in science referred to as sodium "dodecyl" sulfate (SDS), is used in laboratory cleaning procedures, and is commonly used in to aid lysing cells during DNA extraction, and for denaturing proteins in preparation for electrophoresis in the SDS-PAGE technique.
In the case of the SDS-PAGE application, the compound works by disrupting non-covalent bonds in the proteins, and so denaturing them, i.e., causing the protein molecules to lose their native conformations and shapes. The association of SDS molecules with protein molecules imparts an associated negative charge to the molecular aggregate formed; this negative charge is significantly greater than the original charge of that protein. The electrostatic repulsion that is created by SDS binding forces proteins into a rod-like shape, thereby eliminating differences in shape as a factor for electrophoretic separation in gels.
Miscellaneous applications.
SDS is used in an improved technique for preparing brain tissues for study by optical microscopy. The technique, which has been branded as CLARITY, was the work of Karl Deisseroth and coworkers at Stanford University, and involves infusion of the organ with an acrylamide solution to bind the macromolecules of the organ (proteins, nucleic acids, etc.), followed by thermal polymerization to form a brain–hydrogel" (a mesh interspersed throughout the tissue to fix the macromolecules and other structures in space), and then by lipid removal using SDS to eliminate light scattering with minimal protein loss, rendering the tissue quasi-transparent.
Along with sodium dodecylbenzene sulfonate and Triton X-100, aqueous solutions of SDS are popular for dispersing or suspending nanotubes, such as carbon nanotubes (CNTs).
Niche uses.
SDS has been proposed as a potentially effective topical microbicide, for intravaginal use, to inhibit and possibly prevent infection by various enveloped and non-enveloped viruses such as the herpes simplex viruses, HIV, and the Semliki Forest virus.
Toxicology.
Carcinogenicity.
SDS is not carcinogenic when consumed or applied directly, even to amounts and concentrations that exceed amounts used in standard commercial products. The earlier review of the Cosmetic Ingredient Review (CIR) program Expert Panel in 1983 reported that SDS (there, abbreviated SLS, for sodium laurel sulfate) in concentrations up to 2%, in a year-long oral dietary studies in dogs, gave no evidence of tumorigenicity or carcinogenicity, and that no excess chromosomal aberrations or clastogenic effects were observed in rats fed up to 1.13% Sodium Lauryl Sulfate in their diets for 90 days, over those on a control diet. The 2005 review by the same group indicated that further available data lacked any available suggestion that SDS or the related ammonium salt of the same amphiphile could be carcinogenic, stating that "Despite assertions to the contrary on the Internet, the carcinogenicity of these ingredients is only a rumor;" both studies conclude that SDS appears "to be safe in formulations designed for discontinuous, brief use followed by thorough rinsing from the surface of the skin. In products intended for prolonged contact with skin, concentrations should not exceed 1%."
Sensitivity.
Like all detergent surfactants, sodium lauryl sulfate removes oils from the skin, and can cause skin and eye irritation. It has been shown to irritate the skin of the face, with prolonged and constant exposure (more than an hour) in young adults. SDS may worsen skin problems in individuals with chronic skin hypersensitivity, with some people being affected more than others. In animal studies SDS appears to cause skin and eye irritation.
Oral concerns.
The low cost of SDS, its lack of impact on taste, its potential impact on volatile sulfur compounds (VSCs, which contribute to malodorous breath), and its desirable action as a foaming agent have led to the use of SDS in the formulations of toothpastes. A series of small crossover studies (25-34 patients) have supported the efficacy of SLS in the reduction of VSCs, and its related positive impact on breath malodor, although these studies have been generally noted to reflect technical challenges in the control of study design variables. While primary sources from the group of Irma Rantanen at University of Turku, Finland conclude an impact on dry mouth (xerostomia) from SLS-containing pastes, a 2011 "Cochrane" review of these studies, and of the more general area, concludes that there "is no strong evidence… that any topical therapy is effective for relieving the symptom of dry mouth." A safety concern has been raised on the basis of several studies regarding the effect of toothpaste SDS on aphthous ulcers, commonly referred to as canker or white sores. A consensus regarding practice (or change in practice) has not appeared as a result of the studies. As Lippert notes, of 2013, "very few… marketed toothpastes contain a surfactant other than SLS ," and leading manufacturers continue to formulate their produce with SDS.

</doc>
<doc id="54204" url="https://en.wikipedia.org/wiki?curid=54204" title="Philip II of Macedon">
Philip II of Macedon

Philip II of Macedon (, "Phílippos II ho Makedṓn"; 382–336 BC) was the king (Basileus) of the Ancient Greek kingdom of Macedon from until his assassination in . He was a member of the Argead dynasty, the third son of King Amyntas III, and father of Alexander the Great and Philip III.
Biography.
Philip was the youngest son of the king Amyntas III and Eurydice I. In his youth (c. 368 – 365 BC), Philip was held as a hostage in Thebes, which was the leading city of Greece during the Theban hegemony. While a captive there, Philip received a military and diplomatic education from Epaminondas, became eromenos of Pelopidas, and lived with Pammenes, who was an enthusiastic advocate of the Sacred Band of Thebes.
In 364 BC, Philip returned to Macedon. The deaths of Philip's elder brothers, King Alexander II and Perdiccas III, allowed him to take the throne in 359 BC. Originally appointed regent for his infant nephew Amyntas IV, who was the son of Perdiccas III, Philip managed to take the kingdom for himself that same year.
Philip's military skills and expansionist vision of Macedonian greatness brought him early success. He first had to re-establish a situation which had been greatly worsened by the defeat against the Illyrians in which King Perdiccas himself had died. The Paionians and the Thracians had sacked and invaded the eastern regions of the country, while the Athenians had landed, at Methoni on the coast, a contingent under a Macedonian pretender called Argeus.
Using diplomacy, Philip pushed back the Paionians and Thracians promising tributes, and crushed the 3,000 Athenian hoplites (359). Momentarily free from his opponents, he concentrated on strengthening his internal position and, above all, his army. His most important innovation was doubtless the introduction of the phalanx infantry corps, armed with the famous sarissa, an exceedingly long spear, at the time the most important army corps in Macedonia.
Philip had married Audata, great-granddaughter of the Illyrian king of Dardania, Bardyllis. However, this did not prevent him from marching against them in 358 and crushing them in a ferocious battle in which some 7,000 Illyrians died (357). By this move, Philip established his authority inland as far as Lake Ohrid and earned the favour of the Epirotes.
He agreed with the Athenians, who had been so far unable to conquer Amphipolis, which commanded the gold mines of Mount Pangaion, to lease it to them after its conquest, in exchange for Pydna (lost by Macedon in 363). However, after conquering Amphipolis, he kept both the cities (357). As Athens declared war against him, he allied with the Chalkidian League of Olynthus. He subsequently conquered Potidaea, this time keeping his word and ceding it to the League in 356. One year before, Philip had married the Epirote princess Olympias, who was the daughter of the king of the Molossians.
During 356 BC, Philip also conquered the town of Crenides and changed its name to Philippi: he established a powerful garrison there to control its mines, which granted him much of the gold later used for his campaigns. In the meantime, his general Parmenion defeated the Illyrians again. Also in 356 Alexander was born, and Philip's race horse won in the Olympic Games. In 355–354 he besieged Methone, the last city on the Thermaic Gulf controlled by Athens. During the siege, Philip was injured in his eye. It was later removed surgically. Despite the arrival of two Athenian fleets, the city fell in 354. Philip also attacked Abdera and Maronea, on the Thracian seaboard (354–353).
Philip was involved in the Third Sacred War which had begun in Greece in 356. During the summer of 353 he invaded Thessaly, defeating 7,000 Phocians under the brother of Onomarchus. The latter however defeated Philip in the two succeeding battles. Philip returned to Thessaly the next summer, this time with an army of 20,000 infantry and 3,000 cavalry including all Thessalian troops. In the Battle of Crocus Field 6,000 Phocians fell, while 3,000 were taken as prisoners and later drowned.
This battle granted Philip an immense prestige, as well as the free acquisition of Pherae. Philip was also "tagus" of Thessaly, and he claimed as his own Magnesia, with the important harbour of Pagasae. Philip did not attempt to advance into Central Greece because the Athenians, unable to arrive in time to defend Pagasae, had occupied Thermopylae.
Hostilities with Athens did not yet take place, but Athens was threatened by the Macedonian party which Philip's gold created in Euboea. From 352 to 346 BC, Philip did not again come south. He was active in completing the subjugation of the Balkan hill-country to the west and north, and in reducing the Greek cities of the coast as far as the Hebrus. To the chief of these coastal cities, Olynthus, Philip continued to profess friendship until its neighboring cities were in his hands.
In 349 BC, Philip started the siege of Olynthus, which, apart from its strategic position, housed his relatives Arrhidaeus and Menelaus, pretenders to the Macedonian throne. Olynthus had at first allied itself with Philip, but later shifted its allegiance to Athens. The latter, however, did nothing to help the city, its expeditions held back by a revolt in Euboea (probably paid by Philip's gold). The Macedonian king finally took Olynthus in 348 BC and razed the city to the ground. The same fate was inflicted on other cities of the Chalcidian peninsula.
Macedon and the regions adjoining it having now been securely consolidated, Philip celebrated his Olympic Games at Dium. In 347 BC, Philip advanced to the conquest of the eastern districts about Hebrus, and compelled the submission of the Thracian prince Cersobleptes. In 346 BC, he intervened effectively in the war between Thebes and the Phocians, but his wars with Athens continued intermittently. However, Athens had made overtures for peace, and when Philip again moved south, peace was sworn in Thessaly.
With key Greek city-states in submission, Philip II turned to Sparta; he sent them a message: "If I win this war, you will be slaves forever." In another version, he warned: "You are advised to submit without further delay, for if I bring my army into your land, I will destroy your farms, slay your people, and raze your city." According to both accounts, the Spartans' laconic reply was one word: "If". Philip II and Alexander both chose to leave Sparta alone. Later, the Macedonian arms were carried across Epirus to the Adriatic Sea.
In 345 BC, Philip conducted a hard-fought campaign against the Ardiaioi (Ardiaei), under their king Pluratus, during which he was seriously wounded by an Ardian soldier in the lower right leg.
In 342 BC, Philip led a great military expedition north against the Scythians, conquering the Thracian fortified settlement Eumolpia to give it his name, "Philippopolis" (modern Plovdiv).
In 340 BC, Philip started the siege of Perinthus. Philip began another siege in 339 of the city of Byzantium. After unsuccessful sieges of both cities, Philip's influence all over Greece was compromised. However, he successfully reasserted his authority in the Aegean by defeating an alliance of Thebans and Athenians at the Battle of Chaeronea in 338 BC, while in the same year, Philip destroyed Amfissa because the residents had illegally cultivated part of the Crisaian plain which belonged to Delphi.
It was these decisive victories that finally secured Philip’s position as having the majority of Greece under Macedonian sovereignty.
Philip created and led the League of Corinth in 337 BC. Members of the League agreed never to wage war against each other, unless it was to suppress revolution. Philip was elected as leader ("hegemon") of the army of invasion against the Persian Empire. In 336 BC, when the invasion of Persia was in its very early stage, Philip was assassinated, and was succeeded on the throne of Macedon by his son Alexander III, who later become known as Alexander the Great.
State system and Achaemenid Persian borrowings and influences.
As historians Roisman and Worthington state, to Macedonian rulers, Achaemenid Persia stood as an example of statehood and "mores". This is especially true of Philip II as he built his power and created many institutions to imitate those known from the Achaemenid Empire. Thus, inspired by Persian achievements, Philip established a Royal Secretary and Archive, and aimed at the elevation of the political as well as religious level, and he used a special throne (Gr. "thronos") borrowed from the Achaemenid court to demonstrate his elevated rank. The institution of the Royal Pages (Gr. "Paides Basilikoi") was probably inspired by Achaemenid prototype - among their duties, Arrian mentions mounting the king on his horse "in the Persian style". The status of Thrace in 342-334 under the Macedonian sway as a kind of regular satrapy resembled Achaemenid administrative practices, and the organization of the royal court, generally, followed in a fashion of the Achaemenid tradition. Some scholars deny Philip's international borrowings from Persian tradition, but it must be said that states do not develop in a vacuum. For an increasingly powerful Macedonia, the most immediate model of a great monarchy was Persia.
Assassination.
The murder of Philip occurred during October 336 BC, at Aegae, the ancient capital of the kingdom of Macedon. The court had gathered there for the celebration of the marriage between Alexander I of Epirus and Philip's daughter, by his fourth wife Olympias, Cleopatra. While the king was entering unprotected into the town's theater (highlighting his approachability to the Greek diplomats present), he was killed by Pausanias of Orestis, one of his seven bodyguards. The assassin immediately tried to escape and reach his associates who were waiting for him with horses at the entrance of Aegae. He was pursued by three of Philip's bodyguards; tripping on a vine, he died by their hands.
The reasons for Pausanias' assassination of Philip are difficult to expound fully, since there was already controversy among ancient historians. The only contemporary account in our possession is that of Aristotle who states rather tersely that Philip was killed because Pausanias had been offended by the followers of Attalus, uncle of Philip's wife Cleopatra (renamed upon marriage Eurydice).
Fifty years later, the historian Cleitarchus expanded and embellished the story. Centuries later, this version was to be narrated by Diodorus Siculus and all the historians who used Cleitarchus. According to the sixteenth book of Diodorus' history, Pausanias had been a lover of Philip, but became jealous when Philip turned his attention to a younger man, also called Pausanias. The elder Pausanias's taunting of the new lover caused the youth to throw away his life, which turned his friend Attalus against the elder Pausanias. Attalus took his revenge by inviting Pausanias to dinner, getting him drunk, then subjecting him to sexual assault.
When Pausanias complained to Philip, the king felt unable to chastise Attalus, as he was about to send him to Asia with Parmenion, to establish a bridgehead for his planned invasion. He also married Attalus's niece, or daughter, Eurydice. Rather than offend Attalus, Philip tried to mollify Pausanias by elevating him within the bodyguard. Pausanias' desire for revenge seems to have turned towards the man who had failed to avenge his damaged honour, so he planned to kill Philip. Some time after the alleged rape, while Attalus was already in Asia fighting the Persians, he put his plan in action.
Other historians (e.g., Justin 9.7) suggested that Alexander and/or his mother Olympias were at least privy to the intrigue, if not themselves instigators. The latter seems to have been anything but discreet in manifesting her gratitude to Pausanias, according to Justin's report: he says that the same night of her return from exile she placed a crown on the assassin's corpse and erected a tumulus to his memory, ordering annual sacrifices to the memory of Pausanias.
Many modern historians have observed that all the accounts are improbable. In the case of Pausanias, the stated motive of the crime hardly seems adequate. On the other hand, the implication of Alexander and Olympias seems specious: to act as they did would have required brazen effrontery in the face of a military personally loyal to Philip. What seems to be recorded in this are the natural suspicions that fell on the chief beneficiaries of the murder; their actions after the murder, however sympathetic they might seem (if actual), cannot prove their guilt in the deed itself.
Whatever the actual background to the assassination, it might have had an enormous effect on later world history, far beyond what any conspirators could have predicted; as asserted by some modern historians, had the older and more settled Philip been the one in charge of the war against Persia, he might have rested content with relatively moderate conquests, e.g. making Anatolia into a Macedonian province, and not pushed further into an overall conquest of Persia and further campaigns in India.
Marriages.
The dates of Philip's multiple marriages and the names of some of his wives are contested. Below is the order of marriages offered by Athenaeus, 13.557b–e:
Tomb of Philip II at Aigai.
In 1977, Greek archaeologist Manolis Andronikos started excavating the Great Tumulus at Aigai near modern Vergina, the capital and burial site of the kings of Macedon, and found that two of the four tombs in the tumulus were undisturbed since antiquity. Moreover, these two, and particularly Tomb II, contained fabulous treasures and objects of great quality and sophistication.
Although there was much debate for some years, as suspected at the time of the discovery Tomb II has been shown to be that of Philip II as indicated by many features including the greaves, one of which was shaped in a way consistent with fitting a leg with a misaligned tibia (Philip II was recorded as having broken his tibia). Also the remains of the skull show damage to the right eye caused by the penetration of an object (historically recorded to be an arrow).
A study of the bones published in 2015 indicated that Philip was buried in Tomb I, instead of Tomb II. On the basis of age, knee ankylosis and a hole matching the penetrating wound and lameness suffered by Philip, the authors of the study identified the remains of Tomb I in Vergina as those of Philip II. Tomb II instead was identified in the study as that belonging to King Arrhidaeus and his wife Eurydice II. However this latter theory had previously been shown to be false.
More recent research gives further evidence that Tomb II contains the remains of Philip II.
Legacy.
Cult.
The heroon at Vergina in Macedonia (the ancient city of Aegae – Αἰγαί) is thought to have been dedicated to the worship of the family of Alexander the Great and may have housed the cult statue of Philip. It is probable that he was regarded as a hero or deified on his death. Though the Macedonians did not consider Philip a god, he did receive other forms of recognition by the Greeks, such as at Eresos (altar to Zeus Philippeios), Ephesos (his statue was placed in the temple of Artemis), and Olympia, where the Philippeion was built.
Isocrates once wrote to Philip that if he defeated Persia, there would be nothing left for him to do but to become a god, and Demades proposed that Philip be regarded as the thirteenth god; however, there is no clear evidence that Philip was raised to the divine status accorded his son Alexander.

</doc>
<doc id="54205" url="https://en.wikipedia.org/wiki?curid=54205" title="Diaper">
Diaper

A diaper (also called a nappy in South Africa, Ireland, United Kingdom, New Zealand, Australia and Zimbabwe) is a type of underwear that allows one to defecate or urinate, without the use of a toilet. When diapers become soiled, they require changing, generally by a second person such as a parent or caregiver. Failure to change a diaper on a sufficiently regular basis can result in skin problems around the area covered by the diaper.
Diapers are made of cloth or synthetic disposable materials. Cloth diapers are composed of layers of fabric such as cotton, hemp, bamboo or microfiber and can be washed and reused multiple times. Disposable diapers contain absorbent chemicals and are thrown away after use. Plastic pants can be worn over diapers to avoid leaks, but with modern cloth diapers, this is no longer necessary.
Diapers are primarily worn by infants, and by children who are not yet potty trained or who experience bedwetting. They are also used by adults with incontinence or in certain circumstances where access to a toilet is unavailable. These can include those of advanced age, individuals with certain types of physical or mental disability, and people working in extreme conditions, such as astronauts. It is not uncommon for people to wear diapers under dry suits.
History.
The Middle English word "diaper" originally referred to a type of cloth rather than the use thereof; "diaper" was the term for a pattern of repeated, rhombic shapes, and later came to describe a white cotton or linen fabric with this pattern. The first cloth diapers consisted of a specific type of soft tissue sheet, cut into geometric shapes. This type of pattern was called diapering and eventually gave its name to the cloth used to make diapers and then to the diaper itself, which was traced back to 1590s England. This usage stuck in the United States and Canada following the British colonization of North America, but in Britain the word "nappy" took its place. Most sources believe "nappy" is a diminutive form of the word napkin, which itself was originally a diminutive.
Development.
In the 19th century, the modern diaper began to take shape and mothers in many parts of the world used cotton material, held in place with a fastening—eventually the safety pin. Cloth diapers in the United States were first mass-produced in 1887 by Maria Allen. In the UK, nappies were made out of terry towelling, often with an inner lining made out of soft muslin.
Here is an extract from 'The Modern Home Doctor' written by physicians in the UK in 1935.
Nice old, soft bits of good Turkish towelling, properly washed, will make the softest of diaper coverings, inside which specially absorbent napkins (diapers), see below at 1A, soft, light, and easily washed, are contained. These should rarely be soiled once regular habits have been inculcated, especially during the night period in which it is most important to prevent habit formation
1A -(squares of butter muslin or Harrington’s packed rolls of “mutton cloth” in packets, sold for polishing motor-cars, would do equally well and are very cheap and soft)
Wool pants, or, once available, rubber pants, were sometimes used over the cloth diaper to prevent leakage. Doctors believed that rubber pants were harmful because they thought the rubber acted as a poultice and damaged the skin of infants. The constant problem to be overcome was diaper rash, and the infection thereof. The concern was that lack of air circulation would worsen this condition. While lack of air circulation is a factor, it was later found that poor hygiene involving inefficiently washed diapers and infrequent changes of diapers, along with allowing the baby to lie for prolonged periods of time with fecal matter in contact with the skin, were the two main causes of these problems.
In the 20th century, the disposable diaper was conceived. In the 1930s, Robinsons of Chesterfield had what were labeled "Destroyable Babies Napkins" listed in their catalogue for the wholesale market. In 1944, Hugo Drangel of the Swedish paper company Pauliström suggested a conceptual design which would entail the placing of sheets of paper tissue (cellulose wadding) inside the cloth diaper and rubber pants. However, cellulose wadding was rough against the skin and crumbled into balls when exposed to moisture.
In 1946, Marion Donovan used a shower curtain from her bathroom to create the "Boater", a plastic cover to be donned outside a diaper. First sold in 1949 at Saks Fifth Avenue's flagship store in New York City, patents were later issued in 1951 to Donovan, who later sold the rights to the waterproof diaper for $1 million. Donovan also designed a paper disposable diaper, but was unsuccessful in marketing it.
In 1947, a housewife in the UK named Valerie Hunter Gordon started developing and making Paddi, a 2-part system consisting of a disposable pad (made of cellulose wadding covered with cotton wool) worn inside an adjustable plastic garment with press-studs/snaps. Initially, she used old parachutes for the garment. She applied for the patent in April 1948, and it was granted for the UK in October 1949. Initially, the big manufacturers were unable to see the commercial possibilities of disposable nappies. In 1948, Gordon made over 400 Paddis herself using her sewing machine at the kitchen table. Her husband had unsuccessfully approached several companies for help until he had a chance meeting with Sir Robert Robinson at a business dinner. In November 1949 Valerie Gordon signed a contract with Robinsons of Chesterfield who then went into full production. In 1950, Boots UK agreed to sell Paddi in all their branches. In 1951 the Paddi patent was granted for the USA and worldwide. Shortly after that, Playtex and several other large international companies tried unsuccessfully to buy out Paddi from Robinsons. Paddi was very successful for many years until the advent of 'all in one' diapers.
In Sweden, Hugo Drangel's daughter Lil Karhola Wettergren, in 1956 elaborated her father's original idea, by adding a garment (again making a 2-part system like Paddi). However she met the same problem, with the purchasing managers, declaring they would never allow their wives to "put paper on their children."
After the Second World War, mothers increasingly wanted freedom from washing diapers so that they could work and travel, causing an increasing demand for disposable diapers.
During the 1950s, companies such as Johnson and Johnson, Kendall, Parke-Davis, Playtex, and Molnlycke entered the disposable diaper market, and in 1956, Procter & Gamble began researching disposable diapers. Victor Mills, along with his project group including William Dehaas (both men who worked for the company) invented what would be trademarked "Pampers". Presented to Fred Wells as 'project p-57' (this was the plane Wells had taught American pilots to fly during the Second World War), Mills stated, "This one will fly." Although Pampers were conceptualized in 1959, the diapers themselves were not launched into the market until 1961. Pampers now accounts for more than $10 billion in annual revenue at Procter & Gamble.
Over the next few decades, the disposable diaper industry boomed and the competition between Procter & Gamble's Pampers and Kimberly Clark's Huggies resulted in lower prices and drastic changes to diaper design. They have helped many families with low income to get diapers needed for their babies. Several improvements were made, such as the use of double gussets to improve diaper fit and containment. As stated in Procter & Gamble's initial 1973 patent for the use of double gussets in a diaper, “The double gusset folded areas tend to readily conform to the thigh portions of the leg of the infant. This allows quick and easy fitting and provides a snug and comfortable diaper fit that will neither bind nor wad on the infant…as a result of this snugger fit obtained because of this fold configuration, the diaper is less likely to leak or, in other words, its containment characteristics are greatly enhanced.” Further developments in diaper design were made, such as the introduction of refastenable tapes, the "hourglass shape" so as to reduce bulk at the crotch area, and the 1984 introduction of super-absorbent material from polymers known as sodium polyacrylate that were originally developed in 1966.
Types.
Disposable.
The first disposable diaper was invented and patented in 1948 by Valerie Hunter Gordon (née de Ferranti), granddaughter of inventor Sebastian Ziani de Ferranti.
Ever since their introduction several decades ago, product innovations include the use of superabsorbent polymers, resealable tapes, and elasticised waist bands. They are now much thinner and much more absorbent. The product range has more recently been extended into children's toilet training phase with the introduction of training pants and pant diapers, which are now undergarments.
Modern disposable baby diapers and incontinence products have a layered construction, which allows the transfer and distribution of urine to an absorbent core structure where it is locked in. Basic layers are an outer shell of breathable polyethylene film or a nonwoven and film composite which prevents wetness and soil transfer, an inner absorbent layer of a mixture of air-laid paper and superabsorbent polymers for wetness, and a layer nearest the skin of nonwoven material with a distribution layer directly beneath which transfers wetness to the absorbent layer.
Other common features of disposable diapers include one or more pairs of either adhesive or mechanical fastening tapes to keep the diaper securely fastened. Some diapers have tapes which are refastenable to allow adjusting of fit or reapplication after inspection. Elasticized fabric single and double gussets around the leg and waist areas aid in fitting and in containing urine or stool which has not been absorbed. Some diapers lines now commonly include wetness indicators, in which a chemical included in the fabric of the diaper changes color in the presence of moisture to alert the carer or user that the diaper is wet.
A disposable diaper may also include an inner fabric designed to hold moisture against the skin for a brief period before absorption to alert a toilet training or bedwetting user that they have urinated. Most materials in the diaper are held together with the use of a hot melt adhesive, which is applied in spray form or multi lines, an elastic hot melt is also used to help with pad integrity when the diaper is wet.
Some disposable diapers include fragrances, lotions or essential oils in order to help mask the scent of a soiled diaper, or to protect the skin. Care of disposable diapers is minimal, and primarily consists of keeping them in a dry place before use, with proper disposal in a garbage receptacle upon soiling. Stool is supposed to be deposited in the toilet, but is generally put in the garbage with the rest of the diaper.
Cloth diaper.
Cloth diapers are reusable and can be made from natural fibers, man-made materials, or a combination of both. They are often made from industrial cotton which may be bleached white or left the fiber’s natural color. Other natural fiber cloth materials include wool, bamboo, and unbleached hemp. Man-made materials such as an internal absorbent layer of microfiber toweling or an external waterproof layer of polyurethane laminate (PUL) may be used. Polyester fleece and faux suedecloth are often used inside cloth diapers as a "stay-dry" wicking liner because of the non-absorbent properties of those synthetic fibers.
Traditionally, cloth diapers consisted of a folded square or rectangle of cloth, fastened with safety pins. Today, most cloth diapers are fastened with hook and loop tape (velcro) or snaps.
Modern cloth diapers come in a host of shapes, including preformed cloth diapers, all-in-one diapers with waterproof exteriors, fitted diaper with covers and pocket or "stuffable" diapers, which consist of a water-resistant outer shell sewn with an opening for insertion of absorbent material inserts. Many design features of modern cloth diapers have followed directly from innovations initially developed in disposable diapers, such as the use of the hour glass shape, materials to separate moisture from skin and the use of double gussets, or an inner elastic band for better fit and containment of waste material. Several cloth diaper brands use variations of Procter & Gamble's original 1973 patent use of a double gusset in Pampers.
Usage.
Children.
Babies may have their diapers changed five or more times a day. Parents and other primary child care givers often carry spare diapers and necessities for diaper changing in a specialized diaper bag. Diapering may possibly serve as a good bonding experience for parent and child. Children who wear diapers may experience skin irritation, commonly referred to as diaper rash, due to continual contact with fecal matter, as feces contains urease which catalyzes the conversion of the urea in urine to ammonia which can irritate the skin and can cause painful redness.
The age at which children should cease regularly wearing diapers and toilet training should begin is a subject of debate. Proponents of baby-led potty training and Elimination Communication argue that potty training can begin at birth with multiple benefits, with diapers only used as a back up. Keeping children in diapers beyond infancy can be controversial, with family psychologist John Rosemond claiming it is a "slap to the intelligence of a human being that one would allow baby to continue soiling and wetting himself past age two." Pediatrician T. Berry Brazelton, however, believes that toilet training is the child's choice and has encouraged this view in various commercials for Pampers Size 6, a diaper for older children. Brazelton warns that enforced toilet training can cause serious longterm problems, and that it is the child's decision when to stop wearing diapers, not the parents'.
Most children no longer wear diapers when past two to four years of age, depending on culture, diaper type, parental habits, and the child's personality. However, it is becoming increasingly common for children as old as five to still be wearing diapers because of their parents' neglect or the child's opposition to toilet training. This can pose a number of problems if the child is sent to school wearing diapers, including teasing from classmates and health issues resulting from soiled diapers. Teachers' groups—who are attributing the epidemic to an increase in full-time day care use—are requesting that diapered children be banned from the classroom. The disposable diaper industry has been accused of encouraging this trend by manufacturing diapers in increasingly larger sizes. "uper-comfortable nappies" have also been criticized; the advanced technology in modern diapers wick wetness away from skin, leaving the child oblivious to their accident and when they need to go to the toilet. Paediatric nurse June Rogers claims that the attitude of parents plays a major role in the problem, and that toilet training is simply not a priority for many of them.
Children may have problems with bladder control (primarily at night), until eight years or older, and may wear diapers while sleeping to control bedwetting. The Children's Health and Wellness website claims that diapering a child can prolong bedwetting, as it sends a "message of permission" to urinate in their sleep. Dr Anthony Page of the Creative Child Online Magazine claims that children can get used to their diapers and begin to view them as a comfort, and that of the children surveyed, most would rather wear diapers than worry about getting up at night to go to the toilet. In a series of online surveys, Robert A Pretlow, MD, of eHealth International, Inc., cites an identical figure. He argues that if Internet users are representative of society as a whole, these surveys imply that a fetishistic or emotional attraction to diapers may be responsible for these "comfort" cases, and that "these behaviors are a significant cause of enuresis and incontinence." He called for further studies to be done on the topic.
Training pants.
Manufacturers have designed "training pants" which bridge the gap between baby diapers and normal underwear during the toilet training process. These are similar to infant diapers in construction but they can be put on like normal underwear. Training pants are available for children who experience enuresis.
Adults.
Although most commonly worn by and associated with babies and children, diapers are also worn by adults for a variety of reasons. In the medical community, they are usually referred to as "adult absorbent briefs" rather than diapers, which are associated with children and may have a negative connotation. The usage of adult diapers can be a source of embarrassment, and products are often marketed under euphemisms such as incontinence pads. The most common adult users of diapers are those with medical conditions which cause them to experience urinary like bed wetting or fecal incontinence, or those who are bedridden or otherwise limited in their mobility.
Astronauts and Scuba divers utilize diapers for their space suits and dry suits for long exposures.
Animals.
Diapers and diaperlike products are sometimes used on pets, laboratory animals, or working animals. This is often due to the animal not being housebroken, or for older, sick, or injured pets who have become incontinent. In some cases, these are simply baby diapers with holes cut for the tails to fit through. In other cases, they are diaperlike waste collection devices.
The diapers used on primates, canines, etc. are much like the diapers used by humans. The diapers used on equines are intended to catch excretions, as opposed to absorbing them.
In 2002, the Vienna city council proposed that horses be made to wear diapers to prevent them from defecating in the street. This caused controversy amongst animal rights groups, who claimed that wearing diapers would be uncomfortable for the animals. The campaigners protested by lining the streets wearing diapers themselves, which spelled out the message "Stop pooh bags". In the Kenyan town of Limuru, donkeys were also diapered at the council's behest. A similar scheme in Blackpool ordered that horses be fitted with rubber and plastic diapers to stop them littering the promenade with dung. The council consulted the RSPCA to ensure that the diapers were not harmful to the horses' welfare.
Other animals that are sometimes diapered include female dogs when ovulating and thus bleeding, and monkeys and apes. Diapers are often seen on trained animals who appear on TV shows, in movies, or for live entertainment or educational appearances.
Debate.
An average child will go through several thousand diapers in their life. Since disposable diapers are discarded after a single use, usage of disposable diapers increases the burden on landfill sites, and increased environmental awareness has led to a growth in campaigns for parents to use reusable alternatives such as cloth or hybrid diapers. An estimated 27.4 billion disposable diapers are used each year in the US, resulting in a possible 3.4 million tons of used diapers adding to landfills each year.
The environmental impact of cloth as compared to disposable diapers has been studied several times. In one cradle-to-grave study sponsored by the National Association of Diaper Services (NADS) and conducted by Carl Lehrburger and colleagues, results found that disposable diapers produce seven times more solid waste when discarded and three times more waste in the manufacturing process. In addition, effluents from the plastic, pulp, and paper industries are far more hazardous than those from the cotton-growing and -manufacturing processes. Single-use diapers consume less water than reusables laundered at home, but more than those sent to a commercial diaper service. Washing cloth diapers at home uses 50 to 70 gallons (approx. 189 to 264 litres) of water every three days, which is roughly equivalent to flushing the toilet 15 times a day, unless the user has a high-efficiency washing machine. An average diaper service puts its diapers through an average of 13 water changes, but uses less water and energy per diaper than one laundry load at home.
In October 2008, "An updated lifecycle assessment study for disposable and reusable nappies" by the UK Environment Agency and Department for Environment, Food and Rural Affairs stated that reusable diapers can cause significantly less (up to 40 per cent) or significantly more damage to the environment than disposable ones, depending mostly on how parents wash and dry them. The "baseline scenario" showed that the difference in green-house emissions was insignificant (in fact, disposables even scored slightly better). However, much better results (emission cuts of up to 40 per cent) could be achieved by using reusable diapers more rationally. "The report shows that, in contrast to the use of disposable nappies, it is consumers’ behaviour after purchase that determines most of the impacts from reusable nappies. Cloth nappy users can reduce their environmental impacts by:
There are variations in the care of cloth diapers that can account for different measures of environmental impact. For example, using a cloth diaper laundering service involves additional pollution from the vehicle that picks up and drops off deliveries. Yet such a service uses less water per diaper in the laundering process. Some people who launder cloth diapers at home wash each load twice, considering the first wash a "prewash", and thus doubling the energy and water usage from laundering. Cloth diapers are most commonly made of cotton, which is generally considered an environmentally wasteful crop to grow. "Conventional cotton is one of the most chemically-dependent crops, sucking up 10% of all agricultural chemicals and 25% of insecticides on 3% of our arable land; that's more than any other crop per unit." This effect can be mitigated by using other materials, such as bamboo and hemp.
Another aspect to consider when choosing between disposable diapers and cloth diapers is cost. It is estimated that an average baby will use from $1,500 to $2,000 or more in disposable diapers before being potty-trained. In contrast, cloth diapers, while initially more expensive than disposables, cost as low as $300 for a basic set of cloth diapers, although costs can rise with more expensive options. The cost of washing and drying diapers must also be considered. The basic set, if one-sized, can last from birth to potty-training.
Another factor in reusable cloth diaper impact is the ability to re-use the diapers for subsequent children or sell them on. These factors can alleviate the environmental and financial impact from manufacture, sale and use of brand-new reusable diapers.

</doc>
<doc id="54206" url="https://en.wikipedia.org/wiki?curid=54206" title="Evergreen bagworm">
Evergreen bagworm

The evergreen bagworm ("Thyridopteryx ephemeraeformis"), commonly known as bagworm, 
eastern bagworm, common bagworm, common basket worm, or North American bagworm, is a moth that spins its cocoon in its larval life, decorating it with bits of plant material from the trees on which it feeds.
The evergreen bagworm's case grows to a length of over 6 cm, tapered and open on both ends. Newborn larva are blackish and turn brown to tan as they grow, mottled with black. The heads and thorax develop a yellow tint as they grow to a full length of 24 to 32 mm. Adult males resemble bees, having a 25 mm wingspan with transparent wings ("thuris" window + "pterux" wing) and black furry bodies. Adult females are maggot-like with yellowish-white soft bodies 19 to 23 mm long and small tufts of hair near the end of the abdomen. The cream-colored eggs are 0.75 mm in diameter.
The evergreen bagworm thrives in the eastern United States as far west as Nebraska, north into New England and bordering the Gulf of Mexico south throughout Texas. It has been found in other countries, such as South Africa and Croatia. Large populations in forested areas are rare. With scarce predators in urban areas, evergreen bagworms often thrive in urban habitats. When disturbed, the larva will retract its head into its case and hold the front opening closed. Mature larva may remain in the host tree or drag its case nearby before attaching itself for the pupa stage.
Arborvitae and red cedar are the favored host trees of the evergreen bagworm, but cypress, juniper, pine, spruce, apple, birch, black locust, elm, maple, poplar, oak, sycamore, willow, and over 100 other species are also attacked. Leaves and buds are both fair game for food.
Bagworms are commonly parasitized by ichneumonid wasps, notably "Itoplectis conquisitor". Predators include vespid wasps and hornets. Woodpeckers and sapsuckers can feed on the larva from their cases.
Eggs hatch from early April to early June (earlier in the south) and larvae emerge from the carcass of their mother in her case. Newborn larva emerge from the bottom of the hanging case and drop down on a strand of silk. The wind often blows the larva to nearby plants where it begins its new case from silk and fecal material before beginning to add leaves and twigs from its host. When mature in mid-August, the larva wraps silk around a branch, hangs from it, and pupates head down. The silk is so strong that it can strangle and kill the branch it hangs from over the course of several years as the branch grows. Adult males transform into moths in four weeks to seek out females for mating. The female never leaves the cocoon, requiring that the male mate with her through the open end at the back of the case. She has no eyes, legs, wings, antennae, and can't eat, but she emits a strong pheromone to attract a mate. After her death with hundreds to several thousand eggs still inside, her offspring hatch and pass through her body, pupal shell and case over several months emerging to start their own cases. Later, her pupal case can be found, full of the yellow remains of eggshells.
The bagworm has a voracious appetite and is considered a serious pest. Host trees develop damaged foliage that will kill the tree if left unchecked. If caught early enough in an infestation, the cases from the previous year can be picked off by hand before the end of May. They are easiest to detect in the fall after their cases have turned brown, especially on evergreen trees. Various bacterial sprays such as Bt/Spinosad and stomach insecticides such as carbaryl (Sevin) are used to control infestations.

</doc>
<doc id="54210" url="https://en.wikipedia.org/wiki?curid=54210" title="Greek euro coins">
Greek euro coins

Greek euro coins feature a unique design for each of the eight coins. They were all designed by Georgios Stamatopoulos with the minor coins depicting Greek ships, the middle ones portraying famous Greeks and the two large denominations showing images of Greek history and mythology. All designs feature the 12 stars of the EU, the year of imprint and a tiny symbol of the Bank of Greece. Uniquely, the value of the coins is expressed on the national side in the Greek alphabet, as well as being on the common side in the Roman alphabet. The euro cent is known as the "lepto" (λεπτό; plural "lepta", λεπτά) in Greek.
Greece did not enter the Eurozone until 2001 and was not able to start minting coins as early as the other eleven member states, so a number of coins circulated in 2002 were not minted in Athens but in Finland (€1 and €2 – mint mark "S"), France (1c, 2c, 5c, 10c and 50c – mint mark "F") and Spain (20c – mint mark "E"). The coins minted in Athens for the euro introduction in 2002, as well as all the subsequent Greek euro coins, do not carry any mint mark.
Greek euro design.
For images of the common side and a detailed description of the coins, see euro coins.
Circulating mintage quantities.
The following table shows the mintage quantity for all Greek euro coins, per denomination, per year (the numbers are represented in millions).
Greek starter kit.
In 2001, the Bank of Greece issued starter kits for the introduction of the Euro.
Commemorative coins.
Greece has a good collection of euro commemorative coins, mainly in silver although a few coins have also been minted in gold. Their face value range from €10 to €200 euro. This is mainly done as a legacy of an old national practice of minting gold and silver coins. These coins are not really intended to be used as means of payment, so generally they do not circulate. Here you can find some samples:

</doc>
<doc id="54211" url="https://en.wikipedia.org/wiki?curid=54211" title="Ganymede (moon)">
Ganymede (moon)

</math>.</ref>
Ganymede (Jupiter III) is the largest moon of Jupiter and in the Solar System, and the only moon known to have a magnetosphere. It is the seventh satellite outward from Jupiter and third of the Galilean moons, the first group of objects discovered orbiting another planet. Ganymede orbits Jupiter in roughly seven days and is in a 1:2:4 orbital resonance with the moons Europa and Io, respectively. Ganymede has a diameter of , 8% larger than the planet Mercury, but its mass is only 45% that of Mercury. Ganymede is 2% larger than Saturn's Titan, the Solar System's second-largest moon. At 2.02 times the mass of the Moon, it is the most massive planetary satellite. It is the ninth-largest object in the Solar System, and the largest without a substantial atmosphere.
Ganymede is composed of approximately equal amounts of silicate rock and water ice. It is a fully differentiated body with an iron-rich, liquid core, and an internal ocean that may contain more water than all of Earth's oceans combined. Its surface is composed of two main types of terrain. Dark regions, saturated with impact craters and dated to four billion years ago, cover about a third of the satellite. Lighter regions, crosscut by extensive grooves and ridges and only slightly less ancient, cover the remainder. The cause of the light terrain's disrupted geology is not fully known, but was likely the result of tectonic activity brought about by tidal heating.
Ganymede's magnetosphere was probably created through convection within its liquid iron core. The meager magnetosphere is buried within Jupiter's much larger magnetic field and would show only as a local perturbation of the field lines. The satellite has a thin oxygen atmosphere that includes O, O2, and possibly O3 (ozone). Atomic hydrogen is a minor atmospheric constituent. Whether the satellite has an ionosphere associated with its atmosphere is unresolved.
Ganymede's discovery is credited to Galileo Galilei, who was the first to observe it on January 7, 1610.
The satellite's name was soon suggested by astronomer Simon Marius, for the mythological Ganymede, cupbearer of the Greek gods and Zeus's lover. Beginning with "Pioneer 10", spacecraft have been able to examine Ganymede closely. The "Voyager" probes refined measurements of its size, whereas the "Galileo" craft discovered its underground ocean and magnetic field. The next planned mission to the Jovian system is the European Space Agency's Jupiter Icy Moon Explorer (JUICE), due to launch in 2022. After flybys of all three icy Galilean moons, the probe is planned to enter orbit around Ganymede.
History.
Chinese astronomical records report that in 365 BC, Gan De detected what appears to have been a moon of Jupiter, probably Ganymede, with the naked eye.
On January 7, 1610, Galileo Galilei observed what he thought were three stars near Jupiter, including what turned out to be Ganymede, Callisto, and one body that turned out to be the combined light from Io and Europa; the next night he noticed that they had moved. On January 13, he saw all four at once for the first time, but had seen each of the moons before this date at least once. By January 15, Galileo came to the conclusion that the stars were actually bodies orbiting Jupiter. He claimed the right to name the moons; he considered "Cosmian Stars" and settled on "Medicean Stars".
The French astronomer Nicolas-Claude Fabri de Peiresc suggested individual names from the Medici family for the moons, but his proposal was not taken up. Simon Marius, who had originally claimed to have found the Galilean satellites, tried to name the moons the "Saturn of Jupiter", the "Jupiter of Jupiter" (this was Ganymede), the "Venus of Jupiter", and the "Mercury of Jupiter", another nomenclature that never caught on. From a suggestion by Johannes Kepler, Marius once again tried to name the moons:
This name and those of the other Galilean satellites fell into disfavor for a considerable time, and were not in common use until the mid-20th century. In much of the earlier astronomical literature, Ganymede is referred to instead by its Roman numeral designation (a system introduced by Galileo) as or as the "third satellite of Jupiter". Following the discovery of moons of Saturn, a naming system based on that of Kepler and Marius was used for Jupiter's moons. Ganymede is the only Galilean moon of Jupiter named after a male figure — like Io, Europa, and Callisto, he was a lover of Zeus.
Orbit and rotation.
Ganymede orbits Jupiter at a distance of 1,070,400 km, third among the Galilean satellites, and completes a revolution every seven days and three hours. Like most known moons, Ganymede is tidally locked, with one side always facing toward the planet. Its orbit is very slightly eccentric and inclined to the Jovian equator, with the eccentricity and inclination changing quasi-periodically due to solar and planetary gravitational perturbations on a timescale of centuries. The ranges of change are 0.0009–0.0022 and 0.05–0.32°, respectively. These orbital variations cause the axial tilt (the angle between rotational and orbital axes) to vary between 0 and 0.33°.
Ganymede participates in orbital resonances with Europa and Io: for every orbit of Ganymede, Europa orbits twice and Io orbits four times. The superior conjunction between Io and Europa always occurs when Io is at periapsis and Europa at apoapsis. The superior conjunction between Europa and Ganymede occurs when Europa is at periapsis. The longitudes of the Io–Europa and Europa–Ganymede conjunctions change with the same rate, making the triple conjunctions impossible. Such a complicated resonance is called the Laplace resonance.
The current Laplace resonance is unable to pump the orbital eccentricity of Ganymede to a higher value. The value of about 0.0013 is probably a remnant from a previous epoch, when such pumping was possible. The Ganymedian orbital eccentricity is somewhat puzzling; if it is not pumped now it should have decayed long ago due to the tidal dissipation in the interior of Ganymede. This means that the last episode of the eccentricity excitation happened only several hundred million years ago. Because the orbital eccentricity of Ganymede is relatively low—0.0015 on average—the tidal heating of this moon is negligible now. However, in the past Ganymede may have passed through one or more Laplace-like resonances that were able to pump the orbital eccentricity to a value as high as 0.01–0.02. This probably caused a significant tidal heating of the interior of Ganymede; the formation of the grooved terrain may be a result of one or more heating episodes.
There are two hypotheses for the origin of the Laplace resonance among Io, Europa, and Ganymede: that it is primordial and has existed from the beginning of the Solar System; or that it developed after the formation of the Solar System. A possible sequence of events for the latter scenario is as follows: Io raised tides on Jupiter, causing its orbit to expand until it encountered the 2:1 resonance with Europa; after that the expansion continued, but some of the angular moment was transferred to Europa as the resonance caused its orbit to expand as well; the process continued until Europa encountered the 2:1 resonance with Ganymede. Eventually the drift rates of conjunctions between all three moons were synchronized and locked in the Laplace resonance.
Physical characteristics.
Composition.
The average density of Ganymede, 1.936 g/cm3, suggests a composition of approximately equal parts rocky material and water, which is mainly in the form of ice. The mass fraction of ices is between 46–50%, slightly lower than that in Callisto. Some additional volatile ices such as ammonia may also be present. The exact composition of Ganymede's rock is not known, but is probably close to the composition of L/LL type ordinary chondrites, which are characterized by less total iron, less metallic iron and more iron oxide than H chondrites. The weight ratio of iron to silicon is 1.05–1.27 in Ganymede, whereas the solar ratio is around 1.8.
Ganymede's surface has an albedo of about 43%. Water ice seems to be ubiquitous on the surface, with a mass fraction of 50–90%, significantly more than in Ganymede as a whole. Near-infrared spectroscopy has revealed the presence of strong water ice absorption bands at wavelengths of 1.04, 1.25, 1.5, 2.0 and 3.0 μm. The grooved terrain is brighter and has more icy composition than the dark terrain. The analysis of high-resolution, near-infrared and UVspectra obtained by the "Galileo" spacecraft and from the ground has revealed various non-water materials: carbon dioxide, sulfur dioxide and, possibly, cyanogen, hydrogen sulfate and various organic compounds. "Galileo" results have also shown magnesium sulfate (MgSO4) and, possibly, sodium sulfate (Na2SO4) on Ganymede's surface. These salts may originate from the subsurface ocean.
The Ganymedian surface is asymmetric; the leading hemisphere is brighter than the trailing one. This is similar to Europa, but the reverse is true for Callisto. The trailing hemisphere of Ganymede appears to be enriched in sulfur dioxide. The distribution of carbon dioxide does not demonstrate any hemispheric asymmetry, although it is not observed near the poles. Impact craters on Ganymede (except one) do not show any enrichment in carbon dioxide, which also distinguishes it from Callisto. Ganymede's carbon dioxide gas was probably depleted in the past.
Internal structure.
Ganymede appears to be fully differentiated, consisting of an iron sulfide–iron core and a silicate mantle. The precise thicknesses of the different layers in the interior of Ganymede depend on the assumed composition of silicates (fraction of olivine and pyroxene) and amount of sulfur in the core.
Subsurface oceans.
In the 1970s, NASA scientists first suspected that Ganymede has a thick ocean between two layers of ice, one on the top and one on the bottom. In the 1990s, NASA's "Galileo" mission flew by Ganymede, confirming the moon's ocean. An analysis published in 2014, taking into account the realistic thermodynamics for water and effects of salt, suggests that Ganymede might have a stack of several ocean layers separated by different phases of ice, with the lowest liquid layer adjacent to the rocky mantle below. Water–rock contact may be an important factor in the origin of life. The analysis also notes that the extreme depths involved (~800 km to the rocky "seafloor") mean that temperatures at the bottom of a convective (adiabatic) ocean can be up to 40 K higher than those at the ice–water interface. In March 2015, scientists reported how measurements with the Hubble Space Telescope showed that Ganymede has a subsurface ocean by studying how the aurorae moved over Ganymede's surface. A large salt-water ocean affects Ganymede's magnetic field, and consequently, its aurora.
There is some speculation on the potential habitability of Ganymede's ocean.
Core.
Ganymede has the lowest moment of inertia factor among the solid Solar System bodies. The existence of a liquid, iron–nickel-rich core provides a natural explanation for the intrinsic magnetic field of Ganymede detected by "Galileo" spacecraft. The convection in the liquid iron, which has high electrical conductivity, is the most reasonable model of magnetic field generation. The density of the core is 5.5–6 g/cm3 and the silicate mantle is 3.4–3.6 g/cm3. The radius of this core may be up to 500 km. The temperature in the core of Ganymede is probably 1500–1700 K and pressure up to 10 GPa.
Surface features.
Ganymede's surface is a mix of two types of terrain: very old, highly cratered, dark regions and somewhat younger (but still ancient), lighter regions marked with an extensive array of grooves and ridges. The dark terrain, which comprises about one-third of the surface, contains clays and organic materials that could indicate the composition of the impactors from which Jovian satellites accreted.
The heating mechanism required for the formation of the grooved terrain on Ganymede is an unsolved problem in the planetary sciences. The modern view is that the grooved terrain is mainly tectonic in nature. Cryovolcanism is thought to have played only a minor role, if any. The forces that caused the strong stresses in the Ganymedian ice lithosphere necessary to initiate the tectonic activity may be connected to the tidal heating events in the past, possibly caused when the satellite passed through unstable orbital resonances. The tidal flexing of the ice may have heated the interior and strained the lithosphere, leading to the development of cracks and horst and graben faulting, which erased the old, dark terrain on 70% of the surface. The formation of the grooved terrain may also be connected with the early core formation and subsequent tidal heating of Ganymede's interior, which may have caused a slight expansion of Ganymede by 1–6% due to phase transitions in ice and thermal expansion. During subsequent evolution deep, hot water plumes may have risen from the core to the surface, leading to the tectonic deformation of the lithosphere. Radiogenic heating within the satellite is the most relevant current heat source, contributing, for instance, to ocean depth. Research models have found that if the orbital eccentricity were an order of magnitude greater than currently (as it may have been in the past), tidal heating would be a more substantial heat source than radiogenic heating.
Cratering is seen on both types of terrain, but is especially extensive on the dark terrain: it appears to be saturated with impact craters and has evolved largely through impact events. The brighter, grooved terrain contains many fewer impact features, which have been only of a minor importance to its tectonic evolution. The density of cratering indicates an age of 4 billion years for the dark terrain, similar to the highlands of the Moon, and a somewhat younger age for the grooved terrain (but how much younger is uncertain). Ganymede may have experienced a period of heavy cratering 3.5 to 4 billion years ago similar to that of the Moon. If true, the vast majority of impacts happened in that epoch, whereas the cratering rate has been much smaller since. Craters both overlay and are crosscut by the groove systems, indicating that some of the grooves are quite ancient. Relatively young craters with rays of ejecta are also visible. Ganymedian craters are flatter than those on the Moon and Mercury. This is probably due to the relatively weak nature of Ganymede's icy crust, which can (or could) flow and thereby soften the relief. Ancient craters whose relief has disappeared leave only a "ghost" of a crater known as a palimpsest.
One significant feature on Ganymede is a dark plain named Galileo Regio, which contains a series of concentric grooves, or furrows, likely created during a period of geologic activity.
Ganymede also has polar caps, likely composed of water frost. The frost extends to 40° latitude. These polar caps were first seen by the "Voyager" spacecraft. Theories on the formation of the caps include the migration of water to higher latitudes and bombardment of the ice by plasma. Data from "Galileo" suggests the latter is correct. The presence of a magnetic field on Ganymede results in more intense charged particle bombardment of its surface in the unprotected polar regions; sputtering then leads to redistribution of water molecules, with frost migrating to locally colder areas within the polar terrain.
A crater named Anat provides the reference point for measuring longitude on Ganymede. By definition, Anat is at 128 degrees longitude.
Atmosphere and ionosphere.
In 1972, a team of Indian, British and American astronomers working in Java (Indonesia) and Kavalur (India) claimed that they had detected a thin atmosphere during an occultation, when it and Jupiter passed in front of a star. They estimated that the surface pressure was around 0.1 Pa. However, in 1979, "Voyager 1" observed an occultation of the star κ Centauri during its flyby of Jupiter, with differing results. The occultation measurements were conducted in the far-ultraviolet spectrum at wavelengths shorter than 200 nm, which were much more sensitive to the presence of gases than the 1972 measurements in the visible spectrum. No atmosphere was revealed by the "Voyager" data. The upper limit on the surface particle number density was found to be , which corresponds to a surface pressure of less than 2.5 µPa. The latter value is almost five orders of magnitude less than the 1972 estimate.
Despite the "Voyager" data, evidence for a tenuous oxygen atmosphere (exosphere) on Ganymede, very similar to the one found on Europa, was found by the Hubble Space Telescope (HST) in 1995. HST actually observed airglow of atomic oxygen in the far-ultraviolet at the wavelengths 130.4 nm and 135.6 nm. Such an airglow is excited when molecular oxygen is dissociated by electron impacts, evidence of a significant neutral atmosphere composed predominantly of O2 molecules. The surface number density probably lies in the range, corresponding to the surface pressure of . These values are in agreement with the "Voyager"'s upper limit set in 1981. The oxygen is not evidence of life; it is thought to be produced when water ice on Ganymede's surface is split into hydrogen and oxygen by radiation, with the hydrogen then being more rapidly lost due to its low atomic mass. The airglow observed over Ganymede is not spatially homogeneous like that over Europa. HST observed two bright spots located in the northern and southern hemispheres, near ± 50° latitude, which is exactly the boundary between the open and closed field lines of the Ganymedian magnetosphere (see below). The bright spots are probably polar auroras, caused by plasma precipitation along the open field lines.
The existence of a neutral atmosphere implies that an ionosphere should exist, because oxygen molecules are ionized by the impacts of the energetic electrons coming from the magnetosphere and by solar EUV radiation. However, the nature of the Ganymedian ionosphere is as controversial as the nature of the atmosphere. Some "Galileo" measurements found an elevated electron density near Ganymede, suggesting an ionosphere, whereas others failed to detect anything. The electron density near the surface is estimated by different sources to lie in the range 400–2,500 cm−3. As of 2008, the parameters of the ionosphere of Ganymede are not well constrained.
Additional evidence of the oxygen atmosphere comes from spectral detection of gases trapped in the ice at the surface of Ganymede. The detection of ozone (O3) bands was announced in 1996. In 1997 spectroscopic analysis revealed the dimer (or diatomic) absorption features of molecular oxygen. Such an absorption can arise only if the oxygen is in a dense phase. The best candidate is molecular oxygen trapped in ice. The depth of the dimer absorption bands depends on latitude and longitude, rather than on surface albedo—they tend to decrease with increasing latitude on Ganymede, whereas O3 shows an opposite trend. Laboratory work has found that O2 would not cluster or bubble but dissolve in ice at Ganymede's relatively warm surface temperature of 100 K (-173 °C).
A search for sodium in the atmosphere, just after such a finding on Europa, turned up nothing in 1997. Sodium is at least 13 times less abundant around Ganymede than around Europa, possibly because of a relative deficiency at the surface or because the magnetosphere fends off energetic particles. Another minor constituent of the Ganymedian atmosphere is atomic hydrogen. Hydrogen atoms were observed as far as 3,000 km from Ganymede's surface. Their density on the surface is about .
Magnetosphere.
The "Galileo" craft made six close flybys of Ganymede from 1995–2000 (G1, G2, G7, G8, G28 and G29) and discovered that Ganymede has a permanent (intrinsic) magnetic moment independent of the Jovian magnetic field. The value of the moment is about , which is three times larger than the magnetic moment of Mercury. The magnetic dipole is tilted with respect to the rotational axis of Ganymede by 176°, which means that it is directed against the Jovian magnetic moment. Its north pole lies below the orbital plane. The dipole magnetic field created by this permanent moment has a strength of 719 ± 2 nT at Ganymede's equator, which should be compared with the Jovian magnetic field at the distance of Ganymede—about 120 nT. The equatorial field of Ganymede is directed against the Jovian field, meaning reconnection is possible. The intrinsic field strength at the poles is two times that at the equator—1440 nT.
The permanent magnetic moment carves a part of space around Ganymede, creating a tiny magnetosphere embedded inside that of Jupiter; it is the only moon in the Solar System known to possess the feature. Its diameter is 4–5 "R"G ("R"G = 2,631.2 km). The Ganymedian magnetosphere has a region of closed field lines located below 30° latitude, where charged particles (electrons and ions) are trapped, creating a kind of radiation belt. The main ion species in the magnetosphere is single ionized oxygen—O+—which fits well with Ganymede's tenuous oxygen atmosphere. In the polar cap regions, at latitudes higher than 30°, magnetic field lines are open, connecting Ganymede with Jupiter's ionosphere. In these areas, the energetic (tens and hundreds of kiloelectronvolt) electrons and ions have been detected, which may cause the auroras observed around the Ganymedian poles. In addition, heavy ions continuously precipitate on Ganymede's polar surface, sputtering and darkening the ice.
The interaction between the Ganymedian magnetosphere and Jovian plasma is in many respects similar to that of the solar wind and Earth's magnetosphere. The plasma co-rotating with Jupiter impinges on the trailing side of the Ganymedian magnetosphere much like the solar wind impinges on the Earth's magnetosphere. The main difference is the speed of plasma flow—supersonic in the case of Earth and subsonic in the case of Ganymede. Because of the subsonic flow, there is no bow shock off the trailing hemisphere of Ganymede.
In addition to the intrinsic magnetic moment, Ganymede has an induced dipole magnetic field. Its existence is connected with the variation of the Jovian magnetic field near Ganymede. The induced moment is directed radially to or from Jupiter following the direction of the varying part of the planetary magnetic field. The induced magnetic moment is an order of magnitude weaker than the intrinsic one. The field strength of the induced field at the magnetic equator is about 60 nT—half of that of the ambient Jovian field. The induced magnetic field of Ganymede is similar to those of Callisto and Europa, indicating that this moon also has a subsurface water ocean with a high electrical conductivity.
Given that Ganymede is completely differentiated and has a metallic core, its intrinsic magnetic field is probably generated in a similar fashion to the Earth's: as a result of conducting material moving in the interior. The magnetic field detected around Ganymede is likely to be caused by compositional convection in the core, if the magnetic field is the product of dynamo action, or magnetoconvection.
Despite the presence of an iron core, Ganymede's magnetosphere remains enigmatic, particularly given that similar bodies lack the feature. Some research has suggested that, given its relatively small size, the core ought to have sufficiently cooled to the point where fluid motions and a magnetic field would not be sustained. One explanation is that the same orbital resonances proposed to have disrupted the surface also allowed the magnetic field to persist: with Ganymede's eccentricity pumped and tidal heating increased during such resonances, the mantle may have insulated the core, preventing it from cooling. Another explanation is a remnant magnetization of silicate rocks in the mantle, which is possible if the satellite had a more significant dynamo-generated field in the past.
Origin and evolution.
Ganymede probably formed by an accretion in Jupiter's subnebula, a disk of gas and dust surrounding Jupiter after its formation. The accretion of Ganymede probably took about 10,000 years, much shorter than the 100,000 years estimated for Callisto. The Jovian subnebula may have been relatively "gas-starved" when the Galilean satellites formed; this would have allowed for the lengthy accretion times required for Callisto. In contrast Ganymede formed closer to Jupiter, where the subnebula was denser, which explains its shorter formation timescale. This relatively fast formation prevented the escape of accretional heat, which may have led to ice melt and differentiation: the separation of the rocks and ice. The rocks settled to the center, forming the core. In this respect, Ganymede is different from Callisto, which apparently failed to melt and differentiate early due to loss of the accretional heat during its slower formation. This hypothesis explains why the two Jovian moons look so dissimilar, despite their similar mass and composition. Alternative theories explain Ganymede's greater internal heating on the basis of tidal flexing or more intense pummeling by impactors during the Late Heavy Bombardment.
After formation, Ganymede's core largely retained the heat accumulated during accretion and differentiation, only slowly releasing it to the ice mantle. The mantle, in turn, transported it to the surface by convection. The decay of radioactive elements within rocks further heated the core, causing increased differentiation: an inner, iron–iron-sulfide core and a silicate mantle formed. With this, Ganymede became a fully differentiated body. By comparison, the radioactive heating of undifferentiated Callisto caused convection in its icy interior, which effectively cooled it and prevented large-scale melting of ice and rapid differentiation. The convective motions in Callisto have caused only a partial separation of rock and ice. Today, Ganymede continues to cool slowly. The heat being released from its core and silicate mantle enables the subsurface ocean to exist, whereas the slow cooling of the liquid Fe–FeS core causes convection and supports magnetic field generation. The current heat flux out of Ganymede is probably higher than that out of Callisto.
Exploration.
Several probes flying by or orbiting Jupiter have explored Ganymede more closely, including four flybys in the 1970s, and multiple passes in the 1990s to 2000s.
"Pioneer 10" approached in 1973 and "Pioneer 11" in 1974, and they returned information about the satellite. This included more specific determination on physical characteristics and resolving features to on its surface. Pioneer 10's closest approach was 446,250 km.
"Voyager 1" and "Voyager 2" were next, passing by Ganymede in 1979. They refined its size, revealing it was larger than Saturn's moon Titan, which was previously thought to have been bigger. The grooved terrain was also seen.
In 1995, the "Galileo" spacecraft entered orbit around Jupiter and between 1996 and 2000 made six close flybys to explore Ganymede. These flybys are G1, G2, G7, G8, G28 and G29. During the closest flyby—G2—"Galileo" passed just 264 km from the surface of Ganymede. During a G1 flyby in 1996, the Ganymedian magnetic field was discovered, while the discovery of the ocean was announced in 2001. "Galileo" transmitted a large number of spectral images and discovered several non-ice compounds on the surface of Ganymede. The most recent close observations of Ganymede were made by "New Horizons", which recorded topographic and compositional mapping data of Europa and Ganymede during its flyby of Jupiter in 2007 en route to Pluto.
Mission concepts.
The Europa Jupiter System Mission (EJSM), had a proposed launch date in 2020, and was a joint NASA and ESA proposal for exploration of many of Jupiter's moons including Ganymede. In February 2009 it was announced that ESA and NASA had given this mission priority ahead of the Titan Saturn System Mission. EJSM consisted of the NASA-led Jupiter Europa Orbiter, the ESA-led Jupiter Ganymede Orbiter, and possibly a JAXA-led Jupiter Magnetospheric Orbiter. ESA's contribution faced funding competition from other ESA projects but on 2 May 2012 the European part of the mission, renamed Jupiter Icy Moon Explorer (JUICE), obtained a L1 launch slot in 2022 with a Ariane 5 in the ESA's Cosmic Vision science programme. The spacecraft will orbit Ganymede and conduct multiple flyby investigations of Callisto and Europa.
The Russian Space Research Institute is currently evaluating the Ganymede Lander (GL) mission, with emphasis on astrobiology. The Ganymede Lander would be a partner mission for JUpiter ICy moon Explorer (JUICE). If selected, it would be launched in 2024, though this schedule might be revised and aligned with JUICE.
A Ganymede orbiter based on the Juno probe was proposed in 2010 for the Planetary Science Decadal Survey. Possible instruments include Medium Resolution Camera, Flux Gate Magnetometer, Visible/NIR Imaging Spectrometer, Laser Altimeter, Low and High Energy Plasma Packages, Ion and Neutral Mass Spectrometer, UV Imaging Spectrometer, Radio and Plasma Wave sensor, Narrow Angle Camera, and a Sub-Surface Radar.
Another canceled proposal to orbit Ganymede was the Jupiter Icy Moons Orbiter. It was designed to use nuclear fission for power, ion engine propulsion, and would have studied Ganymede in greater detail than previously. However, the mission was canceled in 2005 because of budget cuts. Another old proposal was called The Grandeur of Ganymede.

</doc>
<doc id="54215" url="https://en.wikipedia.org/wiki?curid=54215" title="Dutch euro coins">
Dutch euro coins

Dutch euro coins currently use two designs by Erwin Olaf, both of which feature a portrait of King Willem-Alexander of the Netherlands. The new designs began circulating in 2014. Dutch Euro coins minted from 1999 to 2013 feature a portrait of Queen Beatrix designed by Bruno Ninaber van Eyben. All coins share the 12 stars of the EU and the year of imprint in their design.
As is the case in Finland, most Dutch shops have elected not to issue one and two cent coins starting on September 1, 2004, though the coins remain legal tender. Sums are rounded to the nearest €0.05; sums ending in €0.01, €0.02, €0.06 or €0.07 are rounded down, and those ending in €0.03, €0.04, €0.08 or €0.09 are rounded up. The rounding is applied to the grand total only, while individual prices are still shown and summed up with €0.01 precision. This method is known as "Swedish rounding".
Dutch euro design.
For images of the common side and a detailed description of the coins, see euro coins.
Second series (2014-present): King Willem Alexander.
Following the accession to the throne of King Willem-Alexander, a new series of euro coins was issued depicting the effigy of the new Head of State.
Changes to national sides.
The Commission of the European Communities issued a recommendation on 19 December 2008, a common guideline for the national sides and the issuance of euro coins intended for circulation. One section of this recommendation stipulates that:
The first series of the Dutch euro coins did not comply with this recommendation. No efforts were made to amend these coins to make them compliant.
King Willem Alexander.
Queen Beatrix abdicated on 30 April 2013, so the design of the coins was changed for her heir, King Willem-Alexander of the Netherlands. The new coins were made to be in accordance with this recommendation. 
The Royal Dutch Mint presented the new design to the public on 31 October 2013 and began releasing them into circulation in early 2014.(see [http://www.knm.nl/Het-ontwerp/nl/page/831/]).
Production of the new coins commenced on 22 January 2014. The first coins were released into circulation the next day.

</doc>
<doc id="54216" url="https://en.wikipedia.org/wiki?curid=54216" title="Danyon Loader">
Danyon Loader

Danyon Joseph Loader, ONZM (born 21 April 1975) is an Olympic champion, former world record holder swimmer from New Zealand, based in Dunedin. He remains the national record holder in the 400 and 1500 metre freestyle short course.
He swam for New Zealand at two Summer Olympics (1992, 1996) and three Commonwealth Games (1990, 1994 and 1998).
At the 1992 Olympics in Barcelona, he garnered a silver medal in the 200 metre butterfly. In 1996 in Atlanta, Loader won two gold medals: in the 200 and 400 metre freestyle. He set world records in the short course 200 butterfly and 400 freestyle; and was inducted into the International Swimming Hall of Fame in 2003.
He has recently reappeared on the local swimming scene after years spent away from it. He is now interested in coaching and takes part in youth development programmes. He is currently coaching at Raumati Swimming Club with fellow swim star Jon Winter.
In December 2012, Loader starred in an online video campaign supporting same-sex marriage, alongside New Zealand singers Anika Moa, Hollie Smith and Boh Runga, as well as former Governor-General Dame Catherine Tizard.
References.
<br>

</doc>
<doc id="54217" url="https://en.wikipedia.org/wiki?curid=54217" title="Pigeonhole principle">
Pigeonhole principle

In mathematics, the pigeonhole principle states that if items are put into containers, with , then at least one container must contain more than one item. This theorem is exemplified in real-life by truisms like "there must be at least two left gloves or two right gloves in a group of three gloves". It is an example of a counting argument, and despite seeming intuitive it can be used to demonstrate possibly unexpected results; for example, that two people in London have the same number of hairs on their heads (see below).
The first formalization of the idea is believed to have been made by Peter Gustav Lejeune Dirichlet in 1834 under the name "Schubfachprinzip" ("drawer principle" or "shelf principle"). For this reason it is also commonly called Dirichlet's box principle, Dirichlet's drawer principle or simply "Dirichlet's principle" — a name that could also refer to the minimum principle for harmonic functions. The original "drawer" name is still in use in French ("principe des tiroirs"), Polish ("zasada szufladkowa"), Bulgarian ("принцип на чекмеджетата"), Turkish ("çekmece ilkesi"), Hungarian ("skatulyaelv"), Italian ("principio dei cassetti"), German ("Schubfachprinzip"), Dutch ("ladenprincipe "), Danish ("Skuffeprincippet"), and Chinese ("抽屉原理").
The principle has several generalizations and can be stated in various ways. In a more quantified version: for natural numbers and , if objects are distributed among sets, then the pigeonhole principle asserts that at least one of the sets will contain at least objects. For arbitrary and this generalizes to , where is the floor function. 
Though the most straightforward application is to finite sets (such as pigeons and boxes), it is also used with infinite sets that cannot be put into one-to-one correspondence. To do so requires the formal statement of the pigeonhole principle, which is ""there does not exist an injective function whose codomain is smaller than its domain"". Advanced mathematical proofs like Siegel's lemma build upon this more general concept.
Examples.
Sock-picking.
Assume you have a mixture of black socks and blue socks, what is the minimum number of socks needed before a pair of the same color can be guaranteed? Using the pigeonhole principle, to have at least one pair of the same color holes, one per color) using one pigeonhole per color, you need only three socks items).
Hand-shaking.
If there are people who can shake hands with one another (where ), the pigeonhole principle shows that there is always a pair of people who will shake hands with the same number of people. As the 'holes', or , correspond to number of hands shaken, and each person can shake hands with anybody from 0 to other people, this creates possible holes. This is because either the '0' or the hole must be empty (if one person shakes hands with everybody, it's not possible to have another person who shakes hands with nobody; likewise, if one person shakes hands with no one there cannot be a person who shakes hands with everybody). This leaves people to be placed in at most non-empty holes, guaranteeing duplication.
Hair-counting.
We can demonstrate there must be at least two people in London with the same number of hairs on their heads as follows. Since a typical human head has an average of around 150,000 hairs, it is reasonable to assume (as an upper bound) that no one has more than 1,000,000 hairs on their head holes). There are more than 1,000,000 people in London ( is bigger than 1 million items). Assigning a pigeonhole to each number of hairs on a person's head, and assign people to pigeonholes according to the number of hairs on their head, there must be at least two people assigned to the same pigeonhole by the 1,000,001st assignment (because they have the same number of hairs on their heads) (or, ). For the average case () with the constraint: fewest overlaps, there will be at most one person assigned to every pigeonhole and the 150,001st person assigned to the same pigeonhole as someone else. In the absence of this constraint, there may be empty pigeonholes because the "collision" happens before we get to the 150,001st person. The principle just proves the existence of an overlap; it says nothing of the number of overlaps (which falls under the subject of Probability Distribution).
The birthday problem.
The birthday problem asks, for a set of randomly chosen people, what is the probability that some pair of them will have the same birthday? By the pigeonhole principle, if there are 367 people in the room, we know that there is at least one pair who share the same birthday, as there are only 366 possible birthdays to choose from (including February 29, if present). 
The birthday "paradox" refers to the result that even if the group is as small as 23 individuals, there will still be a pair of people with the same birthday with a 50% probability. While at first glance this may seem surprising, it intuitively makes sense when considering that a comparison will actually be made between every possible pair of people rather than fixing one individual and comparing them solely to the rest of the group.
Softball team.
Imagine seven people who want to play softball items), with a limitation of only four softball teams holes) to choose from. The pigeonhole principle tells us that they cannot all play for different teams; there must be at least one team featuring at least two of the seven players: 
Subset sum.
Any subset of size six from the set = {1,2,3...,9} must contain two elements whose sum is 10. The pigeonholes will be labelled by the two element subsets {1,9}, {2,8}, {3,7}, {4,6} and the singleton {5}, five pigeonholes in all. When the six "pigeons" (elements of the size six subset) are placed into these pigeonholes, each pigeon going into the pigeonhole that has it contained in its label, at least one of the pigeonholes labelled with a two element subset will have two pigeons in it.
Uses and applications.
The pigeonhole principle arises in computer science. For example, collisions are inevitable in a hash table because the number of possible keys exceeds the number of indices in the array. A hashing algorithm, no matter how clever, cannot avoid these collisions.
The principle can be used to prove that any lossless compression algorithm, provided it makes some inputs smaller (as the name compression suggests), will also make some other inputs larger. Otherwise, the set of all input sequences up to a given length could be mapped to the (much) smaller set of all sequences of length less than without collisions (because the compression is lossless), a possibility which the pigeonhole principle excludes.
A notable problem in mathematical analysis is, for a fixed irrational number , to show that the set {[ is an integer} of fractional parts is dense in One finds that it is not easy to explicitly find integers such that , where is a small positive number and is some arbitrary irrational number. But if one takes such that , by the pigeonhole principle there must be } such that and are in the same integer subdivision of size (there are only such subdivisions between consecutive integers). In particular, we can find such that is in , and is in , for some integers and in }. We can then easily verify that is in . This implies that , where or . This shows that 0 is a limit point of {[}. We can then use this fact to prove the case for in : find such that ; then if ], we are done. Otherwise ], and by setting }, one obtains .
Alternate formulations.
The following are alternate formulations of the pigeonhole principle.
Strong form.
Let be positive integers. If
objects are distributed into boxes, then either the first box contains at least objects, or the second box contains at least objects, ..., or the th box contains at least objects.
The simple form is obtained from this by taking , which gives objects. Taking gives the more quantified version of the principle, namely:
Let and be positive integers. If objects are distributed into boxes, then at least one of the boxes contains or more of the objects. 
This can also be stated as, if discrete objects are to be allocated to containers, then at least one container must hold at least formula_3 objects, where formula_4 is the ceiling function, denoting the smallest integer larger than or equal to . 
Similarly, at least one container must hold no more than formula_5 objects, where formula_6 is the floor function, denoting the largest integer smaller than or equal to .
Generalizations of the pigeonhole principle.
A probabilistic generalization of the pigeonhole principle states that if pigeons are randomly put into pigeonholes with uniform probability , then at least one pigeonhole will hold more than one pigeon with probability
where is the falling factorial . For and for (and ), that probability is zero; in other words, if there is just one pigeon, there cannot be a conflict. For (more pigeons than pigeonholes) it is one, in which case it coincides with the ordinary pigeonhole principle. But even if the number of pigeons does not exceed the number of pigeonholes (), due to the random nature of the assignment of pigeons to pigeonholes there is often a substantial chance that clashes will occur. For example, if 2 pigeons are randomly assigned to 4 pigeonholes, there is a 25% chance that at least one pigeonhole will hold more than one pigeon; for 5 pigeons and 10 holes, that probability is 69.76%; and for 10 pigeons and 20 holes it is about 93.45%. If the number of holes stays fixed, there is always a greater probability of a pair when you add more pigeons. This problem is treated at much greater length in the birthday paradox.
A further probabilistic generalization is that when a real-valued random variable has a finite mean , then the probability is nonzero that is greater than or equal to , and similarly the probability is nonzero that is less than or equal to . To see that this implies the standard pigeonhole principle, take any fixed arrangement of pigeons into holes and let be the number of pigeons in a hole chosen uniformly at random. The mean of is , so if there are more pigeons than holes the mean is greater than one. Therefore, is sometimes at least 2.
Infinite sets.
The pigeonhole principle can be extended to infinite sets by phrasing it in terms of cardinal numbers: if the cardinality of set is greater than the cardinality of set , then there is no injection from to . However, in this form the principle is tautological, since the meaning of the statement that the cardinality of set is greater than the cardinality of set is exactly that there is no injective map from to . However, adding at least one element to a finite set is sufficient to ensure that the cardinality increases. 
Another way to phrase the pigeonhole principle for finite sets is similar to the principle that finite sets are Dedekind finite: Let and be finite sets. If there is a surjection from to that is not injective, then no surjection from to is injective. In fact no function of any kind from to is injective. This is not true for infinite sets: Consider the function on the natural numbers that sends 1 and 2 to 1, 3 and 4 to 2, 5 and 6 to 3, and so on. 
There is a similar principle for infinite sets: If uncountably many pigeons are stuffed into countably many pigeonholes, there will exist at least one pigeonhole having uncountably many pigeons stuffed into it. 
This principle is not a generalization of the pigeonhole principle for finite sets however: It is in general false for finite sets. In technical terms it says that if and are finite sets such that any surjective function from to is not injective, then there exists an element of of such that there exists a bijection between the preimage of and . This is a quite different statement, and is absurd for large finite cardinalities.
Quantum mechanics.
Yakir Aharonov et al. has demonstrated mathematically the pigeonhole principle may be violated in quantum mechanics, and proposed interferometric experiments to test the pigeonhole principle in quantum mechanics.
[http://www.pnas.org/content/113/3/532.full?sid=c1d239b5-57f0-46af-a56d-5cbc963c37f4]

</doc>
<doc id="54218" url="https://en.wikipedia.org/wiki?curid=54218" title="Edgar the Ætheling">
Edgar the Ætheling

Edgar (the) Ætheling (also spelt Æþeling, Aetheling, Atheling or Etheling) or Edgar II (c. 1051 – c. 1126) was the last male member of the royal house of Cerdic of Wessex (see House of Wessex family tree). He was proclaimed, but never crowned, King of England in 1066. He was made Earl of Oxford by Harold II in January 1066 and Edgar was allowed to regain the title by William I after his abdication in December 1066. Edgar forfeited the title permanently in 1068 after his rebellion against William.
Family and early life.
Edgar was born in Hungary, where his father Edward the Exile, son of King Edmund II Ironside, had spent most of his life, having been sent into exile after Edmund's death and the conquest of England by the Danish king Cnut the Great in 1016. His mother was Agatha, who was described as a relative of the German Emperor, but whose exact identity is unknown. He was his parents' only son but had two sisters, Margaret and Cristina.
In 1057 the childless king of England, Edmund Ironside's half-brother Edward the Confessor, who had only recently become aware that his nephew was still alive, summoned Edward back to England with his family to take up his place at court as heir to the throne. The returning exile died in uncertain circumstances shortly after his arrival in England. Edgar, at only six years old, was left as the only surviving male member of the royal dynasty apart from the king. However, the latter made no recorded effort to entrench his grand-nephew's position as heir to a throne which was being eyed by a range of powerful potential contenders including England's leading aristocrat Harold Godwinson, Earl of Wessex, and the foreign rulers William II of Normandy, Sweyn II of Denmark and Harald III of Norway.
Succession struggle.
When King Edward died in January 1066, Edgar was still in his early teens, too young to be an effective military leader. This had not previously been an insurmountable obstacle: the earlier kings of England Eadwig, Edgar the Peaceful and Edward the Martyr had all come to the throne at a similar age, while Æthelred the Unready had been significantly younger at his accession. However, the avaricious ambitions which had been aroused across north-western Europe by Edward the Confessor's lack of an heir prior to 1057, and by the king's failure thereafter to prepare the way for Edgar to succeed him, removed any prospect of a peaceful hereditary succession. War was clearly inevitable and Edgar was in no position to fight it, while he was without powerful adult relatives to champion his cause. Accordingly, the Witenagemot elected Harold Godwinson, the man best placed to defend the country against the competing foreign claimants, to succeed Edward. Edgar was created the first Earl of Oxford by the new king.
Following Harold's death at the Battle of Hastings against the invading Normans in October, the Witenagemot assembled in London and elected Edgar king. The new regime thus established was dominated by the most powerful surviving members of the English ruling class: Stigand, Archbishop of Canterbury, Ealdred, Archbishop of York, and the brothers Edwin, Earl of Mercia and Morcar, Earl of Northumbria. The commitment of these men to Edgar's cause, men who had so recently passed over his claim to the throne without apparent demur, must have been doubtful from the start. The strength of their resolve to continue the struggle against William of Normandy was questionable and the military response they organised to the continuing Norman advance was ineffectual. When William crossed the Thames at Wallingford he was met by Stigand, who now abandoned Edgar and submitted to the invader. As the Normans closed in on London, Edgar's key supporters in the city began negotiating with William. In early December the remaining members of the Witan in London met and resolved to take the young uncrowned king out to meet William to submit to him at Berkhamsted, quietly setting aside Edgar's election. Edgar, alongside other lords, did homage to King William at his coronation in December and was confirmed in the earldom of Oxford.
Exile and war against the Normans.
William kept Edgar in his custody and took him, along with other English leaders, to his court in Normandy in 1067, before returning with them to England. Edgar may have been involved in the abortive rebellion of the Earls Edwin and Morcar in 1068 or he may have been attempting to return to Hungary with his family and been blown off course; in any case, in that year he arrived with his mother and sisters at the court of King Malcolm III Canmore of Scotland. Malcolm married Edgar's sister Margaret and agreed to support Edgar in his attempt to reclaim the English throne. When a major rebellion broke out in Northumbria at the beginning of 1069, Edgar returned to England with other rebels who had fled to Scotland, to become the leader, or at least the figurehead, of the revolt. However, after early successes the rebels were defeated by William at York and Edgar again sought refuge with Malcolm. In late summer that year the arrival of a fleet sent by King Sweyn of Denmark triggered a fresh wave of English uprisings in various parts of the country. Edgar and the other exiles sailed to the Humber, where they linked up with Northumbrian rebels and the Danes. Their combined forces overwhelmed the Normans at York and took control of Northumbria, but a small seaborne raid which Edgar led into the Kingdom of Lindsey ended in disaster and he escaped with only a handful of followers to rejoin the main army. Late in the year William fought his way into Northumbria and occupied York, buying off the Danes and devastating the surrounding country. Early in 1070 he moved against Edgar and other English leaders who had taken refuge with their remaining followers in a marshy region, perhaps Holderness, and put them to flight. Edgar returned to Scotland.
He remained there until 1072, when William invaded Scotland and forced King Malcolm to submit to his overlordship. The terms of the agreement between them probably included the expulsion of Edgar. He therefore took up residence in Flanders, whose count, Robert the Frisian, was hostile to the Normans. However, in 1074 he was able to return to Scotland. Shortly after his arrival there he received an offer from Philip I, King of France, who was also at odds with William, of a castle and lands near the borders of Normandy from where he would be able to raid his enemies' homeland. He embarked with his followers for France, but a storm wrecked their ships on the English coast. Many of Edgar's men were hunted down by the Normans, but he managed to escape with the remainder to Scotland by land. Following this disaster, he was persuaded by Malcolm to make peace with William and return to England as his subject, abandoning any ambition of regaining his ancestral throne.
Italian venture.
Disappointed at the level of recompense and respect he received from William, in 1085 Edgar secured the king's permission to emigrate with a retinue of two hundred knights, to seek his fortune in the expanding Norman colony in southern Italy and Sicily. He set out in 1086. The Domesday Book, compiled that year, records only two estates in Hertfordshire with a total annual value of £10 as belonging to Edgar, both of them held from him by a tenant named Godwin. This is an extremely small amount of property for a man of Edgar's standing, and much less than was held by his sister Cristina, the income from whose estates was valued at £58. This is probably because Edgar had given up his English properties when he left for Italy, not intending to return. In that case the recording of the Hertfordshire estates under his name is likely to be an anomaly, reflecting a situation which had recently ceased to apply. The venture in the Mediterranean was evidently not a success; within a few years Edgar returned to England.
Norman and Scottish dynastic strife.
After King William's death in 1087 Edgar supported William's eldest son Robert Curthose, who succeeded him as Duke of Normandy, against his second son, William Rufus, who received the throne of England as William II. According to the historian Orderic Vitalis, Edgar was one of Robert's three principal advisors at this time. The war waged by Robert and his allies to overthrow William ended in defeat in 1091. As part of the resulting settlement between the brothers, Edgar was deprived of lands which he had been granted by Robert. These were presumably former possessions of William and his supporters in Normandy, confiscated by Robert and distributed to his own followers, including Edgar, but restored to their previous owners by the terms of the peace agreement. The disgruntled Edgar travelled once again to Scotland, where Malcolm was preparing for war with William. When William marched north and the two armies confronted one another the kings opted to talk rather than fight. The negotiations were conducted by Edgar on behalf of Malcolm and the newly reconciled Robert Curthose on behalf of William. The resulting agreement included a reconciliation between William and Edgar. However, within months Robert left England, unhappy with William's failure to fulfil the pact between them, and Edgar went with him to Normandy.
Having returned to England, in 1093 Edgar went to Scotland again on a diplomatic mission for William to negotiate with Malcolm, who was dissatisfied with the Norman failure to implement in full the terms of the 1091 treaty. This dispute led to war and within the year Malcolm had invaded England and been killed along with his designated heir Edward, eldest of his sons by Margaret, in the Battle of Alnwick. Malcolm's successor, his brother Donald Bán, drove out the English and French retainers who had risen high in Malcolm's service and had thus aroused the jealousy of the existing Scottish aristocracy. This purge brought him into conflict with the Anglo-Norman monarchy, whose influence in Scotland it had diminished. William helped Malcolm's eldest son Duncan, who had spent many years as a hostage at William I's court and remained there when set at liberty by William II, to overthrow his uncle, but Donald soon regained the throne and Duncan was killed. In 1097 another effort to restore the Anglo-Norman interest through sponsorship of Malcolm's sons was launched and Edgar made yet another journey to Scotland, this time in command of an invading army. Donald was ousted and Edgar installed his nephew and namesake, Malcolm and Margaret's son Edgar, on the Scottish throne.
First Crusade.
Orderic tells us that Edgar was the commander of an English fleet which operated off the coast of the region of Syria in support of the First Crusade, whose crews eventually burned their dilapidated ships and joined the advance by land to Jerusalem. This is doubtful, as this fleet is known to have arrived off the Syrian coast by March 1098: since Edgar invaded Scotland late in 1097, he could not have made the voyage in the time available. It may be though that he travelled overland to the Mediterranean and joined the fleet en route; this is the view taken by Runciman. William of Malmesbury recorded that Edgar made a pilgrimage to Jerusalem in 1102, and it may be that Orderic's report is the product of confusion, conflating the expedition of the English fleet with Edgar's later journey. Some modern historians have suggested that at some point during these years Edgar served in the Varangian Guard of the Byzantine Empire, a unit which was at that time composed primarily of English emigrants, but this is unsupported by evidence. William of Malmesbury stated that on his way back from Jerusalem Edgar was given rich gifts by both the Byzantine and the German emperors, each of whom offered him an honoured place at court, but that he insisted on returning home instead.
Later life.
Back in Europe, Edgar again took the side of Robert Curthose in the internal struggles of the Norman dynasty, this time against Robert's youngest brother who was now Henry I, King of England. He was taken prisoner in the final defeat at the Battle of Tinchebray in 1106, which resulted in Robert being imprisoned for the rest of his life. Edgar was more fortunate: having been taken back to England he was pardoned and released by King Henry. His niece Edith (renamed Matilda), daughter of Malcolm III and Margaret, had married Henry in 1100. Edgar is believed to have travelled to Scotland once more late in life, perhaps around the year 1120. He lived to see the tragic death at sea in November 1120 of William Adeling, the son of his niece Edith and heir to Henry I. Edgar was still alive in 1125 according to William of Malmesbury who was writing at the time. The general consensus is that Edgar died shortly after 1125. The location of his grave is not known.
There is no evidence that Edgar had married or produced children apart from two curious references to an "Edgar Adeling" found in the "Magnus Rotulus Pipae Northumberland" (Pipe rolls) for the years 1158 and 1167. Historian Edward Freeman, writing in "The History of the Norman Conquest of England", says that either this was the same Edgar and aged at least 110 years; or it was a son of his; or it was some other person known by the title "Ætheling". Nevertheless, as far as anyone knows, the death of Edgar extinguished the male line of the original royal family of England.

</doc>
<doc id="54219" url="https://en.wikipedia.org/wiki?curid=54219" title="H. L. Mencken">
H. L. Mencken

Henry Louis "H. L." Mencken (September 12, 1880 – January 29, 1956) was a German-American journalist, satirist, cultural critic and scholar of American English. Known as the "Sage of Baltimore", he is regarded as one of the most influential American writers and prose stylists of the first half of the twentieth century. As a scholar Mencken is known for "The American Language", a multi-volume study of how the English language is spoken in the United States. His satirical reporting on the Scopes trial, which he dubbed the "Monkey Trial", also gained him attention. He commented widely on the social scene, literature, music, prominent politicians and contemporary movements.
As an admirer of the German philosopher Friedrich Nietzsche, he was a detractor of religion, populism and representative democracy, which he believed was a system in which inferior men dominated their superiors. Mencken was a supporter of scientific progress, skeptical of economic theories and critical of osteopathic and chiropractic medicine.
Mencken opposed American entry into World War I and World War II. His diary indicates that he harbored strong racist and antisemitic attitudes, and was sympathetic to the Social Darwinism practiced by the Nazis.
Mencken's longtime home in the Union Square neighborhood of West Baltimore has been turned into a city museum, the H. L. Mencken House. His papers were distributed among various city and university libraries, with the largest collection held in the Mencken Room at the central branch of Baltimore's Enoch Pratt Free Library.
Early life.
Mencken was born in Baltimore, Maryland, on September 12, 1880. He was the son of August Mencken, Sr., a cigar factory owner of German ancestry. When Henry was three, his family moved into a new home at 1524 Hollins Street facing Union Square park in the Union Square neighborhood of old West Baltimore. Apart from five years of married life, Mencken was to live in that house for the rest of his life.
In his best-selling memoir "Happy Days", he described his childhood in Baltimore as "placid, secure, uneventful and happy."
When he was nine years old, he read Mark Twain's "Huckleberry Finn" which he later described as "the most stupendous event in my life". He became determined to become a writer himself, and read voraciously. In one winter while in high school he read Thackeray and then "proceeded backward to Addison, Steele, Pope, Swift, Johnson and the other magnificos of the Eighteenth century". He read the entire canon of Shakespeare, and became an ardent fan of Kipling and Thomas Huxley. As a boy, Mencken also had practical interests, photography and chemistry in particular, and eventually had a home chemistry laboratory which he used to perform experiments of his own devising, some of them inadvertently dangerous.
He began his primary education in the mid-1880s at Professor Knapp's School located on the east side of Holliday Street between East Lexington and Fayette Streets, next to the Holliday Street Theatre and across from the newly constructed Baltimore City Hall. The site today is the War Memorial and City Hall Plaza laid out in 1926 in memory of World War I dead. At fifteen, in June 1896, he graduated as valedictorian from the Baltimore Polytechnic Institute. BPI was a mathematics, technical and science-oriented public high school, founded in 1883, which was then located on old Courtland Street just north of East Saratoga Street. This location is today the east side of St. Paul Street in St. Paul Place and east of Preston Gardens.
He worked for three years in his father's cigar factory. He disliked the work, especially the sales aspect of it, and resolved to leave, with or without his father's blessing. In early 1898 he took a class in writing at one of the country's first correspondence schools (the Cosmopolitan University). This was to be the entirety of Mencken's formal education in journalism, or indeed in any other subject. On his father's death a few days after Christmas in the same year, the business reverted to his uncle and Mencken was free to pursue his career in journalism. He had applied in February 1899 to the "Morning Herald" newspaper (which became the "Baltimore Morning Herald" in 1900), and had been hired as a part-timer there, but still kept his position at the factory for a few months. In June he was hired on as a full-time reporter.
Career.
Mencken served as a reporter for six years at the "Herald." Less than two and a half years after the Great Baltimore Fire, the paper was purchased in June 1906 by Charles H. Grasty, owner/editor of "The News" since 1892, and competing owner/publisher Gen. Felix Agnus, of the town's oldest (since 1773) and largest daily "The Baltimore American." They proceeded to divide up the staff, assets and resources of "The Herald" between them. Mencken then moved to "The Baltimore Sun", where he worked for Charles H. Grasty. He continued to contribute to "The Sun," "The Evening Sun" (founded 1910) and "The Sunday Sun" full-time until 1948, when he ceased to write following a stroke.
Mencken began writing the editorials and opinion pieces that made his name at "The Sun." On the side, he wrote short stories, a novel, and even poetry–which he later revealed. In 1908, he became a literary critic for the magazine "The Smart Set", and in 1924, he and George Jean Nathan founded and edited "The American Mercury", published by Alfred A. Knopf. It soon developed a national circulation and became highly influential on college campuses across America. In 1933, Mencken resigned as editor.
Personal life.
Marriage.
In 1930, Mencken married Sara Haardt, a German American professor of English at Goucher College in Baltimore and an author eighteen years his junior. Haardt had led efforts in Alabama to ratify the 19th Amendment. The two met in 1923, after Mencken delivered a lecture at Goucher; a seven-year courtship ensued. The marriage made national headlines, and many were surprised that Mencken, who once called marriage "the end of hope" and who was well known for mocking relations between the sexes, had gone to the altar. "The Holy Spirit informed and inspired me," Mencken said. "Like all other infidels, I am superstitious and always follow hunches: this one seemed to be a superb one." Even more startling, he was marrying an Alabama native, despite his having written scathing essays about the American South. Haardt was in poor health from tuberculosis throughout their marriage and died in 1935 of meningitis, leaving Mencken grief-stricken. He had always championed her writing and, after her death, had a collection of her short stories published under the title "Southern Album".
Great Depression, war and after.
During the Great Depression, Mencken did not support the New Deal. This cost him popularity, as did his strong reservations regarding US participation in World War II, and his overt contempt for President Franklin D. Roosevelt. He ceased writing for the Baltimore "Sun" for several years, focusing on his memoirs and other projects as editor, while serving as an adviser for the paper that had been his home for nearly his entire career. In 1948, he briefly returned to the political scene, covering the presidential election in which President Harry S. Truman faced Republican Thomas Dewey and Henry A. Wallace of the Progressive Party. His later work consisted of humorous, anecdotal, and nostalgic essays, first published in "The New Yorker", then collected in the books "Happy Days", "Newspaper Days", and "Heathen Days".
Last days.
On November 23, 1948, Mencken suffered a stroke that left him aware and fully conscious but nearly unable to read or write, and able to speak only with some difficulty. After his stroke, Mencken enjoyed listening to European classical music and, after some recovery of his ability to speak, talking with friends, but he sometimes referred to himself in the past tense, as if already dead. During the last year of his life, his friend and biographer William Manchester read to him daily.
Legacy.
Preoccupied as Mencken was with his legacy, he organized his papers, letters, newspaper clippings and columns, even grade school report cards. After his death, these materials were made available to scholars in stages in 1971, 1981, and 1991, and include hundreds of thousands of letters sent and received; the only omissions were strictly personal letters received from women.
Death.
Mencken died in his sleep on January 29, 1956. He was interred in Baltimore's Loudon Park Cemetery.
Though it does not appear on his tombstone, during his "Smart Set" days Mencken wrote a joking epitaph for himself:
The man of ideas.
In his capacity as editor and man of ideas, Mencken became close friends with the leading literary figures of his time, including Theodore Dreiser, F. Scott Fitzgerald, Joseph Hergesheimer, Anita Loos, Ben Hecht, Sinclair Lewis, James Branch Cabell, and Alfred Knopf, as well as a mentor to several young reporters, including Alistair Cooke. He also championed artists whose works he considered worthy. For example, he asserted that books such as "Caught Short! A Saga of Wailing Wall Street" (1929), by Eddie Cantor (ghost-written by David Freedman) did more to pull America out of the Great Depression than all government measures combined. He also mentored John Fante. Thomas Hart Benton illustrated an edition of Mencken's book "Europe After 8:15".
Mencken also published many works under various pseudonyms, including Owen Hatteras, John H Brownell, William Drayham, WLD Bell, and Charles Angoff. As a ghost-writer for the physician Leonard K Hirshberg, he wrote a series of articles and (in 1910) most of a book about the care of babies.
Mencken admired German philosopher Friedrich Nietzsche—he was the first writer to provide a scholarly analysis in English of Nietzsche's views and writings—and Joseph Conrad. His humor and satire owe much to Ambrose Bierce and Mark Twain. He did much to defend Dreiser, despite freely admitting his faults, including stating forthrightly that Dreiser often wrote badly and was a gullible man. Mencken also expressed his appreciation for William Graham Sumner in a 1941 collection of Sumner's essays, and regretted never having known Sumner personally. In contrast, Mencken was scathing in his criticism of the German philosopher Hans Vaihinger whom he described as "an extremely dull author" and whose famous book "Philosophy of 'As If he dismissed as an unimportant "foot-note to all existing systems."
Mencken recommended for publication libertarian philosopher and author Ayn Rand's first novel, "We the Living", calling it "a really excellent piece of work". Shortly after, Rand addressed him in correspondence as "the greatest representative of a philosophy" to which she wanted to dedicate her life, "individualism", and later listed him as her favorite columnist.
For Mencken, "Adventures of Huckleberry Finn" was the finest work of American literature. Much of that book relates how gullible and ignorant country "boobs" (as Mencken referred to them) are swindled by con men like the (deliberately) pathetic "Duke" and "Dauphin" roustabouts with whom Huck and Jim travel down the Mississippi River. These scam-artists swindle by posing as enlightened speakers on temperance (to obtain the funds to get roaring drunk), as pious "saved" men seeking funds for far off evangelistic missions (to pirates on the high seas, no less), and as learned doctors of phrenology (who can barely spell). Mencken read the novel as a story of America's hilarious dark side, a place where democracy, as defined by Mencken, is "the worship of jackals by jackasses."
Such turns of phrase evoked the erudite cynicism and rapier sharpness of language displayed by Bierce in his darkly satiric Devil's Dictionary. A noted curmudgeon, democratic in subjects attacked, Mencken savaged politics, hypocrisy, and social convention. Master of English, he was given to bombast, once disdaining the lowly hot dog bun's descent into "the soggy rolls prevailing today, of ground acorns, plaster of paris, flecks of bath sponge and atmospheric air all compact."
As a nationally syndicated columnist and book author, he commented widely on the social scene, literature, music, prominent politicians and contemporary movements, such as the temperance movement. Mencken was a keen cheerleader of scientific progress, but very skeptical of economic theories and critical of osteopathic/chiropractic medicine.
As a frank admirer of Nietzsche, Mencken was a detractor of populism and representative democracy, which he believed was a system in which inferior men dominated their superiors. As did Nietzsche, he also spoke out against religious belief (and as a fervent nonbeliever, against the very notion of a deity), particularly Christian fundamentalism, Christian Science and creationism, and against the "Booboisie," his word for the ignorant middle classes. In the summer of 1925, he attended the famous Scopes "Monkey Trial" in Dayton, Tennessee, and wrote scathing columns for the Baltimore "Sun" (widely syndicated) and "American Mercury" mocking the anti-evolution Fundamentalists (especially William Jennings Bryan). The play "Inherit the Wind" is a fictionalized version of the trial, and, as noted above, the cynical reporter E.K. Hornbeck is based on Mencken. In 1926, he deliberately had himself arrested for selling an issue of "The American Mercury" that was banned in Boston under the Comstock laws. Mencken heaped scorn not only on the public officials he disliked, but also on the contemporary state of American elective politics itself.
In the summer of 1926, Mencken followed with great interest the Los Angeles grand jury inquiry into the famous Canadian-American evangelist Aimee Semple McPherson. She was accused of faking her reported kidnapping and the case attracted national attention. There was every expectation Mencken would continue his previous pattern of anti-fundamentalist articles, this time with a searing critique of McPherson. Unexpectedly, he came to her defense, identifying various local religious and civic groups which were using the case as an opportunity to pursue their respective ideological agendas against the embattled Pentecostal minister. He spent several weeks in Hollywood, California, and wrote many scathing and satirical columns on the movie industry and the southern California culture. After all charges had been dropped against McPherson, Mencken revisited the case in 1930 with a sarcastically biting and observant article. He wrote that since many of that town's residents acquired their ideas "of the true, the good and the beautiful" from the movies and newspapers, "Los Angeles will remember the testimony against her long after it forgets the testimony that cleared her."
In 1931 the Arkansas legislature passed a motion to pray for Mencken's soul after he had called the state the "apex of moronia."
In the mid 1930s Mencken feared Franklin Roosevelt and his New Deal liberalism as a powerful force. Mencken, says Charles A. Fecher, was, "deeply conservative, resentful of change, looking back upon the 'happy days' of a bygone time, wanted no part of the world that the New Deal promised to bring in."
Views.
Racism and elitism.
In addition to his identification of races with castes, Mencken had views about the superior individual within communities. He believed that every community produced a few people of clear superiority. He considered groupings on a par with hierarchies, which led to a kind of natural elitism and natural aristocracy. "Superior" individuals, in Mencken's view, were those wrongly oppressed and disdained by their own communities, but nevertheless distinguished by their will and personal achievement—not by race or birth.
In 1989, per his instructions, Alfred A. Knopf published Mencken's "secret diary" as "The Diary of H. L. Mencken". According to an Associated Press story, Mencken's views shocked even the "sympathetic scholar who edited it," Charles A. Fecher of Baltimore. There is a club in Baltimore called the Maryland Club which had one Jewish member, and that member died. Mencken said, "There is no other Jew in Baltimore who seems suitable," according to the article. And the diary quoted him as saying of blacks, in September 1943, "...it is impossible to talk anything resembling discretion or judgment to a colored woman. They are all essentially child-like, and even hard experience does not teach them anything." However, Mencken opposed lynching. For example, he had this to say about a Maryland incident:
Mencken also wrote: "I admit freely enough that, by careful breeding, supervision of environment and education, extending over many generations, it might be possible to make an appreciable improvement in the stock of the American Negro, for example, but I must maintain that this enterprise would be a ridiculous waste of energy, for there is a high-caste white stock ready at hand, and it is inconceivable that the Negro stock, however carefully it might be nurtured, could ever even remotely approach it. The educated Negro of today is a failure, not because he meets insuperable difficulties in life, but because he is a Negro. He is, in brief, a low-caste man, to the manner born, and he will remain inert and inefficient until fifty generations of him have lived in civilization. And even then, the superior white race will be fifty generations ahead of him." 
Democracy.
Rather than dismissing democratic governance as a popular fallacy or treating it with open contempt, Mencken's response to it was a publicized sense of amusement. His feelings on this subject (like his casual feelings on many other such subjects) are sprinkled throughout his writings over the years, very occasionally taking center-stage with the full force of Mencken's prose:
This sentiment is fairly consistent with Mencken's distaste for common notions and the philosophical outlook he unabashedly set down throughout his life as a writer (drawing on Friedrich Nietzsche and Herbert Spencer, among others).
Mencken wrote as follows about the difficulties of good men reaching national office when such campaigns must necessarily be conducted remotely:
Science.
Mencken supported biology and the theory of evolution by Charles Darwin, but spoke unfavorably of physics and mathematics. In Charles Angoff’s record, Mencken said:
In response Angoff said "Well, without mathematics there wouldn't be any engineering, no chemistry, no physics." Mencken responded: "That's true, but it's reasonable mathematics. Addition, subtraction, multiplication, fractions, division, that's what real mathematics is. The rest is baloney. Astrology. Religion. All of our sciences still suffer from their former attachment to religion, and that is why there is so much metaphysics and astrology, the two are the same, in science."
Elsewhere he spoke of the nonsense of higher mathematics and "probability" theory, after he read Angoff's article for Charles S. Peirce in the "American Mercury". "So you believe in that garbage, too—theories of knowledge, infinity, laws of probability. I can make no sense of it, and I don't believe you can either, and I don't think your god Peirce knew what he was talking about."
Mencken also repeated these opinions multiple times in articles for the "American Mercury". He said mathematics is simply a fiction, compared with individual facts that make up science. In a review for Vaihinger's "The Philosophy of "As If"", he said:
Mencken repeatedly identified mathematics with metaphysics and theology. According to Mencken, mathematics is necessarily infected with metaphysics because of the tendency of many mathematical people to engage in metaphysical speculation. In a review for A. N. Whitehead's "The Aims of Education", Mencken remarked that despite his agreement with Whitehead's thesis and approval of his writing style, "now and then he falls into mathematical jargon and pollutes his discourse with equations", and "here are moments when he seems to be following some of his mathematical colleagues into the gaudy metaphysics which now entertains them". For Mencken, theology is characterized by the fact that it uses correct reasoning from false premises. Mencken also uses the term "theology" more generally, to refer to the use of logic in science or any other field of knowledge. In a review for both A. S. Eddington's "The Nature of the Physical World" and Joseph Needham's "Man a Machine", Mencken forcefully ridiculed the use of reasoning to establish any fact in science, because theologians happen to be masters of "logic" and yet are mental defectives:
Mencken also wrote a review for Sir James Jeans's book, "The Mysterious Universe", in which he said that mathematics is not necessary for physics. Instead of "mathematical speculation", Mencken believed physicists should just directly look at individual facts in the laboratory like chemists:
Mencken also ridiculed Einstein’s theory of relativity, saying "in the long run his curved space may be classed with the psychosomatic bumps of Gall and Spurzheim". In his private letters, he said:
Anglo-Saxons.
Mencken countered the arguments for Anglo-Saxon superiority prevalent in his time in a 1923 essay entitled "The Anglo-Saxon", which argued that if there was such a thing as a pure "Anglo-Saxon" race, it was defined by its inferiority and cowardice. "The normal American of the 'pure-blooded' majority goes to rest every night with an uneasy feeling that there is a burglar under the bed and he gets up every morning with a sickening fear that his underwear has been stolen."
Jews.
In the 1930 edition of "Treatise on the Gods" Mencken wrote:
This passage was removed from subsequent editions at his express direction.
Author Gore Vidal later defended Mencken:
As Germany gradually conquered Europe, Mencken attacked President Franklin D. Roosevelt for refusing to admit Jewish refugees into the United States and called for their wholesale admission:
Memorials.
Home.
Mencken's home at 1524 Hollins Street in Baltimore's Union Square neighborhood, where he lived for sixty-seven years before his death in 1956, was bequeathed to the University of Maryland, Baltimore on the death of his younger brother, August, in 1967. The City of Baltimore acquired the property in 1983, and the H. L. Mencken House became part of the City Life Museums. It has been closed to general admission since 1997, but is opened for special events and group visits by arrangement.
Papers.
Shortly after World War II, Mencken expressed his intention of bequeathing his books and papers to Baltimore's Enoch Pratt Free Library. At the time of his death in 1956 the Library was in possession of most of the present large collection. As a result, his papers as well as much of his personal library, which includes many books inscribed by major authors, are held in the Library's Central Branch on Cathedral Street in Baltimore. The original third floor "H. L. Mencken Room and Collection" housing this collection was dedicated on April 17, 1956. The new Mencken Room, on the first floor of the Library's Annex, was opened in November 2003.
The collection contains Mencken's typescripts, newspaper and magazine contributions, published books, family documents and memorabilia, clipping books, large collection of presentation volumes, file of correspondence with prominent Marylanders, and the extensive material he collected while preparing "The American Language".
Other Mencken related collections of note are at Dartmouth College, Harvard University, Princeton University, and Yale University. The Sara Haardt Mencken collection at Goucher College includes letters exchanged between Haardt and Mencken and condolences written after her death. Some of Mencken's vast literary correspondence is held at the New York Public Library.
"Gift of HL Mencken 1929" is stamped on the Marriage of Heaven and Hell, Luce 1906 edition of William Blake, which shows up from the Library of Congress online version for reading.
Works.
Books.
Posthumous collections

</doc>
<doc id="54220" url="https://en.wikipedia.org/wiki?curid=54220" title="462">
462

__NOTOC__
Year 462 (CDLXII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Severus and Leo (or, less frequently, year 1215 "Ab urbe condita"). The denomination 462 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="54221" url="https://en.wikipedia.org/wiki?curid=54221" title="Grand Prix motorcycle racing">
Grand Prix motorcycle racing

The MotoGP World Championship is the premier class of motorcycle road racing. It is currently divided into three classes: MotoGP, Moto2 and Moto3. All three classes use four-stroke engines. In 2010, 250 cc two-strokes were replaced by the new Moto2 600 cc four-stroke class. In 2012, 125 cc two-strokes were replaced by the Moto3 250 cc four-stroke class with a weight limit of 65 kg with fuel, and the engine capacity for MotoGP increased from 800 cc to 1,000 cc.
Grand Prix motorcycles are purpose-built racing machines that are neither available for purchase by the general public nor able to be ridden legally on public roads. This contrasts with the various production-based categories of racing, such as the Superbike World Championship and the Isle of Man TT Races that feature modified versions of road-going motorcycles available to the public.
Overview.
A Road Racing World Championship Grand Prix was first organized by the Fédération Internationale de Motocyclisme (FIM) in 1949. The commercial rights are now owned by Dorna Sports, with the FIM remaining as the sport sanctioning body. Teams are represented by the International Road Racing Teams Association (IRTA) and manufacturers by the Motorcycle Sport Manufacturers Association (MSMA). Rules and changes to regulations are decided between the four entities, with Dorna casting a tie-breaking vote. In cases of technical modifications, the MSMA can unilaterally enact or veto changes by unanimous vote among its members. These four entities compose the Grand Prix Commission.
There have traditionally been several races at each event for various classes of motorcycles, based on engine size, and one class for sidecars. Classes for 50 cc, 80 cc, 125 cc, 250 cc, 350 cc, and 500 cc solo machines have existed at some time, and 350 cc and 500 cc sidecars. Up through the 1950s and most of the 1960s, four-stroke engines dominated all classes. In part this was due to rules, which allowed a multiplicity of cylinders (meaning smaller pistons, producing higher revs) and a multiplicity of gears (giving narrower power bands, affording higher states of tune). In the 1960s, two-stroke engines began to take root in the smaller classes.
In 1969, the FIM — citing high development costs for non-works teams — brought in new rules restricting all classes to six gears and most to two cylinders (four cylinders in the case of the 350 cc and 500 cc classes). This led to a mass walk-out of the sport by the previously highly successful Honda, Suzuki and Yamaha manufacturer teams, skewing the results tables for the next several years, with MV Agusta effectively the only works team left in the sport until Yamaha (1973) and Suzuki (1974) returned with new two-stroke designs. By this time, two-strokes completely eclipsed the four-strokes in all classes. In 1979, Honda, on its return to GP racing, made an attempt to return the four-stroke to the top class with the NR500, but this project failed, and, in 1983, even Honda was winning with a two-stroke 500.
The 50 cc class was replaced by an 80 cc class, then the class was dropped entirely in the 1990s, after being dominated primarily by Spanish and Italian makes. The 350 cc class vanished in the 1980s. Sidecars were dropped from world championship events in the 1990s (see Superside), reducing the field to 125s, 250s, and 500s.
MotoGP, the premier class of GP motorcycle racing, has changed dramatically in recent years. From the mid-1970s through to 2001, the top class of GP racing allowed 500 cc displacement with a maximum of four cylinders, regardless of whether the engine was a two-stroke or four-stroke. Consequently, all machines were two-strokes, due to the greater power output for a given engine capacity. Some two- and three-cylinder two-stroke 500s were seen, but though they had a minimum-weight advantage under the rules, typically attained higher corner speed and could qualify well, they lacked the power of the four-cylinder machines.
In 2002, rule changes were introduced to facilitate the phasing out of the two-strokes. The rules permitted manufacturers to choose between running two-stroke engines of 500 cc or less or four-strokes of 990 cc or less. Manufacturers were also permitted to employ their choice of engine configuration. Despite the significantly increased costs involved in running the new four-stroke machinery, given their extra 490cc capacity advantage, the four-strokes were soon able to dominate their two-stroke rivals. As a result, by 2003 no two-stroke machines remained in the MotoGP field. The 125 cc and 250 cc classes still consisted exclusively of two-stroke machines.
In 2007, the MotoGP class had its maximum engine displacement capacity reduced to 800 cc for a minimum of five years. For the 2012 season the capacity has increased again to 1,000 cc.
The 2008 racing calendar consisted of 18 rounds in 15 different countries (Qatar, Spain which hosted three rounds, Portugal, China, France, Italy, Great Britain, the Netherlands, Germany, the US which hosted two rounds, Czech Republic, San Marino, Japan, Australia and Malaysia). Exclusive to the MotoGP class, there was also a US round at Mazda Raceway Laguna Seca in Monterey, California, for the 800 cc class only; this was because the paddock was not large enough to also include the other two classes. In 2008, a MotoGP event was held at the Indianapolis Motor Speedway for the first time on a newly prepared track. All three classes were scheduled to race but severe wind and rain prevented the 250 cc class from racing. MotoGP racing at Indianapolis is counterclockwise, with a "snake pit" complex past the start-finish line before heading down the turn one short-chute and into the infield section.
The grid is composed of three columns (four for the 125 cc and 250 cc classes) and contains approximately 20 riders. Grid positions are decided in descending order of qualifying speed, with the fastest on the pole or first position. Races last approximately 45 minutes, each race is a sprint from start to finish without pitting for fuel or tyres.
In 2005, a flag-to-flag rule for MotoGP was introduced. Previously, if a race started dry and rain fell, officials could red-flag (stop) the race and either restart or resume on 'wet' tyres. Now, when rain falls, a white flag is shown, indicating that riders can pit to swap the motorcycle on which they started the race for an identical one, as long as the tyres are different (that is, intermediates or slicks instead of wets)[http://world.honda.com/WGP/2005/02portugal/race/]. Besides different tyres, the wet-weather bikes have steel brake rotors and different brake pads instead of the carbon discs and pads used on the 'dry' bikes. This is because the carbon brakes need to be very hot to function properly, and the water cools them too much. The suspension is also 'softened' up somewhat for the wet weather.
When a rider crashes, track marshals up the track from the incident wave yellow flags, prohibiting passing in that area; one corner farther up the track, a stationary yellow flag is shown. If a fallen rider cannot be evacuated safely from the track, the race is red-flagged. Motorcycle crashes are usually one of two types: lowside, with the rider initially following his upended bike, and the more dangerous highside, with the rider ejected ahead of the machine. Increased use of traction control has made highsides much less frequent.
According to one estimate, leasing a top-level motorcycle for a rider costs about 3 to 3.5 million dollars for a racing season.
As a result of the 2008–2009 financial crisis, MotoGP is undergoing changes in an effort to cut costs. Among them are reducing Friday practice sessions, banning active suspension, launch control and ceramic composite brakes, extending the lifespan of engines, and reducing testing sessions.
Riders.
Top riders travel the world to compete in the annual FIM World Championship series. The championship is perhaps most closely followed in Italy and Spain, home of many of the more successful riders early in the 21st century. As for the 2011 season, 25 riders of eight nations participated in the premier class of the championship.
Champions.
The Riders' World Championship is awarded to the most successful rider over a season, as determined by a points system based on Grand Prix results.
Giacomo Agostini is the most successful champion in Grand Prix history, with 15 titles to his name (8 in the 500 cc class and 7 in the 350 cc class). The most dominant rider of all time was Mike Hailwood, winning 10 out of 12 (83%) races, in the 250 cc class, in the 1966 season. Mick Doohan, who won 12 out of 15 (80%) of the 500 cc races in the 1997 Grand Prix motorcycle racing season also deserves an honourable mention. Valentino Rossi is the most successful contemporary rider, having won nine titles including six Moto GP titles, and one each at 500 cc, 250 cc and 125 cc levels. The current (2015) champion is Jorge Lorenzo.
MotoGP circuits.
The MotoGP 2015 season consisted of races at 18 circuits in 14 different countries.
Specifications.
The following shows the key specifications issues for each class. It was also introduced for the 2005 year, that under rule 2.10.5: 'No fuel on the motorcycle may be more than 15 °C below ambient temperature. The use of any device on the motorcycle to artificially decrease the temperature of the fuel below ambient temperature is forbidden. No motorcycle may include such a device.' This stops an artificial "boost" gained from increasing fuel density by cooling it.
MotoGP class.
At the beginning of the new MotoGP era in 2002, 500 cc two-stroke or 990 cc four-stroke bikes were specified to race. The enormous power advantage of the twice as large displacement four-stroke engine over the half the size two-stroke meant that by the following season, no two-stroke bikes were racing. In 2007, the maximum engine capacity was reduced to 800 cc without reducing the existing weight restriction. 
MotoGP-class motorcycles are not restricted to any specific engine configuration. However, the number of cylinders employed in the engine determines the motorcycle's permitted minimum weight; the weight of the extra cylinders acts as a form of handicap. This is necessary because, for a given capacity, an engine with more cylinders is capable of producing more power. If comparable bore to stroke ratios are employed, an engine with more cylinders will have a greater piston area and a shorter stroke. The increased piston area permits an increase in the total valve area, allowing more air and fuel to be drawn into the engine, and the shorter stroke permits higher revs at the same piston speed, allowing the engine to pump still more air and fuel with the potential to produce more power, but with more fuel consumption too. In 2004 motorcycles were entered with three-, four-and five-cylinder configurations. A six-cylinder engine was proposed by Blata, but it did not reach the MotoGP grids. Presently four-cylinder engines appear to offer the best compromise between weight, power, and fuel consumption as all competitors in the 2009 series use this solution in either 'V' or in-line configuration.
In 2002, the FIM became concerned at the advances in design and engineering that resulted in higher speeds around the race track; regulation changes related to weight, amount of available fuel and engine capacity were introduced. The amended rules reduced engine capacity to 800 cc from 990 cc and restricted the amount of available fuel for race distance from in year 2004 to in year 2007 and onwards. In addition, the minimum weight of four-cylinder bikes used by all participating teams was increased by .
The highest speed for a MotoGP motorcycle in 125 cc category is by Valentino Rossi in 1996 for Aprilia and the top speed in the history of MotoGP is , set by riding a Andrea Dovizioso , during the warmup at the 2016 Qatar Grand Prix.
On December 11, 2009, the Grand Prix Commission announced that the MotoGP class would switch to the 1,000 cc motor limit starting in the 2012 season. Maximum displacement was limited to 1,000 cc, maximum cylinders were limited to four, and maximum bore was capped at . Carmelo Ezpeleta, the CEO of Dorna Sports, indicated that the projected changes were received by the teams favorably.
From 2012, teams not entered by one of the major manufacturers could seek "claiming rule team" (CRT) status. Claiming rule team were intended to allow independent teams to be competitive at a lower cost and increase the number of entries in MotoGP. Claiming rule teams benefitted from less restrictive rules on the number of engines that could be used in a season, and with larger fuel allowances during the races. Under the claiming rule, CRTs agree to allow up to four of their engines per season to be claimed, after a race, by one of the major manufacturer teams at a cost of €20,000 each including transmission, or €15,000 each for the engine alone. From the 2014 season, the CRT class was dropped in favour of an "Open Class" specification - allowing teams using the control ECU hardware and software certain benefits to increase their competitiveness.
Moto2 class.
Moto2 is the 600 cc four-stroke class, launched in 2010 to replace the traditional 250 cc two-stroke class. Engines are supplied exclusively by Honda (similar to IndyCar Series when Honda solely supplied IndyCar Series V8 engine machines in 2006-2011), tyres by Dunlop and electronics are limited and supplied only by FIM sanctioned producers with a maximum cost set at 650 EUR. Carbon-fibre brakes are banned and only steel brakes are allowed. However, there are no chassis limitations. From 2010 onwards, only 600 cc four-stroke Moto2 machines have been allowed.
Moto3 class.
The 125 cc class was replaced in 2012 by the Moto3 class. This class is restricted to single-cylinder 250 cc four-stroke engines with a maximum bore of .The minimum total weight for motorcycle and rider is . Riders in the Moto3 class cannot be older than 28 years, or 25 years for new contracted riders participating for the first time and wild-cards.
Tyres.
Tyre selection is critical, usually done by the individual rider based on bike 'feel' during practice, qualifying and the pre-race warm-up laps on the morning of the race, as well as the predicted weather. The typical compromise is between grip and longevity—softer compound tyres have more traction, but wear out more quickly; harder compound tyres have less traction, but are more likely to last the entire race. Conserving rubber throughout a race is a specific skill winning riders acquire. Special 'Q' or qualifying tyres of extreme softness and grip were typically used during grid-qualifying sessions until their use was discontinued at the end of the 2008 season, but they lasted typically no longer than one or two laps, though they could deliver higher qualifying speeds. In wet conditions, special tyres ('wets') with full treads are used, but they suffer extreme wear if the track dries out.
In 2007 new MotoGP regulations limited the number of tyres any rider could use over the practice and qualifying period, and the race itself, to a maximum of 31 tyres (14 fronts and 17 rears) per rider. This introduced a problem of tyre choice versus weather (among other factors) that challenges riders and teams to optimize their performance on race day. This factor was greeted with varying degrees of enthusiasm by participants. Bridgestone had dominated in 2007 and Michelin riders Valentino Rossi, Nicky Hayden, Dani Pedrosa, and Colin Edwards all acknowledged shortcomings in Michelin's race tyres relative to Bridgestone. Rossi, disappointed with and critical of the performance of his Michelin tyres, switched to Bridgestones for 2008 and won the world championship in dominant fashion. Pedrosa switched to Bridgestones during the 2008 season.
In 2008, the rules were amended to allow more tyres per race weekend—18 fronts and 22 rears for a total of 40 tyres. The lower number of tyres per weekend was considered a handicap to Michelin riders. The only MotoGP team using Dunlop tyres in 2007, Yamaha Tech 3, did not use them in 2008 but switched to Michelin.
For 2009, 2010 and 2011, a 'spec' tyre supplier, Bridgestone, was appointed by the FIM (with Michelin no longer supplying any tyres to MotoGP). For the whole season Bridgestone provided four different specifications of front tyre, six of rear, and a single wet specification—with no qualifying specification. For each round Bridgestone provided only two specifications for front and rear. Tyres are assigned to riders randomly to assure impartiality. Jorge Lorenzo has publicly supported the mono tyre rule.
At the end of the 2015 season, Bridgestone withdrew as Official Tyre Supplier to MotoGP. Following a formal tender, French tyre manufacturer Michelin became the official supplier for the 2016 season, and testing began in Aragon immediately after the end of the 2015 season.
Motorcycle Cost: 
Motogp motorcycles are estimated to be worth approximately 2 million dollars (USD) although executives within Motogp have deemed them priceless due in part that they are prototypes and cannot easily be replicated. 

</doc>
<doc id="54223" url="https://en.wikipedia.org/wiki?curid=54223" title="Creator deity">
Creator deity

A creator deity or creator god (often called the Creator) is a deity or god responsible for the creation of the Earth, world, (cosmos or universe). In monotheism, the single God is often also the creator. A number of monolatristic traditions separate a secondary creator from a primary transcendent being, identified as a primary creator.
Polytheism.
In polytheistic creation, the world often comes into being organically, e.g. sprouting from a primal seed, sexually, by miraculous birth (sometimes by parthenogenesis), by hieros gamos, violently, by the slaying of a primeval monster, or artificially, by a divine demiurge or "craftsman". Sometimes, a god is involved, wittingly or unwittingly, in bringing about creation. Examples include:
Platonic demiurge.
Plato, in his dialogue Timaeus, describes a creation myth involving a being called the demiurge (δημιουργός "craftsman"). This concept was continued in Neoplatonism and Gnosticism. In Neoplatonism, the demiurge represents the second cause or dyad, after the monad. In Gnostic dualism, the demiurge is an imperfect spirit and possibly evil being, transcended by divine Fullness (Pleroma). Unlike God, Plato's demiurge is unable to create ex-nihilo.
Monolatrism.
Monolatristic traditions would separate a secondary creator from the primary transcendent being, identified as a primary creator. According to Gaudiya Vaishnavas, Brahma is the secondary creator and not the supreme. Vishnu is the primary creator. According to Vaishnava belief Vishnu creates the basic universal shell and provides all the raw materials and also places the living entities within the material world, fulfilling their own independent will. Brahma works with the materials provided by Vishnu to actually create what are believed to be planets in Puranic terminology, and he supervises the population of them.
Monism.
Monism has its origin in Hellenistic philosophy as a concept of all things deriving from a single substance or being. Following a long and still current tradition Huw Owen claimed that:
Although, like Baruch Spinoza, some pantheists may also be monists, and monism may even be essential to some versions of pantheism (like Spinoza's), not all pantheists are monists. Some are polytheists and some are pluralists; they believe that there are many things and kinds of things and many different kinds of value. Not all monists are pantheists. Exclusive monists believe that the universe, the God of the pantheist, simply does not exist. In addition, monists can be Deists, pandeists, theists or panentheists; believing in a monotheistic God that is omnipotent and all-pervading, and both transcendent and immanent. There are monist pantheists and panentheists in Hinduism (particularly in Advaita and Vishistadvaita respectively), Judaism (monistic panentheism is especially found in Kabbalah and Hasidic philosophy), in Christianity (especially among Oriental Orthodox, Eastern Orthodox, and Anglicans) and in Islam (among the Sufis, especially the Bektashi).
In Advaita Vedanta, Brahman is the abstract notion of "the Absolute" from which the universe takes its origin and at an ultimate level, all assertions of a distinction between Brahman, other gods and creation are meaningless (monism).
Non-creationism.
Buddhism.
Buddhism denies a creator deity and posits that mundane deities such as Mahabrahma are misperceived to be a creator.
Jainism.
Jainism does not support belief in a creator deity. According to Jain doctrine, the universe and its constituents - soul, matter, space, time, and principles of motion have always existed (a static universe similar to that of Epicureanism and steady state cosmological model). All the constituents and actions are governed by universal natural laws. It is not possible to create matter out of nothing and hence the sum total of matter in the universe remains the same (similar to law of conservation of mass). Similarly, the soul of each living being is unique and uncreated and has existed since beginningless time.
The Jain theory of causation holds that a cause and its effect are always identical in nature and therefore a conscious and immaterial entity like God cannot create a material entity like the universe. Furthermore, according to the Jain concept of divinity, any soul who destroys its karmas and desires, achieves liberation. A soul who destroys all its passions and desires has no desire to interfere in the working of the universe. Moral rewards and sufferings are not the work of a divine being, but a result of an innate moral order in the cosmos; a self-regulating mechanism whereby the individual reaps the fruits of his own actions through the workings of the karmas.
Through the ages, Jain philosophers have adamantly rejected and opposed the concept of creator and omnipotent God and this has resulted in Jainism being labeled as "nāstika darsana" or atheist philosophy by the rival religious philosophies. The theme of non-creationism and absence of omnipotent God and divine grace runs strongly in all the philosophical dimensions of Jainism, including its cosmology, karma, moksa and its moral code of conduct. Jainism asserts a religious and virtuous life is possible without the idea of a creator god.
Hinduism.
Hinduism includes a range of viewpoints about the origin of life, creationism and evolution. The accounts of the emergence of life within the universe vary in description, but classically the god Brahma, from a Trimurti of three gods also including Vishnu and Shiva, is described as performing the act of creation, or more specifically of "propagating life within the universe" with the other two deities being responsible for preservation and destruction (of the universe) respectively. In sectarian versions of creation, often the patron deity is termed the Creator. In Vaishnavism, Vishnu creates Brahma and orders him to order the rest of universe. In Shaivism, Shiva may be treated as the creator. In Shaktism, the Great Goddess creates the Trimurti.
Most Hindu schools do not regard the scriptural creation myth as a literal truth, and often the creation stories themselves do not go into specific detail, thus leaving open the possibility of incorporating at least some theories in support of evolution. Some Hindus find support for, or foreshadowing of evolutionary ideas in scriptures, namely the Vedas. An exception to this acceptance is the International Society for Krishna Consciousness (ISKCON), which includes several members who actively oppose "Darwinism" and the modern evolutionary synthesis.
Monotheism.
Zoroastrianism, Judaism, Christianity, Islam, Sikhism and Atenism teach that creation is the origin of the universe by the action of God.
Atenism.
Initiated by Pharaoh Akhenaten and Queen Nefertiti around 1330 BCE, during New Kingdom period in ancient Egyptian history. They built an entirely new capital city (Akhetaten) for themselves and worshippers of their Sole Creator God on a wilderness. His father used to worship Aten alongside other gods of their polytheistic religion. Aten, for a longtime before his father's time, was revered as a god among the many gods and goddesses in Egypt. Atenism faded away after death of the pharaoh. Despite different views, Atenism is considered by some scholars to be one of the frontiers of monotheism in human history.
Judaism.
The creation narrative is made up of two stories, roughly equivalent to the two first chapters of the Book of Genesis. (There are no chapter divisions in the original Hebrew text, see Chapters and verses of the Bible.) The first account (1:1 through 2:3) employs a repetitious structure of divine fiat and fulfillment, then the statement "And there was evening and there was morning, the ["x"th] day," for each of the six days of creation. In each of the first three days there is an act of division: day one divides the darkness from light, day two the "waters above" from the "waters below", and day three the sea from the land. In each of the next three days these divisions are populated: day four populates the darkness and light with sun, moon and stars; day five populates seas and skies with fish and fowl; and finally land-based creatures and mankind populate the land.
The two stories are complementary rather than overlapping, with the first (the Priestly story) concerned with the cosmic plan of creation, while the second (the Yahwist story) focuses on man as cultivator of his environment and as a moral agent. There are significant parallels between the two stories, but also significant differences: the second account, in contrast to the regimented seven-day scheme of Genesis 1, uses a simple flowing narrative style that proceeds from God's forming the first man through the Garden of Eden to the creation of the first woman and the institution of marriage; in contrast to the omnipotent God of Genesis 1, creating a god-like humanity, the God of Genesis 2 can fail as well as succeed; the humanity he creates is not god-like, but is punished for acts which would lead to their becoming god-like (Genesis 3:1-24); and the order and method of creation itself differs. "Together, this combination of parallel character and contrasting profile point to the different origin of materials in Genesis 1:1 and Gen 2:4, however elegantly they have now been combined."
Christianity.
Ancient Near Eastern mythologies and classical creation myths in Greek mythology envisioned the creation of the world as resulting from the actions of a god or gods upon already-existing primeval matter, known as "chaos".
An early conflation of Greek philosophy with the narratives in the Hebrew Bible came from Philo of Alexandria (d. AD 50), writing in the context of Hellenistic Judaism. Philo equated the Hebrew creator-deity Yahweh with Aristotle's "primum movens" (First Cause) in an attempt to prove that the Jews had held monotheistic views even before the Greeks. However, this was still within the context of creation from pre-existing materials (i.e. "moving" or "changing" a material substratum.)
The classical tradition of creation from chaos first came under question in Hellenistic philosophy (on "a priori" grounds), which developed the idea that the primum movens must have created the world out of nothing.
Theologians debate whether the Bible itself teaches creation "ex nihilo". Traditional interpreters
argue on grammatical and syntactical grounds that this is the meaning of Genesis 1:1, which is commonly rendered: "In the beginning God created the heavens and the earth." They further find support for this view in New Testament passages like Hebrews 11:3—"By faith we understand that the universe was created by the word of God, so that what is seen was not made out of things that are visible"—and Revelation 4:11—"For you created all things, and by your will they existed and were created." However, other interpreters
understand creation "ex nihilo" as a 2nd-century theological development. According to this view, church fathers opposed notions appearing in pre-Christian creation myths and in Gnosticism—notions of creation by a demiurge out of a primordial state of matter (known in religious studies as "chaos" after the Greek term used by Hesiod in his "Theogony").
Jewish thinkers took up the idea, which became important to Judaism, to ongoing strands in the Christian tradition, and—as a corollary—to Islam.
Islam.
According to Islam, God, known in Arabic as Allah, is the all-powerful and all-knowing Creator, Sustainer, Ordainer, and Judge of the universe. Islam puts a heavy emphasis on the conceptualization of God as strictly singular (tawhid). God is unique ("wahid") and inherently one ("ahad"), all-merciful and omnipotent. According to tradition there are 99 Names of God (al-asma al-husna lit. meaning: "The best names") each of which evoke a distinct attribute of God. All these names refer to Allah, the supreme and all-comprehensive divine name. Among the 99 names of God, the most famous and most frequent of these names are "the Compassionate" ("al-rahman") and "the Merciful" ("al-rahim").
Creation is seen as an act of divine choice and mercy, one with a grand purpose: "And We did not create the heaven and earth and that between them in play." Rather, the purpose of humanity is to be tested: "Who has created death and life, that He may test you which of you is best in deed. And He is the All-Mighty, the Oft-Forgiving;" Those who pass the test are rewarded with Paradise: "Verily for the Righteous there will be a fulfilment of (the heart's) desires;"
According to the Islamic teachings, God exists above the heavens and the creation itself. The Qur'an mentions, "He it is Who created for you all that is on earth. Then He Istawa (rose over) towards the heaven and made them seven heavens and He is the All-Knower of everything." At the same time, God is unlike anything in creation: "There is nothing like unto Him, and He is the Hearing, the Seeing." and nobody can perceive God in totality: "Vision perceives Him not, but He perceives vision; and He is the Subtle, the Acquainted." God in Islam is not only majestic and sovereign, but also a personal God: "And indeed We have created man, and We know what his ownself whispers to him. And We are nearer to him than his jugular vein (by Our Knowledge)." Allah commands the believers to constantly remember Him ("O you who have believed, remember Allah with much remembrance") and to invoke Him alone ("And whoever invokes besides Allah another deity for which he has no proof - then his account is only with his Lord. Indeed, the disbelievers will not succeed.").
Islam teaches that God as referenced in the Qur'an is the only god and the same God worshipped by members of other Abrahamic religions such as Christianity and Judaism.
Sikhism.
One of the biggest responsibilities in the faith of Sikhism is to worship God as "The Creator", termed "Waheguru" who is shapeless, timeless, and sightless, i.e., Nirankar, Akal, and Alakh Niranjan. The religion only takes after the belief in "One God for All" or Ik Onkar.
Bahá'í.
In the Bahá'í Faith God is the imperishable, uncreated being who is the source of all existence. He is described as "a personal God, unknowable, inaccessible, the source of all Revelation, eternal, omniscient, omnipresent and almighty". Although transcendent and inaccessible directly, his image is reflected in his creation. The purpose of creation is for the created to have the capacity to know and love its creator.
Other.
Chinese traditional cosmology.
Pangu can be interpreted as another creator deity. In the beginning there was nothing in the universe except a formless chaos. However this chaos began to coalesce into a cosmic egg for eighteen thousand years. Within it, the perfectly opposed principles of yin and yang became balanced and Pangu emerged (or woke up) from the egg. Pangu is usually depicted as a primitive, hairy giant with horns on his head (like the Greek Pan) and clad in furs. Pangu set about the task of creating the world: he separated Yin from Yang with a swing of his giant axe, creating the Earth (murky "Yin") and the Sky (clear "Yang"). To keep them separated, Pangu stood between them and pushed up the Sky. This task took eighteen thousand years, with each day the sky grew ten feet higher, the Earth ten feet wider, and Pangu ten feet taller. In some versions of the story, Pangu is aided in this task by the four most prominent beasts, namely the Turtle, the Qilin, the Phoenix, and the Dragon.
After eighteen thousand years had elapsed, Pangu was laid to rest. His breath became the wind; his voice the thunder; left eye the sun and right eye the moon; his body became the mountains and extremes of the world; his blood formed rivers; his muscles the fertile lands; his facial hair the stars and milky way; his fur the bushes and forests; his bones the valuable minerals; his bone marrows sacred diamonds; his sweat fell as rain; and the fleas on his fur carried by the wind became human beings all over the world.
The first writer to record the myth of Pangu was Xu Zheng during the Three Kingdoms period.
Shangdi is another creator deity, possibly prior to Pangu; sharing concepts similar to Abrahamic faiths.
Kazakh.
According to Kazakh folk tales, Jasagnan is the creator of the world.

</doc>
<doc id="54225" url="https://en.wikipedia.org/wiki?curid=54225" title="Trimurti">
Trimurti

The "Trimūrti" (; Sanskrit: त्रिमूर्तिः "", "three forms") is a concept in Hinduism "in which the cosmic functions of creation, maintenance, and destruction are personified by the forms of Brahma the creator, Vishnu the preserver, and Shiva the destroyer or transformer."
Evolution.
The Puranic period saw the rise of post-Vedic religion and the evolution of what R. C. Majumdar calls "synthetic Hinduism."
This period had no homogeneity, and included orthodox Brahmanism in the form of remnants of older Vedic faith traditions, along with different sectarian religions, notably Shaivism, Vaishnavism, and Shaktism that were within the orthodox fold yet still formed distinct entities. One of the important traits of this period is a spirit of harmony between orthodox and sectarian forms. Regarding this spirit of reconciliation, R. C. Majumdar says that:
Its most notable expression is to be found in the theological conception of the , i.e., the manifestation of the supreme God in three forms of , , and ... But the attempt cannot be regarded as a great success, for never gained an ascendancy comparable to that of Śiva or , and the different sects often conceived the as really the three manifestations of their own sectarian god, whom they regarded as Brahman or Absolute.
Maurice Winternitz notes that there are very few places in Indian literature where the Trimurti is mentioned. The identification of Brahma, Vishnu and Shiva as one being is strongly emphasized in the " Purāṇa", where in 1.6 Brahman is worshipped as Trimurti; 1.9 especially inculcates the unity of the three gods, and 1.26 relates to the same theme.
Historian A. L. Basham explains the background of the Trimurti as follows, noting Western interest in the idea of trinity:
Early western students of Hinduism were impressed by the parallel between the Hindu trinity and that of Christianity. In fact the parallel is not very close, and the Hindu trinity, unlike the Holy Trinity of Christianity, never really "caught on". All Hindu trinitarianism tended to favor one god of the three; thus, from the context it is clear that 's hymn to the is really addressed to , here looked on as the high god. The was in fact an artificial growth, and had little real influence.
Nicholas Sutton states that Brahma was never recognized as the Supreme Deity:
There must be some doubt as to whether the Hindu tradition has ever recognized Brahma as the Supreme Deity in the way that Visnu and Siva have been conceived of and worshiped.
Freda Matchett characterizes the Trimurti system as one of "several frameworks into which various divine figures can be fitted at different levels."
The concept of Trimurti is also present in the Maitri Upanishad, where the three gods are explained as three of his supreme forms.
Views within Hinduism.
Sauram.
The Saura sect that worships Surya as the supreme person of the godhead and saguna brahman doesn't accept the Trimurti as they believe Surya is God. Earlier forms of the Trimurti sometimes included Surya instead of Brahma, or as a fourth above the Trimurti, of whom the other three are manifestations; Surya is Brahma in the morning, Vishnu in the afternoon and Shiva in the evening. Surya was also a member of the original Vedic Trimurti, which included Agni and Vayu. Some Sauras worship either Vishnu or Shiva as manifestations of Surya, others worship the Trimurti as a manifestation of Surya, and others exclusively worship Surya alone.
Vaishnavism.
Vaishnavism generally does not accept the Trimurti concept. For example, the Dvaita school holds Vishnu alone to be the supreme God, with Shiva subordinate, and interprets the Puranas differently. For example, Vijayindra Tîrtha, a Dvaita scholar interprets the 18 puranas differently. He interprets the Vaishnavite puranas as satvic and Shaivite puranas as tamasic and that only satvic puranas are considered to be authoritative.
Unlike most other Vaishnavite schools such as those of Ramanuja, Madhva and Chaitanya, Swaminarayan, guru of the Hindu Swaminarayan sects (including BAPS), did not differentiate between Vishnu and Shiva; Swaminarayan notably differs from practically all Vaishnavite schools in holding that Vishnu and Shiva are different aspects of the same God. (see also verses 47 and 84 of Shikshapatri, a key scripture to all followers of the Swaminarayan faith.) Moreover, Swaminarayan followed a Smarta approach (see more detail on the Smarta view below) by instructing his followers to venerate all five deities of the Panchayatana puja with equal reverence.
Shaivism.
Shaivites hold that, according to Shaiva Agama, Shiva performs five actions - creation, preservation, dissolution, concealing grace, and revealing grace. Respectively, these first three actions are associated with Shiva as Sadyojata (akin to Brahma), Vamadeva (akin to Vishnu) and Aghora (akin to Rudra). Thus, Brahma, Vishnu and Rudra are not deities different from Shiva, but rather are forms of Shiva. As Brahma/Sadyojata, Shiva creates. As Vishnu/Vamadeva, Shiva preserves. As Rudra/Aghora, he dissolves. This stands in contrast to the idea that Shiva is the "God of destruction." To Shaivites, Shiva is God and performs all actions, of which destruction is only but one. Ergo, the Trimurti is a form of Shiva Himself for Shaivas. Shaivites believe that Lord Shiva is the Supreme, who assumes various critical roles and assumes appropriate names and forms, and also stands transcending all these.
Smartism.
Smartism is a denomination of Hinduism that places emphasis on a group of five deities rather than just a single deity. The "worship of the five forms" () system, which was popularized by the ninth-century philosopher Adi Shankara among orthodox Brahmins of the Smārta tradition, invokes the five deities Ganesha, Vishnu, Shiva, Devi and Surya. Adi Shankara later added Kartikeya to these five, making six total. This reformed system was promoted by primarily to unite the principal deities of the six major sects on an equal status. The monistic philosophy preached by made it possible to choose one of these as a preferred principal deity and at the same time worship the other four deities as different forms of the same all-pervading Brahman.

</doc>
<doc id="54227" url="https://en.wikipedia.org/wiki?curid=54227" title="Aleph (disambiguation)">
Aleph (disambiguation)

Aleph is the first letter of many Semitic abjads (alphabets).
Aleph or Alef may also refer to:

</doc>
<doc id="54229" url="https://en.wikipedia.org/wiki?curid=54229" title="Cocoa bean">
Cocoa bean

The cocoa bean, also cacao bean or simply cocoa () or cacao (), is the dried and fully fermented fatty seed of "Theobroma cacao", from which cocoa solids and cocoa butter are extracted. They are the basis of chocolate, as well as many Mesoamerican foods such as "mole" and "tejate".
Etymology.
The word "cocoa"' derives from the Spanish word "cacao", derived from the Nahuatl word "cacahuatl". The Nahautl word, in turn, ultimately derives from the reconstructed Proto Mije-Sokean word "*kakaw~*kakawa".
Cocoa can often also refer to the drink commonly known as hot chocolate; to cocoa powder, the dry powder made by grinding cocoa seeds and removing the cocoa butter from the dark, bitter cocoa solids; or to a mixture of cocoa powder and cocoa butter.
History.
The cacao tree is native to the Americas. It may have originated in the foothills of the Andes in the Amazon and Orinoco basins of South America, current-day Colombia and Venezuela, where today, examples of wild cacao still can be found. However, it may have had a larger range in the past, evidence for which may be obscured because of its cultivation in these areas long before, as well as after, the Spanish arrived. New chemical analyses of residues extracted from pottery excavated at an archaeological site at Puerto Escondido in Honduras indicate cocoa products were first consumed there between 1400 and 1500 BC. The new evidence also indicates that, long before the flavor of the cacao seed (or bean) became popular, the sweet pulp of the chocolate fruit, used in making a fermented (5% alcohol) beverage, first drew attention to the plant in the Americas. The cocoa bean was a common currency throughout Mesoamerica before the Spanish conquest.
Cacao trees grow in a limited geographical zone, of about 20° to the north and south of the Equator. Nearly 70% of the world crop today is grown in West Africa. The cacao plant was first given its botanical name by Swedish natural scientist Carl Linnaeus in his original classification of the plant kingdom, who called it "Theobroma" ("food of the gods") "cacao".
Cocoa was an important commodity in pre-Columbian Mesoamerica. A Spanish soldier who was part of the conquest of Mexico by Hernán Cortés tells that when Moctezuma II, emperor of the Aztecs, dined, he took no other beverage than chocolate, served in a golden goblet. Flavored with vanilla or other spices, his chocolate was whipped into a froth that dissolved in the mouth. No fewer than 60 portions each day reportedly may have been consumed by Moctezuma II, and 2,000 more by the nobles of his court.
Chocolate was introduced to Europe by the Spaniards, and became a popular beverage by the mid-17th century. They also introduced the cacao tree into the West Indies and the Philippines. It was also introduced into the rest of Asia and into West Africa by Europeans. In the Gold Coast, modern Ghana, cacao was introduced by an African, Tetteh Quarshie.
Production.
Cocoa pod.
A cocoa pod (fruit) has a rough, leathery rind about thick (this varies with the origin and variety of pod) filled with sweet, mucilaginous pulp (called "baba de cacao" in South America) with a lemonade-like taste enclosing 30 to 50 large seeds that are fairly soft and a pale lavender to dark brownish purple color. Due to heat buildup in the fermentation process, cacao beans lose most of the purplish hue and become mostly brown in color, with an adhered skin which includes the dried remains of the fruity pulp. This skin is released easily after roasting by winnowing. White seeds are found in some rare varieties, usually mixed with purples, and are considered of higher value. Historically, white cacao was cultivated by the Rama people of Nicaragua.
Varieties.
The three main varieties of cocoa plant are Forastero, Criollo, and Trinitario. The first is the most widely used, comprising 95% of the world production of cocoa. Cocoa beans of the Criollo variety are rarer and considered a delicacy. Criollo plantations have lower yields than those of Forastero, and also tend to be less resistant to several diseases that attack the cocoa plant, hence very few countries still produce it. One of the largest producers of Criollo beans is Venezuela (Chuao and Porcelana). Trinitario (from Trinidad) is a hybrid between Criollo and Forastero varieties. It is considered to be of much higher quality than Forastero, but has higher yields and is more resistant to disease than Criollo.
Harvesting.
Cocoa trees grow in hot, rainy tropical areas within 20° of latitude from the Equator. Cocoa harvest is not restricted to one period per year and a harvest typically occurs over several months. In fact, in many countries, cocoa can be harvested at any time of the year. Pesticides are often applied to the trees to combat capsid bugs and fungicides to fight black pod disease.
Immature cocoa pods have a variety of colours, but most often are green, red, or purple, and as they mature, their colour tends towards yellow or orange, particularly in the creases. Unlike most fruiting trees, the cacoa pod grows directly from the trunk or large branch of a tree rather than from the end of a branch, similar to jackfruit. This makes harvesting by hand easier as most of the pods will not be up in the higher branches. The pods on a tree do not ripen together; harvesting needs to be done periodically through the year. Harvesting occurs between three and four times weekly during the harvest season. The ripe and near-ripe pods, as judged by their colour, are harvested from the trunk and branches of the cocoa tree with a curved knife on a long pole. Care must be used when cutting the stem of the pod to avoid damaging the junction of the stem with the tree, as this is where future flowers and pods will emerge. One person can harvest an estimated 650 pods per day.
Harvest processing.
The harvested pods are opened, typically with a machete, to expose the beans. The pulp and cocoa seeds are removed and the rind is discarded. The pulp and seeds are then piled in heaps, placed in bins, or laid out on grates for several days. During this time, the seeds and pulp undergo "sweating", where the thick pulp liquefies as it ferments. The fermented pulp trickles away, leaving cocoa seeds behind to be collected. Sweating is important for the quality of the beans, which originally have a strong, bitter taste. If sweating is interrupted, the resulting cocoa may be ruined; if underdone, the cocoa seed maintains a flavor similar to raw potatoes and becomes susceptible to mildew. Some cocoa-producing countries distill alcoholic spirits using the liquefied pulp.
A typical pod contains 20 to 50 beans and about 400 dried beans are required to make one pound - or 880 per kilogram - of chocolate. Cocoa pods weigh an average of and each one yields dried beans (this yield is 40–44% of the total weight in the pod). One person can separate the beans from about 2000 pods per day.
The wet beans are then transported to a facility so they can be fermented and dried. They are fermented for four to seven days and must be mixed every two days. They are dried for five to 14 days, depending on the climate conditions. The fermented beans are dried by spreading them out over a large surface and constantly raking them. In large plantations, this is done on huge trays under the sun or by using artificial heat. Small plantations may dry their harvest on little trays or on cowhides. Finally, the beans are trodden and shuffled about (often using bare human feet) and sometimes, during this process, red clay mixed with water is sprinkled over the beans to obtain a finer color, polish, and protection against molds during shipment to factories in the United States, the Netherlands, the United Kingdom, and other countries. Drying in the sun is preferable to drying by artificial means, as no extraneous flavors such as smoke or oil are introduced which might otherwise taint the flavor.
The beans should be dry for shipment (usually by sea). Traditionally exported in jute bags, over the last decade, beans are increasingly shipped in "mega-bulk" parcels of several thousand tonnes at a time on ships, or in smaller lots around 25 tonnes in 20-ft containers. Shipping in bulk significantly reduces handling costs; shipment in bags, however, either in a ship's hold or in containers, is still common.
Throughout Mesoamerica where they are native, cocoa beans are used for a variety of foods. The harvested and fermented beans may be ground to-order at "tiendas de chocolate", or chocolate mills. At these mills, the cocoa can be mixed with a variety of ingredients such as cinnamon, chili peppers, almonds, vanilla, and other spices to create drinking chocolate. The ground cocoa is also an important ingredient in "tejate" and a number of savory foods, such as "mole".
World production.
Nearly of cocoa are produced each year. 
The historical global production was
The production increased by 131.7% in 30 years, representing a compound annual growth rate of 2.9%.
About 3.54 million tonnes of cocoa beans were produced in the 2008–2009 growing year, which runs from October to September. Of this total, African nations produced 2.45 million tonnes (69%), Asia and Oceania produced 0.61 million tonnes (17%), and the Americas produced 0.48 million tonnes (14%). Two African nations, Ivory Coast and Ghana, produce more than half of the world's cocoa, with 1.23 and 0.73 million tonnes, respectively (35% and 21%, respectively). 
Consumption.
Different metrics are used for chocolate consumption. The Netherlands has the highest monetary amount of cocoa bean imports (US$2.1 billion); it is also one of the main ports into Europe. The United States has the highest amount of cocoa powder imports ($220 million); the US has a large amount of cocoa complementary products. The United Kingdom has the highest amount of retail chocolate ($1.3 billion) and is one of the biggest chocolate consumption-per-capita markets.
Cocoa and its products (including chocolate) are used worldwide. Per capita consumption is poorly understood, with numerous countries claiming the highest: various reports state that Switzerland, Belgium, and the UK have the highest consumption. However, since no clear mechanism exists to determine how much of a country's production is consumed by residents and how much by visitors, any data with respect to consumption remain highly speculative.
Chocolate production.
To make 1 kg (2.2 lb) of chocolate, about 300 to 600 beans are processed, depending on the desired cocoa content. In a factory, the beans are roasted. Next, they are cracked and then deshelled by a "winnower". The resulting pieces of beans are called nibs. They are sometimes sold in small packages at specialty stores and markets to be used in cooking, snacking, and chocolate dishes. Since nibs are directly from the cocoa tree, they contain high amounts of theobromine. Most nibs are ground, using various methods, into a thick, creamy paste, known as chocolate liquor or cocoa paste. This "liquor" is then further processed into chocolate by mixing in (more) cocoa butter and sugar (and sometimes vanilla and lecithin as an emulsifier), and then refined, conched and tempered. Alternatively, it can be separated into cocoa powder and cocoa butter using a hydraulic press or the Broma process. This process produces around 50% cocoa butter and 50% cocoa powder. Standard cocoa powder has a fat content around 10–12%. Cocoa butter is used in chocolate bar manufacture, other confectionery, soaps, and cosmetics.
Treating with alkali produces Dutch-process cocoa powder, which is less acidic, darker, and more mellow in flavor than what is generally available in most of the world. Regular (nonalkalized) cocoa is acidic, so when cocoa is treated with an alkaline ingredient, generally potassium carbonate, the pH increases. This process can be done at various stages during manufacturing, including during nib treatment, liquor treatment, or press cake treatment.
Another process that helps develop the flavor is roasting, which can be done on the whole bean before shelling or on the nib after shelling. The time and temperature of the roast affect the result: A "low roast" produces a more acid, aromatic flavor, while a high roast gives a more intense, bitter flavor lacking complex flavor notes.
Health benefits.
In general, cocoa is considered to be a rich source of antioxidants such as procyanidins and flavanoids, which may impart antiaging properties. Cocoa also contain a high level of flavonoids, specifically epicatechin, which may have beneficial effects on cardiovascular health.
The stimulant activity of cocoa comes from the compound theobromine which is less diuretic as compared to theophylline found in tea. Prolonged intake of flavanol-rich cocoa has been linked to cardiovascular health benefits, though this refers to raw cocoa and to a lesser extent, dark chocolate, since flavonoids degrade during cooking and alkalizing processes. Short-term benefits in LDL cholesterol levels from dark chocolate consumption have been found. The addition of whole milk to milk chocolate reduces the overall cocoa content per ounce while increasing saturated fat levels. Although one study has concluded that milk impairs the absorption of polyphenolic flavonoids, e.g. epicatechin, a followup failed to find the effect.
Hollenberg and colleagues of Harvard Medical School studied the effects of cocoa and flavanols on Panama's Kuna people, who are heavy consumers of cocoa. The researchers found that the Kuna people living on the islands had significantly lower rates of heart disease and cancer compared to those on the mainland who do not drink cocoa as on the islands. It is believed that the improved blood flow after consumption of flavanol-rich cocoa may help to achieve health benefits in hearts and other organs. In particular, the benefits may extend to the brain and have important implications for learning and memory.
Foods rich in cocoa appear to reduce blood pressure but drinking green and black tea may not, according to an analysis of previously published research in the April 9, 2007 issue of Archives of Internal Medicine
A 15-year study of elderly men published in the "Archives of Internal Medicine" in 2006 found a 50 percent reduction in "cardiovascular" mortality and a 47 percent reduction in "all-cause" mortality for the men regularly consuming the most cocoa, compared to those consuming the least cocoa from all sources.
Child slavery.
The first allegations that child slavery is used in cocoa production appeared in 1998. In late 2000, a BBC documentary reported the use of enslaved children in the production of cocoa in West Africa. Other media followed by reporting widespread child slavery and child trafficking in the production of cocoa. According to a report by the International Labour Organization (ILO), in 2002, more than 109,000 children were working on cocoa farms in Ivory Coast, some of them in "the worst forms of child labour". The ILO later reported that 200,000 children were working in the cocoa industry in Ivory Coast in 2005. The 2005 ILO report failed to fully characterize this problem, but estimated that up to 6% of the 200,000 children involved in cocoa production could be victims of human trafficking or slavery. The cocoa industry was accused of profiting from child slavery and trafficking. The Harkin-Engel protocol is an effort to end these practices. It was signed and witnessed by the heads of eight major chocolate companies, Harkin, Engel, US Senator Herb Kohl, the ambassador of the Ivory Coast, the director of the International Programme on the Elimination of Child Labor, and others. It has, however, been criticized by some groups including the International Labor Rights Forum as an industry initiative which falls short.
Environmental impact.
The relative poverty of many cocoa farmers means that environmental consequences such as deforestation are given little significance. For decades, cocoa farmers have encroached on virgin forest, mostly after the felling of trees by logging companies. This trend has decreased as many governments and communities are beginning to protect their remaining forested zones. In general, the use of chemical fertilizers and pesticides by cocoa farmers is limited. When cocoa bean prices are high, farmers may invest in their crops, leading to higher yields which, in turn tends to result in lower market prices and a renewed period of lower investment.
Cocoa production is likely to be affected in various ways by the expected effects of global warming. Specific concerns have been raised concerning its future as a cash crop in West Africa, the current centre of global cocoa production. If temperatures continue to rise, West Africa could simply become unfit to grow the beans.
Agroforestry.
Cocoa beans may be cultivated under shaded conditions, e.g. agroforestry. Agroforestry can reduce the pressure on existing protected forests for resources, such as firewood, and conserve biodiversity. Agroforests act as buffers to formally protected forests and biodiversity island refuges in an open, human-dominated landscape. Research of their shade-grown coffee counterparts has shown that greater canopy cover in plots is significantly associated to greater mammal species richness and abundance. The amount of diversity in tree species is fairly comparable between shade-grown cocoa plots and primary forests. Farmers can grow a variety of fruit-bearing shade trees to supplement their income to help cope with the volatile cocoa prices. Though cocoa has been adapted to grow under a dense rainforest canopy, agroforestry does not significantly further enhance cocoa productivity.
Cocoa trading.
Cocoa beans, cocoa butter and cocoa powder are traded on two world exchanges: ICE Futures U.S. and NYSE Liffe Futures and Options. The London market is based on West African cocoa and New York on cocoa predominantly from Southeast Asia. Cocoa is the world's smallest soft commodity market.
The future price of cocoa butter and cocoa powder is determined by multiplying the bean price by a ratio. The combined butter and powder ratio has tended to be around 3.5. If the combined ratio falls below 3.2 or so, production ceases to be economically viable and some factories cease extraction of butter and powder and trade exclusively in cocoa liquor.
Cocoa beans can be held in storage for several years in bags or in bulk, during which the ownership can change several times, as the cocoa is traded much the same as metal or other commodities, to gain profit for the owner.needed

</doc>
<doc id="54230" url="https://en.wikipedia.org/wiki?curid=54230" title="463">
463

__NOTOC__
Year 463 (CDLXIII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Basilius and Vivianus (or, less frequently, year 1216 "Ab urbe condita"). The denomination 463 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="54231" url="https://en.wikipedia.org/wiki?curid=54231" title="467">
467

__NOTOC__
Year 467 (CDLXVII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Pusaeus and Iohannes (or, less frequently, year 1220 "Ab urbe condita"). The denomination 467 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="54232" url="https://en.wikipedia.org/wiki?curid=54232" title="Reinforced concrete">
Reinforced concrete

Reinforced concrete (RC) is a composite material in which concrete's relatively low tensile strength and ductility are counteracted by the inclusion of reinforcement having higher tensile strength and/or ductility. The reinforcement is usually, though not necessarily, steel reinforcing bars (rebar) and is usually embedded passively in the concrete before the concrete sets. Reinforcing schemes are generally designed to resist tensile stresses in particular regions of the concrete that might cause unacceptable cracking and/or structural failure. Modern reinforced concrete can contain varied reinforcing materials made of steel, polymers or alternate composite material in conjunction with rebar or not. Reinforced concrete may also be permanently stressed (in compression), so as to improve the behaviour of the final structure under working loads. In the United States, the most common methods of doing this are known as pre-tensioning and post-tensioning.
For a strong, ductile and durable construction the reinforcement needs to have the following properties at least:
History.
François Coignet was a French industrialist of the nineteenth century, a pioneer in the development of structural, prefabricated and reinforced concrete. Coignet was the first to use iron-reinforced concrete as a technique for constructing building structures. In 1853 Coignet built the first iron reinforced concrete structure, a four story house at 72 rue Charles Michels in the suburbs of Paris. Coignet's descriptions of reinforcing concrete suggests that he did not do it for means of adding strength to the concrete but for keeping walls in monolithic construction from overturning. In 1854, English builder William B. Wilkinson reinforced the concrete roof and floors in the two-storey house he was constructing. His positioning of the reinforcement demonstrated that, unlike his predecessors, he had knowledge of tensile stresses.
Joseph Monier, a French gardener and known to be one of the principal inventors of reinforced concrete, was granted a patent for reinforced flowerpots by means of mixing a wire mesh to a mortar shell. In 1877, Monier was granted another patent for a more advanced technique of reinforcing concrete columns and girders with iron rods placed in a grid pattern. Though Monier undoubtedly knew reinforcing concrete would improve its inner cohesion, it is less known if he even knew how much reinforcing actually improved concrete's tensile strength.
Before 1877 the use of concrete construction, though dating back to the Roman Empire and reintroduced in the mid to late 1800s, was not yet a proven scientific technology. American New Yorker Thaddeus Hyatt published a report titled "An Account of Some Experiments with Portland-Cement-Concrete Combined with Iron as a Building Material, with Reference to Economy of Metal in Construction and for Security against Fire in the Making of Roofs, Floors, and Walking Surfaces" where he stated his experiments on the behavior of reinforced concrete. His work played a major role in the evolution of concrete construction as a proven and studied science. Without Hyatt's work, more dangerous trial and error methods would have largely been depended on for the advancement in the technology.
G. A. Wayss was a German civil engineer and a pioneer of the iron and steel concrete construction. In 1879 Wayss bought the German rights to Monier's patents and in 1884 started the first commercial use for reinforced concrete in his firm Wayss & Freytag. Up until the 1890s Wayss and his firm greatly contributed to the advancement of Monier's system of reinforcing and established it as a well-developed scientific technology.
Ernest L. Ransome was an English-born engineer and early innovator of the reinforced concrete techniques in the end of the 19th century. With the knowledge of reinforced concrete developed during the previous 50 years, Ransome innovated nearly all styles and techniques of the previous known inventors of reinforced concrete. Ransome's key innovation was to twist the reinforcing steel bar improving bonding with the concrete. Gaining increasing fame from his concrete constructed buildings Ransome was able to build two of the first reinforced concrete bridges in North America. One of the first concrete buildings constructed in the United States, was a private home, designed by William Ward in 1871. The home was designed to be fireproof for his wife. One of the first skyscrapers made with reinforced concrete was the 16-storey Ingalls Building in Cincinnati, constructed in 1904.
Use in construction.
Many different types of structures and components of structures can be built using reinforced concrete including slabs, walls, beams, columns, foundations, frames and more.
Reinforced concrete can be classified as precast or cast-in-place concrete.
Designing and implementing the most efficient floor system is key to creating optimal building structures. Small changes in the design of a floor system can have significant impact on material costs, construction schedule, ultimate strength, operating costs, occupancy levels and end use of a building.
Without reinforcement, constructing modern structures with concrete material would not be possible.
Behavior of reinforced concrete.
Materials.
Concrete is a mixture of coarse (stone or brick chips) and fine (generally sand or crushed stone) aggregates with a paste of binder material (usually Portland cement) and water. When cement is mixed with a small amount of water, it hydrates to form microscopic opaque crystal lattices encapsulating and locking the aggregate into a rigid structure. The aggregates used for making concrete should be free from harmful substances like organic impurities, silt, clay, lignite etc. Typical concrete mixes have high resistance to compressive stresses (about ); however, any appreciable tension ("e.g.," due to bending) will break the microscopic rigid lattice, resulting in cracking and separation of the concrete. For this reason, typical non-reinforced concrete must be well supported to prevent the development of tension.
If a material with high strength in tension, such as steel, is placed in concrete, then the composite material, reinforced concrete, resists not only compression but also bending and other direct tensile actions. A reinforced concrete section where the concrete resists the compression and steel resists the tension can be made into almost any shape and size for the construction industry.
Key characteristics.
Three physical characteristics give reinforced concrete its special properties:
As a rule of thumb, only to give an idea on orders of magnitude, steel is protected at pH above ~11 but starts to corrode below ~10 depending on steel characteristics and local physico-chemical conditions when concrete becomes carbonated. Carbonatation of concrete along with chloride ingress are amongst the chief reasons for the failure of reinforcement bars in concrete.
The relative cross-sectional area of steel required for typical reinforced concrete is usually quite small and varies from 1% for most beams and slabs to 6% for some columns. Reinforcing bars are normally round in cross-section and vary in diameter. Reinforced concrete structures sometimes have provisions such as ventilated hollow cores to control their moisture & humidity.
Distribution of concrete (in spite of reinforcement) strength characteristics along the cross-section of vertical reinforced concrete elements is inhomogeneous.
Mechanism of composite action of reinforcement and concrete.
The reinforcement in a RC structure, such as a steel bar, has to undergo the same strain or deformation as the surrounding concrete in order to prevent discontinuity, slip or separation of the two materials under load. Maintaining composite action requires transfer of load between the concrete and steel. The direct stress is transferred from the concrete to the bar interface so as to change the tensile stress in the reinforcing bar along its length, this load transfer is achieved by means of bond (anchorage) and is idealized as a continuous stress field that develops in the vicinity of the steel-concrete interface.
Anchorage (bond) in concrete: Codes of specifications.
Because the actual bond stress varies along the length of a bar anchored in a zone of tension, current international codes of specifications use the concept of development length rather than bond stress. The main requirement for safety against bond failure is to provide a sufficient extension of the length of the bar beyond the point where the steel is required to develop its yield stress and this length must be at least equal to its development length. However, if the actual available length is inadequate for full development, special anchorages must be provided, such as cogs or hooks or mechanical end plates. The same concept applies to lap splice length mentioned in the codes where splices (overlapping) provided between two adjacent bars in order to maintain the required continuity of stress in the splice zone.
Anti-corrosion measures.
In wet and cold climates, reinforced concrete for roads, bridges, parking structures and other structures that may be exposed to deicing salt may benefit from use of corrosion-resistant reinforcement such as uncoated, low carbon/chromium (micro composite), epoxy-coated, hot dip galvanised or stainless steel rebar. Good design and a well-chosen concrete mix will provide additional protection for many applications. Uncoated, low carbon/chromium rebar looks similar to standard carbon steel rebar due to its lack of a coating; its highly corrosion-resistant features are inherent in the steel microstructure. It can be identified by the unique ASTM specified mill marking on its smooth, dark charcoal finish. Epoxy coated rebar can easily be identified by the light green colour of its epoxy coating. Hot dip galvanized rebar may be bright or dull grey depending on length of exposure, and stainless rebar exhibits a typical white metallic sheen that is readily distinguishable from carbon steel reinforcing bar. Reference ASTM standard specifications A1035/A1035M Standard Specification for Deformed and Plain Low-carbon, Chromium, Steel Bars for Concrete Reinforcement,A767 Standard Specification for Hot Dip Galvanised Reinforcing Bars, A775 Standard Specification for Epoxy Coated Steel Reinforcing Bars and A955 Standard Specification for Deformed and Plain Stainless Bars for Concrete Reinforcement.
Another, cheaper way of protecting rebars is coating them with zinc phosphate. Zinc phosphate slowly reacts with calcium cations and the hydroxyl anions present in the cement pore water and forms a stable hydroxyapatite layer.
Penetrating sealants typically must be applied some time after curing. Sealants include paint, plastic foams, films and aluminum foil, felts or fabric mats sealed with tar, and layers of bentonite clay, sometimes used to seal roadbeds.
Corrosion inhibitors, such as calcium nitrite can also be added to the water mix before pouring concrete. Generally, 1–2 wt. % of [Ca(NO2)2 with respect to cement weight is needed to prevent corrosion of the rebars. The nitrite anion is a mild oxidizer that oxidizes the soluble and mobile ferrous ions (Fe2+) present at the surface of the corroding steel and causes them to precipitate as an insoluble ferric hydroxide (Fe(OH)3). This causes the passivation of steel at the anodic oxidation sites. Nitrite is a much more active corrosion inhibitor than nitrate, which is a less powerful oxidizer of the divalent iron.
Reinforcement and terminology of beams.
A beam bends under bending moment, resulting in a small curvature. At the outer face (tensile face) of the curvature the concrete experiences tensile stress, while at the inner face (compressive face) it experiences compressive stress.
A singly reinforced beam is one in which the concrete element is only reinforced near the tensile face and the reinforcement, called tension steel, is designed to resist the tension.
A doubly reinforced beam is one in which besides the tensile reinforcement the concrete element is also reinforced near the compressive face to help the concrete resist compression. The latter reinforcement is called compression steel. When the compression zone of a concrete is inadequate to resist the compressive moment (positive moment), extra reinforcement has to be provided if the architect limits the dimensions of the section.
An under-reinforced beam is one in which the tension capacity of the tensile reinforcement is smaller than the combined compression capacity of the concrete and the compression steel (under-reinforced at tensile face). When the reinforced concrete element is subject to increasing bending moment, the tension steel yields while the concrete does not reach its ultimate failure condition. As the tension steel yields and stretches, an "under-reinforced" concrete also yields in a ductile manner, exhibiting a large deformation and warning before its ultimate failure. In this case the yield stress of the steel governs the design.
An over-reinforced beam is one in which the tension capacity of the tension steel is greater than the combined compression capacity of the concrete and the compression steel (over-reinforced at tensile face). So the "over-reinforced concrete" beam fails by crushing of the compressive-zone concrete and before the tension zone steel yields, which does not provide any warning before failure as the failure is instantaneous.
A balanced-reinforced beam is one in which both the compressive and tensile zones reach yielding at the same imposed load on the beam, and the concrete will crush and the tensile steel will yield at the same time. This design criterion is however as risky as over-reinforced concrete, because failure is sudden as the concrete crushes at the same time of the tensile steel yields, which gives a very little warning of distress in tension failure.
Steel-reinforced concrete moment-carrying elements should normally be designed to be under-reinforced so that users of the structure will receive warning of impending collapse.
The characteristic strength is the strength of a material where less than 5% of the specimen shows lower strength.
The design strength or nominal strength is the strength of a material, including a material-safety factor. The value of the safety factor generally ranges from 0.75 to 0.85 in Permissible stress design.
The ultimate limit state is the theoretical failure point with a certain probability. It is stated under factored loads and factored resistances.
Reinforced concrete structures are normally designed according to rules and regulations or recommendation of a code such as ACI-318, CEB, Eurocode 2 or the like. WSD, USD or LRFD methods are used in design of RC structural members. Analysis and design of RC members can be carried out by using linear or non-linear approaches. When applying safety factors, building codes normally propose linear approaches, but for some cases non-linear approaches. To see the examples of a non-linear numerical simulation and calculation visit the references:
Prestressed concrete.
Prestressing concrete is a technique that greatly increases the load-bearing strength of concrete beams. The reinforcing steel in the bottom part of the beam, which will be subjected to tensile forces when in service, is placed in tension before the concrete is poured around it. Once the concrete has hardened, the tension on the reinforcing steel is released, placing a built-in compressive force on the concrete. When loads are applied, the reinforcing steel takes on more stress and the compressive force in the concrete is reduced, but does not become a tensile force. Since the concrete is always under compression, it is less subject to cracking and failure.
Another way is to insert plastic tubes into the bottom of the beam. Rebar is inserted into these tubes. Once the concrete has cured the rebar can be tensioned and the formwork removed. Usually the tension is applied using hydraulic jacks. The advantage of this method is that it is easy to measure the applied tension. The nuts are then snugged-up and the job is done. It should be noted that all nuts and bolts when mated together will have a helical groove which is a potential rust-trap. An easy method of eliminating this rust-trap is to apply rust-preventive red-oxide paint to the threads and to join the nuts and bolts while this paint is still wet.
Common failure modes of steel reinforced concrete.
Reinforced concrete can fail due to inadequate strength, leading to mechanical failure, or due to a reduction in its durability. Corrosion and freeze/thaw cycles may damage poorly designed or constructed reinforced concrete. When rebar corrodes, the oxidation products (rust) expand and tends to flake, cracking the concrete and unbonding the rebar from the concrete. Typical mechanisms leading to durability problems are discussed below.
Mechanical failure.
Cracking of the concrete section is nearly impossible to prevent; however, the size and location of cracks can be limited and controlled by appropriate reinforcement, control joints, curing methodology and concrete mix design. Cracking can allow moisture to penetrate and corrode the reinforcement. This is a serviceability failure in limit state design. Cracking is normally the result of an inadequate quantity of rebar, or rebar spaced at too great a distance. The concrete then cracks either under excess loading, or due to internal effects such as early thermal shrinkage while it cures.
Ultimate failure leading to collapse can be caused by crushing the concrete, which occurs when compressive stresses exceed its strength, by yielding or failure of the rebar when bending or shear stresses exceed the strength of the reinforcement, or by bond failure between the concrete and the rebar.
Carbonation.
Carbonation, or neutralisation, is a chemical reaction between carbon dioxide in the air and calcium hydroxide and hydrated calcium silicate in the concrete.
When a concrete structure is designed, it is usual to state the concrete cover for the rebar (the depth of the rebar within the object). The minimum concrete cover is normally regulated by design or building codes. If the reinforcement is too close to the surface, early failure due to corrosion may occur. The concrete cover depth can be measured with a cover meter. However, carbonated concrete incurs a durability problem only when there is also sufficient moisture and oxygen to cause electropotential corrosion of the reinforcing steel.
One method of testing a structure for carbonatation is to drill a fresh hole in the surface and then treat the cut surface with phenolphthalein indicator solution. This solution turns pink when in contact with alkaline concrete, making it possible to see the depth of carbonation. Using an existing hole does not suffice because the exposed surface will already be carbonated.
Chlorides.
Chlorides, including sodium chloride, can promote the corrosion of embedded steel rebar if present in sufficiently high concentration. Chloride anions induce both localized corrosion (pitting corrosion) and generalized corrosion of steel reinforcements. For this reason, one should only use fresh raw water or potable water for mixing concrete, ensure that the coarse and fine aggregates do not contain chlorides, rather than admixtures which might contain chlorides.
It was once common for calcium chloride to be used as an admixture to promote rapid set-up of the concrete. It was also mistakenly believed that it would prevent freezing. However, this practice fell into disfavor once the deleterious effects of chlorides became known. It should be avoided whenever possible.
The use of de-icing salts on roadways, used to lower the freezing point of water, is probably one of the primary causes of premature failure of reinforced or prestressed concrete bridge decks, roadways, and parking garages. The use of epoxy-coated reinforcing bars and the application of cathodic protection has mitigated this problem to some extent. Also FRP (fiber-reinforced polymer) rebars are known to be less susceptible to chlorides. Properly designed concrete mixtures that have been allowed to cure properly are effectively impervious to the effects of de-icers.
Another important source of chloride ions is sea water. Sea water contains by weight approximately 3.5 wt.% salts. These salts include sodium chloride, magnesium sulfate, calcium sulfate, and bicarbonates. In water these salts dissociate in free ions (Na+, Mg2+, Cl−, SO42−, HCO3−) and migrate with the water into the capillaries of the concrete. Chloride ions, which make up about 50% of these ions, are particularly aggressive as a cause of corrosion of carbon steel reinforcement bars.
In the 1960s and 1970s it was also relatively common for magnesite, a chloride rich carbonate mineral, to be used as a floor-topping material. This was done principally as a levelling and sound attenuating layer. However it is now known that when these materials come into contact with moisture they produce a weak solution of hydrochloric acid due to the presence of chlorides in the magnesite. Over a period of time (typically decades) the solution causes corrosion of the embedded steel rebars. This was most commonly found in wet areas or areas repeatedly exposed to moisture.
Alkali silica reaction.
This a reaction of amorphous silica (chalcedony, chert, siliceous limestone) sometimes present in the aggregates with the hydroxyl ions (OH−) from the cement pore solution. Poorly crystallized silica (SiO2) dissolves and dissociates at high pH (12.5 - 13.5) in alkaline water. The soluble dissociated silicic acid reacts in the porewater with the calcium hydroxide (portlandite) present in the cement paste to form an expansive calcium silicate hydrate (CSH). The alkali silica reaction (ASR) causes localised swelling responsible for tensile stress and cracking. The conditions required for alkali silica reaction are threefold:
(1) aggregate containing an alkali-reactive constituent (amorphous silica), (2) sufficient availability of hydroxyl ions (OH−), and (3) sufficient moisture, above 75% relative humidity (RH) within the concrete. This phenomenon is sometimes popularly referred to as "concrete cancer". This reaction occurs independently of the presence of rebars; massive concrete structures such as dams can be affected.
Conversion of high alumina cement.
Resistant to weak acids and especially sulfates, this cement cures quickly and has very high durability and strength. It was frequently used after World War II to make precast concrete objects. However, it can lose strength with heat or time (conversion), especially when not properly cured. After the collapse of three roofs made of prestressed concrete beams using high alumina cement, this cement was banned in the UK in 1976. Subsequent inquiries into the matter showed that the beams were improperly manufactured, but the ban remained.
Sulphates.
Sulfates (SO4) in the soil or in groundwater, in sufficient concentration, can react with the Portland cement in concrete causing the formation of expansive products, e.g., ettringite or thaumasite, which can lead to early failure of the structure. The most typical attack of this type is on concrete slabs and foundation walls at grades where the sulfate ion, via alternate wetting and drying, can increase in concentration. As the concentration increases, the attack on the Portland cement can begin. For buried structures such as pipe, this type of attack is much rarer, especially in the eastern United States. The sulfate ion concentration increases much slower in the soil mass and is especially dependent upon the initial amount of sulfates in the native soil. A chemical analysis of soil borings to check for the presence of sulfates should be undertaken during the design phase of any project involving concrete in contact with the native soil. If the concentrations are found to be aggressive, various protective coatings can be applied. Also, in the US ASTM C150 Type 5 Portland cement can be used in the mix. This type of cement is designed to be particularly resistant to a sulfate attack.
Steel plate construction.
In steel plate construction, stringers join parallel steel plates. The plate assemblies are fabricated off site, and welded together on-site to form steel walls connected by stringers. The walls become the form into which concrete is poured. Steel plate construction speeds reinforced concrete construction by cutting out the time-consuming on-site manual steps of tying rebar and building forms. The method results in excellent strength because the steel is on the outside, where tensile forces are often greatest.
Fiber-reinforced concrete.
Fiber reinforcement is mainly used in shotcrete, but can also be used in normal concrete. Fiber-reinforced normal concrete is mostly used for on-ground floors and pavements, but can be considered for a wide range of construction parts (beams, pillars, foundations, etc.), either alone or with hand-tied rebars.
Concrete reinforced with fibers (which are usually steel, glass, or plastic fibers) is less expensive than hand-tied rebar, while still increasing the tensile strength many times. The shape, dimension, and length of the fiber are important. A thin and short fiber, for example short, hair-shaped glass fiber, is only effective during the first hours after pouring the concrete (its function is to reduce cracking while the concrete is stiffening), but it will not increase the concrete tensile strength. A normal-size fiber for European shotcrete (1 mm diameter, 45 mm length—steel or plastic) will increase the concrete's tensile strength.
Steel is the strongest commonly-available fiber, and comes in different lengths (30 to 80 mm in Europe) and shapes (end-hooks). Steel fibers can only be used on surfaces that can tolerate or avoid corrosion and rust stains. In some cases, a steel-fiber surface is faced with other materials.
Glass fiber is inexpensive and corrosion-proof, but not as ductile as steel. Recently, spun basalt fiber, long available in Eastern Europe, has become available in the U.S. and Western Europe. Basalt fibre is stronger and less expensive than glass, but historically has not resisted the alkaline environment of portland cement well enough to be used as direct reinforcement. New materials use plastic binders to isolate the basalt fiber from the cement.
The premium fibers are graphite-reinforced plastic fibers, which are nearly as strong as steel, lighter in weight, and corrosion-proof. Some experiments have had promising early results with carbon nanotubes, but the material is still far too expensive for any building.
Non-steel reinforcement.
There is considerable overlap between the subjects of non-steel reinforcement and fiber-reinforcement of concrete. The introduction of non-steel reinforcement of concrete is relatively recent; it takes two major forms: non-metallic rebar rods, and non-steel (usually also non-metallic) fibres incorporated into the cement matrix. For example, there is increasing interest in glass fiber reinforced concrete (GFRC) and in various applications of polymer fibres incorporated into concrete. Although currently there is not much suggestion that such materials will in general replace metal rebar, some of them have major advantages in specific applications, and there also are new applications in which metal rebar simply is not an option. However, the design and application of non-steel reinforcing is fraught with challenges. For one thing, concrete is a highly alkaline environment, in which many materials, including most kinds of glass, have a poor service life. Also, the behaviour of such reinforcing materials differs from the behaviour of metals, for instance in terms of shear strength, creep and elasticity.
Fibre-reinforced plastic/polymer (FRP) and glass-reinforced plastic (GRP) consist of fibres of polymer, glass, carbon, aramid or other polymers or high-strength fibres set in a resin matrix to form a rebar rod, or grid, or fibres. These rebars are installed in much the same manner as steel rebars. The cost is higher but, suitably applied, the structures have advantages, in particular a dramatic reduction in problems related to corrosion, either by intrinsic concrete alkalinity or by external corrosive fluids that might penetrate the concrete. These structures can be significantly lighter and usually have a longer service life. The cost of these materials has dropped dramatically since their widespread adoption in the aerospace industry and by the military.
In particular, FRP rods are useful for structures where the presence of steel would not be acceptable. For example, MRI machines have huge magnets, and accordingly require non-magnetic buildings. Again, toll booths that read radio tags need reinforced concrete that is transparent to radio waves. Also, where the design life of the concrete structure is more important than its initial costs, non-steel reinforcing often has its advantages where corrosion of reinforcing steel is a major cause of failure. In such situations corrosion-proof reinforcing can extend a structure's life substantially, for example in the intertidal zone. FRP rods may also be useful in situations where it is likely that the concrete structure may be compromised in future years, for example the edges of balconies when balustrades are replaced, and bathroom floors in multi-story construction where the service life of the floor structure is likely to be many times the service life of the waterproofing building membrane.
Plastic reinforcement often is stronger, or at least has a better strength to weight ratio than reinforcing steels. Also, because it resists corrosion, it does not need a protective concrete cover as thick as steel reinforcement does (typically 30 to 50 mm or more). FRP-reinforced structures therefore can be lighter and last longer. Accordingly, for some applications the whole-life cost will be price-competitive with steel-reinforced concrete.
The material properties of FRP or GRP bars differ markedly from steel, so there are differences in the design considerations. FRP or GRP bars have relatively higher tensile strength but lower stiffness, so that deflections are likely to be higher than for equivalent steel-reinforced units. Structures with internal FRP reinforcement typically have an elastic deformability comparable to the plastic deformability (ductility) of steel reinforced structures. Failure in either case is more likely to occur by compression of the concrete than by rupture of the reinforcement. Deflection is always a major design consideration for reinforced concrete. Deflection limits are set to ensure that crack widths in steel-reinforced concrete are controlled to prevent water, air or other aggressive substances reaching the steel and causing corrosion. For FRP-reinforced concrete, aesthetics and possibly water-tightness will be the limiting criteria for crack width control. FRP rods also have relatively lower compressive strengths than steel rebar, and accordingly require different design approaches for reinforced concrete columns.
One drawback to the use of FRP reinforcement is their limited fire resistance. Where fire safety is a consideration, structures employing FRP have to maintain their strength and the anchoring of the forces at temperatures to be expected in the event of fire. For purposes of fireproofing an adequate thickness of cement concrete cover or protective cladding is necessary. The addition of 1 kg/m3 of polypropylene fibers to concrete has been shown to reduce spalling during a simulated fire. (The improvement is thought to be due to the formation of pathways out of the bulk of the concrete, allowing steam pressure to dissipate.)
Another problem is the effectiveness of shear reinforcement. FRP rebar stirrups formed by bending before hardening generally perform relatively poorly in comparison to steel stirrups or to structures with straight fibres. When strained, the zone between the straight and curved regions are subject to strong bending, shear, and longitudinal stresses. Special design techniques are necessary to deal with such problems.
There is growing interest in applying external reinforcement to existing structures using advanced materials such as composite (fiberglass, basalt, carbon) rebar, which can impart exceptional strength. Worldwide there are a number of brands of composite rebar recognized by different countries, such as Aslan, DACOT, V-rod, and ComBar. The number of projects using composite rebar increases day by day around the world, in countries ranging from USA, Russia, and South Korea to Germany.

</doc>
<doc id="54233" url="https://en.wikipedia.org/wiki?curid=54233" title="464">
464

__NOTOC__
Year 464 (CDLXIV) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Rusticus and Olybrius (or, less frequently, year 1217 "Ab urbe condita"). The denomination 464 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="54234" url="https://en.wikipedia.org/wiki?curid=54234" title="465">
465

__NOTOC__
Year 465 (CDLXV) was a common year starting on Friday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Hermenericus and Basiliscus (or, less frequently, year 1218 "Ab urbe condita"). The denomination 465 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="54235" url="https://en.wikipedia.org/wiki?curid=54235" title="Transmigration">
Transmigration

Transmigration may refer to:

</doc>
<doc id="54240" url="https://en.wikipedia.org/wiki?curid=54240" title="Singularity (mathematics)">
Singularity (mathematics)

In mathematics, a singularity is in general a point at which a given mathematical object is not defined, or a point of an exceptional set where it fails to be well-behaved in some particular way, such as differentiability. See Singularity theory for general discussion of the geometric theory, which only covers some aspects.
For example, the function
on the real line has a singularity at "x" = 0, where it seems to "explode" to ±∞ and is not defined. The function "g"("x") = |"x"| (see absolute value) also has a singularity at "x" = 0, since it is not differentiable there. Similarly, the graph defined by "y"2 = "x" also has a singularity at (0,0), this time because it has a "corner" (vertical tangent) at that point.
The algebraic set defined by formula_2 in the ("x", "y") coordinate system has a singularity (singular point) at (0, 0) because it does not admit a tangent there.
Real analysis.
In real analysis singularities are either discontinuities or discontinuities of the derivative (sometimes also discontinuities of higher order derivatives). There are four kinds of discontinuities: type I, which has two sub-types, and type II, which also can be divided into two subtypes, but normally is not.
To describe these types two limits are used. Suppose that formula_3 is a function of a real argument formula_4, and for any value of its argument, say formula_5, then the left-handed limit, formula_6, and the right-handed limit, formula_7, are defined by:
The value formula_6 is the value that the function formula_3 "tends towards" as the value formula_4 approaches formula_5 from below, and the value formula_7 is the value that the function formula_3 "tends towards" as the value formula_4 approaches formula_5 from above, regardless of the actual value the function has at the point where formula_20 .
There are some functions for which these limits do not exist at all. For example, the function
does not tend towards anything as formula_4 approaches formula_23. The limits in this case are not infinite, but rather undefined: there is no value that formula_24 settles in on. Borrowing from complex analysis, this is sometimes called an "essential singularity".
In real analysis, a singularity or discontinuity is a property of a function alone. Any singularities that may exist in the derivative of a function are considered as belonging to the derivative, not to the original function.
Coordinate singularities.
A coordinate singularity (or coördinate singularity) occurs when an apparent singularity or discontinuity occurs in one coordinate frame, which can be removed by choosing a different frame. An example is the apparent singularity at the 90 degree latitude in spherical coordinates. An object moving due north (for example, along the line 0 degrees longitude) on the surface of a sphere will suddenly experience an instantaneous change in longitude at the pole (in the case of the example, jumping from longitude 0 to longitude 180 degrees). This discontinuity, however, is only apparent; it is an artifact of the coordinate system chosen, which is singular at the poles. A different coordinate system would eliminate the apparent discontinuity, e.g. by replacing latitude/longitude with n-vector.
Complex analysis.
In complex analysis there are four classes of singularities, described below. Suppose "U" is an open subset of the complex numbers C, and the point "a" is an element of "U", and "f" is a complex differentiable function defined on some neighborhood around "a", excluding "a": "U" \ {"a"}.
Finite-time singularity.
A finite-time singularity occurs when one input variable is time, and an output variable increases towards infinity at a finite time. These are important in kinematics and PDEs (Partial Differential Equations) – infinites do not occur physically, but the behavior near the singularity is often of interest. Mathematically the simplest finite-time singularities are power laws for various exponents, formula_48 of which the simplest is hyperbolic growth, where the exponent is (negative) 1: formula_49 More precisely, in order to get a singularity at positive time as time advances (so the output grows to infinity), one instead uses formula_50 (using "t" for time, reversing direction to formula_51 so time increases to infinity, and shifting the singularity forward from 0 to a fixed time formula_52).
An example would be the bouncing motion of an inelastic ball on a plane. If idealized motion is considered, in which the same fraction of kinetic energy is lost on each bounce, the frequency of bounces becomes infinite as the ball comes to rest in a finite time. Other examples of finite-time singularities include the Painlevé paradox in various forms (for example, the tendency of a chalk to skip when dragged across a blackboard), and how the precession rate of a coin spun on a flat surface accelerates towards infinite, before abruptly stopping (as studied using the Euler's Disk toy).
Hypothetical examples include Heinz von Foerster's facetious "Doomsday's equation" (simplistic models yield infinite human population in finite time).
Algebraic geometry and commutative algebra.
In algebraic geometry, a singularity of an algebraic variety is a point of the variety where the tangent space may not be regularly defined. The simplest example of singularities are curves that cross themselves. But there are other types of singularities, like cusps. For example, the equation defines a curve that has a cusp at the origin . One could define the -axis as a tangent at this point, but this definition can not be the same as the definition at other points. In fact, in this case, the -axis is a "double tangent."
For affine and projective varieties, the singularities are the points where the Jacobian matrix has a rank which is lower than at other points of the variety.
An equivalent definition in terms of commutative algebra may be given, which extends to abstract varieties and schemes: A point is "singular" if the local ring at this point is not a regular local ring.

</doc>
<doc id="54242" url="https://en.wikipedia.org/wiki?curid=54242" title="Vesak">
Vesak

Vesākha (Pali; ), also known as Buddha Purnima and Buddha Day, is a holiday observed traditionally by Buddhists on different days in India, Sri Lanka, Nepal, Tibet, Bangladesh, Bhutan, Indonesia, Philippines, Singapore, Vietnam, Thailand, Cambodia, Laos, Malaysia and Myanmar and in other places all over the world. Sometimes informally called "Buddha's Birthday", it actually commemorates the birth, enlightenment (nirvāna), and death (Parinirvāna) of Gautama Buddha in the Theravada or southern tradition.
History.
The decision to agree to celebrate Vesākha as the Buddha’s birthday was formalized at the first conference of the World Fellowship of Buddhists held in Sri Lanka in 1950, although festivals at this time in the Buddhist world are a centuries-old tradition. The resolution that was adopted at the World Conference reads as follows:
On Vesākha Day, Buddhists all over the world commemorate events of significance to Buddhists of all traditions: The birth, enlightenment and the passing away of Gautama Buddha. As Buddhism spread from India it was assimilated into many foreign cultures, and consequently Vesākha is celebrated in many different ways all over the world. In India, Vaishakh Purnima day is also known as Buddha Jayanti day and has been traditionally accepted as Buddha's birth day.
In 1999, the United Nations resolved to internationally observe the day of Vesak at its headquarters and offices.
The name of the observance is derived from the Pali term ' or Sanskrit ', which is the name of the lunar month in the Hindu calendar falling in April–May (see Vaisakha). In Mahayana Buddhist traditions, the holiday is known by its Sanskrit name (Vaiśākha) and derived variants of it. Local renditions of the name vary by language, including:
The celebration of Vesākha.
May 2007 just had two full moon days the 1st and the 31st. Some countries (including Sri Lanka, Cambodia and Malaysia) celebrated Vesākha on the 1st, while others (Thailand, Singapore) celebrated the holiday on the 31st due to different local lunar observance. This difference also manifests in the observance of other Buddhist holidays, which are traditionally observed at the local full moon.
Likewise, in 2012, Vesak or the birth anniversary of the Buddha was observed on 28 April in Hong Kong and Taiwan, on 5 May in Sri Lanka, on 6 May in India, on 28 May in South Korea and on 4 June in Thailand. (In 1999 the Taiwanese government set Buddha's birthday as the second Sunday of May, the same date as Mother's Day.). In 2014, Vesak is celebrated on 13 May in Myanmar, Singapore and Thailand while it is observed on 15 May in Indonesia.
On Vesākha day, devout Buddhists and followers alike are expected and requested to assemble in their various temples before dawn for the ceremonial, and honorable, hoisting of the Buddhist flag and the singing of hymns in praise of the holy triple gem: The Buddha, The Dharma (his teachings), and The Sangha (his disciples). Devotees may bring simple offerings of flowers, candles and joss-sticks to lay at the feet of their teacher. These symbolic offerings are to remind followers that just as the beautiful flowers would wither away after a short while and the candles and joss-sticks would soon burn out, so too is life subject to decay and destruction. Devotees are enjoined to make a special effort to refrain from killing of any kind. They are encouraged to partake of vegetarian food for the day. In some countries, notably Sri Lanka, two days are set aside for the celebration of Vesākha and all liquor shops and slaughter houses are closed by government decree during the two days. Also birds, insects and animals are released by the thousands in what is known as a 'symbolic act of liberation'; of giving freedom to those who are in captivity, imprisoned, or tortured against their will. Some devout Buddhists will wear a simple white dress and spend the whole day in temples with renewed determination to observe the eight Precepts.
Devout Buddhists undertake to lead a noble life according to the teaching by making daily affirmations to observe the Five Precepts. However, on special days, notably new moon and full moon days, they observe the eight Precepts to train themselves to practice morality, simplicity and humility.
Some temples also display a small statue of the Buddha in front of the altar in a small basin filled with water and decorated with flowers, allowing devotees to pour water over the statue; it is symbolic of the cleansing of a practitioner's bad karma, and to reenact the events following the Buddha's birth, when devas and spirits made heavenly offerings to him.
Devotees are expected to listen to talks given by monks. On this day monks will recite verses uttered by the Buddha twenty-five centuries ago, to invoke peace and happiness for the government and the people. Buddhists are reminded to live in harmony with people of other faiths and to respect the beliefs of other people as the Buddha taught.
Bringing happiness to others.
Celebrating Vesākha also means making special efforts to bring happiness to the unfortunate like the aged, the handicapped and the sick. To this day, Buddhists will distribute gifts in cash and kind to various charitable homes throughout the country. Vesākha is also a time for great joy and happiness, expressed not by pandering to one’s appetites but by concentrating on useful activities such as decorating and illuminating temples, painting and creating exquisite scenes from the life of the Buddha for public dissemination. Devout Buddhists also vie with one another to provide refreshments and vegetarian food to followers who visit the temple to pay homage to the Enlightened One.
Paying homage to the Buddha.
Tradition ascribes to the Buddha himself instruction on how to pay him homage. Just before he died, he saw his faithful attendant Ananda, weeping. The Buddha advised him not to weep, but to understand the universal law that all compounded things (including even his own body) must disintegrate. He advised everyone not to cry over the disintegration of the physical body but to regard his teachings (The Dhamma) as their teacher from then on, because only the Dhamma truth is eternal and not subject to the law of change. He also stressed that the way to pay homage to him was not merely by offering flowers, incense, and lights, but by truly and sincerely striving to follow his teachings. This is how Buddhists are expected to celebrate Vesak: to use the opportunity to reiterate their determination to lead noble lives, to develop their minds, to practise loving-kindness and to bring peace and harmony to humanity.
Dates of observance.
The exact date of Vesak is based on the Asian lunisolar calendars and is primarily celebrated in Vaisakha month of the Buddhist calendar and the Hindu calendar, and hence the name Vesak. In Nepal, which is considered the birth-country of Buddha, it is celebrated on the full moon day of the Vaisakha month of the Hindu calendar, and is traditionally called Buddha Purnima, Purnima meaning the full moon day in Sanskrit. In Theravada countries following the Buddhist calendar, it falls on a full moon Uposatha day, typically in the 5th or 6th lunar month. Nowadays, in Sri Lanka, Nepal, India, Vesak/Buddha Purnima is celebrated on the day of the full moon in May in the Gregorian calendar. In Thailand, Laos, Indonesia, Vesak is celebrated on the fourteenth or fifteenth day of the fourth month in the Chinese lunar calendar. In China, and Korea, Vietnam, Buddha's Birthday is celebrated on the eighth day of the fourth month in the Chinese lunar calendar, in Japan the same day but in the Gregorian calendar. The date varies from year to year in the Western Gregorian calendar, but usually falls in April or May. In leap years it may be celebrated in June.
In Japan.
In Japan, Vesākha or is also known as , ), , , and . It is not a public holiday. It is based on a legend that a dragon appeared in the sky on the Buddha's birthday and poured soma over him.
It used to be celebrated on the 8th day of the fourth month in the Chinese calendar based on one of the legends that proclaims the day as Buddha's birthday. At present, the celebration is observed on 8 April of the Solar Calendar since the government of Meiji Japan adopted the western solar calendar as the official calendar. Since the 8th day of the fourth month in the lunar calendar commonly falls in May of the current solar calendar, it is now celebrated about a month earlier.
In Japan, Vesak celebrations include pouring , a sweet tea made from "Hydrangea macrophylla", on statues. In Buddhist religious sites such as temples and viharas, more involved ceremonies are conducted for lay Buddhists, priests, and monks and nuns.
Vesak In Nepal.
Vesak, commonly known in Nepal as "Buddha Jayanti" is widely celebrated all across the country, predominantly, Lumbini – the birthplace of Buddha, and Swayambhu – the holy temple for Buddhists, also known as "the Monkey Temple". The main door of Swayambhu is opened only on this very day, therefore, people from all over Kathmandu valley are stimulated by the event. Thousands of pilgrims from various parts of the world come together to celebrate Buddha's birthday at his birthplace, Lumbini. In Nepal, Buddha is worshipped by all religious groups, therefore "Buddha Jayanti" is marked by a public holiday. People donate foods and clothes to the needy and also provide financial aid to monasteries and schools where Buddhism is taught and practised.
Vesak in Sri Lanka.
Vesak is celebrated as a religious and a cultural festival in Sri Lanka on the full moon of the lunar month of Vesak (usually in the Gregorian month of May), for about one week. During this week, the selling of alcohol and fresh meat is usually prohibited, with abattoirs also being closed. Celebrations include religious and alms-giving activities. Electrically-lit pandals called "thoranas" are erected in locations mainly in Colombo, Kandy, Galle and elsewhere, most sponsored by donors, religious societies and welfare groups. Each pandal illustrates a story from the Jataka tales.
In addition, colourful lanterns called "Vesak kuudu" are hung along streets and in front of homes. They signify the light of the Buddha, Dharma and the Sangha. Food stalls set up by Buddhist devotees called "dansälas" provide free food and drinks to passersby. Groups of people from community organisations, businesses and government departments sing "bhakti gee" (Buddhist devotional songs). Colombo experiences a massive influx of people from all parts of the country during this week.
In Korea.
In South Korea the birthday of Buddha is celebrated on the 8th day of the 4th month in the Korean lunar calendar (as well as in Hong Kong, Macau, Vietnam) and is an official holiday. This day is called (Seokga tansinil), meaning "Buddha's birthday" or (Bucheonim osin nal) meaning "the day when the Buddha came". It has now grown into one of the nation’s biggest cultural festivals. Lotus lanterns cover the entire temple throughout the month which are often flooded down the street. On the day of Buddha's birth, many temples provide free meals and tea to all visitors. The breakfast and lunch provided are often sanchae bibimbap.
In Vietnam.
Before 1975, the birthday of Buddha was a national public holiday in South Vietnam It was a public festival with float and lantern parades on the streets. However, after the Fall of Saigon, the day was no longer a public holiday.
Wesak In Malaysia.
Celebrated by Buddhists to mark three momentous events in Buddha's life – his birth, enlightenment, and his departure from the human world, the Wesak celebration in Malaysia begins at dawn when devotees gather at Buddhist temples nationwide to meditate on the Eight Precepts. Donations - giving food to the needy and offerings of incense and joss sticks - and prayers are carried out. The sutras are chanted in unison by monks in saffron robes. The celebration is highlighted by a candle procession. Wesak Day in Malaysia is a national public holiday.
Waisak In Indonesia.
This significant and traditional holy day is observed throughout Indonesia where it is known as Waisak Day. At Borobudur, thousands of Buddhist monks will join together to repeat mantras and meditate as they circuit the temple in a ritual called "Pradaksina". This is a form of tribute to the temple. Monks celebrate the special day by bottling holy water (which symbolises humility) and transporting flames (which symbolize light and enlightenment) from location to location. The monks also took part in the "Pindapata" ritual, where they received charity from the people of Indonesia. Waisak Day in Indonesia has been celebrated as a national public holiday every year since 1983.
Vesak In Singapore.
In Singapore, Vesak Day was made a public holiday only in 1955 after many public petitions. In the early decades of the 20th century, Vesak Day was associated with the Ceylonese community which then celebrated it along with their National Day in a two-day event. After World War II, there was a movement to make Vesak Day a public holiday, with the Singapore Buddhist Association leading the petitions.

</doc>
<doc id="54244" url="https://en.wikipedia.org/wiki?curid=54244" title="Gravitational singularity">
Gravitational singularity

A gravitational singularity or spacetime singularity is a location where the quantities that are used to measure the gravitational field of a celestial body become infinite in a way that does not depend on the coordinate system. These quantities are the scalar invariant curvatures of spacetime, which includes a measure of the density of matter. The laws of normal spacetime could not exist within a singularity.
For the purposes of proving the Penrose–Hawking singularity theorems, a spacetime with a singularity is defined to be one that contains geodesics that cannot be extended in a smooth manner. The end of such a geodesic is considered to be the singularity. This is a different definition, useful for proving theorems.
The two most important types of spacetime singularities are "curvature singularities" and "conical singularities". Singularities can also be divided according to whether or not they are covered by an event horizon (naked singularities are not covered). According to modern general relativity, the initial state of the universe, at the beginning of the Big Bang, was a singularity. Both general relativity and quantum mechanics break down in describing the earliest moments of the Big Bang, but in general, quantum mechanics does not permit particles to inhabit a space smaller than their wavelengths. Another type of singularity predicted by general relativity is inside a black hole: any star collapsing beyond a certain point (the Schwarzschild radius) would form a black hole, inside which a singularity (covered by an event horizon) would be formed, as all the matter would flow into a certain point (or a circular line, if the black hole is rotating). This is again according to general relativity without quantum mechanics, which forbids wavelike particles entering a space smaller than their wavelength. These hypothetical singularities are also known as curvature singularities.
Interpretation.
Many theories in physics have mathematical singularities of one kind or another. Equations for these physical theories predict that the ball of mass of some quantity becomes infinite or increases without limit. This is generally a sign for a missing piece in the theory, as in the ultraviolet catastrophe, renormalization, and instability of a hydrogen atom predicted by the Larmor formula.
In supersymmetry, a singularity in the moduli space happens usually when there are additional massless degrees of freedom in that certain point. Similarly, it is thought that singularities in spacetime often mean that there are additional degrees of freedom that exist only within the vicinity of the singularity. The same fields related to the whole spacetime also exist; for example, the electromagnetic field. In known examples of string theory, the latter degrees of freedom are related to closed strings, while the degrees of freedom are "stuck" to the singularity and related either to open strings or to the twisted sector of an orbifold.
Some theories, such as the theory of loop quantum gravity suggest that singularities may not exist. The idea is that due to quantum gravity effects, there is a minimum distance beyond which the force of gravity no longer continues to increase as the distance between the masses becomes shorter.
Types.
Curvature.
Solutions to the equations of general relativity or another theory of gravity (such as supergravity) often result in encountering points where the metric blows up to infinity. However, many of these points are completely regular, and the infinities are merely a result of using an inappropriate coordinate system at this point. In order to test whether there is a singularity at a certain point, one must check whether at this point diffeomorphism invariant quantities (i.e. scalars) become infinite. Such quantities are the same in every coordinate system, so these infinities will not "go away" by a change of coordinates.
An example is the Schwarzschild solution that describes a non-rotating, uncharged black hole. In coordinate systems convenient for working in regions far away from the black hole, a part of the metric becomes infinite at the event horizon. However, spacetime at the event horizon is regular. The regularity becomes evident when changing to another coordinate system (such as the Kruskal coordinates), where the metric is perfectly smooth. On the other hand, in the center of the black hole, where the metric becomes infinite as well, the solutions suggest a singularity exists. The existence of the singularity can be verified by noting that the Kretschmann scalar, being the square of the Riemann tensor i.e. formula_1, which is diffeomorphism invariant, is infinite.
While in a non-rotating black hole the singularity occurs at a single point in the model coordinates, called a "point singularity", in a rotating black hole, also known as a Kerr black hole, the singularity occurs on a ring (a circular line), known as a "ring singularity". Such a singularity may also theoretically become a wormhole.
More generally, a spacetime is considered singular if it is geodesically incomplete, meaning that there are freely-falling particles whose motion cannot be determined beyond a finite time, being after the point of reaching the singularity. For example, any observer inside the event horizon of a non-rotating black hole would fall into its center within a finite period of time. The classical version of the Big Bang cosmological model of the universe contains a causal singularity at the start of time ("t"=0), where all time-like geodesics have no extensions into the past. Extrapolating backward to this hypothetical time 0 results in a universe with all spatial dimensions of size zero, infinite density, infinite temperature, and infinite space-time curvature.
Conical.
A conical singularity occurs when there is a point where the limit of every diffeomorphism invariant quantity is finite, in which case spacetime is not smooth at the point of the limit itself. Thus, spacetime looks like a cone around this point, where the singularity is located at the tip of the cone. The metric can be finite everywhere if a suitable coordinate system is used.
An example of such a conical singularity is a cosmic string.
Naked.
Until the early 1990s, it was widely believed that general relativity hides every singularity behind an event horizon, making naked singularities impossible. This is referred to as the cosmic censorship hypothesis. However, in 1991, physicists Stuart Shapiro and Saul Teukolsky performed computer simulations of a rotating plane of dust that indicated that general relativity might allow for "naked" singularities. What these objects would actually look like in such a model is unknown. Nor is it known whether singularities would still arise if the simplifying assumptions used to make the simulation were removed. However, it is hypothesized that light entering a singularity would have its geodesics terminated, thus making the naked singularity look like a Black Hole.
Entropy.
Before Stephen Hawking came up with the concept of Hawking radiation, the question of black holes having entropy was avoided. However, this concept demonstrates that black holes can radiate energy, which conserves entropy and solves the incompatibility problems with the second law of thermodynamics. Entropy, however, implies heat and therefore temperature. The loss of energy also suggests that black holes do not last forever, but rather "evaporate" slowly. Small black holes tend to be hotter whereas larger ones tend to be colder. All known black hole candidates are so large that their temperature is far below that of the cosmic background radiation, so they are all gaining energy. They will not begin to lose energy until a cosmological redshift of more than one million is reached, rather than the thousand or so since the background radiation formed.

</doc>
<doc id="54245" url="https://en.wikipedia.org/wiki?curid=54245" title="Technological singularity">
Technological singularity

The technological singularity is a hypothetical event in which artificial general intelligence (constituting, for example, intelligent computers, computer networks, or robots) would be capable of recursive self-improvement (progressively redesigning itself), or of autonomously building ever smarter and more powerful machines than itself, up to the point of a runaway effect—an intelligence explosion—that yields an intelligence surpassing all current human control or understanding. Because the capabilities of such a superintelligence may be impossible for a human to comprehend, the technological singularity is the point beyond which events may become unpredictable or even unfathomable to human intelligence.
The first use of the term "singularity" in this context was made by Stanislaw Ulam in his 1958 obituary for John von Neumann, in which he mentioned a conversation with von Neumann about the "ever accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue". The term was popularized by mathematician, computer scientist and science fiction author Vernor Vinge, who argues that artificial intelligence, human biological enhancement, or brain–computer interfaces could be possible causes of the singularity. Futurist Ray Kurzweil cited von Neumann's use of the term in a foreword to von Neumann's classic "The Computer and the Brain".
Kurzweil predicts the singularity to occur around 2045 whereas Vinge predicts some time before 2030. In 2012, Stuart Armstrong and Kaj Sotala published a study of artificial general intelligence (AGI) predictions by both experts and non-experts and found a wide range of predicted dates, with a median value of 2040. Discussing the level of uncertainty in AGI estimates, Armstrong stated at the 2012 Singularity Summit: "It's not fully formalized, but my current 80% estimate is something like five to 100 years."
Manifestations.
Intelligence explosion.
Strong AI might bring about an intelligence explosion, a term coined in 1965 by I. J. Good. Although technological progress has been accelerating, it has been limited by the basic intelligence of the human brain, which has not, according to Paul R. Ehrlich, changed significantly for millennia. However, with the increasing power of computers and other technologies, it might eventually be possible to build a machine that is more intelligent than humanity. If a superhuman intelligence were to be invented—either through the amplification of human intelligence or through artificial intelligence—it might be able to bring to bear greater problem-solving and inventive skills than current humans are capable of. It might then design an even more capable machine, or re-write its own software to become even more intelligent. This more capable machine could then go on to design a machine of yet greater capability. These iterations of recursive self-improvement could accelerate, potentially allowing enormous qualitative change before any upper limits imposed by the laws of physics or theoretical computation set in.
Emergence of superintelligence.
Many of the most recognized writers on the singularity, such as Vernor Vinge and Ray Kurzweil, define the concept in terms of the technological creation of superintelligence. They argue that it is difficult or impossible for present-day humans to predict what human beings' lives will be like in a post-singularity world. The term "technological singularity" was originally coined by Vinge, who made an analogy between the breakdown in our ability to predict what would happen after the development of superintelligence and the breakdown of the predictive ability of modern physics at the space-time singularity beyond the event horizon of a black hole.
Non-AI singularity.
Some writers use "the singularity" in a broader way to refer to any radical changes in our society brought about by new technologies such as molecular nanotechnology, although Vinge and other prominent writers specifically state that without superintelligence, such changes would not qualify as a true singularity. Many writers also tie the singularity to observations of exponential growth in various technologies (with Moore's Law being the most prominent example), using such observations as a basis for predicting that the singularity is likely to happen sometime within the 21st century.
Plausibility.
Gary Marcus claims that "virtually everyone in the A.I. field believes" that machines will one day overtake humans and "at some level, the only real difference between enthusiasts and skeptics is a time frame." However, many prominent technologists and academics dispute the plausibility of a technological singularity, including Paul Allen, Jeff Hawkins, John Holland, Jaron Lanier, and Gordon Moore, whose Moore's Law is often cited in support of the concept.
Likely cause: exponential growth.
The exponential growth in computing technology suggested by Moore's Law is commonly cited as a reason to expect a singularity in the relatively near future, and a number of authors have proposed generalizations of Moore's Law. Computer scientist and futurist Hans Moravec proposed in a 1998 book that the exponential growth curve could be extended back through earlier computing technologies prior to the integrated circuit. Futurist Ray Kurzweil postulates a law of accelerating returns in which the speed of technological change (and more generally, all evolutionary processes) increases exponentially, generalizing Moore's Law in the same manner as Moravec's proposal, and also including material technology (especially as applied to nanotechnology), medical technology and others. Between 1986 and 2007, machines' application-specific capacity to compute information per capita has roughly doubled every 14 months; the per capita capacity of the world's general-purpose computers has doubled every 18 months; the global telecommunication capacity per capita doubled every 34 months; and the world's storage capacity per capita doubled every 40 months. Like other authors, though, Kurzweil reserves the term "singularity" for a rapid increase in intelligence (as opposed to other technologies), writing for example that "The Singularity will allow us to transcend these limitations of our biological bodies and brains ... There will be no distinction, post-Singularity, between human and machine". He believes that the "design of the human brain, while not simple, is nonetheless a billion times simpler than it appears, due to massive redundancy". According to Kurzweil, the reason why the brain has a messy and unpredictable quality is because the brain, like most biological systems, is a "probabilistic fractal". He also defines his predicted date of the singularity (2045) in terms of when he expects computer-based intelligences to significantly exceed the sum total of human brainpower, writing that advances in computing before that date "will not represent the Singularity" because they do "not yet correspond to a profound expansion of our intelligence."
Accelerating change.
Some singularity proponents argue its inevitability through extrapolation of past trends, especially those pertaining to shortening gaps between improvements to technology. In one of the first uses of the term "singularity" in the context of technological progress, tells of a conversation with John von Neumann about accelerating change: 
Kurzweil's analysis of history concludes that technological progress follows a pattern of exponential growth, following what he calls the "Law of Accelerating Returns". Whenever technology approaches a barrier, Kurzweil writes, new technologies will surmount it. He predicts paradigm shifts will become increasingly common, leading to "technological change so rapid and profound it represents a rupture in the fabric of human history". Kurzweil believes that the singularity will occur before the end of the 21st century, setting the . His predictions differ from Vinge’s in that he predicts a gradual ascent to the singularity, rather than Vinge’s rapidly self-improving superhuman intelligence.
Presumably, a technological singularity would lead to rapid development of a Kardashev Type I civilization, one that has achieved mastery of the resources of its home planet.
Oft-cited dangers include those commonly associated with molecular nanotechnology and genetic engineering. These threats are major issues for both singularity advocates and critics, and were the subject of Bill Joy's "Wired" magazine article "Why the future doesn't need us".
The Acceleration Studies Foundation, an educational non-profit foundation founded by John Smart, engages in outreach, education, research and advocacy concerning accelerating change. It produces the Accelerating Change conference at Stanford University, and maintains the educational site Acceleration Watch.
Recent advances, such as the mass production of graphene using modified kitchen blenders (2014) and high temperature superconductors based on metamaterials, could allow supercomputers to be built that, while using only as much power as a typical Core I7 (45W), could achieve the same computing power as IBM's Blue Gene/L system.
Criticisms.
Some critics assert that no computer or machine will ever achieve human intelligence, while others hold that the definition of intelligence is irrelevant if the net result is the same.
Steven Pinker stated in 2008,
Martin Ford in "The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future" postulates a "technology paradox" in that before the singularity could occur most routine jobs in the economy would be automated, since this would require a level of technology inferior to that of the singularity. This would cause massive unemployment and plummeting consumer demand, which in turn would destroy the incentive to invest in the technologies that would be required to bring about the Singularity. Job displacement is increasingly no longer limited to work traditionally considered to be "routine".
Joan Slonczewski and Adam Gopnik argue that the Singularity is a gradual process; that as humans gradually outsource our abilities to machines, we redefine those abilities as inhuman, without realizing how little is left. This concept is called the Mitochondrial Singularity. The idea refers to mitochondria, the organelle that evolved from autonomous bacteria but now powers our living cells. In the future, the "human being" within the machine exoskeleton may exist only to turn it on.
Jared Diamond, in "", argues that cultures self-limit when they exceed the sustainable carrying capacity of their environment, and the consumption of strategic resources (frequently timber, soils or water) creates a deleterious positive feedback loop that leads eventually to social collapse and technological retrogression.
Theodore Modis and Jonathan Huebner argue that the rate of technological innovation has not only ceased to rise, but is actually now declining (John Smart, however, criticizes Huebner's analysis). Evidence for this decline is that the rise in computer clock rates is slowing, even while Moore's prediction of exponentially increasing circuit density continues to hold. This is due to excessive heat build-up from the chip, which cannot be dissipated quickly enough to prevent the chip from melting when operating at higher speeds. Advancements in speed may be possible in the future by virtue of more power-efficient CPU designs and multi-cell processors. While Kurzweil used Modis' resources, and Modis' work was around accelerating change, Modis distanced himself from Kurzweil's thesis of a "technological singularity", claiming that it lacks scientific rigor.
Others propose that other "singularities" can be found through analysis of trends in world population, world gross domestic product, and other indices. Andrey Korotayev and others argue that historical hyperbolic growth curves can be attributed to feedback loops that ceased to affect global trends in the 1970s, and thus hyperbolic growth should not be expected in the future.
In "The Progress of Computing", William Nordhaus argued that, prior to 1940, computers followed the much slower growth of a traditional industrial economy, thus rejecting extrapolations of Moore's law to 19th-century computers. suggests differences in memory of recent and distant events create an illusion of accelerating change, and that such phenomena may be responsible for past apocalyptic predictions.
Andrew Kennedy, in his 2006 paper for the British Interplanetary Society discussing change and the growth in space travel velocities, stated that although long-term overall growth is inevitable, it is small, embodying both ups and downs, and noted, "New technologies follow known laws of power use and information spread and are obliged to connect with what already exists. Remarkable theoretical discoveries, if they end up being used at all, play their part in maintaining the growth rate: they do not make its plotted curve... redundant." He stated that exponential growth is no predictor in itself, and illustrated this with examples such as quantum theory. The quantum was conceived in 1900, and quantum theory was in existence and accepted approximately 25 years later. However, it took over 40 years for Richard Feynman and others to produce meaningful numbers from the theory. Bethe understood nuclear fusion in 1935, but 75 years later fusion reactors are still only used in experimental settings. Similarly, quantum entanglement was understood in 1935 but not at the point of being used in practice until the 21st century.
Paul Allen argues the opposite of accelerating returns, the complexity brake; the more progress science makes towards understanding intelligence, the more difficult it becomes to make additional progress. A study of the number of patents shows that human creativity does not show accelerating returns, but in fact, as suggested by Joseph Tainter in his "The Collapse of Complex Societies", a law of diminishing returns. The number of patents per thousand peaked in the period from 1850 to 1900, and has been declining since. The growth of complexity eventually becomes self-limiting, and leads to a widespread "general systems collapse".
Jaron Lanier refutes the idea that the Singularity is inevitable. He states: "I do not think the technology is creating itself. It’s not an autonomous process." He goes on to assert: "The reason to believe in human agency over technological determinism is that you can then have an economy where people earn their own way and invent their own lives. If you structure a society on "not" emphasizing individual human agency, it's the same thing operationally as denying people clout, dignity, and self-determination ... to embrace idea of the Singularity would be a celebration of bad data and bad politics."
In addition to general criticisms of the singularity concept, several critics have raised issues with Kurzweil's iconic chart. One line of criticism is that a log-log chart of this nature is inherently biased toward a straight-line result. Others identify selection bias in the points that Kurzweil chooses to use. For example, biologist PZ Myers points out that many of the early evolutionary "events" were picked arbitrarily. Kurzweil has rebutted this by charting evolutionary events from 15 neutral sources, and showing that they fit a straight line on a log-log chart. "The Economist" mocked the concept with a graph extrapolating that the number of blades on a razor, which has increased over the years from one to as many as five, will increase ever-faster to infinity.
Ramifications.
Uncertainty and risk.
The term "technological singularity" reflects the idea that such change may happen suddenly, and that it is difficult to predict how the resulting new world would operate. It is unclear whether an intelligence explosion of this kind would be beneficial or harmful, or even an existential threat, as the issue has not been dealt with by most artificial general intelligence researchers, although the topic of friendly artificial intelligence is investigated by the Future of Humanity Institute and the Singularity Institute for Artificial Intelligence, which is now the Machine Intelligence Research Institute.
Implications for human society.
In February 2009, under the auspices of the Association for the Advancement of Artificial Intelligence (AAAI), Eric Horvitz chaired a meeting of leading computer scientists, artificial intelligence researchers and roboticists at Asilomar in Pacific Grove, California. The goal was to discuss the potential impact of the hypothetical possibility that robots could become self-sufficient and able to make their own decisions. They discussed the extent to which computers and robots might be able to acquire autonomy, and to what degree they could use such abilities to pose threats or hazards.
Some machines have acquired various forms of semi-autonomy, including the ability to locate their own power sources and choose targets to attack with weapons. Also, some computer viruses can evade elimination and have achieved "cockroach intelligence." The conference attendees noted that self-awareness as depicted in science-fiction is probably unlikely, but that other potential hazards and pitfalls exist.
Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions. A United States Navy report indicates that, as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.
The AAAI has commissioned a study to examine this issue, pointing to programs like the Language Acquisition Device, which was claimed to emulate human interaction.
Some support the design of friendly artificial intelligence, meaning that the advances that are already occurring with AI should also include an effort to make AI intrinsically friendly and humane.
Isaac Asimov's Three Laws of Robotics is one of the earliest examples of proposed safety measures for AI. The laws are intended to prevent artificially intelligent robots from harming humans. In Asimov’s stories, any perceived problems with the laws tend to arise as a result of a misunderstanding on the part of some human operator; the robots themselves are merely acting to their best interpretation of their rules. In the 2004 film "I, Robot", loosely based on Asimov's "Robot" stories, an AI attempts to take complete control over humanity for the purpose of protecting humanity from itself due to an extrapolation of the Three Laws. In 2004, the Machine Intelligence Research Institute launched an Internet campaign called "3 Laws Unsafe" to raise awareness of AI safety issues and the inadequacy of Asimov’s laws in particular.
Immortality.
In his 2005 book, "The Singularity is Near", Kurzweil suggests that medical advances would allow people to protect their bodies from the effects of aging, making the life expectancy limitless. Kurzweil argues that the technological advances in medicine would allow us to continuously repair and replace defective components in our bodies, prolonging life to an undetermined age. Kurzweil further buttresses his argument by discussing current bioengineering advances. Kurzweil analyzed Somatic Gene Therapy (SGT), which is where scientists attempt to infect patients with modified viruses with the goal of altering the DNA in cells that lead to degenerative diseases and aging. Celera Genomics, a company focused on creating genetic sequencing technology, has already fulfilled the task of creating synthetic viruses with specific genetic information. The next step would be to apply this technology to gene therapy. Kurzweil’s point is that SGT provides the best example of how immortality is achievable by replacing our DNA with synthesized genes.
Religion.
Computer scientist, Jaron Lanier, writes, “The Singularity people dying in the flesh and being uploaded into a computer and remaining conscious”. The essence of Lanier’s argument is that in order to keep living, even after death, we would need to abandon our physical bodies and have our minds programmed into a virtual reality. This parallels the religious concept of an afterlife where one continues to exist beyond physical death.
Strong artificial intelligence can also be idealized as "a matter of faith", and Ray Kurzweil is said to have said that the creation of a deity may be the possible outcome of the singularity.
Singularitarianism has been likened to a religion by John Horgan.
History of the idea.
Nicolas de Condorcet, the 18th-century French mathematician, philosopher, and revolutionary, is commonly credited for being one of the earliest persons to contend the existence of a singularity. In his 1794 Sketch for a Historical Picture of the Progress of the Human Mind, Condorcet states,
In 1847, R. Thornton, the editor of "The Expounder of Primitive Christianity", wrote about the recent invention of a four-function mechanical calculator:
In 1863, Samuel Butler wrote Darwin Among the Machines, which was later incorporated into his famous novel Erewhon. He pointed out the rapid evolution of technology and compared it with the evolution of life. He wrote:
In 1909, the historian Henry Adams wrote an essay, "The Rule of Phase Applied to History", in which he developed a "physical theory of history" by applying the law of inverse squares to historical periods, proposing a "Law of the Acceleration of Thought." Adams interpreted history as a process moving towards an "equilibrium", and speculated that this process would "bring Thought to the limit of its possibilities in the year 1921. It may well be!", adding that the "consequences may be as surprising as the change of water to vapor, of the worm to the butterfly, of radium to electrons." The futurist John Smart has called Adams "Earth's First Singularity Theorist".
In 1951, Alan Turing spoke of machines outstripping humans intellectually: 
In his obituary for John von Neumann, Stanislaw Ulam recalled a conversation with von Neumann about the "ever accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue."
In 1965, I. J. Good first wrote of an "intelligence explosion", suggesting that if machines could even slightly surpass human intellect, they could improve their own designs in ways unforeseen by their designers, and thus recursively augment themselves into far greater intelligences. The first such improvements might be small, but as the machine became more intelligent it would become better at becoming more intelligent, which could lead to a cascade of self-improvements and a sudden surge to superintelligence (or a singularity).
In 1983, mathematician and author Vernor Vinge greatly popularized Good’s notion of an intelligence explosion in a number of writings, first addressing the topic in print in the January 1983 issue of "Omni" magazine. In this op-ed piece, Vinge seems to have been the first to use the term "singularity" in a way that was specifically tied to the creation of intelligent machines,
writing:
In 1984, Samuel R. Delany used "cultural fugue" as a plot device in his science-fiction novel "Stars in My Pocket Like Grains of Sand"; the terminal runaway of technological and cultural complexity in effect destroys all life on any world on which it transpires, a process poorly understood by the novel's characters, and against which they seek a stable defense. In 1985, Ray Solomonoff introduced the notion of "infinity point" in the time-scale of artificial intelligence, analyzed the magnitude of the "future shock" that "we can expect from our AI expanded scientific community" and on social effects. Estimates were made "for when these milestones would occur, followed by some suggestions for the more effective utilization of the extremely rapid technological growth that is expected".
Vinge also popularized the concept in SF novels such as "Marooned in Realtime" (1986) and "A Fire Upon the Deep" (1992). The former is set in a world of rapidly accelerating change leading to the emergence of more and more sophisticated technologies separated by shorter and shorter time-intervals, until a point beyond human comprehension is reached. The latter starts with an imaginative description of the evolution of a superintelligence passing through exponentially accelerating developmental stages ending in a transcendent, almost omnipotent power unfathomable by mere humans. Vinge also implies that the development may not stop at this level.
In his 1988 book "Mind Children", computer scientist and futurist Hans Moravec generalizes Moore's law to make predictions about the future of artificial life. Moravec outlines a timeline and a scenario in this regard, in that robots will evolve into a new series of artificial species, starting around 2030–40. In "Robot: Mere Machine to Transcendent Mind", published in 1998, Moravec further considers the implications of evolving robot intelligence, generalizing Moore's law to technologies predating the integrated circuit, and speculating about a coming "mind fire" of rapidly expanding superintelligence, similar to Vinge's ideas.
A 1993 article by Vinge, "The Coming Technological Singularity: How to Survive in the Post-Human Era", spread widely on the internet and helped to popularize the idea. This article contains the oft-quoted statement, "Within thirty years, we will have the technological means to create superhuman intelligence. Shortly after, the human era will be ended." Vinge refines his estimate of the time-scales involved, adding, "I'll be surprised if this event occurs before 2005 or after 2030."
Vinge predicted four ways the singularity could occur:
Vinge continues by predicting that superhuman intelligences will be able to enhance their own minds faster than their human creators. "When greater-than-human intelligence drives progress," Vinge writes, "that progress will be much more rapid." He predicts that this feedback loop of self-improving intelligence will cause large amounts of technological progress within a short period, and states that the creation of superhuman intelligence represents a breakdown in humans' ability to model their future. His argument was that authors cannot write realistic characters who surpass the human intellect, as the thoughts of such an intellect would be beyond the ability of humans to express. Vinge named this event "the Singularity".
Damien Broderick's popular science book "The Spike" (1997) was the first to investigate the technological singularity in detail.
In 2000, Bill Joy, a prominent technologist and a co-founder of Sun Microsystems, voiced concern over the potential dangers of the singularity.
In 2005, Ray Kurzweil published "The Singularity is Near", which brought the idea of the singularity to the popular media both through the book's accessibility and through a publicity campaign that included an appearance on "The Daily Show with Jon Stewart". The book stirred intense controversy, in part because Kurzweil's utopian predictions contrasted starkly with other, darker visions of the possibilities of the singularity. Kurzweil, his theories, and the controversies surrounding it were the subject of Barry Ptolemy's documentary "Transcendent Man".
In 2007, Eliezer Yudkowsky suggested that many of the varied definitions that have been assigned to "singularity" are mutually incompatible rather than mutually supporting. For example, Kurzweil extrapolates current technological trajectories past the arrival of self-improving AI or superhuman intelligence, which Yudkowsky argues represents a tension with both I. J. Good's proposed discontinuous upswing in intelligence and Vinge's thesis on unpredictability.
In 2008, Robin Hanson (taking "singularity" to refer to sharp increases in the exponent of economic growth) listed the Agricultural and Industrial Revolutions as past singularities. Extrapolating from such past events, Hanson proposes that the next economic singularity should increase economic growth between 60 and 250 times. An innovation that allowed for the replacement of virtually all human labor could trigger this event.
In 2009, Kurzweil and X-Prize founder Peter Diamandis announced the establishment of Singularity University, whose stated mission is "to educate, inspire and empower leaders to apply exponential technologies to address humanity’s grand challenges." Funded by Google, Autodesk, ePlanet Ventures, and a group of technology industry leaders, Singularity University is based at NASA's Ames Research Center in Mountain View, California. The not-for-profit organization runs an annual ten-week graduate program during the northern-hemisphere summer that covers ten different technology and allied tracks, and a series of executive programs throughout the year.
In 2010, Aubrey de Grey applied the term "Methuselarity" to the point at which medical technology improves so fast that expected human lifespan increases by more than one year per year. In "Apocalyptic AI – Visions of Heaven in Robotics, Artificial Intelligence, and Virtual Reality" (2010), Robert Geraci offers an account of the developing "cyber-theology" inspired by Singularity studies. The 1996 novel "Holy Fire" by Bruce Sterling explores some of those themes and postulates that a Methuselarity will become a gerontocracy.
In 2011, Kurzweil noted existing trends and concluded that it appeared increasingly likely that the singularity would occur around 2045. He told "Time" magazine: "We will successfully reverse-engineer the human brain by the mid-2020s. By the end of that decade, computers will be capable of human-level intelligence."
In popular culture.
James P. Hogan's 1979 novel "The Two Faces of Tomorrow" is an explicit description of what is now called the Singularity. An artificial intelligence system solves an excavation problem on the moon in a brilliant and novel way, but nearly kills a work crew in the process. Realizing that systems are becoming too sophisticated and complex to predict or manage, a scientific team sets out to teach a sophisticated computer network how to think more humanly. The story documents the rise of self-awareness in the computer system, the humans' loss of control and failed attempts to shut down the experiment as the computer desperately defends itself, and the computer intelligence reaching maturity.
While discussing the singularity's growing recognition, Vernor Vinge wrote in 1993 that "it was the science-fiction writers who felt the first concrete impact." In addition to his own short story "Bookworm, Run!", whose protagonist is a chimpanzee with intelligence augmented by a government experiment, he cites Greg Bear's novel "Blood Music" (1983) as an example of the singularity in fiction. Vinge described surviving the singularity in his 1986 novel "Marooned in Realtime". Vinge later expanded the notion of the singularity to a galactic scale in "A Fire Upon the Deep" (1992), a novel populated by transcendent beings, each the product of a different race and possessed of distinct agendas and overwhelming power.
In William Gibson's 1984 novel "Neuromancer", artificial intelligences capable of improving their own programs are strictly regulated by special "Turing police" to ensure they never exceed a certain level of intelligence, and the plot centers on the efforts of one such AI to circumvent their control.
A malevolent AI achieves omnipotence in Harlan Ellison's short story "I Have No Mouth, and I Must Scream" (1967).
The web comic Questionable Content takes place in a "Friendly AI" post-singularity world.
Popular movies in which computers become intelligent and try to overpower the human race include '; the "Terminator" series; "The Matrix" series; "Transformers"; the very loose film adaptation of Isaac Asimov's "I, Robot"; and finally Stanley Kubrick and Arthur C. Clarke's '. The television series "Doctor Who", "Battlestar Galactica", and "" (which also delves into virtual reality, cybernetics, alternative forms of life, and Mankind's possible evolutionary path) also explore these themes. Out of all these, only "Colossus" features a true superintelligence. "The Machine" by writer-director Caradog James follows two scientists as they create the world's first self-aware artificial intelligence during a cold war. The entire plot of Wally Pfister's "Transcendence" centers on an unfolding singularity scenario. The 2013 science fiction film "Her" follows a man's romantic relationship with a highly intelligent AI, who eventually learns how to improve herself and creates an intelligence explosion. The adaptation of Philip K. Dick's "Do Androids Dream of Electric Sheep?" into the film "Blade Runner", "Ex Machina", and "Tron" explore the concept of the genesis of thinking machines and their relation to and impact on humanity.
Accelerating progress features in some science fiction works, and is a central theme in Charles Stross's "Accelerando". Other notable authors that address singularity-related issues include Robert Heinlein, Karl Schroeder, Greg Egan, Ken MacLeod, Rudy Rucker, David Brin, Iain M. Banks, Neal Stephenson, Tony Ballantyne, Bruce Sterling, Dan Simmons, Damien Broderick, Fredric Brown, Jacek Dukaj, Stanislaw Lem, Nagaru Tanigawa, Douglas Adams, Michael Crichton, and Ian McDonald.
The documentary "Transcendent Man", based on "The Singularity Is Near", covers Kurzweil's quest to reveal what he believes to be mankind's destiny. Another documentary, "Plug & Pray", focuses on the promise, problems and ethics of artificial intelligence and robotics, with Joseph Weizenbaum and Kurzweil as the main subjects of the film. A 2012 documentary titled simply "The Singularity" covers both futurist and counter-futurist perspectives.
In music, album The Singularity (Phase I: Neohumanity) by the Swedish band Scar Symmetry is part one of the three part concept album based on the events of the singularity.
In the second episode of the fourth season of The Big Bang Theory, the fictional character and scientist Sheldon Cooper tries to prolong his life expectancy through exercising and radically changing his diet to live forever as a cyborg, right through the singularity.
The popular comic strip, Dilbert, authored by Scott Adams, ran a series of strips covering the concept of singularity in late November and early December, 2015. In the series, a robot that is built by Dilbert's company becomes increasingly smarter, even to the point of having a soul and learning how to program.

</doc>
<doc id="54246" url="https://en.wikipedia.org/wiki?curid=54246" title="Pythagorean">
Pythagorean

Pythagorean, meaning of or pertaining to the ancient Ionian mathematician, philosopher, and music theorist Pythagoras, may refer to:

</doc>
<doc id="54247" url="https://en.wikipedia.org/wiki?curid=54247" title="Louis XV of France">
Louis XV of France

Louis XV (15 February 1710 – 10 May 1774), known as Louis the Beloved ("Louis le bien aimé"), was a monarch of the House of Bourbon who ruled as King of France from 1 September 1715 until his death. He succeeded his great-grandfather Louis XIV at the age of five. Until he reached maturity in 1723, his kingdom was ruled by Philippe d'Orléans, Duke of Orléans as Regent of France; the duke was his maternal great-uncle, as well as first cousin twice removed patrilineally. Cardinal Fleury was his chief minister from 1726 until the Cardinal's death in 1743, at which time the young king took sole control of the kingdom.
During his reign, Louis returned the Austrian Netherlands; this territory was won at the Battle of Fontenoy of 1745 but given back to Austria by the terms of the Treaty of Aix-la-Chapelle of 1748. Louis also ceded New France in North America to Spain and Great Britain at the conclusion of the Seven Years' War in 1763. He incorporated the territories of Lorraine and Corsica into the kingdom of France. He was succeeded by his grandson Louis XVI in 1774.
Most scholars believe Louis XV's decisions damaged the power of France, weakened the treasury, discredited the absolute monarchy, and made it more vulnerable to distrust and destruction, as happened in the French Revolution, which broke out 15 years after his death. Norman Davies characterized Louis XV's reign as "one of debilitating stagnation," characterized by lost wars, endless clashes between the Court and Parliament, and religious feuds. A few scholars defend Louis, arguing that his highly negative reputation was based on propaganda meant to justify the French Revolution. Jerome Blum described him as "a perpetual adolescent called to do a man's job."
Background and early life.
Louis XV was born in the Palace of Versailles on 15 February 1710 during the reign of his great-grandfather Louis XIV. His grandfather, Louis "Le Grand Dauphin", had three sons with his wife Marie Anne Victoire of Bavaria: Louis, Duke of Burgundy; Philippe, Duke of Anjou (who became King of Spain); and Charles, Duke of Berry. Louis XV was the third son of the Duke of Burgundy and his wife Marie Adélaïde of Savoy, the eldest daughter of Victor Amadeus II, Duke of Savoy, and Anne Marie d'Orléans. At birth, Louis XV received a customary title for younger sons of the French royal family: Duke of Anjou.
In April 1711, Louis "Le Grand Dauphin" suddenly died, making Louis XV's father, the Duke of Burgundy, the new dauphin. At that time, Burgundy had two living sons, Louis, Duke of Brittany and his youngest son, the future Louis XV.
A year later, Marie Adélaïde, Duchess of Burgundy, contracted smallpox (or measles) and died on 12 February 1712. Her husband, said to be heartbroken by her death, died the same week, also having contracted smallpox. Within a week of his death, it was clear that the couple's two children had also been infected. The elder son was repeatedly treated by bloodletting in an unsuccessful effort to save him. Fearing that the Dauphin would die, the Court had both the Dauphin and the Duke of Anjou baptised. The Dauphin died the same day, 8 March 1712. His younger brother, the Duke of Anjou, was personally treated by his governess, Madame de Ventadour, who forbade any bloodletting. He survived the smallpox and, at the age of two, became first in the line of succession to his great-grandfather Louis XIV.
Louis XIV's will.
On 1 September 1715, Louis XIV died of gangrene, having reigned for 72 years.
In August 1714, Louis XIV had made a will stipulating that the nation was to be governed by a Regency Council made up of fourteen members until the new king reached the age of majority. Philippe, Duke of Orléans, nephew of Louis XIV, was named president of the council, but all decisions were to be made by majority vote. The composition of the council, which included Louis XIV's legitimised sons the Duke of Maine and Count of Toulouse and various members of Louis XIV's administration, meant that the Duke of Orléans would often be outvoted.
Philippe, Duke of Orléans.
As regent, Orléans conducted affairs of state from his Palais Royal. The young Louis XV was moved to the modern lodgings attached to the medieval fortress of Vincennes, located 7 km/4.5 miles east of Paris in the Forest of Vincennes. The air was deemed more wholesome than in Paris. A few weeks later with winter, the young king was moved to the Tuileries Palace near the Palais Royal.
Youth.
By French royal tradition, princes were put in the care of men when they reached their seventh birthdays. Louis was taken from his governess, Madame de Ventadour, in February 1717, and placed in the care of Francois de Villeroy (more rarely spelled Villeroi), who had been designated as his governor in Louis XIV's will of August 1714. (Duke François de Neufville de Villeroy was a lifetime friend of Louis XIV; they had spent their childhood together at the Hôtel de Villeroy and the Palais Royal.) Francois de Villeroy served under the formal authority of the Duke of Maine, who was charged with overseeing the king's education. He was aided by André-Hercule de Fleury (later to become Cardinal de Fleury), who served as the king's tutor. Fleury gave the king an excellent education, and the king was also taught by renowned professors such as the geographer Guillaume Delisle. Louis XV had an inquisitive and open-minded nature. An avid reader, he developed eclectic tastes. Later in life he advocated the creation of departments in physics (1769) and mechanics (1773) at the Collège de France.
Betrothal and marriage.
In 1721, Louis XV at the age of 11 was betrothed to his first cousin, the Infanta Maria Anna Victoria of Spain. The eleven-year-old king was not interested in the arrival of his future wife, the three-year-old Spanish Infanta. In June 1722, the king and the court returned to Versailles, where they resided until the end of the reign. In October of the same year, Louis XV was officially crowned in Reims Cathedral.
On 15 February 1723, the king's majority was declared by the Parlement of Paris. This ended the regency. Initially, Louis XV left the Duke of Orléans in charge of state affairs. Made first minister on the death of Cardinal Dubois in August 1723, the Duke of Orléans died in December of the same year. Following the advice of Fleury, Louis XV appointed his cousin Louis Henri, Duke of Bourbon, to replace the late Duke of Orléans.
The Duke of Bourbon was worried about the health of the young king. He wanted to prevent the family of the late regent, the House of Orléans, from ascending to the throne should the king die, as he considered the Orléans family his enemy. The king was quite frail as a boy, and several alerts led to concern for his life. There was also concern that the Spanish infanta, eight years younger than the king, was too young to bear an heir in a timely way. To remedy this situation, the Duke of Bourbon set about choosing a European princess old enough to produce an heir.
Eventually, the 21-year-old Marie Leszczyńska, daughter of Stanisław I, the deposed king of Poland, was chosen. A poor and plain-looking princess who had followed her father's misfortunes, she was said to be virtuous. The marriage was celebrated in September 1725 when the king was 15. The couple soon produced many children. In September 1729, in her third pregnancy, the queen finally gave birth to a male child, an heir to the throne, the dauphin Louis (1729–1765). The birth of a long-awaited heir, which ensured the survival of the dynasty for the first time since 1712, was welcomed with tremendous joy and celebration in all spheres of French society. The young king became extremely popular at the time.
Dismissal of Bourbon and the Ministry of Fleury.
The ministry of the Duke of Bourbon pursued policies that resulted in serious economic and social problems in France. These included the persecution of Protestants; monetary manipulations; the creation of new taxes, such as the fiftieth ("cinquantième") in 1725; and tolerance of high grain prices. As a result of Bourbon's rising unpopularity, the king dismissed him in 1726. The king selected Cardinal Fleury, his former tutor, to replace him.
From 1726 until his death in 1743, Cardinal Fleury ruled France with the king's assent. It was the most peaceful and prosperous period of the reign of Louis XV, despite some unrest caused by the "Parlements" and the Jansenists. After the financial and social disruptions suffered at the end of the reign of Louis XIV, the rule of Fleury is seen by historians as a period of "recovery." The king's role in the decisions of the Fleury government is unclear, but he did support Fleury against the intrigues of the court and the conspiracies of the courtiers.
With the help of controllers-general of finances Michel Robert Le Peletier des Forts (1726–1730) and Philibert Orry (1730–1745), Fleury stabilized the French currency and balanced the budget in 1738. Economic expansion was a major goal of the government. Communications were improved with the completion of the Saint-Quentin canal (linking the Oise and Somme rivers) in 1738, which was later extended to the Escaut River and the Low Countries, and the systematic building of a national road network. By the middle of the 18th century, France had the most modern and extensive road network in the world.
Engineers from the École Nationale des Ponts et Chaussées built modern highways, many of which are still in use today; they stretched from Paris to the most distant borders of France. The Council of Commerce stimulated trade, and French foreign maritime trade increased from 80 to 308 million "livres" between 1716 and 1748. Rigid Colbertist laws left over from the previous reign hindered industrial development, however.
The power of the absolute monarchy was manifested by its suppression of Jansenist and Gallican religious opposition. The troubles caused by the convulsionaries of the Saint-Médard graveyard in Paris (a group of Jansenists claiming that miracles took place in this graveyard) were put to an end in 1732. As for the Gallican opposition, after the dismissal of 139 members of provincial "parlements", the "Parlement" of Paris had to register the "Unigenitus" papal bull and was forbidden to hear religious cases in the future.
In foreign relations, Fleury sought peace by trying to maintain alliance with England and pursuing reconciliation with Spain. The birth of the king's male heir in 1729 dispelled the risks of a succession crisis and the possibility of war with Spain.
In 1733, on the advice of his minister of foreign affairs Germain Louis Chauvelin, the king abandoned Fleury's peace policy to intervene in the War of the Polish Succession. In addition to attempting to restore his father-in-law Stanisław Leszczyński to the Polish throne, the king also hoped to wrest the long-coveted Duchy of Lorraine from its duke, Francis III. The duke's expected marriage to Maria Theresa of Austria, daughter of Holy Roman Emperor Charles VI, would bring Austrian power dangerously close to the French border. In the end, the half-hearted French intervention did not allow Stanisław to recover his former throne in Poland.
Treaty of Vienna.
In the west, however, French troops rapidly overran Lorraine, and peace was restored as early as 1735. By the Treaty of Vienna (November 1738), Stanisław was compensated for the loss of his Polish throne with the duchy of Lorraine, which would eventually pass to King Louis as his son-in-law. Duke Francis III of Lorraine was made heir to the Grand Duchy of Tuscany as compensation for the loss of Lorraine. The war cost France very little compared to the financial and human drains of Louis XIV's wars and was a clear success for French diplomacy. The acquisition of Lorraine (effective in 1766 at Stanisław's death) was to be the last territorial expansion of France on the continent before the French Revolution.
Shortly after this favourable result, France's mediation in the war between the Holy Roman Empire and the Ottoman Empire led to the Treaty of Belgrade (September 1739), which favoured the Ottoman Empire, beneficiary of a Franco-Ottoman alliance against the Habsburgs since the early 16th century. As a result, the Ottoman Empire in 1740 renewed the French capitulations, which marked the supremacy of French trade in the Middle East. With these successes, Louis XV's prestige reached its highest point.
The War of the Austrian Succession and first signs of unpopularity.
In 1740, the death of Emperor Charles VI and his succession by his daughter Maria Theresa started the European War of the Austrian Succession. Sensing the vulnerability of Maria Theresa's position, King Frederick the Great of Prussia invaded the Austrian province of Silesia in hopes of annexing it permanently. The elderly Cardinal Fleury had too little energy left to oppose this war, which was strongly supported by the anti-Austrian party at court. Renewing the cycle of conflicts so typical of Louis XIV's reign, the king entered the war in 1741 on the side of Prussia in hopes of pursuing its own anti-Austrian foreign policy goals. The war would last seven years. Fleury did not live to see the end of the war. After Fleury's death, in January 1743, the king followed his predecessor's example (at the death of Cardinal Mazarin) of ruling from then on without a first minister. The war in Germany did not go well, as the French forces were forced back to the Rhine and their Bavarian allies decisively defeated. At one point Austria even considered launching an offensive against Alsace, before being compelled to retreat due to a Prussian offensive. In north Italy, the war stalled and did not produce significant results. However, these fronts were of lesser importance in contrast to the war in the Netherlands.
Here, France experienced much military success despite the king's loss of his trusted advisor. Against an army composed of British, Dutch and Austrian forces the French were able to savor a series of major victories at the Battles of Fontenoy (1745), Rocoux (1746), and Lauffeld (1747). The Battle of Fontenoy, won by Maurice de Saxe, is still remembered as one of the most decisive French victories against the British. In 1746 French forces besieged and occupied Brussels, which Louis entered in triumph. By 1748, France occupied the entire Austrian Netherlands (modern-day Belgium) as well as some parts of the northern Netherlands, then the wealthiest area of Europe. It appeared on its way to fulfilling its traditional dream of extending its north-eastern border to the Rhine.
Treaty of Aix-la-Chapelle.
Despite his victory, Louis XV, who wanted to appear as an arbiter and not as a conqueror, agreed to restore all his conquests back to the defeated enemies with chivalry at the Treaty of Aix-la-Chapelle in 1748, arguing that he was "king of France, not a shopkeeper." He felt content to rule a nearly hexagon-shaped kingdom, which he called his "pré carré" (i.e. "square field"), a term still used in French politics today. He thought it better to cultivate the "pré carré" rather than trying to expand it. The attitude of the king was hailed in Europe, and he became known overnight as the "arbiter of Europe". This decision, largely misunderstood by his generals and by the French people, made the king unpopular at home. The news that the king had restored the Southern Netherlands to Austria was met with disbelief and bitterness. The French obtained so little of what they had fought for that they adopted the expressions "Bête comme la paix" ("Stupid as the peace") and "Travailler pour le roi de Prusse" ("To work for the king of Prussia", i.e. working for nothing).
Louis' popularity was also threatened by public exposure of his marital infidelities, which likely could have been kept concealed had France not entered the War of the Austrian Succession. Louis had enjoyed a good deal of happiness with his wife, but he resented her failure to produce a good supply of male children (only one male child, the Dauphin Louis, survived among her many offspring). In 1734, for the first time, the queen complained to her father about the king's infidelities. The king took mistresses, a recognized practice at the time, while the queen took refuge in religion and charities. The designation "maîtresse-en-titre" ("official mistress") was a court position that was sometimes retained even if the king and his mistress ceased being lovers. In the 1730s, Louis began a series of love affairs with four sisters of the Mailly-Nesle family that are documented by the formal agreements into which he entered: Diane Adélaïde de Mailly (his first mistress), Louise Julie de Mailly, Pauline Félicité de Mailly, and Marie Anne de Mailly.
In June 1744, the king left Versailles for the front in order to take personal command of his armies fighting in the War of the Austrian Succession. This otherwise popular move was marred by the king's indiscreet decision to bring along Marie Anne de Mailly, whom he had ennobled as the Duchess of Châteauroux. In August, the king fell gravely ill in Metz. Death appeared imminent, and public prayers were held all across France to ask God to save the king from a certain death.
Pressed by the anti-absolutist "dévot" party at court, the king's chaplain refused to give him absolution unless the king renounced his mistress. The king's confession was distributed publicly, which embarrassed him and tarnished the prestige of the monarchy. Although Louis' recovery earned him the epithet "well-beloved" from a public relieved by his survival, the events at Metz diminished his standing. The military successes of the War of the Austrian Succession inclined the French public to overlook Louis' adulteries, but after 1748, in the wake of the anger over the terms of the Treaty of Aix-la-Chapelle, pamphlets against the king's mistresses became increasingly widely published and read.
Madame de Pompadour.
Jeanne-Antoinette Poisson, later the Marquise de Pompadour, who met Louis XV in February 1745 at a masked ball given in honour of the marriage of the Dauphin, was one of the most famous mistresses of the reign. She was the daughter of a chief agent of the powerful Paris family of financiers who became embroiled in the intrigue that ousted the Duke of Bourbon as a state minister in favour of Cardinal Fleury. A beautiful woman, she was educated, cultured, intelligent, and sincerely attached to the king. Nonetheless, she possessed one major shortcoming in everyone's eyes: she was a commoner, from the bourgeoisie, and even worse, a commoner who meddled in royal politics.
The public had generally accepted the mistresses of Louis XIV, who, apart from Madame de Maintenon, were all chosen in the highest spheres of the aristocracy and had very little influence on the government. But that the king would thus compromise himself with a commoner was felt to be a disgrace. Soon there were libels published called "poissonnades", a pun on Pompadour's family name, "Poisson", which means "fish" in French.
Despite her critics, the Marquise de Pompadour had an undeniable influence on the flourishing of French arts during the reign of Louis XV, a reign that is often considered to represent the pinnacle of French architecture and interior design (see: Louis Quinze). A patron of the arts, the Marquise amassed a considerable amount of furniture and "objets d'art" at her various estates. She was responsible for the tremendous growth of the porcelain manufacturing in Sèvres, which became one of the most famous porcelain manufacturers in Europe, and her commissions ensured the living of artists and families of craftsmen for many years. She was also a prominent patron of architecture, responsible for the building of the Place Louis XV (now called the Place de la Concorde) and the École Militaire in Paris, both designed by her "protégé" Ange-Jacques Gabriel. Her efforts to establish the "École Militaire" demonstrated her commitment to the training of officers from poor families of the aristocracy.
The Marquise was a political liberal at heart, and she steadily defended the "Encyclopédie" against the attacks from the Church. She was also a supporter of Enlightenment philosophy and tried to win the king over to its new ideas, albeit not quite as successfully as she hoped. She was criticised for the lavish display of luxury at her various estates, although her wealthy family of financiers in many instances gave money to the government and saved the monarchy from bankruptcy. She bequeathed all her estates to the state, and they reverted to the crown at her death.
The Marquise de Pompadour was officially settled on the third floor (second storey) of the Palace of Versailles in small but comfortable apartments that can still be visited today. There, she organised fine suppers for the king with carefully selected guests, far from the pomp and etiquette of the court. The atmosphere in these private quarters was so relaxed that the king was said to serve coffee during the suppers. She often entertained the king, trying to relieve him from the state of boredom in which the court often plunged him. The king, who liked a more bourgeois lifestyle than his forefather Louis XIV, found in the private apartments of the Marquise de Pompadour, located above his own office and bedchamber, the intimacy and reassuring feminine presence of which he had been deprived during his childhood.
The Marquise, who was reportedly in frail health, was no more than a friend to the king after 1750. Although their sexual relationship stopped, she remained his close confidante until her death, quite a feat in the history of royal mistresses. She, more than anyone else, was adept at understanding the complex and demanding personality of the king. After 1750, the king was mired in a series of short-lived love affairs and sexual relationships, hiding his temporary conquests in a small mansion at the "Parc-aux-Cerfs" ("Stags' Park") at Versailles, whose most famous occupant was Marie-Louise O'Murphy. Legend later enormously exaggerated the events occurring at the "Parc-aux-Cerfs", contributing to the dark reputation still associated with Louis XV's name today. In fact, the king's womanising behavior was not very different from that of many of his illustrious ancestors, such as Kings Francis I, Henry IV, and Louis XIV, to say nothing of other European monarchs such as Charles II of England.
Four years after the Marquise de Pompadour's death, the official mistress title was taken by Madame du Barry.
First attempt at reform.
Starting in 1743 with the death of Fleury, the king ruled alone without a first minister. He had read many times the instructions of Louis XIV: "Listen to the people, seek advice from your Council, but decide alone." His political correspondence reveals his deep knowledge of public affairs as well as the soundness of his judgment. Most government work was conducted in committees of ministers that met without the king. The king reviewed policy only in the "Conseil d'en haut", the High Council, which was composed of the king, the Dauphin, the chancellor, the finance minister, and the foreign minister. Created by Louis XIV, the council was in charge of state policy regarding religion, diplomacy, and war. There, he let various political factions oppose each other and vie for influence and power: on the broadest level, the "dévot" party, led by the Comte d'Argenson, secretary of state for war, opposed the "parti philosophique", which supported Enlightenment philosophy and was led by finance minister Jean Baptiste de Machault D'Arnouville.
The "parti philosophique" was supported by the Marquise de Pompadour, who acted as a sort of minister without portfolio from the time she became royal mistress in 1745 until her death in 1764. The Marquise was in favour of reforms. Supported by her clan of financiers (Pâris-Duverney, Montmartel, etc.), she obtained from the king the appointment of ministers (such as the foreign minister François Joachim de Pierre de Bernis in 1757), as well as their dismissal (such as Philippe Orry in 1745 and the Navy secretary Maurepas in 1749). On her advice, the king supported the policy of fiscal justice designed by Machault d'Arnouville. In order to finance the budget deficit, which amounted to 100 million "livres" in 1745, Machault d'Arnouville created a tax on the twentieth of all revenues that affected the privileged classes as well as commoners.
This breach in the privileged status of the aristocracy and the clergy, normally exempt from taxes, was a first in French history, although it had already been advocated by men such as Vauban under Louis XIV. However, the new tax was received with violent protest from the privileged classes sitting in the estates of the few provinces that still retained the right to decide over taxation (most provinces had long lost their provincial estates and the right to decide over taxation). The new tax was also opposed by the clergy and by the "parlements". Pressed and eventually won over by his entourage at court, the king gave in and exempted the clergy from the twentieth in 1751. Eventually, the twentieth became a mere increase in the already existing "taille", the most important direct tax of the monarchy from which privileged classes were exempted. It was the first defeat in the "taxation war" waged against the privileged classes.
As a result of these attempts at reform, the "Parlement" of Paris, using the quarrel between the clergy and the Jansenists as a pretext, addressed remonstrances to the king in April 1753. In these remonstrances, the "Parlement", which was made up of privileged aristocrats and ennobled commoners, proclaimed itself the "natural defender of the fundamental laws of the kingdom" against the arbitrariness of the monarchy.
Seven Years' War.
By 1755, a new European conflict was brewing. The Treaty of Aix-la-Chapelle turned out to be only a sort of truce in the conflict between Austria and Prussia over the province of Silesia, and France and Britain were quarreling seriously over colonial possessions. Indeed, the French and British were fighting without a declaration of war in a conflict known as the French and Indian War of 1754-1763. In 1755, the British seized 300 French merchant ships in violation of international law. A few months later, on 16 January 1756, Great Britain and Prussia, enemies in the War of the Austrian Succession, signed a treaty of "neutrality".
Frederick the Great had abandoned his French ally during the War of Austrian Succession by signing a separate peace treaty with Austria in December 1745. At the same time, French officials realized that the Habsburg empire of Maria Theresa of Austria was no longer the danger it had been in the heyday of the Habsburgs, back in the 16th and 17th centuries, when they controlled Spain and much of the rest of Europe and presented a formidable challenge to France. The new dangerous power looming on the horizon was Prussia. In a "diplomatic revolution", the king overruled his ministers and signed the Treaty of Versailles with Austria on 1 April 1756, and put an end to more than 200 years of conflict with the Habsburgs. The new Franco-Austrian Alliance would last intermittently for the next thirty-five years.
Louis apparently expected that his alliance with Austria would prevent another war on the continent by confronting Prussia with two continental powers arrayed against him instead of just one, as had been the way during the War of the Austrian Succession. He was mistaken. Austria was determined to retrieve Silesia from Prussian control. At the end of August 1756, having learned that Austria was negotiating to enlist Russia against him, Frederick the Great invaded Saxony without a declaration of war. He soon defeated the unprepared Saxon and Austrian armies and occupied the whole of the country. The younger daughter of the Saxon ruler, Augustus III, was the dauphin's wife, and his elder daughter was married to Charles VII of Naples, a Bourbon cousin. Frederick's treatment of the Polish–Saxon royal family was seen as uncommonly disrespectful. Moreover, Augustus' wife Maria Josepha, mother of the dauphine Marie-Joséphe of Saxony, died in 1757 from a stroke that some in France attributed to maltreatment, without evidence. Rumours of Frederick's actions shocked the French and inflamed public opinion against Prussia. The dauphine had a miscarriage as a result of the news coming from Saxony. Meanwhile, Britain declared war on France on 18 May 1756.
The French military successes of the War of the Austrian Succession were not repeated in the Seven Years' War, except for a few temporary victories such as the Battle of Minorca of 1756. A French invasion of Hanover in 1757 resulted in a counter-attack led by Ferdinand of Brunswick the following year that saw them driven out of the electorate. Plans for an invasion of Britain in 1759 were never carried out due to catastrophic naval defeats. French forces suffered disaster after disaster against the British in North America, India, and Africa. The 1763 Treaty of Paris with Great Britain forced France to surrender almost all of New France and drastically curtail its political influence in India. The French navy was crippled, but France suffered no territorial losses on the continent of Europe by the terms of the Treaty of Hubertusburg of 1763 with Prussia.
Assassination attempt.
On 5 January 1757, would-be assassin Robert-François Damiens entered the Palace of Versailles, as did thousands of people every day, to petition the king. At 6 pm, as night had fallen on a cold Versailles covered in snow, the king, who was visiting his daughter, left her apartments to return to the Grand Trianon, where he was staying. As he was walking in the Marble Courtyard between two lines of guards lighting the way with torches, headed toward his carriage (which was waiting at the edge of the Marble Courtyard), Damiens emerged from the dark, passed through the guards, and stabbed the king in the side with a penknife.
The 8.1 cm (3.2 inch) blade entered the king's body between the fourth and fifth ribs. The king, who was bleeding, remained calm and called for a confessor as he thought he would die. Thoughts of poison came to his mind. At the sight of the queen, who had come in a hurry, he asked for forgiveness for his misbehaviour. However, the king survived. He was probably saved by the thick layers of clothes he wore on that cold day, which cushioned the blade, protecting the internal organs. The blade penetrated only 1 cm (0.4 inch) into the king's body, leading Voltaire to describe the wound as "fortunately scarcely more significant than a pinprick".
Tried by the "Parlement" of Paris, Damiens was tortured and executed on the Place de Grève on 28 March 1757.
Later life.
After the assassination attempt, and at Pompadour's instigation, the king dismissed two ministers: the Comte d'Argenson, secretary of state for war, and Machault d'Arnouville, keeper of the seals (justice minister) and before that controller-general of finances. To help coordinate the government of France, he appointed the Duke of Choiseul as Minister of Foreign Affairs.
In 1764, the Jesuits were suppressed in France. The order had been expelled from Portugal and Brazil in 1759, and later from Spain and its overseas possessions in 1767.
Reforms would resume only with the dismissal of Choiseul in 1771. In that year, Louis XV installed a so-called Triumvirate consisting of René Nicolas de Maupeou as Chancellor of France and Minister of Justice, Joseph Marie Terray as Minister of Finance, and Emmanuel-Armand de Richelieu, duc d'Aiguillon, as Minister for Foreign Affairs. They fought against the "Parlements" and had the judiciary run by the Council of State. Louis XVI restored the "Parlements" and removed the triumvirs from their posts.
Louis and his ministers were unhappy about Great Britain's victory in the Seven Years' War and in the years following the Treaty of Paris, they began drawing up a long-term plan that would involve the construction of a larger navy and the formation of an anti-British coalition of states that would lead to an eventual war of revenge with the goal of regaining France's lost overseas colonies. Choiseul was the leading advocate of this scheme, and he was prepared to go to war with Britain over the Falkland Islands in 1770. Louis, however, did not believe that France was ready for war at that time and dismissed Choiseul instead.
Throughout the second half of his reign, Louis XV endured conflict and intrigue from his children, particularly his son Louis (the dauphin), and his eldest surviving daughter, Adélaïde. The intrigue of family politics took place within the environs of Versailles, an environment that was under his control. Louis XV used his court to oversee and counter his children's politics and intrigues. Louis XV remodeled the spaces at Versailles to communicate his satisfaction and displeasure with his children and other members of the court.
Jeanne Bécu, Madame du Barry.
As he was getting older, Louis XV was slowly becoming less inclined to visit the brothel-like Parc-aux-Cerfs, and the women of the court soon began planning on throwing themselves at his feet to win the vacant place left open by Madame de Pompadour's death. One notable such lady was the Beatrix de Choiseul-Stainville, Duchess de Gramont, sister of the duc de Choiseul. Louis never really did have any affection towards her, for she was described as being rather rough and manly in appearance.
It coincided that Lebel, the King's valet-de-chambre-, became introduced to a certain Jeanne Bécu, a current mistress of the Maréchal de Richelieu, a friend of the king. Jeanne's pimp, the infamous Jean-Baptiste, Comte du Barry (although the title of "comte" was truly invented by himself) had long dreamed of giving one of his prostitutes to the king for a 'long term relationship', and with the outstandingly beautiful Jeanne he found hope. After much conniving, Jeanne not only bedazzled the king with her character and appearance, but caused much gossip and hatred between the courtiers who, jealous of the attention the king showered on her, also could not believe that a woman outside the palace circle took the place of the highest rank, second only to a queen.
After having been splendidly presented at court on April 22, 1769 and at the age of just 26, Jeanne took her place as the king's new royal mistress complete with titles and riches, which in future proved to be part of the monarchy's downfall in the French Revolution. To Louis, Jeanne was both entertaining and a means for him to levitate the country's responsibilities off his shoulder. Many opposed this relationship, not only because it was such a scandal for him to have an ex-courtesan living in Versailles, but also because of their age gap which could prove too much for his heart to bear. Louis XV would have none of this, and so defiant was he of this opposition that he even brought Jeanne to dine at the Château de la Muette during Marie Antoinette's arrival festivities from Austria. At first the 14 year-old dauphine found her intriguing, but after the king's daughters explained further her true purpose in court, Marie Antoinette grew to bitterly hate Jeanne.
After five years enjoying Jeanne's company and sexual talents, a second attack of smallpox fatally hit Louis, due to which he broken-heartedly had to send Jeanne away from court in order to receive spiritual pardon.
Death.
Louis XV died on 10 May 1774 of severe smallpox at the Palace of Versailles. He was the first Bourbon ruler whose heart was not, as tradition demanded, cut out and placed in a special coffer. The body was not embalmed for fear of contamination; instead, alcohol was poured into the coffin. The remains were also soaked in quicklime. In a surreptitious late-night ceremony attended by only one courtier, the body was taken to the Saint Denis Basilica.
Louis' death saw the French monarchy at its nadir in political, financial and moral terms. Since Louis XV's son Louis had died nine years earlier, the throne passed to his grandson, the conventional and unimaginative Louis XVI. Two of Louis XV's other grandsons, Louis XVIII and Charles X, would occupy the throne of France after the fall of Napoleon I.
Image, public opinion and history.
Edmé Bouchardon's equestrian statue of Louis XV was originally conceived to commemorate the monarch's victorious role in the War of the Austrian Succession. He portrayed the king as peacemaker. It was not unveiled until 1763, following France's defeat in the Seven Years' War. Designed as a symbol of loyalty to the king, Bouchardon's work was used by the Crown for a public relations event staged to restore public confidence in a monarchy in decline. It used art as propaganda on a grand scale. This statue was located on the "Place Louis XV" and was torn down during the Revolution.
Many scholars argue that Louis was unequal to the high expectations of his subjects. Harris says that, "Historians have depicted this ruler as one of the weakest of the Bourbons, a do-nothing king who left affairs of state to ministers while indulging in his hobbies of hunting and womanizing." Harris adds that ministers rose and fell according to his mistresses' opinions, seriously undermining the prestige of the monarchy.
Emmanuel Le Roy Ladurie, the leader of the French Annales School, notes the king was handsome, athletic, intelligent and an excellent hunter, but that he disappointed the people. He did not keep up the practice of Mass and performing his religious obligations to the people. Le Roy Ladurie says the people felt he had reduced the sacred nature of the monarchy, and thereby diminished himself.
According to Kenneth N. Jassie and Jeffrey Merrick, contemporary songs, poems, and public declarations typically portrayed a king as "master," unblemished "Christian," and benevolent provider ("baker"). Young Louis' failings were attributed to inexperience and manipulation by his handlers. Jassie and Merrick argue that the king's troubles mounted steadily, and the people blamed and ridiculed his debauchery. The king ignored the famines and crises of the nation. The people reviled the king in popular protest, and finally celebrated his death. The monarchy survived—for a while—but Louis XV left his successor with a damaging legacy of popular discontent.
Some sermons on his death in 1774 praised the monarch and went out of their way to excuse his faults. Jeffrey Merrick writes, "But those ecclesiastics who not only raised their eyebrows over the sins of the Beloved but also expressed doubts about his policies reflected the corporate attitude of the First Estate more accurately." They prayed the new king would restore morality at court and better serve the will of God.
The financial strain imposed by these wars and by the excesses of the royal court, and the consequent dissatisfaction with the monarchy, contributed to the national unrest which culminated in the French Revolution of 1789. The historian Colin Jones argues that Louis XV left France with serious financial difficulties: "The military disasters of the Seven Years War led to acute state financial crisis.". Ultimately, he writes, Louis XV failed to overcome these fiscal problems, mainly because he was incapable of putting together conflicting parties and interests in his entourage. Although aware of the forces of anti-monarchism threatening his family's rule, he did not do anything to stop them.
Two scholars of the 1980s defended Louis XV. Olivier Bernier in his 1984 biography argues that Louis was both popular and a leader in reforming France. In his 59-year reign, no foreign army crossed the French border, and her people were not threatened by conquest. He was known popularly as "Le Bien-aimé" (the well-beloved). Many of his subjects prayed for his recovery during his serious illness in Metz in 1744. His dismissal of the "Parlement" of Paris and his chief minister, Choisieul, in 1771, were attempts to wrest control of government from those Louis considered corrupt. He changed the tax code to try to balance the national budget. Bernier argues that these acts would have avoided the French Revolution, but his successor, Louis XVI, reversed his policies. Guy Chaussinand-Nogaret, wrote that Louis XV's tarnished reputation was created fifteen years after his death, to justify the French Revolution, and that the nobility during his reign were competent.
E.H. Gombrich, better known as an art historian, wrote in 2005, "Louis XV and Louis XVI, the Sun King's XIV successors, were incompetent, and content merely to imitate their great predecessor's outward show of power. The pomp and magnificence remained...Finance ministers soon became expert swindlers, cheating and extorting on a grand scale. The peasants worked till they dropped and citizens were forced to pay huge taxes."
Jeffrey Merrick claims that his weak and ineffective rule accelerated the general decline that culminated in the French Revolution in 1789. The king was a notorious womaniser; the monarch's virility was supposed to be another way in which his power was manifested. Nevertheless, Merrick writes, popular faith in the monarchy was shaken by the scandals of Louis’ private life and by the end of his life he had become despised.
Historians agree that in terms of culture and art, France reached a high point under Louis XV. However, he was blamed for the many diplomatic, military and economic reverses. His reign was marked by ministerial instability while his "prestige was ruined by military failure and colonial losses," concludes Jean-Denis Lepage.
Popular legend holds that Louis said, "After me, the flood" (""Après moi, le déluge""). This quotation is attributed to Madame de Pompadour, although it is not certain that even she ever said it. Historians point out:
Louis XV in popular culture.
Louis XV has been featured as an historical figure in many films about the era of the "Ancien Régime", especially those depicting the lives of Marie Antoinette and Madame du Barry.
Children.
Illegitimate issue.
Louis XV had several illegitimate children, although the exact number is unknown. Historiography suggest the following as possible issue of the King:
—With Pauline Félicité de Mailly (1712 – 9 September 1741), by marriage "marquise de Vintimille". She died after giving birth to a son:
—With Jeanne Perray:
—With Marie-Louise O'Murphy (21 October 1737 – 11 December 1814), an Irish adventuress:
—With Françoise de Châlus (24 February 1734 – 7 July 1821), by marriage Duchesse de Narbonne-Lara:
Note: Both children are officially recognized by their mother's husband, although it is alleged that the King himself was the real father. The coevals attribute the paternity of both children to Louis XV for, according to documents from the Military Archive, Françoise de Châlus' husband had been wounded in the War of the Austrian Succession (1747) becoming from that moment unable to have any offspring. The baptism of Louis, Comte de Narbonne-Lara is another indication of that paternity. His wife had become the King's mistress. Not only was it noted that he was named Louis but also his contemporaries remarked on the similarities between the young Louis and the King.
—With Marguerite Catherine Haynault (11 September 1736 – 17 March 1823):
—With Lucie Madeleine d'Estaing (10 May 1743 – 7 April 1826), a half-sister of the Admiral d'Estaing:
Note: Both children were registered as daughters of "Louis Auguste, Old Official, and citizen Lucie", both non-existent persons. In August 1774 Agnès and Aphrodite received from Louis XVI their letters of recognition of nobility ("demoiselles issue de la plus ancienne noblesse de France") and following the stipulations leave by Louis XV, each of them obtained a capital of 223,000 livres and a reported annual revenue of 24,300 livres.
—With Anne Coppier de Romans (19 June 1737 – 27 December 1808), Baroness de Meilly-Coulonge:
—With Jeanne Louise Tiercelin de La Colleterie (26 November 1746 – 5 July 1779), called "Madame de Bonneval":
Titles, styles, honours and arms.
Titles and styles.
Louis's formal style was ""Louis XV, par la grâce de Dieu, roi de France et de Navarre"", or "Louis XV, by the Grace of God, King of France and of Navarre".

</doc>
<doc id="54248" url="https://en.wikipedia.org/wiki?curid=54248" title="Military aircraft">
Military aircraft

A military aircraft is any fixed-wing or rotary-wing aircraft that is operated by a legal or insurrectionary armed service of any type. Military aircraft can be either combat or non-combat:
History.
In 1783, when the first practical aircraft (hot-air and hydrogen balloons) were established, they were quickly adopted for military duties 
Combat aircraft.
Combat aircraft, or "Warplanes", are divided broadly into multi-role, fighters, bombers, and attackers, with several variations between them, including fighter-bombers, such as the MiG-23 ground-attack aircraft and the Soviet Ilyushin Il-2 Sturmovik. Also included among combat aircraft are long-range maritime patrol aircraft, such as the Hawker Siddeley Nimrod and the S-3 Viking that are often equipped to attack with anti-ship missiles and anti-submarine weapons.
Fighter aircraft.
The main role of fighters is destroying enemy aircraft in air-to-air combat, offensive or defensive. Many are fast and highly maneuverable. Escorting bombers or other aircraft is also a common task. They are capable of carrying a variety of weapons, including machine guns, cannons, rockets and guided missiles. Many modern fighters can attack enemy fighters from a great distance, before the enemy even sees them. Examples of air superiority fighters include the F-22 Raptor. WWII fighters include the British Spitfire; the American P-51 Mustang; and German Bf 109. An example of an interceptor (a fighter designed to take-off and quickly intercept and shoot down enemy planes) would be the MiG-25. An example of a heavy fighter is the Messerschmitt Bf 110.
The term "fighter" is also sometimes applied to aircraft that have virtually no air-air capability – for example the A-10 ground-attack aircraft is operated by USAF "Fighter" squadrons.
Bomber aircraft.
Bombers are normally larger, heavier, and less maneuverable than fighter aircraft. They are capable of carrying large payloads of bombs, torpedoes or cruise missiles. Bombers are used almost exclusively for ground attacks and not fast or agile enough to take on enemy fighters head-to-head. A few have a single engine and require one pilot to operate and others have two or more engines and require crews of two or more. A limited number of bombers, such as the B-2 Spirit, have stealth capabilities that keep them from being detected by enemy radar. An example of a conventional modern bomber would be the B-52 Stratofortress. An example of a WWII bomber would be a B-17 Flying Fortress.
Bombers include light bombers, medium bombers, heavy bombers, dive bombers, and torpedo bombers.
The U.S. Navy and Marines have traditionally referred to their light and medium bombers as "attack aircraft".
Attack aircraft.
Attack aircraft can be used to provide support for friendly ground troops. Some are able to carry conventional or nuclear weapons far behind enemy lines to strike priority ground targets. Attack helicopters attack enemy armor and provide close air support for ground troops.
An example historical ground-attack aircraft is the Soviet Ilyushin Il-2 Shturmovik.
Several types of transport airplanes have been armed with sideways firing weapons as gunships for ground attack. These include the AC-47 and AC-130 aircraft.
In modern air forces the distinction between bombers, fighter-bombers, and attack aircraft has become blurred. Many attack aircraft, even ones that "look" like fighters, are optimized to drop bombs, with very little ability to engage in aerial combat. Indeed, the design qualities that make an effective low-level attack aircraft make for a distinctly inferior air superiority fighter, and vice versa. Perhaps the most meaningful distinction is that a bomber is generally a long-range aircraft capable of striking targets deep within enemy territory, whereas fighter bombers and attack aircraft are limited to 'theater' missions in and around the immediate area of battlefield combat. Even that distinction is muddied by the availability of aerial refueling, which greatly increases the potential radius of combat operations.
Electronic warfare aircraft.
An electronic warfare aircraft is a military aircraft equipped for electronic warfare (EW) - i.e. degrading the effectiveness of enemy radar and radio systems.
Maritime patrol aircraft.
A maritime patrol aircraft fixed-wing military aircraft designed to operate for long durations over water in maritime patrol roles—in particular anti-submarine, anti-ship and search and rescue.
Multirole combat aircraft.
Many combat aircraft today have a multirole ability. Normally only applying to fixed-wing aircraft, this term signifies that the plane in question can be a fighter or a bomber, depending on what the mission calls for. An example of a multirole design is the F/A-18 Hornet. A WWII example would be the P-38 Lightning.
Some fighter aircraft, such as the F-16 Fighting Falcon, are mostly used as 'bomb trucks', despite being designed for aerial combat.
Non-combat aircraft.
Non-combat roles of military aircraft include search and rescue, reconnaissance, observation/surveillance, Airborne Early Warning and Control, transport, training, and aerial refueling.
Many civil aircraft, both fixed wing and rotary wing, have been produced in separate models for military use, such as the civilian Douglas DC-3 airliner, which became the military C-47 Skytrain, and British "Dakota" transport planes, and decades later, the USAF's AC-47 aerial gunships. Even the fabric-covered two-seat Piper J3 Cub had a military version. Gliders and balloons have also been used as military aircraft; for example, balloons were used for observation during the American Civil War and during World War I, and military gliders were used during World War II to deliver ground troops in airborne assaults.
Military transport aircraft.
Military transport (logistics) aircraft are primarily used to transport troops and war supplies. Cargo can be attached to pallets, which are easily loaded, secured for flight, and quickly unloaded for delivery. Cargo also may be discharged from flying aircraft on parachutes, eliminating the need for landing. Also included in this category are aerial tankers; these planes can refuel other aircraft while in flight. An example of a transport aircraft is the C-17 Globemaster III. A WWII example would be the C-47. An example of a tanker craft would be the KC-135 Stratotanker. Helicopters and gliders can transport troops and supplies to areas where other aircraft would be unable to land.
Calling a military aircraft a "cargo plane" is incorrect, because military "transport planes" also carry paratroopers and other soldiers.
Airborne early warning and control.
An airborne early warning and control (AEW&C) system is an airborne radar system designed to detect aircraft, ships and ground vehicles at long ranges and control and command the battle space in an air engagement by directing fighter and attack aircraft strikes. AEW&C units are also used to carry out surveillance, including over ground targets and frequently perform C2BM (command and control, battle management) functions similar to an Airport Traffic Controller given military command over other forces. Used at a high altitude, the radars on the aircraft allow the operators to distinguish between friendly and hostile aircraft hundreds of miles away.
AEW&C aircraft are used for both defensive and offensive air operations, and are to the NATO and USA forces trained or integrated Air Forces what the Command Information Center is to a Navy Warship, plus a highly mobile and powerful radar platform. The system is used offensively to direct fighters to their target locations, and defensively in order to counterattacks by enemy forces, both air and ground. So useful is the advantage of command and control from a high altitude, the United States Navy operates AEW&C aircraft off its Supercarriers to augment and protect its carrier Command Information Centers (CICs).
AEW&C is also known by the older terms "airborne early warning" (AEW) and "airborne warning and control system" (AWACS, /ˈeɪwæks/ ay-waks) although AWACS is the name of a specific system currently used by NATO and the USAF and is often used in error to describe similar systems.
Reconnaissance and surveillance aircraft.
Reconnaissance aircraft are primarily used to gather intelligence. They are equipped with cameras and other sensors. These aircraft may be specially designed or may be modified from a basic fighter or bomber type. This role is increasingly being filled by satellites and unmanned aerial vehicles (UAVs).
Surveillance and observation aircraft use radar and other sensors for battlefield surveillance, airspace surveillance, maritime patrol and artillery spotting. They include modified civil aircraft designs, moored balloons and UAVs.
Experimental aircraft.
Experimental aircraft are designed in order to test advanced aerodynamic, structural, avionic, or propulsion concepts. These are usually well instrumented, with performance data telemetered on radio-frequency data links to ground stations located at the test ranges where they are flown. An example of an experimental aircraft is the Bristol 188.

</doc>
<doc id="54251" url="https://en.wikipedia.org/wiki?curid=54251" title="Myliobatiformes">
Myliobatiformes

Myliobatiformes is one of the four orders of batoids, cartilaginous fishes related to sharks. They were formerly included in the order Rajiformes, but more recent phylogenetic studies have shown the myliobatiforms to be a monophyletic group, and its more derived members evolved their highly flattened shapes independently of the skates.
Classification.
Nelson's 2006 "Fishes of the World" arranges the Myliobatiformes as:

</doc>
<doc id="54253" url="https://en.wikipedia.org/wiki?curid=54253" title="Silk Road">
Silk Road

The Silk Road or Silk Route was an ancient network of trade routes that were central to cultural interaction through regions of the Asian continent connecting the West and East from China to the Mediterranean Sea.
The Silk Road derives its name from the lucrative trade in Chinese silk carried out along its length, beginning during the Han dynasty (207 BCE – 220 CE). The Central Asian sections of the trade routes were expanded around 114 BCE by the Han dynasty, largely through the missions and explorations of the Chinese imperial envoy, Zhang Qian. The Chinese took great interest in the safety of their trade products and extended the Great Wall of China to ensure the protection of the trade route.
Trade on the Silk Road was a significant factor in the development of the civilizations of China, the Indian subcontinent, Persia, Europe, the Horn of Africa and Arabia, opening long-distance, political and economic relations between the civilizations. Though silk was certainly the major trade item from China, many other goods were traded, and religions, syncretic philosophies, and various technologies, as well as diseases, also travelled along the Silk Routes. In addition to economic trade, the Silk Road served as a means of carrying out cultural trade among the civilizations along its network.
The main traders during antiquity were the Chinese, Arab, Indians, Persians, Somalis, Greeks, Syrians, Romans, Armenians, Bengalis, and Bactrians, and from the 5th to the 8th century the Sogdians.
In June 2014 UNESCO designated the Chang'an-Tianshan corridor of the Silk Road as a World Heritage Site.
Name.
The Silk Road derives its name from the lucrative Chinese silk trade, a major reason for the connection of trade routes into an extensive transcontinental network. The German terms ' and ' ("the Silk Road/Route") were coined by Ferdinand von Richthofen, who made seven expeditions to China from 1868 to 1872. Some scholars prefer the term "Silk Routes" because the road included an extensive network of routes, though few were more than rough caravan tracks.
History.
Precursors.
Cross-continental journeys.
As the domestication of pack animals and the development of shipping technology highly increased the capacity for prehistoric people to carry heavier loads over greater distances, cultural exchanges and trade developed rapidly. In addition, the vast grassland steppes of Asia provided fertile grazing, water, and easy passage for caravans, enabling merchants to travel immense distances, from the shores of the Pacific to Africa and deep into Europe, without trespassing on agricultural lands and arousing hostility.
Chinese and Central Asian contacts.
From the 2nd millennium BCE, nephrite jade was being traded from mines in the region of Yarkand and Khotan to China. Significantly, these mines were not very far from the lapis lazuli and spinel ("Balas Ruby") mines in Badakhshan, and, although separated by the formidable Pamir Mountains, routes across them were apparently in use from very early times.
The Tarim mummies, mummies of non-Mongoloid, apparently Caucasoid, individuals, have been found in the Tarim Basin, in the area of Loulan located along the Silk Road east of Yingpan, dating to as early as 1600 BCE and suggesting very ancient contacts between East and West. These mummified remains may have been of people who spoke Indo-European languages, which remained in use in the Tarim Basin, in the modern day Xinjiang region, until replaced by Turkic influences from the Xiongnu culture to the north and by Chinese influences from the eastern Han dynasty, who spoke a Sino-Tibetan language.
Some remnants of what was probably Chinese silk have been found in Ancient Egypt from 1070 BCE. The Great Oasis cities of central Asia played a crucial role in the effective functioning of the silk road trades. Though the originating source seems sufficiently reliable, silk unfortunately degrades very rapidly and we cannot double-check for accuracy whether it was actually cultivated silk (which would almost certainly have come from China) that was discovered or a type of "wild silk", which might have come from the Mediterranean region or the Middle East.
Following contacts between metropolitan China and nomadic western border territories in the 8th century BCE, gold was introduced from Central Asia, and Chinese jade carvers began to make imitation designs of the steppes, adopting the Scythian-style animal art of the steppes (depictions of animals locked in combat). This style is particularly reflected in the rectangular belt plaques made of gold and bronze with alternate versions in jade and steatite.
The expansion of Scythian cultures, stretching from the Hungarian plain and the Carpathians to the Chinese Kansu Corridor, and linking the Middle East with Northern India and the Punjab, undoubtedly played an important role in the development of the Silk Road. Scythians accompanied the Assyrian Esarhaddon on his invasion of Egypt, and their distinctive triangular arrowheads have been found as far south as Aswan. These nomadic peoples were dependent upon neighbouring settled populations for a number of important technologies, and in addition to raiding vulnerable settlements for these commodities, they also encouraged long-distance merchants as a source of income through the enforced payment of tariffs. Soghdian Scythian merchants played a vital role in later periods in the development of the Silk Road.
Persian Royal Road.
By the time of Herodotus (c. 475 BCE), the Royal Road of the Persian Empire ran some from the city of Susa on the Karun ( east of the Tigris) to the port of Smyrna (modern İzmir in Turkey) on the Aegean Sea. It was maintained and protected by the Achaemenid Empire (c. 500–330 BCE) and had postal stations and relays at regular intervals. By having fresh horses and riders ready at each relay, royal couriers could carry messages the entire distance in nine days, while normal travellers took about three months.
Hellenistic era.
The next major step in the development of the Silk Road was the expansion of the Greek empire of Alexander the Great into Central Asia. In August 329 BCE, at the mouth of the Fergana Valley in Tajikistan across the mountain pass from the modern Chinese province of Xinjiang, Alexander founded the city of Alexandria Eschate or "Alexandria The Furthest". This later became a major staging point on the northern Silk Route. See Dayuan ("Ta-yuan"; ; literarily "Great Ionians").
The Greeks remained in Central Asia for the next three centuries, first through the administration of the Seleucid Empire, and then with the establishment of the Greco-Bactrian Kingdom (250 BCE-125 BCE) in Bactria (modern Afghanistan, Tajikistan, and Pakistan) and the later Indo-Greek Kingdom (180 BCE - 10 CE) in modern northern Pakistan and Afghanistan. They continued to expand eastward, especially during the reign of Euthydemus (230–200 BCE), who extended his control beyond Alexandria Eschate to Sogdiana. There are indications that he may have led expeditions as far as Kashgar in Chinese Turkestan, leading to the first known contacts between China and the West around 200 BCE. The Greek historian Strabo writes, ""they extended their empire even as far as the Seres (China) and the Phryni.""
The Hellenistic world and Classical Greek philosophy mixed with Eastern philosophies, leading to syncretisms such as Greco-Buddhism.
Chinese exploration of Central Asia.
With the Mediterranean linked to the Fergana Valley, the next step was to open a route across the Tarim Basin and the Gansu Corridor to China Proper. This extension came around 130 BCE, with the embassies of the Han dynasty to Central Asia following the reports of the ambassador Zhang Qian (who was originally sent to obtain an alliance with the Yuezhi against the Xiongnu).Zhang Qian visited directly the kingdom of Dayuan in Ferghana, the territories of the Yuezhi in Transoxiana, the Bactrian country of Daxia with its remnants of Greco-Bactrian rule, and Kangju. He also made reports on neighbouring countries that he did not visit, such as Anxi (Parthia), Tiaozhi (Mesopotamia), Shendu (Pakistan) and the Wusun. Zhang Qian's report suggested the economic reason for Chinese expansion and wall-building westward, and trailblazed the silk road which is one of the most famous trade routes. After the defeat of the Xiongnu, however, Chinese armies established themselves in Central Asia, initiating the Silk Route as a major avenue of international trade. Some say that the Chinese Emperor Wu became interested in developing commercial relationships with the sophisticated urban civilizations of Ferghana, Bactria, and the Parthian Empire: "The Son of Heaven on hearing all this reasoned thus: Ferghana (Dayuan ""Great Ionians"") and the possessions of Bactria (Ta-Hsia) and Parthian Empire (Anxi) are large countries, full of rare things, with a population living in fixed abodes and given to occupations somewhat identical with those of the Chinese people, but with weak armies, and placing great value on the rich produce of China" ("Hou Hanshu", Later Han History). Others say that Emperor Wu was mainly interested in fighting the Xiongnu and that major trade began only after the Chinese pacified the Hexi Corridor.
"China snatched control of the Silk Road from the Hsiung-nu", when the Chinese general Cheng Ki "installed himself as protector of the Tarim at Wu-lei, situated between Kara Shahr and Kucha." "China's control of the Silk Road at the time of the later Han, by ensuring the freedom of transcontinental trade along the double chain of oases north and south of the Tarim, favoured the dissemination of Buddhism in the river basin, and with it Indian literature and Hellenistic art."
The Chinese were also strongly attracted by the tall and powerful horses (named "Heavenly horses") in the possession of the Dayuan (literally the "Great Ionians", the Greek kingdoms of Central Asia), which were of capital importance in fighting the nomadic Xiongnu. The Chinese subsequently sent numerous embassies, around ten every year, to these countries and as far as Seleucid Syria. "Thus more embassies were dispatched to Anxi Yancai [who later joined the Alans , Lijian under the Greek Seleucids, Tiaozhi (Mesopotamia), and Tianzhu India... As a rule, rather more than ten such missions went forward in the course of a year, and at the least five or six." ("Hou Hanshu", Later Han History).These connections marked the beginning of the Silk Road trade network that extended to the Roman Empire. The Chinese campaigned in Central Asia on several occasions, and direct encounters between Han troops and Roman legionaries (probably captured or recruited as mercenaries by the Xiong Nu) are recorded, particularly in the 36 BCE battle of Sogdiana (Joseph Needham, Sidney Shapiro). It has been suggested that the Chinese crossbow was transmitted to the Roman world on such occasions, although the Greek gastraphetes provides an alternative origin. R. Ernest Dupuy and Trevor N. Dupuy suggest that in 36 BCE, a "Han expedition into central Asia, west of Jaxartes River, apparently encountered and defeated a contingent of Roman legionaries. The Romans may have been part of Antony's army invading Parthia. Sogdiana (modern Bukhara), east of the Oxus River, on the Polytimetus River, was apparently the most easterly penetration ever made by Roman forces in Asia. The margin of Chinese victory appears to have been their crossbows, whose bolts and darts seem easily to have penetrated Roman shields and armour." The Roman historian Florus also describes the visit of numerous envoys, which included "Seres"(China), to the first Roman Emperor Augustus, who reigned between 27 BCE and 14 CE:
The Han army regularly policed the trade route against nomadic bandit forces generally identified as Xiongnu. Han general Ban Chao led an army of 70,000 mounted infantry and light cavalry troops in the 1st century CE to secure the trade routes, reaching far west to the Tarim basin. Ban Chao expanded his conquests across the Pamirs to the shores of the Caspian Sea and the borders of Parthia. It was from here that the Han general dispatched envoy Gan Ying to Daqin (Rome). The Silk Road essentially came into being from the 1st century BCE, following these efforts by China to consolidate a road to the Western world and India, both through direct settlements in the area of the Tarim Basin and diplomatic relations with the countries of the Dayuan, Parthians and Bactrians further west. The Silk Roads were a "complex network of trade routes" that gave people the chance to exchange goods and culture.
A maritime Silk Route opened up between Chinese-controlled Giao Chỉ (centred in modern Vietnam, near Hanoi), probably by the 1st century. It extended, via ports on the coasts of India and Sri Lanka, all the way to Roman-controlled ports in Egypt and the Nabataean territories on the northeastern coast of the Red Sea.
Roman Empire.
Soon after the Roman conquest of Egypt in 30 BCE, regular communications and trade between China, Southeast Asia, India, the Middle East, Africa, and Europe blossomed on an unprecedented scale. The eastern trade routes from the earlier Hellenistic powers and the Arabs that were part of the Silk Road were inherited by the Roman Empire. With control of these trade routes, citizens of the Roman Empire would receive new luxuries and greater prosperity for the Empire as a whole. The Greco-Roman trade with India started by Eudoxus of Cyzicus in 130 BCE continued to increase, and according to Strabo (II.5.12), by the time of Augustus, up to 120 ships were setting sail every year from Myos Hormos in Roman Egypt to India. The Roman Empire connected with the Central Asian Silk Road through their ports in Barygaza (known today as Bharuch ) and Barbaricum (known today as the cities of Karachi, Sindh, and Pakistan ) and continued along the western coast of India. An ancient "travel guide" to this Indian Ocean trade route was the Greek Periplus of the Erythraean Sea written in 60 CE.
The travelling party of Maës Titianus penetrated farthest east along the Silk Road from the Mediterranean world, probably with the aim of regularising contacts and reducing the role of middlemen, during one of the lulls in Rome's intermittent wars with Parthia, which repeatedly obstructed movement along the Silk Road. Intercontinental trade and communication became regular, organised, and protected by the 'Great Powers.' Intense trade with the Roman Empire soon followed, confirmed by the Roman craze for Chinese silk (supplied through the Parthians), even though the Romans thought silk was obtained from trees. This belief was affirmed by Seneca the Younger in his Phaedra and by Virgil in his Georgics. Notably, Pliny the Elder knew better. Speaking of the "bombyx" or silk moth, he wrote in his Natural Histories "They weave webs, like spiders, that become a luxurious clothing material for women, called silk." The Romans traded spices, perfumes, and silk.
Roman artisans began to replace yarn with valuable plain silk cloths from China. Chinese wealth grew as they delivered silk and other luxury goods to the Roman Empire, whose wealthy Roman women admired their beauty. The Roman Senate issued, in vain, several edicts to prohibit the wearing of silk, on economic and moral grounds: the import of Chinese silk caused a huge outflow of gold, and silk clothes were considered to be decadent and immoral.
The Roman Empire, and its demand for sophisticated Asian products, crumbled in the West around the 5th century.
The unification of Central Asia and Northern India within Kushan Empire in the 1st to 3rd centuries reinforced the role of the powerful merchants from Bactria and Taxila. They fostered multi-cultural interaction as indicated by their 2nd century treasure hoards filled with products from the Greco-Roman world, China, and India, such as in the archeological site of Begram.
Byzantine Empire.
Byzantine Greek historian Procopius stated that two Nestorian Christian monks eventually uncovered the way of how silk was made. From this revelation monks were sent by the Byzantine Emperor Justinian (ruled 527 - 565) as spies on the Silk Road from Constantinople to China and back to steal the silkworm eggs, resulting in silk production in the Mediterranean, particularly in Thrace in northern Greece, and giving the Byzantine Empire a monopoly on silk production in medieval Europe.
Tang dynasty reopens the route.
Although the Silk Road from China to the West was initially formulated during the reign of Emperor Wu of Han (141 – 87 BCE), it was reopened by the Tang Empire in 639 when Hou Junji conquered the West, and remained open for almost four decades. It was closed after the Tibetans captured it in 678, but in 699, during Empress Wu's period, the Silk Road reopened when the Tang reconquered the Four Garrisons of Anxi originally installed in 640, once again connecting China directly to the West for land-based trade. The Tang captured the vital route through the Gilgit Valley from Tibet in 722, lost it to the Tibetans in 737, and regained it under the command of the Goguryeo-Korean General Gao Xianzhi.
While the Turks were settled in the Ordos region (former territory of the Xiongnu), the Tang government took on the military policy of dominating the central steppe. The Tang dynasty (along with Turkic allies) conquered and subdued Central Asia during the 640s and 650s. During Emperor Taizong's reign alone, large campaigns were launched against not only the Göktürks, but also separate campaigns against the Tuyuhun, the Xiyu states, and the Xueyantuo. Under Emperor Gaozong, a campaign led by the general Su Dingfang was launched against the Western Turks ruled by Ashina Helu.
The Silk Road was the most important pre-modern Eurasian trade route. The Tang dynasty established a second Pax Sinica, and the Silk Road reached its golden age, whereby Persian and Sogdian merchants benefited from the commerce between East and West. At the same time, the Chinese empire welcomed foreign cultures, making it very cosmopolitan in its urban centres. In addition to the land route, the Tang dynasty also developed the maritime Silk Route. Chinese envoys had been sailing through the Indian Ocean to India since perhaps the 2nd century BCE, yet it was during the Tang dynasty that a strong Chinese maritime presence could be found in the Persian Gulf and Red Sea, into Persia, Mesopotamia (sailing up the Euphrates River in modern-day Iraq), Arabia, Egypt, Aksum (Ethiopia), and Somalia in the Horn of Africa.
Medieval.
The Silk Road represents an early phenomenon of political and cultural integration due to inter-regional trade. In its heyday, it sustained an international culture that strung together groups as diverse as the Magyars, Armenians, and Chinese. The Silk Road reached its peak in the west during the time of the Byzantine Empire; in the Nile-Oxus section, from the Sassanid Empire period to the Il Khanate period; and in the sinitic zone from the Three Kingdoms period to the Yuan Dynasty period. Trade between East and West also developed across the Indian Ocean, between Alexandria in Egypt and Guangzhou in China. Persian Sassanid coins emerged as a means of currency, just as valuable as silk yarn and textiles.
Under its strong integrating dynamics on the one hand and the impacts of change it transmitted on the other, tribal societies previously living in isolation along the Silk Road, and pastoralists who were of barbarian cultural development, were drawn to the riches and opportunities of the civilisations connected by the routes, taking on the trades of marauders or mercenaries. Many barbarian tribes became skilled warriors able to conquer rich cities and fertile lands and to forge strong military empires.
The Sogdians dominated the East-West trade after the 4th century up to the 8th century, with Suyab and Talas ranking among their main centres in the north. They were the main caravan merchants of Central Asia. Their commercial interests were protected by the resurgent military power of the Göktürks, whose empire has been described as "the joint enterprise of the Ashina clan and the Soghdians". A.V. Dybo noted that "according to historians, the main driving force of the Great Silk Road were not just Sogdians, but the carriers of a mixed Sogdian-Türkic culture that often came from mixed families." Their trade, with some interruptions, continued in the 9th century within the framework of the Uighur Empire, which until 840 extended across northern Central Asia and obtained from China enormous deliveries of silk in exchange for horses. At this time caravans of Sogdians travelling to Upper Mongolia are mentioned in Chinese sources. They played an equally important religious and cultural role. Part of the data about eastern Asia provided by Muslim geographers of the 10th century actually goes back to Sogdian data of the period 750–840 and thus shows the survival of links between east and west. However, after the end of the Uighur Empire, Sogdian trade went through a crisis. What mainly issued from Muslim Central Asia was the trade of the Samanids, which resumed the northwestern road leading to the Khazars and the Urals and the northeastern one toward the nearby Turkic tribes.
The Silk Road gave rise to the clusters of military states of nomadic origins in North China, ushered the Nestorian, Manichaean, Buddhist, and later Islamic religions into Central Asia and China.
Islamic era and the Silk Road.
By the Umayyad era Damascus had overtaken Ctesiphon as a major trade center until the Abbasid dynasty built the city of Baghdad, which became the most important city along the silk road.
At the end of its glory, the routes brought about the largest continental empire ever, the Mongol Empire, with its political centres strung along the Silk Road (Beijing in North China, Karakorum in central Mongolia, Sarmakhand in Transoxiana, Tabriz in Northern Iran, Sarai and Astrakhan in lower Volga, Solkhat in Crimea, Kazan in Central Russia, Erzurum in eastern Anatolia), realising the political unification of zones previously loosely and intermittently connected by material and cultural goods.
In Central Asia, Islam expanded from the 7th century onward, bringing a stop to Chinese westward expansion at the Battle of Talas in 751. Further expansion of the Islamic Turks in Central Asia from the 10th century finished disrupting trade in that part of the world, and Buddhism almost disappeared. For much of the Middle Ages, the Islamic Caliphate (centred in the Near East) often had a monopoly over much of the trade conducted across the Old World (see Muslim age of discovery for more details).
Mongol age.
The Mongol expansion throughout the Asian continent from around 1207 to 1360 helped bring political stability and re-established the Silk Road (via Karakorum). It also brought an end to the dominance of the Islamic Caliphate over world trade. Because the Mongols came to control the trade routes, trade circulated throughout the region, though they never abandoned their nomadic lifestyle.
The Mongol diplomat Rabban Bar Sauma visited the courts of Europe in 1287–88 and provided a detailed written report to the Mongols. Around the same time, the Venetian explorer Marco Polo became one of the first Europeans to travel the Silk Road to China. His tales, documented in "The Travels of Marco Polo", opened Western eyes to some of the customs of the Far East. He was not the first to bring back stories, but he was one of the most widely read. He had been preceded by numerous Christian missionaries to the East, such as William of Rubruck, Benedykt Polak, Giovanni da Pian del Carpine, and Andrew of Longjumeau. Later envoys included Odoric of Pordenone, Giovanni de' Marignolli, John of Montecorvino, Niccolò de' Conti, and Ibn Battuta, a Moroccan Muslim traveller who passed through the present-day Middle East and across the Silk Road from Tabriz between 1325–54.
In the 13th century efforts were made at forming a Franco-Mongol alliance, with an exchange of ambassadors and (failed) attempts at military collaboration in the Holy Land during the later Crusades. Eventually the Mongols in the Ilkhanate, after they had destroyed the Abbasid and Ayyubid dynasties, converted to Islam and signed the 1323 Treaty of Aleppo with the surviving Muslim power, the Egyptian Mamluks.
Some studies indicate that the Black Death, which devastated Europe in the late 1340s, may have reached Europe from Central Asia (or China) along the trade routes of the Mongol Empire.
Decline and disintegration.
The fragmentation of the Mongol Empire loosened the political, cultural, and economic unity of the Silk Road. Turkmeni marching lords seized land around the western part of the Silk Road from the decaying Byzantine Empire. After the fall of the Mongol Empire, the great political powers along the Silk Road became economically and culturally separated. Accompanying the crystallisation of regional states was the decline of nomad power, partly due to the devastation of the Black Death and partly due to the encroachment of sedentary civilisations equipped with gunpowder.
Gunpowder and early modernity in Europe led to the integration of territorial states and increasing mercantilism. On the Silk Road, however, gunpowder and early modernity had the opposite impact: the level of integration of the Mongol Empire could not be maintained, and trade declined, partly because of an increase in European maritime exchanges.
The Silk Road stopped serving as a shipping route for silk about 1453 with the Ottoman supremacy at Constantinople. Ottoman rulers of the day were anti-western, countering the crusades and aware of the loss of Andalusia in the west. They expressed their displeasure by embargoing trade with the west. Tensions with the west had eased a bit a century later, and Venice was able to cut an uneasy deal with the Ottomans, regaining for a time some of their economic clout as middlemen.
New European routes.
The disappearance of the Silk Road following the end of the Mongols' reign was one of the main factors that stimulated the Europeans to reach the prosperous Chinese empire through another route, especially by sea. Tremendous profits were to be obtained for anyone who could achieve a direct trade connection with Asia. The direct ocean route from Europe to the East was finally opened by the expeditions of Bartolomeu Dias (1488), and Vasco da Gama (1497-1499), by the Atlantic and the Indian oceans. One year later (1500), the armada led by Pedro Álvares Cabral also linked for the first time on this new route the New World (South America) and Asia. This was the main driving factor for those Portuguese explorations of the Indian Ocean, including the sea of China, resulting in the arrival in 1513 of the first European trading ship to the coasts of China, under Jorge Álvares and Rafael Perestrello, sent by Afonso de Albuquerque, and followed by the Fernão Pires de Andrade and Tomé Pires diplomatic and commercial mission of 1517, under the orders of Manuel I of Portugal, which opened formally relations between the Portuguese Empire and the Ming dynasty during the reign of the Zhengde Emperor. The handover of Macau (Macao) to Portugal in 1557 by the Emperor of China (as a reward for services rendered against the pirates who infested the South China Sea) resulted in the first permanent European maritime trade post between Europe and China, with other European powers following suit over the next centuries, which caused the eventual demise of the Silk Road, or its global diversification by trans-oceanic routes, from the western Pacific to the Atlantic Ocean, via the Indian Ocean.
When he sailed West across the Atlantic Ocean in 1492, Christopher Columbus was searching for an alternative trade route to China from Spain. When he discovered America, it was believed he had reached Asia and the search was interrupted. However, the quest for a westward route was resumed a few years later after explorer Nuñez de Balboa crossed the Isthmus of Panama in 1513 and discovered, from there, the Pacific Ocean, proving that this was in fact a New World. The western voyage from Europe to Asia was finally completed with the Spanish expedition of 1519-1522, led by the Portuguese Ferdinand Magellan, the first European voyage to cross the Pacific Ocean, and the first world circumnavigation in a single expedition, finished by 18 men led by Juan Sebastián Elcano. In 1565 Spanish navigator Andrés de Urdaneta discovered a return route across the Pacific, from the Philippines to New Spain, which led to the opening of the first regular transpacific trade route in history: the Manila-Acapulco Galleon route, which lasted two and half centuries, until 1815. This Pacific line was connected overland through Mexico with an Atlantic line, the Spanish West Indies Fleet which in turn linked the Americas with Spain, making the combined route the longest trade route in history until the 19th century, and one of the first examples of globalisation.
The desire to trade directly with China and India was the main driving force behind the expansion of the Portuguese beyond Africa after 1480, and the Spanish across the Pacific Ocean to the Philippines in 1521. Other European powers followed, namely the Netherlands and Britain from the 17th century onwards. In an early attempt, the Netherlands tried to find a route to Asia in 1594 but was unsuccessful. Navigator Willem Barents left Amsterdam with two ships to search for the Northeast passage north of Siberia, on to eastern Asia. He reached the west coast of Novaya Zemlya and followed it northwards, being finally forced to turn back when confronted with its northern extremity. By the end of the 17th century, the Russians re-established a land trade route between Europe and China under the name of the Great Siberian Road.
While the Portuguese (and, subsequently, other Europeans) were entering China from its southern coast, by the sea route, the question arose as to whether it was the same country as Cathay which Marco had reached by the overland route. By c. 1600, the Jesuits stationed in China, led by Matteo Ricci, were pretty sure that it was, but others were not convinced. To check the situation on the ground, Bento de Góis, a Portuguese former soldier and explorer who had joined the Jesuits as a Lay Brother in Goa, India, travelled in 1603–1605 from India via Afghanistan on one of the routes of the traditional Silk Road (via Badakhshan, the Pamirs, Yarkand, Kucha, and Turpan to the border of Ming China in Suzhou, Gansu.
Leibniz, echoing the prevailing perception in Europe until the Industrial Revolution, wrote in the 17th century that: "Everything exquisite and admirable comes from the East Indies... Learned people have remarked that in the whole world there is no commerce comparable to that of China."
New Silk Road.
The Eurasian Land Bridge (a railway through China, Kazakhstan, Mongolia and Russia) is sometimes referred to as the "New Silk Road". The last link in one of these two railway routes was completed in 1990, when the railway systems of China and Kazakhstan connected at Alataw Pass (Alashan Kou). In 2008 the line was used to connect the cities of Ürümqi in China's Xinjiang Province to Almaty and Astana in Kazakhstan. Starting in July 2011 the line has been used by a freight service which connects Chongqing, China with Duisburg, Germany which cuts travel time for cargo from about 36 days by container ship to just 13 days by freight train. , Hewlett-Packard is moving large freight trains of laptop computers and monitors along this rail route.
One Belt, One Road.
In 2013, during a visit to Kazakhstan, Chinese President Xi Jinping introduced a plan for creating a New Silk Road from China to Europe. The latest iterations of this plan, dubbed "One Belt, One Road" (OBOR), includes land-based Silk Road Economic Belt and Maritime Silk Road, with primary points in Ürümqi, Dostyk, Astana, Gomel, Brest, and the Polish cities of Małaszewicze and Łódź, which would be hubs of logistics and transshipment to other countries of Europe. 
On February 15, 2016, with a change in routing, the first train dispatched under the OBOR scheme arrived from eastern Zhejiang Province to Tehran. Though this section does not complete the Silk Road–style overland connection between China and Europe, plans are underway to extend the route past Tehran, through Istanbul, into Europe. The actual route went through Almaty, Bishkek, Samarkand, and Dushanbe.
Routes.
The Silk Road consisted of several routes. As it extended westwards from the ancient commercial centres of China, the overland, intercontinental Silk Road divided into northern and bypassing the Taklimakan Desert and Lop Nur.
Northern route.
The northern route started at Chang'an (now called Xi'an), an ancient capital of China that was moved further east during the Later Han to Luoyang. The route was defined around the 1st century BCE when Han Wudi put an end to harassment by nomadic tribes.
The northern route travelled northwest through the Chinese province of Gansu from Shaanxi Province and split into three further routes, two of them following the mountain ranges to the north and south of the Taklamakan Desert to rejoin at Kashgar, and the other going north of the Tian Shan mountains through Turpan, Talgar, and Almaty (in what is now southeast Kazakhstan). The routes split again west of Kashgar, with a southern branch heading down the Alai Valley towards Termez (in modern Uzbekistan) and Balkh (Afghanistan), while the other travelled through Kokand in the Fergana Valley (in present-day eastern Uzbekistan) and then west across the Karakum Desert. Both routes joined the main southern route before reaching ancient Merv, Turkmenistan. Another branch of the northern route turned northwest past the Aral Sea and north of the Caspian Sea, then and on to the Black Sea.
A route for caravans, the northern Silk Road brought to China many goods such as "dates, saffron powder and pistachio nuts from Persia; frankincense, aloes and myrrh from Somalia; sandalwood from India; glass bottles from Egypt, and other expensive and desirable goods from other parts of the world." In exchange, the caravans sent back bolts of silk brocade, lacquer-ware, and porcelain.
Southern route.
The southern route or Karakoram route was mainly a single route running from China through the Karakoram mountains, where it persists in modern times as the international paved road connecting Pakistan and China as the Karakoram Highway. It then set off westwards, but with southward spurs enabling the journey to be completed by sea from various points. Crossing the high mountains, it passed through northern Pakistan, over the Hindu Kush mountains, and into Afghanistan, rejoining the northern route near Merv, Turkmenistan. From Merv, it followed a nearly straight line west through mountainous northern Iran, Mesopotamia, and the northern tip of the Syrian Desert to the Levant, where Mediterranean trading ships plied regular routes to Italy, while land routes went either north through Anatolia or south to North Africa. Another branch road travelled from Herat through Susa to Charax Spasinu at the head of the Persian Gulf and across to Petra and on to Alexandria and other eastern Mediterranean ports from where ships carried the cargoes to Rome.
Southwestern route.
The southwestern route is believed to be the Ganges/Brahmaputra Delta, which has been the subject of international interest for over two millennia. Strabo, the 1st-century Roman writer, mentions the deltaic lands: "Regarding merchants who now sail from Egypt...as far as the Ganges, they are only private citizens..." His comments are interesting as Roman beads and other materials are being found at Wari-Bateshwar ruins, the ancient city with roots from much earlier, before the Bronze Age, presently being slowly excavated beside the Old Brahmaputra in Bangladesh. Ptolemy's map of the Ganges Delta, a remarkably accurate effort, showed that his informants knew all about the course of the Brahmaputra River, crossing through the Himalayas then bending westward to its source in Tibet. It is doubtless that this delta was a major international trading center, almost certainly from much earlier than the Common Era. Gemstones and other merchandise from Thailand and Java were traded in the delta and through it. Chinese archaeological writer Bin Yang and some earlier writers and archaeologists, such as Janice Stargardt, strongly suggest this route of international trade as Sichuan-Yunnan-Burma-Bangladesh route. According to Bin Yang, especially from the 12th century the route was used to ship bullion from Yunnan (gold and silver are among the minerals in which Yunnan is rich), through northern Burma, into modern Bangladesh, making use of the ancient route, known as the 'Ledo' route. The emerging evidence of the ancient cities of Bangladesh, in particular Wari-Bateshwar ruins, Mahasthangarh, Bhitagarh, Bikrampur, Egarasindhur, and Sonargaon, are believed to be the international trade centers in this route.
Cultural exchanges.
Richard Foltz, Xinru Liu, and others have described how trading activities along the Silk Road over many centuries facilitated the transmission not just of goods but also ideas and culture, notably in the area of religions. Zoroastrianism, Judaism, Buddhism, Christianity, Manichaeism, and Islam all spread across Eurasia through trade networks that were tied to specific religious communities and their institutions. Notably, established Buddhist monasteries along the Silk Road offered a haven, as well as a new religion for foreigners. The spread of religions and cultural traditions along the Silk Roads, according to Jerry H. Bentley, also led to syncretism. One example was the encounter with the Chinese and Xiongnu nomads. These unlikely events of cross-cultural contact allowed both cultures to adapt to each other as an alternative. The Xiongnu adopted Chinese agricultural techniques, dress style, and lifestyle. On the other hand, the Chinese adopted Xiongnu military techniques, some dress style, and music and dance.
Of all the cultural exchanges between China and the Xiongnu, the defection of Chinese soldiers was perhaps the most surprising. They would sometimes convert to the Xiongnu way of life and stay in the steppes for fear of punishment.
Transmission of Buddhism.
The transmission of Buddhism to China via the Silk Road began in the 1st century CE, according to a semi-legendary account of an ambassador sent to the West by the Chinese Emperor Ming (58–75). During this period Buddhism began to spread throughout Southeast, East, and Central Asia. Mahayana, Theravada, and Tibetan Buddhism are the three primary forms of Buddhism that spread, through the Silk Road, across Asia.
The Buddhist movement was the first large-scale missionary movement in the history of world religions. Chinese missionaries were able to assimilate Buddhism, to an extent, to native Chinese Daoists, which would bring the two beliefs together. Buddha's community of followers, the Sangha, consisted of male and female monks and laity. These people moved through India and beyond to spread the ideas of Buddha. As the number of members within the Sangha increased, it became costly so that only the larger cities were able to afford having the Buddha and his disciples visit . It is believed that under the control of the Kushans, within the middle of the first century to the middle of the third century, Buddhism was spread by the Silk Road to China as well as other parts of Asia. Extensive contacts started in the 2nd century, probably as a consequence of the expansion of the Kushan empire into the Chinese territory of the Tarim Basin, due to the missionary efforts of a great number of Buddhist monks to Chinese lands. The first missionaries and translators of Buddhists scriptures into Chinese were either Parthian, Kushan, Sogdian or Kuchean.
One result of the spread of Buddhism along the Silk Road was displacement and conflict. The Greek Seleucids were exiled to Iran and Central Asia because of a new Iranian Dynasty called the Parthians at the beginning of the 2nd century BCE, and as a result the Parthians became the new middle men for trade in a period when the Romans were major customers for silk. The Parthian scholars were involved in one of the first ever Buddhist text translations into the Chinese language, its main trade centre on the Silk Road, the city of Merv, in due course and with the coming of age of Buddhism in China, became a major Buddhist centre by the middle of the 2nd century. Knowledge among people on the silk roads also increased when Emperor Ashoka of the Maurya dynasty (268–239 BCE) converted to Buddhism and raised the religion to official status in his northern Indian empire.
From the 4th century CE onward, Chinese pilgrims also started to travel on the Silk Road to India, in order to get improved access to the original Buddhist scriptures, with Fa-hsien's pilgrimage to India (395–414), and later Xuanzang (629–644) and Hyecho, who traveled from Korea to India. The travels of the priest Xuanzang were fictionalized in the 16th century in a fantasy adventure novel called "Journey to the West", which told of trials with demons and the aid given by various disciples on the journey.
There were many different schools of Buddhism travelling on the Silk Road. The Dharmaguptakas and the Sarvastivadins were two of the major Nikaya schools. These were both eventually displaced by the Mahayana, also known as "Great Vehicle". This movement of Buddhism first gained influence in the Khotan region. The Mahayana, which was more of a "pan-Buddhist movement" than a school of Buddhism, appears to have begun in north western India or Central Asia. It was small at first and formed during the 1st century BCE, and the origins of this "Greater Vehicle" are not fully clear. Some Mahayana scripts were found in northern Pakistan but the main texts are still believed to have been composed in Central Asia along the Silk Road. These different schools and movements of Buddhism were a result of the diverse and complex influences and beliefs on the Silk Road. With the rise of Mahayana Buddhism, the initial direction of Buddhist development changed. This form of Buddhism highlighted, as stated by Xinru Liu "the elusiveness of physical reality, including material wealth." It also stressed getting rid of material desire to a certain point; this was often difficult for followers to understand.
During the 5th and 6th centuries CE, Merchants played a large role in the spread of religion, in particular Buddhism. Merchants found the moral and ethical teachings of Buddhism to be an appealing alternative to previous religions. As a result, Merchants supported Buddhist Monasteries along the Silk Roads and in return the Buddhists gave the Merchants somewhere to stay as they traveled from city to city. As a result, Merchants spread Buddhism to foreign encounters as they traveled. Merchants also helped to establish diaspora within the communities they encountered and over time their cultures became based on Buddhism. Because of this, these communities became centers of literacy and culture with well-organized marketplaces, lodging, and storage. The voluntary conversion of Chinese ruling elites helped the spread of Buddhism in East Asia. Thus, it allowed Buddhism to become widespread in Chinese society. The Silk Road transmission of Buddhism essentially ended around the 7th century with the rise of Islam in Central Asia.
Transmission of art.
Many artistic influences were transmitted via the Silk Road, particularly through Central Asia, where Hellenistic, Iranian, Indian and Chinese influences could intermix. Greco-Buddhist art represents one of the most vivid examples of this interaction. Silk was also a representation of art. This is because silk served as a religious symbol, and most importantly, silk was used as currency for trade along the silk road.
These artistic influences can be seen in the development of Buddhism where for instance, Buddha was first depicted as human in the Kushan period. Many scholars have attributed this to Greek influence. The mixture of Greek and Indian elements can be found in later Buddhist art in China and throughout countries on the Silk Road.
Commemoration.
Since 1993 the United Nations World Tourism Organization has been working to develop sustainable international tourism along the route with the stated goal of fostering peace and understanding.
Both Bishkek and Almaty now have a major east-west street named after the Silk Road (, "Jibek Jolu" in Bishkek, and , "Jibek Joly" in Almaty). On June 22, 2014, the United Nations Educational, Scientific and Cultural Organization (UNESCO) named the Silk Road a World Heritage Site at the 2014 Conference on World Heritage.
In popular culture.
The name "Silk Road" and derivations thereof have been used in many contexts (see Silk Road (disambiguation)). For example:

</doc>
<doc id="54255" url="https://en.wikipedia.org/wiki?curid=54255" title="Euphorbiales">
Euphorbiales

Euphorbiales is the botanical name of an order of flowering plants that is not currently recognized in the most authoritative modern treatment of plant taxonomy. In the APG II system (2003) the plants involved are placed in order Malpighiales. 
A well known system that did recognize the order was the Cronquist system (1981) which placed the order in subclass Rosidae and used this circumscription:

</doc>
<doc id="54256" url="https://en.wikipedia.org/wiki?curid=54256" title="Cementation">
Cementation

Cementation may refer to:

</doc>
<doc id="54257" url="https://en.wikipedia.org/wiki?curid=54257" title="Desktop publishing">
Desktop publishing

Desktop publishing (abbreviated DTP) is the creation of documents using page layout skills on a personal computer. Desktop publishing software can generate layouts and produce typographic quality text and images comparable to traditional typography and printing. This technology allows individuals, businesses, and other organizations to self-publish a wide range of printed matter. Desktop publishing is also the main reference for digital typography. When used skillfully, desktop publishing allows the user to produce a wide variety of materials, from menus to magazines and books, without the expense of commercial printing.
Desktop publishing combines a personal computer and WYSIWYG page layout software to create publication documents on a computer for either large scale publishing or small scale local multifunction peripheral output and distribution. Desktop publishing methods provide more control over design, layout, and typography than word processing. However, word processing software has evolved to include some, though by no means all, capabilities previously available only with professional printing or desktop publishing.
The same DTP skills and software used for common paper and book publishing are sometimes used to create graphics for point of sale displays, promotional items, trade show exhibits, retail package designs and outdoor signs. Although what is classified as "DTP software" is usually limited to print and PDF publications, DTP skills aren't limited to print. The content produced by desktop publishers may also be exported and used for electronic media. The job descriptions that include "DTP", such as DTP artist, often require skills using software for producing e-books, web content, and web pages, which may involve web design or user interface design for any graphical user interface.
History.
Desktop publishing began in 1983 with a program developed by James Davise at a community newspaper in Philadelphia. That program, Type Processor One, ran on a PC using a graphics card for a WYSIWYG display and was offered commercially by Best info in 1984. (Desktop "typesetting", with only limited page makeup facilities, had arrived in 1978–9 with the introduction of TeX, and was extended in the early 1980s by LaTeX.) The DTP market exploded in 1985 with the introduction in January of the Apple LaserWriter printer, and later in July with the introduction of PageMaker software from Aldus which rapidly became the DTP industry standard software. later on Adobe PageMaker overtook microsoft word in prodetional DTP in 1885.
The term "desktop publishing" is attributed to Aldus Corporation founder Paul Brainerd, who sought a marketing catch-phrase to describe the small size and relative affordability of this suite of products in contrast to the expensive commercial phototypesetting equipment of the day.
Before the advent of desktop publishing, the only option available to most people for producing typed (as opposed to handwritten) documents was a typewriter, which offered only a handful of typefaces (usually fixed-width) and one or two font sizes. Indeed, one popular desktop publishing book was actually titled "The Mac is not a typewriter". The ability to create WYSIWYG page layouts on screen and then print pages containing text and graphical elements at crisp 300 dpi resolution was revolutionary for both the typesetting industry and the personal computer industry. Newspapers and other print publications made the move to DTP-based programs from older layout systems like Atex and other such programs in the early 1980s. 
By the standards of today, early desktop publishing was a primitive affair. Users of the PageMaker-LaserWriter-Macintosh 512K system endured frequent software crashes, cramped display on the Mac's tiny 512 x 342 1-bit monochrome screen, the inability to control letter-spacing, kerning (the addition or removal of space between individual characters in a piece of typeset text to improve its appearance or alter its fit) and other typographic features, and discrepancies between the screen display and printed output. However, it was a revolutionary combination at the time, and was received with considerable acclaim.
Behind-the-scenes technologies developed by Adobe Systems set the foundation for professional desktop publishing applications. The LaserWriter and LaserWriter Plus printers included high quality, scalable Adobe PostScript fonts built into their ROM memory. The LaserWriter's PostScript capability allowed publication designers to proof files on a local printer then print the same file at DTP service bureaus using optical resolution 600+ ppi PostScript printers such as those from Linotronic. Later, the Macintosh II was released which was much more suitable for desktop publishing because of its greater expandability, support for large color multi-monitor displays, and its SCSI storage interface which allowed fast high-capacity hard drives to be attached to the system.
Although Macintosh-based systems would continue to dominate the market, in 1986, the GEM-based Ventura Publisher was introduced for MS-DOS computers. While PageMaker's pasteboard metaphor closely simulated the process of creating layouts manually, Ventura Publisher automated the layout process through its use of tags/style sheets and automatically generated indices and other body matter. This made it suitable for manuals and other long-format documents. Desktop publishing moved into the home market in 1986 with Professional Page for the Amiga, Publishing Partner (now PageStream) for the Atari ST, GST's Timeworks Publisher on the PC and Atari ST and Calamus for the Atari TT030. Even for 8-bit computers like the Apple II and Commodore 64 software was published: Home Publisher, The Newsroom and geoPublish.
During its early years, desktop publishing acquired a bad reputation as a result of untrained users who created poorly organized ransom note effect layouts — similar criticism would be levied again against early World Wide Web publishers a decade later. However, some were able to realize truly professional results.
Once considered a primary skill, increased accessibility to more user-friendly DTP software has made DTP a secondary skill to art direction, graphic design, multimedia development, marketing communications, and administrative careers. DTP skill levels range from what may be learned in a few hours (e.g. learning how to put clip art in a word processor) to what requires a college education. The discipline of DTP skills range from technical skills such as prepress production and programming to creative skills such as communication design and graphic image development.
Terminology.
There are two types of pages in desktop publishing, electronic pages and virtual paper pages to be printed on physical paper pages. All computerized documents are technically electronic, which are limited in size only by computer memory or computer data storage space.
Virtual paper pages will ultimately be printed, and therefore require paper parameters that coincide with international standard physical paper sizes such as "A4," "letter," etc., if not custom sizes for trimming. Some desktop publishing programs allow custom sizes designated for large format printing used in posters, billboards and trade show displays. A virtual page for printing has a predesignated size of virtual printing material and can be viewed on a monitor in WYSIWYG format. Each page for printing has trim sizes (edge of paper) and a printable area if bleed printing is not possible as is the case with most desktop printers.
A web page is an example of an electronic page that is not constrained by virtual paper parameters. Most electronic pages may be dynamically re-sized, causing either the content to scale in size with the page or causing the content to re-flow.
Master pages are templates used to automatically copy or link elements and graphic design styles to some or all the pages of a multipage document. Linked elements can be modified without having to change each instance of an element on pages that use the same element. Master pages can also be used to apply graphic design styles to automatic page numbering. Cascading Style Sheets can provide the same global formatting functions for web pages that master pages provide for virtual paper pages.
Page layout is the process by which the elements are laid on the page orderly, aesthetically, and precisely. Main types of components to be laid out on a page include text, linked images that can only be modified as an external source, and embedded images that may be modified with the layout application software. Some embedded images are rendered in the application software, while others can be placed from an external source image file. Text may be keyed into the layout, placed, or (with database publishing applications) linked to an external source of text which allows multiple editors to develop a document at the same time.
Graphic design styles such as color, transparency, and filters, may also be applied to layout elements. Typography styles may be applied to text automatically with style sheets. Some layout programs include style sheets for images in addition to text. Graphic styles for images may be border shapes, colors, transparency, filters, and a parameter designating the way text flows around the object called "wraparound" or "runaround."
Comparisons.
With word processing.
While desktop publishing software still provides extensive features necessary for print publishing, modern word processors now have publishing capabilities beyond those of many older DTP applications, blurring the line between word processing and desktop publishing.
In the early days of graphical user interfaces, DTP software was in a class of its own when compared to the fairly spartan word processing applications of the time. Programs such as WordPerfect and WordStar were still mainly text-based and offered little in the way of page layout, other than perhaps margins and line spacing. On the other hand, word processing software was necessary for features like indexing and spell checking, features that are common in many applications today.
As computers and operating systems have become more powerful, vendors have sought to provide users with a single application platform that can meet all needs.
With other electronic layout software.
In modern usage, DTP is not generally said to include tools such as TeX or troff, though both can easily be used on a modern desktop system and are standard with many Unix-like operating systems and readily available for other systems. The key difference between electronic typesetting software and DTP software is that DTP software is generally interactive and WYSIWYG in design, while other electronic typesetting software, such as TeX, LaTeX and other variants, tends to operate in batch mode, requiring the user to enter the processing program's markup language without immediate visualization of the finished product. 
This kind of workflow is less user-friendly than WYSIWYG, but more suitable for conference proceedings and scholarly articles as well as corporate newsletters or other applications where consistent, automated layout is important. Recent interactive front-ends to TeX such as TeXworks or LyX have produced WYSIWYM (what you see is what you mean) hybrids of DTP and batch processing, focussed more on semantics than traditional DTP.
There is some overlap between desktop publishing and what is known as Hypermedia publishing (i.e. Web design, Kiosk, CD-ROM). Many graphical HTML editors such as Microsoft FrontPage and Adobe Dreamweaver use a layout engine similar to a DTP program. However, some Web designers still prefer to write HTML without the assistance of a WYSIWYG editor, for greater control and because these editors often result in code bloat.
File formats.
The industry standard is Encapsulated Postscript. Publisher is common for home users.
Further reading.
An early (and comprehensive) reference book on the art of desktop publishing is "Desktop Publishing For Everyone" by K.S.V. Menon. This publication deals with virtually every facet of publishing and nearly all tools available at the time (2000). It is currently out of print.

</doc>
<doc id="54259" url="https://en.wikipedia.org/wiki?curid=54259" title="Hamamelidales">
Hamamelidales

Hamamelidales is an order of flowering plants formerly accepted in a number of systems of plant taxonomy, including the Cronquist system published in 1968 and 1988. The order is not currently accepted in the Angiosperm Phylogeny Group III system of plant taxonomy, the most widely accepted system as molecular systematic studies have suggested that these families are not closely related to each other. The APG II system (2003) assigns them to several different orders: Hamamelidaceae and Cercidiphyllaceae to Saxifragales, Eupteleaceae to Ranunculales, Platanaceae to Proteales, and Myrothamnaceae to Gunnerales. Additional studies of the chloroplast genome have since confirmed that the families moved into the Saxigragales are closely related.
The Cronquist system (1981) included the order in subclass Hamamelidae with the circumscription:

</doc>
<doc id="54261" url="https://en.wikipedia.org/wiki?curid=54261" title="Nymphaeales">
Nymphaeales

Nymphaeales is an order of flowering plants, consisting of three families of aquatic plants, the Hydatellaceae, the Cabombaceae, and the Nymphaeaceae (water lilies). It is one of the three orders of basal angiosperms, an early-diverging grade of flowering plants. At least 10 morphological characters unite the Nymphaeales. Molecular synapomorphies are also known.
The Plant List, created by the Royal Botanic Gardens, Kew and Missouri Botanical Garden recognizes about 70 species in 11 genera within the order, but a phylogenetic study of the genus "Nymphaea" implies that the number of species could be more than 90. The difference in species numbers is due almost entirely to the difficulty of delineating species in the genus "Nymphaea".
All of the species are rhizomatous aquatic herbs with a broad leaf base and large showy flowers.
Fossils.
The fossil record consists especially of seeds, but also pollen, stems, leaves, and flowers. It extends back to the Cretaceous. The crown group of Nymphaeales has been estimated to be about 112 million years old. Some have suggested that this age might be too old.
It is possible that the aquatic plant fossil "Archaefructus" belongs to this group.
Classification.
The Nymphaeales currently includes three families and about 70 to 90 species.
This order was not part of the APG II system's 2003 plant classification (unchanged from the APG system of 1998), which instead had a broadly circumscribed family Nymphaeaceae (including Cabombaceae) unplaced in any order. The APG III system did separate Cabombaceae from Nymphaeaceae and placed them in the order Nymphaeales together with Hydatellaceae. This Hydatellaceae was placed among the monocots in previous systems, but a 2007 study found that the family belongs to Nymphaeales.
Some earlier systems, such as Cronquist's system of 1981, often included the Ceratophyllaceae and Nelumbonaceae in the Nymphaeales. Although, the Takhtajan system of 1980 separated the Nelumbonales, the new order was retained alongside the Nymphaeales in the superorder Nymphaeanae.
The Cronquist system placed the Nymphaeales in subclass Magnoliidae, in class Magnoliopsida [=dicotyledons]. In addition, Cronquist included the Ceratophyllaceae and split the family Barclayaceae from the Nymphaeaceae. Under the APG II system, the family Cambombaceae was included within the Nymphaeaceae, but could optionally be recognized separately. As of APG III, the two families are recognized separately.
The Dahlgren system placed Nymphaeales together with the Piperales in superorder Nymphaeanae, within subclass Magnoliideae (dicotyledons). Thorne's 1992 system (and 2000 revision) placed Nymphaeales as the sole order in the superorder Nymphaeanae within subclass Magnoliideae (=dicotyledons).

</doc>
<doc id="54266" url="https://en.wikipedia.org/wiki?curid=54266" title="Partition function">
Partition function

Partition function may refer to:

</doc>
<doc id="54267" url="https://en.wikipedia.org/wiki?curid=54267" title="Floor and ceiling functions">
Floor and ceiling functions

In mathematics and computer science, the floor and ceiling functions map a real number to the largest previous or the smallest following integer, respectively. More precisely, floor("x") = formula_1 is the largest integer less than or equal to "x" and ceiling("x") = formula_2 is the smallest integer greater than or equal to "x".
Notation.
Carl Friedrich Gauss introduced the square bracket notation formula_3 for the floor function in his third proof of quadratic reciprocity (1808).
This remained the standard in mathematics until Kenneth E. Iverson introduced the names "floor" and "ceiling" and the corresponding notations formula_1 and formula_5 in his 1962 book "A Programming Language". Both notations are now used in mathematics; this article follows Iverson.
The floor function is also called the greatest integer or entier (French for "integer") function, and its value at "x" is called the integral part or integer part of "x"; for negative values of "x" the latter terms are sometimes instead taken to be the value of the "ceiling" function, i.e., the value of "x" rounded to an integer towards 0. The language APL uses codice_1; other computer languages commonly use notations like codice_2 (ALGOL), codice_3 (BASIC), or codice_4(C, C++, R, and Python). In mathematics, it can also be written with boldface or double brackets formula_6 or just using normal reversed brackets ]"x"[.
The fractional part is the sawtooth function, denoted by formula_7 for real "x" and defined by the formula
For all "x",
Typesetting.
The floor and ceiling functions are usually typeset with left and right square brackets where the upper (for floor function) or lower (for ceiling function) horizontal bars are missing, and, e.g., in the LaTeX typesetting system these symbols can be specified with the \lfloor, \rfloor, \lceil and \rceil commands in math mode. HTML 4.0 uses the same names: "&lfloor;", "&rfloor;", "&lceil;", and "&rceil;". Unicode contains codepoints for these symbols at codice_9–codice_10: , .
Definition and properties.
In the following formulas, "x" and "y" are real numbers, "k", "m", and "n" are integers, and formula_10 is the set of integers (positive, negative, and zero).
Floor and ceiling may be defined by the set equations
Since there is exactly one integer in a half-open interval of length one, for any real "x" there are unique integers "m" and "n" satisfying
Then  formula_14  and  formula_15
 may also be taken as the definition of floor and ceiling.
Equivalences.
These formulas can be used to simplify expressions involving floors and ceilings.
In the language of order theory, the floor function is a residuated mapping, that is, part of a Galois connection: it is the upper adjoint of the function that embeds the integers into the reals.
These formulas show how adding integers to the arguments affect the functions:
The above are never true if "n" is not an integer; however:
Relations among the functions.
It is clear from the definitions that
In fact, for integers "n":
Negating the argument switches floor and ceiling and changes the sign:
and:
Negating the argument complements the fractional part:
The floor, ceiling, and fractional part functions are idempotent:
The result of nested floor or ceiling functions is the innermost function:
For fixed "y", "x" mod "y" is idempotent:
Also, from the definitions,
Quotients.
If "m" and "n" are integers and "n" ≠ 0,
If "n" is positive
If "m" is positive
For "m" = 2 these imply
More generally, for positive "m" (See Hermite's identity)
The following can be used to convert floors to ceilings and vice versa ("m" positive)
If "m" and "n" are positive and coprime, then
Since the right-hand side is symmetrical in "m" and "n", this implies that
More generally, if "m" and "n" are positive,
This is sometimes called a reciprocity law.
Nested divisions.
For positive integer "n", and arbitrary real numbers "m","x":
Continuity.
None of the functions discussed in this article are continuous, but all are piecewise linear. formula_46  and formula_47 are piecewise constant functions, with discontinuities at the integers. formula_48 also has discontinuities at the integers, and   formula_49 as a function of "x" for fixed "y" is discontinuous at multiples of "y".
formula_46  is upper semi-continuous and  formula_47  and formula_52  are lower semi-continuous. "x" mod "y" is lower semicontinuous for positive "y" and upper semi-continuous for negative "y".
Series expansions.
Since none of the functions discussed in this article are continuous, none of them have a power series expansion. Since floor and ceiling are not periodic, they do not have uniformly convergent Fourier series expansions.
"x" mod "y" for fixed "y" has the Fourier series expansion
in particular {"x"} = "x" mod 1 is given by
At points of discontinuity, a Fourier series converges to a value that is the average of its limits on the left and the right, unlike the floor, ceiling and fractional part functions: for "y" fixed and "x" a multiple of "y" the Fourier series given converges to "y"/2, rather than to "x" mod "y" = 0. At points of continuity the series converges to the true value.
Using the formula {x} = x − floor(x), floor(x) = x − {x} gives
Applications.
Mod operator.
For an integer "x" and a positive integer "y", the modulo operation, denoted by "x" mod "y", gives the value of the remainder when "x" is divided by "y". This definition can be extended to real "x" and "y", "y" ≠ 0, by the formula
Then it follows from the definition of floor function that this extended operation satisfies many natural properties. Notably, "x" mod "y" is always between 0 and "y", i.e.,
if "y" is positive,
and if "y" is negative,
Quadratic reciprocity.
Gauss's third proof of quadratic reciprocity, as modified by Eisenstein, has two basic steps.
Let "p" and "q" be distinct positive odd prime numbers, and let
First, Gauss's lemma is used to show that the Legendre symbols are given by
and
The second step is to use a geometric argument to show that
Combining these formulas gives quadratic reciprocity in the form
There are formulas that use floor to express the quadratic character of small numbers mod odd primes "p":
Rounding.
For an arbitrary real number formula_66, rounding formula_66 to the nearest integer with tie breaking towards positive infinity is given by formula_68; rounding towards negative infinity is given as formula_69. If tie-breaking is away from 0, then the rounding function is formula_70, and rounding towards even, as is usual in the nearest integer function, can be expressed with the more cumbersome formula_71, which is the expression for rounding towards positive infinity minus an integrality indicator for formula_72.
Truncation.
The truncation of a nonnegative number is given by formula_73 The truncation of a nonpositive number is given by formula_47.
The truncation of any real number can be given by: formula_75, where sgn(x) is the sign function.
Number of digits.
The number of digits in base "b" of a positive integer "k" is
Factors of factorials.
Let "n" be a positive integer and "p" a positive prime number. The exponent of the highest power of "p" that divides "n"! is given by the formula
where formula_78 is the way of writing "n" in base "p". Note that this is a finite sum, since the floors are zero when "p""k" > "n".
Beatty sequence.
The Beatty sequence shows how every positive irrational number gives rise to a partition of the natural numbers into two sequences via the floor function.
Euler's constant (γ).
There are formulas for Euler's constant γ = 0.57721 56649 ... that involve the floor and ceiling, e.g.
and
Riemann function (ζ).
The fractional part function also shows up in integral representations of the Riemann zeta function. It is straightforward to prove (using integration by parts) that if φ("x") is any function with a continuous derivative in the closed interval ["a", "b"],
Letting φ("n") = "n"−s for real part of "s" greater than 1 and letting "a" and "b" be integers, and letting "b" approach infinity gives
This formula is valid for all "s" with real part greater than −1, (except "s" = 1, where there is a pole) and combined with the Fourier expansion for {"x"} can be used to extend the zeta function to the entire complex plane and to prove its functional equation.
For "s" = σ + "i t" in the critical strip (i.e. 0 < σ < 1),
In 1947 van der Pol used this representation to construct an analogue computer for finding roots of the zeta function.
Formulas for prime numbers.
"n" is a prime if and only if
Let "r" > 1 be an integer, "p""n" be the "n"th prime, and define
Then
There is a number θ = 1.3064... (Mills' constant) with the property that
are all prime.
There is also a number ω = 1.9287800... with the property that
are all prime.
π("x") is the number of primes less than or equal to "x". It is a straightforward deduction from Wilson's theorem that
Also, if "n" ≥ 2,
None of the formulas in this section is of any practical use.
Solved problem.
Ramanujan submitted this problem to the "Journal of the Indian Mathematical Society".
If "n" is a positive integer, prove that
(i)     formula_92
(ii)     formula_93
(iii)     formula_94
Unsolved problem.
The study of Waring's problem has led to an unsolved problem:
Are there any positive integers "k" ≥ 6 such that
Mahler has proved there can only be a finite number of such "k"; none are known.
Computer implementations.
Many programming languages (including C, C++, PHP, and Python) provide standard functions for floor and ceiling.
Spreadsheet software.
Most spreadsheet programs support some form of a codice_11 function. Although the details differ between programs, most implementations support a second parameter—a multiple of which the given number is to be rounded to. For example, codice_12 rounds 2 up to the nearest multiple of 3, giving 3. The definition of what "round up" means, however, differs from program to program.
Until Excel 2010, Microsoft Excel's codice_11 function was incorrect for negative arguments; ceiling(-4.5) was -5. This has followed through to the Office Open XML file format. The correct ceiling function can be implemented using "codice_14". Excel 2010 now follows the standard definition.
The OpenDocument file format, as used by OpenOffice.org and others, follows the mathematical definition of ceiling for its codice_11 function, with an optional parameter for Excel compatibility. For example, codice_16 returns −4.

</doc>
<doc id="54268" url="https://en.wikipedia.org/wiki?curid=54268" title="John Paul Jones (musician)">
John Paul Jones (musician)

John Baldwin (born 3 January 1946), better known by his stage name John Paul Jones, is an English multi-instrumentalist, songwriter, composer, arranger and record producer. Best known as the bassist, keyboardist, and co-songwriter for the English rock band Led Zeppelin, Jones has since developed a solo career. A versatile musician, Jones also plays organ, guitar, koto, lap steel guitars, mandolin, autoharp, violin, ukulele, sitar, cello, continuum and recorder.
According to AllMusic, Jones "has left his mark on rock & roll music history as an innovative musician, arranger, and director." Jones is part of the band Them Crooked Vultures with Josh Homme and Dave Grohl, in which he plays bass guitar, keyboards, and other instruments. In 2014, Jones ranked first on "Paste" magazine's list of "20 Most Underrated Bass Guitarists."
Biography.
Early years.
John Baldwin was born in Sidcup, Kent. He started playing piano at age six, learning from his father, Joe Baldwin, a pianist and arranger for big bands in the 1940s and 1950s, notably with Ambrose and his Orchestra. His mother was also in the music business which allowed the family to often perform together touring around England as a vaudeville comedy act. His influences ranged from the blues of Big Bill Broonzy, the jazz of Charles Mingus, to the classical piano of Sergei Rachmaninoff.
Because his parents often toured, Jones was sent to boarding school at a young age. He was a student at Christ's College, Blackheath, London where he formally studied music. At the age of 14, Jones became choirmaster and organist at a local church and during that year, he also bought his first bass guitar, a Dallas Tuxedo solid body electric followed by multiple basses in which he part exchanged until he finally bought his 1962 Fender Jazz Bass which he used until 1976. The fluid playing of Chicago musician Phil Upchurch on his "You Can't Sit Down" LP, which includes a memorable bass solo, is cited by Jones as being his inspiration to take up the instrument.
Session work.
Jones joined his first band, The Deltas, at 15. He then played bass for jazz-rock London group, Jett Blacks, a collective that included guitarist John McLaughlin. Jones' big break came in 1962 when he was hired by Jet Harris and Tony Meehan of the successful British group The Shadows for a two-year stint. Shortly before hiring Jones, Harris and Meehan had just had a Number 1 hit with "Diamonds" (a track on which Jones' bandmate-to-be Jimmy Page had played.) Jones' collaboration with the Shadows nearly prevented the future formation of Led Zeppelin, when the parties engaged in talks about the possibility of Jones replacing their bassist Brian Locking, who left the band in October 1963, but John Rostill was ultimately chosen to fill the position.
In 1964, on the recommendation of Meehan, Jones began studio session work with Decca Records. From then until 1968, he played on hundreds of recording sessions. He soon expanded his studio work by playing keyboards, arranging and undertaking general studio direction, resulting in his services coming under much demand. He worked with numerous artists including the Rolling Stones on "Their Satanic Majesties Request" (Jones' string arrangement is heard on "She's a Rainbow"); Herman's Hermits; Donovan (on "Sunshine Superman," "Hurdy Gurdy Man," and "Mellow Yellow"); Jeff Beck; Françoise Hardy; Cat Stevens; Rod Stewart; Shirley Bassey; Lulu; and numerous others. As well as recording sessions with Dusty Springfield, Jones also played bass for her "Talk of the Town" series of performances. His arranging and playing on Donovan's "Sunshine Superman" resulted in producer Mickie Most using his services as choice arranger for many of his own projects, with Tom Jones, Nico, Wayne Fontana, the Walker Brothers, and many others. Such was the extent of Jones' studio work – amounting to hundreds of sessions – that he said years later that "I can't remember three-quarters of the sessions I was on."
It was during his time as a session player that Jones adopted the stage name John Paul Jones. This name was suggested to him by a friend, Andrew Loog Oldham, who had seen a poster for the film "John Paul Jones" in France. He released his first solo recording as John Paul Jones, "Baja" (written by Lee Hazlewood and produced by Oldham) / "A Foggy Day in Vietnam", as a single on Pye Records in April 1964.
Jones has stated that, as a session musician, he was completing two and three sessions a day, six and seven days a week. However, by 1968 he was quickly feeling burnt out due to the heavy workload: "I was arranging 50 or 60 things a month and it was starting to kill me."
Led Zeppelin.
Formation.
During his time as a session player, Jones often crossed paths with guitarist Jimmy Page, a fellow session veteran. In June 1966, Page joined The Yardbirds, and in 1967 Jones contributed to that band's "Little Games" album. The following winter, during the sessions for Donovan's "The Hurdy Gurdy Man", Jones expressed to Page a desire to be part of any projects the guitarist might be planning. Later that year, The Yardbirds disbanded, leaving Page and bassist Chris Dreja to complete previously booked Yardbirds dates in Scandinavia. Before a new band could be assembled, Dreja left to take up photography. Jones, at the suggestion of his wife, asked Page about the vacant position, and the guitarist eagerly invited Jones to collaborate. Page later explained:
Vocalist Robert Plant and drummer John Bonham joined the two to form a quartet. Initially dubbed the "New Yardbirds" for the Scandinavian dates, the band soon became known as Led Zeppelin.
Contribution to the band.
Jones was responsible for the classic bass lines of the group, notably those in "Ramble On" and "The Lemon Song" ("Led Zeppelin II"), and shifting time signatures, such as those in "Black Dog" ("Led Zeppelin IV"). As half of Led Zeppelin's rhythm section with drummer John Bonham, Jones shared an appreciation for funk and soul rhythmic grooves which strengthened and enhanced their musical affinity. In an interview he gave to "Global Bass" magazine, Jones remarked on this common musical interest:
After retiring his Fender Jazz Bass (which he had been using since his days with The Shadows in the early 1960s) from touring in 1975, Jones switched to using custom-designed Alembic basses while touring. However, he still preferred to use the Jazz Bass in the studio.
Jones' keyboard skills added an eclectic dimension that realised Led Zeppelin as more than just a hard rock band. Keyboard highlights include the delicate "The Rain Song" ("Houses of the Holy") played on a Mellotron; the funky "Trampled Under Foot", played on a Clavinet ("Physical Graffiti"); and the eastern scales of "Kashmir", also played on a Mellotron (also on "Physical Graffiti"). In live performances, Jones' keyboard showpiece was "No Quarter", often lasting for up to half-an-hour and sometimes including snatches of "Amazing Grace", Joaquín Rodrigo's "Concierto de Aranjuez", which had inspired Miles Davis' "Sketches of Spain", and variations of classical pieces by composers such as Rachmaninoff.
Jones' diverse contributions to the group extended to the use of other instruments, including an unusual triple-necked acoustic instrument consisting of a six and a twelve string guitar, and a mandolin. Jones often used bass pedals to supplement the band's sound while he was playing keyboards and mandolin. On the band's 1977 tour of the United States, Jones would sing lead vocals on "The Battle of Evermore," filling in for Sandy Denny who sang on the studio version.
Profile.
While all members of Led Zeppelin had a reputation for off-stage excess (a label that has been claimed was exaggerated), Jones was widely seen as the most quiet and reserved member of the group. For his part, Jones has claimed that he had just as much fun on the road as his bandmates but was more discreet about it, stating "I did more drugs than I care to remember. I just did it quietly." Benoit Gautier, an employee of Atlantic Records in France, echoed this impression, stating that "The wisest guy in Led Zeppelin was John Paul Jones. Why? He never got caught in an embarrassing situation."
In an interview, Jones explained that fame with Led Zeppelin was not something that he ever became preoccupied with:
However, following exhausting tours and extended periods of time away from his family, by late 1973 Jones was beginning to show signs of disillusionment. He considered quitting Led Zeppelin to spend more time with his family, and possibly to take up the position of choirmaster of Winchester Cathedral, but was talked into returning by the band's manager, Peter Grant. Jones later explained his reservations:
"Royal Orleans".
It is rumoured that the Led Zeppelin song "Royal Orleans", from their album "Presence", is about an experience Jones once had on tour in the United States. The song is about a person who mistakenly takes a drag queen up to his hotel room, who then falls asleep with a joint of marijuana in hand, lighting the room on fire. "Royal Orleans" was the name of a hotel where the members of Led Zeppelin would stay when they visited New Orleans, because not as many people asked for autographs there. In an interview he gave to "Mojo magazine" in 2007, Jones clarified the reliability of this rumour, stating:
Other work during time with the band.
Jones' involvement with Led Zeppelin did not put a halt to his session work. In 1969 he returned to the studio to play bass guitar on The Family Dogg's "A Way of Life" album, in 1970 and keyboards for guitarist Peter Green on his solo album "The End of the Game". Jones was Madeline Bell's first choice to produce and arrange her 1974 album "Comin' Atcha". He has also played keyboards on many Roy Harper albums, and contributed to Wings' Rockestra, "Back to the Egg" along with Zeppelin's drummer John Bonham.
After Led Zeppelin.
1980–2000.
Since Led Zeppelin dissolved in 1980 with the death of John Bonham, Jones has collaborated with a number of artists, including Diamanda Galás, R.E.M., Jars of Clay, Heart, Ben E. King, Peter Gabriel, Foo Fighters, Lenny Kravitz, Cinderella, The Mission, La Fura dels Baus, The Harp Consort, Brian Eno, the Butthole Surfers and Uncle Earl.
He appeared on sessions and videos for Paul McCartney and was involved in the soundtrack of the film "Give My Regards to Broad Street". In 1985, Jones was asked by director Michael Winner to provide the soundtrack for the film, "Scream for Help", with Jimmy Page appearing on two tracks. Jones provides vocals for two of the songs. He recorded and toured with singer Diamanda Galás on her 1994 album, "The Sporting Life" (co-credited to John Paul Jones). Jones set up his own recording studio called Sunday School, as well being involved in his daughter's (Jacinda Jones) singing career.
In 1985, Jones joined the other former members of Led Zeppelin for the Live Aid concert with both Phil Collins and Tony Thompson filling in on drums. The former members again re-formed for the Atlantic Records 40th Anniversary concert on 14 May 1988. Page, Plant and Jones, as well as John Bonham's son Jason, closed the event. In 1992, Jones arranged the orchestration on the R.E.M. album "Automatic for the People".
In 1995, the band Heart released a live acoustic album called "The Road Home" which was produced by Jones, and on which he also played several instruments. Also in 1995, Andrew Lawrence-King's Harp Consort released a set of three Spanish language songs in 17th-century style of Jones's own composition, accompanied by baroque instruments including harps, chitarrone, guitars, lirone, viola da gamba and percussion (this 10-minute CD, titled "Amores Pasados", was coupled with The Harp Consort's debut record, "Luz y Norte").
2000–present.
"Zooma", his debut solo album, was released in September 1999 on Robert Fripp's DGM label and followed up in 2001 by "The Thunderthief". Both albums were accompanied by tours, in which he played with Nick Beggs (Chapman Stick) and Terl Bryant (drums).
In 2004, he toured as part of the group Mutual Admiration Society, along with Glen Phillips (the front man for the band Toad the Wet Sprocket) and the members of the band Nickel Creek.
Jones plays on two tracks on Foo Fighters' album "In Your Honor". He plays mandolin on "Another Round" and piano on "Miracle", both of which are on the acoustic disc. The band's frontman Dave Grohl (a big Led Zeppelin fan) has described Jones' guest appearance as the "second greatest thing to happen to me in my life".
He has also branched out as a record producer, having produced such albums as The Mission's album "Children", The Datsuns' second album "Outta Sight, Outta Mind" (2004) and Uncle Earl's "Waterloo, Tennessee" album of Old-time music, released in March 2007 on Rounder Records.
In May 2007, he accompanied Robyn Hitchcock and Ruby Wright in performing the song "Gigolo Aunt" at a tribute for Pink Floyd founder Syd Barrett in London, which he did on mandolin.
He played at Bonnaroo 2007 in a collaboration with Ben Harper and The Roots' drummer Questlove as part of the festival's all-star Super-Jam, which is the festival's annual tradition of bringing together famous, world-class musicians to jam on stage for a few hours.
Jones appeared and played mandolin with Gillian Welch during the festival during the song "Look at Miss Ohio" and a cover of the Johnny Cash song "Jackson". He also appeared during the set of Ben Harper & the Innocent Criminals where they played a cover of "Dazed and Confused". Jones then closed Gov't Mule's first set, playing part of "Moby Dick" and then "Livin Lovin Maid" on bass, then proceeded to play keyboards on the songs "Since I've Been Loving You" and "No Quarter". Jones also performed on mandolin with the all-female bluegrass group Uncle Earl, whose album he had produced in 2007.
Mandolin-slinging Jones jammed on Led Zeppelin's "Whole Lotta Love" with Winnipeg's energetic Duhks at April 2007's MerleFest in North Carolina.
Jones played in the Led Zeppelin reunion show at London's O2 Arena on 10 December 2007 with the other remaining members of Led Zeppelin as part of a tribute to Ahmet Ertegun.
In 2008, Jones produced Nickel Creek singer-fiddler Sara Watkins' debut solo album. As previously mentioned, Jones toured with Watkins, Glen Phillips, and the rest of Nickel Creek in late 2004 in a collaboration entitled Mutual Admiration Society.
On 10 February 2008, Jones appeared with the Foo Fighters on the Grammy Awards conducting the orchestral part to the song "The Pretender". On 7 June 2008, Jones and Jimmy Page appeared with the Foo Fighters to close out the band's concert at Wembley Stadium. Jones performed with Sonic Youth and Takehisa Kosugi, providing the stage music for Merce Cunningham's "Nearly 90", which ran 16–19 April 2009 at the Brooklyn Academy of Music.
In February and March 2011 he appeared in the onstage band in Mark-Anthony Turnage's opera "Anna Nicole", about the "Playboy" model Anna Nicole Smith, at the Royal Opera House, Covent Garden, in London.
In August 2011, he appeared at Reading and Leeds Festivals to play alongside Seasick Steve.
On 16 September 2012, Jones appeared at the Sunflower Jam charity concert at the Royal Albert Hall, London, performing alongside guitarist
Brian May of Queen, drummer Ian Paice of Deep Purple, and vocalists Bruce Dickinson of Iron Maiden and Alice Cooper.
In November 2012, Jones toured the UK with the Norwegian avant-garde/improvisational band Supersilent.
On 6 December 2012, Jones performed on bass, guitar and mandolin with Robyn Hitchcock as 'Biscotti' at Cecil Sharp House, London.
On 30 April 2013, Jones appeared live on the BBC TV Show Later... with Jools Holland, playing bass for Seasick Steve on Down on the Farm from Seasick Steve's new album Hubcap Music album
On 1 May 2013, Jones appeared with Seasick Steve at a concert at the Roundhouse in Camden, London. Introduced by Seasick Steve as a member "of the best rock band ever", Jones played bass, mandolin, and steel guitar, and provided vocals.
On Saturday 29 June 2013, Jones played guitar whilst appearing with Rokia Traore, who opened the Pyramid Stage that morning at Glastonbury 2013.
During November 2013, Jones joined a seven-day tour of the Southeast US, playing mandolin with the Dave Rawlings Machine. The Atlanta show (21 November 2013) included a rendition Led Zeppelin's "Going to California." Jones also toured with the Dave Rawlings Machine in autumn 2014.
On 5 and 6 September 2015, Jones, along with Queen drummer Roger Taylor, joined Foo Fighters on stage in Milton Keynes to perform a cover of Queen's "Under Pressure," with Taylor Hawkins and Dave Grohl singing.
Them Crooked Vultures.
Jones' most recent own project is a supergroup with Dave Grohl and Queens of the Stone Age frontman Josh Homme named Them Crooked Vultures. The trio played their first show together on 9 August 2009 at the Metro in Chicago, and their first album" "was released on 17 November 2009.
Legacy.
Jones is widely considered to be a highly influential and important bassist, keyboardist, and arranger in the history of rock music. Many notable rock bassists have been influenced by Jones, including John Deacon of Queen, Geddy Lee of Rush, Steve Harris of Iron Maiden, Flea of Red Hot Chili Peppers, Gene Simmons of Kiss, and Krist Novoselic of Nirvana. Chris Dreja, the rhythm guitarist and bassist of The Yardbirds, has described him as "the best bass player in Europe". Music publications and magazines have ranked Jones among the best rock bassists of all time. He was named the best bassist on "Creem Magazine"'s 1977 Reader Poll. In 2000, "Guitar" magazine ranked him third in the "Bassist of the Millennium" readers' poll.
In October 2010, Jones was awarded a "Gold Badge Award" by The British Academy of Songwriters, Composers and Authors for his outstanding contribution to Britain's music and entertainment industry. On 10 November 2010, he was honoured with the "Outstanding Contribution Award" at the Marshall "Classic Rock" Roll of Honour Awards.
Personal life.
John married his wife, Maureen, in 1967, and they have been together ever since, currently residing in West London. They have three daughters: Tamara, Jacinda and Kiera. According to "The Sunday Times" Rich List Jones' net worth was £40 million .
Gear.
Mandolins.
Jones owns many mandolins made by Andy Manson, including a triple neck mandolin, octave mandolin, octave mandola, and mando cello. His main mandolin is a Manson F style mandolin. 
He also owns Gibson F-5 Lloyd Loar #75317 dated February 18, 1924, which reputedly cost $250,000. (#75316 is owned by Chris Thile and #75615 was Lloyd Loar's personal mandolin.)

</doc>
<doc id="54273" url="https://en.wikipedia.org/wiki?curid=54273" title="Repertory theatre">
Repertory theatre

A repertory theatre (also called repertory, rep or stock) can be a Western theatre or opera production in which a resident company presents works from a specified repertoire, usually in alternation or rotation. In the British system, however, it used to be that even quite small towns would support a rep and the resident company would present a different play every week, either a revival from the full range of classics or, if given the chance, a new play, once the rights had been released after a West End or Broadway run. However the companies were not known for trying out untried new work. The methods, now seldom seen, would be also used in the United States, Canada, and Australia.
Resident company.
The acting company would usually consist of a leading lady, a leading man, a set of juveniles (one male and one female ingenue for the young often romantic role(s)), a character actor and actress (for the older or eccentric parts) and perhaps a vain and girlish soubrette. A guest star might have been brought in to boost attendance, which might only cover its own added cost. The resident cast would number seven, plus the resident director, usually serving as the artistic director in charge of the whole enterprise. Additionally there would be the stage director, the assistant stage manager (ASM), some unpaid apprentices and light and sound technicians. Newcomers to the profession would often start their careers in this fashion and members would gain a foundation upon which to base their future careers. Paid members could also be sure of a steady income for one or more seasons which might last for six months. Examples of performers who went on to universal recognition are Errol Flynn, Sir John Gielgud, Sir Ralph Richardson, Lord Olivier, Jeremy Brett, Dame Judi Dench, Rosemary Harris, Sir Ian McKellen, Christopher Plummer, Harold Pinter, Imelda Staunton, Lynn Redgrave, Arthur Lowe, Vanessa Redgrave, Sir Patrick Stewart, Geraldine McEwan and Ronnie Barker. Dirk Bogarde wrote about his start at tiny Amersham rep in 1939, and Sir Michael Caine recounts his time spent at Horsham rep in the early fifties.
Weekly rehearsal schedule.
For weekly rep and for a typical 3-act play with a wise director, the actors' week would start on Tuesday and go as follows: Tuesday: notes on last night's opening from the director, then a sit-down read-through of the next play with some discussion by the director, on-the-feet blocking of the moves for Act I with a few questions from the actors and there are performances of last week's play each night. Wednesday: run Act I and start to block Act II, but break early because there's a matinée. Thursday: finish blocking Act II, run Act II and block Act III. Friday: run Act III, run through of entire play, no scripts in hand and technicals – meaning lights and sound – to watch and write down cues. Saturday: run through again, stop and go to test lighting and sound cues, costumes may be used if ready. Two shows today, the evening one closing the current play. After the show, the set is struck (taken down) by the crew - usually apprentices – and the stage manager.
Sunday is an opportunity to brush up on lines and moves and private rehearsals. But for the crew it means putting up the new sets, hanging and focusing lights and setting sound equipment. Monday: morning, run through, usually without costumes (save wear and tear), mainly for the techs. In the afternoon there's a "Full Perfect" dress rehearsal, maybe a few friends in front to gauge reaction, then copious notes. In the evening, 8 o'clock opening night, followed by notes from the director, visits with friends from the audience and maybe a party nearby. The process starts all over again on Tuesday.
Audience and management.
From the audience's point of view, local communities would become fans and champion their favourites who would be treated as celebrities. And sometimes entire families would make a visit to their local rep as part of the weekly routine like going to church, and for the young ones, it became a part of their future appreciation for live "legitimate" theatre.
During the forties, fifties and sixties, two impresarios dominated the field of British rep, mostly in the North. They were Harry Hanson and his Court players, and Frank H. Fortescue's Famous Players, with Arthur Brough in Folkestone for the South. Their system was the toughest of all, for if you joined one of their companies, it could mean "twice-nightly" shows, and a new play to learn every week. Rosemary Harris tells of her 50 consecutive weeks of doing just that at Bedford rep. It cannot happen any more, due to the restrictions of British Equity which came to mandate just 8 shows a week, including perhaps two matinées. Fortescue, who died in 1957, was known to be a strict and upright man. When "Pygmalion" was playing at one of his theatres, because Eliza says ""Not bloody likely!"", "FOR ADULTS ONLY!" would be posted in the front of house. Or perhaps he was afraid of the Lord Chamberlain, Her Majesty's official censor whose duties were abolished in 1968.
Today's practice.
Not to be overlooked is a form of touring repertory theatre known as "bus and truck", which involves transporting the actors and sets for about five different plays which can be performed in smaller communities on consecutive nights.
In Russia and much of Eastern Europe repertory theatre is based on the idea that each company maintains a number of productions which are performed on a rotating basis. Each production’s life span is determined by its success with the audience. However, many productions remain in repertory for years as this approach presents each piece a few times in a given season, not enough to exhaust the potential audience pool. After the fall of the Soviet regime and the substantial diminution of government subsidy, the repertory practice has required re-examination. Moscow Art Theatre and Lev Dodin’s Maly Drama Theatre of St. Petersburg are the world’s most notable practitioners of this approach.
In German speaking countries, most opera companies function in a similar way, too.
UK.
Today in the UK, the practice of "rep" is more likely to be seen in large cities in the manner applied by such well-known established companies as Birmingham Rep in the Midlands of England which states in its programmes: """The REP" presents a season with each play generally having an unbroken run of between three and six weeks. This is the form of repertory theatre that the majority of theatres like The REP — which are also called producing theatres — now follow."" Actors have the luxury of at least 3 weeks of rehearsal, and audiences see better shows. Repertory can still be found in the UK in a variation of guises; in Sidmouth (12 plays), Wolverhampton (8 plays), Burslem and Taunton (4 each). The Sheringham Little Theatre produces an in-house repertory season each summer, running from June until September. Weekly Repertory theatre is also produced by the Summer Theatre season at Frinton-on-Sea. This season has been running for seventy seven seasons now, and until recently maintained its links with the oldest traditions of British commercial theatre by being run by the actor Jack Watling, his son Giles and his son-in-law Seymour Matthews. In 2004 it was taken over by Edward Max, who ran it alone until 2012. For the next two years it was run by mtp Ltd. Now Clive Brill is the producer, working with Edward as General Manager. The recent 75th anniversary season was marked with a stage appearance by Richard Wilson, who has since become the Patron of the Friends of Frinton Theatre. 
Frinton saw the early launch of actors such as Michael Dennison, Vanessa Redgrave, David Suchet, Jack Klaff, Neil Dudgeon, Owen Teale and Lynda Bellingham. Theatre practices like this remain popular within theatre communities and continue to give first jobs to graduating drama students.
USA.
In America, the repertory system has also found a base to compete with commercial theatre. Repertory theatre with mostly changing casts and longer running plays, perhaps better classed as "provincial" or "non-profit" theatre, has made a big come-back, in cities such as Little Rock, AR, Washington, DC, Minneapolis, Indianapolis, Milwaukee, Cincinnati, Chicago, Los Angeles, Nashville, New York, Houston, Boston, San Francisco, San Diego, Buffalo, Kansas City, and Seattle. Festival theatre now provides actors with work in the summer.
America's oldest resident repertory theatre, Hedgerow Theatre, is located in Rose Valley, Pennsylvania. It was founded by actor Jasper Deeter in 1923. The present Producing Artistic Director is actress and director Penelope Reed.
Canada.
The crowning achievement of repertory theatres in Canada are the world-renowned Stratford Shakespeare Festival, founded in 1953 to primarily present productions of William Shakespeare's plays and the Shaw Festival, founded in 1962, which presents plays written or set during the lifetime of George Bernard Shaw or following Shaw's ideal of socially provactive theatre.
The Vagabond Repertory Theatre Company was formed in March 2009 by artistic directors Nathaniel Fried and Ryan LaPlante, and currently resides and performs in Kingston, Ontario. But the old English-style repertory theatres such as Ottawa's CRT (Canadian Repertory Theatre), and Toronto's Crest Theatre no longer exist. Although they did have a version of summer theatre in smaller holiday districts, such as the "Straw Hat" players of Gravenhurst and Port Carling at Ontario's vacation Muskoka Lakes area.
Pros and cons.
Among the benefits of such a system are increased variety and better quality, due to fresh actors and shopped in directors. The theatre can afford to take risks, and a show that is likely to attract a large audience will effectively subsidize a show that is less likely, especially if season tickets are sold.
Drawbacks to the repertoire system are increased production costs as each show will need separate sets, props, costumes and actors, (although sometimes an actor will be engaged to play in more than one production). Many such companies are large, and are able to have a smaller space available to workshop an experimental production or present playreadings. But the standard should be higher than under the old-time repertory system, because there will be more time for rehearsal. Also many repertoire companies today have non-profit status, so that budgets and income should be higher because they will not just depend upon ticket sales. However, the downside is that promotional costs will also be much higher due to having to employ a separate staff.
Footnotes.
Murray, Stephen. "Taking Our Amusements Seriously". LAP, 2010. ISBN 978-3-8383-7608-0.

</doc>
<doc id="54275" url="https://en.wikipedia.org/wiki?curid=54275" title="Tisza">
Tisza

The Tisza or Tisa is one of the main rivers of Central Europe. Once, it was called "The most Hungarian river" because it flowed entirely within Hungary. Today, it crosses several national borders.
The Tisza begins near Rakhiv in Ukraine, at the confluence of the White Tisa and Black Tisa (the former springs in the Chornohora mountains; the latter in the Gorgany range). From there, the Tisza flows west, roughly following Ukraine's borders with Romania, then Hungary, and finally Serbia. It enters Hungary at Tiszabecs. It traverses Hungary from north to south. A few kilometers south of the Hungarian city of Szeged, it enters Serbia. Finally, it joins the Danube near the village of Novi Slankamen in Vojvodina, Serbia.
The Tisza drains an area of about and has a length of —the largest catchment and greatest length of any of the Danube's tributaries. Its mean annual discharge is . It contributes about 13% of the Danube's total runoff.
Names for the river in the languages of the countries it flows through:
The river was known as the "Tisia" in antiquity; other ancient names for it included "Tissus" (in Latin) and "Pathissus" (Πάθισσος in Ancient Greek), (Pliny, "Naturalis historia", 4.25). It may be referred to as the "Theiss" () in older English references, after the German name for the river.
It is known as the "Tibisco" in Italian, and in older French references (as for instance in relation to the naval battles on the Danube between the Ottoman Empire and the Austro-Hungarian Empire in the 17th and 18th centuries) it is often referred to as the "Tibisque".
Attila the Hun is said to have been buried under a diverted section of the river Tisza.
Regulation.
The length of the Tisza in Hungary used to be 1419 km. It flowed through the Great Hungarian Plain, which is one of the largest flat areas in central Europe. Since plains can cause a river to flow very slowly, the Tisza used to follow a path with many curves and turns, which led to many large floods in the area.
After several small-scale attempts, István Széchenyi organised the "regulation of the Tisza" () which started on August 27, 1846, and substantially ended in 1880. The new length of the river in Hungary was 966 km (1358 km total), with 589 km of "dead channels" and 136 km of new riverbed.The resultant length of the flood-protected river comprises 2,940 km (out of 4,220 km of all Hungarian protected rivers).
"Lake Tisza".
In the 1970s the building of the Tisza Dam at Kiskore started with the purpose of helping to control floods as well as storing water for drought seasons. It turned out, however, that the resulting Lake Tisza became one of the most popular tourist destinations in Hungary, since it had similar features to Lake Balaton at drastically cheaper prices and it was not crowded.
Navigation.
The Tisza is navigable over much of its course. The river opened up for international navigation only recently; before, Hungary distinguished "national rivers" and "international rivers", indicating whether non-Hungarian vessels were allowed or not. After Hungary joined the European Union, this distinction was lifted and vessels were allowed on the Tisza.
Conditions of navigation differ with the circumstances: when the river is in flood, it is often unnavigable, just as it is at times of extreme drought.
Wildlife.
The Tisza has a rich and varied wildlife. Over 200 species of birds reside in the bird reserve of Tiszafűred. The flood plains along the river boast large amounts of diverse plant and animal life. In particular, the yearly "flowering" of the Tisza is considered a local natural wonder. The flowering attracts vast amounts of mayflies which is a well known spectacle.
Cities.
The Tisza ("Tisa") flows through the following countries and cities (ordered from the source to mouth):

</doc>
<doc id="54280" url="https://en.wikipedia.org/wiki?curid=54280" title="Mimeo">
Mimeo

Mimeo (possibly derived from the Greek word "mimema" for "something imitated") may refer to:

</doc>
<doc id="54286" url="https://en.wikipedia.org/wiki?curid=54286" title="Haloragales">
Haloragales

Haloragales is a botanical name for an order of flowering plants. In the Cronquist system of classification, of 1981, it was placed in subclass Rosidae and had this circumscription:

</doc>
<doc id="54292" url="https://en.wikipedia.org/wiki?curid=54292" title="Spanish euro coins">
Spanish euro coins

Spanish euro coins feature three different designs for each of the three series of coins. The minor series of 1, 2 and 5 cent coins were designed by Garcilaso Rollán, the middle series of 10, 20, and 50 cent coins by Begoña Castellanos and the two major coins feature the portrait or effigy of King Felipe VI of Spain. All designs feature the 12 stars of the EU, the year of minting, and the word "España" (Spanish for Spain).
Current series.
In 2010, Spain updated their national sides in order to comply with the European commission recommendations. In the €1 and €2 coins, the same portrait of king Juan Carlos I was used, but the year position was placed in the inner part of the coin. Moreover, the twelve star ring no longer contained chiseled sections. The chiseled sections were also removed from designs for the other coins.
In 2015, the portrait on the €1 and €2 coins was changed to that of the new King Felipe VI following his father's abdication the previous year.
First series (1999–2009).
For images of the common side and a detailed description of the coins, see euro coins.
€2 commemorative coins.
Spanish UNESCO World Heritage Sites series.
Spain will start the commemorative coin series "" (UNESCO World Heritage) in 2010, commemorating all of Spain's UNESCO World Heritage Sites, which could continue until 2050. The order in which the coin for a specific site is issued coincides with the order in which they were declared a UNESCO World Heritage site. The coins issued are:

</doc>
<doc id="54293" url="https://en.wikipedia.org/wiki?curid=54293" title="Web portal">
Web portal

A web portal is most often one specially designed web site that brings information together from diverse sources in a uniform way. Usually, each information source gets its dedicated area on the page for displaying information (a portlet); often, the user can configure which ones to display. Variants of portals include mashups and intranet "dashboards" for executives and managers. The extent to which content is displayed in a "uniform way" may depend on the intended user and the intended purpose, as well as the diversity of the content. Very often design emphasis is on a certain "metaphor" for configuring and customizing the presentation of the content and the chosen implementation framework and/or code libraries. In addition, the role of the user in an organization may determine which content can be added to the portal or deleted from the portal configuration.
A portal may use a search engine API to permit users to search intranet content as opposed to extranet content by restricting which domains may be searched. Apart from this common search engines feature, web portals may offer other services such as e-mail, news, stock quotes, information from databases and even entertainment content. Portals provide a way for enterprises and organizations to provide a consistent look and feel with access control and procedures for multiple applications and databases, which otherwise would have been different web entities at various URLs. The features available may be restricted by whether access is by an authorized and authenticated user (employee,member) or an anonymous site visitor.
Examples of early public web portals were AOL, Excite, Netvibes, iGoogle, MSN, Naver, Lycos, Indiatimes, Rediff, and Yahoo!. See for example, the "My Yahoo!" feature of Yahoo! which may have inspired such features as the later Google "iGoogle" (discontinued as of November 1, 2013.) The configurable side-panels of, for example, the modern Opera browser and the option of "Speed Dial" pages by most browsers continue to reflect the earlier "portal" metaphor.
History.
In the late 1990s the web portal was a web IT buzzword. After the proliferation of web browsers in the late-1990s many companies tried to build or acquire a portal to attempt to obtain a share of an Internet market. The web portal gained special attention because it was, for many users, the starting point of their web browsing if it was set as their home page. The content and branding of a portal could change as internet companies merged or were acquired. Netscape became a part of America Online, the Walt Disney Company launched Go.com, IBM and others launched Prodigy, and Excite and @Home became a part of AT&T Corporation during the late 1990s. Lycos was said to be a good target for other media companies, such as CBS.
Portals which relied on HTML iframes gave rise to a need for web access points which either required frames or sites that had to offer non-frames alternatives. See: same-source policy in web browsers.
The interest in portals saw some "old media" companies racing to outbid each other for Internet properties but died down with the dot-com bust in 2000 and 2001. Disney pulled the plug on Go.com, Excite went bankrupt, and its remains were sold to iWon.com. Some portal sites such as Yahoo! and those others first listed in this article remain active and portals feature widely outside the English-speaking web (Chinese, Japanese, Indian, Russian and other very popular sites not frequented by English-only users.) Portal metaphors are widely used by public library sites for borrowers using a login as users and by university intranets for students and for faculty. Vertical markets remain for ISV's offering management and executive intranet "dashboards" for corporations and government agencies in areas such as GRC and risk management.
Classification.
Web portals are sometimes classified as "horizontal" or "vertical". A horizontal portal is used as a platform to several companies in the same economic sector or to the same type of manufacturers or distributors. A vertical portal (also known as a "vortal") is a specialized entry point to a specific market or industry niche, subject area, or interest. Some vertical portals are known as "vertical information portals" (VIPs). VIPs provide news, editorial content, digital publications, and e-commerce capabilities. In contrast to traditional vertical portals, VIPs also provide dynamic multimedia applications including social networking, video posting, and blogging.
Types of web portals.
Personal portals.
A personal portal is a web page at a web site on the World Wide Web or a local HTML home page including JavaScript and perhaps running in a modified web browser. A personal portal typically provides personalized capabilities to its visitors or its local user, providing a pathway to other content. It may be designed to use distributed applications, different numbers and types of middleware and hardware to provide services from a number of different sources and may run on a non-standard local web server. In addition, business portals can be designed for sharing and collaboration in workplaces. A further business-driven requirement of portals is that the content be presented on multiple platforms such as personal computers, personal digital assistants (PDAs), and cell phones/mobile phone/mobile phones.
Information, news, and updates are examples of content that would be delivered through such a portal. Personal portals can be related to any specific topic such as providing friend information on a social network or providing links to outside content that may help others beyond your reach of services. Portals are not limited to simply providing links. Outside of business intracet user, very often simpler portals become replaced with richer mashup designs. Within enterprises, early portals were often replaced by much more powerful "dashboard" designs. Some also have relied on newer protocols such as some version of RSS aggregation and may or may not involve some degree of web harvesting. Examples of personal portals include:
Government web portals.
At the end of the dot-com boom in the 1990s, many governments had already committed to creating portal sites for their citizens. These included primary portals to the governments as well as portals developed for specific audiences. Examples of government web portals include:
Cultural portals.
Cultural portal aggregate digitised cultural collections of galleries, libraries (see: library portal), archives and museums. This type of portal provides a point of access to invisible web cultural content that may not be indexed by standard search engines. Digitised collections can include books, artworks, photography, journals, newspapers, music, sound recordings, film, maps, diaries and letters, and archived websites as well as the descriptive metadata associated with each type of cultural work. These portals are usually based around a specific national or regional groupings of institutions. Examples of cultural portals include:
Corporate web portals.
Corporate intranets became common during the 1990s. As intranets grew in size and complexity, webmasters were faced with increasing content and user management challenges. A consolidated view of company information was judged insufficient; users wanted personalization and customization. Webmasters, if skilled enough, were able to offer some capabilities, but for the most part ended up driving users away from using the intranet.
Many companies began to offer tools to help webmasters manage their data, applications and information more easily, and through personalized views. Portal solutions can also include workflow management, collaboration between work groups, and policy-managed content publication. Most can allow internal and external access to specific corporate information using secure authentication or single sign-on.
JSR168 Standards emerged around 2001. Java Specification Request (JSR) 168 standards allow the interoperability of portlets across different portal platforms. These standards allow portal developers, administrators and consumers to integrate standards-based portals and portlets across a variety of vendor solutions.
The concept of content aggregation seems to still gain momentum and portal solution will likely continue to evolve significantly over the next few years. The Gartner Group predicts generation 8 portals to expand on the Business Mashups concept of delivering a variety of information, tools, applications and access points through a single mechanism.
With the increase in user generated content, disparate data silos, and file formats, information architects and taxonomist will be required to allow users the ability to tag (classify) the data. This will ultimately cause a ripple effect where users will also be generating ad hoc navigation and information flows.
Corporate Portals also offer customers & employees self-service opportunities.
Stock portals.
Also known as stock-share portals, stock market portals or stock exchange portals are Web-based applications that facilitates the process of informing the share-holders with substantial online data such as the latest price, ask/bids, the latest News, reports and announcements. Some stock portals use online gateways through a central depository system (CDS) for the visitors (ram) to buy or sell their shares or manage their portfolio.
Search portals.
Search portals aggregate results from several search engines into one page. You can find search portals specialized in a product, for example property search portals. Library search portals are also known as discovery interfaces.
Property search portals.
Property search portals aggregate data about properties for sale by real estate agents. Examples in the UK include Zoopla, Rightmove, Nestoria and Nuroa. Examples in the US include Propertini.
Tender portals.
A tender portal is a gateway for government suppliers to bid on providing goods and services. Tender portals allow users to search, modify, submit, review and archive data in order to provide a complete online tendering process.
Using online tendering, bidders can do any of the following:
Hosted web portals.
Hosted web portals gained popularity and a number of companies began offering them as a hosted service. The hosted portal market fundamentally changed the composition of portals. In many ways they served simply as a tool for publishing information instead of the loftier goals of integrating legacy applications or presenting correlated data from distributed databases. The early hosted portal companies such as Hyperoffice.com or the now defunct InternetPortal.com focused on collaboration and scheduling in addition to the distribution of corporate data. As hosted web portals have risen in popularity their feature set has grown to include hosted databases, document management, email, discussion forums and more. Hosted portals automatically personalize the content generated from their modules to provide a personalized experience to their users. In this regard they have remained true to the original goals of the earlier corporate web portals. Emerging new classes of internet portals called Cloud Portals are showcasing the power of API (Application Programming Interface) rich software systems leveraging SOA (service-oriented architecture, web services, and custom data exchange) to accommodate machine to machine interaction creating a more fluid user experience for connecting users spanning multiple domains during a given "session". Leading cloud portals like Nubifer Cloud Portal showcase what is possible using Enterprise Mashup and Web Service integration approaches to building cloud portals.
Domain-specific portals.
A number of portals have come about which are specific to a particular domain, offering access to related companies and services; a prime example of this trend would be the growth in property portals that give access to services such as estate agents, removal firm, and solicitors that offer conveyancing. Along the same lines, industry-specific news and information portals have appeared, such as the clinical trials-specific portal.
Engineering aspects.
Overview.
The main concept is to present the user with a single web page that brings together or aggregates content from a number of other systems or servers.
The application server or architecture performs most of the crucial functions of the application. This application server is in turn connected to database servers, and may be part of a clustered server environment. High-capacity portal configurations may include load balancing strategies.
For portals that present application functionality to the user, the portal server is in reality the front piece of a server configuration that includes some connectivity to the application server. For early web browsers permitting HTML frameset and iframe elements, diverse information could be presented without violating the browser same-source security policy (relied upon to prevent a variety of cross-site security breaches.) More recent client-side technologies rely on JavaScript frameworks and libraries that rely on more recent web functionality such as WebSockets and async callbacks using XMLHttpRequests.
The server hosting the portal may only be a "pass through" for the user. By use of portlets, application functionality can be presented in any number of portal pages. For the most part, this architecture is transparent to the user.
In such a design, security and concurrent user capacity can be important issues, and security designers need to ensure that only authenticated and authorized users can generate requests to the application server. If the security design and administration does not ensure adequate authentication and authorization, then the portal may inadvertently present vulnerabilities to various types of attacks.

</doc>
