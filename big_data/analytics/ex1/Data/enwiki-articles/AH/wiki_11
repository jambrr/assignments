<doc id="48711" url="https://en.wikipedia.org/wiki?curid=48711" title="Oregon Trail">
Oregon Trail

The Oregon Trail is a historic east–west, large-wheeled wagon route and emigrant trail that connected the Missouri River to valleys in Oregon. The eastern part of the Oregon Trail spanned part of the future state of Kansas, and nearly all of what are now the states of Nebraska and Wyoming. The western half of the trail spanned most of the future states of Idaho and Oregon.
The Oregon Trail was laid by fur trappers and traders from about 1811 to 1840, and was only passable on foot or by horseback. By 1836, when the first migrant wagon train was organized in Independence, Missouri, a wagon trail had been cleared to Fort Hall, Idaho. Wagon trails were cleared increasingly further west, and eventually reached all the way to the Willamette Valley in Oregon, at which point what came to be called the Oregon Trail was complete, even as almost annual improvements were made in the form of bridges, cutoffs, ferries, and roads, which made the trip faster and safer. From various starting points in Iowa, Missouri, or Nebraska Territory, the routes converged along the lower Platte River Valley near Fort Kearny, Nebraska Territory and led to rich farmlands west of the Rocky Mountains.
From the early to mid-1830s (and particularly through the epoch years, 1846–69) the Oregon Trail and its many offshoots were used by about 400,000 settlers, farmers, miners, ranchers, and businessmen and their families. The eastern half of the trail was also used by travelers on the California Trail (from 1843), Mormon Trail (from 1847), and Bozeman Trail (from 1863), before turning off to their separate destinations. Use of the trail declined as the first transcontinental railroad was completed in 1869, making the trip west substantially faster, cheaper, and safer. Today, modern highways, such as Interstate 80 and Interstate 84, follow parts of the same course westward and pass through towns originally established to serve those using the Oregon Trail.
History.
Lewis and Clark Expedition.
In 1803, President Thomas Jefferson issued the following instructions to Meriwether Lewis: "The object of your mission is to explore the Missouri river, & such principal stream of it, as, by its course & communication with the waters of the Pacific Ocean, whether the Columbia, Oregon, Colorado and/or other river may offer the most direct & practicable water communication across this continent, for the purposes of commerce." Although Lewis and William Clark found a path to the Pacific Ocean, it was not until 1859 that a direct and practicable route, the Mullan Road, connected the Missouri River to the Columbia River.
The first land route across what is now the United States was partially mapped by the Lewis and Clark Expedition between 1804 and 1806. Lewis and Clark initially believed they had found a practical overland route to the west coast; however, the two passes they found going through the Rocky Mountains, Lemhi Pass and Lolo Pass, turned out to be much too difficult for wagons to pass through without considerable road work. On the return trip in 1806 they traveled from the Columbia River to the Snake River and the Clearwater River over Lolo pass again. They then traveled overland up the Blackfoot River and crossed the Continental Divide at Lewis and Clark Pass and on to the head of the Missouri River. This was ultimately a shorter and faster route than the one they followed west. This route had the disadvantages of being much too rough for wagons and controlled by the Blackfoot Indians. Even though Lewis and Clark had only traveled a narrow portion of the upper Missouri River drainage and part of the Columbia River drainage, these were considered the two major rivers draining most of the Rocky Mountains, and the expedition confirmed that there was no "easy" route through the northern Rocky Mountains as Jefferson had hoped. Nonetheless, this famous expedition had mapped both the eastern and western river valleys (Platte and Snake Rivers) that bookend the route of the Oregon Trail (and other emigrant trails) across the continental dividethey just had not located the South Pass or some of the interconnecting valleys later used in the high country. They did show the way for the mountain men, who within a decade would find a better way across, even if it was not to be an easy way.
Pacific Fur Company.
Founded by John Jacob Astor as a subsidiary of his American Fur Company in 1810, the Pacific Fur Company operated in the Pacific Northwest in the ongoing North American fur trade. Two movements of PFC employees were planned by Astor, one detachment to be sent to the Columbia River by the "Tonquin" and the other overland under an expedition led by Wilson Price Hunt. Hunt and his party was to find possible supply routes and trapping territories for fur trading posts. Upon arriving at the river in March 1811, the "Tonquin" crew began construction of what became Fort Astoria. The ship left supplies and men to continue work on the station and ventured north up the coast to Clayoquot Sound for a trading expedition. There it was attacked and overwhelmed by the indigenous Nuu-chah-nulth before being blown up, killing all the crew and many natives.
Under Hunt, fearing attack by the Niitsitapi, the overland expedition veered south of Lewis and Clark's route into what is now Wyoming and in the process passed across Union Pass and into Jackson Hole, Wyoming. From there they went over the Teton Range via Teton Pass and then down to the Snake River into modern Idaho. They abandoned their horses at the Snake River, made dugout canoes, and attempted to use the river for transport. After a few days' travel they soon discovered that steep canyons, waterfalls and impassable rapids made travel by river impossible. Too far from their horses to retrieve them, they had to cache most of their goods and walk the rest of the way to the Columbia River where they made new boats and traveled to the newly established Fort Astoria. The expedition demonstrated that much of the route along the Snake River plain and across to the Columbia was passable by pack train or with minimal improvements, even wagons. This knowledge would be incorporated into the concatenated trail segments as the Oregon Trail took its early shape.
American Fur Company partner Robert Stuart led a small group of men back east to report to Astor. The group planned to retrace the path followed by the overland expedition back up to the east following the Columbia and Snake rivers. Fear of Indian attack near Union Pass in Wyoming forced the group further south where they luckily discovered South Pass, a wide and easy pass over the Continental Divide. The party continued east via the Sweetwater River, North Platte River (where they spent the winter of 1812–13) and Platte River to the Missouri River, finally arriving in St. Louis in the spring of 1813. The route they had used appeared to potentially be a practical wagon route, requiring minimal improvements, and Stuart's journals provided a meticulous account of most of the route. Because of the War of 1812 and the lack of U.S. fur trading posts in the Pacific Northwest, most of the route was unused for more than 10 years.
The North West Company and Hudson's Bay Company.
In August 1811, three months after Fort Astor was established, David Thompson and his team of British North West Company explorers came floating down the Columbia to Fort Astoria. He had just completed a journey through much of western Canada and most of the Columbia River drainage system. He was mapping the country for possible fur trading posts. Along the way he camped at the confluence of the Columbia and Snake rivers and posted a notice claiming the land for Britain and stating the intention of the North West Company to build a fort on the site (Fort Nez Perces was later established there). Astor, concerned the British navy would seize their forts and supplies in the War of 1812, sold to the North West Company in 1812 their forts, supplies and furs on the Columbia and Snake River. The North West Company started establishing more forts and trading posts of their own.
By 1821, when armed hostilities broke out with their Hudson's Bay Company (HBC) rivals, the North West Company was pressured by the British government to merge with the HBC. The HBC had nearly a complete monopoly on trading (and most governing issues) in the Columbia District, or Oregon Country as it was referred to by the Americans, and also in Rupert's Land. That year the British parliament passed a statute applying the laws of Upper Canada to the district and giving the HBC power to enforce those laws.
From 1812 to 1840 the British, through the HBC, had nearly complete control of the Pacific Northwest and the western half of the Oregon Trail. In theory, the Treaty of Ghent, which ended the War of 1812, restored possession of Oregon territory to the United States. "Joint occupation" of the region was formally established by the Anglo-American Convention of 1818. The British, through the HBC, tried to discourage any U.S. trappers, traders and settlers from work or settlement in the Pacific Northwest.
By overland travel, American missionaries and early settlers (initially mostly ex-trappers) started showing up in Oregon around 1824. Although officially the HBC discouraged settlement because it interfered with their lucrative fur trade, their Chief Factor at Fort Vancouver, John McLoughlin, gave substantial help, including employment, until they could get established. In the early 1840s thousands of American settlers arrived and soon greatly outnumbered the British settlers in Oregon. McLoughlin, despite working for the HBC, gave help in the form of loans, medical care, shelter, clothing, food, supplies and seed to U.S. emigrants. These new emigrants often arrived in Oregon tired, worn out, nearly penniless, with insufficient food or supplies, just as winter was coming on. McLoughlin would later be hailed as the Father of Oregon.
The York Factory Express, establishing another route to the Oregon territory, evolved from an earlier express brigade used by the North West Company between Fort Astoria and Fort William, Ontario on Lake Superior. By 1825 the HBC started using two brigades, each setting out from opposite ends of the express route—one from Fort Vancouver on the Columbia River and the other from York Factory on Hudson Bay—in spring and passing each other in the middle of the continent. This established a "quick"—about 100 days for one way—to resupply their forts and fur trading centers as well as collecting the furs the posts had bought and transmitting messages between Fort Vancouver and York Factory on Hudson Bay.
The HBC built a new much larger Fort Vancouver in 1824 slightly upstream of Fort Astoria on the north side of the Columbia River (they were hoping the Columbia would be the future Canada–U.S. border). The fort quickly became the center of activity in the Pacific Northwest. Every year ships would come from London to the Pacific (via Cape Horn) to drop off supplies and trade goods in their trading posts in the Pacific Northwest and pick up the accumulated furs used to pay for these supplies. It was the nexus for the fur trade on the Pacific Coast; its influence reached from the Rocky Mountains to the Hawaiian Islands, and from Russian Alaska into Mexican-controlled California. At its pinnacle in about 1840, Fort Vancouver and its Factor (manager) watched over 34 outposts, 24 ports, 6 ships, and about 600 employees.
When American emigration over the Oregon Trail began in earnest in the early 1840s, for many settlers the fort became the last stop on the Oregon Trail where they could get supplies, aid and help before starting their homestead. Fort Vancouver was the main re-supply point for nearly all Oregon trail travelers until U.S. towns could be established. The HBC established Fort Colville in 1825 on the Columbia River near Kettle Falls as a good site to collect furs and control the upper Columbia River fur trade. Fort Nisqually was built near the present town of DuPont, Washington and was the first HBC fort on Puget Sound. Fort Victoria was erected in 1843 and became the headquarters of operations in British Columbia, eventually growing into modern-day Victoria, the capital city of British Columbia.
By 1840 the HBC had three forts: Fort Hall (purchased from Nathaniel Jarvis Wyeth in 1837), Fort Boise and Fort Nez Perce on the western end of the Oregon Trail route as well as Fort Vancouver near its terminus in the Willamette Valley. With minor exceptions they all gave substantial and often desperately needed aid to the early Oregon Trail pioneers.
When the fur trade slowed in 1840 because of fashion changes in men's hats, the value of the Pacific Northwest to the British was seriously diminished. Canada had few potential settlers who were willing to move more than to the Pacific Northwest, although several hundred ex-trappers, British and American, and their families did start settling in Oregon, Washington and California. They used most of the York Express route through northern Canada. In 1841 James Sinclair, on orders from Sir George Simpson, guided nearly 200 settlers from the Red River Colony (located at the junction of the Assiniboine River and Red River near present Winnipeg, Canada) into the Oregon territory. This attempt at settlement failed when most of the families joined the settlers in the Willamette Valley, with their promise of free land and HBC-free government.
In 1846 the Oregon Treaty ending the Oregon boundary dispute was signed with Britain. The British lost the land north of the Columbia River they had so long controlled. The new Canada–United States border was established much further north at the 49th parallel. The treaty granted the HBC navigation rights on the Columbia River for supplying their fur posts, clear titles to their trading post properties allowing them to be sold later if they wanted, and left the British with good anchorages at Vancouver and Victoria. It gave the United States what it mostly wanted, a "reasonable" boundary and a good anchorage on the West Coast in Puget Sound. While there were almost no United States settlers in the future state of Washington in 1846, the United States had already demonstrated it could induce thousands of settlers to go to the Oregon Territory, and it would be only a short time before they would vastly outnumber the few hundred HBC employees and retirees living in Washington.
Great American Desert.
Reports from expeditions in 1806 by Lieutenant Zebulon Pike and in 1819 by Major Stephen Long described the Great Plains as "unfit for human habitation" and as "The Great American Desert". These descriptions were mainly based on the relative lack of timber and surface water. The images of sandy wastelands conjured up by terms like "desert" were tempered by the many reports of vast herds of millions of Plains Bison that somehow managed to live in this "desert". In the 1840s, the Great Plains appeared to be unattractive for settlement and were illegal for homesteading until well after 1846 — initially it was set aside by the U.S. government for Indian settlements. The next available land for general settlement, Oregon, appeared to be free for the taking and had fertile lands, disease free climate (yellow fever and malaria were prevalent in much of the Missouri and Mississippi River drainage then), extensive uncut, unclaimed forests, big rivers, potential seaports, and only a few nominally British settlers.
Fur traders, trappers and explorers.
Fur trappers, often working for fur traders, followed nearly all possible streams looking for beaver in the years (1812–40) the fur trade was active. Fur traders included Manuel Lisa, Robert Stuart, William Henry Ashley, Jedediah Smith, William Sublette, Andrew Henry, Thomas Fitzpatrick, Kit Carson, Jim Bridger, Peter Skene Ogden, David Thompson, James Douglas, Donald Mackenzie, Alexander Ross, James Sinclair, and other mountain men. Besides discovering and naming many of the rivers and mountains in the Intermountain West and Pacific Northwest they often kept diaries of their travels and were available as guides and consultants when the trail started to become open for general travel. The fur trade business wound down to a very low level just as the Oregon trail traffic seriously began around 1840.
In fall of 1823, Jedediah Smith and Thomas Fitzpatrick led their trapping crew south from the Yellowstone River to the Sweetwater River. They were looking for a safe location to spend the winter. Smith reasoned since the Sweetwater flowed east it must eventually run into the Missouri River. Trying to transport their extensive fur collection down the Sweetwater and North Platte River, they found after a near disastrous canoe crash that the rivers were too swift and rough for water passage. On July 4, 1824, they cached their furs under a dome of rock they named Independence Rock and started their long trek on foot to the Missouri River. Upon arriving back in a settled area they bought pack horses (on credit) and retrieved their furs. They had re-discovered the route that Robert Stuart had taken in 1813—eleven years before. Thomas Fitzpatrick was often hired as a guide when the fur trade dwindled in 1840. Jedediah Smith was killed by Indians around 1831.
Up to 3,000 mountain men were trappers and explorers, employed by various British and United States fur companies or working as free trappers, who roamed the North American Rocky Mountains from about 1810 to the early 1840s. They usually traveled in small groups for mutual support and protection. Trapping took place in the fall when the fur became prime. Mountain men primarily trapped beaver and sold the skins. A good beaver skin could bring up to $4 at a time when a man's wage was often $1 per day. Some were more interested in exploring the West. In 1825, the first significant American Rendezvous occurred on the Henry's Fork of the Green River. The trading supplies were brought in by a large party using pack trains originating on the Missouri River. These pack trains were then used to haul out the fur bales. They normally used the north side of the Platte River—the same route used 20 years later by the Mormon Trail. For the next 15 years the American rendezvous was an annual event moving to different locations, usually somewhere on the Green River in the future state of Wyoming. Each rendezvous, occurring during the slack summer period, allowed the fur traders to trade for and collect the furs from the trappers and their Indian allies without having the expense of building or maintaining a fort or wintering over in the cold Rockies. In only a few weeks at a rendezvous a year's worth of trading and celebrating would take place as the traders took their furs and remaining supplies back east for the winter and the trappers faced another fall and winter with new supplies. Trapper Jim Beckwourth described the scene as one of "Mirth, songs, dancing, shouting, trading, running, jumping, singing, racing, target-shooting, yarns, frolic, with all sorts of extravagances that white men or Indians could invent." In 1830, William Sublette brought the first wagons carrying his trading goods up the Platte, North Platte, and Sweetwater rivers before crossing over South Pass to a fur trade rendezvous on the Green River near the future town of Big Piney, Wyoming. He had a crew that dug out the gullies and river crossings and cleared the brush where needed. This established that the eastern part of most of the Oregon Trail was passable by wagons. In the late 1830s the HBC instituted a policy intended to destroy or weaken the American fur trade companies. The HBC's annual collection and re-supply Snake River Expedition was transformed to a trading enterprise. Beginning in 1834, it visited the American Rendezvous to undersell the American traders—losing money but undercutting the American fur traders. By 1840 the fashion in Europe and Britain shifted away from the formerly very popular beaver felt hats and prices for furs rapidly declined and the trapping almost ceased.
Fur traders tried to use the Platte River, the main route of the eastern Oregon Trail, for transport but soon gave up in frustration as its many channels and islands combined with its muddy waters were too shallow, crooked and unpredictable to use for water transport. The Platte proved to be unnavigable. The Platte River and North Platte River Valley, however, became an easy roadway for wagons, with its nearly flat plain sloping easily up and heading almost due west.
There were several U.S. government-sponsored explorers who explored part of the Oregon Trail and wrote extensively about their explorations. Captain Benjamin Bonneville on his expedition of 1832 to 1834 explored much of the Oregon trail and brought wagons up the Platte, North Platte, Sweetwater route across South Pass to the Green River in Wyoming. He explored most of Idaho and the Oregon Trail to the Columbia. The account of his explorations in the west was published by Washington Irving in 1838.). John C. Frémont of the U.S. Army's Corps of Topographical Engineers and his guide Kit Carson led three expeditions from 1842 to 1846 over parts of California and Oregon. His explorations were written up by him and his wife Jessie Benton Frémont and were widely published. The first "decent" map of California and Oregon were drawn by Frémont and his topographers and cartographers in about 1848.
Missionaries.
In 1834, The Dalles Methodist Mission was founded by Reverend Jason Lee just east of Mount Hood on the Columbia River. In 1836, Henry H. Spalding and Marcus Whitman traveled west to establish the Whitman Mission near modern-day Walla Walla, Washington. The party included the wives of the two men, Narcissa Whitman and Eliza Hart Spalding, who became the first European-American women to cross the Rocky Mountains. En route, the party accompanied American fur traders going to the 1836 rendezvous on the Green River in Wyoming and then joined Hudson's Bay Company fur traders traveling west to Fort Nez Perce (also called Fort Walla Walla). The group was the first to travel in wagons all the way to Fort Hall, where the wagons were abandoned at the urging of their guides. They used pack animals for the rest of the trip to Fort Walla Walla and then floated by boat to Fort Vancouver to get supplies before returning to start their missions. Other missionaries, mostly husband and wife teams using wagon and pack trains, established missions in the Willamette Valley, as well as various locations in the future states of Washington, Oregon, and Idaho.
Early emigrants.
On May 1, 1839, a group of eighteen men from Peoria, Illinois, set out with the intention of colonizing the Oregon country on behalf of the United States of America and drive out the HBC operating there. The men of the Peoria Party were among the first pioneers to traverse most of the Oregon Trail. The men were initially led by Thomas J. Farnham and called themselves the Oregon Dragoons. They carried a large flag emblazoned with their motto ""Oregon Or The Grave"". Although the group split up near Bent's Fort on the South Platte and Farnham was deposed as leader, nine of their members eventually did reach Oregon.
In September 1840, Robert Newell, Joseph L. Meek, and their families reached Fort Walla Walla with three wagons that they had driven from Fort Hall. Their wagons were the first to reach the Columbia River over land, and they opened the final leg of Oregon Trail to wagon traffic.
In 1841 the Bartleson-Bidwell Party was the first emigrant group credited with using the Oregon Trail to emigrate west. The group set out for California, but about half the party left the original group at Soda Springs, Idaho, and proceeded to the Willamette Valley in Oregon, leaving their wagons at Fort Hall.
On May 16, 1842, the second organized wagon train set out from Elm Grove, Missouri, with more than 100 pioneers. The party was led by Elijah White. The group broke up after passing Fort Hall with most of the single men hurrying ahead and the families following later.
Great Migration of 1843.
In what was dubbed "The Great Migration of 1843" or the "Wagon Train of 1843", an estimated 700 to 1,000 emigrants left for Oregon. They were led initially by John Gantt, a former U.S. Army Captain and fur trader who was contracted to guide the train to Fort Hall for $1 per person. The winter before, Marcus Whitman had made a brutal mid-winter trip from Oregon to St. Louis to appeal a decision by his Mission backers to abandon several of the Oregon missions. He joined the wagon train at the Platte River for the return trip. When the pioneers were told at Fort Hall by agents from the Hudson's Bay Company that they should abandon their wagons there and use pack animals the rest of the way, Whitman disagreed and volunteered to lead the wagons to Oregon. He believed the wagon trains were large enough that they could build whatever road improvements they needed to make the trip with their wagons. The biggest obstacle they faced was in the Blue Mountains of Oregon where they had to cut and clear a trail through heavy timber. The wagons were stopped at The Dalles, Oregon by the lack of a road around Mount Hood. The wagons had to be disassembled and floated down the treacherous Columbia River and the animals herded over the rough Lolo trail to get by Mt. Hood. Nearly all of the settlers in the 1843 wagon trains arrived in the Willamette Valley by early October. A passable wagon trail now existed from the Missouri River to The Dalles. In 1846, the Barlow Road was completed around Mount Hood, providing a rough but completely passable wagon trail from the Missouri River to the Willamette Valley: about .
Oregon Country.
In 1843, settlers of the Willamette Valley drafted the Organic Laws of Oregon organizing land claims within the Oregon Country. Married couples were granted at no cost (except for the requirement to work and improve the land) up to (a section or square mile), and unmarried settlers could claim . As the group was a provisional government with no authority, these claims were not valid under United States or British law, but they were eventually honored by the United States in the Donation Land Act of 1850. The Donation Land Act provided for married settlers to be granted and unmarried settlers . Following the expiration of the act in 1854 the land was no longer free but cost $1.25 per acre ($3.09/hectare) with a limit of —the same as most other unimproved government land.
Women on the Overland Trail.
Historians are reassessing the experiences of women traveling on the Overland Trails. Past interpretations, as found in John Faragher’s book, "Women and Men on the Overland Trail" (1979), held that men and women’s power within marriage was uneven. This meant that women did not experience the trail as liberating, but instead only found harder work than they had handled back east. However, scholarship, by historians such as Lillian Schlissel, Sandra Myres, and Glenda Riley, tells a very different story. In the new interpretation of the women’s experiences on the trail and in the West women no longer quietly followed behind their husbands, supporting all their decisions. Men and women did not view the West and western migration in the same way. Whereas men might deem the dangers of the trail acceptable if there was a strong economic reward at the end, women viewed those dangers as threatening to the stability and survival of the family. Women’s fears differed from men because their priorities were different. In addition, once they arrived at their new western home, women’s public role in building western communities and participating in the western economy gave them a greater authority than they had known back East. There was a “female frontier” that was distinct and different from that experienced by men.
Women’s diaries kept during their travels or the letters they wrote home once they arrived at their destination supports these contentions. Women wrote with sadness and concern of the numerous deaths along the trail. Anna Maria King wrote to her family in 1845 about her trip to the Luckiamute Valley Oregon and of the multiple deaths experienced by her traveling group. “But listen to the deaths: Sally Chambers, John King and his wife, their little daughter Electa and their babe, a son 9 months old, and Dulancy C. Norton’s sister are gone. Mr. A. Fuller lost his wife and daughter Tabitha. Eight of our two families have gone to their long home.” Anna, like many other women, also advised family and friends back home of the realities of the trip and offered advice on how to prepare for the trip. Women also reacted and responded, often enthusiastically, to the landscape of the West. Betsey Bayley in a letter to her sister, Lucy P. Griffith described how travelers responded to the new environment they encountered. “The mountains looked like volcanoes and the appearance that one day there had been an awful thundering of volcanoes and a burning world. The valleys were all covered with a white crust and looked like salaratus. Some of the company used it to raise their bread.”
Mormon emigration.
Following persecution and mob action in Missouri, Illinois, and other states, and the assassination of their prophet Joseph Smith in 1844, Mormon leader Brigham Young was chosen by the leaders of the Latter Day Saints (LDS) church to lead the LDS settlers west. He chose to lead his people to the Salt Lake Valley in present-day Utah. In 1847 Young led a small, especially picked fast-moving group of men and women from their Winter Quarters encampments near Omaha, Nebraska, and their approximately 50 temporary settlements on the Missouri River in Iowa including Council Bluffs. About 2,200 LDS pioneers went that first year as they filtered in from Mississippi, Colorado, California, and several other states. The initial pioneers were charged with establishing farms, growing crops, building fences and herds, and establishing preliminary settlements to feed and support the many thousands of emigrants expected in the coming years. After ferrying across the Missouri River and establishing wagon trains near what became Omaha, the Mormons followed the northern bank of the Platte River in Nebraska to Fort Laramie in present-day Wyoming. They initially started out in 1848 with trains of several thousand emigrants, which were rapidly split into smaller groups to be more easily accommodated at the limited springs and acceptable camping places on the trail. Organized as a complete evacuation from their previous homes, farms, and cities in Illinois, Missouri, and Iowa, this group consisted of entire families with no one left behind. The much larger presence of women and children meant these wagon trains did not try to cover as much ground in a single day as Oregon and California bound emigrants did, typically taking about 100 days to cover the trip to Salt Lake City. (The Oregon and California emigrants typically averaged about per day.) In Wyoming the Mormon emigrants followed the main Oregon/California/Mormon Trail through Wyoming to Fort Bridger, where they split from the main trail and followed (and improved) the crude path established by the ill-fated Donner Party of 1846 into Utah and the Salt Lake Valley.
Between 1847 and 1860 over 43,000 Mormon settlers and tens of thousands of travelers on the California Trail and Oregon Trail followed Young to Utah. After 1848, the travelers headed to California or Oregon resupplied at the Salt Lake Valley, and then went back over the Salt Lake Cutoff, rejoining the trail near the future Idaho–Utah border at the City of Rocks in Idaho.
Starting in 1855, many of the poorer Mormon travelers made the trek with hand built handcarts and fewer wagons. Guided by experienced guides, handcarts—pulled and pushed by two to four people—were as fast as ox-drawn wagons and allowed them to bring of possessions plus some food, bedding, and tents to Utah. Accompanying wagons carried more food and supplies. Upon arrival in Utah, the handcart pioneers were given or found jobs and accommodations by individual Mormon families for the winter until they could become established. About 3,000 out of over 60,000 Mormon pioneers came across with handcarts.
Along the Mormon Trail, the Mormon pioneers established a number of ferries and made trail improvements to help later travelers and earn much needed money. One of the better known ferries was the Mormon Ferry across the North Platte near the future site of Fort Caspar in Wyoming which operated between 1848 and 1852 and the Green River ferry near Fort Bridger which operated from 1847 to 1856. The ferries were free for Mormon settlers while all others were charged a toll of from $3 to $8.
California Gold Rush.
In January 1848, James Marshall found gold in the Sierra Nevada portion of the American River, sparking the California Gold Rush. It is estimated that about two-thirds of the male population in Oregon went to California in 1848 to cash in on the opportunity. To get there, they helped build the Lassen Branch of the Applegate-Lassen Trail by cutting a wagon road through extensive forests. Many returned with significant gold which helped jump-start the Oregon economy. Over the next decade, gold seekers from the Midwestern United States and East Coast of the United States dramatically increased traffic on the Oregon and California Trails. The "forty-niners" often chose speed over safety and opted to use shortcuts such as the Sublette-Greenwood Cutoff in Wyoming which reduced travel time by almost seven days but spanned nearly of desert without water, grass, or fuel for fires. 1849 was the first year of large scale cholera epidemics in the United States, and thousands are thought to have died along the trail on their way to California—most buried in unmarked graves in Kansas and Nebraska. The "adjusted" 1850 U.S. Census of California showed this rush was overwhelmingly male with about 112,000 males to 8,000 females (with about 5,500 women over age 15). Women were significantly underrepresented in the California Gold Rush, and sex ratios did not reach essential equality in California (and other western states) until about 1950. The relative scarcity of women gave them many opportunities to do many more things that were not "normally" considered "women's work" of this era. After 1849 the California Gold Rush continued for several years as the miners continued to find about $50,000,000 worth of gold per year at $21 per ounce. Once California was established as a prosperous state many thousands more emigrated there each year for the opportunities.
Later emigration and uses of the trail.
The trail was still in use during the Civil War, but traffic declined after 1855 when the Panama Railroad across the Isthmus of Panama was completed. Paddle wheel steamships and sailing ships, often heavily subsidized to carry the mail, provided rapid transport to and from the east coast and New Orleans, Louisiana, to and from Panama to ports in California and Oregon.
Over the years many ferries were established to help get across the many rivers on the path of the Oregon Trail. Multiple ferries were established on the Missouri River, Kansas River, Little Blue River, Elkhorn River, Loup River, Platte River, South Platte River, North Platte River, Laramie River, Green River, Bear River, two crossings of the Snake River, John Day River, Deschutes River, Columbia River, as well as many other smaller streams. During peak immigration periods several ferries on any given river often competed for pioneer dollars. These ferries significantly increased speed and safety for Oregon Trail travelers. They increased the cost of traveling the trail by roughly $30 per wagon but increased the speed of the transit from about 160 to 170 days in 1843 to 120 to 140 days in 1860. Ferries also helped prevent death by drowning at river crossings.
In April 1859, an expedition of U.S. Corps of Topographical Engineers led by Captain James H. Simpson left Camp Floyd, Utah, to establish an army supply route across the Great Basin to the eastern slope of the Sierras. Upon return in early August, Simpson reported that he had surveyed the Central Overland Route from Camp Floyd to Genoa, Nevada. This route went through central Nevada (roughly where U.S. Route 50 goes today) and was about shorter than the "standard" Humboldt River California trail route.
The Army improved the trail for use by wagons and stagecoaches in 1859 and 1860. Starting in 1860, the American Civil War closed the heavily subsidized Butterfield Overland Mail stage Southern Route through the deserts of the American Southwest.
In 1860–61 the Pony Express, employing riders traveling on horseback day and night with relay stations about every to supply fresh horses, was established from St. Joseph, Missouri, to Sacramento, California. The Pony Express built many of their eastern stations along the Oregon/California/Mormon/Bozeman trails and many of their western stations along the very sparsely settled Central Route across Utah and Nevada. The Pony Express delivered mail summer and winter in roughly 10 days from the midwest to California.
In 1861 John Butterfield, who since 1858 had been using the Butterfield Overland Mail, also switched to the Central Route to avoid traveling through hostile territories during the American Civil War. George Chorpenning immediately realized the value of this more direct route, and shifted his existing mail and passenger line along with their stations from the "Northern Route" (California Trail) along the Humboldt River. In 1861 the First Transcontinental Telegraph also laid its lines alongside the Central Overland Route. Several stage lines were set up carrying mail and passengers that traversed much of the route of the original Oregon Trail to Fort Bridger and from there over the Central Overland Route to California. By traveling day and night with many stations and changes of teams (and extensive mail subsidies) these stages could get passengers and mail from the midwest to California in about 25 to 28 days. These combined stage and Pony Express stations along the Oregon Trail and Central Route across Utah and Nevada were joined by the First Transcontinental Telegraph stations and telegraph line, which followed much the same route in 1861 from Carson City, Nevada to Salt Lake City. The Pony Express folded in 1861 as they failed to receive an expected mail contract from the U.S. government and the telegraph filled the need for rapid east–west communication. This combination wagon/stagecoach/pony express/telegraph line route is labeled the "Pony Express National Historic Trail" on the National Trail Map. From Salt Lake City the telegraph line followed much of the Mormon/California/Oregon trails to Omaha, Nebraska.
After the First Transcontinental Railroad was completed in 1869, telegraph lines usually followed the railroad tracks as the required relay stations and telegraph lines were much easier to maintain alongside the tracks. Telegraph lines to unpopulated areas were largely abandoned.
As the years passed, the Oregon Trail became a heavily used corridor from the Missouri River to the Columbia River. Offshoots of the trail continued to grow as gold and silver discoveries, farming, lumbering, ranching, and business opportunities resulted in much more traffic to many areas. Traffic became two-directional as towns were established along the trail. By 1870 the population in the states served by the Oregon Trail and its offshoots increased by about 350,000 over their 1860 census levels. With the exception of most of the 180,000 population increase in California, most of these people living away from the coast traveled over parts of the Oregon Trail and its many extensions and cutoffs to get to their new residences.
Even before the famous Texas cattle drives after the Civil War, the trail was being used to drive herds of thousands of cattle, horses, sheep, and goats from the midwest to various towns and cities along the trails. According to studies by trail historian John Unruh the livestock may have been as plentiful or more plentiful than the immigrants in many years. In 1852 there were even records of a 1,500-turkey drive from Illinois to California. The main reason for this livestock traffic was the large cost discrepancy between livestock in the midwest and at the end of the trail in California, Oregon, or Montana. They could often be bought in the midwest for about 1/3 to 1/10 what they would fetch at the end of the trail. Large losses could occur and the drovers would still make significant profit. As the emigrant travel on the trail declined in later years and after livestock ranches were established at many places along the trail large herds of animals often were driven along part of the trail to get to and from markets.
Trail decline.
The first transcontinental railroad was completed in 1869, providing faster, safer, and usually cheaper travel east and west (the journey took seven days and cost as little as $65). Some emigrants continued to use the trail well into the 1890s, and modern highways and railroads eventually paralleled large portions of the trail, including U.S. Highway 26, Interstate 84 in Oregon and Idaho and Interstate 80 in Nebraska. Contemporary interest in the overland trek has prompted the states and federal government to preserve landmarks on the trail including wagon ruts, buildings, and "registers" where emigrants carved their names. Throughout the 20th and 21st centuries there have been a number of re-enactments of the trek with participants wearing period garments and traveling by wagon.
Routes.
As the trail developed it became marked by many cutoffs and shortcuts from Missouri to Oregon. The basic route follows river valleys as grass and water were absolutely necessary.
While the first few parties organized and departed from Elm Grove, the Oregon Trail's primary starting point was Independence, Missouri, or Westport, (which was annexed into modern day Kansas City), on the Missouri River. Later, several feeder trails led across Kansas, and some towns became starting points, including Weston, Fort Leavenworth, Atchison, St. Joseph, and Omaha.
The Oregon Trail's nominal termination point was Oregon City, at the time the proposed capital of the Oregon Territory. However, many settlers branched off or stopped short of this goal and settled at convenient or promising locations along the trail. Commerce with pioneers going further west helped establish these early settlements and launched local economies critical to their prosperity.
At dangerous or difficult river crossings, ferries or toll bridges were set up and bad places on the trail were either repaired or bypassed. Several toll roads were constructed. Gradually the trail became easier with the average trip (as recorded in numerous diaries) dropping from about 160 days in 1849 to 140 days 10 years later.
Many other trails followed the Oregon Trail for much of its length, including the Mormon Trail from Illinois to Utah; the California Trail to the gold fields of California; and the Bozeman Trail to Montana. Because it was more a network of trails than a single trail, there were numerous variations with other trails eventually established on both sides of the Platte, North Platte, Snake, and Columbia rivers. With literally thousands of people and thousands of livestock traveling in a fairly small time slot the travelers had to spread out to find clean water, wood, good campsites, and grass. The dust kicked up by the many travelers was a constant complaint, and where the terrain would allow it there may be between 20 and 50 wagons traveling abreast.
Remnants of the trail in Kansas, Nebraska, Wyoming, Idaho, and Oregon have been listed on the National Register of Historic Places, and the entire trail is a designated National Historic Trail (listed as the Oregon National Historic Trail).
Missouri.
Initially, the main "jumping off point" was the common head of the Santa Fe Trail and Oregon trail—Independence, and Kansas City. Travelers starting in Independence had to ferry across the Missouri River. After following the Santa Fe trail to near present-day Topeka, they ferried across the Kansas River to start the trek across Kansas and points west. Another busy "jumping off point" was St. Joseph—established in 1843. In its early days, St. Joseph was a bustling outpost and rough frontier town, serving as one of the last supply points before heading over the Missouri River to the frontier. St. Joseph had good steamboat connections to St. Louis and other ports on the combined Ohio, Missouri, and Mississippi River systems. During the busy season there were several ferry boats and steamboats available to transport travelers to the Kansas shore where they started their travels westward. Before the Union Pacific Railroad was started in 1865, St. Joseph was the westernmost point in the United States accessible by rail. Other towns used as supply points in Missouri included Old Franklin, Arrow Rock, and Fort Osage.
Iowa.
In 1803 President Thomas Jefferson obtained from France the Louisiana Purchase for $15 million (equivalent to about $230 million today) which included all the land drained by the Missouri River and roughly doubled the size of U.S. territory. The future states of Iowa and Missouri, located west of the Mississippi River and east of Missouri River, were part of this purchase. The Lewis and Clark Expedition stopped several times in the future state of Iowa on their 1805–1806 expedition to the west coast. A disputed 1804 treaty between Quashquame and William Henry Harrison (future ninth President of the U.S.) that surrendered much of the future state of Illinois to the U.S. enraged many Sauk (Sac) Indians and led to the 1832 Black Hawk War. As punishment for the uprising, and as part of a larger settlement strategy, treaties were subsequently designed to remove all Indians from Iowa Territory. Some settlers started drifting into Iowa in 1833. President Martin Van Buren on July 4, 1838, signed the U.S. Congress laws establishing the Territory of Iowa. Iowa was located opposite the junction of the Platte and Missouri rivers and was used by some of the fur trapper rendezvous traders as a starting point for their supply expeditions. In 1846 the Mormons, expelled from Nauvoo, Illinois, traversed Iowa (on part of the Mormon Trail) and settled temporarily in significant numbers on the Missouri River in Iowa and the future state of Nebraska at their Winter Quarters near the future city of Omaha, Nebraska. (See: Missouri River settlements (1846–1854)) The Mormons established about 50 temporary towns including the town of Kanesville, Iowa (renamed Council Bluffs in 1852) on the east bank of the Missouri River opposite the mouth of the Platte River. For those travelers to Oregon, California, and Utah who were bringing their teams to the Platte River junction Kanesville and other towns became major "jumping off places" and supply points. In 1847 the Mormons established three ferries across the Missouri River and others established even more ferries for the spring start on the trail. In the 1850 census there were about 8,000 mostly Mormons tabulated in the large Pottawattamie County, Iowa District 21. (The original Pottawattamie County was subsequently made into five counties and parts of several more.) By 1854 most of the Mormon towns, farms and villages were largely taken over by non-Mormons as they abandoned them or sold them for not much and continued their migration to Utah. After 1846 the towns of Council Bluffs, Iowa, Omaha (est. 1852) and other Missouri River towns became major supply points and "jumping off places" for travelers on the Mormon, California, Oregon, and other trails west.
Kansas.
Starting initially in Independence, Missouri, or Kansas City in Missouri, the initial trail follows the Santa Fe Trail into Kansas south of the Wakarusa River. After crossing Mount Oread at Lawrence, the trail crosses the Kansas River by ferry or boats near Topeka and crossed the Wakarusa and Vermillion rivers by ferries. After the Vermillion River the trail angles northwest to Nebraska paralleling the Little Blue River until reaching the south side of the Platte River. Travel by wagon over the gently rolling Kansas countryside was usually unimpeded except where streams had cut steep banks. There a passage could be made with a lot of shovel work to cut down the banks or the travelers could find an already established crossing.
Nebraska.
Those emigrants on the eastern side of the Missouri River in Missouri or Iowa used ferries and steamboats (fitted out for ferry duty) to cross into towns in Nebraska. Several towns in Nebraska were used as "jumping off places" with Omaha eventually becoming a favorite after about 1855. Fort Kearny (est. 1848) is about from the Missouri River, and the trail and its many offshoots nearly all converged close to Fort Kearny as they followed the Platte River west. The army maintained fort was the first chance on the trail to buy emergency supplies, do repairs, get medical aid, or mail a letter. Those on the north side of the Platte could usually wade the shallow river if they needed to visit the fort.
The Platte River and the North Platte River in the future states of Nebraska and Wyoming typically had many channels and islands and were too shallow, crooked, muddy and unpredictable for travel even by canoe. The Platte as it pursued its braided paths to the Missouri River was "too thin to plow and too thick to drink". While unusable for transportation, the Platte River and North Platte River valleys provided an easily passable wagon corridor going almost due west with access to water, grass, buffalo, and buffalo chips for fuel. The trails gradually got rougher as it progressed up the North Platte. There were trails on both sides of the muddy rivers. The Platte was about wide and deep. The water was silty and bad tasting but it could be used if no other water was available. Letting it sit in a bucket for an hour or so or stirring in a 1/4 cup of cornmeal allowed most of the silt to settle out. Those traveling south of the Platte crossed the South Platte River with its muddy and treacherous crossings using one of about three ferries (in dry years it could sometimes be forded without a ferry) before continuing up the North Platte River Valley to Fort Laramie in present-day Wyoming. After crossing over the South Platte the travelers encountered Ash Hollow with its steep descent down Windlass Hill.
In the spring in Nebraska and Wyoming the travelers often encountered fierce wind, rain and lightning storms. Until about 1870 travelers encountered hundreds of thousands of bison migrating through Nebraska on both sides of the Platte River, and most travelers killed several for fresh meat and to build up their supplies of dried jerky for the rest of the journey. The prairie grass in many places was several feet high with only the hat of a traveler on horseback showing as they passed through the prairie grass. In many years the Indians fired much of the dry grass on the prairie every fall so the only trees or bushes available for firewood were on islands in the Platte River. Travelers gathered and ignited dried cow dung to cook their meals. These burned fast in a breeze, and it could take two or more bushels of chips to get one meal prepared. Those traveling south of the Platte crossed the South Platte fork at one of about three ferries (in dry years it could be forded without a ferry) before continuing up the North Platte River Valley into present-day Wyoming heading to Fort Laramie. Before 1852 those on the north side of the Platte crossed the North Platte to the south side at Fort Laramie. After 1852 they used Child's Cutoff to stay on the north side to about the present day town of Casper, Wyoming, where they crossed over to the south side.
Notable landmarks in Nebraska include Courthouse and Jail Rocks, Chimney Rock, Scotts Bluff, and Ash Hollow State Historical Park.
Today much of the Oregon Trail follows roughly along Interstate 80 from Wyoming to Grand Island, Nebraska. From there U.S. Highway 30 which follows the Platte River is a better approximate path for those traveling the north side of the Platte. The National Park Service (NPS) gives traveling advice for those who want to follow other branches of the trail.
Cholera on the Platte River.
Because of the Platte's brackish water, the preferred camping spots were along one of the many fresh water streams draining into the Platte or the occasional fresh water spring found along the way. These preferred camping spots became sources of cholera in the epidemic years (1849–1855) as many thousands of people used the same camping spots with essentially no sewage facilities or adequate sewage treatment. One of the side effects of cholera is acute diarrhea which helps contaminate even more water unless it is isolated and/or treated. The cause of cholera, ingesting the "Vibrio cholerae" bacterium from contaminated water, and the best treatment for cholera infections were unknown in this era. Thousands of travelers on the combined California, Oregon, and Mormon trails succumbed to cholera between 1849 and 1855. Most were buried in unmarked graves in Kansas, Nebraska and Wyoming. There are many cases cited involving people who were alive and apparently healthy in the morning and dead by nightfall.
Colorado.
A branch of the Oregon trail crossed the very northeast corner of Colorado if they followed the South Platte River to one of its last crossings. This branch of the trail passed through present day Julesburg before entering Wyoming. Later settlers followed the Platte and South Platte Rivers into their settlements there (much of which became the state of Colorado).
Wyoming.
After crossing the South Platte River the Oregon Trail follows the North Platte River out of Nebraska into Wyoming. Fort Laramie, at the confluence of the Laramie and North Platte rivers, was a major stopping point. Fort Laramie was a former fur trading outpost originally named Fort John that was purchased in 1848 by the U.S. Army to protect travelers on the trails. It was the last army outpost till travelers reached the coast.
Fort Laramie was the end of most cholera outbreaks which killed thousands along the lower Platte and North Platte from 1849 to 1855. Spread by cholera bacteria in fecal contaminated water, cholera caused massive diarrhea, leading to dehydration and death. In those days its cause and treatment were unknown, and it was often fatal—up to 30 percent of infected people died. It is believed that the swifter flowing rivers in Wyoming helped prevent the germs from spreading.
After crossing the South Platte the trail continues up the North Platte River, crossing many small swift-flowing creeks. As the North Platte veers to the south, the trail crosses the North Platte to the Sweetwater River Valley, which heads almost due west. Independence Rock is on the Sweetwater River. The Sweetwater would have to be crossed up to nine times before the trail crosses over the Continental Divide at South Pass, Wyoming. From South Pass the trail continues southwest crossing Big Sandy Creek—about wide and deep—before hitting the Green River. Three to five ferries were in use on the Green during peak travel periods. The deep, wide, swift, and treacherous Green River which eventually empties into the Colorado River, was usually at high water in July and August, and it was a dangerous crossing. After crossing the Green, the main trail continued approximately southwest until the Blacks Fork of the Green River and Fort Bridger. From Fort Bridger the Mormon Trail continued southwest following the upgraded Hastings Cutoff through the Wasatch Mountains. From Fort Bridger, the main trail, comprising several variants, veered northwest over the Bear River Divide and descended to the Bear River Valley. The trail turned north following the Bear River past the terminus of the Sublette-Greenwood Cutoff at Smiths Fork and on to the Thomas Fork Valley at the present Wyoming–Idaho border.
Over time, two major heavily used cutoffs were established in Wyoming. The Sublette-Greenwood Cutoff was established in 1844 and cut about off the main route. It leaves the main trail about west of South Pass and heads almost due west crossing Big Sandy Creek and then about of waterless, very dusty desert before reaching the Green River near the present town of La Barge. Ferries here transferred them across the Green River. From there the Sublette-Greenwood Cutoff trail had to cross a mountain range to connect with the main trail near Cokeville in the Bear River Valley.
The Lander Road, formally the Fort Kearney, South Pass, and Honey Lake Wagon Road, was established and built by U.S. government contractors in 1858–59. It was about shorter than the main trail through Fort Bridger with good grass, water, firewood and fishing but it was a much steeper and rougher route, crossing three mountain ranges. In 1859, 13,000 of the 19,000 emigrants traveling to California and Oregon used the Lander Road. The traffic in later years is undocumented.
The Lander Road departs the main trail at Burnt Ranch near South Pass, crosses the Continental Divide north of South Pass and reaches the Green River near the present town of Big Piney, Wyoming. From there the trail followed Big Piney Creek west before passing over the Thompson Pass in the Wyoming Range. It then crosses over the Smith Fork of the Bear River before ascending and crossing another pass on the Salt River Range of mountains and then descending into Star Valley. It exited the mountains near the present Smith Fork road about south of the town of Smoot. The road continued almost due north along the present day Wyoming–Idaho western border through Star Valley. To avoid crossing the Salt River (which drains into the Snake River) which runs down Star Valley the Lander Road crossed the river when it was small and stayed west of the Salt River. After traveling down the Salt River Valley (Star Valley) about north the road turned almost due west near the present town of Auburn, and entered into the present state of Idaho along Stump Creek. In Idaho it followed the Stump Creek valley northwest until it crossed the Caribou Mountains and proceeded past the south end of Grays Lake. The trail then proceeded almost due west to meet the main trail at Fort Hall; alternatively, a branch trail headed almost due south to meet the main trail near the present town of Soda Springs.
Numerous landmarks are located along the trail in Wyoming including Independence Rock, Ayres Natural Bridge and Register Cliff.
Utah.
In 1847, Brigham Young and the Mormon pioneers departed from the Oregon Trail at Fort Bridger in Wyoming and followed (and much improved) the rough trail originally recommended by Lansford Hastings to the Donner Party in 1846 through the Wasatch Mountains into Utah. After getting into Utah they immediately started setting up irrigated farms and cities—including Salt Lake City. In 1848, the Salt Lake Cutoff was established by Sam Hensley, and returning members of the Mormon Battalion providing a path north of the Great Salt Lake from Salt Lake City back to the California and Oregon trails. This cutoff rejoined the Oregon and California Trails near the City of Rocks near the Utah–Idaho border and could be used by both California and Oregon bound travelers. Located about half way on both the California and Oregon trails many thousands of later travelers used Salt Lake City and other Utah cities as an intermediate stop for selling or trading excess goods or tired livestock for fresh livestock, repairs, supplies or fresh vegetables. The Mormons looked on these travelers as a welcome bonanza as setting up new communities from scratch required nearly everything the travelers could afford to part with. The overall distance to California or Oregon was very close to the same whether one "detoured" to Salt Lake City or not. For their own use and to encourage California and Oregon bound travelers the Mormons improved the Mormon Trail from Fort Bridger and the Salt Lake Cutoff trail. To raise much needed money and facilitate travel on the Salt Lake Cutoff they set up several ferries across the Weber, Bear, and Malad rivers, which were used mostly by travelers bound for Oregon or California.
Idaho.
The main Oregon and California Trail went almost due north from Fort Bridger to the Little Muddy Creek where it passed over the Bear River Mountains to the Bear River Valley, which it followed northwest into the Thomas Fork area, where the trail crossed over the present day Wyoming line into Idaho. In the Eastern Sheep Creek Hills in the Thomas Fork valley the emigrants encountered Big Hill. Big Hill was a detour caused by a then-impassable cut the Bear River made through the mountains and had a tough ascent often requiring doubling up of teams and a very steep and dangerous descent. (Much later, U.S. Highway 30, using modern explosives and equipment, was built through this cut). In 1852 Eliza Ann McAuley found and with help developed the McAuley Cutoff which bypassed much of the difficult climb and descent of Big Hill. About on they passed present-day Montpelier, Idaho, which is now the site of the National Oregon-California Trail Center. The trail follows the Bear River northwest to present-day Soda Springs. The springs here were a favorite attraction of the pioneers who marveled at the hot carbonated water and chugging "steamboat" springs. Many stopped and did their laundry in the hot water as there was usually plenty of good grass and fresh water available. Just west of Soda Springs the Bear River turns southwest as it heads for the Great Salt Lake, and the main trail turns northwest to follow the Portneuf River valley to Fort Hall, Idaho. Fort Hall was an old fur trading post located on the Snake River. It was established in 1832 by Nathaniel Jarvis Wyeth and company and later sold in 1837 to the Hudson's Bay Company. At Fort Hall nearly all travelers were given some aid and supplies if they were available and needed. Mosquitoes were constant pests, and travelers often mention that their animals were covered with blood from the bites. The route from Fort Bridger to Fort Hall is about , taking nine to twelve days.
At Soda Springs was one branch of Lander Road (established and built with government contractors in 1858), which had gone west from near South Pass, over the Salt River Mountains and down Star Valley before turning west near present-day Auburn, Wyoming, and entering Idaho. From there it proceeded northwest into Idaho up Stump Creek canyon for about . One branch turned almost 90 degrees and proceeded southwest to Soda Springs. Another branch headed almost due west past Gray's Lake to rejoin the main trail about west of Fort Hall.
On the main trail about west of Soda Springs Hudspeth's Cutoff (established 1849 and used mostly by California trail users) took off from the main trail heading almost due west, bypassing Fort Hall. It rejoined the California Trail at Cassia Creek near the City of Rocks. Hudspeth's Cutoff had five mountain ranges to cross and took about the same amount of time as the main route to Fort Hall, but many took it thinking it was shorter. Its main advantage was that it helped spread out the traffic during peak periods, making more grass available.
West of Fort Hall the main trail traveled about on the south side of the Snake River southwest past American Falls, Massacre Rocks, Register Rock, and Coldwater Hill near present-day Pocatello, Idaho. Near the junction of the Raft River and Snake River the California Trail diverged from the Oregon Trail at another Parting of the Ways junction. Travellers left the Snake River and followed Raft River about southwest past present day Almo. This trail then passed through the City of Rocks and over Granite Pass where it went southwest along Goose Creek, Little Goose Creek, and Rock Spring Creek. It went about through Thousand Springs Valley, West Brush Creek, and Willow Creek, before arriving at the Humboldt River in northeastern Nevada near present-day Wells. The California Trail proceeded west down the Humboldt before reaching and crossing the Sierra Nevadas.
There were only a few places where the Snake River was not buried deep in a canyon, and few spots where the river slowed down enough to make a crossing possible. Two of these fords were near Fort Hall, where travelers on the Oregon Trail North Side Alternate (established about 1852) and Goodale's Cutoff (established 1862) crossed the Snake to travel on the north side. Nathaniel Wyeth, the original founder of Fort Hall in 1834, writes in his diary that they found a ford across the Snake River southwest of where he founded Fort Hall. Another possible crossing was a few miles upstream of Salmon Falls where some intrepid travelers floated their wagons and swam their stock across to join the north side trail. Some lost their wagons and teams over the falls. The trails on the north side joined the trail from Three Island Crossing about west of Glenns Ferry on the north side of the Snake River.
Goodale's Cutoff, established in 1862 on the north side of the Snake River, formed a spur of the Oregon Trail. This cutoff had been used as a pack trail by Indians and fur traders, and emigrant wagons traversed parts of the eastern section as early as 1852. After crossing the Snake River the cutoff headed north from Fort Hall toward Big Southern Butte following the Lost River part of the way. It passed near the present-day town of Arco, and wound through the northern part of what is now Craters of the Moon National Monument. From there it went southwest to Camas Prairie and ended at Old Fort Boise on the Boise River. This journey typically took two to three weeks and was noted for its very rough lava terrain and extremely dry climate, which tended to dry the wooden wheels on the wagons, causing the iron rims to fall off the wheels. Loss of wheels caused many wagons to be abandoned along the route. It rejoined the main trail east of Boise. Goodale's Cutoff is visible at many points along U.S. Highway 20, U.S. Highway 26, and U.S. Highway 93 between Craters of the Moon National Monument and Carey.
From the present site of Pocatello, the trail proceeded almost due west on the south side of the Snake River for about . This route passed Cauldron Linn rapids, Shoshone Falls, two falls near the present city of Twin Falls, and Upper Salmon Falls on the Snake River. At Salmon Falls there were often a hundred or more Indians fishing who would trade for their salmon, a welcome treat.
The trail continued west to Three Island Crossing (near present-day Glenns Ferry.) Here most emigrants used the divisions of the river caused by three islands to cross the difficult and swift Snake River by ferry or by driving or sometimes floating their wagons and swimming their teams across. The crossings were doubly treacherous because there were often hidden holes in the river bottom which could overturn the wagon or entangle the team, sometimes with fatal consequences. Before ferries were established there were several drownings here nearly every year.
The north side of the Snake had better water and grass than the south. The trail from Three Island Crossing to Old Fort Boise was about long. The usually lush Boise River Valley was a welcome relief. The next crossing of the Snake River was near Old Fort Boise. This last crossing of the Snake could be done on bull boats while swimming the stock across. Others would chain a large string of wagons and teams together. The theory was that the front teams, usually oxen, would get out of water first and with good footing help pull the whole string of wagons and teams across. How well this worked in practice is not stated. Often young Indian boys were hired to drive and ride the stock across the river—they knew how to swim, unlike many pioneers. Today's Idaho Interstate 84 roughly follows the Oregon Trail until it leaves the Snake River near Burley. From there Interstate 86 to Pocatello roughly approximates the trail. Highway 30 roughly follows the path of the Oregon Trail from there to Montpelier.
Starting in about 1848 the South Alternate of Oregon Trail (also called the Snake River Cutoff) was developed as a spur off the main trail. It bypassed the Three Island Crossing and continued traveling down the south side of the Snake River. It rejoined the trail near present-day Ontario, Oregon. It hugged the southern edge of the Snake River canyon and was a much rougher trail with poorer water and grass, requiring occasional steep descents and ascents with the animals down into the Snake River canyon to get water. Travellers on this route avoided two dangerous crossings of the Snake River. Today's Idaho State Route 78 roughly follows the path of the South Alternate route of the Oregon Trail.
In 1869 the Central Pacific established Kelton, Utah as a railhead and the terminus of the western mail was moved from Salt Lake City. The Kelton Road became important as a communication and transportation road to the Boise Basin.
Boise has 21 monuments in the shape of obelisks along its portion of the Oregon Trail.
Oregon.
Once across the Snake River ford near Old Fort Boise the weary travelers traveled across what would become the state of Oregon. The trail then went to the Malheur River and then past Farewell Bend on the Snake River, up the Burnt River canyon and northwest to the Grande Ronde Valley near present-day La Grande before coming to the Blue Mountains. In 1843 settlers cut a wagon road over these mountains making them passable for the first time to wagons. The trail went to the Whitman Mission near Fort Nez Perces in Washington until 1847 when the Whitmans were killed by Native Americans. At Fort Nez Perce some built rafts or hired boats and started down the Columbia; others continued west in their wagons until they reached The Dalles. After 1847 the trail bypassed the closed mission and headed almost due west to present day Pendleton, Oregon, crossing the Umatilla River, John Day River, and Deschutes River before arriving at The Dalles. Interstate 84 in Oregon roughly follows the original Oregon Trail from Idaho to The Dalles.
Arriving at the Columbia at The Dalles and stopped by the Cascade Mountains and Mount Hood, some gave up their wagons or disassembled them and put them on boats or rafts for a trip down the Columbia River. Once they transited the Cascade's Columbia River Gorge with its multiple rapids and treacherous winds they would have to make the portage around the Cascade Rapids before coming out near the Willamette River where Oregon City was located. The pioneer's livestock could be driven around Mount Hood on the narrow, crooked and rough Lolo Pass.
Several Oregon Trail branches and route variations led to the Willamette Valley. The most popular was the Barlow Road, which was carved though the forest around Mount Hood from The Dalles in 1846 as a toll road at $5 per wagon and 10 cents per head of livestock. It was rough and steep with poor grass but still cheaper and safer than floating goods, wagons and family down the dangerous Columbia River.
In Central Oregon, there was the Santiam Wagon Road (established 1861), which roughly parallels Oregon Highway 20 to the Willamette Valley. The Applegate Trail (established 1846), cutting off the California Trail from the Humboldt River in Nevada, crossed part of California before cutting north to the south end of the Willamette Valley. U.S. Route 99 and Interstate 5 through Oregon roughly follow the original Applegate Trail.
Travel equipment.
Wagons and pack animals.
Three types of draft and pack animals were used by Oregon Trail pioneers: oxen, mules, and horses.
By 1842, many emigrants favored oxen—castrated bulls (males) of the genus "Bos" (cattle), generally over four years old—as the best animal to pull wagons, because they were docile, generally healthy, and able to continue moving in difficult conditions such as mud and snow. Oxen could also survive on prairie grasses and sage, unlike horses, who had to be fed. Moreover, oxen were less expensive to purchase and maintain than horses. Oxen also could stand idle for long periods without suffering damage to the feet and legs. Oxen were trained by leading, the use of a whip or goad, and the use of oral commands (such as "Gee" (right), "Haw" (left), and "Whoa" (stop)). Two oxen were typically yoked together at the neck or head; the left oxen was referred to as the "neight" ox, the right ox as the "off" ox. While no reins, bits, or halters were needed, the trainer had to be forceful. Oxen typically traveled at a steady pace up to two miles an hour.
One drawback of oxen was the difficulty of shoeing. Oxen hooves are cloven (split), and they had to be shod with two curved pieces of metal, one on each side of the hoof. While horses and mules allowed themselves to be shod relatively easily, the process was more difficult with oxen, which would lie down and tuck their feet under themselves. As a result, several men had to lift and hold an ox while he was being shod.
Mules were used by some emigrants. The competing merits of oxen and mules were hotly debated among emigrants. Some found oxen to be more durable. Others, by contrast, believed that mules were more durable, and mules may have had a lower attrition rate on the trail than oxen. Like oxen, mules could survive on prairie grasses. Mules were, however, notoriously ill-tempered. Mules also cost about three times as much as oxen, a deciding factor for many emigrants.
Food.
The typical cost of food for four people for six months was about $150.
Food and water were key concerns for migrants. Wagons typically carried at least one large water keg, and guidebooks available from the 1840s and later gave similar advice to migrants on what food to take. T.H. Jefferson, in his "Brief Practice Advice" guidebook for migrants, recommended that each adult take 200 pounds of flour: "Take plenty of bread stuff; this is the staff of life when everything else runs short."
Food often took the form of crackers or hardtack; Southerners sometimes chose cornmeal or pinole rather than wheat flour. Emigrants typically ate rice and beans only at forts stopped at along the way, because boiling water was difficult on the trail, and fuel was not abundant. Lansford Hastings recommended that each emigrant take 200 pounds of flour, 150 pounds of "bacon" (a word which, at the time, referred broadly to all forms of salt pork), 20 pounds of sugar, and 10 pounds of salt. Chipped beef, rice, tea, dried beans, dried fruit, saleratus (for raising bread), vinegar, pickles, mustard, and tallow might also be taken. Joseph Ware's 1849 guide recommends that travelers take for each individual a barrel of flour or 180 pounds of ship's biscuit (i.e., hardtack), 150-180 pounds of bacon, 60 pounds of beans or peas, 25 pounds of rice, 25 pounds of coffee, 40 pounds of sugar, a keg of lard, 30 or 40 pounds of dried fruit (peaches or apples), a keg of clear, rendered beef suet (to substitute for butter), as well as some vinegar, salt, and pepper. Many emigrant families also carried a small amount of tea and maple sugar.
Randolph B. Marcy, an Army officer who wrote a 1859 guide, advised taking less bacon than the earlier guides had recommended. He advised emigrants to drive cattle instead as a source of fresh beef. Marcy also instructed emigrants to store sides of bacon in canvas bags or in boxes surrounded by bran to protect against extreme heat, which could make bacon go rancid. Marcy instructed emigrants to put salt pork on the bottom of wagons to avoid exposure to extreme heat. Marcy also recommended the use of pemmican, as well as the storage of sugar in India-rubber or gutta-percha sacks, to prevent it from becoming wet.
Canning technology had just begun to be developed, and it gained in popularity through the period of westward expansion. Initially, only upper-class migrants typically used canned goods. There are references in sources to canned cheese, fruit, meat, oysters, and sardines. By the time Marcy wrote his 1859 guide, canned foods were increasingly available but remained expensive. Canning also added weight to a wagon. Rather than canned vegetables, Marcy suggested that travelers take dried vegetables which had been used in the Crimean War and by the U.S. Army.
Some pioneers took eggs and butter packed in barrels of flour, and some took dairy cows along the trail. Hunting provided another source of food along the trail; pioneers hunted American bison as well as pronghorn antelope, deer, bighorn sheep, and wildfowl. From rivers and lakes, emigrants also fished for catfish and trout. When emigrants faced starvation, they would sometimes slaughter their animals (horses, mules, and oxen). In desperate times, migrants would search for less-popular sources of food, including coyote, fox, jackrabbit, marmot, prairie dog, and rattlesnake (nicknamed "bush fish" in the later period).
At the time, scurvy was well-recognized, but there was a lack of clear understanding of how to prevent the disease. Nevertheless, pioneers' consumption of the wild berries (including chokeberry, gooseberry, and serviceberry) and currants that grew along the trail (particularly along the Platte River) and were consumed, helped make scurvy infrequent. Marcy's guide correctly suggested that the consumption of wild grapes, greens, and onions could help prevent the disease and that if vegetables were not available, citric acid could be drunk with sugar and water.
Emigrant families, who were mostly middle-class, prided themselves on preparing a good table. Although operating Dutch ovens and kneading dough was difficult on the trail, many baked good bread and even pies.
For fuel to heat food, travelers would collect cedar wood, cottonwood, or willow wood, when available, and sometimes dry prairie grass. More frequently, however, travelers relied on "buffalo chips"—dried bison dung—to fuel fires. Buffalo chips resembled rotten wood and would make clear and hot fires. Chips burned quickly, however, and it took up to three bushels of chips to heat a single meal. Collecting buffalo chips was a common task for children and was one chore that even very young children could carry out. As a result, "memoirs written by those who were very young when they made the journey west invariably refer to this aspect of life on the trail."
Clothing and equipment and supplies.
Tobacco was popular, both for personal use, and for trading with Indians and other pioneers. Each person brought at least two changes of clothes and multiple pairs of boots (two to three pairs often wore out on the trip). About 25 pounds of soap was recommended for a party of four, for bathing and washing clothes. A washboard and tub were usually brought for washing clothes. Wash days typically occurred once or twice a month, or less, depending on availability of good grass, water, and fuel. Most wagons carried tents for sleeping, though in good weather most would sleep outside. A thin fold-up mattress, blankets, pillows, canvas, or rubber gutta percha ground covers were used for sleeping. Sometimes an unfolded feather bed mattress was brought for the wagon, if there were pregnant women or very young children along. The wagons had no springs, and the ride along the trail was very rough. Despite modern depictions, hardly anyone actually rode in the wagons; it was too dusty, too rough, and too hard on the livestock.
Travelers brought books, Bibles, trail guides, and writing quills, ink, and paper for writing letters or journalling (about one in 200 kept a diary).
A belt and folding knives were carried by nearly all men and boys. Awls, scissors, pins, needles, and thread for mending were required. Spare leather was used for repairing shoes, harnesses, and other equipment. Some used goggles to keep dust out of the eyes. Storage boxes were ideally the same height, so they could be arranged to give a flat surface inside the wagon for a sleeping platform.
Saddles, bridles, hobbles, and ropes were needed if the party had a horse or riding mule, and many men did. Extra harnesses and spare wagon parts were often carried. Most carried steel shoes for horses, mules, or livestock. Tar was carried to help repair an ox's injured hoof.
Goods, supplies, and equipment were often shared by fellow travelers. Items that were forgotten, broken, or worn out could be bought from a fellow traveler, post, or fort along the way. New iron shoes for horses, mules, and oxen were put on by blacksmiths found along the way. Equipment repairs and other goods could be procured from blacksmith shops established at some forts and some ferries. Emergency supplies, repairs, and livestock were often provided by local residents in California, Oregon, and Utah for late travelers on the trail who were hurrying to beat the snow.
Non-essential items were often abandoned to lighten the load, or in case of emergency. Many travelers would salvage discarded items, picking up essentials or leaving behind their lower quality item when a better one was found abandoned along the road. Some profited by collecting discarded items, hauling them back to jumping off places, and reselling them. In the early years, Mormons sent scavenging parties back along the trail to salvage as much iron and other supplies as possible and haul it to Salt Lake City, where supplies of all kinds were needed. Others would use discarded furniture, wagons, and wheels as firewood. During the 1849 gold rush, Fort Laramie was known as "Camp Sacrifice" because of the large amounts merchandise discarded nearby. Travelers had pushed along the relatively easy path to Fort Laramie with their luxury items but discarded them before the difficult mountain crossing ahead, and after discovering that many items could be purchased at the forts or located for free along the way. Some travelers carried their excess goods to Salt Lake City to be sold.
Professional tools used by blacksmiths, carpenters, and farmers were carried by nearly all. Axes, crow bars, hammers, hatchets, hoes, mallets, mattocks, picks, planes, saws, scythes, and shovels were used to clear or make a road through brush or trees, cut down the banks to cross a wash or steep banked stream, build a raft or bridge, or repair the wagon. In general, as little road work as possible was done. Travel was often along the top of ridges to avoid the brush and washes common in many valleys.
Statistics.
Overall, some 268,000 pioneers used the Oregon Trail and its three primary offshoots, the Bozeman, California, and Mormon trails to reach the West Coast, 1840-60. Another 48,000 headed to Utah. There is no estimate on how many used it to return East.
Emigrants.
Some of the trail statistics for the early years were recorded by the U.S. Army at Fort Laramie, Wyoming, from about 1849 to 1855. None of these original statistical records have been found—the Army either lost them or destroyed them. Only some partial written copies of the Army records and notes recorded in several diaries have survived.
Emigration to California spiked considerably with the 1849 gold rush. Following the discovery of gold, California remained the destination of choice for most emigrants on the trail up to 1860, with almost 200,000 people traveling there between 1849 and 1860.
Travel diminished after 1860, as the Civil War caused considerable disruptions on the trail. Many of the people on the trail in 1861–1863 were fleeing the war and its attendant drafts in both the south and the north. Trail historian Merrill J. Mattes has estimated the number of emigrants for 1861–1867 given in the total column of the above table. But these estimates may well be low since they only amount to an extra 125,000 people, and the 1870 census shows that over 200,000 additional people (ignoring most of the population increase in California, which had excellent sea and rail connections across Panama by then) showed up in all the states served by the Bozeman, California, Mormon, and Oregon Trail(s) and their offshoots.
Mormon emigration records after 1860 are reasonably accurate, as newspaper and other accounts in Salt Lake City give most of the names of emigrants arriving each year from 1847 to 1868. Gold and silver strikes in Colorado, Idaho, Montana, Nevada, and Oregon caused a considerable increase in people using the trails, often in directions different from the original trail users.
Though the numbers are significant in the context of the times, far more people chose to remain at home in the 31 states. Between 1840 and 1860, the population of the United States rose by 14 million, yet only about 300,000 decided to make the trip. Many were discouraged by the cost, effort and danger of the trip. Western scout Kit Carson is thought to have said, "The cowards never started and the weak died on the way", though the general saying was written by Joaquin Miller, in reference to the California gold rush. According to several sources, 3 to 10 percent of the emigrants are estimated to have perished on the way west.
Many who went were between the ages 12 and 24. Between 1860 and 1870, the U.S. population increased by seven million; about 350,000 of this increase was in the Western states.
Western census data.
These census numbers show a 363,000 population increase in the western states and territories between 1860 and 1870. Some of this increase is because of a high birth rate in the western states and territories, but most is from emigrants moving from the east to the west and new immigration from Europe. Much of the increase in California and Oregon is from emigration by ship, as there was fast and reasonably low cost transportation via east and west coast steamships and the Panama Railroad after 1855. The census numbers imply at least 200,000 emigrants (or more) used some variation of the California/Oregon/Mormon/Bozeman trails to get to their new homes between 1860 and 1870.
Costs.
The cost of traveling over the Oregon Trail and its extensions varied from nothing to a few hundred dollars per person. Women seldom went alone. The cheapest way was to hire on to help drive the wagons or herds, allowing one to make the trip for nearly nothing or even make a small profit. Those with capital could often buy livestock in the Midwest and drive the stock to California or Oregon for profit. About 60 to 80 percent of the travelers were farmers and as such already owned a wagon, livestock team, and many of the necessary supplies. This lowered the cost of the trip to about $50 per person for food and other items. Families planned the trip months in advance and made much of the extra clothing and many other items needed. Individuals buying most of the needed items would end up spending between $150–$200 per person. As the trail matured, additional costs for ferries and toll roads were thought to have been about $30 per car.
Deaths.
The route west was arduous and fraught with many dangers, but the number of deaths on the trail is not known with any precision; there are only wildly varying estimates. Estimating is difficult because of the common practice of burying people in unmarked graves that were intentionally disguised to avoid their being dug up by animals or Indians. Graves were often put in the middle of a trail and then run over by the livestock to make them difficult to find. Disease was the main killer of trail travelers; cholera killed up to 3 percent of all travelers in the epidemic years from 1849 to 1855.
Indian attacks increased significantly after 1860, when most of the army troops were withdrawn, and miners and ranchers began fanning out all over the country, often encroaching on Indian territory. Increased attacks along the Humboldt led to most travelers' taking the Central Nevada Route. The Goodall cutoff, developed in Idaho in 1862, kept Oregon bound travelers away from much of the Indian trouble nearer the Snake River. Other trails were developed that traveled further along the South Platte to avoid local Indian hot spots.
Other common causes of death included hypothermia, drowning in river crossings, getting run over by wagons, and accidental gun deaths. Later, more family groups started traveling, and many more bridges and ferries were being put in, so fording a dangerous river became much less common and dangerous. Surprisingly few people were taught to swim in this era. Being run over was a major cause of death, despite the wagons' only averaging 2–3 miles per hour. The wagons could not easily be stopped, and people, particularly children, were often trying to get on and off the wagons while they were moving—not always successfully. Another hazard was a dress getting caught in the wheels and pulling the person under. Accidental shootings declined significantly after Fort Laramie, as people became more familiar with their weapons and often just left them in their wagons. Carrying around a ten-pound rifle all day soon became tedious and usually unnecessary, as the perceived Indian threat faded and hunting opportunities receded.
A significant number of travelers were suffering from scurvy by the end of their trips. Their typical flour and salted pork/bacon diet had very little vitamin C in it. The diet in the mining camps was also typically low in fresh vegetables and fruit, which indirectly led to early deaths of many of the inhabitants. Some believe that scurvy deaths may have rivaled cholera as a killer, with most deaths occurring after the victim reached California.
Miscellaneous deaths included deaths by childbirth, falling trees, flash floods, homicides, kicks by animals, lightning strikes, snake bites, and stampedes. According to an evaluation by John Unruh, a 4 percent death rate or 16,000 out of 400,000 total pioneers on all trails may have died on the trail.
Reaching the Sierra Nevada before the start of the winter storms was critical for a successful completion of a trip. The most famous failure in that regard was that of the Donner Party, whose members struggled to traverse what is today called Donner Pass, in November 1846. When the last survivor was rescued in April 1847, 33 men, women, and children had died at Donner Lake; with some of the 48 survivors' confessing to having resorted to cannibalism to survive.
Other trails west.
There were other possible migration paths for early settlers, miners, or travelers to California or Oregon besides the Oregon trail prior to the establishment of the transcontinental railroads.
From 1821–1846, the Hudson's Bay Company twice annually used the York Factory Express overland trade route from Fort Vancouver to Hudson Bay then on to London. James Sinclair led a large party of nearly 200 settlers from the Red River Colony in 1841. These northern routes were largely abandoned after Britain ceded its claim to the southern Columbia River basin by way of the Oregon Treaty of 1846.
The longest trip was the voyage of about on an uncomfortable sailing ship rounding the treacherous, cold, and dangerous Cape Horn between Antarctica and South America and then sailing on to California or Oregon. This trip typically took four to seven months (120 to 210 days) and cost about $350 to $500. The cost could be reduced to zero if you signed on as a crewman and worked as a common seaman. The hundreds of abandoned ships, whose crews had deserted in San Francisco Bay in 1849–50, showed many thousands chose to do this.
Other routes involved taking a ship to Colón, Panama (then called Aspinwall) and a strenuous, disease ridden, five- to seven-day trip by canoe and mule over the Isthmus of Panama before catching a ship from Panama City, Panama to Oregon or California. This trip could be done from the east coast theoretically in less than two months if all ship connections were made without waits and typically cost about $450/person. Catching a fatal disease was a distinct possibility as Ulysses S. Grant in 1852 learned when his unit of about 600 soldiers and some of their dependents traversed the Isthmus and lost about 120 men, women, and children. This passage was considerably sped up and made safer in 1855 when the Panama Railroad was completed at terrible cost in money and life across the Isthmus. The once treacherous trip could be done in less than a day. The time and the cost for transit dropped as regular paddle wheel steamships and sailing ships went from ports on the east coast and New Orleans, Louisiana, to Colón, Panama ($80–$100), across the Isthmus of Panama by railroad ($25) and by paddle wheel steamships and sailing ships to ports in California and Oregon ($100–$150).
Another route established by Cornelius Vanderbilt in 1849 was across Nicaragua. The long San Juan River to the Atlantic Ocean helps drain the long Lake Nicaragua. From the western shore of Lake Nicaragua it is only about to the Pacific Ocean. Vanderbilt decided to use paddle wheel steam ships from the U.S. to the San Juan River, small paddle wheel steam launches on the San Juan River, boats across Lake Nicaragua, and a stage coach to the Pacific where connections could be made with another ship headed to California, Oregon, etc.. Vanderbilt, by undercutting fares to the Isthmus of Panama and stealing many of the Panama Railroad workers, managed to attract roughly 30% of the California bound steam boat traffic. All his connections in Nicaragua were never completely worked out before the Panama Railroad's completion in 1855. Civil strife in Nicaragua and a payment to Cornelius Vanderbilt of a "non-compete" payment (bribe) of $56,000 per year killed the whole project in 1855.
Another possible route consisted of taking a ship to Mexico traversing the country and then catching another ship out of Acapulco, Mexico to California etc. This route was used by some adventurous travelers but was not too popular because of the difficulties of making connections and the often hostile population along the way.
The Gila Trail going along the Gila River in Arizona, across the Colorado River and then across the Sonora Desert in California was scouted by Stephen Kearny's troops and later by Captain Philip St. George Cooke's Mormon Battalion in 1846 who were the first to take a wagon the whole way. This route was used by many gold hungry miners in 1849 and later but suffered from the disadvantage that you had to find a way across the very wide and very dry Sonora Desert. It was used by many in 1849 and later as a winter crossing to California, despite its many disadvantages.
Running from 1857 to 1861, the Butterfield Stage Line won the $600,000/yr. U.S. mail contract to deliver mail to San Francisco, California. As dictated by southern Congressional members, the route ran from St. Louis, Missouri through Arkansas, Oklahoma Indian Territory, Texas, New Mexico Territory, and across the Sonora Desert before ending in San Francisco, California. Employing over 800 at its peak, it used 250 Concord Stagecoaches seating 12 very crowded passengers in three rows. It used 1,800 head of stock, horses and mules and 139 relay stations to ensure the stages ran day and night. A one way fare of $200 delivered a very thrashed and tired passenger into San Francisco in 25 to 28 days. After traveling the route, "New York Herald" reporter Waterman Ormsby said, "I now know what Hell is like. I've just had 24 days of it."
Other ways to get to Oregon were: using the York Factory Express route across Canada, and down the Columbia River; ships from Hawaii, San Francisco, or other ports that stopped in Oregon; emigrants trailing up from California, etc. All provided a trickle of emigrants, but they were soon overwhelmed in numbers by the emigrants coming over the Oregon Trail.
The ultimate competitor arrived in 1868, the First Transcontinental Railroad, which cut travel time to about seven days at a low fare of about $60 (economy)
Legacy.
One of the enduring legacies of the Oregon Trail is the expansion of the United States territory to the West Coast. Without the many thousands of United States settlers in Oregon and California, and thousands more on their way each year, it is highly unlikely that this would have occurred.
Art, entertainment, and media.
The western expansion, and the Oregon Trail in particular, inspired many creative works about the settlers' experiences.
Games.
The story of the Oregon Trail inspired the popular educational computer game, "The Oregon Trail" (1971), which became widely popular in the 1980s and early 1990s. Several sequels to the game were also released, such as "The Oregon Trail II"(1995), "The Yukon Trail" (1994), and "The Amazon Trail" (1994).
Music.
The song "Uncle Sam's Farm" encouraged east-coast dwellers to "Come right away. Our lands they are broad enough, so don't be alarmed. Uncle Sam is rich enough to give us all a farm."
In "Western Country", the singer exhorts that, "if I had no horse at all, I'd still be a hauling, far across those Rocky Mountains, goin' away to Oregon."
Television.
"The Oregon Trail" was a television series that ran from September 22 through October 26, 1977, on NBC. The show stars Rod Taylor, Tony Becker, Darleen Carr, Charles Napier, and Ken Swofford. Although the show was canceled after six episodes, the remaining seven episodes were later aired on BBC 2 in the United Kingdom, the entire series was shown in the UK on BBC1, from November 1977 to January 1978, and in On April 13, 2010, Timeless Media Group (TMG) released in the USA the entire show on six DVDs, running 750 minutes. The set includes 14 original episodes, including the feature-length pilot and the six episodes that did not air on NBC.

</doc>
<doc id="48713" url="https://en.wikipedia.org/wiki?curid=48713" title="St John's College, Cambridge">
St John's College, Cambridge

St John's College is a constituent college of the University of Cambridge. (The full, formal name of the college is ""The Master, Fellows and Scholars of the College of St John the Evangelist in the University of Cambridge"".) The college was founded by Lady Margaret Beaufort. In constitutional terms, the college is a charitable corporation established by a charter dated 9 April 1511. The aims of the college, as specified by its Statutes, are the promotion of education, religion, learning and research.
The college's alumni include the winners of nine Nobel Prizes, seven prime ministers and twelve archbishops of various countries, at least two princes, and three Saints.
St John's College is well known for its choir, for its members' participation in a wide variety of inter-collegiate sporting competitions, and for its annual May Ball.
In 2011 the college celebrated its quincentenary, an event marked by a visit of HM Queen Elizabeth II and HRH Prince Philip, Duke of Edinburgh. HRH Prince William was affiliated with the college while undertaking a university-run course in 2014.
History.
The college was founded on the site of the 13th century Hospital of St John in Cambridge at the suggestion of Saint John Fisher, Bishop of Rochester and chaplain to Lady Margaret. However, Lady Margaret died without having mentioned the foundation of St John's in her will, and it was largely the work of Fisher that ensured that the college was founded. He had to obtain the approval of King Henry VIII of England, the Pope through the intermediary Polydore Vergil, and the Bishop of Ely to suppress the religious hospital and convert it to a college. The college received its charter on 9 April 1511. Further complications arose in obtaining money from the estate of Lady Margaret to pay for the foundation and it was not until 22 October 1512 that a codicil was obtained in the court of the Archbishop of Canterbury. In November 1512 the Court of Chancery allowed Lady Margaret's executors to pay for the foundation of the college from her estates. When Lady Margaret's executors took over they found most of the old Hospital buildings beyond repair, but repaired and incorporated the Chapel into the new college. A kitchen and hall were added, and an imposing gate tower was constructed for the College Treasury. The doors were to be closed each day at dusk, sealing the monastic community from the outside world.
Over the course of the following five hundred years, the college expanded westwards towards the River Cam, and now has eleven courts, the most of any Oxford or Cambridge College. The first three courts are arranged in enfilade.
St John's College first admitted women in October 1981, when K. M. Wheeler was admitted to the fellowship, along with nine female graduate students. The first women undergraduates arrived a year later.
In 2015 St John's created controversy with student drinking societies that "glorify rape" and require members to "stand up if you hate the poor" during meetings.
Buildings and grounds.
The Great Gate.
St John's distinctive Great Gate follows the standard contemporary pattern employed previously at Christ's College and Queens' College. The gatehouse is crenelated and adorned with the arms of the foundress Lady Margaret Beaufort. Above these are displayed her ensigns, the Red Rose of Lancaster and Portcullis. The college arms are flanked by curious creatures known as yales, mythical beasts with elephants' tails, antelopes' bodies, goats' heads, and swivelling horns. Above them is a tabernacle containing a socle figure of St John the Evangelist, an Eagle at his feet and symbolic, poisoned chalice in his hands. The fan vaulting above is contemporary with tower, and may have been designed by William Swayne, a master mason of King's College Chapel.
First Court.
First Court is entered via the Great Gate, and is highly architecturally varied. First Court was converted from the hospital on the foundation of the college, and constructed between 1511 and 1520. Though it has since been gradually changed, the front (east) range is still much as it appeared when first erected in the 16th-century. The south range was refaced between 1772–6 in the Georgian style by the local architect James Essex, as part of an abortive attempt to modernise the entire court in the same fashion. The most dramatic alteration to the original, Tudor court however remains the Victorian amendment of the north range, which involved the demolition of the original mediaeval chapel and the construction of a new, far larger set of buildings in the 1860s. These included the Chapel, designed by Sir George Gilbert Scott, which includes in its interior some pieces saved from the original chapel. It is the tallest building in Cambridge. The alteration of the north range necessitated the restructuring of the connective sections of First Court; another bay window was added to enlarge the college's hall, and a new building constructed to the north of Great Gate. Parts of First Court were used as a prison in 1643 during the English Civil War. In April 2011, Queen Elizabeth II visited St John's college to inaugurate a new pathway in First Court, which passes close to the ruins of the Old Chapel.
Dining Hall.
The college's Hall has a fine hammerbeam-roof, painted in black and gold and decorated with the armorial devices of its benefactors. The hall is lined to cill-level with linenfold panelling which dates from 1528–9, and has a five-bay screen, surmounted by the Royal Arms. Above is a hexagonal louvre, dating to 1703. The room was extended from five to eight bays according to designs by Sir George Gilbert Scott in 1863. It has two bay windows, containing heraldic glass dating from the fifteenth to nineteenth centuries. In 1564, Queen Elizabeth rode into the college's Hall on horseback, during a state visit to Cambridge.
Second Court.
Second Court, built from 1598 to 1602, has been described as 'the finest Tudor court in England'. Built atop the demolished foundations of an earlier, far smaller court, Second Court was begun in 1598 to the plans of Ralph Symons of Westminster, and Gilbert Wigge of Cambridge. Their original architectural drawings are housed in the college's library, and are the oldest surviving plans for an Oxford or Cambridge college building. It was financed by the Countess of Shrewsbury, whose arms and statue stand above the court's western gatehouse. The court's Oriel windows are perhaps its most striking feature, though the dominating Shrewsbury Tower to the west is undoubtedly the most imposing. This gatehouse, built as a mirror image of the college's Great Gate, contains a statue of the benefactress Mary Talbot, Countess of Shrewsbury, added in 1671. Behind the Oriel window of the north range lies the Long Gallery, a promenading room that was, prior to its segmentation, 148 feet long. In this room, the treaty between England and France was signed that established the marriage of King Charles I of England to Queen Henrietta Maria. In the 1940s, parts of the D-day landings were planned there. Second Court is also home to the college's famous 'triple set', K6.
The College Library.
The Old Library was built in 1624, largely with funds donated by John Williams, Bishop of Lincoln. Hearing of the college's urgent need for greater library space, Williams donated £1,200 anonymously, later revealing his identity and donating a total of £2,011 towards the library's total cost of £3,000. The Library's fine bay window overlooks the River Cam, and bears the letters ILCS on it, standing for Iohannes Lincolniensis Custos Sigilli, or John of Lincoln, Keeper of the Seal. The original intention of the college had been to construct an elegant, classical building supported by pillared porticos, but Bishop William insisted on a more traditional design. Thus, though the college lays claim to few examples of neo-classical design, the college Library stands as one of the earliest examples of English neo-Gothic architecture.
Third Court.
Third Court is entered through Shrewsbury Tower, which from 1765 to 1859 housed an observatory. Each of its ranges was built in a different style. Following the completion of the college library in 1624, the final sides of Third Court were added between 1669 and 1672, after the college had recovered from the trauma of the English Civil War. The additions included a fine set of Dutch-gabled buildings backing onto the River Cam, and a 'window-with-nothing-behind-it' that was designed to solve the problem of connecting the windowed library with the remainder of the court.
Kitchen "or" Wren Bridge.
This was the first stone bridge erected at St John's college, continuing on from Kitchen lane. The crossing's chief distinction is the use of illusory intaglio; Wren's bridge is carved from a limestone monolith incised to give the appearance of masonry. The crossing lies south of the Bridge of Sighs, and was a replacement for a wooden bridge that had stood on the site since the foundation's early days as a hospital. Though Sir Christopher Wren submitted designs for the bridge, it was eventually built on a different site by a local mason, Robert Grumbold, who also built Trinity College Library. As with the Library, Grumbold's work was based on Wren's designs, and the bridge has become known more famously as 'the Wren Bridge'.
Kitchen Court.
This tiny court, formed within the walls of the old Kitchen Lane, is used as an outdoor dining area.
The Bridge of Sighs.
Though it bears little resemblance to its namesake in Venice, the bridge connecting Third Court to New Court, originally known as New Bridge, is now commonly known as the Bridge of Sighs. It is one of the most photographed buildings in Cambridge, and was described by the visiting Queen Victoria as "so pretty and picturesque". It is a single-span bridge of stone with highly decorative Neo-Gothic covered footwalk over with traceried openings. There is a three bay arcade at the East end of the bridge. The architect was Henry Hutchinson.
New Court.
The 19th century neo-Gothic New Court, probably one of the best known buildings in Cambridge, was the first major building built by any of the colleges on the west side of the river. Designed by Thomas Rickman and Henry Hutchinson, New Court was built between 1826 and 1831 to accommodate the college's rapidly increasing numbers of students. Despite the college's original intention to get the architects to build another copy of Second Court, plans were eventually accepted for a fashionably romantic building in the 'Gothic' style. It is a three-sided court of tall Gothic Revival buildings, closed on the fourth side by an open, seven-bayed cross-vaulted cloister and gateway. It is four storeys high, has battlements and is pinnacled. The main portal has a fan vault with a large octagonal pendant, and the interior of the main building retains many of its original features including ribbed plaster ceilings in the mock-Gothic style. Its prominent location (especially when seen from the river) and flamboyant design have led it to be nicknamed "The Wedding Cake". Hutchinson was suitably proud of his creation, and it is said that he once dashed up a staircase to reprimand an undergraduate for spoiling its symmetry by sitting too near one of its windows.
College Chapel.
The Chapel of St John's College is entered by the north west-corner of First Court, and was constructed between 1866 and 1869 to replace the smaller, mediaeval chapel which dated back to the 13th century. When in 1861 the college's administration decided that a new building was needed, Sir George Gilbert Scott was selected as architect. He had recently finished work on the chapel at Exeter College, Oxford, and went about constructing the chapel of St John's College along similar lines, drawing inspiration from the Church of Saint Chapelle in Paris.
The benefactor Henry Hoare offered a downpayment of £3000 to finance the chapel's construction, in addition to which he promised to pay £1000 a year if a tower were added to Scott's original plans, which had included only a small fleche. Work began, but Mr Hoare's death in a railway accident left the college £3000 short of his expected benefaction. The tower was completed, replete with louvres but left without bells. It is based on Pershore Abbey. The tower is 50 metres high, and is the tallest structure in Cambridge (followed by the Cambridge University Library and King's College Chapel). The Chapel's antechamber contains statues of Margaret Beaufort and John Fisher. Inside the building is a stone-vaulted antechapel, at the end of which hangs a 'Deposition of the Cross' by Anton Rafael Mengs, completed around 1777. The misericordes and panelling date from 1516, and were salvaged from the old chapel. The chapel contains some fifteenth-century glass, but most was cast by Clayton and Bell, Hardman, and Wailes, in around 1869. Freestanding statues and plaques commemorate college benefactors such as James Wood, Master 1815–39, as well as alumni including William Wilberforce, Thomas Clarkson and William Gilbert. The college tower can be climbed, and is accessed via a small door on First Court.
The Chapel is surrounded on three sides by large tabernacles which form part of the external buttresses. Each contains a statue of a prominent college alumnus, alumna or benefactor. The persons commemorated are, beginning with the buttress next to the transept on the south side:
The Master's Lodge and Garden.
St John's Master's lodge is located in a grassy clearing to the north of Third Court. It was built at the same time as the new Chapel was being constructed, and has Tudor fittings, wainscot, portraits and other relics from the demolished north wing of First Court. It has a large garden, and in the winter its westmost rooms have excellent views of the college's old library, the River Cam, and the Bridge of Sighs. The architect was Sir George Gilbert Scott.
Buildings and Courts since 1900.
Located to the west of the Chapel tower lies Chapel Court, which was constructed together with North Court and Forecourt in the 1930s to account for an increase in student numbers. North Court is located just north of Chapel Court and Forecourt is situated to the east, facing St John's Street. The latter is used partly as a car park for fellows and night entrance to the college. All three courts were designed by the architect Edward Maufe.
Further increases in student numbers following WWII prompted the college to again increase the number of accommodation buildings. Cripps Court was built in the late 1960s to satisfy this demand. It is located just behind New Court and forms two courts (Upper & Lower River Court). Designed by architects Philip Powell and Hidalgo Moya, the building is Grade II* listed having received an award from the British Architectural Institution. It is considered an exemplar of late 20th-century architectural style and is named after its main benefactor, Humphrey Cripps.
To the west of Cripps Court lies the School of Pythagoras. Built around 1200, it predates the college with 300 years and is both the oldest secular building in Cambridge and the oldest building continuously in use by a university in Britain. The building now serves as the location for the College Archives. Next to the School of Pythagoras lies Merton Hall. From 1266 until 1959 both the School of Pythagoras and Merton Hall were property of Merton College, Oxford. Merton Court is the college's eleventh and westernmost court.
In 1987 the construction of the Fisher Building was completed. Named after cardinal John Fisher, the building contains teaching rooms, conference facilities, and the student-run college cinema. It was designed by the architect Peter Boston.
Located directly opposite the college's Great Gate is All Saints' Yard. The complex is formed from the buildings of the so-called 'Triangle Site', a collection of structures owned by the college. An extensive renovation project finished in Michaelmas Term 2012 had a budget of approximately £9.75 million. The centrepiece of the Yard is Corfield Court, named after the project's chief benefactor, Charles Corfield. The site can be entered through one of two card-activated gates, or through the School of Divinity. The School of Divinity is the largest building on the site, and was built between 1878–1879 by Basil Champneys for the University of Cambridge's Divinity Faculty on land leased by St John's College. Control of the building reverted to St John's when the Faculty of Divinity moved to a new building on the Sidgwick site in 2000.
College Choir.
St John's College Choir has a tradition of religious music and has sung the daily services in the College Chapel since the 1670s. The services follow the cathedral tradition of the Church of England, Evensong being sung during Term six days a week and Sung Eucharist on Sunday mornings. The Choir is currently directed by Mr Andrew Nethsingha, who has previously been Director of Music at Gloucester and Truro Cathedrals. The boys of the choir are all educated at the St John's College School. During university vacations the choir carries out engagements elsewhere. Recent tours have taken it to places including the Netherlands, the USA and France. The choir has made a large number of recordings.
The Choir has an extensive discography dating back to the 1950s, when it was signed to the Decca/Argo label under George Guest. More recently, the Choir has completed a sequence of recordings of English 20th century choral for Naxos, which sold over 200,000 copies. The Choir now records with Hyperion Records, and has released four discs to date with the label: one of the music of Mendelssohn, a collection of music for Advent, Christmas and Epiphany, Christmas at St John's, a recording of the choral and vocal music of Jongen and Peeters and most recently, a collection of the music of Bairstow. The Choir has received invitations to perform throughout the world, recently touring in France, Austria, the Netherlands, Estonia, Hungary and America.
The men of the choir, or choral scholars, also form their own close harmony group, The Gentlemen of St John's. Their repertoire spans the 15th century through to the modern day, and concert tours have taken them to Europe, the USA and Japan. They provide a mixture of classical a capella music and folksongs, as well as covers of recently chart hits and light-hearted entertainment.
Traditions and legends.
Eating Swan.
Fellows of St John's College are the only people outside the Royal Family legally allowed to eat unmarked mute swans. Swan traps were originally built into the walls of the college alongside the river, but these are no longer used. The Crown (the British monarch) retains the right to ownership of all unmarked mute swans in open water, but the Queen only exercises her ownership on certain stretches of the Thames and its surrounding tributaries. This ownership is shared with the Vintners' and Dyers' Companies, who were granted rights of ownership by the Crown in the fifteenth century, and was extended to the college via ancient Royalist ties.
Ghosts.
According to popular legend, St John's College is inhabited by a number of ghosts. In 1706, four fellows exorcised some ghosts from a house opposite the college by the simple method of threatening to fire their pistols at the positions the moans and groans were coming from. Second court is apparently still haunted by the ghost of the former undergraduate, James Wood. Wood was so poor that he could not afford to light his room, and would often do his work in the well-lit stairway.
New Court's Clock Tower.
New Court's central cupola has four blank clock-faces. These are subject to various apocryphal explanations. One legend maintains that a statute limiting the number of chiming clocks in Cambridge rendered the addition of a mechanism illegal. No such limitation is known to exist. More likely explanations include Hutchinson's fear that the installation of a clockface would spoil the building's symmetry, and that the college's financial situation in the early nineteenth century made completion impossible.
Other legends explaining the absence of clockfaces claim that St John's College and its neighbour, Trinity College, were engaged in a race to build the final (or tallest) clocktower in Cambridge. Supposedly, whichever was finished first (or was tallest) would be permitted to house the 'final' chiming clock in Cambridge. Trinity's Tower was finished first (or, in another version of the same story, was made taller overnight by the addition of a wooden cupola), and its clock was allowed to remain.
In truth, the completion of New Court and Trinity's Clock (which is in King Edward's Tower) was separated by nearly two centuries. Trinity's famous double-striking was installed in the seventeenth century by its then-Master, Richard Bentley, a former student of St John's, who dictated that the clock chime once for Trinity, and once for his alma mater, St John's.
College rivalry.
The college remains a great rival of Trinity which is its main competitor in sports and academia (Trinity is situated next to John's). This has given rise to a number of anecdotes and myths. It is often cited as the reason why the older courts of Trinity generally have no J staircases, despite including other letters in alphabetical order. A far more likely reason remains the absence of the letter J in the Latin alphabet, and it should be noted that St John's College's older courts also lack J staircases. There are also two small muzzle-loading cannons on Trinity's bowling green pointing in the direction of John's, though this orientation may be coincidental. Generally the colleges maintain a cordial relationship with one other; compatriotism led famously to the splitting of the atomic nucleus in 1932 by Ernest Walton and John Cockcroft, of Trinity and St John's respectively.
Shield and Arms.
St John's College and Christ's College, Cambridge both bear the arms of the Lady Margaret Beaufort, Countess of Richmond and Derby, mother of Henry VII. These arms are recorded in the College of Arms as being borne by right, and are described as: "Quarterly: 1 and 4 azure three fleurs-de-lis gold (France, Modern); 2 and 3 gules three lions passant gardant or (England); all within a border compony silver and azure". In addition, both foundations use the Beaufort crest, "an eagle displayed arising out of a coronet of roses and fleurs-de-lis all gold", but their title to this is more doubtful. When displayed in their full achievement, the arms are flanked by mythical yales.
Motto.
The college motto is "souvent me souvient", supplied by Lady Margaret Beaufort, and written in Mediaeval French. It is inscribed over gates, lintels and within tympana throughout the college, functioning as a triple pun. It means 'often I remember', 'think of me often' and, when spoken (exploiting the homonym "souvent me sous vient"), 'I often pass beneath it' (referring to the inscriptions). The college shares its motto with Christ's College, Cambridge and Lady Margaret Hall, Oxford.
College Grace.
The College Grace is customarily said before and after dinner in Hall. The reading of Grace before dinner (ante prandium) is usually the duty of a Scholar of the College; Grace after dinner (post prandium) is said by the President or the Senior Fellow dining. The Graces used in St John's have been in continuous use for some centuries and it is known that the Ante Prandium is based upon mediaeval monastic models. The Grace is said shortly after the fellows enter the Hall, signalled by the sounding of a Gong, and accompanied by the ringing of the college's Grace Bell. The Ante Prandium is read after the Fellows have entered, the Post Prandium after they have finished dining:
Student life.
The buildings of St John's College include the Chapel, the Hall, two libraries, a bar, and common rooms for fellows, graduates and undergraduates. There are also extensive gardens, lawns, a neighbouring sportsground, College School and boat-house. On-site accommodation is provided for all undergraduate and most graduate students. This is generally spacious, and some undergraduate rooms comprise 'sets' of living and sleeping rooms. Members of the college can choose to dine either in the Hall, where silver service three-course meals are served, or in the buttery, where food can be purchased from a cafeteria-style buffet. College catering is organised by Michelin Star Chef Bill Brogan, overseer of the intercollegiate Stewards' Cup.
The college maintains an extensive library, which supplements the university libraries. Most undergraduate supervisions are carried out in the college, though for some specialist subjects undergraduates may be sent to tutors in other colleges.
The college has two official combination rooms for junior members, which represent the interests of students in college and are responsible for social aspects of college life. Undergraduates are members of the Junior Combination Room (JCR). Graduate students have membership to the JCR, but also belong to the Samuel Butler Room, which is the name of the Middle Combination Room (MCR) of St John's College.
The fleet of punts is kept in a purpose-built punt pool behind the Cripps Building. St John's tends to be ranked near the middle of the Tompkins Table of undergraduate degree results, with an average position of 12.8 since 1997.
Sports.
The college has a sporting history, enjoying success in most of the major sports on offer in Cambridge.
The Red Boys, St John's College Rugby Club, won the Division One League title for nine years in a row, before finally losing to Jesus in 2010–11, and the cuppers trophy for 6 years in a row from 2006-2011, making it one of the most successful collegiate sports teams in Cambridge's history. The rugby club has produced several notable alumni including RFU executive Francis Baron, former Newcastle and England fly-half and current RFU Director of Elite Rugby Rob Andrew, and Battlestar Galactica actor Jamie Bamber.
The college rowing club, the Lady Margaret Boat Club (LMBC), is the oldest in the University, and was founded in 1825. Despite many gruesome rumours concerning the name of the club, it was merely the most successful of the many boat clubs established in the college in the 19th century. In a similar fashion the traditional rival of the LMBC, the Boat Club of Trinity College, is known as 'First and Third' in a reference to its formation from two original clubs.
Scholarships and prizes.
Every year the college awards scholarships to a handful of graduate students under the Benefactors' and Scholarships Scheme. The most generous of all the early benefactors of St John's College was Dr Roger Lupton (d. 1540), Provost of Eton and chaplain to Henry VIII. Lupton had amassed immense wealth through a lifetime of royal service and ecclesiastical pluralism and his scholarships exist today as the Lupton and Hebblethwaite Exhibitions. Other scholarships include the Craik Scholarship, the J.C. Hall Scholarship, the Luisa Aldobrandini Studentship Competition, the Paskin Scholarship and the Pelling Scholarship. Competition for these scholarships is very fierce as students from any country reading for any graduate degree—not only members of the college—can apply. There is also the famous Adams Prize in mathematics, named after the mathematician (and alumnus of St John's) John Couch Adams for his discovery of Neptune – it is an annual competition and can be awarded to any mathematician resident in the UK, with an age limit of under 40. The college is also associated with the Dr Manmohan Singh Scholarship, first awarded in 2008.
May Ball.
St John's hosts a large and typically spectacular May Ball, which is traditionally held on the Tuesday of May Week. In recent years, tickets have only been available to Johnians and their guests. Highlights include an extravagant fireworks display and a variety of musical acts.
People associated with the college.
"See also :Category:Alumni of St John's College, Cambridge", :Category:Fellows of St John's College, Cambridge".
Notable Johnians include former Heads of State, politicians, academics, Nobel laureates, poets and writers. Over 1000 former members of St John's College appear in the Oxford Dictionary of National Biography.
Prime Ministers: Charles Watson-Wentworth, 2nd Marquess of Rockingham (briefly admitted)
, Prime Minister of the United Kingdom, 1785-66 and 1782, F. J. Robinson, 1st Viscount Goderich, Prime Minister of the United Kingdom, 1827–28, George Hamilton-Gordon, 4th Earl of Aberdeen, Prime Minister of the United Kingdom, 1852–55, Henry John Temple, 3rd Viscount Palmerston, Prime Minister of the United Kingdom, 1855–58 & 1859–65, Alfred Domett, Prime Minister of New Zealand, 1862–63, Sir Francis Bell, Prime Minister of New Zealand, 1925, Manmohan Singh, Prime Minister of India, 2004–2014.
Nobel Prize winners: Sir Edward Appleton, for discovering the Appleton layer, Sir John Cockcroft KCB, physicist who first split the atom, Allan Cormack, for the invention of the CAT scan, Paul Dirac, one of the founders of quantum mechanics, Sir Nevill Francis Mott, for work on the behaviour of electrons in magnetic solids, Abdus Salam, for unifying the electromagnetic force and the weak force, Frederick Sanger, molecular biologist and Maurice Wilkins, awarded Nobel prize for Medicine or Physiology with Watson and Crick for discovering the structure of DNA.
Copley Medallists: John Frederick William Herschel (1821), John Frederick William Herschel (1847), John Couch Adams (1848), James Joseph Sylvester (1880), George Howard Darwin (1911), Joseph Larmor (1921), Charles Algernon Parsons (1928), Arthur Schuster (1931), Paul Adrien Maurice Dirac (1952), Harold Jeffreys (1960), Nevill Francis Mott (1972), William Valance Douglas Hodge (1974), Frederick Sanger (1977), Rudolf Ernst Peierls (1986), Abdus Salam (1990), Roger Penrose (2008), David Roxbee Cox (2010)
Notable Alumni
St John's and the abolition of the British slave trade.
Several of St John's graduates were deeply involved in the efforts to abolish the British Slave Trade which culminated in the Act of 1807. In particular, Thomas Clarkson, William Wilberforce, Thomas Gisborne and Thomas Babington were active in the Committee for the Abolition of the Slave Trade and other abolitionist efforts.
As part of the commemoration of the bicentenary of the 1807 Act, and as a representative of one of the Ivy League universities offering American historical perspective on the Triangular Trade, President Ruth J. Simmons of Brown University (herself a direct descendant of American slaves) gave a public lecture at St John's College entitled "Hidden in Plain Sight: Slavery and Justice in Rhode Island" on 16 February 2007. St John's College hosted some of the key events relating to the commemoration, including an academic conference and a Gospel Mass in the College Chapel with the London Adventist Chorale.

</doc>
<doc id="48716" url="https://en.wikipedia.org/wiki?curid=48716" title="Pulitzer Prize for Drama">
Pulitzer Prize for Drama

The Pulitzer Prize for Drama is one of the seven American Pulitzer Prizes that are annually awarded for Letters, Drama, and Music. It is one of the original Pulitzers, for the program was inaugurated in 1917 with seven prizes, four of which were awarded that year. (No Drama prize was given, however, so that one was inaugurated 1918 in a sense.) It recognizes a theatrical work staged in the U.S. during the preceding calendar year.
Through 2006 the Drama Prize was unlike the majority of the other Pulitzer Prizes: during these years, the eligibility period for the drama prize ran from March 2 to March 1, to reflect the Broadway 'season' rather than the calendar year. The decision was made, however, that the 2007 Prize would consider works staged during an eligibility period of January 1 to December 31, 2006—thus bringing the schedule for the Drama Prize in line with those of the other prizes.
The drama jury, which consists of one academic and four critics, attends plays in New York and in regional theaters. The Pulitzer board has the authority to overrule the jury's choice, however, as happened in 1986 when the jury chose "" to receive the prize, but due to the board's opposition no award was given.
In 1955, Joseph Pulitzer, Jr. pressured the prize jury into presenting the Prize to "Cat on a Hot Tin Roof", which the jury considered the weakest of the five shortlisted nominees ("amateurishly constructed... from the stylistic points of view annoyingly pretentious"), instead of Clifford Odets' "The Flowering Peach" (their preferred choice) or "The Bad Seed", their second choice. Edward Albee's "Who's Afraid of Virginia Woolf?" was selected for the 1963 Pulitzer Prize for Drama by that award's committee. However, the committee's selection was overruled by the award's advisory board, the trustees of Columbia University, because of the play's then-controversial use of profanity and sexual themes. Had Albee been awarded, he would be tied with Eugene O'Neill for the most Pulitzer Prizes for Drama (four).
Awards and nominations.
In its first 98 years to 2013, the Drama Pulitzer was awarded 82 times; none was given in 15 years and it was never split. Many of the prizes were won by multiple people for their collaboration, as many as five in 1976.
Musicals.
Nine musicals have won the Pulitzer Prize for Drama, roughly one per decade from the 1930s to the 2010s¹. They are: George and Ira Gershwin's "Of Thee I Sing" (1932), Rodgers and Hammerstein's "South Pacific" (1950), Bock & Harnick's "Fiorello!" (1960), Frank Loesser's "How to Succeed in Business Without Really Trying" (1962), Marvin Hamlisch, Ed Kleban, James Kirkwood, and Nicholas Dante's "A Chorus Line" (1976), Stephen Sondheim's and James Lapine's "Sunday in the Park with George" (1985), Jonathan Larson's "Rent" (1996), Brian Yorkey and Tom Kitt's "Next to Normal" (2010), and Lin-Manuel Miranda's "Hamilton" (2016).
"Of Thee I Sing", "Sunday in the Park with George", and "Next to Normal" are the only musicals that won the Pulitzer Prize and did not win the Tony Award for Best Musical. However, "Of Thee I Sing" opened when the Tony Awards did not exist, and "Next to Normal" won the Tony Award for Best Original Score and the Tony Award for Best Orchestrations.
The award goes to the playwright, although production of the play is also taken into account. In the case of a musical being awarded the prize, the composer, lyricist and book writer are generally the recipients. An exception to this was the first Pulitzer ever awarded to a musical: when "Of Thee I Sing" won in 1932, book authors George S. Kaufman and Morrie Ryskind, as well as lyricist Ira Gershwin, were cited as the winners, while composer George Gershwin's contribution was overlooked by the committee. The reason given was that the Pulitzer Prize for Drama is a "dramatic" award, and not a "musical" one. However, by 1950 the Pulitzer committee included composer Richard Rodgers as a recipient when "South Pacific" won the award, in recognition of music as an integral and important part of the theatrical experience.
Additionally, since 1983, when the identity of finalists was first disclosed, three musicals have been finalists for the Pulitzer Prize for Drama. They are: Lee Breuer and Bob Telson's "The Gospel at Colonus" (1985); Lin-Manuel Miranda and Quiara Alegría Hudes' "In the Heights" (2009); and Jeanine Tesori and Lisa Kron's "Fun Home" (2014). The latter two shows, however, each won the Tony Award for Best Musical.
¹All listed dates are Prize years. Generally, the musical in question opened in New York during either the preceding calendar year or the preceding Broadway season.
Repeat winners.
Eugene O'Neill won the Pulitzer for Drama four times, three in the 1920s. Several people have won two or three.
The most recipients of the prize in one Prize year was in 1976, when five people—Michael Bennett, James Kirkwood, Jr., Nicholas Dante, Marvin Hamlisch, and Edward Kleban—shared the prize for the musical "A Chorus Line".

</doc>
<doc id="48726" url="https://en.wikipedia.org/wiki?curid=48726" title="Occupational therapist">
Occupational therapist

An occupational therapist works with a client to help them achieve a fulfilled and satisfied state in life through the use of "purposeful activity or interventions designed to achieve functional outcomes which promote health, prevent injury or disability and which develop, improve, sustain or restore the highest possible level of independence." 
A practical definition for OT can also be illustrated with the use of models such as the Occupational Performance Model (Australia), known as the OPM(A). At the core of this approach is the ideology that occupational therapists are concerned with the occupations of people and how these contribute to health. Specifically it is a person's occupational performance that influences their health and personal satisfaction of their individual needs. The OPM(A) is constructed on the following definition of Occupational Performance:
It can be seen that occupational performance, the roles it creates for a client, and the areas it can encompass are so far-reaching that an occupational therapist can work with a wide range of clients of various limitations who are being cared for in an array of settings. Occupational therapy is about helping people do the day-to-day tasks that "occupy" their time, sustain themselves, and enable them to contribute to the wider community. It is these opportunities to "do", which occupational therapy provides, that prove important and meaningful to the health of people.
Role.
Occupational therapists (OTs) help people of all ages to improve their ability to perform tasks in their daily living and working environments. They work with individuals who have conditions that are mentally, physically, developmentally, socially or emotionally disabling. They also help them to develop, recover, or maintain daily living and work skills. Occupational therapists help clients not only to improve their basic motor functions and reasoning abilities, but also to compensate for permanent loss of function. Occupational therapists assist clients in performing activities of all types, ranging from using a computer to caring for daily needs such as dressing, cooking, and eating. Physical exercises may be used to increase strength and dexterity, while other activities may be chosen to improve visual acuity and the ability to discern patterns. For example, a client with short-term memory loss might be encouraged to make lists to aid recall, and a person with coordination problems might be assigned exercises to improve hand-eye coordination. Occupational therapists also use computer programs to help clients improve decision-making, abstract-reasoning, problem solving, and perceptual skills, as well as memory, sequencing, and coordination —- all of which are important for independent living. Occupational therapists are often skilled in psychological strategies such as cognitive behavioral therapy and Acceptance and Commitment Therapy, and may use cognitive therapy especially when introducing people to new strategies for carrying out daily activities such as activity pacing or using effective communication strategies.
Clients with permanent disabilities.
Therapists instruct those with permanent disabilities, such as spinal cord injuries, cerebral palsy, or muscular dystrophy, in the use of adaptive equipment, including wheelchairs, orthotics, and aids for eating and dressing. They also design or make special equipment needed at home or at work. Therapists develop computer-aided adaptive equipment and teach clients with severe limitations how to use that equipment in order to communicate better and control various aspects of their environment.
Work-related therapy.
Some occupational therapists treat individuals whose ability to function in a work environment has been impaired. These practitioners arrange employment, evaluate the work environment, plan work activities, and assess the client's progress. Therapists also may collaborate with the client and the employer to modify the work environment so that the work can be successfully completed.
With children.
Occupational therapists may work exclusively with individuals in a particular age group or with particular disabilities. In schools, for example, they evaluate children's abilities, recommend and provide therapy, modify classroom equipment, and help children participate as fully as possible in school programs and activities. A therapist may work with children individually, lead small groups in the classroom, consult with a teacher, or serve on a curriculum or other administrative committee. Early intervention therapy services are provided to infants and toddlers who have, or are at the risk of having, developmental delays. Occupational therapist may specialize in the care of infants in the Neonatal Intensive Care Unit, providing developmental care, addressing specific physical problems, assessing neurological function, and providing care givers with education on the care of their infant and the specific problems of a premature infant. Specific therapies may include facilitating the use of the hands, promoting skills for listening and following directions, fostering social skills, or teaching dressing and grooming skills.
With the elderly.
Occupational therapy is very beneficial to the elderly population. Therapists help the elderly lead more productive, active, and independent lives through a variety of methods, including the use of adaptive equipment. Occupational therapists work with the elderly in many varied environments, such as in their homes in the community, in hospital, and in residential care facilities to name a few. In the home environment, occupational therapists may work with the client to assess for hazards and to identify environmental factors that contribute to falls. Occupational therapists are often instrumental in assessing for appropriate wheelchairs for the elderly. In addition, therapists with specialized training in driver rehabilitation assess an individual's ability to drive using both clinical and on-the-road tests. The evaluations allow the therapist to make recommendations for adaptive equipment, training to prolong driving independence, and alternative transport options.
Mental health.
Occupational therapists also work with people who have mental health problems and learning disabilities. In this work, therapists choose activities that help people learn to engage in and cope with daily life. Activities include time management skills, budgeting, shopping, homemaking, and the use of public transportation. Occupational therapists also may work with individuals who are dealing with alcoholism, drug abuse, depression, eating disorders, or stress-related disorders. The ultimate aim would be to help people to engage in a personally satisfying and socially adaptive range of occupations.
With terminally ill patients.
Occupational therapists work with patients with terminal illness like cancer, Muscular dystrophy,etc. All performance areas including work, play and leisure are widely affected in these sets of patients. An occupational therapist provides various means to these patients to restore or maintain their deteriorating performance components by using their residual capacities and capabilities to give them a sense of self-importance and a measure of confidence.
With people experiencing chronic pain.
Occupational therapists often work within interdisciplinary or multidisciplinary teams (professionals such as nurses and doctors) to help individuals with chronic pain develop active self-management strategies. An area of specific concern to occupational therapists is the use of time but it is also common for occupational therapists to help people return to work, and to return to leisure and family activities. Occupational therapists may use a variety of interventions including biofeedback, relaxation, goal setting, problem solving, planning, and carry this out within both group and individual settings. Therapists may work within a clinic setting, or in the community including the workplace, school, home and health care centres. Occupational therapists may assess occupational performance before and after intervention, as a measure of effectiveness and reduction in disability.
Assessment.
Assessing and recording a client's activities and progress is an important part of an occupational therapist's job. Accurate records are essential for evaluating clients, for billing, and for reporting to physicians and other health care providers.
Thorough and accurate assessment ensures that Occupational Therapists select appropriate and effective interventions for their clients. Assessment in Occupational Therapy is complex and multifaceted, and is an essential component of the Occupational Therapy Process. Assessment occurs at the beginning of the Process (providing the foundation for effective treatment), at the end (evaluation). Reassessment also occurs throughout intervention.
Hand therapy.
Occupational Therapy also plays a major role in the rehabilitation and recovery of patients who have hand or upper extremity injuries. They play a significant role in liaising with Hand Surgeon/Orthopeadic Surgeon and patients employers or case managers in providing the best client centered rehabilitation program. Occupational Therapist treats conditions ranging from soft tissue injuries such as Tennis Elbows to nerve neuropathies such as Cubital Tunnel Syndrome/ Carpal Tunnel Syndrome. An Array of Upper Limb assessment are utilised to provide a treatment care that is effective and appropriate. Treatment modalities such as orthosis/splints, soft braces and education are some of the common treatment tool that an occupational therapist will use during treatment. Hand Therapy is a specialised field of occupational therapy and it requires therapist to be highly skilled and knowledgeable in upper limb anatomy to be able to work in this area. It is definitely an area where Occupational Therapy is famous for due to the therapeutic models that the profession practices which focus on occupation as means and ends and their aim of returning patients to them performing their daily functions.

</doc>
<doc id="48727" url="https://en.wikipedia.org/wiki?curid=48727" title="Corpus Juris Civilis">
Corpus Juris Civilis

"This article is about the Roman law codification of Justinian I. For the canon law codification of a similar name, see Corpus Juris Canonici."
The Corpus Juris (or Iuris) Civilis ("Body of Civil Law") is the modern name for a collection of fundamental works in jurisprudence, issued from 529 to 534 by order of Justinian I, Eastern Roman Emperor. It is also sometimes referred to as the Code of Justinian, although this name belongs more properly to the part titled "Codex Justinianus".
The work as planned had three parts: the "Code" ("Codex") is a compilation, by selection and extraction, of imperial enactments to date; the "Digest" or "Pandects" (the Latin title contains both "Digesta" and "Pandectae") is an encyclopedia composed of mostly brief extracts from the writings of Roman jurists; and the "Institutes" ("Institutiones") is a student textbook, mainly introducing the "Code", although it has important conceptual elements that are less developed in the "Code" or the "Digest". All three parts, even the textbook, were given force of law. They were intended to be, together, the sole source of law; reference to any other source, including the original texts from which the "Code" and the "Digest" had been taken, was forbidden. Nonetheless, Justinian found himself having to enact further laws and today these are counted as a fourth part of the Corpus, the "Novellae Constitutiones" ("Novels", literally "New Laws").
The work was directed by Tribonian, an official in Justinian's court. His team was authorized to edit what they included. How far they made amendments is not recorded and, in the main, cannot be known because most of the originals have not survived. The text was composed and distributed almost entirely in Latin, which was still the official language of the government of the Empire in 529–534, whereas the prevalent language of merchants, farmers, seamen, and other citizens was Greek. By the early 7th century, the official government language had become Greek during the lengthy reign of Heraclius (610–641).
How far the Corpus Iuris Civilis or any of its parts was effective, whether in the east or (with reconquest) in the west, is unknown. However, it was not in general use during the Early Middle Ages. After the Early Middle Ages, interest in it revived. It was "received" or imitated as private law and its public-law content was quarried for arguments by both secular and ecclesiastical authorities. This revived Roman law, in turn, became the foundation of law in all civil law jurisdictions. The provisions of the Corpus Juris Civilis also influenced the Canon Law of the church: it was said that "ecclesia vivit lege romana" — the church lives by Roman law. Influence on the common-law systems has been much smaller, although some basic concepts from the Corpus have survived through Norman law - such as the contrast, especially in the "Institutes", between "law and custom ("lex et consuetudo")". The Corpus continues to have a major influence on public international law. Its four parts thus constitute the foundation documents of the Western legal tradition.
The four parts.
Codex.
The "Codex" was the first part to be finished, on 7 April 529. It contained in Latin most of the existing imperial "constitutiones" (imperial pronouncements having force of law), back to the time of Hadrian. It used both the "Codex Theodosianus" and the fourth-century collections embodied in the "Codex Gregorianus" and "Codex Hermogenianus", which provided the model for division into books that were themselves divided into titles. These works had developed authoritative standing. This first edition is now lost; a second edition was issued in 534 and is the text that has survived. At least the second edition contained some of Justinian's own legislation, including some legislation in Greek. It is not known whether he intended there to be further editions, although he did envisage translation of Latin enactments into Greek.
Legislation about religion.
Numerous provisions served to secure the status of Christianity as the state religion of the empire, uniting Church and state, and making anyone who was not connected to the Christian church a non-citizen.
The very first law in the Codex requires all persons under the jurisdiction of the Empire to hold the Christian faith. This was primarily aimed against heresies such as Nestorianism. This text later became the springboard for discussions of international law, especially the question of just what persons are under the jurisdiction of a given state or legal system.
Other laws, while not aimed at pagan belief as such, forbid particular pagan practices. For example, it is provided that all persons present at a pagan sacrifice may be indicted as if for murder.
Digesta.
The "Digesta" or "Pandectae", completed in 533, is a collection of juristic writings, mostly dating back to the second and third centuries. Fragments were taken out of various legal treatises and opinions and inserted in the Digest. In their original context, the statements of the law contained in these fragments were just private opinions of legal scholars - although some juristic writings had been privileged by Theodosius II's Law of Citations in 426. The Digest, however, was given complete force of law.
Institutiones.
As the "Digest" neared completion, Tribonian and two professors, Theophilus and Dorotheus, made a student textbook, called the "Institutions" or "Elements". As there were four elements, the manual consists of four books. The "Institutiones" are largely based on the "Institutiones" of Gaius. Two thirds of the "Institutiones" of Justinian consists of literal quotes from Gaius. The new "Institutiones" were used as a manual for jurists in training from 21 November 533 and were given the authority of law on 30 December 533 along with the "Digest".
Novellae.
The Novellae consisted of new laws that were passed after 534. They were later re-worked into the "Syntagma", a practical lawyer's edition, by Athanasios of Emesa during the years 572–77.
Continuation in the East.
The term "Byzantine Empire" is used today to refer to what remained of the Roman Empire in the Eastern Mediterranean following the collapse of the Empire in the West. This Eastern empire continued to practice Roman Law and formalized it via the Corpus Juris Civilis. The law was modified to be adequate for the new social relationships in the Middle ages. Thus the Byzantine law was created. New legal codes, based on Corpus Juris Civilis, were enacted. The most known are: Ecloga (740)—enacted by emperor Leo the Isaurian, Proheiron (c. 879)—enacted by emperor Basil the Macedonian and Basilika (late 9th century)—started by Basil the Macedonian and finished by his son Leo the Wise. The last one was a complete adaptation of Justinian's codification. At 60 volumes it proved to be difficult for judges and lawyers to use. There was need for a short and handy version. It was finally made by Constantine Harmenopoulos, a judge from Thesaloniki, in 1345. He made a short version of Basilika in six books, called "Hexabiblos". Serbian state, law and culture was built on the foundations of Rome and Byzantium. Therefore, the most important Serbian legal codes: Zakonopravilo (1219) and Dušan's Code (1349 and 1354), transplanted Roman-Byzantine Law included in Corpus Juris Civilis, Prohiron and Basilika. These Serbian codes were practised until the Serbian Despotate fell to the Turkish Ottoman Empire in 1459. After the liberation from the Turks in the Serbian Revolution, Serbs continued to practise Roman Law by enacting Serbian civil code in 1844. It was a short version of Austrian civil code (called "Allgemeines bürgerliches Gesetzbuch"), which was made on the basis of Corpus Juris Civilis.
Recovery in the West.
Justinian's "Corpus Juris Civilis" was distributed in the West but was lost sight of; it was scarcely needed in the comparatively primitive conditions that followed the loss of the Exarchate of Ravenna by the Byzantine empire in the 8th century. A two-volume edition of the Digest was published in Paris in 1549 and 1550, translated by Antonio Augustini, Bishop of Tarragona, who was well known for other legal works. The full title of the Digest was "Digestorum Seu Pandectarum tomus alter", and it was published by "Apud Carolam Guillards". Vol. 1 of the Digest has 2934 pages, while Vol. 2 has 2754 pages. The only western province where the Justinianic code was effectively introduced was Italy, following its recovery by Byzantine armies (Pragmatic Sanction of 554), but a continuous tradition of Roman law in medieval Italy has not been proven. Historians disagree on the precise way it was recovered in Northern Italy about 1070: legal studies were undertaken on behalf of papal authority central to the Gregorian Reform of Pope Gregory VII, which may have led to its accidental rediscovery. Aside from the Littera Florentina (a 6th-century codex of the Pandects that was preserved at Pisa) there may have been other manuscript sources for the text that began to be taught at Bologna, by Pepo and then by Irnerius. Irnerius' technique was to read a passage aloud, which permitted his students to copy it, then to deliver an excursus explaining and illuminating Justinian's text, in the form of glosses. Irnerius' pupils, the so-called Four Doctors of Bologna, were among the first of the "glossators" who established the curriculum of medieval Roman law. The tradition was carried on by French lawyers, known as the Ultramontani, in the 13th century.
The merchant classes of Italian communes required law with a concept of equity, and law that covered situations inherent in urban life better than the primitive Germanic oral traditions. The provenance of the Code appealed to scholars who saw in the Holy Roman Empire a revival of venerable precedents from the classical heritage. The new class of lawyers staffed the bureaucracies that were beginning to be required by the princes of Europe. The University of Bologna, where Justinian's Code was first taught, remained the dominant centre for the study of law through the High Middle Ages.
Referring to Justinian's Code as "Corpus Juris Civilis" was only adopted in the 16th century, when it was printed in 1583 by Dionysius Gothofredus under this title. The legal thinking behind the "Corpus Juris Civilis" served as the backbone of the single largest legal reform of the modern age, the Napoleonic Code, which marked the abolition of feudalism.
The "Corpus Juris Civilis" was translated into French, German, Italian, and Spanish in the 19th century. However, no English translation of the entire "Corpus Juris Civilis "existed until 1932 when Samuel Parsons Scott published his version "The Civil Law". Unfortunately, Scott did not base his translation on the best available Latin versions, and his work was severely criticized. Fortunately, Fred. H. Blume did use the best-regarded Latin editions for his translations of the Code and of the Novels.

</doc>
<doc id="48728" url="https://en.wikipedia.org/wiki?curid=48728" title="Social Security (United States)">
Social Security (United States)

In the United States, Social Security is primarily the Old-Age, Survivors, and Disability Insurance (OASDI) federal program. The original Social Security Act was signed into law by President Franklin Roosevelt in 1935, and the current version of the Act, as amended, encompasses several social welfare and social insurance programs.
Social Security is funded through payroll taxes called Federal Insurance Contributions Act tax (FICA) or Self Employed Contributions Act Tax (SECA). Tax deposits are collected by the Internal Revenue Service (IRS) and are formally entrusted to the Federal Old-Age and Survivors Insurance Trust Fund, the Federal Disability Insurance Trust Fund, the Federal Hospital Insurance Trust Fund, or the Federal Supplementary Medical Insurance Trust Fund which make up the Social Security Trust Funds. With a few exceptions, all salaried income, up to an amount specifically determined by law (see tax rate table below) has a FICA or SECA tax collected on it. All income over said amount is not taxed. For 2015 the maximum amount of taxable earnings was $118,500.
With few exceptions, all legal residents working in the United States now have an individual Social Security number. Indeed, nearly all working (and many non-working) residents since Social Security's 1935 inception have had a Social Security number, because it is required to do a wide range of things including paying the IRS and getting a job.
In 2013, the total Social Security expenditures were $1.3 trillion, 8.4% of the $16.3 trillion GNP (2013) and 37% of the federal expenditures of $3.684 trillion. Income derived from Social Security is currently estimated to keep roughly 20% of all Americans, age 65 or older, above the federally defined poverty level. The Social Security Administration is headquartered in Woodlawn, Maryland, just west of Baltimore.
History.
Social Security Timeline
A limited form of the Social Security program began, during President Franklin D. Roosevelt's first term, as a measure to implement "social insurance" during the Great Depression of the 1930s, when poverty rates among senior citizens exceeded 50 percent. The Act was an attempt to limit unforeseen and unprepared for dangers in the modern life, including old age, disability, poverty, unemployment, and the burdens of widow(er)s with and without children.
Opponents, however, decried the proposal as socialism. In a Senate Finance Committee hearing, the Democratic Oklahoma Senator Thomas Gore asked Secretary of Labor Frances Perkins, "Isn't this socialism?" She said that it was not, but he continued, "Isn't this a teeny-weeny bit of socialism?"
The provisions of Social Security have been changing since the 1930s, shifting in response to economic worries as well as coverage for the poor, dependent children, spouses, survivors and the disabled. By 1950, debates moved away from which occupational groups should be included to get enough taxpayers to fund Social Security to how to provide more benefits. Changes in Social Security have reflected a balance between promoting "equality" and efforts to provide "adequate" and affordable protection for low wage workers.
Major Social Security programs.
The larger and better known programs under the Social Security Administration, SSA, are:
Benefits.
Social Security Benefits and Income 2012.
The largest component of OASDI is the payment of retirement benefits. These retirement benefits are a form of social insurance that is heavily biased toward lower paid workers to make sure they do not have to retire in relative poverty. With few exceptions, throughout a worker's career, the Social Security Administration and the Internal Revenue Service (IRS) keeps track of his or her earnings and requires Federal Insurance Contribution Act, FICA or Self Employed Contribution Act, SECA, taxes to be paid on the earnings. The OASI accounts plus trust funds are the only Social Security funding source that brings in more than it sends out.
Social Security revenues exceeded expenditures, between 1983 and 2009.
The disability insurance (DI) taxes of 1.4% are included in the OASDI rate of 6.2% for workers and employers or 12.4% for the self-employed. Outgo of $140.3 billion while having income of only $109.1 billion means the disability trust fund is rapidly being depleted and may require either revisions on what "disabilities" are included/allowed/defined as, fraud minimization or tax increases.
The Medicare hospital insurance, HI, (Part A: Hospital Insurance, inpatient care, skilled nursing facility care, home health care, and hospice care) expenditure rate of $266.8 billion in 2012 while bringing in only $243.0 billion means that the medicare HI trust funds are being seriously depleted and increased taxes or reduced coverage will be required. The additional retirees expected under the "baby boom bulge" will hasten this trust fund depletion. Medicare expenses, tied to medical costs growth rates, have traditionally increased much faster than GDP growth rates.
The Supplementary Medical Insurance, SMI, (otherwise known as Medicare Part B & D) expenditure rate of $307.4 billion in 2012 while bringing in only $293.9 billion means that the Supplementary Medical Insurance trust funds are also being seriously depleted and increased tax rates or reduced coverage will be required. The additional retirees expected under the "baby boom bulge" will hasten this trust fund depletion as well as legislation to end the Medicare Part D medical prescription drug funding "donut hole" are all tied to medical costs growth rates, which have traditionally increased much faster than GDP growth rates.
For workers the Social Security tax rate is 6.2% on income under $118,500 through the end of 2015. The worker Medicare tax rate is 1.45% of all income—employers pay another 1.45%. Employers pay 6.2% up to the wage ceiling and the Medicare tax of 1.45 percent on all income. Workers defined as "self employed" pay 12.4% on income under $113,700 and a 2.9% Medicare tax on all income.
The amount of the monthly Social Security benefit to which a worker is entitled depends upon the earnings record they have paid FICA or SECA taxes on and upon the age at which the retiree chooses to begin receiving benefits.
Primary Insurance Amount and benefit calculations.
All workers paying FICA (Federal Insurance Contributions Act) and SECA (Self Employed Contributions Act) taxes for forty quarters of credit (QC) or more on a specified minimum income or more are "fully insured" and eligible to retire at age 62 with reduced benefits and higher benefits at full retirement ages, FRA, of 65, 66 or 67 depending on birth date. Retirement benefits depend upon the "adjusted" average wage you or your spouse have earned in the last 35 years and your respective ages. Wages of earlier years are "adjusted" before averaging by multiplying each annual salary by an annual adjusted wage index factor, AWI, for earlier salaries. Adjusted wages for 35 years are always used to compute the 35 year "average" indexed monthly salary. Only wages lower than the "ceiling" income are considered in calculating the adjusted average wage. If the worker has fewer than 35 years of covered earnings these non-contributory years are assigned zero earnings. If there are more than 35 years of covered earnings only the highest 35 are considered. The sum of the 35 adjusted salaries (or less if worker has less than 35 years of covered income) times its inflation index, AWI divided by 420 (35 yrs x 12 months/yr) gives the 35 year covered Average Indexed Monthly salary, AIME.
To calculate your Average Indexed Monthly salary (AIME) earnings, the records of your covered salaries may be obtained from the Social Security Administration by applying for them and paying a fee ranging from $15.00 for one year's covered wages to $80.00 for 40 years of wages. The adjusted wage indexes are available at Social Security's "Benefit Calculation Examples For Workers Retiring In 2013". The data from this site can be copied and pasted directly into a spreadsheet. For earlier AWI factors see:. By erasing the example salary data in the spreadsheet and substituting your own salaries and deleting the example indexed salaries and calculating your own Indexed salary (Salary*Index = Indexed salary) you can get your indexed salaries. In the spreadsheet the adjusted salaries can easily be summed and divided by 420 to find your adjusted indexed monthly salary, AIME.
To calculate the total benefits a retiree is eligible for the average indexed monthly salary (AIME) is then divided into three separate salary brackets which are each multiplied by a different benefit percentage for each bracket. The benefits you can receive (the so-called Primary Insurance Amount, PIA) are the sum of the salary in each bracket times the benefit percentages that apply to each bracket. The benefit percentages are set by Congress and so can easily change in the future. The "bendpoints", where the brackets change, are adjusted for inflation each year by Social Security. For example, in 2013 the first bracket runs from $1.00 to $791.00/month and is multiplied by the benefit percentage of 90%, the second salary bracket extends from $791.00 to $4781.00/month is multiplied by 32%, the third salary bracket of more than $4781.00/month is multiplied by 15%. Any higher incomes than the ceiling income are not FICA covered and are not considered in the benefits calculation or in determining the average indexed monthly salary, AIME. At full retirement age the projected retirement income amount (PIA) is the sum of these three brackets of income multiplied by the appropriate benefit percentages—90%, 32% and 15%. Unlike income tax brackets, the Social Security benefits are heavily biased towards lower salaried workers. Social Security has always been primarily a retirement, disability and spousal insurance policy for low wage workers and a very poor retirement plan for higher salaried workers who hopefully have a supplemental retirement plan unless they want to live on significantly less after retirement than they used to earn.
Full retirement age spouses and divorced spouses (married over 10 years before divorce) are entitled to the higher of 50% of the wage earners benefits or their own earned benefits. A low salary worker and his full retirement age spouse making less than or equal to $791/month with 40 quarters of employment credit and at full retirement age (65 if born before 1938, 66 if born from 1938 to 1954 and 67 if born after 1960) could retire with 135% of his indexed average salary. A full retirement age worker and his full retirement age spouse making the ceiling income or more would be eligible for 43% of the ceiling FICA salary (29% if single) and even less if making more than the ceiling income.
During working years, the low wage worker is eligible for the Earned Income Tax Credit (FICA refunds) and federal child credits and may pay little or no FICA tax or Income tax. By Congressional Budget Office (CBO) calculations the lowest income quintile (0-20%) and second quintile (21-40%) of households in the U.S. pay an average income tax of -9.3% and -2.6% and Social Security taxes of 8.3% and 7.9% respectively. By CBO calculations the household incomes in the first quintile and second quintile have an average Total Federal Tax rate of 1.0% and 3.8% respectively. Higher income retirees will have to pay income taxes on 85% of their Social Security benefits and 100% on all other retirement benefits they may have.
All workers paying FICA and SECA taxes for forty quarters of credit (QC) or more on a specified minimum income is "fully insured" and eligible to retire at age 62 with reduced benefits. In general the Social Security Administration tries to limit the projected life time benefits to the same amounts of retirement income the recipient would receive if retiring at full retirement age. If a recipient retires earlier he/she draws a lower Social Security benefit income for a longer prospective lifetime after retirement. The basic correction of benefits are age 62 retirees can only draw 75% of what they would draw at full retirement age with higher percentages at different ages more than 62 and less than full retirement age.
Similar computations based on career average adjusted earnings and age of recipient determine disability and survivor benefits. Federal, state and local employees who have elected (when they could) NOT to pay FICA taxes are eligible for a reduced FICA benefits and full Medicare coverage if they have more than forty quarters of qualifying Social Security covered work. To minimize the Social Security payments to those who have not contributed to FICA for 35+ years and are eligible for federal, state and local benefits, which are usually much more generous, Congress passed the Windfall Elimination Provision, WEP. The WEP provision will not eliminate all Social Security or Medicare eligibility if the worker has 40 quarters of qualifying income, but calculates the benefit payments by reducing the 90% multiplier in the first salary bracket to 40-85% depending on age etc. The WEP provision rarely causes hardship since by and large the people affected are reasonably well off because by definition they also receive government pensions from noncovered work.
For those few cases where workers with very low earnings over a long working lifetime that were too low to receive full retirement credits and the recipients would receive a very small Social Security retirement benefit a "special minimum benefit" (special minimum PIA) provides a "minimum" of $804 per month in Social Security benefits in 2013. To be eligible the recipient along with their auxiliaries and survivors must have very low assets and not be eligible for other retirement system benefits. About 75,000 people in 2013 receive this benefit.
The benefits someone is eligible for are potentially so complicated that potential retirees should consult the Social Security Administration directly for advice. Many questions are addressed and at least partially answered on many online publications and online calculators.
Online Social Security benefits estimate.
On July 22, 2008, the Social Security Administration introduced a new online benefits estimator. A worker who has enough Social Security credits to qualify for benefits, but who is not currently receiving benefits on his or her own Social Security record and who is not a Medicare beneficiary, can obtain an estimate of the retirement benefit that will be provided, for different assumptions about age at retirement. This process is done by opening a secure online account called "my Social Security." For retirees who have non FICA or SECA taxed wages the rules get complicated and probably require additional help.
Normal retirement age.
The earliest age at which (reduced) benefits are payable is 62. Full retirement benefits depend on a retiree's year of birth.
This table was copied in November 2011 from the Social Security Administration web site cited above and referenced in the footnotes. There are different rules for widows and widowers. Also from that site, come the following two notes:
Notes:
1. Persons born on January 1 of any year should refer to the normal retirement age for the previous year.
2. For the purpose of determining benefit reductions for early retirement, widows and widowers whose entitlement is based on having attained age 60 should add 2 years to the year of birth shown in the table.
Those born before 1938 have a normal retirement age of 65. Normal retirement age increases by two months for each ensuing year of birth until 1943, when it reaches 66 and stays at 66 until 1955. Thereafter the normal retirement age increases again by two months for each year until 1960, when normal retirement age is 67 and remains 67 for all individuals born thereafter.
A worker who starts benefits before normal retirement age has their benefit reduced based on the number of months before normal retirement age they start benefits. This reduction is 5/9 of 1% for each month up to 36 and then 5/12 of 1% for each additional month. This formula gives an 80% benefit at age 62 for a worker with a normal retirement age of 65, a 75% benefit at age 62 for a worker with a normal retirement age of 66, and a 70% benefit at age 62 for a worker with a normal retirement age of 67. The 2008–2012 global recession has resulted in an increase in long-term unemployment and an increase in workers taking early retirement.
A worker who delays starting retirement benefits past normal retirement age earns delayed retirement credits that increase their benefit until they reach age 70. These credits are also applied to their widow(er)'s benefit. Children and spouse benefits are not affected by these credits.
The normal retirement age for widow(er) benefits shifts the year-of-birth schedule upward by two years, so that those widow(er)s born before 1940 have age 65 as their normal retirement age.
Spouse's benefit and government pension offsets.
The spousal "retirement benefit" is "one-half" the "PIA" benefit amount of their spouse or their own earned benefits, whichever is higher, if they both retire at "normal" retirement ages. Only after the working spouse applies for retirement benefits may the non-working spouse apply for spousal retirement benefits. The spousal benefit is the PIA times an "early-retirement factor" if the spouse is younger than the "normal" full retirement age. The early-retirement factor is 50% minus 25/36 of 1% per month for the first 36 months and 5/12 of 1% for each additional month earlier than the "normal" full retirement date. This typically works out to between 50% and 32.5% of the primary workers PIA benefit. There is no increase for starting spousal benefits "after" normal retirement age. This can occur if there is a married couple in which the younger person is the only worker and is more than 5 years younger. Any current spouse is eligible, and divorced or former spouses are eligible for spousal benefits if the marriage lasted for at least 10 years. It is arithmetically possible for one worker to generate spousal benefits for up to five of his/her spouses that he/she may have, each must be in succession after a proper divorce for each after a marriage that lasted at least ten years each. 
The spousal "survivor benefit" is the full PIA benefit of the working spouse (reduced if the deceased was receiving a reduced benefit) or their own benefit, whichever is higher.
There is a Social Security government pension offset that will reduce or eliminate any spousal (or ex-spouse) or widow(er)'s benefits if the spouse or widow(er) is also receiving a government (federal, state or local) pension that did not require paying Social Security taxes. The basic "rule" is that Social Security benefits will be reduced by 2/3's of the spouse or widow(er)'s non-FICA taxed government pension. If the spouse's or widow(er)'s government (non-FICA paying) pension exceeds 150% of the "normal" spousal or widow(er)'s benefit the spousal benefit is eliminated. For example, a "normal" spousal or widow(er)'s benefit of $1,000/month would be reduced to $0.00 if the spouse or widow(er)'s if already drawing a non-FICA taxed government pension of $1,500/month or more per month. Pensions not based on income do not reduce Social Security spousal or widow(er)'s benefits.
The passage of the Senior Citizens' Freedom to Work Act, in 2000, allows the worker to earn unlimited outside income without offsets in the year after they reach full retirement. It also allows the spouse and children of a worker who has reached normal full retirement age to receive benefits under some circumstances while he/she does not. The full retirement age worker has to have begun the receipt of benefits, to allow the spousal/children's benefits to begin, and then subsequently suspended his/her own benefits in order to continue the postponement of benefits in exchange for an increased benefit amount (5.5-8.0%/yr increase) up to the age of 70. Thus a worker can delay retirement up to age seventy without affecting spousal or children's benefits.
Delayed Social Security Benefits.
If a worker delays receiving Social Security retirement benefits until after they reach full retirement age there is a Social Security benefits increase by a certain percentage—depending on date of birth. After age 70 there are no more increases in retirement benefits allowed. Social Security uses an "average" survival rate at your full retirement age to prorate the increase in the amount of benefit increase so that the total benefits are roughly the same whenever you retire. Women may benefit more than men from this delayed benefit increase since the "average" survival rates are based on both men and women and women live approximately three years longer than men. The other consideration is that workers only have a limited number of years of "good" health left after they reach full retirement age and unless they enjoy their job they may be passing up an opportunity to do something else they may enjoy doing while they are still relatively healthy.
Social Security Benefits while continuing work.
Due to changing needs or personal preferences, a person may go back to work after retiring. In this case, it is possible to get Social Security retirement or survivors benefits and work at the same time. A worker who is of full retirement age or older may (with spouse) keep all benefits, after taxes, regardless of earnings. But, if this worker or the worker's spouse are younger than full retirement age and receiving benefits and earn "too much", the benefits will be reduced. If working under full retirement age for the entire year and receiving benefits, Social Security deducts $1 from the worker's benefit payments for every $2 earned above the annual limit of $15,120 (2013). Deductions cease when the benefits have been reduced to zero and the worker will get one more year of income and age credit, slightly increasing future benefits at retirement. For example, if you were receiving benefits of $1,230/month (the average benefit paid) or $14,760 a year and have an income of $29,520/year above the $15,120 limit ($44,640/year) you would lose all ($14,760) of your benefits. If you made $1,000 more than $15,200/year you would "only lose" $500 in benefits. You would get no benefits for the months you work until the $1 deduction for $2 income "squeeze" is satisfied. Your first social security check will be delayed for several months—the first check may only be a fraction of the "full" amount. The benefit deductions change in the year you reach full retirement age and are still working—Social Security only deducts $1 in benefits for every $3 you earn above $40,080 in 2013 for that year and has no deduction thereafter. The income limits change (presumably for inflation) year by year.
Widow(er) benefits.
If a worker covered by Social Security dies, a surviving spouse can receive survivors' benefits. In some instances, survivors' benefits are available even to a divorced spouse. A father or mother with minor or disabled children in his or her care can receive benefits which are not actuarially reduced. The earliest age for a non-disabled widow(er)'s benefit is age 60. The benefit is equal to the worker's basic retirement benefit (PIA) (reduced if the deceased was receiving reduced benefits) for spouses who are at, or older than, normal retirement age. If the surviving spouse starts benefits before normal retirement age, there is an actuarial reduction. If the worker earned delayed retirement credits by waiting to start benefits after their normal retirement age, the surviving spouse will not have those credits applied to their benefit.
Children's benefits.
Children of a retired, disabled or deceased worker receive benefits as a "dependent" or "survivor" if they are under the age of 18, or as long as attending primary or secondary school up to age 19 years, 2 months; or are over the age of 18 and were disabled before the age of 22.
In "Astrue v. Capato" (2012), the Supreme Court unanimously held that children conceived after a parent's death (by in vitro fertilization procedure) are not entitled to Social Security survivors' benefits if the laws of the state in which the parent's will was signed do not provide for such benefits.
Disability.
A worker who has worked long enough and recently enough (based on "quarters of coverage" within the recent past) to be covered "can" receive disability benefits. These benefits start after five full calendar months of disability, regardless of his or her age. The eligibility formula requires a certain number of credits (based on earnings) to have been earned overall, and a certain number within the ten years immediately preceding the disability, but with more-lenient provisions for younger workers who become disabled before having had a chance to compile a long earnings history.
The worker must be unable to continue in his or her previous job and unable to adjust to other work, with age, education, and work experience taken into account; furthermore, the disability must be long-term, lasting 12 months, expected to last 12 months, resulting in death, or expected to result in death. As with the retirement benefit, the amount of the disability benefit payable depends on the worker's age and record of covered earnings.
Supplemental Security Income (SSI) uses the same disability criteria as the insured social security disability program, but SSI is not based upon insurance coverage. Instead, a system of means-testing is used to determine whether the claimants' income and net worth fall below certain income and asset thresholds.
Severely disabled children may qualify for SSI. Standards for child disability are different from those for adults.
Disability determination at the Social Security Administration has created the largest system of administrative courts in the United States. Depending on the state of residence, a claimant whose initial application for benefits is denied can request "reconsideration" or a "hearing before an Administrative Law Judge (ALJ)". Such hearings sometimes involve participation of an independent vocational expert (VE) or medical expert (ME), as called upon by the ALJ.
Reconsideration involves a re-examination of the evidence and, in some cases, the opportunity for a hearing before a (non-attorney) disability hearing officer. The hearing officer then issues a decision in writing, providing justification for his/her finding. If the claimant is denied at the reconsideration stage, (s)he may request a hearing before an Administrative Law Judge. In some states, SSA has implemented a pilot program that eliminates the reconsideration step and allows claimants to appeal an initial denial directly to an Administrative Law Judge.
Because the number of applications for Social Security disability is very large (approximately 650,000 applications per year), the number of hearings requested by claimants often exceeds the capacity of Administrative Law Judges. The number of hearings requested and availability of Administrative Law Judges varies geographically across the United States. In some areas of the country, it is possible for a claimant to have a hearing with an Administrative Law Judge within 90 days of his/her request. In other areas, waiting times of 18 months are not uncommon.
After the hearing, the Administrative Law Judge (ALJ) issues a decision in writing. The decision can be "Fully Favorable" (the ALJ finds the claimant disabled as of the date that (s) he alleges in the application through the present), "Partially Favorable" (the ALJ finds the claimant disabled at some point, but not as of the date alleged in the application; OR the ALJ finds that the claimant "was" disabled but has improved), or "Unfavorable" (the ALJ finds that the claimant was not disabled at all). Claimants can appeal decisions to Social Security's Appeals Council, which is in Virginia. The Appeals Council does not hold hearings; it accepts written briefs. Response time from the Appeals Council can range from 12 weeks to more than 3 years.
If the claimant disagrees with the Appeals Council's decision, (s)he can appeal the case in the federal district court for his/her jurisdiction. As in most federal court cases, an unfavorable district court decision can be appealed to the appropriate United States Court of Appeals, and an unfavorable appellate court decision can be appealed to the United States Supreme Court.
The Social Security Administration has maintained its goal for judges to resolve 500-700 cases per year but an Administrative Law Judge on the average nationwide disposes of approximately 400 cases per year. The debate about the social security system in the United States has been ongoing for decades and there is much concern about its sustainability.
Current operation.
Joining and quitting.
Obtaining a Social Security number for a child is voluntary. Further, there is no general legal requirement that individuals join the Social Security program unless they want or have to work. Under normal circumstances, FICA taxes or SECA taxes will be collected on all wages. About the only way to avoid paying either FICA or SECA taxes are to join a "religion" that does not believe in insurance, such as the Amish, Christian Science or a religion whose members have taken a vow of poverty (see IRS publication 517 and 4361). Federal workers employed before 1987, various state and local workers including those in some school districts who had their own retirement and disability programs were given the one-time option of joining Social Security. Many employees and retirement and disability systems opted to keep out of the Social Security system because of the cost and the limited benefits. It was often much cheaper to obtain much higher retirement and disability benefits by staying in their original retirement and disability plans. Now only a few of these plans allow new hires to join their existing plans without also joining Social Security. In 2004, the Social Security Administration estimated that 96% of all U.S. workers were covered by the system with the remaining 4% mostly a minority of government employees enrolled in public employee pensions and not subject to Social Security taxes due to historical exemptions.
It is possible for railroad employees to get a "coordinated" retirement and disability benefits. The U.S. Railroad Retirement Board (or "RRB") is an independent agency in the executive branch of the United States government created in 1935 to administer a social insurance program providing retirement benefits to the country's railroad workers. Railroad retirement Tier I payroll taxes are coordinated with social security taxes so that employees and employers pay Tier I taxes at the same rate as social security taxes and have the same benefits. In addition, both workers and employers pay Tier II taxes (about 6.2% in 2005) which are used to finance railroad retirement and disability benefit payments that are over and above social security levels. Tier 2 benefits are a supplemental retirement and disability benefit system which pays 0.875% times years of service times average highest five years of employment salary, in addition to Social Security benefits.
The FICA taxes are imposed on nearly all workers and self-employed persons. Employers are required to report wages for covered employment to Social Security for processing Forms W-2 and W-3. There are some specific wages which are not a part of the Social Security program (discussed below). Internal Revenue Code provisions section 3101 imposes payroll taxes on individuals and employer matching taxes. Section 3102 mandates that employers deduct these payroll taxes from workers' wages before they are paid. Generally, the payroll tax is imposed on everyone in employment earning "wages" as defined in 3121 of the Internal Revenue Code. and also taxes net earnings from self-employment.
Trust fund.
Social Security taxes are paid into the Social Security Trust Fund maintained by the U.S. Treasury (technically, the "Federal Old-Age and Survivors Insurance Trust Fund", as established by ). Current year expenses are paid from current Social Security tax revenues. When revenues exceed expenditures, as they did between 1983 and 2009, the excess is invested in special series, non-marketable U.S. government bonds. Thus, the Social Security Trust Fund indirectly finances the federal government's general purpose deficit spending. In 2007, the cumulative excess of Social Security taxes and interest received over benefits paid out stood at $2.2 trillion. The Trust Fund is regarded by some as an accounting construct which holds no economic significance. Others argue that it has specific legal significance because the Treasury securities it holds are backed by the "full faith and credit" of the U.S. government, which has an obligation to repay its debt.
The Social Security Administration's authority to make benefit payments as granted by Congress extends only to its current revenues and existing Trust Fund balance, "i.e.", redemption of its holdings of Treasury securities. Therefore, Social Security's ability to make full payments once annual benefits exceed revenues depends in part on the federal government's ability to make good on the bonds that it has issued to the Social Security trust funds. As with any other federal obligation, the federal government's ability to repay Social Security is based on its power to tax and borrow and the commitment of Congress to meet its obligations.
In 2009 the Office of the Chief Actuary of the Social Security Administration calculated an unfunded obligation of $15.1 trillion for the Social Security program. The unfunded obligation is the difference between the future cost of Social Security (based on several demographic assumptions such as mortality, work force participation, immigration, and age expectancy) and total assets in the Trust Fund given the expected contribution rate through the current scheduled payroll tax. This unfunded obligation is expressed in present value dollars and is a part of the Fund's long-range actuarial estimates, not necessarily a certainty of what will occur in the long run. An Actuarial Note to the calculation says that "The term obligation is used in lieu of the term liability, because liability generally indicates a contractual obligation (as in the case of private pensions and insurance) that cannot be altered by the plan sponsor without the agreement of the plan participants."
Office of Disability Adjudication and Review (ODAR).
The Office of Disability Adjudication and Review (ODAR), known before 2006 as the Office of Hearings and Appeals (OHA), administers the hearings and appeals program for the Social Security Administration (SSA). Administrative Law Judges (ALJs) conduct hearings and issue decisions. The Appeals Council considers appeals from hearing decisions, and acts as the final level of administrative review for the Social Security Administration.
Social Security Benefit payout comparisons.
Some federal, state, local and education government employees pay no Social Security but have their own retirement, disability systems that nearly always pay much better retirement and disability benefits than Social Security. These plans typically requires vesting—working for 5–10 years for the same employer before becoming eligible for retirement. But their retirement typically only depends on the average of the best 3–10 years salaries times some retirement factor (typically 0.875%-3.0%) times years employed. This retirement benefit can be a "reasonably good" (75–85% of salary) retirement at close to the monthly salary they were last employed at. For example, if a person joined the University of California retirement system at age 25 and worked for 35 years they could receive 87.5% (2.5% × 35) of their average highest three year salary with full medical coverage at age 60. Police and firemen who joined at 25 and worked for 30 years could receive 90% (3.0% × 30) of their average salary and full medical coverage at age 55. These retirements have cost of living adjustments (COLA) applied each year but are limited to a maximum average income of $350,000/year or less. Spousal survivor benefits are available at 100–67% of the primary benefits rate for 8.7% to 6.7% reduction in retirement benefits, respectively. UCRP retirement and disability plan benefits are funded by contributions from both members and the University (typically 5% of salary each) and by the compounded investment earnings of the accumulated totals. These contributions and earnings are held in a trust fund that is invested. The retirement benefits are much more generous than Social Security but are believed to be actuarially sound. The main difference between state, local government sponsored retirement systems and Social Security is the state and local retirement systems use compounded investments that are usually heavily weighted in the stock market securities which historically have returned more than 7.0%/year on average despite some years with losses. Short term federal government investments may be "more" secure but pay much lower average percentages. Nearly all other federal, state and local retirement systems work in a similar fashion with different benefit retirement ratios. Some plans are now combined with Social Security and are "piggy backed" on top of Social Security benefits. For example, the current Federal Employees Retirement System, which covers the vast majority of federal civil service employees hired after 1986, combines Social Security, a modest defined-benefit pension (1.1% per year of service) and the defined-contribution Thrift Savings Plan.
The current Social Security formula used in calculating the benefit level (primary insurance amount or PIA) is very biased towards lower average salaries. Anyone who worked in OASDI covered employment and other retirement would be entitled to both the alternative non-OASDI pension and an Old Age retirement benefit from Social Security. Because of their limited time working in OASDI covered employment the sum of their covered salaries times inflation factor divided by 420 months yields a low adjusted indexed monthly salary over 35 years, AIME. The low wage bias of the PIA formula would in effect allow these workers to also get a slightly higher Social Security Benefit percentage on this low average salary. Congress passed in 1983 the Windfall Elimination Provision to minimize Social Security benefits for these recipients. The basic provision is that the first salary bracket, $0–791/month (2013) has its normal benefit percentage of 90% reduced to 40–90%—see Social Security for the exact percentage. The reduction is limited to roughly 50% of what you would be eligible for if you had always worked under OASDI taxes. The 90% benefit percentage factor is not reduced if you have 30 or more years of "substantial" earnings.
Social Security should only be the "minimum" retirement that one has as the retirement benefits are relatively small for workers earning even average and higher salaries. The average Social Security payment of $1,230/month ($14,760/year) in 2013 is only slightly above the federal poverty level for one—$11,420/yr and below the poverty guideline of $15,500/yr for two. One "good" supplemental retirement plan option is an employer sponsored 401(K) (or 403(B)) plan when they are offered by an employer. Many employers will match a portion of an employee's savings $1.00 for $1.00 up to some percentage of the employee's salary. Even without employer matches, individual retirement accounts (IRAs) are portable, self-directed, tax deferred retirement accounts that offer the potential to substantially increase retirement savings. Their main limitations are their requirements of self-discipline to allot from an early age the required percentage of salary into "good" investment account(s), and the self–discipline needed to leave it there to earn compound interest until needed after retirement. Long term investment horizons should be used as historically short term investment losses "self correct" and most investments continue to deliver good average investment returns. Living on less than an employee earns and investing the rest over a long period of time is still the "best" retirement plan—compounded earnings steadily accumulate if given enough time. The IRS has tax penalties for withdrawals from IRAs, 401(K)s, etc. before 59½ and require mandatory withdrawals once the retiree reaches 70 and other restrictions on the amount of tax deferred income one can put in the account(s). Self-directed retirement savings plans have the potential to match or even exceed the benefits earned by federal, state and local government retirement plans.
International agreements.
People sometimes relocate from one country to another, either permanently or on a limited-time basis. This presents challenges to businesses, governments, and individuals seeking to ensure future benefits or having to deal with taxation authorities in multiple countries. To that end, the Social Security Administration has signed treaties, often referred to as "Totalization Agreements", with other social insurance programs in various foreign countries.
Overall, these agreements serve two main purposes. First, they eliminate dual Social Security taxation, the situation that occurs when a worker from one country works in another country and is required to pay Social Security taxes to both countries on the same earnings. Second, the agreements help fill gaps in benefit protection for workers who have divided their careers between the United States and another country.
The following countries have signed totalization agreements with the SSA (and the date the agreement became effective):
Social Security number.
A side effect of the Social Security program in the United States has been the near-universal adoption of the program's identification number, the Social Security number, as the "de facto" U.S. national identification number. The social security number, or SSN, is issued pursuant to section 205(c)(2) of the Social Security Act, codified as . The government originally stated that the SSN would not be a means of identification, but currently a multitude of U.S. entities use the Social Security number as a personal identifier. These include government agencies such as the Internal Revenue Service, the military as well as private agencies such as banks, colleges and universities, health insurance companies, and employers.
Although the Social Security Act itself does not require a person to have a Social Security Number (SSN) to live and work in the United States, the Internal Revenue Code does generally require the use of the social security number by individuals for federal tax purposes:
Importantly, most parents apply for Social Security numbers for their dependent children in order to include them on their income tax returns as a dependent. Everyone filing a tax return, as taxpayer or spouse, must have a Social Security Number or Taxpayer Identification Number (TIN) since the IRS is unable to process returns or post payments for anyone without an SSN or TIN.
The Privacy Act of 1974 was in part intended to limit usage of the Social Security number as a means of identification. Paragraph (1) of subsection (a) of section 7 of the Privacy Act, an uncodified provision, states in part:
However, the Social Security Act provides:
Further, paragraph (2) of subsection (a) of section 7 of the Privacy Act provides in part:
The exceptions under section 7 of the Privacy Act include the Internal Revenue Code requirement that social security numbers be used as taxpayer identification numbers for individuals.
Demographic and revenue projections.
In each year since 1982, OASDI tax receipts, interest payments and other income have exceeded benefit payments and other expenditures, for example by more than $150 billion in 2004. As the "baby boomers" move out of the work force and into retirement, however, expenses will come to exceed tax receipts and then, after several more years, will exceed all OASDI trust income, including interest. At that point the system will begin drawing on its trust fund Treasury Notes, and will continue to pay benefits at the current levels until the Trust Fund is exhausted. In 2013, the OASDI retirement insurance fund collected $731.1 billion and spent $645.5 billion; the disability program (DI) collected $109.1 billion and spent $140.3 billion; Medicare (HI) collected $243.0 and spent $266.8 billion and Supplementary Medical Insurance, SMI, collected $293.9 billion and spent $307.4 billion. In 2013 all Social Security programs except the retirement trust fund (OASDI) spent more than they brought in and relied on significant withdrawals from their respective trust funds to pay their bills. The retirement (OASDI) trust fund of $2,541 billion is expected to be emptied by 2033 by one estimate as new retirees become eligible to join. The disability (DI) trust fund's $153.9 billion will be exhausted by 2018; the Medicare (HI) trust fund of $244.2 billion will be exhausted by 2023 and the Supplemental Medical Insurance (SMI) trust fund will be exhausted by 2020 if the present rate of withdrawals continues—even sooner if they increase. The total "Social Security" expenditures in 2013 were $1,360 billion dollars which were 8.4% of the $16,200 billion GNP (2013) and 37.0% of the federal expenditures of $3,684 billion (including a $971.0 billion deficit). All other parts of the Social Security program: medicare (HI), disability (DI) and Supplemental Medical (SMI) trust funds are already drawing down their trust funds and are projected to go into deficit in about 2020 if the present rate of withdrawals continue. As the trust funds are exhausted either benefits will have to be cut, fraud minimized or taxes increased. According to the Center for Economic and Policy Research, upward redistribution of income is responsible for about 43% of the projected Social Security shortfall over the next 75 years.
In 2005, this exhaustion of the OASDI Trust Fund was projected to occur in 2041 by the Social Security Administration or by 2052 by the Congressional Budget Office, CBO. Thereafter, however, the projection for the exhaustion date of this event was moved up slightly after the recession worsened the U.S. economy's financial picture. The 2011 OASDI Trustees Report stated:
Annual cost exceeded non-interest income in 2010 and is projected to continue to be larger throughout the remainder of the 75-year valuation period. Nevertheless, from 2010 through 2022, total trust fund income, including interest income, is more than is necessary to cover costs, so trust fund assets will continue to grow during that time period. Beginning in 2023, trust fund assets will diminish until they become exhausted in 2036. Non-interest income is projected to be sufficient to support expenditures at a level of 77 percent of scheduled benefits after trust fund exhaustion in 2036, and then to decline to 74 percent of scheduled benefits in 2085.
In 2007, the Social Security Trustees suggested that either the payroll tax could increase to 16.41 percent in 2041 and steadily increased to 17.60 percent in 2081 or a cut in benefits by 25 percent in 2041 and steadily increased to an overall cut of 30 percent in 2081.
The Social Security Administration projects that the demographic situation will stabilize. The cash flow deficit in the Social Security system will have leveled off as a share of the economy. This projection has come into question. Some demographers argue that life expectancy will improve more than projected by the Social Security Trustees, a development that would make solvency worse. Some economists believe future productivity growth will be higher than the current projections by the Social Security Trustees. In this case, the Social Security shortfall would be smaller than currently projected.
Tables published by the government's National Center for Health Statistics show that life expectancy at birth was 47.3 years in 1900, rose to 68.2 by 1950 and reached 77.3 in 2002. The latest annual report of the Social Security Agency (SSA) trustees projects that life expectancy will increase just six years in the next seven decades, to 83 in 2075. A separate set of projections, by the Census Bureau, shows more rapid growth. The Census Bureau projection is that the longer life spans projected for 2075 by the Social Security Administration will be reached in 2050. Other experts, however, think that the past gains in life expectancy cannot be repeated, and add that the adverse effect on the system's finances may be partly offset if health improvements or reduced retirement benefits induce people to stay in the workforce longer.
Actuarial science, of the kind used to project the future solvency of social security, is by nature subject to uncertainty. The SSA actually makes three predictions: optimistic, midline, and pessimistic (until the late 1980s it made 4 projections). The Social Security crisis that was developing prior to the 1983 reforms resulted from midline projections that turned out to be too optimistic. It has been argued that the overly pessimistic projections of the mid to late 1990s were partly the result of the low economic growth (according to actuary David Langer) assumptions which resulted in the projected exhaustion date being pushed back (from 2028 to 2042) with each successive Trustee's report. During the heavy-boom years of the 1990s, the midline projections were too pessimistic. Obviously, projecting out 75 years is a significant challenge and, as such, the actual situation might be much better or much worse than predicted.
The Social Security Advisory Board has on three occasions since 1999 appointed a Technical Advisory Panel to review the methods and assumptions used in the annual projections for the Social Security trust funds. The most recent report of the Technical Advisory Panel, released in June 2008 with a copyright date of October 2007, includes a number of recommendations for improving the Social Security projections.
, under current law, the Congressional Budget Office reported that the "Disability Insurance trust fund will be exhausted in fiscal year 2017 and the Old-Age and Survivors Insurance trust fund will be exhausted in 2033".
Increased spending for Social Security will occur at the same time as increases in Medicare, as a result of the aging of the baby boomers. One projection illustrates the relationship between the two programs:
From 2004 to 2030, the combined spending on Social Security and Medicare is expected to rise from 8% of national income (gross domestic product) to 13%. Two-thirds of the increase occurs in Medicare.
Ways to eliminate the projected Social Security shortfall.
Social Security is predicted to start running out of having enough money to pay all prospective retirees at today's benefit payouts by 2033.
Taxation.
Tax on wages and self-employment income.
Benefits are funded by taxes imposed on wages of employees and self-employed persons. As explained below, in the case of employment, the employer and employee are each responsible for one half of the Social Security tax, with the employee's half being withheld from the employee's pay check. In the case of self-employed persons (i.e., independent contractors), the self-employed person is responsible for the entire amount of Social Security tax.
The portion of taxes collected from the employee for Social Security are referred to as "trust fund taxes" and the employer is required to remit them to the government. These taxes take priority over everything, and represent the only debts of a corporation or LLC that can impose personal liability upon its officers or managers. A sole proprietor and officers of a corporation and managers of an LLC can be held personally liable for non-payment of the income tax and social security taxes whether or not actually collected from the employee.
The "Federal Insurance Contributions Act" (FICA) (codified in the Internal Revenue Code) imposes a Social Security withholding tax equal to 6.20% of the gross wage amount, up to but not exceeding the "Social Security Wage Base" ($97,500 for 2007; $102,000 for 2008; and $106,800 for 2009, 2010, and 2011). The same 6.20% tax is imposed on employers. For 2011 and 2012, the employee's contribution was reduced to 4.2%, while the employer's portion remained at 6.2%. In 2012, the wage base increased to $110,100. In 2013, the wage base increased to $113,700. For each calendar year for which the worker is assessed the FICA contribution, the SSA credits those wages as that year's covered wages. The income cutoff is adjusted yearly for inflation and other factors.
A separate payroll tax of 1.45% of an employee's income is paid directly by the employer, and an additional 1.45% deducted from the employee's paycheck, yielding a total tax rate of 2.90%. There is no maximum limit on this portion of the tax. This portion of the tax is used to fund the Medicare program, which is primarily responsible for providing health benefits to retirees.
The Social Security tax rates from 1937–2010 can be accessed on the Social Security Administration's website.
The combined tax rate of these two federal programs is 15.30% (7.65% paid by the employee and 7.65% paid by the employer). In 2011-2012 it temporarily dropped to 13.30% (5.65% paid by the employee and 7.65% paid by the employer).
For self-employed workers (who technically are not employees and are deemed not to be earning "wages" for federal tax purposes), the self-employment tax, imposed by the Self-Employment Contributions Act of 1954, codified as Chapter 2 of Subtitle A of the Internal Revenue Code, , is 15.3% of "net earnings from self-employment." In essence, a self-employed individual pays both the employee and employer share of the tax, although half of the self-employment tax (the "employer share") is deductible when calculating the individual's federal income tax.
If an employee has overpaid payroll taxes by having more than one job or switching jobs during the year, the excess taxes will be refunded when the employee files his federal income tax return. Any excess taxes paid by employers, however, are not refundable to the employers.
Wages not subject to tax.
Workers are not required to pay Social Security taxes on wages from certain types of work:
Federal income taxation of benefits.
Originally the benefits received by retirees were not taxed as income. Beginning in tax year 1984, with the Reagan-era reforms to repair the system's projected insolvency, retirees with incomes over $25,000 (in the case of married persons filing separately who did not live with the spouse at any time during the year, and for persons filing as "single"), or with combined incomes over $32,000 (if married filing jointly) or, in certain cases, any income amount (if married filing separately from the spouse in a year in which the taxpayer lived with the spouse at any time) generally saw part of the retiree benefits subject to federal income tax. In 1984, the portion of the benefits potentially subject to tax was 50%. The Deficit Reduction Act of 1993 set the portion to 85%.
Criticisms.
Claim that it discriminates against the poor and the middle class.
Workers must pay 12.4 percent, including a 6.2 percent employer contribution, on their wages below the Social Security Wage Base ($110,100 in 2012), but no tax on income in excess of this amount. Therefore, high earners pay a lower percentage of their total income because of the income caps; because of this, and the fact there is no tax on unearned income, social security taxes are often viewed as being regressive. However, benefits are adjusted to be significantly more progressive, even when accounting for differences in life expectancy. According to the non-partisan Congressional Budget Office, for people in the bottom fifth of the earnings distribution, the ratio of benefits to taxes is almost three times as high as it is for those in the top fifth.
Despite its regressive "tax formula", Social Security benefits are calculated using a progressive "benefit formula" that replaces a much higher percentage of low-income workers' pre-retirement income than that of higher-income workers (although these low-income workers pay a higher percentage of their pre-retirement income). Supporters of the current system also point to numerous studies that show that, relative to high-income workers, Social Security disability and survivor benefits paid on behalf of low-income workers more than offset any retirement benefits that may be lost because of shorter life expectancy (this offset would only apply at a population level). Other research asserts that survivor benefits, allegedly an offset, actually exacerbate the problem because survivor benefits are denied to single individuals, including widow(er)s married fewer than nine months (except in certain situations), divorced widow(er)s married fewer than 10 years, and co-habiting or same-sex couples, unless they are legally married in their state of residence. Unmarried individuals and minorities tend to be less wealthy.
Social Security's benefit formula provides 90% of average indexed monthly earnings (AIME) below the first "bend point" of $791/month, 32% of AIME between the first and second bend points $791 to $4781/month, and 15% of AIME in excess of the second bend point up to the Ceiling cap of $113,700 in 2013. The low income bias of the benefit calculation means that lower paid worker receives a much higher percentage of his or salary in benefit payments than higher paid workers. Indeed, a married low salaried worker can receive over 100% of their salary in benefits after retiring at the full retirement age. High-salaried workers receive 43% or less of their salary in benefits despite having paid into the "system" at the same rate—(see benefit calculations above.) To minimize the impact of Social Security taxes on low salaried workers the Earned Income Tax Credit" and the Child Care Tax Credit were passed, which largely refund the FICA and or SECA payments of low-salaried workers through the income tax system. By Congressional Budget Office (CBO) calculations the lowest income quintile (0-20%) and second quintile (21-40%) of households in the U.S. pay an average federal income tax of -9.3% and -2.6% of income and Social Security taxes of 8.3% and 7.9% of income respectively. By CBO calculations the household incomes in the first quintile and second quintile have an average total federal tax rate of 1.0% and 3.8% respectively. However, these groups also have by far the smallest percentage of American household incomes – the first quintile earns just 3.2% of all income, while the second quintile earns only 8.4% of all income. Higher-income retirees will have to pay income taxes on 85% of their Social Security benefits and 100% on all other retirement benefits they may have.
Marital status.
The Social Security Act defines the rules for determining marital relationships for SSI recipients. The act requires that if a man and a woman are found to be "holding out"—that is, presenting themselves to the community as husband and wife—they should be considered married for purposes of the SSI program. Consequently, if the claimant is found disabled and found to be "holding out"; this claimant will be entitled of reduced or no SSI benefits. However, the Social Security Act does not accept that a claimant "holding out as husband or wife" should be entitled of Survivor, Retirement or Widows benefits, when the claimant's "husband or wife" dies. SSA rules and regulations about marital status either prohibit (SRDI program) or reduce (SSI program) benefits to indigent claimants.
Claim that politicians exempted themselves from the tax.
Critics of Social Security have said that the politicians who created Social Security exempted themselves from having to pay the Social Security tax. When the federal government created Social Security, all federal employees, including the president and members of Congress, were exempt from having to pay the Social Security tax, and they received no Social Security benefits. This law was changed by the Social Security Amendments of 1983, which brought within the Social Security system all members of Congress, the president and the vice president, federal judges, and certain executive-level political appointees, as well as all federal employees hired in any capacity on or after January 1, 1984. Many state and local government workers, however, are exempt from Social Security taxes because they contribute instead to alternative retirement systems set up by their employers.
Claim that the government lied about the maximum tax.
George Mason University economics professor Walter E. Williams claimed that the federal government has broken its own promise regarding the maximum Social Security tax. Williams used data from the federal government to back up his claim.
According to a 1936 pamphlet on the Social Security website, the federal government promised the following maximum level of taxation for Social Security, "... beginning in 1949, twelve years from now, you and your employer will each pay 3 cents on each dollar you earn, up to $3,000 a year. That is the most you will ever pay."
However, according to the Social Security website, by the year 2008, the tax rate was 6.2% each for the employer and employee, and the maximum income level that was subject to the tax was $102,000 raising the bar to $6,324 maximum contribution by both employee and employer (total $12,648).
In 2005, Dr. Williams wrote, "Had Congress lived up to those promises, where $3,000 was the maximum earnings subject to Social Security tax, controlling for inflation, today's $50,000-a-year wage earner would pay about $700 in Social Security taxes, as opposed to the more than $3,000 that he pays today."
According to the Social Security website, "The tax rate in the original 1935 law was 1% each on the employer and the employee, on the first $3,000 of earnings. This rate was increased on a regular schedule in four steps so that by 1949 the rate would be 3% each on the first $3,000. The figure was never $1,400, and the rate was never fixed for all time at 1%."
Claim that it gives a low rate of return.
Critics of Social Security claim that it gives a low rate of return, compared to what is obtained through private retirement accounts. For example, critics point out that under the Social Security laws as they existed at that time, several thousand employees of Galveston County, Texas were allowed to opt out of the Social Security program in the early 1980s, and have their money placed in a private retirement plan instead. While employees who earned $50,000 per year would have collected $1,302 per month in Social Security benefits, the private plan paid them $6,843 per month. While employees who earned $20,000 per year would have collected $775 per month in Social Security benefits, the private plan paid them $2,740 per month, at interest rates prevailing in 1996. While some advocates of privatization of Social Security point to the Galveston pension plan as a model for Social Security reform, critics point to a GAO report to the House Ways and Means Committee, which indicates that, for low and middle income employees, particularly those with shorter work histories, the outcome may be less favorable.
This claim also discounts the fact that investment in private markets is not risk-free and private investments can and often do lose value. A person whose investments fail for whatever reason may lose everything they invest and enter their retirement years penniless. Therefore, advocates argue, Social Security plays an important role by providing every American worker a guaranteed minimum level of retirement income that cannot be lost to market fluctuations, disappear through business failures or be stolen by fraudulent investment schemes.
Claim that it is a Ponzi scheme.
Critics have drawn parallels between Social Security and Ponzi schemes, e.g.:
One criticism of the analogy is that while Ponzi schemes and Social Security have similar "structures" (in particular, a sustainability problem when the number of new people paying in is declining), they have different "transparencies". In the case of a Ponzi scheme, the fact that there is no return-generating mechanism other than contributions from new entrants is obscured whereas Social Security payouts have always been openly underwritten by incoming tax revenue and the interest on the Treasury bonds held by or for the Social Security system. The sudden loss of confidence resulting in a collapse of a conventional Ponzi scheme when the scheme's true nature is revealed is unlikely to occur in the case of the Social Security system. Private sector Ponzi schemes are also vulnerable to collapse because they cannot compel new entrants, whereas participation in the Social Security program is a condition for joining the U.S. labor force. In connection with these and other issues, Robert E. Wright calls Social Security a "quasi" pyramid scheme in his book, "Fubarnomics".
Estimated net Social Security benefits under differing circumstances.
In 2004, Urban Institute economists C. Eugene Steuerle and Adam Carasso created a Web-based Social Security benefits calculator. Using this calculator it is possible to estimate net Social Security benefits (i.e., estimated lifetime benefits minus estimated lifetime FICA taxes paid) for different types of recipients. In the book "Democrats and Republicans – Rhetoric and Reality" Joseph Fried used the calculator to create graphical depictions of the estimated net benefits of men and women who were at different wage levels, single and married (with stay-at-home spouses), and retiring in different years. These graphs vividly show that generalizations about Social Security benefits may be of little predictive value for any given worker, due to the wide disparity of net benefits for people at different income levels and in different demographic groups. For example, the graph below (Figure 168) shows the impact of wage level and retirement date on a male worker. As income goes up, net benefits get smaller – even negative.
, the impact is much greater for the future retiree (in 2045) than for the current retiree (2005). The male earning $95,000 per year and retiring in 2045 is estimated to lose over $200,000 by participating in the Social Security system.
In the next graph (Figure 165) the depicted net benefits are averaged for people turning age 65 anytime during the years 2005 through 2045. (In other words, the disparities shown are not related to retirement.) However, we do see the impact of gender and wage level. Because women tend to live longer, they generally collect Social Security benefits for a longer time. As a result, they get a higher net benefit, on average, no matter what the wage level.
Two significant factors are evident: First, every column in Figure 166 depicts a net benefit that is higher than any column in Figure 165. In other words, the average married person (with a stay-at-home spouse) gets a greater benefit per FICA tax dollar paid than does the average single person – no matter what the gender or wage level. Second, there is only limited progressivity among married workers with stay-at-home spouses. Review Figure 166 carefully: The net benefits drop as the wage levels increase from $50,000 to $95,000; however, they increase as the wage levels grow from $5,000 to $50,000. In fact, net benefits are lowest for those earning just $5,000 per year.
The last graph shown (Figure 167) is a combination of Figures 165 and 166. In this graph it is very clear why generalizations about the value of Social Security benefits are meaningless. At the $95,000 wage level a married person could be a big winner – getting net benefits of about $165,000. On the other hand, he could lose an estimated $152,000 in net benefits if he remains single. Altogether, there is a "swing" of over $300,000 based upon the marriage decision (and the division of earnings between the spouses). In addition there is a large disparity between the high net benefits of the married person earning $95,000 ($165,152) versus the relatively low net benefits of the man or woman earning just $5,000 ($30,025 or $41,890, depending on gender). In other words, the high earner, in this scenario, gets a far greater return on his FICA tax investment than does the low earner.
In the book "How Social Security Picks Your Pocket" other factors affecting Social Security net benefits are identified: Generally, people who work for more than 35 years get a lower net benefit – all other factors being equal. People who do not live long after retirement age get a much lower net benefit. Finally, people who derive a high percentage of income from non-wage sources get high Social Security net benefits because they appear to be poor, when they are not. The progressive benefit formula for Social Security is blind to the income a worker may have from non-wage sources, such as spousal support, dividends and interest, or rental income.
Current controversies.
Proposals to reform of the Social Security system have led to heated debate, centering on funding of the program. In particular, proposals to "privatize" funding have caused great controversy.
Contrast with private pensions.
Although Social Security is sometimes compared to private pensions, the two systems are different in a number of respects. It has been argued that Social Security is an insurance plan as opposed to a retirement plan. Unlike a pension, for example, Social Security pays disability benefits. A private pension fund accumulates the money paid into it, eventually using those reserves to pay pensions to the workers who contributed to the fund; and a private system is not universal. Social Security cannot "prefund" by investing in marketable assets such as equities, because federal law prohibits it from investing in assets other than those backed by the U.S. government. As a result, its investments to date have been limited to special non-negotiable securities issued by the U.S. Treasury, although some argue that debt issued by the Federal National Mortgage Association and other quasi-governmental organizations could meet legal standards. Social Security cannot by law invest in private equities, although some other countries (such as Canada) and some states permit their pension funds to invest in private equities. As a universal system, Social Security generally operates as a pipeline, through which current tax receipts from workers are used to pay current benefits to retirees, survivors, and the disabled. When there is an excess of taxes withheld over benefits paid, by law this excess is invested in Treasury securities (not in private equities) as described above.
Two broad categories of private pension plans are "defined benefit pension plans" and "defined contribution pension plans." Of these two, Social Security is more similar to a defined benefit pension plan. In a defined benefit pension plan, the benefits ultimately received are based on some sort of pre-determined formula (such as one based on years worked and highest salary earned). Defined benefit pension plans generally do not include separate accounts for each participant. By contrast, in a defined contribution pension plan each participant has a specific account with funds put into that account (by the employer or the participant, or both), and the ultimate benefit is based on the amount in that account at the time of retirement. Some have proposed that the Social Security system be modified to provide for the option of individual accounts (in effect, to make the system, at least in part, more like a defined contribution pension plan). Specifically, on February 2, 2005, President George W. Bush made Social Security a prominent theme of his State of the Union Address. He described the Social Security system as "headed for bankruptcy", and outlined, in general terms, a proposal based on partial privatization. Critics responded that privatization would require huge new government borrowing to fund benefit payments during the transition years. See Social Security debate (United States).
Both "defined benefit" and "defined contribution" private pension plans are governed by the Employee Retirement Income Security Act (ERISA), which requires employers to provide minimum levels of funding to support "defined benefits" pensions. The purpose is to protect the workers from corporate mismanagement and outright bankruptcy, although in practice many private pension funds have fallen short in recent years. In terms of financial structure, the current Social Security system is analogous to an underfunded "defined benefit" pension ("underfunded" meaning not that it is in trouble, but that its savings are not enough to pay future benefits without collecting future tax revenues).
Contrast with insurance.
Besides the argument over whether the returns on Social Security contributions should or can be compared to returns on private investment instruments, there is the question of whether the contributions are nonetheless analogous to pooled insurance premiums charged by for-profit commercial insurance companies to maintain and generate a return on a "risk pool of funds". Like any insurance program, Social Security "spreads risk" as the program protects workers and covered family members against loss of income from the wage earner's retirement, disability, or death. For example, a worker who becomes disabled at a young age could receive a large return relative to the amount they contributed in FICA before becoming disabled, since disability benefits can continue for life. As in private insurance plans, everyone in the particular insurance pool is insured against the same risks, but not everyone will benefit to the same extent.
The analogy to insurance, however, is limited"See also:" Theda Skocpol, Social Policy in the United States: Future Possibilities in Historical Perspective, (Princeton University Press: 1995) p. 162: "The ideology that Altmeyer and other Social Security administrators fashioned for the old-age security system was individualistic and based on a (technically quite false) analogy to private savings or insurance."</ref> by the fact that paying FICA taxes creates no legal right to benefits and by the extent to which Social Security is, in fact, funded by FICA taxes. During 2011 and 2012, for example, FICA tax revenue was insufficient to maintain Social Security's solvency without transfers from general revenues. These transfers added to the general budget deficit like general program spending.
Private retirement savings crisis.
While inflation-adjusted stock market values generally rose from 1978 to 1997, from 1998 through 2007 they were higher than in March 2013. This has caused workers' supplemental retirement plans such as 401(k)s to perform substantially more poorly than expected when current retirees were investing the bulk of their savings in them. In 2010, the median household retirement account balance for workers aged 55 to 64 was $120,000, which will provide only a trivial supplement to Social Security benefits, but about a third of households had no retirement savings at all. 75% of Americans nearing retirement age had less than $30,000 in their retirement accounts, which "Forbes" called "the greatest retirement crisis in American history."
Court interpretation of the Act to provide benefits.
The United States Court of Appeals for the Seventh Circuit has indicated that the Social Security Act has a moral purpose and should be liberally interpreted in favor of claimants when deciding what counted as covered wages for purposes of meeting the quarters of coverage requirement to make a worker eligible for benefits. That court has also stated: ". . . he regulations should be liberally applied in favor of beneficiaries" when deciding a case in favor of a felon who had his disability payments retroactively terminated upon incarceration. According to the court, that the Social Security Act "should be liberally construed in favor of those seeking its benefits can not be doubted." "The hope behind this statute is to save men and women from the rigors of the poor house as well as from the haunting fear that such a lot awaits them when journey's end is near."
Constitutionality.
The constitutionality of Social Security is intricately linked to the evolving nature of Supreme Court jurisprudence on federal power (the 20th century saw a dramatic increase in allowed congressional action). When Social Security was first passed, there were significant questions over its constitutionality as the Court had found another pension scheme, the original Railroad Retirement Act, to violate the due process clause of the Fifth Amendment. Some, such as University of Chicago law professor Richard Epstein and Harvard University professor Robert Nozick, have argued that Social Security should be unconstitutional.
In the 1937 U.S. Supreme Court case of "Helvering v. Davis", the Court examined the constitutionality of Social Security when George Davis of the Edison Electric Illuminating Company of Boston sued in connection with the Social Security tax. The U.S. District Court for the District of Massachusetts first upheld the tax. The District Court judgment was reversed by the Circuit Court of Appeals. Commissioner Guy Helvering of the Bureau of Internal Revenue (now the Internal Revenue Service) took the case to the Supreme Court, and the Court upheld the validity of the tax.
During the 1930s President Franklin Delano Roosevelt was in the midst of promoting the passage of a large number of social welfare programs under the New Deal and the High Court struck down many of those programs (such as the Railroad Retirement Act and the National Recovery Act) as unconstitutional. Modified versions of the affected programs were afterwards approved by the Court, including Social Security.
When "Helvering v. Davis" was argued before the Court, the larger issue of constitutionality of the old-age insurance portion of Social Security was not decided. The case was limited to whether the payroll tax was a suitable use of Congress's taxing power. Despite this, no serious challenges regarding the system's constitutionality are now being litigated, and Congress's spending power may be more coextensive, as shown in cases like "South Dakota v. Dole" during the Reagan Administration.
Payments to former Nazis.
In June 2015, the Associated Press revealed that the US government had given US$20 million to former Nazis in Social Security payments between February 1962 and January 2015.
Fraud and abuse.
Social security number theft.
Because Social Security Numbers have become useful in identity theft and other forms of crime, various schemes have been perpetrated to acquire valid Social Security Numbers and related identity information.
In February 2006, the Social Security Administration received several reports of an email message being circulated addressed to "Dear Social Security Number And Card owner" and purporting to be from the Social Security Administration. The message informs the reader "that someone illegally is using your Social Security number and assuming your identity" and directs the reader to a website designed to look like Social Security's Internet website.
"I am outraged that someone would target an unsuspecting public in this manner," said Commissioner Jo Anne B. Barnhart. "I have asked the Inspector General to use all the resources at his command to find and prosecute whoever is perpetrating this fraud."
Once directed to the phony website, the individual is reportedly asked to confirm his or her identity with "Social Security and bank information." Specific information about the individual's credit card number, expiration date and PIN is then requested. "Whether on our online website or by phone, Social Security will never ask you for your credit card information or your PIN," Commissioner Jo Anne B. Barnhart reported.
Social Security Administration Inspector General O'Carroll recommended people always take precautions when giving out personal information. "You should never provide your Social Security number or other personal information over the Internet or by telephone unless you are extremely confident of the source to whom you are providing the information," O'Carroll said. See Press Release.
Fraud in the acquisition and use of benefits.
Given the vast size of the program, fraud occurs. The Social Security Administration has its own investigatory group, Continuing Disability Investigations (CDI). In addition, the Social Security Administration may request investigatory assistance from other federal law enforcement agencies including the Office of the Inspector General and the FBI.
Restrictions on potentially deceptive communications.
Because of the importance of Social Security to millions of Americans, many direct-mail marketers packaged their mailings to resemble official communications from the Social Security Administration, hoping that recipients would be more likely to open them. In response, Congress amended the Social Security Act in 1988 to prohibit the private use of the phrase "Social Security" and several related terms in any way that would convey a false impression of approval from the Social Security Administration. The constitutionality of this law () was upheld in "United Seniors Association, Inc. v. Social Security Administration", 423 F.3d 397 (4th Cir. 2005), cert den 547 U.S. 1162; 126 S.Ct. 2346 (2006) (text at Findlaw).
Public economics.
Current recipients.
The 2011 annual report by the program's Board of Trustees noted the following: in 2010, 54 million people were receiving Social Security benefits, while 157 million people were paying into the fund; of those receiving benefits, 44 million were receiving retirement benefits and 10 million disability benefits. In 2011, there will be 56 million beneficiaries and 158 million workers paying in. In 2010, total income was $781.1 billion and expenditures were $712.5 billion, which meant a total net increase in assets of $68.6 billion. Assets in 2010 were $2.6 trillion, an amount that is expected to be adequate to cover the next 10 years. In 2023, total income and interest earned on assets are projected to no longer cover expenditures for Social Security, as demographic shifts burden the system. By 2035, the ratio of potential retirees to working age persons will be 37 percent — there will be less than three potential income earners for every retiree in the population. At this rate the Social Security Trust Fund would be exhausted by 2036.
Saving behavior.
Social Security affects the saving behavior of the people in three different ways. The wealth substitution effect occurs when a person saving for retirement recognizes that the Social Security system will take care of him and decreases his expectations about how much he needs to personally save. The retirement effect occurs when a taxpayer saves more each year in an effort to reduce the total number of years he must work to accumulate enough savings before retirement. The bequest effect occurs when a taxpayer recognizes a decrease in resources stemming from the Social Security tax and compensates by increasing personal savings to cover future expected costs of having children.
Reducing cost of living adjustment (COLA).
At present, a retiree's benefit is annually adjusted for inflation to reflect changes in the consumer price index. Some economists argue that the consumer price index overestimates price increases in the economy and therefore is not a suitable metric for adjusting benefits, while others argue that the CPI underestimates the effect of inflation on what retired people actually need to buy to live.
The current cost of living adjustment is based on the consumer price index for Urban Wage Earners and Clerical Workers (CPI-W). The Bureau of Labor Statistics routinely checks the prices of 211 different categories of consumption items in 38 geographical areas to compute 8,018 item-area indices. Many other indices are computed as weighted averages of these base indices. CPI-W is based on a market basket of goods and services consumed by urban wage earners and clerical workers. The weights for that index are updated in January of every even-numbered year. People who say that the CPI-W overestimates inflation recommend updating the weights each month; this produces the Chained Consumer Price Index for all urban consumers (C-CPI-U). People who say that the C-CPI-U the unchained CPI for All Urban Consumers (CPI-U) disadvantages the elderly point out that seniors consume more medical care than younger people, and that the costs of medical care have been rising faster than inflation in other parts of the economy. According to this view, the costs of the things the elderly buy have been rising faster than the market basket averaged to obtain CPI-W, CPI-U or C-CPI-U. Some have recommended fixing this by using a CPI for the Elderly (CPI-E).
In 2003 economics researchers Hobijn and Lagakos estimated that the social security trust fund would run out of money in 40 years using CPI-W and in 35 years using CPI-E.
References.
Works referenced

</doc>
<doc id="48732" url="https://en.wikipedia.org/wiki?curid=48732" title="Pyramid scheme">
Pyramid scheme

A pyramid scheme is a business model that recruits members via a promise of payments or services for enrolling others into the scheme, rather than supplying investments or sale of products or services. As recruiting multiplies, recruiting becomes quickly impossible, and most members are unable to profit; as such, pyramid schemes are unsustainable and often illegal.
Pyramid schemes have existed for at least a century in different guises. Some multilevel marketing plans have been classified as pyramid schemes.
Concept and basic models.
In a pyramid scheme an organization compels individuals to join and make a payment. In exchange, the organization promises its new members a share of the money taken from every additional member that they recruit. The directors of the organization (those at the top of the pyramid) also receive a share of these payments. For the directors, the scheme is potentially lucrative—whether or not they do any work, the organization's membership has a strong incentive to continue recruiting and funneling money to the top of the pyramid.
Such organizations seldom involve sales of products or services with value. Without creating any goods or services, the only ways for a pyramid scheme to generate revenue are to recruit more members or solicit more money from current members. Eventually, recruiting is no longer possible and most members are unable to profit from the scheme.
The "eightball" model.
Many pyramids are more sophisticated than the simple model. These recognize that recruiting a large number of others into a scheme can be difficult so a seemingly simpler model is used. In this model each person must recruit two others, but the ease of achieving this is offset because the depth required to recoup any money also increases. The scheme requires a person to recruit two others, who must each recruit two others, who must each recruit two others.
Prior instances of this scheme have been called the "Airplane Game" and the four tiers labelled as "captain", "co-pilot", "crew", and "passenger" to denote a person's level. Another instance was called the "Original Dinner Party" which labeled the tiers as "dessert", "main course", "side salad", and "appetizer". A person on the "dessert" course is the one at the top of the tree. Another variant, "Treasure Traders", variously used gemology terms such as "polishers", "stone cutters", etc.
Such schemes may try to downplay their pyramid nature by referring to themselves as "gifting circles" with money being "gifted". Popular schemes such as "Women Empowering Women" do exactly this.
Whichever euphemism is used, there are 15 total people in four tiers (1 + 2 + 4 + 8) in the scheme—with the Airplane Game as the example, the person at the top of this tree is the "captain", the two below are "co-pilots", the four below are "crew," and the bottom eight joiners are the "passengers".
The eight passengers must each pay (or "gift") a sum (e.g., $5,000) to join the scheme. This sum (e.g., $40,000) goes to the captain who leaves, with everyone remaining moving up one tier. There are now two new captains so the group splits in two with each group requiring eight new passengers. A person who joins the scheme as a passenger will not see a return until they advance through the crew and co-pilot tiers and exit the scheme as a captain. Therefore, the participants in the bottom three tiers of the pyramid lose their money if the scheme collapses.
If a person is using this model as a scam, the confidence trickster would take the majority of the money. They would do this by filling in the first three tiers (with one, two, and four people) with phony names, ensuring they get the first seven payouts, at eight times the buy-in sum, without paying a single penny themselves. So if the buy-in were $5,000, they would receive $40,000, paid for by the first eight investors. They would continue to buy in underneath the real investors, and promote and prolong the scheme for as long as possible to allow them to skim even more from it before it collapses.
Although the "captain" is the person at the top of the tree, having received the payment from the eight paying passengers, once they leave the scheme they are able to re-enter the pyramid as a "passenger" and hopefully recruit enough to reach captain again, thereby earning a second payout.
Matrix schemes.
Matrix schemes use the same fraudulent non-sustainable system as a pyramid; here, the participants pay to join a waiting list for a desirable product, which only a fraction of them can ever receive. Since matrix schemes follow the same laws of geometric progression as pyramids, they are subsequently as doomed to collapse. Such schemes operate as a queue, where the person at head of the queue receives an item such as a television, games console, digital camcorder, etc. when a certain number of new people join the end of the queue. For example, ten joiners may be required for the person at the front to receive their item and leave the queue. Each joiner is required to buy an expensive but potentially worthless item, such as an e-book, for their position in the queue. The scheme organizer profits because the income from joiners far exceeds the cost of sending out the item to the person at the front. Organizers can further profit by starting a scheme with a queue with "shill" names that must be cleared out before genuine people get to the front. The scheme collapses when no more people are willing to join the queue. Schemes may not reveal, or may attempt to exaggerate, a prospective joiner's queue position, a condition that essentially means the scheme is a lottery. Some countries have ruled that matrix schemes are illegal on that basis.
Connection to multi-level marketing.
Some multi-level marketing (MLM) companies operate as pyramid schemes, and consumers often confuse legitimate multi-level marketing with pyramid schemes.
According to the U.S. Federal Trade Commission legitimate MLM, unlike pyramid schemes -
Pyramid schemes however "may purport to sell a product, but they often simply use the product to hide their pyramid structure". While some people call MLMs in general "pyramid selling" others use the term to denote an illegal pyramid scheme masquerading as an MLM.
The Federal Trade Commission warns, "It’s best not to get involved in plans where the money you make is based primarily on the number of distributors you recruit and your sales to them, rather than on your sales to people outside the plan who intend to use the products." It states that research is your best tool and gives eight steps to follow:
Some commentators contend that MLMs in general are nothing more than legalized pyramid schemes.
Legality.
Pyramid schemes are illegal in many countries or regions including Albania, Australia, Austria, Belgium, Brazil, Canada, China, Colombia, Denmark, the Dominican Republic, Estonia, France, Germany, Hong Kong, Hungary, Iceland, Iran, Ireland, Italy, Japan, Malaysia, Maldives, Mexico, Nepal, the Netherlands, New Zealand, Norway, the Philippines, Poland, Portugal, Romania, Russian Federation, Serbia, South Africa, Spain, Sri Lanka, Sweden, Switzerland, Taiwan, Thailand, Turkey, Ukraine, the United Kingdom, and the United States.
Franchise fraud is defined by the United States Federal Bureau of Investigation as a pyramid scheme. The FBI website states:
Pyramid schemes—also referred to as franchise fraud or chain referral schemes—are marketing and investment frauds in which an individual is offered a distributorship or franchise to market a particular product. The real profit is earned, not by the sale of the product, but by the sale of new distributorships. Emphasis on selling franchises rather than the product eventually leads to a point where the supply of potential investors is exhausted and the pyramid collapses.
Notable recent cases.
The 1997 rebellion in Albania was partially motivated by the collapse of Ponzi schemes; however, they were widely referred to as pyramid schemes due to their prevalence in Albanian society.
In 2003, the United States Federal Trade Commission (FTC) disclosed what it called an Internet-based "pyramid scam." Its complaint states that customers would pay a registration fee to join a program that called itself an "internet mall" and purchase a package of goods and services such as internet mail, and that the company offered "significant commissions" to consumers who purchased and resold the package. The FTC alleged that the company's program was instead and in reality a pyramid scheme that did not disclose that most consumers' money would be kept, and that it gave affiliates material that allowed them to scam others.
WinCapita was a scheme run by Finnish criminals that involved about €100 million. The scheme started in 2005.
In early 2006, Ireland was hit by a wave of schemes with major activity in Cork and Galway. Participants were asked to contribute €20,000 each to a "Liberty" scheme which followed the classic eight-ball model. Payments were made in Munich, Germany to skirt Irish tax laws concerning gifts. Spin-off schemes called "Speedball" and "People in Profit" prompted a number of violent incidents and calls were made by politicians to tighten existing legislation. Ireland has launched a website to better educate consumers to pyramid schemes and other scams.
On 12 November 2008, riots broke out in the municipalities of Pasto, Tumaco, Popayan and Santander de Quilichao, Colombia after the collapse of several pyramid schemes. Thousands of victims had invested their money in pyramids that promised them extraordinary interest rates. The lack of regulation laws allowed those pyramids to grow excessively during several years. Finally, after the riots, the Colombian government was forced to declare the country in a state of economic emergency to seize and stop those schemes. Several of the pyramid's managers were arrested, and are being prosecuted for the crime of "illegal massive money reception."
The "Kyiv Post" reported on 26 November 2008 that American citizen Robert Fletcher (Robert T. Fletcher III; aka "Rob") was arrested by the SBU (Ukraine State Police) after being accused by Ukrainian investors of running a Ponzi scheme and associated pyramid scam netting US$20 million. (The "Kiev Post" also reports that some estimates are as high as US$150M.)
In the United Kingdom in 2008 and 2009, a £21 million pyramid scheme named 'Give and Take' involved at least 10,000 victims in the south-west of England and South Wales. Leaders of the scheme were prosecuted and served time in jail before being ordered to pay £500,000 in compensation and costs in 2015. The cost of bringing the prosecution was in excess of £1.4 million.
Throughout 2010 and 2011 a number of authorities around the world including the Australian Competition and Consumer Commission, the Bank of Namibia and the Central Bank of Lesotho have declared TVI Express to be a pyramid scheme. TVI Express, operated by Tarun Trikha from India has apparently recruited hundreds of thousands of "investors", very few of whom, it is reported, have recouped any of their investment. In 2013, Tarun Trikha was arrested at the IGI Airport in New Delhi.
BurnLounge, Inc. was a multi-level marketing online music store founded in 2004 and based in New York City. By 2006 the company reported 30,000 members using the site to sell music through its network. In 2007 the company was sued by the Federal Trade Commission for being an illegal pyramid scheme. The company lost the suit in 2012, and lost appeal in June 2014. In June 2015, the FTC began returning $1.9 million to people who had lost money in the scheme.

</doc>
<doc id="48733" url="https://en.wikipedia.org/wiki?curid=48733" title="Ragnar Lodbrok">
Ragnar Lodbrok

Ragnar Lodbrok or Lothbrok (, "Ragnar Shaggy-Breeches") was a legendary Viking ruler, king, and hero from the Viking Age described in Old Norse poetry and several sagas. In this tradition, Ragnar was the scourge of France and England in the 9th century and the father of many renowned sons, including Ivar the Boneless, Björn Ironside, Halfdan Ragnarsson, Sigurd Snake-in-the-Eye, and Ubba. While these men are historical figures, it is uncertain whether Ragnar himself existed or really fathered them. Many of the tales about him appear to conflate the deeds of several historical Viking heroes and rulers.
According to legend, Ragnar was married three times: to the shieldmaiden Lagertha, to the noblewoman Þóra Borgarhjǫrtr, and to Aslaug. Said to have been a relative of the Danish king Gudfred and son of the Swedish king Sigurd Hring, he became king himself and distinguished himself by many raids and conquests. There are two different accounts of his death. One is that he was seized by his foe, King Ælla of Northumbria, and killed by being thrown into a pit of snakes. His sons bloodily avenged him by invading England with the Great Heathen Army. The other was that Ragnar died from a combination of cholera and wounds he sustained from trying to invade Paris.
Historicity.
As a figure of legend whose life only partially took place in times and places covered by written sources, the extent of Ragnar's historicity is not quite clear.
In her commentary on Saxo's "Gesta Danorum", Hilda Ellis Davidson notes that Saxo's coverage of Ragnar's legend in book IX of the "Gesta" appears to be an attempt to consolidate many of the confusing and contradictory events and stories known to the chronicler into the reign of one king, Ragnar. That is why many acts ascribed to Ragnar in the "Gesta" can be associated, through other sources, with various figures, some of which are more historically certain. These candidates for the "historical Ragnar" include:
So far, attempts to firmly link the legendary Ragnar with one or several of those men have failed because of the difficulty in reconciling the various accounts and their chronology. Nonetheless, the core tradition of a Viking hero named Ragnar (or similar) who wreaked havoc in mid-ninth-century Europe and who fathered many famous sons is remarkably persistent, and some aspects of it are covered by relatively reliable sources, such as the "Anglo-Saxon Chronicle". According to Davidson, writing in 1979, "certain scholars in recent years have come to accept at least part of Ragnar's story as based on historical fact". Katherine Holman, on the other hand, concludes that "although his sons are historical figures, there is no evidence that Ragnar himself ever lived, and he seems to be an amalgam of several different historical figures and pure literary invention."
Sources.
The medieval sources that cover Ragnar include:

</doc>
<doc id="48738" url="https://en.wikipedia.org/wiki?curid=48738" title="Revolution of 1905">
Revolution of 1905

The Revolution of 1905 was a wave of mass political and social unrest that spread through vast areas of the Russian Empire, some of which was directed at the government. It included worker strikes, peasant unrest, and military mutinies. It led to Constitutional Reform including the establishment of the State Duma (Russian Empire), the multi-party system, and the Russian Constitution of 1906.
Causes.
According to Sidney Harcave, author of "The Russian Revolution of 1905", four problems in Russian society contributed to the revolution. Newly emancipated peasants earned too little, and were not allowed to sell or mortgage their allotted land. Ethnic minorities resented the government because of its "Russification", discrimination and repression, both social and formal, such as banning them from voting and serving in the Guard or Navy and limited attendance in schools. A nascent industrial working class resented the government for doing too little to protect them, banning strikes and labor unions. Finally, the educated class fomented and spread radical ideas after a relaxing of discipline in universities allowed a new consciousness to grow among students.
Taken individually, these issues may not have affected the course of Russian history, but together they created the conditions for a potential revolution. "At the turn of the century, discontent with the Tsar’s dictatorship was manifested not only through the growth of political parties dedicated to the overthrow of the monarchy but also through industrial strikes for better wages and working conditions, protests and riots among peasants, university demonstrations, and the assassination of government officials, often done by Socialist Revolutionaries."
The government finally recognized these problems, albeit in a shortsighted and narrow-minded way. The minister of interior Plehve stated in 1903 that, after the agrarian problem, the most serious ones plaguing the country were those of the Jews, the schools, and the workers, in that order. Because the Russian economy was tied to European finances, the Western money markets contraction in 1899–1900 plunged Russian industry into a deep and prolonged crisis which outlasted the dip in European industrial production. This setback aggravated social unrest during the five years preceding the revolution of 1905.
Agrarian problem.
Every year, thousands of nobles in debt mortgaged their estates to the noble land bank or sold them to municipalities, merchants, or peasants. By the time of the revolution, the nobility had sold off one-third of its land and mortgaged another third. The government hoped to make peasants—recently emancipated from serfdom—a politically conservative, land-holding class by enacting laws to enable them to buy land from nobility and pay small installments over many decades.
The land, known as "allotment land", would not be owned by individual peasants, but by the community of peasants; individual peasants would have rights to strips of land that were assigned to them under the open field system. Unfortunately, a peasant could not sell or mortgage his land, so in practice he could not renounce his rights to his land and thus he would be required to pay his share of redemption dues to the village commune. This plan was meant to prevent proletarianisation of the peasants. However, the peasants were not given enough land to provide for their needs. "Their earnings were often so small that they could neither buy the food they needed nor keep up the payment of taxes and redemption dues they owed the government for their land allotments. By the tenth year of Nicholas II's reign, their total arrears in payments of taxes and dues was 118 million rubles." The situation became worse. Masses of hungry peasants roamed the countryside looking for work and sometimes walked hundreds of miles to find it. Desperate peasants proved capable of violence. "In the provinces of Kharkov and Poltava in 1902, thousands of them, ignoring restraints and authority, burst out in a rebellious fury that led to extensive destruction of property and looting of noble homes before troops could be brought to subdue and punish them."
These violent outbreaks caught the attention of the government, so it created many committees to investigate their causes. The committees concluded that no part of the countryside was prosperous; some parts, especially the fertile areas known as "black-soil region", were in decline. Although cultivated acreage had increased in the last half century, the increase had not been proportionate to the growth of peasant populations, which had doubled. "There was general agreement at the turn of the century that Russia faced a grave and intensifying agrarian crisis due mainly to rural overpopulation with an annual excess of fifteen to eighteen live births over deaths per 1,000 inhabitants." The investigations revealed many difficulties but could not find solution that were both sensible and "acceptable" to the government.
Nationality problem.
Russia was a multi-ethnic empire. Nineteenth-century Russians saw cultures and religions in a clear hierarchy. Non-Russian cultures were tolerated in the empire but were not necessarily respected. "European civilization was valued over Asian or African culture, and Christianity was on the whole considered more progressive and 'true' than other religions."
For generations, Russian Jews had been considered a special problem. "The official view had come to be that they were enemies of Christianity, exploiters of the peasantry, and the fountain head of the revolutionary movement." Like other minorities in Russia, the Jews lived in "miserable and circumscribed lives, forbidden to settle or acquire land outside the cities and towns, legally limited in attendance at secondary school and higher schools, virtually barred from legal professions, denied the right to vote for municipal councilors, and excluded from services in the Navy or the Guards."
The government's treatment of Jews, although considered its own issue, was similar to the government's policies in dealing with all national and religious minorities. "Russian administrators, who never succeeded in coming up with a legal definition of "Pole", despite the decades of restrictions on that ethnic group, regularly spoke of individuals 'of Polish descent' or, alternatively, 'of Russian descent,' making identity a function of birth." This policy only succeeded in producing or aggravating feelings of disloyalty. There was growing impatience with their inferior status and resentment against "Russification". Russification is cultural assimilation definable as "a process culminating in the disappearance of a given group as a recognisably distinct element within a larger society." 
Besides the imposition of a uniform Russian culture throughout the empire, the government's pursuit of Russification, especially during the second half of the nineteenth century, had political motives. After the emancipation of the serfs in 1861, the Russian state was compelled to take into account public opinion, but the government failed to gain the public's support. Another motive for Russification policies was the Polish uprising of 1863. Unlike other minority nationalities, the Poles, in the eyes of the Tsar, were a direct threat to the empire's stability. After the rebellion was crushed, the government implemented policies to reduce Polish cultural influences. In the 1870s the government began to distrust German elements on the western border. The Russian government felt that the unification of Germany would upset the power balance among the great powers of Europe and that Germany would use its strength against Russia. The government thought that the borders would be defended better if the borderland were more "Russian" in character. The culmination of cultural heterogeneity created a cumbersome nationality problem that plagued the Russian government in the years before leading to the revolution.
Labour problem.
The economic situation in Russia before the revolution presented a grim picture. The government had experimented with "laissez faire" capitalist policies, but this strategy largely failed to gain traction within the Russian economy until the 1890s. Meanwhile, "agricultural productivity stagnated, while international prices for grain dropped, and Russia’s foreign debt and need for imports grew. War and military preparations continued to consume government revenues. At the same time, the peasant taxpayers' ability to pay was strained to the utmost, leading to widespread famine in 1891."
In the 1890s, under the minister of finance Sergei Witte, a crash governmental programme was proposed to promote industrialization. His policies included heavy government expenditures for railroad building and operations, subsidies and supporting services for private industrialists, high protective tariffs for Russian industries (especially heavy industry), an increase in exports, currency stabilization, and encouragement of foreign investments. His plan was successful and during the 1890s "Russian industrial growth averaged 8 percent per year. Railroad mileage grew from a very substantial base by 40 percent between 1892 and 1902." Ironically, Witte's success in implementing this program helped spur the 1905 revolution and eventually the 1917 revolution because it exacerbated social tensions. "Besides dangerously concentrating a proletariat, a professional and a rebellious student body in centers of political power, industrialization infuriated both these new forces and the traditional rural classes." The government policy of financing industrialization through taxing peasants forced millions of peasants to work in towns. The "peasant worker" saw his labour in the factory as the means to consolidate his family's economic position in the village and played a role in determining the social consciousness of the urban proletariat. The new concentrations and flows of peasants spread urban ideas to the countryside, breaking down isolation of peasants on communes.
Industrial workers began to feel dissatisfaction with the Tsarist government despite the protective labour laws the government decreed. Some of those laws included the prohibition of children under 12 from working, with the exception of night work in glass factories. Employment of children aged 12 to 15 was prohibited on Sundays and holidays. Workers had to be paid in cash at least once a month, and limits were placed on the size and bases of fines for workers who were tardy. Employers were prohibited from charging workers for the cost of lighting of the shops and plants. Despite these labor protections, the workers believed that the laws were not enough to free them from unfair and inhumane practices. At the start of the 20th century, Russian industrial workers worked on average an 11-hour day (10 hours on Saturday), factory conditions were perceived as grueling and often unsafe, and attempts at independent unions were often not accepted. Many worker were forced to work beyond the maximum of 11 and a half hours per day. Others were still subject to arbitrary and excessive fines for tardiness, mistakes in their work, or absence. Russian industrial workers were also the lowest wage-workers in Europe. Although the cost of living in Russia was low, "the average worker's 16 rubles per month could not buy the equal of what the French worker's 110 francs would buy for him." Furthermore, the same labour laws prohibited organization of trade unions and strikes. Dissatisfaction turned into despair for many impoverished workers, which made them more sympathetic to radical ideas. These discontented, radicalized workers became key to the revolution by participating in illegal strikes and revolutionary protests.
The government responded by arresting labour agitators and enacting more "paternalistic" legislation. Introduced in 1900 by Sergei Zubatov, head of the Moscow security department, "police socialism" planned to have workers form workers' societies with police approval to "provide healthful, fraternal activities and opportunities for cooperative self-help together with 'protection' against influences that might have inimical effect on loyalty to job or country." Some of these groups organized in Moscow, Odessa, Kiev, Nikolayev (Ukraine), and Kharkov, but these groups and the idea of police socialism failed.
In 1900–1903, the period of industrial depression caused many firm bankruptcies and a reduction in the employment rate. Employees were restive: they would join legal organizations but turn the organizations toward an end that the organizations' sponsors did not intend. Workers used legitimate means to organize strikes or to draw support for striking workers outside these groups. A strike that began in 1902 by workers in the railroad shops in Vladikavkaz and Rostov-on-Don created such a huge response that by the next summer, 225,000 in various industries in southern Russia and Transcaucasia were on strike. These were not the first illegal strikes in the country's history but the their aims, and the political awareness and support among workers and non-workers made them more troubling to the government than earlier strikes. The government responded by closing all legal organizations by the end of 1903.
Educated class as a problem.
The Minister of the Interior, Plehve, designated schools as a pressing problem for the government, but he did not realize it was only a symptom of antigovernment feelings among the educated class. Students of universities, other schools of higher learning, and occasionally of secondary schools and theological seminaries were part of this group.
Student radicalism began around the time Tsar Alexander II came to power. Alexander abolished serfdom and enacted fundamental reforms in the legal and administrative structure of the Russian empire, which were revolutionary for their time. He lifted many restrictions on universities and abolished obligatory uniforms and military discipline. This ushered in a new freedom in the content and reading lists of academic courses. In turn, that created student subcultures, as youth were willing to live in poverty in order to receive an education. As universities expanded, there was a rapid growth of newspapers, journals, and an organization of public lectures and professional societies. The 1860s was a time when the emergence of a new public sphere was created in social life and professional groups. This created the idea of their right to have an independent opinion.
The government was alarmed by these communities, and in 1861 tightened restrictions on admission and prohibited student organizations; these restrictions resulted in the first ever student demonstration, held in St. Petersburg, which led to a two-year closure of the university. The consequent conflict with the state was an important factor in the chronic student protests over subsequent decades. The atmosphere of the early 1860s gave rise to political engagement by students outside universities that became a tenet of student radicalism by the 1870s. Student radicals described "the special duty and mission of the student as such to spread the new word of liberty. Students were called upon to extend their freedoms into society, to repay the privilege of learning by serving the people, and to become in Nikolai Ogarev's phrase 'apostles of knowledge.' " During the next two decades, universities produced a significant share of Russia's revolutionaries. Prosecution records from the 1860s and 1870s show that more than half of all political offences were committed by students despite being a minute proportion of the population. "The tactics of the left-wing students proved to be remarkably effective, far beyond anyone's dreams. Sensing that neither the university administrations nor the government any longer possessed the will or authority to enforce regulations, radicals simply went ahead with their plans to turn the schools into centres of political activity for students and non students alike."
They took up problems that were unrelated to their "proper employment", and displayed defiance and radicalism by boycotting examinations, rioting, arranging marches in sympathy with strikers and political prisoners, circulating petitions, and writing anti-government propaganda.
This disturbed the government, but it believed the cause was lack of training in patriotism and religion. Therefore, the curriculum was "toughened up" to emphasize classical language and mathematics in secondary schools, but defiance continued. Expulsion, exile, and forced military service also did not stop students. "In fact, when the official decision to overhaul the whole educational system was finally made, in 1904, and to that end Vladimir Glazov, head of General Staff Academy, was selected as Minister of Education, the students had grown bolder and more resistant than ever."
Rise of the opposition.
The events of 1905 were preceded by a Progressive and academic agitation for more political democracy and limits to Tsarist rule in Russia; plus an increase in strikes by workers against employers for radical economic demands and union recognition, especially in southern Russia. Many socialists view this as a period when the rising revolutionary movement was met with rising reactionary movements. As Rosa Luxemburg stated in "The Mass Strike", when collective strike activity was met with what is perceived as repression from an autocratic state, economic and political demands grew into and reinforced each other.
Russian progressives formed the Union of Zemstvo Constitutionalists in 1903 and the Union of Liberation in 1904, which called for a constitutional monarchy. Russian socialists formed two major groups: the Socialist-Revolutionary Party, following the Russian populist tradition, and the Marxist Russian Social Democratic Labour Party.
In the autumn of 1904, liberals started a series of banquets celebrating the 40th anniversary of the liberal court statutes and calling for political reforms and a constitution. On , the Moscow City Duma passed a resolution demanding establishment of an elected national legislature, full freedom of the press, and freedom of religion. Similar resolutions and appeals from other city dumas and zemstvo councils followed.
Tsar Nicholas II made a move to fulfill many of these demands, appointing liberal Pyotr Dmitrievich Sviatopolk-Mirskii Minister of the Interior after the assassination of Vyacheslav von Plehve. On , the Tsar issued a manifesto promising the broadening of the Zemstvo and local municipal councils' authority, insurance for industrial workers, the emancipation of Inorodtsy, and the abolition of censorship. However, the crucial demand of representative national legislature was missing in the manifesto.
In 1902, worker strikes in the Caucasus broke out in March, and strikes on the Railway originating from pay disputes took on other issues, and drew in other industries, culminating in a general strike at Rostov-on-Don in November. Daily meetings of 15,000 to 20,000 heard openly revolutionary appeals for the first time, before a massacre defeated the strikes. But reaction to the massacres brought political demands to purely economic ones. In 1903 "the whole of South Russia in May, June and July was aflame", including Baku where separate wage struggles culminated in a city-wide general strike, and Tiflis, where commercial workers gained a reduction in the working day, and were joined by factory workers. In 1904, massive strike waves broke out in Odessa in the spring, Kiev in July, and Baku in December. This all set the stage for the strikes in St. Petersburg in December 1904 to January 1905 seen as the first step in the 1905 revolution.
Start of the revolution.
In December 1904, a strike occurred at the Putilov plant (a railway and artillery supplier) in St. Petersburg. Sympathy strikes in other parts of the city raised the number of strikers to 150,000 workers in 382 factories. By , the city had no electricity and newspaper distribution was halted. All public areas were declared closed.
Controversial Orthodox priest Georgy Gapon, who headed a police-sponsored workers' association, led a huge workers' procession to the Winter Palace to deliver a petition to the Tsar on Sunday, . The troops guarding the Palace were ordered to tell the demonstrators not to pass a certain point, according to Sergei Witte, and at some point, troops opened fire on the demonstrators, causing between 200 (according to Witte) and 1000 deaths. The event became known as Bloody Sunday, and is considered by many scholars as the start of the active phase of the revolution.
The events in St. Petersburg provoked public indignation and a series of massive strikes that spread quickly throughout the industrial centers of the Russian Empire. Polish socialists—both the PPS and the SDKPiL—called for a general strike. By the end of January 1905, over 400,000 workers in Russian Poland were on strike (see Revolution in the Kingdom of Poland (1905–1907)). Half of European Russia's industrial workers went on strike in 1905, and 93.2% in Poland. There were also strikes in Finland and the Baltic coast. In Riga, 130 protesters were killed on , and in Warsaw a few days later over 100 strikers were shot on the streets. By February, there were strikes in the Caucasus, and by April, in the Urals and beyond. In March, all higher academic institutions were forcibly closed for the remainder of the year, adding radical students to the striking workers. A strike by railway workers on quickly developed into a general strike in Saint Petersburg and Moscow. This prompted the setting up of the short-lived Saint Petersburg Soviet of Workers' Delegates, an admixture of Bolsheviks and Mensheviks headed by Khrustalev-Nossar and despite the Iskra split would see the likes of Julius Martov and Georgi Plekhanov spar with Lenin. Leon Trotsky, who felt a strong connection to the Bolsheviki, had not given up a compromise but spearheaded strike action in over 200 factories. By , over 2 million workers were on strike and there were almost no active railways in all of Russia. Growing inter-ethnic confrontation throughout the Caucasus resulted in Armenian-Tatar massacres, heavily damaging the cities and the Baku oilfields.
With the unsuccessful and bloody Russo-Japanese War (1904–1905) there was unrest in army reserve units. On 2 January 1905, Port Arthur was lost, and the Russian Baltic Fleet was defeated at Tsushima; in February 1905, the Russian army was defeated at Mukden, losing almost 80,000 men. Witte was dispatched to make peace, negotiating the Treaty of Portsmouth (signed ). In 1905, there were naval mutinies at Sevastopol (see Sevastopol Uprising), Vladivostok, and Kronstadt, peaking in June with the mutiny aboard the battleship "Potemkin"—some sources claim over 2,000 sailors died in the suppression. The mutinies were disorganised and quickly crushed. Despite these mutinies, the armed forces were largely apolitical and remained mostly loyal, if dissatisfied — and were widely used by the government to control the 1905 unrest.
Nationalist groups had been angered by the Russification undertaken since Alexander II. The Poles, Finns, and the Baltic provinces all sought autonomy, and also freedom to use their national languages and promote their own culture. Muslim groups were also active — the First Congress of the Muslim Union took place in August 1905. Certain groups took the opportunity to settle differences with each other rather than the government. Some nationalists undertook anti-Jewish pogroms, possibly with government aid, and in total over 3,000 Jews were killed.
The number of prisoners throughout the Russian Empire, which had peaked at 116,376 in 1893, fell by over a third to a record low of 75,009 in January 1905, chiefly because of several mass amnesties granted by the Tsar; the historian S G Wheatcroft has wondered what role these released criminals played in the 1905–06 social unrest.
Government response.
On 12 January, the Tsar appointed Dmitri Feodorovich Trepov as governor in St Petersburg and dismissed the Minister of the Interior, Pyotr Sviatopolk-Mirskii, on . He appointed a government commission "to enquire without delay into the causes of discontent among the workers in the city of St Petersburg and its suburbs" in view of the strike movement. The commission was headed by Senator NV Shidlovsky, a member of the State Council, and included officials, chiefs of government factories, and private factory owners. It was also meant to have included workers’ delegates elected according to a two-stage system. Elections of the workers delegates were, however, blocked by the socialists who wanted to divert the workers from the elections to the armed struggle. On , the Commission was dissolved without having started work.
Following the assassination of his uncle, the Grand Duke Sergei Aleksandrovich, on , the Tsar made new concessions. On he published the "Bulygin Rescript", which promised the formation of a consultative assembly, religious tolerance, freedom of speech (in the form of language rights for the Polish minority) and a reduction in the peasants' redemption payments.
On , about 300 Zemstvo and municipal representatives held three meetings in Moscow, which passed a resolution, asking for popular representation at the national level. On , Nicholas II had received a Zemstvo deputation. Responding to speeches by Prince Sergei Trubetskoi and Mr Fyodrov, the Tsar confirmed his promise to convene an assembly of people's representatives.
Height of the Revolution.
Tsar Nicholas II agreed on to the creation of a State Duma of the Russian Empire but with consultative powers only. When its slight powers and limits on the electorate were revealed, unrest redoubled. The Saint Petersburg Soviet was formed and called for a general strike in October, refusal to pay taxes, and the withdrawal of bank deposits.
In June and July 1905, there were many peasant uprisings in which peasants seized land and tools. Disturbances in the Russian-controlled Congress Poland culminated in June 1905 in the Łódź insurrection. Surprisingly, only one landlord was recorded as killed. Far more violence was inflicted on peasants outside the commune: 50 deaths were recorded.
The October Manifesto, written by Sergei Witte and Alexis Obolenskii, was presented to the Tsar on . It closely followed the demands of the Zemstvo Congress in September, granting basic civil rights, allowing the formation of political parties, extending the franchise towards universal suffrage, and establishing the Duma as the central legislative body. The Tsar waited and argued for three days, but finally signed the manifesto on , citing his desire to avoid a massacre and his realisation that there was insufficient military force available to pursue alternate options. He regretted signing the document, saying that he felt "sick with shame at this betrayal of the dynasty ... the betrayal was complete".
When the manifesto was proclaimed, there were spontaneous demonstrations of support in all the major cities. The strikes in Saint Petersburg and elsewhere officially ended or quickly collapsed. A political amnesty was also offered. The concessions came hand-in-hand with renewed, and brutal, action against the unrest. There was also a backlash from the conservative elements of society, with right-wing attacks on strikers, left-wingers, and Jews.
While the Russian liberals were satisfied by the October Manifesto and prepared for upcoming Dumas elections, radical socialists and revolutionaries denounced the elections and called for an armed uprising to destroy the Empire.
Some of the November uprising of 1905 in Sevastopol, headed by retired naval Lieutenant Pyotr Schmidt, was directed against the government, while some was undirected. It included terrorism, worker strikes, peasant unrest and military mutinies, and was only suppressed after a fierce battle. The Trans-Baikal railroad fell into the hands of striker committees and demobilised soldiers returning from Manchuria after the Russo–Japanese War. The Tsar had to send a special detachment of loyal troops along the Trans-Siberian Railway to restore order.
Between , there was a general strike by Russian workers. The government sent troops on 7 December, and a bitter street-by-street fight began. A week later, the Semyonovsky Regiment was deployed, and used artillery to break up demonstrations and to shell workers' districts. On , with around a thousand people dead and parts of the city in ruins, the workers surrendered. After a final spasm in Moscow, the uprisings ended in December 1905.
According to figures presented in the Duma by Professor Maksim Kovalevsky, by April 1906, more than 14,000 people had been executed and 75,000 imprisoned. Historian Brian Taylor states the number of deaths in the 1905 Revolution was in the "thousands", and notes one source that puts the figure at over 13,000 deaths.
Results.
Following the Revolution of 1905, the Tsar made last attempts to save his regime, and offered reforms similar to most rulers when pressured by a revolutionary movement. The military remained loyal throughout the Revolution of 1905, as shown by their shooting of revolutionaries when ordered by the Tsar, making overthrow difficult. These reforms were outlined in a precursor to the Constitution of 1906 known as the October Manifesto which created the Imperial Duma. The Russian Constitution of 1906, also known as the Fundamental Laws, set up a multiparty system and a limited constitutional monarchy. The revolutionaries were quelled and satisfied with the reforms, but it was not enough to prevent the 1917 revolution that would later topple the Tsar's regime.
Creation of Duma and Stolypin.
The creation of the Duma and the beginning of the Revolution of 1905 arose from Russia’s loss in the Russo-Japanese War, where Sergei Witte gained political notoriety. On 17 October 1905, the October Manifesto was signed by Tsar Nicholas II guaranteeing civil liberties to all citizens and the creation of the First Duma. The First Duma was created to be the lower house, with the upper house being the Council of State which was appointed. The composition of the First Duma was 48.1% peasants and 36.7% nobles. Thus, peasants were able to use their representation to their advantage to show discontent and be problematic towards authority. Both houses were needed to meet and agree on laws before they could go to the Tsar. The Tsar had absolute veto power, and some absolute powers, in particular control over the army, which hindered the Duma’s ability to be truly representative. Among the political parties formed or legalized were the liberal-intelligentsia Constitutional Democratic party (the Kadets), the peasant leaders' Labour Group (Trudoviks), the less liberal Union of 17 October (the Octobrists), and the reactionary Union of Land-Owners.
Laws for electing Duma representatives were passed in December 1905. All male citizens older than 25 years could vote, but the votes of some sections of society were worth more than others. For example, the vote of a landowner was worth 45 times more than the vote of an industrial worker. The electoral system had four colleges. The first Duma election took place in March 1906 and were boycotted by the socialists, the SRs and the Bolsheviks. The First Duma consisted of 170 Kadets, 90 Trudoviks, 100 non-aligned peasant representatives, 63 nationalists of various hues, and 16 Octobrists.
The Duma proved to be an ineffective institution. Its framework and power were controlled by the government-issued Fundamental Law (Constitution of 1906), which reserved most important functions and control of government for the Tsar. The Tsar could dissolve and recall the Duma at any time, and did both often. The First and Second Dumas were dissolved before they could enact comprehensive reforms. The first Duma demanded further liberalisation and acted as a platform for "agitators", and was dissolved in July 1906. Despite hopes by the Kadets and fears by the government, the dissolution didn ot cause widespread popular reaction. However, an assassination attempt on Pyotr Stolypin led to the establishment of field trials for terrorists, and over the next eight months more than a thousand people were hanged. In 1907, the Tsar wrote another manifesto revising elections law to allow him extreme manipulation in determining who was in the Duma. While the election framework allowed for gerrymandering, the Duma was used as a platform for those elected to express an opinion and have some ground in Russia’s bureaucracy that the autocratic Tsar had to deal with. The Third and Fourth Dumas also accomplished very little, and the institution was dissolved with the end of the empire in 1917.
October Manifesto.
The October Manifesto served as a precursor to the Constitution of 1906. It was reluctantly enacted by Tsar Nicholas II who was convinced by Sergei Witte (who had negotiated the end of the Russo-Japanese War) that it was necessary. The manifesto was what finally stopped the 1905 Revolution and kept Nicholas II in power for 12 more years. The opposition against the Tsar government was far too strong to not have a manifesto written that would help to quell uprising. Witte was a strong proponent of constitutional monarchy, an elected parliament, and enumerated rights and freedoms within the constitution. The main provisions and reforms of the manifesto were:
The manifesto was discussed by the Tsar and Witte until its signing by Nicholas II on 17 October 1905. Witte, the author of the Manifesto, was also named chair of the new Council of Ministers under the new government. The strikes ended on 19 October, and singing, cheering, and other forms of demonstration followed the signing of the October Manifesto as it were unexpected that such concessions expressed by the constitution were to be made by the government. Main problems with the manifesto were that it did not mention the word "constitution", and Nicholas II never felt much pressure to enact the provisions of the manifesto as he for that moment regained the support of his people. However, the rights listed, coupled with the institution of the Duma seemed to signal an end to authoritarian rule, and the October Manifesto failed to pacify liberals and isolate the left in Russia. Many groups saw the manifesto as a movement towards democracy although they had doubts about its implementation, while other groups saw it as an incentive to keep moving forward with the Revolution. Kadets were in favor of the document's freedom of speech and other rights, while Marxists felt it was not enough of a concession and not a true signifier of democracy. While the October Manifesto outlined civil liberties and the establishment of a two-house Parliament, none of these measures came into effect until the Constitution of 1906.
Constitution of 1906.
The Russian Constitution of 1906 was published on the eve of the convocation of the First Duma. The new Fundamental Law was enacted to institute promises of the October Manifesto as well as add new reforms. The Tsar was confirmed as absolute leader, with complete control of the executive, foreign policy, church, and the armed forces. The structure of the Duma was changed, becoming a lower chamber below the Council of Ministers, and was half-elected, half-appointed by the Tsar. Legislation had to be approved by the Duma, the Council, and the Tsar to become law. The Fundamental State Laws were the "culmination of the whole sequence of events set in motion in October 1905 and which consolidated the new "status quo"". The introduction of The Russian Constitution of 1906 was not simply an institution of the October Manifesto. The introduction of the constitution states (and thus emphasizes) the following:
The Constitution did not mention any of the provisions of the October Manifesto. While it did enact the provisions laid out previously, its sole purpose seems again to be the propaganda for the monarchy and to simply not fall back on prior promises. The provisions and the new constitutional monarchy did not satisfy Russians and Lenin. The Constitution lasted until the fall of the empire in 1917.
Rise of terrorism.
The years 1904 and 1907 saw a decline of mass movements, strikes and protests, and a rise of political terrorism. Combat groups such as the SR Combat Organization carried out many assassinations targeting civil servants and police, and robberies. Between 1906 and 1909, revolutionaries killed 7,293 people, of whom 2,640 were officials, and wounded 8,061. Notable victims included:
Repression.
The years of revolution were marked by a dramatic rise in the numbers of death sentences and executions. Different figures on the number of executions were compared by Senator Nikolai Tagantsev, and are listed in the table.
These numbers reflect only executions of civilians, and do not include a large number of summary executions by punitive army detachments and executions of military mutinees.
Anarchist thinker Peter Kropotkin also noted that official statistics excluded executions during punitive expeditions, especially in Siberia, the Caucasus, and the Baltic provinces.
By 1906 there were 4,509 political prisoners in Russian Poland, 20% of the empire's total.
Ivanovo Soviet.
Ivanovo Voznesensk was known as the 'Russian Manchester' for its textile mills. In 1905, its local revolutionaries were overwhelmingly Bolshevik. It was the first Bolshevik branch where workers outnumbered intellectuals.
11 May 1905: The 'Group', the revolutionary leadership, called for all the textile mills to strike.
12 May: The strike begins. Strike leaders meet in the local woods.
13 May: 40,000 workers assemble before the Administration Building to give Svirskii, the regional factory inspector, a list of demands.
14 May: Workers' delegates are elected. This was done at the suggestion of Svirskii who wanted people to negotiate with. A mass meeting is held in Administration Square. Svirskii tells them the mill owners will not meet their demands but will negotiate with elected mill delegates who will be immune to prosecution according to the governor.
15 May: Svirskii tells the strikers they can only negotiate over each factory in turn but they can hold elections wherever. The strikers elect delegates by mill right there in the surrounding boulevards. Later the delegates elect a chairman.
17 May: The meetings are moved to the bank of the Talka river, on suggestion by the police chief.
27 May: The delegates' meeting house is closed.
3 June: Cossacks break up a workers meeting, arresting over 20. Workers start sabotaging telephone wires and burn down a mill.
9 June: The police chief resigns.
12 June: All prisoners are released. Mill owners mostly flee to Moscow. Neither side gives in.
27 June: Workers agree to stop striking 1 July.
Finland.
In the Grand Duchy of Finland, the Social Democrats organised the general strike of 1905 (). The Red Guards were formed, led by captain Johan Kock. During the general strike, the "Red Declaration", written by Finnish politician and journalist Yrjö Mäkelin, was published in Tampere, demanding dissolution of the Senate of Finland, universal suffrage, political freedoms, and abolition of censorship. Leader of the constitutionalists, Leo Mechelin crafted the "November Manifesto" that led to the abolition of the Diet of Finland and of the four Estates, and to the creation of the modern Parliament of Finland. It also resulted in a temporary halt to the Russification policy started in 1899.
On , Russian artillerymen and military engineers rose to rebellion in the fortress of Sveaborg (later called Suomenlinna), Helsinki. The Finnish Red Guards supported the Sveaborg Rebellion with a general strike, but the mutiny was quelled by loyal troops and ships of the Baltic Fleet within 60 hours.
Estonia.
In the Governorate of Estonia, Estonians called for freedom of the press and assembly, for universal suffrage, and for national autonomy. On , the Russian army opened fire in a meeting on a street market in Tallinn in which about 8 000-10 000 people participated, killing 94 and injuring over 200. The October Manifesto was supported in Estonia and the Estonian flag was displayed publicly for the first time. Jaan Tõnisson used the new political freedoms to widen the rights of Estonians by establishing the first Estonian political party - "National Progress Party".
Another, more radical political organisation, the "Estonian Social Democratic Workers' Union" was founded as well. The moderate supporters of Tõnisson and the more radical supporters of Jaan Teemant could not agree about how to continue with the revolution, and only agreed that both wanted to limit the rights of Baltic Germans and to end Russification. The radical views were publicly welcomed and in December 1905, martial law was declared in Tallinn. A total of 160 manors were looted, resulting in ca. 400 workers and peasants being killed by the army. Estonian gains from the revolution were minimal, but the tense stability that prevailed between 1905 and 1917 allowed Estonians to advance the aspiration of national statehood.
Latvia.
Following the shooting of demonstrators in St. Petersburg, a wide-scale general strike began in Riga. On , Russian army troops opened fire on demonstrators killing 73 and injuring 200 people. During the summer of 1905, the focus of revolutionary events moved to the countryside with mass meetings and demonstrations. 470 new parish administrative bodies were elected in 94% of the parishes in Latvia. The Congress of Parish Representatives was held in Riga in November. In autumn 1905, armed conflict between the Baltic German nobility and the Latvian peasants began in the rural areas of Livland and Courland. In Courland, the peasants seized or surrounded several towns. In Livland, the fighters controlled the Rūjiena-Pärnu railway line. Martial law was declared in Courland in August 1905, and in Livland in late November. Special punitive expeditions were dispatched in mid-December to suppress the movement. They executed 1170 people without trial or investigation and burned 300 peasant homes. Thousands were exiled to Siberia. Many Latvian intellectuals only escaped by fleeing to Western Europe or USA. In 1906, the revolutionary movement gradually subsided.

</doc>
<doc id="48740" url="https://en.wikipedia.org/wiki?curid=48740" title="Henri Poincaré">
Henri Poincaré

Jules Henri Poincaré (; 29 April 1854 – 17 July 1912) was a French mathematician, theoretical physicist, engineer, and a philosopher of science. He is often described as a polymath, and in mathematics as "The Last Universalist" by Eric Temple Bell, since he excelled in all fields of the discipline as it existed during his lifetime.
As a mathematician and physicist, he made many original fundamental contributions to pure and applied mathematics, mathematical physics, and celestial mechanics. He was responsible for formulating the Poincaré conjecture, which was one of the most famous unsolved problems in mathematics until it was solved in 2002–2003. In his research on the three-body problem, Poincaré became the first person to discover a chaotic deterministic system which laid the foundations of modern chaos theory. He is also considered to be one of the founders of the field of topology.
Poincaré made clear the importance of paying attention to the invariance of laws of physics under different transformations, and was the first to present the Lorentz transformations in their modern symmetrical form. Poincaré discovered the remaining relativistic velocity transformations and recorded them in a letter to Dutch physicist Hendrik Lorentz (1853–1928) in 1905. Thus he obtained perfect invariance of all of Maxwell's equations, an important step in the formulation of the theory of special relativity.
The Poincaré group used in physics and mathematics was named after him.
Life.
Poincaré was born on 29 April 1854 in Cité Ducale neighborhood, Nancy, Meurthe-et-Moselle into an influential family. His father Leon Poincaré (1828–1892) was a professor of medicine at the University of Nancy. His adored younger sister Aline married the spiritual philosopher Emile Boutroux. Another notable member of Henri's family was his cousin, Raymond Poincaré, who would serve as President of France from 1913 to 1920, and who was a fellow member of the Académie française. He was raised in the Roman Catholic faith.
Education.
During his childhood he was seriously ill for a time with diphtheria and received special instruction from his mother, Eugénie Launois (1830–1897).
In 1862, Henri entered the Lycée in Nancy (now renamed the Lycée Henri Poincaré in his honour, along with the University of Nancy). He spent eleven years at the Lycée and during this time he proved to be one of the top students in every topic he studied. He excelled in written composition. His mathematics teacher described him as a "monster of mathematics" and he won first prizes in the concours général, a competition between the top pupils from all the Lycées across France. His poorest subjects were music and physical education, where he was described as "average at best". However, poor eyesight and a tendency towards absentmindedness may explain these difficulties. He graduated from the Lycée in 1871 with a bachelor's degree in letters and sciences.
During the Franco-Prussian War of 1870, he served alongside his father in the Ambulance Corps.
Poincaré entered the École Polytechnique in 1873 and graduated in 1875. There he studied mathematics as a student of Charles Hermite, continuing to excel and publishing his first paper ("Démonstration nouvelle des propriétés de l'indicatrice d'une surface") in 1874. From November 1875 to June 1878 he studied at the École des Mines, while continuing the study of mathematics in addition to the mining engineering syllabus, and received the degree of ordinary mining engineer in March 1879.
As a graduate of the École des Mines, he joined the Corps des Mines as an inspector for the Vesoul region in northeast France. He was on the scene of a mining disaster at Magny in August 1879 in which 18 miners died. He carried out the official investigation into the accident in a characteristically thorough and humane way.
At the same time, Poincaré was preparing for his doctorate in sciences in mathematics under the supervision of Charles Hermite. His doctoral thesis was in the field of differential equations. It was named "Sur les propriétés des fonctions définies par les équations différences". Poincaré devised a new way of studying the properties of these equations. He not only faced the question of determining the integral of such equations, but also was the first person to study their general geometric properties. He realised that they could be used to model the behaviour of multiple bodies in free motion within the solar system. Poincaré graduated from the University of Paris in 1879.
The first scientific achievements.
After receiving his degree, Poincaré began teaching as junior lecturer in mathematics at the University of Caen in Normandy (in December 1879). At the same time he published his first major article concerning the treatment of a class of automorphic functions.
There, in Caen, he met his future wife, Louise Poulin d'Andesi (Louise Poulain d'Andecy) and on 20 April 1881, they married. Together they had four children: Jeanne (born 1887), Yvonne (born 1889), Henriette (born 1891), and Léon (born 1893).
Poincaré immediately established himself among the greatest mathematicians of Europe, attracting the attention of many prominent mathematicians. In 1881 Poincaré was invited to take a teaching position at the Faculty of Sciences of the University of Paris; he accepted the invitation. During the years of 1883 to 1897, he taught mathematical analysis in École Polytechnique.
In 1881–1882, Poincaré created a new branch of mathematics: the qualitative theory of differential equations. He showed how it is possible to derive the most important information about the behavior of a family of solutions without having to solve the equation (since this may not always be possible). He successfully used this approach to problems in celestial mechanics and mathematical physics.
Career.
He never fully abandoned his mining career to mathematics. He worked at the Ministry of Public Services as an engineer in charge of northern railway development from 1881 to 1885. He eventually became chief engineer of the Corps de Mines in 1893 and inspector general in 1910.
Beginning in 1881 and for the rest of his career, he taught at the University of Paris (the Sorbonne). He was initially appointed as the "maître de conférences d'analyse" (associate professor of analysis). Eventually, he held the chairs of Physical and Experimental Mechanics, Mathematical Physics and Theory of Probability, and Celestial Mechanics and Astronomy.
In 1887, at the young age of 32, Poincaré was elected to the French Academy of Sciences. He became its president in 1906, and was elected to the Académie française in 1909.
In 1887, he won Oscar II, King of Sweden's mathematical competition for a resolution of the three-body problem concerning the free motion of multiple orbiting bodies. (See #The three-body problem section below)
In 1893, Poincaré joined the French Bureau des Longitudes, which engaged him in the synchronisation of time around the world. In 1897 Poincaré backed an unsuccessful proposal for the decimalisation of circular measure, and hence time and longitude. It was this post which led him to consider the question of establishing international time zones and the synchronisation of time between bodies in relative motion. (See #Work on relativity section below)
In 1899, and again more successfully in 1904, he intervened in the trials of Alfred Dreyfus. He attacked the spurious scientific claims of some of the evidence brought against Dreyfus, who was a Jewish officer in the French army charged with treason by colleagues.
In 1912, Poincaré underwent surgery for a prostate problem and subsequently died from an embolism on 17 July 1912, in Paris. He was 58 years of age. He is buried in the Poincaré family vault in the Cemetery of Montparnasse, Paris.
A former French Minister of Education, Claude Allègre, has recently (2004) proposed that Poincaré be reburied in the Panthéon in Paris, which is reserved for French citizens only of the highest honour.
Students.
Poincaré had two notable doctoral students at the University of Paris, Louis Bachelier (1900) and Dimitrie Pompeiu (1905).
Work.
Summary.
Poincaré made many contributions to different fields of pure and applied mathematics such as: celestial mechanics, fluid mechanics, optics, electricity, telegraphy, capillarity, elasticity, thermodynamics, potential theory, quantum theory, theory of relativity and physical cosmology.
He was also a populariser of mathematics and physics and wrote several books for the lay public.
Among the specific topics he contributed to are the following:
The three-body problem.
The problem of finding the general solution to the motion of more than two orbiting bodies in the solar system had eluded mathematicians since Newton's time. This was known originally as the three-body problem and later the "n"-body problem, where "n" is any number of more than two orbiting bodies. The "n"-body solution was considered very important and challenging at the close of the 19th century. Indeed, in 1887, in honour of his 60th birthday, Oscar II, King of Sweden, advised by Gösta Mittag-Leffler, established a prize for anyone who could find the solution to the problem. The announcement was quite specific:
Given a system of arbitrarily many mass points that attract each according to Newton's law, under the assumption that no two points ever collide, try to find a representation of the coordinates of each point as a series in a variable that is some known function of time and for all of whose values the series converges uniformly.
In case the problem could not be solved, any other important contribution to classical mechanics would then be considered to be prizeworthy. The prize was finally awarded to Poincaré, even though he did not solve the original problem.
One of the judges, the distinguished Karl Weierstrass, said, ""This work cannot indeed be considered as furnishing the complete solution of the question proposed, but that it is nevertheless of such importance that its publication will inaugurate a new era in the history of celestial mechanics.""
(The first version of his contribution even contained a serious error; for details see the article by Diacu). The version finally printed contained many important ideas which led to the theory of chaos. The problem as stated originally was finally solved by Karl F. Sundman for "n" = 3 in 1912 and was generalised to the case of "n" > 3 bodies by Qiudong Wang in the 1990s.
Work on relativity.
Local time.
Poincaré's work at the Bureau des Longitudes on establishing international time zones led him to consider how clocks at rest on the Earth, which would be moving at different speeds relative to absolute space (or the "luminiferous aether"), could be synchronised. At the same time Dutch theorist Hendrik Lorentz was developing Maxwell's theory into a theory of the motion of charged particles ("electrons" or "ions"), and their interaction with radiation. In 1895 Lorentz had introduced an auxiliary quantity (without physical interpretation) called "local time" formula_1
and introduced the hypothesis of length contraction to explain the failure of optical and electrical experiments to detect motion relative to the aether (see Michelson–Morley experiment).
Poincaré was a constant interpreter (and sometimes friendly critic) of Lorentz's theory. Poincaré as a philosopher was interested in the "deeper meaning". Thus he interpreted Lorentz's theory and in so doing he came up with many insights that are now associated with special relativity. In (1898), Poincaré said, "
A little reflection is sufficient to understand that all these affirmations have by themselves no meaning. They can have one only as the result of a convention." He also argued that scientists have to set the constancy of the speed of light as a postulate to give physical theories the simplest form.
Based on these assumptions he discussed in 1900 Lorentz's "wonderful invention" of local time and remarked that it arose when moving clocks are synchronised by exchanging light signals assumed to travel with the same speed in both directions in a moving frame.
Principle of relativity and Lorentz transformations.
He discussed the "principle of relative motion" in two papers in 1900
and named it the principle of relativity in 1904, according to which no physical experiment can discriminate between a state of uniform motion and a state of rest.
In 1905 Poincaré wrote to Lorentz about Lorentz's paper of 1904, which Poincaré described as a "paper of supreme importance." In this letter he pointed out an error Lorentz had made when he had applied his transformation to one of Maxwell's equations, that for charge-occupied space, and also questioned the time dilation factor given by Lorentz.
In a second letter to Lorentz, Poincaré gave his own reason why Lorentz's time dilation factor was indeed correct after all: it was necessary to make the Lorentz transformation form a group and gave what is now known as the relativistic velocity-addition law.
Poincaré later delivered a paper at the meeting of the Academy of Sciences in Paris on 5 June 1905 in which these issues were addressed. In the published version of that he wrote:
The essential point, established by Lorentz, is that the equations of the electromagnetic field are not altered by a certain transformation (which I will call by the name of Lorentz) of the form:
and showed that the arbitrary function formula_3 must be unity for all formula_4 (Lorentz had set formula_5 by a different argument) to make the transformations form a group. In an enlarged version of the paper that appeared in 1906 Poincaré pointed out that the combination formula_6 is invariant. He noted that a Lorentz transformation is merely a rotation in four-dimensional space about the origin by introducing formula_7 as a fourth imaginary coordinate, and he used an early form of four-vectors. Poincaré expressed a lack of interest in a four-dimensional reformulation of his new mechanics in 1907, because in his opinion the translation of physics into the language of four-dimensional geometry would entail too much effort for limited profit. So it was Hermann Minkowski who worked out the consequences of this notion in 1907.
Mass–energy relation.
Like others before, Poincaré (1900) discovered a relation between mass and electromagnetic energy. While studying the conflict between the action/reaction principle and Lorentz ether theory, he tried to determine whether the center of gravity still moves with a uniform velocity when electromagnetic fields are included. He noticed that the action/reaction principle does not hold for matter alone, but that the electromagnetic field has its own momentum. Poincaré concluded that the electromagnetic field energy of an electromagnetic wave behaves like a fictitious fluid ("fluide fictif") with a mass density of "E"/"c"2. If the center of mass frame is defined by both the mass of matter "and" the mass of the fictitious fluid, and if the fictitious fluid is indestructible—it's neither created or destroyed—then the motion of the center of mass frame remains uniform. But electromagnetic energy can be converted into other forms of energy. So Poincaré assumed that there exists a non-electric energy fluid at each point of space, into which electromagnetic energy can be transformed and which also carries a mass proportional to the energy. In this way, the motion of the center of mass remains uniform. Poincaré said that one should not be too surprised by these assumptions, since they are only mathematical fictions.
However, Poincaré's resolution led to a paradox when changing frames: if a Hertzian oscillator radiates in a certain direction, it will suffer a recoil from the inertia of the fictitious fluid. Poincaré performed a Lorentz boost (to order "v"/"c") to the frame of the moving source. He noted that energy conservation holds in both frames, but that the law of conservation of momentum is violated. This would allow perpetual motion, a notion which he abhorred. The laws of nature would have to be different in the frames of reference, and the relativity principle would not hold. Therefore, he argued that also in this case there has to be another compensating mechanism in the ether.
Poincaré himself came back to this topic in his St. Louis lecture (1904). This time (and later also in 1908) he rejected the possibility that energy carries mass and criticized the ether solution to compensate the above-mentioned problems:
He also discussed two other unexplained effects: (1) non-conservation of mass implied by Lorentz's variable mass formula_8, Abraham's theory of variable mass and Kaufmann's experiments on the mass of fast moving electrons and (2) the non-conservation of energy in the radium experiments of Madame Curie.
It was Albert Einstein's concept of mass–energy equivalence (1905) that a body losing energy as radiation or heat was losing mass of amount "m" = "E"/"c"2 that resolved Poincaré's paradox, without using any compensating mechanism within the ether. The Hertzian oscillator loses mass in the emission process, and momentum is conserved in any frame. However, concerning Poincaré's solution of the Center of Gravity problem, Einstein noted that Poincaré's formulation and his own from 1906 were mathematically equivalent.
Poincaré and Einstein.
Einstein's first paper on relativity was published three months after Poincaré's short paper, but before Poincaré's longer version. Einstein relied on the principle of relativity to derive the Lorentz transformations and used a similar clock synchronisation procedure (Einstein synchronisation) to the one that Poincaré (1900) had described, but Einstein's was remarkable in that it contained no references at all. Poincaré never acknowledged Einstein's work on special relativity. However, Einstein expressed sympathy with Poincaré's outlook obliquely in a letter to Hans Vaihinger on 3 May 1919, when Einstein considered Vaihinger's general outlook to be close to his own and Poincaré's to be close to Vaihinger's. In public, Einstein acknowledged Poincaré posthumously in the text of a lecture in 1921 called "Geometrie und Erfahrung" in connection with non-Euclidean geometry, but not in connection with special relativity. A few years before his death, Einstein commented on Poincaré as being one of the pioneers of relativity, saying "Lorentz had already recognised that the transformation named after him is essential for the analysis of Maxwell's equations, and Poincaré deepened this insight still further ..."
Algebra and number theory.
Poincaré introduced group theory to physics, and was the first to study the group of Lorentz transformations. He also made major contributions to the theory of discrete groups and their representations.
Topology.
The subject is clearly defined by Felix Klein in his "Erlangen Program" (1872): the geometry invariants of arbitrary continuous transformation, a kind of geometry. The term "topology" was introduced, as suggested by Johann Benedict Listing, instead of previously used "Analysis situs". Some important concepts were introduced by Enrico Betti and Bernhard Riemann. But the foundation of this science, for a space of any dimension, was created by Poincaré. His first article on this topic appeared in 1894.
His research in geometry led to the abstract topological definition of homotopy and homology. He also first introduced the basic concepts and invariants of combinatorial topology, such as Betti numbers and the fundamental group. Poincaré proved a formula relating the number of edges, vertices and faces of "n"-dimensional polyhedron (the Euler–Poincaré theorem) and gave the first precise formulation of the intuitive notion of dimension.
Astronomy and celestial mechanics.
Poincaré published two now classical monographs, "New Methods of Celestial Mechanics" (1892–1899) and "Lectures on Celestial Mechanics" (1905–1910). In them, he successfully applied the results of their research to the problem of the motion of three bodies and studied in detail the behavior of solutions (frequency, stability, asymptotic, and so on). They introduced the small parameter method, fixed points, integral invariants, variational equations, the convergence of the asymptotic expansions. Generalizing a theory of Bruns (1887), Poincaré showed that the three-body problem is not integrable. In other words, the general solution of the three-body problem can not be expressed in terms of algebraic and transcendental functions through unambiguous coordinates and velocities of the bodies. His work in this area were the first major achievements in celestial mechanics since Isaac Newton.
These include the idea of Poincaré, who later became the base for mathematical "chaos theory" (see, in particular, the Poincaré recurrence theorem) and the general theory of dynamical systems.
Poincaré authored important works on astronomy for the equilibrium figures gravitating rotating fluid. He introduced the important concept of bifurcation points, proved the existence of equilibrium figures of non-ellipsoid, including ring-shaped and pear-shaped figures, their stability. For this discovery, Poincaré received the Gold Medal of the Royal Astronomical Society (1900).
Differential equations and mathematical physics.
After defending his doctoral thesis on the study of singular points of the system of differential equations, Poincaré wrote a series of memoirs under the title "On curves defined by differential equations" (1881–1882). In these articles, he built a new branch of mathematics, called "qualitative theory of differential equations". Poincaré showed that even if the differential equation can not be solved in terms of known functions, yet from the very form of the equation, a wealth of information about the properties and behavior of the solutions can be found. In particular, Poincaré investigated the nature of the trajectories of the integral curves in the plane, gave a classification of singular points (saddle, focus, center, node), introduced the concept of a limit cycle and the loop index, and showed that the number of limit cycles is always finite, except for some special cases. Poincaré also developed a general theory of integral invariants and solutions of the variational equations. For the finite-difference equations, he created a new direction – the asymptotic analysis of the solutions. He applied all these achievements to study practical problems of mathematical physics and celestial mechanics, and the methods used were the basis of its topological works.
Assessments.
Poincaré's work in the development of special relativity is well recognised, though most historians stress that despite many similarities with Einstein's work, the two had very different research agendas and interpretations of the work. Poincaré developed a similar physical interpretation of local time and noticed the connection to signal velocity, but contrary to Einstein he continued to use the ether-concept in his papers and argued that clocks in the ether show the "true" time, and moving clocks show the local time. So Poincaré tried to keep the relativity principle in accordance with classical concepts, while Einstein developed a mathematically equivalent kinematics based on the new physical concepts of the relativity of space and time.
While this is the view of most historians, a minority go much further, such as E. T. Whittaker, who held that Poincaré and Lorentz were the true discoverers of Relativity.
Character.
Poincaré's work habits have been compared to a bee flying from flower to flower. Poincaré was interested in the way his mind worked; he studied his habits and gave a talk about his observations in 1908 at the Institute of General Psychology in Paris. He linked his way of thinking to how he made several discoveries.
The mathematician Darboux claimed he was "un intuitif" (intuitive), arguing that this is demonstrated by the fact that he worked so often by visual representation. He did not care about being rigorous and disliked logic. (Despite this opinion, Jacques Hadamard wrote that Poincaré's research demonstrated marvelous clarity. and Poincaré himself wrote that he believed that logic was not a way to invent but a way to structure ideas and that logic limits ideas.)
Toulouse's characterisation.
Poincaré's mental organisation was not only interesting to Poincaré himself but also to Édouard Toulouse, a psychologist of the Psychology Laboratory of the School of Higher Studies in Paris. Toulouse wrote a book entitled "Henri Poincaré" (1910). In it, he discussed Poincaré's regular schedule:
These abilities were offset to some extent by his shortcomings:
In addition, Toulouse stated that most mathematicians worked from principles already established while Poincaré started from basic principles each time (O'Connor et al., 2002).
His method of thinking is well summarised as:
Attitude towards transfinite numbers.
Poincaré was dismayed by Georg Cantor's theory of transfinite numbers, and referred to it as a "disease" from which mathematics would eventually be cured.
Poincaré said, "There is no actual infinite; the Cantorians have forgotten this, and that is why they have fallen into contradiction."
Honours.
Awards
Named after him
Henri Poincaré did not receive the Nobel Prize in Physics, but he had influential advocates like Henri Becquerel or committee member Gösta Mittag-Leffler. The nomination archive reveals that Poincaré received a total of 51 nominations between 1904 and 1912, the year of his death. Of the 58 nominations for the 1910 Nobel Prize, 34 named Poincaré. Nominators included Nobel laureates Hendrik Lorentz and Pieter Zeeman (both of 1902), Marie Curie (of 1903), Albert Michelsen (of 1907), Gabriel Lippmann (of 1908) and Guglielmo Marconi (of 1909).
The fact that renowned theoretical physicists like Poincaré, Boltzmann or Gibbs were not awarded the Nobel Prize is seen as evidence that the Nobel committee had more regard for experimentation than theory. In Poincaré's case, several of those who nominated him pointed out that the greatest problem was to name a specific discovery, invention, or technique.
Philosophy.
Poincaré had philosophical views opposite to those of Bertrand Russell and Gottlob Frege, who believed that mathematics was a branch of logic. Poincaré strongly disagreed, claiming that intuition was the life of mathematics. Poincaré gives an interesting point of view in his book "Science and Hypothesis":
Poincaré believed that arithmetic is a synthetic science. He argued that Peano's axioms cannot be proven non-circularly with the principle of induction (Murzi, 1998), therefore concluding that arithmetic is "a priori" synthetic and not analytic. Poincaré then went on to say that mathematics cannot be deduced from logic since it is not analytic. His views were similar to those of Immanuel Kant (Kolak, 2001, Folina 1992). He strongly opposed Cantorian set theory, objecting to its use of impredicative definitions.
However, Poincaré did not share Kantian views in all branches of philosophy and mathematics. For example, in geometry, Poincaré believed that the structure of non-Euclidean space can be known analytically. Poincaré held that convention plays an important role in physics. His view (and some later, more extreme versions of it) came to be known as "conventionalism". Poincaré believed that Newton's first law was not empirical but is a conventional framework assumption for mechanics (Gargani, 2012). He also believed that the geometry of physical space is conventional. He considered examples in which either the geometry of the physical fields or gradients of temperature can be changed, either describing a space as non-Euclidean measured by rigid rulers, or as a Euclidean space where the rulers are expanded or shrunk by a variable heat distribution. However, Poincaré thought that we were so accustomed to Euclidean geometry that we would prefer to change the physical laws to save Euclidean geometry rather than shift to a non-Euclidean physical geometry.
Free will.
Poincaré's famous lectures before the Société de Psychologie in Paris (published as "Science and Hypothesis", "The Value of Science", and "Science and Method") were cited by Jacques Hadamard as the source for the idea that creativity and invention consist of two mental stages, first random combinations of possible solutions to a problem, followed by a critical evaluation.
Although he most often spoke of a deterministic universe, Poincaré said that the subconscious generation of new possibilities involves chance.
It is certain that the combinations which present themselves to the mind in a kind of sudden illumination after a somewhat prolonged period of unconscious work are generally useful and fruitful combinations... all the combinations are formed as a result of the automatic action of the subliminal ego, but those only which are interesting find their way into the field of consciousness... A few only are harmonious, and consequently at once useful and beautiful, and they will be capable of affecting the geometrician's special sensibility I have been speaking of; which, once aroused, will direct our attention upon them, and will thus give them the opportunity of becoming conscious... In the subliminal ego, on the contrary, there reigns what I would call liberty, if one could give this name to the mere absence of discipline and to disorder born of chance.
Poincaré's two stages—random combinations followed by selection—became the basis for Daniel Dennett's two-stage model of free will.
References.
Poincaré's writings in English translation.
Popular writings on the philosophy of science:
On algebraic topology:
On celestial mechanics:
On the philosophy of mathematics:
Other:

</doc>
<doc id="48743" url="https://en.wikipedia.org/wiki?curid=48743" title="List of phobias">
List of phobias

The English suffixes -phobia, -phobic, -phobe (from Greek φόβος "phobos", "fear") occur in technical usage in psychiatry to construct words that describe irrational, abnormal, unwarranted, persistent, or disabling fear as a mental disorder (e.g. agoraphobia), in chemistry to describe chemical aversions (e.g. hydrophobic), in biology to describe organisms that dislike certain conditions (e.g. acidophobia), and in medicine to describe hypersensitivity to a stimulus, usually sensory (e.g. photophobia). In common usage, they also form words that describe dislike or hatred of a particular thing or subject. The suffix is antonymic to -phil-.
For more information on the psychiatric side, including how psychiatry groups phobias such as agoraphobia, social phobia, or simple phobia, see phobia. The following lists include words ending in "-phobia", and include fears that have acquired names. In some cases, the naming of phobias has become a word game, of notable example being a 1998 humorous article published by "BBC News". In some cases, a word ending in "-phobia" may have an antonym with the suffix "-phil-", e.g. Germanophobe / Germanophile.
A large number of "-phobia" lists circulate on the Internet, with words collected from indiscriminate sources, often copying each other. Also, a number of psychiatric websites exist that at the first glance cover a huge number of phobias, but in fact use a standard text to fit any phobia and reuse it for all unusual phobias by merely changing the name. Sometimes it leads to bizarre results, such as suggestions to cure "prostitute phobia". Such practice is known as content spamming and is used to attract search engines.
Psychological conditions.
Specialists may prefer to avoid the suffix "-phobia" and use more descriptive terms such as personality disorders, anxiety disorders, and avoidant personality disorder.
Biology, chemistry.
Biologists use a number of "-phobia/-phobic" terms to describe predispositions by plants and animals against certain conditions. For antonyms, see here
Prejudices and discrimination.
The suffix "-phobia" is used to coin terms that denote a particular anti-ethnic or anti-demographic sentiment, such as Americanophobia, Europhobia, Francophobia, Hispanophobia, and Indophobia. Often a synonym with the prefix "anti-" already exists (e.g. Polonophobia vs. anti-Polonism). Anti-religious sentiments are expressed in terms such as Christianophobia and Islamophobia.
Other prejudices include:

</doc>
<doc id="48745" url="https://en.wikipedia.org/wiki?curid=48745" title="400s BC (decade)">
400s BC (decade)


</doc>
<doc id="48748" url="https://en.wikipedia.org/wiki?curid=48748" title="Phil Austin">
Phil Austin

Philip Baine "Phil" Austin (April 6, 1941 – June 19, 2015) was a comedian and writer, best known as a member of The Firesign Theatre. 
Biography.
Austin was born in Denver, Colorado and later grew up in Fresno, California, attending Fresno High School. His mother was a drama teacher which influenced his upbringing as an actor. He attended Bowdoin College in Brunswick, Maine because it was the most distant point in the continental United States from Fresno. He also attended Fresno State College and UCLA, but did not graduate from any of them. In Los Angeles in the late 1960s, he was one of the first apprentices for the Center Theatre Group and worked on the staff of KPFK radio in Los Angeles. At KPFK he met other staffers David Ossman and Phil Proctor. Along with Proctor's friend Peter Bergman, they formed The Firesign Theatre.
Starting as live radio actors, the group would go on to record a series of surrealistic comedy albums that were a hit amongst an underground audience. Austin played the group's best-known creation, private investigator Nick Danger. Other prominent roles were as Harry (Happy) Cox, the narrator of "Everything You Know Is Wrong" and Bebop Loco/Lobo on "Give Me Immortality or Give Me Death". He had also served as the troupe's musician and record producer. 
His collection of short stories, "Tales of the Old Detective and Other Big Fat Lies", is published by Audio Editions. Two of his stories appear in the third volume of "Mirth of a Nation".
Austin also wrote a solo work, "Roller Maidens From Outer Space", and directed (and acted in) "Eat Or Be Eaten". 
Stage versions of "Don't Crush That Dwarf, Hand Me the Pliers"; "The Further Adventures of Nick Danger, Third Eye"; "Waiting for the Electrician or Someone Like Him"; and "Temporarily Humboldt County" are published by Broadway Play Publishing Inc.. 
Austin died of at his home in Fox Island, Washington on June 19, 2015 at the age of 74. The cause of death was originally given as cardiac arrest, but this was later changed to an aneurysm. He also had cancer.

</doc>
<doc id="48755" url="https://en.wikipedia.org/wiki?curid=48755" title="Neo-fascism">
Neo-fascism

Neo-fascism is a post–World War II ideology that includes significant elements of fascism. Neo-fascism usually includes ultranationalism, populism, anti-immigration policies or, where relevant, nativism, anti-communism, anti-Marxism, anti-anarchism and opposition to the parliamentary system and liberal democracy. Allegations that a group is neo-fascist may be hotly contested, especially if the term is used as a political epithet. Some post–World War II regimes have been described as neo-fascist due to their authoritarian nature, and sometimes due to their fascination and sympathy towards fascist ideology and rituals.
Post-fascism is a label that has been applied to several European political parties that espouse a modified form of fascism and which partake in constitutional politics.
Bolivia.
The Bolivian Socialist Falange party founded in 1937 played a crucial role in mid-century Bolivian politics. Luis García Meza Tejada's regime took power during the 1980 "Cocaine Coup" in Bolivia with the help of Italian neo-fascist Stefano Delle Chiaie, Nazi war criminal Klaus Barbie and the Buenos Aires junta. That regime has been accused of neo-fascist tendencies and of admiration for Nazi paraphernalia and rituals. Hugo Banzer Suárez, who preceded Tejada, also displayed admiration towards Nazism and fascism.
Greece.
In April 1967, a few weeks prior to an election, a military coup d'état took place in Greece and a fascist military government ruled the country from 1967 to 1974. It was called the "Regime of the Colonels", and was headed by Colonel George Papadopoulos. The official reason given for the coup was that a "communist conspiracy" had infiltrated all levels of society.
The contemporary Greek political party Golden Dawn, which found its roots in Papadopoulos' regime, has been described as subscribing to neo-fascist and neo-Nazi beliefs and practices.
Although there have been persistent rumors about an active support of the coup by the U.S. government, there is no evidence to support such claims. The timing of the coup apparently caught the CIA by surprise.
Indonesia.
Adolf Hitler's propaganda for the hegemony of "Greater Germany" inspired similar ideas of "Indonesia Mulia" (esteemed Indonesia) and "Indonesia Raya" (great Indonesia) in the former Dutch colony. The first fascist party was the Partai Fasis Indonesia (PFI). Sukarno did admire Hitler's Third Reich and its vision of happiness for all: "It's in the Third Reich that the Germans will see Germany at the apex above other nations in this world," he said in 1963. He stated that Hitler was 'extraordinarily clever' in 'depicting his ideals': he spoke about Hitler's rhetorical skills, but denied any association with Nazism as an ideology, saying that Indonesian nationalism was not as narrow as Nazi nationalism.
Italy.
Italy was broadly divided into two political blocs following World War II, the Christian Democracy, which remained in power until the 1980s, and the Italian Communist Party (PCI), very strong immediately after the war.
With the beginning of Cold War it was feared by British government that the requested extradition of Italian war criminals to Yugoslavia would benefit PCI. Preventing anything like the Nuremberg trial for Italian war crimes, the collective memory of the crimes committed by Italians was expelled from public media, from textbooks in Italian schools, and also from the academic discourse on Western side of the Iron curtain throughout the Cold War. PCI was expulsed from power in May 1947, a month before the Paris Conference on the Marshall Plan, along with the French Communist Party (PCF).
In 1946 a group of Fascist soldiers founded the Italian Social Movement to continue the idea of Benito Mussolini. The leader of the MSI was Giorgio Almirante. who remained at the head of the party until his death in 1988.
Despite attempts in the 1970s towards a "historic compromise" between the PCI and the DC, the PCI didn't take part in the executive power until the 1980s. In December 1970, Junio Valerio Borghese attempted, along with Stefano Delle Chiaie, the "Borghese Coup" which was supposed to install a neo-fascist regime. Neo-fascist groups took part in various false flag terrorist attacks, starting with the December 1969 Piazza Fontana massacre, for which Vincenzo Vinciguerra was convicted, and usually considered to have stopped with the 1980 Bologna railway bombing. A 2000 parliamentary report from the center-left Olive Tree coalition concluded that "the strategy of tension had been supported by the United States in order to impede the PCI, and, in a lesser measure, the PSI from reaching executive power".
Since the 1990s, National Alliance, led by Gianfranco Fini, a former member of Italian Social Movement, has distanced itself from Mussolini and fascism and made efforts to improve relations with Jewish groups, with most die-hards leaving it; it now seeks to present itself as a respectable right-wing party. Fini joined Silvio Berlusconi's government. Neo-fascist parties in Italy are Tricolour Flame ("Fiamma Tricolore"), New Force ("Forza Nuova") and the National Social Front ("fronte sociale nazionale").
Lebanon.
Lebanon (1982–1988) – The far-right wing Christian Phalangist Party "Kataeb" and Lebanese Forces, backed by its own private army and inspired by the Spanish Falangists. As it evolved it gained nominal in power in the country during the 1980s but had limited authority over the highly factionalised state, two-thirds of which was controlled by Israeli and Syrian troops.
Its core political beliefs are not neo-fascist and include the following
It is only on this list because of its early symbolism. The military activity was common and broadly used across all pre-colonial states, through to today. All the political parties today in Lebanon have private armies, from Hezbollah to the Christian militias.
Slovakia.
Kotleba – People's Party Our Slovakia is a far-right political party with views considered extremist and fascist. The Party's leader, Marian Kotleba, was formerly a neo-Nazi, and until recently, dressed in a uniform modelled on the Hlinka Guard, the militia of the 1939-45 Nazi-sponsored Slovak State. He is openly against Roma people, immigrants, Slovak National Uprising, NATO, the United States, and the European Union.
In 2003, Kotleba founded the far-right political party Slovak Togetherness (Slovak: "Slovenská Pospolitosť"). In 2007, the Slovak interior ministry banned the party from running and campaigning in elections. In spite of this ban, Kotleba's party got 8,04% of votes in the Slovak 2016 parliamentary elections, and voter opinion towards the party continues to increase.
Taiwan.
The National Socialism Association (NSA) is a neo-fascist political organization founded in Taiwan in September 2006 by Hsu Na-chi (許娜琦), a 22-year-old female political science graduate of Soochow University. The NSA views Adolf Hitler as its leader and often uses the slogan "Long live Hitler". This has brought them condemnation from the Simon Wiesenthal Center, an international Jewish human rights center.
Mongolia.
With Mongolia located between the larger nations Russia and China, ethnic insecurities have driven many Mongolians to neo-fascism, expressing nationalism centered around Genghis Khan and Adolf Hitler. Groups advocating these ideologies include Blue Mongolia, Dayar Mongol, and Mongolian National Union.
Turkey.
Grey Wolves is a Turkish ultra-nationalist and neo-fascist youth organization. It is the "unofficial militant arm" of the Nationalist Movement Party. The Grey Wolves have been accused of terrorism. According to Turkish authorities, the organization carried out 694 murders during the late-1970s political violence in Turkey, between 1974 and 1980.
United Kingdom.
The British National Party are a nationalist party in the United Kingdom who have the ideology of fascism and anti-immigration. Ex-party leader Nick Griffin said in 1998 that he believes the Holocaust "...'extermination' tale is a mixture of Allied wartime propaganda...", although has since retracted this statement.
The UK Independence Party has been accused by political opponents of holding to elements of Fascism e.g. populist nationalist and anti-immigration policies. However, UKIP have denied this, stating that their policies are not anti-immigration but pro-controlled immigration, patriotic not nationalist, in support of British democracy, and for all British citizens without regard to ethnicity or country of birth. Furthermore, they support a small state and economic freedom, which are not typically found within Fascism. A London School of Economics blog examined both UKIP and the BNP and, while it did find similarities in demographic support and a few policies, it failed to conclude any strong ideological links between them. However, it did remark on a coincidental increase in support of UKIP and a decrease in support for the BNP, speculating a possible relationship between them. Other left-wing literature, critical of UKIP, also denies that they are Fascist.
United States.
Groups identified as neo-fascist in the United States generally include neo-Nazi organizations such as the National Alliance and the American Nazi Party. The Institute for Historical Review publishes negationist historical papers often of an anti-semitic nature.
International networks.
In 1951, the New European Order (NEO) neo-fascist Europe-wide alliance was set up to promote Pan-European nationalism. It was a more radical splinter group of the European Social Movement. The NEO had its origins in the 1951 Malmö conference when a group of rebels led by René Binet and Maurice Bardèche refused to join the European Social Movement as they felt that it did not go far enough in terms of racialism and anti-communism. As a result, Binet joined with Gaston-Armand Amaudruz in a second meeting that same year in Zurich to set up a second group pledged to wage war on communists and non-white people.
Several Cold War regimes and international neo-fascist movements collaborated in operations such as assassinations and false flag bombings. Stefano Delle Chiaie, involved in Italy's strategy of tension, took part in Operation Condor; organizing the 1976 assassination attempt of Chilean Christian Democrat Bernardo Leighton. Vincenzo Vinciguerra escaped to Franquist Spain with the help of the SISMI, following the 1972 Peteano attack, for which he was sentenced to life. Along with Delle Chiaie, Vinciguerra testified in Rome in December 1995 before judge Maria Servini de Cubria, stating that Enrique Arancibia Clavel (a former Chilean secret police agent prosecuted for crimes against humanity in 2004) and US expatriate DINA agent Michael Townley were directly involved in General Carlos Prats' assassination. Michael Townley was sentenced in Italy to 15 years of prison for having served as intermediary between the DINA and the Italian neo-fascists.
The regimes of Franquist Spain, Augusto Pinochet's Chile and Alfredo Stroessner's Paraguay participated together in Operation Condor, which targeted political opponents worldwide. During the Cold War, these international operations gave rise to some cooperation between various neo-fascist elements engaged in a "Crusade against Communism". Anti-Fidel Castro terrorist Luis Posada Carriles was condemned for the Cubana Flight 455 bombing on 6 October 1976. According to the "Miami Herald", this bombing was decided on at the same meeting during which it was decided to target Chilean former minister Orlando Letelier, who was assassinated on 21 September 1976. Carriles wrote in his autobiography: "... we the Cubans didn't oppose ourselves to an isolated tyranny, nor to a particular system of our fatherland, but that we had in front of us a colossal enemy, whose main head was in Moscow, with its tentacles dangerously extended on all the planet."

</doc>
<doc id="48756" url="https://en.wikipedia.org/wiki?curid=48756" title="Battle of Lesnaya">
Battle of Lesnaya

The Battle of Lesnaya ( "Bitva pri Lesnoy", ), was one of the major battles of the Great Northern War. It took place on September 28, 1708 (O.S.) / September 29, 1708 (Swedish calendar) / October 9, 1708 (N.S.) between a Russian army of between 26,500 and 29,000 men commanded by Peter I of Russia, Mikhail Mikhailovich Golitsyn, Aleksandr Danilovich Menshikov, Christian Felix Bauer and Nikolai Grigorovitj von Werden and a Swedish army of about 12,500 men commanded by Adam Ludwig Lewenhaupt and Berndt Otto Stackelberg, at the village of Lesnaya, located close to the border between the Polish–Lithuanian Commonwealth and Russia (now the village of Lyasnaya, south-east of Mogilev in Belarus). The Swedes were escorting a supply column of more than 4,500 wagons for their main army in Ukraine.
Peter I intercepted Lewenhaupt's column before it reached the safety of Charles XII, the Swedish king, with the intention of destroying it. After eight hours of fighting, with heavy casualties, neither side stood as winner. As the night approached the Russians decided to withdraw to the nearest forest where they would stay until next morning to continue the fight. The Swedes however stayed in their battle formations for hours during the night, in case of a renewed attack. With no sign of further combat and intelligence saying further Russian reinforcements had arrived, the Swedes in turn withdrew from the place of battle, in order to continue the march towards the main army. Fearing a full-scale Russian pursuit, Lewenhaupt decided to burn or abandon most of the wagons and cannons in order to increase speed. While doing this many of the Swedish soldiers decided to loot the abandoned wagons and get drunk, thousands got lost in the woods, many of whom fell victim to Russian irregular cavalry. Lewenhaupt soon crossed the river of Sozh with the rest of his army, to find himself relatively safe. After some days he met up with Charles XII at Rukova with very few wagons left and only half of his initial army. The two soon continued their march towards Ukraine, eventually finding themselves at the battle of Poltava and the surrender at Perevolochna which severely crippled the Swedish army and is known for being the turning point of the war.
Background.
In 1700 Sweden, under Charles XII, was attacked by a coalition of Saxony, Russia, and Denmark–Norway. Saxony, under Augustus II, invaded Swedish Livonia and quickly attacked the city of Riga. Meanwhile, Denmark–Norway under Frederick IV of Denmark attacked the Swedish allied duchies of Holstein and Gottorp in order to secure his rear, before commencing with the planned invasion of Scania, which had been previously annexed by Sweden in the Treaty of Roskilde in 1658. A short time later, Russia under Peter I swept into Swedish Ingria and besieged the strategic city of Narva. Unprepared for these developments, the Swedes were forced into a war on three fronts.
Denmark–Norway was quickly knocked out of the war by a bold Swedish landing on Humlebæk resulting in the Peace of Travendal. After this the Russians were forced to abandon their campaign in Ingria after their crushing defeat in the battle of Narva. The Swedes next beat the Saxons, Poles and Russians at the battle of Düna. Soon Sweden invaded the Polish-Lithuanian Commonwealth in order to remove Agustus from the Polish throne. The subsequent conflict became known as the Swedish invasion of Poland. After several defeats in the battles of Kliszów, Kraków, Pultusk and Toruń, Agustus was finally dethroned in favor of a monarch installed by the Swedes, Stanisław Leszczyński who was crowned king in 1705. During this time, the Russians had been able to capture several Swedish possessions in their Baltic Dominions, among others, the fortresses of Nöteborg, Nyenskans, Dorpat and Narva.
In 1705 the two sides prepared for a final confrontation in the Polish-Lithuanian Commonwealth, the Russians intervened with full force in order to put Agustus back on the throne. After the battles of Gemauerthof, Warsaw, Grodno and Fraustadt the campaign was decided in favor of the Swedes who chased their enemies out of Poland in 1706 and subsequently invaded Saxony, where Agustus saw himself defeated and forced to make peace. Seeing how only one major threat remained, the Swedes decided to invade Russia in 1707. After some time of fighting against the Russians under Peter I, the Swedish king soon called upon reinforcements from Livonia where Adam Ludwig Lewenhaupt was acting Commander-in-chief.
Prelude.
In early April 1708, the governor of Riga, Adam Ludwig Lewenhaupt visited Charles XII at the Royal army's winter quarters in Radoszkowice to discuss strategy and receive orders for the ongoing campaign against Russia. Here he was instructed to obtain a large amount of supplies and wagons that could be sufficient for the main army for about three weeks. Once having collected the supplies Lewenhaupt would assemble as much men as possible from the area, without leaving the garrisons completely stripped. Lewenhaupt would then use these troops to escort the convoy and rendezvous with Charles' main army at Mogilev, in early August.
In May same year, Lewenhaupt returned to Riga in order to complete the task, which proved far from easy. The near lands had suffered many campaigns in the years of the Great Northern War and so much was drained of needed resources. In early June, the column—of which Lewenhaupt was gathering—was ordered to start campaigning to reach Charles XII in Mogilev, according to schedule. However, the convoy was nowhere ready to leave because of the difficulties assembling it. Only in the beginning of July it was "ready", having then suffered three to four weeks behind the schedule and a significant shortage of men as 20,000 men were expected, but only 13,000 soldiers proved able to march.
Lewenhaupt's convoy.
The march turned out slower than expected, torrential rain turned the roads into mud, streams became over flooded which turned out to be a major task to cross and so, unfortunately for Lewenhaupt and Charles, the expected time of arrival kept moving back. However, after several weeks of waiting and no words heard from Lewenhaupt, there was a twist to the plans as Charles found his position in Mogilev unsustainable and instead on September 26, decided to abandon his camps and march South towards Severia in Ukraine, hoping to reach that rich granary before winter. During this time Lewenhaupt was about 135 kilometers (90 miles) away from Charles and on September 28, he received new orders to rendezvous at Starodub and started marching south himself. His convoy passed between Mogilev and Gorki heading for Propoisk on the river Sozh. By October 3, Lewenhaupt had crossed the Dnieper and headed south, the crossing itself has to be considered a "military masterpiece". Having observed these movements, Peter I dispatched an army under Boris Sheremetev after Charles and gathered a force of his own to intercept with Lewenhaupt. The Russians made contact with Lewenhaupt's convoy on October 6, and immediately started harassing it, forcing the Swedes to march in defensive formation across difficult terrain while the numbers of shadowing Russian troops steady grew.
Peter I, who overestimated the Swedish force being 16,000 men strong, had gathered numbers far superior to those of Lewenhaupt and was eager to catch his convoy while it was still out of reach of Charles' main army and safety. He planned to destroy the convoy before its crossing of the river Sozh where it would otherwise reach—as Peter thought—the protection of the main army (the Russians had misleading reports saying Charles was 25 kilometers away from Sozh and not 120 as they had previously presumed). On October 7, the Russians in the area were large enough that they posed a considerable threat to the convoy and so the two sides confronted each other for some time at the village of Belitsa. Subsequently however, Lewenhaupt ordered a cavalry attack consisting of 4,000 men on the equally numbered Russian dragoons who were facing them, the Russian horse did not desire a fight and instead started retreating, persecuted by their enemies for a good four–kilometers step. In this encounter losses amounted to more than 40 Russians killed and three to eleven captured, to four wounded Swedes, a real battle did not develop as both sides parted and the confrontation ended with the quick cavalry skirmish. The Swedes however, received intelligence from the captured Russians saying the Tsar was following Lewenhaupt with a force of about 20,000 cavalry, 12,000 infantry and four guns. Later during the day, the vanguard of the convoy reached the small village of Lesnaya and there made preparations to set camp for the rest of the army, accordingly.
The next morning, Lewenhaupt, who during this time stayed with his rearguard, would once again find himself confronted as the Russians stepped up their efforts to harass the back of the convoy as it made its crossing over at Dolgij Moch, towards Lesnaya. Here the Russians under Mikhail Golitsyn and Alexander Menshikov attacked him on two fronts over the river of Resta. The engagement concluded in a standoff after four hours of musket and artillery exchange in which the Swedes successfully denied every attempt made by the Russians to cross the river for the convoy. Later the same day, Lewenhaupt reached the village of Lesnaya with most of his army and was within a day's march from Propoisk. By now he knew that Peter I was in the area with a fairly large amount of Russian troops. But he did not know exactly how large the Russian army was or if more units were on their way. Once he reached Propoisk he could cross the Sozh river and achieve relative safety in case he was the target of the whole Russian force.
Battle.
On October 9, the Russians gathered all their available forces to attack the Swedes in the rear as they were crossing the stream of Lesnjanka at the village of Lesnaya, to march south against Propoisk in order to reach safety by crossing the river of Sozh. Thousands of wagons made for slow progress and bottlenecks and the scattered Swedish army was by then very vulnerable to Russian attacks. Furthermore, Bauer put a small detachment of 1,000 dragoons along with a portion of irregular troops at Propoisk to further stall the Swedish advance. The Swedish vanguard of 800 men soon stumbled upon this unit which did not hesitate to open fire. The sudden engagement put a halt to the Swedish convoy with its vanguard put in slight confusion as there was uncertainty regarding the size or position of the Russians at Propoisk. Decision was made to await orders from Lewenhaupt before committing to any course of action. In the meantime, Peter I took the advantage and pressed home the assault, marching with the majority of his troops towards Lesnaya and the rest of the Swedish convoy deployed there (at least one third of the convoy still remained at Lesnaya). Unaware of these developments, the Swedes were put in–between two forces, with an enemy no longer contented with harassment, but a decisive battle.
Opposing forces.
The Swedish army was commanded by General Lewenhaupt with Berndt Otto Stackelberg assisting, it totaled around 12,500 men with 6 eight–pounder and 10 or 11 four–pounder guns. Of these, at least 2,900 men were ordered to protect and maintain the baggage convoy consisting of at least 4,500 wagons. This resulted in a reduced force of combat personal as the regiments had to be stripped on men. The exact location of the troops at the start of the battle is not certain, however, between 4,500 and 7,000 men remained on the north side of the Lesnjanka stream facing the Russian main army. About 900 of these were detached even further to the north at "the Middlefield" working as an outpost in order to stall possible Russian attacks. The rest of the army were on the other side of the stream towards the south, facing Propoisk and would intervene in the battle later as Lewenhaupt requested reinforcements.
The Russian army was commanded by Tsar Peter I and consisted of three divisions under generals Mikhail Mikhailovich Golitsyn, Aleksandr Menshikov, Christian Felix Bauer and Nikolai Grigorovitj von Werden. In an operational stance, the army totaled between 26,500 and 29,000 men, including between 2,500 and 5,000 irregulars (Cossacks and Kalmyks, also referred to as "light cavalry"), or 900 to 10,000 according to other estimates, and more than 90 artillery pieces (30 cannons and 60 six–pounder mortars). However, the division under Werden would only enjoy limited to no engagement as these troops arrived at the end of the battle. The intention of Peter I was to attack Lewenhaupt with 13,000 regular soldiers along with thousands of irregulars initially available, in order to pin him down long enough for the rest of the army to arrive. The closest division available was that of Bauer at Berezovka who marched with about 4,976 men along with thousands of irregulars, about 900 of these had been detached at Propoisk and were the ones halting the Swedish vanguard as it tried to reach the town, the rest would find themselves at the battle–site later on during the day. The last division marching towards the battle was located at Patskovo, led by Werden and consisted of about 6,191 men, however, as previously noted, these would only take limited part in the action.
Peter I initially split his 13,000 men into two columns, the western one consisting of 5,910 men under himself with Mikhail Mikhailovich Golitsyn assisting (in reality, Golitsyn commanded this group and Peter I worked as his assistant) and the eastern one with 7,040 soldiers lead by Aleksandr Menshikov. The two columns along with the irregulars, marched toward "the Middlefield" between the northern and southern forest fringes. Lewenhaupt's army was behind the southern fringe and Peter I attacked from the north. Menshikov's force traversed two kilometers of road while Peter I struggled to penetrate three kilometers of dense forest.
Fighting at the Middlefield.
Around 11:00, the battle began. Peter I's column under Menshikov had reached the "Middlefield" from the north-west, finding the 900 Swedes deployed there. Unfortunately for Menshikov, the commander of the heavily outnumbered Swedish outpost, Lieutenant Colonel Freijbourg, seized the initiative and launched a "Carolean-style" surprise attack which threw the Russian column into confusion, while the sudden musket and cannon fire alerted the nearby main Swedish force. After this initial success, the Swedes were forced to retreat with many wounded through the southern fringe of the forest, where they were relieved by five fresh battalions under the command of Berndt Otto Stackelberg which had marched from Lesnaya.
Meanwhile, Tsar Peter's right column had reached the Crossroads and traversed the marshes of Krivl, just south of the "Middlefield", close to where Menshikov's column had been in action. Having Peter to their left flank and Menshikov to the front, Stackelberg's five Swedish battalions were now fighting two Russian columns numbering 13,000 in all. Six other Swedish battalions were on their way to the battle zone. The Russians at the Crossroads under Peter were almost routed by the Swedes and could have faced a crushing defeat, had not the Russian Guards halted their advance. The fighting at the Crossroads surged back and forth. The Russian line was strengthened by six artillery pieces. However, the Swedes who themselves had no artillery in this particular fight, were able to capture four of them and block Peter's progress at the Krivl bridge.
Facing the Swedish right flank at the "Middlefield", Menshikov's guardsmen then executed a successful flanking maneuver, forcing the five Swedish battalions to retreat into the southern fringe of the forest and prepare to receive the expected Russian onslaught. Their departure left unguarded a bridge near the "Crossroads", leaving it clear for Russian troops to march out and form up "en masse". Thus trapped in a "pincer movement", hemmed in and outnumbered, Stackelberg—against the wishes of Lewenhaupt—ordered an orderly withdrawal. The six Swedish battalions which were yet to arrive on their march through the forest, were also ordered to retreat, an action which isolated and exposed Hälsinge's second battalion which had previously routed the Russians and now came close to being annihilated by them.
Lewenhaupt (who sought to gather his cavalry to support the Swedish infantry during the fighting at the "Middlefield" and "Crossroads") came under attack by Russian dragoons who swept eastward through the southern fringe of the forest and headed for the Swedish dragoons deployed east of Lesnaya, on the open field. The Russians had some success at first, but as soon as the main bulk of the Swedish cavalry arrived and charged in typical Carolean wedge formation the Russian cavalry was being repulsed and quickly broke.
Tsar Peter with his Russian infantry and dragoons had now pushed away the last retreating Swedes and had full control over the "southern forest edge". The Russians now strove to reach the "Lesnaya field" between the forest and the village of Lesnaya, to block the bridge over which the Swedes might obtain further reinforcements. (A company of 1,000 cavalry had already managed to get back to assist in the fight at Lesnaya.) A Swedish counter-offensive to push the Russians out of the forest was now ordered by Lewenhaupt, who had been very disappointed by Stackelberg's decision to retreat. The Swedes counter–attacked with the support of 16 artillery pieces from Lesnaya. However the Russian troops, backed by their own 30 cannons, were too strong and the Swedes had to fall back.
Fighting at Lesnaya.
The Swedes retreated almost to the village of Lesnaya and the Russians followed them to the adjacent open terrain, intending to launch a decisive attack from there. However, both sides being exhausted by the day's intense combat, hostilities were ceased at about 15:00 when, separated by only 150–200 meters, the two sides sank down on the field, facing each other, and rested. During this extraordinary interlude, in which only three Russian cannons sounded off, the two armies distributed food, water and ammunition to their ranks, issued orders and deployed reinforcements in preparation for the final conflict. Somehow during this remarkable phase, the Russian General Friedrich von Hessen-Darmstadt was shot and mortally wounded as he rode back and forth in a provocative manner between the two armies. He died of his wounds four days later. The hour-long pause concluded at about 16:00, with the arrival, after a long march, of Bauer's company of 4,000 Russian dragoons.
At a little past 16:00, the Swedes opened fire, with cannons positioned 600 meters from the southern forest edge, on the newly arrived dragoons, who were then attaching themselves to the Russians' left flank. The Russian dragoons under Bauer then—without awaiting orders from Peter I—charged against the Swedes, supported by most of the other Russian troops. The open terrain gave the Swedish army opportunity to closely coordinate its infantry and cavalry, an advantage which they gratefully seized. Repeatedly, Russian front line troops retreated from infantry "Gå–På" shock attacks only to find themselves under immediate attack from the rear by Swedish cavalry. However, this could only be a temporary advantage in view of the Russian reserve strength, reportedly three battalions deep by this time, enabling an irresistible grinding advance.
The Russian right flank under Mikhail Mikhailovich Golitsyn moved to secure the sole bridge across the Lesnjanka in order to prevent the flow of Swedish reinforcements across it, while seeking to trap them with their backs to the river. However, the bridge was ferociously defended and the Russians were beaten off, suffering heavy losses. At this time, both sides were inconvenienced by a snowstorm, a rare event for early–October, even in Russia. At 17:00, Lewenhaupt ordered a concerted attack which, however, was blunted by a tactic of continuous fire which the Russians had devised to counter the Swedish "Gå–På" onslaught. The Swedes took heavy casualties and were driven further back towards the village. Their line was also split in two, one side against the Lesnaya (east of the bridge) and the other against the forest to the west. The all–important bridge was on the brink of being taken when it was saved by the arrival of 900 Swedish dragoons from across the river, whose fierce onslaught drove the Russians back. At 19:00 when night fell, the Russians left the field and drew back to the forest fringe. The Swedes stood in their battle formations for several hours, expecting a night attack which did not come.
Aftermath.
For a few hours the Swedes remained in their positions in case of a renewed attack and to convince the Russians that they intended to stay. Subsequently Lewenhaupt decided to withdraw his army under the cover of the darkness and continue on his march against Propoisk. One major reason for this decision is said to have been a report coming from a captured Russian officer speaking about recent Russian reinforcements consisting of up to 10,000 men referring to the more than 6,000 strong infantry division under Nikolai Grigorovitj von Werden. Each unit slowly made its way across the stream as they were covered by the remaining units. During this progress, a number of wagons broke and partially blocked the road where the Swedish artillery was moving down, so it was decided a number of these would be sunk in the mud (to prevent them falling in Russian hands) as they were hard bringing in the rapid march. Having successfully crossed the stream with all his troops, Lewenhaupt continued towards Propoisk. However, this withdrawal was the beginning of the end for a large part of his army.
Swedish disaster.
Despite the difficult condition, having men lost in the woods during the march, the Swedes reached Propoisk, only to find that the town and bridge had been burned down. This was most likely done by Bauer's detachment as they were still blocking the crossing. By now the Swedish army was disintegrating into a mob as fear grew, possibly of being trapped between Peter's army behind them and Bauer's detachment. There were also no suited material for building a bridge. The Swedes saw the risk in having the Russian army pursue them from behind and so Lewenhaupt decided that everything that could be carried be taken from the wagons, subsequently all wagons but a few, were burned and the bulk of the essential supplies within. This resulted in that a large part of the army took the opportunity to get drunk and so was left for the enemy to catch, others decided that they were better off surrendering or try to reach home by themselves. The Swedes mustered about 3,451 infantry and 3,052 cavalry at Propoisk who were in good condition to fight. Lewenhaupt decided that all the combatants would be mounted on the remaining horses to increase the speed of the march. Between 1,000 and 1,500 wounded and sick soldiers were left at Propoisk as these seemed unable to follow the pace Lewenhaupt now made in order to reach the main army. The rest were missing, perhaps as many as 4,000 men. The next morning the Russians caught up with the soldiers at Propoisk which had now increased to 3,000 men as more stragglers had joined its defenses. The Russians demanded their surrender, however as the Swedes refused and instead answered with musket fire, they soon assaulted the town. After an hour or so long defense, the Russians gained the upper hand and pushed the Swedes out of the town, further to the river of Soz, where they could escape the onslaught. The Russians were content with this and proceeded to round up any deserters they could find, however, they did not attempt to confront the main body of Lewenhaupt's army as they were allowed to withdraw unmolested.
The following day Lewenhaupt found a crossing over the river Sozh and over the next two days the soldiers swam across the river to relative safety. By now order had been restored in the Swedish army and all signs of Russian pursuit had gone. The army—now without any artillery or wagon train—made good speed to reach its rendezvous with Charles' army at Starodub. During their way, on October 19, the Swedish rearguard was attacked by reportedly 4,000 Russians at the village of Lysjtjitji. After a sharp engagement the Russians were driven off with the cost of slightly more than 30 killed and 50 wounded Swedes. On October 23, Lewenhaupt's troops reached the main army at Rukova. Having only 6,000 men left in his lines with very few of the sufficient wagons, from the train. Subsequently, Charles XII continued the march towards Ukraine where he found the condition of supplying his army better but also because a possible alliance with the Cossack hetman, Ivan Mazepa. The campaign would however end with the disastrous Swedish defeat at Poltava and the surrender of the whole army at Perevolochna, except for a few who followed the king into exile in the Ottoman Empire.
Modern look.
Lesnaya is often seen as the first great Russian victory of the war and the first indication of the final result of the campaign, in Russia it is said to be the "mother of Poltava". The battle was certainly proclaimed as a Russian triumph at the time, but in modern view, this may not be the case. The victorious Russian army had suffered considerable losses throughout the battle and did not manage to succeed with their goal, to crush the Lewenhaupt's army. Neither did it seriously pursue the retreating Swedish army, instead they contented themselves with catching the stragglers and march in the opposite direction of Lewenhaupt to celebrate their victory. Tsar Peter arranged for the news of the victory to be spread as much as possibly through official declarations and leaflets. At first the Russian version of events claimed they had completely destroyed a superior force, it soon became clear that this was not true so they subsequently modified it down to only equal odds. But the official declarations, leaflets etc., had already been dispatched and still influence the view of the battle today.
The two sides were in fact not equal in numbers, they only appear so in many accounts because the numbers given usually only count the initial Russian forces under the Tsar without taking in account the irregulars that accompanied the force or the later arrival of Bauer's command. Sometimes the Swedish units are also assumed to have been at full strength at the battle. Also while the initial Russian forces were about the same strength as the whole Swedish army, they did not all participate in the fighting. The Russians, in fact enjoyed a considerable numerical advantage in all stages of the battle, yet they had not been able to defeat their enemy. Similarly the Swedes were greatly constrained during the battle by the need to protect the vital wagons and their supplies.
Casualties.
The estimated number of casualties sustained by both sides during the battle varies widely, depending on the source.
Swedish casualties, according to General Adam Ludwig Lewenhaupt, numbered not much more than 1,000 men during the battle itself, with a total of 1,674 dead and captured in the battle "and" on the road towards Propoisk. Overall, he claims, the casualties could not exceed 3,000 men in the battle "and" the following days (with the events at Propoisk), however, these figures are regarded as questionable and too low, according to the Swedish and Russian writers Einar Lyth and Pavel Konovalchuk. According to Lewenhaupt's Lieutenant, Friedrich Christoph von Weihe, the Swedish losses in killed amounted to 2,000 men in the battle along with a number of captured. In total, Weihe estimates that there were 3,800 Swedish casualties in the battle "and" in the following days. Robert Petre, a second-lieutenant in the Swedish army and veteran soldier in the Hälsinge regiment, however, puts the total Swedish casualties at 4,549 men. According to the Russian official description regarding the Swedish casualties, 8,000 were killed on the battlefield and a total of 3,500 captured soon thereafter, other sources claim 6,700 Swedes killed and wounded in the battle and another 5,000 in the pursuit, numbers which are proven unrealistic and impossible in regards to the initial strength of the army.
Later attempts have been made by authors trying to calculate the Swedish casualties using the initial strength of the force as basis. Lewenhaupt said there were less than 10,914 men present under his command, Weihe and Petre in turn claimed there were 11,450 and 12,950 men, respectively, at the beginning of the march from Riga in early July. Nicholas Dorrell, a student in history, estimates the Swedish force at about 12,500 men strong in the battle, in an attempt to apply "marching losses" to the army. In regards to this, 6,500 Swedes were patterned after the battle in ""condition to fight"" at Propoisk, according to Petre (of which above 6,000 made it to the main army under Charles XII), about 1,000–1,500 wounded and sick Swedish soldiers along with some stragglers were left at Propoisk, of which the majority were later either killed or captured by Russian cavalry, according to Russian sources. Between 2,500 and 3,300 soldiers went missing, of which most marched on their own back towards Sweden, between 1,250 and 1,500 of these arrived and the other perished during the march due to wounds, sickness, starvation or exhaustion, or possible Cossack attacks.
Einar Lyth and Pavel Konovalchuk make an estimation calculated out of these numbers in their book ""Vägen till Poltava. Slaget vid Lesnaja 1708 (The road to Poltava. The battle of Lesnaya 1708)"" using the initial strength presented by Petre of 13,000 men, which concludes up to 4,000 Swedes killed, captured or dispersed in total, during the battle and the days after and no more than 2,500 men killed or captured in the battle itself. Using the same calculation on the number of 12,500 Swedes presented by Dorrell, the total losses would amount to 3,500 men and 2,000 in the battle "and" on the road towards Propoisk (similar estimation to that of Weihe), applying a rough estimation of 1,000–1,500 wounded to this number, representing the large numbers of wounded left at Propoisk and the ones being wounded while marching back towards Sweden, there's a possibility that the Swedes suffered 3,000–3,500 men dead, wounded and captured in the battle alone. Another estimation is made by the Russian historian Vladimir A. Artamonov in his book "“The Dawn of the Poltava Victory: The Battle of Lesnaya”", where the author estimates the Swedish casualties at 3,873 dead and wounded in the battle and another 877 captured afterwards, totaling losses of 4,750 Swedish soldiers, also here, using Petre's number of 12,950 Swedish soldiers as the basis for the calculation.
Russian casualties, according to Russian official claims, amounted to about 1,111 dead and another 2,856 wounded in the battle, figures which are disputed as "incomplete and contradictory", according to the Russian and Swedish writers Pavel Konovalchuk and Einar Lyth. Alexander Gordon, an officer of Scottish descent who served with the Russian army during the war, wrote a book on the history of Peter the Great, in which he puts the Russian casualties at about 3,000 killed and 4,000 wounded.
Swedish official reports declared that more than 20,000 Russians died in the battle, which is considered to be a highly unlikely number by most authors. Lewenhaupt initially estimated more than 6,000 dead and wounded Russians during the battle, but later increased that number to 9,000 dead and wounded, claiming that this estimate was reported to him by Russian officers, while he was in captivity in Moscow. Artamonov questions the reliability of this claim. Another Swedish source, Gustaf Adlerfelt, a court historian of Charles XII, declared that the Russians lost 6,000 men killed and many more wounded, referring to the "confession" of a captured Russian Adjutant-General named Schultz.

</doc>
<doc id="48757" url="https://en.wikipedia.org/wiki?curid=48757" title="Great Northern War">
Great Northern War

The Great Northern War (1700–1721) was a conflict in which a coalition led by the Tsardom of Russia successfully contested the supremacy of the Swedish Empire in Central, Northern, and Eastern Europe. The initial leaders of the anti-Swedish alliance were Peter the Great of Russia, Frederick IV of Denmark–Norway and Augustus II the Strong of Saxony-Poland. Frederick IV and Augustus II were forced out of the alliance in 1700 and 1706 respectively, but rejoined it in 1709. George I of Brunswick-Lüneburg (Hanover) joined the coalition in 1714 for Hanover and in 1717 for Britain, and Frederick William I of Brandenburg-Prussia joined it in 1715.
Charles XII led the Swedish army. On the Swedish side were Holstein-Gottorp, several Polish magnates under Stanisław I Leszczyński (1704–10) and Cossacks under the Ukrainian Hetman Ivan Mazepa (1708–10). The Ottoman Empire temporarily hosted Charles XII of Sweden and intervened against Peter I.
The war started when an alliance of Denmark–Norway, Saxony, Poland and Russia declared war on the Swedish Empire, launching a threefold attack at Swedish Holstein-Gottorp, Swedish Livonia, and Swedish Ingria, sensing an opportunity as Sweden was ruled by the young Charles XII, who was eighteen years old and inexperienced. Sweden parried the Danish and Russian attacks at Travendal and Narva, and in a counter-offensive pushed Augustus II's forces through the Polish-Lithuanian Commonwealth to Saxony, dethroning Augustus on the way and forcing him to acknowledge defeat in the Treaty of Altranstädt. The treaty also secured the extradition and execution of Johann Reinhold Patkul, architect of the alliance seven years earlier. Peter I had meanwhile recovered and gained ground in Sweden's Baltic provinces, where he cemented Russia's access to the Baltic Sea by founding Saint Petersburg in 1703. Charles XII moved from Saxony into Russia to confront Peter, but the campaign ended with the destruction of the main Swedish army at the decisive 1709 Battle of Poltava (in present-day Ukraine), and Charles' exile in Ottoman Bender. The Ottoman Empire defeated the Russian-Moldavian army in the Pruth River Campaign, but the peace treaty was in the end without great consequence to Russia's position.
After Poltava, the anti-Swedish coalition was re-established and subsequently joined by Hanover and Prussia. The remaining Swedish forces in plague-stricken areas south and east of the Baltic Sea were evicted, with the last city, Riga, falling in 1710. Most of the Swedish dominions were partitioned among the coalition members, destroying the Swedish "dominium maris baltici". Sweden proper was invaded from the west by Denmark–Norway and from the east by Russia, which had occupied Finland by 1714. The Danish forces were defeated. Charles XII opened up a Norwegian front, but was killed in Fredriksten in 1718.
The war ended with Sweden's defeat, leaving Russia as the new dominant power in the Baltic region and a major force in European politics. The Western Powers, Great Britain and France, were caught up in another conflict which embroiled over Philip of Anjou's succession into the Spanish Throne. The formal conclusion of the war was marked by the Swedish-Hanoverian and Swedish-Prussian Treaties of Stockholm (1719), the Dano-Swedish Treaty of Frederiksborg (1720), and the Russo-Swedish Treaty of Nystad (1721). Therein, Sweden ceded her exemption from the Sound Dues, and lost the Baltic provinces and the southern part of Swedish Pomerania. The peace treaties also ended her alliance with Holstein-Gottorp. Hanover gained Bremen-Verden, Brandenburg-Prussia incorporated the Oder estuary (Stettin Lagoons), Russia secured the Baltic provinces, and Denmark strengthened her position in Schleswig-Holstein. In Sweden, the absolute monarchy had come to an end with the death of Charles XII, and the Age of Liberty began.
Background.
Between 1560 and 1658, Sweden created a Baltic empire centred on the Gulf of Finland and comprising the provinces of Karelia, Ingria, Estonia, and Livonia. During the Thirty Years' War Sweden gained tracts in Germany as well, including Western Pomerania, Wismar, the Duchy of Bremen, and Verden. During the same period Sweden conquered Danish and Norwegian provinces north of the Sound (1645; 1658). These victories may be ascribed to a well-trained army, which despite its comparatively small size, was far more professional than most continental armies, and also to a modernization of administration (both civilian and military) in the course of the 17th century which enabled the monarchy to harness the resources of the country and its empire in an effective way. Fighting in the field, the Swedish army (which during the Thirty Years' War contained more German and Scottish mercenaries than ethnic Swedes, but was administered by the Swedish Crown) was able, in particular, to make quick, sustained marches across large tracts of land and to maintain a high rate of small arms fire due to proficient military drill.
However, the Swedish state ultimately proved unable to support and maintain its army in a prolonged war. Campaigns on the continent had been proposed on the basis that the army would be financially self-supporting through plunder and taxation of newly gained land, a concept shared by most major powers of the period. The cost of the warfare proved to be much higher than the occupied countries could fund, and Sweden's coffers, and resources in manpower, were eventually drained in the course of long conflicts.
The foreign interventions in Russia during the Time of Troubles resulted in Swedish gains in the Treaty of Stolbovo (1617). The treaty deprived Russia of direct access to the Baltic Sea. Russian fortunes began to reverse in the final years of the 17th century, notably with the rise to power of Peter the Great, who looked to address the earlier losses and re-establish a Baltic presence. In the late 1690s, the adventurer Johann Patkul managed to ally Russia with Denmark and Saxony by the secret Treaty of Preobrazhenskoye and in 1700 the three powers attacked.
Opposing parties.
Swedish camp.
Charles XII of Sweden succeeded Charles XI of Sweden in 1697, aged 14. From his predecessor, he took over the Swedish Empire as an absolute monarch. Charles XI had tried to keep the empire out of wars, and concentrated on inner reforms such as reduction and allotment, which had strengthened the monarch's status and the empire's military abilities. Charles XII refrained from all kinds of luxury and alcohol and usage of the French language, since he considered these things decadent and superfluous. He preferred the life of an ordinary soldier on horseback, not that of contemporary baroque courts. He determinedly pursued his goal of dethroning his adversaries, whom he considered unworthy of their thrones due to broken promises, thereby refusing to take several chances to make peace. During the war, the most important Swedish commanders besides Charles XII were his close friend Carl Gustav Rehnskiöld, also Magnus Stenbock and Adam Ludwig Lewenhaupt.
Charles Frederick, son of Frederick IV, Duke of Holstein-Gottorp (a cousin of Charles XII) and Hedvig Sophia, daughter of Charles XI of Sweden, had been the Swedish heir since 1702. He claimed the throne upon Charles XII's death, but was supplanted by Ulrike Eleonora. Charles Frederick was married to a daughter of Peter I, Anna Petrovna.
Ivan Mazepa was a Ukrainian Cossack hetman who fought for Russia but defected to Charles XII in 1708. Mazepa died in 1710 in Ottoman exile.
Allied camp.
Peter the Great became Tsar in 1682 upon the death of his elder brother Feodor but did not become the actual ruler until 1689. He commenced reforming the country, turning the Russian tsardom into a modernized empire relying on trade and on a strong, professional army and navy. He greatly expanded the size of Russia during his reign while providing access to the Baltic, Black, and Caspian seas. Beside Peter, the principal Russian commanders were Aleksandr Danilovich Menshikov and Boris Sheremetev.
Augustus II the Strong, elector of Saxony and another cousin of Charles XII, gained the Polish crown after the death of King John III Sobieski in 1696. His ambitions to transform the Polish–Lithuanian Commonwealth into an absolute monarchy were not realized due to the zealous nature of the Polish nobility and the previously initiated laws that decreased the power of the monarch. His meeting with Peter the Great in Rawa Ruska in September 1698, where the plans to attack Sweden were made, became legendary for its decadence.
Frederick IV of Denmark-Norway, another cousin of Charles XII, succeeded Christian V in 1699 and continued his anti-Swedish policies. After the setbacks of 1700, he focused on transforming his state, an absolute monarchy, in a manner similar to Charles XI of Sweden. He did not achieve his main goal: to regain the former eastern Danish provinces lost to Sweden in the course of the 17th century. He was not able to keep northern Swedish Pomerania, Danish from 1715 to 1720. He did put an end to the Swedish threat south of Denmark. He ended Sweden's exemption from the Sound Dues (transit taxes/tariffs on cargo moved between the North Sea and the Baltic Sea).
Frederick William I entered the war as elector of Brandenburg and king in Prussia – the royal title had been secured in 1701. He was determined to gain the Oder estuary with its access to the Baltic Sea for the Brandenburgian core areas, which had been a state goal for centuries.
George I of the House of Hanover, elector of Brunswick-Lüneburg and, since 1714, king of Great Britain and of Ireland, took the opportunity to connect his landlocked German electorate to the North Sea.
Army size.
In 1700, Charles XII had a standing army of 77,000 men (based on annual training). By 1707 this number had swollen to at least 120,000 despite casualties.
Russia was able to mobilize a larger army, but could not put all of it into action simultaneously. The Russian mobilization system was ineffective and the expanding nation needed to be defended in many locations. A grand mobilization covering Russia's vast territories would have been unrealistic. Peter I tried to raise his army's morale to Swedish levels. Denmark contributed 20,000 men in their invasion of Holstein-Gottorp and more on other fronts. Poland and Saxony together could mobilize at least 100,000 men.
1700: Denmark, Riga and Narva.
Frederik IV of Denmark–Norway directed his first attack against Sweden's ally Holstein-Gottorp. In March 1700, a Danish army laid siege to Tönning. Simultaneously, Augustus II's forces advanced through Swedish Livonia, captured Dünamünde and laid siege to Riga.
Charles XII of Sweden first focused on attacking Denmark. The Swedish navy was able to outmaneuver the Danish Sound blockade and deploy an army near the Danish capital, Copenhagen. At the same time, a combined British-Dutch fleet had also set course towards Denmark. Together with the Swedish fleet, they carried out a bombardment of Copenhagen from 20–26 July. This surprise move and pressure by the Maritime Powers (England and the Dutch Republic) forced Denmark–Norway to withdraw from the war in August 1700 according to the terms of the Peace of Travendal.
Charles XII was now able to speedily deploy his army to the eastern coast of the Baltic Sea and face his remaining enemies: besides the army of Augustus II in Livonia, an army of Russian tsar Peter I was already on its way to invade Swedish Ingria, where it laid siege to Narva in October. In November, the Russian and Swedish armies met at the First Battle of Narva where the Russians suffered a crushing defeat.
After the dissolution of the first coalition through the peace of Travendal and with the victory at Narva; the Swedish chancellor, Benedict Oxenstjerna, attempted to use the bidding for the favour of Sweden by France and the Maritime Powers (then on the eve of the War of the Spanish Succession) to end the war and make Charles an arbiter of Europe.
1701–1706: Poland-Lithuania and Saxony.
Charles XII then turned south to meet his last undefeated opponent: Augustus II, Elector of Saxony, King of Poland and Grand Duke of Lithuania. The Polish-Lithuanian Commonwealth was formally neutral at this point, as Augustus started the war as an Elector of Saxony. Disregarding Polish negotiation proposals supported by the Swedish parliament, Charles crossed into the Commonwealth and decisively defeated the Saxe-Polish forces in the Battle of Klissow in 1702 and in the Battle of Pultusk in 1703. This successful invasion enabled Charles XII to dethrone Augustus II and coerce the Polish sejm to replace him with Stanisław I Leszczyński in 1704. August II resisted, still possessing control of his native Saxony, but was decisively defeated at the Battle of Fraustadt in 1706, a battle sometimes compared to the Ancient Battle of Cannae due to the Swedish forces' use of double envelopment, with a deadly result for the Saxon army. August II was forced to sign the Treaty of Altranstädt in 1706 in which he made peace with the Swedish Empire, renounced his claims to the Polish crown, accepted Stanisław Leszczyński as king, and ended his alliance with Russia. Patkul was also extradited and executed by breaking on the wheel in 1707, an incident which given his diplomatic immunity, infuriated opinion against the Swedish king, who then was expected to win the war against the only hostile power remaining, Tsar Peter's Russia.
1702–1710: Russia and the Baltic provinces.
The Battle of Narva dealt a severe setback to Peter the Great, but the shift of Charles XII's army to the Polish-Saxon threat soon afterwards, provided him with an opportunity to regroup and regain territory in the Baltic provinces. Russian victories at Erastfer and Nöteborg (Shlisselburg) provided access to Ingria in 1703, where Peter captured the Swedish fortress of Nyen, guarding the mouth of the River Neva. Thanks to General Adam Ludwig Lewenhaupt, whose outnumbered forces fended the Russians off in the battles of Gemäuerthof and Jakobstadt, Sweden was able to maintain control of most of her Baltic provinces. Before going to war, Peter had made preparations for a navy and a modern-style army, based primarily on infantry drilled in the use of firearms.
The Nyen fortress was soon abandoned and demolished by Peter, who constructed nearby a superior fortress as a beginning to the city of Saint Petersburg. By 1704, other fortresses were situated on the island of Kotlin and the sand flats to its south. These became known as Kronstadt and Kronslot. The Swedes attempted a raid on the Neva fort on 13 July 1704 with ships and landing forces, but the Russian fortifications held. In 1705, repeated Swedish attacks were made against Russian fortifications in the area, to little effect. A major assault on 15 July 1705 resulted in the deaths of more than a third of a 1,500-strong Swedish landing force.
In view of continued failure to check Russian consolidation, and with declining manpower, Sweden opted to blockade Saint Petersburg in 1705. In the summer of 1706, Swedish General Georg Johan Maidel crossed the Neva with 4000 troops and defeated an opposing Russian force, but made no move on Saint Petersburg. Later in the autumn Peter I led an army of 20,000 men in an attempt to take the Swedish town and fortress of Viborg. However, bad roads proved impassable to his heavy siege guns. The troops, who arrived on 12 October, therefore had to abandon the siege after only a few days. On 12 May 1708, a Russian galley fleet made a lightning raid on Borgå and managed to return to Kronslot just one day before the Swedish battlefleet returned to the blockade, after being delayed by unfavourable winds.
In August 1708, a Swedish army of 12,000 men under General Georg Henrik Lybecker attacked Ingria, crossing the Neva from the north. They met stubborn resistance, ran out of supplies and, after reaching the Gulf of Finland west of Kronstadt, had to be evacuated by sea between 10–17 October. Over 11,000 men were evacuated but more than 5000 horses were slaughtered, which crippled the mobility and offensive capability of the Swedish army in Finland for several years. Peter I took advantage of this, and was able to redeploy a large number of men from Ingria to the Ukraine.
Charles spent the years 1702–06 in a protracted struggle with August the Strong; he had already inflicted defeat on him at Riga in June 1701 and took Warsaw the following year, but trying to force a decisive defeat proved elusive. Russia withdraws from Poland in the Spring of 1706, abandoning their artillery but escape from the pursuing Swedes who stop at Pinsk. Charles wanted not just to defeat the Commonwealth army but to depose August (see above), whom he regarded as especially treasonous, and have him replaced with someone who would be a Swedish ally, and this goal proved hard to achieve. After years of marches and fighting around Poland he finally had to invade August's hereditary Saxony to bring him out of the war. In the treaty of Altranstädt (1706), August was indeed forced to step down from the Polish throne, but Charles had lost a valuable time advantage over his main enemy in the east, Peter I, who had had the time to recover and build up a new and better army.
At this point, in 1707, Peter offered to retrocede everything he had so far occupied (essentially Ingria) except Saint Petersburg and the line of the Neva, to avoid a full-scale war, but Charles XII refused. Instead he initiated a march from Saxony to invade Russia. Though his primary goal was Moscow, the strength of his forces was sapped by the cold weather (the winter of 1708/09 being one of the most severe in modern European history) and Peter's use of scorched earth tactics. When the main army turned south to recover in the Ukraine, the second army with supplies and reinforcements was intercepted and routed at Lesnaya—and so were the supplies and reinforcements of Swedish ally Ivan Mazepa in Baturyn. Charles was crushingly defeated by a larger Russian force under Peter in the Battle of Poltava and fled to the Ottoman Empire while the remains of his army surrendered at Perevolochna.
This shattering defeat in 1709 did not end the war, although it decided it. Denmark and Saxony joined the war again and Augustus the Strong, through the politics of Boris Kurakin, regained the Polish throne. Peter continued his campaigns in the Baltics, and eventually he built up a powerful navy. In 1710 the Russian forces captured Riga, at the time the most populated city in the Swedish realm, and Tallinn, evicting the Swedes from the Baltic provinces, now integrated in the Russian Empire by the capitulation of Estonia and Livonia.
Formation of a new anti-Swedish alliance.
After Poltava, Peter the Great and Augustus the Strong allied again in the Treaty of Thorn (1709); Frederick IV of Denmark-Norway with Augustus the Strong in the Treaty of Dresden (1709); and Russia with Denmark–Norway in the subsequent Treaty of Copenhagen. In the Treaty of Hanover (1710), Brunswick-Lüneburg (Hanover) whose elector was to become George I of Great Britain allied with Russia. In 1713, Brandenburg-Prussia allied with Russia in the Treaty of Schwedt. George I of Great Britain and Hanover concluded three alliances in 1715: the Treaty of Berlin with Denmark–Norway, the Treaty of Stettin with Brandenburg-Prussia, and the Treaty of Greifswald with Russia.
1709–1714: Ottoman Empire.
When his army surrendered, Charles XII of Sweden and a few soldiers escaped to Ottoman territory, founding a colony in front of Bender, Moldova. Peter I demanded Charles's eviction, and when the sultan refused, Peter decided to force it by invading the Ottoman Empire. Peter's army was trapped by an Ottoman army at the Pruth river. Peter managed to negotiate a retreat, making a few territorial concessions and promising to withdraw his forces from the Holy Roman Empire as well as allowing Charles's return to Sweden. These terms were laid out in the Treaty of Adrianople (1713). Charles showed no interest in returning, established a provisional court in his colony, and sought to persuade the sultan to engage in an Ottoman-Swedish assault on Russia. The sultan put an end to the generous hospitality granted and had the king arrested in what became known as the "kalabalik" in 1713. Charles was then confined at Timurtash and Demotika; later he abandoned his hopes for an Ottoman front and returned to Sweden in a 14-day ride.
1710–1716: Sweden and Northern Germany.
In 1710, the Swedish army in Poland retreated to Swedish Pomerania, pursued by the coalition. In 1711, siege was laid to Stralsund. Yet the town could not be taken due to the arrival of a Swedish relief army, which secured the Pomeranian pocket before turning west to defeat an allied army in the Battle of Gadebusch. Pursued by coalition forces, the Swedish army was trapped and surrendered in the Siege of Tönning.
In 1714, Charles XII returned from the Ottoman Empire, arriving in Stralsund in November. In nearby Greifswald, already lost to Sweden, Russian tsar Peter the Great and British king George I, in his position as Elector of Hanover, had just signed an alliance on 17 (OS)/28 (NS) October. Previously a formally neutral party in the Pomeranian campaigns, Brandenburg-Prussia openly joined the coalition by declaring war on Sweden in the summer of 1715. Charles was then at war with much of Northern Europe, and Stralsund was doomed. Charles remained there until December 1715, escaping only days before Stralsund fell. When Wismar surrendered in 1716, all of Sweden's Baltic and German possessions were lost.
1716–1718: Norway.
After Charles XII had returned from the Ottoman Empire and resumed personal control of the war effort, he initiated two Norwegian Campaigns, starting in February 1716, to force Denmark–Norway into a separate peace treaty. Furthermore, he attempted to bar Great Britain access to the Baltic Sea. In search for allies, Charles XII also negotiated with the British Jacobite party. This resulted in Great Britain declaring war on Sweden in 1717. The Norwegian campaigns were halted and the army withdrawn when Charles XII was shot dead while besieging Norwegian Fredriksten on 30 November 1718 (OS). He was succeeded by his sister, Ulrika Eleonora.
1710–1721: Finland.
War between Russia and Sweden continued to rage. After the disaster of Poltava in 1709, the shattered Swedish continental army could provide very little help. Russia captured Viborg (ru. Vyborg) in 1710 and successfully held it against Swedish attempts to retake the town in 1711. In 1712 started first Russian campaign to capture Finland under command of General Admiral Fyodor Apraksin. Apraksin gathered an army of 15,000 men to Vyborg and started the operation in late August. Swedish General Georg Henrik Lybecker chose not to face the Russians with his 7,500 men in the prepared positions close to Vyborg and instead withdrew west of Kymijoki river using scorched earth tactics. Apraksin's forces reached the river but chose not to cross it and instead withdrew back to Vyborg likely due to problems in supply. Swedish efforts to maintain their defences were greatly hampered by the drain of manpower by the continental army and various garrisons around the Baltic Sea as well as by the plague outbreak which struck Finland and Sweden between 1710–1713 which devastated the land killing amongst others over half of the population of Helsingfors (Helsinki).
After the failure of 1712 Peter the Great ordered that further campaigns in war ravaged regions of Finland with poor transportation network were to be performed along the coastline and the seaways near the coast. Alarmed by the Russian preparations Lybecker requested naval units to be brought in as soon as possible in the spring of 1713. However like so often Swedish naval units arrived only after the initial Russian spring campaign had ended. Nominally under command of Fyodor Apraksin, but accompanied by Peter the Great, fleet of coastal ships together with 12,000 men of infantry and artillery started the campaign by sailing from Kronstadt on 2 May 1713, further 4000 cavalry were later sent overland to join up with the army. The fleet had already arrived at Helsinki on 8 May and were met by 1,800 Swedish infantry under General Carl Gustaf Armfeldt. Together with rowers from the ships Russians had 20,000 men in their disposal even without the cavalry. Defenders, however, managed to fend off landing attempts by the attackers until Russians landed to their flank at Sandviken which forced Armfelt to retire towards Porvoo (Borgå) after setting afire both the town and all the supplies stored there as well as bridges leading north from the town. It was only on 12 May that Swedish squadron under Admiral Erik Johan Lillie made it to Helsinki but there was nothing it could do.
Following this bulk of the Russian forces moved along the coast towards Borgå towards the forces of Lybecker to whom Armfelt had joined. On 21–22 May 1713 Russian force of 10,000 men landed at Pernå (Pernaja) and constructed fortifications there. Large stores of supplies and munitions were transported from Vyborg and Saint Petersburg to the new base of operations. Russian cavalry managed to link up with the rest of the army there as well. Lybecker's army of 7000 infantry and 3000 cavalry avoided contact with the Russians and instead kept withdrawing further inland without even contesting the control of Borgå region or the important coastal road between Helsinki (Helsingfors) and Turku (Åbo). This also severed the contact between Swedish fleet and ground forces and prevented Swedish naval units from supplying it. Soldiers in the Swedish army who were mostly Finnish resented being repeatedly ordered to withdraw without even seeing the enemy. Lybecker was soon recalled to Stockholm for a hearing and Armfelt was ordered to the command of the army. Under Armfelt's command Swedish army in Finland stopped to engage the advancing Russians at Pälkäne in October 1713 where Russian flanking manoeuvre forced him to withdraw to avoid getting encircled. Armies met later again at Storkyro (Isokyrö) in February 1714 where Russians won a decisive victory.
In 1714 far greater Swedish naval assets were diverted towards Finland which managed to cut the coastal sea route past Hangö cape already in early May 1714. This caused severe trouble for Russian supply route to Turku and beyond as supplies had to be carried overland. Russian galley fleet arrived to the area already on 29 June but stayed idle until 26–27 July when under leadership of Peter Russian galleys managed to run the blockade making use of calm weather which immobilized the Swedish battlefleet losing only one galley of his force of roughly 100 galleys. Small hastily assembled Swedish coastal squadron met the Russian galley fleet west of Hanko (Hangö) cape in the battle of Gangut and was overpowered by the Russians who had nearly 10 fold superiority. Russian breach of the blockade at Hangö forced Swedish fleet to withdraw to prevent Russian galley fleet from reaching Sweden itself. The Russian army occupied Finland mostly in 1713–1714, capturing Åland from where population had already fled to Sweden on 13 August 1714. Since Russian galley fleet was not able to raid the Swedish coast, with exception of Umeå which was plundered on 18 September, fleet supported the advance of the Russian army which led to hastily withdrawal of the Swedish army from Raahe (Brahestad) to Tornio (Torneå). The occupation period of Finland in 1714–1721 is known as the Greater Wrath.
1719–1721: Sweden.
After the death of Charles XII, Sweden still refused to make peace with Russia on Peter's terms. Despite a continued Swedish naval presence and strong patrols to protect the coast since 1715 small Russian raids took place in 1716 at Öregrund while in July 1717 Russian squadron landed troops to Gotland who raided for supplies. To place pressure on Sweden, Russia sent a large fleet in July 1719 to the Swedish east coast. There under protection of the Russian battlefleet the Russian galley fleet was split into three groups. One group headed for coast of Uppland, second to the vicinity of Stockholm and last to coast of Södermanland. Together they carried a landing force of nearly 30,000 men. Raiding continued for a month and devastated amongst others the towns of Norrtälje, Södertälje, Nyköping and Norrköping and almost all buildings in the archipelago of Stockholm were burned. A smaller Russian force advanced on the Swedish capital, but was stopped at the battle of Stäket on 13 August. Swedish and British fleets, now allied with Sweden, sailing from the west coast of Sweden failed to catch the raiders.
Since treaty of Frederiksborg in early 1720 Sweden was no longer in war with Denmark which allowed more forces to be placed against the Russians. This did not prevent Russian galleys from raiding town of Umeå once again. Later in July 1720 a squadron from Swedish battlefleet engaged the Russian galley fleet in battle of Grengam. While the result of the battle is contested it ended Russian galley raids in 1720. As negotiations for peace did not progress the Russian galleys were once again in 1721 sent to raid Swedish coast targeting primarily the Swedish coast between Gävle and Piteå.
Peace.
By the time of Charles XII's death, the anti-Swedish allies became increasingly divided on how to fill the power gap left behind by the defeated and retreating Swedish armies. George I and Frederik IV both coveted hegemony in northern Germany, while August the Strong was concerned about Frederick William I's ambitions on the southeastern Baltic coast. Peter the Great, whose forces were spread all around the Baltic Sea, envisioned hegemony in East Central Europe and sought to establish naval bases as far west as Mecklenburg. In January 1719, George I, August II and emperor Charles VI concluded a treaty in Vienna aimed at the reduction of Russia's frontiers to the pre-war limits.
Hanover-Great Britain and Brandenburg-Prussia thereupon negotiated separate peace treaties with Sweden, the treaties of Stockholm in 1719 and early 1720, which partitioned Sweden's northern German dominions among the parties. The negotiations were mediated by French diplomats, who sought to prevent a complete collapse of Sweden's position on the southern Baltic coast and achieved that Sweden was to retain Wismar and northern Swedish Pomerania. Hanover gained Swedish Bremen-Verden, Brandenburg-Prussia incorporated southern Swedish Pomerania.
In addition to the rivalries in the anti-Swedish coalition, there was an inner-Swedish rivalry between Charles Frederick, Duke of Holstein-Gottorp, and Frederick I of Hesse-Cassel for the Swedish throne. The Gottorp party succumbed and Ulrike Eleonora, wife of Frederick I, transferred power to her husband in May 1720. When peace was concluded with Denmark, the anti-Swedish coalition had already fallen apart, and Denmark was not in a military position to negotiate a return of her former eastern provinces across the sound. Frederick I was however willing to cede the Swedish support for his rival in Holstein-Gottorp, which came under Danish control and the northern part annexed, and furthermore cede the Swedish privilege of exemption from the Sound Dues. A respective treaty was concluded in Frederiksborg in June 1720.
When Sweden finally was at peace with Hanover, Great Britain, Brandenburg-Prussia and Denmark–Norway, she hoped that the anti-Russian sentiments of the Vienna parties and France would culminate in an alliance which would restore to her her Russian-occupied eastern provinces. Yet, primarily due to internal conflicts in Great Britain and France, that did not happen. Therefore, the war was finally concluded by the Treaty of Nystad between Russia and Sweden in Uusikaupunki ("Nystad") on 30 August 1721 (OS). Finland was returned to Sweden, while Swedish Estonia, Livonia, Ingria, Kexholm and the bulk of Karelia were ceded to Russia. Sweden's dissatisfaction with the result led to fruitless attempts at recovering the lost territories in the course of the following century, such as the Russo-Swedish War (1741–1743), and the Russo-Swedish War (1788–1790).
Saxe-Poland-Lithuania and Sweden did not conclude a formal peace treaty, instead, they renewed the Peace of Oliva that had ended the Second Northern War in 1660.
Sweden had lost almost all of its "overseas" holdings gained in the 17th century, and ceased to be a major power. Russia gained its Baltic territories, and became one of the greatest powers in Europe.

</doc>
<doc id="48761" url="https://en.wikipedia.org/wiki?curid=48761" title="Denazification">
Denazification

Denazification () was an Allied initiative to rid German and Austrian society, culture, press, economy, judiciary, and politics of any remnants of the National Socialist ideology (Nazism). It was carried out specifically by removing from positions of power and influence those who had been Nazi Party members and by disbanding or rendering impotent the organizations associated with Nazism. The program of denazification was launched after the end of the Second World War and was solidified by the Potsdam Agreement.
The term "denazification" was first coined as a legal term in 1943 in the Pentagon, intended to be applied in a narrow sense with reference to the post-war German legal system. Soon afterward, it took on the more general meaning.
Overview.
Denazification in Germany was attempted through a series of directives issued by the Allied Control Council, seated in Berlin, beginning in January 1946. "Denazification directives" identified specific people and groups and outlined judicial procedures and guidelines for handling them. Though all the occupying forces had agreed on the initiative, the methods used for denazification and the intensity with which they were applied differed between the occupation zones.
Denazification also refers to the removal of the physical symbols of the Nazi regime. For example, in 1957 the West German government re-issued World War II Iron Cross medals, among other decorations, without the swastika in the center.
About 8.5 million Germans, or 10% of the population, had been members of the Nazi Party. Nazi-related organizations also had huge memberships, such as the German Labour Front (25 million), the National Socialists People's Welfare organization (17 million), the League of German Women, Hitler Youth, the Doctors' League, and others. It was through the Party and these organizations that the Nazi state was run, involving as many as 45 million Germans in total. In addition, Nazism found significant support among industrialists, who produced weapons or used slave labour, and large landowners, especially the Junkers in Prussia. Denazification after the surrender of Germany was thus an enormous undertaking, fraught with many difficulties.
The first difficulty was the enormous number of Germans who might have to be first investigated, then penalized if found to have supported the Nazi state to an unacceptable degree. In the early months of denazification there was a great will to be utterly thorough, to investigate everyone and hold every supporter of Nazism to account; however, it turned out that the numbers simply made that goal impractical. It soon became evident, too, that pursuing denazification too scrupulously would make it impossible to create a functioning, democratic society in Germany, one that would be able to support itself economically and not become a burden on the victorious nations. Enforcing the strictest sanctions against lesser offenders would prevent too many talented people from participating in the reconstruction process. The Morgenthau Plan had recommended that the Allies create a post-war Germany with all its industrial capacity destroyed, reduced to a level of subsistence farming; however, that plan was soon abandoned as unrealistic and too likely, because of its punitiveness, to give rise to German anger and aggressiveness. As time went on, another consideration that moderated the denazification effort in the West was the concern to keep enough good will of the German population to prevent the growth of communism.
The denazification process was often completely disregarded by both the Soviets and the Western powers for German rocket scientists and other technical experts, who were taken out of Germany to work on projects in the victor's own country or simply seized in order to prevent the other side from taking them. The U.S. sent 785 scientists and engineers from Germany to the United States, some of whom formed the backbone of the U.S. space program.
In the case of the top-ranking Nazis, such as Göring, Hess, von Ribbentrop, Streicher, and Speer, the initial proposal by the British was to simply arrest them and shoot them, but that course of action was replaced by putting them on trial for war crimes at the Nuremberg Trials in order to publicize their crimes while demonstrating that the trials and the sentences were just, especially to the German people. However, the legal foundations of the trials were questioned, and the German people were not convinced that the trials were anything more than "victors' justice".
Many refugees from Nazism were Germans and Austrians, and some had fought for Britain in the Second World War. Some were transferred into the Intelligence Corps and sent back to Germany and Austria in British uniform. However, German-speakers were small in number in the British zone, which was hampered by the language deficit. The Americans were able to bring a larger number of German-speakers to the task of working in the Allied Military Government, although many were poorly trained. They were assigned to all aspects of military administration, the interrogation of POWs, collecting evidence for the War Crimes Investigation Unit and the search for war criminals.
Application.
American zone.
The Joint Chiefs of Staff Directive 1067 directed US Army General Dwight D. Eisenhower's policy of denazification. A report of the Institute on Re-education of the Axis Countries in June 1945 recommended: "Only an inflexible long-term occupation authority will be able to lead the Germans to a fundamental revision of their recent political philosophy." The United States military pursued denazification in a zealous, albeit bureaucratic, fashion, especially during the first months of the occupation. It had been agreed among the Allies that denazification would begin by requiring Germans to fill out a questionnaire () about their activities and memberships during the Third Reich. Five categories were established: "Major Offenders", "Offenders", "Lesser Offenders", "Followers", and "Exonerated Persons". The Americans, unlike the British, French, and Soviets, interpreted this to apply to every German over the age of eighteen in their zone. Eisenhower initially estimated that the denazification process would take 50 years.
When the nearly complete list of Nazi Party memberships was turned over to the Allies (by a German anti-Nazi who had rescued it from destruction in April 1945 as American troops advanced on Munich), it became possible to verify claims about participation or non-participation in the Party. The 1.5 million Germans who had joined before Hitler came to power were deemed to be hard-core Nazis.
Progress was slowed by the overwhelming numbers of Germans to be processed, but also by difficulties such as incompatible power systems and power outages, with the Hollerith IBM data machine that held the American vetting list in Paris. As many as 40,000 forms could arrive in a single day to await processing. By December 1945, even though a full 500,000 forms had been processed, there remained a backlog of 4,000,000 forms from POWs and a potential case load of 7,000,000. The "Fragebogen" were, of course, filled out in German. The number of Americans working on denazification was inadequate to handle the workload, partly as a result of the demand in the U.S. by families to have soldiers returned home. Replacements were mostly unskilled and poorly trained. In addition, there was too much work to be done to complete the process of denazification by 1947, the year American troops were expected to be completely withdrawn from Europe.
Pressure also came from the need to find Germans to run their own country. In January 1946 a directive came from the Control Council entitled "Removal from Office and from Positions of Responsibility of Nazis and Persons Hostile to Allied Purposes." One of the punishments for Nazi involvement was to be barred from public office and/or restricted to manual labour or "simple work". At the end of 1945 3.5 million former Nazis awaited classification, many of them barred from work in the meantime. By the end of the winter of 1945–46 42% of public officials had been dismissed. Malnutrition was widespread, and the economy needed leaders and workers to help clear away debris, rebuild infrastructure, and get foreign exchange to buy food and other essential resources.
Another concern leading to the Americans relinquishing responsibility for denazification and handing it over to the Germans arose from the fact that many of the American denazifiers were German Jews, former refugees returning to administer justice against the tormentors and killers of their relatives. It was felt, both among Germans and top American officials, that their objectivity might be contaminated by a desire for revenge.
As a result of these various pressures, and following a 15 January 1946 a report of the Military Government decrying the efficiency of denazification, saying, "The present procedure fails in practice to reach a substantial number of persons who supported or assisted the Nazis," it was decided to involve Germans in the process. In March 1946 The Law for Liberation from National Socialism and Militarism () came into effect, turning over responsibility for denazification to the Germans. Each zone had a Minister of Denazification. On 1 April 1946, a special law established 545 civilian tribunals under German administration (), with a staff of 22,000 of mostly lay judges, enough, perhaps, to start to work but too many for all the staff themselves to be thoroughly investigated and cleared. They had a case load of 900,000. Several new regulations came into effect in the setting up of the German-run tribunals, including the idea that the aim of denazification was now rehabilitation rather than merely punishment, and that someone whose guilt might meet the formal criteria could also have their specific actions taken into consideration for mitigation. Efficiency thus improved, while rigor declined.
Many people had to fill in a new background form, called a "Meldebogen" (replacing the widely disliked "Fragebogen"), and were given over to justice under a "Spruchkammer", which assigned them to one of five categories.
Again because the caseload was impossibly large, the German tribunals began to look for ways to speed up the process. Unless their crimes were serious, members of the Nazi Party born after 1919 were exempted on the grounds that they had been brainwashed. Disabled veterans were also exempted. To avoid the necessity of a slow trial in open court, which was required for those belonging to the most serious categories, more than 90% of cases were judged not to belong to the serious categories and therefore were dealt with more quickly. More "efficiencies" followed. The tribunals accepted statements from other people regarding the accused's involvement in National Socialism. These statements earned the nickname of "Persilscheine", after advertisements for the laundry and whitening detergent Persil. There was corruption in the system, with Nazis buying and selling denazification certificates on the black market. Nazis who were found guilty were often punished with fines assessed in deutsche marks, which had become nearly worthless. In Bavaria the Denazification Minister, Anton Pfeiffer, bridled under the "victor's justice", and presided over a system that reinstated 75% of officials the Americans had dismissed and reclassified 60% of senior Nazis. The denazification process lost a great deal of credibility, and there was often local hostility against Germans who helped administer the tribunals.
By early 1947, the Allies held 90,000 Nazis in detention; another 1,900,000 were forbidden to work as anything but manual labourers.
By 1948, the Cold War was clearly in progress and the US began to worry more about a threat from the Eastern Bloc rather than the latent Nazism within occupied Germany. The remaining cases were tried through summary proceedings that left insufficient time to thoroughly investigate the accused, so that many of the judgments of this period have questionable judicial value. For example, by 1952 members of the SS like Otto Skorzeny could be declared formally denazified () "in absentia" by a German government arbitration board and without any proof that this was true.
The delicate task of distinguishing those truly complicit in or responsible for Nazi activities from mere "followers" made the work of the courts yet more difficult. US President Harry S. Truman alluded to this problem: "though all Germans might not be guilty for the war, it would be too difficult to try to single out for better treatment those who had nothing to do with the Nazi regime and its crimes." Denazification was from then on supervised by special German ministers, like the Social Democrat Gottlob Kamm in Baden-Württemberg, with the support of the US occupation forces.
Contemporary American critics of denazification denounced it as a "counterproductive witch hunt" and a failure; in 1951 the provisional West German government granted amnesties to lesser offenders and ended the program.
Censorship.
While judicial efforts were handed over to German authorities, the US Army continued its efforts to denazify Germany through control of German media. The Information Control Division of the US Army had by July 1946 taken control of 37 German newspapers, six radio stations, 314 theaters, 642 cinemas, 101 magazines, 237 book publishers, and 7,384 book dealers and printers. Its main mission was democratization but part of the agenda was also the prohibition of any criticism of the Allied occupation forces. In addition, on May 13, 1946 the Allied Control Council issued a directive for the confiscation of all media that could contribute to Nazism or militarism. As a consequence a list was drawn up of over 30,000 book titles, ranging from school textbooks to poetry, which were then banned. All copies of books on the list were confiscated and destroyed; the possession of a book on the list was made a punishable offense. All the millions of copies of these books were to be confiscated and destroyed. The representative of the Military Directorate admitted that the order was in principle no different from the Nazi book burnings.
The censorship in the U.S. zone was regulated by the occupation directive JCS 1067 (valid until July 1947) and in the May 1946 order valid for all zones (rescinded in 1950), Allied Control Authority Order No. 4, "No. 4 – Confiscation of Literature and Material of a Nazi and Militarist Nature". All confiscated literature was reduced to pulp instead of burning. It was also directed by Directive No. 30, "Liquidation of German Military and Nazi Memorials and Museums." An exception was made for tombstones "erected at the places where members of regular formations died on the field of battle."
Artworks were under the same censorship as other media;
The directives were very broadly interpreted, leading to the destruction of thousands of paintings and thousands more were shipped to deposits in the U.S. Those confiscated paintings still surviving in U.S. custody include for example a painting "depicting a couple of middle aged women talking in a sunlit street in a small town". Artists were also restricted in which new art they were allowed to create; "OMGUS was setting explicit political limits on art and representation".
The publication "Der Ruf" ("The Call") was a popular literary magazine first published in 1945 by Alfred Andersch and edited by Hans Werner Richter. "Der Ruf", also called "Independent Pages of the New Generation", claimed to have the aim of educating the German people about democracy. In 1947 its publication was blocked by the American forces for being overly critical of occupational government. Richter attempted to print many of the controversial pieces in a volume entitled "Der Skorpion" ("The Scorpion"). The occupational government blocked publication of "Der Skorpion" before it began, saying that the volume was too "nihilistic".
Publication of "Der Ruf" resumed in 1948 under a new publisher, but "Der Skorpion" was blocked and not widely distributed. Unable to publish his works, Richter founded Group 47.
The Allied costs for occupation were charged to the German people. A newspaper which revealed the charges (including, among other things, thirty thousand bras) was banned by the occupation authorities for revealing this information.
Soviet zone.
From the beginning, denazification in the Soviet zone took on the political tone of class warfare. As they moved into Prussia, amid the invasion, the Soviets expelled, arrested, or put in internment camps the Junkers and other large landowners, not only for their reputation of being supporters of militarism and Nazism but also in order to seize their lands and redistribute it to small farmers. Many industries were expropriated, with entire factories moved to the Soviet Union as reparations, or nationalized.
In July 1945, the Soviets were the first of the Allies to install state ("Länder") governments and the first to allow political parties. These were later either disbanded, or absorbed into the Communist Party, which was then renamed the Socialist Unity Party.
The Soviet secret service, NKVD, set up a number of "special camps" where – among others – alleged Nazis were interned. People were sometimes arrested arbitrarily and did not receive a fair trial, with some not even receiving any trial . At least 43,000 died in the camps . Doing special tasks for the Soviet government could protect Nazi members from prosecution, enabling them to continue working.
The abandonment of stringent denazification in the West became a major theme of East German government propaganda, which claimed that the West German government was an extension of the old Nazi regime. Such allegations appeared frequently in the official Socialist Unity Party of Germany newspaper, the "Neues Deutschland". The 1953 June 17 riots in Berlin were officially blamed on Nazi "agents provocateurs" from West Berlin, who the "Neues Deutschland" alleged were then working in collaboration with the Western government with the ultimate aim of restoring Nazi rule throughout Germany. The Berlin Wall was officially called the Anti-Fascist Security Wall () by the East German government.
British zone.
The British prepared a plan from 1942 onwards, assigning a number of quite junior civil servants to head the administration of liberated territory in the rear of the Armies, with draconian powers to remove from their post, in both public and private domains, anyone suspected, usually on behavioural grounds, of harbouring Nazi sympathies. For the British government, the rebuilding of German economic power was more important than the imprisonment of Nazi criminals. Economically hard pressed at home after the war, they did not want the burden of feeding and otherwise administering Germany.
In October 1945, in order to constitute a working legal system, and given that 90% of German lawyers had been members of the Nazi Party, the British decided that 50% of the German Legal Civil Service could be staffed by "nominal" Nazis. Similar pressures caused them to relax the restriction even further in April 1946. In industry, especially in the economically crucial Ruhr area, the British began by being lenient about who owned or operated businesses, turning stricter by autumn of 1945. In order to reduce the power of industrialists, the British expanded the role of trade unions, giving them some decision-making powers.
They were, however, especially zealous during the early months of occupation in bringing to justice anyone, soldiers or civilians, who committed war crimes against POWs or captured Allied aircrew. In June 1945 an 
interrogation centre at Bad Nenndorf was opened, where ex-Nazis and suspected communist agents were tortured with beatings, whippings, thumb-screws, cold, starvation, etc.. A public scandal ensued but only one person was found guilty of neglect.
The British to some extent avoided being overwhelmed by the potential numbers of denazification investigations by requiring that no one need fill out the "Fragebogen" unless they were applying for an official or responsible position. This difference between American and British policy was decried by the Americans and caused some Nazis to seek shelter in the British zone.
In January 1946, the British handed over their denazification panels to the Germans.
French zone.
The French were less vigorous, for a number of reasons, than the Americans, not even using the term "denazification," instead calling it "épuration" (purification). They did not view it as critical to distinguish Nazis from non-Nazis, since in their eyes all Germans were to blame. At the same time, some French occupational commanders had served in the collaborationist Vichy regime during the war where they had formed friendly relationships with Germans. As a result, in the French zone mere membership in the Nazi party was much less important than in the other zones.
Because teachers had been strongly Nazified, the French began by removing three-quarters of all teachers from their jobs. However, finding that the schools could not be run without them, they were soon rehired, although subject to easy dismissal. A similar process governed technical experts. The French were the first to turn over the vetting process to Germans, while maintaining French power to reverse any German decision. Overall, the business of denazification in the French zone was considered a "golden mean between an excessive degree of severity and an inadequate standard of leniency," laying the groundwork for an enduring reconciliation between France and Germany. In the French zone only thirteen Germans were categorized as "major offenders."
Brown book.
In 1965, the National Front of the German Democratic Republic published what became known as the "Brown Book: War and Nazi Criminals in West Germany: State, Economy, Administration, Army, Justice, Science". As the title would indicate, the presence of former Gestapo members in the "Volkspolizei" and ex-Nazis at all levels of the Socialist Unity Party was not covered. The book, among other things, mentioned 1,800 names of former Nazis who held positions of authority in West Germany. These included 15 ministers and deputy ministers, 100 generals and admirals of the armed forces, 828 senior judges and prosecutors, 245 leading members of the Foreign Ministry, embassies and consulates officials, and 297 senior police officers and Federal Office for the Protection of the Constitution officials. The listing was inaccurate; many of the military names had not been Party members, as the armed forces did not permit its officers to join, while many low level Party members in other groups were overlooked altogether. As revealed by BKA official Dieter Senk in 1989, "today we know that Brown Book didn't contain even approximately all the relevant names [... For example it mentions only 3 names from the BKA [...]" The book had a controversial impact in West Germany. Reflecting this, a judge ordered the seizure of the volume from the Frankfurt Book Fair in 1967.
Implications.
For future German states.
The culture of denazification strongly influenced the parliamentary council charged with drawing up a constitution for those occupation zones that would become West Germany.
This Constitution (, Basic Law), was completed on May 8, 1949, ratified on May 23, and came into effect the next day. This date effectively marks the foundation of the Federal Republic of Germany.
For the future of Europe.
The end of denazification saw the "ad hoc" creation initially of the Western Union (not to be confused with the commercial operation of that name) which would be institutionalised as the Western European Union in 1947 and 1955, with a broad socio-economic remit actually implemented in the strict domain of arms control.
Responsibility and collective guilt.
[[File:Eure Schuld.jpg|thumb|right|Diese Schandtaten: Eure Schuld! ("These atrocities: Your Fault!") One of the posters distributed by U.S. occupation authorities in the summer of 1945.]]
The ideas of collective guilt and collective punishment originated not with the US and British people, but on higher policy levels. Not until late in the war did the U.S. public assign collective responsibility to the German people. The most notable policy document containing elements of collective guilt and collective punishment is JCS 1067 from early 1945. Eventually horrific footage from the concentration camps would serve to harden public opinion and bring it more in line with that of policymakers.
Already in 1944, prominent U.S. opinion makers had initiated a domestic propaganda campaign (which was to continue until 1948) arguing for a harsh peace for Germany, with a particular aim to end the apparent habit in the U.S. of viewing the Nazis and the German people as separate entities.
Statements made by the British and U.S. governments, both before and immediately after Germany's surrender, indicate that the German nation as a whole was to be held responsible for the actions of the Nazi regime, often using the terms "collective guilt" and "collective responsibility".
To that end, as the Allies began their post-war denazification efforts, the Psychological Warfare Division (PWD) of Supreme Headquarters Allied Expeditionary Force undertook a psychological propaganda campaign for the purpose of developing a German sense of collective responsibility.
The Public Relations and Information Services Control Group of the British Element (CCG/BE) of the Allied Control Commission for Germany began in 1945 to issue directives to officers in charge of producing newspapers and radio broadcasts for the German population to emphasize "the moral responsibility of all Germans for Nazi crimes." Similarly, among U.S. authorities, such a sense of collective guilt was "considered a prerequisite to any long-term education of the German people."
Using the German press, which was under Allied control, as well as posters and pamphlets, a program was conducted to acquaint ordinary Germans with what had taken place in the concentration camps. For example, using posters with images of concentration camp victims coupled to text such as "YOU ARE GUILTY OF THIS!" or "These atrocities: Your Fault!"
A number of films showing the concentration camps were made and screened to the German public, such as "Die Todesmühlen", released in the U.S. zone in January 1946, and "Welt im Film No. 5" in June 1945. A film that was never finished due partly to delays and the existence of the other films was "Memory of the Camps". According to Sidney Bernstein, chief of PWD, the object of the film was to:
English writer James Stern recounted an example in a German town soon after the German surrender.
Immediately upon the liberation of the concentration camps, many German civilians were forced to see the conditions in the camps, bury rotting corpses and exhume mass graves. In some instances, civilians were also made to provide items for former concentration camp inmates.
Surveys.
The U.S. conducted opinion surveys in occupied Germany . Tony Judt in his book "Postwar: a History of Europe since 1945" extracted and used some of them.
However, in "Hitler, Germans, and the 'Jewish Question, Sarah Ann Gordon notes the difficulty of drawing conclusions from the surveys. For example, respondents were given three alternatives from which to choose, as in question 1:
To the question of whether an Aryan who marries a Jew should be condemned, 91% responded "No". To the question of whether "All those who ordered the murder of civilians or participated in the murdering should be made to stand trial," 94% responded "Yes".
Gordon singles out the question "Extermination of the Jews and Poles and other non-Aryans was not necessary for the security of the Germans", which included an implicit double negative to which the response was either yes or no. She concludes that this question was confusingly phrased (given that in the German language the affirmative answer to a question containing a negative statement is "no"): Some interviewees may have responded "no" they did not agree with the statement, when they actually did agree that the extermination was not necessary. She further highlights the discrepancy between the antisemitic implications of the survey results (such as those later identified by Judt) with the 77% percent of interviewees who responded that actions against Jews were in no way justified.
Gordon states that if the 77 percent result is to be believed then an "overwhelming majority" of Germans disapproved of extermination, and if the 37 percent result is believed to be correct then over one third of Germans were willing to exterminate Poles and Jews and others for German security. She concludes that the phrasing of the question on German security lowers the confidence in the later interpretation.
Gordon follows this with another survey where interviewees were asked if Nazism was good or bad (53% chose bad) and reasons for their answer. Among the nine possible choices on why it was bad, 21% chose the effects on the German people before the war, while 3–4 percent chose the answer "race policy, atrocities, pogroms" However, Gordon highlights the issue that it is difficult to pin-down at which point in time respondents became aware of the exterminations, before or after they were interviewed: questionnaire reports indicate that a significant minority had no knowledge until the Nuremberg trials.
She also notes that when confronted with the exterminations there was an element of denial, disbelief, and confusion. Asked about concentration camps, very few Germans associated them with the Jews, leading to the conclusion that they did not understand how they had been used against the Jews during the war and instead continued to think of them as they were before the war, the place where political opponents to the Nazis were kept. "This naivete is only understandable if large numbers of Germans were truly ignorant of the existence of these camps". A British study on the same attitudes concluded thatThose who said National Socialism was a good idea pointed to social welfare plans, the lack of unemployment, the great construction plans of the Nazis ... Nearly all those who thought it a good idea nevertheless rejected Nazi racial theories and disagreed with the inhumanity of the concentration camps and the 'SS'.
Sarah Gordon writes that a majority of Germans appeared to approve of nonviolent removal of Jews from civil service and professions and German life. The German public also accepted the Nuremberg laws because they thought they would act as stabilizers and end violence against Jews. The German public had as a result of the Nazi antisemitic propaganda hardened their attitudes between 1935 and 1938 from the originally favorable stance. By 1938, the propaganda had taken effect and antisemitic policies were accepted, provided no violence was involved. Kristallnacht caused German opposition to antisemitism to peak, with the vast majority of Germans rejecting the violence and destruction, and many Germans aiding the Jews.
The Nazis responded by intimidation in order to discourage opposition, those aiding Jews being victims of large-scale arrests and intimidation. With the start of the war the anti-Semitic minority that approved of restrictions on Jewish domestic activities was growing, but there is no evidence that the general public had any acceptance for labor camps or extermination. As the number of antisemites grew, so too did the number of Germans opposed to racial persecution, and rumors of deportations and shootings in the east led to snowballing criticism of the Nazis. Gordon states that "one can probably conclude that labor camps, concentration camps, and extermination were opposed by a majority of Germans."
Gordon concludes in her analysis on German public opinion based German SD-reports during the war and the Allied questionnaires during the occupation: it would appear that a majority of Germans supported elimination of Jews from the civil service; quotas on Jews in professions, academic institutions, and commercial fields; restrictions on intermarriage; and voluntary emigration of Jews. However, the rabid antisemites' demands for violent boycotts, illegal expropriation, destruction of Jewish property, pogroms, deportation, and extermination were probably rejected by a majority of Germans. They apparently wanted to restrict Jewish rights substantially, but not to annihilate Jews.
End.
The West German political system, as it emerged from the occupation, was increasingly opposed to the Allied denazification policy. As denazification was deemed ineffective and counterproductive by the Americans, they did not oppose the plans of the German chancellor Konrad Adenauer to end the denazification efforts. Adenauer's intention was to switch government policy to reparations and compensation for the victims of Nazi rule ("Wiedergutmachung"), stating that the main culprits had been persecuted. In 1951 several laws were passed, ending the denazification. Officials were allowed to retake jobs in the civil service, with the exception of people assigned to Group I (Major Offenders) and II (Offenders) during the denazification review process.
Several amnesty laws were also passed which affected about 792,176 people. Those pardoned included people with six-month sentences, 35,000 people with sentences of up to one year and include more than 3,000 functionaries of the SA, the SS, and the Nazi Party who participated in dragging victims to jails and camps; 20,000 other Nazis sentenced for "deeds against life" (presumably murder); 30,000 sentenced for causing bodily injury, and 5,200 who committed "crimes and misdemeanors in office." As a result, several people with a former Nazi past ended up again in the political apparatus of Western Germany.
Criticism by the Red Army Faction.
Because the Cold War had curtailed the process of denazification in the West, certain radical leftist groups such as the Red Army Faction tried to justify their use of violence against the West German government based on the notion that the West German establishment had benefited from the Nazi period, and that, while having officially renounced the Holocaust and the war crimes of the Wehrmacht, it was still supposedly fascist in outlook in all other aspects. They pointed out that many former Nazis held government posts, while the German Communist Party was illegal. They argued that "What did you do in the war, daddy?" was not a question that many of the leaders of the generation who fought World War II and prospered in the postwar ""Wirtschaftswunder"" (German Economic Miracle) encouraged their children to ask.
One of the major justifications that the Red Army Faction gave in 1977 for murdering Hanns-Martin Schleyer, President of the Confederation of German Employers' Associations (BDA) and perceived as one of the most powerful industrialists in West Germany, was that as a former member of the SS he was part of an informal network of ex-Nazis who still had great economic power and political influence in West Germany.
Hiding one's Nazi past.
Even today, membership in Nazi organizations is still not an open topic of discussion among most Germans. It was not until 2006 that famous German writer Günter Grass, often viewed as a spokesman of 'the nation's moral conscience', spoke publicly about the fact that he had been a member of the Waffen SS (even though his involvement appears to have been less than criminal; he was conscripted into the Waffen SS while barely seventeen years old and his duties were strictly military in nature). Joseph Ratzinger (later Pope Benedict XVI), on the other hand, has been open about his membership at the age of fourteen in Hitler Youth, when his church youth group was forced to merge with them. Statistically it is likely that there are many more Germans of Grass's generation (also called the "Flakhelfer-Generation") with biographies similar to his.
In other countries.
In practice, denazification was not limited to Germany and Austria; in every European country with a vigorous Nazi or Fascist party measures of denazification were carried out. In France the process was called épuration légale (). Prisoners of war held in detention in Allied countries were also subject to denazification qualifications before their repatriation.
Denazification was also practised in many countries which came under German occupation, including Belgium, Norway, Greece and Yugoslavia, because satellite regimes had been established in these countries with the support of local collaborators.
In Greece, for instance, Special Courts of Collaborators were created after 1945 to try former collaborators. The three Greek 'quisling' prime ministers were convicted and sentenced to death or life imprisonment. Other Greek collaborators after German withdrawal underwent repression and public humiliation, besides being tried (mostly on treason charges). In the context of the emerging Greek Civil War however, most wartime figures from the civil service, the Greek Gendarmerie and the notorious Security Battalions were quickly integrated into the strongly anti-Communist postwar establishment.

</doc>
<doc id="48764" url="https://en.wikipedia.org/wiki?curid=48764" title="Tocantins">
Tocantins

Tocantins () is one of the states of Brazil. (From: Tukã´, "Toucan" + tï, "beak". lit. "Toucan's beak" in Tupi language). It is the newest of the 26 Brazilian states, formed in 1988 and encompassing what had formerly been the northern two-fifths of the state of Goiás. Tocantins covers and has a population of 1,496,880 (2014 est.). Construction of its capital, Palmas, began in 1989; most of the other cities in the state date to the Portuguese colonial period. With the exception of Araguaína there are few other cities with a significant population in the state. The government has invested in a new capital, a major hydropower dam, railroads and related infrastructure to develop this primarily agricultural area.
Tocantins has attracted hundreds of thousands of new residents, primarily to Palmas. It is building on its hydropower resources. The Araguaia and Tocantins rivers drain the largest watershed that lies entirely inside Brazilian territory. The Rio Tocantins has been dammed for hydropower, creating a large reservoir that has become a center of recreation. Because it is in the central zone of the country, Tocantins has characteristics of the Amazon Basin, and also semi-open pastures, known as "cerrado". The Bananal Island ("Ilha do Bananal"), in the southwest of the State, is the largest fluvial island in the world. Tocantins is also home to the Araguaia National Park, the Carajás Indian reservations, and Jalapão state park, which is about from Palmas. There, the rivers create oases in the dry landscape, attracting many ecotourists to the region.
Geography.
Tocantins geography is varied. It straddles both the Amazon Rainforest and the coastal savanna. Many rivers (including the Tocantins River) traverse the state. Researchers have identified more than 20 archaeologically significant sites related to indigenous cultures.
Tocantins is bordered to the northeast by the states of Maranhão and Piauí, Bahia to the east, Goiás to the south, Mato Grosso to the west, and Pará to the northwest. Tocantins was created from the northern two-fifths of Goiás state in 1989 and is divided into 139 municipalities.
Climate.
Most of Tocantins (except the extreme western and northern regions) is situated within a vast Brazilian area known as the cerrado. The cerrado region's typical climate is hot and semi-humid, with pronounced seasonal variation marked by a dry winter from May through October. The annual rainfall is around 800 to 1600 mm. The soils are generally very old, deep, and naturally nutrient-poor.
Vegetation.
The "cerrado" landscape cover 87% of Tocantins and is characterized by extensive savanna formations crossed by gallery forests and stream valleys. Cerrado includes various types of vegetation. Humid fields and "buriti" palm paths are found where the water table is near the surface. Alpine pastures occur at higher altitudes and mesophytic forests on more fertile soils.
The savanna formations are not homogenous. There is great variation between the amount of woody and herbaceous vegetation, forming a gradient from completely open "cerrado" — open fields dominated by grasses — to the closed, forest-like "cerrado" and the "cerradão" ("big cerrado"), a closed canopy forest. Intermediate forms include the dirty field, the "cerrado" field, and the "cerrado" sensu stricto, according to a growing density of trees.
The "cerrado" trees have characteristic twisted trunks covered by a thick bark, and leaves that are usually broad and rigid. Many herbaceous plants have extensive roots to store water and nutrients. The plant's thick bark and roots serve as adaptations for the periodic fires which sweep the cerrado landscape. The adaptations protect the plants from destruction and make them capable of sprouting again after the fire.
As in many savannas in the world, the "cerrado" ecosystems have been coexisting with fire since ancient times. Initially they developed adaptations to natural fires caused by lightning or volcanic activity, and later to those caused by man.
Along the western boundary of the state is the floodplain of the Araguaia River, which includes extensive wetlands and Amazon tropical forest ecosystems. Bananal Island, formed by two branches of the Araguaia, is said to be the largest river island in the world. It consists mostly of marshlands and seasonally flooded savannas, with gallery forest. Where the two branches meet again they form an inland delta called Cantão, a typical Amazonian igapó flooded forest. The Araguaia is also one of the main links between the Amazonian lowlands and the Pantanal wetlands to the south, but the river is not fully navigable.
History.
Portuguese Jesuit missionaries explored what is today Tocantins state about 1625, seeking to convert the Amerindian peoples of the area to Christianity. The area is named after the Tocantins River, whose name is derived from an indigenous language. (From: Tukã´, "Toucan" + tï, "beak". lit. "Toucan's beak" in Tupi language.)
Before 1988 the area made up the northern two-fifths or one-third of Goiás state. Since the 17th century, this area was relatively isolated by rivers navigable only in short portions and mountains, and difficult to access. As a result, the southern area of the state became more developed, particularly after this area was selected in 1956 as the site for the development of the new capital of Brasília and the Federal District. A strong separatist movement developed in the north for independence of its people. 
After the government levied heavy taxes on mining in 1809, local residents began to organize a separatists movement. They made a minor revolt which was quickly crushed by the army. In the 19th century, a string of failed uprisings occurred in the north. Historically the area was inhabited chiefly by Amerindians in some intact indigenous tribes and pardos of Amerindian and Portuguese descent.
In the 1970s, the population of northern Goiás lobbied the government to establish a separate state. In the 1988 Constitution, the State of Tocantins was officially created and admitted as a new Brazilian state.
Since its establishment and investment by the government, as in the new capital of Palmas, Tocantins has been the fastest-growing Brazilian state. Its thriving economy is based on agriculture and agro-industry, attracting thousands of migrants from all over the country. The construction of the long-planned North-South Railway (Brazil) will probably boost economic growth even more. 
Demographics.
According to the IBGE, as of 2014, there were 1,496,880 people residing in the state. The population density was 4.98 inh./km².
Urbanization: 71.5% (2004); Population growth: 2.6% (1991–2000); Houses: 355,502 (2005).
The last PNAD (National Survey of Households) census revealed the following numbers: 948,000 Pardos (brown, Multiracial) people (68.9%), 330,000 White people (24.0%), 95,000 Black people (6.9%), 2,000 Asian or Amerindian people (0.2%).
Economy.
The service sector is the largest component of GDP at 59.9%, followed by the industrial sector at 27.2%. Agriculture represents 12.9% of GDP (2004). Tocantins exports: soybean 89.2%, beef 10.5% (2002).
Share of the Brazilian economy: 0.4% (2005).
As with much of Brazil, Tocantins' economy is dependent on cattle ranching. The state's pineapple plantations supply much of Brazil with the fruit, as well as many other Mercosul nations. In the state's north, charcoal and oils are extracted from the babaçu palm tree.
Seeking to broaden Tocantins' economic base by funding the construction of a hydroelectric dam in the state, the government allowed a private company to construct a sizable five-turbine hydroelectric dam, blocking the Tocantins River to create a reservoir. This construction displaced some indigenous inhabitants. The dam's economic contribution to the state is large: one turbine provides enough power for the entire state of Tocantins, and the remaining four provide electricity that is sold to other parts of Brazil.
Education.
Portuguese is the official national language, and thus the primary language taught in schools. But English and Spanish are part of the official high school curriculum.
Infrastructure.
Palmas Airport.
The facility occupies one of Brazil’s largest airport sites and has privileged location near the Lajeado Hydroelectric Station.
Designed with a modern concept of visual communication, the new Palmas Airport Complex contains an Aeroshopping area. This is part of a program developed by Infraero, to develop Brazil’s main airports as commercial centers with their own brand and identity.
The passenger terminal has 12.300 square meters of constructed area and capacity to serve up to 370 thousand people a year. It has a food court, cultural space, shops, panoramic deck, elevators, and air conditioning. The runway can receive aircraft the size of a Boeing 767. Three taxiways and aprons are reserved for general aviation, making operations more flexible. The airport's full infrastructure includes a control tower and installations for the Air Navigation Group, fire brigade, a covered equipment parking area, canteen and training rooms, two aircraft fueling stations, a gate with electronic entry control, guard booths, parking and flight protection buildings, besides a 4 km (2.48 mi) access road linking the airport to the Tocantins capital city’s main thoroughfare.
Protected areas.
Araguaia National Park, established in 1959, is located on Bananal Island. It borders Cantão State Park, and together, these strictly protected areas form the core of the Araguaia Mosaic of Protected Areas, which consists of over four million hectares of state and federal protected areas and Indian lands along the Araguaia wetlands. The mosaic also extends into the neighboring states of Pará and Mato Grosso.
Nascentes do Rio Parnaiba National Park is located on the opposite corner of the state, in the transition zone between the Cerrado and the semi-arid Caatinga. It also extends into the neighboring states of Maranhão and Piauí.
In addition, the State of Tocantins has established state parks at Jalapão and Serra do Lajeado, protecting two unique samples of the Cerrado. The state parks and protected areas of Tocantins are managed by Naturatins, the state environmental agency.
Flag.
The message of the flag is the phrase "where the sun rises for all". In the middle of the flag is the golden yellow sun, with its rays symbolically targeting to the future of the state. The sun is placed on a white band, where the white color represents peace. The blue in the upper left and the yellow in the bottom right represent the waters and the soil of the state. The colors date back to a flag used by the Autonomous Government of Palmas in the 19th century.
The flag was adopted with the state flag law (law no 094/89) of November 17, 1989.
Represented in popular culture.
"Survivor:" Tocantins — The Brazilian Highlands was the setting for the eighteenth season of the United States reality show "Survivor," filmed in the microregion of Jalapão in Tocantins. The premiere aired February 12, 2009.

</doc>
