<doc id="55671" url="https://en.wikipedia.org/wiki?curid=55671" title="Connotation">
Connotation

A connotation is a commonly understood cultural or emotional association that some word or phrase carries, in addition to the word's or phrase's explicit or literal meaning, which is its denotation.
A connotation is frequently described as either positive or negative, with regards to its pleasing or displeasing emotional connection. For example, a stubborn person may be described as being either "strong-willed" or "pig-headed"; although these have the same literal meaning ("stubborn"), "strong-willed" connotes admiration for the level of someone's will (a positive connotation), while "pig-headed" connotes frustration in dealing with someone (a negative connotation).
Usage.
"Connotation" branches into a mixture of different meanings. These could include the contrast of a word or phrase with its primary, literal meaning (known as a denotation), with what that word or phrase specifically denotes. The connotation essentially relates to how anything may be associated with a word or phrase, for example, an implied value judgment or feelings.
It is often useful to avoid words with strong connotations (especially pejorative or disparaging ones) when striving to achieve a neutral point of view. A desire for more positive connotations, or fewer negative ones, is one of the main reasons for using euphemisms. 
Logic.
In logic and semantics, "connotation" is roughly synonymous with "intension". Connotation is often contrasted with "denotation", which is more or less synonymous with "extension". Alternatively, the connotation of the word may be thought of as the set of all its possible referents (as opposed to merely the actual ones). A word's "denotation" is the collection of things it refers to; its connotation is what it implies about the things it is used to refer to. The denotation of dog is (something like) four-legged canine carnivore. So saying, "You are a dog" would imply that you were ugly or aggressive rather than stating that you were canine.

</doc>
<doc id="55678" url="https://en.wikipedia.org/wiki?curid=55678" title="Interstate Commerce Commission">
Interstate Commerce Commission

The Interstate Commerce Commission (ICC) was a regulatory agency in the United States created by the Interstate Commerce Act of 1887. The agency's original purpose was to regulate railroads (and later trucking) to ensure fair rates, to eliminate rate discrimination, and to regulate other aspects of common carriers, including interstate bus lines and telephone companies. Congress expanded ICC authority to regulate other modes of commerce beginning in 1906. The agency was abolished in 1995, and its remaining functions were transferred to the Surface Transportation Board.
The Commission's five members were appointed by the President with the consent of the United States Senate. This was the first independent agency (or so-called "Fourth Branch").
Creation.
The ICC was established by the Interstate Commerce Act of 1887, which was signed into law by President Grover Cleveland. The creation of the commission was the result of widespread and longstanding anti-railroad agitation. Western farmers, specifically those of the Grange Movement, were the dominant force behind the unrest, but Westerners generally — especially those in rural areas — believed that the railroads possessed economic power that they systematically abused. A central issue was rate discrimination between similarly situated customers and communities. Other potent issues included alleged attempts by railroads to obtain influence over city and state governments and the widespread practice of granting free transportation in the form of yearly passes to opinion leaders (elected officials, newspaper editors, ministers, and so on) so as to dampen any opposition to railroad practices.
Various sections of the Interstate Commerce Act banned "personal discrimination" and required shipping rates to be "just and reasonable."
Initial implementation and legal challenges.
The Commission had a troubled start because the law that created it failed to give it adequate enforcement powers.
Following passage of the 1887 act, the ICC proceeded to set maximum shipping rates for railroads. However, in the late 1890s several railroads challenged the agency's ratemaking authority in litigation, and the courts severely limited the ICC's powers. 
Expansion of ICC authority.
Congress expanded the commission's powers through subsequent legislation. The 1893 Railroad Safety Appliance Act gave the ICC jurisdiction over railroad safety, removing this authority from the states, and this was followed with amendments in 1903 and 1910. The Hepburn Act of 1906 authorized the ICC to set maximum railroad rates, and extended the agency's authority to cover bridges, terminals, ferries, sleeping cars, express companies and oil pipelines.
A long-standing controversy was how to interpret language in the Act that banned long haul-short haul fare discrimination. The Mann-Elkins Act of 1910 addressed this question by strengthening ICC authority over railroad rates, This amendment also expanded the ICC's jurisdiction to include regulation of telephone, telegraph and wireless companies.
The Valuation Act of 1913 required the ICC to organize a Bureau of Valuation that would assess the value of railroad property. This information would be used to set rates.
In 1934, Congress transferred the telecommunications authority to the new Federal Communications Commission.
In 1935, Congress passed the Motor Carrier Act, which extended ICC authority to regulate interstate bus lines and trucking as common carriers.
Ripley Plan to consolidate railroads into regional systems.
The Transportation Act of 1920 directed the Interstate Commerce Commission to prepare and adopt a plan for the consolidation of the railway properties of the United States into a limited number of systems. Between 1920–3 William Z. Ripley, a professor of political economy at Harvard University, wrote up ICC's plan for the regional consolidation of the U.S. railways. His plan became known as the "Ripley Plan". In 1929 the ICC published Ripley's Plan under the title "Complete Plan of Consolidation". Numerous hearings were held by ICC regarding the plan under the topic "In the Matter of Consolidation of the Railways of the United States into a Limited Number of Systems".
The proposed 21 regional railroads were as follows:
Terminal railroads proposed.
There were 100 terminal railroads that were also proposed. Below is a sample:
Plan rejected.
Many small railroads failed during the Great Depression of the 1930s. Of those lines that survived, the stronger ones were not interested in supporting the weaker ones. Congress repudiated Ripley's Plan with the "Transportation Act of 1940," and the consolidation idea was scrapped.
Racial integration of transport.
Although racial discrimination was never a major focus of its efforts, the ICC had to address civil rights issues when passengers filed complaints.
Relationship between regulatory body and the regulated.
A friendly relationship between the regulators and the regulated is evident in several early civil rights cases. Throughout the South, railroads had established segregated facilities for sleeping cars, coaches and dining cars. At the same time, the plain language of the Act (forbidding "undue or unreasonable preference" as well as "personal discrimination") could be read as an implied invitation for activist regulators to chip away at racial discrimination.
In at least two landmark cases, however, the Commission sided with the railroads rather than with the African-American passengers who had filed complaints. In both "Mitchell v. United States (1941)" and "Henderson v. United States," the Supreme Court took a more expansive view of the Act than the Commission. In 1962, the ICC banned racial discrimination in buses and bus stations, but it did not do so until several months after a binding pro-integration Supreme Court decision "Boynton v. Virginia" and the Freedom Rides (in which activists engaged in civil disobedience to desegregate interstate buses).
Criticism.
The limitation on railroad rates in 1906-07 depreciated the value of railroad securities, a factor in causing the panic of 1907.
Some economists and historians, such as Milton Friedman assert that existing railroad interests took advantage of ICC regulations to strengthen their control of the industry and prevent competition, constituting regulatory capture.
Economist David D. Friedman argues that the ICC always served the railroads as a cartelizing agent and used its authority over other forms of transportation to prevent them, where possible, from undercutting the railroads.
Abolition.
Congress passed various deregulation measures in the 1970s and 1980s which diminished ICC authority, including the Railroad Revitalization and Regulatory Reform Act of 1976 ("4R Act"), the Motor Carrier Act of 1980 and the Staggers Rail Act of 1980. Senator Fred R. Harris of Oklahoma was a strong supporter of abolishing the Commission. In 1995, when most of the ICC's powers had been eliminated, Congress finally abolished the agency with the Interstate Commerce Commission Termination Act. Final Chair Gail McDonald oversaw transferring its remaining functions to a new agency, the Surface Transportation Board.
Prior to its abolition, the ICC issued identification numbers to Motor Carriers (bus lines, shipping companies, etc.) which it issued licenses. These identification numbers were generally in the form of ICC MC-000000. When the ICC was dissolved, the function of licensing interstate Motor Carriers was transferred to the Department of Transportation, so now all motor carriers which have federal licenses have a different "DOT number" such as DOT 000000.
Legacy.
The ICC served as a model for later regulatory efforts. Unlike, for example, state medical boards (historically administered by the doctors themselves), the seven Interstate Commerce Commissioners and their staffs were full-time regulators who could have no economic ties to the industries they regulated. Since 1887, some state and other federal agencies adopted this structure. And, like the ICC, later agencies tended to be organized as multi-headed independent commissions with staggered terms for the commissioners. At the federal level, agencies patterned after the ICC included the Federal Trade Commission (1914), the Federal Communications Commission (1934), the U.S. Securities and Exchange Commission (1934), the National Labor Relations Board (1935), the Civil Aeronautics Board (1940), Postal Regulatory Commission (1970) and the Consumer Product Safety Commission (1975). In recent decades, this regulatory structure of independent federal agencies has gone out of fashion. The agencies created after the 1970s generally have single heads appointed by the President and are divisions inside executive Cabinet Departments (e.g., the Occupational Safety and Health Administration (1970) or the Transportation Security Administration (2002)). The trend is the same at the state level, though it is probably less pronounced.
International influence.
The Interstate Commerce Commission had a strong influence on the founders of Australia. The Constitution of Australia provides (; also ) for the establishment of an Inter-State Commission, modeled after the United States' Interstate Commerce Commission. However, these provisions have largely not been put into practice; the Commission existed between 1913–1920, and 1975–1989, but never assumed the role which Australia's founders had intended for it.

</doc>
<doc id="55680" url="https://en.wikipedia.org/wiki?curid=55680" title="Peter the Aleut">
Peter the Aleut

Cungagnaq (date of birth unknown - d. 1815) is venerated as a martyr and saint (as Peter the Aleut) by some jurisdictions of the Eastern Orthodox Church. He was allegedly a native of Kodiak Island (Alutiiq or Sugpiaq), and is said to have received the Christian name of Peter when he was baptized into the Orthodox faith by the monks of St. Herman's missionaries operating in the north. He is purported to have been captured by Spanish soldiers near San Pedro (Pacifica, California) and tortured and killed at the instigation of Roman Catholic priests either there or at Mission Dolores, in San Francisco. At the time identified for his death, California was Spanish territory, and Spain was worried about Russian advances southwards from Alaska. Hubert Howe Bancroft, in his multi-volume "History of California", only notes that, in connection with an incident wherein a Russian fur-hunting expedition was taken into custody after declining to leave San Pedro; one Russian source accused "the Spaniards of cruelty to the captives, stating that according to Kuskof’s report one Aleut who refused to become a Catholic died from ill-treatment received from the padre at San Francisco."
Martyrdom.
According to the most fully developed version of the story, in 1815 a group of Russian employees of the Russian American Company and their Aleut seal and otter hunters, including Peter, was captured by Spanish soldiers, while hunting illicitly for seals near San Pedro. According to the original account, the soldiers took them to "the mission in Saint-Pedro" for interrogation. One Russian source states that after being taken prisoner near modern Los Angeles, the captives were taken to Mission Dolores—that is, modern San Francisco. With threats of torture, the Roman Catholic priests attempted to force the Aleuts to deny their Orthodox faith and to convert to Roman Catholicism.
When the Aleuts refused, the priest had a toe severed from each of Peter's feet. Peter still refused to renounce his faith and the Spanish priest ordered a group of Native Americans, indigenous to California, to cut off each finger of Peter's hands, one joint at a time, finally removing both his hands. They eventually disemboweled him, making him a martyr to the Eastern Orthodox faith. They were about to torture the next Aleut when orders were received to release them.
Historicity.
An account of the martyrdom of Peter the Aleut is contained in a lengthy letter written on Nov. 22, 1865, by Symeon Ivanovich Yanovsky to Damascene, abbot of the Valaam Monastery in Finland. Yanovsky (1789–1876), who is also one of the chief sources of information about St. Herman of Alaska, was chief manager of the Russian colonies from 1818-1820. In the letter he was reporting on an incident that he had heard from a supposed eyewitness, and that had taken place fifty years earlier in 1815. The letter contains the description of Peter being tortured by "Jesuits" but this would have been virtually impossible, as the Jesuit order had been expelled from all Spanish territories in 1767, suppressed generally in 1773, and had only been reconstituted in 1814 (one year before Peter's alleged death). In 1815 there were no Jesuits within several thousand miles of California, as the reconstitution of the Jesuits in New Spain (that is, Mexico) would not take place until 1816. There were only Franciscans in California at the time, and it would be highly unlikely that anyone could confuse members of the two well-known and very dissimilar orders. Yanovsky adds, "At the time I reported all this to the Head Office in St. Petersburg." And indeed, this earlier communication, his official dispatch to the company's main office—dated Feb. 15, 1820, five years after the event—also relates the story of St. Peter's martyrdom, albeit with different details.
The most significant difference is that Yanovsky's original brief letter of 1820 accompanied a Russian translation of an account given in 1819 by a Kodiak Islander with the Russian name "Ivan Kiglay". This is the only account that purports to be from a witness, and any differences found in other accounts (including in those of Yanovsky himself) are additions or embroideries that lack foundation or support. Kiglay's account describes the capture of Russian-led fur poachers by Spanish soldiers in the vicinity of San Pedro Bay (the modern Port of Los Angeles) and taken to "the mission in Saint-Pedro". (As there was no mission or settlement at San Pedro, it is unclear where the party was supposed to have been taken; the nearest mission would have been San Gabriel, although the non-mission village of Los Angeles would have been closer.) While the rest of the prisoners are removed to Mission Santa Barbara, Kiglay and another Kodiak Islander named Chukagnak -- who had been wounded in a battle with the soldiers -- are imprisoned separately at "the mission at Saint-Pedro", and the next day Indians acting at the behest of a Spaniard torture and kill Chukagnak. Kiglay is apparently going to receive the same treatment, until the Spaniard receives a letter that apparently gives other directions. Kiglay is reimprisoned, and eventually escapes to Fort Ross, where he gives his testimony. There is nothing in the account that links the execution of Chucagnak to a refusal on his part to abandon Orthodoxy. Instead, the eyewitness account states that the Kodiak islanders were all previously offered the opportunity to become Catholics, that they had all declined because they were already Christians, and then with the exceptions of Kiglay and Chukagnak were all transferred to Santa Barbara with no further mention of, or demand for, conversion. 
Veneration.
According to Yanovsky's 1865 letter, upon receiving the report of Peter's death, St. Herman on Kodiak Island was moved to cry out, "Holy new-martyr Peter, pray to God for us!"
Peter the Aleut was glorified as a saint by the Russian Orthodox Church Outside Russia and locally glorified by the Diocese of Alaska of the Orthodox Church in America as the "Martyr of San Francisco" in 1980. His feast day is celebrated on September 24 or December 12.
There are a number of churches dedicated to him in North America: for example, the church at Lake Havasu City, Arizona; Minot, North Dakota; Calgary; and Abita Springs, Louisiana.

</doc>
<doc id="55683" url="https://en.wikipedia.org/wiki?curid=55683" title="1310s BC">
1310s BC


</doc>
<doc id="55684" url="https://en.wikipedia.org/wiki?curid=55684" title="Time-out (parenting)">
Time-out (parenting)

Time-out (also known as" social exclusion") is a form of behavioural modification that involves temporarily separating a child from an environment where unacceptable behavior occurred. The goal is to remove reinforcement for the behavior and therefore lead to the extinction of the offending behavior. It is an educational and parenting technique recommended by some pediatricians and developmental psychologists as an effective form of child discipline. Often a corner (hence the common term "corner time") or a similar space where the child is to stand or sit during time-outs is designated. This form of discipline is especially popular in North America. 
In the UK, the punishment is often known as the naughty chair or naughty step. This term became popular in the US thanks to two reality TV series, "Supernanny" and "Nanny 911".
History.
The concept of time-out was invented, named, and used by Arthur Staats in his extended work with his daughter (and later son), and was part of a long-term program of behavioral analysis beginning in 1958 that treated various aspects of child development. He introduced various elements that later composed foundations for applied behavior analysis and behavior therapy (the token reward system was another invention). Montrose Wolf, a graduate student assistant of Staats on several studies dealing with reading learning in preschoolers (see, for example, Staats, A.W.; Staats, C.K.; Schultz, R.E.; Wolf, M.M. "The conditioning of textual responses using 'extrinsic' reinforcers."), used that background when he went to the University of Washington where he began his creative program of research. Wolf first used Staats' time-out procedure in a 1964 published study dealing with the behavioral treatment of a child. 
Staats described the discipline of his 2-year old daughter in 1962: "I would put her in her crib and indicate that she had to stay there until she stopped crying. If we were in a public place her behavior was inappropriate, I would pick her up and go outside." This has the effect of weakening the offending behavior so that it occurs less frequently, quickly disappearing unless the behavior has been well learned.
Application.
The use of time-out as an acceptable therapeutic procedure has gained wide acceptance in schools, clinics, and hospitals. The main purpose is to isolate or separate (hence "social exclusion") the child for a short period of time, usually 5 to 15 minutes, in order to allow the child to calm down as well as to discourage inappropriate behavior.
Time-outs may be on a chair, step, corner, bedroom, or any other location where there are no distractions. The procedure has been recommended as a time for parents to separate feelings of anger toward the child for their misbehavior, replacing yelling with a calmer and more predictable approach.
In some views, the only requirement for release is for the child to be sitting peacefully, while others advocate a set period of time. When the child has calmed down, they may then express their needs in a more polite manner or return to their activity.
For this disciplinary technique to be most effective and to produce the desired results, the child should be old enough to sit still and is required to remain there for a fixed period. Also, according to developmental psychologists, parents should evaluate each situation to determine what may be causing the misbehavior, such as a toy, frustration, hunger, or lack of sleep, and then respond accordingly with the punishment consistent with the desired behavior. Parents should also clearly explain why the child was put there, in order to make it an opportunity for learning, and how long he needs to stay there (but too much explanation can reinforce the unwanted behavior). Furthermore, experts suggest that time-out should remain brief, proposing a general guideline: the length of time that the child should remain in time-out should correlate with the child's age - each of year of the child's age constitutes one minute in time-out.
Time-out is one behavior control method based on removing positive reinforcement. Less elaborate methods from the same class like tactical ignoring also can be effective in cases where parental/care-giver attention is the positive reinforcer. This class of methods are more effective if the child gets a significant amount positive reinforcement (praise, attention) for good behavior. Tactical ignoring is the preferred method in Parent Management Training for behaviors that can be ignored.
Effectiveness.
Several studies show that time-out is an especially effective disciplinary strategy, reducing aggressive and non-compliant behavior, when other positive parenting methods are also used. Time out must be linked with "time in" in order to be effective because children need to be able to find reinforcement through positive experiences. 
There are differences between strategies for ending time out. While some proponents of time-outs insist on silence and stillness from the child during the time-out, it is easier to use a "release-contingency," such that the requirement is only that the child is sitting peacefully at the end of the time-out period. Those who use time-out for children to get anger and frustration "out of their system" or for children to think about their behavior are using time-out in a way that is different than those basing it on operant behavioral principles (that time-out from positive reinforcement may reduce recurrences of the unwanted target behavior).
In a study by Donaldson and Vollmer, the efficacy of a fixed duration time-out and a release contingency time-out were compared. In the fixed duration condition, children were sent to time-out for a total of 4 minutes and were released from time-out whether or not they performed problem behavior during the time-out session. In the release contingency condition, children were not released from time-out if they were performing problem behavior during the last 30 seconds of their time-out. The time-out was extended until there were no occurrences of problem behavior for a total of 30 seconds or until the time-out reached the ten-minute mark. Results showed that both time-out procedures were successful in reducing the problem behavior for the subjects. The subjects in the release contingency did not benefit from staying in time-out for an extended period of time either. Moreover, the results show that only 4 minutes is necessary for a successful time-out procedure.
The effectiveness of time-out also varies with each individual child, dependent on the child's age, temperament and emotional wellness.
Disadvantages.
Critics of time-out include Thomas Gordon, Alfie Kohn, and Aletha Solter, who claim that the approach may lead to short-term compliance but has the same disadvantages as other forms of punishment. According to these authors, the use of time-out does not enhance moral behavior or teach children useful conflict-resolution skills, and it fails to address the underlying cause of the behavior. Furthermore, they claim that the parent/child bond can be damaged by forced isolation and withdrawal of love in an effort to control a child’s behavior, and this can lead to feelings of insecurity or anxiety in children. Another argument is that time-out, like all other methods of coercive control, eventually stops working as children grow older and begin to rebel against their parents’ authoritarian approach to discipline.
In addition to the potential psychological drawbacks resulting from the use of time-out, there also appears to be a risk to the child’s developing brain, according to research in neuroscience by Daniel J. Siegel. “In a brain scan, relational pain (that caused by isolation during punishment) can look the same as physical abuse,” and “Repeated experiences actually change the physical structure of the brain.” 
The Australian Association for Infant Mental Health has published a position statement in which the use of time-out is considered inappropriate, especially for children under three years of age. In addition to a list of disadvantages of time-out, the position statement asserts that “separation may increase a child’s insecurity and distress.”
The use of time-out appears to be especially ineffective in families dealing with special challenges. In a review of parenting intervention programs for drug-abusing mothers, researchers found that programs emphasizing behavioral approaches to discipline (such as the use of time-out and rewards) “were not successful in fostering measurable improvement in mother-child interactions or promoting child development.” An attachment-based approach focusing on strengthening the parent/child relationship was found to be more successful than behavioral approaches in changing children’s behavior in these families.
Other studies have found that the traditional behavioral approach to discipline (such as the use of time-out and rewards) was not very effective in changing the behavior of children in foster care with attachment disorders resulting from early abuse or neglect. Foster parents benefit more from training that addresses these children’s attachment and emotional issues, which lie at the root of their challenging behavior.
Time-out has been misused to the point of becoming abusive in some schools. There are reported cases of children being locked in closets for extended periods of solitary confinement for behaviors such as crying or failing to finish an assignment.

</doc>
<doc id="55686" url="https://en.wikipedia.org/wiki?curid=55686" title="Andrew Bobola">
Andrew Bobola

Saint Andrew Bobola, S.J. (, 1591 – 16 May 1657) was a Polish missionary and martyr of the Society of Jesus, known as the Apostle of Lithuania and the "hunter of souls".
Life.
Bobola was born in 1591 into a noble family in the Sandomir Palatinate in the Province of Lesser Poland of the Crown of the Kingdom of Poland, then a constituent part of the Polish–Lithuanian Commonwealth. In 1611 he entered the Society of Jesus in Vilnius, then in the Grand Duchy of Lithuania, the other part of the Commonwealth. He subsequently professed solemn vows and was ordained in 1622, after which he served for several years as an advisor, preacher, Superior of a Jesuit residence, etc., in various places.
From 1652 Bobola also worked as a country "missionary", in various locations of Lithuania: these included Polotsk, where he was probably stationed in 1655, and also Pinsk, (both now in Belarus). On 16 May 1657, during the Khmelnytsky Uprising, he was captured in the village of Janów (now Ivanava, Belarus) by the Cossacks of Bohdan Chmielnicki and, after being subjected to a variety of tortures, killed.
One description of Bobola's death written in 1865 states:
Veneration.
Bobola's body was originally buried in the Jesuit church in Pinsk. It was later moved to their church in Polotsk. By the beginning of the 18th century, however, nobody knew where Bobola's body was buried. In 1701 Father Martin Godebski, S.J., the Rector of the Pinsk College, reputedly had a vision of Bobola. This caused him to order a search for the body. It was reportedly found completely incorrupt, which was recognized by the Church and its supporters as proof of holiness. In 1719 the casket was officially reopened and the body inspected by qualified medical personnel (five physicians and pharmacists). It was reportedly still completely incorrupt: pliable and with soft flesh.
In 1922, the Bolsheviks moved the corpse, later described by an American journalist as a "remarkably well-preserved mummy", to the Museum of Hygiene of People's Commissioners of Health in Moscow. The whereabouts of the remains was not known to the Catholic authorities, and Pope Pius XI charged the Papal Famine Relief Mission in Russia, headed by American Jesuit Father Edmund A. Walsh, with the task of locating and "rescuing" them. In October 1923—as a kind of "pay" for help during famine—the remains were released to Walsh and his Assistant Director, Father Louis J. Gallagher, S.J. Well packed by the two Jesuits, they were delivered to the Holy See by Gallagher on All Saints' Day (1 November) 1923. In May 1924, the relics were installed in Rome's Church of the Gesù, the main church of the Society of Jesus.
Since 17 June 1938 the body has been venerated at a shrine in Warsaw, with an arm remaining at the original shrine in Rome.
Declared Blessed by Pope Pius IX on 30 October 1853, Bobola was canonized by Pope Pius XI on 17 April 1938. His feast day was originally celebrated by the Jesuits on 23 May, but it is now generally celebrated on 16 May. On his feast day in 2002, Pope John Paul II declared Bobola a patron saint of Poland and of the Roman Catholic Archdiocese of Warsaw.
Today some join Bobola with St. Peter the Aleut, an alleged martyr for the Eastern Orthodox Church at the hands of Catholics, in a special devotion for the reunion of the two branches of Christianity. However, the historicity of the martyrdom of Peter the Aleut is not clearly established.
External links.
<BR>

</doc>
<doc id="55687" url="https://en.wikipedia.org/wiki?curid=55687" title="Silver City Airways">
Silver City Airways

Silver City Airways was a private, British independent airline formed in 1946. The name "Silver City" was derived from the eponymous Australian mining town at Broken Hill, where "The Zinc Corporation" was headquartered. Silver City's first commercial flight departed London Heathrow for Sydney via Johannesburg in late 1946. The following year, Silver City leased its first Bristol Freighter, moved its base to Blackbushe and participated in the airlift of Hindu and Muslim refugees between Pakistan and India. In 1948, control of Silver City passed from the Zinc Corporation to British Aviation Services. In July of that year, the airline inaugurated the world's first air ferry service across the English Channel between Lympne Airport and Le Touquet Airport. In 1948–49, Silver City participated in the Berlin Airlift. In 1949, it established a French sister airline.
In 1953, Silver City took delivery of its first Bristol Superfreighter. The following year, the company moved to a new permanent home at Lydd "Ferryfield", Britain's first newly constructed post-war airport. The same year, Silver City Airways came under the control of the Peninsular and Oriental Steam Navigation Company (P&O). By the mid-1950s, Silver City had become the biggest air cargo carrier in the United Kingdom while annual passenger numbers at its "Ferryfield" base had reached ¼ of a million. During that time, the airline also inaugurated air ferry services between Scotland and Ireland and from/to the Midlands. This period also saw the launch of "Silver Arrow", a London—Paris coach-air-coach/rail service, with the cross-Channel air portion operating between Lydd and Le Touquet. In 1957, Silver City accomplished its one-millionth Channel crossing. In summer 1958, Silver City's "Ferryfield" base recorded more aircraft movements than any other UK airport. That year, also marked the conclusion of Silver City's first decade of air ferry operations during which the airline operated more than 100,000 flights carrying over 200,000 vehicles and ¾ of a million passengers, with peak-day frequency exceeding 200. In 1959, Silver City took over sister airline Britavia's Handley Page Hermes fleet and Manston base. That year, the airline also began oil industry support flights in Libya.
By 1960, Silver City's 40,000 annual cross-Channel flights transported 220,000 passengers and 90,000 vehicles while network-wide freight haulage reached 135,000 tons a year. The following summer, the airline reached agreement with a French rival to co-finance construction of a branch line linking Le Touquet Airport with the nearby main railway line to reduce surface travelling time from/to Paris. Unsustainable losses as a result of the loss of the Libyan oil industry support flight contract, increasing competition from roll-on/roll-off ferries and the lack of suitable replacements for the ageing Bristol Freighters resulted in growing financial difficulties, culminating in Silver City's takeover by British United Airways (BUA) holding company Air Holdings in 1962.
History.
The 1940s.
In 1946, Air Cdre Griffith James ("Taffy") Powell got in touch with W.S. Robinson, chairman of London-based mining company "The Zinc Corporation". That meeting resulted in Robinson appointing Powell as the Zinc Corporation's adviser.
One of Powell's first visits in his new capacity took him to Broken Hill, Australia, also known as "Silver City". This visit resulted in the decision to set up a new air transport operator to serve the mining industry, to be named "Silver City".
Silver City Airways was incorporated on 25 November 1946. British Aviation Services (BAS), an early post-World War II airline holding company and air transport operator, became one of Silver City's shareholders, initially taking a 10% stake. Air Cdre Griffith James Powell was the first managing director of both BAS and Silver City.
Silver City's first base was at Langley Aerodrome.
The airline's initial fleet comprised four ex-military Douglas Dakotas and three Avro Lancastrians, the 13-seater civil version of the Lancaster Mark 3 bomber. Two of the latter were new aircraft that had been ordered by British South American Airways (BSAA).
Lancastrian G-AHBW operated the company's first commercial flight, from London Airport (Heathrow) to Sydney via Johannesburg in November 1946. This was followed by similar operations to Johannesburg via Karachi and to Malta before the end of the year.
In October 1947, Silver City became involved in the airlift of Hindu and Muslim refugees between Pakistan and India, following the Subcontinent's partitioning. This operation constituted the fledgling airline's first major engagement. Initially, the repatriation airlift was undertaken by four Dakotas. On short journeys, the authorities granted Silver City dispensation to raise the limit on the maximum number of passengers it could carry from 28 to 52 to airlift as many people as quickly as possible.
Also that year, Silver City moved its base to Blackbushe Airport, as a result of Langley's closure due to Heathrow's expansion.
Also in 1947, Silver City leased its first Bristol Freighter from the manufacturer to replace one of the four Dakotas that had originally been allocated to the repatriation airlift in the Indian subcontinent. Like the Dakotas it had operated on that airlift, Silver City was given dispensation to increase the maximum number of passengers it could carry on the Bristol Freighter above the normal limit of 32. Actual loads on this aircraft type often exceeded 100 passengers per flight, resulting in a total of 1,105 evacuees and their belongings being transported aboard Silver City's single Freighter over a period of nine days. The airline's Bristol Freighter fleet soon expanded to four aircraft. The Freighter would play a major role in the company's development over the coming years. Powell realised that the Bristol Freighter could be adapted to fly car owners with their vehicles from Britain to Continental Europe and the Channel Islands. This "air ferry" would allow British holidaymakers avoid long waits for sea ferries and time-consuming, bumpy rides in rough waters.
On 7 July 1948, a Silver City Bristol Freighter operated the first cross-Channel air ferry service, between Lympne near Folkestone in Kent and Le Touquet on France's northern Côte d'Opale coast, with good road connections from and to London and Paris respectively. The new service, which initially operated on a seasonal charter basis, became a year-round scheduled operation in 1949. In the beginning, there was a flat £32 one-way fare to take a group of four passengers along with their car across the Channel. Once opposition from British European Airways (BEA) to the carriage of passengers travelling without vehicles was overcome, a new fare structure was introduced. For example, a group of four travelling with a small car was charged only £27, while the comparable fare for four people travelling with a large car remained at £32. By the end of 1949, this operation fully utilised five Freighters, which carried 2,700 cars and 10,000 passengers. These figures represented a significant increase over the previous year when only 178 cars and their occupants, as well as some motorcycles and bicycles had been carried until the end of the season in September.
The same year, the Zinc Corporation sold its shareholding in Silver City to BAS, making the latter the airline's sole owner. Silver City subsequently became BAS's biggest operating division.
Silver City joined the 1948–49 Berlin Airlift with a single Bristol Freighter in September 1948. Owing to heavy demand for additional civilian airlift capacity, the airline leased a further two Freighters from the Bristol Aeroplane Company. By the time the civil contribution to the Airlift was scaled down in February 1949, the company's three Bristol Freighters were the last twin-engined airliners employed in this operation. When it came to an end, the firm's Freighters had flown a total of about 800 hours.
In February 1949, Silver City established a French sister airline headquartered in Paris to operate vehicle ferry flights from Le Touquet Airport. The new company was registered under the name "Société Commerciale Aérienne du Littoral" (SCAL). A number of Silver City aircraft were registered to this company. These were transferred onto the French aircraft register. In addition, an agreement was reached to appoint the "Automobile Club de France" as Silver City's and SCAL's official representative in France. These steps were necessary to secure French approval to turn the seasonal charter flights Silver City had operated on this route into a full-fledged scheduled operation.
The 1950s.
By 1950, the number of cars and passengers carried on Silver City's cross-Channel services roughly doubled to 5,000 and 24,000 respectively.
To encourage further traffic growth on its Lympne — Le Touquet cross-Channel car ferry service, Silver City reduced fares with effect from 19 September 1950: the rate for cars up to 14 feet in length was cut from £27 to £19 while the rate for larger vehicles dropped from £32 to £25. This reduction left Silver City's fares only slightly higher than the Dover—Calais ferry fares of British Railways' Southern Region and, together with the service's earlier extension permitting the carriage of cyles and motor cycles, helped establish the airline's ferry services as a serious competitor to the railways.
The success of Silver City's Lympne — Le Touquet air ferry service resulted in subsequent introduction of additional routes across the English Channel and to other parts of the British Isles.
Over the coming years, Silver City pursued a policy of continuous fare reductions to fill the additional capacity on its growing air ferry network. This included new car ferry services between Southampton (Eastleigh) and Cherbourg as well as between Southend (Rochford) and Ostend and a DC-3 passenger service linking Gatwick and Le Touquet. Both of the former commenced in spring 1952, while the latter was inaugurated the following year. As a result, the number of vehicles carried doubled from 5,000 to 10,000 between 1950 and 1952 and quadrupled to 40,000 by the end of the following year. The latter was the consequence of an average 40% fare reduction.
BAS's takeover of Air Kruise, an independent charter and pleasure flight operator based at Lympne, in March 1953 brought a fleet of all-passenger de Havilland Dragon Rapides and Douglas Dakotas. This acquisition resulted in formation of Silver City's "Passenger Division".
In summer 1953, Silver City leased a Breguet Br.763 to participate in the second "Little Berlin Airlift" on the Hamburg (Fuhlsbüttel) — Berlin (Tempelhof) route. A total of 127 round trips carried of freight with up to three round trips being made in a day, each leg taking 52 minutes' flight time.
In 1953, Silver City also took delivery of its first stretched Mark 32 Bristol Superfreighter, the first of six. The Superfreighter's elongated nose enabled it to accommodate three cars or to be fitted with 60 seats in an all-passenger Super Wayfarer configuration. The new Superfreighters joined a fleet of nine standard Mark 21 Freighters. Other freight charter work at this time included flights to the Suez Canal Zone supporting the UK military forces then stationed there.
As operations expanded, the small grass airfield at Lympne became increasingly inadequate. The search for a suitable location to site a new, purpose-built airport began in 1953. Interim moves to Southend and West Malling were followed by final selection of an area covered by grazing land on the edge of the Dungeness shingle desert on the Kentish coast close to the village of Lydd. This site would host Britain's first newly constructed post-war and first privately owned airport. It would feature two runways, a control tower, passenger terminal with a restaurant, maintenance area and petrol station. The new airport — named "Ferryfield" — opened on 14 July 1954, after six months' work costing £400,000. However, it took almost another two years for the official opening ceremony to be performed at "Ferryfield", which occurred on 5 April 1956. On that day, HRH the Duke of Edinburgh arrived at "Ferryfield" just before 11.00 am on board the Royal Heron. The occasion marked the Duke's first visit to a private British airline at an all-new, privately owned airport. Following his tour of the airport's facilities, the Duke boarded one of Silver City's scheduled air ferry services to Le Touquet on Superfreighter G-AMWD. During the 19-minute flight, the Duke flew the aircraft at its scheduled en route height of 1,000 ft. The Duke's reception at Le Touquet Airport was followed by an informal lunch hosted in his honour by the president of the French Aero Clubs in the airport restaurant. The Duke then departed, flying the Royal Heron to London Airport.
By 1954, the Silver City cross-Channel network comprised five routes: Gatwick — Le Touquet, Lydd — Le Touquet, Lympne—Calais, Lympne—Ostend and Southampton—Cherbourg.
Following the opening of "Ferryfield" in mid-1954, Silver City initially split its operations between the new airport and Lympne. For a short while, Le Touquet flights operated from the former while Calais and Ostend services continued to use the latter. The last of 33,000 Silver City flights, which had carried a total of 54,000 cars and 208,000 passengers since 1948, departed Lympne on 3 October. From then on, vehicle ferry services were concentrated at "Ferryfield".
Also in 1954, control of Silver City passed to P&O via General Steam Navigation, which had acquired a 70% stake in BAS, the airline's parent company. It was also the year Silver City complemented its Gatwick — Le Touquet all-passenger operation with a vehicle ferry service.
By 1955, "Ferryfield" handled 250,000 passengers annually. This made it busier than Gatwick.
Also in 1955, Silver City launched its first air ferry services between Scotland and Ireland and its first such service from the Midlands. These linked Stranraer with Belfast and Birmingham with Le Touquet. In addition, the airline opened a new service from Southampton to Deauville.
That year also saw Silver City become the UK's biggest air cargo carrier with an annual freight volume of 70,190 tons.
In 1956, Silver City commenced London—Paris coach-air-coach/rail services via Lydd ("Ferryfield") and Le Touquet/Étaples. As Le Touquet Airport was not linked to the French railway network at the time, the journey between the airport and Paris involved an additional change between coach and train at Étaples. DC-3s initially operated these all-passenger services, which were marketed as "Silver Arrow" in the UK and as "Flèche d'argent" in France. "Silver Arrow"/"Flèche d'argent" was a joint operation between British Railways, Silver City and Société Nationale des Chemins de Fer français (SNCF).
By 1957, BAS's airline subsidiaries included Air Kruise, Aquila Airways, Britavia, the Lancashire Aircraft Corporation and the original Manx Airlines, apart from Silver City Airways itself.
Also in 1957, Silver City completed its one-millionth Channel crossing since its inaugural Lympne — Le Touquet air ferry service took to the air in July 1948.
That year also saw Silver City become involved in supporting the oil industry in Libya, flying geologists and supplying desert camps with a fleet of DC-3s and a single DC-2 from bases at Tripoli and Benghazi. The airline's sole DC-2 was originally operated by Swissair and subsequently sold to new owners in South Africa, who leased it to Silver City.
By 1958, "Ferryfield" had become one of Britain's three busiest airports. It recorded more aircraft movements during the peak summer months than any other airport in the UK, and only Heathrow and Northolt were busier in terms of annual air freight volume.
That year also marked the conclusion of the first decade of Silver City's air ferry services. During that period, the airline completed 125,000 ferry flights. These carried 215,000 vehicles and 750,000 passengers. At its peak, Silver City operated 222 daily ferry flights across the English Channel, as well as between Scotland and Ireland and to/from the Isle of Wight, the Channel Islands and the Isle of Man. Cross-Channel flights to France operated between 7.30 am and 11.00 pm. The average fare was £25 per car and £4 per passenger. This was furthermore the time the Air Kruise cross-Channel services, as well as all Dragon Airways, Lancashire Aircraft Corporation and Manx Airlines operations from Newcastle upon Tyne, Blackpool and the Isle of Man were transferred to Silver City's new Northern Division to streamline BAS's fragmented airline operations. It was hoped that these measures would improve BAS's financial performance.
In May of the same year, the crew of a Silver City Dakota made the first sighting of the "Lady Be Good", a WW II bomber that had disappeared in 1943 while returning from an operation to Naples, in the Libyan Desert.
In 1959, Britavia transferred its five-strong Hermes 4A fleet to sister airline Silver City, as a consequence of the loss of a trooping contract to Eagle. The Hermes were based at Manston, from where they operated "Silver Arrow" all-passenger services to Le Touquet and inclusive tour charters to European destinations until parent company BAS's acquisition by British United Airways (BUA) parent Air Holdings in 1962.
Also in 1959, Silver City opened a Blackpool-Dublin route.
By the end of that decade, Silver City advertised £8 18s day-return fares for its London—Paris "Silver Arrow"/"Flèche d'argent" service.
The 1960s.
By 1960, Silver City made 40,000 yearly Channel crossings, carrying 90,000 vehicles and 220,000 passengers. During that year, it also moved 135,000 tons of freight across its network. This represented an increase of 35% over the previous year.
In summer 1961, Silver City agreed with rival French air ferry operator Compagnie Air Transport (CAT) for the latter to finance the construction of a two-mile rail spur into Le Touquet Airport from the nearby main line to reduce the travelling time between the airport and Paris by cutting out the coach/rail change at Étaples. In return, Silver City transferred three of its Superfreighters to CAT along with the traffic rights to operate the "Ferryfield" — Le Touquet and Bournemouth (Hurn) — Cherbourg routes. This arrangement gave CAT a 25% share of the car ferry market between Britain and France.
Having been outbid by Belgium's flag carrier Sabena for the Libyan oil industry support flight contract that year, Silver City's losses became unsustainable. This necessitated the sale of three Superfreighters to CAT for £192,300.
Following growing financial difficulties, Silver City was taken over by BUA parent Air Holdings in 1962. The takeover was officially announced in January of that year. Air Holdings were the owners of Channel Air Bridge, a rival air ferry operator based at Southend in Essex, which operated similar services from Southend to the Continent. The BUA-BAS merger removed BUA's last remaining independent competitor in the air ferry business. The addition of Silver City's 650,000 annual ferry passengers increased the yearly combined total to just under one million, accounting for two thirds of BUA's total passengers. However, the change in ownership failed to staunch the airline's losses. These amounted to £650,000 during the first half of 1962. By the end of the year, the Silver City name ceased to be used as all aircraft had either been repainted in BUA colours or retired.
Despite the poor financial performance, 1962 turned out to be the busiest year in Silver City's 16-year history. During that year, the airline and its French partner CAT carried 96,272 vehicles and 238,748 passengers on 43,064 flights, representing increases of 10%, 6% and 12% compared with 1961. In addition, over 43,000 tonnes of cargo were carried. However, these record-breaking traffic statistics did not alter the fact that the airline's air ferry operation was no longer economically viable. With the advent of new, high-capacity roll-on/roll-off ferries and hovercraft that were faster and more reliable than traditional ferries, competition intensified. Established aircraft manufacturers were not interested in producing reasonably priced replacements for the ageing Bristol Freighters/Superfreighters that were suffering from wing fatigue. The airline's long-standing policy of stimulating the market by continuously reducing fares had resulted in uneconomic yields in the absence of a corresponding reduction in costs. The Hermes fleet had continued in operation serving several UK airports, mainly on inclusive tour flights, with the last example being retired from service in late 1962.
On 1 January 1963, Air Holdings merged Silver City with Channel Air Bridge to form British United Air Ferries.
Fleet details.
Silver City operated the following aircraft types during its 16-year existence:
Fleet in 1950.
In 1950, Silver City operated 16 aircraft.
Fleet in 1954.
23 aircraft.
Fleet in 1958.
38 aircraft.
Fleet in 1962.
31 aircraft.
Accidents and incidents.
There are three recorded accidents involving Silver City aircraft, two of which were fatal.
The worst accident in company history occurred on 27 February 1958. Bristol 170 Mark 21E Freighter registration G-AICS operating a charter flight from the Isle of Man to Manchester on behalf of Manx Airlines crashed in bad weather on Winter Hill near Bolton, Lancashire, destroying the aircraft and killing 35 of 39 passengers (all three crew members survived).
The aircraft was chartered by the Isle of Man motor trade to take members to the Exide battery factory in Clifton Junction, and it hit the northeast slope of Winter Hill in thick fog at a height of approximately and burst into flames, as a result of a navigational error committed by the first officer.
The second fatal accident occurred on 1 November 1961. Bristol 170 Mark 32 Superfreighter registration G-ANWL operating a scheduled service from Cherbourg to Guernsey crashed after losing height during a missed approach to Guernsey Airport, damaging the aircraft beyond repair and killing two out of three crew members (all seven passengers survived).
Having failed to gain height following a power increase to go around, the aircraft struck the ground with its starboard wing and cartwheeled due to a malfunctioning automatic pitch coarsening unit of the starboard propeller.
The non-fatal accident occurred on 19 January 1953. Bristol 170 Mark 21 Freighter registration G-AICM operating a non-scheduled cargo flight from West Berlin crash-landed near Tempelhof Airport as a result of fuel starvation when bad weather at the destination forced it to return to Berlin. Although the accident damaged the aircraft beyond repair, both pilots survived.
Resurrection.
Air Holdings, which had retained the rights to the "Silver City" name following the merger between Silver City and Channel Air Bridge to form British United Air Ferries a decade earlier, resurrected Silver City for a short period during 1973.
The airline's second incarnation was as a specialist livestock carrier transporting cattle between Norwich and Germany. This operation utilised three of five Vickers Vanguards owned by Air Holdings, which had been leased to Invicta International Airlines. That airline's failure to pay for the leases had resulted in Air Holdings repossessing the aircraft and starting its own air freight operation.
Air Holdings' lack of success with its German cattle charters led to a decision to put the aircraft up for sale in October and to close down the airline the following month, with the "Silver City" name being de-activated by the end of the year.
External links.
<br>

</doc>
<doc id="55688" url="https://en.wikipedia.org/wiki?curid=55688" title="Buckinghamshire">
Buckinghamshire

Buckinghamshire ( or , abbreviated Bucks; archaically the County of Buckingham) is a ceremonial county in South East England. It borders Greater London to the south east, Berkshire to the south, Oxfordshire to the west, Northamptonshire to the north, Bedfordshire to the north east and Hertfordshire to the east.
Buckinghamshire is a home county and towns such as High Wycombe, Amersham and the Chalfonts in the east and southeast of the county are parts of the London commuter belt, forming some of the most densely-populated parts of the county. Development in this region is restricted by the Metropolitan Green Belt. Other large settlements include the county town of Aylesbury, Marlow in the south near the Thames and Princes Risborough in the west near Oxford. Some areas without direct rail links to London, such as around the old county town of Buckingham and near Olney in the northeast, are much less populous. The largest town is Milton Keynes in the northeast, which with the surrounding area is administered as a unitary authority separately to the rest of Buckinghamshire. The remainder of the county is administered by Buckinghamshire County Council as a non-metropolitan county. In national elections, Buckinghamshire is considered a reliable supporter of the Conservative party.
A large part of the Chiltern Hills, an Area of Outstanding Natural Beauty, runs through the south of the county and attracts many walkers and cyclists from London. In this area older buildings are often made from local flint and red brick. Many parts of the county are quite affluent and like many areas around London this has led to problems with housing costs: several reports have identified the market town of Beaconsfield as having among the highest property prices outside London. Chequers, a mansion estate owned by the government, is the country retreat of the incumbent Prime Minister. To the north of the county lies rolling countryside in the Vale of Aylesbury and around the Great Ouse. The Thames forms part of the county’s southwestern boundary. Notable service amenities in the county are Pinewood Film Studios, Dorney rowing lake and part of Silverstone race track on the Northamptonshire border. Many national companies have offices in Milton Keynes. Heavy industry and quarrying is limited, with agriculture predominating after service industries.
History.
The name Buckinghamshire is Anglo-Saxon in origin and means "The district (scire) of Bucca's home". "Bucca's home" refers to Buckingham in the north of the county, and is named after an Anglo-Saxon landowner. The county has been so named since about the 12th century; however, the county has existed since it was a subdivision of the kingdom of Mercia (585–919).
The history of the area predates the Anglo-Saxon period and the county has a rich history starting from the Celtic and Roman periods, though the Anglo-Saxons perhaps had the greatest impact on Buckinghamshire: the geography of the rural county is largely as it was in the Anglo-Saxon period. Later, Buckinghamshire became an important political arena, with King Henry VIII intervening in local politics in the 16th century and just a century later the English Civil War was reputedly started by John Hampden in mid-Bucks.
Historically, the biggest change to the county came in the 19th century, when a combination of cholera and famine hit the rural county, forcing many to migrate to larger towns to find work. Not only did this alter the local economic situation, it meant a lot of land was going cheap at a time when the rich were more mobile and leafy Bucks became a popular rural idyll: an image it still has today. Buckinghamshire is a popular home for London commuters, leading to greater local affluence; however, some pockets of relative deprivation remain.
The expansion of London and coming of the railways promoted the growth of towns in the south of the county such as Aylesbury, Amersham and High Wycombe, leaving the town Buckingham itself to the north in a relative backwater. As a result, most county institutions are now based in the south of the county or Milton Keynes, rather than in Buckingham.
Geography.
The county can be split into two sections geographically. The south leads from the River Thames up the gentle slopes of the Chiltern Hills to the more abrupt slopes on the northern side leading to the Vale of Aylesbury, a large flat expanse of land, which includes the path of the River Great Ouse.
Waterways.
Rivers.
The county includes parts of two of the four longest rivers in England. The River Thames forms the southern boundary with Berkshire, which has crept over the border at Eton and Slough so that the river is no longer the sole boundary between the two counties. The River Great Ouse rises just outside the county in Northamptonshire and flows east through Buckingham, Milton Keynes and Olney.
Canals.
The main branch of the Grand Union Canal passes through the county as do its arms to Slough, Aylesbury, Wendover (disused) and Buckingham (disused). The canal has been incorporated into the landscaping of Milton Keynes.
Landscape.
The southern part of the county is dominated by the Chiltern Hills. The two highest points in Buckinghamshire are Haddington Hill in Wendover Woods (a stone marks its summit) at above sea level, and Coombe Hill near Wendover at .
Mineral extraction.
Quarrying has taken place for chalk, clay for brickmaking and gravel and sand in the river valleys. Flint, also extracted from quarries, was often used to build older local buildings. Several former quarries, now flooded, have become nature reserves.
Demography.
As can be seen from the table, the Vale of Aylesbury and the Borough of Milton Keynes have been identified as growth areas, with a projected population surge of almost 40,000 in Aylesbury Vale between 2011 and 2026 and 75,000 in Milton Keynes within the same 15 years. The population of the Borough of Milton Keynes is expected to reach almost 350,000 by 2031, whilst the urban population of the county town of Aylesbury is expected to exceed 100,000.
Buckinghamshire is sub-divided into civil parishes.
Today Buckinghamshire is ethnically diverse, particularly in the larger towns. At the end of the 19th century some Welsh drover families settled in north Bucks and, in the last quarter of the 20th century, a large number of Londoners in Milton Keynes. Between 6 and 7% of the population of Aylesbury are of Asian or Asian British origin. Likewise Chesham has a similar-sized Asian community, and High Wycombe is the most ethnically diverse town in the county, with large Asian and Afro-Caribbean populations. During the Second World War there were many Polish settlements in Bucks, Czechs in Aston Abbotts and Wingrave, and Albanians in Frieth. Remnants of these communities remain in the county.
Politics.
Ceremonial.
The ceremonial county of Buckinghamshire consists of the area administered by Milton Keynes Borough Council as well as that administered by Buckinghamshire County Council. The ceremonial county has a Lord Lieutenant and a High Sheriff. Currently the Lord Lieutenant of Buckinghamshire is Sir Henry Aubrey-Fletcher and the High Sheriff of Buckinghamshire is Amanda Nicholson. The office of "Custos rotulorum" has been combined with that of Lord Lieutenant since 1702.
Local government.
At present, the county has two top-level administrations: Buckinghamshire County Council, which administers about four-fifths of the county (see map above) and the Borough of Milton Keynes, a unitary authority, which administers the remaining fifth. There are four district councils that are subsidiary to the county council: Aylesbury Vale, Chiltern, South Bucks and Wycombe districts.
Buckinghamshire County Council.
The county council was founded in 1889 with its base in new municipal buildings in Walton Street, Aylesbury (which are still there). In Buckinghamshire, local administration is run on a two-tier system where public services are split between the county council and a series of district councils.
In the 1960s the council moved into new premises: a 15-storey tower block in the centre of Aylesbury (pictured) designed by architect Fred Pooley. Said to be one of the most unpopular and disliked buildings in Buckinghamshire, it is now a Grade II listed building.
In 1997 the northernmost part of Buckinghamshire, then Milton Keynes District, was separated to form a unitary authority, the Borough of Milton Keynes; however for ceremonial and some other purposes Milton Keynes is still considered in law to be part of Buckinghamshire.
Buckinghamshire County Council is a large employer in the County and provides a variety of services, including education (schools, adult education and youth services), social services, highways, libraries, County Archives and Record Office, the County Museum and the Roald Dahl Children's Gallery in Aylesbury, consumer services and some aspects of waste disposal and planning.
Coat of arms.
The coat of arms of Buckinghamshire County Council features a white swan in chains. This dates back to the Anglo-Saxon period, when swans were bred in Buckinghamshire for the king's pleasure. That the swan is in chains illustrates that the swan is bound to the monarch, an ancient law that still applies to wild swans in the UK today. The arms were first borne at the Battle of Agincourt by the Duke of Buckingham.
Above the swan is a gold band, in the centre of which is Whiteleaf Cross, representing the many ancient landmarks of the county. The shield is surmounted by a beech tree, representing the Chiltern Forest that once covered almost half the county. Either side of the shield are a buck, for Buckingham, and a swan, the county symbol.
The motto of the shield is "Vestigia Nulla Retrorsum". This is Latin and means 'no stepping back'.
Flag.
The traditional flag of Buckinghamshire, which flies outside County Hall in Aylesbury, comprises red and black halves with a white swan. The flag takes the county emblem which is on the county shield.
Economy.
Buckinghamshire has a modern service-based economy and is part of the Berkshire, Buckinghamshire and Oxfordshire NUTS-2 region, which was the seventh richest subregion in the European Union in 2002. As well as the highest GDP per capita outside Inner London, Buckinghamshire has the highest quality of life, the highest life expectancy and the best education results in the country. The southern part of the county is a prosperous section of the London commuter belt. The county has fertile agricultural lands, with many landed estates, especially those of the Rothschild banking family of England in the 19th century (see Rothschild properties in England). The county has several annual agricultural shows, with the Bucks County Show established in 1859. Manufacturing industries include furniture-making (traditionally centred at High Wycombe), pharmaceuticals and agricultural processing.
This is a chart of trend of regional gross value added of Buckinghamshire at current basic prices published by the Office for National Statistics with figures in millions of British Pounds sterling (except GVA index).
Places of interest.
Buckinghamshire is notable for its open countryside and natural features, including the Chiltern Hills Area of Outstanding Natural Beauty, Stowe Landscaped Gardens near Buckingham, and the River Thames. The Ridgeway Path, a long-distance footpath, passes through the county. The county also has many historic houses. Some of these are opened to the public by the National Trust, such as Waddesdon Manor, West Wycombe Park and Cliveden. Other historic houses are still in use as private homes, such as the Prime Minister's country retreat Chequers.
Claydon House is a National Trust property, situated near the village of Steeple Claydon. Home to the Verney family and was also home to Florence Nightingale for some time.
Buckinghamshire is the location of Bletchley Park, the site of World War II British codebreaking and Colossus, the world's first programmable electronic digital computer.
Buckinghamshire is the home of various notable people in connection with whom tourist attractions have been established: for example the author Roald Dahl who included many local features and characters in his works.
Sports facilities in Buckinghamshire include half of the international Silverstone Circuit which straddles the Buckinghamshire and Northamptonshire border, Adams Park in the south and in the north, and the county is also home to the world famous Pinewood Studios. Dorney Lake, named 'Eton Dorney' for the event, was used as the rowing venue for the 2012 Summer Olympics.
Transport.
Roads.
Buckinghamshire (including Milton Keynes) is served by four motorways, although two are on its borders:
Five important A roads also enter the county (from north to south):
The county is poorly served with internal routes, with the A413 and A418 linking the south and north of the county.
Rail.
As part of the London commuter belt, Buckinghamshire is well connected to the national rail network, with both local commuter and inter-city services serving some destinations.
Chiltern Railways is a principal train operating company in Buckinghamshire, providing the majority of local commuter services from the centre and south of the county, with trains running into . First Great Western provides commuter services from and into . London Midland provides commuter services from into whilst Southern provides services (via the West London Line) from Milton Keynes to Croydon.
For intercity services, Virgin Trains runs services from Milton Keynes Central to Euston, North West England, the West Midlands, the Scottish Central Belt, and North Wales. Meanwhile, First Great Western operates non-stop inter-city services through the south of the county between Paddington and South West England and/or South Wales.
There are four main lines running through the county:
There are the following additional lines:
From 2017, Iver will have Crossrail services. From 2019, the East West Rail Link is to reinstate the route via between and Bletchley, enabling electrified services to Milton Keynes Central. The line between Aylesbury and Claydon Junction is also to be reinstated in the same programme, enabling services between Aylesbury and Milton Keynes. of the Marston Vale Line is not programmed, meaning that passengers for must change at Bletchley. Finally, the High Speed 2 line may run non-stop through the county at some future date. 
Settlements.
For the full list of towns, villages and hamlets in Buckinghamshire, see List of places in Buckinghamshire. Throughout history, there have been a number of changes to the Buckinghamshire boundary.
Education.
Education in Buckinghamshire is governed by two Local Education Authorities. Buckinghamshire County Council is one of the few remaining LEAs still using the tripartite system, albeit with some revisions such as the abolition of secondary technical schools. It has a completely selective education system: pupils transfer either to a grammar school or to a secondary modern school depending on how they perform in the 11 plus test and on their preferences. Pupils who do not take the test can only be allocated places at secondary modern schools. There are 9 independent schools and 34 maintained (state) secondary schools, not including sixth form colleges, in the county council area. The unitary authority of Milton Keynes operates a comprehensive education system: there are 8 maintained (state) secondary schools in the borough council area. Buckinghamshire and Milton Keynes are also home to the University of Buckingham, Buckinghamshire New University, the Open University and the University Campus Milton Keynes.
Notable people.
Buckinghamshire is the birthplace and/or final resting place of several notable individuals. St Osyth was born in Quarrendon and was buried in Aylesbury in the 7th century while at about the same time Saint Rumwold was buried in Buckingham. In the medieval period Roger of Wendover was, as the name suggests, from Wendover and Anne Boleyn also owned property in the same town. It is said that King Henry VIII made Aylesbury the county town in preference to Buckingham because Boleyn's father owned property there and was a regular visitor himself. Other medieval residents included Edward the Confessor, who had a palace at Brill, and John Wycliffe who lived in Ludgershall.
Buckinghamshire later became home to some notable literary characters. Edmund Waller was brought up in Beaconsfield and served as Member of Parliament for both Amersham and Wycombe. Percy Bysshe Shelley and his wife Mary lived for some time in Marlow, attracted to the town by their friend Thomas Love Peacock who also lived there. John Milton lived in Chalfont St Giles and his cottage can still be visited there and John Wilkes was MP for Aylesbury. Later authors include Jerome K. Jerome who lived at Marlow, T. S. Eliot who also lived at Marlow, Roald Dahl who lived at Great Missenden, Enid Blyton who lived in Beaconsfield and Edgar Wallace who lived at Bourne End and is buried in Little Marlow. Modern-day writers from Bucks include Terry Pratchett who was born in Beaconsfield, Tim Rice who is from Amersham and Andy Riley who is from Aylesbury.
During the Second World War a number of European politicians and statesmen were exiled in England. Many of these settled in Bucks as it is close to London. President Edvard Beneš of Czechoslovakia lived at Aston Abbotts with his family while some of his officials were stationed at nearby Addington and Wingrave. Meanwhile, Władysław Sikorski, military leader of Poland, lived at Iver and King Zog of Albania lived at Frieth. Much earlier, King Louis XVIII of France lived in exile at Hartwell House from 1809 to 1814.
Also on the local political stage Buckinghamshire has been home to Nancy Astor who lived in Cliveden, Frederick, Prince of Wales who also lived in Cliveden, Baron Carrington who lives in Bledlow, Benjamin Disraeli who lived at Hughenden Manor and was made Earl of Beaconsfield, John Hampden who was from Great Hampden and is revered in Aylesbury to this day and Prime Minister Archibald Primrose, 5th Earl of Rosebery who lived at Mentmore. Also worthy of note are William Penn who believed he was descended from the Penn family of Penn and so is buried nearby and the current Prime Minister of the United Kingdom, who has an official residence at Chequers. Finally John Archdale colonial governor of North Carolina and South Carolina, although more notably American, was born in Buckinghamshire.
Other notable natives of Buckinghamshire include:
Celebrities living in Bucks include:

</doc>
<doc id="55690" url="https://en.wikipedia.org/wiki?curid=55690" title="Acre, Israel">
Acre, Israel

Acre ( or , , "ʻAkko", most commonly spelled as Akko; , "ʻAkkā") is a city in the northern coastal plain region of the Northern District, Israel at the northern extremity of Haifa Bay. The city occupies an important location, as it sits on the coast of the Mediterranean, traditionally linking the waterways and commercial activity with the Levant. Acre is one of the oldest sites in the world.
Historically, it was a strategic coastal link to the Levant. During the Crusades it was known as "St. John d'Acre" after the Knights Hospitaller, who had their headquarters there.
Acre is the holiest city of the Bahá'í Faith, and as such gets many Baha'i pilgrims. In the population was . Acre is a mixed city, that includes Jews, Muslims, Christians and Baha'is. The mayor is Shimon Lankri, who was reelected in 2011.
Etymology.
The city was known as Ptolemais during the Hellenistic and later Roman-Byzantine period.
History.
Antiquity.
Acre is one of the oldest continuously inhabited sites in the region. The name "Aak", which appears on the tribute-lists of Thutmose III (c. 15th century BC), may be a reference to Acre. The Amarna letters also mention a place named "Akka", as well as the Execration texts, that pre-date them. First settlement at the site of Ancient Acre appears to have been in the Early Bronze Age, or about 3000 BC. In the Hebrew Bible, (Judges 1:31), Akko is one of the places from which the Israelites did not drive out the Canaanites. It is later described in the territory of the tribe of Asher and according to Josephus, was ruled by one of Solomon's provincial governors. Throughout Israelite rule, it was politically and culturally affiliated with Phoenicia. Around 725 BC, Akko joined Sidon and Tyre in a revolt against Shalmaneser V.
Greek, Judean and Roman periods.
Greek historians refer to the city as "Ake", meaning "cure." According to the Greek myth, Heracles found curative herbs here to heal his wounds. Josephus calls it "Akre". The name was changed to "Antiochia Ptolemais" (in Greek Αντιόχεια Πτολεμαίς) shortly after Alexander the Great's conquest, and then to Ptolemais, probably by Ptolemy Soter, after the partition of the kingdom of Alexander the Great.
Strabo refers to the city as once a rendezvous for the Persians in their expeditions against Egypt. About 165 BC Judas Maccabeus defeated the Seleucids in several battles in Galilee, and drove them into Ptolemais. About 153 BC Alexander Balas, son of Antiochus Epiphanes, contesting the Seleucid crown with Demetrius, seized the city, which opened its gates to him. Demetrius offered many bribes to the Maccabees to obtain Jewish support against his rival, including the revenues of Ptolemais for the benefit of the Temple in Jerusalem, but in vain. Jonathan Maccabaeus threw in his lot with Alexander, and in 150 BC he was received by him with great honour in Ptolemais. Some years later, however, Tryphon, an officer of the Seleucids, who had grown suspicious of the Maccabees, enticed Jonathan into Ptolemais and there treacherously took him prisoner.
The city was captured by Alexander Jannaeus, Cleopatra VII of Egypt and Tigranes II of Armenia. Here Herod built a gymnasium. The Acts of the Apostles reports that Luke the Evangelist, the apostle Paul and their companions spent a day in Ptolemais with the Christian brethren there (). A Roman colonia was established at the city, Colonia Claudii Cæsaris. The Romans enlarged the port and the city, that flourished for six centuries even as a Christian center. After the permanent division of the Roman Empire in 395 AD, Ptolemais-Akko was administered by the Eastern ("Byzantine") Empire. In 636 AD the city was conquered by the Arabs.
Early Islamic era.
Following the defeat of the Byzantine army of Heraclius by the Muslim army of Khalid ibn al-Walid in the Battle of Yarmouk, and the capitulation of the Christian city of Jerusalem to the Caliph Umar, Acre came under the rule of the Rashidun Caliphate beginning in 638. According to the early Muslim chronicler al-Baladhuri, the actual conquest of Acre was led by Shurahbil ibn Hasana, and it likely surrendered without resistance. The Arab conquest brought a revival to the town of Acre, and it served as the main port of Palestine through the Umayyad and Abbasid Caliphates that followed, and through Crusader rule into the 13th century.
The first Umayyad caliph, Mu'awiyah (r. 661-680), regarded the coastal towns of the Levant as strategically important. Thus, he strengthened Acre's fortifications and settled Persians from other parts of Muslim Syria to inhabit the city. From Acre, which became one of the region's most important dockyards along with Tyre, Mu'awiyah launched an attack against Byzantine-held Cyprus. The Byzantines assaulted the coastal cities in 669, prompting Mu'awiyah to assemble and send shipbuilders and carpenters to Acre. The city would continue to serve as the principal naval base of Jund al-Urdunn ("Military District of Jordan") until the reign of Caliph Hisham ibn Abd al-Malik (723-743), who moved the bulk of the shipyards north to Tyre. Nonetheless, Acre remained militarily significant through the early Abbasid period, with Caliph al-Mutawakkil issuing an order to make Acre into a major naval base in 861, equipping the city with battleships and combat troops.
During the 10th century, Acre was still part of Jund al-Urdunn. Local Arab geographer al-Muqaddasi visited Acre during the early Fatimid era in 985, describing it as a fortified coastal city with a large mosque possessing a substantial olive grove. Fortifications had been previously built by the autonomous Emir Ibn Tulun of Egypt, who annexed the city in the 870s, and provided relative safety for merchant ships arriving at the city's port. When Persian traveller Nasir Khusraw visited Acre in 1047, he noted that the large Friday mosque was built of marble, located in the centre of the city and just south of it lay the "tomb of the Prophet Salih." Khusraw provided a description of the city's size, which roughly translated as having a length of and a width of . This figure indicates that Acre at that time was larger than its current Old City area, most of which was built between the 18th and 19th centuries.
Crusader and Mamluk period.
First Crusader Kingdom of Jerusalem.
After roughly four years of siege, Acre finally capitulated to the forces of King Baldwin I of Jerusalem in 1104 during the First Crusade. The Crusaders made the town their chief port in Palestine. On the first Crusade, Fulcher relates his travels with the Crusading armies of King Baldwin, including initially staying over in Acre before the army’s advance to Jerusalem. This demonstrates that even from the beginning, Acre was an important link between the Crusaders and their advance into the Levant. Its function was to provide Crusaders with a foothold in the region and access to vibrant trade that made them prosperous, especially giving them access to the Asiatic spice trade. By the 1130s it had a population of around 25,000 and was only matched for size in the Crusader kingdom by the city of Jerusalem. Around 1170 it became the main port of the eastern Mediterranean, and the kingdom of Jerusalem was regarded in the west as enormously wealthy above all because of Acre. According to an English contemporary, it provided more for the Crusader crown than the total revenues of the king of England.
The Andalusian geographer Ibn Jubayr wrote that in 1185 there was still a Muslim community in the city who worshipped in a small mosque.
Ayyubid intermezzo (1187-1191).
Acre, along with Beirut and Sidon, capitulated without a fight to the Ayyubid sultan Saladin in 1187, after his decisive victory at Hattin and the subsequent Muslim capture of Jerusalem.
Second Crusader Kingdom of Jerusalem (1191-1291).
Acre remained in Muslim hands until it was unexpectedly besieged by King Guy of Lusignan—reinforced by Pisan naval and ground forces—in August 1189. The siege was unique in the history of the Crusades since the Frankish besiegers were themselves besieged, by Saladin's troops. It was not captured until July 1191 when the forces of the Third Crusade, led by King Richard I of England and King Philip II of France, came to King Guy's aid. Acre then served as the "de facto" capital of the remnant Kingdom of Jerusalem in 1192. During the siege, German merchants from Lübeck and Bremen had founded a field hospital, which became the nucleus of the chivalric Teutonic Order. Upon the Sixth Crusade, the city was placed under the administration of the Knights Hospitaller military order. Acre continued to prosper as major commercial hub of the eastern Mediterranean, but also underwent turbulent times due to the bitter infighting among the Crusader factions that occasionally resulted in civil wars.
The old part of the city, where the port and fortified city were located, protrudes from the coastline, exposing both sides of the narrow piece of land to the sea. This could maximize its efficiency as a port, and the narrow entrance to this protrusion served as a natural and easy defense to the city. Both the archaeological record and Crusader texts emphasize Acre’s strategic importance—a city in which it was crucial to pass through, control, and, as evidenced by the massive walls, protect.
Mamluk Period (1291-1517).
Acre was the final stronghold of the Crusader states when much of the Levantine coastline was conquered by Mamluk forces. The city, having been isolated and largely abandoned by Europe, capitulated to the Mamluks led by Sultan al-Ashraf Khalil in a bloody siege in 1291. In line with Mamluk policy regarding the coastal cities (to prevent their future utilization by Crusader forces), Acre was entirely destroyed with the exception of a few religious edifices considered sacred by the Muslims, namely the Nabi Salih tomb and the Ayn Bakar spring. The destruction of the city led to popular Arabic sayings in the region enshrining its past glory. In 1321 the Syrian geographer Abu'l Fida wrote that Acre was "a beautiful city" but still in ruins following its capture by the Mamluks. Nonetheless, the "spacious" port was still in use and the city was full of artisans. Throughout the Mamluk era (1260-1517), Acre was succeeded by Safad as the principal city of its province.
Ottoman era.
The Ottomans under Sultan Selim I captured what remained of the city in 1517, which had been burned down by the Mamluks and had become a tiny fishing village. English academic Henry Maundrell in 1697 found it a ruin, save for a "khan" (caravanserai) built and occupied by French merchants for their use, a mosque and a few poor cottages. The "khan" was named Khan al-Ilfranj after its French founders.
During Ottoman rule, Acre continued to play an important role in the region via smaller autonomous sheikhdoms. Towards the end of the 18th century Acre revived under the rule of Zahir al-Umar, the Arab ruler of the Galilee, who made the city capital of his autonomous sheikhdom. Zahir rebuilt Acre's fortifications, using materials from the city's medieval ruins. He died outside its walls during an offensive against him by the Ottoman state in 1775. His successor, Jezzar Pasha, further fortified its walls when he virtually moved the capital of the Saida Eyelet ("Province of Sidon") to Acre where he resided. Jezzar's improvements were accomplished through heavy imposts secured for himself all the benefits derived from his improvements. About 1780 Jezzar peremptorily banished the French trading colony, in spite of protests from the French government, and refused to receive a consul. Both Zahir and Jezzar undertook ambitious architectural projects in the city, building several caravanserais, mosques, public baths and other structures. Some of the notable works included the Jezzar Pasha Mosque, which was built out of stones from the ancient ruins of Caesarea and Atlit and the Khan al-Umdan, both built on Jezzar's orders.
In 1799 Napoleon, in pursuance of his scheme for raising a Syrian rebellion against Turkish domination, appeared before Acre, but after a siege of two months (March–May) was repulsed by the Turks, aided by Sir Sidney Smith and a force of British sailors. Having lost his siege cannons to Smith, Napoleon attempted to lay siege to the walled city defended by Ottoman troops on 20 March 1799, using only his infantry and small-calibre cannons, a strategy which failed, leading to his retreat two months later on 21 May.
Jezzar was succeeded on his death by his "mamluk" Sulayman Pasha, under whose milder rule the town advanced in prosperity till his death in 1819. After his death, Haim Farhi, who was his adviser, paid a huge sum in bribes to assure that Abdullah Pasha (son of Ali Pasha, the deputy of Sulayman Pasha), whom he had known from youth, will be appointed as ruler. Abdullah Pasha ruled Acre until 1831, when Ibrahim Pasha besieged and reduced the town and destroyed its buildings. During the Oriental Crisis of 1840 it was bombarded on 4 November 1840 by the allied British, Austrian and French squadrons, and in the following year restored to Turkish rule. It regained some of its former prosperity after linking with Hejaz Railway by a branch line from Haifa in 1913. It was a sanjak centre (Sanjak of Acre) in Beyrut Eyalet until English occupation on 23 September 1918 during World War I.
Mandatory Palestine.
At the beginning of the Mandate period, in the 1922 census of Palestine, Acre had 6,420 residents: 4,883 of whom were Muslim; 1,344 Christian; 102 Baha'i; 78 Jewish and 13 Druze. The British Mandate government reconstructed Acre, and its economic situation improved. The 1931 census counted 7,897 people in Acre, 6076 Muslims, 1523 Christians, 237 Jews, 51 Baha'i and 10 Druse. In 1946 Acre's population numbered around 13,000.
Acre's fort was converted into a jail, where members of the Jewish underground were held during their struggle against the British, among them Zeev Jabotinski, Shlomo ben Yossef, and Dov Grunner. Grunner and ben Yossef were executed there. Other Jewish inmates were freed by members of the Irgun, who broke into the jail on 4 May 1947 and succeeded in releasing Jewish underground movement activists. Over 200 Arab inmates also escaped.
In the 1947 UN Partition Plan, Acre was designated part of a future Arab state. Before the 1948 Arab-Israeli War broke out, Acre's Arabs attacked neighbouring Jewish settlements and Jewish transportation; in March 1948 42 Jews were killed on an attack on a convoy north of the city, whilst on 18 March four Jewish employees of the electricity company and five British soldiers protecting them were killed whilst travelling to repair damaged lines near the city.
During the 1948 War, Acre was besieged by Israeli forces. A typhoid fever outbreak occurred in Acre at this time. According to the Red Cross archives, an emergency meeting held at the Lebanese Red Cross hospital in Acre concluded that the infection was water borne, not due to crowded or unhygienic conditions. Brigadier Beveridge, chief of the British medical services, Colonel Bonnet of the British army, and delegates of Red Cross were present in this meeting. Beveridge
proclaimed at the time that "Nothing like that ever happened in Palestine". According to anti-Zionist historian Ilan Pappé, even the guarded language of Red Cross reports points to outside poisoning as the sole explanation of the outbreak.
State of Israel.
Acre was captured by Israel on 17 May 1948, displacing about three-quarters of the Arab population of the city (13,510 of 17,395). Throughout the 1950s many Jewish neighbourhoods were established at the northern and eastern parts of the city, as it became a development town, designated to absorb numerous Jewish immigrants, largely Jews from Morocco. The old city of Akko remained largely Arab Muslim (including several Bedouin families), with Arab Christian neighbourhood in close proximity. The city also attracted Bahá'í worshippers, some of whom became permanent residents in the city, where the Bahá'í Mansion of Bahjí is located. Acre has also served as a base for important events in Baha'i history, including being the birthplace of Shoghi Effendi, and the short-lived schism between Baha'is initiated by the attacks by Mírzá Muhammad `Alí against `Abdu'l-Bahá. Baha'is have since commemorated various events that have occurred in the city, including the imprisonment of Baha'u'llah.
In the 1990s the city absorbed thousands of Jews, who immigrated from the Soviet Union and later from Russia and Ukraine. Within several years, however, the population balance between Jews and Arabs shifted backwards, as northern neighbourhoods were abandoned by many of its Jewish residents in favour of new housing projects in nearby Nahariya, while many Muslim Arabs moved in (largely coming from nearby Arab villages). Nevertheless, the city still has a clear Jewish majority; in 2011 the population of 46,000 included 30,000 Jews and 14,000 Arabs.
Ethnic tensions erupted in the city on 8 October 2008 after an Arab citizen drove through a predominantly Jewish neighbourhood during Yom Kippur, leading to five days of violence between Arabs and Jews.
In 2009, the population of Acre reached 46,300. The current mayor Shimon Lankri was re-elected in 2011.
Demography.
According to the Israeli Central Bureau of Statistics, there are 46,300 citizens in Acre. Acre's population is mixed with Jews and Arabs. Most Arabs are Muslims and Christians, with small minorities of Druze and Baha'i. Jews are 67.1% of the city's population, Muslim Arabs are 25.3% of the city's population, Christian Arabs are 2.4% of the city's population and other citizens make up 5.2% of the city's population. 
According to the Israeli Central Office of Statistics, 95% of the residents in the Old City are Arab. Only about 15% percent of the current Arab population in the city descends from families who lived there before 1948. In 1999, there were 22 schools in Acre with an enrollment of 15,000 children.
Transportation.
The Acre central bus station, served by Egged and Nateev Express, offers intra-city and inter-city bus routes to destinations all over Israel. Nateev Express is currently contracted to provide the intra-city bus routes within Acre. The city is also served by the Acre Railway Station, which is on the main Coastal railway line to Nahariya, with southerly trains to Beersheba and Modi'in. Acre is intended to be the terminus for a future branch line to Karmiel, which is currently under construction.
Education and culture.
The Sir Charles Clore Jewish-Arab Community Centre in the Kiryat Wolfson neighbourhood runs youth clubs and programs for Jewish and Arab children. In 1990, Mohammed Faheli, an Arab resident of Acre, founded the Acre Jewish-Arab association, which originally operated out of two bomb shelters. In 1993, Dame Vivien Duffield of the Clore Foundation donated funds for a new building. Among the programs offered is Peace Child Israel, which employs theatre and the arts to teach coexistence. The participants, Jews and Arabs, spend two months studying conflict resolution and then work together to produce an original theatrical performance that addresses the issues they have explored. Another program is Patriots of Acre, a community responsibility and youth tourism program that teaches children to become ambassadors for their city. In the summer, the centre runs an Arab-Jewish summer camp for 120 disadvantaged children aged 5–11. Some 1,000 children take part in the Acre Centre's youth club and youth programming every week. Adult education programs have been developed for Arab women interested in completing their high school education and acquiring computer skills to prepare for joining the workforce. The centre also offers parenting courses, and music and dance classes.
The Acre Festival of Alternative Israeli Theatre is an annual event that takes place in October, coinciding with the holiday of Sukkot. The festival, inaugurated in 1979, provides a forum for non-conventional theatre, attracting local and overseas theatre companies. Theatre performances by Jewish and Arab producers are staged at indoor and outdoor venues around the city.
Sports.
The city's football team Hapoel Ironi Acre is a member of the Israeli Premier League, the top tier of Israeli football. They play in the Acre Municipal Stadium which was opened in September 2011. At the end of the 2008–09 season the club finished in the top five and was promoted to the top tier for a second time, after an absence of 31 years. 
In the past the city was also home to Maccabi Acre. however, the club was relocated to nearby Kiryat Ata and was renamed Maccabi Ironi Kiryat Ata. 
Other current active clubs are Ahi Acre and the newly formed Maccabi Ironi Acre, both playing in Liga Bet. Both club also host their matches in the Acre Municipal Stadium. 
Landmarks.
Acre's Old City has been designated by UNESCO as a World Heritage Site. Since the 1990s, large-scale archaeological excavations have been undertaken and efforts are being made to preserve ancient sites. In 2009, renovations were planned for Khan al-Umdan, the "Inn of the Columns," the largest of several Ottoman inns still standing in Acre. It was built near the port at the end of the 18th century by Ahmed Pasha al-Jazzar. Merchants who arrived at the port would unload their wares on the first floor and sleep in lodgings on the second floor. In 1906, a clock tower was added over the main entrance marking the 25th anniversary of the reign of the Turkish sultan, Abdul Hamid II.
City walls.
In 1750, Zahir al-Umar, the ruler of Acre, utilized the remnants of the Crusader walls as a foundation for his walls. Two gates were set in the wall, the "land gate" in the eastern wall, and the "sea gate" in the southern wall. The walls were reinforced between 1775 and 1799 by Jezzar Pasha and survived Napoleon's siege. The wall was thin: its height was between and and its thickness only .
A heavy land defense wall was built north and east to the city in 1800–1814 by Jezzar Pasha and his Jewish advisor Haim Farhi. It consists of a modern counter artillery fortification which includes a thick defensive wall, a dry moat, cannon outposts and three "burges" (large defensive towers). Since then, no major modifications have taken place. The sea wall, which remains mostly complete, is the original wall built by Zahir that was reinforced by Jezzar Pasha. In 1910 two additional gates were set in the walls, one in the northern wall and one in the north-western corner of the city. In 1912 the Acre lighthouse was built on the south-western corner of the walls. 
Jezzar Pasha Mosque.
The Mosque of Jezzar Pasha was built in 1781. Jezzar Pasha and his successor Sulayman Pasha, are both buried in a small graveyard adjacent to the mosque. In a shrine on the second level of the mosque, a single hair from the prophet Mohammed's beard is kept and shown on special ceremonial occasions.
Citadel of Acre.
The current building which constitutes the citadel of Acre is an Ottoman fortification, built on the foundation of the Hospitallerian citadel. The citadel was part of the city's defensive formation, reinforcing the northern wall. During the 20th century the citadel was used mainly as a prison and as the site for a gallows. During the British mandate period, activists of Jewish Zionist resistance movements were held prisoner there; some were executed there.
Hamam al-Basha.
Built in 1795 by Jezzar Pasha, Acre's hammam has a series of hot rooms and a hexagonal steam room with a marble fountain. It was used by the Irgun as a bridge to break into the citadel's prison. The bathhouse kept functioning until 1950.
Hospitaller refectory.
Under the citadel and prison of Acre, archaeological excavations revealed a complex of halls, which was built and used by the Hospitallers Knights. This complex was a part of the Hospitallers' citadel, which was included in the northern defences of Acre. The complex includes six semi-joined halls, one recently excavated large hall, a dungeon, a refectory (dining room) and remains of a Gothic church.
Other medieval sites.
Other Medieval European remains include the Church of Saint George and adjacent houses at the Genovese Square (called Kikar ha-Genovezim or Kikar Genoa in Hebrew). There were also residential quarters and marketplaces run by merchants from Pisa and Amalfi in Crusader and medieval Acre. 
Bahá'í holy places.
There are many Bahá'í holy places in and around Acre. They originate from Bahá'u'lláh's imprisonment in the Citadel during Ottoman Rule. The final years of Bahá'u'lláh's life were spent in the Mansion of Bahjí, just outside Acre, even though he was still formally a prisoner of the Ottoman Empire. Bahá'u'lláh died on 29 May 1892 in Bahjí, and his shrine is the most holy place for Bahá'ís — their Qiblih, the location they face when saying their daily prayers. It contains the remains of Bahá'u'lláh and is near the spot where he died in the Mansion of Bahjí. Other Bahá'í sites in Acre are the House of `Abbúd (where Bahá'u'lláh and his family resided) and the House of `Abdu'lláh Páshá (where later 'Abdu'l-Bahá resided with his family), and the Garden of Ridván where he spent the end of his life. In 2008, the Bahai holy places in Acre and Haifa were added to the UNESCO World Heritage List.
Archaeology.
In 2012, archaeologists excavating at the foot of the city's southern seawall found a quay and other evidence of a 2,300-year old port. Mooring stones weighing 250-300 kilograms each were unearthed at the edge of a 5-meter long stone platform chiseled in Phoenician-style, thought to be an installation that helped raise military vessels from the water onto the shore.
Crusades.
Under the citadel and prison of Acre, archaeological excavations revealed a complex of halls, which was built and used by the Hospitallers Knights. This complex was a part of the Hospitallers' citadel, which was combined in the northern wall of Acre. The complex includes six semi-joined halls, one recently excavated large hall, a dungeon, a dining room and remains of an ancient Gothic church. Medieval European remains include the Church of Saint George and adjacent houses at the Genovese Square (called Kikar ha-Genovezim or Kikar Genoa in Hebrew). There were also residential quarters and marketplaces run by merchants from Pisa and Amalfi in Crusader and medieval Acre. 
International relations.
Acre is twinned with:
Notable people associated with Acre.
Apart from those mentioned in the article (Alexander the Great, St Paul, Richard the Lionheart, Napoleon):

</doc>
<doc id="55691" url="https://en.wikipedia.org/wiki?curid=55691" title="CDA">
CDA

CDA or Cda may refer to:

</doc>
<doc id="55693" url="https://en.wikipedia.org/wiki?curid=55693" title="Turquoise">
Turquoise

Turquoise is an opaque, blue-to-green mineral that is a hydrated phosphate of copper and aluminium, with the chemical formula CuAl6(phosphate)4(OH)8·4water. It is rare and valuable in finer grades and has been prized as a gem and ornamental stone for thousands of years owing to its unique hue. In recent times, turquoise has been devalued, like most other opaque gems, by the introduction onto the market of treatments, imitations, and synthetics.
The substance has been known by many names, but the word "turquoise" dates to the 17th century and is derived from the French "turques" for "Turks" because the mineral was first brought to Europe from Turkey, from mines in the historical Khorasan Province of Persia. Pliny the Elder referred to the mineral as "callais" and the Aztecs knew it as "chalchihuitl".
Properties of turquoise.
The finest of turquoise reaches a maximum hardness of just under 6, or slightly more than window glass. Characteristically a cryptocrystalline mineral, turquoise almost never forms single crystals and all of its properties are highly variable. Its crystal system is proven to be triclinic via X-ray diffraction testing. With lower hardness comes lower specific gravity (2.60–2.90) and greater porosity: These properties are dependent on grain size. The lustre of turquoise is typically waxy to subvitreous, and transparency is usually opaque, but may be semitranslucent in thin sections. Colour is as variable as the mineral's other properties, ranging from white to a powder blue to a sky blue, and from a blue-green to a yellowish green. The blue is attributed to idiochromatic copper while the green may be the result of either iron impurities (replacing aluminium) or dehydration.
The refractive index (as measured by sodium light, 589.3 nm) of turquoise is approximately 1.61 or 1.62; this is a mean value seen as a single reading on a gemmological refractometer, owing to the almost invariably polycrystalline nature of turquoise. A reading of 1.61–1.65 (birefringence 0.040, biaxial positive) has been taken from rare single crystals. An absorption spectrum may also be obtained with a hand-held spectroscope, revealing a line at 432 nanometres and a weak band at 460 nanometres (this is best seen with strong reflected light). Under longwave ultraviolet light, turquoise may occasionally fluoresce green, yellow or bright blue; it is inert under shortwave ultraviolet and X-rays.
Turquoise is insoluble in all but heated hydrochloric acid. Its streak is a pale bluish white and its fracture is conchoidal, leaving a waxy lustre. Despite its low hardness relative to other gems, turquoise takes a good polish. Turquoise may also be peppered with flecks of pyrite or interspersed with dark, spidery limonite veining.
Formation.
As a secondary mineral, turquoise apparently forms by the action of percolating acidic aqueous solutions during the weathering and oxidation of pre-existing minerals. For example, the copper may come from primary copper sulfides such as chalcopyrite or from the secondary carbonates malachite or azurite; the aluminium may derive from feldspar; and the phosphorus from apatite. Climate factors appear to play an important role as turquoise is typically found in arid regions, filling or encrusting cavities and fractures in typically highly altered volcanic rocks, often with associated limonite and other iron oxides. In the American southwest turquoise is almost invariably associated with the weathering products of copper sulfide deposits in or around potassium feldspar bearing porphyritic intrusives. In some occurrences alunite, potassium aluminium sulfate, is a prominent secondary mineral. Typically turquoise mineralization is restricted to a relatively shallow depth of less than , although it does occur along deeper fracture zones where secondary solutions have greater penetration or the depth to the water table is greater.
Although the features of turquoise occurrences are consistent with a secondary or supergene origin, some sources refer to a hypogene origin. The "hypogene" hypothesis holds that the aqueous solutions originate at significant depth, from hydrothermal processes. Initially at high temperature, these solutions rise upward to surface layers, interacting with, and leaching essential elements from pre-existing minerals in the process. As the solutions cool, turquoise precipitates, lining cavities and fractures within the surrounding rock. This hypogene process is applicable to the original copper sulfide deposition; however, it is difficult to account for the many features of turquoise occurrences by a hypogene process. That said, there are reports of two phase fluid inclusions within turquoise grains that give elevated homogenization temperatures of that require explanation.
Turquoise is nearly always cryptocrystalline and massive and assumes no definite external shape. Crystals, even at the microscopic scale, are exceedingly rare. Typically the form is vein or fracture filling, nodular, or botryoidal in habit. Stalactite forms have been reported. Turquoise may also pseudomorphously replace feldspar, apatite, other minerals, or even fossils. Odontolite is fossil bone or ivory that has been traditionally thought to have been altered by turquoise or similar phosphate minerals such as the iron phosphate vivianite. Intergrowth with other secondary copper minerals such as chrysocolla is also common.
Occurrence.
Turquoise was among the first gems to be mined, and while many historic sites have been depleted, some are still worked to this day. These are all small-scale, often seasonal operations, owing to the limited scope and remoteness of the deposits. Most are worked by hand with little or no mechanization. However, turquoise is often recovered as a byproduct of large-scale copper mining operations, especially in the United States.
Iran.
For at least 2,000 years, Iran, previously known as Persia in the West, has remained an important source of turquoise which was named by Iranians initially "pirouzeh" meaning "victory" and later after Arab invasion "firouzeh". In Iranian architecture, the blue turquoise was used to cover the domes of the Iranian palaces because its intense blue colour was also a symbol of heaven on earth.
This deposit, which is blue naturally, and turns green when heated due to dehydration, is restricted to a mine-riddled region in Nishapur, the mountain peak of Ali-mersai, which is tens of kilometers from Mashhad, the capital of Khorasan Province, Iran. A weathered and broken trachyte is host to the turquoise, which is found both "in situ" between layers of limonite and sandstone, and amongst the scree at the mountain's base. These workings, together with those of the Sinai Peninsula, are the oldest known.
Sinai.
Since at least the First Dynasty (3000 BCE), and possibly before then, turquoise was used by the Egyptians and was mined by them in the Sinai Peninsula, called "Country of Turquoise" by the native Monitu. There are six mines in the region, all on the southwest coast of the peninsula, covering an area of some . The two most important of these mines, from a historic perspective, are Serabit el-Khadim and Wadi Maghareh, believed to be among the oldest of known mines. The former mine is situated about 4 kilometres from an ancient temple dedicated to Hathor.
The turquoise is found in sandstone that is, or was originally, overlain by basalt. Copper and iron workings are present in the area. Large-scale turquoise mining is not profitable today, but the deposits are sporadically quarried by Bedouin peoples using homemade gunpowder. In the rainy winter months, miners face a risk from flash flooding; even in the dry season, death from the collapse of the haphazardly exploited sandstone mine walls is not unheard of. The colour of Sinai material is typically greener than Iranian material, but is thought to be stable and fairly durable. Often referred to as "Egyptian" turquoise, Sinai material is typically the most translucent, and under magnification its surface structure is revealed to be peppered with dark blue discs not seen in material from other localities.
United States.
The Southwest United States is a significant source of turquoise; Arizona, California (San Bernardino, Imperial, Inyo counties), Colorado (Conejos, El Paso, Lake, Saguache counties), New Mexico (Eddy, Grant, Otero, Santa Fe counties) and Nevada (Clark, Elko, Esmeralda County, Eureka, Lander, Mineral County and Nye counties) are (or were) especially rich. The deposits of California and New Mexico were mined by pre-Columbian Native Americans using stone tools, some local and some from as far away as central Mexico. Cerrillos, New Mexico is thought to be the location of the oldest mines; prior to the 1920s, the state was the country's largest producer; it is more or less exhausted today. Only one mine in California, located at Apache Canyon, operates at a commercial capacity today.
The turquoise occurs as vein or seam fillings, and as compact nuggets; these are mostly small in size. While quite fine material is sometimes found—rivalling Iranian material in both colour and durability—most American turquoise is of a low grade (called "chalk turquoise"); high iron levels mean greens and yellows predominate, and a typically friable consistency in the turquoise's untreated state precludes use in jewellery.
Arizona is currently the most important producer of turquoise by value. Several mines exist in the state, two of them famous for their unique colour and quality and considered the best in the industry: the Sleeping Beauty Mine in Globe ceased turquoise mining in August 2012. The mine chose to send all ore to the crusher and to concentrate on copper production due to the rising price of copper on the world market. The price of natural untreated Sleeping Beauty turquoise has risen dramatically since the mine's closing. The Kingman Mine as of 2015 is still operates alongside a copper mine outside of the city. Other mines include the Blue Bird mine, Castle Dome, and Ithaca Peak, but they are mostly inactive due to the high cost of operations and federal regulations The Phelps Dodge Lavender Pit mine at Bisbee ceased operations in 1974 and never had a turquoise contractor. All Bisbee turquoise was "lunch pail" mined. It came out of the copper ore mine in miners lunch pails. Morrenci and Turquoise Peak are either inactive or depleted.
Nevada is the country's other major producer, with more than 120 mines which have yielded significant quantities of turquoise. Unlike elsewhere in the US, most Nevada mines have been worked primarily for their gem turquoise and very little has been recovered as a byproduct of other mining operations. Nevada turquoise is found as nuggets, fracture fillings and in breccias as the cement filling interstices between fragments. Because of the geology of the Nevada deposits, a majority of the material produced is hard and dense, being of sufficient quality that no treatment or enhancement is required. While nearly every county in the state has yielded some turquoise, the chief producers are in Lander and Esmeralda counties. Most of the turquoise deposits in Nevada occur along a wide belt of tectonic activity that coincides with the state's zone of thrust faulting. It strikes about N15°E and extends from the northern part of Elko County, southward down to the California border southwest of Tonopah. Nevada has produced a wide diversity of colours and mixes of different matrix patterns, with turquoise from Nevada coming in various shades of blue, blue-green, and green. Some of this unusually coloured turquoise may contain significant zinc and iron, which is the cause of the beautiful bright green to yellow-green shades. Some of the green to green yellow shades may actually be variscite or faustite, which are secondary phosphate minerals similar in appearance to turquoise. A significant portion of the Nevada material is also noted for its often attractive brown or black limonite veining, producing what is called "spiderweb matrix". While a number of the Nevada deposits were first worked by Native Americans, the total Nevada turquoise production since the 1870s has been estimated at more than 600 tons, including nearly 400 tons from the Carico Lake mine. In spite of increased costs, small scale mining operations continue at a number of turquoise properties in Nevada, including the Godber, Orvil Jack and Carico Lake mines in Lander County, the Pilot Mountain Mine in Mineral County, and several properties in the Royston and Candelaria areas of Esmerelda County.
In 1912, the first deposit of distinct, single-crystal turquoise was discovered in Lynch Station, Campbell County, Virginia. The crystals, forming a druse over the mother rock, are very small; 1 mm (0.04 in) is considered large. Until the 1980s Virginia was widely thought to be the only source of distinct crystals; there are now at least 27 other localities.
In an attempt to recoup profits and meet demand, some American turquoise is treated or "enhanced" to a certain degree. These treatments include innocuous waxing and more controversial procedures, such as dyeing and impregnation (see Treatments). There are however, some American mines which produce materials of high enough quality that no treatment or alterations are required. Any such treatments which have been performed should be disclosed to the buyer on sale of the material.
Other sources.
China has been a minor source of turquoise for 3,000 years or more. Gem-quality material, in the form of compact nodules, is found in the fractured, silicified limestone of Yunxian and Zhushan, Hubei province. Additionally, Marco Polo reported turquoise found in present-day Sichuan. Most Chinese material is exported, but a few carvings worked in a manner similar to jade exist. In Tibet, gem-quality deposits purportedly exist in the mountains of Derge and Nagari-Khorsum in the east and west of the region respectively.
Other notable localities include: Afghanistan; Australia (Victoria and Queensland); north India; northern Chile (Chuquicamata); Cornwall; Saxony; Silesia; and Turkestan.
History of use.
The pastel shades of turquoise have endeared it to many great cultures of antiquity: it has adorned the rulers of Ancient Egypt, the Aztecs (and possibly other Pre-Columbian Mesoamericans), Persia, Mesopotamia, the Indus Valley, and to some extent in ancient China since at least the Shang Dynasty. Despite being one of the oldest gems, probably first introduced to Europe (through Turkey) with other Silk Road novelties, turquoise did not become important as an ornamental stone in the West until the 14th century, following a decline in the Roman Catholic Church's influence which allowed the use of turquoise in secular jewellery. It was apparently unknown in India until the Mughal period, and unknown in Japan until the 18th century. A common belief shared by many of these civilizations held that turquoise possessed certain prophylactic qualities; it was thought to change colour with the wearer's health and protect him or her from untoward forces.
The Aztecs inlaid turquoise, together with gold, quartz, malachite, jet, jade, coral, and shells, into provocative (and presumably ceremonial) mosaic objects such as masks (some with a human skull as their base), knives, and shields. Natural resins, bitumen and wax were used to bond the turquoise to the objects' base material; this was usually wood, but bone and shell were also used. Like the Aztecs, the Pueblo, Navajo and Apache tribes cherished turquoise for its amuletic use; the latter tribe believe the stone to afford the archer dead aim. Among these peoples turquoise was used in mosaic inlay, in sculptural works, and was fashioned into toroidal beads and freeform pendants. The Ancestral Puebloans (Anasazi) of the Chaco Canyon and surrounding region are believed to have prospered greatly from their production and trading of turquoise objects. The distinctive silver jewellery produced by the Navajo and other Southwestern Native American tribes today is a rather modern development, thought to date from circa 1880 as a result of European influences.
In Persia, turquoise was the "de facto" national stone for millennia, extensively used to decorate objects (from turbans to bridles), mosques, and other important buildings both inside and out, such as the Medresseh-I Shah Husein Mosque of Isfahan. The Persian style and use of turquoise was later brought to India following the establishment of the Mughal Empire there, its influence seen in high purity gold jewellery (together with ruby and diamond) and in such buildings as the Taj Mahal. Persian turquoise was often engraved with devotional words in Arabic script which was then inlaid with gold.
Cabochons of imported turquoise, along with coral, was (and still is) used extensively in the silver and gold jewellery of Tibet and Mongolia, where a greener hue is said to be preferred. Most of the pieces made today, with turquoise usually roughly polished into irregular cabochons set simply in silver, are meant for inexpensive export to Western markets and are probably not accurate representations of the original style.
The Egyptian use of turquoise stretches back as far as the First Dynasty and possibly earlier; however, probably the most well-known pieces incorporating the gem are those recovered from Tutankhamun's tomb, most notably the Pharaoh's iconic burial mask which was liberally inlaid with the stone. It also adorned rings and great sweeping necklaces called "pectorals". Set in gold, the gem was fashioned into beads, used as inlay, and often carved in a scarab motif, accompanied by carnelian, lapis lazuli, and in later pieces, coloured glass. Turquoise, associated with the goddess Hathor, was so liked by the Ancient Egyptians that it became (arguably) the first gemstone to be imitated, the fair structure created by an artificial glazed ceramic product known as faience.
The French conducted archaeological excavations of Egypt from the mid-19th century through the early 20th. These excavations, including that of Tutankhamun's tomb, created great public interest in the western world, subsequently influencing jewellery, architecture, and art of the time. Turquoise, already favoured for its pastel shades since c. 1810, was a staple of Egyptian Revival pieces. In contemporary Western use, turquoise is most often encountered cut "en cabochon" in silver rings, bracelets, often in the Native American style, or as tumbled or roughly hewn beads in chunky necklaces. Lesser material may be carved into fetishes, such as those crafted by the Zuni. While strong sky blues remain superior in value, mottled green and yellowish material is popular with artisans. In Western culture, turquoise is also the traditional birthstone for those born in the month of December.
The turquoise is also a stone in the Jewish High Priest's breastplate, described in Exodus 28.
Cultural history.
In many cultures of the Old and New Worlds, this gemstone has been esteemed for thousands of years as a holy stone, a bringer of good fortune or a talisman. The oldest evidence for this claim was found in Ancient Egypt, where grave furnishings with turquoise inlay were discovered, dating from approximately 3000 BCE. In the ancient Persian Empire, the sky-blue gemstones were earlier worn round the neck or wrist as protection against unnatural death. If they changed colour, the wearer was thought to have reason to fear the approach of doom. Meanwhile, it has been discovered that the turquoise certainly can change colour, but that this is not necessarily a sign of impending danger. The change can be caused by the light, or by a chemical reaction brought about by cosmetics, dust or the acidity of the skin.
The goddess Hathor was associated with turquoise, as she was the patroness of Serabit el-Khadim, where it was mined. Her titles included "Lady of Turquoise", "Mistress of Turquoise", and "Lady of Turquoise Country".
Imitations.
The Egyptians were the first to produce an artificial imitation of turquoise, in the glazed earthenware product faience. Later glass and enamel were also used, and in modern times more sophisticated porcelain, plastics, and various assembled, pressed, bonded, and sintered products (composed of various copper and aluminium compounds) have been developed: examples of the latter include "Viennese turquoise", made from precipitated aluminium phosphate coloured by copper oleate; and "neolith", a mixture of bayerite and copper phosphate. Most of these products differ markedly from natural turquoise in both physical and chemical properties, but in 1972 Pierre Gilson introduced one fairly close to a true synthetic (it does differ in chemical composition owing to a binder used, meaning it is best described as a simulant rather than a synthetic). Gilson turquoise is made in both a uniform colour and with black "spiderweb matrix"
veining not unlike the natural Nevada material.
The most common imitation of turquoise encountered today is dyed howlite and magnesite, both white in their natural states, and the former also having natural (and convincing) black veining similar to that of turquoise. Dyed chalcedony, jasper, and marble is less common, and much less convincing. Other natural materials occasionally confused with or used in lieu of turquoise include: variscite and faustite; chrysocolla (especially when impregnating quartz); lazulite; smithsonite; hemimorphite; wardite; and a fossil bone or tooth called odontolite or "bone turquoise", coloured blue naturally by the mineral vivianite. While rarely encountered today, odontolite was once mined in large quantities—specifically for its use as a substitute for turquoise—in southern France.
These fakes are detected by gemologists using a number of tests, relying primarily on non-destructive, close examination of surface structure under magnification; a featureless, pale blue background peppered by flecks or spots of whitish material is the typical surface appearance of natural turquoise, while manufactured imitations will appear radically different in both colour (usually a uniform dark blue) and texture (usually granular or sugary). Glass and plastic will have a much greater translucency, with bubbles or flow lines often visible just below the surface. Staining between grain boundaries may be visible in dyed imitations.
Some destructive tests may, however, be necessary; for example, the application of diluted hydrochloric acid will cause the carbonates odontolite and magnesite to effervesce and howlite to turn green, while a heated probe may give rise to the pungent smell so indicative of plastic. Differences in specific gravity, refractive index, light absorption (as evident in a material's absorption spectrum), and other physical and optical properties are also considered as means of separation.
Treatments.
Turquoise is treated to enhance both its colour and durability (i.e., increased hardness and decreased porosity). As is so often the case with any precious stones, full disclosure about treatment is frequently not given. It is therefore left to gemologists to detect these treatments in suspect stones using a variety of testing methods—some of which are necessarily destructive. For example, the use of a heated probe applied to an inconspicuous spot will reveal oil, wax, or plastic treatment with certainty.
Waxing and oiling.
Historically, light waxing and oiling were the first treatments used in ancient times, providing a wetting effect, thereby enhancing the colour and lustre. This treatment is more or less acceptable by tradition, especially because treated turquoise is usually of a higher grade to begin with. Oiled and waxed stones are prone to "sweating" under even gentle heat or if exposed to too much sun, and they may develop a white surface film or bloom over time. (With some skill, oil and wax treatments can be restored.)
Stabilization.
Material treated with plastic or water glass is termed "bonded" or "stabilized" turquoise. This process consists of pressure impregnation of otherwise unsaleable chalky American material by epoxy and plastics (such as polystyrene) and water glass (sodium silicate) to produce a wetting effect and improve durability. Plastic and water glass treatments are far more permanent and stable than waxing and oiling, and can be applied to material too chemically or physically unstable for oil or wax to provide sufficient improvement. Conversely, stabilization and bonding are rejected by some as too radical an alteration.
The epoxy binding technique was first developed in the 1950s and has been attributed to Colbaugh Processing of Arizona, a company that still operates today. The majority of American material is now treated in this manner although it is a costly process requiring many months to complete.
Dyeing.
The use of Prussian blue and other dyes (often in conjunction with bonding treatments) to "enhance"—that is, make uniform or completely change—colour is regarded as fraudulent by some purists, especially since some dyes may fade or rub off on the wearer. Dyes have also been used to darken the veins of turquoise.
Reconstitution.
Perhaps the most extreme of treatments is "reconstitution", wherein fragments of fine turquoise material, too small to be used individually, are powdered and then bonded with resin to form a solid mass. Very often the material sold as "reconstituted" turquoise is artificial, with little or no natural stone, made entirely from resins and dyes. In the trade "reconstituted" turquoise is often called "block" turquoise or simply "block."
Backing.
Since finer turquoise is often found as thin seams, it may be glued to a base of stronger foreign material as a means of reinforcement. These stones are termed "backed," and it is standard practice that all thinly cut turquoise in the Southwestern United States is backed. Native indigenous peoples of this region, because of their considerable use and wearing of turquoise, have found that backing increases the durability of thinly cut slabs and cabochons of turquoise. They observe that if the stone is not backed it will often crack. Early backing materials included the casings of old model T batteries, old phonograph records, and more recently epoxy steel resins. Backing of turquoise is not widely known outside of the Native American and Southwestern United States jewellery trade. Backing does not diminish the value of high quality turquoise, and indeed the process is expected for most thinly cut American commercial gemstones.
Valuation and care.
Hardness and richness of colour are two of the major factors in determining the value of turquoise; while colour is a matter of individual taste, generally speaking, the most desirable is a strong sky to robin egg blue (in reference to the eggs of the American robin). Whatever the colour, turquoise should not be excessively soft or chalky; even if treated, such lesser material (to which most turquoise belongs) is liable to fade or discolour over time and will not hold up to normal use in jewellery.
The mother rock or "matrix" in which turquoise is found can often be seen as splotches or a network of brown or black veins running through the stone in a netted pattern; this veining may add value to the stone if the result is complementary, but such a result is uncommon. Such material is sometimes described as "spiderweb matrix"; it is most valued in the Southwest United States and Far East, but is not highly appreciated in the Near East where unblemished and vein-free material is ideal (regardless of how complementary the veining may be). Uniformity of colour is desired, and in finished pieces the quality of workmanship is also a factor; this includes the quality of the polish and the symmetry of the stone. Calibrated stones—that is, stones adhering to standard jewellery setting measurements—may also be more sought after. Like coral and other opaque gems, turquoise is commonly sold at a price according to its physical size in millimetres rather than weight.
Turquoise is treated in many different ways, some more permanent and radical than others. Controversy exists as to whether some of these treatments should be acceptable, but one can be more or less forgiven universally: This is the "light" waxing or oiling applied to most gem turquoise to improve its colour and lustre; if the material is of high quality to begin with, very little of the wax or oil is absorbed and the turquoise therefore does not "rely" on this impermanent treatment for its beauty. All other factors being equal, untreated turquoise will always command a higher price. Bonded and "reconstituted" material is worth considerably less.
Being a phosphate mineral, turquoise is inherently fragile and sensitive to solvents; perfume and other cosmetics will attack the finish and may alter the colour of turquoise gems, as will skin oils, as will most commercial jewellery cleaning fluids. Prolonged exposure to direct sunlight may also discolour or dehydrate turquoise. Care should therefore be taken when wearing such jewels: cosmetics, including sunscreen and hair spray, should be applied before putting on turquoise jewellery, and they should not be worn to a beach or other sun-bathed environment. After use, turquoise should be gently cleaned with a soft cloth to avoid a buildup of residue, and should be stored in its own container to avoid scratching by harder gems. Turquoise can also be adversely affected if stored in an airtight container.

</doc>
<doc id="55695" url="https://en.wikipedia.org/wiki?curid=55695" title="Mirage">
Mirage

A mirage is a naturally occurring optical phenomenon in which light rays are bent to produce a displaced image of distant objects or the sky. The word comes to English via the French "mirage", from the Latin "mirari", meaning "to look at, to wonder at". This is the same root as for "mirror" and "to admire".
In contrast to a hallucination, a mirage is a real optical phenomenon that can be captured on camera, since light rays are actually refracted to form the false image at the observer's location. What the image appears to represent, however, is determined by the interpretive faculties of the human mind. For example, inferior images on land are very easily mistaken for the reflections from a small body of water.
Mirages can be categorized as "inferior" (meaning lower), "superior" (meaning higher) and "Fata Morgana", one kind of superior mirage consisting of a series of unusually elaborate, vertically stacked images, which form one rapidly changing mirage.
Inferior mirage.
For exhausted travelers in the desert, an inferior mirage may appear to be a lake of water in the distance. An inferior mirage is called "inferior" because the mirage is located under the real object. The real object in an inferior mirage is the (blue) sky or any distant (therefore bluish) object in that same direction. The mirage causes the observer to see a bright and bluish patch on the ground in the distance.
Light rays coming from a particular distant object all travel through nearly the same air layers and all are bent over about the same amount. Therefore, rays coming from the top of the object will arrive lower than those from the bottom. The image usually is upside down, enhancing the illusion that the sky image seen in the distance is really a water or oil puddle acting as a mirror.
Inferior images are not stable. Hot air rises, and cooler air (being more dense) descends, so the layers will mix, giving rise to turbulence. The image will be distorted accordingly. It may be vibrating; it may be vertically extended (towering) or horizontally extended (stooping). If there are several temperature layers, several mirages may mix, perhaps causing double images. In any case, mirages are usually not larger than about half a degree high (same apparent size as the sun and moon) and from objects only a few kilometers away.
Heat haze.
Heat haze, also called heat shimmer, refers to the inferior mirage experienced when viewing objects through a layer of heated air; for example, viewing objects across hot asphalt or through the exhaust gases produced by jet engines. When appearing on roads due to the hot asphalt, it is often referred to as a highway mirage.
Convection causes the temperature of the air to vary, and the variation between the hot air at the surface of the road and the denser cool air above it creates a gradient in the refractive index of the air. This produces a blurred shimmering effect, which affects the ability to resolve objects, the effect being increased when the image is magnified through a telescope or telephoto lens.
Light from the sky at a shallow angle to the road is refracted by the index gradient, making it appear as if the sky is reflected by the road's surface. The mind interprets this as a pool of water on the road, since water also reflects the sky. The illusion fades as one gets closer.
On tarmac roads it may look as if water, or even oil, has been spilled. These kinds of inferior mirages are often called "desert mirages" or "highway mirages". Both sand and tarmac can become very hot when exposed to the sun, easily being more than 10°C hotter than the air one meter above, enough to create conditions suitable for the formation of the mirage.
Heat haze is not related to the atmospheric phenomenon of haze.
Superior mirage.
A superior mirage occurs when the air below the line of sight is colder than the air above it. This unusual arrangement is called a temperature inversion, since warm air above cold air is the opposite of the normal temperature gradient of the atmosphere. Passing through the temperature inversion, the light rays are bent down, and so the image appears above the true object, hence the name "superior". Superior mirages are in general less common than inferior mirages, but, when they do occur, they tend to be more stable, as cold air has no tendency to move up and warm air has no tendency to move down.
Superior mirages are quite common in polar regions, especially over large sheets of ice that have a uniform low temperature. Superior mirages also occur at more moderate latitudes, although in those cases they are weaker and tend to be less smooth and stable. For example, a distant shoreline may appear to "tower" and look higher (and, thus, perhaps closer) than it really is. Because of the turbulence, there appear to be dancing spikes and towers. This type of mirage is also called the Fata Morgana or "hafgerdingar" in the Icelandic language.
A superior mirage can be right-side up or upside down, depending on the distance of the true object and the temperature gradient. Often the image appears as a distorted mixture of up and down parts.
Superior mirages can have a striking effect due to the Earth's curvature. Were the Earth flat, light rays that bend down would soon hit the ground and only nearby objects would be affected. Since Earth is round, if their downward bending curve is about the same as the curvature of the Earth, light rays can travel large distances, perhaps from beyond the horizon. This was observed and documented for the first time in 1596, when a ship under the command of Willem Barentsz in search of the Northeast passage became stuck in the ice at Novaya Zemlya. The crew was forced to endure the polar winter there. They saw their midwinter night come to an end with the rise of a distorted Sun about two weeks earlier than expected. It was not until the 20th century that science could explain the reason: the real Sun had still been below the horizon, but its light rays followed the curvature of the Earth. This effect is often called a Novaya Zemlya mirage. For every the light rays can travel parallel to the Earth's surface, the Sun will appear 1° higher on the horizon. The inversion layer must have just the right temperature gradient over the whole distance to make this possible.
In the same way, ships that are in reality so far away that they should not be visible above the geometric horizon may appear on the horizon or even above the horizon as superior mirages. This may explain some stories about flying ships or coastal cities in the sky, as described by some polar explorers. These are examples of so-called Arctic mirages, or "hillingar" in Icelandic.
If the vertical temperature gradient is +12.9°C per 100 meters (where the positive sign means temperature gets hotter as one goes higher) then horizontal light rays will just follow the curvature of the Earth, and the horizon will appear flat. If the gradient is less (as it almost always is) the rays are not bent enough and get lost in space, which is the normal situation of a spherical, convex "horizon".
In some situations, distant objects can get elevated or lowered, stretched or shortened with no mirage involved.
Fata Morgana.
A Fata Morgana, the name of which comes from the Italian translation of Morgan le Fay, the fairy shapeshifting half-sister of King Arthur, is a very complex superior mirage. It appears with alternations of compressed and stretched zones, erect images, and inverted images. A Fata Morgana is also a fast-changing mirage.
Fata Morgana mirages are most common in polar regions, especially over large sheets of ice with a uniform low temperature, but they can be observed almost anywhere. In polar regions, a Fata Morgana may be observed on cold days; in desert areas and over oceans and lakes, a Fata Morgana may be observed on hot days. For a Fata Morgana, temperature inversion has to be strong enough that light rays' curvatures within the inversion are stronger than the curvature of the Earth.
The rays will bend and create arcs. An observer needs to be within an atmospheric duct to be able to see a Fata Morgana.
Fata Morgana mirages may be observed from any altitude within the Earth's atmosphere, including from mountaintops or airplanes. 
A Fata Morgana can go from superior to inferior mirage and back within a few seconds, depending on the constantly changing conditions of the atmosphere. Sixteen frames of the mirage of the Farallon Islands, which cannot be seen from sea level at all under normal conditions because they are located below the horizon, were photographed on the same day. The first fourteen frames have elements of a Fata Morgana display—alternations of compressed and stretched zones. The last two frames were photographed a few hours later around sunset. The air was cooler while the ocean was probably a little bit warmer, which made temperature inversion lower. The mirage was still present, but it was not as complex as it had been a few hours before sunset, and it corresponded no longer to a Fata Morgana but rather to a superior mirage display.
Distortions of image and bending of light can produce spectacular effects. In his book "Pursuit: The Chase and Sinking of the "Bismarck"", the author Ludovic Kennedy describes an incident that allegedly took place below the Denmark Strait during 1941, following the sinking of the "Hood". The "Bismarck", while pursued by the British cruisers "Norfolk" and "Suffolk", passed out of sight into a sea mist. Within a matter of seconds, the ship re-appeared steaming toward the British ships at high speed. In alarm the cruisers separated, anticipating an imminent attack, and observers from both ships watched in astonishment as the German battleship fluttered, grew indistinct and faded away. Radar watch during these events indicated that the "Bismarck" had in fact made no changes of course.
Night-time mirages.
The conditions for producing a mirage can take place at night. Under most conditions, these are not observed. However, under some circumstances lights from moving vehicles, aircraft, ships, buildings, etc. can be observed at night, even though, as with a daytime mirage, they would not be observable.
This includes the mirage of astronomical objects.
Mirage of astronomical objects.
A mirage of an astronomical object is a naturally occurring optical phenomenon, in which light rays are bent to produce distorted or multiple images of an astronomical object. The mirages might be observed for such astronomical objects as the Sun, the Moon, the planets, bright stars, and very bright comets. The most commonly observed are sunset and sunrise mirages.

</doc>
<doc id="55697" url="https://en.wikipedia.org/wiki?curid=55697" title="Parenting">
Parenting

Parenting or child rearing is the process of promoting and supporting the physical, emotional, social, financial, and intellectual development of a child from infancy to adulthood. Parenting refers to the aspects of raising a child aside from the biological relationship.
The most common caretaker in parenting is the biological parent(s) of the child in question, although others may be an older sibling, a grandparent, a legal guardian, aunt, uncle or other family member, or a family friend. Governments and society may have a role in child-rearing as well. In many cases, orphaned or abandoned children receive parental care from non-parent blood relations. Others may be adopted, raised in foster care, or placed in an orphanage. Parenting skills vary, and a parent with good parenting skills may be referred to as a "good parent". The English pediatrician and psychoanalyst Donald Winnicott described the concept of "good-enough" parenting in which a minimum of prerequisites for healthy child development are met. Winnicott wrote, "The good-enough mother...starts off with an almost complete adaptation to her infant's needs, and as time proceeds she adapts less and less completely, gradually, according to the infant's growing ability to deal with her failure." Views on the characteristics that make one a good or "good-enough" parent vary from culture to culture. Additionally, research has supported that parental history both in terms of attachments of varying quality as well as parental psychopathology, particularly in the wake of adverse experiences, can strongly influence parental sensitivity and child outcomes.
Factors that affect decisions.
Social class, wealth, culture and income have a very strong impact on what methods of child rearing are used by parents. Cultural values play a major role in how a parent raises their child. However, parenting is always evolving; as times change, cultural practices and social norms and traditions change
In psychology, the parental investment theory suggests that basic differences between males and females in parental investment have great adaptive significance and lead to gender differences in mating propensities and preferences.
A family's social class plays a large role in the opportunities and resources that will be made available to a child. Working-class children often grow up at a disadvantage with the schooling, communities, and parental attention made available to them compared to middle-class or upper-class upbringings. Also, lower working-class families do not get the kind of networking that the middle and upper classes do through helpful family members, friends, and community individuals and groups as well as various professionals or experts.
Styles.
A parenting style is the overall emotional climate in the home. Developmental psychologist Diana Baumrind identified three main parenting styles in early child development: authoritative, authoritarian, and permissive. These parenting styles were later expanded to four, including an uninvolved style. These four styles of parenting involve combinations of acceptance and responsiveness on the one hand and demand and control on the other. Recent research has found that parenting style is significantly related to children's subsequent mental health and well-being. In particular, authoritative parenting is positively related to mental health and satisfaction with life, and authoritarian parenting is negatively related to these variables.
Parenting practices reflect the cultural understanding of children. Parents in individualistic countries like Germany spend more time engaged in face-to-face interaction with babies and more time talking to the baby about the baby. Parents in more communal cultures, such as West African cultures, spend more time talking to the baby about other people, and more time with the baby facing outwards, so that the baby sees what the mother sees. Children develop skills at different rates as a result of differences in these culturally driven parenting practices. Children in individualistic cultures learn to act independently and to recognize themselves in a mirror test at a younger age than children whose cultures promote communal values. However, these independent children learn self-regulation and cooperation later than children in communal cultures. In practice, this means that a child in an independent culture will happily play by herself, but a child in a communal culture is more likely to follow his mother's instruction to pick up his toys. Children that grow up in communities with a collaborative orientation to social interaction, such as some Indigenous American communities, are also able to self-regulate and become very self-confident, while remaining involved in the community.
In Kenya, Africa, many male parents are not encouraged to be involved in their children's lives till they are about 12 years old.
Skills.
Parenting styles are only a small piece of what it takes to be a "good parent". Parenting takes a lot of skill and patience and is constant work and growth. Research shows that children benefit most when their parents:
Parenting skills are often assumed to be self-evident or naturally present in parents. That this is a very much oversimplified view is emphasized by Virginia Satir, a pioneer in family therapy:
Values.
Parents around the world want what they believe is best for their children. However, parents in different cultures have different ideas of what is best. For example, parents in a hunter–gatherer society or surviving through subsistence agriculture are likely to promote practical survival skills from a young age. Many such cultures begin teaching babies to use sharp tools, including knives, before their first birthdays. This seen in communities where children have a considerate amount of autonomy at a younger age and are given the opportunity to become skilled in tasks that are sometimes classified as adult work by other cultures. In some Indigenous American communities, child work provides children the opportunity to learn cultural values of collaborative participation and prosocial behavior through observation and participation alongside adults. American parents strongly value intellectual ability, especially in a narrow "book learning" sense. Italian parents value social and emotional abilities and having an even temperament. Spanish parents want their children to be sociable. Swedish parents value security and happiness. Dutch parents value independence, long attention spans, and predictable schedules. The Kipsigis people of Kenya value children who are not only smart, but who employ that intelligence in a responsible and helpful way, which they call "ng/om". Many Indigenous American communities value respect, participation in the community, and non-interference. The practice of non-interference is an important value in Cherokee culture. It requires that one respects the autonomy of others in the community by not interfering in their decision making by giving unsolicited advice.
Differences in values cause parents to interpret different actions in different ways. Asking questions is seen by many European American parents as a sign that the child is smart. Italian parents, who value social and emotional competence, believe that asking questions is a sign that the child has good interpersonal skills. Dutch parents, who value independence, view asking questions negatively, as a sign that the child is not independent. Indigenous American parents often try to encourage curiosity in their children. Many use a permissive parenting style that enables the child to explore and learn through observation of the world around it.
Cultural tools.
Differences in values can also cause parents to employ different tools to promote their values. Many European American parents expect specially purchased educational toys to improve their children's intelligence. Some Spanish parents promote social skills by taking their children out for daily walks around the neighborhood.
In indigenous American cultures.
It is common for parents in many Indigenous American communities to use different tools in parenting such as storytelling—like myths—consejos, educational teasing, nonverbal communication, and observational learning to teach their children important values and life lessons.
Storytelling is a way for Indigenous American children to learn about their identity, community, and cultural history. Indigenous myths and folklore often personify animals and objects, reaffirming the belief that everything possess a soul and must be respected. These stories help preserve language and are used to reflect certain values or cultural histories.
Consejos are a narrative form of advice giving that provides the recipient with maximum autonomy in the situation as a result of their indirect teaching style. Rather than directly informing the child what they should do, the parent instead might tell a story of a similar situation or scenario. The character in the story is used to help the child see what the implications of their decision may be, without directly making the decision for them. This teaches the child to be decisive and independent, while still providing some guidance.
The playful form of teasing is a parenting method used in some Indigenous American communities to keep children out of danger and guide their behavior. This form of teasing utilizes stories, fabrications, or empty threats to guide children in making safe, intelligent decisions. It can teach children values by establishing expectations and encouraging the child to meet them via playful jokes and/or idle threats. For example, a parent may tell a child that there is a monster that jumps on children's backs if they walk alone at night. This explanation can help keep the child safe because instilling that alarm creates greater awareness and lessens the likelihood that they will wander alone into trouble.
In Navajo families, a child’s development is partly focused on the importance of "respect" for all things as part of the child’s moral and human development. "Respect" in this sense is an emphasis of recognizing the significance of and understanding for one's relationship with other things and people in the world. Nonverbal communication is much of the way that children learn about such "respect" from parents and other family members.
For example, in a Navajo parenting tool using nonverbal communication, children are initiated at an early age into the practice of an early morning run through any weather condition. This form of guidance fosters “respect” not only for the child's family members but also to the community as a whole. On this run, the community uses humor and laughter with each other, without directly including the child—who may not wish to get up early and run—to promote the child’s motivation to participate and become an active member of the community. To modify children’s behavior in a nonverbal manner, parents also promote inclusion in the morning runs by placing their child in the snow and having them stay longer if they protest; this is done within a context of warmth, laughter, and community, to help incorporate the child into the practice. 
A tool parents use in Indigenous American cultures is to incorporate children into everyday life, including adult activities, to pass on the parents’ knowledge by allowing the child to learn through observation. This practice is known as LOPI, learning by observing and pitching in, where children are integrated into all types of mature daily activities and encouraged to observe and contribute in the community. This inclusion as a parenting tool promotes both community participation and learning.
In some Mayan communities, young girls are not permitted around the hearth, for an extended period of time since corn is sacred. Despite this being an exception to the more common Indigenous American practice of integrating children into all adult activities, including cooking, it is a strong example of observational learning. These Mayan girls can only see their mothers making tortillas in small bits at a time, they will then go and practice the movements their mother used on other objects, such as the example of kneading thin pieces of plastic like a tortilla. From this practice, when a girl comes of age, she is able to sit down and make tortillas without any explicit verbal instruction as a result of her observational learning.
In Judaism and Jewish culture.
Judaism has an extensive tradition of parenting with an emphasis on education.
Across the lifespan.
Pre-pregnancy.
Family planning is the decision regarding whether and when to become parents, including planning, preparing, and gathering resources. Parents should assess (among other matters) whether they have the required financial resources (the raising of a child costs around $16,198 yearly in the United States) and should also assess whether their family situation is stable enough and whether they themselves are responsible and qualified enough to raise a child. Reproductive health and preconceptional care affect pregnancy, reproductive success and maternal and child physical and mental health.
Pregnancy and prenatal parenting.
During pregnancy the unborn child is affected by many decisions his or her parents make, particularly choices linked to their lifestyle. The health and diet decisions of the mother can have either a positive or negative impact on the child during prenatal parenting. In addition to physical management of the pregnancy, medical knowledge of your physician, hospital, and birthing options are important. Here are some key items of advice:
Many people believe that parenting begins with birth, but the mother begins raising and nurturing a child well before birth.
Scientific evidence indicates that from the fifth month on, the unborn baby is able to hear sounds, become aware of motion, and possibly exhibit short-term memory. Several studies (e.g. Kissilevsky et al., 2003) show evidence that the unborn baby can become familiar with his or her parents' voices. Other research indicates that by the seventh month, external schedule cues influence the unborn baby's sleep habits. Based on this evidence, parenting actually begins well before birth.
How many children the mother carries also determines the amount of care needed during prenatal and post-natal periods.
Newborns and infants.
Newborn parenting, is where the responsibilities of parenthood begins. A newborn's basic needs are food, sleep, comfort and cleaning which the parent provides. An infant's only form of communication is crying, and attentive parents will begin to recognize different types of crying which represent different needs such as hunger, discomfort, boredom, or loneliness. Newborns and young infants require feedings every few hours which is disruptive to adult sleep cycles. They respond enthusiastically to soft stroking, cuddling and caressing. Gentle rocking back and forth often calms a crying infant, as do massages and warm baths. Newborns may comfort themselves by sucking their thumb or a pacifier. The need to suckle is instinctive and allows newborns to feed. Breastfeeding is the recommended method of feeding by all major infant health organizations. If breastfeeding is not possible or desired, bottle feeding is a common alternative. Other alternatives include feeding breastmilk or formula with a cup, spoon, feeding syringe, or nursing supplementer.
The forming of attachments is considered to be the foundation of the infant/child's capacity to form and conduct relationships throughout life. Attachment is not the same as love and/or affection although they often go together. Attachments develop immediately and a lack of attachment or a seriously disrupted capacity for attachment could potentially do serious damage to a child's health and well-being. Physically, one may not see symptoms or indications of a disorder but the child may be emotionally affected. Studies show that children with secure attachment have the ability to form successful relationships, express themselves on an interpersonal basis and have higher self-esteem . Conversely children who have caregivers who are neglectful or emotionally unavailable can exhibit behavioral problems such as post-traumatic stress disorder or oppositional-defiant disorder 
Oppositional-defiant disorder is a pattern of disobedient, hostile, and defiant behavior toward authority figures
Toddlers.
Toddlers are much more active than infants and are challenged with learning how to do simple tasks by themselves. At this stage, parents are heavily involved in showing the child how to do things rather than just doing things for them, and the child will often mimic the parents. Toddlers need help to build their vocabulary, increase their communication skills, and manage their emotions. Toddlers will also begin to understand social etiquette such as being polite and taking turns.
Toddlers are very curious about the world around them and eager to explore it. They seek greater independence and responsibility and may become frustrated when things do not go the way they want or expect. Tantrums begin at this stage, which is sometimes referred to as the 'Terrible Twos'. Tantrums are often caused by the child's frustration over the particular situation, sometimes simply not being able to communicate properly. Parents of toddlers are expected to help guide and teach the child, establish basic routines (such as washing hands before meals or brushing teeth before bed), and increase the child's responsibilities. It is also normal for toddlers to be frequently frustrated. It is an essential step to their development. They will learn through experience; trial and error. This means that they need to experience being frustrated when something does not work for them, in order to move on to the next stage. When the toddler is frustrated, they will often behave badly with actions like screaming, hitting or biting. Parents need to be careful when reacting to such behaviours, giving threats or punishments is not helpful and will only make the situation worse. Research groups led by Daniel Schechter, Alytia Levendosky, and others have shown that parents with histories of maltreatment and violence exposure often have difficulty helping their toddlers and preschool-age children with these very same emotionally dysregulated behaviours, which can remind traumatized parents of their adverse experiences and associated mental states.
Regarding gender differences in parenting, data from the US in 2014 states that, on an average day, among adults living in households with children under age 6, women spent 1.0 hour providing physical care (such as bathing or feeding a child) to household children. By contrast, men spent 23 minutes providing physical care. 
Child.
Younger children are becoming more independent and are beginning to build friendships. They are able to reason and can make their own decisions given hypothetical situations. Young children demand constant attention, but will learn how to deal with boredom and be able to play independently. They also enjoy helping and feeling useful and able. Parents may assist their child by encouraging social interactions and modelling proper social behaviors. A large part of learning in the early years comes from being involved in activities and household duties. Parents who observe their children in play or join with them in child-driven play have the opportunity to glimpse into their children’s world, learn to communicate more effectively with their children and are given another setting to offer gentle, nurturing guidance. Parents are also teaching their children health, hygiene, and eating habits through instruction and by example.
Parents are expected to make decisions about their child's education. Parenting styles in this area diverge greatly at this stage with some parents becoming heavily involved in arranging organized activities and early learning programs. Other parents choose to let the child develop with few organized activities.
Children begin to learn responsibility, and consequences of their actions, with parental assistance. Some parents provide a small allowance that increases with age to help teach children the value of money and how to be responsible with it.
Parents who are consistent and fair with their discipline, who openly communicate and offer explanations to their children, and who do not neglect the needs of their children in some way often find they have fewer problems with their children as they mature.
Adolescents.
During adolescence children are beginning to form their identity and are testing and developing the interpersonal and occupational roles that they will assume as adults. Therefore it is important that parents treat them as young adults. Although adolescents look to peers and adults outside the family for guidance and models for how to behave, parents remain influential in their development. A teenager who thinks poorly of him or herself, is not confident, hangs around with gangs, lacks positive values, follows the crowd, is not doing well in studies, is losing interest in school, has few friends, lacks supervision at home or is not close to key adults like parents and is vulnerable to peer pressure. Parents often feel isolated and alone in parenting adolescents, but they should still make efforts to be aware of their adolescents' activities, and to provide guidance, direction, and consultation. Adolescence can be a time of high risk for children, where new-found freedoms can result in decisions that drastically open up or close off life opportunities. Adolescents tend to increase the amount of time they spend with peers of the opposite gender; however, they still maintain the amount of time they spend with those of the same gender, and they do this by decreasing the amount of time they spend with their parents. Also, peer pressure is not the reason why peers have influence on adolescents; instead, it is often because they respect, admire and like their peers. Parental issues at this stage of parenting include dealing with "rebellious" teenagers, who didn't know freedom while they were smaller. In order to prevent all these, it is important for the parents to build a trusting relationship with their children. This can be achieved by planning and taking part in fun activities together, keeping promises made to them, spending time with them, not reminding them about their past mistakes and listening to and talking to them. When a trusting relationship is built, adolescents are more likely to approach their parents for help when faced with negative peer pressure. Helping the child build a strong foundation will help them to resist negative peer pressure. It is important for the parents to build up the self-esteem of their child: Praise the child's strengths instead of focusing on their weaknesses (It will help to grow the child's sense of self-worth and self-confidence, so he/she does not feel the need to gain acceptance from his/her peers), acknowledge the child's efforts, do not simply focus on the final result (when they notice that the parent recognizes their efforts, they will keep trying), and lastly, disapprove the behavior, not the child, or they will turn to their peers for acceptance and comfort.
Adults.
Parenting doesn't usually end when a child turns 18. Support can be needed in a child's life well beyond the adolescent years and continues into middle and later adulthood. Parenting can be a lifelong process.
Assistance.
Parents may receive assistance with caring for their children through child care programs.
Childbearing and happiness.
Data from the British Household Panel Survey and the German Socio-Economic Panel suggests that having up to two children increases happiness in the years around the birth, and mostly so for those who have postponed childbearing. However, having a third child does not increase happiness.

</doc>
<doc id="55700" url="https://en.wikipedia.org/wiki?curid=55700" title="Tactile illusion">
Tactile illusion

Tactile illusions are illusions that exploit the sense of touch. Some touch illusions require active touch (e.g., movement of the fingers or hands), whereas others can be evoked passively (e.g., with external stimuli that press against the skin).

</doc>
<doc id="55702" url="https://en.wikipedia.org/wiki?curid=55702" title="Hospital volunteer">
Hospital volunteer

Hospital volunteers also known as "candy stripers" work without regular pay in varieties of health care settings, usually under direct supervision of nurses. Most hospitals train and supervise volunteers through specialized non-profit organizations known as auxiliaries. Directors of auxiliaries are most often paid employees of the hospitals. 
The term candy striper is derived from the fact that the red-and-white striped pinafores that female volunteers traditionally wore in the United States, because of their resemblances to candy canes. The term and its associated uniform are less frequently used in current clinical settings.
Another hospital volunteer organization was sponsored by the American Red Cross. The "Blue Teens" wore blue-and-white striped pinafores. The adult women were known as "Grey Ladies" and wore light grey uniforms. 
In the United States, volunteers' services are of considerable importance to individual patients as well as the health care system in general. Some people volunteer during high school or college (or rarely at the middle school level), either out of curiosity about health-care professions or in order of satisfying mandatory community service requirements imposed by some schools. Still others volunteer at later stages in their life, particularly after retirement.
History.
Candy Stripers originated as a high-school civics class project in East Orange, New Jersey, in 1944. The uniforms were sewn by the girls in the class from material provided by the teacher – a red-and-white-striped fabric known as "candy stripe". The students chose East Orange General Hospital as the home for their class project. 
"Blue Teens" and "Grey Ladies" were also hospital volunteer organizations sponsored by the American Red Cross. Blue Teens, usually high school age students, wore blue and white striped uniforms. The Grey Ladies wore solid light grey uniforms. Red Cross pins and patches were also worn on the uniforms indicating completion of required Red Cross training. 
Usually a hospital sponsored either Candy Striper or Blue Teen volunteers but not both.
Duties.
Duties of hospital volunteers vary widely depending upon the facility. Volunteers may work in staff reception areas and gift shops; file and retrieve documents and mails; take out trash; clean; provide administrative backup; assist with research by doing the dishes and autoclaving; help visitors; visit with patients; or transport various small items like flowers, medical records, lab specimens, and drugs from unit to unit.
A few hospitals ask their volunteers to help out with janitorial duties, like cleaning beds. Other "advanced volunteers" include patient-care liaisons and volunteer orderlies. These volunteers must operate on the orders of a nurse or a physician and are given special training to permit them to work with patients. They are also more common in large hospitals, particularly university-affiliated hospitals and teaching hospitals, as they allow pre-medical students to gain experience in patient care while taking pressure off a busy care team.
Some hospitals manage their volunteers from a dispersal unit and assign them to tasks based on real-time labor demand, while other hospitals assign volunteers to a single unit for the duration of their service. Female volunteers traditionally wore pink-and-white jumpers, while male volunteers traditionally wore light-blue tunics or shirts over dark slacks. Today, male and female volunteers often wear a uniform shirt or a short-sleeved shirt with slacks. Some volunteers (particularly "advanced volunteers") will wear scrubs, but this is usually avoided so volunteers are not confused with medical personnel. All volunteers wear ID tags within the hospital and these will prominently indicate the volunteer's status and position.

</doc>
<doc id="55706" url="https://en.wikipedia.org/wiki?curid=55706" title="Richard Whittington">
Richard Whittington

Sir Richard Whittington (c. 1354–1423) was a medieval merchant and a politician. He is also the real-life inspiration for the English folk tale Dick Whittington and His Cat. He was four times Lord Mayor of London, a member of parliament and a sheriff of London. In his lifetime he financed a number of public projects, such as drainage systems in poor areas of medieval London, and a hospital ward for unmarried mothers. He bequeathed his fortune to form the Charity of Sir Richard Whittington which, nearly 600 years later, continues to assist people in need. 
Biography.
He was born in Gloucestershire, England, at Pauntley in the Forest of Dean, although his family originated from Kinver in Staffordshire, England, where his grandfather Sir William de Whittington was a knight at arms. His date of birth is variously given as in the 1350s and he died in London in 1423. However, he was a younger son and so would not inherit his father's estate as the eldest son might expect to do. Consequently he was sent to the City of London to learn the trade of mercer. He became a successful trader, dealing in valuable imports such as silks and velvets, both luxury fabrics, much of which he sold to the Royal and noble court from about 1388. There is indirect evidence that he was also a major exporter to Europe of much sought after English woollen cloth such as Broadcloth. From 1392 to 1394 he sold goods to Richard II worth £3,500 (equivalent to more than £1.5m today). He also began money-lending in 1388, preferring this to outward shows of wealth such as buying property. By 1397 he was also lending large sums of money to the King.
In 1384 Whittington had become a Councilman. In 1392 he was one of the city's delegation to the King at Nottingham at which the King seized the City of London's lands because of alleged misgovernment. By 1393, he had become an alderman and was appointed Sheriff by the incumbent mayor, William Staundone, as well as becoming a member of the Mercers' Company. When Adam Bamme, the mayor of London, died in June 1397, Whittington was imposed on the city by the King as Lord Mayor of London two days later to fill the vacancy with immediate effect. Within days Whittington had negotiated with the King a deal in which the city bought back its liberties for £10,000 (nearly £4m today). He was elected mayor by a grateful populace on 13 October 1397.
The deposition of Richard II in 1399 did not affect Whittington and it is thought that he merely acquiesced in the coup led by Bolingbroke. Whittington had long supplied the new king, Henry IV, as a prominent member of the landowning elite and so his business simply continued as before. He also lent the new king substantial amounts of money. He was elected mayor again in 1406—during 1407 he was simultaneously Mayor in both London and Calais—and in 1419. In 1416, he became a member of parliament, and was also in turn influential with Henry IV's son, Henry V, also lending him large amounts of money and serving on several Royal Commissions of oyer and terminer. For example, Henry V employed him to supervise the expenditure to complete Westminster Abbey. Despite being a moneylender himself he was sufficiently trusted and respected to sit as a judge in usury trials in 1421. Whittington also collected revenues and import duties. A long dispute with the Company of Brewers over standard prices and measures of ale was won by Whittington.
Benefactions.
In his lifetime Whittington donated much of his profit to the city and left further endowments by his Will. He financed: 
He also provided accommodation for his apprentices in his own house. He passed a law prohibiting the washing of animal skins by apprentices in the River Thames in cold, wet weather because many young boys had died through hypothermia or drowning in the strong river currents.
Death and bequests.
Whittington died in March 1423. In 1402 (aged 48) he had married Alice, daughter of Sir Ivo FitzWarin (or Fitzwarren) of Wantage in Berkshire (now Oxfordshire), but she predeceased him in 1411. They had no children. He was buried in the church of St Michael Paternoster Royal, to which he had donated large sums during his lifetime. The tomb is now lost, and the mummified cat found in the church tower in 1949 during a search for its location probably dates to the time of the Wren restoration.
In the absence of heirs, Whittington left £7,000 in his will to charity, in those days a large sum, with a modern-day equivalence of about £3m. Some of this was used to 
The almshouses were relocated in 1966 to Felbridge near East Grinstead. Sixty elderly women and a few married couples currently live in them. The Whittington Charity also disburses money each year to the needy through the Mercers' Company. The Whittington hospital is now at Archway in the London Borough of Islington and a small statue of a cat along Highgate Hill further commemorates his legendary feline.
Dick Whittington—stage character.
The gifts left in Whittington's will made him well known and he became a character in an English story that was adapted for the stage as a play, "The History of Richard Whittington, of his lowe byrth, his great fortune", in February 1604. In the 19th century this became popular as a pantomime called "Dick Whittington and His Cat", very loosely based on Richard Whittington. There are several versions of the traditional story, which tells how Dick, a boy from a poor Gloucestershire family, sets out for London to make his fortune, accompanied by, or later acquiring, his cat. At first he meets with little success, and is tempted to return home. However, on his way out of the city, whilst climbing Highgate Hill from modern-day Archway, he hears the Bow Bells of London ringing, and believes they are sending him a message. There is now a large hospital on Highgate Hill, named the Whittington Hospital, after this supposed episode. A traditional rhyme associated with this tale is:
On returning to London, Dick embarks on a series of adventures. In one version of the tale, he travels abroad on a ship, and wins many friends as a result of the rat-catching activities of his cat; in another he sends his cat and it is sold to make his fortune. Eventually he does become prosperous, marries his master's daughter Alice Fitzwarren (the name of the real Whittington's wife), and is made Lord Mayor of London three times. The common belief that he served three rather than four times as Lord Mayor stems from the City's records 'Liber Albus' compiled at his request by the City Clerk John Carpenter wherein his name appears only three times as the remainder term of his deceased predecessor Adam Bamme and his own consequent term immediately afterwards appear as one entry for 1397.
As the son of gentry Whittington was never very poor and there is no evidence that he kept a cat. Whittington may have become associated with a thirteenth-century Persian folktale about an orphan who gained a fortune through his cat, but the tale was common throughout Europe at that time. Folklorists have suggested that the most popular legends about Whittington—that his fortunes were founded on the sale of his cat, who was sent on a merchant vessel to a rat-beset Eastern emperor—originated in a popular 17th-century engraving by Renold Elstracke in which his hand rested on a cat, but the picture only reflects a story already in wide circulation. Elstracke's oddly-shaped cat was in fact a later replacement by printseller Peter Stent for what had been a skull in the original, with the change being made to conform to the story already in existence, to increase sales.
There was also known to be a painted portrait of Whittington shown with a cat, hanging at Mercer Hall, but it was reported that the painting had been trimmed down to smaller size, and the date "1572" that appears there was something painted after the cropping, which raises doubt as to the authenticity of the date, though Malcolm who witnessed it ca. early 1800s felt the date should be taken in good faith. The print published in "The New Wonderful Museum" (vol. III, 1805, pictured above) is presumably a replica of this painting.

</doc>
<doc id="55707" url="https://en.wikipedia.org/wiki?curid=55707" title="Hatch Act">
Hatch Act

Hatch Act may refer to:

</doc>
<doc id="55708" url="https://en.wikipedia.org/wiki?curid=55708" title="Sherman Silver Purchase Act">
Sherman Silver Purchase Act

The Sherman Silver Purchase Act was a United States federal law 
enacted on July 14, 1890.
The measure did not authorize the free and unlimited coinage of silver that the Free Silver supporters wanted; however, it increased the amount of silver the government was required to purchase on a recurrent monthly basis to 4.5 million ounces. The Sherman Silver Purchase Act had been passed in response to the growing complaints of farmers' and miners' interests. Farmers had immense debts that could not be paid off due to deflation caused by overproduction, and they urged the government to pass the Sherman Silver Purchase Act in order to boost the economy and cause inflation, allowing them to pay their debts with cheaper dollars. Mining companies, meanwhile, had extracted vast quantities of silver from western mines; the resulting oversupply drove down the price of their product, often to below the point at which the silver could be profitably extracted. They hoped to enlist the government to increase the demand for silver.
Originally, the bill was simply known as the Silver Purchase Act of 1890. Only after the bill was signed into law, did it become the "Sherman Silver Purchase Act." Senator John Sherman, an Ohio Republican and chairman of the Senate Finance Committee was not the author of the bill, but once both houses of Congress had passed the Act and the Act had been sent to a Senate/House conference committee to iron out differences between the Senate and House versions of the Act, Senator John Sherman was instrumental in getting the conference committee to reach agreement on a final draft of the Act. Nonetheless, once agreement on the final version was reached in the conference committee, Sherman found that he disagreed with many sections of the act. So tepid was Sherman's support that when he was asked his opinion of the act by President Benjamin Harrison, Sherman ventured only that the bill was "safe" and would cause no harm if the President signed it.
The act was enacted in tandem with the McKinley Tariff of 1890. William McKinley, an Ohio Republican and chairman of the House Ways and Means Committee worked with John Sherman to create a package that could both pass the Senate and receive the President's approval.
Under the Act, the federal government purchased millions of ounces of silver, with issues of paper currency. It became the second-largest buyer in the world, after the British Crown in India, where the Indian rupee was backed by silver rather than gold. In addition to the $2 million to $4 million that had been required by the Bland–Allison Act of 1878, the US government was now required to purchase an additional 4.5 million ounces of silver bullion every month. The law required the Treasury to buy the silver with a special issue of Treasury (Coin) Notes that could be redeemed for either silver or gold. That plan backfired, as people (mostly investors) redeemed the new coin notes for gold dollars, thus depleting the government's gold reserves. After the Panic of 1893 broke, President Grover Cleveland oversaw the repeal of the act to prevent the depletion of the gold reserves.
In 1890, the price of silver dipped to $1.16 per ounce. By the end of the year, it had fallen to $0.69. By December 1894, the price had dropped to $0.60. On November 1, 1895, US mints halted production of silver coins, and the government closed the New Orleans Mint. Banks discouraged the use of silver dollars.

</doc>
<doc id="55709" url="https://en.wikipedia.org/wiki?curid=55709" title="Pantomime (disambiguation)">
Pantomime (disambiguation)

Pantomime is a type of musical comedy stage production, developed in England and designed for family entertainment, mostly performed during Christmas and New Year season.
Pantomime may also refer to:

</doc>
<doc id="55710" url="https://en.wikipedia.org/wiki?curid=55710" title="McKinley Tariff">
McKinley Tariff

The Tariff Act of 1890, commonly called the McKinley Tariff, was an act of the United States Congress framed by Representative William McKinley that became law on October 1, 1890. The tariff raised the average duty on imports to almost fifty percent, an act designed to protect domestic industries from foreign competition. Protectionism, a tactic supported by Republicans, was fiercely debated by politicians and condemned by Democrats. The McKinley Tariff was replaced with the Wilson–Gorman Tariff Act in 1894, which promptly lowered tariff rates.
Tariff politics.
Tariffs, taxes on foreign goods entering a country, served two purposes for the United States in the late 19th century. One was to raise fiscal revenue for the federal government, and the other was to protect domestic manufacturers from foreign competition. This controversial idea was known as protectionism.
In December 1887, President Grover Cleveland, a Democrat, devoted his entire State of the Union Address to the issue of the tariff. He called emphatically for the reduction of duties and the abolition of duties on raw materials. This speech succeeded in making the tariff, and the idea of protectionism, a true party matter. In the 1888 election, the Republicans were victorious with the election of President Harrison, and majorities in both the Senate and the House. For the sake of holding the party line, the Republicans felt obligated to pass stronger tariff legislation.
William McKinley, of Ohio, was defeated by Thomas B. Reed to be Speaker of the House after the 1888 elections. McKinley instead became chairman of the House Ways and Means Committee and was responsible for framing a new tariff bill. He believed that a protectionist tariff had been mandated by the people through the election, and that it was necessary for America’s wealth and prosperity.
In addition to the protectionist debate, politicians were also concerned about the high revenue accruing from tariffs. After the Civil War, tariffs remained elevated to raise revenue and cover the high costs of war. However, in the early 1880s, the federal government was running a large surplus. Both parties agreed that the surplus needed to lessen, but disagreed about whether to raise or lower tariffs to accomplish the same goal. The Democrats' hypothesis stated that tariff revenue could be reduced by reducing the tariff rate. Conversely, Republicans believed that by increasing the tariff, imports would be lessened, and total tariff revenue would drop "(See Laffer curve)". This point, along with the dialogue surrounding protectionism, created what would be known as “The Great Tariff Debate of 1888.”
Tariff description.
After 450 amendments, the Tariff Act of 1890 was passed, and increased average duties across all imports from 38% to 49.5%. McKinley was known as the “Napoleon of Protection,” and the act reflected this sentiment. It raised rates on some goods and lowered rates on others, always attempting to protect American manufacturing interests. Changes in duties for specific products such as tin-plates and wool were the most controversial, and emblematic of the spirit of the Tariff of 1890. However, on certain items, the Act eliminated tariffs altogether, with the threat of reinstatement as an enticement to get other countries to lower their tariffs on items imported from the U.S.
Tin-plates.
Tin-plates were a major import for the United States; tens of millions of dollars in these goods entered the country each year. In the preceding 20 years tariff rates had been raised and dropped multiple times on tin-plates with no change in import levels, and domestic production had remained inconsequential. In a last attempt to stimulate the infant domestic tin-plate industry, the 1890 tariff raised the duty level from thirty percent to seventy percent. The Act also included a unique provision that stated tin-plates should be admitted free of any duty after 1897, unless domestic production in any year reached one third the imports in that year. The goal was for the duty to be protective, or not exist at all.
Wool.
The new tariff provisions for wool and woolen goods were exceedingly protectionist. Wool was previously taxed based on a schedule, meaning that more valuable wool was taxed at a higher rate. Through a multitude of complicated tariff schedule revisions, the act made almost all woolen goods subject to the maximum duty rate. Further, the act increased the tariff on carpet wool, a wool of very low quality that is not produced in the US. The government wanted to ensure that importers were not declaring higher quality wool as carpet wool to evade the tariff.
Eliminated tariffs.
The Act removed tariffs on sugar, molasses, tea, coffee and hides, but authorized the President to reinstate such tariffs on these types of items when exported from countries which treated U.S. exports in a "reciprocally unequal and unreasonable" fashion. The idea was "to secure reciprocal trade" by allowing the executive branch to use the mere threat of reimposing tariffs as a means to get other countries to lower their tariffs on U.S. exports. Although this delegation of power had the appearance of being an unconstitutional violation of the nondelegation doctrine, it was upheld by the Supreme Court in "Field v. Clark" in 1892 as merely authorizing the executive to act as an "agent" of Congress, rather than a law-maker itself. The President did not use the delegated power to re-impose tariffs on the five types of imported goods, but used the threat of doing so to successfully negotiate ten treaties in which other countries reduced their tariffs on U.S. goods.
Tariff effects.
Douglas Irwin’s 1998 paper examines the validity of the opposite tariff hypotheses posed by the Republicans and Democrats in 1890. Irwin looked at historical data to estimate import demand elasticities, and export supply elasticities for the US in the years before 1888. With this information, he calculated that tariffs had not reached the maximum revenue rate, and therefore a "reduction", not an increase, in the tariff would have reduced revenue and the federal surplus. His findings confirmed the Democrats' hypothesis, and refuted the Republicans'. After examining the actual tariff revenue data, it appears that revenue did decrease by about four percent from $225 million to $215 million after the Tariff of 1890 increased rates. Irwin explains that this is due to the Tariff of 1890’s provision that raw sugar be moved to the duty-free list. Sugar, at this time, was the item that raised the most tariff revenue, so making it duty-free reduced this revenue. If sugar is excluded from import calculations, the tariff revenue increased by 7.8 percent from $170 million to $183 million.
Irwin concluded that the tariff hastened the development of domestic tinplate production by about a decade, but also that this benefit to the industry was outweighed by the cost to consumers.
The tariff was not well received by Americans who suffered a steep increase in the cost of products. In the 1890 election Republicans lost their majority in the House with the number of seats they won reduced by nearly half, from 171 to 88. In the 1892 presidential election, Harrison was soundly defeated by Grover Cleveland, and the Senate, House, and Presidency were all under Democratic control. Lawmakers immediately started drafting new tariff legislation, and in 1894 the Wilson-Gorman Tariff passed which lowered US tariff averages. Nor was the tariff well received abroad. Protectionists within the British Empire used the McKinley Tariff to argue for tariff retaliation and imperial trade preference.

</doc>
<doc id="55711" url="https://en.wikipedia.org/wiki?curid=55711" title="Wilson–Gorman Tariff Act">
Wilson–Gorman Tariff Act

The Revenue Act or Wilson-Gorman Tariff of 1894 (ch. 349, §73, , August 27, 1894) slightly reduced the United States tariff rates from the numbers set in the 1890 McKinley tariff and imposed a 2% income tax. It is named for William L. Wilson, Representative from West Virginia, chair of the U.S. House Ways and Means Committee, and Senator Arthur P. Gorman of Maryland, both Democrats.
Supported by pro-free trade members of the Democratic Party, this attempt at tariff reform was important because it imposed the first peacetime income tax (2% on income over $4,000, or $88,100 in 2010 dollars, which meant fewer than 10% of households would pay any). The purpose of the income tax was to make up for revenue that would be lost by tariff reductions. By coincidence, $4,000 ($88,100 in 2010 dollars) would be the exemption for married couples when the Revenue Act of (October) 1913 was signed into law by President Woodrow Wilson, as a result of the ratification of the 16th Amendment to the U.S. Constitution in February 1913.
The bill introduced by Wilson and passed by the House significantly lowered tariff rates, in accordance with Democratic platform promises, and dropped the tariff to zero on iron ore, coal, lumber and wool, which angered American producers. With Senator Gorman operating behind the scenes, protectionists in the Senate added more than 600 amendments that nullified most of the reforms and raised rates again. The "Sugar Trust" in particular made changes that favored itself at the expense of the consumer.
President Grover Cleveland, who had campaigned on lowering the tariff and supported Wilson's version of the bill, was devastated that his program had been ruined. He denounced the revised measure as a disgraceful product of "party perfidy and party dishonor," but still allowed it to become law without his signature, believing that it was better than nothing and was at the least an improvement over the McKinley tariff.
The Wilson-Gorman Tariff attracted much opposition in West Texas, where sheepraisers opposed the measure. A Republican, George H. Noonan, was elected to Congress from the district stretching from San Angelo to San Antonio but only for a single term. Among Noonan's backers was a former slave, George B. Jackson, a businessman in San Angelo often called "the wealthiest black man in Texas" in the late 19th century.
Income Tax Amendment.
The "New York Times" reported that many Democrats in the East, "prefer to take the income tax, odious as it is, and unpopular as it is bound to be with their constituents," than to defeat the Wilson tariff bill. Democratic Representative Johnson of Ohio supported the income tax as the lesser of two evils:
"he was for an income tax as against a tariff tax; but he believed, that it was un-Democratic, inquisitorial, and wrong in principle."
Legacy.
The income tax provision was struck down in 1895 by the U.S. Supreme Court case "Pollock v. Farmers' Loan & Trust Co.", . In 1913, the 16th Amendment permitted a federal income tax.
The tariff provisions of Wilson-Gorman were superseded by the Dingley Tariff of 1897.

</doc>
<doc id="55714" url="https://en.wikipedia.org/wiki?curid=55714" title="Dawes Act">
Dawes Act

The Dawes Act of 1887 (also known as the General Allotment Act or the Dawes Severalty Act of 1887),
adopted by Congress in 1887, authorized the President of the United States to survey American Indian tribal land and divide it into allotments for individual Indians. Those who accepted allotments and lived separately from the tribe would be granted United States citizenship. The Dawes Act was amended in 1891, in 1898 by the Curtis Act, and again in 1906 by the Burke Act.
The Act was named for its creator, Senator Henry Laurens Dawes of Massachusetts. The objectives of the Dawes Act were to lift the Native Americans out of poverty and to stimulate assimilation of them into mainstream American society. Individual household ownership of land and subsistence farming on the European-American model was seen as an essential step. The act also provided what the government would classify as "excess" those Indian reservation lands remaining after allotments, and sell those lands on the open market, allowing purchase and settlement by non-Native Americans.
The Dawes Commission, set up under an Indian Office appropriation bill in 1893, was created to try to persuade the Five Civilized Tribes to agree to allotment plans. (They had been excluded from the Dawes Act by their treaties.) This commission registered the members of the Five Civilized Tribes on what became known as the Dawes Rolls.
The Curtis Act of 1898 amended the Dawes Act to extend its provisions to the Five Civilized Tribes; it required abolition of their governments, allotment of communal lands to people registered as tribal members, and sale of lands declared surplus, as well as dissolving tribal courts. This completed the extinguishment of tribal land titles in Indian Territory, preparing it to be admitted to the Union as the state of Oklahoma.
During the ensuing decades, the Five Civilized Tribes lost 90 million acres of former communal lands, which were sold to non-Natives. In addition, many individuals, unfamiliar with land ownership, the target of speculators and criminals, and stuck with allotments that were too small for profitable farming, lost their household lands. Tribe members also suffered from the breakdown of the social structure of the tribes.
During the Great Depression, the Franklin D. Roosevelt administration supported passage on June 18, 1934 of the US Indian Reorganization Act (also known as the Wheeler-Howard Law). It ended land allotment and created a "New Deal" for Indians, renewing their rights to reorganize and form their self-governments.
The Indian Problem.
During the 1850s, the United States federal government's attempt to exert control over the Native Americans expanded. Numerous new European immigrants were settling on the eastern border of the Indian territories, where most of the Native Americans tribes were situated. Conflicts between the groups increased as they competed for resources and operated according to different cultural systems. Many European Americans did not believe that members of the two racial societies could coexist within the same communities. Searching for a quick solution to their problem, William Medill the Commissioner of Indian Affairs, proposed establishing "colonies" or "reservations" that would be exclusively for the natives, similar to those which some native tribes had created for themselves in the east. It was a form of removal whereby the US government would uproot the natives from their current locations to positions to areas in the region beyond the Mississippi River; this would enable settlement by European Americans in the Southeast in turn opening up new placement for the new white settlers and at the same time protecting them from the corrupt "evil" ways of the subordinate natives.
The new policy intended to concentrate Native Americans in areas away from encroaching settlers, but it caused considerable suffering and many deaths. During the nineteenth century, Native American tribes resisted the imposition of the reservation system and engaged with the United States Army in what were called the Indian Wars in the West for decades. Finally defeated by the US military force and continuing waves of encroaching settlers, the tribes negotiated agreements to resettle on reservations. Native Americans ended up with a total of over of land, ranging from arid deserts to prime agricultural land.
The Reservation system, though forced upon Native Americans, was a system that allotted each tribe a claim to their new lands, protection over their territories, and the right to govern themselves. With the Senate supposedly being able to intervene only through the negotiation of treaties, they adjusted their ways of life and tried to continue their traditions. The traditional tribal organization, a defining characteristic of Native Americans as a social unit, became apparent to the non-native communities of the United States and created a mixed stir of emotions. The tribe was viewed as a highly cohesive group, led by a hereditary, chosen chief, who exercised power and influence among the members of the tribe by aging traditions. The tribes were seen as strong, tight-knit societies led by powerful men who were opposed to any change that weakened their positions. Many white Americans feared them and sought reformation. The Indians' failure to adopt the "Euroamerican" lifestyle, which was the social norm in the United States at the time, was seen as both unacceptable and uncivilized.
By the end of the 1880s, a general consensus seem to have been reached among many US stakeholders that the assimilation of Native Americans into white American culture was top priority; it was the time for them to leave behind their tribal landholding, reservations, traditions and ultimately their Indian identities.
On February 8, 1887, the Dawes Allotment Act was signed into law by President Grover Cleveland.
Responsible for enacting the division of the American native reserves into plots of land for individual households, the Dawes Act was created by reformers to achieve six goals:
The compulsory Act forced natives to succumb to their inevitable fate; they would undergo severe attempts to become "Euro-Americanized" as the government allotted their reservations with or without their consent. Native Americans held very specific ideologies pertaining to their land, to them the land and earth were things to be valued and cared for, for they represented all things that produced and sustained life, it embodied their existence and identity, and created an environment of belonging. In opposition to their white counterparts, they did not see it from an economic standpoint.
But, many natives began to believe they had to adapt to the majority culture in order to survive. They would have to embrace these beliefs and surrender to the forces of progress. They were to adopt the values of the dominant society and see land as real estate to be bought and developed; they were to learn how to use their land effectively in order to become prosperous farmers. As they were inducted as citizens of the country, they would shed their uncivilized discourses and ideologies, and exchange them for ones that allowed them to become industrious self-supporting citizens, and finally rid themselves of their "need" for government supervision.
Provisions of the Dawes Act.
The important provisions of the Dawes Act were: 
Every member of the bands or tribes receiving a land allotment is subject to laws of the state or territory in which they reside. Every Indian who receives a land allotment "and has adopted the habits of civilized life" (lived separate and apart from the tribe) is bestowed with United States citizenship "without in any manner impairing or otherwise affecting the right of any such Indian to tribal or other property."
The Secretary of Interior could issue rules to assure equal distribution of water for irrigation among the tribes, and provided that "no other appropriation or grant of water by any riparian proprietor shall be authorized or permitted to the damage of any other riparian proprietor."
The Dawes Act did not apply to the territory of the:
Provisions were later extended to the Wea, Peoria, Kaskaskia, Piankeshaw, and Western Miami tribes by act of 1889. Allotment of the lands of these tribes was mandated by the Act of 1891, which amplified the provisions of the Dawes Act.
Dawes Act 1891 Amendments.
In 1891 the Dawes Act was amended:
Provisions of the Curtis Act.
The Curtis Act of 1898 extended the provisions of the Dawes Act to the Five Civilized Tribes in Indian Territory. It did away with their self-government, including tribal courts. In addition to providing for allotment of lands to tribal members, it authorized the Dawes Commission to make determination of members when registering tribal members.
Provisions of the Burke Act.
The Burke Act of 1906 amended the sections of the Dawes Act dealing with US Citizenship (Section 6) and the mechanism for issuing allotments. The Secretary of Interior could force the Indian Allottee to accept title for land. US Citizenship was granted unconditionally upon receipt of land allotment (the individual did not need to move off the reservation to receive citizenship). Land allotted to Indians was taken out of Trust and subject to taxation. The Burke Act did not apply to any Indians in Indian Territory.
Effects.
The Dawes Act had a negative effect on American Indians, as it ended their communal holding of property (with crop land often being privately owned by families or clans), by which they had ensured that everyone had a home and a place in the tribe. The act "was the culmination of American attempts to destroy tribes and their governments and to open Indian lands to settlement by non-Indians and to development by railroads." Land owned by Indians decreased from in 1887 to in 1934.
Senator Henry M. Teller of Colorado was one of the most outspoken opponents of allotment. In 1881, he said that allotment was a policy "to despoil the Indians of their lands and to make them vagabonds on the face of the earth." Teller also said, 
"the real aim allotment was "to get at the Indian lands and open them up to settlement. The provisions for the apparent benefit of the Indians are but the pretext to get at his lands and occupy them. ... If this were done in the name of Greed, it would be bad enough; but to do it in the name of Humanity ... is infinitely worse."
The amount of land in native hands rapidly depleted from some to a small by 1900. The remainder of the land once allotted to appointed natives was declared surplus and sold to non-native settlers as well as railroad and other large corporations; other sections were converted into federal parks and military compounds. The concern shifted from encouraging private native landownership to satisfying the white settlers' demand for larger portions of land.
By dividing reservation lands into privately owned parcels, legislators hoped to complete the assimilation process by forcing Indians to adopt individual households, and strengthen the nuclear family and values of economic dependency strictly within this small household unit.
Given the conditions on the Great Plains, the land granted to most allottees was not sufficient for economic viability of farming. Division of land among heirs upon the allottees' deaths quickly led to land fractionalization. Most allotment land, which could be sold after a statutory period of 25 years, was eventually sold to non-Native buyers at bargain prices. Additionally, land deemed to be "surplus" beyond what was needed for allotment was opened to white settlers, though the profits from the sales of these lands were often invested in programs meant to aid the American Indians. Over the 47 years of the Act's life, Native Americans lost about 90 million acres (360,000 km²) of treaty land, or about two-thirds of the 1887 land base. About 90,000 Native Americans were made landless.
In 1906 the Burke Act (also known as the forced patenting act) amended the GAA to give the Secretary of the Interior the power to issue allottees a patent in fee simple to people classified "competent and capable." The criteria for this determination is unclear but meant that allottees deemed "competent" by the Secretary of the Interior would have their land taken out of trust status, subject to taxation, and could be sold by the allottee. The allotted lands of Indians determined to be incompetent by the Secretary of the Interior were automatically leased out by the Federal Government.
The act reads:
... the Secretary of the Interior may, in his discretion, and he is hereby authorized, whenever he shall be satisfied that any Indian allottee is competent and capable of managing his or her affairs at any time to cause to be issued to such allottee a patent in fee simple, and thereafter all restrictions as to sale, encumbrance, or taxation of said land shall be removed.
The use of competence opens up the categorization, making it much more subjective and thus increasing the exclusionary power of the Secretary of Interior. Although this act gives power to the allottee to decide whether to keep or sell the land, given the harsh economic reality of the time, and lack of access to credit and markets, liquidation of Indian lands was almost inevitable. It was known by the Department of Interior that virtually 95% of fee patented land would eventually be sold to whites.
The allotment policy depleted the land base, ending hunting as a means of subsistence. According to Victorian ideals, the men were forced into the fields (but the Indians thought this made them take on what in their society had traditionally been the woman's role, and the women were relegated to the domestic sphere). This Act imposed a patriarchal nuclear household onto many matrilineal Native societies, in which women had controlled property and descent.
Native gender roles and relations quickly changed with this policy, since communal living had shaped the social order of Native communities. Women were no longer the caretakers of the land and they were no longer valued in the public political sphere. Even in the home, the Native woman was dependent on her husband. Before allotment, women divorced easily and had important political and social status, as they were usually the center of their kin network. Under the Dawes Act, to receive the full , women had to be officially married.
In 1926, Secretary of the Interior Hubert Work commissioned a study of federal administration of Indian policy and the condition of Indian people. Completed in 1936, "The Problem of Indian Administration"commonly known as the Meriam Report after the study's director, Lewis Meriam documented fraud and misappropriation by government agents. In particular, the Meriam Report found that the General Allotment Act had been used to illegally deprive Native Americans of their land rights.
After considerable debate, Congress terminated the allotment process under the Dawes Act by enacting the Indian Reorganization Act of 1934 ("Wheeler-Howard Act"). However, the allotment process in Alaska, under the separate Alaska Native Allotment Act, continued until its revocation in 1993 by the Alaska Native Claims Settlement Act.
Despite termination of the allotment process in 1934, effects of the General Allotment Act continue into the present. For example, one provision of the Act was the establishment of a trust fund, administered by the Bureau of Indian Affairs, to collect and distribute revenues from oil, mineral, timber, and grazing leases on Native American lands. The BIA's alleged improper management of the trust fund resulted in litigation, in particular the case "Cobell v. Kempthorne" (settled in 2009 for $3.4 billion), to force a proper accounting of revenues.
Fractionation.
For nearly one hundred years, the consequences of federal Indian allotments have developed into the problem of "fractionation". As original allottees die, their heirs receive equal, undivided interests in the allottees' lands. In successive generations, smaller undivided interests descend to the next generation. Fractionated interests in individual Indian allotted land continue to expand exponentially with each new generation.
Today, there are approximately four million owner interests in the of individually owned trust lands, a situation the magnitude of which makes management of trust assets extremely difficult and costly. These four million interests could expand to 11 million interests by the year 2030 unless an aggressive approach to fractionation is taken. There are now single pieces of property with ownership interests that are less than 0.0000001% or 1/9 millionth of the whole interest, which has an estimated value of .004 cent.
The economic consequences of fractionation are severe. Some recent appraisal studies suggest that when the number of owners of a tract of land reaches between ten and twenty, the value of that tract drops to zero. Highly fractionated land is for all practical purposes worthless.
In addition, the fractionation of land and the resultant ballooning number of trust accounts quickly produced an administrative nightmare. Over the past 40 years, the area of trust land has grown by approximately per year. Approximately 357 million dollars is collected annually from all sources of trust asset management, including coal sales, timber harvesting, oil and gas leases and other rights-of-way and lease activity. No single fiduciary institution has ever managed as many trust accounts as the Department of the Interior has managed over the last century.
Interior is involved in the management of 100,000 leases for individual Indians and tribes on trust land that encompasses approximately . Leasing, use permits, sale revenues, and interest of approximately $226 million per year are collected for approximately 230,000 individual Indian money (IIM) accounts, and about $530 million per year are collected for approximately 1,400 tribal accounts. In addition, the trust currently manages approximately $2.8 billion in tribal funds and $400 million in individual Indian funds.
Under current regulations, probates need to be conducted for every account with trust assets, even those with balances between one cent and one dollar. While the average cost for a probate process exceeds $3,000, even a streamlined, expedited process costing as little as $500 would require almost $10,000,000 to probate the $5,700 in these accounts.
Unlike most private trusts, the Federal Government bears the entire cost of administering the Indian trust. As a result, the usual incentives found in the commercial sector for reducing the number of small or inactive accounts do not apply to the Indian trust. Similarly, the United States has not adopted many of the tools that States and local government entities have for ensuring that unclaimed or abandoned property is returned to productive use within the local community.
Fractionation is not a new issue. In the 1920s the Brookings Institution conducted a major study of conditions of the American Indian and included data on the impacts of fractionation. This report, which became known as the Meriam Report, was issued in 1928. Its conclusions and recommendations formed the basis for land reform provisions that were included in what would become the IRA. The original versions of the IRA included two key titles, one dealing with probate and the other with land consolidation. Because of opposition to many of these provisions in Indian Country, often by the major European-American ranchers and industry who leased land and other private interests, most were removed while Congress was considering the bill. The final version of the IRA included only a few basic land reform and probate measures. Although Congress enabled major reforms in the structure of tribes through the IRA and stopped the allotment process, it did not meaningfully address fractionation as had been envisioned by John Collier, then Commissioner of Indian Affairs, or the Brookings Institution.
In 1922, the General Accounting Office (GAO) conducted an audit of 12 reservations to determine the severity of fractionation on those reservations. The GAO found that on the 12 reservations for which it compiled data, there were approximately 80,000 discrete owners but, because of fractionation, there were over a million ownership records associated with those owners. The GAO also found that if the land were physically divided by the fractional interests, many of these interests would represent less than one square foot of ground. In early 2002, the Department of the Interior attempted to replicate the audit methodology used by GAO and to update the GAO report data to assess the continued growth of fractionation; it found that it increased by more than 40% between 1992 and 2002.
As an example of continuing fractionation, consider a real tract identified in 1987 in "Hodel v. Irving", 481 U.S. 704 (1987):
Tract 1305 is and produces $1,080 in income annually. It is valued at $8,000. It has 439 owners, one-third of whom receive less than $.05 in annual rent and two-thirds of whom receive less than $1. The largest interest holder receives $82.85 annually. The common denominator used to compute fractional interests in the property is 3,394,923,840,000. The smallest heir receives $.01 every 177 years. If the tract were sold (assuming the 439 owners could agree) for its estimated $8,000 value, he would be entitled to $.000418. The administrative costs of handling this tract are estimated by the Bureau of Indian Affairs at $17,560 annually.
Today, this tract produces $2,000 in income annually and is valued at $22,000. It now has 505 owners but the common denominator used to compute fractional interests has grown to 220,670,049,600,000. If the tract were sold (assuming the 505 owners could agree) for its estimated $22,000 value, the smallest heir would now be entitled to $.00001824. The administrative costs of handling this tract in 2003 are estimated by the BIA at $42,800.
Fractionation has become significantly worse. As noted above, in some cases the land is so highly fractionated that it can never be made productive. With such small ownership interests, it is nearly impossible to obtain the level of consent necessary to lease the land. In addition, to manage highly fractionated parcels of land, the government spends more money probating estates, maintaining title records, leasing the land, and attempting to manage and distribute tiny amounts of income to individual owners than is received in income from the land. In many cases, the costs associated with managing these lands can be significantly more than the value of the underlying asset.
Contemporary interpretations.
Angie Debo's landmark work, "And Still the Waters Run: The Betrayal of the Five Civilized Tribes" (1940), detailed how the allotment policy of the Dawes Act (as later extended to apply to the Five Civilized Tribes through such devices as the Dawes Commission and the Curtis Act of 1898) was systematically manipulated to deprive the Native Americans of their lands and resources. In the words of historian Ellen Fitzpatrick, Debo's book "advanced a crushing analysis of the corruption, moral depravity, and criminal activity that underlay white administration and execution of the allotment policy."

</doc>
<doc id="55715" url="https://en.wikipedia.org/wiki?curid=55715" title="Dingley Act">
Dingley Act

The Dingley Act of 1897 (ch. 11, , July 24, 1897), introduced by U.S. Representative Nelson Dingley, Jr., of Maine, raised tariffs in United States to counteract the Wilson–Gorman Tariff Act of 1894, which had lowered rates. 
Following the election of 1896, McKinley followed through with his promises for protectionism. Congress imposed duties on wool and hides which had been duty-free since 1872. Rates were increased on woolens, linens, silks, china, and sugar (the tax rates for which doubled). The Dingley Tariff remained in effect for twelve years, making it the longest-lived tariff in U.S. history. It was also the highest in U.S. history, averaging about 52% in its first year of operation. Over the life of the tariff, the rate averaged at around 47%.
The Dingley Act remained in effect until the Payne-Aldrich Tariff Act of 1909.

</doc>
<doc id="55716" url="https://en.wikipedia.org/wiki?curid=55716" title="Hua Mulan">
Hua Mulan

Hua Mulan () is a legendary woman warrior from the Southern and Northern Dynasties (420–589) of China who was originally described in a ballad known as the "Ballad of Mulan" (). In the ballad, Hua Mulan takes her aged father's place in the army. She was known for practicing martial arts such as kung fu and for being skilled with the sword. She fought for twelve years and gained high merit, but she refused any reward and retired to her hometown instead.
The historical setting of Hua Mulan is in the Han Dynasty. Over a thousand years later, Xu Wei's play from the Ming places her in the Northern Wei (386–536), whereas the Qing dynasty "Sui Tang Romance" has her active around the founding of the Tang c. 620. In 621, the founder of the Tang dynasty was victorious over Wang Shichong and Dou Jiande, the latter was the father of Dou Xianniang, another female warrior who became Mulan's laotong in the "Sui Tang Romance".
The Hua Mulan crater on Venus is named after her.
History.
The "Ballad of Mulan" was first transcribed in the "Musical Records of Old and New" () in the 6th century, the century before the founding of the Tang dynasty. The original work still exists and the original text of this poem comes from another work known as the "Music Bureau Collection" (), an anthology of lyrics, songs and poems compiled by Guo Maoqian during the 11th or 12th century. The author explicitly mentions the "Musical Records of Old and New" as his source for the poem. As a ballad, the lines do not necessarily have equal numbers of syllables. The poem consists of 31 couplets, and is mostly composed of five-character phrases, with a few extending to seven or nine.
There was no treatment of the legend since the two 12th century poems, until in the late Ming, playwright Xu Wei (d. 1593) dramatized the tale as "The Female Mulan" ( or, more fully, "The Heroine Mulan Goes to War in Her Father's Place" (), in two acts.
Later, the character of Mulan was incorporated into the "", a historical novel written by in the 17th century, early in the Qing dynasty.
Over time, the story of Hua Mulan rose in popularity as a folk tale among the Chinese people on the same level as the Butterfly Lovers.
Name.
In Chinese, "mùlán" () refers to the magnolia. The heroine of the poem is given different family names in different versions of her story. According to "History of Ming", her family name is Zhu (朱), while the "History of Qing" says it is Wei (魏). The family name 花 ("Huā", lit. "flower"), which was introduced by Xu Wei, has become the most popular in recent years in part because of its more poetic meaning.
Historicity.
The story of Hua Mulan is treated more as a legend than a historical person, and her name does not appear in "Exemplary Women" which is a compilation of biographies of women during the Northern Wei dynasty. Her legend is however, included in Yan Xiyuan's "One Hundred Beauties" which is a compilation of various women in Chinese folklore. A possible candidate would have been the Chinese female strategist Fu Hao but she existed in the Shang dynasty centuries later.
Plot.
The poem starts with Mulan sitting worriedly at her loom, as one male from each family is called to serve in the army to defend China from invaders. Her father is old and weak and her younger brother is just a child, so she decides to take his place and bids farewell to her parents. After twelve years of fighting, the army returns and the warriors are rewarded. Mulan turns down an official post, and asks only for a swift horse to carry her home. She is greeted with joy by her family. Mulan dons her old clothes and meets her comrades, who are shocked that in their years traveling together, they did not realize that she was a woman.
The "Sui Tang Romance".
Zhu Renhuo's "Romance of the Sui and Tang" (c. 1675) provides additional backdrops and plot-twists. Here, Mulan lives under the rule of Heshana Khan of the Western Turkic Khaganate. When the Khan agrees to wage war in alliance with the emergent Tang dynasty, which was poised to conquer all of China, Mulan's father Hua Hu () fears he will be conscripted into military service since he only has two daughters and an infant son. Mulan crossdresses as a man and enlists in her father's stead. She is intercepted by the forces of the Xia king Dou Jiande and is brought under questioning by the king's warrior daughter Xianniang (), who tries to recruit Mulan as a man. Discovering Mulan to be a fellow female warrior, she is so delighted that they become sworn sisters.
In the "Sui Tang Romance", Mulan comes to a tragic end, a "detail that cannot be found in any previous legends or stories associated Hua Mulan," and believed to have been interpolated by the author Chu Renho. Xianniang's father is vanquished after siding with the enemy of the Tang dynasty, and the two sworn sisters, with knives in their mouths, surrender themselves to be executed in the place of the condemned man. The act of filial piety wins reprieve from Emperor Taizong of Tang and the imperial consort who was birth-mother to the Emperor bestows money to Mulan to provide for her parents and wedding funds for the princess who confessed to having promised herself to general (). (In reality, Dou Jiande was executed, but in the novel he lives on as a monk.)
Mulan is given leave to journey back to her homeland, and once arrangements were made for Mulan's parents to relocate, it is expected that they will all be living in the princess's old capital of Leshou (, modern Cangzhou, Xian County, Hebei). Mulan is devastated to discover her father has long died and her mother has remarried. According to the novel, Mulan's mother was surnamed Yuan (袁) and remarried a man named Wei (魏). Even worse, the Khan has summoned her to the palace to become his concubine.
Rather than to suffer this fate, she commits suicide. But before she dies, she entrusts an errand to her younger sister, Youlan (), which was to deliver Xianniang's letter to her fiancé, Luō Chéng. This younger sister dresses as a man to make her delivery, but her disguise is discovered, and it arouses her recipient's amorous attention.
In the novel, Mulan's father was non-Han, a Xianbei (described as "a Hebei person of the people of the Northern Wei dynasty, ruled by the Tuoba clan"), while her mother was Han Chinese from the Central Plain. But "even a half-Chinese woman would prefer death by her own hand to serving a foreign ruler," as some commentators have explained this Mulan character's motive for committing suicide. Mulan's words before she committed suicide were, "I'm a girl, I been through war and did enough. I now want to be with my father."
Modern adaptations.
The story of Hua Mulan has inspired a number of screen and stage adaptations in the modern era, which include:

</doc>
<doc id="55717" url="https://en.wikipedia.org/wiki?curid=55717" title="Mulan (Disney character)">
Mulan (Disney character)

Fa Mulan, a character inspired by an actual historic figure is a character who appears in Walt Disney Pictures' 36th animated feature film "Mulan "(1998), as well as its sequel "Mulan II "(2004). Her speaking voice is provided by Chinese-American actress Ming-Na Wen, while Filipina singer Lea Salonga provides the character's singing voice. Created by author Robert D. San Souci, Mulan is based on the legendary Chinese warrior Hua Mulan from the poem the "Ballad of Mulan". The only child of an aging war veteran, Mulan disregards both tradition and the law by disguising herself as a man in order to enlist herself in the army in lieu of her feeble father.
Disney had originally conceived Mulan as an oppressed young Mongolian woman who ultimately elopes to Europe to be with a British prince. However, director Tony Bancroft, who was inspired by the well-being of his own daughters, wanted Mulan to be a different, unique kind of Disney heroine – one who is strong and independent, whose fate does not depend upon a male character. Thus, the relationship between Mulan and Captain Li Shang was relegated to that of a minor subplot, while Mulan's bravery and strength were emphasized in order to ensure that she remained the hero of her own story. Mulan's supervising animator was Mark Henn, who deliberately designed the character so that she would appear less feminine than her predecessors.
Reception towards Mulan's personality has been generally positive, with critics praising her bravery and heroism. However, some commentators have accused Disney of Westernizing the character, while her romantic relationship with Shang has been widely accused of compromising Mulan's heroism. Chronologically, Mulan is the eighth Disney Princess, and the franchise's first East Asian member.
Development.
Conception and writing.
"Mulan "was originally conceived as an animated short in 1994, in which the heroine is depicted as a miserable Chinese girl who elopes to the West to be with a British prince. While developing a series of treatments based on traditional stories and folk tales, children's book author Robert D. San Souci discovered the "Ballad of Mulan", an ancient Chinese poem about Hua Mulan – a Chinese woman who replaces her ailing father in the army by disguising herself as a man. Fascinated by Hua Mulan's story, San Souci suggested the poem to Disney; the studio hired San Souci himself to write the film's treatment and story.
"Mulan "explores the age-old theme of remaining true to oneself, with co-director Tony Bancroft summarizing the character's role in the film as "the story of a girl who can't help who she is but she exists in a different society that tells her who she is supposed to be." Because the "Ballad of Mulan" is such a beloved and well-known story, San Souci longed to maintain the character's integrity. However, certain creative liberties were taken with the story in regards to Mulan's role, such as the character neglecting to ask her parents' permission prior to enlisting herself in the army. Additionally, Mulan's surname was changed from "Hua" to "Fa." Finally, Mulan's true identity is discovered much earlier in the film, soon after the army's initial encounter with the enemy, whereas her comrades remain ignorant throughout their entire 12 years at war until after Mulan has returned home.
In addition, unlike preceding traditional Disney animated feature films, the developing romantic relationship between Mulan and Li Shang is treated as more of a subplot as opposed to a traditional central plot, as observed by film critic Andy Klein of Animation World Network. Klein commented, "Mulan isn't waiting for her prince to someday come; when he does arrive, having known her primarily as a man, and having learned to admire her for her deeper qualities, the romance is muted and subtle." Throughout the movie they are constantly working towards helping each other change into better and truer versions of themselves in order to achieve their true potential.
Voice.
Mulan's speaking voice is provided by Chinese-American actress Ming-Na Wen. Because the character "represented Chinese values" and is depicted as being "dramatic ... close to her father, very respectful," Bancroft believed that Wen possessed the "perfect" voice for Mulan, which he additionally described as "very Chinese." Born and raised in Macau, China, Wen was very much familiar with both the legend of Hua Mulan and the "Ballad of Mulan "at the time of her audition for the role, having grown up being read the poem by her mother. Wen explained, "I think every Chinese kid grows up with this story," additionally likening the poem's popularity in China to that of the Western Parson Weems fable in which American president George Washington chops down his father's beloved cherry tree.
Mulan served as Wen's first voice-acting role. In an interview with IGN, the actress elaborated on the recording process, specifically the fact that she was required to record the majority of the character's dialogue in isolation, saying, "I just loved the story so much and identified so much with the character of Mulan it was easy for me. I loved using my imagination. I felt like I was a little kid again, being silly with an imaginary sword and riding on an imaginary horse and talking to an imaginary dragon. So it was a lot of fun for me." In spite of the fact that, throughout the film, Mulan shares several intimate scenes with her guardian, a miniature Chinese dragon named Mushu who is voiced by American actor and comedian Eddie Murphy, Wen and her co-star never actually encountered each other while working on "Mulan "due to the fact that they recorded their respective dialogue at separate times in separate locations.
Upon being cast as Mulan's speaking voice, Wen was immediately informed by Disney that she would not be providing the character's singing voice. The actress took no offense to this decision, commenting jokingly "I don't blame them." The directors hired Filipina singer and actress Lea Salonga to dub the character's respective singing voice, heard in the film's songs "Reflection", "I'll Make a Man Out of You" and "A Girl Worth Fighting For", on Wen's behalf. According to Thomas S. Hischak, author of the book "Disney Voice Actors: A Biographical Dictionary", Salonga was originally cast to provide both Mulan's speaking and singing voices. However, the directors eventually felt that her attempt at impersonating a man in the form of Mulan's male alter-ego "Ping" was rather unconvincing, and ultimately replacing Salonga with Wen. Six years prior to "Mulan", Salonga provided the singing voice of Princess Jasmine in Disney's "Aladdin "(1992) on behalf of American actress Linda Larkin. While auditioning for Mulan, Salonga asked jokingly, "Why do I have to audition? ... I was already a princess before. Wasn't that enough?"
Characterization and design.
The film's screenplay was constantly being revised and re-written. Naturally, so was Mulan's characterization and role in the film. The writers wanted Mulan to represent a "different kind of Disney heroine," specifically described as one who "didn't need a tiara, but was still just as much as graceful, strong, and courageous." Between the two, Bancroft and his twin brother Tom, an animator who also worked on "Mulan", have a total of seven daughters. This further inspired the filmmakers to portray Mulan as a unique heroine who is "not another damsel in distress" in favor of having her resemble "a strong female Disney character who would truly be the heroine of her own story" instead, essentially a "female role model. The characteristics of strength and courage were a must for Mulan." In an interview with "The Christian Post", Bancroft elaborated on the way in which he, as the film's director, continued to consider the well-being of his two young daughters while working on "Mulan", having "wanted to make ... a unique heroine that hadn't been seen before" and provide for them "someone who would be strong on her own, without a prince saving her." Addressing the way in which Mulan differs from traditional Disney heroines and princesses, Bancroft explained, "Most Disney heroines have an outside source that comes in and helps them change. Mulan stays consistent. From the first frame all the way through the end of the movie, her personality, her drive it all stays the same." 
Visually, the animators were influenced by both traditional Chinese and Japanese artwork. In the specific case of Mulan, "The characters' simple lines ... resemble classic Asian painting", as demonstrated by the animators' innovate "'less is more' approach" to traditional animation. Chinese artist Chen Yi mentored the animators, "helping to come up with these designs." Mark Henn served as Mulan's supervising animator. Animating the character in her male disguise as "Ping" offered an unprecedented challenge for Henn. In order to solve this unique dilemma, Henn was provided with "the opportunity to ... adjust her design a little bit so that when she was disguised as Ping, as a soldier, that she was physically a little different in how we drew her than when she was herself as Mulan." Physically, Mulan was also designed to appear less feminine than preceding traditional Disney animated heroines, specifically Pocahontas from "Pocahontas "(1995) and Esmeralda from "The Hunchback of Notre Dame "(1996), because "you can't pass as a man in the army with a Barbie-style figure."
Henn revealed that he was drawn to "Mulan's story it was so unique and compelling that it just captivated me from the beginning". Animating the characters' distinct emotions using the traditional Chinese style turned out to be somewhat challenging for Henn. The animator explained, "We don't create realism in the sense that if you're doing a human character, it's not going to look realistic ... the balance is finding an appealing way of drawing using the visual tools that you have in the design to convey the believable emotions that you want to get across." In addition to Mulan, Henn was also responsible for animating Fa Zhou, Mulan's elderly father. He described the complex relationship between the two characters as "the emotional heart of the story". Fathering one daughter himself, Henn drew inspiration from his own emotions as well as past personal experiences while animating several intimate scenes shared by the two characters.
Several film critics have described Mulan as a tomboy. Andy Patrizio of IGN observed, "In this slightly modernized version of the story, Mulan ... is something of a rebel and a tomboy. She has no interest in being a good little subservient wife, despite her sighing parents' wishes." Jo Johnson, in contribution to the book "Queers in American Popular Culture Volume 1: Film and Television", wrote that "Unlike other Disney heroines, Mulan is immediately coded as a tomboy," observing the way in which the character speaks using a full mouth. Johnson additionally noticed several ways in which Mulan's design and personality differ from those typically associated with traditional Disney heroines and princesses, citing the character's clumsy, awkward demeanor; broad shoulders and muscular limbs; unruly single strand of hair; and choice of everyday attire which usually consists of loose, baggy clothing concealing her "traditionally slim Disney waist." Additionally, Mulan's intelligence has been observed in several professional analyses, with critics often citing the character as "brainy."
Appearances.
"Mulan".
The Huns, led by Shan Yu, invade Han China, forcing the Chinese emperor to command a general mobilization. The emperor requires one man from each family to join the Chinese army. When Fa Mulan hears that her elderly father Fa Zhou, the only man in their family, is forced to rejoin the army, she decides to stand in his place, disguising herself as a young man named "Ping". Mulan's family learns that she has taken Fa Zhou's place and pray to their family ancestors, who then order their "Great Stone Dragon" to protect her. The ancestors are unaware that the statue of Great Stone Dragon failed to come to life, and that Mushu, a small dragon is the one to go and protect Mulan.
Mulan is initially misguided by Mushu who encourages her to go to war and in how to behave like a man. However, under command of Li Shang, she and her new friends at the camp, Yao, Ling and Chien-Po, become skilled warriors. Mushu, desiring to see Mulan succeed, creates a fake order from Li Shang's father, General Li, ordering Li Shang to follow them into the mountains. They arrive at a burnt-out village and discover that General Li and his forces have been wiped out by the Huns. As they solemnly leave the mountains, they are ambushed by the Huns when Mushu accidentally fired a cannon causing their position to be given away, but a second firing of a cannon by Mulan buries most of the enemy forces in an avalanche. Mulan is slashed by Shan Yu in his rage at her wiping out his army during the battle, and she is forced to reveal her deception when she receives medical attention. Instead of executing Mulan as the law states, Li Shang spares her life for saving his life from the avalanche by leaving her on the mountain as the rest of the army departs for the Imperial City to report the news of the Huns' demise. However, the avalanche failed to eliminate all the enemies, as Mulan catches sight of a small number of surviving Huns, including Shan Yu, making their way to the City, intent on capturing the Emperor.
In the Imperial City, Mulan attempts to warn Li Shang about Shan Yu, but he refuses to listen. The Huns appear and capture the Emperor, locking themselves inside the palace. With Mulan's help, Li Shang, Yao, Ling, and Chien-Po pose as concubines and are able to enter the palace and defeat Shan Yu's men. As Shang prevents Shan Yu from assassinating the Emperor, Mulan lures the Hun onto the roof where she engages him in single combat. Meanwhile, acting on Mulan's instructions, Mushu fires a bundle of fireworks rockets at Shan Yu on her signal and kills him.
Mulan is praised by the Emperor and the people of China, who all bow to her, an unprecedented honor. Mulan accepts the Emperor's crest and Shan Yu's sword as gifts, but politely declines his offer to be his advisor and instead asks to return to her family. She returns home and presents the imperial gifts to her father, but he is more overjoyed to have his daughter back safely. Li Shang, who has become enamored with Mulan, soon arrives under the guise of returning her helmet, but accepts the family's invitation for dinner. Earlier in the film, Mulan was declared unfit for marriage, but this now appears not to be the case with her strong budding romance with Li Shang. Mushu is granted a position as a Fa family guardian by the ancestors amid a returning celebration.
"Mulan II".
The sequel finds Mulan and Li Shang preparing to marry but distracted by a task from the Emperor, who wants his three daughters escorted to their own marriage ceremony. Their romantic relationship becomes somewhat strained during the trip, as the romantic couple has differing views on various issues. Meanwhile, Mushu realizes that if Mulan marries Shang, she will not need him anymore as her guardian spirit. Taking advantage of this, he manages to trick the two into breaking up. When bandits attack, Mulan and Shang fight them off, but Mulan is devastated when Shang is seemingly killed trying to save her. To make sure the three princesses are not forced to marry against their will, Mulan takes their place marrying the eldest son of the ruler of the neighboring land. Shang survives the accident and arrives in time to stop the wedding but ultimately Mulan is saved by Mushu who, posing as the mighty Golden Dragon of Unity, frees the three princesses from their vows, and marries Mulan and Li Shang himself causing Mulan to forgive him for his actions. Afterwards, Mulan informs Li Shang of Mushu's existence and he combines the temples of his family and hers, allowing Mushu to keep his position.
Miscellaneous.
Mulan is the eighth official member the Disney Princess franchise, a media franchise marketed towards young girls. As children, the characters such as Mulan, demonstrates the positive aspects of: never giving up, not being restricted to gender roles and the importance of family and honor. These aspects of the film are more in keeping with a traditional Chinese perspective on cultural value, such as the importance of family and honor. Featured on the official Disney Princess website, the character's brief biography reads, "Mulan is a loving girl who is always brave and bold. When her country needs it most, she disguises herself as a man and goes off to fight. She uses courage and determination to win the day." Interestingly, Mulan is currently the only official member of the Disney Princess franchise who is technically not a legitimate princess "in the traditional sense" because of the fact that she was not born the daughter of a king or queen, nor does she become princess consort by marrying a prince. Additionally, she is also the franchise's first and currently only East Asian member.
Mulan appears as a playable character in "", an action video game released in December 1999 by Disney Interactive Studios exclusively for the video game console Sony PlayStation. Loosely based on the plot of the original animated film, the video game's concept and premise revolves around "Players ... assum the role of Mulan on her quest to recover the missing scrolls." Mulan also appears as a playable character in "Disney's Mulan", a similar video game released the previous year on October 10, 1998 by THQ for Nintendo Game Boy. Additionally, Mulan appears in the video game "Kingdom Hearts II" in the Land of the Dragons world. She aids Sora in battle, taking the place of either Donald or Goofy. She uses a jian called "Sword of the Ancestor" for regular combat, and her combination attacks include Red Rocket and other fire attacks, thanks to Mushu. She goes under her pseudonym (Ping) for the majority of Sora's first visit to her world, but has abandoned it by the time of their second visit, which follows an original storyline.
Mulan makes cameo appearances in the "Disney's House of Mouse" television series and the direct-to-video release "". She was scheduled to appear in the second installment of the Disney Princess Enchanted Tales series of DVDs along with Cinderella. It was to premiere in 2008 but was cancelled due to poor sales of the first DVD.
Mulan appears regularly for meet-and-greets, parades and shows at the Walt Disney Parks and Resorts, including at the Chinese Pavilion at Epcot. Mulan and Mushu, as a kite, make cameo appearances in the Hong Kong Disneyland and Disneyland Resort versions of It's a Small World. In Disneyland, she also makes appearances in the Disney Princess Fantasy Faire Village and regularly performs in the new show "Mickey and the Magical Map" in the Fantasyland Theater. In the aforementioned show, she performs a trio with fellow Disney Princesses Pocahontas and Rapunzel. As a tribute, there is a portrait of her along other Disney Princesses at the Princess Fairytale Hall at the Magic Kingdom.
On the Disney Cruise Line ships and in Hong Kong Disneyland, Mulan and Li Shang appear in the stage show "The Golden Mickeys". Mulan is also known to come out for meet-and-greets on the ships as well. She is also featured in the Disney on Ice shows "Princess Classics" and "Princess Wishes."
In the Square Enix and Disney game "Kingdom Hearts II", Mulan is a playable character when the protagonists visit her world.
Actress Jamie Chung portrays a live-action version of Mulan in the second, third and fifth seasons of the ABC television series, "Once Upon a Time". She first appeared in the series' second season premiere, "Broken", assisting Prince Phillip in rescuing Aurora. The "Once Upon a Time" version of Mulan differs from the film version as she is in love with Aurora, as revealed in the 2013 episode "Quite a Common Fairy".
On August 2014, Ming-Na Wen and Lea Salonga reprise their roles as Mulan for the first time since "Mulan 2" in the Disney Channel show "Sofia the First". In the episode "Princesses To The Rescue," Mulan reminds Sofia and her friends Amber and Jun they are "Stronger Than They Know" in song. Mulan is the 7th Disney princess to appear on the show.
Disney Infinity 3.0 has announced and released Mulan as one of the playable characters and figures.
Reception and legacy.
Critical response.
Reception towards Mulan's personality and characterization have been generally positive. "Time Out "hailed Mulan as "A feisty young go-getter rises above the male-dominated world in which she lives." Ken Fox of "TV Guide "wrote, "Intelligent and fiercely independent, Mulan ... runs afoul of social expectations that a woman will be always obedient and duty-bound to her husband." Bridget Byrne of "Boxoffice "wrote that "Mulan ... has pride, charm, spirit and aesthetic appeal which prevents her from being upstaged by the vigorous and exciting action in which she participates." "Variety"'s Todd McCarthy praised the character for inspiring "a turn of the circle from such age-old Disney classics ... in which passive heroines were rescued by blandly noble princes." McCarthy continued, "Here, it's the girl who does the rescuing, saving not only the prince but the emperor himself from oblivion, and this in a distant culture where women were expected to obey strictly prescribed rules." Similarly, Margaret A. McGurk of "The Cincinnati Inquirer" lauded Mulan for "solv[ing her "G.I. Jane" dilemma by proving that brains can do more than brawn." Hailing the character as "Among the strongest heroines in Walt's cartoon canon," Ian Freer of "Empire "enthused, "Mulan's engaging mixture of vulnerability and derring-do becomes incredibly easy to root for." Hollis Chacona of "The Austin Chronicle "dubbed Mulan a "winning protagonist." Likewise, the "Los Angeles Times"' Kenneth Turan wrote, "As a vivacious rebel who has to be true to herself no matter what, Mulan is an excellent heroine, perfect for the young female demographic the studio is most anxious to attract", additionally calling her a "more likable and resourceful role model than Pocahontas".
Although largely well-liked, Mulan's characterization has drawn some mild criticism and speculation, inspiring a series of generally mixed to positive reviews from some film critics. "Entertainment Weekly"'s Owen Gleiberman wrote, "Far more than "Beauty and the Beast" or the stolidly virtuous "Pocahontas", "Mulan" showcases a girl who gets to use her "wits "... a testament to the power of mind over brawn." However, Gleiberman continued, ""Mulan" finally falls a notch short of Disney's best ... because the heroine's empowerment remains ... an emotionally isolated quest." Similarly, Moira Macdonald of "The Seattle Times "hailed Mulan as "a strong, engaging character who, unlike many of her Disney counterparts, needs no one to rescue her from danger," while questioning her personality, asking, "was it really necessary to bestow Mulan with self-esteem problems? Because she seems so confident and intelligent, her sad statement that she wants to 'see something worthwhile' in the mirror comes as a bit of a shock."
Critics were not unanimous in their praise. "The Phoenix"'s Jeffrey Gantz felt that character was unoriginal, inaccurate and Westernized, writing, " costumes (particularly the kimono and obi Mulan wears to the Matchmaker) and hairdos look Japanese ... Give Mulan Native American features and you have Pocahontas." Similarly, James Berardinelli of "ReelViews "felt that the character's depiction was too "familiar," reviewing, "Although she looks different from Ariel, Belle, Jasmine, and Pocahontas, Mulan is very much the same type of individual: a woman with a strong, independent streak who is unwilling to bend to the customs of her culture, which decree that the role of the female is to be ornamental. The film isn't very subtle in reinforcing the idea of equality between the sexes". Additionally, some critics, such as Alex von Tunzelmann of "The Guardian", have criticized Mulan for her violence, writing, "Disney struggles to make Mulan both a killer and a heroine ... Gingerly, the film attempts to tread a middle path, implying that Mulan annihilates most of the Hun army by causing an avalanche, and having her dispatch Shan Yu with a load of fireworks. Very pretty. But still technically killing." However, von Tunzelmann did conclude more positively, "as Disney heroines go, Mulan herself is a clear improvement on the standard-issue drippy princess."
Relationship with Shang.
Unlike the generally positive reviews received by Mulan, critical reception towards the character's romantic relationship with Li Shang has been largely negative, drawing much speculation from critics who accused "Mulan "of having "a typical girl-hooks-up-with-boy ending." Roger Ebert of the "Chicago Sun-Times "observed, "The message here is standard feminist empowerment: Defy the matchmaker, dress as a boy, and choose your own career. But "Mulan" has it both ways, since inevitably Mulan's heart goes pitty-pat over Shang, the handsome young captain she's assigned to serve under. The movie breaks with the tradition in which the male hero rescues the heroine, but is still totally sold on the Western idea of romantic love." "The New York Times' "Janet Maslin negatively opined, "For all of Mulan's courage and independence in rebelling against the matchmakers, this is still enough of a fairy tale to need Mr. Right."
Citing Mulan's relationship with Shang as an example of sexism, a film critic writing for "Teen Ink" wrote:
Betsy Wallace of Common Sense Media observed that Mulan "doesn't fit the princess mold, and most moviegoers had never heard of her." Conclusively, Wallace wrote, "it's too bad that in the end she still needs to be married off to a 'Prince Charming' who saves the day." In contribution to the book "Beyond Adaptation: Essays on Radical Transformations of Original Works", Lan Dong wrote, "Even though Mulan achieves success after she resumes her female self ... it is compromised by Mulan and Li Shang's potential engagement at the end of the film."
Cultural significance and accolades.
Mulan is culturally recognized for her unique role in "Mulan "specifically in regards to the character's heroism, ethnicity and disinterest in romance, serving as a departure from traditional Disney heroines and princesses because she "challenged gender stereotypes and offered up an animated Disney experience that isn't princess-centric" as "one of the few strong, self-propelled female characters that Disney has." Kenneth Turan of the "Los Angeles Times "observed the way in which Mulan's role in the film as "an independent, not completely boy-crazy heroine is somewhat new for Disney." According to Sara Veal of "The Jakarta Post", Mulan "promotes self-reliance, determination and is uninterested in marriage or romance ... the film ends on her saving her country, rather than a romantic resolution." Succeeding non-white Disney Princesses Jasmine and Pocahontas, Mulan's characterization as Disney's first East Asian princess assisted in the diversification of the Disney Princess franchise, introducing "Disney princesses ... portrayed as women of color." Peter Travers of' "Rolling Stone commented, "Mulan ... makes a feisty prefeminist," continuing, "She doesn't swoon over Captain Shang, the hunky officer ... which leaves Shang ... frustrated ... Mulan, let the record show, does not put out." PopMatters' Jesse Hassenger wrote that unlike other Disney films, "Mulan holds the advantage of a smart, strong heroine—not just a superhot princess figure." Ryan Mazie of Box Office Prophets felt that Mulan "might be the most important and forward-thinking Disney Princess movie made up until that point where the female character solely takes control over her own destiny without the aid of a mighty Prince."
In 2012, CNN's Stephanie Goldberg recognized Mulan as one of Disney's bravest and most heroic animated heroines to-date in her article ""Brave"'s Merida and other animated heroines," writing, "Mulan bent traditional gender roles when she took her father's place in the Chinese army." The Georgia Institute of Technology ranked Mulan the fourteenth greatest Disney character of all-time. Similarly, in 2013, Mulan was ranked the greatest animated Disney heroine according to a poll conducted by Jim Vejvoda of IGN.
In 1999, "Mulan"'s theme song "Reflection", performed by Mulan, was nominated for the Golden Globe Award for Best Original Song at the 56th Golden Globe Awards, but ultimately lost to Celine Dion and Andrea Bocelli's "The Prayer" from "Quest for Camelot "(1998). "Reflection" is often credited with establishing the successful musical career of American recording artist Christina Aguilera, who famously recorded a pop rendition of the ballad prior to the release of her platinum-selling self-titled debut album in 1999, on which the song is featured. Additionally, the song peaked at number nineteen on the "Billboard"Adult Contemporary chart. In 2011, Salonga was honored with a Disney Legends award in commemoration of her role as Mulan's singing voice. Additionally, Salonga performed a live rendition of "Reflection" at the ceremony.
Controversy.
The 2013 Disney princess redesigns portrayed Mulan with features that differ from her film appearance. The artwork featured Mulan with blue eyes, bigger lips, noticeably lighter skin, and golden clothing which does not resemble any outfit she has worn in the film. Her new appearance has caused an uproar due to the whitewash of her character. This was particularly troubling as Mulan is one of the few princesses of color. Shavon L. McKinstry of "SPARK Movement" writes that Mulan's redesign "seem to be directly counter to her personality and character in her film", and also notes how all the princesses of color have been "noticeably pushed to the back or left out completely" from the new Disney merchandise which featured the redesigns.
Through stereotypical images, dialogue and action, it is easy for the audience to make the distinction between good characters and bad characters. Good characters "have big eyes and round cheeks and are drawn in curves, smooth, round, soft bright and with European features" (Xu, M & Tian, C. 2013), while bad characters are defined by having "sharp angles, oversized, and often darkly" (Xu, M & Tian, C. 2013). Disney indisputably represents an empire of symbols of westernized imperialism and cultural hegemony and of globalization that dominates within their heroes. These visual keys help the audience know who to root for in the film and what behaviours and morals you wish to follow if you want to achieve greatness like the heroes.
McKinstry argues that Disney "prefers to portray one demographic of princess, simultaneously alienating so much of their fanbase", pointing out that of the "ten Disney Princesses in the brand, six are white". The importance of Mulan and other non-white princesses can be seen in the 2009 study of the effects of children's cartoons on the body image of young girls by doctors Sharon Hayes and Stacey Tantleff-Dunn. The study revealed that in the group of girls ranging from 3 to 6 years old, 30.6% of the group would change their physical appearance if they could. Of these respondents, over half would change their hair and over a quarter would change something about their body, such as skin color. Of all girls surveyed, 8% said they would have to change their hair or skin color to become a princess, stating things like they would "change from brown skin to white skin", for example. The interviewed group was predominantly white.
Disney has since altered the coloration in Mulan's design by changing the blue eye highlight to brown, darkening the color of her skin, and changing her clothing to better resemble her attire in the film.

</doc>
<doc id="55718" url="https://en.wikipedia.org/wiki?curid=55718" title="Foraker Act">
Foraker Act

The Foraker Act, , officially known as the Organic Act of 1900, is a United States federal law that established civilian (albeit limited popular) government on the island of Puerto Rico, which had recently become a possession of the United States as a result of the Spanish–American War. Section VII of the Foraker Act also established Puerto Rican citizenship. President William McKinley signed the act on April 12, 1900 and it became known as the "Foraker Act" after its sponsor, Ohio Senator Joseph B. Foraker. Its main author has been identified as Secretary of War Elihu Root.
The new government had a governor and an 11-member executive council appointed by the President of the United States, a House of Representatives with 35 elected members, a judicial system with a Supreme Court and a United States District Court, and a non-voting Resident Commissioner in Congress. The Executive council was all appointed: five individuals were selected from Puerto Rico residents while the rest were from those in top cabinet positions, including attorney general and chief of police (also appointed by the President). The Insular Supreme Court was also appointed. In addition, all federal laws of the United States were to be in effect on the island. The first civil governor of the island under the Foraker Act was Charles H. Allen, inaugurated on May 1, 1900 in San Juan, Puerto Rico. This law was superseded in 1917 by the Jones–Shafroth Act.

</doc>
<doc id="55719" url="https://en.wikipedia.org/wiki?curid=55719" title="Gold Standard Act">
Gold Standard Act

The Gold Standard Act of the United States was passed in 1900 (approved on March 14) and established gold as the only standard for redeeming paper money, stopping bimetallism (which had allowed silver in exchange for gold). It was signed by President William McKinley.
The Act made the "de facto" gold standard in place since the Coinage Act of 1873 (whereby debt holders could demand reimbursement in whatever metal was preferred—usually gold) a "de jure" gold standard alongside other major European powers at the time.
The Act fixed the value of the dollar at  grains of gold at "nine-tenths fine" (90% purity), equivalent to 23.22 grains (1.5046 grams) of pure gold.
The Gold Standard Act confirmed the United States' commitment to the gold standard by assigning gold a specific dollar value (just over $20.67 per Troy ounce). This took place after McKinley sent a team to Europe to try to make a silver agreement with France and Great Britain.
On April 25, 1933, the United States and Canada dropped the gold standard.

</doc>
<doc id="55720" url="https://en.wikipedia.org/wiki?curid=55720" title="Mulan (1998 film)">
Mulan (1998 film)

Mulan is a 1998 American animated musical action-comedy-drama film produced by Walt Disney Feature Animation based on the Chinese legend of Fa Mulan. The 36th animated feature in the Walt Disney Animated Classics, it was directed by Tony Bancroft and Barry Cook, with story by Robert D. San Souci and screenplay by Rita Hsiao, Philip LaZebnik, Chris Sanders, Eugenia Bostwick-Singer, and Raymond Singer. Ming-Na, Eddie Murphy, Miguel Ferrer and BD Wong star in the English version, while Jackie Chan provided his voice for the Chinese dubs of the film. The film's plot takes place during the Han Dynasty, where Fa Mulan, daughter of aged warrior Fa Zhou, impersonates a man to take her father's place during a general conscription to counter a Hun invasion.
Released during the Disney Renaissance, "Mulan" was the first of three features produced primarily at the Disney animation studio at Disney-MGM Studios in Orlando, Florida. Development for the film began in 1994, when a number of artistic supervisors were sent to China to receive artistic and cultural inspiration. "Mulan" was well received by critics and the public, grossing $304 million, earning Golden Globe and Academy Award nominations, and winning several Annie Awards including Best Animated Feature. A 2005 direct-to-video sequel, "Mulan II", followed.
Plot.
After the Huns, led by the ruthless Shan Yu, invade Han China, the Chinese emperor begins to command a general mobilization. Each family is given a conscription notice, requiring one man from each family to join the Chinese army. When Fa Mulan hears that her elderly father Fa Zhou, the only man in their family, is once more to go to war, she becomes anxious and apprehensive. She decides to deal with this herself by disguising herself as a man so that she can go to war instead of her father. When her family learns of Mulan's departure, they all become anxious. Grandmother Fa, Mulan's grandmother, prays to the family ancestors for Mulan's safety. The ancestors then order their "Great Stone Dragon" to protect Mulan. The ancestors are unaware that the statue of Great Stone Dragon failed to come to life, and that Mushu, a small dragon, is the one to go and protect Mulan.
Mulan is misguided by Mushu in how to behave like a man, which starts a ruckus at the training camp. However, under command of Li Shang, she and her new co-workers at the camp, Yao, Ling and Chien-Po, become skilled warriors. Mushu, desiring to see Mulan succeed, creates a fake order from Shang's father, General Li, ordering Shang to follow them into the mountains. The troops set out to meet General Li, but arrive at a burnt-out encampment and discover that General Li and his troops have all been killed by the Huns. As they solemnly leave the mountains, they are ambushed by the Huns, but Mulan cleverly uses a cannon to create an avalanche which buries most of the Huns. An enraged Shan Yu slashes her in the chest, and her deception is revealed when the wound is bandaged. Instead of executing Mulan as the law requires, Shang relents and decides to spare her life for saving him, but expels her from the army, stranding her on the mountain as the rest of the army departs for the Imperial City to report the news of the Huns' demise. However it is revealed that several Hun warriors including Shan Yu survive the avalanche, and Mulan catches sight of them as they make their way to the City, intent on capturing the Emperor.
At the Imperial City, Mulan attempts to warn Shang about Shan Yu, but he refuses to listen. The Huns appear to capture the Emperor, then they lock up the palace. With Mulan's help, Yao, Ling, and Chien-Po pose as concubines and are able to enter the palace and, with the help of Shang, they defeat Shan Yu's men. As Shang prevents Shan Yu from assassinating the Emperor, Mulan lures the boss Hun onto the roof where she engages him in solo combat. Meanwhile, acting on Mulan's instructions, Mushu fires a bundle of fireworks rockets at Shan Yu on her signal. The fireworks strike Shan Yu and explode, killing him. Mulan is praised by the Emperor and the people of China, who all bow to her as an unprecedented honor. While she accepts the Emperor's crest and Shan Yu's sword as gifts, she politely declines his offer to be his advisor and asks to return to her family. She returns home and presents these gifts to her father and Grandmother, but they are more overjoyed to have Mulan back safely. Shang, who has become enamored with Mulan, soon arrives under the guise of returning her helmet, but accepts the family's invitation for dinner. Mushu is granted a position as a Fa family guardian by the ancestors amid a returning celebration.
Cast.
Kelly Chen, Coco Lee and Xu Qing voiced Mulan in the Cantonese, Taiwanese Mandarin and Mainland standard versions of the film respectively, while Jackie Chan provided the voice of Li Shang in all three Chinese versions and appeared in the version of promotional music videos of "I'll Make a Man Out of You".
Production.
Development.
In 1989, Walt Disney Feature Animation Florida had opened with 40 to 50 employees, with its original purpose to produce cartoon shorts and featurettes. However, by late 1993, following several animation duties on "Beauty and the Beast", "Aladdin", and "The Lion King", Disney executives were convinced to allow the Feature Animation Florida studios to produce their first independent film. Around that same time, Disney Feature Animation developed an interest into Asian-themed legends beginning with the optioning several books by children's book author Robert D. San Souci who had a consulting relationship with Disney executive Jay Dyer. Around that same time, a short straight-to-video film titled "China Doll" about an oppressed and miserable Chinese girl who is whisked away by a British Prince Charming to happiness in the West was in development. Thomas Schumacher asked Souci if he had any additional stories, in which Souci turned in a manuscript of a book based on the Chinese poem "The Song of Fa Mu Lan". Ultimately, Disney decided to combine the two separate projects.
Following the opening of the Feature Animation Florida studios, Barry Cook, who had served as a special-effects animator department since 1982, had previously directed the Roger Rabbit cartoon "Trail Mix-Up" produced at the satellite studio. Upon a lunch invitation with Thomas Schumacher, Cook was offered two projects in development: a Scottish folk tale with a dragon or "Mulan". Knowledgeable about the existence of dragons in Chinese mythology, Cook suggested adding a dragon to "Mulan", in which a week later, Schumacher urged Cook to drop the Scottish project and accept "Mulan" as his next project. Following this, Cook was immediately assigned as the initial director of the project, and cited influences from Charlie Chaplin and David Lean during production. While working as a supervising animator on the gargoyles on "The Hunchback of Notre Dame", Tony Bancroft was offered to co-direct the film following a recommendation from Rob Minkoff, co-director of "The Lion King", to Schumacher, in which he accepted, and joined the creative team by early 1995.
Development for "Mulan" began in 1994, after the production team sent a select group of artistic supervisors to China for three weeks to take photographs and drawings of local landmarks for inspiration; and to soak up local culture. Key members of the creative team at the time – Pam Coats, Barry Cook, Ric Sluiter, Robert Walker, and Mark Henn – were invited to travel to China as a research trip to study the landscape, people, and history of the original legend. From June 17 to July 2, 1994, the research trip flew to Beijing, China, which is where Pam Coats became inspired by the placement of flags on the Great Wall, Datong, Luoyang, Xi'an, Jiayuguan, Dunhuang, and Guilin.
Writing.
In its earliest stages, the story was originally conceived as a "Tootsie"-like romantic comedy film where Mulan, who was a misfit tomboy that loves her father, is betrothed to Shang whom she has not met. On her betrothal day, her father Fa Zhou carves her destiny on a stone tablet in the family temple, in which she shatters in anger, and runs away to forge her own destiny. In November 1993, Chris Sanders, who had just finished storyboard work on "The Lion King", was hopeful to work on "The Hunchback of Notre Dame" until Schumacher appointed him to work on "Mulan" instead. Acting as Head of Story, Sanders grew frustrated with the romantic comedy aspect of the story, and urged producer Pam Coats to be more faithful to the original legend by having Mulan leave home because of the love for her father. This convinced the filmmakers to decide to change Mulan's character in order to make her more appealing and selfless. Sequence Six – in which Mulan takes her father's conscription order, cuts her long hair, and dons her father's armor – served as a pivotal moment in the evolution of Mulan's character. Director Barry Cook explained that the sequence initially started as a song storyboarded by Barry Johnson and redrawn by character designer Chen-Yi Chang. Following the story changes to have Mulan leave to save her father, the song was dropped. Storyboard artist and co-head of story Dean DeBlois was tasked to revise the sequence, and decided to board the sequence with "minimal dialogue". Assisted with an existing musical selection from another film score courtesy of Sanders, the sequence reel was screened for Peter Schneider and Thomas Schumacher, both of whom were impressed. DeBlois stated, "Sequence Six was the first sequence that got put into production, and it helped to establish our 'silent' approach." Additionally, General Li was not originally going to be related to Shang at all, but by changing the story, the filmmakers were able to mirror the stories of Shang and Mulan's love for their fathers.
Because there was no dragon in the original legend, Mulan did not have animal companions; it was Roy E. Disney who suggested the character of Mushu. Veteran story artist Joe Grant created the cricket character, Cri-Kee for, though animator Barry Temple admitted "the directors didn't want him in the movie, the story department didn't want him in the movie. The only people who truly wanted him in the movie were Michael Eisner and Joe Grant – and myself, because I was assigned the character. I would sit in meetings and they’d say, 'Well, where's the cricket during all this?' Somebody else would say, 'Oh, to hell the cricket.' They felt Cri-Kee was a character who wasn't necessary to tell the story, which is true." Throughout development on the film, Grant would slip sketches of Cri-Kee under the directors' door.
Casting.
Before production began, the production team sought out Chinese, Japanese, Filipino, or Korean vocal talents. Tia Carrere was an early candidate to voice the title character, and Lea Salonga, who previously was the singing voice of Princess Jasmine in "Aladdin", was also originally cast as Mulan's speaking voice, but the directors did not find her attempt at a deeper speaking voice when Mulan impersonated Ping convincing, so Ming-Na Wen was brought in to speak the role. Salonga was later relegated to providing the singing voice. Wen herself landed the role after the filmmakers listened to her narration at the beginning of "The Joy Luck Club". Coats reflected on her decision, stating "When we heard Ming-Na doing that voice-over, we knew we had our Mulan. She has a very likable and lovely voice, and those are the qualities we were looking for." For the role of Mushu, Disney was aiming for top Hollywood talent in the vein of Robin Williams's performance as the Genie, and approached Eddie Murphy, who at first balked during recording in the Disney studios, and asked to record the voice in his basement at his Bubble Hill mansion in Englewood, New Jersey. For the speaking voice of Captain Li Shang, BD Wong was hired, although his singing voice, for the song "I'll Make a Man Out of You", was performed by Donny Osmond, who had originally auditioned as the speaking voice of the title character in "Hercules". Osmond's casting originated from a suggestion from the casting director, and throughout recording, Osmond studied Wong's dialogue tapes, and aimed to match his inflections and personality. Osmond commented that his sons decided that he had finally "made it" in show business when he was in a Disney film. Likewise for the role of Grandmother Fa, June Foray provided for the speaking voice, and Marni Nixon supplied the singing voice.
Animation and design.
To achieve a harmonious visual look, producer designer Hans Bacher and art director Ric Sluiter, along with Robert Walker and Head of Backgrounds Robert Stanton collaborated to establish a proper chronological location for the film in Chinese history. Since there was no general consensus on the time of Mulan's existence, they based on the visual design on the Ming and Ching dynasties. An important element of Bacher's design was to turn the art style closer to Chinese painting, with watercolor and simpler design - as opposed to the details of "The Lion King" and "The Hunchback of Notre Dame". Bacher further studied more than thirty-five film directors ranging from the silent era German Expressionism, British and American epics of the 1950s and 60s, and the spaghetti westerns for inspiration for composition, lighting, and staging that would establish settings that enhanced the characters, and additional inspiration was found in the earlier Disney animated films such as "Bambi", "Pinocchio", and "Dumbo" to establish a sense of staging.
In October 1997, the Walt Disney Company announced a major expansion of its Florida animation operations constructing a 200,000-square-foot, four-story animation building and the addition of 400 animators to the workforce.
To create 2,000 Hun soldiers during the Huns' attack sequence, the production team developed crowd simulation software called "Attila". This software allows thousands of unique characters to move autonomously. A variant of the program called "Dynasty" was used in the final battle sequence to create a crowd of 3,000 in the Forbidden City. Pixar's photorealistic open API RenderMan was used to render the crowd. Another software developed for this movie was "Faux Plane" which was used to add depth to flat two-dimensional painting. Although developed late in production progress, Faux Plane was used in five shots, including the dramatic sequence which features the Great Wall of China, and the final battle sequence when Mulan runs to the Forbidden City. During the scene in which the Chinese are bowing to Mulan, the crowd is a panoramic film of real people bowing. It was edited into the animated foreground of the scene.
Music.
In March 1994, Stephen Schwartz was attached to compose the lyrics and music for the songs for the film. Following the research trip to China in June 1994, Schwartz was contacted by former Disney studio chairman Jeffrey Katzenberg to compose songs for "The Prince of Egypt", which he agreed. Peter Schneider, the then-president of Walt Disney Feature Animation, threatened to have Schwartz's name removed from any publicity materials for "Pocahontas" and "The Hunchback of Notre Dame". Michael Eisner phoned Schwartz, and urged him to back out of his commitment to DreamWorks which he refused and left the project. After Schwartz's departure, his three songs, "Written in Stone", "Destiny", and "China Doll", were dropped amid story and character changes by 1995. Shortly after, Disney music executive Chris Montan heard Matthew Wilder's demo for a stage musical adaption of Anne Rice's "Cry to Heaven", and selected Wilder to replace Schwartz. David Zippel then joined to write the lyrics. The film featured five songs composed by Wilder and Zippel, with a sixth originally planned for Mushu, but dropped following Eddie Murphy's involvement with the character.
After Danny Elfman and Thomas Newman were considered to score the film, English composer Rachel Portman was selected as the film composer. However, Portman became pregnant during production, and decided to back out. Following Portman's departure, Randy Edelman—whose "Dragonheart" theme was used in the trailer—and Kitarō were considered, until Jerry Goldsmith became available and signed on after dropping out of a project. The film's soundtrack is credited for starting the career of pop singer Christina Aguilera, whose first song to be released in the U.S. was her rendition of "Reflection," the first single from the "Mulan" soundtrack. The song, and Aguilera's vocals, were so well received that it landed her a recording contract with RCA records. In 1999, she would go on to release her self-titled debut album, on which "Reflection" was also included. The pop version of "Reflection" has a Polish version ("Lustro" performed by Edyta Górniak) and 2 Spanish versions, for Spain (performed by Malú) and Latin America (performed by Lucero). Other international versions include a Brazilian Portuguese version by Sandy & Junior ("Imagem"), a Korean version performed by Lena Park, and a Mandarin version by Coco Lee.
The music featured during the haircut scene, often referred as the "Mulan Decision" score, is different in the soundtrack album. The soundtrack album uses an orchestrated score while the movie uses heavy synthesizer music. The synthesizer version is available on the limited edition CD. Salonga, who often sings movie music in her concerts, has done a Disney medley which climaxes with an expanded version of "Reflection" (not the same as those in Aguilera's version). Salonga also provided the singing voice for Mulan in the movie's sequel, "Mulan II".
Release.
Because of the disappointing box office performances of "The Hunchback of Notre Dame" and "Hercules", Disney restricted its marketing campaign for "Mulan" spending $30 million on promotional advertisements compared to more than $60 million for "Hercules" the year before. Instead of the lavish media event premieres of "Pocahontas" in Central Park and the electric light parade on Fifth Avenue for "Hercules", Disney opted to premiere the film at the Hollywood Bowl complete with Chinese lanterns and fortune cookies. Two days before the general release, McDonald's launched its promotional campaign by including one of eight toys free with the purchase of a Happy Meal. In collaboration with Disney, Hyperion Books published "The Art of Mulan" authored by Jeff Kurtti, which chronicled the production of the film. In addition with its publication, Hyperion Books also issued a collector's "folding, accordion book" of the ancient poem that inspired the film. On August 18, 1998, around 3,700 backpacks and 1,800 pieces of luggage were recalled back to their manufacture, Pyramid Accessories Inc., when it is discovered they contained lead-based paint.
Home video.
"Mulan" was first released on VHS on February 2, 1999 after part of the Walt Disney Masterpiece Collection. It was then re-released under the 1999 "Limited Issues" line and 2000 Walt Disney Gold Classic Collection. The film was released on a 2 disc "Special Edition" DVD on October 26, 2004. "Mulan" and its sequel were released on a 3 disc Blu-Ray and DVD combo pack in March 2013 as part of the film's 15th anniversary.
Reception.
Critical reaction.
Reception of "Mulan" was mostly positive. Rotten Tomatoes gives it a rating of 86%, based on 73 reviews, with an average rating of 7.5/10. The site's consensus reads, "Exploring themes of family duty and honor, "Mulan" breaks new ground as a Disney film, while still bringing vibrant animation and sprightly characters to the screen." In a 2009 countdown, Rotten Tomatoes ranked it twenty-fourth out of the fifty canonical animated Disney features. On Metacritic, the film has a score of 71 out of 100, based on 24 critics, indicating "generally favorable reviews". CinemaScore reported that audiences gave the film a rare "A+" grade.
Kyle Suggs described the visuals as "breathtaking," and Dan Jardine described them as "magnificently animated." Film critic Roger Ebert gave "Mulan" three and a half stars out of four in his written review. He said that "Mulan is an impressive achievement, with a story and treatment ranking with "Beauty and the Beast" and "The Lion King"". Negative reviews described it as a "disappointment." The songs were accused of not being memorable, and slowing down the pace of the movie. Ed Gonzalez of "Slant Magazine" criticized the film as "soulless" in its portrayal of Asian society.
This movie was also the subject of comment from feminist critics. Mimi Nguyen says the film "pokes fun at the ultimately repressive gender roles that seek to make Mulan a domesticated creature." Nadya Labi agreed, saying "there is a lyric in the film that gives the lie to the bravado of the entire girl-power movement." She pointed out that Mulan needed to become a boy in order to accomplish what she did. Kathleen Karlyn, an assistant professor of English at the University of Oregon, also criticized the film's portrayal of gender roles: "In order to even imagine female heroism, we're placing it in the realm of fantasy". Pam Coats, the producer of Mulan, said that the film aims to present a character who exhibits both masculine and feminine influences, being both physically and mentally strong.
Box office.
"Mulan"'s opening weekend box office gross revenues were $22.8 million, making it the second-highest grossing movie that week, behind only "The X-Files". It went on to gross $120 million in the U.S. and Canada combined, and $304 million worldwide, making it the second-highest grossing family film of the year, behind "A Bug's Life", and the seventh-highest grossing film of the year overall. While "Mulan" outgrossed the two Disney films which had preceded it, "The Hunchback of Notre Dame" and "Hercules", its box office returns failed to match those of the Disney films of the early 1990s such as "Beauty and the Beast", "Aladdin", and "The Lion King". Internationally, its highest grossing releases included those in the United Kingdom ($14.6 million) and France ($10.2 million).
Awards.
"Mulan" won several Annie Awards, including Best Animated Feature and Individual achievement awards to Pam Coats for producing; Barry Cook and Tony Bancroft for directing; Rita Hsiao, Christopher Sanders, Phillip LaZebnick, Raymond Singer and Eugenia Bostwick-Singer for writing, Chris Sanders for storyboarding, Hans Bacher for production design, David Tidgwell for effects animation, Ming-Na for voice acting for the character of Mulan, Ruben A. Aquino for character animation, and Matthew Wilder, David Zippel and Jerry Goldsmith for music. (Tom Bancroft and Mark Henn were also nominated for an Annie Award for Character Animation.) The musical score also received significant praise. Jerry Goldsmith won the 1999 BMI Film Music Award. Goldsmith was nominated for the Academy Award for Best Original Music Score, but lost to Stephen Warbeck's score for "Shakespeare in Love". Goldsmith was nominated for the Golden Globe Award for Best Original Score. Matthew Wilder and David Zippel were nominated for a Golden Globe Award for Best Original Song for "Reflection". They were beaten by "The Truman Show" and "The Prayer" from "Quest for Camelot", respectively.
Reception in China.
Disney was keen to promote "Mulan" to the Chinese, hoping to replicate their success with the 1994 film "The Lion King", which was one of the country's highest-grossing Western films at that time. Disney also hoped it might smooth over relations with the Chinese government which had soured after the release of "Kundun", a Disney-funded biography of the Dalai Lama that the Chinese government considered politically provocative. China had threatened to curtail business negotiations with Disney over that film and, as the government only accepts ten Western films per year to be shown in their country, "Mulan"'s chances of being accepted were low. Finally, after a year's delay, the Chinese government did allow the film a limited Chinese release, but only after the Chinese New Year, so as to ensure that local films dominated the more lucrative holiday market. Box office income was low, due to both the unfavorable release date and rampant piracy. Chinese people also complained about Mulan's depiction as too foreign-looking and the story as too different from the myths.
Legacy.
Video game.
A PlayStation action-adventure game based on the film, titled "Disney's Story Studio: Mulan", published by Ubisoft and developed by Revolution Software (under the name "Kids Revolution"), was released on December 15, 1999. The game was met with generally positive reception and currently holds a 70.67% average rating at the review aggregator website GameRankings.
Live action adaptation.
Disney expressed interest in a live action and 3D adaptation of "Mulan" starring international star Zhang Ziyi. Chuck Russell was chosen as the director. The film was originally planned to start filming on October 2010, but was canceled. On March 30, 2015, "The Hollywood Reporter" reported that Disney was developing a live-action remake with Chris Bender and J.C. Spink producing while Elizabeth Martin and Lauren Hynek will write the screenplay.
References in Disney media.
Although she is royalty neither by birth nor marriage (her husband is merely a high-ranking military officer), "Mulan" is part of the Disney Princess media franchise. In the film "Lilo & Stitch", Nani has a poster of Mulan in her room. "Mulan" is also present in the Disney and Square Enix video game series "Kingdom Hearts". In the first "Kingdom Hearts" and in "", Mushu is a summonable character, and in "Kingdom Hearts II", the movie is featured as a playable world named "The Land of Dragons", with the plot being changed to accommodate the game's characters (Sora, Donald and Goofy) and Mulan (both as herself and as "Ping") able to join the player's party as a skilled sword fighter. Actress Jamie Chung plays a live-action version of Mulan in the second, third, and fifth seasons of the ABC television series "Once Upon a Time".

</doc>
<doc id="55721" url="https://en.wikipedia.org/wiki?curid=55721" title="King Lear">
King Lear

King Lear is a tragedy written by William Shakespeare. It depicts the gradual descent into madness of the title character, after he disposes of his kingdom giving bequests to two of his three daughters based on their flattery of him, bringing tragic consequences for all. Derived from the legend of Leir of Britain, a mythological pre-Roman Celtic king, the play has been widely adapted for the stage and motion pictures, with the title role coveted by many of the world's most accomplished actors.
Originally drafted in 1605 or 1606, with its first known performance on St. Stephen's Day in 1606, the first attribution to Shakespeare was a 1608 publication in a quarto of uncertain provenance; it may be an early draft or simply reflect the first performance text. "The Tragedy of King Lear", a more theatrical revision, was included in the 1623 First Folio. Modern editors usually conflate the two, though some insist that each version has its own individual integrity that should be preserved.
After the English Restoration, the play was often revised with a happy, non-tragic ending for audiences who disliked its dark and depressing tone, but since the 19th century Shakespeare's original version has been regarded as one of his supreme achievements. The tragedy is particularly noted for its probing observations on the nature of human suffering and kinship.
Synopsis.
King Lear of Britain, elderly and wanting to retire from the duties of the monarchy, decides to divide his realm among his three daughters, and declares he'll offer the largest share to the one who loves him most. The eldest, Goneril, speaks first, declaring her love for her father in fulsome terms. Moved by her flattery Lear proceeds to grant to Goneril her share as soon as she's finished her declaration, before Regan and Cordelia have a chance to speak. He then awards to Regan her share as soon as she has spoken. When it is finally the turn of his youngest daughter, Cordelia, at first she refuses to say anything ("Nothing, my Lord") and then declares there is nothing to compare her love to, nor words to properly express it; she speaks honestly but bluntly, which infuriates him. In his anger he disinherits Cordelia and divides her share between Regan and Goneril.
The Earl of Gloucester and the Earl of Kent observe that, by dividing his realm between Goneril and Regan, Lear has awarded his realm in equal shares to the peerages of the Duke of Albany (Goneril's husband) and the Duke of Cornwall (Regan's husband). Kent objects to Lear's unfair treatment of Cordelia; enraged by Kent's protests, Lear banishes him from the country. Lear then summons the Duke of Burgundy and the King of France, who have both proposed marriage to Cordelia. Learning that Cordelia has been disinherited, the Duke of Burgundy withdraws his suit, but the King of France is impressed by her honesty and marries her nonetheless. Meanwhile, Gloucester has introduced his illegitimate son Edmund to Kent.
Lear announces he will live alternately with Goneril and Regan, and their husbands. He reserves to himself a retinue of one hundred knights, to be supported by his daughters. Goneril and Regan speak privately, revealing that their declarations of love were fake, and that they view Lear as a foolish, old man.
Edmund resents his illegitimate status, and plots to dispose of his legitimate older brother Edgar. He tricks their father Gloucester with a forged letter, making him think Edgar plans to usurp the estate. Kent returns from exile in disguise under the name of Caius, and Lear hires him as a servant. Lear and Caius quarrel with Oswald, Goneril's steward. Lear discovers that now that Goneril has power, she no longer respects him. She orders him to behave better and reduces his retinue. Enraged, Lear departs for Regan's home. The Fool mocks Lear's misfortune.
Edmund learns from Curan, a courtier, that there is likely to be war between Albany and Cornwall, and that Regan and Cornwall are to arrive at Gloucester's house that evening. Taking advantage of the arrival of the duke and Regan, Edmund fakes an attack by Edgar, and Gloucester is completely taken in. He disinherits Edgar and proclaims him an outlaw.
Bearing Lear's message to Regan, Caius meets Oswald again at Gloucester's home, quarrels with him again, and is put in the stocks by Regan and her husband Cornwall. When Lear arrives, he objects to the mistreatment of his messenger, but Regan is as dismissive of her father as Goneril was. Lear is enraged but impotent. Goneril arrives and supports Regan's argument against him. Lear yields completely to his rage. He rushes out into a storm to rant against his ungrateful daughters, accompanied by the mocking Fool. Kent later follows to protect him. Gloucester protests against Lear's mistreatment. With Lear's retinue of a hundred knights dissolved, the only companions he has left are his Fool and Caius. Wandering on the heath after the storm, Edgar, in the guise of a madman named Tom o' Bedlam, meets Lear. Edgar babbles madly while Lear denounces his daughters. Kent leads them all to shelter.
Edmund betrays Gloucester to Cornwall, Regan and Goneril. He reveals evidence that his father knows of an impending French invasion designed to reinstate Lear to the throne; and in fact a French army has landed in Britain. Once Edmund leaves with Goneril to warn Albany about the invasion, Gloucester is arrested, and Regan and Cornwall gouge out Gloucester's eyes. As he is doing so, a servant is overcome with rage by what he is witnessing and attacks Cornwall, mortally wounding him. Regan kills the servant, and tells Gloucester that Edmund betrayed him; then she turns him out to wander the heath too. Edgar, in his madman's guise, meets his blinded father on the heath. Gloucester, not recognising him, begs Tom to lead him to a cliff at Dover so that he may jump to his death.
Goneril discovers that she finds Edmund more attractive than her honest husband Albany, whom she regards as cowardly. Albany has developed a conscience — he is disgusted by the sisters' treatment of Lear, and the mutilation of Gloucester, and denounces his wife. Goneril sends Edmund back to Regan; receiving news of Cornwall's death, she fears her newly widowed sister may steal Edmund and sends him a letter through Oswald. By now alone with Lear, Kent leads him to the French army, which is commanded by Cordelia. But Lear is half-mad and terribly embarrassed by his earlier follies. At Regan's instigation, Albany joins his forces with hers against the French. Goneril's suspicions about Regan's motives are confirmed and returned, as Regan rightly guesses the meaning of her letter and declares to Oswald that she is a more appropriate match for Edmund. Edgar pretends to lead Gloucester to a cliff, then changes his voice and tells Gloucester he has miraculously survived a great fall. Lear appears, by now completely mad. He rants that the whole world is corrupt and runs off.
Oswald appears, still looking for Edmund. On Regan's orders, he tries to kill Gloucester but is killed by Edgar. In Oswald's pocket, Edgar finds Goneril's letter, in which she encourages Edmund to kill her husband and take her as his wife. Kent and Cordelia take charge of Lear, whose madness quickly passes. Regan, Goneril, Albany, and Edmund meet with their forces. Albany insists that they fight the French invaders but not harm Lear or Cordelia. The two sisters lust for Edmund, who has made promises to both. He considers the dilemma and plots the deaths of Albany, Lear, and Cordelia. Edgar gives Goneril's letter to Albany. The armies meet in battle, the British defeat the French, and Lear and Cordelia are captured. Edmund sends Lear and Cordelia off with secret-joint orders from him (representing Regan and her forces) and Goneril (representing Albany's) for the execution of Cordelia.
The victorious British leaders meet, and the recently widowed Regan now declares she will marry Edmund. But Albany exposes the intrigues of Edmund and Goneril and proclaims Edmund a traitor. Regan falls ill, having been poisoned by Goneril, and is escorted offstage, where she dies. Edmund defies Albany, who calls for a trial by combat. Edgar appears masked and in armour, and challenges Edmund to a duel. No one knows who he is. Edgar wounds Edmund fatally, though he does not die immediately. Albany confronts Goneril with the letter which was intended to be his death warrant; she flees in shame and rage. Edgar reveals himself, and reports that Gloucester died offstage from the shock and joy of learning that Edgar is alive, after Edgar revealed himself to his father.
Offstage, Goneril, with all her evil plans thwarted, commits suicide. The dying Edmund decides, though he admits it is against his own character, to try to save Lear and Cordelia; however, his confession comes too late. Soon after Albany sends men to countermand Edmund's orders, Lear enters bearing Cordelia's corpse in his arms, having survived by killing the executioner. Kent appears and Lear now recognises him. Albany urges Lear to resume his throne, but like Gloucester, the trials Lear has been through have finally overwhelmed him, and he dies. Albany then asks Kent and Edgar to take charge of the throne. Kent declines, explaining that his master is calling him on a journey. Finally, Albany (in the Quarto version) or Edgar (in the Folio version) implies that he will now become king.
Sources.
Shakespeare's play is based on various accounts of the semi-legendary Brythonic figure Leir of Britain, whose name has been linked by some scholars to the Brythonic god Lir/Llŷr, though in actuality the names are not etymologically related. Shakespeare's most important source is probably the second edition of "The Chronicles of England, Scotlande, and Irelande" by Raphael Holinshed, published in 1587. Holinshed himself found the story in the earlier "Historia Regum Britanniae" by Geoffrey of Monmouth, that was written in the 12th century. Edmund Spenser's "The Faerie Queene", published 1590, also contains a character named Cordelia, who also dies from hanging, as in "King Lear".
Other possible sources are the anonymous play "King Leir" (published in 1605); "The Mirror for Magistrates" (1574), by John Higgins; "The Malcontent" (1604), by John Marston; "The London Prodigal" (1605); Montaigne's "Essays", which were translated into English by John Florio in 1603; "An Historical Description of Iland of Britaine" (1577), by William Harrison; "Remaines Concerning Britaine" (1606), by William Camden; "Albion's England" (1589), by William Warner; and "A Declaration of egregious Popish Impostures" (1603), by Samuel Harsnett, which provided some of the language used by Edgar while he feigns madness. "King Lear" is also a literary variant of a common fairy tale, Love Like Salt, Aarne-Thompson type 923, in which a father rejects his youngest daughter for a statement of her love that does not please him.
The source of the subplot involving Gloucester, Edgar, and Edmund is a tale in Philip Sidney's "Countess of Pembroke's Arcadia" (1580–90), with a blind Paphlagonian king and his two sons, Leonatus and Plexitrus.
Changes from source material.
Besides the subplot involving the Earl of Gloucester and his sons, the principal innovation Shakespeare made to this story was the death of Cordelia and Lear at the end; in the account by Geoffrey of Monmouth, Cordelia restores Lear to the throne, and succeeds him as ruler after his death. During the 17th century, Shakespeare's tragic ending was much criticised and alternative versions were written by Nahum Tate, in which the leading characters survived and Edgar and Cordelia were married (despite the fact that Cordelia was previously betrothed to the King of France). As Harold Bloom states: "Tate's version held the stage for almost 150 years, until Edmund Kean reinstated the play's tragic ending in 1823."
Date and text.
Although an exact date of composition cannot be given, many academic editors of the play date "King Lear" between 1603 and 1606. The latest it could have been written is 1606, as the Stationers' Register notes a performance on 26 December 1606. The 1603 date originates from words in Edgar's speeches which may derive from Samuel Harsnett's "Declaration of Egregious Popish Impostures" (1603). In his Arden edition, R.A. Foakes argues for a date of 1605–6, because one of Shakespeare's sources, "The True Chronicle History of King Leir", was not published until 1605; close correspondences between that play and Shakespeare's suggest that he may have been working from a text (rather than from recollections of a performance). Conversely, Frank Kermode, in the "Riverside Shakespeare", considers the publication of "Leir" to have been a response to performances of Shakespeare's already-written play; noting a sonnet by William Strachey that may have verbal resemblances with "Lear", Kermode concludes that "1604-5 seems the best compromise". Dr. Naseeb Shaheen dates the play c1605-6 per line 1.2.103
"These late eclipses in the sun and moon" which relates to the lunar eclipse of 27 September 1605 and the solar eclipse of 2 October 1605.
As early as 1931, Madeleine Doran suggested that the two texts had basically different provenances, and that these differences between them were critically interesting. This argument, however, was not widely discussed until the late 1970s, when it was revived, principally by Michael Warren and Gary Taylor. Their thesis, while controversial, has gained significant acceptance. It posits, essentially, that the Quarto derives from something close to Shakespeare's foul papers, and the Folio is drawn in some way from a promptbook, prepared for production by Shakespeare's company or someone else. In short, Q1 is "authorial"; F1 is "theatrical". In criticism, the rise of "revision criticism" has been part of the pronounced trend away from mid-century formalism.
The New Cambridge Shakespeare has published separate editions of Q and F; the most recent Pelican Shakespeare edition contains both the 1608 Quarto and the 1623 Folio text as well as a conflated version; the New Arden edition edited by R.A. Foakes is the only recent edition to offer the traditional conflated text. Both Anthony Nuttall of Oxford University and Harold Bloom of Yale University have endorsed the view of Shakespeare having revised the tragedy at least once during his lifetime. As Bloom indicates: "At the close of Shakespeare's revised "King Lear", a reluctant Edgar becomes King of Britain, accepting his destiny but in the accents of despair. Nuttall speculates that Edgar, like Shakespeare himself, usurps the power of manipulating the audience by deceiving poor Gloucester."
Analysis and criticism.
Analysis and criticism of "King Lear" over the centuries has been extensive. 
Historicist interpretations.
John F. Danby, in his "Shakespeare's Doctrine of Nature – A Study of King Lear" (1949), argues that "Lear" dramatizes, among other things, the current meanings of "Nature". The words "nature," "natural" and "unnatural" occur over forty times in the play, reflecting a debate in Shakespeare's time about what nature really was like; this debate pervades the play and finds symbolic expression in Lear's changing attitude to Thunder. There are two strongly contrasting views of human nature in the play: that of the Lear party (Lear, Gloucester, Albany, Kent), exemplifying the philosophy of Bacon and Hooker, and that of the Edmund party (Edmund, Cornwall, Goneril, Regan), akin to the views later formulated by Hobbes. Along with the two views of Nature, "Lear" contains two views of Reason, brought out in Gloucester and Edmund's speeches on astrology (1.2). The rationality of the Edmund party is one with which a modern audience more readily identifies. But the Edmund party carries bold rationalism to such extremes that it becomes madness: a madness-in-reason, the ironic counterpart of Lear's "reason in madness" (IV.6.190) and the Fool's wisdom-in-folly. This betrayal of reason lies behind the play's later emphasis on "feeling".
The two Natures and the two Reasons imply two societies. Edmund is the New Man, a member of an age of competition, suspicion, glory, in contrast with the older society which has come down from the Middle Ages, with its belief in co-operation, reasonable decency, and respect for the whole as greater than the part. "King Lear" is thus an allegory. The older society, that of the medieval vision, with its doting king, falls into error, and is threatened by the new Machiavellianism; it is regenerated and saved by a vision of a new order, embodied in the king's rejected daughter. Cordelia, in the allegorical scheme, is threefold: a person; an ethical principle (love); and a community. Nevertheless, Shakespeare's understanding of the New Man is so extensive as to amount almost to sympathy. Edmund is the last great expression in Shakespeare of that side of Renaissance individualism – the energy, the emancipation, the courage – which has made a positive contribution to the heritage of the West. "He embodies something vital which a final synthesis must reaffirm. But he makes an absolute claim which Shakespeare will not support. It is right for man to feel, as Edmund does, that society exists for man, not man for society. It is not right to assert the kind of man Edmund would erect to this supremacy."
The play offers an alternative to the feudal-Machiavellian polarity, an alternative foreshadowed in France's speech (I.1.245–256), in Lear and Gloucester's prayers (III.4. 28–36; IV.1.61–66), and in the figure of Cordelia. Until the decent society is achieved, we are meant to take as role-model (though qualified by Shakespearean ironies) Edgar, "the machiavel of goodness", endurance, courage and "ripeness".
Psychoanalytic and psychosocial interpretations.
Since there are no literal mothers in "King Lear", Coppélia Kahn provides a psychoanalytic interpretation of the "maternal subtext" found in the play. According to Kahn, Lear in his old age regresses to an infantile disposition, and now seeks for a love that is normally satisfied by a mothering woman. Her characterisation of Lear is that of a child being mothered, but without real mothers, his children become the daughter-mother figures. Lear's contest of love serves as the binding agreement; his daughters will get their inheritance provided they care for him, especially Cordelia, on whose "kind nursery" he will greatly depend. Her refusal to love him as more than a father is often interpreted as a resistance from incest, but Kahn also inserts the image of a rejecting mother. The situation is now a reversal of parent-child roles, in which Lear's madness is essentially a childlike rage from being deprived of maternal care. Even when Lear and Cordelia are captured together, this madness persists as Lear envisions a nursery in prison, where Cordelia's sole existence is for him. However, it is Cordelia's death that ultimately ends his fantasy of a daughter-mother, as the play ends with only male characters left.
Sigmund Freud asserted that Cordelia symbolises Death. Therefore, when the play begins with Lear rejecting his daughter, it can be interpreted as him rejecting death; Lear is unwilling to face the finitude of his being. The play's poignant ending scene, wherein Lear carries the body of his beloved Cordelia, was of great importance to Freud. In this scene, she causes in Lear a realisation of his finitude, or as Freud put it, she causes him to "make friends with the necessity of dying". It is logical to infer that Shakespeare had special intentions with Cordelia's death, as he was the only writer to have Cordelia killed (in the version by the Nahum Tate, she continues to live happily, and in Holinshed's, she restores her father and succeeds him).
Alternatively, an analysis based on Adlerian theory suggests that the King's contest among his daughters in Act one has more to do with his control over the unmarried Cordelia.
In his study of the character-portrayal of Edmund, Harold Bloom refers to him as "Shakespeare's most original character". "As Hazlitt pointed out," writes Bloom, "Edmund does not share in the hypocrisy of Goneril and Regan: his Machiavellianism is absolutely pure, and lacks an Oedipal motive. Freud's vision of family romances simply does not apply to Edmund. Iago is free to reinvent himself every minute, yet Iago has strong passions, however negative. Edmund has no passions whatsoever; he has never loved anyone, and he never will. In that respect, he is Shakespeare's most original character."
The tragedy of Lear's lack of understanding of the consequences of his demands and actions is often observed to be like that of a spoiled child, but it has also been noted that his behaviour is equally likely to be seen in parents who have never adjusted to their children having grown up.
Christianity.
Critics are divided on the question of whether or not "King Lear" represents an affirmation of Christian doctrine. Among those who argue that Lear is redeemed in the Christian sense through suffering are A. C. Bradley and John Reibetanz, who has written: "through his sufferings, Lear has won an enlightened soul". Other critics who find no evidence of redemption and emphasise the horrors of the final act include John Holloway and Marvin Rosenberg. William R. Elton stresses the pre-Christian setting of the play, writing that, "Lear fulfills the criteria for pagan behavior in life," falling "into total blasphemy at the moment of his irredeemable loss".
Fairy tales.
In the first edition of "Kinder- und Hausmärchen" by the Brothers Grimm, the Anhang (appendix) entry to No. 71 Princess Mouse-skin included a note: "as the father here, so asks King Lear his daughter". The English translation of this story by Oliver Loo begins as follows: "A king had three daughters; thereon he wanted to know, which loved him most, let them come in front of him and asked them. The eldest spoke, she loved him more, than the whole kingdom; the second, more than all the precious stones and pearls in the world; but the third said, she loved him more than salt. The king was so upset, that she compared her love of him with such a small thing, gave her to a servant and commanded, he should take her into the forest and kill her."
Rex Warner.
Rex Warner's book ""Men of Stones; A melodrama"" (1949), written in the aftermath of the Greek Civil War, depicts imprisoned Greek leftists presenting "King Lear" in their prison camp, and has various allusions and comparisons between the protagonists' situation and the play's plot and characters.
Performance history.
"King Lear" has been performed by esteemed actors since the 17th Century when men played all the roles. From the 20th Century, a number of women have played male roles in the play; most commonly the Fool, who has been played (among others) by Judy Davis, Emma Thompson and Robyn Nevin. Lear himself has been played by Marianne Hoppe in 1990 and by Kathryn Hunter in 1996-7. Marcia Gay Harden plays Lear in the few scenes of the play-within-the-film If I Were You.
17th century.
Shakespeare wrote the role of Lear for his company's chief tragedian, Richard Burbage, for whom Shakespeare was writing incrementally older characters as their careers progressed. It has been speculated either that the role of the Fool was written for the company's clown Robert Armin, or that it was written for performance by one of the company's boys, doubling the role of Cordelia. Only one specific performance of the play during Shakespeare's lifetime is known: before the court of King James I at Whitehall on 26 December 1606. Its original performances would have been at The Globe, where there were no sets in the modern sense, and characters would have signified their roles visually with props and costumes: Lear's costume, for example, would have changed in the course of the play as his status diminished: commencing in crown and regalia; then as a huntsman; raging bareheaded in the storm scene; and finally crowned with flowers in parody of his original status.
All theatres were closed down by the Puritan government on 6 September 1642. Upon the restoration of the monarchy in 1660, two patent companies (the King's Company and the Duke's Company) were established, and the existing theatrical repertoire divided between them. And from the restoration until the mid-19th century the performance history of "King Lear" is not the story of Shakespeare's version, but instead of "The History of King Lear", a popular adaptation by Nahum Tate. Its most significant deviations from Shakespeare were to omit the Fool entirely, to introduce a happy ending in which Lear and Cordelia survive, and to develop a love story between Cordelia and Edgar (two characters who never interact in Shakespeare) which ends with their marriage. Like most Restoration adapters of Shakespeare, Tate admired Shakespeare's natural genius but saw fit to augment his work with contemporary standards of art (which were largely guided by the neoclassical unities of time, place, and action). Tate's struggle to strike a balance between raw nature and refined art is apparent in his description of the tragedy: "a heap of jewels, unstrung and unpolish't; yet so dazzling in their disorder, that I soon perceiv'd I had seiz'd a treasure." Other changes included giving Cordelia a "confidante" named Arante, bringing the play closer to contemporary notions of poetic justice, and added titilating material such as amorous encounters between Edmund and both Regan and Goneril, a scene in which Edgar rescues Cordelia from Edmund's attempted kidnap and rape, and a scene in which Cordelia wears men's pants that would reveal the actress's ankles. The play ends with a celebration of "the King's blest Restauration", an obvious reference to Charles II.
18th century.
In the early 18th century, some writers began to express objections to this (and other) Restoration adaptations of Shakespeare. For example, in "The Spectator" on 16 April 1711 Joseph Addison wrote ""King Lear" is an admirable Tragedy ... as "Shakespeare" wrote it; but as it is reformed according to the chymerical Notion of poetical Justice in my humble Opinion it hath lost half its Beauty." Yet on the stage, Tate's version prevailed.
David Garrick was the first actor-manager to begin to cut back on elements of Tate's adaptation in favour of Shakespeare's original: he retained Tate's major changes, including the happy ending, but removed many of Tate's lines, including Edgar's closing speech. He also reduced the prominence of the Edgar-Cordelia love story, in order to focus more on the relationship between Lear and his daughters. His version had a powerful emotional impact: Lear driven to madness by his daughters was (in the words of one spectator, Arthur Murphy) "the finest tragic distress ever seen on any stage" and, in contrast, the devotion shown to Lear by Cordelia (a mix of Shakespeare's, Tate's and Garrick's contributions to the part) moved the audience to tears.
The first professional performances of "King Lear" in North America are likely to have been those of the Hallam Company (later the American Company) which arrived in Virginia in 1752 and who counted the play among their repertoire by the time of their departure for Jamaica in 1774.
19th century.
Charles Lamb established the Romantics' attitude to "King Lear" in his 1811 essay "On the Tragedies of Shakespeare, considered with reference to their fitness for stage representation" where he says that the play "is essentially impossible to be represented on the stage", preferring to experience it in the study. In the theatre, he argues, "to see Lear acted, to see an old man tottering about the stage with a walking-stick, turned out of doors by his daughters on a rainy night, has nothing in it but what is painful and disgusting" yet "while we read it, we see not Lear but we are Lear, – we are in his mind, we are sustained by a grandeur which baffles the malice of daughters and storms."
"King Lear" was politically controversial during the period of George III's madness, and as a result was not performed at all in the two professional theatres of London from 1811 to 1820: but was then the subject of major productions in both, within three months of his death. The 19th century saw the gradual reintroduction of Shakespeare's text to displace Tate's version. Like Garrick before him, John Philip Kemble had introduced more of Shakespeare's text, while still preserving the three main elements of Tate's version: the love story, the omission of the Fool, and the happy ending. Edmund Kean played "King Lear" with its tragic ending in 1823, but failed and reverted to Tate's crowd-pleaser after only three performances. At last in 1838 William Macready at Covent Garden performed Shakespeare's version, freed from Tate's adaptions. The restored character of the Fool was played by an actress, Priscilla Horton, as, in the words of one spectator, "a fragile, hectic, beautiful-faced, half-idiot-looking boy." And Helen Faucit's final appearance as Cordelia, dead in her father's arms, became one of the most iconic of Victorian images. John Forster, writing in the "Examiner" on 14 February 1838, expressed the hope that "Mr Macready's success has banished that disgrace version from the stage for ever." But even this version was not close to Shakespeare's: the 19th-century actor-managers heavily cut Shakespeare's scripts: ending scenes on big "curtain effects" and reducing or eliminating supporting roles to give greater prominence to the star. One of Macready's innovations – the use of Stonehenge-like structures on stage to indicate an ancient setting – proved enduring on stage into the 20th century, and can be seen in the 1983 television version starring Laurence Olivier.
In 1843, the Act for Regulating the Theatres came into force, bringing an end to the monopolies of the two existing companies and, by doing so, increased the number of theatres in London. At the same time, the fashion in theatre was "pictorial": valuing visual spectacle above plot or characterisation and often required lengthy (and time consuming) scene changes. For example, Henry Irving's 1892 "King Lear" offered spectacles such as Lear's death beneath a cliff at Dover, his face lit by the red glow of a setting sun; at the expense of cutting 46% of the text, including the blinding of Gloucester. But Irving's production clearly evoked strong emotions: one spectator, Gordon Crosse, wrote of the first entrance of Lear, "a striking figure with masses of white hair. He is leaning on a huge scabbarded sword which he raises with a wild cry in answer to the shouted greeting of his guards. His gait, his looks, his gestures, all reveal the noble, imperious mind already degenerating into senile irritability under the coming shocks of grief and age."
The importance of pictorialism to Irving, and to other theatre professionals of the Victorian era, is exemplified by the fact that Irving had used Ford Madox Brown's painting "Cordelia's Portion" as the inspiration for the look of his production, and that the artist himself was brought in to provide sketches for the settings of other scenes. A reaction against pictorialism came with the rise of reconstructive movement, believers in a simple style of staging more similar to that which would have pertained in renaissance theatres, whose chief early exponent was the actor-manager William Poel. Poel was influenced by a performance of "King Lear" directed by Jocza Savits at the Hoftheater in Munich in 1890, set on an apron stage with a three-tier Globe-like reconstruction theatre as its backdrop. Poel would use this same configuration for his own Shakespearean performances in 1893.
20th century.
By mid-century, the actor-manager tradition had declined, to be replaced by a structure where the major theatre companies employed professional directors as auteurs. The last of the great actor-managers, Donald Wolfit, played Lear in 1944 on a Stonehenge-like set and was praised by James Agate as "the greatest piece of Shakespearean acting since I have been privileged to write for the "Sunday Times"". Wolfit supposedly drank eight bottles of Guinness in the course of each performance.
George Bernard Shaw wrote, "No man will ever write a better tragedy than "Lear"".
The character of Lear in the 19th century was often that of a frail old man from the opening scene, but Lears of the 20th century often began the play as strong men displaying regal authority, including John Gielgud, Donald Wolfit and Donald Sinden. Cordelia, also, evolved in the 20th century: earlier Cordelias had often been praised for being sweet, innocent and modest, but 20th-century Cordelias were often portrayed as war leaders. For example, Peggy Ashcroft, at the RST in 1950, played the role in a breastplate and carrying a sword. Similarly, the Fool evolved through the course of the century, with portrayals often deriving from the music hall or circus tradition.
At Stratford-upon-Avon in 1962, Peter Brook (who would later film the play with the same actor, Paul Scofield, in the role of Lear) set the action simply, against a huge, empty white stage. The effect of the scene when Lear and Gloucester meet, two tiny figures in rags in the midst of this emptiness, was said (by the scholar Roger Warren) to catch "both the human pathos ... and the universal scale ... of the scene." Some of the lines from the radio broadcast were used by The Beatles to add into the recorded mix of the song "I Am the Walrus". John Lennon happened upon the play on the BBC Third Programme while fiddling with the radio while working on the song. The voices of actors Mark Dignam, Philip Guard, and John Bryning from the play are all heard in the song.
Like other Shakespearean tragedies, "King Lear" has proved amenable to conversion into other theatrical traditions. In 1989, David McRuvie and Iyyamkode Sreedharan adapted the play then translated it to Malayalam, for performance in Kerala in the Kathakali tradition – which itself developed around 1600, contemporary with Shakespeare's writing. The show later went on tour, and in 2000 played at Shakespeare's Globe, completing (in Anthony Dawson's words) "a kind of symbolic circle". Perhaps even more radical was Ong Keng Sen's 1997 adaptation of "King Lear", which featured six actors each performing in a separate Asian acting tradition and in their own separate languages. A pivotal moment occurred when the Jingju performer playing Older Daughter (a conflation of Goneril and Regan) stabbed the Noh-performed Lear whose "falling pine" deadfall, straight face-forward into the stage, astonished the audience, in what Yong Li Lan describes as a "triumph through the moving power of "noh" performance at the very moment of his character's defeat".
In 1974, Buzz Goodbody directed "Lear", a deliberately abbreviated title for Shakespeare's text, as the inaugural production of the RSC's studio theatre The Other Place. The performance was conceived as a chamber piece, the small intimate space and proximity to the audience enabled detailed psychological acting, which was performed with simple sets and in modern dress. Peter Holland has speculated that this company/directoral decision – namely "choosing" to present Shakespeare in a small venue for artistic reasons when a larger venue was available – may at the time have been unprecedented.
Brook's earlier vision of the play proved influential, and directors have gone further in presenting Lear as (in the words of R. A. Foakes) "a pathetic senior citizen trapped in a violent and hostile environment". When John Wood took the role in 1990, he played the later scenes in clothes that looked like cast-offs, inviting deliberate parallels with the uncared-for in modern Western societies. Indeed, modern productions of Shakespeare's plays often reflect the world in which they are performed as much as the world for which they were written: and the Moscow theatre scene in 1994 provided an example, when two very different productions of the play (those by Sergei Zhonovach and Alexei Borodin), very different from one another in their style and outlook, were both reflections on the break-up of the Soviet Union.
21st century.
In 2002 and 2010, the Hudson Shakespeare Company of New Jersey staged separate productions as part of their respective Shakespeare in the Parks seasons. The 2002 version was directed by Michael Collins and transposed the action to a West Indies, nautical setting. Actors were featured in outfits indicative of looks of various Caribbean islands. The 2010 production directed by Jon Ciccarelli was fashioned after the atmosphere of the film The Dark Knight with a palette of reds and blacks and set the action in an urban setting. Lear (Tom Cox) appeared as a head of multi-national conglomerate who divided up his fortune among his socialite daughter Goneril (Brenda Scott), his officious middle daughter Regan (Noelle Fair) and university daughter Cordelia (Emily Best).
In 2012, Peter Hinton directed an all-First Nations production of "King Lear" at the National Arts Centre in Ottawa, Ontario, Canada, with the setting changed to an Algonquin nation in the 17th century. The cast included August Schellenberg as Lear, Billy Merasty as Gloucester, Tantoo Cardinal as Regan, Kevin Loring as Edmund, Jani Lauzon in a dual role as Cordelia and the Fool, and Craig Lauzon as Kent.
In 2015, Toronto's Theatre Passe Muraille staged a production set in Upper Canada, against the backdrop of the Upper Canada Rebellion of 1837. This production starred David Fox as Lear.
In the summer of 2015-2016, The Sydney Theatre Company staged "King Lear", directed by Neil Armfield with Geoffrey Rush in the lead role and Robyn Nevin as the Fool. About the madness at the heart of the play, Rush said that for him "it's about finding the dramatic impact in the moments of his mania. What seems to work best is finding a vulnerability or a point of empathy, where an audience can look at Lear and think how shocking it must be to be that old and to be banished from your family into the open air in a storm. That's a level of impoverishment you would never want to see in any other human being, ever."
Screen adaptations.
The play's plot, or major elements from it, have frequently been used by film makers.
The first film of "King Lear" was a five-minute German version made around 1905, which has not survived. The oldest extant version is a ten-minute studio-based version from 1909 by Vitagraph, which made (in Luke McKernan's words) the "ill-advised" decision to attempt to cram in as much of the plot as possible. Two silent versions, both titled "Re Lear", were made in Italy in 1910. Of these, the version by director Gerolamo Lo Savio was filmed on location, and it dropped the Edgar sub-plot and used frequent intertitling to make the plot easier to follow than its Vitagraph predecessor. A contemporary setting was used for Louis Feuillade's 1911 French adaptation "Le Roi Lear Au Village", and in 1914 in America, Ernest Warde expanded the story to an hour, including spectacles such as a final battle scene.
Joseph Mankiewicz' 1949 "House of Strangers" is often considered a "Lear" adaptation, but the parallels are more striking in its 1954 Western remake "Broken Lance" in which a cattle baron played by Spencer Tracy tyrannises over his three sons, of whom only the youngest, Joe, played by Robert Wagner, remains loyal.
The only two significant big-screen performances of Shakespeare's text date from the early 1970s: Grigori Kozintsev was working on his "Korol Lir" at the same time as Peter Brook was filming his "King Lear". Brook's film starkly divided the critics: Pauline Kael said "I didn't just dislike this production, I hated it!" and suggested the alternative title ""Night of the Living Dead"". Yet Robert Hatch in "The Nation" thought it as "excellent a filming of the play as one can expect" and Vincent Canby in The New York Times called it "an exalting "Lear", full of exquisite terror". The film drew heavily on the ideas of Jan Kott, in particular his observation that "King Lear" was the precursor of absurdist theatre: in particular, the film has parallels with Beckett's "Endgame". Critics who dislike the film particularly draw attention to its bleak nature from its opening: complaining that the world of the play does not deteriorate with Lear's suffering, but commences dark, colourless and wintry, leaving (in Douglas Brode's words) "Lear, the land, and "us" with nowhere to go". Cruelty pervades the film, which does not distinguish between the violence of ostensibly good and evil characters, presenting both savagely. Paul Scofield, as Lear, eschews sentimentality: this demanding old man with a coterie of unruly knights provokes audience sympathy for the daughters in the early scenes, and his presentation explicitly rejects the tradition (as Daniel Rosenthal describes it) of playing Lear as "poor old white-haired patriarch".
By contrast, "Korol Lir" has been praised, for example by critic Alexander Anikst for the "serious, deeply thoughtful" even "philosophical approach" of director Grigori Kozintsev and writer Boris Pasternak. Making a thinly veiled criticism of Brook in the process, Anikst praised the fact that there were "no attempts at sensationalism, no efforts to 'modernise' Shakespeare by introducing Freudian themes, Existentialist ideas, eroticism, or sexual perversion. ... has simply made a film of Shakespeare's tragedy." Dmitri Shostakovich provided an epic score, its motifs including an (increasingly ironic) trumpet fanfare for Lear, and a five-bar "Call to Death" marking each character's demise. Kozintzev described his vision of the film as an ensemble piece: with Lear, played by a dynamic Jüri Järvet, as first among equals in a cast of fully developed characters. The film highlights Lear's role as king by including his people throughout the film on a scale no stage production could emulate, charting the central character's decline from their god to their helpless equal; his final descent into madness marked by his realisation that he has neglected the 'poor naked wretches'. As the film progresses, ruthless characters – Goneril, Regan, Edmund – increasingly appear isolated in shots, in contrast to the director's focus, throughout the film, on masses of human beings.
Jonathan Miller twice directed Michael Hordern in the title role for English television, the first for the BBC's "Play of the Month" in 1975 and the second for the "BBC Television Shakespeare" in 1982. Horden received mixed reviews, and was considered a bold choice due to his history of taking much lighter roles. Also for English television, Laurence Olivier took the role in a 1983 TV production for Granada Television. It was his last screen appearance in a Shakespearean role, its pathos deriving in part from the physical frailty of Olivier the actor.
In 1985 a major screen adaptation of the play appeared: "Ran", directed by Akira Kurosawa. At the time the most expensive Japanese film ever made, it tells the story of Hidetora, a fictional 16th-century Japanese warlord, whose attempt to divide his kingdom among his three sons leads to an estrangement with the youngest, and ultimately most loyal, of them, and eventually to civil war. In contrast to the cold drab greys of Brook and Kozintsev, Kurosawa's film is full of vibrant colour: external scenes in yellows, blues and greens, interiors in browns and ambers, and Emi Wada's Oscar-winning colour-coded costumes for each family member's soldiers. Hidetora has a back-story: a violent and ruthless rise to power, and the film portrays contrasting victims: the virtuous characters Sue and Tsurumaru who are able to forgive, and the vengeful Kaede (Mieko Harada), Hidetora's daughter-in-law and the film's Lady Macbeth-like villain.
A scene in which a character is threatened with blinding in the manner of Gloucester forms the climax of the 1973 parody horror "Theatre of Blood". Comic use is made of Sir's inability to physically carry any actress cast as Cordelia opposite his Lear in the 1983 film of the stage play "The Dresser". John Boorman's 1990 "Where the Heart Is" features a father who disinherits his three spoilt children. Francis Ford Coppola deliberately incorporated elements of "Lear" in his 1990 sequel "The Godfather Part III", including Michael Corleone's attempt to retire from crime throwing his domain into anarchy, and most obviously the death of his daughter in his arms. Parallels have also been drawn between Andy García's character Vincent and both Edgar and Edmund, and between Talia Shire's character Connie and Kaede in "Ran".
In 1997, Jocelyn Moorhouse directed "A Thousand Acres", based on Jane Smiley's Pulitzer Prize-winning novel, set in 1990s Iowa. The film is described, by scholar Tony Howard, as the first adaptation to confront the play's disturbing sexual dimensions. The story is told from the viewpoint of the elder two daughters, Ginny played by Jessica Lange and Rose played by Michelle Pfeiffer, who were sexually abused by their father as teenagers. Their younger sister Caroline, played by Jennifer Jason Leigh had escaped this fate and is ultimately the only one to remain loyal.
The play was again adapted to the world of gangsters in Don Boyd's 2001 "My Kingdom", a version which differs from all others in commencing with the Lear character, Sandeman, played by Richard Harris, in a loving relationship with his wife. But her violent death marks the start of an increasingly bleak and violent chain of events (influenced by co-writer Nick Davies' documentary book "Dark Heart") which in spite of the director's denial that the film had "serious parallels" to Shakespeare's play, actually mirror aspects of its plot closely. Unlike Shakespeare's Lear, but like Hidetora and Sandeman, the central character of Uli Edel's 2002 American TV adaptation "King of Texas", John Lear played by Patrick Stewart, has a back-story centred on his violent rise to power as the richest landowner (metaphorically a "king") in General Sam Houston's independent Texas in the early 1840s. Daniel Rosenthal comments that the film was able, by reason of having been commissioned by the cable channel TNT, to include a bleaker and more violent ending than would have been possible on the national networks. 2003's Channel 4-commissioned two-parter "Second Generation" set the story in the world of Asian manufacturing and music in England.

</doc>
<doc id="55726" url="https://en.wikipedia.org/wiki?curid=55726" title="Gentlemen's agreement">
Gentlemen's agreement

A gentlemen's agreement or gentleman's agreement is an informal and legally non-binding agreement between two or more parties. It is typically oral, though it may be written, or simply understood as part of an unspoken agreement by convention or through mutually beneficial etiquette. The essence of a gentlemen's agreement is that it relies upon the honor of the parties for its fulfillment, rather than being in any way enforceable. It is, therefore, distinct from a legal agreement or contract, which can be enforced if necessary.
History.
The phrase appears in British Parliamentary records of 1821, and in Massachusetts public records of 1835. The Oxford English Dictionary cites P. G. Wodehouse's 1929 story collection "Mr Mulliner Speaking" as the first appearance of the term.
Industry.
A gentleman's agreement, defined in the early 20th century as "an agreement between gentlemen looking toward the control of prices," was reported by one source to be the loosest form of a "pool". These types of agreements have been reported to be found in every type of industry, and are numerous in the steel and iron industries.
A report from the United States House of Representatives detailing their investigation of the United States Steel Corporation asserted that there were two general types of loose associations or consolidations between steel and iron interests in the 1890s, in which the individual concerns retained ownership as well as a large degree of independence: the "pool" and the "gentleman's agreement". The latter type lacked any formal organization to regulate output or prices, nor did they contain any provisions for forfeiture in the event of an infraction. The efficacy of the agreement relied on members to keep informal pledges.
In the automotive industry, Japanese manufacturers agreed that no production car would have more than ; this agreement ended in 2005. German manufacturers limit the top speed of high-performance saloons (sedans) and station wagons to . Also, in motorcycle industry, first Suzuki Hayabusa models, mostly those from 1999 till 2000, exceeded 190 mph (or around 305 km/h). Fearing a worldwide ban due to the motorcycle's speed, Japanese and European motorcycle makers made an agreement to never produce a motorcycle that can reach more than 300 km/h (or 186 mph).
International relations.
Intense anti-Japanese sentiment developed on the West Coast. US President Theodore Roosevelt did not want to anger Japan by passing legislation to bar Japanese immigration to the US, as had been done for Chinese immigration. Instead, there was an informal "Gentlemen's Agreement" (1907–8) between the United States and Japan, whereby Japan made sure there was very little or no movement to the US. The agreements were made by Secretary of State, Elihu Root, and Japan's Foreign Minister, Tadasu Hayashi. The agreement banned emigration of Japanese laborers to the US and rescinded the segregation order of the San Francisco School Board in California, which had humiliated and angered the Japanese. The agreement did not apply to the Territory of Hawaii, which was treated at the time as separate and distinct from the US. The agreements remained effect until 1924, when Congress forbade all immigration from Japan.
Trade policies.
Gentlemen's agreements have come to regulate international activities such as the coordination of monetary or trade policies. According to Edmund Osmańczyk in the "Encyclopedia of the United Nations and International Agreements", it is also defined as "an international term for an agreement made orally rather than in writing, yet fully legally valid". This type of agreement may allow a nation to avoid the domestic legal requirements to enter into a formal treaty, or it may be useful when a government wants to enter into a secret agreement that is not binding upon the next administration. According to another author, all international agreements are gentlemen's agreements because, short of war, they are "all" unenforceable. Osmańczyk pointed out that there is a difference between open gentlemen's agreements and secret diplomatic agreements. In the United States, a prohibition against gentlemen's agreements in commercial relations between states was introduced in 1890, because the secretive nature of such agreements was beyond anyone's control.
In English contract law, for an agreement to be binding, there must be an intention to create legal relations; but in commercial dealings (i.e. agreements that are not between family members or friends) there is a legal presumption of an "intention to create legal relations". However, in the 1925 case of "Rose & Frank Co v JR Crompton & Bros Ltd" , the House of Lords held that the phrase, "This arrangement is not ... a formal or legal agreement ... but is only a record of the intention of the parties" was sufficient to rebut the said presumption.
As a discriminatory tactic.
Gentlemen's agreements were a widely used discriminatory tactic reportedly more common than restrictive covenants in "preserving" the homogeneity of upper-class neighborhoods and suburbs in the United States. The nature of these agreements made them extremely difficult to prove or to track, and were effective long after the United States Supreme Court's rulings in "Shelley v. Kraemer" and "Barrows v. Jackson". One source states that gentlemen's agreements "undoubtedly still exist," but that their use has greatly diminished.
In 1934, the National Football League entered into a gentlemen's agreement to ban black players. Until Jackie Robinson was hired by the Brooklyn Dodgers in 1946, a gentlemen's agreement also ensured that African American players were excluded from organized baseball.

</doc>
<doc id="55727" url="https://en.wikipedia.org/wiki?curid=55727" title="Newlands Reclamation Act">
Newlands Reclamation Act

The Reclamation Act (also known as the Lowlands Reclamation Act or National Reclamation Act) of 1902 () is a United States federal law that funded irrigation projects for the arid lands of 20 states in the American West.
The act at first covered only 13 of the western states as Texas had no federal lands. Texas was added later by a special act passed in 1906. The act set aside money from sales of semi-arid public lands for the construction and maintenance of irrigation projects. The newly irrigated land would be sold and money would be put into a revolving fund that supported more such projects. This led to the eventual damming of nearly every major western river. Under the act, the Secretary of the Interior created the "United States Reclamation Service" within the United States Geological Survey to administer the program. In 1907, the Service became a separate organization within the Department of the Interior and was renamed the United States Bureau of Reclamation.
The Act was authored by Democratic Congressional Representative Francis G. Newlands of Nevada. Amendments made by the Reclamation Project Act of 1939 gave the Department of the Interior, among other things, the authority to amend repayment contracts and to extend repayment for not more than 40 years. Amendments made by the Reclamation Reform Act of 1982 (P.L. 97-293) eliminated the residency requirement provisions of reclamation law, raised the acreage limitation on lands irrigated with water supplied by the Bureau of Reclamation, and established and required full-cost rates for land receiving water above the acreage limit.
Background.
John Wesley Powell, often considered the father of reclamation, began a series of expeditions to explore the American West in 1867. He saw that after snowmelt and spring rains, the rivers of the West flooded, releasing huge amounts of water and that for the rest of the year, not enough rain fell to support any kind of real agriculture. He concluded that the Western United States was so arid that it could not support extensive development yet, the U.S. government saw too much economic potential in the West to heed Powell's warning. By damming western rivers in order to support massive irrigation projects, population growth and farming were made possible.
Several private and local farming organizations proved the benefits of irrigation projects. However, when it became apparent that a greater effort would be required, Representative Francis G. Newlands of Nevada introduced legislation into the United States Congress to provide federal help for irrigation projects. The resulting act passed on June 17, 1902.
Newlands carried the bulk of the legislative burden and had a strong technical backup from Frederick Haynes Newell of the Department of the Interior. President Theodore Roosevelt cobbled together the legislative alliances that made passage of the act possible.
It was later amended by the Reclamation Reform Act of 1982 (, Title II) to limit the corporate use of water and speculation on land that would benefit from irrigation. Reclamation includes draining, too.
Summary of the Act.
The full name of the act is ""An Act Appropriating the receipts from the sale and disposal of public lands in certain States and Territories to the construction of irrigation works for the reclamation of arid lands"".
Section One<br>
This section identifies the 16 states and territories to be included in the project; Arizona, California, Colorado, Idaho, Kansas, Montana, Nebraska, Nevada, New Mexico, North Dakota, Oklahoma, Oregon, South Dakota, Utah, Washington, and Wyoming. It requires surplus fees from sales of land be set aside for a ""reclamation fund"" for the development of water resources. Also requires the Treasury Department to fund education from unappropriated monies under certain conditions.
Section Two<br>
Authorizes the Secretary of the Interior to determine the reclamation projects.
Section Three<br>
Requires the Secretary of the Interior to withdraw all such land from public entry.
Section Four<br>
Authorizes the Secretary of the Interior to contract for the project with certain conditions. Also requires that the work day will be 8 hours and that no so-called "Mongolian" labor (unskilled laborers from Asia) will be used.
Section Five<br>
Sets certain requirements for those using the water, including; half of the land must be for agriculture, a user must pay apportioned charges, user cannot use more than the apportioned water, user cannot sell entire water to one neighbor or any water to a non-resident, and user must pay apportioned charges annually.
Section Six<br>
Authorizes to Secretary of the Interior to use the reclamation fund for all works constructed under the act and to pass management of projects over to the users once they have paid.
Section Seven<br>
Gives the Secretary of the Interior the power of Eminent Domain for construction projects.
Section Eight<br>
Requires the Secretary of the Interior to conform to state laws with certain exceptions.
Section Nine<br>
Requires the Secretary of the Interior to expend monies generated by each state within that state as much as is practicable.
Section Ten<br>
Authorizes the Secretary of the Interior to make such rules and regulation as is necessary to carry out the provisions of the act.
Results of the act.
Below are listed the larger of the irrigation projects of the United States, with the area reclaimed or to be reclaimed as of 1925. (1) 
Much of the West could not have been settled without the water provided by the Act. The West became one of the premier agricultural areas in the world. Bureau of Reclamation statistics shows that the more than 600 of their dams on waterways throughout the West provide irrigation for 10 million acres (40,000 km²) of farmland, providing 60% of the nation's vegetables and 25% of its fruits and nuts. Currently, the Bureau operates about 180 projects in the West.
Not envisioned by the act, Bureau of Reclamation dams support 58 power plants producing 40 billion kilowatt hours of electricity annually. Most of the large population centers in the Far West owe their growth to these power sources.
See also.
River systems

</doc>
<doc id="55728" url="https://en.wikipedia.org/wiki?curid=55728" title="Federal Meat Inspection Act">
Federal Meat Inspection Act

The Federal Meat Inspection Act of 1906 (FMIA) is a United States Congress Act that works to prevent adulterated or misbranded meat and meat products from being sold as food and to ensure that meat and meat products are slaughtered and processed under sanitary conditions. These requirements also apply to imported meat products, which must be inspected under equivalent foreign standards. USDA inspection of poultry was added by the Poultry Products Inspection Act of 1957. The Food, Drug, and Cosmetic Act authorizes the Food and Drug Administration (FDA) to provide inspection services for all livestock and poultry species not listed in the FMIA or PPIA, including venison and buffalo. The Agricultural Marketing Act authorizes the USDA to offer voluntary, fee-for-service inspection services for these same species.
Historical motivation for enactment.
The original 1906 Act authorized the Secretary of Agriculture to inspect and condemn any meat product found unfit for human consumption. Unlike previous laws ordering meat inspections, which were enforced to assure European nations from banning pork trade, this law was strongly motivated to protect the American diet. All labels on any type of food had to be accurate (although not all ingredients were provided on the label). Even though all harmful food was banned, a few warnings were still provided on the container. The law was partly a response to the publication of Upton Sinclair's "The Jungle", an exposé of the Chicago meat packing industry, as well as to other Progressive Era muckraking publications of the day. While Sinclair's dramatized account was intended to bring attention to the terrible working conditions in Chicago, the public was more horrified by the prospect of bad meat.
The book's assertions were confirmed in the Neill-Reynolds report, commissioned by President Theodore Roosevelt in 1906. Roosevelt was suspicious of Sinclair's socialist attitude and conclusions in "The Jungle", so he sent labor commissioner Charles P. Neill and social worker James Bronson Reynolds, men whose honesty and reliability he trusted, to Chicago to make surprise visits to meat packing facilities.
Despite betrayal of the secret to the meat packers, who worked three shifts a day for three weeks to thwart the inspection, Neill and Reynolds were still revolted by the conditions at the factories and at the lack of concern by plant managers (though neither had much experience in the field). Following their report, Roosevelt became a supporter of regulation of the meat packing industry, and, on June 30, signed the Meat Inspection Act of 1906.
Provisions.
The FMIA mandated the United States Department of Agriculture (USDA) inspection of meat processing plants that conducted business across state lines. The Pure Food and Drug Act, enacted on the same day in 1906, also gave the government broad jurisdiction over food in interstate commerce.
The four primary requirements of the Meat Inspection Act of 1906 were:
After 1906, many additional laws that further standardized the meat industry and its inspection were passed.
Preemption of state law.
In 2012, the U.S. Supreme Court ruled in "National Meat Assn. v. Harris", that the FMIA preempts a California law regulating the treatment of non-ambulatory livestock.

</doc>
<doc id="55729" url="https://en.wikipedia.org/wiki?curid=55729" title="Pure Food and Drug Act">
Pure Food and Drug Act

The was the first of a series of significant consumer protection laws enacted by Congress in the 20th century and led to the creation of the Food and Drug Administration. Its main purpose was to ban foreign and interstate traffic in adulterated or mislabeled food and drug products, and it directed the U.S. Bureau of Chemistry to inspect products and refer offenders to prosecutors. It required that active ingredients be placed on the label of a drug’s packaging and that drugs could not fall below purity levels established by the United States Pharmacopeia or the National Formulary. "The Jungle" by Upton Sinclair was an inspirational piece that kept the public's attention on the important issue of unsanitary meat processing plants that later led to food inspection legislation.
Historical significance.
The Pure Food and Drug Act of 1906 was a key piece of Progressive Era legislation, signed by President Theodore Roosevelt on the same day as the Federal Meat Inspection Act. Enforcement of the Pure Food and Drug Act was assigned to the Bureau of Chemistry in the U.S. Department of Agriculture which was renamed the U.S. Food and Drug Administration (FDA) in 1930. The Meat Inspection Act was assigned to what is now known as the Food Safety and Inspection Service that remains in the U.S. Department of Agriculture. The first federal law regulating foods and drugs, the 1906 Act's reach was limited to foods and drugs moving in interstate commerce. Although the law drew upon many precedents, provisions, and legal experiments pioneered in individual states, the federal law defined "misbranding" and "adulteration" for the first time and prescribed penalties for each. The law recognized the U.S. Pharmacopeia and the National Formulary as standards authorities for drugs, but made no similar provision for federal food standards. The law was principally a "truth in labeling" law designed to raise standards in the food and drug industries and protect the reputations and pocketbooks of honest businessmen.
Particular drugs deemed dangerous.
Under the law, drug labels, for example, had to list any of 10 ingredients that were deemed "addictive" and/or "dangerous" on the product label if they were present, and could not list them if they were not present. Alcohol, morphine, opium, and cannabis were all included on the list of these "addictive" and/or "dangerous" drugs. The law also established a federal cadre of food and drug inspectors that one Southern opponent of the legislation criticized as "a Trojan horse with a bellyful of inspectors and other employees." Penalties under the law were modest, but an under-appreciated provision of the Act proved more powerful than monetary penalties. Goods found in violation of the law were subject to seizure and destruction at the expense of the manufacturer. That, combined with a legal requirement that all convictions be published as Notices of Judgment, proved to be important tools in the enforcement of the statute and had a deterrent effect upon would-be violators. Deficiencies in this original statute, which had become noticeable by the 1920s, led to the replacement of the 1906 statute with the Federal Food, Drug, and Cosmetic Act, which, was enacted in 1938 and signed by President Franklin Roosevelt. The 1938 Food, Drug, and Cosmetic Act, along with its numerous amendments, remains the statutory basis for federal regulation of all foods, drugs, biological products, cosmetics, medical devices, tobacco, and radiation-emitting devices by the U.S. Food and Drug Administration.
History of passage.
It took 27 years to pass the 1906 statute, during which time the public was made aware of many problems with foods and drugs in the U.S. Muckraking journalists, such as Samuel Hopkins Adams, targeted the patent medicine industry with its high-alcoholic content patent medicines, soothing syrups for infants with opium derivatives, and "red clauses" in newspaper contracts providing that patent medicine ads (upon which most newspapers of the time were dependent) would be withdrawn if the paper expressed support for food and drug regulatory legislation. The Chief Chemist of the Bureau of Chemistry, Dr. Harvey Washington Wiley, captured the country's attention with his hygienic table studies, which began with a modest Congressional appropriation in 1902. The goal of the table trial was to study the human effects of common preservatives used in foods during a period of rapid changes in the food supply brought about by the need to feed cities and support an industrializing nation increasingly dependent on immigrant labor. Wiley recruited young men to eat all their meals at a common table as he added increased "doses" of preservatives including borax, benzoate, formaldehyde, sulfites, and salicylates. The table trials captured the nation's fancy and were soon dubbed "The Poison Squad" by newspapers covering the story. The men soon adopted the motto "Only the Brave dare eat the fare" and at times the publicity given to the trials became a burden. Though many results of the trial came to be in dispute, there was no doubt that formaldehyde was dangerous and it disappeared quickly as a preservative. Wiley himself felt that he had found adverse effects from large doses of each of the preservatives and the public seemed to agree with Wiley. In many cases, most particularly with ketchup and other condiments, the use of preservatives was often used to disguise insanitary production practices. Although the law itself did not proscribe the use of some of these preservatives, consumers increasingly turned away from many products with known preservatives.
The 1906 statute regulated food and drugs moving in interstate commerce and forbade the manufacture, sale, or transportation of poisonous patent medicines. The Act arose due to public education and exposés from public interest guardians such as Upton Sinclair and Samuel Hopkins Adams, social activist Florence Kelley, researcher Harvey W. Wiley, and President Theodore Roosevelt.
Beginnings of the Food and Drug Administration.
The 1906 Act paved the way for the eventual creation of the Food and Drug Administration (FDA) and is generally considered to be that agency's founding date, though the agency existed before the law was passed and was not named FDA until later. "While the Food and Drug act remains a foundational law of the FDA mission, it's not the law that created the FDA. the Bureau of Chemistry (the precursor to the FDA) regulated food safety. In 1927, the Bureau was reorganized into the Food, Drug, and Insecticide Administration and the Bureau of Chemistry and Soils. The FDIA was renamed the FDA in 1930."
The law itself was largely replaced by the much more comprehensive Federal Food, Drug, and Cosmetic Act of 1938.
Enforcement of labeling and future ramifications.
The Pure Food and Drug Act was initially concerned with ensuring products were labeled correctly. Later efforts were made to outlaw certain products that were not safe, followed by efforts to outlaw products which were safe but not effective. For example, there was an attempt to outlaw Coca-Cola in 1909 because of its excessive caffeine content; caffeine had replaced cocaine as the active ingredient in Coca-Cola in 1903. In the case "United States v. Forty Barrels and Twenty Kegs of Coca-Cola", the judge found that Coca-Cola had a right to use caffeine as it saw fit, although Coca-Cola eventually lost when the government appealed to the Supreme Court. It reached a settlement with the United States government to reduce the caffeine amount.
In addition to caffeine, the Pure Food and Drug Act required that drugs such as alcohol, cocaine, heroin, morphine, and cannabis, be accurately labeled with contents and dosage. Previously many drugs had been sold as patent medicines with secret ingredients or misleading labels. Cocaine, heroin, cannabis, and other such drugs continued to be legally available without prescription as long as they were labeled. It is estimated that sale of patent medicines containing opiates decreased by 33% after labeling was mandated. The Pure Food and Drug Act of 1906 is cited by drug policy reform advocates such as James P. Gray as a successful model for re-legalization of currently prohibited drugs by requiring accurate labels, monitoring of purity and dose, and consumer education.

</doc>
<doc id="55731" url="https://en.wikipedia.org/wiki?curid=55731" title="Aldrich–Vreeland Act">
Aldrich–Vreeland Act

The Aldrich–Vreeland Act was passed in response to the Panic of 1907 and established the National Monetary Commission, which recommended the Federal Reserve Act of 1913.
On May 27, 1908, the bill passed the House on a mostly party-line vote of 166–140, with 13 Republicans voting against it and no Democrats voting for it. On May 30, it passed in the Senate with 43 Republicans in favor and five Republicans joining 17 Democrats opposed. President Roosevelt signed the bill that same night.
The act also allowed national banks to start national currency associations in groups of ten or more, with at least $5 million in total capital, to issue emergency currency. These bank notes were to be backed by not just government bonds but also just about any securities the banks were holding. The act proposed that this emergency currency had to go through a process of approval by the officers of these national currency associations and then distributed by the Comptroller of the Currency.
However, it is possible that because there was a 5 percent tax placed on this emergency currency for the first month it was "outstanding" and a 1 percent increase for the following months it was "outstanding," no bank notes were issued. Another possible explanation that the emergency currency was never issued might have been that it was unnecessary.
Congress modified and extended the law in 1914 when British and other foreign creditors demanded immediate payments, in gold, of amounts which would ordinarily have been carried over and paid through exports of commodities.
Senator Nelson W. Aldrich (R-RI) was largely responsible for the "Aldrich-Vreeland Currency Law" and became the Chairman of the "National Monetary commission". The co-sponsor of the legislation was Rep. Edward Vreeland, a Republican from New York.
A usage of the law occurred at the outbreak of the World War I in 1914 when the first great financial panic of the 20th century befell the world, necessitating the closure of the New York Stock Exchange. Secretary of the Treasury William Gibbs McAdoo appeared in New York City and assured the public that ample stocks of emergency banknotes had been prepared in accordance with the Aldrich–Vreeland Act and were available for issue to the banks. As of October 23, 1914, $368,616,990 was outstanding.
The Federal Reserve Act of December 23, 1913 took effect in November 1914 when the 12 regional banks opened for business. Ultimately the emergency currency issued under the "Aldrich-Vreeland Law" was entirely withdrawn.

</doc>
<doc id="55732" url="https://en.wikipedia.org/wiki?curid=55732" title="Elkins Act">
Elkins Act

The Elkins Act is a 1903 United States federal law that amended the Interstate Commerce Act of 1887. The Act authorized the Interstate Commerce Commission (ICC) to impose heavy fines on railroads that offered rebates, and upon the shippers that accepted these rebates. The railroad companies were not permitted to offer rebates. Railroad corporations, their officers, and their employees, were all made liable for discriminatory practices.
Prior to the Elkins Act, the livestock and petroleum industries paid standard rail shipping rates, but then would demand that the railroad company give them rebates. The railroad companies resented being extorted by the railroad trusts and therefore welcomed passage of the Elkins Act. The law was sponsored by President Theodore Roosevelt as a part of his "Square Deal" domestic program, and greatly boosted his popularity.
Background.
Congress passed the Elkins Act as an amendment to the Interstate Commerce Act. Without restrictive legislation, large firms could demand rebates or prices below the collusive price from railroad companies as condition for their business. As a result, it was common practice for railroads to offer competitive lower rates for transport between the large cities with high density of firms than the monopolistic rates between less industrial cities, irrespective of length of travel. Trusts constituted such a substantial portion of a carrier's revenue that the trusts could demand rebates as a condition for business, and the carrier would be forced to cooperate.
Purpose.
The ICC had been unable to protect competition and fair pricing. Section 2 of the Interstate Commerce Act prohibits a carrier from offering preferential prices or rebates; however, enforcement of this section was ineffective. Powerful trusts would pay the standard shipping price, but demand a rebate from the carrier. Court cases brought before the commission generally did not result in punitive action, as the ICC was composed primarily of railroad interests. Carriers found guilty of price discrimination, moreover, could appeal the ICC decision to federal courts, delaying punishment for years.
The Elkins Act was named for its sponsor, Senator Stephen B. Elkins of West Virginia, who introduced a bill in 1902 at the behest of the Pennsylvania Railroad. The law was passed by the 57th Congress and signed by President Roosevelt on February 19, 1903. The Act made it a misdemeanor for a carrier to impose preferential rebates, and implicated both the carrier and the recipient of the low price. The Act also abolished imprisonment as a punishment for breaching the law, so a violator could only be fined. By reducing the severity of punishment, legislators hoped to encourage firms to testify against each other, and promote stricter enforcement of the law.
Impact.
Following the passage of the Elkins Act, real freight rates decreased only slightly. In 1905, leaders in the regulation movement testified before Congress to identify the reduction in prices that resulted from the Act. Yet, in the first months following the passage of the law, the most pronounced change in railroad pricing was the elimination of rebates. However, later analysis has found that decreases in carrier prices are better attributable to decreases in the costs of operation due to technology advances. The elimination of rebates led the railroads to seek other methods to compete for business, leading Governor Albert B. Cummins of Iowa to declare, in 1905, that the elimination of rebates simply forces railroads to seek alternative noncompetitive means to secure business. The Elkins Act, thus, was more effective in stabilizing prices and entrenching price collusion than demonstrably lowering prices.
A diverse group of stakeholders publicly supported the Elkins Act. Citizens who supported the law hoped that reducing price discrimination would lower freight prices uniformly, and railroad interests lobbied for the passage of the Act as a means of enforcing collusive pricing. While the Act restricted preferential pricing, it did not specify what constituted a "reasonable" shipping rate; thus, railroads could use the law to entrench a system of collusive prices. Collusion is unsustainable in a market where it is easy to undercut competitors. However in industries that only have a small number of competitors (e.g. railroads, airlines, or transportation companies operating between two given cities) collusion is far more likely. The result of the Elkins Act was that Railroads had a stronger mechanism to protect their collusive prices and corporate trusts were weakened in their ability to gain shipping discounts. Farmers and other railroad users, instead of benefiting from greater competition, were unaffected by the Act.
While farmers may have benefited from the establishment of a price ceiling on freight rates, the nature of the railroad industry may have not have permitted perfect competition. Economist Robert Harbeson argues that the price wars prior to the Elkins Act suggest that the railroad industry was more oligopolistic. In an industry with decreasing marginal costs and high fixed costs, it would be futile to enforce a price cap. Moreover, he argues, stronger regulation would have prevented carriers from reaching economies of scale.
Contemporary criticism.
In reaction to the Elkins Act, it was argued that the law was drafted by Congress on behalf of the railroads, and that while some railroads curtailed rebates for some customers, for others the practice continued unabated. Congress was criticized for enacting only monetary fines for violations of the law and avoiding imposition of criminal penalties.
Subsequent legislation.
Citing the shortcomings of the Elkins Act, Progressives began to call for greater regulation of railroad interests, and, in 1906, President Roosevelt signed the Hepburn Act to replace the Elkins Act. The Hepburn Act set maximum freight rates for railroads, representing the greater interests of Americans. The regulations of the Hepburn Act strained railroads, which saw new competition from the rise of trucks and automobiles. The Panic of 1907 was, in part, a result of the turmoil of the railroad industry that resulted from the Hepburn Act.

</doc>
<doc id="55733" url="https://en.wikipedia.org/wiki?curid=55733" title="Hepburn Act">
Hepburn Act

The "Hepburn Act." is a 1906 United States federal law that gave the Interstate Commerce Commission (ICC) the power to set maximum railroad rates and extend its jurisdiction. This led to the discontinuation of free passes to loyal shippers. In addition, the ICC could view the railroads' financial records, a task simplified by standardized bookkeeping systems. For any railroad that resisted, the ICC's conditions would remain in effect until the outcome of legislation said otherwise. By the Hepburn Act, the ICC's authority was extended to cover bridges, terminals, ferries, railroad sleeping cars, express companies and oil pipelines.
Along with the Elkins Act of 1903, the Hepburn Act, named for its sponsor, eleven-term Republican William Peters Hepburn, was a subset of one of President Theodore Roosevelt's major goals: railroad regulation.
The final version was close to what Roosevelt had asked, and easily passed Congress with only three dissenting votes. The most important provision gave the ICC the power to replace existing rates with "just-and-reasonable" maximum rates, with the ICC to define what was just and reasonable. The Act made ICC orders binding; that is, the railroads had to either obey or contest the ICC orders in federal court. To speed the process, appeals from the district courts would go directly to the U.S. Supreme Court.
Anti-rebate provisions were toughened, free passes were outlawed, and the penalties for violation were increased. The ICC staff grew from 104 in 1890 to 178 in 1905, 330 in 1907, and 527 in 1909. Finally, the ICC gained the power to prescribe a uniform system of accounting, require standardized reports, and inspect railroad accounts.
The limitation on railroad rates depreciated the value of railroad securities, a factor in causing the Panic of 1907.
Scholars consider the Hepburn Act the most important piece of legislation regarding railroads in the first half of the 20th century. Economists and historians debate whether it crippled the railroads, giving so much advantage to the shippers that a giant unregulated trucking industry—undreamed of in 1906—took away their business.

</doc>
<doc id="55734" url="https://en.wikipedia.org/wiki?curid=55734" title="Payne–Aldrich Tariff Act">
Payne–Aldrich Tariff Act

The Payne–Aldrich Tariff Act of 1909 (ch. 6, 36 Stat. 11), named for Representative Sereno E. Payne (R–NY) and Senator Nelson W. Aldrich (R–RI), began in the United States House of Representatives as a bill raising certain tariffs on goods entering the United States. The high rates angered Republican reformers, and led to a deep split in the Republican Party.
History.
It was the first change in tariff laws since the Dingley Act of 1897. President William Howard Taft called Congress into a special session in 1909 shortly after his inauguration to discuss the issue. Thus, the House of Representatives immediately passed a tariff bill sponsored by Payne, calling for reduced tariffs. However, the United States Senate speedily substituted a bill written by Aldrich, calling for fewer reductions and more increases in tariffs.
An additional provision of the bill provided for the creation of a tariff board to study the problem of tariff modification in full and to collect information on the subject for the use of Congress and the President in future tariff considerations. Another provision allowed for free trade with the Philippines, then under American control. Congress passed the bill officially on April 9, 1909.
Taft promptly appointed members to serve on the tariff board.
Impact.
The Payne Act, in its essence a compromise bill, had the immediate effect of frustrating both proponents and opponents of reducing tariffs. In particular, the bill greatly angered Progressives, who began to withdraw support from President Taft. Because it increased the duty on print paper used by publishers, the publishing industry viciously criticized the President, further tarnishing his image. Although Taft met and consulted with Congress during its deliberations on the bill, critics charged that he ought to have imposed more of his own recommendations on the bill such as that of a slower schedule. However, unlike his predecessor (Theodore Roosevelt), Taft felt that the president should not dictate lawmaking and should leave Congress free to act as it saw fit.
Taft signed the bill. The debate over the tariff split the Republican Party into Progressives and Old Guards and led the split party to lose the 1910 congressional election. 
The bill enacted a small income tax on the privilege of conducting business as a corporation, which was affirmed in the Supreme Court decision "Flint v. Stone Tracy Co." (also known as the Corporation Tax case).

</doc>
<doc id="55737" url="https://en.wikipedia.org/wiki?curid=55737" title="Clear and Present Danger">
Clear and Present Danger

Clear and Present Danger is a novel by Tom Clancy, written in 1989, and is a canonical part of the Jack Ryan universe. In the novel, Jack Ryan is thrown into the position of Central Intelligence Agency (CIA) Acting Deputy Director (Intelligence) and discovers that he is being kept in the dark by his colleagues who are conducting a covert war against a drug cartel based in Colombia.
Plot summary.
When U.S. Coast Guard cutter "Panache" intercepts a yacht in the Caribbean Sea, the crew discovers two men cleaning up the vessel after murdering a man and his family. Through a mock execution, the Coast Guardsmen force the killers to confess to the crime. It is later learned that the murdered man was involved in a money laundering scheme for a drug cartel.
Upon hearing that the owner of the yacht was a long-time political ally and friend, the President of the United States, who is running for re-election, feels compelled to take drastic measures against drug trafficking; his challenger, J. Robert Fowler, has rallied the public behind the administration's failures in the War on Drugs. The president initiates covert operations within Colombia and a step-up of operations against aircraft believed to be distributing narcotics. Aiding the president are U.S. National Security Advisor James Cutter, CIA Deputy Director of Operations Robert Ritter, and Director of Central Intelligence Arthur Moore.
The plan consists of four operations:
Meanwhile, Félix Cortez, a former intelligence officer from Cuba employed by the cartel, feigns romantic interest in the aide of Emil Jacobs, the Director of the FBI. The aide unknowingly reveals information regarding the date of Jacobs' official visit to the Attorney General of Colombia. Cortez delivers this information to the cartel, which orders Jacobs' assassination as retaliation for the U.S. seizure of cartel money. During his visit, Jacobs and several other Americans in his delegation are killed.
Jack Ryan suspects the CIA's involvement in the situation in Colombia. As acting Deputy Director of the Intelligence Directorate, Ryan should be privy to most operations, but he realizes he is being kept out of the loop. After Robby Jackson, assigned to the Pentagon, makes an inquiry into activity in the region, Ryan goes to Moore to demand an explanation. Moore is evasive, yet orders Ryan to withhold information about Colombia from a congressional oversight committee.
Cortez eventually uncovers the U.S. operations. He suppresses this information, planning to engineer a war within the cartel that will leave him in a position to seize power. Cortez orders mercenaries to hunt down the U.S. troops, and blackmails Cutter into ending SHOWBOAT, promising the intracartel war will slow drug imports to the States. Cutter's meeting with Cortez is shadowed by the FBI. Clark is outraged at Cutter's abandonment of the troops and, with Ryan, plans a rescue operation with personnel from the FBI and U.S. Air Force.
Clark makes radio contact with two of the SHOWBOAT teams, ordering them to alternate pickup points to await extraction. The other two teams encounter mercenaries and take casualties. Clark makes radio contact with some survivors of these remaining teams—which include Domingo Chavez—then flies into Colombia to retrieve them. Ryan uses an Air Force helicopter to pick up other survivors. Together, Clark and Ryan launch a raid on the cartel's command post, capturing Cortez and extracting the remaining ground team. Due to a hurricane and damage to the helicopter, they land on the deck of the "Panache".
Cortez is returned to Cuba, where he is a marked as a traitor. Upon being confronted by Clark with evidence of his treason, Cutter commits suicide. Ryan confronts the defiant president, informing him that despite his classifying the drug cartel as a "clear and present danger", Ryan must brief Congress over the illegal operations. After Ryan briefs the committee, the president deliberately loses the election to hide the covert operations and protect the honor of those involved. Ryan realizes the president has more honor and dignity than he originally thought. Clark recruits one distinguished soldier from the operation, Sgt. Domingo "Ding" Chavez, into the CIA, and becomes his mentor.

</doc>
<doc id="55738" url="https://en.wikipedia.org/wiki?curid=55738" title="Federal Farm Loan Act">
Federal Farm Loan Act

The Federal Farm Loan Act of 1916 () was a United States federal law aimed at increasing credit to rural family farmers. It did so by creating a federal farm loan board, twelve regional farm loan banks and tens of farm loan associations. The act was signed into law by President of the United States Woodrow Wilson.
Background.
In 1908, the Administration of Theodore Roosevelt commissioned a study on the problems facing rural families. At this point in U.S. history, these families made up the largest demographic. The commission concluded that access to credit was one of the most serious problems facing rural farmers and recommended the introduction of a cooperative credit system.
Four years later, Presidents William Howard Taft and Woodrow Wilson sent a commission of Americans to study cooperative credit systems for farmers in Europe. Components of such European programs at the time included cooperative land-mortgage banks and rural credit unions. This commission concluded that the best form of cooperative credit system would include both long-term credit to cover land mortgages and short-term credit to cover regular business needs.
Effect on the rural farmer.
The most visible component of the Act were the loans to individual farmers and their families. Under the act, farmers could borrow up to 50% of the value of their land and 20% of the value of their improvements. The minimum loan was $100 and the maximum was $10,000. Loans made through the Act were paid off through amortization over 5 to 40 years. 
Borrowers also purchased shares of the National Farm Loan Association. This meant that it served as a cooperative agency that lent money from farmer to farmer. This was heavily influenced by a successful cooperative credit system in Germany called Landschaft.
The next most visible component of the Act were the mortgage-backed bonds that were issued. The rate of interest on the mortgages could be no more than 1 percent higher than the rate of interest on the bonds. This spread covered the issuers' administrative costs, but did not lead to a significant profit. In addition, the maximum rate of interest on the bonds was 6 percent, ensuring that borrowing costs for farmers was often much lower than before the Act was passed.
The act furthered Wilson's reputation against trusts and big business. By providing small farmers with competitive loans, they were now more able to compete with big business. As a result, the likelihood of agricultural monopolies decreased.
While Wilson's commission suggested that short-term credit also be incorporated in any nationalized credit system, the Act lacked this crucial component. Due to increased competition and the need for agriculture machinery, a system for short-term credit was incorporated into the current system in Agricultural Credits Act of 1923. 
Sponsored by Senator Henry F. Hollis (D) of New Hampshire and Representative Asbury F. Lever (D) of South Carolina, it was a reintroduced version of the Hollis-Bulkley Act of 1914 that had not passed Congress due to Wilson's opposition.
Structure of implementation.
The Act established the Federal Farm Loan Board to oversee and supervise federal land banks and national farm loan associations. It was also responsible for setting benchmark rates of interest for mortgages and bonds. Finally, it could intervene when it thought specific banks were making irresponsible loans.
The twelve Federal Land Banks were required to hold at least $750,000 in capital. Stock ownership of the banks were held by national farm loan associations and other interested investors, including any individual, corporation or fund. In the case of insufficient capital, the U.S. Treasury (through the Federal Farm Loan Board) made up the difference. When additional subscriptions were made from other sources, federal ownership in the banks was retired.
National Farm Loan Associations were established groups of 10 or more mortgage-holding farmers who together owned 5% or more of a federal land bank. Once formed, they were subject to a charter review process by the Federal Farm Loan Board. This structure aimed to align the incentives of individual farmers with the banks, as farmers held two roles: borrowers and lenders.
Subsequent history.
Under the administration of Herbert Hoover, the Agricultural Marketing Act of 1929 established the Federal Farm Board from the Federal Farm Loan Board established by the Federal Farm Loan Act with a revolving fund of half a billion dollars.
Further reading.
Farm finance and Rural Credit

</doc>
<doc id="55739" url="https://en.wikipedia.org/wiki?curid=55739" title="Railway Labor Act">
Railway Labor Act

The Railway Labor Act is a United States federal law that governs labor relations in the railroad and airline industries. The Act, passed in 1926 and amended in 1934 and 1936, seeks to substitute bargaining, arbitration and mediation for strikes as a means of resolving labor disputes. Its provisions were originally enforced under the Board of Mediation, but were later enforced under a National Mediation Board.
Historical antecedents to the RLA.
The Great Railroad Strike of 1877 lasted for six weeks and was eventually put down with the intervention of federal troops. Congress later passed the Arbitration Act of 1888, which authorized the creation of arbitration panels with the power to investigate the causes of labor disputes and to issue non-binding arbitration awards. The Act was a complete failure: only one panel was ever convened under the Act, and that one, in the case of the 1894 Pullman Strike, issued its report only after the strike had been ended by a federal court injunction backed by federal troops.
Congress attempted to correct these shortcomings in the Erdman Act, passed in 1898. The Act likewise provided for voluntary arbitration, but made any award issued by the panel binding and enforceable in federal court. It also outlawed discrimination against employees for union activities, prohibited "yellow dog contracts" (in which an employee agrees not to join a union while employed), and required both sides to maintain the status quo during any arbitration proceedings and for three months after an award was issued. The arbitration procedures were rarely used. A successor statute, the Newlands Act of 1913, which created the Board of Mediation, proved to be more effective, but was largely superseded when the federal government nationalized the railroads in 1917. ("See" United States Railroad Administration.)
The Adamson Act, passed in 1916, provided workers with an eight-hour day, at the same daily wage they had received previously for a ten-hour day, and required time and a half pay for overtime work. Another law passed in the same year gave President Woodrow Wilson the power to "take possession of and assume control of any system of transportation" for transportation of troops and war material.
Wilson exercised that authority on December 26, 1917. While Congress considered nationalizing the railroads on a permanent basis after World War I, the Wilson administration announced that it was returning the railroad system to its owners. Congress tried to preserve, on the other hand, the most successful features of the federal wartime administration, the adjustment boards, by creating a Railroad Labor Board (RLB) with the power to issue non-binding proposals for the resolution of labor disputes, as part of the Esch–Cummins Act (Transportation Act of 1920).
The RLB soon destroyed whatever moral authority its decisions might have had in a series of decisions. In 1921 it ordered a twelve percent reduction in employees' wages, which the railroads were quick to implement. The following year, when shop employees of the railroads launched a national strike, the RLB issued a declaration that purported to outlaw the strike; the Department of Justice then obtained an injunction that carried out that declaration. From that point forward railway unions refused to have anything to do with the RLB.
Passage and amendment of the RLA.
The RLA was the product of negotiations between the major railroad companies and the unions that represented their employees. Like its predecessors, it relied on boards of adjustment, established by the parties, to resolve labor disputes, with a government-appointed Board of Mediation to attempt to resolve those disputes that board of adjustment could not. The RLA promoted voluntary arbitration as the best method for resolving those disputes that the Board of Mediation could not settle.
Congress strengthened these procedures in the 1934 amendments to the Act, which created a procedure for resolving whether a union had the support of the majority of employees in a particular "craft or class," while turning the Board of Mediation into a permanent agency, the National Mediation Board (NMB), with broader powers.
Congress extended the RLA to cover airline employees in 1936.
Bargaining and strikes under the RLA.
Unlike the National Labor Relations Act (NLRA), which adopts a less interventionist approach to the way the parties conduct collective bargaining or resolve their disputes arising under collective bargaining agreements, the RLA specifies both (1) the negotiation and mediation procedures that unions and employers must exhaust before they may change the status quo, and (2) the methods for resolving "minor" disputes over the interpretation or application of collective bargaining agreements. The RLA permits strikes over major disputes only after the union has exhausted the RLA's negotiation and mediation procedures, while barring almost all strikes over minor disputes. The RLA also authorizes the courts to enjoin strikes if the union has not exhausted those procedures.
On the other hand, the RLA imposes fewer restrictions on the tactics that unions may use when they do have the right to strike. The RLA does not, unlike the NLRA, bar secondary boycotts against other RLA-regulated carriers; it may also permit employees to engage in other types of strikes, such as intermittent strikes, that might be unprotected under the NLRA.
"Major" and "Minor" Disputes.
The RLA categorizes all labor disputes as either "major" disputes, which concern the making or modification of the collective bargaining agreement between the parties, or "minor" disputes, which involve the interpretation or application of collective bargaining agreements. Unions can strike over major disputes only after they have exhausted the RLA's "almost interminable" negotiation and mediation procedures. They cannot, on the other hand, strike over minor disputes, either during the arbitration procedures or after an award is issued.
The federal courts have the power to enjoin a strike over a major dispute if the union has not exhausted the RLA's negotiation and mediation procedures. The Norris-LaGuardia Act dictates the procedures that the court must follow. Once the NMB releases the parties from mediation, however, they retain the power to engage in strikes or lockouts, even if they subsequently resume negotiations or the NMB offers mediation again.
The federal courts likewise have the power to enjoin a union from striking over arbitrable disputes, that is minor disputes. The court may, on the other hand, also require the employer to restore the status quo as a condition of any injunctive relief against a strike.
Major Dispute bargaining is handled through the "Section 6" process, named for the section of the Act that describes the bargaining process. The railroad carriers have formed a coalition for national handling of Railway Labor Act bargaining under Section 6, named the National Carriers Conference Committee (NCCC). The railroad unions also form coalitions of various unions to increase bargaining power in the Section 6 process. 
Discipline and replacement of strikers.
Carriers can lawfully replace strikers engaged in a lawful strike, but may not, however, discharge them, except for misconduct, or eliminate their jobs to retaliate against them for striking. It is not clear whether the employer can discharge workers for striking before exhausting all of the RLA's bargaining and mediation processes.
The employer must also allow strikers to replace replacements hired on a temporary basis and permanent replacements who have not completed the training required before they can become active employees. The employer may, on the other hand, allow less senior employees who crossed the picket line to keep the jobs they were given after crossing the line, even if the seniority rules in effect before the strike would have required the employer to reassign their jobs to returning strikers.
Representation elections under the RLA.
The NMB has the responsibility for conducting elections when a union claims to represent a carrier's employees. The NMB defines the craft or class of employees eligible to vote, which almost always extends to all of the employees performing a particular job function throughout the company's operations, rather than just those at a particular site or in a particular region.
A union seeking to represent an unorganized group of employees must produce signed and dated authorization cards or other proof of support from at least fifty percent of the craft or class. A party attempting to oust an incumbent union must produce evidence of support from a majority of the craft of class and then the NMB must conduct an election. If the employees are unrepresented and the employer agrees, the NMB may certify the union based on the authorization cards alone.
The NMB usually uses mail ballots to conduct elections, unlike the National Labor Relations Board (NLRB), which has historically preferred walk-in elections under the NLRA. The NMB can order a rerun election if it determines that either an employer or union has interfered with employees' free choice.
Protecting employees' rights.
Unlike the NLRA, which gives the NLRB nearly exclusive power to enforce the Act, the RLA allows employees to sue in federal court to challenge an employer's violation of the Act. The courts can grant employees reinstatement and backpay, along with other forms of equitable relief.

</doc>
<doc id="55740" url="https://en.wikipedia.org/wiki?curid=55740" title="Clayton Antitrust Act">
Clayton Antitrust Act

The Clayton Antitrust Act of 1914 (, codified at , ), was a part of United States antitrust law with the goal of adding further substance to the U.S. antitrust law regime; the Clayton Act sought to prevent anticompetitive practices in their incipiency. That regime started with the Sherman Antitrust Act of 1890, the first Federal law outlawing practices considered harmful to consumers (monopolies, cartels, and trusts). The Clayton Act specified particular prohibited conduct, the three-level enforcement scheme, the exemptions, and the remedial measures.
Like the Sherman Act, much of the substance of the Clayton Act has been developed and animated by the U.S. courts, particularly the Supreme Court.
Background.
Since the Sherman Antitrust Act of 1890, courts in the United States had interpreted the law on cartels as applying against trade unions. This had created an impossible situation for workers, who needed to organize so as to rebalance the equal bargaining power against their employers. The Sherman Act had also triggered the largest wave of mergers in US history, as businesses realized that instead of creating a cartel they could simply fuse into a single corporation, and have all the benefits of market power that a cartel could bring. At the end of the Taft administration, and the start of the Woodrow Wilson administration, a "Commission on Industrial Relations" was established. During its proceedings, and in anticipation of its first report on the 23 October 1914, legislation was introduced by Alabama Democrat Henry De Lamar Clayton Jr. in the U.S. House of Representatives. The Clayton Act passed by a vote of 277 to 54 on June 5, 1914. Though the Senate passed its own version on September 2, 1914, by a vote of 46–16, the final version of the law (written after deliberation between Senate and the House), did not pass the Senate until October 5 and the House until October 8 of the next year.
Contents.
The Clayton Act made both substantive and procedural modifications to federal antitrust law. Substantively, the act seeks to capture anticompetitive practices in their incipiency by prohibiting particular types of conduct, not deemed in the best interest of a competitive market. There are 4 sections of the bill that proposed substantive changes in the antitrust laws by way of supplementing the Sherman Antitrust Act of 1890. In those sections, the Act thoroughly discusses the following four principles of economic trade and business:
Comparisons to other acts.
Unilateral price discrimination is clearly outside the reach of Section 1 of the Sherman Act, which only extended to "concerted activities" (agreements). Exclusive dealing, tying, and mergers are all agreements, and theoretically, within the reach of Section 1 of the Sherman Act. Likewise, mergers that create monopolies would be actionable under Sherman Act Section 2.
Section 7 of the Clayton Act allows greater regulation of mergers than just Sherman Act Section 2, since it does not require a merger-to-monopoly before there is a violation. It allows the Federal Trade Commission and Department of Justice to regulate all mergers, and gives the government discretion whether to give approval to a merger or not, which it still commonly does today. The government often employs the Herfindahl-Hirschman Index (HHI) test for market concentration to determine whether the merger is presumptively anticompetitive; if the HHI level for a particular merger exceeds a certain level, the government will investigate further to determine its probable competitive impact.
Section 7.
Section 7 elaborates on specific and crucial concepts of the Clayton Act; "holding company" defined as "a company whose primary purpose is to hold stocks of other companies", which the government saw as a "common and favorite method of promoting monopoly" and a mere corporated form of the 'old fashioned' trust.
Another important factor to consider is the amendment passed in Congress on Section 7 of the Clayton Act in 1950. This original position of the US government on mergers and acquisitions was strengthened by the Celler-Kefauver amendments of 1950, so as to cover asset as well as stock acquisitions.
Pre-merger notification.
Section 7a, , requires that companies notify the Federal Trade Commission and the Assistant Attorney General of the United States Department of Justice Antitrust Division of any contemplated mergers and acquisitions that meet or exceed certain thresholds. Pursuant to the Hart–Scott–Rodino Antitrust Improvements Act, section 7A(a)(2) requires the Federal Trade Commission to revise those thresholds annually, based on the change in gross national product, in accordance with Section 8(a)(5) and take effect 30 days after publication in the Federal Register. (For example, see and 16 C.F.R. 801.)
Section 8.
Section 8 of the Act refers to the prohibition of one person of serving as director of two or more corporations if the certain threshold values are met, which are required to be set by regulation of the Federal Trade Commission, revised annually based on the change in gross national product, pursuant to the Hart–Scott–Rodino Antitrust Improvements Act. (For example, see .)
Other.
Because the act singles out exclusive dealing and tying arrangements, one may assume they would be subject to heightened scrutiny, perhaps they would even be illegal "per se". That remains true for tying, under the authority of "Jefferson Parish Hospital District No. 2 v. Hyde". However, when exclusive dealings are challenged under Clayton-3 (or Sherman-1), they are treated under the rule of reason. Under the 'rule of reason', the conduct is only illegal, and the plaintiff can only prevail, upon proving to the court that the defendants are doing substantial economic harm.
Exemptions.
An important difference between the Clayton Act and its predecessor, the Sherman Act, is that the Clayton Act contained safe harbors for union activities. Section 6 of the Act (codified at ) exempts labor unions and agricultural organizations, saying "that the labor of a human being is not a commodity or article of commerce, and permit labor organizations to carry out their legitimate objective". Therefore, boycotts, peaceful strikes, peaceful picketing, and collective bargaining are not regulated by this statute. Injunctions could be used to settle labor disputes only when property damage was threatened.
The Supreme Court ruled in the 1922 case "Federal Baseball Club v. National League" that Major League Baseball was not "interstate commerce" and thus was not subject to federal antitrust law.
Enforcement.
Procedurally, the Act empowers private parties injured by violations of the Act to sue for treble damages under Section 4 and injunctive relief under Section 16. The Supreme Court has expressly ruled that the "injunctive relief" clause in Section 16 includes the implied power to force defendants to divest assets.
Under the Clayton Act, only civil suits could be brought to the court's attention and a provision "permits a suit in the federal courts for three times the actual damages caused by anything forbidden in the antitrust laws", including court costs and attorney's fees.
The Act is enforced by the Federal Trade Commission, which was also created and empowered during the Wilson Presidency by the Federal Trade Commission Act, and also the Antitrust Division of the U.S. Department of Justice.

</doc>
<doc id="55741" url="https://en.wikipedia.org/wiki?curid=55741" title="Federal Trade Commission Act">
Federal Trade Commission Act

The Federal Trade Commission Act of 1914 established the Federal Trade Commission. The Act, signed into law by Woodrow Wilson in 1913, outlaws unfair methods of competition and to outlaw unfair acts or practices that affect commerce.
Origin of Act.
The inspiration and motivation for this act started in 1890, when the Sherman Act was passed. This era in time was an antitrust movement to prevent manufacturers from joining price-fixing cartels. After the case Northern Securities Co. v. United States, which dismantled a J. P. Morgan company, antitrust enforcement became institutionalized. Soon after, Roosevelt created the Bureau of Corporations, an agency that reported on the economy and businesses in the industry. This agency was the predecessor to the Federal Trade Commission. In 1913, President Wilson expanded on this agency by passing the Federal Trade Commissions Act along with the Clayton Antitrust Act. The Federal Trade Commission Act was designed for business reform. Congress passed this Act with the hopes of protecting consumers against methods of deception in advertisement, forcing the business to be upfront and truthful about items being sold.
Summary.
The Federal Trade Commission Act does more than just create the Commission, "Under this Act, the Commission is empowered, among other things, to (a) prevent unfair methods of competition, and unfair or deceptive acts or practices in or affecting commerce; (b) seek monetary redress and other relief for conduct injurious to consumers; (c) prescribe trade regulation rules defining with specificity acts or practices that are unfair or deceptive, and establishing requirements designed to prevent such acts or practices; (d) conduct investigations relating to the organization, business, practices, and management of entities engaged in commerce; and (e) make reports and legislative recommendations to Congress." This act was part of a bigger movement in the early 1900s to use special groups like commissions to regulate and oversee certain forms of business. The Federal Trade Commission Act works in junction with The Sherman Act and The Clayton Act. Any violations of The Sherman Act will also violate the Federal Trade Commission Act so the Federal Trade Commission can act on cases that violate each act. The Federal Trade Commission Act, along with other two antitrust laws, have were created for the sole objective to "protect the process of competition for the benefit of consumers, making sure there are strong incentives for businesses to operate efficiently, keep prices down, and keep quality up." These acts are considered the core of antitrust laws and are still very important in today's society.
This commission was authorized to issue “cease and desist” orders to large corporations to curb unfair trade practices. Some of the unfair methods of competition that were targeted include deceptive advertisements and pricing. It passed the Senate by a 43-5 vote on September 8, 1914; passed the House on September 10, without a tally of yeas and nays, and was signed into law by President Wilson on September 26.

</doc>
<doc id="55742" url="https://en.wikipedia.org/wiki?curid=55742" title="Federal Reserve Act">
Federal Reserve Act

The Federal Reserve Act (ch. 6, , enacted December 23, 1913, ) is an Act of Congress that created and established the Federal Reserve System, the central banking system of the United States, and which created the authority to issue Federal Reserve Notes (now commonly known as the U.S. Dollar) and Federal Reserve Bank Notes as legal tender. The Act was signed into law by President Woodrow Wilson.
The Act.
The Federal Reserve Act created a system of private and public entities. There were to be at least eight and no more than twelve private regional Federal Reserve banks. Twelve were established, and each had various branches, a board of directors, and district boundaries. The Federal Reserve Board, consisting of seven members, was created as the governing body of the Fed. Each member is appointed by the President of the United States and confirmed by the U.S. Senate. In 1935, the Board was renamed and restructured. Also created as part of the Federal Reserve System was a 12-member Federal Advisory Committee and a single new United States currency, the Federal Reserve Note. The Federal Reserve Act created a national currency and a monetary system that could respond effectively to the stresses in the banking system and create a stable financial system. With the goal of creating a national monetary system and financial stability, the Federal Reserve Act also provided many other functions and financial services for the economy, such as check clearing and collection for all members of the Federal Reserve.
With the passing of the Federal Reserve Act, Congress required that all nationally chartered banks become members of the Federal Reserve System. These banks were required to purchase specified non-transferable stock in their regional Federal Reserve banks, and to set aside a stipulated amount of non-interest bearing reserves with their respective reserve banks. Since 1980, all depository institutions have been required to set aside reserves with the Federal Reserve. Such institutions are entitled to certain Federal Reserve services. State chartered banks were given the option of becoming members of the Federal Reserve System and in the case of the exercise of such option were to be subject to supervision, in part, by the Federal Reserve System. Member banks became entitled to have access to discounted loans at the discount window in their respective reserve banks, to a 6% annual dividend in their Federal Reserve stock, and to other services.
Background.
Central banking has made various institutional appearances throughout the history of the United States. These institutions started with the First and Second banks of the United States, which were championed in large part by Alexander Hamilton.
The First Bank of United States.
The American financial system was deeply fragmented after the American Revolutionary War. The government was burdened with large wartime debts, and the new republic needed a strong financial institution to give the country a resilient financial footing. Alexander Hamilton and Thomas Jefferson had opposing views regarding whether or not the US could benefit from a European-style national financial institution. Hamilton was in favor of building a strong centralized political and economic institution to solve the country’s financial problem. He argued that a central bank could bring order to the US monetary system, manage the government’s revenues and payments, and provide credit to both the public and private sectors. On the other hand, Jefferson was deeply suspicious of a central bank because, he argued, it would undermine democracy. Jefferson and Southern members of congress also believed that a strong central financial institution would serve commercial interests of the north at the expense of Southern-based agriculture interests whose credit was provided by local banks during the post-revolutionary war era.
The First Bank of the United States was established in 1791 chartered for a period of twenty years. The US government was the largest shareholder of the bank. Despite its shareholder status, the government was not permitted to participate in management of the bank. The bank accepted deposits, issued bank notes, and provided short-term loans to the government. It also functioned as a clearinghouse for government debt. The bank could also regulate state-charted banks to prevent overproduction of banknotes. The bank was very successful in financing the government and stimulating the economy. In spite of its successes, hostility against the bank did not fade. Jeffersonians questioned the bank’s constitutionality. In 1811, the first bank of the United States failed to be renewed by one vote in both the House and the Senate.
The Second Bank of the United States.
After the War of 1812, economic instability necessitated the creation of a second national bank. Due to expanding money supply and lack of supervision, individual bank activity sparked high inflation. In 1816, a second national bank was created with a charter of twenty years. Three years later, during the panic of 1819 the second bank of the United States was blamed for overextending credit in a land boom, and would tighten up credit policies following the panic (Wiletnz, 2008).
The Second bank was unpopular among the western and southern state-chartered banks, and constitutionality of a national bank was questioned. President Jackson would come into office, and wished to end the current central bank during his presidency. Under the premise that the bank favored a small economic and political elite at the expense of the public majority, the Second Bank became private after its charter expired in 1836, and would undergo liquidation in 1841.
For nearly eighty years, the U.S. was without a central bank after the charter for the Second Bank of the United States was allowed to expire. After various financial panics, particularly a severe one in 1907, some Americans became persuaded that the country needed some sort of banking and currency reform that would, when threatened by financial panics, provide a ready reserve of liquid assets, and furthermore allow for currency and credit to expand and contract seasonally within the U.S. economy.
Some of this was chronicled in the reports of the National Monetary Commission (1909–1912), which was created by the Aldrich–Vreeland Act in 1908. Included in a report of the Commission, submitted to Congress on January 9, 1912, were recommendations and draft legislation with 59 sections, for proposed changes in U.S. banking and currency laws. The proposed legislation was known as the Aldrich Plan, named after the chairman of the Commission, Republican Senator Nelson W. Aldrich of Rhode Island.
The Plan called for the establishment of a National Reserve Association with 15 regional district branches and 46 geographically dispersed directors primarily from the banking profession. The Reserve Association would make emergency loans to member banks, print money, and act as the fiscal agent for the U.S. government. State and nationally chartered banks would have the option of subscribing to specified stock in their local association branch. It is generally believed that the outline of the Plan had been formulated in a secret meeting on Jekyll Island in November 1910, which Aldrich and other well connected financiers attended.
Since the Aldrich Plan gave too little power to the government, there was strong opposition to it from rural and western states because of fears that it would become a tool of bankers, specifically the Money Trust of NYC. Indeed, from May 1912 through January 1913 the Pujo Committee, a subcommittee of the House Committee on Banking and Currency, held investigative hearings on the alleged Money Trust and its interlocking directorates. These hearings were chaired by Rep. Arsene Pujo, a Democratic representative from Louisiana.
In the election of 1912, the Democratic Party won control of the White House and both chambers of Congress. The party's platform stated strong opposition to the Aldrich Plan. The platform also called for a systematic revision of banking laws in ways that would provide relief from financial panics, unemployment and business depression, and would protect the public from the "domination by what is known as the Money Trust." The final plan, however, was quite similar to the Aldrich Plan, with a few revisions. Sen. Carter Glass made these revisions, although the main premise of the Aldrich Plan was in there.
Legislative history of the Act.
The Federal Reserve Act was a part of the banking and currency reform plan advocated by President Wilson in 1912. The chairmen of the House and Senate Banking and Currency committees sponsored this legislation; Rep. Carter Glass, a Democrat of Virginia, and Senator Robert Latham Owen, a Democrat of Oklahoma. According to the House committee report accompanying the Currency bill (H.R. 7837) or the Glass-Owen bill, as it was often called during the time.
Attempts to reform currency and banking had been made in the United States prior H.R. 7837. The major first form of this type of legislation came through with the First Bank of the United States in 1791. Championed by Alexander Hamilton, this established a central bank that included in a three-part expansion of federal fiscal and monetary power (including federal mint and excise taxes). Attempts were made to extend this bank’s charter, but they would fail before the charters expiration in 1811, which would lead to the creation of the Second Bank of the United States. In 1816 the U.S. Congress chartered this Second bank for a twenty-year period to create irredeemable currency with which to pay for the costs of the War of 1812. The creation of congressionally authorized irredeemable currency by the Second Bank of the United States opened the door to the possibility of taxation by inflation. Congress did not want state-chartered banks as competition in the inflation of currency. The charter for the Second Bank would expire in 1836, leaving the U.S. without a central bank for nearly eighty years. The last major form of legislation preceding the Federal Reserve Act came in 1908 with the Aldrich-Vreeland Act, which was the initial response the Panic of 1907, and established the National Monetary Commission, which recommended the Federal Reserve act of 1913.
According to the House committee report accompanying the Currency bill (H.R. 7837) or the Glass-Owen bill, the legislation was drafted from ideas taken from various proposals, including the Aldrich bill. However, unlike the Aldrich plan, which gave controlling interest to private bankers with only a small public presence, the new plan gave an important role to a public entity, the Federal Reserve Board, while establishing a substantial measure of autonomy for the (regional) Reserve Banks which, at that time, were allowed to set their own discount rates. Also, instead of the proposed currency being an obligation of the private banks, the new Federal Reserve note was to be an obligation of the U.S. Treasury. In addition, unlike the Aldrich plan, membership by nationally chartered banks was mandatory, not optional. The changes were significant enough that the earlier opposition to the proposed reserve system from Progressive Democrats was largely appeased; instead, opposition to the bill came largely from the more business-friendly Republicans instead of from the Democrats. 
After months of hearings, debates, votes and amendments, the proposed legislation, with 30 sections, was enacted as the Federal Reserve Act.
Subsequent amendments.
The Federal Reserve act has undergone many amendments after its implementation. Early, bureaucratic amendments were made to account for states like Hawaii and Alaska’s admission to the union; such as district restructuring and jurisdiction specifications.
Charter extension.
The Federal Reserve Act was originally granted a twenty-year charter, to be renewed in 1933. This clause was amended on February 25, 1927: "To have succession after the approval of this Act until dissolved by Act of Congress or until forfeiture of franchise for violation of law." 12 U.S.C. ch. 3. As amended by act of Feb. 25, 1927 (44 Stat. 1234). The success of this amendment is notable, as in 1933, the US was in the throes of the Great Depression and public sentiment with regards to the Federal Reserve System and the banking community in general had significantly deteriorated. Given the political climate, including of Franklin D. Roosevelt’s administration and New Deal legislation, it was uncertain whether the Federal Reserve System would survive.
The Federal Open Market Committee.
In 1933, by way of the Banking Act of 1933, the Federal Reserve Act was amended to create the Federal Open Market Committee (FOMC), which consists of the seven members of the Board of Governors of the Federal Reserve System and five representatives from the Federal Reserve Banks. The FOMC is required to meet at least four times a year (in practice, the FOMC usually meets eight times) and has the power to direct all open-market operations of the Federal Reserve banks.
12 USC § 225a.
On November 16, 1977, the Federal Reserve Act was amended to require the Board and the FOMC "to promote effectively the goals of maximum employment, stable prices, and moderate long-term interest rates." This same amendment stated that the member governor proposed by the President to be Chairman would have a four-year term as Chairman and would be subject to confirmation by the Senate (member governors per se each have 14 year terms, with a specific term ending every two years). The Chairman was also required to appear before Congress at semi-annual hearings to report on the conduct of monetary policy, on economic development, and on the prospects for the future.
The Federal Reserve Act has been amended by some 200 subsequent laws of Congress. It continues to be one of the principal banking laws of the United States.
Implications and impacts of the Federal Reserve Act.
The passing of the Federal Reserve act of 1913 carried implications both domestically and internationally for the United States economic system. The absence of a central banking structure in the U.S. previous to this act left a financial essence that was characterized by immobile reserves and inelastic currency. The Federal Reserve Act also permitted national banks to make mortgage loans for farm land, which had not been permitted previously.
Criticisms of the Act.
Throughout the history of the United States, there has been an enduring economic and political debate regarding the costs and benefits of central banking. Since the inception of a central bank in the United States, there were multiple opposing views to this type of economic system. Opposition was based on protectionist sentiment; a central bank would serve a handful of financiers at the expense of small producers, businesses, farmers and consumers, and could destabilize the economy through speculation and inflation. This created even further controversy over who would select the decision-makers in charge of the Federal Reserve. Proponents argued that a strong banking system could provide enough credit for a growing economy and avoid economic depressions. Other critical views included the belief that the bill gave too much power to the federal government after the senate revised the bill to create 12 board members who were each appointed by the president.
Preceding the creation of the Federal Reserve, no U.S. central banking systems lasted for more than 25 years. Some of the questions raised include: whether Congress has the Constitutional power to delegate its power to coin money or issue paper money, whether the structure of the federal reserve is transparent enough, whether the Federal Reserve is a public Cartel of private banks (also called a banking cartel) established to protect powerful financial interests, fears of inflation, high government deficits, and whether the Federal Reserve's actions increased the severity of the Great Depression in the 1930s. However, the debate over the right to coin money was minimal due to the fact the US government had already done this in the past.

</doc>
<doc id="55744" url="https://en.wikipedia.org/wiki?curid=55744" title="Mann Act">
Mann Act

The White-Slave Traffic Act, better known as the Mann Act, is a United States federal law, passed June 25, 1910 (ch. 395, ; "codified as amended at" ).
It is named after Congressman James Robert Mann of Illinois, and in its original form made it a felony to engage in interstate or foreign commerce transport of "any woman or girl for the purpose of prostitution or debauchery, or for any other immoral purpose". Its primary stated intent was to address prostitution, "immorality", and human trafficking particularly where it was trafficking for the purposes of prostitution. This is one of several acts of protective legislation aimed at moral reform during the progressive era. Its ambiguous language of "immorality" meant it could be used to criminalize consensual sexual behavior between adults. It was amended by Congress in 1978 and again in 1986 to apply to transport for the purpose of prostitution or illegal sexual acts. It is commonly thought that this legislation came to be due to racial bias against boxer John Arthur "Jack" Johnson.
Promotion.
In the 19th century, most of America's cities had a designated, legally protected area of prostitution. Increased urbanization and young women entering the workforce led to greater flexibility in courtship without supervision. It is in this changing social sphere that the panic over "white slavery" began. This term referred to women being kidnapped for the purposes of prostitution.
Numerous communities appointed vice commissions to investigate the extent of local prostitution, whether prostitutes participated in it willingly or were forced into it and the degree to which it was organized by any cartel-type organizations. The second significant action at the local levels was to close the brothels and the red light districts. From 1910 to 1913, city after city withdrew this tolerance and forced the closing of their brothels. Opposition to openly practiced prostitution had been growing steadily throughout the last decades of the 19th century. The federal government's response to the moral panic was the Mann Act. The purpose of the act was to make it a crime to coerce transportation of unwilling women. The statute made it a crime to "transport or cause to be transported, or aid to assist in obtaining transportation for" or to "persuade, induce, entice or coerce" a woman to travel. Many of the changes that occurred after 1900 were a result of tensions between family ideals and practical realities. Family form and functions changed in response to a complex set of circumstances which were the effects of economic class and ethnicity.
According to historian Mark Thomas Connelly, "a group of books and pamphlets appeared announcing a startling claim: a pervasive and depraved conspiracy was at large in the land, brutally trapping and seducing American girls into lives of enforced prostitution, or 'white slavery.' These white slave narratives, or white-slave tracts, began to circulate around 1909." Such narratives often portrayed innocent girls "victimized by a huge, secret and powerful conspiracy controlled by foreigners", as they were drugged or imprisoned and forced into prostitution.
This excerpt from "The War on the White Slave Trade" was written by the United States District Attorney in Chicago:
According to Connelly, such concerns represented a "hysterical" version of genuine and long-standing issues arising from the concentration of young women from rural backgrounds in the expanding cities of the era, many of whom were drawn into prostitution for "mundane" economic reasons. A number of Vice Commission reports had drawn attention to the issue. Some contemporaries questioned the idea of abduction and foreign control of prostitution through cartels. For example, noted radical and feminist Emma Goldman asked "What is really the cause of the trade in women? Not merely white women, but yellow and black women as well. Exploitation, of course; the merciless Moloch of capitalism that fattens on underpaid labor, thus driving thousands of women and girls into prostitution. With Mrs. Warren these girls feel, 'Why waste your life working for a few shillings a week in a scullery, eighteen hours a day?'... Whether our reformers admit it or not, the economic and social inferiority of woman is responsible for prostitution." While prostitution was widespread, contemporary studies by local vice commissions indicate that it was "overwhelmingly locally organized without any large business structure, and willingly engaged in by the prostitutes."
Suffrage activists, especially Harriet Burton Laidlaw and Rose Livingston, took up these concerns. They worked in New York City's Chinatown and in other cities to rescue young white and Chinese girls from forced prostitution, and helped pass the Mann Act to make interstate sex trafficking a federal crime. Livingston publicly discussed her past as a prostitute and claimed to have been abducted and developed a drug problem as a sex slave in a Chinese man's home, narrowly escaped and experienced a Christian conversion narrative. Her story in several ways exemplifies the stereotypes used to pass the Mann Act- fear of foreigners, especially Jewish, Italian or Asian men, abduction and drugging in order to be raped and enslaved, a narrow escape and salvation through Christian conversion. Other groups like the Woman's Christian Temperance Union and Hull House focused on children of prostitutes and poverty in community life while trying to pass protective legislation. The American Purity Alliance also supported the Mann Act.
The 1921 Convention set new goals for international efforts to stem human trafficking, primarily by giving the anti-trafficking movement further official recognition, as well as a bureaucratic apparatus to research and fight the problem. The Advisory Committee on the Traffic of Women and Children was a permanent advisory committee of the League. Its members were nine countries, and several non-governmental organizations. An important development was the implementation of a system of annual reports of member countries. Member countries formed their own centralized offices to track and report on trafficking of women and children. The advisory committee also worked to expand its research and intervention program beyond the United States and Europe. In 1929, a need to expand into the Near East (Asia Minor), the Middle East and Asia was acknowledged. An international conference of central authorities in Asia was planned for 1937, but no further action was taken during the late 1930s.
Legal application.
Although the law was created to stop forced sexual slavery of women, the most common use of the Mann Act was to prosecute men for having sex with under-age females. The phrase "immoral purpose" in the statute allowed an extremely broad application of the law following the United States Supreme Court ruling in "Caminetti v. United States" (1917), which held that "illicit fornication" even when consensual constituted an "immoral purpose." The law was also frequently used to prosecute interracial and unapproved pre-marital and extra-marital relationships in addition to its stated purpose of preventing human trafficking. The penalties would be applied to men whether or not the woman involved consented and if she did the woman could be considered an accessory to the offense. There was also a strong racial bias against black men with white women such as in the case of Jack Johnson. It was also used to harass others who had drawn the authorities' wrath for "immoral" or controversial behavior.
During the Jim Crow era, a time of racism and discrimination against African Americans, many white were furious that a black man, Jack Johnson, was publicly open about having interracial sex with white women. It is known that Johnson would be intimate with white women (some of whom he met at the fighting venue) after his fights and during the Jim Crow era, a period in United States history when these sort of relations were not publicly accepted. To prevent Johnson (who had a higher status than any other sports figure at that time) from the "immoral purpose" of defiling white women, whom he would pick up during his reign as World Heavyweight Champion (1908–1915) the Mann Act of 1912 was enacted and later in that very year Jack Johnson would be prosecuted and convicted for "transporting women across state lines for immoral purposes" due to his relationship with Lucille Cameron (his caucasian wife).
For instance, the 1948 prosecution of Frank LaSalle for abducting Florence Sally Horner is believed to have been an inspiration for Vladimir Nabokov in writing his novel "Lolita". The Mann Act has also been used by the U.S. federal government to prosecute polygamists such as Mormon fundamentalists because there is no federal U.S. law against polygamy. All U.S. states have anti-polygamy laws, but it has only been in recent years that state authorities have used them to prosecute bigamy. Colorado City, Arizona; and Hildale, Utah; Bountiful, British Columbia; and sites in Mexico are historic locations of several Mormon Fundamentalist sects. Mormon fundamentalist leaders and individuals have been charged under the Mann Act when "wives" are transported across the Utah–Arizona state line or the U.S.–Canadian and U.S.–Mexican borders.
Congressional amendments to the law.
In 1978, Congress updated the act's definition of "transportation" and added protections against commercial sexual exploitation for minors. It added a 1986 amendment which further protected minors and added protection for adult males. In particular, as part of a larger 1986 bill focused on criminalizing various aspects of child pornography that passed unanimously in both houses of Congress, the Mann act was further amended to replace the ambiguous "debauchery" and "any other immoral purpose" with the more specific "any sexual activity for which any person can be charged with a criminal offense" as well as to make it gender-neutral.
Effects and alterations of the Mann Act.
While the Mann Act was meant to combat forced prostitution, it had repercussions that extended into consensual sexual activity. Because the Mann Act lacked specificity, it criminalized many who were not participating in prostitution. It became a way to persecute many unmarried couples participating in premarital or extramarital activities, especially when it involved crossing state lines such as in the cases for Chuck Berry and Jack Johnson. The Mann Act also became a form of blackmail, by wives suspicions of cheating husbands and other women alike. This was the case for both Drew Caminetti and Maury Diggs. Both men from Sacramento, California, were married and took their mistresses Lola Norris and Marsha Warrington to Reno, Nevada. The men's wives contacted the police, and they were then arrested in Reno, and found guilty under the Mann Act. One author wrote:
In 1914 a woman by the name of Jessie A. Cope was arrested in Chicago for attempting to bribe an official to assist her in the blackmail of Colonel Charles Alexander of Providence Rhode Island, on a white slavery charge. The two had met two years previous in LA, Alexander had promised to divorce his wife, and marry her. When he attempted to leave her, Cope and her mother pursued him to Providence. Cope consulted lawyers in Providence and LA, then brought the charges in Chicago, where she was arrested.
Upon continuous blackmail accounts, "The New York Times" became an advocate against the Mann Act:
In 1915 the paper published an editorial pointing out how the act led to extortion. In 1916 it labeled the Mann Act "The Blackmail Act", noting that its dangers had been clear from the start. The act made a harmless spree or simple elopement a crime, and the blackmail that resulted from the Mann Act was worse than the prostitution it sought to suppress.
While the Mann Act has never been repealed, it has been amended and altered since its initial passing. The Mann Act continued essentially unchanged until 1978 and expanded coverage to issues around child pornography and exploitation. Most recently, in 1986, The Mann Act was significantly altered, making the whole Act gender neutral, making the transportation of "any person" and changed the wording to "any sexual activity for which any person can be charged with a criminal offense" illegal. Since sodomy was illegal until "Lawrence v. Texas" (2003), the law would also apply to consenting adult gay couples, although rarely enforced in this way. Since 1978 most convictions have been related to child abuse and child trafficking cases.

</doc>
<doc id="55745" url="https://en.wikipedia.org/wiki?curid=55745" title="Mann–Elkins Act">
Mann–Elkins Act

The Mann–Elkins Act was a 1910 United States federal law that was among the Progressive era reforms. Progressives also regulated shipping prices and filed criminal actions for the railroads. The Act extended the authority of the Interstate Commerce Commission (ICC) to regulate the telecommunications industry, and designated telephone, telegraph and wireless companies as common carriers. During William H. Taft's administration, the federal government moved to strengthen its regulatory control over the railroad industry by the passage of the Mann–Elkins Act.
Supported by President William Howard Taft, the law also expanded on the powers granted to the ICC in the 1906 Hepburn Act. The ICC was authorized to investigate proposed railroad rate increases and suspend them if warranted. The "long-and-short haul" clause of the original Interstate Commerce Act (1887) was strengthened to prohibit railroads from charging passengers more for a short distance trip, compared to a longer distance ride, over the same route, unless specifically approved by the ICC.
The Act also created the short-lived United States Commerce Court for adjudication of railway disputes. The Court presided until 1913, when it was abolished by Congress.
Legislative history.
It was passed by the United States Senate, 50-12.

</doc>
<doc id="55751" url="https://en.wikipedia.org/wiki?curid=55751" title="Agricultural Marketing Act of 1929">
Agricultural Marketing Act of 1929

The Agricultural Marketing Act of 1929, under the administration of Herbert Hoover, established the Federal Farm Board from the Federal Farm Loan Board established by the Federal Farm Loan Act of 1916 with a revolving fund of half a billion dollars. The original act was sponsored by Hoover in an attempt to stop the downward spiral of crop prices by seeking to buy, sell and store agricultural surpluses or by generously lending money to farm organizations. Money was lent out to the farmers in order to buy seed and food for the livestock, which was especially important since there had previously been a drought in the Democratic South. However, Hoover refused to lend to the farmers themselves, as he thought that it would be unconstitutional to do so and if they were lent money, they would become dependent on government money.
Effects.
The Federal Farm Board's purchase of surplus could not keep up with the production; as farmers realized that they could just sell the government their crops, they reimplemented the use of fertilizers and other techniques to increase production. Overall, the deflation could not be countered because of a massive fault in the bill: there was no production limit. Had there been a production limit, the deflation might have been helped somewhat. The funds appropriated were eventually exhausted and the losses of the farmers kept rising.
The H.R. 1 legislation was passed by the 71st Congressional session and enacted by the 31st President of the United States Herbert Hoover on June 15, 1929.
The Act was the precursor to the Agricultural Adjustment Act.

</doc>
<doc id="55752" url="https://en.wikipedia.org/wiki?curid=55752" title="Indian Reorganization Act">
Indian Reorganization Act

The Indian Reorganization Act of June 18, 1934, or the Wheeler-Howard Act, was U.S. federal legislation that dealt with the status of Native Americans (known in law as American Indians or Indians). It was the centerpiece of what has been often called the "Indian New Deal." The major goal was to reverse the traditional goal of assimilation of Indians into American society, and to strengthen, encourage and perpetuate the tribes and their historic traditions and culture. 
The Act also restored to Indians the management of their assets—land and mineral rights—and included provisions intended to create a sound economic foundation for the inhabitants of Indian reservations. The law did not apply to Hawaii; Alaska and Oklahoma were added under another law in 1936. (Native American tribes in Oklahoma had their land allotted and land title extinguished, so did not have any reservations left.) The census counted 332,000 Indians in 1930 and 334,000 in 1940, including those on and off reservations in the 48 states. Total spending on Indians averaged $38 million a year in the late 1920s, dropping to a low of $23 million in 1933, and reaching $38 million in 1940.
The IRA was the most significant initiative of John Collier, who was President Franklin D. Roosevelt's Commissioner of the Bureau of Indian Affairs (BIA) from 1933 to 1945. He had long studied Indian issues and worked for change since the 1920s, particularly with the American Indian Defense Association. He intended to reverse the assimilationist policies that had resulted in considerable damage to Native American cultures, and to provide a means for American Indians to re-establish sovereignty and self-government, to reduce the losses of reservation lands, and to build economic self-sufficiency. He believed that Indian traditional culture was superior to that of modern America, and thought it worthy of emulation. His proposals were considered highly controversial, as numerous powerful interests had profited from the sale and management of Native lands. Congress revised Collier's proposals and preserved oversight of tribes and reservations by the Bureau of Indian Affairs within the Department of Interior. 
The self-government provisions would automatically go into effect for a tribe unless a clear majority of the eligible Indians voted it down. When approved, a tribe would adopt a variation of the model constitution drafted by BIA lawyers. Of the tribes that voted on the IRA, 174 voted yes and 78 rejected it.
History of IRA.
Background.
At the time the Act passed, it was United States policy to eliminate Indian reservations, dividing the communal territory and allotting 160-acre plots to individual heads of households, to be owned in severalty. Before allotment, reservation territory was not owned in the usual European-American sense, but was reserved for the benefit of entire Indian tribes. The communal benefits were apportioned to tribe members according to tribal law and custom. Generally, Indians held the land in a communal fashion. Non-Indians were not allowed to own land on reservations, a fact which limited the value of the land to the Indians. (It reduced the market for it).
The process of allotment started with the General Allotment Act of 1887. By 1934, two thirds of Indian land had converted to traditional private ownership (i.e. it was owned in fee simple). Most of that had been sold by Indian allottees, often because they had no means to pay local taxes on the lands, for which they were newly responsible. The IRA provided a mechanism for the recovery of land that had been sold—including land that had been sold to tribal Indians. They would lose individual property under the law. 
John Collier was appointed Commissioner of the Indian Bureau (it is now called the Bureau of Indian Affairs, BIA) in April 1933 by President Franklin Delano Roosevelt. He had the full support of his boss, Secretary of the Interior Harold L. Ickes, who was also an expert on Indian issues.
The federal government held land in trust for many tribes. Numerous claims cases had been presented to Congress because of failures in the government's management of such lands. There were particular grievances and claims due to the government's failure to provide for sustainable forestry. The Indian Claims Act included a requirement that the Interior Department manage Indian forest resources "on the principle of sustained-yield management." Representative Edgar Howard of Nebraska, co-sponsor of the Act and Chairman of the House Committee on Indian Affairs, explained that the purpose of the provision was "to assure a proper and permanent management of the Indian Forest" under modern sustained-yield methods so as to "assure that the Indian forests will be permanently productive and will yield continuous revenues to the tribes."
Implementation and results.
The act slowed the practice of allotting communal tribal lands to individual tribal members. It did not restore to Indians land that had already been patented to individuals, but much land at the time was still unallotted or was allotted to an individual but still held in trust for that individual by the U.S. government. Because the Act did not disturb existing private ownership of Indian reservation lands, it left reservations as a checkerboard of tribal or individual trust and fee land, which remains the case today. .
However, the Act also allowed the U.S. to purchase some of the fee land and restore it to tribal trust status. Due to the Act and other actions of federal courts and the government, more than two million acres (8,000 km²) of land were returned to various tribes in the first 20 years after passage.
In 1954, the United States Department of the Interior (DOI) began implementing the termination and relocation phases of the Act, which had been added by Congress. These provisions were the result of the continuing interest by some members of Congress in having American Indians assimilate to the majority society. Among other effects, termination resulted in the legal dismantling of 61 tribal nations within the United States and ending their recognized relationships with the federal government. This also ended the eligibility of the tribal nations and their members for various government programs to assist American Indians.
Constitutional challenges.
Since the late 20th century and the rise of Indian activism over sovereignty issues, as well as many tribes' establishment of casino gambling on reservations as a revenue source, the US Supreme Court has been repeatedly asked to address the IRA's constitutionality. The provision of the Act that is controversial is the one that allows the US government to acquire non-Indian land (by voluntary transfer) and convert it to Indian land ("take it into trust"). In so doing, the US government partially removes the land from the jurisdiction of the state, which makes certain activities, such as casino gambling, possible on the land for the first time. It also makes the land exempt from state property taxes and some other state taxes. Consequently, many people oppose implementation of this part of the Act and, typically represented by state or local governments, they sue to prevent it.
In 1995, South Dakota challenged the authority of the Interior Secretary, under the IRA, to take of land into trust on behalf of the Lower Brule Sioux Tribe (based on the Lower Brule Indian Reservation), in "South Dakota v. United States Dep't of the Interior", 69 F.3d 878, 881-85 (8th Cir. 1995). The Eighth Circuit Court of Appeals found Section 5 of the IRA to be unconstitutional, ruling that it violated the non-delegation doctrine and that the Secretary of Interior did not have the authority to take the land into trust.
The US Department of the Interior (DOI) sought U.S. Supreme Court review. But, as DOI was implementing new regulations related to land trusts, the agency asked the Court to remand the case to the lower court, to be reconsidered with the decision to be based on the new regulations. The US Supreme Court granted Interior's petition, vacated the lower court's ruling, and remanded the case back to the lower court.
Justices Scalia, O'Connor and Thomas dissented, stating that "decision today—to grant, vacate, and remand in light of the Government's changed position—is both unprecedented and inexplicable." They went on, "[What makes today's action inexplicable as well as unprecedented is the fact that the Government's change of legal position does not even purport to be applicable to the present case." Seven months after the Supreme Court's decision to grant, vacate, and remand, the DOI removed the land in question from trust.
In 1997, the Lower Brulé Sioux submitted an amended trust application to DOI, requesting that the United States take the of land into trust on the Tribe's behalf. South Dakota challenged this in 2004 in district court, which upheld DOI's authority to take the land in trust. The state appealed to the Eighth Circuit, but when the court reexamined the constitutionality issue, it upheld the constitutionality of Section 5 in agreement with the lower court. The US Supreme Court denied the State's petition for "certiorari". Since then, district and circuit courts have rejected non-delegation claims by states. The Supreme Court refused to hear the issue in 2008.
In 2008 (before the US Supreme Court heard the "Carcieri" case below), in "MichGO v Kempthorne", Judge Janice Rogers Brown of the D.C. Circuit Court of Appeals wrote a dissent stating that she would have struck down key provisions of the IRA. Of the three circuit courts to address the IRA's constitutionality, Judge Brown is the only judge to dissent on the IRA's constitutionality. The majority opinion upheld its constitutionality. The U.S. Supreme Court did not accept the "MichGO" case for review, thus keeping the previous precedent in place. The First, Eighth and Tenth Circuits of the U.S. Court of Appeals have upheld the constitutionality of the IRA.
In 2008, "Carcieri v Kempthorne" was argued before the U.S. Supreme Court; the Court ruled on it in 2009, with the decision called "Carcieri v. Salazar". In 1991, the Narragansett Indian tribe bought of land. They requested that the DOI take it into trust, which the agency did in 1998, thus exempting it from many state laws. The State was concerned that the tribe would open a casino or tax-free business on the land and sued to block the transfer. The state argued that the IRA did not apply because the Narragansett was not "now under federal jurisdiction" as of 1934, as distinguished from "federally recognized." In fact, the Narragansett had been placed under Rhode Island guardianship since 1709. In 1880, the tribe relinquished its tribal authority to Rhode Island. The tribe did not receive federal recognition until 1980, after the 1934 passage of the IRA. The US Supreme Court agreed with the State.
In a challenge to the U.S. DOI's decision to take land into trust for the Oneida Indian Nation in present-day New York, Upstate Citizens for Equality (UCE), New York, Oneida County, Madison County, the town of Verona, the town of Vernon, and others argue that the IRA is unconstitutional. Most recently, Judge Kahn dismissed UCE's complaint, including the failed theory that the IRA is unconstitutional, on the basis of longstanding and settled law on this issue.
Approval by tribes.
Section 18 of the IRA required that members of the affected Indian nation or tribe vote on whether to accept it within one year of the effective date of the act (25 U.S.C. 478), and had to approve it by a majority. There was confusion about who should be allowed to vote on creating new governments, as many non-Indians lived on reservations many Indians owned no land there, and also over the effect of abstentions.
Under the voting rules, abstentions were counted as yes votes, but in Oglala Lakota culture, for example, abstention had traditionally equaled a no vote. The resulting confusion caused disputes on many reservations about the results.
When the final results were in, 172 tribes had accepted the act, and 73 had rejected it. The largest tribe, the Navajo, had been badly hurt by the federal Navajo Livestock Reduction Program, which took away half their livestock and jailed dissenters. They strongly opposed the act, John Collier the chief promoter, and the entire Indian New Deal. Historian Brian Dippie notes that the Indian Rights Association denounced Collier as a 'dictator' and accused him of a "near reign of terror" on the Navajo reservation. Dippie adds that, "He became an object of 'burning hatred' among the very people whose problems so preoccupied him."
Legacy.
Historians have mixed reactions to the Indian New Deal. Many praise Collier's energy and his initiative. Philp praised Collier's Indian New Deal for protecting Indian freedom to engage in traditional religious practices, obtaining additional relief money for reservations, providing a structure for self-government, and enlisting the help of anthropologists who respected traditional cultures. However, he concludes that the Indian New Deal was unable to stimulate economic progress nor did it provide a usable structure for Indian politics. Philp argues these failures gave ammunition to the return to the previous policy of termination that took place after Collier resigned in 1945. In surveying the scholarly literature, Schwartz concludes that there is:
Collier's reputation among the Indians was mixed—praised by some, vilified by others. He antagonized the Navajo, the largest tribe as well as the Seneca people, Iroquois, and many others. Anthropologists criticized him for not recognizing the diversity of Native American lifestyles. Hauptman argues that his emphasis on Northern Pueblo arts and crafts and the uniformity of his approach to all tribes are partly explained by his belief that his tenure as Commissioner would be short, meaning that packaging large, lengthy legislative reforms seemed politically necessary.
The Reorganization Act was wide-ranging legislation authorizing tribal self-rule under federal supervision, putting an end to land allotment and generally promoting measures to enhance tribes and encouraging education.
Having described the American society as "physically, religiously, socially, and aesthetically shattered, dismembered, directionless", Collier was later criticized for his romantic views about the moral superiority of traditional society as opposed to modernity. Philp says after his experience at the Taos Pueblo, Collier "made a lifelong commitment to preserve tribal community life because it offered a cultural alternative to modernity...His romantic stereotyping of Indians often did not fit the reality of contemporary tribal life."
The act has helped conserve the communal tribal land bases. Collier supporters blame Congress for altering the legislation proposed by Collier, so that it has not been as successful as possible. On many reservations, its provisions exacerbated longstanding differences between traditionals and those who had adopted more European-American ways. Many Native Americans believe their traditional systems of government were better for their culture.

</doc>
<doc id="55755" url="https://en.wikipedia.org/wiki?curid=55755" title="Fordney–McCumber Tariff">
Fordney–McCumber Tariff

The Fordney–McCumber Tariff of 1922 was a law that raised American tariffs on many imported goods in order to protect factories and farms. Congress displayed a pro-business attitude in passing the tariff and in promoting foreign trade through providing huge loans to Europe, which in turn bought more American goods. The Roaring Twenties brought a period of sustained economic prosperity with an end to the Depression of 1920–21; the prosperity ended in late 1929, and the tariff was revised in 1930.
Background.
The first sector of the economy that was hit by a fall in post-war demand was agriculture. During World War I, the American agricultural industry enjoyed prosperity, through the raising of prices which led to increased output which Americans used to supply Europe. Farmers borrowed heavily to expand their acreage; they had difficulty paying back the loans when prices fell. Some of the post war problems for the American agriculture come from the great surplus of farm goods that could not be absorbed in the national market, because European countries had recovered sufficiently from the war, and their markets no longer required large quantities of American agricultural products. Gross farm income in 1919 amounted to $17.7 billion. By 1921, exports to Europe had plummeted and farm income fell to $10.5 billion. Other sectors of the economy wanted to avoid a similar fate. The 1920 election put the conservative pro-business and pro-farm Republicans in control of Congress and the White House.
The hearings held by Congress led to the creation of several new tools of protection. The first was the "scientific tariff". The purpose of the scientific tariff was to equalize production costs among countries so that no country could undercut the prices charged by American companies. The difference of production costs was calculated by the Tariff Commission.
A second novelty was the "American Selling Price". This allowed the president to calculate the duty based on the price of the American price of a good, not the imported good.
The bill also gave the president the power to raise or lower rates on products if it was recommended by the Tariff Commission.
In September 1922, the Fordney–McCumber Tariff bill (named after Joseph Fordney, chair of the House Ways and Means Committee, and Porter McCumber, chair of the Senate Finance Committee) was signed by President Warren Harding. In the end, the tariff law raised the American ad valorem tariff rate to an average of about 38.5 percent for dutiable imports and an average of 14% overall. The measure was defensive tariff rather than an offensive. An ad valorem tariff was determined by the cost of production and market value.
Economic effects.
The Roaring Twenties brought a sustained period of economic prosperity principally to North America, but also to London, Berlin and Paris, with the end of the Depression of 1920-21 in the U.S. and a robust American economy. For agriculture, the tariff raised the purchasing power of the farmers by two to three percent, with other industries raising the price of some farm equipment. In September 1926, economic statistics were released by farming groups that revealed the rising cost of farm machinery. For example, the average cost of a harness rose from $46 in 1918 to $75 in 1926, the 14-inch plow doubled in cost from $14 to $28, mowing machines went from $45 to $95, and farm wagons from $85 to $150.
Reaction.
The tariff was supported by the Republican party and conservatives and was generally opposed by the Democratic Party and liberal progressives. One intent of the tariff was to help those returning from World War I have greater job opportunities. Trading partners complained immediately. European nations affected by World War I sought access for their exports to the American market to make payments to the U.S. for war loans. Democratic Representative Cordell Hull said, "Our foreign markets depend both on the efficiency of our production and the tariffs of countries in which we would sell. Our own tariffs are an important factor in each. They injure the former and invite the latter."
Five years after the passage of the tariff, American trading partners had raised their own tariffs by a significant degree. France raised its tariffs on automobiles from 45% to 100%, Spain raised tariffs on American goods by 40%, and Germany and Italy raised tariffs on wheat.
In 1928, Henry Ford attacked the Fordney–McCumber Tariff, arguing that the American automobile industry did not need protection since it dominated the domestic market, and their interest was in expanding foreign sales.
Some farmers opposed the Fordney- McCumber Tariff, blaming it for the agricultural depression. The American Farm Bureau Federation claimed that because of the tariff, the raised price of raw wool cost to farmers $27 million. Democratic Senator David Walsh challenged the tariff by arguing that the farmer is the net exporter and does not need protection because they depend on foreigner markets to sell their surplus. The Senator pointed out that during the first year of the tariff the cost of living climbed higher than any other year except during the war, presenting a survey of the Department of Labor, in which all of 32 cities assessed had seen an increase in the cost of living. For example, the food costs increased 16.5% in Chicago and 9.4% in New York. Clothing prices raised by 5.5% in Buffalo, New York, and 10.2% in Chicago. Republican Frank W. Murphy, head of the Minnesota Farm Bureau, also claimed that the problem was not in the world price of farm products, but in the things farmers had to buy. Republican Congressman W. R. Green, chairman of the House Ways and Means Committee, acknowledged that the statistics of the Bureau of Research of the American Farm Bureau that showed farmers had lost more than $300 million annually as a result of the tariff.

</doc>
<doc id="55757" url="https://en.wikipedia.org/wiki?curid=55757" title="Shepard tone">
Shepard tone

A Shepard tone, named after Roger Shepard, is a sound consisting of a superposition of sine waves separated by octaves. When played with the base pitch of the tone moving upward or downward, it is referred to as the "Shepard scale". This creates the auditory illusion of a tone that continually ascends or descends in pitch, yet which ultimately seems to get no higher or lower. It has been described as a "sonic barber's pole".
Construction.
Each square in the figure indicates a tone, with any set of squares in vertical alignment together making one Shepard tone. The color of each square indicates the loudness of the note, with purple being the quietest and green the loudest. Overlapping notes that play at the same time are exactly one octave apart, and each scale fades in and fades out so that hearing the beginning or end of any given scale is impossible. As a conceptual example of an ascending Shepard scale, the first tone could be an almost inaudible C(4) (middle C) and a loud C(5) (an octave higher). The next would be a slightly louder C(4) and a slightly quieter C(5); the next would be a still louder D(4) and a still quieter D(5). The two frequencies would be equally loud at the middle of the octave (F), and the eleventh tone would be a loud B(4) and an almost inaudible B(5) with the addition of an almost inaudible B(3). The twelfth tone would then be the same as the first, and the cycle could continue indefinitely. (In other words, each tone consists of two sine waves with frequencies separated by octaves; the intensity of each is a gaussian function of its separation in semitones from a peak frequency, which in the above example would be B(4).)
The acoustical illusion can be constructed by creating a series of overlapping ascending or descending scales. Similar to the Penrose stairs optical illusion (as in M. C. Escher's lithograph "Ascending and Descending") or a barber's pole, the basic concept is shown in Figure 1.
The scale as described, with discrete steps between each tone, is known as the discrete Shepard scale. The illusion is more convincing if there is a short time between successive notes (staccato or marcato instead of legato or portamento).
Jean-Claude Risset subsequently created a version of the scale where the tones glide continuously, and it is appropriately called the continuous Risset scale or Shepard–Risset glissando. When done correctly, the tone appears to rise (or descend) continuously in pitch, yet return to its starting note. Risset has also created a similar effect with rhythm in which tempo seems to increase or decrease endlessly.
The tritone paradox.
A sequentially played pair of Shepard tones separated by an interval of a tritone (half an octave) produces the tritone paradox. In this auditory illusion, first reported by Diana Deutsch in 1986, the scales may be heard as either descending or ascending. Shepard had predicted that the two tones would constitute a bistable figure, the auditory equivalent of the Necker cube, that could be heard ascending or descending, but never both at the same time. Deutsch later found that perception of which tone was higher depended on the absolute frequencies involved, and that different listeners may perceive the same pattern as being either ascending or descending.

</doc>
<doc id="55758" url="https://en.wikipedia.org/wiki?curid=55758" title="Emergency Quota Act">
Emergency Quota Act

__NOTOC__
The Emergency Quota Act, also known as the Emergency Immigration Act of 1921, the Immigration Restriction Act of 1921, the Per Centum Law, and the Johnson Quota Act (ch. 8, of May 19, 1921) restricted immigration into the United States. Although intended as temporary legislation, the Act "proved in the long run the most important turning-point in American immigration policy" because it added two new features to American immigration law: numerical limits on immigration and the use of a system for establishing those limits. These limits came to be known as the National Origins Formula.
The Emergency Quota Act restricted the number of immigrants admitted from any country annually to 3% of the number of residents from that same country living in the United States as of the U.S. Census of 1910. This meant that people from northern European countries had a higher quota and were more likely to be admitted to the U.S. than people from eastern Europe, southern Europe, or other, non-European countries. Professionals were to be admitted without regard to their country of origin. The Act set no limits on immigration from Latin America. The act did not apply to countries with bilateral agreements with the US, or to Asian countries listed in the Immigration Act of 1917, known as the Asiatic Barred Zone Act.
Based on that formula, the number of new immigrants admitted fell from 805,228 in 1920 to 309,556 in 1921-22. The average annual inflow of immigrants prior to 1921 was 175,983 from Northern and Western Europe, and 685,531 from other countries, principally Southern and Eastern Europe. In 1921, there was a drastic reduction in immigration levels from other countries, principally Southern and Eastern Europe.
Following the end of World War I, both Europe and the United States were suffering economic and social upheaval. In Europe, the destruction of the war, the Russian Revolution, and the dissolution of both the Austro-Hungarian Empire and Ottoman Empire led to greater immigration to the United States, while in the United States an economic downturn following post-war demobilization increased unemployment. The combination of increased immigration from Europe at the time of higher American unemployment strengthened the anti-immigrant movement.
The act, sponsored by Rep. Albert Johnson (R-Washington), was passed without a recorded vote in the U.S. House of Representatives and by a vote of 90-2-4 in the U.S. Senate. 
The Act was revised by the Immigration Act of 1924.
The use of such a National Origins Formula continued until 1965 when the Immigration and Nationality Act of 1965 replaced it with a system of preferences based on immigrants' skills and family relationships with U.S. citizens or U.S. residents.

</doc>
<doc id="55759" url="https://en.wikipedia.org/wiki?curid=55759" title="Esch–Cummins Act">
Esch–Cummins Act

The Transportation Act, 1920, commonly known as the Esch–Cummins Act, was a United States federal law that returned railroads to private operation after World War I, with much regulation. It also officially encouraged private consolidation of railroads and mandated that the Interstate Commerce Commission (ICC) ensure their profitability.
Background.
The United States had entered World War I in April 1917, and the government found that the nation's railroads were not prepared to serve the war effort. On December 26, 1917, President Woodrow Wilson had ordered that U.S. railroads be nationalized in the public interest. This order was implemented through the creation of the United States Railroad Administration. Congress ratified the order in the "Railway Administration Act of 1918."
Major provisions.
The Esch–Cummins Act:
Subsequent legislation.
Title III of the Esch–Cummins Act, which pertained to labor disputes, was repealed in 1926 by the Railway Labor Act.

</doc>
<doc id="55761" url="https://en.wikipedia.org/wiki?curid=55761" title="Volstead Act">
Volstead Act

The National Prohibition Act, known informally as the Volstead Act, was enacted to carry out the intent of the Eighteenth Amendment, which established prohibition in the United States. The Anti-Saloon League's Wayne Wheeler conceived and drafted the bill, which was named for Andrew Volstead, Chairman of the House Judiciary Committee, who managed the legislation.
Procedure.
While the Eighteenth Amendment to the United States Constitution prohibited the production, sale, and transport of "intoxicating liquors", it did not define "intoxicating liquors" or provide penalties. It granted both the federal government and the states the power to enforce the ban by "appropriate legislation." A bill to do so was introduced in Congress in 1919. Later this act was repealed by the Twenty-first amendment.
The bill was vetoed by President Woodrow Wilson, largely on technical grounds because it also covered wartime prohibition, but his veto was overridden by the House on the same day, October 27, 1919, and by the Senate one day later. The three distinct purposes of the Act were:
It provided further that "no person shall manufacture, sell, barter, transport, import, export, deliver, or furnish any intoxicating liquor except as authorized by this act." It did not specifically prohibit the use of intoxicating liquors. The act defined intoxicating liquor as any beverage containing more than 0.5% alcohol by volume and superseded all existing prohibition laws in effect in states that had such legislation.
Enforcement and impact.
The production, importation, and distribution of alcoholic beverages — once the province of legitimate business — were taken over by criminal gangs, which fought each other for market control in violent confrontations, including murder. Major gangsters, such as Omaha's Tom Dennison and Chicago's Al Capone, became rich and were admired locally and nationally. Enforcement was difficult because the gangs became so rich they were often able to bribe underpaid and understaffed law enforcement personnel and pay for expensive lawyers. Many citizens were sympathetic to bootleggers, and respectable citizens were lured by the romance of illegal speakeasies, also called "blind tigers". The loosening of social morals during the 1920s included popularizing the cocktail and the cocktail party among higher socio-economic groups. Those inclined to help authorities were often intimidated, even murdered. In several major cities — notably those that served as major points of liquor importation (including Chicago and Detroit) — gangs wielded significant political power. A Michigan State Police raid on Detroit's Deutsches Haus once netted the mayor, the sheriff, and the local congressman.
Prohibition came into force at midnight on January 17, 1920, and the first documented infringement of the Volstead Act occurred in Chicago on January 17 at 12:59 a.m. According to police reports, six armed men stole $100,000 worth of "medicinal" whiskey from two freight train cars. This trend in bootlegging liquor created a domino effect, with criminals across the United States. Some gang leaders were stashing liquor months before the Volstead Act was enforced. The ability to sustain a lucrative business in bootlegging liquor was largely helped by the minimal police surveillance at the time. There were only 134 agents designated by the Prohibition Unit to cover all of Illinois, Iowa, and parts of Wisconsin. According to Charles C. Fitzmorris, Chicago's Chief of Police during the beginning of the Prohibition period: "Sixty percent of my police in the bootleg business."
Section 29 of the Act allowed 200 gallons (the equivalent of about 1000 750 ml bottles) of "non-intoxicating cider and fruit juice" to be made each year at home. Initially "intoxicating" was defined as anything more than 0.5%, but the Bureau of Internal Revenue soon struck that down and this effectively legalized home wine-making. For beer, however, the 0.5% limit remained until 1933. Some vineyards embraced the sale of grapes for making wine at home; Zinfandel grapes were popular among home winemakers living near the vineyards, but its tight bunches left their thin skins vulnerable to rot, due to rubbing and abrasion, on the long journey to East Coast markets. The thick skins of Alicante Bouschet were less susceptible to rot, so this and similar varieties were widely planted for the home wine-making market.
The Act contained a number of exceptions and exemptions. Many of these were used to evade the law's intended purpose. For example, the Act allowed a physician to prescribe whiskey for his patients, but limited the amount that could be prescribed. Subsequently, the House of Delegates of the American Medical Association voted to submit to Congress a bill to remove the limit on the amount of whiskey that could be prescribed and questioning the ability of a legislature to determine the therapeutic value of any substance.
The Act called for trials for anyone charged with an alcohol-related offense, and juries often failed to convict. Under the state of New York's Mullan–Gage Act, a short-lived local version of the Volstead Act, the first 4,000 arrests led to just six convictions and not one jail sentence.
Repeal.
Prohibition lost advocates as ignoring the law gained increasing social acceptance and as organized crime violence increased. By 1933, public opposition to prohibition had become overwhelming. In March of that year, Congress passed the Cullen–Harrison Act, which legalized "3.2 beer" ("i.e.," beer containing 3.2% alcohol by weight or 4% by volume) and wines of similarly low alcohol content, rather than the 0.5% limit defined by the original Volstead Act.
Congress passed the Blaine Act, a proposed constitutional amendment to repeal the Eighteenth Amendment to end Prohibition, in February. On December 5, 1933, Utah became the 36th state to ratify the Twenty-first Amendment, which repealed the Eighteenth Amendment, voiding the Volstead Act, and restored control of alcohol to the states. The creation of the Federal Alcohol Administration in 1935 defined a modest role for the federal government with respect to alcohol and its taxation.

</doc>
<doc id="55762" url="https://en.wikipedia.org/wiki?curid=55762" title="Harmonic function">
Harmonic function

In mathematics, mathematical physics and the theory of stochastic processes, a harmonic function is a twice continuously differentiable function "f" : "U" → R (where "U" is an open subset of R"n") which satisfies Laplace's equation, i.e.
everywhere on "U". This is usually written as
or
Etymology of the term "harmonic".
The descriptor "harmonic" in the name harmonic function originates from a point on a taut string which is undergoing harmonic motion. This solution to the differential equation for this type of motion can be written in terms of sines and cosines, functions which are thus referred to as "harmonics". Fourier analysis involves expanding periodic functions on the unit circle in terms of a series of these harmonics. Considering higher dimensional analogues of the harmonics on the unit n-sphere, one arrives at the spherical harmonics. These functions satisfy Laplace's equation and over time "harmonic" was used to refer to all functions satisfying Laplace's equation.
Examples.
Examples of harmonic functions of two variables are:
Examples of harmonic functions of three variables are given in the table below with formula_9:
Harmonic functions that arise in physics are determined by their singularities and boundary conditions (such as Dirichlet boundary conditions or Neumann boundary conditions). On regions without boundaries, adding the real or imaginary part of any entire function will produce a harmonic function with the same singularity, so in this case the harmonic function is not determined by its singularities; however, we can make the solution unique in physical situations by requiring that the solution goes to 0 as you go to infinity. In this case, uniqueness follows by Liouville's theorem.
The singular points of the harmonic functions above are expressed as "charges" and "charge densities" using the terminology of electrostatics, and so the corresponding harmonic function will be proportional to the electrostatic potential due to these charge distributions. Each function above will yield another harmonic function when multiplied by a constant, rotated, and/or has a constant added. The inversion of each function will yield another harmonic function which has singularities which are the images of the original singularities in a spherical "mirror". Also, the sum of any two harmonic functions will yield another harmonic function.
Finally, examples of harmonic functions of "n" variables are:
Remarks.
The set of harmonic functions on a given open set "U" can be seen as the kernel of the Laplace operator Δ and is therefore a vector space over R: sums, differences and scalar multiples of harmonic functions are again harmonic.
If "f" is a harmonic function on "U", then all partial derivatives of "f" are also harmonic functions on "U". The Laplace operator Δ and the partial derivative operator will commute on this class of functions.
In several ways, the harmonic functions are real analogues to holomorphic functions. All harmonic functions are analytic, i.e. they can be locally expressed as power series. This is a general fact about elliptic operators, of which the Laplacian is a major example.
The uniform limit of a convergent sequence of harmonic functions is still harmonic. This is true because every continuous function satisfying the mean value property is harmonic. Consider the sequence on (−∞, 0) × R defined by formula_12. This sequence is harmonic and converges uniformly to the zero function; however note that the partial derivatives are not uniformly convergent to the zero function (the derivative of the zero function). This example shows the importance of relying on the mean value property and continuity to argue that the limit is harmonic.
Connections with complex function theory.
The real and imaginary part of any holomorphic function yield harmonic functions on R2 (these are said to be a pair of harmonic conjugate functions). Conversely, any harmonic function "u" on an open subset Ω of R2 is "locally" the real part of a holomorphic function. This is immediately seen observing that, writing "z" = "x" + "iy", the complex function "g"("z") := "ux" − i "uy" is holomorphic in Ω because it satisfies the Cauchy–Riemann equations. Therefore, "g" has locally a primitive "f", and "u" is the real part of "f" up to a constant, as "ux" is the real part of formula_13 .
Although the above correspondence with holomorphic functions only holds for functions of two real variables, harmonic functions in "n" variables still enjoy a number of properties typical of holomorphic functions. They are (real) analytic; they have a maximum principle and a mean-value principle; a theorem of removal of singularities as well as a Liouville theorem holds for them in analogy to the corresponding theorems in complex functions theory.
Properties of harmonic functions.
Some important properties of harmonic functions can be deduced from Laplace's equation.
Regularity theorem for harmonic functions.
Harmonic functions are infinitely differentiable. In fact, harmonic functions are real analytic.
Maximum principle.
Harmonic functions satisfy the following "maximum principle": if "K" is any compact subset of "U", then "f", restricted to "K", attains its maximum and minimum on the boundary of "K". If "U" is connected, this means that "f" cannot have local maxima or minima, other than the exceptional case where "f" is constant. Similar properties can be shown for subharmonic functions.
The mean value property.
If "B"("x", "r") is a ball with center "x" and radius "r" which is completely contained in the open set Ω ⊂ R"n", then the value "u"("x") of a harmonic function "u": Ω → R at the center of the ball is given by the average value of "u" on the surface of the ball; this average value is also equal to the average value of "u" in the interior of the ball. In other words
where ω"n" is the volume of the unit sphere in "n" dimensions and σ is the "n"-1 dimensional surface measure .
Conversely, all locally integrable functions satisfying the (volume) mean-value property are both infinitely differentiable and harmonic.
In terms of convolutions, if
denotes the characteristic function of the ball with radius "r" about the origin, normalized so that formula_16, the function "u" is harmonic on Ω if and only if
as soon as "B"("x", "r") ⊂ Ω.
Sketch of the proof. The proof of the mean-value property of the harmonic functions and its converse follows immediately observing that the non-homogeneous equation, for any 0 < "s" < "r"
admits an easy explicit solution "wr,s" of class "C"1,1 with compact support in "B"(0, "r"). Thus, if "u" is harmonic in Ω
holds in the set Ω"r" of all points "x" in formula_20 with formula_21 .
Since "u" is continuous in Ω, "u"*χ"r" converges to "u" as "s" → 0 showing the mean value property for "u" in Ω. Conversely, if "u" is any formula_22 function satisfying the mean-value property in Ω, that is,
holds in Ω"r" for all 0 < "s" < "r" then, iterating "m" times the convolution with χ"r" one has:
so that "u" is formula_25 because the m-fold iterated convolution of χ"r" is of class formula_26 with support "B"(0, "mr"). Since "r" and "m" are arbitrary, "u" is formula_27 too. Moreover
formula_28
for all 0 < "s" < "r" so that Δ"u" = 0 in Ω by the fundamental theorem of the calculus of variations, proving the equivalence between harmonicity and mean-value property.
This statement of the mean value property can be generalized as follows: If "h" is any spherically symmetric function supported in "B"("x","r") such that ∫"h" = 1, then "u"("x") = "h" * "u"("x"). In other words, we can take the weighted average of "u" about a point and recover "u"("x"). In particular, by taking "h" to be a "C"∞ function, we can recover the value of "u" at any point even if we only know how "u" acts as a distribution. See Weyl's lemma.
Harnack's inequality.
Let "u" be a non-negative harmonic function in a bounded domain Ω. Then for every connected set
Harnack's inequality 
holds for some constant "C" that depends only on "V" and Ω.
Removal of singularities.
The following principle of removal of singularities holds for harmonic functions. If "f" is a harmonic function defined on a dotted open subset formula_31 of R"n" , which is less singular at "x"0 than the fundamental solution, that is
then "f" extends to a harmonic function on Ω (compare Riemann's theorem for functions of a complex variable).
Liouville's theorem.
If "f" is a harmonic function defined on all of R"n" which is bounded above or bounded below, then "f" is constant (compare Liouville's theorem for functions of a complex variable).
Edward Nelson gave a particularly short proof of this theorem, using the mean value property mentioned above: 
Given two points, choose two balls with the given points as centers and of equal radius. If the radius is large enough, the two balls will coincide except for an arbitrarily small proportion of their volume. Since "f" is bounded, the averages of it over the two balls are arbitrarily close, and so "f" assumes the same value at any two points. 
Generalizations.
Weakly harmonic function.
A function (or, more generally, a distribution) is weakly harmonic if it satisfies Laplace's equation
in a weak sense (or, equivalently, in the sense of distributions). A weakly harmonic function coincides almost everywhere with a strongly harmonic function, and is in particular smooth. A weakly harmonic distribution is precisely the distribution associated to a strongly harmonic function, and so also is smooth. This is Weyl's lemma.
There are other weak formulations of Laplace's equation that are often useful. One of which is Dirichlet's principle, representing harmonic functions in the Sobolev space "H"1(Ω) as the minimizers of the Dirichlet energy integral
with respect to local variations, that is, all functions formula_35 such that "J"("u") ≤ "J"("u" + "v") holds for all formula_36 or equivalently, for all formula_37
Harmonic functions on manifolds.
Harmonic functions can be defined on an arbitrary Riemannian manifold, using the Laplace–Beltrami operator Δ. In this context, a function is called "harmonic" if 
Many of the properties of harmonic functions on domains in Euclidean space carry over to this more general setting, including the mean value theorem (over geodesic balls), the maximum principle, and the Harnack inequality. With the exception of the mean value theorem, these are easy consequences of the corresponding results for general linear elliptic partial differential equations of the second order.
Subharmonic functions.
A "C"2 function that satisfies Δ"f" ≥ 0 is called subharmonic. This condition guarantees that the maximum principle will hold, although other properties of harmonic functions may fail. More generally, a function is subharmonic if and only if, in the interior of any ball in its domain, its graph lies below that of the harmonic function interpolating its boundary values on the ball.
Harmonic forms.
One generalization of the study of harmonic functions is the study of harmonic forms on Riemannian manifolds, and it is related to the study of cohomology. Also, it is possible to define harmonic vector-valued functions, or harmonic maps of two Riemannian manifolds, which are critical points of a generalized Dirichlet energy functional (this includes harmonic functions as a special case, a result known as Dirichlet principle). This kind of harmonic maps appear in the theory of minimal surfaces. For example, a curve, that is, a map from an interval in R to a Riemannian manifold, is a harmonic map if and only if it is a geodesic.
Harmonic maps between manifolds.
If "M" and "N" are two Riemannian manifolds, then a harmonic map is defined to be a critical point of the Dirichlet energy
in which is the differential of "u", and the norm is that induced by the metric on "M" and that on "N" on the tensor product bundle "T"*"M" ⊗ "u"−1 "TN".
Important special cases of harmonic maps between manifolds include minimal surfaces, which are precisely the harmonic immersions of a surface into three-dimensional Euclidean space. More generally, minimal submanifolds are harmonic immersions of one manifold in another. Harmonic coordinates are a harmonic diffeomorphism from a manifold to an open subset of a Euclidean space of the same dimension.

</doc>
<doc id="55766" url="https://en.wikipedia.org/wiki?curid=55766" title="Norris–La Guardia Act">
Norris–La Guardia Act

The Norris–La Guardia Act (also known as the Anti-Injunction Bill) was a 1932 United States federal law that banned yellow-dog contracts, barred the federal courts from issuing injunctions against nonviolent labor disputes, and created a positive right of noninterference by employers against workers joining trade unions. The common title comes from the names of the sponsors of the legislation: Senator George W. Norris of Nebraska and Representative Fiorello H. La Guardia of New York, both Republicans.
History.
It is formally the Act of March 23, 1932 (Ch. 90, ). It is currently codified at , starting at et. seq.
Overview.
The Act states that yellow-dog contracts, where workers agree as a condition of employment to not join a labor union, are unenforceable in federal court. It also establishes that employees are free to form unions without employer interference and prevents the federal courts from issuing injunctions in nonviolent labor disputes. The three provisions include protecting worker's self-organization and liberty or "collective bargaining", removing jurisdiction from federal courts vis-a-vis the issuance of injunctions in non-violent labor disputes, and outlawing the "yellow-dog" contract.
Section 13A of the act was fully applied by the Supreme Court of the United States with a 1938 decision, "New Negro Alliance v. Sanitary Grocery Co.", in an opinion authored by Justice Owen Roberts. The Court held that the act meant to prohibit employers from proscribing the peaceful dissemination of information concerning the "terms and conditions of employment" by those involved in an active labor dispute, even when such dissemination occurs on an employer's private property.
Trivia.
The Living Theater play "Injunction Granted" features a scene in which a judge grants injunctions against many trade unions. There follows a scene in which the Norris - La Guardia Act is passed.

</doc>
<doc id="55769" url="https://en.wikipedia.org/wiki?curid=55769" title="Public Works Administration">
Public Works Administration

Public Works Administration (PWA), part of the New Deal of 1933, was a large-scale public works construction agency in the United States headed by Secretary of the Interior Harold L. Ickes. It was created by the National Industrial Recovery Act in June 1933 in response to the Great Depression. It built large-scale public works such as dams, bridges, hospitals, and schools. Its goals were to spend $3.3 billion in the first year, and $6 billion in all, to provide employment, stabilize purchasing power, and help revive the economy. Most of the spending came in two waves in 1933-35, and again in 1938. Originally called the Federal Emergency Administration of Public Works, it was renamed the Public Works Administration in 1935 and shut down in 1944.
The PWA spent over $6 billion in contracts to private construction firms that did the actual work. It created an infrastructure that generated national and local pride in the 1930s and remains vital seven decades later. The PWA was much less controversial than its rival agency with a confusingly similar name, the Works Progress Administration (WPA), headed by Harry Hopkins, which focused on smaller projects and hired unemployed unskilled workers.
Origins.
Frances Perkins had first suggested a federally financed public works program, and the idea received considerable support from Harold L. Ickes, James Farley, and Henry Wallace. After having scaled back the initial cost of the PWA, Franklin Delano Roosevelt agreed to include the PWA as part of his New Deal proposals in the "Hundred Days" of spring 1933.
Projects.
The PWA headquarters in Washington planned projects, which were built by private construction companies hiring workers on the open market. Unlike the WPA, it did not hire the unemployed directly.
More than any other New Deal program, the PWA epitomized the progressive notion of "priming the pump" to encourage economic recovery. Between July 1933 and March 1939 the PWA funded and administered the construction of more than 34,000 projects including airports, large electricity-generating dams, major warships for the Navy, and bridges, as well as 70% of the new schools and one-third of the hospitals built in 1933–1939.
Streets and highways were the most common PWA projects, as 11,428 road projects, or 33% of all PWA projects, accounted for over 15% of its total budget. School buildings, 7,488 in all, came in second at 14% of spending. PWA functioned chiefly by making allotments to the various Federal agencies; making loans and grants to state and other public bodies; and making loans without grants (for a brief time) to the railroads. For example, it provided funds for the Indian Division of the CCC to build roads, bridges and other public works on and near Indian reservations.
The PWA became, with its ""multiplier-effect"" and first two-year budget of $3.3 billion (compared to the entire GDP of $60 billion), the driving force of America’s biggest construction effort up to that date. By June 1934, the agency had distributed its entire fund to 13,266 federal projects and 2,407 non-federal projects. For every worker on a PWA project, almost two additional workers were employed indirectly. The PWA accomplished the electrification of rural America, the building of canals, tunnels, bridges, highways, streets, sewage systems, and housing areas, as well as hospitals, schools, and universities; every year it consumed roughly half of the concrete and a third of the steel of the entire nation. The PWA also electrified the Pennsylvania Railroad between New York and Washington, DC. At the local level it built courthouses, schools, hospitals and other public facilities that remain in use in the 21st century.
Housing.
The PWA was the centerpiece of the New Deal program for building public housing for the poor people in cities. However it did not create as much affordable housing as supporters would have hoped, building only 29,000 units in years.
Criticism.
The PWA spent over $6 billion, but did not succeed in returning the level of industrial activity to pre-depression levels. Though successful in many aspects, it has been acknowledged that the PWA's objective of constructing a substantial number of quality, affordable housing was a major failure. Some have argued that because Roosevelt was opposed to deficit spending, there was not enough money spent to help the PWA achieve its housing goals.
Reeves (1973) argues that the competitive theory of administration used by Roosevelt proved to be inefficient and produced delays. The competition over the size of expenditure, the selection of the administrator, and the appointment of staff at the state level, led to delays and to the ultimate failure of PWA as a recovery instrument. As director of the budget, Lewis Douglas overrode the views of leading senators in reducing appropriations to $3.5 billion and in transferring much of that money to other agencies in lieu of their own specific appropriations. The cautious and penurious Ickes won out over the more imaginative Hugh S. Johnson as chief of public works administration. Political competition between rival Democratic state organizations and between Democrats and Progressive Republicans led to delays in implementing PWA efforts on the local level. Ickes instituted quotas for hiring skilled and unskilled blacks in construction financed through the Public Works Administration (PWA). Resistance from employers and unions was partially overcome by negotiations and implied sanctions. Although results were ambiguous, the plan helped provide African Americans with employment, especially among unskilled workers.
Termination.
When President Franklin D. Roosevelt moved industry toward World War II production, the PWA was abolished and its functions were transferred to the Federal Works Agency in June 1943.
Contrast with WPA.
The PWA should not be confused with its great rival the Works Progress Administration (WPA), though both were part of the New Deal. The WPA, headed by Harry Hopkins, engaged in smaller projects in close cooperation with local governments—such as building a city hall or sewers or sidewalks. The PWA projects were much larger in scope, such as giant dams. The WPA hired only people on relief who were paid directly by the federal government. The PWA gave contracts to private firms who did all the hiring on the private sector job market. The WPA also had youth programs (the NYA), projects for women, and arts projects that the PWA did not have.

</doc>
